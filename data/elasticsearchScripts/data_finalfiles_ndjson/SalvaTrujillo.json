{"title": "Real-time predictive maintenance for wind turbines using Big Data frameworks\n", "abstract": " This work presents the evolution of a solution for predictive maintenance to a Big Data environment. The proposed adaptation aims for predicting failures on wind turbines using a data-driven solution deployed in the cloud and which is composed by three main modules. (i) A predictive model generator which generates predictive models for each monitored wind turbine by means of Random Forest algorithm. (ii) A monitoring agent that makes predictions every 10 minutes about failures in wind turbines during the next hour. Finally, (iii) a dashboard where given predictions can be visualized. To implement the solution Apache Spark, Apache Kafka, Apache Mesos and HDFS have been used. Therefore, we have improved the previous work in terms of data process speed, scalability and automation. In addition, we have provided fault-tolerant functionality with a centralized access point from where the status of all the\u00a0\u2026", "num_citations": "118\n", "authors": ["1529"]}
{"title": "Visualizing Software Product Line Variabilities in Source Code.\n", "abstract": " Implementing software product lines is a challenging task. Depending on the implementation technique the code that realizes a feature is often scattered across multiple code units. This way it becomes difficult to trace features in source code which hinders maintenance and evolution. While previous effort on visualization technologies in software product lines has focused mainly on the feature model, we suggest tool support for feature traceability in the code base. With our tool CIDE, we propose an approach based on filters and views on source code in order to visualize and trace features in source code.", "num_citations": "90\n", "authors": ["1529"]}
{"title": "Multipartes: Multicore virtualization for mixed-criticality systems\n", "abstract": " Modern embedded applications typically integrate a multitude of functionalities with potentially different criticality levels into a single system. Without appropriate preconditions, the integration of mixed-criticality subsystems can lead to a significant and potentially unacceptable increase of engineering and certification costs. A promising solution is to incorporate mechanisms that establish multiple partitions with strict temporal and spatial separation between the individual partitions. In this approach, subsystems with different levels of criticality can be placed in different partitions and can be verified and validated in isolation. The MultiPARTES FP7 project aims at supporting mixed-criticality integration for embedded systems based on virtualization techniques for heterogeneous multicore processors. A major outcome of the project is the MultiPARTES XtratuM, an open source hyper visor designed as a generic\u00a0\u2026", "num_citations": "69\n", "authors": ["1529"]}
{"title": "MultiPARTES: Multi-core partitioning and virtualization for easing the certification of mixed-criticality systems\n", "abstract": " The consumer market is continuously pushing for smarter, faster, more durable and cheaper products with ever more complex and sophisticated functionality. Other fields such as safety\u2013critical and dependable applications are not unaware of these requirements, and even impose others (e.g. certification). In the current multi-core era, industry and research entities are facing the important challenge of fulfilling all these requirements, which often impose the necessity for integrating components with different levels of dependability in a single hardware platform. In this scenario, new concerns appear with respect to safety certification of the resulting mixed-criticality systems (e.g. temporal and spatial isolation). This article describes the research effort that is being conducted within the FP7 MultiPARTES project, which is one of the initiatives launched by the European Commission to explore new solutions for developing\u00a0\u2026", "num_citations": "39\n", "authors": ["1529"]}
{"title": "Automated model merge by design space exploration\n", "abstract": " Industrial applications of model-driven engineering to develop large and complex systems resulted in an increasing demand for collaboration features. However, use cases such as model differencing and merging have turned out to be a difficult challenge, due to (i) the graph-like nature of models, and (ii) the complexity of certain operations (e.g. hierarchy refactoring) that are common today. In the paper, we present a novel search-based automated model merge approach where rule-based design space exploration is used to search the space of solution candidates that represent conflict-free merged models. Our method also allows engineers to easily incorporate domain-specific knowledge into the merge process to provide better solutions. The merge process automatically calculates multiple merge candidates to be presented to domain experts for final selection. Furthermore, we propose to adopt a\u00a0\u2026", "num_citations": "38\n", "authors": ["1529"]}
{"title": "On the modularization of feature models\n", "abstract": " Feature Models (FM) are used to represent commonality and variability in Software Product Lines. Since the first proposal by Kang, the notation of FM has evolved in different ways: introducing cardinalities, using UML or XML notations, etcetera. In addition, the use of FMs is not only restricted to domain analysis because it is widely accepted that FMs can be used in different stages of SPL development in order to produce other assets such as requirements documents, architectures, reasoning frameworks or even pieces of code. Hence, FMs turn into an important focus of research in the field of model transformation. In this context, two characteristics are needed: i) an agreed base faeture model and ii) a platform independent representation allowing extensions for specific needs. In this paper we propose an abstract feature model, providing an XML representation and mechanisms to extend this model for a particular approach. Therefore, the contribution of this work is the modularization of the FM in order to cope with distinct development stages.", "num_citations": "35\n", "authors": ["1529"]}
{"title": "Context-aware staged configuration of process variants@ Runtime\n", "abstract": " Process-based context-aware applications are increasingly becoming more complex and dynamic. Besides the large sets of process variants to be managed in such dynamic systems, process variants need to be context sensitive in order to accommodate new user requirements and intrinsic complexity. This paradigm shift forces us to defer decisions to runtime where process variants must be customized and executed based on a recognized context. However, there exists a lack of deferral of the entire process variant configuration and execution to perform an automated decision of subsequent variation points at runtime. In this paper, we present a holistic methodology to automatically resolve process variability at runtime. The proposed solution performs a staged configuration considering static and dynamic context data to accomplish effective decision making. We demonstrate our approach by exemplifying\u00a0\u2026", "num_citations": "25\n", "authors": ["1529"]}
{"title": "A safety concept for a wind power mixed-criticality embedded system based on multicore partitioning\n", "abstract": " The development of mixed-criticality systems that integrate applications of different criticality levels (safety, security, real-time and non real-time) can provide multiple benefits such as product cost-size-weight reduction, reliability increase and scalability. However, the integration of applications of different levels of criticality leads to several challenges with respect to safety certification standards.", "num_citations": "25\n", "authors": ["1529"]}
{"title": "European project cluster on mixed-criticality systems\n", "abstract": " Modern embedded applications already integrate a multitude of functionalities with potentially different criticality levels into a single system and this trend is expected to grow in the near future. Without appropriate preconditions, the integration of mixed-criticality subsystems can lead to a significant and potentially unacceptable increase of engineering and certification costs. There are several ongoing research initiatives studying mixedcriticality integration in multicore processors. Key challenges are the combination of software virtualization and hardware segregation and the extension of partitioning mechanisms jointly addressing significant extra-functional requirements (eg, time, energy and power budgets, adaptivity, reliability, safety, security, volume, weight, etc.) along with development and certification methodology. This paper provides a summary of the challenges to be addressed in the design and development of future mixedcriticality systems and the way in which some current European Projects on the topic address those challenges.", "num_citations": "19\n", "authors": ["1529"]}
{"title": "A safety concept for an IEC-61508 compliant fail-safe wind power mixed-criticality system based on multicore and partitioning\n", "abstract": " The development of mixed-criticality systems that integrate applications of different criticality levels (safety, security, real-time and non-real time) in a single embedded system can provide multiple benefits such as product cost-size-weight reduction, reliability increase and scalability. However, the integration of applications of different levels of criticality in a single embedded system leads to several challenges with respect to safety certification standards. This research paper describes a safety concept for a fail-safe wind turbine mixed-criticality control system based on multicore partitioning that meets IEC-61508 and ISO-13849 industrial safety standards. The safety concept has been positively assessed by a certification body.", "num_citations": "17\n", "authors": ["1529"]}
{"title": "Towards a unified meta-model for resources-constrained embedded systems\n", "abstract": " The complexity in embedded systems is increasing steadily due to richer functionalities offered by more powerful hardware to attain market demands. Model Driven Engineering(MDE) is a promising approach for handling this complexity by using models which help to capture several concerns of these systems. In this paper we analyze the modeling of embedded systems that have restrictions on memory, autonomy, and/or computation processing which refer to RCES (Resources-Constrained Embedded Systems). In particular we study existing works including those from standards and industry such as MARTE, SysML and AADL. The first step is to encompass the different concepts introduced in these works to capture computations and resources. This yields a homogeneous formalism to model RCES and we will propose this formalism as a meta-model. In the same way we propose a modeling framework based on\u00a0\u2026", "num_citations": "16\n", "authors": ["1529"]}
{"title": "Flexible and Scalable Modelling in the MONDO Project: Industrial Case Studies.\n", "abstract": " Today, system designs and their management are crucial parts of most systems development processes. To stay competitive engineers from several expertise domains use Model-Based engineering (MBE) to design the systems they intend to implement in order to specify, test, simulate, validate and iterate their design as soon as possible. System designs are living and evolving artefacts this imply to be able to manage them in an efficient and agile way. The MONDO FP7 EU project aims to comprehensively tackle the challenge of scalability in system design and management by developing the theoretical foundations and an open-source implementation of a platform and will offer to Model-Driven Engineering (MDE) users advanced flexibility in their different modeling approaches. This paper describes three different industrial demonstrators and three different modelling approaches that will be utilised to evaluate the capabilities of the MONDO technologies. For each demonstrator the interests of the industrial user partners are described along with their current and desired improvements in technologies to support MBE in a much more flexible way. Specific evaluation scenarios are specified for each of the targeted industrial domains as well.", "num_citations": "10\n", "authors": ["1529"]}
{"title": "Run-time variability for context-aware smart workflows\n", "abstract": " In variant-rich workflow-based systems, a major concern for process variability is the context-aware configuration of the variants. This means that context information, not users, drives process configuration. To support context-aware process configuration in a dynamic environment, in which context information is available only at run time, smart workflows must be customized at run time. The LateVa (Late Variability for Context-Aware Smart Workflows) framework lets developers model and manage process variability by composing base models, fragments, and variability models and by deferring binding to run time. Base models and fragments are reusable, thereby reducing the modeling effort for developing variants. LateVa also includes an automated run-time-variability mechanism for context-aware smart workflows.", "num_citations": "9\n", "authors": ["1529"]}
{"title": "MQT, an Approach for Run-Time Query Translation: From EOL to SQL.\n", "abstract": " Managing models requires extracting information from them and modifying them, and this is performed through queries. Queries can be executed at the model or at the persistence-level. Both are complementary but while model-level queries are closer to modelling engineers, persistence-level queries are specific to the persistence technology and leverage its capabilities. This paper presents MQT, an approach that translates EOL (model-level queries) to SQL (persistence-level queries) at runtime. Runtime translation provides several benefits:(i) queries are executed only when the information is required;(ii) context and metamodel information is used to get more performant translated queries; and (iii) supports translating query programs using variables and dependant queries. Translation process used by MQT is described through two examples and we also evaluate performance of the approach.", "num_citations": "9\n", "authors": ["1529"]}
{"title": "Process flexibility in service orchestration: A systematic literature review\n", "abstract": " In dynamic environments, changes are often unpredictable and complex. Process models cannot be fully specified up-front and process flexibility becomes a key issue. Enterprise applications and systems supporting such processes are increasingly being architected in a service-oriented style. In this light, our goal is to analyze service orchestration approaches from a process flexibility perspective. Through a systematic literature review, we evaluate 17 service orchestration approaches and analyze their support for: (i) variability, support for large collections of process variants, (ii) adaptation, need for instance changes during runtime, (iii) evolution, need for schema changes during runtime, and (iv) looseness, need for loosely-specified models. The review findings provide a clearer understanding of process flexibility requirements and service orchestration mechanisms that support them, helping us to understand the\u00a0\u2026", "num_citations": "8\n", "authors": ["1529"]}
{"title": "Model query translator: A model-level query approach for large-scale models\n", "abstract": " Persisting and querying models larger than a few tens of megabytes using XML introduces a significant time and memory footprint overhead to MDD workflows. In this paper, we present an approach that attempts to address this issue using an embedded relational database as an alternative persistence layer for EMF models, and runtime translation of OCL-like expressions for efficiently querying such models. We have performed an empirical study of the approach using a set of large-scale reverse engineered models and queries from the Grabats 2009 Reverse Engineering Contest. Main contribution of this paper is the Model Query Translator, an approach that translates (and executes) at runtime queries from model-level (EOL) to persistence-level (SQL).", "num_citations": "7\n", "authors": ["1529"]}
{"title": "Process variability through automated late selection of fragments\n", "abstract": " Process-aware information systems must encompass business process flexibility support due to business needs and factors coming from assorted sources, changing market conditions, customer needs, and regulations. However, flexibility may not be always achieved by pre-specified processes whereby, when context information is only available at runtime, decision making should be deferred to execution time. The late selection pattern defers the selection of placeholder activities\u2019 implementations, binding applicable process fragments at runtime. This paper presents the foundations of a novel approach for an end-to-end variability management of process models through late selection of fragments by means of: (i) managing process fragments separately from the base model, (ii) resolving variation points automatically considering constraints and context data at runtime, and (iii) enabling process fragment\u00a0\u2026", "num_citations": "7\n", "authors": ["1529"]}
{"title": "Feature-oriented refinement of models, metamodels and model transformations\n", "abstract": " Done well, the blend of Model Driven Development (MDD) and Software Product Lines (SPL) offers a promising approach, mixing abstraction from MDD and variability from SPL. Although Model Driven Product Lines have flourished recently, the focus so far has been mostly on how to cope with the variability of models. This focus on model variability has limited however the extension of variability to further artifacts apart from models such as metamodels and model transformations, that may cope with variability too in a product line setting. In this paper, we address the application of feature-oriented refinement to models, metamodels and model transformations. We illustrate our work with a case study of an embedded system.", "num_citations": "7\n", "authors": ["1529"]}
{"title": "On the support of multi-perspective process models variability for smart environments\n", "abstract": " Cloud service-based applications are to be adapted to serve multiple platforms and stakeholders. Atop of such services, Smart Green Buildings are fostering a plethora of processes within their sustainability life-cycle. This introduces a number of challenges, as how to support multiple perspectives of domain-specific variability and how to deal with large collections of related process variants. To tackle this, there is a need to handle multi-perspective variability for processes. This paper introduces an approach to manage multi-perspective process variability by means of a meta-model and a modeling methodology, representing separately people and things variability perspectives in smart environments. Initial experimental results are also described, which indicate encouraging results for managing highly complex variability models.", "num_citations": "4\n", "authors": ["1529"]}
{"title": "Towards model-driven engineering for mixed-criticality systems: Multipartes approach\n", "abstract": " Mixed criticality systems emerges as a suitable solution for dealing with the complexity, performance and costs of future embedded and dependable systems. However, this paradigm adds additional complexity to their development. This paper proposes an approach for dealing with this scenario that relies on hardware virtualization and Model-Driven Engineering (MDE). Hardware virtualization ensures isolation between subsystems with different criticality levels. MDE is intended to bridge the gap between design issues and partitioning concerns. MDE tooling will enhance the functional models by annotating partitioning and extra-functional properties. System partitioning and subsystems allocation will be generated with a high degree of automation. System configuration will be validated for ensuring that the resources assigned to a partition are sufficient for executing the allocated software components and that time requirements are met.", "num_citations": "4\n", "authors": ["1529"]}
{"title": "Drain: An engine for quality-of-result driven process-based data analytics\n", "abstract": " The analysis of massive amounts of diverse data provided by large cities, combined with the requirements from multiple domain experts and users, is becoming a challenging trend. Although current process-based solutions rise in data awareness, there is less coverage of approaches dealing with the Quality-of-Result (QoR) to assist data analytics in distributed data-intensive environments. In this paper, we present the fundamental building blocks of a framework for enabling process selection and configuration through user-defined QoR at runtime. These building blocks form the basis to support modeling, execution and configuration of data-aware process variants in order to perform analytics. They can be integrated with different underlying APIs, promoting abstraction, QoR-driven data interaction and configuration. Finally, we carry out a preliminary evaluation on the URBEM scenario, concluding that our\u00a0\u2026", "num_citations": "3\n", "authors": ["1529"]}
{"title": "On the Refinement of Model-to-Text Transformations.\n", "abstract": " Model Driven Development (MDD) is a paradigm to automate the generation of code. A key artifact in this paradigm is a model transformation which defines the mappings from a model to another model or even a code artifact. Although MDD was initially aimed at the generation of an individual program, shortly after appeared the need for families of programs. Hence, the combination of Model Driven and Software Product Lines (SPL) appears as a promising paradigm. Most of the previous work was focused on the necessity to support variability on models, but little work has been done so far on supporting the variability of remaining MDD artifacts such as model transformations or metamodels. This work first motivates the need for variability of model transformations. We address then the application of step-wise refinement to model-to-text transformations expressed in MOFScript. We illustrate this with a case study.", "num_citations": "3\n", "authors": ["1529"]}
{"title": "Tracking the Evolution of Feature Oriented Product Lines.\n", "abstract": " Families of programs are steadily emerging in assorted domains where Software Product Line (SPL) paradigm provides a cost-effective development approach. Feature Oriented Programming (FOP) is a specific approach to SPL development where features not only sketch increments in program functionality, but are the building blocks of programs. There exists some analysis on the evolution of SPL (eg new feature requirements, technical changes, etc), but do not specifically provide a model to track the milestones of such variability evolution. This paper explores evolution tracking in the context of existing approaches. We track the evolution of Feature Oriented Product-Lines by differentiating the changes from a change base, storing only the deltas.", "num_citations": "3\n", "authors": ["1529"]}
{"title": "Runtime translation of model-level queries to persistence-level\n", "abstract": " Different studies have proved that XMI (default persistence in Eclipse Modelling Framework) has some limitations when operating with large models. Recent approaches propose databases for persistence of models. Therefore, persistence level languages could be used to efficiently query models. While persistence level languages increase performance as they take advantages of underlying databases, they compromise usability for model engineers. Model engineers are familiar with model-level query languages (e.g. EOL or OCL). We present MQT (Model Query Translator), a runtime translation of model-level to persistence-level queries. Thus, we provide model engineers the usability of a model level language but also take advantage of performance optimization of databases. We have performed an empirical study of the approach using the GraBaTs 2009 case study (models from 8.8\u00a0MB to 646\u00a0MB\u00a0\u2026", "num_citations": "2\n", "authors": ["1529"]}
{"title": "Two-step transformation of model traversal eol queries for large cdo repositories\n", "abstract": " Recent approaches persist models in databases to overcome performance and memory limitations of XMI. Among them, Connected Data Objects (CDO) is a database-based model repository widely used in Model Based Engineering by academia and industry. Model traversal queries are intensively used in modelling scenarios and their performance greatly impacts tools performance and user experience. In this paper, we introduce the CDO-QT framework to transform model traversal queries from Epsilon Object Language (EOL) into SQL queries and execute them at CDO repositories. This way, model engineers can define queries using domain concepts at performance similar to SQL. We have evaluated CDO-QT executing a set of queries over repositories from 15\u00a0MB to 5\u00a0GB size. CDO-QT results in better performance and memory consumption with respect to other approaches (Plain EMF, MDT OCL\u00a0\u2026", "num_citations": "1\n", "authors": ["1529"]}
{"title": "Supporting CRUD model operations from EOL to SQL\n", "abstract": " Model-based software development promises improvements in terms of quality and cost by raising the abstraction level of the development from code to models, but also requires mature techniques and tools. Although Eclipse Modelling Framework (EMF) introduces a default persistence mechanism for models, namely XMI, its usage is often limited as model size increases. To overcome this limitation, during the last years alternative persistence mechanisms have been proposed in order to store models in RDBMS and NoSQL databases. Under this new paradigm, model operations can be performed at model-level and persistence-level, e.g., mapping EOL model operations into SQL statements. In this paper, we extend our framework (called MQT) to support CRUD (Create, Read, Update and Delete) operations from model-(EOL) to persistence-level (SQL), using a streaming execution of queries at run-time. Through\u00a0\u2026", "num_citations": "1\n", "authors": ["1529"]}
{"title": "Scalable Model Edition, Query and Version Control Through Embedded Database Persistence.\n", "abstract": " Persisting and managing models larger than a few tens of megabytes using XMI introduces a significant time and memory footprint overhead to MDE workflows. Several approaches provide alternative persistence mechanisms based on databases that can be integrated with EMF. However, to the best of our knowledge there is less coverage of approaches on models persistence which include model querying, versioning and edition capabilities leveraging persistence capabilities. In this poster we present an approach that provides model persistence based on embedded databases. This approach aims to provide scalability through model edition, querying and versioning mechanisms that leverage database capabilities.", "num_citations": "1\n", "authors": ["1529"]}