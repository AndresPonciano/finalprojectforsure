{"title": "Metaheuristic optimization frameworks: a survey and benchmarking\n", "abstract": " This paper performs an unprecedented comparative study of Metaheuristic optimization frameworks. As criteria for comparison a set of 271 features grouped in 30 characteristics and 6 areas has been selected. These features include the different metaheuristic techniques covered, mechanisms for solution encoding, constraint handling, neighborhood specification, hybridization, parallel and distributed computation, software engineering best practices, documentation and user interface, etc. A metric has been defined for each feature so that the scores obtained by a framework are averaged within each group of features, leading to a final average score for each framework. Out of 33 frameworks ten have been selected from the literature using well-defined filtering criteria, and the results of the comparison are analyzed with the aim of identifying improvement areas and gaps in specific frameworks and the\u00a0\u2026", "num_citations": "185\n", "authors": ["316"]}
{"title": "On the definition and design-time analysis of process performance indicators\n", "abstract": " A key aspect in any process-oriented organisation is the evaluation of process performance for the achievement of its strategic and operational goals. Process Performance Indicators (PPIs) are a key asset to carry out this evaluation, and, therefore, having an appropriate definition of these PPIs is crucial. After a careful review of the literature related and a study of the current picture in different real organisations, we conclude that there not exists any proposal that allows to define PPIs in a way that is unambiguous and highly expressive, understandable by technical and non-technical users and traceable with the Business Process (BP). In addition, like other activities carried out during the BP lifecycle, the management of PPIs is considered time-consuming and error-prone. Therefore, providing an automated support for them is very appealing from a practical point of view.In this paper, we propose the PPINOT\u00a0\u2026", "num_citations": "149\n", "authors": ["316"]}
{"title": "A requirements elicitation approach based in templates and patterns\n", "abstract": " One of the main problems of requirements elicitation is expressing customer requirements in a form that can be understood not only by requirements engineers but also by noncomputer professional customers and users. The usual choice for expressing elicited requirements is natural language, since it is frequently the only common language to all participants. Problems of natural language are well\u2013known, but using more formal notations too early is a risky choice that can make requirements impossible to understand for customers and users. Moreover, requirements engineers do not usually have good writing skills, and sometimes semantically correct requirements, expressed in natural language, are not understood because of the way they are written. in this paper, we present requirements templates that can improve requirements elicitation and expression, and two kinds of patterns: linguistic patterns, which are very used sentences in natural language requirements descriptions that can be parameterized and integrated into templates, and requirements patterns, which are generic requirements templates that are found very often during the requirements elicitation process and that can be reused with some adaptation.", "num_citations": "145\n", "authors": ["316"]}
{"title": "Predictive monitoring of business processes: a survey\n", "abstract": " Nowadays, process mining is becoming a growing area of interest in business process management (BPM). Process mining consists in the extraction of information from the event logs of a business process. From this information, we can discover process models, monitor and improve our processes. One of the applications of process mining, is the predictive monitoring of business process. The aim of these techniques is the prediction of quantifiable metrics of a running process instance with the generation of predictive models. The most representative approaches for the runtime prediction of business process are summarized in this paper. The different types of computational predictive methods, such as statistical techniques or machine learning approaches, and certain aspects as the type of predicted values and quality evaluation metrics, have been considered for the categorization of these methods. This paper\u00a0\u2026", "num_citations": "126\n", "authors": ["316"]}
{"title": "Improving the automatic procurement of web services using constraint programming\n", "abstract": " Software solutions to automate the procurement of web services are gaining importance when technology evolves, the number of providers increases and the needs of the clients become more complex. There are several proposals in this field, but they all have important drawbacks, namely: many of them are not able to check offers and demands for internal consistency; selecting the best offer usually relies on evaluating linear objective functions, which is quite a naive solution; the language to express offers is usually less expressive than the language to express demands; and, last but not least, providers cannot impose constraints on their clients. In this article, we present a solution to overcome these problems that relies on constraint programming; furthermore, we present a run-time framework, some experimental results, and a comparison with other proposals.", "num_citations": "123\n", "authors": ["316"]}
{"title": "Using Constraint Programming to Reason on Feature Models\n", "abstract": " Feature models have been cited as one of the main contributions to model software product families. However, there is still a gap in product family engineering which is the automated reasoning on feature models. in this paper we describe how to reason on feature models using constraint programming. Although, there are a few attempts to reason on feature models there are two main drawbacks in these proposals: none of them associate parameters to features none of them use constraint programming as the reasoning base. Using constraint programming endows our proposal with a more powerful reasoning capacity and greater expressiveness than others.", "num_citations": "120\n", "authors": ["316"]}
{"title": "Defining process performance indicators: An ontological approach\n", "abstract": " It is increasingly important to evaluate the performance of business processes. A key instrument to carry out this evaluation is by means of Process Performance Indicators (PPIs) as suggested in many methodologies and frameworks like, for instance, COBIT, ITIL or EFQM. As a consequence, it is convenient to integrate the management of PPIs into the whole business process lifecycle from its design to its evaluation. In this paper, we focus on the definition of PPIs as a necessary step to achieve that integration. Unfortunately, current proposals are not able to specify several usual types of PPIs, specially those related to data, and are not well designed to enable the automated analysis of PPIs at design-time. In this paper, we present an ontology for the definition of process performance indicators that overcomes this issue, explicitly defines the relationships between the indicators and the elements defined in a\u00a0\u2026", "num_citations": "103\n", "authors": ["316"]}
{"title": "Quality-aware analysis in product line engineering with the orthogonal variability model\n", "abstract": " Software product line engineering is about producing a set of similar products in a certain domain. A variability model documents the variability amongst products in a product line. The specification of variability can be extended with quality information, such as measurable quality attributes (e.g., CPU and memory consumption) and constraints on these attributes (e.g., memory consumption should be in a range of values). However, the wrong use of constraints may cause anomalies in the specification which must be detected (e.g., the model could represent no products). Furthermore, based on such quality information, it is possible to carry out quality-aware analyses, i.e., the product line engineer may want to verify whether it is possible to build a product that satisfies a desired quality. The challenge for quality-aware specification and analysis is threefold. First, there should be a way to specify quality\u00a0\u2026", "num_citations": "74\n", "authors": ["316"]}
{"title": "Comprehensive explanation of SLA violations at runtime\n", "abstract": " Service Level Agreements (SLAs) establish the Quality of Service (QoS) agreed between service-based systems consumers and providers. Since the violation of such SLAs may involve penalties, quality assurance techniques have been developed to supervise the SLAs fulfillment at runtime. However, existing proposals present some drawbacks: 1) the SLAs they support are not expressive enough to model real-world scenarios, 2) they couple the monitoring configuration to a given SLA specification, 3) the explanations of the violations are difficult to understand and even potentially inaccurate, 4) some proposals either do not provide an architecture, or present low cohesion within their elements. In this paper, we propose a comprehensive solution, from a conceptual reference model to its design and implementation, that overcomes these drawbacks. The resulting platform, SALMonADA, receives the SLA agreed\u00a0\u2026", "num_citations": "71\n", "authors": ["316"]}
{"title": "Abductive Reasoning and Automated Analysis of Feature Models: How are they connected?.\n", "abstract": " In the automated analysis feature models (AAFM), many operations have been defined to extract relevant information to be used on decision making. Most of the proposals rely on logics to give solution to different operations. This extraction of knowledge using logics is known as deductive reasoning. One of the most useful operations are explanations that provide the reasons why some other operations find no solution. However, explanations does not use deductive but abductive reasoning, a kind of reasoning that allows to obtain conjectures why things happen. As a first contribution we differentiate between deductive and abductive reasoning and show how this difference affect to AAFM. Secondly, we broaden the concept of explanations relying on abductive reasoning, applying them even when we obtain a positive response from other operations. Lastly, we propose a catalog of operations that use abduction to provide useful information.", "num_citations": "71\n", "authors": ["316"]}
{"title": "Improving semantic web services discovery using SPARQL-based repository filtering\n", "abstract": " Semantic Web Services discovery is commonly a heavyweight task, which has scalability issues when the number of services or the ontology complexity increase, because most approaches are based on Description Logic reasoning. As a higher number of services becomes available, there is a need for solutions that improve discovery performance. Our proposal tackles this scalability problem by adding a preprocessing stage based on two SPARQL queries that filter service repositories, discarding service descriptions that do not refer to any functionality or non-functional aspect requested by the user before the actual discovery takes place. This approach fairly reduces the search space for discovery mechanisms, consequently improving the overall performance of this task. Furthermore, this particular solution does not provide yet another discovery mechanism, but it is easily applicable to any of the existing ones, as\u00a0\u2026", "num_citations": "70\n", "authors": ["316"]}
{"title": "Automated configuration support for infrastructure migration to the cloud\n", "abstract": " With an increasing number of cloud computing offerings in the market, migrating an existing computational infrastructure to the cloud requires comparison of different offers in order to find the most suitable configuration. Cloud providers offer many configuration options, such as location, purchasing mode, redundancy, and extra storage. Often, the information about such options is not well organised. This leads to large and unstructured configuration spaces, and turns the comparison into a tedious, error-prone search problem for the customers. In this work we focus on supporting customer decision making for selecting the most suitable cloud configuration\u2014in terms of infrastructural requirements and cost. We achieve this by means of variability modelling and analysis techniques. Firstly, we structure the configuration space of an IaaS using feature models, usually employed for the modelling of variability-intensive\u00a0\u2026", "num_citations": "69\n", "authors": ["316"]}
{"title": "RALph: A Graphical Notation for Resource Assignments in Business Processes\n", "abstract": " The business process (BP) resource perspective deals with the management of human as well as non-human resources throughout the process lifecycle. Although it has received increasing attention recently, there exists no graphical notation for it up until now that is both expressive enough to cover well-known resource selection conditions and independent of the BP modelling language. In this paper, we introduce RALph, a graphical notation for the assignment of human resources to BP activities. We define its semantics by mapping this notation to a language that has been formally defined in description logics, which enables its automated analysis. Although we show how RALph can be seamlessly integrated with BPMN, it is noteworthy that the notation is independent of the BP modelling language. Altogether, RALph will foster the visual modelling of the resource perspective in BPs", "num_citations": "66\n", "authors": ["316"]}
{"title": "Migrating to the cloud: a software product line based analysis\n", "abstract": " Identifying which part of a local system should be migrated to a public Cloud environment is often a difficult and error prone process. With the significant (and increasing) number of commercial Cloud providers, choosing a provider whose capability best meets requirements is also often difficult. Most Cloud service providers offer large amounts of configurable resources, which can be combined in a number of different ways. in the case of small and medium companies, finding a suitable configuration with the minimum cost is often an essential requirement to migrate, or even to initiate the decision process for migration. We interpret this need as a problem associated with variability management and analysis. Variability techniques and models deal with large configuration spaces, and have been proposed previously to support configuration processes in industrial cases. Furthermore, this is a mature field which has a large catalog of analysis operations to extract valuable information in an automated way. Some of these operations can be used and tailored for Cloud environments. We focus in this work on Amazon Cloud services, primarily due to the large number of possible configurations available by this service provider and its popularity. Our approach can also be adapted to other providers offering similar capabilities.", "num_citations": "66\n", "authors": ["316"]}
{"title": "Building the core architecture of a NASA multiagent system product line\n", "abstract": " The field of Software Product Lines (SPL) emphasizes building a core architecture for a family of software products from which concrete products can be derived rapidly. This helps to reduce timeto-market, costs, etc., and can result in improved software quality and safety. Current AOSE methodologies are concerned with developing a single Multiagent System. We propose an initial approach to developing the core architecture of a Multiagent Systems Product Line (MAS-PL), exemplifying our approach with reference to a concept NASA mission based on multiagent technology.", "num_citations": "62\n", "authors": ["316"]}
{"title": "RAL: A high-level user-oriented resource assignment language for business processes\n", "abstract": " An important task of business process design is the definition of what and how members of an organization are involved in the activities of the business processes developed within it. In this paper we analyse the capabilities of BPMN 2.0, the de-facto standard for business process modelling, in this regard. The conclusion is that, although it provides some mechanisms to assign resources to business process activities, they present several drawbacks. On the one hand, it does not provide a clear way to relate the assignment of resources with a model of the structure of the organization. On the other hand, it relies on XPath as the default language to assign resources to activities. The consequence is that it has limitations regarding the expressiveness of resource assignment expressions. Furthermore, it makes resource assignment not easy to learn and use since XPath has not been designed for that purpose\u00a0\u2026", "num_citations": "60\n", "authors": ["316"]}
{"title": "Specification and automated design-time analysis of the business process human resource perspective\n", "abstract": " The human resource perspective of a business process is concerned with the relation between the activities of a process and the actors who take part in them. Unlike other process perspectives, such as control flow, for which many different types of analyses have been proposed, such as finding deadlocks, there is an important gap regarding the human resource perspective. Resource analysis in business processes has not been defined, and only a few analysis operations can be glimpsed in previous approaches. In this paper, we identify and formally define seven design-time analysis operations related to how resources are involved in process activities. Furthermore, we demonstrate that for a wide variety of resource-aware BP models, those analysis operations can be automated by leveraging Description Logic (DL) off-the-shelf reasoners. To this end, we rely on Resource Assignment Language (RAL), a domain\u00a0\u2026", "num_citations": "50\n", "authors": ["316"]}
{"title": "An hybrid, qos-aware discovery of semantic web services using constraint programming\n", "abstract": " Most Semantic Web Services discovery approaches are not well suited when using complex relational, arithmetic and logical expressions, because they are usually based on Description Logics. Moreover, these kind of expressions usually appear when discovery is performed including Quality-of-Service conditions. In this work, we present an hybrid discovery process for Semantic Web Services that takes care of QoS conditions. Our approach splits discovery into stages, using different engines in each one, depending on its search nature. This architecture is extensible and loosely coupled, allowing the addition of discovery engines at will. In order to perform QoS-aware discovery, we propose a stage that uses Constraint Programming, that allows to use complex QoS conditions within discovery queries. Furthermore, it is possible to obtain the optimal offer that fulfills a given demand using this approach.", "num_citations": "49\n", "authors": ["316"]}
{"title": "Improving temporal-awareness of WS-agreement\n", "abstract": " WS-Agreement (WS-Ag) is a proposed recommendation of the Open Grid Forum that provides a schema to describe SLAs and a protocol to create them based on a mechanism of templates. However, although it identifies the necessity of specifying temporal-aware agreement terms (e.g. the response time is 30 ms from 8:00h to 17:00h and 15 ms from 17:00h to 8:00h), to the best of our knowledge, there are no existing proposals that deal with that necessity. We propose an extension that gives WS-Ag support to temporality. This allows describing expressive validity periods such as those composed by several periodic or non-periodic intervals and it applies not only to the agreement terms themselves but also to other parts of WS-Ag such as creation constraints and preferences about the service properties. In addition, in this paper we propose a preference XML schema to describe preferences over any set\u00a0\u2026", "num_citations": "49\n", "authors": ["316"]}
{"title": "Run-time prediction of business process indicators using evolutionary decision rules\n", "abstract": " Predictive monitoring of business processes is a challenging topic of process mining which is concerned with the prediction of process indicators of running process instances. The main value of predictive monitoring is to provide information in order to take proactive and corrective actions to improve process performance and mitigate risks in real time. In this paper, we present an approach for predictive monitoring based on the use of evolutionary algorithms. Our method provides a novel event window-based encoding and generates a set of decision rules for the run-time prediction of process indicators according to event log properties. These rules can be interpreted by users to extract further insight of the business processes while keeping a high level of accuracy. Furthermore, a full software stack consisting of a tool to support the training phase and a framework that enables the integration of run-time predictions\u00a0\u2026", "num_citations": "48\n", "authors": ["316"]}
{"title": "Supporting requirements verification using XSLT\n", "abstract": " We present a light-weight approach for the automatic verification of requirements. This approach is not based on natural language parsing techniques but on the representation of requirements in XML. In our approach, XSLT stylesheets are used not only to automatically generate requirements documents, but also to provide verification-oriented heuristics as well as to measure the quality of requirements using some verification-oriented metrics. These ideas have been implemented in REM, an experimental XML-based requirements management tool also described.", "num_citations": "48\n", "authors": ["316"]}
{"title": "Qos-aware services composition using tabu search and hybrid genetic algorithms\n", "abstract": " In a distributed services oriented environment, having a myriad of functionally equivalent services, Quality of Service (QoS) emerges as the key differential factor. In this scenario organizations can dynamically select partners for their core business processes expressed as Composite Web Services (CWS). As a consequence, QoS-aware composition should drive an effective selection by optimizing different factors and meeting constraints according to preferences of organizations. QoS-aware composition can be formulated as a NP-hard optimization problem. In order to deal with this hard problem, different heuristic techniques (such as genetic algorithms with different solution encodings or simulated annealing) had been proposed in the literature. In this paper we apply metaheuristic optimization techniques to this problem, specifically tabu search and an hybrid genetic algorithm. We compare these techniques with other proposals using experimental results, showing that our proposals provide improvements.", "num_citations": "47\n", "authors": ["316"]}
{"title": "A model of user preferences for semantic services discovery and ranking\n", "abstract": " Current proposals on Semantic Web Services discovery and ranking are based on user preferences descriptions that often come with insufficient expressiveness, consequently making more difficult or even preventing the description of complex user desires. There is a lack of a general and comprehensive preference model, so discovery and ranking proposals have to provide ad hoc preference descriptions whose expressiveness depends on the facilities provided by the corresponding technique, resulting in user preferences that are tightly coupled with the underlying formalism being used by each concrete solution. In order to overcome these problems, in this paper an abstract and sufficiently expressive model for defining preferences is presented, so that they may be described in an intuitively and user-friendly manner. The proposed model is based on a well-known query preference model from database\u00a0\u2026", "num_citations": "45\n", "authors": ["316"]}
{"title": "Automated analysis of feature models: Quo vadis?\n", "abstract": " Feature models have been used since the 90s to describe software product lines as a way of reusing common parts in a family of software systems. In 2010, a systematic literature review was published summarizing the advances and settling the basis of the area of automated analysis of feature models (AAFM). From then on, different studies have applied the AAFM in different domains. In this paper, we provide an overview of the evolution of this field since 2010 by performing a systematic mapping study considering 423 primary sources. We found six different variability facets where the AAFM is being applied that define the tendencies: product configuration and derivation; testing and evolution; reverse engineering; multi-model variability-analysis; variability modelling and variability-intensive systems. We also confirmed that there is a lack of industrial evidence in most of the cases. Finally, we present where\u00a0\u2026", "num_citations": "44\n", "authors": ["316"]}
{"title": "Automated Analysis of Conflicts in WS-Agreement\n", "abstract": " WS-Agreement is one of the most widely used SLA specifications. An advantage of WS-Agreement over other agreement metamodels is that it allows one to define conditional and optional term sets inside an agreement document, which are commonly found features in real-world agreements. Unfortunately, they increase the complexity of the automated detection and explanation of conflicts between SLA terms, leading to new kinds of conflicts that are not supported by current techniques. Furthermore, creating a general-purpose conflict analyser in WS-Agreement is a hard task since it should understand the semantics of an unbounded number of languages that can be used in the eight extension points that WS-Agreement includes for the sake of flexibility. In this article, we address these issues by providing a conflict classification for SLAs that includes new conflicts derived from the use of conditional and optional\u00a0\u2026", "num_citations": "43\n", "authors": ["316"]}
{"title": "An approach to temporal-aware procurement of web services\n", "abstract": " In the context of web service procurement (WSP), temporal\u2013 awareness refers to managing service demands and offers which are subject to validity periods, i.e. their evaluation depends not only on quality of service (QoS) values but also on time. For example, the QoS of some web services can be considered critical in working hours (9:00 to 17:00 from Monday to Friday) and irrelevant at any other moment. Until now, the expressiveness of such temporal\u2013aware specifications has been quite limited. As far as we know, most proposals have considered validity periods to be composed of a single temporal interval. Other proposals, which could allow more expressive time\u2013dependent specifications, have not performed a detailed study about all the underlying complexities of such approach, in spite of the fact that dealing with complex expressions on temporality is not a trivial task at all. As a matter of fact, it\u00a0\u2026", "num_citations": "43\n", "authors": ["316"]}
{"title": "Defining and analysing resource assignments in business processes with ral\n", "abstract": " Business process (BP) modelling notations tend to stray their attention from (human) resource management, unlike other aspects such as control flow or even data flow. They not only offer little intuitive languages to assign resources to BP activities, but neither link BPs with the structure of the organization where they are used, so BP models can easily contain errors such as the assignment of resources that do not belong to the organizational model. In this paper we address this problem and define RAL (Resource Assignment Language), a domain-specific language explicitly developed to assign resources to the activities of a BP model. RAL makes BPs aware of organizational structures. Besides, RAL semantics is based on an OWL-DL ontology, which enables the automatic analysis of resource assignment expressions, thus allowing the extraction of information from the resource assignments, and the\u00a0\u2026", "num_citations": "42\n", "authors": ["316"]}
{"title": "From feature models to business processes\n", "abstract": " The variability level of average-size business information systems (BIS) is highly enough for making the design of this kind of systems a complex task. There is an approach called process family engineering (PFE) that tries to ease the design of BIS using ideas from the software product lines (SPL) field. Roughly speaking, they propose to, first, study the variability of the system without entering into details by means of building a variability model (called feature model), that is used later for building the business process. However, in PFE the process of deriving the business process from the feature model is performed manually. Authors use feature models with a different meaning that is commonly accepted in SPL. In this paper, we provide a rigorous description for the new meaning of feature models, and a mapping relationship that defines how to use the information in the FM for obtaining the basic structure of the\u00a0\u2026", "num_citations": "39\n", "authors": ["316"]}
{"title": "Multi-agent system product lines: challenges and benefits\n", "abstract": " The software process proposed in AOSE presents many similarities with the process followed in SPLs for the first activities of the domain engineering, which is in charge of providing the reusable core assets that are exploited during the derivation of products, done during application engineering [10]. Following the nomenclature used in [10], the activities, usually performed iteratively and in parallel, of domain engineering that present correlation with AOSE are:", "num_citations": "38\n", "authors": ["316"]}
{"title": "Automated resource assignment in BPMN models using RACI matrices\n", "abstract": " Organizations need to manage the responsibility of their employees with respect to all the activities that are daily carried out within them. Process-oriented organizations need to do it, in addition, in accordance to the business processes their members participate in. However, powerful mechanisms to manage responsibility in combination with business processes are missing in current modelling notations, usually limited to indicating who is in charge of undertaking the activities. RACI matrices, on the contrary, were specifically conceived to provide responsibility management information. They enable the specification of the level of responsibility each human resource has with regard to each activity carried out in a company, ranging from the performer of the work to the resource that must approve it or receive certain notifications. In this paper, we propose the use of RACI matrices together with business\u00a0\u2026", "num_citations": "35\n", "authors": ["316"]}
{"title": "Hints on how to face business process compliance\n", "abstract": " The concept business process compliance refers to the degree of conformance between the business processes of an organization and the regulations and rules that govern it. This paper intends to be a starting point for people interested in business process compliance who have no knowledge about how to address compliance checking. We introduce the four most relevant points to be considered before facing the problem and present some hints for those points in the form of a state of the art based on the literature about business process compliance checking. We also state possible future work in the context of business process compliance derived from this study.", "num_citations": "35\n", "authors": ["316"]}
{"title": "A quality-aware approach to web services procurement\n", "abstract": " Web services bring programmers a new way to develop advanced applications able to integrate any group of services on the Internet into a single solution. Web services procurement (WSP) is focussed on the acquisition of web services, including some complex tasks such as the specification of demands, the search for available offers, and the best choice selection. Although the technology to support them already exists, there are only a few approaches wherein quality-of-service in demands and offers is taken into account, in addition to functionality. In this paper, we present some implementation issues on a quality-aware approach to WSP, whose solution is mainly based on using mathematical constraints to define quality-of-service in demands and offers.", "num_citations": "35\n", "authors": ["316"]}
{"title": "Integrating semantic web services ranking mechanisms using a common preference model\n", "abstract": " Service ranking has been long-acknowledged to play a fundamental role in helping users to select the best offerings among services retrieved from a search request. There exist many ranking mechanisms, each one providing ad hoc preference models that offer different levels of expressiveness. Consequently, applying a single mechanism to a particular scenario constrains the user to define preferences based on that mechanism\u2019s facilities. Furthermore, a more flexible solution that uses several independent mechanisms will face interoperability issues because of the differences between preference models provided by each ranking mechanism. In order to overcome these issues, we propose a Preference-based Universal Ranking Integration (PURI) framework that enables the combination of several ranking mechanisms using a common, holistic preference model. Using PURI, different ranking mechanisms are\u00a0\u2026", "num_citations": "34\n", "authors": ["316"]}
{"title": "Explaining the non-compliance between templates and agreement offers in ws-agreement\n", "abstract": " A common approach to the process of reaching agreements is the publication of templates that guide parties to create agreement offers that are then sent for approval to the template publisher. In such scenario, a common issue the template publisher must address is to check whether the agreement offer received is compliant or not with the template. Furthermore, in the latter case, an automated explanation of the reasons of such non-compliance is very appealing. Unfortunately, although there are proposals that deal with checking the compliance, the problem of providing an automated explanation to the non-compliance has not yet been studied in this context. In this paper, we take a subset of the WS-Agreement recommendation as a starting point and we provide a rigorous definition of the explanation for the non-compliance between templates and agreement offers. Furthermore, we propose the use of\u00a0\u2026", "num_citations": "33\n", "authors": ["316"]}
{"title": "A model-driven architecture approach for modeling, specifying and deploying policies in autonomous and autonomic systems\n", "abstract": " Autonomic computing (AC), self-management based on high level guidance from humans, is increasingly gaining momentum as the way forward in designing reliable systems that hide complexity and conquer IT management costs. Effectively, AC may be viewed as policy-based self-management. The model driven architecture (MDA) approach focuses on building models that can be transformed into code in an automatic manner. In this paper, we look at ways to implement policy-based self-management by means of models that can be converted to code using transformations that follow the MDA philosophy. We propose a set of UML-based models to specify autonomic and autonomous features along with the necessary procedures, based on modification and composition of models, to deploy a policy as an executing system", "num_citations": "33\n", "authors": ["316"]}
{"title": "Isolated Features Detection in Feature Models.\n", "abstract": " Feature models are commonly used to describe software product lines in terms of features. Features are linked by relations, which may introduce errors in the model. This paper gives a description of isolated features and states the detection of them, as the first step in their treatment. Two implementations are given to automatically support isolated features detection and a third one that uses both and improves the performance.", "num_citations": "33\n", "authors": ["316"]}
{"title": "User-centric adaptation of multi-tenant services: Preference-based analysis for service reconfiguration\n", "abstract": " Multi-tenancy is a key pillar of cloud services. It allows different tenants to share computing resources transparently and, at the same time, guarantees substantial cost savings for the providers. However, from a user perspective, one of the major drawbacks of multi-tenancy is lack of configurability. Depending on the isolation degree, the same service instance and even the same service configuration may be shared among multiple tenants (ie shared multi-tenant service). Moreover tenants usually have different-and in most of the cases-conflicting configuration preferences. To overcome this limitation, this paper introduces a novel approach to support user-centric adaptation in shared multi-tenant services. The adaptation objective aims to maximise tenants\u2019 satisfaction, even when tenants and their preferences change during the service life-time. This paper describes how to engineer the activities of the MAPE loop to\u00a0\u2026", "num_citations": "31\n", "authors": ["316"]}
{"title": "A service ranker based on logic rules evaluation and constraint programming\n", "abstract": " Ranking of Semantic Web Services is usually performed based on user preferences descriptions. These descriptions are expressed in terms of an underlying logical formalism, which limits their expressiveness. Thus, there are some kind of descriptions, such as utility functions, that cannot be handled by reasoners currently being used to perform Semantic Web Services tasks, though utility functions provide a higher level of expressiveness. In this work, we present a hybrid solution to allow the introduction of utility functions in user preferences descriptions, using both Logic Programming rules evaluation and Constraint Programming to perform the ranking process. This proposal is based on the Web Service Modeling Ontology, extending it with a highly expressive framework to specify user preferences, and enabling the integration of different engines to perform the ranking process.", "num_citations": "31\n", "authors": ["316"]}
{"title": "Repairing syntax errors in LR parsers\n", "abstract": " This article reports on an error-repair algorithm for LR parsers. It locally inserts, deletes or shifts symbols at the positions where errors are detected, thus modifying the right context in order to resume parsing on a valid piece of input. This method improves on others in that it does not require the user to provide additional information about the repair process, it does not require precalculation of auxiliary tables, and it can be easily integrated into existing LR parser generators. A Yacc-based implementation is presented along with some experimental results and comparisons with other well-known methods.", "num_citations": "31\n", "authors": ["316"]}
{"title": "Mixing RASCI matrices and BPMN together for responsibility management\n", "abstract": " Organizations need to manage the responsibility of the employees with respect to all the activities that are carried out daily. RACI matrices are used to this end, providing information about who must do what, ie, the responsibility of each human resource regarding each activity, eg responsible for its execution, responsible for approving it once executed, etcetera. On the other hand, nowadays organizations increasingly use modelling notations to represent their processes, being BPMN the standard for business process modelling. In this paper we focus on a concrete type of RACI matrices called RASCI and introduce a novel approach to build RASCI-aware business process models in BPMN based on what we have called RASCI patterns. Furthermore, we explain how the transformation of information between RASCI matrices and RASCI-aware BPMN models can be (semi-) automatically performed. We believe the transformation from RASCI to BPMN and vice versa may be very useful to organizations, since it releases them from having to manually maintain BPMN models and RASCI matrices separately and it allows them to focus on only one of them for responsibility management.", "num_citations": "29\n", "authors": ["316"]}
{"title": "Representing runtime variability in business-driven development systems\n", "abstract": " Business-Driven Development(BDD) is a research field that provides techniques and mechanisms for designing software systems starting from the business processes of the companies. Companies are in continuous evolution to adapt to market changes, thus, current process engineers redesign the processes every time that is needed using ad hoc techniques. This situation motivates that these changes, called runtime variability, must be managed. Some authors have used Software Product Lines (SPL) ideas to manage it. Current approaches for documenting runtime variability in SPL and BDD, proposes different model representations. Unfortunately, we have determined that the expressiveness level in BDD is not adequate, and that SPL solutions needs for adaptation to BDD context for describing under which circumstances a business evolves. In this paper, we present a model for representing runtime variability\u00a0\u2026", "num_citations": "29\n", "authors": ["316"]}
{"title": "Modeling service level agreements with linked USDL agreement\n", "abstract": " Nowadays, service trading over the Web is gaining momentum. In this highly dynamic scenario, both providers and consumers need to formalize their contractual and legal relationship, creating service level agreements. Although there exist some proposals that provide models to describe that relationship, they usually only cover technical aspects, not providing explicit semantics to the agreement terms. Furthermore, these models cannot be effectively shared on the Web, since they do not actually follow Web principles. These drawbacks hamper take-up and automatic analysis. In this article, we introduce Linked USDL Agreement, a semantic model to specify, manage and share service level agreement descriptions on the Web. This model is part of the Linked USDL family of ontologies that can describe not only technical but also business related aspects of services, incorporating Web principles. We validate our\u00a0\u2026", "num_citations": "28\n", "authors": ["316"]}
{"title": "Using templates and linguistic patterns to define process performance indicators\n", "abstract": " Process performance management (PPM) aims at measuring, monitoring and analysing the performance of business processes (BPs), in order to check the achievement of strategic and operational goals and to support decision-making for their optimisation. PPM is based on process performance indicators (PPIs), so having an appropriate definition of them is crucial. One of the main problems of PPIs definition is to express them in an unambiguous, complete, understandable, traceable and verifiable manner. In practice, PPIs are defined informally \u2013 usually in ad hoc, natural language, with its well-known problems \u2013 or they are defined from an implementation perspective, hardly understandable to non-technical people. In order to solve this problem, in this article we propose a novel approach to improve the definition of PPIs using templates and linguistic patterns. This approach promotes reuse, reduces both\u00a0\u2026", "num_citations": "28\n", "authors": ["316"]}
{"title": "Implementing Multiparty Interactions on a Network Computer\n", "abstract": " Classical client/server interaction primitives such as remote procedure call or rendez-vous are not adequate when we need to describe the behaviour of three or more processes that need to collaborate simultaneously in order to solve a problem. Multiparty interactions are the key to describe these problems, and there are several languages that use them for the description of reactive systems. In this paper, we show and compare two different fair implementations of this mechanism and also outline the research we are carrying out in an effort to improve them.", "num_citations": "28\n", "authors": ["316"]}
{"title": "Visual ppinot: A Graphical Notation for Process Performance Indicators\n", "abstract": " Process performance indicators (PPIs) allow the quantitative evaluation of business processes, providing essential information for decision making. It is common practice today that business processes and PPIs are usually modelled separately using graphical notations for the former and natural language for the latter. This approach makes PPI definitions simple to read and write, but it hinders maintenance consistency between business processes and PPIs. It also requires their manual translation into lower-level implementation languages for their operationalisation, which is a time-consuming, error-prone task because of the ambiguities inherent to natural language definitions. In this article, Visual ppinot, a graphical notation for defining PPIs together with business process models, is presented. Its underlying formal metamodel allows the automated processing of PPIs. Furthermore, it improves current state\u00a0\u2026", "num_citations": "27\n", "authors": ["316"]}
{"title": "Defining process performance indicators by using templates and patterns\n", "abstract": " Process Performance Indicators (PPIs) are a key asset for the measurement of the achievement of strategic and operational goals in process\u2013oriented organisations. Ideally, the definition of PPIs should not only be unambiguous, complete, and understandable to non\u2013technical stakeholders, but also traceable to business processes and verifiable by means of automated analysis. In practice, PPIs are defined either informally in natural language, with its well\u2013known problems, or at a very low level, or too formally, becoming thus hardly understandable to managers and users. In order to solve this problem, in this paper, a novel approach to improve the definition of PPIs using templates and ontology\u2013based linguistic patterns is proposed. Its main benefits are that it is easy to learn, promotes reuse, reduces ambiguities and missing information, is understandable to all stakeholders and maintains\u00a0\u2026", "num_citations": "27\n", "authors": ["316"]}
{"title": "Automatic generation of a data-centered view of business processes\n", "abstract": " Most commonly used business process (BP) notations, such as BPMN, focus on defining the control flow of the activities of a BP, i.e., they are activity-centered. In these notations, data play a secondary role, just as inputs or outputs of the activities. However, there is an increasing interest in analysing the life cycle of the data objects that are handled in a BP because it helps understand how data is modified during the execution of the process, detect data anomalies such as checking whether an activity requires a data object in a state that is unreachable, and check data compliance rules such as checking whether only a certain role can change the state of a data object. To carry out such an analysis, it is very appealing to provide a mechanism to transform from the usual activity-centered model of a BP to the set of life cycles of all the data objects involved in the process (i.e., a data-centered model\u00a0\u2026", "num_citations": "26\n", "authors": ["316"]}
{"title": "Towards process-aware cross-organizational human resource management\n", "abstract": " Finding human resources with the required set of skills, experience, and availability to execute an activity at a specific moment, is a socio-technical challenge for enterprises that use business-process aware systems. On an intra-organizational level, there exists an increasing body of knowledge for automated human-resource management. However, the recent pervasiveness of service-oriented cloud computing combined with mobile devices and big data, has resulted in the emergence of crossorganizational ecosystems in which workforce is distributed. Consequently, human-resource management has to consider more requirements compared to a purely intra-organizational setting. This position paper addresses the gap and describes a set of challenges in the management of human resources in service outsourcing scenarios based on process views and automatic process-view matching. The\u00a0\u2026", "num_citations": "25\n", "authors": ["316"]}
{"title": "SALMonADA: A platform for monitoring and explaining violations of WS-agreement-compliant documents\n", "abstract": " Quality assurance techniques have been developed to supervise the service quality (QoS) agreed between service-based systems (SBSs) consumers and providers. Such QoS is usually included in service level agreements (SLAs) and thus, SLA monitoring platforms have been developed supporting violation detection. However, just a few of them provide explanation of the violations caused by observed QoS at monitoring time, but not in an user-friendly format. Therefore, we propose a general monitoring and analysis conceptual reference model and we instantiated it with SALMonADA, a SBS that notifies the clients with violations and their causes in their own easy-to-understand specification terms. In addition, our platform performs an early analysis notification that avoids delays in the client notification time when a violation takes place. Moreover, we have implemented a web application as a SALMonADA client\u00a0\u2026", "num_citations": "25\n", "authors": ["316"]}
{"title": "Automating the procurement of web services\n", "abstract": " As government agencies and business become more dependent on web services, software solutions to automate their procurement gain importance. Current approaches for automating the procurement of web services suffer from an important drawback: neither uncertainty measures nor non-linear, and complex relations among parameters can be used by providers to specify quality-of-service in offers. In this paper, we look deeply into the roots of this drawback and present a proposal which overcomes it. The key point to achieve this improvement has been using the constraint programming as a formal basis, since it endows the model with a very powerful expressiveness. A XML-based implementation is presented along with some experimental results and comparisons with other approaches.", "num_citations": "25\n", "authors": ["316"]}
{"title": "Benchmarking on the Automated Analyses of Feature Models: a Preliminary Roadmap\n", "abstract": " The automated analysis of Feature Models (FMs) is becoming a well-established discipline. New analysis operations, tools and techniques are rapidly proliferating in this context. However, the lack of standard mechanisms to evaluate and compare the performance of different solutions is starting to hinder the progress of this community. To address this situation, we propose the creation of a benchmark for the automated analyses of FMs. This benchmark would enable the objective and repeatable comparison of tools and techniques as well as promoting collaboration among the members of the discipline. Creating a benchmark requires a community to share a common view of the problem faced and come to agreement about a number of issues related to the design, distribution and usage of the benchmark. in this paper, we take a first step toward that direction. in particular, we first describe the main issues to be addressed for the successful development and maintenance of the benchmark. Then, we propose a preliminary research agenda setting milestones and clarifying the types of contributions expected from the community.", "num_citations": "24\n", "authors": ["316"]}
{"title": "FaMa-OVM: a tool for the automated analysis of OVMs\n", "abstract": " Orthogonal Variability Model (OVM) is a modelling language for representing variability in Software Product Line Engineering. The automated analysis of OVMs is defined as the computer-aided extraction of information from such models. In this paper, we present FaMa-OVM, which is a pioneer tool for the automated analysis of OVMs. FaMa-OVM is easy to extend or integrate in other tools. It has been developed as part of the FaMa ecosystem enabling the benefits coming from other tools of that ecosystem as FaMaFW and BeTTy.", "num_citations": "23\n", "authors": ["316"]}
{"title": "An initial approach to explaining sla inconsistencies\n", "abstract": " An SLA signed by all interested parties must be created carefully, avoiding contradictions between terms, because their terms could carry penalties in case of failure. However, this consistency checking may become a challenging task depending on the complexity of the agreement. As a consequence, an automated way of checking the consistency of an SLA document and returning the set of inconsistent terms of the agreement would be very appealing from a practical point of view. For instance, it enables the development of software tools that make the creation of correct SLAs and the consistency checking of imported SLAs easier for users. In this paper, we present the problem of explaining WS-Agreement inconsistencies as a constraint satisfaction problem (CSP), and then we use a CSP solver together with an explanation engine to check the consistency and return the inconsistent terms. Furthermore, a\u00a0\u2026", "num_citations": "23\n", "authors": ["316"]}
{"title": "Expressing customer requirements using natural language requirements templates and patterns\n", "abstract": " Expressing customer requirements so they can be understood not only by requirements engineers but also by noncomputer professional customers is not an easy task. Natural language is frequently the usual choice for expressing customer requirements in spite of its well\u2013known problems, but using more formal notations too early is a risky choice that can make requirements impossible to understand for customers and users. In addition, using natural language do not guarantee understanding. Requirements engineers do not usually have good writing skills, and sometimes requirements expressed in natural language are not understood because of the poor way they are written. In this paper, we propose to use requirements templates and patterns to improve requirements expression. We have identified two types of requirements patterns: linguistic patterns, which are very used, well\u2013understood, sentences in natural language requirements descriptions that can be parameterized and integrated into templates, and requirements patterns, which are generic requirements templates that are found very often during the requirements elicitation process and that can be reused with some adaptation. CSCC\u201999 Proc. pp. 3531-3536", "num_citations": "22\n", "authors": ["316"]}
{"title": "An analysis of RESTful APIs offerings in the industry\n", "abstract": " As distribution models of information systems are moving to XaaS paradigms, microservices architectures are rapidly emerging, having the RESTful principles as the API model of choice. In this context, the term of API Economy is being used to describe the increasing movement of the industries in order to take advantage of exposing their APIs as part of their service offering and expand its business model.                 Currently, the industry is adopting standard specifications such as OpenAPI to model the APIs in a standard way following the RESTful principles; this shift has supported the proliferation of API execution platforms (API Gateways) that allow the XaaS to optimize their costs. However, from a business point of view, modeling offering plans of those APIs is mainly done ad-hoc (or in a platform-dependent way) since no standard model has been proposed. This lack of standardization hinders the\u00a0\u2026", "num_citations": "21\n", "authors": ["316"]}
{"title": "User-centric adaptation analysis of multi-tenant services\n", "abstract": " Multi-tenancy is a key pillar of cloud services. It allows different users to share computing and virtual resources transparently, meanwhile guaranteeing substantial cost savings. Due to the tradeoff between scalability and customization, one of the major drawbacks of multi-tenancy is limited configurability. Since users may often have conflicting configuration preferences, offering the best user experience is an open challenge for service providers. In addition, the users, their preferences, and the operational environment may change during the service operation, thus jeopardizing the satisfaction of user preferences. In this article, we present an approach to support user-centric adaptation of multi-tenant services. We describe how to engineer the activities of the Monitoring, Analysis, Planning, Execution (MAPE) loop to support user-centric adaptation, and we focus on adaptation analysis. Our analysis computes a service\u00a0\u2026", "num_citations": "21\n", "authors": ["316"]}
{"title": "Modelling service level agreements for business process outsourcing services\n", "abstract": " Many proposals to model service level agreements (SLAs) have been elaborated in order to automate different stages of the service lifecycle such as monitoring, implementation or deployment. All of them have been designed for computational services and are not well\u2013suited for other types of services such as business process outsourcing (BPO) services. However, BPO services supported by process\u2013aware information systems could also benefit from modelling SLAs in tasks such as performance monitoring, human resource assignment or process configuration. In this paper, we identify the requirements for modelling such SLAs and detail how they can be faced by combining techniques used to model computational SLAs, business processes, and process performance indicators. Furthermore, our approach has been validated through the modelling of several real BPO SLAs.", "num_citations": "21\n", "authors": ["316"]}
{"title": "A controlled experiment to evaluate the effects of mindfulness in software engineering\n", "abstract": " Context. Many reports support the fact that some psycho--social aspects of software engineers are key factors for the quality of the software development process and its resulting products. Based on the experience of some of the authors after more than a year of practising mindfulness---a meditation technique aimed to increase clearness of mind and awareness---we guessed that it could be interesting to empirically evaluate whether mindfulness affects positively not only the behaviour but also the professional performance of software engineers.Goal. In this paper, we present a quasi--experiment carried out at the University of Seville to evaluate whether Software Engineering & Information Systems students enhance their conceptual modelling skills after the continued daily practice of mindfulness during four weeks.Method. Students were divided into two groups: one group practised mindfulness, and the other---the\u00a0\u2026", "num_citations": "21\n", "authors": ["316"]}
{"title": "Qos-aware semantic service selection: An optimization problem\n", "abstract": " In order to select the best suited service among a set of discovered services, with respect to QoS parameters, a user have to state his or her preferences, so services can be ranked according to these QoS parameters. Current semantic Web services ontologies do not support the definition of QOS-aware user preferences, though there are some proposals that extend those ontologies to allow selection based on those preferences. However, their selection algorithms are very coupled with user preferences descriptions, which are defined without semantics or at a different semantic level than service functionality. In this work, we present a service selection framework that transforms user preferences into an optimization problem where the best service is selected. This framework is based on an ontology that conceptualizes these user preferences. Thus, we use a very expressive solution decoupled with the concrete\u00a0\u2026", "num_citations": "21\n", "authors": ["316"]}
{"title": "Towards modelling and tracing key performance indicators in business processes\n", "abstract": " It is increasingly important to evaluate the performance of business processes. A key instrument in order to detect the state of current and completed processes, as well as to identify undesired behaviour, and suggest potential improvements are the key performance indicators (KPIs). The KPI lifecycle in the context of business process driven development comprises the definition, measuring, analysis and report phases. In this paper we analyse how some current proposals deal with these stages, concluding that none of them covers properly the entire cycle; we also identify the challenges which are to be faced to achieve this goal of evaluating business processes performance.", "num_citations": "20\n", "authors": ["316"]}
{"title": "A framework for classifying and comparing web services procurement platforms\n", "abstract": " The procurement of Web services (WSP) shifts the focus of architects and integrators front functional to quality-of-service (QoS) aspects. A number of platforms have been proposed as supporting infrastructures to assist WSP activities. Notwithstanding, there is a lack of consensus on: (i) what expressiveness degree in QoS specifications should be offered; and (ii) what activities should be supported by these platforms. This paper attempts to provide an answer to both questions, thus it motivates and presents a classification framework for WSP platforms. This framework is used to compare several existing platforms and to identify some key properties and deficiencies, which might be considered as a research agenda for the future.", "num_citations": "20\n", "authors": ["316"]}
{"title": "A template-based approach for responsibility management in executable business processes\n", "abstract": " Process-oriented organisations need to manage the different types of responsibilities their employees may have w.r.t. the activities involved in their business processes. Despite several approaches provide support for responsibility modelling, in current Business Process Management Systems (BPMS) the only responsibility considered at runtime is the one related to performing the work required for activity completion. Others like accountability or consultation must be implemented by manually adding activities in the executable process model, which is time-consuming and error-prone. In this paper, we address this limitation by enabling current BPMS to execute processes in which people with different responsibilities interact to complete the activities. We introduce a metamodel based on Responsibility Assignment Matrices (RAM) to model the responsibility assignment for each activity, and a flexible template-based\u00a0\u2026", "num_citations": "18\n", "authors": ["316"]}
{"title": "CRISTAL: Collection of Resource-centrIc Supporting Tools And Languages.\n", "abstract": " In this demo, we introduce CRISTAL (Collection of ResourcecentrIc Supporting Tools And Languages), a tool suite aimed at improving the human resource management capabilities of current Business Process Management Systems (BPMSs), covering the design and enactment phases of the business process (BP) life cycle. The central element is Resource Assignment Language (RAL), a Domain Specific Language (DSL) for specifying resource assignments in process models. RAL\u2019s strong analysis capabilities enable the automated resolution of resource assignment expressions both (i) at design time, serving for post-design analysis to find and correct potential problems prior to execution, and (ii) at run time, in order to execute the BP in an existing BPMS considering the RAL assignments for resource allocation. The resource assignments can be directly modelled in a Business Process Modelling Notation (BPMN) diagram, or specified by means of a RACI matrix. In the latter case, CRISTAL can take all the RACI information automatically and introduce it into a resource-unaware BPMN model at any moment, resulting in a RACI-aware BP model (and, thus, a resource-aware BP model).", "num_citations": "17\n", "authors": ["316"]}
{"title": "Improving decision making in software product lines product plan management\n", "abstract": " The increasing demand on developing Software Product Lines (SPL) has given a lot of interest to software engineering researchers in improving and also replacing, current methods and techniques applied to clasical sofware systems development.In this paper, we introduce our first ideas within our proposal on improving the decision making while SPL Product Plan Managing. The key points in our proposal are originality and viability. We do not know any other proposal dealing with the same problem so far, and our first impressions guide us to predict a high viability.", "num_citations": "17\n", "authors": ["316"]}
{"title": "Designing business processes with history-aware resource assignments\n", "abstract": " Human resources are actively involved in (BPM), due to their participation in the execution of the work developed within (BP) activities. They, thus, constitute a crucial aspect in BP design. Different approaches have been recently introduced aiming at extending existing BP modelling notations to improve their capabilities for human resource management. However, the scope of the proposals is usually quite limited, and most of them provide ad-hoc solutions for specific scenarios. (RAL) was developed just to overcome such shortcomings, being independent of the modelling notation in which it is used, and providing interesting resource analysis mechanisms. Still, RAL is currently focused on a single BP instance and, thus, resource assignments cannot contain constraints between two process instances. In this paper, we introduce a complete (i.e. syntactical and semantical) extension for RAL to provide it with\u00a0\u2026", "num_citations": "16\n", "authors": ["316"]}
{"title": "Exploring features of a full-coverage integrated solution for business process compliance\n", "abstract": " The last few years have seen the introduction of several techniques for automatically tackling some aspects of compliance checking between business processes and business rules. Some of them are quite robust and mature and are provided with software support that partially or fully implement them. However, as far as we know there is not yet a tool that provides for the complete management of business process compliance in the whole lifecycle of business processes. The goal of this paper is to move towards an integrated business process compliance management system (BPCMS) on the basis of current literature and existing support. For this purpose, we present a description of some compliance-related features such a system should have in order to provide full coverage of the business process lifecycle, from compliance aware business process design to the audit process. Hints about what existing\u00a0\u2026", "num_citations": "16\n", "authors": ["316"]}
{"title": "Modeling NASA swarm-based systems: using agent-oriented software engineering and formal methods\n", "abstract": " The need to collect new data and perform new science is causing the complexity of NASA missions to continually increase. This complexity needs to be controlled via new technological advancements and balanced with a reduction in mission and operation costs. Planned and hypothesized missions involve self-management, biological-inspiration based on swarms, and autonomous operation as a means of achieving these goals. We consider a tailored software engineering approach to developing such systems based on agent-oriented software engineering and formal methods. We report on advances in modeling, implementing, and testing NASA swarm-based concept missions.", "num_citations": "16\n", "authors": ["316"]}
{"title": "Verifying software requirements with XSLT\n", "abstract": " In this article, we present an approach for the automatic verification of software requirements documents. This approach is based on the representation of software requirements in XML and the usage of the XSLT language not only to automatically generate requirements documents, but also to verify some desired quality properties and to compute some metrics. These ideas have been implemented in REM, an experimental requirements management tool that is also described in this paper.", "num_citations": "16\n", "authors": ["316"]}
{"title": "Object-oriented business solutions\n", "abstract": " This report summarises the presentations, discussions, and main results of the ECOOP\u201901 Workshop on Object-Oriented Business Solutions (WOOBS). It was not a pure scientific meeting, but a mixed gathering where people from the industry and the academia met to exchange ideas, experiences and build a network of relationships with others committed to the emergence of object-oriented business solutions. WOOBS had an invited talk on quality of service, twelve presentations and lively discussions during and after them. The main conclusions were on the importance of Multi-Organisational Web-Based Systems in today\u2019s e-commerce world, which justifies the study of a new multidisciplinary paradigm called Web-Oriented Programming.", "num_citations": "16\n", "authors": ["316"]}
{"title": "Edge and cloud pricing for the sharing economy\n", "abstract": " Edge devices and cloud services form crucial parts of the Internet of Things technology stack, where both are integrated into smart cities' ecosystems. However, while the latter usually include pricing plans in their offerings, the former generally don't consider economic aspects of their cooperation. In this article, the authors introduce a framework that leverages pricing aspects as first-class citizens, enabling the sharing economy vision for edge devices applied to the smart city scenario.", "num_citations": "15\n", "authors": ["316"]}
{"title": "Linked USDL agreement: Effectively sharing semantic service level agreements on the web\n", "abstract": " As the use of services available on the Web is becoming mainstream, contracts and legal aspects of the relationship between providers and consumers need to be formalized. However, current proposals to model service level agreements are mostly focused on technical aspects, do not explicitly provide semantics to agreement terms, and do not follow Web principles. These limitations prevent take-up, automatic processing, and effective sharing of agreements. Linked USDL Agreement is a Linked Data based semantic model to describe and share service agreements that extends Linked USDL, which offers a family of languages to describe various technical and business aspects of services. We followed a use case driven approach, evaluating the applicability of our proposal in a cloud computing scenario, and comparing its expressiveness with existing models. Finally, we show a concrete tool that helps to model\u00a0\u2026", "num_citations": "15\n", "authors": ["316"]}
{"title": "Automated analysis of diverse variability models with tool support\n", "abstract": " Over the past twenty years, there have been many contributions in the area of automated analysis of variability models. However, the majority of these researches are focused on feature models. We propose that the knowledge obtained during recent years on the analysis of feature models can be applied to automatically analyse different variability models. In this paper we present FaMa OVM and FaMa DEB, which are prototypical implementations for the automated analysis of two distinct variability models, namely Orthogonal Variability Models and Debian Variablity Models, respectively. In order to minimise efforts and benefit from the feature model know\u2013how, we use FaMa Framework which allows the development of analysis tools for diverse variability modelling languages. This framework provides a well tested system that guides the tool development. Due to the structure provided by the framework, FaMa OVM and FaMa DEB tools are easy to extend and integrate with other tools. We report on the main points of both tools, such as the analysis operations provided and the logical solvers used for the analysis.", "num_citations": "15\n", "authors": ["316"]}
{"title": "Using formal methods and agent-oriented software engineering for modeling NASA swarm-based systems\n", "abstract": " NASA is conducting research on advanced technologies for future exploration using intelligent swarms of robotic vehicles. One of these missions is the Autonomous Nano Technology Swarm (ANTS) mission that will explore the asteroid belt using 1,000 cooperative autonomous spacecraft. From an engineering point of view, the complexity and emergent behavior of this kind of system is one of the main challenges that has to be overcome, since it makes the behavior of the swarm unpredictable. In NASA, many approaches are being explored towards this goal, mainly, a tailored software engineering approach, called agent-oriented software engineering, and formal methods. In this paper, we report on the main advances we have made towards modeling, implementing, and testing NASA swarms-based concept missions", "num_citations": "15\n", "authors": ["316"]}
{"title": "An aspect-oriented approach based on multiparty interactions to specifying the behavior of a system\n", "abstract": " Isolating computation and coordination concerns into separate pure computation and pure coordination enhances modularity, understandability and reusability of parallel and/or distributed software. This can be achieved by moving interaction primitives, which are now commonly scattered in programs, into separate modules written in a language aimed at coordinating objects and expressing how information flows among them. The usual model for coordination is the client/server model, but it is not adequate when several objects need to collaborate simultaneously in order to solve a problem because natural multiparty interactions need to be decomposed into a set of low\u2013level, binary interactions. In this paper, we introduce CAL, an IP\u2013based language for the description of the coordination aspect of a system. We show that it can be successfully described in terms of simple multiparty interactions that can be animated and are also amenable to formal reasoning.", "num_citations": "15\n", "authors": ["316"]}
{"title": "Feature model to orthogonal variability model transformation towards interoperability between tools\n", "abstract": " Feature Model (FM) and Orthogonal Variability Model (OVM) are both modelling approaches employed to represent variability in software product line engineering. The former is the most popular and it is mainly applied to domain engineering. The later is a more recent approach mainly used to document variability in design and realisation artifacts. in the scenario of interest of our research, which focuses on Application Lifecycle Management environment, it would be useful rely on the FM to OVM transformation. To the best of our knowledge, in the literature, there is no proposal for such transformation. in this paper, we propose an algorithm to transform FM into OVM. This algorithm transforms the variable features of a FM into an OVM, thus providing an explicit view of variability of software product line. When working on these transformation, some issues came to light, such as how to preserve semantics. We discuss some of them and suggest a possible solution to transform FM into OVM by extending OVM.", "num_citations": "14\n", "authors": ["316"]}
{"title": "Feature model to orthogonal variability model transformations. A first step\n", "abstract": " Feature Model (FM) and Orthogonal Variability Model (OVM) are both modelling approaches employed to represent variability in software product line engineering. The former is the most popular and it is mainly applied to domain engineering. The later is a more recent approach mainly used to document variability in design and realisation artifacts. in the scenario of interest of our research, which focuses on Application Lifecycle Management environment, it would be useful rely on the FM to OVM transformation. To the best of our knowledge, in the literature, there is no proposal for such transformation. in this paper, we propose an algorithm to transform FM into OVM. This algorithm transforms the variable features of a FM into an OVM, thus providing an explicit view of variability of software product line. When working on these transformation, some issues came to light, such as how to preserve semantics. We discuss some of them and suggest a possible solution to transform FM into OVM by extending OVM.", "num_citations": "14\n", "authors": ["316"]}
{"title": "Measuring performance in knowledge-intensive processes\n", "abstract": " Knowledge-intensive Processes (KIPs) are processes whose execution is heavily dependent on knowledge workers performing various interconnected knowledge-intensive decision-making tasks. Among other characteristics, KIPs are usually non-repeatable, collaboration-oriented, unpredictable, and, in many cases, driven by implicit knowledge, derived from the capabilities and previous experiences of participants. Despite the growing body of research focused on understanding KIPs and on proposing systems to support these KIPs, the research question on how to define performance measures thereon remains open. In this article, we address this issue with a proposal to enable the performance management of KIPs. Our approach comprises an ontology that allows us to define process performance indicators (PPIs) in the context of KIPs, and a methodology that builds on the ontology and the concepts of lead\u00a0\u2026", "num_citations": "13\n", "authors": ["316"]}
{"title": "Narrowing the business-IT gap in process performance measurement\n", "abstract": " To determine whether strategic goals are met, organizations must monitor how their business processes perform. Process Performance Indicators (PPIs) are used to specify relevant performance requirements. The formulation of PPIs is typically a managerial concern. Therefore, considerable effort has to be invested to relate PPIs, described by management, to the exact operational and technical characteristics of business processes. This work presents an approach to support this task, which would otherwise be a laborious and time-consuming endeavor. The presented approach can automatically establish links between PPIs, as formulated in natural language, with operational details, as described in process models. To do so, we employ machine learning and natural language processing techniques. A quantitative evaluation on the basis of a collection of 173 real-world PPIs demonstrates that the\u00a0\u2026", "num_citations": "13\n", "authors": ["316"]}
{"title": "On the Automated Analysis of WS-Agreement Documents Applications to the Processes of Creating and Monitoring Agreements\n", "abstract": " Support: Pre-doctoral scholarship, and scholarships for research visits granted by the Andalusian Government and the University of Seville. Additional support for attending conferences provided by: the European Commission (FEDER); the European Network of Excellence in Software Services and Systems (S-Cube); the Spanish Government under CICYT projects: SETI (TIN2009-07366), and TAPAS (TIN2012\u201332273); and the Andalusian Government projects ISABEL (TIC-2533) and THEOS (TIC-5906).", "num_citations": "13\n", "authors": ["316"]}
{"title": "Interorganizational business modeling: an approach for traceability of goals, organizational models and business processes\n", "abstract": " The main goal of business modelling is to understand the operation of companies in order to provide software solutions with high added value. However, this is a hard task, and becomes more complex when we are modeling not an isolated organization, but several organizations that interact with each other. The current proposals for business modelling have focused their efforts only on representing business processes, of isolated organizations, ignoring both the organizational models and crucial information for managers of enterprises. This because the suggested business models are more oriented towards the construction of the software to provide an abstract view of the behavior of the company. To fill this gap, we present an approach to business modeling, using a methodology of agents called MaCMAS to link business processes to the objectives and the organizational models of interaction. We also provide\u00a0\u2026", "num_citations": "13\n", "authors": ["316"]}
{"title": "Business Family Engineering. Does It Make Sense?\n", "abstract": " Nowadays most companies in whichever field have a software system that helps managing all the aspects of the company, from the strategic management to daily activities. Companies are in continuous evolution to adapt to market changes, and consequently, the Information Technology (IT) infrastructure that supports it must also evolve. Thus, software companies are currently supporting this evolution with ad hoc techniques. We think that, as it is being done for traditional software systems (non-oriented to business process) in the software product line (SPL) field, institutionalized techniques for performing a systematic reuse of business processes across different businesses can be introduced. in this paper, we explore the feasibility of adapting SPL techniques, oriented to reuse software, to Business-Driven Development (BDD), oriented to reuse processes, across different businesses; we call this approach Business Family Engineering (BFE). As a result of our study, we show some of the problems we have identified and some of the key aspects needed to enable this new field.", "num_citations": "13\n", "authors": ["316"]}
{"title": "An experimental replication on the effect of the practice of mindfulness in conceptual modeling performance\n", "abstract": " Context: Mindfulness is a meditation technique aimed to increase clearness of mind and awareness. In the 2013\u20132014 academic year, an experiment was carried out to test whether the practice of mindfulness during 4 weeks improved or not the conceptual modeling performance using UML class diagrams of 32 second\u2013year students of Software Engineering at the University of Seville.Objective: An internal replication with some changes in the original design was performed in the first semester of the 2014\u20132015 academic year in order to confirm the insights provided by the original study and increase the confidence in its conclusions. The sample were 53 students with the same profile than in the original study.Method: Half the students (27 subjects) practiced mindfulness during 6 weeks, while the other half (26 subjects), i.e. the control group, received no treatment during that time. All the students developed two\u00a0\u2026", "num_citations": "12\n", "authors": ["316"]}
{"title": "Identifying variability in process performance indicators\n", "abstract": " The performance perspective of business processes is concerned with the definition of performance requirements usually specified as a set of Process Performance Indicators (PPIs). Like other business process perspectives such as control-flow or data, there are cases in which PPIs are subject to variability. However, although the modelling of business process variability (BPV) has evolved significantly, there are very few contributions addressing the variability in the performance perspective of business processes. Modelling PPI variants with tools and techniques non-suitable for variability may generate redundant models, thus making it difficult its maintenance and future adaptations, also increasing possibility of errors in its managing. In this paper we present different cases of PPI variability detected as result of the analysis of several processes where BPV is present. Based on an existent metamodel used\u00a0\u2026", "num_citations": "12\n", "authors": ["316"]}
{"title": "PPINOT tool suite: a performance management solution for process-oriented organisations\n", "abstract": " A key aspect in any process-oriented organisation is the measurement of process performance for the achievement of its strategic and operational goals. Process Performance Indicators (PPIs) are a key asset to carry out this evaluation, and, therefore, the management of these PPIs throughout the whole BP lifecycle is crucial. In this demo we present PPINOT Tool Suite, a set of tools aimed at facilitating and automating the PPI management. The support includes their definition using either a graphical or a template-based textual notation, their automated analysis at design-time, and their automated computation based on the instrumentation of a Business Process Management System.", "num_citations": "12\n", "authors": ["316"]}
{"title": "Slaws: Towards a conceptual architecture for sla enforcement\n", "abstract": " Current technologies in Service Oriented Computing (SOC) provide a solid framework to drive the interaction of organizations from a functional point of view. In order to introduce non-functional properties in this scenario, the concept of Service Level Agreement (SLAs) comes into play as a key element. SLAs can be seen as containers of the functional and non-functional properties that both parties (the service consumer and the service provider) agree specifying its rights and obligations during the interaction. However this SLAs represent an additional responsibility for the service provider since it motivates the need of a SLA-Enforcement process in its infrastructure. A proper SLA-enforcement implies optimized resource usage that meet SLAs established with consumer, making it possible to the provider afford a larger number of customers to maximize its benefits. Current approaches to SLA enforcement are domain\u00a0\u2026", "num_citations": "12\n", "authors": ["316"]}
{"title": "Temporal-awareness in slas: Why should we be concerned?\n", "abstract": " Traditionally, Service Level Agreements have been decomposed in two sets of properties: functionals (what) and non-functionals (how). However, in our opinion, there has been a third key element that has had a minor attention from academy: temporal awareness (when). We believe temporality is a main concern that should be addressed in realistic scenarios. In doing so, this position paper discuss our experience in extending the specification WS-Agreement with a temporal Domain Specific Language; importantly, main aim of the paper is to provoke a debate about the importance of temporality in SLAs.", "num_citations": "12\n", "authors": ["316"]}
{"title": "Automated validation of compensable SLAs\n", "abstract": " A Service Level Agreement (SLA) regulates the provisioning of a service by defining a set of guarantees. Each guarantee sets a Service Level Objective (SLO) on some service metrics, and optionally a compensation that is applied when the SLO is unfulfilled or overfulfilled. Currently, there are software tools and research proposals that use the information about compensations to automate and optimise certain parts of the service management. However, they assume that compensations are well defined, which is too optimistic in some circumstances and can lead to undesirable situations. In this article we discuss about the notion of validity of guarantees with a compensation, which we refer to as compensable guarantees (CG). We describe an abstract model of CGs and we provide a technique that leverages constraint satisfaction problem solvers to automatically validate them. We also present a materialisation of\u00a0\u2026", "num_citations": "11\n", "authors": ["316"]}
{"title": "Towards a formal specification of slas with compensations\n", "abstract": " In Cooperative Information Systems, service level agreements (SLA) can be used to describe the rights and obligations of parties involved in the transactions (typically the service consumer and the service provider); amongst other information, SLA could define guarantees associated with the idea of service level objectives (SLOs) that normally represent key performance indicators of either the consumer or the provider. In case the guarantee is under-fulfilled or over-fulfilled SLAs could also define some compensations (i.e. penalties or rewards). In such a context, during the last years there have been important steps towards the automation of the management of SLAs, however the formalization of compensations in SLAs still remains as an important challenge.               In this paper we aim to provide a characterization model to create SLAs with compensations; specifically, the main contributions are twofold\u00a0\u2026", "num_citations": "11\n", "authors": ["316"]}
{"title": "Enabling the evolution of service-oriented solutions using an UML2 profile and a reference Petri nets execution platform\n", "abstract": " The activities developed by a company (business processes) have to change frequently to adapt to the environment. The implementation of business processes should support these changes without any receding. In this work, we provide with an approach for modelling and executing agile and adaptable business processes. Our approach is based on UML2 separating choreography (stable interaction patterns) and orchestration (implementation of the evolving business process, also called workflows), allowing the transformation and execution of the models by means of a flexible SOA-based dynamic platform based on reference Petri nets.", "num_citations": "11\n", "authors": ["316"]}
{"title": "Una aproximaci\u00f3n mda para modelar transacciones de negocio a nivel cim\n", "abstract": " Con la globalizaci\u00f3n de los mercados, las transacciones de negocio est\u00e1n adquiriendo una importancia significativa porque permiten tener una visi\u00f3n abstracta de las interacciones que tienen lugar entre las distintas organizaciones que colaboran para el cumplimiento de sus objetivos de negocio. Esto ha permitido el desarrollo de numerosos trabajos de investigaci\u00f3n que tratan de modelar de una u otra forma las transacciones de negocio. No obstante, ninguno de estos trabajos toma como referencia modelos a nivel CIM que est\u00e9n enfocados a observar la interacci\u00f3n entre empresas desde el punto de vista de los gestores de las mismas. Por otra parte, M. Papazoglou propone un modelo que aglutina toda la informaci\u00f3n relevante para este tipo de interacciones llamado Business Transaction Model (BTM) cuyas caracter\u0131sticas lo hacen ser \u00f3ptimo para el nivel CIM. Sin embargo, el autor no propone una\u00a0\u2026", "num_citations": "11\n", "authors": ["316"]}
{"title": "A practical agent-based method to extract semantic information from the web\n", "abstract": " The semantic Web will bring meaning to the Internet, making it possible for web agents to understand the information it contains. However, current trends seem to suggest that it is not likely to be adopted in the forthcoming years. In this sense, meaningful information extraction from the web becomes a handicap for web agents. In this article, we present a framework for automatic extraction of semantically-meaningful information from the current web. Separating the extraction process from the business logic of an agent enhances modularity, adaptability, and maintainability. Our approach is novel in that it combines different technologies to extract information, surf the web and automatically adapt to some changes.", "num_citations": "11\n", "authors": ["316"]}
{"title": "An XML\u2013based Approach for the Automatic Verification of Software Requirements Specifications\n", "abstract": " In this paper, we present an approach for the automatic verification of software requirements specifications. This approach is based on the representation of software requirements in XML and the usage of the XSLT language not only to automatically generate requirements documents, but also to verify some desired quality properties and to automatically compute some metrics. These ideas have been implemented in REM, an experimental requirements management tool that is also described in this paper.", "num_citations": "11\n", "authors": ["316"]}
{"title": "A Template\u2013Based Approach to Describing Metamorphic Relations\n", "abstract": " Metamorphic testing enables the generation of test cases in the absence of an oracle by exploiting relations among different executions of the program under test, called metamorphic relations. In a recent survey, we observed a great variability in the way metamorphic relations are described, typically in an informal manner using natural language. We noticed that the lack of a standard mechanism to describe metamorphic relations often makes them hard to read and understand, which hinders the widespread adoption of the technique. In this paper, we propose a template-based approach for the description of metamorphic relations. The proposed template aims to ease communication among practitioners as well as to contribute to research dissemination. Also, it provides a helpful guide for those approaching metamorphic testing for the first time. For the validation of the approach, we used the proposed template to\u00a0\u2026", "num_citations": "10\n", "authors": ["316"]}
{"title": "Multi-user variability configuration: A game theoretic approach\n", "abstract": " Multi-user configuration is a neglected problem in variability-intensive systems area. The appearance of conflicts among user configurations is a main concern. Current approaches focus on avoiding such conflicts, applying the mutual exclusion principle. However, this perspective has a negative impact on users satisfaction, who cannot make any decision fairly. In this work, we propose an interpretation of multi-user configuration as a game theoretic problem. Game theory is a well-known discipline which analyzes conflicts and cooperation among intelligent rational decision-makers. We present a taxonomy of multi-user configuration approaches, and how they can be interpreted as different problems of game theory. We focus on cooperative game theory to propose and automate a tradeoff-based bargaining approach, as a way to solve the conflicts and maximize user satisfaction at the same time.", "num_citations": "10\n", "authors": ["316"]}
{"title": "On the definition and analysis of process performance indicators\n", "abstract": " A key aspect in any process-oriented organisation is the evaluation of process performance for the achievement of its strategic and operational goals. Process Performance Indicators (PPIs) are a key asset to carry out this evaluation, and, therefore, having an appropriate de\u00bf nition of these PPIs is crucial. After a thorough review of the literature related and a study of the current picture in different real organisations, we conclude that there not exists any proposal that allows de\u00bf ning PPIs in a way that is unambiguous and highly expressive, understandable by technical and non-technical users and traceable with the Business Process (BP). Furthermore, it is also increasingly important to provide these PPI de\u00bf nitions with support to automated analysis allowing implicit information to be extracted from them and their relationships with the BP. This information can assist process analysts in the de\u00bf nition and evolution of\u00a0\u2026", "num_citations": "10\n", "authors": ["316"]}
{"title": "Building and implementing policies in autonomous and autonomic systems using MaCMAS\n", "abstract": " Autonomic Computing, self-management based on high level guidance from humans, is increasingly being accepted as a means forward in designing reliable systems that both hide complexity from the user and control IT management costs. Effectively, AC may be viewed as policy-based self-management. We look at ways of achieving this, with particular focus on agent-oriented software engineering. We propose utilizing MaCMAS, an AOSE methodology for specifying autonomic and autonomous properties of the system independently. Later, by means of composition of these specifications, guided by a policy specification, we construct a specification for the policy and its subsequent deployment. We illustrate this by means of a case study based on a NASA concept mission and describe future work on a support toolkit.", "num_citations": "10\n", "authors": ["316"]}
{"title": "Una Aproximaci\u00f3n Semicualitativa al Tratamiento Autom\u00e1tico de Requisitos de Calidad. Aplicaci\u00f3n a la obtenci\u00f3n autom\u00e1tica de acuerdos de nivel de servicio en MOWS\n", "abstract": " De acuerdo con el tipo de t\u00e9cnicas empleadas, las propuestas que abordan el tratamiento sistem\u00e1tico de los requisitos de calidad pueden ser clasificadas en cuantitativas y cualitativas. Las primeras resultan muy adecuadas para tratar con requisitos de calidad duros, pero insuficientes para tratar con requisitos blandos. Por su parte, las propuestas cualitativas han sido utilizadas ha sta ahora \u00fanicamente con requisitos blandos. En esta tesis presentamos una propuesta que hace posible trabajar al mismo tiempo con ambos tipos de requisitos. Dicha propuesta se compone de un modelo de referencia, un soporte ling\u00fc\u00edstico ejecutable y un conjunto de herramientas de apoyo que facilitan la automatizaci\u00f3n de algunas actividades relacionadas con los requisitos de calidad de productos software, y particularmente de servicios WEB. Esta propuesta es el resultado de una profunda revisi\u00f3n de trabajos relacionados por lo que aglutina buena parte de los aspectos positivos encontrados y a\u00f1ade algunos nuevos que consideramos de gran inter\u00e9s dentro de este contexto de investigaci\u00f3n: consciencias temporal, capacidad de negociaci\u00f3n, dualidad e interoperabilidad.", "num_citations": "10\n", "authors": ["316"]}
{"title": "Automated Analysis of Orthogonal Variability Models Using Constraint Programming.\n", "abstract": " Software Product Line (SPL) Engineering is about producing a family of products that share commonalities and variabilities. The variability models are used for variability management in SPLs. Currently, the automated analysis of variability models has become an active research area. in this paper we focus on the automated analysis of Orthogonal Variability Model (OVM), which is a modelling language for representing variability. The automated analysis of OVMs deals with the computer-aided extraction of information from OVMs. The automated analysis of OVMs has been hardly explored and currently has no tooling support. Considering our know-how to analyse feature models, which are the most popular variability models in SPLs, we propose to automate the analysis of OVMs by means of constraint programming. in addition, we propose to extend OVMs with attributes, allowing to add extra-functional information to OVMs. With this proposal we contribute with a step forward toward a tooling support for analysing OVMs.", "num_citations": "9\n", "authors": ["316"]}
{"title": "On Using Semantic Web Query Languages for Semantic Web Services Provisioning.\n", "abstract": " Although there are several approaches to discover Semantic Web Services based on Description Logics reasoning, the use of standard Semantic Web query languages for this task is not so widely spread, partly because service discovery involves some issues that these languages do not usually deal with, such as complex matching, results ranking or interoperability. In this work we analyze the suitability of existing query languages to perform provisioning tasks (namely discovery, ranking and selection) within a Semantic Web Services scenario. Additionally, the requirements a Semantic Web query language has to fulfill in order to be used within a provisioning scenario are enumerated, giving some insights into how to extend current query languages to do so. Furthermore, an analysis of current provisioning proposals achievement of those requirements is presented.", "num_citations": "9\n", "authors": ["316"]}
{"title": "Aspect-oriented interaction in multi-organisational web-based systems\n", "abstract": " Separation of concerns has been presented as a promising tool to tackle the design of complex systems in which cross-cutting properties that do not fit into the scope of a class must be satisfied. Unfortunately, current proposals assume that objects interact by means of object-oriented method calls, which implies that they embed interactions with others into their functional code. This makes them dependent on this interaction model, and makes it difficult to reuse them in a context in which another interaction model is more suited, e.g., tuple spaces, multiparty meetings, ports, and so forth. In this paper, we show that functionality can be described separately from the interaction model used, which helps enhance reusability of functional code and coordination patterns. Our proposal is innovative in that it is the first that achieves a clear separation between functionality and interaction in an aspect-oriented manner. In order\u00a0\u2026", "num_citations": "9\n", "authors": ["316"]}
{"title": "Automatic extraction of semantically-meaningful information from the web\n", "abstract": " The Semantic Web will bring meaning to the Internet, making it possible for web agents to understand the information it contains. However, current trends seem to suggest that the Semantic Web is not likely to be adopted in the forthcoming years. In this sense, meaningful information extraction from the web becomes a handicap for web agents. In this article, we present a framework for automatic extraction of semanticallymeaningful information from the current web. Separating the extraction process from the business logic of an agent enhances modularity, adaptability, and maintainability. Our approach is novel in that it combines different technologies to extract information, surf the web and automatically adapt to web changes.", "num_citations": "9\n", "authors": ["316"]}
{"title": "Replication of Studies in Empirical Software Engineering: A Systematic Mapping Study, From 2013 to 2018\n", "abstract": " Context: In any discipline, replications of empirical studies are necessary to consolidate the acquired knowledge. In Software Engineering, replications have been reported since the 1990s, although their number is still small. The difficulty in publishing, the lack of guidelines, and the unavailability of replication packages are pointed out by the community as some of the main causes. Objective: Understanding the current state of replications in Software Engineering studies by evaluating current trends and evolution during the last 6 years. Method: A Systematic Mapping Study including articles published in the 2013-2018 period that report at least one replication of an empirical study in Software Engineering. Results: 137 studies were selected and analysed, identifying: i) forums; ii) authors, co-authorships and institutions; iii) most cited studies; iv) research topics addressed; v) empirical methods used; vi) temporal\u00a0\u2026", "num_citations": "8\n", "authors": ["316"]}
{"title": "Enriching decision making with data-based thresholds of process-related KPIs\n", "abstract": " The continuous performance improvement of business processes usually involves the definition of a set of process performance indicators (PPIs) with their target values. These PPIs can be classified into lag PPIs, which establish a goal that the organization is trying to achieve, though are not directly influenceable by process performers, and lead PPIs, which are influenceable by process performers and have a predictable impact on the lag indicator. Determining thresholds for lead PPIs that enable the fulfillment of the related lag PPI is a key task, which is usually done based on the experience and intuition of the process owners. However, the amount and nature of currently available data make it possible for data-driven decisions to be made in this regard. This paper proposes a method that applies statistical techniques for thresholds determination successfully employed in other domains. Its applicability\u00a0\u2026", "num_citations": "8\n", "authors": ["316"]}
{"title": "Automated Analysis of Cloud Offerings for Optimal Service Provisioning\n", "abstract": " Cloud computing paradigm has brought an overwhelming variety of cloud services from different providers, each one offering a plethora of configuration and purchasing options for them. Users may have certain requirements and preferences not only concerning service configuration, but also with respect to their usage schedule. In this situation, an appropriate provisioning plan considering all restrictions would help users to achieve their goals while taking into account the different available providers, their pricing and even the usage discounts they provide. In this work, we describe an automated solution that analyzes user needs that include scheduling restrictions to obtain optimized provisioning plans for different cloud providers, which allow users to compare several offerings that possibly consider volume or usage discounts. We validate this solution against a realistic use case, while also providing a\u00a0\u2026", "num_citations": "8\n", "authors": ["316"]}
{"title": "Dealing with complexity in agent-oriented software engineering: The importance of interactions\n", "abstract": " Agent Oriented Software Engineering was born with the promise of allowing more complex systems to be built than can be with traditional OO techniques. This promise is supported by mimicking human organizations and, thus, using \u201cagents\u201d, rather than Objects, as the main modelling artifact. Systems developed this way usually present features that make them complex; that is to say, their behavior cannot be fully predicted. However, such degrees of unpredictability may not be acceptable for some domain applications, e.g., real-time systems or critical business applications. If we analyze these kinds of system, we soon discover that their complexity is mainly derived as a result of the interactions between their constituent components. These interactions provoke chains of cause-effects that are hard to deal with from an engineering point of view, if we do not counter them with appropriate tools. In this chapter\u00a0\u2026", "num_citations": "8\n", "authors": ["316"]}
{"title": "Extracting orthogonal variability models from debian repositories\n", "abstract": " Software Product-Line (SPL) engineering is about management of a set of similar software products from a set of reusable core assets [2]. Variability Models (VM) are used to describe the variability present in the different stages of an SPL. The automated analysis of variability models involves a large number of techniques and tools. Currently, there are a variety of commercial and open-source tools to automate the reasoning on VMs such as FaMa1, FaMa-OVM 2, pure:: variants3, SEGOS4 are some of them. Although there are several kinds of variability models, the majority of the research works on analysis of these models has focused on Feature Models (FM) and Orthogonal Variability Models (OVM). The former focuses on the domain and variability present in an SPL and the latter in the variability.A well known problem in SPL community is the lack of real models available to researchers [1]. There exists references to real VMs, but those models are not public, probably this is mainly caused by the apprehension of the industry to reveal their business models. Real models are needed for providing an idea of program\u2019s behaviour in a real scenario [5].", "num_citations": "8\n", "authors": ["316"]}
{"title": "On user preferences and utility functions in selection: A semantic approach\n", "abstract": " Discovery tasks in the context of Semantic Web Services are generally performed using Description Logics. However, this formalism is not suited when non-functional, numerical parameters are involved in the discovery process. Furthermore, in selection tasks, where an optimization algorithm is needed, DLs are not capable of computing the optimum. Although there are DLs extensions that can handle numerical parameters, they bring decidability problems. Other solutions, as hybrid approaches which use DLs in functional discovery and other formalisms in non-functional selection, do not provide a semantic framework to describe user preferences based on non-functional properties. In this work, we propose to semantically describe user preferences, so they can be used to perform selection within a hybrid solution. By using semantically described utility functions in order to define user preferences, our\u00a0\u2026", "num_citations": "8\n", "authors": ["316"]}
{"title": "An automated approach to quality-aware web applications\n", "abstract": " Multi-Organisational Web-Based Systems (MOWS) are becoming very popular in the Internet world. It would be desirable for such systems to be quality-aware, and this feature turns the problem of selecting the web services of which they are composed into a complex task. The main reason is that the catalog of available services that meet a set of functional requirements may be quite large, and it is subject to unexpected changes due to the inherent volatility of the Internet. Thus, such systems need an infrastructure able to select the best services at run time so that they can deliver their functionality at the best possible quality level. In this article, we present a proposal that aims at being the core of a run-time system able to support the construction of quality-aware MOWS.", "num_citations": "8\n", "authors": ["316"]}
{"title": "Identificaci\u00f3n de Patrones de Reutilizaci\u00f3n de Requisitos de Sistemas de Informaci\u00f3n.\n", "abstract": " En este art\u00edculo se exponen algunos de los resultados de la aplicaci\u00f3n de las plantillas y patrones de requisitos presentadas en la edici\u00f3n previa del WER [6]. Uno de los resultados m\u00e1s interesantes de la normalizaci\u00f3n del formato de los requisitos ha sido la posibilidad de compararlos e identificar patrones de reutilizaci\u00f3n, tanto a nivel de requisitos de cliente (requisitos\u2013C, normalmente expresados en lenguaje natural) como a nivel de requisitos de desarrollador (requisitos\u2013D, habitualmente modelos conceptuales), que facilitan el desarrollo y mejoran la calidad de las especificaciones de requisitos. La relaciones de rastreabilidad entre requisitos\u2013C, requisitos\u2013D, e incluso elementos de menor nivel de abstracci\u00f3n como componentes software, ha permitido tambi\u00e9n plantear la posibilidad de reutilizar estructuras complejas, desde requisitos\u2013C hasta c\u00f3digo, obteniendo as\u00ed una reutilizaci\u00f3n vertical que abarque distintos niveles de abstracci\u00f3n del desarrollo de software.", "num_citations": "8\n", "authors": ["316"]}
{"title": "Redefining a Process Engine as a Microservice Platform\n", "abstract": " In recent years, microservice architectures have emerged as an agile approach for scalable web applications on cloud environments. As each microservice is developed and deployed independently, they can be developed in the platform and programming language that best suite their purposes, using a simple communication protocol, as REST APIs or asynchronous event-based collaborations, to compose them. In this paper, we argue that process engines provide an excellent platform to develop microservices whose business logic involves complex work flows or processes so that a Business Process language can be used as high-level language to develop these services and a process engine to execute it. We identify the requirements for integrating a process engine in a microservice architecture and we propose how the communication and deployment in a microservice architecture can be handled\u00a0\u2026", "num_citations": "7\n", "authors": ["316"]}
{"title": "An elasticity-aware governance platform for cloud service delivery\n", "abstract": " In cloud service provisioning scenarios with a changing demand from consumers, it is appealing for cloud providers to leverage only a limited amount of the virtualized resources required to provide the service. However, it is not easy to determine how much resources are required to satisfy consumers expectations in terms of Quality of Service (QoS). Some existing frameworks provide mechanisms to adapt the required cloud resources in the service delivery, also called an elastic service, but only for consumers with the same QoS expectations. The problem arises when the service provider must deal with several consumers, each demanding a different QoS for the service. In such an scenario, cloud resources provisioning must deal with trade-offs between different QoS, while fulfilling these QoS, within the same service deployment. In this paper we propose an elasticity-aware governance platform for cloud service\u00a0\u2026", "num_citations": "7\n", "authors": ["316"]}
{"title": "Automated analysis of stateful feature models\n", "abstract": " In CAiSE 2005, we interpreted the extraction of relevant information from extended feature models as an automated reasoning problem based on constraint programming. Such extraction is driven by a catalogue of basic and compound operations. Much has been done since, renaming the problem as the automated analysis of feature models, a widely accepted problem in the Software Product Line (SPL) community. In this chapter, we review this seminal contribution and its impact in the community, highlighting the key milestones up to a more complete problem formulation that we coin as the Automated Analysis of Stateful Feature Models (AASFM). Finally, we envision some breakthroughs and challenges in the AASFM.", "num_citations": "7\n", "authors": ["316"]}
{"title": "A lightweight prototype implementation of SPARQL filters for WSMO-based discovery\n", "abstract": " Semantic Web Services discovery is commonly a heavyweight task, which has scalability issues when the number of services or the ontology complexity increase, because most approaches are based on Description Logics reasoning. As more complex services become available, there is a need for solutions that improve discovery performance. Our proposal tackles this scalability problem by adding a preprocessing stage based on two SPARQL queries that filter service repositories, discarding service descriptions that do not refer to any property requested by the user before the actual discovery. By using this approach, the search space for discovery mechanisms is fairly reduced, consequently improving the overall performance of this task. Furthermore, this particular solution do not provide yet another discovery mechanism, but it is easily applicable to any of the existing ones. Moreover, proposed queries are automatically generated from service requests, transparently to the user. In order to validate our proposal, a concrete application to a wsmo discovery scenario is showcased in this paper. A comprehensive performance analysis is also presented in order to test and compare the results obtained from proposed queries and classical discovery approaches, discussing the benefits of our proposal.", "num_citations": "7\n", "authors": ["316"]}
{"title": "Ranking semantic web services using rules evaluation and constraint programming\n", "abstract": " Current Semantic Web Services discovery and ranking proposals are based on user preferences descriptions whose expressiveness are limited by the underlying logical formalism used. Thus, highly expressive preference descriptions, such as utility functions, cannot be handled by the kind of reasoners traditionally used to perform Semantic Web Services tasks. In this work, we outline a hybrid approach to allow the introduction of utility functions in user preferences descriptions, where both rules evaluation and constraint programming are used to perform the ranking process. Our proposal extends the Web Service Modeling Ontology with these descriptions, providing a highly expressive framework to specify preferences, and enabling a more general ranking process, which can be performed by different engines.", "num_citations": "7\n", "authors": ["316"]}
{"title": "A first approach to build product lines of multi-organizational web based systems (mows)\n", "abstract": " From the recent past and current state of the Internet, it is possible to forecast a wide growing of Multi Organizational Web\u2013based Systems (MOWS). Therefore, the reduction of both costs and time\u2013to\u2013market is desirable. On the other hand, the success of building software in Product Lines (PL) is being demonstrated in different contexts reducing both time\u2013to\u2013market and costs. However, research on PL topics has not been oriented to include web\u2013based assets. In this article, we propose a first approach to use PL methodologies to build MOWS. We identify quality aspects as a key point when building Product Lines of MOWS and we give a way to specify quality aspects in PL.", "num_citations": "7\n", "authors": ["316"]}
{"title": "Automatic extraction of semantically-meaningful information from the web\n", "abstract": " The semantic Web will bring meaning to the Internet, making it possible for web agents to understand the information it contains. However, current trends seem to suggest that the semantic web is not likely to be adopted in the forthcoming years. In this sense, meaningful information extraction from the web becomes a handicap for web agents. In this article, we present a framework for automatic extraction of semantically-meaningful information from the current web. Separating the extraction process from the business logic of an agent enhances modularity, adaptability, and maintainability. Our approach is novel in that it combines different technologies to extract information, surf the web and automatically adapt to web changes.", "num_citations": "7\n", "authors": ["316"]}
{"title": "An automated approach for verification of software requirements\n", "abstract": " In this paper, we present an automated approach for the verification of software requirements. This approach is based on the representation of software requirements in XML and the usage of the XSLT language to automatically verify some desired quality properties. These ideas have been implemented in REM, an experimental requirements management tool that is also described in this paper.", "num_citations": "7\n", "authors": ["316"]}
{"title": "Governify for APIs: SLA-Driven ecosystem for API governance\n", "abstract": " As software architecture design is evolving to a microservice paradigm, RESTful APIs are being established as the preferred choice to build applications. In such a scenario, there is a shift towards a growing market of APIs where providers offer different service levels with tailored limitations typically based on the cost.", "num_citations": "6\n", "authors": ["316"]}
{"title": "EXEMPLAR: An Experimental Information Repository for Software Engineering Research\n", "abstract": " The number and variety of experiments carried in software engineering research is growing, leading to a increasing need of replication and review. In order to support such needs the information about experiments should be provided as lab-packs comprising of: a description of the experiment, the materials used and data generated during the conduction, and the results of the analyzes performed on such data. However, this information is often scattered, poorly structured, and even unavailable, implying a tedious process of search and gathering. EXEMPLAR is an online platform for managing experimental information, that allows the uploading and publication of experimental lab packs, and an efficient search. The platform also supports the use of formal languages for providing experimental descriptions (e.g. SEDL). In so doing, EXEMPLAR enables the automated analysis of lab-packs, in order to detect common validity threats and missing information which could hinder replicability.", "num_citations": "6\n", "authors": ["316"]}
{"title": "An intuitive and formal description of preferences for semantic web service discovery and ranking\n", "abstract": " Preference modeling constitutes an essential component for the execution of Semantic Web Service (SWS) discovery and, especially, ranking processes, providing facilities to define user requests and preferences. In this technical report we describe our proposed preference model, introducing in Section 1 the existing challenges on this topic that motivates our research work. Section 2 presents an abstract upper ontology to define both services and user requests, that serves as a common model to make our proposal independent from concrete SWS frameworks. Then, Section 3 further describes, both intuitively and formally, our preference model and its facilities to define preferences within a user request. Finally, we sum up the main characteristics of our solution to model preferences for discovery and ranking in Section 4, discussing its fulfillment degree with respect to our identified challenges on preference modeling.", "num_citations": "6\n", "authors": ["316"]}
{"title": "Introducing a Mashup-Based Approach for Design-Time Compliance Checking in Business Processes\n", "abstract": " Business process compliance tries to ensure the business processes used in an organization are designed and executed according to the rules that govern the company. However, the nature of rules (expressed in natural language) and the large amount of elements that can be involved in them make their materialization and automated checking quite difficult. That is why the existing support for compliance checking is generally restricted to specific kinds of rules (e.g. rules affecting the control flow of the process). In this paper, we introduce compliance mashups, and show how a mashup-based approach can help solve the problem of rule specification and checking at design time. Some advantages of such an approach are that: (i) any kind of rule can be specified, which implies that each user can specify a rule according to his/her interpretation of the rule; (ii) building the compliance mashup is transparent\u00a0\u2026", "num_citations": "6\n", "authors": ["316"]}
{"title": "Tool supported error detection and explanations on feature models\n", "abstract": " Automated analysis of feature models (FM) is a field of interest in recent years. Many operations over FMs have been proposed and developed, and many researchers and industrial companies have adopted FMs as a way to express variability. This last makes more necessary having support to detect, explain and fix errors on FMs. The notation of FMs makes very easy to express variability, but makes hard detecting errors and find their cause manually. and these errors may cause the model does not express the variability what we want of it. Therefore, we need support to detect errors and find their causes. The contribution of this paper is a method to detect errors in FMs, based on the concept of observation. We also present implementations of this approach and of an approach to explain errors, in FaMa Framework [1] tool. To detect FM errors, firstly we have to identify the different error types and what it means each of them. Void FM error means that the FM does not represent any product, dead feature error means that a feature of the FM does not appear in any product, false optional error means that an optional feature appears in every product that its parent feature also appears, and wrong cardinality error means that one or more values of a set relationship cardinality are not reachable. We can check for these errors in a intuitive way. For instance, to detect if a FM has dead features, we can calculate every product and check if each feature appears in, at least, one product. But further, we propose a method based on observations, it means, FM configurations associated with a specific element (feature or cardinality). Each type of error has its type\u00a0\u2026", "num_citations": "6\n", "authors": ["316"]}
{"title": "FAST-SE: An ESB based framework for SLA trading\n", "abstract": " SLA driven service transaction has been identified as a key challenge to take advantage of a SOA. FAST System provides a software framework for the automated creation of SLAs. In particular it have been developed as an extension to the ESB (Enterprise Service Bus) paradigm to create a transparent SLA management layer that drives any service invocation. Our framework has been successfully applied in two different scenarios and provides an extensible architecture to address new domains.", "num_citations": "6\n", "authors": ["316"]}
{"title": "Spl needs an automatic holistic model for software reasoning with feature models\n", "abstract": " The number of features and their relations in a Software Product Line (SPL) may lead to have SPLs with a big number of potential products which may be difficult to manage. This number of potential products widely increases if, as well as functional features, extra\u2013functional features are taken into account. There are several questions that a SPL engineer would like to ask to his SPL model such as: is it a valid model?, how many potential products a SPL has?, is there any product fulfilling the customer needs? and so forth. These types of questions are error prone to answer without an automatic support. The work reported in this position paper glipmses some misconceptions of previous related proposals: we uphold the need to have an holistic product line model were not distinction are made between functional and extra\u2013functional features, we propose a model based on a formalism strong enough to support both type o features: contraint programming.", "num_citations": "6\n", "authors": ["316"]}
{"title": "Seeking for extra-functional variability\n", "abstract": " Software variability has been widely studied in terms of functionality but not so much in terms of extra-functionality. There already exist several proposals and mechanisms to represent functional variability in component development. However, there are still a lake defining extra-functional variability in component development and component acquisition in product lines. In this paper a mechanism claim to be necessary to formally describe so-called extra functional variability (EFV) in component development. Likewise, some conditions of such mechanism are presented and some solutions to these problems are briefly described.", "num_citations": "6\n", "authors": ["316"]}
{"title": "Automating SLA-Driven API Development with SLA4OAI\n", "abstract": " The OpenAPI Specification (OAS) is the de facto standard to describe RESTful APIs from a functional perspective. OAS has been a success due to its simple model and the wide ecosystem of tools supporting the SLA-Driven API development lifecycle. Unfortunately, the current OAS scope ignores crucial information for an API such as its Service Level Agreement (SLA). Therefore, in terms of description and management of non-functional information, the disadvantages of not having a standard include the vendor lock-in and prevent the ecosystem to grow and handle extra functional aspects.                 In this paper, we present SLA4OAI, pioneering in extending OAS not only allowing the specification of SLAs, but also supporting some stages of the SLA-Driven API lifecycle with an open-source ecosystem. Finally, we validate our proposal having modeled 5488 limitations in 148 plans of 35 real-world APIs and\u00a0\u2026", "num_citations": "5\n", "authors": ["316"]}
{"title": "Towards SLA-driven API gateways\n", "abstract": " As APIs are becoming popular to build Service-Based Ap- plications (SBA), API Gateways are being increasingly used to facilitate API features management. They o er API management functionalities such as pricing plans support, user authentication, API versioning or response caching. Some parts of the information that an API Gateway needs are already included into a Service Level Agreement (SLA), that providers use to describe the rights and the obligations of involved par- ties in the service. Unfortunately, current API Gateways do not use any SLA representation model nor SLA underlying technology, thereby miss- ing potential opportunities. In this paper we analyze the state of the art to justify the current situation and we identify some research challenges so as to achieve SLA-Driven API Gateways.", "num_citations": "5\n", "authors": ["316"]}
{"title": "ISA Packager: a tool for SPL deployment\n", "abstract": " In software projects, and particularly in Software Product Line (SPL) projects, product composition and deployment are tasks that are not supported by open source tools. These tasks are repetitive and error-prone. Automation helps on reducing the errors while the productivity increases. In this paper we present a real-world experience through ISA Packager, a generic tool to package and deploy SPLs. In this experience we build a SPL of SCADAs (Supervisory Control And Data Acquisition). Each customized SCADA product evolves in time and ISA Packager is in charge of easing product maintenance and updating.", "num_citations": "5\n", "authors": ["316"]}
{"title": "Modelado de negocio interorganizacional: Una aproximaci\u00f3n para la trazabilidad entre objetivos, modelos organizacionales y procesos de negocio\n", "abstract": " El principal objetivo del modelado de negocio es comprender el funcionamiento de las empresas para poder aportar soluciones software de alto valor a\u02dcnadido. Sin embargo, esta es una tarea que dista mucho de ser trivial, y se torna m\u00b4as compleja cuando lo que se modela no es una organizaci\u00b4on aislada sino varias organizaciones que interact\u00b4uan entre s\u00b4\u0131. Las propuestas sugeridas para el modelado de negocio han centrado sus esfuerzos en representar \u00b4unicamente los procesos de negocio, generalmente de organizaciones aisladas, dejando de lado tanto los modelos organizacionales como la informaci\u00b4on crucial para los directivos de las empresas. Esto es debido a que los modelos de negocio sugeridos est\u00b4an m\u00b4as orientados hacia la construcci\u00b4on del software que a brindar una vista abstracta del comportamiento de la empresa. Para suplir esta deficiencia, presentamos una aproximaci\u00b4on para el modelado de negocio basada en la metodolog\u00b4\u0131a de agentes MaCMAS en la que vinculamos los procesos de negocio a los objetivos y a los modelos organizacionales de interacci\u00b4on. Adem\u00b4as, aportamos mecanismos para mantener la trazabilidad entre todas las vistas y proveer descripciones a distintos niveles de abstracci\u00b4on, de modo que los modelos m\u00b4as abstractos son \u00b4utiles para los gestores empresariales, mientras que los m\u00b4as refinados son \u00b4utiles para los ingenieros de software.", "num_citations": "5\n", "authors": ["316"]}
{"title": "The Triple Schizophrenia of the Software Engineering Researcher.\n", "abstract": " In this paper we question the problem of a software engineering researcher, who in his daily work, has to deal with researching, teaching and learning activities at the same time. Likewise, we suggest the Action Research as the way to disentagle from that triple schizophrenia.", "num_citations": "5\n", "authors": ["316"]}
{"title": "On the relationships between decision management and performance measurement\n", "abstract": " Decision management is of utmost importance for the achievement of strategic and operational goals in any organisational context. Therefore, decisions should be considered as first-class citizens that need to be modelled, analysed, monitored to track their performance, and redesigned if necessary. Up to now, existing literature that studies decisions in the context of business processes has focused on the analysis of the definition of decisions themselves, in terms of accuracy, certainty, consistency, covering and correctness. However, to the best of our knowledge, no prior work exists that analyses the relationship between decisions and performance measurement. This paper identifies and analyses this relationship from three different perspectives, namely: the impact of decisions on process performance, the performance measurement of decisions, and the use of performance indicators in the definition of\u00a0\u2026", "num_citations": "4\n", "authors": ["316"]}
{"title": "A new framework for defining realistic SLAs: An evidence-based approach\n", "abstract": " In a changing and competitive business world, business processes are at the heart of modern organizations. In some cases, service level agreements (SLAs) are used to regulate how these business processes are provided. This is usually the case when the business process is outsourced, and some guarantees about how the outsourcing service is provided are required. Although some work has been done concerning the structure of SLAs for business processes, the definition of service level objectives (SLOs) remains a manual task performed by experts based on their previous knowledge and intuition. Therefore, an evidence-based approach that curtails humans involvement is required for the definition of realistic while challenging SLOs. This is the purpose of this paper, where performance-focused process mining, goal programming optimization techniques, and simulation techniques have been\u00a0\u2026", "num_citations": "4\n", "authors": ["316"]}
{"title": "Specifying Compensations with WS\u2011Agreement\n", "abstract": " During the last years the use of service level agreements (SLA) is rising uncontrollably to describe the rights and obligations of parties involved in service provisioning (typically the service consumer and the service provider); amongst other information, SLA could define guarantees associated with the idea of service level objectives (SLOs) that normally represent key performance indicators of either the consumer or the provider. In case the guarantee is under or over fulfilled SLAs could also define some compensations (i.e. penalties or rewards). In such a context, there have been important steps towards the automation of the analysis of SLAs. One of these steps is a characterization model of SLAs with compensations proposed by the authors in a previous work; and another step is the standardisation effort in the SLAs notation made by WS-Agreement. However, real-world SLAs includes complex concepts that\u00a0\u2026", "num_citations": "4\n", "authors": ["316"]}
{"title": "Programming elasticity and commitment in dynamic processes\n", "abstract": " In the past, elasticity and commitment in business processes were underexplored. But as businesses increasingly exploit pay-per-use resources in the cloud for on-demand needs, elasticity and commitment have become important issues. Here, the authors discuss the value of using elastic resources and commitments to create more dynamic organizations that can easily balance the need to be adaptable and flexible, while also retaining a high level of manageability.", "num_citations": "4\n", "authors": ["316"]}
{"title": "Configurable feature models\n", "abstract": " Feature models represent all the products that can be built under a variability-intensive system such as a software product line, but they are not fully configurable. There exist no explicit effort in defining configuration models that enable making decisions on attributes and cardinalities in feature models that use these artefacts. In this paper we present configurable feature models as an evolution from feature models that integrate configuration models within, improving the configurability of variability-intensive systems.", "num_citations": "4\n", "authors": ["316"]}
{"title": "iagree studio: A platform to edit and validate WS\u2013Agreement documents\n", "abstract": " The widespread use of SLA-regulated Cloud services, in which the violation of SLA terms may imply a penalty for the parties, have increased the importance and complexity of systems supporting the SLA lifecycle. Although these systems can be very different from each other, ranging from service monitoring platforms to auto-scaling solutions according to SLAs, they all share the need of having machine-processable and semantically valid SLAs. In this paper we present iAgree studio, the first application, up to our knowledge, that is able to edit and semantically validate agreement documents that are compliant with the WS\u2013Agreement specification by checking properties such as its consistency, and the compliance between templates and agreement offers. In addition, it reports explanations when documents are not valid. Moreover, it allows users to combine the validation and explanation operations by\u00a0\u2026", "num_citations": "4\n", "authors": ["316"]}
{"title": "WS-Governance: a policy language for SOA Governance\n", "abstract": " The widespread use of Service Oriented Architectures (SOA) is beginning to create problems derived from the governance of said structures. To date there is not a single effective solution to solve all existing challenges to govern this type of infrastructure. This paper describes the problems encountered when designing a SOA governance solution in a real e-Government scenario. More specifically, we focus on problems related to specification and automated analysis of government policies. We propose a novel SOA governance specification model as a solution to these problems. We have named this model WS-Governance. In order to ease its adoption by SOA practitioners it: i) shares WS-Policy guidelines and is compatible with it, ii) has XML serialization as well as a plain-text one and iii) has a semantics based on a mapping to Constraint Satisfaction Problems that provides a precise description as well\u00a0\u2026", "num_citations": "4\n", "authors": ["316"]}
{"title": "Context-Aware Process Performance Indicator Prediction\n", "abstract": " It is well-known that context impacts running instances of a process. Thus, defining and using contextual information may help to improve the predictive monitoring of business processes, which is one of the main challenges in process mining. However, identifying this contextual information is not an easy task because it might change depending on the target of the prediction. In this paper, we propose a novel methodology named CAP3 (Context-aware Process Performance indicator Prediction) which involves two phases. The first phase guides process analysts on identifying the context for the predictive monitoring of process performance indicators (PPIs), which are quantifiable metrics focused on measuring the progress of strategic objectives aimed to improve the process. The second phase involves a context-aware predictive monitoring technique that incorporates the relevant context information as input for the\u00a0\u2026", "num_citations": "3\n", "authors": ["316"]}
{"title": "Eagle: a team practices audit framework for agile software development\n", "abstract": " Agile/XP (Extreme Programming) software teams are expected to follow a number of specific practices in each iteration, such as estimating the effort (\u201d points\u201d) required to complete user stories, properly using branches and pull requests to coordinate merging multiple contributors\u2019 code, having frequent\u201d standups\u201d to keep all team members in sync, and conducting retrospectives to identify areas of improvement for future iterations. We combine two observations in developing a methodology and tools to help teams monitor their performance on these practices. On the one hand, many Agile practices are increasingly supported by web-based tools whose\u201d data exhaust\u201d can provide insight into how closely the teams are following the practices. On the other hand, some of the practices can be expressed in terms similar to those developed for expressing service level objectives (SLO) in software as a service; as an\u00a0\u2026", "num_citations": "3\n", "authors": ["316"]}
{"title": "The role of limitations and SLAs in the API industry\n", "abstract": " As software architecture design is evolving to a microservice paradigm, RESTful APIs are being established as the preferred choice to build applications. In such a scenario, there is a shift towards a growing market of APIs where providers offer different service levels with tailored limitations typically based on the cost.", "num_citations": "3\n", "authors": ["316"]}
{"title": "Fostering SLA-driven API specifications\n", "abstract": " Software architecture tendencies are shifting to a microservice paradigm. In this context, RESTful APIs are being established the standard of integration. API designer often identifies two key issues to be competitive in such growing market. On the one hand, the generation of accurate documentation of the behavior and capabilities of the API to promote its usage; on the other hand, the design of a pricing plan that fits into the potential API user\u2019s needs. Besides the increasing number of API modeling alternatives is emerging, there is a lack of proposals on the definition of flexible pricing plans usually contained in the Service Level Agreements (SLAs). In this paper we propose two different modeling techniques for the description of SLA in a RESTful API context: iAgree and SLA4OAI.", "num_citations": "3\n", "authors": ["316"]}
{"title": "System and method for compliance event and incident management (ceim)\n", "abstract": " Provided is a system and method for a continuous event and incident management approach to regulatory and compliance management, and business process management.", "num_citations": "3\n", "authors": ["316"]}
{"title": "KPIshare: A Collaborative Space for BPM Practitioners for Full Definitions and Discussions on Process KPIs.\n", "abstract": " The definition of process-related key performance indicators (KPIs) is a key part of performance measurement and one of the most challenging because of the lack of one best way to define businessapplicable KPIs that are both aligned with the strategic goals that the organisation wants to achieve and, at the same time, measurable and as objective as possible. In this demo, we present KPIshare, which is a web platform whose main goal is to provide the BPM community with a knowledge base of well-defined, mature KPIs and a place where they can discuss, collaborate and create process-related KPIs that are applicable in real business situations. To this end, KPIshare introduces a detailed structure for KPI definition and the concept of operational KPI challenge as a mechanism to foster the collaboration in the platform.", "num_citations": "3\n", "authors": ["316"]}
{"title": "Experiences from building a WS\u2013Agreement document analyzer tool (Including use cases in WS\u2013Agreement and WSAg4People) v1. 0\n", "abstract": " The WS\u2013Agreement specification has gained a wide acceptance in the web services community as a means 6 for establishing service level agreements between service providers and consumers. Although there are some implemen-7 tations of the WS\u2013Agreement protocol, the lack of user\u2013friendly tools for the edition and analysis of WS\u2013Agreement 8 documents is still a problem. In this paper, we present some experiences gained during the design and implementation of 9 the ADA framework and the WSAg4People language. On the one hand, ADA is a framework for the automated analysis 10 of WS\u2013Agreement documents, including the detection and explanation of conflicts, which can be used through a web 11 service API and a web\u2013based user interface. On the other hand, the WSAg4People language is a plain\u2013text language 12 equivalent to the XML\u2013based language proposed in the WS\u2013Agreement specification, which is much easier to read 13 and write for human users than its XML\u2013based counterpart. During our work, we have had to make decisions about the 14 variability points in WS\u2013Agreement and we have also identified potential enhancements to the current specification that 15 could be of interest for the WS\u2013Agreement practitioners in particular and for the web services community in general. 16", "num_citations": "3\n", "authors": ["316"]}
{"title": "Challenges to support a ppi management lifecycle\n", "abstract": " An important aspect in the business process lifecycle is the evaluation of business processes performance, since it helps organisations to define and measure progress towards their goals. Performance requirements on business processes can be specified by means of Process Performance Indicators (PPIs), as suggested in many methodologies and frameworks like, for instance, COBIT, ITIL or EFQM. As a consequence, it is convenient to integrate the management of PPIs into the whole business process lifecycle from its design to its evaluation, enabling thus a more effective an efficient automated support to extract information from such indicators. In this paper, we analyse some approaches related to this issue and identify the challenges that need to be faced.", "num_citations": "3\n", "authors": ["316"]}
{"title": "SOA Governance: exploring challenges & Benefits from an autonomic perspective\n", "abstract": " Both Academy and Industry agree in the importance of having an adequate management of the Service Oriented Architecture (SOA) to adapt and scale to meet the evolving needs of the organization. In order to face this problem, SOA Governance is defined as the set of policies and principles that manage the operations related with the SOA and allow an appropriate evolution aligned with the business goals of the organization. These are both human-oriented and infrastructure-oriented and can be applied within the overall life-cycle of the service: from designtime to run-time. Currently, some seminal works have been proposed to create a reference model for SOA Governance and some infrastructures of Governance have been proposed; current approaches rely on human-oriented tasks in governance without advanced autonomic behaviors. This paper shows SOA Governance automation as a challenge in the autonomic computing area, and analyzes how the different self-* properties of autonomic systems could be applied to this context, identifying desirable capabilities and open issues.", "num_citations": "3\n", "authors": ["316"]}
{"title": "ATL Transformation: Feature Models for representing runtime variability in BIS to Business Process Model Notation\n", "abstract": " The variability level of average-size Business Information Systems (BIS) is highly enough for making the design of this kind of systems a complex task. There is an approach, called Process Family Engineering (PFE), that tries to ease the design of BIS using ideas from the Software Product Lines (SPL) field. Roughly speaking, they propose to, first, study the variability of the system without entering into details by means of building a variability model (called feature model), that is used later for building the business process. However, in PFE the process of deriving the business process from the feature model is performed manually. In addition, they use feature models with a different meaning that is commonly accepted in SPL. In this paper, we provide a rigorous description for the new meaning of feature models, and mapping relationship that clearly defines how to use the information in the FM for obtaining the basic structure of the business process (that needs to be completed manually). In addition, as a proof of concepts, we have implemented an MDD transformation that provides the expected results.", "num_citations": "3\n", "authors": ["316"]}
{"title": "A top down approach for describing the acquaintance organisation of multiagent systems\n", "abstract": " \u0422\u0427 \u0429\u042d \u0426 \u0428\u2020 \u0418 \u042a \u0424 \u0427\u042a \u0420\u042d \u0424\u0427\u2020 \u0426 \u0426\u042c\u0427\u0426\u0421\u0427 \u042a\u042d\u0421 \u0419 \u0427\u042a\u042c \u042b\u2020 \u0437\u0438\u0436 \u0438\u041a \u042f \u0432 \u0438 \u0434\u0436\u0433\u0438\u0433 \u0433\u0430 \u0433 \u0433\u0431\u0434\u0430 \u043c \u0425\u0439\u0430\u0438 \u0419 \u0432\u0438 \u042b\u043d\u0437\u0438 \u0431 \u0414\u0425 \u042b\u0415 \u0432 \u0437 \u0438\u0433 \u043a \u0430\u0433\u0434 \u0418 \u0438 \u0438\u0433\u0434\u0419 \u0433\u043b\u0432 \u0434\u0434\u0436\u0433 \u0431\u0434 \u0437 \u0437 \u0437 \u0438\u0433 \u0437\u0438 \u0436\u0438 \u043b \u0438 \u0437\u0438\u0436 \u0438 \u0437 \u0436 \u0434\u0438 \u0433\u0432\u0437 \u0438 \u0438 \u0437 \u0433\u0439\u0430 \u0436 \u0432 \u0432 \u0436 \u0431 \u0432\u0438 \u0430\u0430\u043d \u0439\u0432\u0438 \u0430 \u043b \u043a \u0438 \u0438 \u0430 \u0430 \u043a \u0430 \u0432 \u0437\u0437 \u0436\u043d \u0438\u0433 \u0431\u0434\u0430 \u0431 \u0432\u0438 \u0438\u041a \u042d\u0432 \u0433\u0436\u0438\u0439\u0432 \u0438 \u0430\u043d\u0418 \u0438 \u0436 \u043c \u0437\u0438 \u0437 \u0431 \u0432\u0438 \u0434 \u0432 \u0432\u0438 \u0436 \u0438 \u0433\u0432 \u0434\u0436\u0433\u0438\u0433 \u0433\u0430 \u0431 \u0438 \u0433 \u0433\u0430\u0433 \u0437 \u0439\u0437 \u0431\u0433\u0437\u0438 \u0433 \u0438 \u0431 \u0436\u0437\u0438\u0418 \u0432\u0438 \u043d \u043b \u0438 \u0437 \u0437 \u0437 \u0438\u0433 \u0434 \u0436 \u0433\u0436\u0431 \u0418 \u0432 \u0438 \u0432 \u0439\u0437 \u0430\u0433\u043b \u0430 \u043a \u0430 \u0437 \u0436 \u0434\u0438 \u0433\u0432 \u0437\u0439 \u0437 \u0437 \u0435\u0439 \u0432 \u0437 \u0433 \u0431 \u0437\u0437 \u0437 \u0438\u0433 \u0438 \u0430 \u0438 \u0431\u041a \u0421\u0432 \u0438 \u0437 \u0434 \u0434 \u0436\u0418 \u043b \u0434\u0436\u0433\u0434\u0433\u0437 \u0432 \u0434\u0434\u0436\u0433 \u0438\u0433 \u0436 \u0438 \u0437 \u0434 \u0434\u0436\u0433\u0434\u0433\u0437 \u0432 \u0437 \u0438 \u0433 \u0438 \u0432 \u0435\u0439 \u0437 \u0438 \u0438 \u0436 \u0432\u0438 \u0436 \u0438 \u0432 \u0431 \u0438 \u0433 \u0433\u0430\u0433 \u043d \u0430\u0430 \u0425 \u0425 \u042b \u0414\u0425 \u0438 \u0433 \u0433\u0430\u0433 \u043d \u0433\u0436 \u0432 \u0430\u043d\u0437 \u0432 \u0433\u0431\u0434\u0430 \u043c \u0425\u0439\u0430\u0438 \u0432\u0438 \u042b\u043d\u0437\u0438 \u0431\u0437\u0415\u041a \u042f \u0431\u0433 \u0430 \u0425 \u042b \u0434\u0436\u0433\u0438\u0433 \u0433\u0430\u0437 \u0439\u0437 \u0432 \u0437 \u043a \u0436 \u0430 \u0437\u0438\u0436 \u0438 \u043a \u043b\u0437 \u0433 \u0438 \u0438 \u0437 \u0437 \u0438\u0433 \u0434 \u0436 \u0433\u0436\u0431 \u0418 \u0432 \u0434\u0436\u0433\u043a \u0437\u043d\u0437\u0438 \u0431 \u0438 \u0431 \u0438 \u0433 \u0438\u0433 \u0436 \u0431 \u0437\u0437 \u0437 \u0435\u0439 \u0432 \u0437 \u0437 \u0436 \u0434\u0438 \u0433\u0432\u0437 \u0436\u0433\u0431 \u0438 \u0437 \u0437 \u0436 \u0434\u0438 \u0433\u0432\u0437\u041a \u042c \u0437 \u0438 \u0437 \u0437 \u0436 \u0436 \u0434\u0436 \u0437 \u0432\u0438 \u043d \u0431 \u0432\u0437 \u0433 \u0432\u0438 \u0436 \u0438 \u0433\u0432\u0437 \u0438 \u0438 \u0437 \u0430\u0430 \u0436 \u0432 \u0437\u043d\u0437\u0438 \u0431 \u0438 \u0430\u0430\u043d \u0432\u0438\u0433 \u0430\u0433\u043b \u0436\u0419\u0430 \u043a \u0430 \u0432\u0438 \u0436 \u0438 \u0433\u0432\u0437 \u043b \u0438 \u0438 \u0438 \u0432 \u0435\u0439 \u0437 \u0434\u0436\u0433\u0434\u0433\u0437 \u0432 \u0438 \u0437 \u0434 \u0434 \u0436 \u0414\u0437 \u0431\u0434\u0430 \u0436 \u0432\u0438 \u0436 \u0438 \u0433\u0432\u0437 \u0436 \u0437 \u0436 \u0438\u0433 \u0437 \u0436 \u0432 \u0431\u0434\u0430 \u0431 \u0432\u0438 \u0439\u0437 \u0432 \u0431 \u0437\u0437 \u0434 \u0437\u0437 \u0432 \u041a\u0415 \u042d\u0432 \u0433\u0436\u0438\u0439\u0432 \u0438 \u0430\u043d\u0418 \u0430\u0433 \u0437 \u0431 \u043d \u0434\u0434 \u0436 \u0439 \u0438\u0433 \u0434\u0436\u0433\u0438\u0433 \u0433\u0430 \u0437 \u0432 \u0431 \u0437\u0438 \u0437 \u0433\u0436 \u0439 \u0438\u0433 \u0438 \u0436 \u0432 \u0431 \u0432\u0438 \u0434\u0436\u0433 \u0437\u0437 \u0438 \u0438 \u043b \u0434\u0436 \u0437 \u0432\u0438\u041a \u042c \u0439\u0437\u0418 \u043b \u0430\u0437\u0433 \u0434\u0436\u0433\u0434\u0433\u0437 \u0432 \u0430 \u0433\u0436 \u0438 \u0431 \u0438\u0433 \u0432\u0437\u0439\u0436 \u0438 \u0438 \u0434\u0436\u0433\u0438\u0433 \u0433\u0430\u0437 \u0436 \u0430\u0433 \u0436 \u041a", "num_citations": "3\n", "authors": ["316"]}
{"title": "Early Evaluation of Mobile Applications\u2019 Resource Consumption and Operating Costs\n", "abstract": " The explosive growth of the mobile application market in recent years has led to a large concomitant mobile software industry whose components are, in many cases, startups and small-size software providers. The success of these applications and the firms behind them depends on a subtle balance between different dimensions mainly affected by their architectural design, such as user satisfaction, resource consumption, operating costs, and timing. The present communication describes a framework with a specific set of practices for identifying the boundaries of different architectural designs \u2014in this article we apply it to estimate both the smartphone\u2019s resource consumption and the operating costs in the cloud\u2014 and thus help in the architectural decision-making process. This will enable mobile software developers to predict at early stages which architectural design best suits their business model in accordance\u00a0\u2026", "num_citations": "2\n", "authors": ["316"]}
{"title": "A Mashup-based Framework for Business Process Compliance Checking\n", "abstract": " Business process compliance ensures that the processes of an organisation are designed and executed according to the rules that govern it. We faced the challenge of building a compliance management system for a process-aware organisation and identified several needs that, despite having been identified in the literature, were only partially satisfied by existing approaches. The variability in the types of rules generally restricts the existing support for compliance checking to specific types of rules, a concrete phase of the business process management lifecycle, or certain information systems (ISs) for data retrieval. Motivated by this, we designed a conceptual framework for compliance checking that relies on the use of mashups for rule specification and checking, with the following advantages: (i) an open-ended set of rules can be specified by designing and connecting mashup components; (ii) (parts of) the\u00a0\u2026", "num_citations": "2\n", "authors": ["316"]}
{"title": "Towards compensable slas\n", "abstract": " Service Level Agreements (SLA) describe the rights and obligations of parties involved (typically the service consumer and the service provider); amongst other information they could include the definition of compensations: penalties and/or rewards depending on the level of service provided. We coin the concept of Compensable SLAs to such that include compensation information inside. In such a context, in spite of important steps towards the automation of the management of SLAs have been given, the expression of compensations remains as an important challenge to be addressed. In this paper we aim to provide a characterization model to create Compensable SLAs; specifically, the main contributions include: (i) the conceptualization of the Compensation Function to express consistently penalties and rewards. (ii) a model for Compensable SLAs as a set of guarantees that associate Service Level\u00a0\u2026", "num_citations": "2\n", "authors": ["316"]}
{"title": "Integrando las matrices RASCI en BPMN para la Gesti\u00f3n de la Responsabilidad\n", "abstract": " Las organizaciones necesitan gestionar qu\u00e9 responsabilidad tienen sus empleados sobre cada una de las actividades que se llevan a cabo diariamente en la empresa. Para ello se utilizan las matrices RACI, que indican el papel de cada miembro de la organizaci\u00f3n en cada actividad, por ejemplo si es responsable de su ejecuci\u00f3n, de su aprobaci\u00f3n, etc\u00e9tera. Por otro lado, la organizaciones de hoy en d\u0131a utilizan distintas notaciones para modelar sus procesos, siendo BPMN el est\u00e1ndar de modelado de procesos de negocio. En este art\u0131culo nos centramos en un tipo concreto de matrices RACI, llamado RASCI, e introducimos una aproximaci\u00f3n novedosa para construir modelos de procesos de negocio con informaci\u00f3n RASCI en BPMN bas\u00e1ndonos en lo que hemos llamado patrones RASCI. Adem\u00e1s, explicamos c\u00f3mo se puede transformar (semi-) autom\u00e1ticamente la informaci\u00f3n entre las matrices RASCI y este tipo de modelos. Creemos que la transformaci\u00f3n de RASCI a BPMN y viceversa puede ser \u00fatil para las organizaciones, al liberarlas de tener que mantener los modelos de procesos y las matrices por separado, permiti\u00e9ndoles as\u0131 centrarse s\u00f3lo en uno de estos elementos para hacer la gesti\u00f3n de la responsabilidad.", "num_citations": "2\n", "authors": ["316"]}
{"title": "RAL Solver: a Tool to Facilitate Resource Management in Business Process Models\n", "abstract": " Business process (BP) modelling notations tend to stray their attention from resource management, unlike other aspects such as control flow or even data flow. On the one hand, the languages they offer to assign resources to BP activities are usually either little expressive, or hard to use for non-technical users. On the other hand, they barely care about the subsequent analysis of resource assignments, which would enable the detection of problems and/or inefficiency in the use of the resources available in a company. We present RAL Solver, a tool that addresses the two aforementioned issues, and thus:(i) allows the specification of assignments of resources to BP activities in a reasonably simple way; and (ii) provides capabilities to automatically analyse resource assignments at design time, which allows extracting information from BP models, and detecting inconsistencies and assignment conflicts.", "num_citations": "2\n", "authors": ["316"]}
{"title": "WS-Governance Tooling: SOA Governance Policies Analysis and Authoring\n", "abstract": " Governance is a capital issue in current Service Oriented Arcuitectures, and governance policies are at its base. The governance policies definition must be supported by proper languages and tools, allowing for comfortable and collaborative editing, consistency checking and the evaluation policy meeting. In this paper we present a policy analizer for WS-Governance(a governance policy definition language created by authors, described in) together with an online editor and test suite with classical examples of WS-Governance Documents for consistency validation. Both the test model and the analysis tool prove the suitability of WS-Governance to define SOA governance policies.", "num_citations": "2\n", "authors": ["316"]}
{"title": "Using automated analysis of temporal-aware SLAs in logistics\n", "abstract": " Service level agreements (SLAs) establish the terms in which a logistics service may be provided or consumed. During the last years we have been studying techniques to perform an automated analysis of expressive and realistic SLAs, which makes the agreement creation process easier for involved parties. Firstly, we extended WS-Agreement specification to allow to apply any type of validity periods to SLA terms. Later, we dealt with the automated analysis of SLAs by proposing the explaining of SLAs inconsistencies and non-compliance scenarios. In this paper we show how these contributions are necessary to enable a logistic scenario of package tracking by providing examples for each proposal. We also include a final discussion on the convenience of performing a merge of all contributions to enable a better application of SLAs to logistic scenarios.", "num_citations": "2\n", "authors": ["316"]}
{"title": "Dealing with fixable and non-fixable properties in service matchmaking\n", "abstract": " In the context of service discovery, matchmakers check the compliance of service-level objectives from providers and consumers. The problem of bounded uncertainty arises if some property is non-fixable. In this case, the provider is not able to control the value it takes at runtime, so the eventual consumer must not have the choice to select a value and fix it, but only knowing the guaranteed range of values it may take. To the best of our knowledge, there does not exist any approach which deals with this scenario. Most matchmakers work as if all properties were fixable, and a few have assumed the contrary. In either case, the accuracy of their results is likely to be in question since there may be involved both fixable and non-fixable properties at the same time, and there may also exist dependencies between them. In order to improve the accuracy, we present a holistic approach to matchmaking under\u00a0\u2026", "num_citations": "2\n", "authors": ["316"]}
{"title": "Business Family Engineering. Managing the Evolution of Business Driven Systems\n", "abstract": " Nowadays most companies in whichever field have a software system that helps managing all the aspects of the company, from the strategic management to daily activities. Companies are in continuous evolution to adapt to market changes, and consequently, the Information Technology (IT) infrastructure that supports it must also evolve. Thus, software companies are currently supporting this evolution with ad hoc techniques. We think that, as it is being done for traditional software systems (non-oriented to business process) in the software product line (SPL) field, institutionalized techniques for performing a systematic reuse of business processes across different businesses can be introduced. in this paper, we propose to adapt SPL techniques, oriented to reuse software, to Business-Driven Development (BDD), oriented to reuse processes, across different businesses; we call this proposal Business Family Engineering (BFE). We present a first approach to build a SPL of BDD systems that evolves at runtime", "num_citations": "2\n", "authors": ["316"]}
{"title": "Using constraint programming for the automatic detection of conflicts in quality requirements\n", "abstract": " Requirements negotiation is quite an interesting, ongoing research area. Current requirements engineering models usually propose a negotiation process with similar methods and goals. Unfortunately, only a few have partial automatic support. in this paper, we revisit one of the most mature models, Boehm\u2019s Win\u2013Win model. Win\u2013Win is a qualitative, process\u2013oriented model so that it is specially suited to be used at the early stages of requirements engineering, when knowledge about requirements is still vague, but not for quantitative, product\u2013oriented contexts where a more precise, exact knowledge about the requirements is needed. in this paper, we present a proposal to extend and refine Win\u2013Win in order it can be used in product\u2013oriented contexts. The main benefit of our approach is that the same conceptual model for requirements negotiation can be used during all software development process, instead of using different models in different phases", "num_citations": "2\n", "authors": ["316"]}
{"title": "Especificaci\u00f3n de requisitos de calidad en sistemas multiorganizacionales basados en servicios web\n", "abstract": " Especificaci\u00f3n de requisitos de calidad en sistemas multiorganizacionales basados en servicios web - Dialnet Ir al contenido Dialnet Buscar Revistas Tesis Congresos Ayuda Especificaci\u00f3n de requisitos de calidad en sistemas multiorganizacionales basados en servicios web Autores: Antonio Ruiz, Amador Dur\u00e1n Toro, Jos\u00e9 Miguel Toro Bonilla, Rafael Corchuelo Gil Localizaci\u00f3n: JISBD 2001. Jornadas de ingenier\u00eda del software y bases de datos: 21 y 23 de noviembre de 2001. Almagro (Ciudad Real) / Arantza Illarramendi Echave ( ed. lit. ), \u00d3scar D\u00edaz Garc\u00eda ( ed. lit. ), Mario G. Piattini Velthuis ( ed. lit. ), 2001, ISBN 84-699-6275-2, p\u00e1gs. 615-629 Idioma: espa\u00f1ol Texto completo no disponible (Saber m\u00e1s ...) Fundaci\u00f3n Dialnet Acceso de usuarios registrados Imagen de identificaci\u00f3n Identificarse \u00bfOlvid\u00f3 su contrase\u00f1a? \u00bfEs nuevo? Reg\u00edstrese Ventajas de registrarse Dialnet Plus M\u00e1s informaci\u00f3n sobre Dialnet Plus \u2026", "num_citations": "2\n", "authors": ["316"]}
{"title": "Elastic Smart Contracts in Blockchains\n", "abstract": " In this paper, we deal with questions related to blockchains in complex Internet of Things (IoT)-based ecosystems. Such ecosystems are typically composed of IoT devices, edge devices, cloud computing software services, as well as people, who are decision makers in scenarios such as smart cities. Many decisions related to analytics can be based on data coming from IoT sensors, software services, and people. However, they are typically based on different levels of abstraction and granularity. This poses a number of challenges when multiple blockchains are used together with smart contracts. This work proposes to apply our concept of elasticity to smart contracts and thereby enabling analytics in and between multiple blockchains in the context of IoT. We propose a reference architecture for Elastic Smart Contracts and evaluate the approach in a smart city scenario, discussing the benefits in terms of performance\u00a0\u2026", "num_citations": "1\n", "authors": ["316"]}
{"title": "Design Patterns for Board-Based Collaborative Work Management Tools\n", "abstract": " Board-based software tools for managing collaborative work (eg Trello or Microsoft Planner) are highly configurable information systems. Their structure is based on boards that contain cards organized in lists. This structure allows users to organize a wide variety of formal or informal information and work processes in a very flexible way. However, this flexibility means that in every situation the user is required to make decisions to design a new board from scratch, which is not a straightforward task, specially if performed by non-technical users. In this paper, we carried out a study following an inductive approach consisting of analyzing 91 Trello board designs from both research works and board templates proposed by Trello users, which cover a wide variety of domains and use cases. The result is twofold. First, we propose a metamodel for designing boards that takes into account not only the structure of the board\u00a0\u2026", "num_citations": "1\n", "authors": ["316"]}
{"title": "Virtual environment for evaluating the qos of distributed mobile applications\n", "abstract": " The increasing capabilities of end devices has led to a wider distribution of the computation and the massive deployment of distributed mobile applications. The success of these applications is highly dependent on the Quality of Service they provide. This quality is especially difficult to assess due to the large number of entities involved and their heterogeneity. Current tools are usually focused on evaluating the QoS provided by a single entity. Nevertheless, the QoS of distributed applications not only depend on the QoS of each entity, the interactions among entities has also to be evaluated. Therefore, new techniques are required to perform a comprehensive evaluation of the expected QoS of these applications before their production deployment. This paper presents a framework, called Perses, for launching virtual environments to simulate and test the execution of distributed mobile applications. This simulation\u00a0\u2026", "num_citations": "1\n", "authors": ["316"]}
{"title": "SLA-driven governance for RESTful systems\n", "abstract": " Sofware distribution models are moving to SaaS paradigms where customers no longer need to buy a perpetual license. In this context, SaaS providers leverage the Service Level Agreement (SLA) concept to delimit the functionality and guarantees to which they commit to their customers. However, although formal specifications for the definition of SLAs have been proposed, providers usually have an ad-hoc approach with a low degree of automation. This approach confirms the fact that the SaaS industry has not incorporated the idea of an SLA model that can be implemented within the infrastructure as a decision mechanism. This instrumentation would be of special interest in RESTful microservice architectures in providing an automated governance framework for the service catalog and regulating the behavior of each component in the context of the agreements reached with each client.                 This\u00a0\u2026", "num_citations": "1\n", "authors": ["316"]}
{"title": "On the feasibility of measuring performance using PPINOT in CMMN\n", "abstract": " Monitoring and measuring the performance of business pro- cesses are valuable tasks that facilitate the identi cation of possible im- provement areas within the organisation according to the ful llment of its strategic and business goals. A large number of techniques and tools have been developed with the aim of measuring process performance, but most of those processes are structured processes, usually de ned using BPMN. The object of this paper is to identify and to analyse the feasi- bility of using an existing mechanism for the de nition and modelling of process performance indicators (PPINOT) in a di erent context to struc- tured BPMN processes; such as Cases, usually modelled using CMMN. This analysis is based on the similarities between CMMN and BPMN, and on characteristics and attributes used by PPINOT to get values from the process.", "num_citations": "1\n", "authors": ["316"]}
{"title": "Supporting Compensations with WS-Agreement\n", "abstract": " During the last years the use of service level agreements (SLA) is rising uncontrollably to describe the rights and obligations of parties involved in service provisioning (typically the service consumer and the service provider); amongst other information, SLA could define guarantees associated with the idea of service level objectives (SLOs) that normally represent key performance indicators of either the consumer or the provider. In case the guarantee is under or over fulfilled SLAs could also define some compensations (ie penalties or rewards). In such a context, there have been important steps towards the automation of the analysis of SLAs. One of these steps is a characterization model of SLAs with compensations proposed by the authors in a previous work; and another step is the standardisation effort in the SLAs notation made by WS\u2013Agreement. However, real-world SLAs includes complex concepts that must be considered, namely:(i) SLA terms that specify compensations without an explicit SLO; and (ii) a limit for the compensations. In this paper we extend our prior characterization model considering these complex concepts. Specifically,(i) we provide up to five real-world scenarios whose SLAs incorporate aforementioned new concepts;(ii) we extend our model for compensable guarantees considering terms without an explicit SLO; and (iii) we provide a novel WS\u2013Agreement-based syntax to model SLAs with compensations considering these concepts. These contributions aim to establish a foundation to elaborate tools that could provide an automated support to the modelling and analysis of SLAs with compensations.", "num_citations": "1\n", "authors": ["316"]}
{"title": "Towards assessing open source communities' health using SOC concepts\n", "abstract": " Quality of an open source software ecosystem (OSS ecosystem) is key for different ecosystem actors such as contributors or adopters. In fact, the consideration of several quality aspects(e.g., activeness, visibility, interrelatedness, etc.) as a whole may provide a measure of the healthiness of OSS ecosystems. The more health a OSS ecosystem is, the more and better contributors and adopters it will gather. Some research tools have been developed to gather specific quality information from open source community data sources. However, there exist no frameworks available that can be used to evaluate their quality as a whole in order to obtain the health of an OSS ecosystem. To assess the health of these ecosystems, we propose to adopt robust principles and methods from the Service Oriented Computing field.", "num_citations": "1\n", "authors": ["316"]}
{"title": "Aprendiendo a dise\u00f1ar software usando juegos de mesa de licencia libre como enunciado de pr\u00e1cticas\n", "abstract": " El planteamiento de trabajos pr\u00e1cticos para el aprendizaje del dise\u00f1o de software es una tarea compleja pues resulta necesario encontrar problemas de cierta envergadura, con puntos de variaci\u00f3n y comportamientos complejos que eviten dise\u00f1os triviales y que, adem\u00e1s resulten motivadores para el alumno. En este art\u00edculo describimos nuestra experiencia de 3 a\u00f1os en el dise\u00f1o, por parte del alumno, de software que implementa juegos de mesa. Los juegos de mesa cumplen los requisitos anteriores. Adem\u00e1s, sus exhaustivas reglas son f\u00e1cilmente usables como documentos de requisitos y la existencia de una amplia base de datos de juegos de licencia libre permite disponer con facilidad de multitud de problemas similares. Con este enfoque hemos mejorado significativamente el porcentaje de \u00e9xito de la asignatura.", "num_citations": "1\n", "authors": ["316"]}
{"title": "FaMa Abductive: una herramienta para explicaciones de errores en modelos de caracter\u00edsticas\n", "abstract": " La diagnosis de errores es una asignatura pendiente de gran parte de las herramientas de an\u00b4alisis de modelos de caracter\u00b4\u0131sticas. Realizar este proceso manualmente no es viable con modelos de tama\u02dcno medio/grande, e incluso tampoco para modelos peque\u02dcnos, pues la mayor\u00b4\u0131a de errores son extremadamente dif\u00b4\u0131ciles de detectar y m\u00b4as a\u00b4un de explicar. En esta demo presentamos FaMa Abductive, una extensi\u00b4on de la herramienta FaMa, encargada de la diagnosis autom\u00b4atica en modelos de caracter\u00b4\u0131sticas. Esta herramienta provee detecci\u00b4on y explicaciones para errores en modelos de caracter\u00b4\u0131sticas, tanto b\u00b4asicos como extendidos, y tambi\u00b4en para productos err\u00b4oneos en modelos de caracter\u00b4\u0131sticas b\u00b4asicos.", "num_citations": "1\n", "authors": ["316"]}
{"title": "A Methodological Framework for Obtaining the Core Architecture of Business Information Systems Families\n", "abstract": " Nowadays large organizations are the result of the interrelation of many business units which tend to be managed based on its business processes. The development of the Information Technology (IT) infrastructure that supports these organizations is a complex task, due to the existence of different versions of the same process, namely core process, tailored in terms of each unit that executes it. Thus, organizations lost the matching between each version and the original. It implies problems in the maintenance of process specifications, that drives to an inaccurate execution of the business strategies of the organization. The introduction of Software Product Lines (SPL) techniques into the development of Business Information Systems (BIS) is expected to become a new development paradigm, of what we call Business Families, maximizing reuse and dealing with variability on process definitions. Current SPL-based proposals do not solve the identified problems, because the proposed design of the reusable core specification is not performed in a systematic way that maintains its traceability with derived processes. The main contribution of this paper is to provide a methodological framework that taking into account the identified drawbacks makes feasible to obtain, systematically, the core architecture of a Business Information System Family, composed by the core process and the extra information needed to derive, systematically too, each version. We exemplify our approach with reference to a real-life E-Government case study.", "num_citations": "1\n", "authors": ["316"]}
{"title": "Hacia el enlace entre la estrategia empresarial mediante modelos de valor y el software mediante modelos de negocio: un enfoque mda\n", "abstract": " Uno de los objetivos del modelado de negocio es comprender el funcionamiento de las empresas con el fin de aportar soluciones software de alto valor a\u00f1adido.", "num_citations": "1\n", "authors": ["316"]}
{"title": "Hacia el enlace entre la estrategia empresarial mediante modelos de valor y el software de negocio: Un enfoque MDD\n", "abstract": " Uno de los objetivos del modelado de negocio es comprender el funcionamiento de las empresas con el fin de aportar soluciones software de alto valor a\u00f1adido.", "num_citations": "1\n", "authors": ["316"]}
{"title": "A Case Tool for Specifying Domain Requirements Document with Variability\n", "abstract": " Variability is one of the critical aspects of a Software Product Line (SPL), due to it represents the differences and commonalities inside an application domain. SPL developers need software tools to document variability at requirements documents. Unfortunately, in a first analysis, we have not found a CASE tool covering a complete requirements document.", "num_citations": "1\n", "authors": ["316"]}
{"title": "Breakthroughs and Challenges in Software Engineering\n", "abstract": " In the seminal 1968 NATO Conference on Software Engineering, FL Bauer defined this term as\" the establishment and use of sound engineering principles in order to obtain software that is reliable and works efficiently on real machines\". In the beginning, most proposals focused on programming languages and techniques, which are currently in a rather elaborate state. Later, the discipline experienced a shift from programming to project management, requirements, analysis, design, or maintenance issues. Furthermore, the Internet seems to be a new cornerstone that is gaining currency and paving the way for a new generation of software applications that are becoming more complex at an ever increasing pace. One of the reasons lies in the heterogeneous nature of the run-time and development-time aspects to be taken into account: attractiveness, quality of service, security, robustness, distribution, standards\u00a0\u2026", "num_citations": "1\n", "authors": ["316"]}
{"title": "Vivacidad y justicia en entornos no deterministas\n", "abstract": " El problema de la vivacidad y la selecci\u00f3n justa surge en el contexto de los sistemas con ejecuciones no determinadas. El concepto de selecci\u00f3n completamente justa sirve para garantizar que todos los elementos que se habilitan infinitamente a menudo se ejecutan infinitamente a menudo.", "num_citations": "1\n", "authors": ["316"]}
{"title": "Applying XML technologies in Requirements Verification\n", "abstract": " In this paper, we present an approach for the automatic verification of software requirements specifications. This approach is based on the representation of software requirements in XML and the usage of the XSLT language not only to automatically generate requirements documents, but also to verify some desired quality properties and to automatically compute some defect\u2013predictive metrics. These ideas have been implemented in REM, an experimental requirements management tool that is also described in this paper.", "num_citations": "1\n", "authors": ["316"]}
{"title": "Implementing Automatic Quality Verification of Requirements with XML and XSLT\n", "abstract": " It is widely acknowledged within the software community that requirements quality is one of the most important factors in the success of software projects. In this paper, we show how XML and XSLT can be used to implement requirements verification heuristics that can help to discover hidden conflicts and defects in natural language requirements. This approach is based on the representation of requirements in XML and in the usage of XSLT stylesheets not only to automatically generate requirements documents, but also to implement verification heuristics using some requirements\u2013oriented metrics. These ideas have been implemented in REM, an experimental XML\u2013based requirements management tool also described in this paper.", "num_citations": "1\n", "authors": ["316"]}
{"title": "A first approach to model slas for composite services, using ws-agreement\n", "abstract": " When organizations began to use intensively services oriented applications (SOA) they arose the need of service level agreements (SLAs) to provide the confidence needed on quality of service (QoS). Nowadays, we have a consensus on what an SLA for a service is and as consequence, languages to specify SLAs as WS-Agreement have been proposed and they are becoming popular. One of the key topics in SOA research at present are composite services (CS). CS have been tackled by many authors and there is a consensus on their definition. However, not many works deal with SLAs for CS. The reason could be the lack of an intensive use of CS applications in business context. But in future CS applications comprised by heterogeneous services-defined in diverse specification languages or supported by different platforms-may gain the attention of companies and they will need a QoS support. Then, we consider interesting to obtain a general definition of SLAs for CS starting from current proposals. In this paper we analyze different meanings given in the literature for the expression SLAs for CS, we find the shared aspects, we study the unshared ones and we propose to include important additional elements into our abstract model for defining SLAs for CS, such as temporal information and QoS properties about the whole CS. Finally, we promote the use of WS-Agreement with some non-intrusive extensions proposed by us for the establishment of SLAs for CS according to our abstract model, including several use cases.", "num_citations": "1\n", "authors": ["316"]}
{"title": "Apoyo a la Toma de Decisiones en la Compra de IaaS\n", "abstract": " La dificultad para decidir la compra de un IaaS (Infrastructure as a Service) depende de la complejidad de las opciones de compra dadas por su proveedor y de la complejidad del plan del cliente que quiere realizarla. Es habitual que estos tipos de servicios ofrezcan muchas configuraciones de uso diferentes, y para cada una de ellas sea posible disponer de varias opciones de compra. De este modo, decidir la mejor compra se convierte en una tarea que consume mucho tiempo, tediosa y propensa a errores. En este trabajo inicial, caracterizamos el problema con un caso de estudio ilustrativo y presentamos los desaf\u00edos inmediatos para mejorar las herramientas de soporte actualmente disponibles.", "num_citations": "1\n", "authors": ["316"]}
{"title": "\u00bf Por qu\u00e9 OMG ha elegido BPMN para modelar de Procesos de Negocio si ya existe UML?\n", "abstract": " Desde junio del 2005 la BPMI (Business Process Management Initiative) es miembro de la OMG (Object Management Group). En esta uni\u00f3n confluyen por una lado una organizaci\u00f3n con gran experiencia en el modelado de procesos de negocio y con una notaci\u00f3n ampliamente difundida, BPMN (Bussiness Process Management Notation), y por otro lado la organizaci\u00f3n internacional m\u00e1s importante a la hora de crear est\u00e1ndares relacionados con la ingenier\u00eda del Software. Uno de esos est\u00e1ndares, el m\u00e1s difundido, es UML (Unified Modeling Language) una de cuyas partes, los Diagramas de Actividad, tiene entre sus objetivos el modelado de procesos de negocio. Por tanto, encontramos dos especificaciones con prop\u00f3sitos similares dentro de la misma organizaci\u00f3n. En este trabajo discutimos sobre algunas de las razones que en nuestra opini\u00f3n favorecen que la OMG apueste por BPMN en detrimento de los diagramas de actividad de UML para modelar procesos de negocio.", "num_citations": "1\n", "authors": ["316"]}