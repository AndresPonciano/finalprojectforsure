{"title": "Handbook of Satisfiability: Volume 185 Frontiers in Artificial Intelligence and Applications\n", "abstract": " \u201cSatisfiability (SAT) related topics have attracted researchers from various disciplines: logic, applied areas such as planning, scheduling, operations research and combinatorial optimization, but also theoretical issues on the theme of complexity and much more, they all are connected through SAT. My personal interest in SAT stems from actual solving: The increase in power of modern SAT solvers over the past 15 years has been phenomenal. It has become the key enabling technology in automated verification of both computer hardware and software. Bounded Model Checking (BMC) of computer hardware is now probably the most widely used model checking technique. The counterexamples that it finds are just satisfying instances of a Boolean formula obtained by unwinding to some fixed depth a sequential circuit and its specification in linear temporal logic. Extending model checking to software verification is a much more difficult problem on the frontier of current research. One promising approach for languages like C with finite word-length integers is to use the same idea as in BMC but with a decision procedure for the theory of bit-vectors instead of SAT. All decision procedures for bit-vectors that I am familiar with ultimately make use of a fast SAT solver to handle complex formulas. Decision procedures for more complicated theories, like linear real and integer arithmetic, are also used in program verification. Most of them use powerful SAT solvers in an essential way. Clearly, efficient SAT solving is a key technology for 21st century computer science. I expect this collection of papers on all theoretical and practical aspects of SAT solving will\u00a0\u2026", "num_citations": "2110\n", "authors": ["1804"]}
{"title": "Solving and verifying the boolean pythagorean triples problem via cube-and-conquer\n", "abstract": " The boolean Pythagorean Triples problem has been a longstanding open problem in Ramsey Theory: Can the set  of natural numbers be divided into two parts, such that no part contains a triple (a,\u00a0b,\u00a0c) with  ? A prize for the solution was offered by Ronald Graham over two decades ago. We solve this problem, proving in fact the impossibility, by using the Cube-and-Conquer paradigm, a hybrid SAT method for hard problems, employing both look-ahead and CDCL solvers. An important role is played by dedicated look-ahead heuristics, which indeed allowed to solve the problem on a cluster with 800 cores in about 2 days. Due to the general interest in this mathematical problem, our result requires a formal proof. Exploiting recent progress in unsatisfiability proofs of SAT solvers, we produced and verified a proof in the DRAT format, which is almost 200 terabytes in size. From this we\u00a0\u2026", "num_citations": "192\n", "authors": ["1804"]}
{"title": "DRAT-trim: Efficient checking and trimming using expressive clausal proofs\n", "abstract": " The DRAT-trim tool is a satisfiability proof checker based on the new DRAT proof format. Unlike its predecessor, DRUP-trim, all presently known SAT solving and preprocessing techniques can be validated using DRAT-trim. Checking time of a proof is comparable to the running time of the proof-producing solver. Memory usage is also similar to solving memory consumption, which overcomes a major hurdle of resolution-based proof checkers. The DRAT-trim tool can emit trimmed formulas, optimized proofs, and new TraceCheck\u2009+\u2009 dependency graphs. We describe the output that is produced, what optimizations have been made to check RAT clauses, and potential applications of the tool.", "num_citations": "164\n", "authors": ["1804"]}
{"title": "Exact DFA identification using SAT solvers\n", "abstract": " We present an exact algorithm for identification of deterministic finite automata (DFA) which is based on satisfiability (SAT) solvers. Despite the size of the low level SAT representation, our approach is competitive with alternative techniques. Our contributions are fourfold: First, we propose a compact translation of DFA identification into SAT. Second, we reduce the SAT search space by adding lower bound information using a fast max-clique approximation algorithm. Third, we include many redundant clauses to provide the SAT solver with some additional knowledge about the problem. Fourth, we show how to use the flexibility of our translation in order to apply it to very hard problems. Experiments on a well-known suite of random DFA identification problems show that SAT solvers can efficiently tackle all instances. Moreover, our algorithm outperforms state-of-the-art techniques on several hard problems.", "num_citations": "115\n", "authors": ["1804"]}
{"title": "March_eq: Implementing additional reasoning into an efficient look-ahead SAT solver\n", "abstract": " This paper discusses several techniques to make the look- ahead architecture for satisfiability (Sat) solvers more competitive. Our contribution consists of reduction of the computational costs to perform look-ahead and a cheap integration of both equivalence reasoning and local learning. Most proposed techniques are illustrated with experimental results of their implementation in our solver march_eq.", "num_citations": "113\n", "authors": ["1804"]}
{"title": "Trimming while checking clausal proofs\n", "abstract": " Conflict-driven clause learning (CDCL) satisfiability solvers can emit more than a satisfiability result; they can also emit clausal proofs, resolution proofs, unsatisfiable cores, and Craig interpolants. Such additional results may require substantial modifications to a solver, especially if preprocessing and inprocessing techniques are used; however, CDCL solvers can easily emit clausal proofs with very low overhead. We present a new approach with an associated tool that efficiently validates clausal proofs and can distill additional results from clausal proofs. Our tool architecture makes it easy to obtain such results from any CDCL solver. Experimental evaluation shows that our tool can validate clausal proofs faster than existing tools. Additionally, the quality of the additional results, such as unsatisfiable cores, is higher when compared to modified SAT solvers.", "num_citations": "97\n", "authors": ["1804"]}
{"title": "Clause Elimination Procedures for CNF Formulas.\n", "abstract": " We develop and analyze clause elimination procedures, a specific family of simplification techniques for conjunctive normal form (CNF) formulas. Extending known procedures such as tautology, subsumption, and blocked clause elimination, we introduce novel elimination procedures based on hidden and asymmetric variants of these techniques. We analyze the resulting nine (including five new) clause elimination procedures from various perspectives: size reduction, BCP-preservance, confluence, and logical equivalence. For the variants not preserving logical equivalence, we show how to reconstruct solutions to original CNFs from satisfying assignments to simplified CNFs. We also identify a clause elimination procedure that does a transitive reduction of the binary implication graph underlying any CNF formula purely on the CNF level.", "num_citations": "90\n", "authors": ["1804"]}
{"title": "SAT competition 2016: Recent developments\n", "abstract": " We give an overview of SAT Competition 2016, the 2016 edition of thefamous competition for Boolean satisfiability (SAT) solvers with over 20 years of history. A key aim is to point out``what's hot''in SAT competitions in 2016, ie, new developments in thecompetition series, including new competition tracks and new solver techniquesimplemented in some of the award-winning solvers.", "num_citations": "82\n", "authors": ["1804"]}
{"title": "Schur number five\n", "abstract": " We present the solution of a century-old problem known as Schur Number Five: What is the largest (natural) number n such that there exists a five-coloring of the positive numbers up to n without a monochromatic solution of the equation a+ b= c? We obtained the solution, n= 160, by encoding the problem into propositional logic and applying massively parallel satisfiability solving techniques on the resulting formula. We also constructed and validated a proof of the solution to increase trust in the correctness of the multi-CPU-year computations. The proof is two petabytes in size and was certified using a formally verified proof checker, demonstrating that any result by satisfiability solvers---no matter how large---can now be validated using highly trustworthy systems.", "num_citations": "73\n", "authors": ["1804"]}
{"title": "Look-Ahead Based SAT Solvers.\n", "abstract": " Imagine that you are for the first time in New York City (NYC). A cab just dropped you off at a crossing and now you want to see the most beautiful part of town. You consider two potential strategies to get going: A conflict-driven strategy and a look-ahead strategy.The conflict-driven strategy consists of the following heuristics: On each crossing you look in all directions and walk towards the crossing which appears most beautiful at first sight. If at a certain crossing all new directions definitely lead to dead end situations, you write the location in a booklet to avoid the place in the future and you evaluate which was the nearest crossing where you likely chose the wrong direction. You go back to that crossing and continue with a new preferred direction.", "num_citations": "72\n", "authors": ["1804"]}
{"title": "Verifying refutations with extended resolution\n", "abstract": " Modern SAT solvers use preprocessing and inprocessing techniques that are not solely based on resolution; existing unsatisfiability proof formats do not support SAT solvers using such techniques. We present a new proof format for checking unsatisfiability proofs produced by SAT solvers that use techniques such as extended resolution and blocked clause addition. Our new format was designed with three goals: proofs should be easy to generate, proofs should be compact, and validating proofs must be simple. We show how existing preprocessors and solvers can be modified to generate proofs in our new format. Additionally, we implemented a mechanically-verified proof checker in ACL2 and a proof checker in C for the proposed format.", "num_citations": "65\n", "authors": ["1804"]}
{"title": "A new method to construct lower bounds for van der Waerden numbers\n", "abstract": " We present the Cyclic Zipper Method, a procedure to construct lower bounds for Van der Waerden numbers. Using this method we improved seven lower bounds. For natural numbers ,  and  a Van der Waerden certificate  is a partition of  into  subsets, such that none of them contains an arithmetic progression of length (or larger). Van der Waerden showed that given  and , a smallest  exists-the Van der Waerden number -for which no certificate  exists. In this paper we investigate Van der Waerden certificates which have certain symmetrical and repetitive properties. Surprisingly, it shows that many Van der Waerden certificates, which must avoid repetitions in terms of arithmetic progressions, reveal strong regularities with respect to several other criteria. The Cyclic Zipper Method exploits these regularities. To illustrate these regularities, two techniques are introduced to visualize certificates.", "num_citations": "63\n", "authors": ["1804"]}
{"title": "Proceedings of SAT Competition 2014\n", "abstract": " The area of Boolean satisfiability (SAT) solving has seen tremendous progress over the last years. Many problems (eg, in hardware and software verification) that seemed to be completely out of reach a decade ago can now be handled routinely. Besides new algorithms and better heuristics, refined implementation techniques turned out to be vital for this success. To keep up the driving force in improving SAT solvers, SAT solver competitions provide opportunities for solver developers to present their work to a broader audience and to objectively compare the performance of their own solvers with that of other state-of-theart solvers.SAT Competition 2014 (SC 2014), an open competitive event for SAT solvers, was organized as a satellite event of the 17th International Conference on Theory and Applications of Satisfiability Testing (SAT 2014) and FLoC Olympic Games 2014 within the largest event in the history of logic, Vienna Summer of Logic (VSL) 2014, and the Federated Logic Conference (FLoC 2014) in Vienna, Austria. SC 2014 stands in the tradition of the previously organized main competitive events for SAT solvers: the SAT Competitions held 2002-2005 and biannually during 2007-2013, the SAT-Races held in 2006, 2008 and 2010, and SAT Challenge 2012.", "num_citations": "60\n", "authors": ["1804"]}
{"title": "March_dl: Adding adaptive heuristics and a new branching strategy\n", "abstract": " We introduce the march_dl satisfiability (SAT) solver, a successor of march_eq. The latter was awarded state-of-the-art in two categories during the Sat 2004 competition. The focus lies on presenting those features that are new in march_dl. Besides a description, each of these features is illustrated with some experimental results. By extending the pre-processor, using adaptive heuristics, and by using a new branching strategy, march_dl is able to solve nearly all benchmarks faster than its predecessor. Moreover, various instances which were beyond the reach of march_eq, can now be solved-relatively easily-due to these new features.", "num_citations": "60\n", "authors": ["1804"]}
{"title": "The science of brute force\n", "abstract": " Mathematics solves problems by pen and paper. CS helps us to go far beyond that.", "num_citations": "58\n", "authors": ["1804"]}
{"title": "Aligning CNF-and equivalence-reasoning\n", "abstract": " Structural logical formulas sometimes yield a substantial fraction of so called equivalence clauses after translation to CNF. Probably the best known example of this is the parity-family. Large instances of such CNF formulas cannot be solved in reasonable time if no detection of, and extra reasoning with, these clauses is incorporated. That is, in solving these formulas, there is a more or less separate algorithmic device dealing with the equivalence clauses, called equivalence reasoning, and another dealing with the remaining clauses. In this paper we propose a way to align these two reasoning devices by introducing parameters for which we establish optimal values over a variety of existing benchmarks. We obtain a truly convincing speed-up in solving such formulas with respect to the best solving methods existing so far.", "num_citations": "58\n", "authors": ["1804"]}
{"title": "Software model synthesis using satisfiability solvers\n", "abstract": " We introduce a novel approach for synthesis of software models based on identifying deterministic finite state automata. Our approach consists of three important contributions. First, we argue that in order to model software, one should focus mainly on observed executions (positive data), and use the randomly generated failures (negative data) only for testing consistency. We present a new greedy heuristic for this purpose, and show how to integrate it in the state-of-the-art evidence-driven state-merging (EDSM) algorithm. Second, we apply the enhanced EDSM algorithm to iteratively reduce the size of the problem. Yet during each iteration, the evidence is divided over states and hence the effectiveness of this algorithm is decreased. We propose\u2014when EDSM becomes too weak\u2014to tackle the reduced identification problem using satisfiability solvers. Third, in case the amount of positive data is small, we\u00a0\u2026", "num_citations": "46\n", "authors": ["1804"]}
{"title": "A SAT approach to clique-width\n", "abstract": " Clique-width is a graph invariant that has been widely studied in combinatorics and computational logic. Computing the clique-width of a graph is an intricate problem, because the exact clique-width is not known even for very small graphs. We present a new method for computing clique-width via an encoding to propositional satisfiability (SAT), which is then evaluated by a SAT solver. Our encoding is based on a reformulation of clique-width in terms of partitions that utilizes an efficient encoding of cardinality constraints. Our SAT-based method is the first to discover the exact clique-width of various small graphs, including famous named graphs from the literature as well as random graphs of various density. With our method, we determined the smallest graphs that require a small predescribed clique-width. We further show how our method can be modified to compute the linear clique-width of graphs, a variant of\u00a0\u2026", "num_citations": "37\n", "authors": ["1804"]}
{"title": "Static detection of DoS vulnerabilities in programs that use regular expressions\n", "abstract": " In an algorithmic complexity attack, a malicious party takes advantage of the worst-case behavior of an algorithm to cause denial-of-service. A prominent algorithmic complexity attack is regular expression denial-of-service (ReDoS), in which the attacker exploits a vulnerable regular expression by providing a carefully-crafted input string that triggers worst-case behavior of the matching algorithm. This paper proposes a technique for automatically finding ReDoS vulnerabilities in programs. Specifically, our approach automatically identifies vulnerable regular expressions in the program and determines whether an \u201cevil\u201d input string can be matched against a vulnerable regular expression. We have implemented our proposed approach in a tool called Rexploiter and found 41 exploitable security vulnerabilities in Java web applications.", "num_citations": "36\n", "authors": ["1804"]}
{"title": "Mechanical verification of SAT refutations with extended resolution\n", "abstract": " We present a mechanically-verified proof checker developed with the ACL2 theorem-proving system that is general enough to support the growing variety of increasingly complex satisfiability (SAT) solver techniques, including those based on extended resolution. A common approach to assure the correctness of SAT solvers is to emit a proof of unsatisfiability when no solution is reported to exist. Contemporary proof checkers only check logical equivalence using resolution-style inference. However, some state-of-the-art, conflict-driven clause-learning SAT solvers use preprocessing, inprocessing, and learning techniques, that cannot be checked solely by resolution-style inference. We have developed a mechanically-verified proof checker that assures refutation clauses preserve satisfiability. We believe our approach is sufficiently expressive to validate all known SAT-solver techniques.", "num_citations": "36\n", "authors": ["1804"]}
{"title": "Expressing symmetry breaking in DRAT proofs\n", "abstract": " An effective SAT preprocessing technique is the addition of symmetry-breaking predicates: auxiliary clauses that guide a SAT solver away from needless exploration of isomorphic sub-problems. Symmetry-breaking predicates have been in use for over a decade. However, it was not known how to express the addition of these predicates in proofs of unsatisfiability. Hence, results obtained by symmetry breaking cannot be validated by existing proof checkers. We present a method to express the addition of symmetry-breaking predicates in DRAT, a clausal proof format supported by top-tier solvers. We applied this method to generate SAT problems that have not been previously solved without symmetry-breaking predicates. We validated these proofs with an ACL2-based, mechanically-verified DRAT proof checker and the proof-checking tool of SAT Competition 2014.", "num_citations": "33\n", "authors": ["1804"]}
{"title": "EagleUP: Solving random 3-SAT using SLS with unit propagation\n", "abstract": " While the application of unit propagation (UP) is of vital importance in systematic search solvers to solve structured problems of the SAT competitions [8], its application in stochastic local search (SLS) solvers is rare. Examples for combining UP with SLS solvers are UnitWalk [4] and QingTing [6] and both solvers show strong performance on structured instances.", "num_citations": "31\n", "authors": ["1804"]}
{"title": "Efficient, verified checking of propositional proofs\n", "abstract": " Satisfiability (SAT) solvers\u2014and software in general\u2014sometimes have serious bugs. We mitigate these effects by validating the results. Today\u2019s SAT solvers emit proofs that can be checked with reasonable efficiency. However, these checkers are not trivial and can have bugs as well. We propose to check proofs using a formally verified program that adds little overhead to the overall process of proof validation. We have implemented a sequence of increasingly efficient, verified checkers using the ACL2 theorem proving system, and we discuss lessons from this effort. This work is already being used in industry and is slated for use in the next SAT competition.", "num_citations": "29\n", "authors": ["1804"]}
{"title": "Between restarts and backjumps\n", "abstract": " This paper introduces a novel technique that significantly reduces the computational costs to perform a restart in conflict-driven clause learning (CDCL) solvers. Our technique exploits the observation that CDCL solvers make many redundant propagations after a restart. It efficiently predicts which decisions will be made after a restart. This prediction is used to backtrack to the first level at which heuristics may select a new decision rather than performing a complete restart.                 In general, the number of conflicts that are encountered while solving a problem can be reduced by increasing the restart frequency, even though the solving time may increase. Our technique counters the latter effect. As a consequence CDCL solvers will favor more frequent restarts.", "num_citations": "28\n", "authors": ["1804"]}
{"title": "Dynamic symmetry breaking by simulating Zykov contraction\n", "abstract": " We present a new method to break symmetry in graph coloring problems. While most alternative techniques add symmetry breaking predicates in a pre-processing step, we developed a learning scheme that translates each encountered conflict into one conflict clause which covers equivalent conflicts arising from any permutation of the colors.               Our technique introduces new Boolean variables during the search. For many problems the size of the resolution refutation can be significantly reduced by this technique. Although this is shown for various hand-made refutations, it is rarely used in practice, because it is hard to determine which variables to introduce defining useful predicates. In case of graph coloring, the reason for each conflicting coloring can be expressed as a node in the Zykov-tree, that stems from merging some vertices and adding some edges. So, we focus on variables that represent\u00a0\u2026", "num_citations": "28\n", "authors": ["1804"]}
{"title": "Extended resolution simulates DRAT\n", "abstract": " We prove that extended resolution\u2014a well-known proof system introduced by Tseitin\u2014polynomially simulates , the standard proof system in modern SAT solving. Our simulation procedure takes as input a  proof and transforms it into an extended-resolution proof whose size is only polynomial with respect to the original proof. Based on our simulation, we implemented a tool that transforms  proofs into extended-resolution proofs. We ran our tool on several benchmark formulas to estimate the increase in size caused by our simulation in practice. Finally, as a side note, we show how blocked-clause addition\u2014a generalization of the extension rule from extended resolution\u2014can be used to replace the addition of resolution asymmetric tautologies in  without introducing new variables.", "num_citations": "26\n", "authors": ["1804"]}
{"title": "MUS extraction using clausal proofs\n", "abstract": " Recent work introduced an effective method for extraction of reduced unsatisfiable cores of CNF formulas as a by-product of validation of clausal proofs emitted by conflict-driven clause learning SAT solvers. In this paper, we demonstrate that this method for trimming CNF formulas can also benefit state-of-the-art tools for the computation of a Minimal Unsatisfiable Subformula (MUS). Furthermore, we propose a number of techniques that improve the quality of trimming, and demonstrate a significant positive impact on the performance of MUS extractors from the improved trimming.", "num_citations": "26\n", "authors": ["1804"]}
{"title": "Reusing the Assignment Trail in CDCL Solvers system description\n", "abstract": " We present the solver RestartSAT which includes a novel technique to reduce the cost to perform a restart in CDCL SAT solvers. This technique, called ReusedTrail, exploits the observation that CDCL solvers often reassign the same variables to the same truth values after a restart. It computes a partial restart level for which it is guaranteed that all variables below this level will be reassigned after a full restart. RestartSAT, an extended version of MiniSAT, incorporates ReusedTrail which can be implemented easily in almost any CDCL solver. On average, it saves over a third of the decisions and propagations necessary to solve a problem using a Luby restart policy with unit run 1. Experimental results show that RestartSAT solves over a dozen more application instances than the default MiniSAT.", "num_citations": "26\n", "authors": ["1804"]}
{"title": "Computing small unit-distance graphs with chromatic number 5\n", "abstract": " We present a new method for reducing the size of graphs with a given property. Our method, which is based on clausal proof minimization, allowed us to compute several 553-vertex unit-distance graphs with chromatic number 5, while the smallest published unit-distance graph with chromatic number 5 has 1581 vertices. The latter graph was constructed by Aubrey de Grey to show that the chromatic number of the plane is at least 5. The lack of a 4-coloring of our graphs is due to a clear pattern enforced on some vertices. Also, our graphs can be mechanically validated in a second, which suggests that the pattern is based on a reasonably short argument.", "num_citations": "25\n", "authors": ["1804"]}
{"title": "Towards ultra rapid restarts\n", "abstract": " We observe a trend regarding restart strategies used in SAT solvers. A few years ago, most state-of-the-art solvers restarted on average after a few thousands of backtracks. Currently, restarting after a dozen backtracks results in much better performance. The main reason for this trend is that heuristics and data structures have become more restart-friendly. We expect further continuation of this trend, so future SAT solvers will restart even more rapidly. Additionally, we present experimental results to support our observations.", "num_citations": "24\n", "authors": ["1804"]}
{"title": "Bridging the gap between easy generation and efficient verification of unsatisfiability proofs\n", "abstract": " Several proof formats have been used to verify refutations produced by satisfiability (SAT) solvers. Existing formats are either costly to check or hard to implement. This paper presents a practical approach that facilitates checking of unsatisfiability results in a time similar to proof discovery by embedding clause deletion information into clausal proofs. By exploiting this information, the proof\u2010checking time is reduced by an order of magnitude on medium\u2010to\u2010hard benchmarks as compared to checking proofs using similar clausal formats. Proofs in a new format can be produced by making only minor changes to existing conflict\u2010driven clause\u2010learning solvers and their preprocessors, and the runtime overhead is negligible. This approach can easily be integrated into Glucose 2.1, the SAT 2012 challenge winner, and SatELite, a popular SAT\u2010problem preprocessor. Copyright \u00a9 2014 John Wiley & Sons, Ltd.", "num_citations": "23\n", "authors": ["1804"]}
{"title": "SmArT solving: Tools and techniques for satisfiability solvers\n", "abstract": " The satisfiability problem (Sat) lies at the core of the complexity theory. This is a decision problem: Not the solution itself, but whether or not a solution exists given a specified set of requirements is the central question. Over the years, the satisfiability problem has taken center stage as a means of effective representation to tackle problems with different characteristics: Many problems can first be translated into Sat and then solved by means of software dedicated to the Sat problem. Due to the increasing power of these Sat solvers, the number of applications climbs every year. Examples of this kind of translatable problems are scheduling problems, verification of software and hardware, bounded model checking and a wide variety of mathematical puzzles. Sat solvers come in two flavors: Complete and incomplete. Complete solvers systematically go over the whole search space and are able to determine with certainty whether a solution exists. Incomplete Sat solvers look for a solution at a venture. They dont follow a system, yet they might hit a solution. Most complete Sat solvers are based on the ConflictDriven architecture. At a dead end, they analyze what went wrong and where in the search space it happened. Then they resume the search from there. Conflict-driven solvers make relatively cheap decisions (in terms of computational costs), which enables them to search the space swiftly. Only a few complete Sat solvers are based on an architecture that chooses its battles, so to speak. The LookAhead architecture peers further into the search space before making the next move. Look-ahead solvers make expensive decisions in order to keep the\u00a0\u2026", "num_citations": "22\n", "authors": ["1804"]}
{"title": "Solving Very Hard Problems: Cube-and-Conquer, a Hybrid SAT Solving Method.\n", "abstract": " A recent success of SAT solving has been the solution of the boolean Pythagorean Triples problem [Heule et al., 2016], delivering the largest proof yet, of 200 terabytes in size. We present this and the underlying paradigm Cube-and-Conquer, a powerful general method to solve big SAT problems, based on integrating the \u201cold\u201d and \u201cnew\u201d methods of SAT solving.", "num_citations": "20\n", "authors": ["1804"]}
{"title": "Solving edge-matching problems with satisfiability solvers\n", "abstract": " Programs that solve Boolean satisfiability (SAT) problems have become powerful tools to tackle a wide range of applications. The usefulness of these solvers does not only depend on their strength and the properties of a certain problem, but also on how the problem is translated into SAT. This paper offers additional evidence for this claim. To show the impact of the translation on the performance, we studied encodings of edge-matching problems. The popularity of these problems was boosted by the release of Eternity II in July 2007: Whoever solves this 256 piece puzzle first wins $2,000,000. There exists no straightforward translation into SAT for edge-matching problems. Therefore, a variety of possible encodings arise.The basic translation used in our experiments and described in this paper, is the smallest one that comes to mind. This translation can be extended using redundant clauses representing additional knowledge about the problem. The results show that these redundant clauses can guide the search\u2013both for complete and incomplete SAT solvers\u2013yielding significant performance gains.", "num_citations": "19\n", "authors": ["1804"]}
{"title": "Effective incorporation of double look-ahead procedures\n", "abstract": " We introduce an adaptive algorithm to control the use of the double look-ahead procedure. This procedure sometimes enhances the performance of look-ahead based satisfiability solvers. Current use of this procedure is driven by static heuristics. Experiments show that over a wide variety of instances, different parameter settings result in optimal performance. Moreover, a strategy that yields fast performance on one particular class of instances may cause a significant slowdown on other families. Using a single adaptive strategy, we accomplish performances close to the optimal performances reached by the various static settings. On some families, we clearly outperform even the fastest performance based on static heuristics. This paper provides a description of the algorithm and a comparison with the static strategies. This method is incorporated in march_dl, satz, and kcnfs. Also, the dynamic behavior of the\u00a0\u2026", "num_citations": "18\n", "authors": ["1804"]}
{"title": "Solving games: Dependence of applicable solving procedures\n", "abstract": " We introduce an alternative concept to determine the solvability of two-player games with perfect information. This concept \u2014 based on games currently solved \u2014 claims that the applicable solving procedures have a significant influence on the solvability of games. This contrasts with current views that suggest that solvability is related to state-space and game-tree complexity. Twenty articles on this topic are discussed, including those that describe the currently obtained solutions. Results include a description of the available solving procedures as well as an overview of essential techniques from the past. Besides well-known classic games, the solvability of popular and recent games z\u00e8rtz, dvonn, and yinsh are analyzed. We conclude that our proposed concept could determine the solvability of games more accurately. Based on our concept, we expect that new solving techniques are required to obtain solutions for\u00a0\u2026", "num_citations": "17\n", "authors": ["1804"]}
{"title": "The resolution of Keller\u2019s conjecture\n", "abstract": " We consider three graphs, , , and , related to Keller\u2019s conjecture in dimension 7. The conjecture is false for this dimension if and only if at least one of the graphs contains a clique of size . We present an automated method to solve this conjecture by encoding the existence of such a clique as a propositional formula. We apply satisfiability solving combined with symmetry-breaking techniques to determine that no such clique exists. This result implies that every unit cube tiling of  contains a facesharing pair of cubes. Since a faceshare-free unit cube tiling of  exists (which we also verify), this completely resolves Keller\u2019s conjecture.", "num_citations": "15\n", "authors": ["1804"]}
{"title": "Symmetry within solutions\n", "abstract": " We define the concept of an internal symmetry. This is a symmety within a solution of a constraint satisfaction problem. We compare this to solution symmetry, which is a mapping between different solutions of the same problem. We argue that we may be able to exploit both types of symmetry when finding solutions. We illustrate the potential of exploiting internal symmetries on two benchmark domains: Van der Waerden numbers and graceful graphs. By identifying internal symmetries we are able to extend the state of the art in both cases.", "num_citations": "15\n", "authors": ["1804"]}
{"title": "Whose side are you on?\n", "abstract": " We introduce a new jump strategy for look-ahead based satisfiability (Sat) solvers that aims to boost their performance on satisfiable formulae, while maintaining their behavior on unsatisfiable instances.", "num_citations": "14\n", "authors": ["1804"]}
{"title": "Uniform sampling from kconfig feature models\n", "abstract": " Random sampling of configuration spaces is a useful tool for working with software product lines (SPLs), enabling, analyzing and reasoning about spaces too large for exhaustive exploration. Being able to create uniform sampling is critical for making statistical inferences about SPLs, but it particularly hard for massive, real-world systems. We show how uniform random sampling can be done on systems that use the Kconfig feature modeling language, a popular choice among low-level and embedded systems. Despite its importance, prior work considered uniform random sampling infeasible and sampled configurations without confirming that their samples were uniformly distributed. Especially, existing Kconfig models were not known to be suitable for uniform random sampling, although they were used extensively. We solve these challenges with algorithmic advances embodied in two tools: Kclause to produce compact models and Smarch to perform efficient sampling guaranteed to be uniform. Kclause has been extended to model Kconfig semantics with hand-tuned, simplified formulas that minimizing the number of clauses, a critical property for fast sampling. Smarch is a new recursive, sampling algorithm based on sharpSAT that supports massive configuration spaces with 38% faster sampling times.", "num_citations": "13\n", "authors": ["1804"]}
{"title": "The DRAT format and DRAT-trim checker\n", "abstract": " This document describes the DRAT format for clausal proofs and the DRAT-trim proof checker.", "num_citations": "13\n", "authors": ["1804"]}
{"title": "march hi\n", "abstract": " The march hi Sat solver is an upgraded version of the successful march ks, march dl and march eq Sat solvers, which won several awards at the Sat 2004, 2005 and 2007 competitions. For the latest detailed description, we refer to [3, 2]. Like its predecessors, march hi integrates equivalence reasoning into a DPLL architecture and uses look-ahead heuristics to determine the branch variable in all nodes of the DPLL search-tree. The main improvements in march hi are:\u2022 an improved guided jumping strategy: instead of the conventional depth-first search, march hi uses a jumping strategy based on the distribution of solutions measured on random 3-Sat instances. It jumps more aggressively then the march ks implementation [1].\u2022 a more accurate look-ahead evaluation function for 3-Sat formulae.2 pre-processingThe pre-processor of march dl, reduces the formula at hand prior to calling the main solving (DPLL) procedure. Earlier versions already contained unit-clause and binary equivalence propagation, as well as equivalence reasoning, a 3-Sat translator, and finally a full-using all free variables-iterative root look-ahead. However, march hi (as well as march ks) does not use a 3-Sat translator by default (although it is still optional). The motivation for its removal is to examine the effect of (not) using a 3-Sat translator on the performance. Because the addition of resolvents was only based on the ternary clauses in the formula (after the translation) we developed a new algorithm for this addition which uses all clauses with at least three literals.", "num_citations": "13\n", "authors": ["1804"]}
{"title": "Parallel SAT solving using bit-level operations\n", "abstract": " We show how to exploit the 32/64 bit architecture of modern computers to accelerate some of the algorithms used in satisfiability solving by modifying assignments to variables in parallel on a single processor. Techniques such as random sampling demonstrate that while using bit vectors instead of Boolean values solutions to satisfiable formulae can be obtained faster. Here, we reveal that more complex algorithms, like unit propagation and detection of autarkies, can be parallelized efficiently, as well.", "num_citations": "13\n", "authors": ["1804"]}
{"title": "Generating the uniform random benchmarks\n", "abstract": " The uniform random k-SAT instances described here, together with the hard satisfiable random instances described on pages 60\u201362 of this compilation, constitute the benchmark set of the Random Track of SAT Competition 2016.", "num_citations": "10\n", "authors": ["1804"]}
{"title": "Decomposing clause-sets: Integrating DLL algorithms, tree decompositions and hypergraph cuts for variable and clause-based graph representations of CNF\u2019s\n", "abstract": " CiteSeerX \u2014 Decomposing clause-sets: Integrating DLL algorithms, tree decompositions and hypergraph cuts for variable- and clause-based graph representations of CNF\u2019s Documents Authors Tables Log in Sign up MetaCart DMCA Donate CiteSeerX logo Documents: Advanced Search Include Citations Authors: Advanced Search Include Citations Tables: DMCA Decomposing clause-sets: Integrating DLL algorithms, tree decompositions and hypergraph cuts for variable- and clause-based graph representations of CNF\u2019s (2006) Cached Download as a PDF Download Links [www.st.ewi.tudelft.nl] [www.cs.swansea.ac.uk] Other Repositories/Bibliography DBLP Save to List Add to Collection Correct Errors Monitor Changes by Marijn Heule , Oliver Kullmann Citations: 2 - 1 self Summary Citations Active Bibliography Co-citation Clustered Documents Version History Share Facebook Twitter Reddit Bibsonomy \u2026", "num_citations": "10\n", "authors": ["1804"]}
{"title": "What's hot in the SAT and ASP competitions\n", "abstract": " During the Vienna Summer of Logic, the first FLoC Olympic Games were organized, bringing together a dozen competitions related to logic. Here we present the highlights of the Satisfiability (SAT) and Answer Set Programming (ASP) competitions.", "num_citations": "9\n", "authors": ["1804"]}
{"title": "Sums of squares based approximation algorithms for MAX-SAT\n", "abstract": " We investigate the Semidefinite Programming based sums of squares (SOS) decomposition method, designed for global optimization of polynomials, in the context of the (Maximum) Satisfiability problem. To be specific, we examine the potential of this theory for providing tests for unsatisfiability and providing MAX-SAT upper bounds. We compare the SOS approach with existing upper bound and rounding techniques for the MAX-2-SAT case of Goemans and Williamson [Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming, J. Assoc. Comput. Mach. 42(6) (1995) 1115\u20131145] and Feige and Goemans [Approximating the value of two prover proof systems, with applications to MAX2SAT and MAXDICUT, in: Proceedings of the Third Israel Symposium on Theory of Computing and Systems, 1995, pp. 182\u2013189] and the MAX-3-SAT case of Karloff and Zwick [A 7/8\u00a0\u2026", "num_citations": "9\n", "authors": ["1804"]}
{"title": "Validating Unsatisfiability Results of Clause Sharing Parallel SAT Solvers.\n", "abstract": " As satisfiability (SAT) solver performance has improved, so has their complexity, which make it more likely that SAT solvers contain bugs. One important source of increased complexity is clause sharing in parallel SAT solvers. SAT solvers can emit a proof of unsatisfiability to gain confidence that their results are correct. Such proofs must contain deletion information in order to check them efficiently. Computing deletion information is easy and cheap for parallel solvers without clause sharing, but tricky for parallel solvers with clause sharing.We present a method to generate unsatisfiability proofs from clause sharing parallel SAT solvers. We show that the overhead of our method is small and that the produced proofs can be validated in a time similar to the solving (CPU) time. However, proofs produced by parallel solvers without clause sharing can be checked in a time similar to the solving (wall-clock) time. This raises the question whether our method can be improved such that the checking time of proofs from parallel solvers without clause sharing is comparable to the time to check proofs from parallel solver with clause sharing.", "num_citations": "8\n", "authors": ["1804"]}
{"title": "Symmetry in gardens of eden\n", "abstract": " Conway's Game of Life has inspired enthusiasts to search for a wide range of patterns for this classic cellular automaton. One important challenge in this context is finding the smallest Garden of Eden (GoE), a state without a predecessor. We take up this challenge by applying two techniques. First, we focus on GoEs that contain a symmetry. This significantly reduces the size of the search space for interesting sizes of the grid. Second, we implement the search using incremental satisfiability solving to check thousands of states per second. By combining these techniques, we broke several records regarding GoEs: the fewest defined cells, the smallest bounding box, and the lowest living density. Furthermore, we established a new lower bound for the smallest GoE.", "num_citations": "8\n", "authors": ["1804"]}
{"title": "Generating the uniform random benchmarks for SAT Competition 2013\n", "abstract": " This description explains how the benchmarks were created of the uniform random categories of the SAT Competition 2013. These categories consists of uniform random k-SAT instances with k\u2208 3, 4, 5, 6, 7\u2013Boolean formulas for which all clauses have length k. For each k the same number of benchmarks have been generated. All instances have been generated with the Uniform Random k-SAT Generator which was also used in the SAT Challenge 2012 and is freely available online1.", "num_citations": "8\n", "authors": ["1804"]}
{"title": "Prototypes for automated architectural 3D-layout\n", "abstract": " Prototypes for automated spatial layout in architecture focus on approaches, which define occupiable space as an orthogonal 2D-grid and use algorithms to allocate each rectangle of the grid to a particular function. However, these approaches are limiting the design to 2D spatial layouts. Based on SAT solving techniques, the prototype presented in this paper proposes a methodology for automated 3D-space planning for voxelized curvilinear geometries.", "num_citations": "8\n", "authors": ["1804"]}
{"title": "Computing properties of stable configurations of thermodynamic binding networks\n", "abstract": " The promise of chemical computation lies in controlling systems incompatible with traditional electronic micro-controllers, with applications in synthetic biology and nano-scale manufacturing. Computation is typically embedded in kinetics\u2014the specific time evolution of a chemical system. However, if the desired output is not thermodynamically stable, basic physical chemistry dictates that thermodynamic forces will drive the system toward error throughout the computation. The thermodynamic binding network (TBN) model was introduced to formally study how the thermodynamic equilibrium can be made consistent with the desired computation, and it idealizes tradeoffs between configurational entropy and binding. Here we prove the computational hardness of natural questions about TBNs and develop a practical algorithm for verifying the correctness of constructions by translating the problem into propositional logic\u00a0\u2026", "num_citations": "7\n", "authors": ["1804"]}
{"title": "Modeling techniques for logic locking\n", "abstract": " Logic locking is a method to prevent intellectual property (IP) piracy. However, under a reasonable attack model, SAT-based methods have proven to be powerful in obtaining the secret key. In response, many locking techniques have been developed to specifically resist this form of attack. In this paper, we demonstrate two SAT modeling techniques that can provide many orders of magnitude speed up in discovering the correct key. Specifically, we consider relaxed encodings and symmetry breaking. To demonstrate their impact, we model and attack a state-of-the-art logic locking technique, Full-Lock. We show that circuits previously unbreakable within 15 days of run time can be solved in seconds. Consequently, in assessing the strength of any given locking, it is imperative that these modeling techniques be considered. To remedy this vulnerability in the considered locking technique, we demonstrate an extended\u00a0\u2026", "num_citations": "6\n", "authors": ["1804"]}
{"title": "The application and the hard combinatorial benchmarks in sat competition 2014\n", "abstract": " The benchmarks for the Application and the Hard Combinatorial tracks of SAT Competition 2014 were drawn from a pool containing benchmarks that either (i) were used in the past seven competitive SAT events (SAT Competitions 2007, 2009, 2011, 2013; SAT Races 2008, 2010; SAT Challenge 2012);(ii) were submitted to these events but not used; or (iii) are new benchmarks submitted to SAT Competition 2014 (the descriptions for these benchmarks are provided in these proceedings). The main factor that influenced the benchmark selection process of SAT Competition 2014 is the fact that, as with the previous SAT competitions, the SAT solvers participating in the competition are ranked using the solution-count ranking system. Thus the primary requirement is that the selected set of benchmarks should contain as few as possible benchmarks that would not be solved by any of the submitted solvers. At the same time, the set should contain as few as possible benchmarks that would be solved by all submitted solvers. In order to level out the playing field for submitters who do not have the resources to tune their solvers on all benchmark sets used in the previous competitions, an additional requirement is that the selected set should contain as many new benchmarks, ie, benchmarks that were not used in the previous SAT competitions, as possible. Finally, the selected set should not contain a dominating number of benchmarks from the same application domain and the same source. To accomodate this latter requirement, we assigned the benchmarks in the pool to buckets, where the assignment is guided by the combination of the specific\u00a0\u2026", "num_citations": "6\n", "authors": ["1804"]}
{"title": "Trimming graphs using clausal proof optimization\n", "abstract": " We present a method to gradually compute a smaller and smaller unsatisfiable core of a propositional formula by minimizing proofs of unsatisfiability. The goal is to compute a minimal unsatisfiable core that is relatively small compared to other minimal unsatisfiable cores of the same formula. We try to achieve this goal by postponing deletion of arbitrary clauses from the formula as long as possible\u2014in contrast to existing minimal unsatisfiable core algorithms. We applied this method to reduce the smallest known unit-distance graph with chromatic number 5 from 553 vertices and  edges to 529 vertices and  edges.", "num_citations": "5\n", "authors": ["1804"]}
{"title": "Avoiding triples in arithmetic progression\n", "abstract": " Some patterns cannot be avoided ad infinitum. A well-known example of such a pattern is an arithmetic progression in partitions of natural numbers. We observed that in order to avoid arithmetic progressions, other patterns emerge. A visualization is presented that reveals these patterns. We capitalize on the observed patterns by constructing techniques to avoid arithmetic progressions.", "num_citations": "5\n", "authors": ["1804"]}
{"title": "The quest for perfect and compact symmetry breaking for graph problems\n", "abstract": " Symmetry breaking is a crucial technique to solve many graph problems. However, current state-of-the-art techniques break graph symmetries only partially, causing search algorithms to unnecessarily explore many isomorphic parts of the search space. We study properties of perfect symmetry breaking for graph problems. One promising and surprising result on small-sized graphs-up to order five- is that perfect symmetry breaking can be achieved using a compact propositional formula in which each literal occurs at most twice. At least for small graphs, perfect symmetry breaking can be expressed more compactly than the existing (partial) symmetry-breaking methods. We present several techniques to compute and analyze perfect symmetry-breaking formulas.", "num_citations": "5\n", "authors": ["1804"]}
{"title": "The application and the hard combinatorial benchmarks in sat competition 2013\n", "abstract": " The benchmarks for the Application and the Hard Combinatorial tracks of SAT Competition 2013 were drawn from a pool containing benchmarks that either (i) were used in the past six competitive SAT events (SAT Competitions 2007, 2009, 2011; SAT Races 2008, 2010; SAT Challenge 2012);(ii) were submitted to these 6 events but not used;(iii) new benchmarks submitted to SAT Competition 2013 (the descriptions for these benchmarks are provided in these proceedings). The main factor that influenced the benchmark selection process of SAT Competition 2013 is the fact that, as with the previous SAT competitions, the SAT solvers participating in the competition are ranked using the solution-count ranking system. Thus the primary requirement is that the selected set of benchmarks should contain as few as possible benchmarks that would not be solved by any submitted solver. At the same time, the set should contain as few as possible benchmarks that would be solved by all submitted solvers. In order to level out the playing field for the submitters that do not have the resources to tune their solvers on all benchmark sets used in the previous competitions, an additional requirement is that the selected set should contain as many benchmarks as possible that were not used in the previous SAT competitions. Finally, the selected set should not contain a dominating number of benchmarks from the same application domain and the same source. To accommodate this latter requirement, we assigned the benchmarks in the pool to buckets, where the assignment is guided by the combination of the specific application or a specific combinatorial problem\u00a0\u2026", "num_citations": "5\n", "authors": ["1804"]}
{"title": "Sensitivity analysis of locked circuits\n", "abstract": " Globalization of integrated circuits manufacturing has led to increased security concerns, notably theft of intellectual property. In response, logic locking techniques have been developed for protecting designs, but many of these techniques have been shown to be vulnerable to SAT-based attacks. In this paper, we explore the use of Boolean sensitivity to analyze these locked circuits. We show that in typical circuits there is an inverse relationship between input width and sensitivity. We then demonstrate the utility of this relationship for deobfuscating circuits locked with a class of \u201cprovably secure\u201d logic locking techniques. We conclude with an example of how to resist this attack, although the resistance is shown to be highly circuit dependent.", "num_citations": "4\n", "authors": ["1804"]}
{"title": "Constructing Minimal Perfect Hash Functions Using SAT Technology\n", "abstract": " Minimal perfect hash functions (MPHFs) are used to provide efficient access to values of large dictionaries (sets of key-value pairs). Discovering new algorithms for building MPHFs is an area of active research, especially from the perspective of storage efficiency. The information-theoretic limit for MPHFs is 1/ln 2\u2248 1.44 bits per key. The current best practical algorithms range between 2 and 4 bits per key. In this article, we propose two SAT-based constructions of MPHFs. Our first construction yields MPHFs near the information-theoretic limit. For this construction, current state-of-the-art SAT solvers can handle instances where the dictionaries contain up to 40 elements, thereby outperforming the existing (brute-force) methods. Our second construction uses XORSAT filters to realize a practical approach with long-term storage of approximately 1.83 bits per key.", "num_citations": "4\n", "authors": ["1804"]}
{"title": "Coloring unit-distance strips using SAT\n", "abstract": " Satisfiability (SAT) solving has become an important technology in computer-aided mathematics with various successes in number and graph theory. In this paper we apply SAT solvers to color infinitely long strips in the plane with a given height and number of colors. The coloring is constrained as follows: two points that are exactly unit distance apart must be colored differently. To finitize the problem, we tile the strips and all points on a tile have the same color. We evaluated our approach using two different tile shapes: squares and hexagons. The visualization of bounded height strips using 3 to 6 colors reveal patterns that are similar to the best known lower bounds for infinite strips. Our method can be a useful tool for mathematicians to search for patterns that can be generalized to infinite strips and allowed us to increase the lower bound for the strip height with 5 colors to an improved height of 1.700084.", "num_citations": "4\n", "authors": ["1804"]}
{"title": "Optimal symmetry breaking for graph problems\n", "abstract": " Symmetry breaking is a crucial technique to solve many graph problems. However, current state-of-the-art techniques break graph symmetries only partially, causing search algorithms to unnecessarily explore many isomorphic parts of the search space. We study properties of perfect symmetry breaking for graph problems. One promising and surprising result on small-sized graphs\u2014up to order five\u2014is that perfect symmetry breaking can be achieved using a compact propositional formula in which each literal occurs at most twice. At least for small graphs, perfect symmetry breaking can be expressed more compactly than the existing (partial) symmetry-breaking methods. We present several techniques to compute and analyze perfect symmetry-breaking formulas.", "num_citations": "4\n", "authors": ["1804"]}
{"title": "Proceedings of sat competition 2018: Solver and benchmark descriptions\n", "abstract": " The area of Boolean satisfiability (SAT) solving has seen tremendous progress over the last years. Many problems (eg, in hardware and software verification) that seemed to be completely out of reach a decade ago can now be handled routinely. Besides new algorithms and better heuristics, refined implementation techniques turned out to be vital for this success. To keep up the driving force in improving SAT solvers, SAT solver competitions provide opportunities for solver developers to present their work to a broader audience and to objectively compare the performance of their own solvers with that of other state-of-the-art solvers.SAT Competition 2018 (SC 2018; http://sat2018. forsyte. tuwien. ac. at), a competitive event for SAT solvers, was organized as a satellite event of the 21st International Conference on Theory and Applications of Satisfiability Testing (SAT 2018), Oxford, UK, as part of the Federated Logic Conference (FLoC 2018). SC 2018 stands in the tradition of the previously organized main competitive events for SAT solvers: the SAT Competitions held 2002-2005, biannually during 2007-2013, and 2014, 2016-2017; the SAT-Races held in 2006, 2008, 2010, and 2015; and SAT Challenge 2012.", "num_citations": "4\n", "authors": ["1804"]}
{"title": "The Potential of Interference-Based Proof Systems.\n", "abstract": " We want to encourage researchers to investigate the potential of proof systems that modify a given set of formulas (eg, a set of clauses in propositional logic) in a way that preserves satisfiability but not necessarily logical equivalence. We call such modifications interferences, because they can change the models of a given set of formulas. Interferences differ from classical inferences, which do not affect the models of a set of formulas, because they only allow the derivation of formulas (conclusions) that are implied by the original formulas (premises). Moreover, while inferences reason about the presence of formulas (the premises), interferences can be seen as reasoning about their absence. Most traditional proof systems such as Frege systems, sequent calculi, or resolution-based systems use conventional inference rules. Popular examples of these rules are the modus ponens (left) and the propositional resolution rule (right):", "num_citations": "4\n", "authors": ["1804"]}
{"title": "Generating the uniform random benchmarks\n", "abstract": " INTRO This description explains how the benchmarks of the uniform random tracks of SAT Competition 2014 were generated. The benchmarks in the tracks consist of uniform random k-SAT instances with k\u2208 3, 4, 5, 6, 7\u2013Boolean formulas for which all clauses have length k. For each k the same number of benchmarks were generated.GENERATING THE SATISFIABLE BENCHMARKS The satisfiable uniform random k-SAT benchmarks are generated for two different sizes: medium and huge. The mediumsized benchmarks have a clause-to-variable ratio equal to the phase-transition ratio1. The number of variables also varies. The huge benchmarks have a few million clauses and are therefore as large as some of the application benchmarks. For the huge benchmarks, the ratio ranges from far from the phasetransition threshold to relatively close, while for each k the number of variables is the same. The used parameter values are detailed in Table I.", "num_citations": "4\n", "authors": ["1804"]}
{"title": "Minimal unsatisfiable cores of random formulas\n", "abstract": " A uniform random k-SAT formula consists of clauses of length k for which the literals are chosen by a uniform random distribution and literals have a 50% chance to be negated. Uniform random k-SAT formulas are particularly hard when they are generated near the phase-transition density: the clause-variable ratio for which the fraction of satisfiable/unsatisfiable formulas is 50%/50%. Fig. 1 and 2 shows the phase-transition phenomenon for random 3-SAT.", "num_citations": "4\n", "authors": ["1804"]}
{"title": "cake lpr: Verified propagation redundancy checking in CakeML\n", "abstract": " Modern SAT solvers can emit independently checkable proof certificates to validate their results. The state-of-the-art proof system that allows for compact proof certificates is propagation redundancy (PR). However, the only existing method to validate proofs in this system with a formally verified tool requires a transformation to a weaker proof system, which can result in a significant blowup in the size of the proof and increased proof validation time. This paper describes the first approach to formally verify PR proofs on a succinct representation; we present (i) a new Linear PR (LPR) proof format,(ii) a tool to efficiently convert PR proofs into LPR format, and (iii) cake_lpr, a verified LPR proof checker developed in CakeML. The LPR format is backwards compatible with the existing LRAT format, but extends the latter with support for the addition of PR clauses. Moreover, cake_lpr is verified using CakeML\u2019s binary code extraction toolchain, which yields correctness guarantees for its machine code (binary) implementation. This further distinguishes our clausal proof checker from existing ones because unverified extraction and compilation tools are removed from its trusted computing base. We experimentally show that LPR provides efficiency gains over existing proof formats and that the strong correctness guarantees are obtained without significant sacrifice in the performance of the verified executable.", "num_citations": "3\n", "authors": ["1804"]}
{"title": "Sorting parity encodings by reusing variables\n", "abstract": " Parity reasoning is challenging for CDCL solvers: Refuting a formula consisting of two contradictory, differently ordered parity constraints of modest size is hard. Two alternative methods can solve these reordered parity formulas efficiently: binary decision diagrams and Gaussian Elimination (which requires detection of the parity constraints). Yet, implementations of these techniques either lack support of proof logging or introduce many extension variables.               The compact, commonly-used encoding of parity constraints uses Tseitin variables. We present a technique for short clausal proofs that exploits these Tseitin variables to reorder the constraints within the DRAT system. The size of our refutations of reordered parity formulas is .", "num_citations": "3\n", "authors": ["1804"]}
{"title": "Static detection of dos vulnerabilities in programs that use regular expressions (extended version)\n", "abstract": " In an algorithmic complexity attack, a malicious party takes advantage of the worst-case behavior of an algorithm to cause denial-of-service. A prominent algorithmic complexity attack is regular expression denial-of-service (ReDoS), in which the attacker exploits a vulnerable regular expression by providing a carefully-crafted input string that triggers worst-case behavior of the matching algorithm. This paper proposes a technique for automatically finding ReDoS vulnerabilities in programs. Specifically, our approach automatically identifies vulnerable regular expressions in the program and determines whether an \"evil\" input string can be matched against a vulnerable regular expression. We have implemented our proposed approach in a tool called REXPLOITER and found 41 exploitable security vulnerabilities in Java web applications.", "num_citations": "3\n", "authors": ["1804"]}
{"title": "Computing Maximum Unavoidable Subgraphs Using SAT Solvers\n", "abstract": " Unavoidable subgraphs have been widely studied in the context of Ramsey Theory. The research in this area focuses on highly structured graphs such as cliques, cycles, paths, stars, trees, and wheels. We propose to study maximum unavoidable subgraphs measuring the size in the number of edges. We computed maximum unavoidable subgraphs for graphs up\u00a0to order nine via SAT solving and observed that these subgraphs are less structured, although all are bipartite. Additionally, we found large unavoidable bipartite subgraphs up\u00a0to order twelve. We also present the concept of multi-component unavoidable subgraphs and show that large multi-component subgraphs are unavoidable in small graphs. We envision that maximum unavoidable subgraphs can be exploited using an alternative approach to breaking graph symmetries.", "num_citations": "3\n", "authors": ["1804"]}
{"title": "The implication problem of computing policies\n", "abstract": " A computing policy is a sequence of rules, where each rule consists of a predicate and an action, and where each action is either \u201caccept\u201d or \u201creject\u201d. A policy P is said to accept (or reject, respectively) a request iff the action of the first rule in P, that is matched by the request is \u201caccept\u201d (or \u201creject\u201d, respectively). A pair of policies (P, Q) is called an accept-implication pair iff every request that is accepted by policy P is also accepted by policy Q. The implication problem of policies is to design an efficient algorithm that can take as input any policy pair (P, Q) and determine whether (P, Q) is an accept-implication pair. Such an algorithm can support step-wise refinement methods for designing policies. In this paper, we present a polynomial algorithm that can take any policy pair (P, Q) and determine whether (P, Q) is an accept-implication pair. The time complexity of this algorithm is (()), where m is the\u00a0\u2026", "num_citations": "3\n", "authors": ["1804"]}
{"title": "Internal symmetry\n", "abstract": " We have been studying the internal symmetries within an individual solution of a constraint satisfaction problem [1]. Such internal symmetries can be compared with solution symmetries which map between different solutions of the same problem. We show that we can take advantage of both types of symmetry when solving constraint satisfaction solutions within two benchmark domains. By identifying internal symmetries and breaking solution symmetries, we are able to increase the size of problems which have been solved.", "num_citations": "3\n", "authors": ["1804"]}
{"title": "From idempotent generalized boolean assignments to multi-bit search\n", "abstract": " This paper shows that idempotents in finite rings of integers can act as Generalized Boolean Assignments (GBA\u2019s) by providing a completeness theorem. We introduce the notion of a generic Generalized Boolean Assignment. The mere propagation of such an assignment reveals feasibility (existence of a solution) of a formula in propositional logic. Then, we demystify this general concept by formulating the process on the bit-level: It turns out that propagation of a GBA only simulates bitwise (non-communicating) parallel computing. We capitalize on this by modifying the state-of-the-art local search Sat solver UnitWalk accordingly. This modification involves a more complicated parallelism.", "num_citations": "3\n", "authors": ["1804"]}
{"title": "Sat competition 2020\n", "abstract": " The SAT Competitions constitute a well-established series of yearly open international algorithm implementation competitions, focusing on the Boolean satisfiability (or propositional satisfiability, SAT) problem. In this article, we provide a detailed account on the 2020 instantiation of the SAT Competition, including the new competition tracks and benchmark selection procedures, overview of solving strategies implemented in top-performing solvers, and a detailed analysis of the empirical data obtained from running the competition.", "num_citations": "2\n", "authors": ["1804"]}
{"title": "An Automated Approach to the Collatz Conjecture\n", "abstract": " We explore the Collatz conjecture and its variants through the lens of termination of string rewriting. We construct a rewriting system that simulates the iterated application of the Collatz function on strings corresponding to mixed binary-ternary representations of positive integers. We prove that the termination of this rewriting system is equivalent to the Collatz conjecture. We also prove that a previously studied rewriting system that simulates the Collatz function using unary representations does not admit termination proofs via matrix interpretations. To show the feasibility of our approach in proving mathematically interesting statements, we implement a minimal termination prover that uses matrix/arctic interpretations and we find automated proofs of nontrivial weakenings of the Collatz conjecture. Finally, we adapt our rewriting system to show that other open problems in mathematics can also be approached as termination problems for relatively small rewriting systems. Although we do not succeed in proving the Collatz conjecture, we believe that the ideas here represent an interesting new approach.", "num_citations": "2\n", "authors": ["1804"]}
{"title": "Scalable Uniform Sampling for Real-World Software Product Lines\n", "abstract": " Software Product Lines (SPLs) often have huge numbers of configurations that are impossible to enumerate. This raises the need for uniform sampling, which yields samples that are representative of the configuration space and enables accurate estimates of configuration properties by classical statistical methods. Prior work on sampling SPLs either achieved uniform sampling or scaled to large configuration spaces but not both, limiting their applicability to real-world SPLs. Smarch is a new uniform sampling algorithm that scales to real-world SPLs. It maintains a one-to-one correspondence between integers and configurations, converting uniformly sampled integers into uniformly sampled configurations. As Smarch only creates configurations that are used as samples, it has better scalability than other uniform sampling algorithms. Smarch can be optimized with respect to variable selection, parallelism, and caching to reduce its sampling time.", "num_citations": "2\n", "authors": ["1804"]}
{"title": "SAT race 2019\n", "abstract": " SAT Race 2019 - Overview and Results Page 1 SAT Race 2019 Overview and Results Marijn Heule1 Matti J\u00e4rvisalo2 Martin Suda3 1 Department of Computer Science, The University of Texas at Austin, USA 2 HIIT, Department of Computer Science, University of Helsinki, Finland 3 Czech Technical University, Prague, Czech Republic July 12, 2019 @ SAT 2019, Lisbon Marijn Heule SAT Race 2019 July 12, 2019 1 / 13 Page 2 SAT Solver Competitions Goals identify new challenging benchmarks promote SAT solvers & their development \u201csnapshot\u201d evaluation of current solvers Long tradition, starting from 1992 3 competitions in the 90s (1992, 1993, 1996) 12 SAT Competitions (2002\u2013) 5 SAT Races (2006, 2008, 2010, 2015, 2019) 1 SAT Challenge (2012) Marijn Heule SAT Race 2019 July 12, 2019 2 / 13 Page 3 Key rules Certified UNSAT using DRAT proof logging Disqualification of buggy solvers Provided model \u2026", "num_citations": "2\n", "authors": ["1804"]}
{"title": "Using a satisfiability solver to identify deterministic finite state automata\n", "abstract": " We present an exact algorithm for identification of deterministic finite automata (DFA) which is based on satisfiability (SAT) solvers. Despite the size of the low level SAT representation, our approach seems to be competitive with alternative techniques. Our contributions are threefold: First, we propose a compact translation of DFA identification into SAT. Second, we reduce the SAT search space by adding lower bound information using a fast max-clique approximation algorithm. Third, we include many redundant clauses to provide the SAT solver with some additional knowledge about the problem. Experiments on a well-known suite of random DFA identification problems show that SAT solvers can efficiently tackle all instances. Moreover, our exact algorithm outperforms state-of-the-art techniques on several hard problems.", "num_citations": "2\n", "authors": ["1804"]}
{"title": "Cnf symmetry breaking options in conflict driven SAT solving\n", "abstract": " Many CNF formulas representing real-world problems exhibit symmetries. Various efforts have been made to deal with these symmetries efficiently. After Crawford et al [2], which gives a theoretical framework for detecting and exploiting symmetries, different suggestions have been posed to prevent the exponential blow up of overhead costs which shows up performing so-called full symmetry breaking. Aloul et al [1] give an overview of these preprocessing methods and they present a new device (Shatter) which tries to eliminate the costs of overhead substantially. We propose an alternative way of symmetry breaking in cases where conflict-clause driven Sat solvers are used in solving the CNF at hand. Instead of preprocessing the formula involved we investigate the effect of applying permutations of the symmetry group on the emerging conflict-clauses only and to add them to the conflict-clause list additionally. We use random graph k-colourings in this experimental study, first because difficult examples can be generated easily and second because of the fact that the size of the full symmetry group grows exponentially in k. In doing so we are able to obtain a clear picture of the trade-off between costs of overhead and gains of dealing with smaller search trees. We compare our results with the Shatter preprocessing option and we selected the conflict driven zChaff Sat solver [3] as a standard representative of the family of conflict driven solvers.", "num_citations": "2\n", "authors": ["1804"]}
{"title": "Chinese Remainder Encoding for Hamiltonian Cycles\n", "abstract": " The Hamiltonian Cycle Problem (HCP) consists of two constraints: i) each vertex contributes exactly two edges to the cycle; and ii) there is exactly one cycle. The former can be encoded naturally and compactly, while the encodings of the latter either lack arc consistency or require an exponential number of clauses. We present a new, small encoding for HCP based on the Chinese remainder theorem. We demonstrate the effectiveness of the encoding on challenging HCP instances.", "num_citations": "2\n", "authors": ["1804"]}
{"title": "The impact of bounded variable elimination on solving pigeonhole formulas\n", "abstract": " Variable elimination is arguably the most important pre-and in-processing technique in state-of-the-art SAT solvers. There are hardly any problems for which variable elimination by substitution, as presented by E\u00e9n and Biere in 2005, hurts performance. However, during an experimental study, we observed that variable elimination resulted in substantial slowdowns of the 2020 SAT Competition winner Kissat on pigeonhole formulas. In this paper we evaluated the impact of different variable elimination orderings on solving pigeon hole formulas using recent SAT competition winners. The results show that some solvers are more stable than others, while the formulas obtained by some elimination orderings are consistently more difficult to solve. Further, we implemented static variable decision heuristics in the solver CaDiCaL that outperformed all other solvers.", "num_citations": "1\n", "authors": ["1804"]}
{"title": "Tighter Bounds on Directed Ramsey Number R (7)\n", "abstract": " Tournaments are orientations of the complete graph, and the directed Ramsey number  is the minimum number of vertices a tournament must have to be guaranteed to contain a transitive subtournament of size , which we denote by . We include a computer-assisted proof of a conjecture by Sanchez-Flores that all -free tournaments on 24 and 25 vertices are subtournaments of , the unique largest TT_6-free tournament. We also classify all -free tournaments on 23 vertices. We use these results, combined with assistance from SAT technology, to obtain the following improved bounds: .", "num_citations": "1\n", "authors": ["1804"]}
{"title": "Mycielski Graphs and  Proofs\n", "abstract": " Mycielski graphs are a family of triangle-free graphs  with arbitrarily high chromatic number.  has chromatic number k and there is a short informal proof of this fact, yet finding proofs of it via automated reasoning techniques has proved to be a challenging task. In this paper, we study the complexity of clausal proofs of the uncolorability of  with  colors. In particular, we consider variants of the  (propagation redundancy) proof system that are without new variables, and with or without deletion. These proof systems are of interest due to their potential uses for proof search. As our main result, we present a sublinear-length and constant-width  proof without new variables or deletion. We also implement a proof generator and verify the correctness of our proof. Furthermore, we consider formulas extended with clauses from the proof until a short resolution proof exists, and investigate the performance\u00a0\u2026", "num_citations": "1\n", "authors": ["1804"]}
{"title": "Proceedings of SAT Race 2019: Solver and Benchmark Descriptions\n", "abstract": " The area of Boolean satisfiability (SAT) solving has seen tremendous progress over the last years. Many problems (eg, in hardware and software verification) that seemed to be completely out of reach a decade ago can now be handled routinely. Besides new algorithms and better heuristics, refined implementation techniques turned out to be vital for this success. To keep up the driving force in improving SAT solvers, SAT solver competitions provide opportunities for solver developers to present their work to a broader audience and to objectively compare the performance of their own solvers with that of other state-of-the-art solvers.SAT Race 2019 (SR 2019; http://sat-race-2019. ciirc. cvut. cz), a competitive event for SAT solvers, was organized as a satellite event of the 22nd International Conference on Theory and Applications of Satisfiability Testing (SAT 2019), Lisbon, Portugal. SR 2019 stands in the tradition of the previously organized main competitive events for SAT solvers: the SAT Competitions held 2002-2005, biannually during 2007-2013, and 2014, 2016-2018; the SAT Races held in 2006, 2008, 2010, and 2015; and SAT Challenge 2012.", "num_citations": "1\n", "authors": ["1804"]}
{"title": "Analysis of computing policies using sat solvers (short paper)\n", "abstract": " A computing policy is a sequence of rules, where each rule consists of a predicate and a decision, and where each decision is either \u201caccept\u201d or \u201creject\u201d. A policy P is said to accept (or reject, respectively) a request iif the decision of the first rule in P, that matches the request is \u201caccept\u201d (or \u201creject\u201d, respectively). Examples of computing policies are firewalls, routing policies and software-defined networks in the Internet, and access control policies. A policy P is called adequate iff P accepts at least one request. It has been shown earlier that the problem of determining whether a given policy is adequate (called the policy adequacy problem) is NP-hard. In this paper, we present an efficient algorithm that use SAT solvers to solve the policy adequacy problem. Experimental results show that our algorithm can determine whether a given policy with 90\u00a0K rules is adequate in about 3\u00a0min.", "num_citations": "1\n", "authors": ["1804"]}
{"title": "Analysis of computing policies using sat solvers\n", "abstract": " A computing policy is a sequence of rules, where each rule consists of a predicate and a decision, and where each decision is either \u201caccept\u201d or \u201creject\u201d. A policy P is said to accept (or reject, respectively) a request if and only if the decision of the first rule in P, that matches the request is \u201caccept\u201d(or \u201creject\u201d, respectively). Examples of computing policies are firewalls, routing policies and software-defined networks in the Internet, and access control policies. It has been shown earlier that the problems of determining whether a given policy satisfies a property, such as adequacy, completeness, implication, equivalence, and redundancy, are all NP-hard. In this paper, we present efficient algorithms that use SAT solvers to determine whether any given policy satisfies a property. Experimental results show that our algorithms can determine whether a given policy with 90K rules satisfies the adequacy or completeness property in about 3 minutes. They also show that our algorithms can determine whether a given policy with 90K rules satisfies the implication, equivalence, or redundancy property in about 1 hour.", "num_citations": "1\n", "authors": ["1804"]}
{"title": "Theory and Applications of Satisfiability Testing\u2013SAT 2016\n", "abstract": " This volume contains the papers presented at the 18th International Conference on Theory and Applications of Satisfiability Testing (SAT 2015), held during September 24\u201327, 2015 in Austin, Texas, USA. SAT 2015 was colocated with Formal Methods in Computer-Aided Design (FMCAD 2015) and was hosted by the University of Texas at Austin.The International Conference on Theory and Applications of Satisfiability Testing (SAT) is the primary annual meeting for researchers focusing on the theory and applications of the propositional satisfiability problem, broadly construed: Besides plain propositional satisfiability, it includes Boolean optimization (including MaxSAT and Pseudo-Boolean (PB), constraints), Quantified Boolean Formulas (QBF), Satisfiability Modulo Theories (SMT), and Constraint Programming (CP) for problems with clear connections to propositional reasoning. Many hard combinatorial problems\u00a0\u2026", "num_citations": "1\n", "authors": ["1804"]}
{"title": "Theory and Applications of Satisfiability Testing--SAT 2015: 18th International Conference, Austin, TX, USA, September 24-27, 2015, Proceedings\n", "abstract": " This book constitutes the refereed proceedings of the 18th International Conference on Theory and Applications of Satisfiability Testing, SAT 2015, held in Austin, TX, USA, in September 2015. The 21 regular papers, 2 short papers and 7 tool papers presented together with 3 invited talks were carefully reviewed and selected from 70 submissions. The papers address different aspects of SAT, including theoretical advances (exact algorithms, proof complexity, and other complexity issues), practical search algorithms, knowledge compilation, implementation-level details of SAT solvers and SAT-based systems, problem encodings and reformulations, and applications, as well as case studies and reports on insightful findings based on rigorous experimentation. The paper'Constructing SAT Filters with a Quantum Annealer'is published open access under a CC BY-NC 2.5 license at link. springer. com.", "num_citations": "1\n", "authors": ["1804"]}