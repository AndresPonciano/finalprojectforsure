{"title": "Software Reuse and Software Component Technology [J]\n", "abstract": " Software reuse offers a solution to eliminate repeated work and improve efficiency and quality in the software development. In the recent ten years, object oriented technology has appeared and become a mainstream technology, thereby providing fundamental technology support for software reuse. Software reuse regains more attention in software engineering research and is considered a pratical and feasible approach to solving the software crisis. Software reuse is generally classified into two catalogues: product reuse and process reuse. Reuse based on software components is the important form of product reuse and is the major area of software reuse research. At the same time, software component technology plays an important role in distributed object research. Therefore, software component technology is regarded as a key factor of successful software reuse. The development and application of software reuse technology will facilitate the revolution of software development and reorganize software industry. As a result, the development of software components will become an independent and inseparable industry. The revolution offers a good chance for Chinese software development. This paper is a summarization on the development of software reuse technology. It presents fundamental concepts and key techniques of software reuse. After introducing several successful research and practice in software reuse, including Jade Bird Project, a Chinese national key project supported by the government, it proposes some ideas on how to reinforce research and application of related techniques and facilitate the development of software\u00a0\u2026", "num_citations": "228\n", "authors": ["2184"]}
{"title": "A two dimensional buddy system for dynamic resource allocation in a partitionable mesh connected system\n", "abstract": " The system partitioning problem in a partitionable mesh connected system (PMCS) is addressed. A two dimensional buddy system (2DBS) is proposed as a partitioning scheme for dynamic resource allocation in a PMCS. Allocation and reclamation algorithms and the method for locating buddies are designed. Internal fragmentation of our proposed 2DBS under various probability distributions of job sizes is analyzed. Experimental results on external and total fragmentations are also presented.", "num_citations": "214\n", "authors": ["2184"]}
{"title": "On three-dimensional packing\n", "abstract": " The three-dimensional packing problem is discussed in this paper. The problem is a generalization of the one- and two-dimensional packing problems. It is demonstrated that some basic packing strategies such as NFDH and FFDH for two-dimensional packing have unbounded worst-case performance ratios in the three-dimensional case. Let  denote the asymptotic performance bound of an approximation algorithm A. An approximation algorithm G is developed, and it is shown that . The algorithm is improved to algorithm C and it is proven that . For the special case when all boxes have square bottoms, the two algorithms are adapted to algorithms  and , respectively, with  and . For the case when both sides of the bottom of a box are no larger then , two families of algorithms,  and , are presented. It is shown that  and \u00a0\u2026", "num_citations": "119\n", "authors": ["2184"]}
{"title": "Distributed deep learning model for intelligent video surveillance systems with edge computing\n", "abstract": " In this paper, we propose a Distributed Intelligent Video Surveillance (DIVS) system using Deep Learning (DL) algorithms and deploy it in an edge computing environment. We establish a multi-layer edge computing architecture and a distributed DL training model for the DIVS system. The DIVS system can migrate computing workloads from the network center to network edges to reduce huge network communication overhead and provide low-latency and accurate video analysis solutions. We implement the proposed DIVS system and address the problems of parallel training, model synchronization, and workload balancing. Task-level parallel and model-level parallel training methods are proposed to further accelerate the video analysis process. In addition, we propose a model parameter updating method to achieve model synchronization of the global DL model in a distributed EC environment. Moreover, a\u00a0\u2026", "num_citations": "106\n", "authors": ["2184"]}
{"title": "Job scheduling in a partitionable mesh using a two-dimensional buddy system partitioning scheme\n", "abstract": " The job scheduling problem in a partitionable mesh-connected system in which jobs require square meshes and the system is a square mesh whose size is a power of two is discussed. A heuristic algorithm of time complexity O (n (log n+ log p)), in which n is the number of jobs to be scheduled and p is the size of the system is presented. The algorithm adopts the largest-job-first scheduling policy and uses a two-dimensional buddy system as the system partitioning scheme. It is shown that, in the worst case, the algorithm produces a schedule four times longer than an optimal schedule, and, on the average, schedules generated by the algorithm are twice as long as optimal schedules.", "num_citations": "66\n", "authors": ["2184"]}
{"title": "Energy-aware data allocation and task scheduling on heterogeneous multiprocessor systems with time constraints\n", "abstract": " In this paper, we address the problem of energy-aware heterogeneous data allocation and task scheduling on heterogeneous multiprocessor systems for real-time applications. In a heterogeneous distributed shared-memory multiprocessor system, an important problem is how to assign processors to real-time application tasks, allocate data to local memories, and generate an efficient schedule in such a way that a time constraint can be met and the total system energy consumption can be minimized. We propose an optimal approach, i.e., an integer linear programming method, to solve this problem. As the problem has been conclusively shown to be computationally very complicated, we also present two heuristic algorithms, i.e., task assignment considering data allocation (TAC-DA) and task ratio greedy scheduling (TRGS), to generate near-optimal solutions for real-time applications in polynomial time. We\u00a0\u2026", "num_citations": "64\n", "authors": ["2184"]}
{"title": "A scheduling scheme in the cloud computing environment using deep Q-learning\n", "abstract": " Task scheduling, which plays a vital role in cloud computing, is a critical factor that determines the performance of cloud computing. From the booming economy of information processing to the increasing need of quality of service (QoS) in the business of networking, the dynamic task-scheduling problem has attracted worldwide attention. Due to its complexity, task scheduling has been defined and classified as an NP-hard problem. Additionally, most dynamic online task scheduling often manages tasks in a complex environment, which makes it even more challenging to balance and satisfy the benefits of each aspect of cloud computing. In this paper, we propose a novel artificial intelligence algorithm, called deep Q-learning task scheduling (DQTS), that combines the advantages of the Q-learning algorithm and a deep neural network. This new approach is aimed at solving the problem of handling directed acyclic\u00a0\u2026", "num_citations": "63\n", "authors": ["2184"]}
{"title": "Computer-implemented method, computer system, and computer program product for optimization of evaluation of a policy specification\n", "abstract": " The present description relates to a computer-implemented method, computer system, and computer program product for optimization of evaluation of a policy specification. In one aspect, the computer-implemented method for optimization of evaluation of a policy specification may comprise receiving the policy specification represented as a tree, the tree comprising a plurality of nodes. A visiting history of the tree may be determined by computing a density at least for each node in a subset of the plurality of nodes having been visited. The density may be determined by a relationship between a position of a node v in the tree and a frequency F (v) in which the node v is visited. The tree may be transformed with respect to the visiting history into a similar tree such that sibling nodes in the subset of the plurality of nodes are sorted in decreasing order according to their density.", "num_citations": "51\n", "authors": ["2184"]}
{"title": "Test generation from security policies specified in or-bac\n", "abstract": " Security policy testing is a practical way to ensure security policies are correctly implemented in information or networking systems with a certain level of confidence. In this paper, we adapt model based testing techniques for formal models of security policies, and propose a two stage approach to produce test cases from a security policy specified in Or-BAC, i.e., test purpose generation from Or-BAC rules, and test case generation from test purposes.", "num_citations": "50\n", "authors": ["2184"]}
{"title": "CP-ABSE: A ciphertext-policy attribute-based searchable encryption scheme\n", "abstract": " Searchable encryption provides an effective mechanism that achieves secure search over encrypted data. A popular application model of searchable encryption is that a data owner stores encrypted data to a server and the server can effectively perform keyword-based search over encrypted data according to a query trapdoor submitted by a data user, where the owner\u2019s data and the user\u2019s queries are kept secret in the server. Recently, many searchable encryptions have been proposed to achieve better security and performance, provide secure data updatable feature ( dynamics ), and search results verifiable capability ( verifiability ). However, most of the existing works endow the data user an unlimited search capacities and do not consider a data user\u2019s search permissions. In practical application, granting search privileges for data users is a very important measure to enforce data access control. In this paper\u00a0\u2026", "num_citations": "46\n", "authors": ["2184"]}
{"title": "Complexity of resource allocation and job scheduling problems in partitionable mesh connected systems\n", "abstract": " Complexity of resource allocation and job scheduling problems in partitionable mesh connected systems | Interconnection networks for high-performance parallel computers ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksInterconnection networks for high-performance parallel computersComplexity of resource allocation and job scheduling problems in partitionable mesh connected systems chapter Complexity of resource allocation and job scheduling problems in partitionable mesh connected systems Share on Authors: Keqin Li profile image Keqin Li View Profile , Kamhoi Cheng profile image Kam Hoi Cheng View Profile \u2026", "num_citations": "44\n", "authors": ["2184"]}
{"title": "Representing and retrieving reusable software components in JB(jade bird) system\n", "abstract": " How to represent and retrieve reusable software component is always of interest to the reuse community. As a soft-ware development environment supporting systematic reuse, JB system chose faceted classification as the primary classification method, with several other methods constituting a combined solution, which supports multiple retrieval methods and their combination. The representation, classification and retrieval of reusable components in JB system, the assumptions we made, the design rationale, system architecture, data model and features of related subsystems are all introduced.", "num_citations": "42\n", "authors": ["2184"]}
{"title": "A new cloud service mechanism for profit optimizations of a cloud provider and its users\n", "abstract": " In this paper, we try to design a service mechanism for profit optimizations of both a cloud provider and its multiple users. We consider the problem from a game theoretic perspective and characterize the relationship between the cloud provider and its multiple users as a Stackelberg game, in which the strategies of all users are subject to that of the cloud provider. The cloud provider tries to select and provision appropriate servers and configure a proper request allocation strategy to reduce energy cost while satisfying its cloud users at the same time. We approximate its servers selection space by adding a controlling parameter and configure an optimal request allocation strategy. For each user, we design a utility function which combines the net profit with time efficiency and try to maximize its value under the strategy of the cloud provider. We formulate the competitions among all users as a generalized Nash\u00a0\u2026", "num_citations": "41\n", "authors": ["2184"]}
{"title": "Modular system verification by inference, testing and reachability analysis\n", "abstract": " Verification of a modular system composed of communicating components is a difficult problem, especially when the models of the components are not available. Conventional testing techniques are not efficient in detecting erroneous interactions of components because such interactions often occur as interleavings of events that are difficult to reproduce in a modular system. The problem of detecting intermittent errors in the absence of models of components is addressed in this paper. A method to infer a controllable approximation of components through testing is elaborated. The inferred finite state models of components are used to detect intermittent errors and other compositional problems in the system through reachability analysis. The models are refined at each analysis step thus making the approach iterative.", "num_citations": "40\n", "authors": ["2184"]}
{"title": "Static job scheduling in partitionable mesh connected systems\n", "abstract": " The static job scheduling problem in a partitionable mesh connected system (PMCS) is addressed. The relationship between static job scheduling and system partitioning is discussed and a lower bound for the absolute worst case performance of any polynomial time static job scheduling approximation algorithm in PMCS is obtained. A heuristic algorithm based on the simple partitioning strategy, layer by layer, and the scheduling policy, longest processing time first, is presented and its performance is analyzed. We prove that 5 + 4p/(8q \u2212 p) is a worst case absolute performance bound of our algorithm, where p \u00d7 q is the size of the PMCS. The bound is improved to 5 when each job requires a square submesh. If for any job we have a \u2a7d p/m and b \u2a7d q/m, where a \u00d7 b is the size of the job and m \u2a7e 3, then the bound is reduced to 2 + 2/(m \u2212 2); if, in addition, every job requires a square submesh, then the bound is\u00a0\u2026", "num_citations": "40\n", "authors": ["2184"]}
{"title": "An overview of JB (Jade Bird) component library system JBCL\n", "abstract": " The article introduces the JB (Jade Bird) Component Library system-JBCL. The goal of JBCL is to describe, manage, store and retrieve components. Based on the JB component model, the JB Component Library Data Model is developed. JBCL provides three sets of tools to assist users and managers to make best use of the JB component library, and uses a faceted method as the main classification strategy, and uses some other methods as auxiliary. Accordingly, it provides multiple retrieval means.", "num_citations": "39\n", "authors": ["2184"]}
{"title": "Citywide traffic flow prediction based on multiple gated spatio-temporal convolutional neural networks\n", "abstract": " Traffic flow prediction is crucial for public safety and traffic management, and remains a big challenge because of many complicated factors, e.g., multiple spatio-temporal dependencies, holidays, and weather. Some work leveraged 2D convolutional neural networks (CNNs) and long short-term memory networks (LSTMs) to explore spatial relations and temporal relations, respectively, which outperformed the classical approaches. However, it is hard for these work to model spatio-temporal relations jointly. To tackle this, some studies utilized LSTMs to connect high-level layers of CNNs, but left the spatio-temporal correlations not fully exploited in low-level layers. In this work, we propose novel spatio-temporal CNNs to extract spatio-temporal features simultaneously from low-level to high-level layers, and propose a novel gated scheme to control the spatio-temporal features that should be propagated through the\u00a0\u2026", "num_citations": "38\n", "authors": ["2184"]}
{"title": "A game approach to multi-servers load balancing with load-dependent server availability consideration\n", "abstract": " In this paper, we focus on request migration strategies among multi-servers for load balancing. Different from the general load balancing problem, we consider it under a distributed, non-cooperative, and competitive environment. Due to the mentioned characteristics, we view our problem from a game theoretic perspective and formulate it into a non-cooperative game among the multiple servers, in which each server is informed with incomplete information of other servers. For each server, we define its expected response time as a disutility function and try to minimize its value. We also take into account server availability, which impacts the processing capacity of a server and thus its disutility. We solve the problem by employing variational inequality (VI) theory and prove that there exists a Nash equilibrium solution set for the formulated game. Then, we propose an iterative proximal algorithm (IPA) to compute a Nash\u00a0\u2026", "num_citations": "38\n", "authors": ["2184"]}
{"title": "Integration testing of components guided by incremental state machine learning\n", "abstract": " The design of complex systems, e.g., telecom services, is nowadays usually based on the integration of components (COTS), loosely coupled in distributed architectures. When components come from third party sources, their internal structure is usually unknown and the documentation is insufficient. Therefore, the system integrator faces the problem of providing a required system assembling COTS whose behaviour is barely specified and for which no model is usually available. In this paper, we address the problem of integration testing of COTS. It combines test generation techniques with machine learning algorithms. State-based models of components are built from observed behaviours. The models are alternatively used to generate tests and extended to take into account observed behaviour. This process is iterated until a satisfactory level of confidence in testing is achieved", "num_citations": "38\n", "authors": ["2184"]}
{"title": "A survey on applications of artificial intelligence in fighting against COVID-19\n", "abstract": " The COVID-19 pandemic caused by the SARS-CoV-2 virus has spread rapidly worldwide, leading to a global outbreak. Most governments, enterprises, and scientific research institutions are participating in the COVID-19 struggle to curb the spread of the pandemic. As a powerful tool against COVID-19, artificial intelligence (AI) technologies are widely used in combating this pandemic. In this survey, we investigate the main scope and contributions of AI in combating COVID-19 from the aspects of disease detection and diagnosis, virology and pathogenesis, drug and vaccine development, and epidemic and transmission prediction. In addition, we summarize the available data and resources that can be used for AI-based COVID-19 research. Finally, the main challenges and potential directions of AI in fighting against COVID-19 are discussed. Currently, AI mainly focuses on medical image inspection, genomics, drug\u00a0\u2026", "num_citations": "37\n", "authors": ["2184"]}
{"title": "A Stackelberg game approach to multiple resources allocation and pricing in mobile edge computing\n", "abstract": " Mobile edge computing is a new paradigm that can enhance the computation capability of end devices and alleviate communication traffic loads during transmission. Mobile edge computing is highly useful for emerging resource-hungry mobile applications. However, a key challenge for mobile edge computing systems is multiple resources allocation between Mobile Edge Clouds (MECs) and End Users (EUs), especially for multiple heterogeneous MECs and EUs. To address this problem, we propose a Stackelberg game-based framework in which EUs and MECs act as followers and leaders, respectively. The proposed framework aims to compute a Stackelberg equilibrium solution in which each MEC achieves the maximum revenue while each EU obtains utility-maximized resources under budget constraints. We decompose the multiple resources allocation and pricing problem into a set of subproblems in which\u00a0\u2026", "num_citations": "37\n", "authors": ["2184"]}
{"title": "Model-checking driven security testing of web-based applications\n", "abstract": " Model checking and security testing are two verification techniques available to help finding flaws in security-sensitive, distributed applications. In this paper, we present an approach to security testing of web-based applications in which test cases are automatically derived from counterexamples found through model checking. We illustrate our approach by discussing its application against of the SAML-based Single Sign-On for Google Apps.", "num_citations": "37\n", "authors": ["2184"]}
{"title": "Learning and integration of parameterized components through testing\n", "abstract": " We investigate the use of parameterized state machine models to drive integration testing, in the case where the models of components are not available beforehand. Therefore, observations from tests are used to learn partial models of components, from which further tests can be derived for integration. We have extended previous algorithms to the case of finite state models with predicates on input parameters and observable non-determinism. We also propose a new strategy where integration tests can be derived from the data collected during the learning process. Our work typically addresses the problem of assembling telecommunication services from black box COTS.", "num_citations": "37\n", "authors": ["2184"]}
{"title": "An optimized MapReduce workflow scheduling algorithm for heterogeneous computing\n", "abstract": " The MapReduce framework is considered to be an effective resolution for huge and parallel data processing. This paper treats a massive data processing workflow as a DAG graph consisting of MapReduce jobs. In a heterogeneous computing environment, the computation speed can be different even on the same slot depending on various jobs. For this problem, this paper proposes an optimized MapReduce workflow scheduling algorithm. This algorithm comprises a job prioritizing phase and a task assignment phase. First, the jobs can be classified as I/O-intensive and computing-intensive, and the priorities of all jobs are computed according to their corresponding types. Then, the suitable slots are allocated for each block, and the MapReduce tasks in the workflow are scheduled with respect to data locality. The experimental results show that the optimized MapReduce workflow scheduling algorithm can\u00a0\u2026", "num_citations": "36\n", "authors": ["2184"]}
{"title": "Progressive approaches for pareto optimal groups computation\n", "abstract": " Group skyline query is a powerful tool for optimal group analysis. Most of the existing group skyline queries select optimal groups by comparing the dominance relationship between aggregate-based points; such feature creates difficulties for users to specify an appropriate aggregate function. Besides, many significant groups that have great attractions to users in practice may be overlooked. To address these issues, the group skyline (GSky) query is formulated on the basis of a general definition of group dominance operator. While the existing GSky query algorithms are effective, there is still room for improvement in terms of progressiveness and efficiency. In this paper, we propose some new lemmas which facilitate direct generation of the GSky query results. Consecutively, we design a layered unit-based (LU) algorithm that applies a layered optimum strategy. Additionally, for the GSky query over the data that are\u00a0\u2026", "num_citations": "32\n", "authors": ["2184"]}
{"title": "A keyword-based combination approach for detecting phishing webpages\n", "abstract": " In this paper, the Search & Heuristic Rule & Logistic Regression (SHLR) combination detection method is proposed for detecting the obfuscation techniques commonly used by phishing websites and improving the filtering efficiency of legitimate webpages. The method is composed of three steps. First, the title tag content of the webpage is input as search keywords to the Baidu search engine, and the webpage is considered legal if the webpage domain matches the domain name of any of the top-10 search results; otherwise, further evaluation is performed. Second, if the webpage cannot be identified as legal, then the webpage is further examined to determine whether it is a phishing page based on the heuristic rules defined by the character features. The first two steps can quickly filter webpages to meet the needs of real-time detection. Finally, a logistic regression classifier is used to assess the remaining pages to\u00a0\u2026", "num_citations": "30\n", "authors": ["2184"]}
{"title": "Scalable molecular dynamics with NAMD on the summit system\n", "abstract": " NAnoscale Molecular Dynamics (NAMD) is a parallel molecular dynamics application that has been used to make breakthroughs in understanding the structure and dynamics of large biomolecular complexes, such as viruses like HIV and various types of influenza. State-of-the-art biomolecular simulations often require integration of billions of timesteps, computing all interatomic forces for each femtosecond timestep. Molecular dynamics simulation of large biomolecular systems and long-timescale biological phenomena requires tremendous computing power. NAMD harnesses the power of thousands of heterogeneous processors to meet this demand. In this paper, we present algorithmic improvements and performance optimizations that enable NAMD to achieve high performance on the IBM Newell platform (with IBM POWER9 processors and NVIDIA Volta V100 GPUs), which underpins the Oak Ridge National\u00a0\u2026", "num_citations": "30\n", "authors": ["2184"]}
{"title": "Vera: A flexible model-based vulnerability testing tool\n", "abstract": " There exist an abundant number of tools for aiding developers and penetration testers to spot common software security vulnerabilities. However, testers are often confronted with situations where existing tools are of little help because a) they do not account for a particular configuration of the SUT and b) they do not include tests for certain vulnerabilities. To cope with this we propose a tool that allows users to define attacker models where the payloads and the behavior are cleanly separated and that abstract away from low-level implementation details such as HTTP requests.", "num_citations": "30\n", "authors": ["2184"]}
{"title": "A query privacy-enhanced and secure search scheme over encrypted data in cloud computing\n", "abstract": " With the emerging of the cloud computing, secure search over encrypted cloud data has become a hot research spot. Previous schemes achieve weaker query privacy-preserving ability due to the limitations of query trapdoor generation mechanisms. In these schemes, a data owner usually knows fully well the query contents of data users and a data user can also easily analyze query contents of another data user. In some application scenarios, the data user may be unwilling to leak their query privacy to anyone else except himself. We propose a privacy-enhanced search scheme by allowing the data user to generate random query trapdoor every time. We leverage Bloom filter and bilinear pairing operation to construct secure index for each data file, which enables the cloud to perform search without obtaining any useful information. We prove that our scheme is secure and extensive experiments demonstrate the\u00a0\u2026", "num_citations": "29\n", "authors": ["2184"]}
{"title": "Learning parameterized state machine model for integration testing\n", "abstract": " Although many of the software engineering activities can now be model-supported, the model is often missing in software development. We are interested in retrieving state- machine models from black-box software components. We assume that the details of the development process of such components (third-party software or COTS) are not available. To adequately support software engineering activities, we need to learn more complex models than simple automata. Our model is an extension of finite state machines that incorporates the notions of predicates and parameters on transitions. We argue that such a model can offer a suitable trade-off between expressivity of the model and complexity of model learning. We have been able to extend polynomial learning algorithms to extract such models in an incremental testing approach. In turn, the models can be used to derive tests or for component documentation.", "num_citations": "29\n", "authors": ["2184"]}
{"title": "Integration testing of distributed components based on learning parameterized I/O models\n", "abstract": " The design of complex systems, e.g., telecom services, is usually based on the integration of components (COTS). When components come from third party sources, their internal structure is usually unknown and the documentation is scant or inadequate.               Our work addresses the issue of providing a sound support to component integration in the absence of formal models. We consider components as black boxes and use an incremental learning approach to infer partial models. At the same time, we are focusing on the richer models that are more expressive in the designing of complex systems. Therefore, we propose an I/O parameterized model and an algorithm to infer it from a black box component. This is combined with interoperability testing covering models of the components.", "num_citations": "29\n", "authors": ["2184"]}
{"title": "Computation offloading strategy optimization with multiple heterogeneous servers in mobile edge computing\n", "abstract": " Computation offloading from a user equipment (UE) to a mobile edge cloud (MEC) is an effective way to ease the computational burden of mobile devices, to improve the performance of mobile applications, to reduce the energy consumption and to extend the battery lifetime of mobile user equipments. In this paper, we consider computation offloading strategy optimization with multiple heterogeneous servers in mobile edge computing. Queueing models are established for a UE and multiple heterogeneous servers from different MECs, and the average task response time of the UE and each MEC server and the average response time of all offloadable and non-offloadable tasks generated on the UE are rigorously analyzed. Three multi-variable optimization problems are formulated, i.e., minimization of average response time with average power consumption constraint, minimization of average power consumption\u00a0\u2026", "num_citations": "27\n", "authors": ["2184"]}
{"title": "Slow-movement particle swarm optimization algorithms for scheduling security-critical tasks in resource-limited mobile edge computing\n", "abstract": " Mobile edge computing (MEC) allows mobile devices to offload computation tasks to nearby MEC servers for achieving low latency and energy efficiency. This paper aims at scheduling security-critical tasks, which require data encryption and thus incur extra runtime and energy costs, in a MEC system consisting of multiple resource-limited MEC servers. The scheduling objective is to minimize task completion time as well as the mobile device\u2019s energy consumption. We propose two slow-movement particle swarm optimization algorithms to solve the resultant NP-hard problem. Specifically, we develop a position-based mapping scheme to map particles onto scheduling solutions. The mapping method relies on the current best solution and a position-based probability model to generate high-quality solutions that can inherit the good schemata from the current best solution. To prevent the significant change in particles\u00a0\u2026", "num_citations": "24\n", "authors": ["2184"]}
{"title": "Privacy-preserving range query over multi-source electronic health records in public clouds\n", "abstract": " Range query is an important data search technique in cloud-based electronic healthcare (eHealth) systems. It enables authorized doctors to retrieve target electronic health records (EHRs) that are generated and outsourced by patients from the cloud server. In reality, patients always encrypt their EHRs before outsourcing, making the range query impossible. In this paper, we identify three threats in real cloud-based eHealth systems, i.e., privacy leakage, frequency analysis, and identical data inference. To capture the security properties that resist these threats, we define a security notion of indistinguishability under multi-source ordered chosen plaintext attack (IND-MSOCPA). Then, we propose a multi-source order-preserving encryption (MSOPE) scheme for cloud-based eHealth systems to enable range queries over encrypted EHRs from multiple patients. Security analysis proves that the MSOPE scheme is IND\u00a0\u2026", "num_citations": "24\n", "authors": ["2184"]}
{"title": "An object-oriented method for domain engineering\n", "abstract": " In this paper, an object-oriented domain engineering method, Jade Bird domain engineering method is proposed. In domain engineering, several systems in a domain are analyzed, and their commonalities and variabilities are identified. Through development for reuse, domain-specific components and the architecture are produced. Domain engineering approach helps successfully for software reuse. Based on the Jade Bird object-oriented method, this method defines activities and artifacts in every domain engineering stage, and gives guidelines for each stage and the activities in it.[Fund]: \u56fd\u5bb6\u81ea\u7136\u79d1\u5b66\u57fa\u91d1\u8d44\u52a9\u9879\u76ee (60103001);; \u56fd\u5bb6 \u201c\u4e5d\u4e94\u201d \u91cd\u70b9\u79d1\u6280\u653b\u5173\u9879\u76ee (98-780);; \u56fd\u5bb6\u6559\u80b2\u90e8\u9ad8\u7b49\u5b66\u6821\u9aa8\u5e72\u6559\u5e08\u8d44\u52a9\u9879\u76ee~", "num_citations": "24\n", "authors": ["2184"]}
{"title": "An energy-aware algorithm for virtual machine placement in cloud computing\n", "abstract": " Virtualization technology, as a key technology in cloud computing, makes the virtual machine placement (VMP) play an important role in improving the energy efficiency of data centers. In this paper, an energy-aware algorithm named GATA is proposed for the VMP problem. It combines the genetic algorithm with the tabu search algorithm. The goal is to obtain an optimal VMP scheme to achieve energy efficiency while maximizing load balance among various resources. The algorithm is compared with two meta-heuristic algorithms and a newly proposed algorithm that is based on ant colony algorithm. The execution time of these algorithms is also discussed. The results show that the proposed algorithm is superior to those methods mentioned above.", "num_citations": "23\n", "authors": ["2184"]}
{"title": "A survey of hierarchical energy optimization for mobile edge computing: A perspective from end devices to the cloud\n", "abstract": " With the development of wireless technology, various emerging mobile applications are attracting significant attention and drastically changing our daily lives. Applications such as augmented reality and object recognition demand stringent delay and powerful processing capability, which exerts enormous pressure on mobile devices with limited resources and energy. In this article, a survey of techniques for mobile device energy optimization is presented in a hierarchy of device design and operation, computation offloading, wireless data transmission, and cloud execution of offloaded computation. Energy management strategies for mobile devices from hardware and software aspects are first discussed, followed by energy-efficient computation offloading frameworks for mobile applications that trade application response time for device energy consumption. Then, techniques for efficient wireless data\u00a0\u2026", "num_citations": "22\n", "authors": ["2184"]}
{"title": "An ultra-lightweight encryption scheme in underwater acoustic networks\n", "abstract": " We tackle a fundamental security problem in underwater acoustic networks (UANs). The S-box in the existing block encryption algorithm is more energy consuming and unsuitable for resources-constrained UANs. In this paper, instead of S-box, we present a lightweight, 8-round iteration block cipher algorithm for UANs communication based on chaotic theory and increase the key space by changing the number of iteration round. We further propose secure network architecture of UANs. By analysis, our algorithm can resist brute-force searches and adversarial attacks. Simulation results show that, compared with traditional AES-128 and PRESENT algorithms, our cryptographic algorithm can make a good trade-off between security and overhead, has better energy efficiency, and applies to UANs.", "num_citations": "22\n", "authors": ["2184"]}
{"title": "Type-based enforcement of secure programming guidelines\u2014code injection prevention at SAP\n", "abstract": " Code injection and cross-site scripting belong to the most common security vulnerabilities in modern software, usually caused by incorrect string processing. These exploits are often addressed by formulating programming guidelines or \u201cbest practices\u201d.             In this paper, we study the concrete example of a guideline used at SAP for the handling of untrusted, potentially executable strings that are embedded in the output of a Java servlet. To verify adherence to the guideline, we present a type system for a Java-like language that is extended with refined string types, output effects, and polymorphic method types.             The practical suitability of the system is demonstrated by an implementation of a corresponding string type verifier and context-sensitive inference for real Java programs.", "num_citations": "22\n", "authors": ["2184"]}
{"title": "A passive testing approach for security checking and its practical usage for web services monitoring\n", "abstract": " To achieve a meaningful business goal,Web services are combined and connected together based on a predefined workflow. In this distributed configuration, tasks are executed by different entities usually managed by different business partners which makes the security monitoring of the whole business process complex. Indeed, the application of classical monitoring methods is not suitable in this kind of service oriented architecture (SOA) where execution traces collection is generally distributed and security requirements implicate several Web services. In this paper we propose a passive testing approach for SOA, encompassing a non-intrusive module that gathers selected traces for web services in both cases of centralized and decentralized workflows, and also a passive tester that analyzes the distributed collected traces and deduces a verdict concerning the respect of the Web services to their security requirements. Finally we apply the proposed methodology to a Loan Origination Process using BPEL workflow", "num_citations": "22\n", "authors": ["2184"]}
{"title": "Probabilistic analysis of scheduling precedence constrained parallel tasks on multicomputers with contiguous processor allocation\n", "abstract": " Given a set of precedence constrained parallel tasks with their processor requirements and execution times, the problem of scheduling precedence constrained parallel tasks on multicomputers with contiguous processor allocation is to find a nonpreemptive schedule of the tasks on a multicomputer such that the schedule length is minimized. This scheduling problem is substantially more difficult than other scheduling problems due to precedence constraints among tasks, the inherent difficulty of task scheduling, and processor allocation in multicomputers. We present an approximation algorithm called LLB that schedules tasks level-by-level using the largest-task-first strategy supported by the binary system partitioning scheme to handle the three difficult issues in our scheduling problem. Though algorithm LLB does not have a bounded worst-case performance ratio, we show through probabilistic analysis that LLB\u00a0\u2026", "num_citations": "22\n", "authors": ["2184"]}
{"title": "A pipeline computing method of SpTV for three-order tensors on CPU and GPU\n", "abstract": " Tensors have drawn a growing attention in many applications, such as physics, engineering science, social networks, recommended systems. Tensor decomposition is the key to explore the inherent intrinsic data relationship of tensor. There are many sparse tensor and vector multiplications (SpTV) in tensor decomposition. We analyze a variety of storage formats of sparse tensors and develop a piecewise compression strategy to improve the storage efficiency of large sparse tensors. This compression strategy can avoid storing a large number of empty slices and empty fibers in sparse tensors, and thus the storage space is significantly reduced. A parallel algorithm for the SpTV based on the high-order compressed format based on slices is designed to greatly improve its computing performance on graphics processing unit. Each tensor is cut into multiple slices to form a series of sparse matrix and vector\u00a0\u2026", "num_citations": "20\n", "authors": ["2184"]}
{"title": "COOPER-MATCH: Job offloading with a cooperative game for guaranteeing strict deadlines in MEC\n", "abstract": " While mobile edge computing (MEC) holds promise to enhance users' mobile experience, building a framework under multiple MECs environment to make appropriate offloading decision is challenging. When involving quality of service (QoS), the problem becomes even harder. Few works can be found for this. In this work, we focus on QoS guaranteed offloading under multiple MECs environment. Specifically, there are multiple mobile devices (MDs) and each one is associated with a job which can be offloaded to an access point (AP) for execution. Each job is associated with a block of input data, an execution workload, and a QoS requirement, i.e., a time deadline that the job is expected to be completed before it if it is offloaded to an AP for execution. Our goal is to find an efficient offloading strategy which guides for offloading MDs' jobs to appropriate MEC servers, such that the number of jobs whose deadlines\u00a0\u2026", "num_citations": "20\n", "authors": ["2184"]}
{"title": "On elasticity measurement in cloud computing\n", "abstract": " Elasticity is the foundation of cloud performance and can be considered as a great advantage and a key benefit of cloud computing. However, there is no clear, concise, and formal definition of elasticity measurement, and thus no effective approach to elasticity quantification has been developed so far. Existing work on elasticity lack of solid and technical way of defining elasticity measurement and definitions of elasticity metrics have not been accurate enough to capture the essence of elasticity measurement. In this paper, we present a new definition of elasticity measurement and propose a quantifying and measuring method using a continuous-time Markov chain (CTMC) model, which is easy to use for precise calculation of elasticity value of a cloud computing platform. Our numerical results demonstrate the basic parameters affecting elasticity as measured by the proposed measurement approach. Furthermore, our simulation and experimental results validate that the proposed measurement approach is not only correct but also robust and is effective in computing and comparing the elasticity of cloud platforms. Our research in this paper makes significant contribution to quantitative measurement of elasticity in cloud computing.", "num_citations": "20\n", "authors": ["2184"]}
{"title": "Egroupnet: a feature-enhanced network for age estimation with novel age group schemes\n", "abstract": " Although age estimation is easily affected by smiling, race, gender, and other age-related attributes, most of the researchers did not pay attention to the correlations among these attributes. Moreover, many researchers perform age estimation from a wide range of age; however, conducting an age prediction over a narrow age range may achieve better results. This article proposes a hierarchic approach referred to as EGroupNet for age prediction. The method includes two main stages, i.e., feature enhancement via excavating the correlations among age-related attributes and age estimation based on different age group schemes. First, we apply the multi-task learning model to learn multiple face attributes simultaneously to obtain discriminative features of different attributes. Second, we project the outputs of fully connected layers of several subnetworks into a highly correlated matrix space via the correlation learning\u00a0\u2026", "num_citations": "19\n", "authors": ["2184"]}
{"title": "Secure conjunctive multi-keyword ranked search over encrypted cloud data for multiple data owners\n", "abstract": " Recently, secure search over encrypted cloud data has become a hot research spot and challenging task. A number of secure search schemes have been proposed to try to meet this challenge. However, most of them only consider the single data owner model. In this paper, we propose a conjunctive multi-keyword ranked secure search scheme for multiple data owners. To guarantee data security and system flexibility in the multiple data owners environment, we design an ingenious secure query scheme that allows each data owner to adopt randomly chosen temporary keys to build secure indexes for different data files. An authorized data user does not need to know these temporary keys of constructing indexes and can instead randomly choose another temporary query keys to encrypt query keywords, while the cloud server can correctly perform keywords matching over encrypted data files. To rank the query\u00a0\u2026", "num_citations": "19\n", "authors": ["2184"]}
{"title": "COOPER-SCHED: A cooperative scheduling framework for mobile edge computing with expected deadline guarantee\n", "abstract": " While mobile edge computing (MEC) holds promise to enhance users' mobile experiences, building a scheduling framework to make full use of MEC capabilities is challenging. When involving quality of service (QoS) in MEC, the problem becomes even harder. In this work, we focus on QoS guaranteed scheduling in MEC with a cloudlet, which is a small cloud center deployed at the wireless access point (AP) to serve nearby mobile devices. There are multiple mobile devices (MDs) and each one is associated with a job to be offloaded to the AP and executed in the cloudlet. Each job is associated with a block of input data, an execution workload, and a QoS requirement, i.e., a time deadline that the job is expected to be completed before it. Our goal is to find an efficient schedule, which involves radio access network (RAN) allocation and job mapping on multiple heterogeneous servers, such that the number of jobs\u00a0\u2026", "num_citations": "19\n", "authors": ["2184"]}
{"title": "Stochastic bounds for parallel program execution times with processor constraints\n", "abstract": " A parallel program can be modeled as an acyclic directed graph, where a node represents a task, which is the smallest grain of computation to be assigned to a processor, and arcs stand for precedence (synchronization) constraints among the tasks. Due to different input data and unpredictable dynamic run time environments, the execution times of tasks as well as the entire program can be treated as random variables. In this paper, we develop some stochastic lower and upper bounds for parallel program execution times when there are limited processors. Such analysis can provide important information for job scheduling and resource allocation. For several typical classes of parallel programs, we derive very accurate closed form approximations for the bounds. Examples are also given to demonstrate the quality of the bounds derived.", "num_citations": "19\n", "authors": ["2184"]}
{"title": "Multi-objective VM consolidation based on thresholds and ant colony system in cloud computing\n", "abstract": " With the large-scale deployment of cloud datacenters, high energy consumption and serious service level agreement (SLA) violations in datacenters have become an increasingly urgent problem to be addressed. Implementing an effective virtual machine (VM) consolidation methods is of great significance to reduce energy consumption and SLA violations. The VM consolidation problem is a well-known NP-hard problem. Meanwhile, efficient VM consolidation should consider multiple factors synthetically, including quality of service, energy consumption, and migration overhead, which is a multi-objective optimization problem. To solve the problem above, we propose a new multi-objective VM consolidation approach based on double thresholds and ant colony system (ACS). The proposed approach leverages double thresholds of CPU utilization to identify the host load status, VM consolidation is triggered when the\u00a0\u2026", "num_citations": "18\n", "authors": ["2184"]}
{"title": "RLT code based handshake-free reliable MAC protocol for underwater sensor networks\n", "abstract": " The characteristics of underwater acoustic channels such as long propagation delay and low bit rate cause the medium access control (MAC) protocols designed for radio channels to either be inapplicable or have low efficiency for underwater sensor networks (UWSNs). Meanwhile, due to high bit error, conventional end-to-end reliable transfer solutions bring about too many retransmissions and are inefficient in UWSN. In this paper, we present a recursive LT (RLT) code. With small degree distribution and recursive encoding, RLT achieves reliable transmission hop-by-hop while reducing the complexity of encoding and decoding in UWSN. We further propose an RLT code based handshake-free (RCHF) reliable MAC protocol. In RCHF protocol, each node maintains a neighbor table including the field of state, and packages are forwarded according to the state of a receiver, which can avoid collisions of sending-receiving and overhearing. The transmission-avoidance time in RCHF decreases data-ACK collision dramatically. Without RTS/CTS handshaking, the RCHF protocol improves channel utilization while achieving reliable transmission. Simulation results show that, compared with the existing reliable data transport approaches for underwater networks, RCHF can improve network throughput while decreasing end-to-end overhead.", "num_citations": "18\n", "authors": ["2184"]}
{"title": "Robust dynamic network traffic partitioning against malicious attacks\n", "abstract": " The continual growth of network traffic rates leads to heavy packet processing overheads, and a typical solution is to partition traffic into multiple network processors for parallel processing especially in emerging software-defined networks. This paper is thus motivated to propose a robust dynamic network traffic partitioning scheme to defend against malicious attacks. After introducing the conceptual framework of dynamic network traffic partitioning based on flow tables, we strengthen its TCP connection management by building a half-open connection separation mechanism to isolate false connections in the initial connection table (ICT). Then, the lookup performance of the ICT table is reinforced by applying counting bloom filters to cope with malicious behaviors such as SYN flooding attacks. Finally, we evaluate the performance of our proposed traffic partitioning scheme with real network traffic traces and simulated\u00a0\u2026", "num_citations": "17\n", "authors": ["2184"]}
{"title": "Implicit flows in malicious and nonmalicious code\n", "abstract": " Information-flow technology is a promising approach for ensuring security by design and construction. When tracking information flow, of particular concern are implicit flows, ie, flows through control flow when computation branches on secret data and performs publicly observed side effects depending on which branch is taken.", "num_citations": "16\n", "authors": ["2184"]}
{"title": "Job scheduling in partitionable mesh connected systems\n", "abstract": " The job-scheduling problem in partitionable mesh connected systems (PMCSs) is addressed. The relationship between job scheduling and system partitioning is discussed, and a lower bound on the worst-case performance of any polynomial-time job-scheduling approximation algorithm in a PMCS is obtained. A heuristic algorithm based on a simple partitioning strategy and scheduling policy is presented, and its performance is analyzed. (I.E.)", "num_citations": "16\n", "authors": ["2184"]}
{"title": "A survey of profit optimization techniques for cloud providers\n", "abstract": " As the demand for computing resources grows, cloud computing becomes more and more popular as a pay-as-you-go model, in which the computing resources and services are provided to cloud users efficiently. For cloud providers, the typical goal is to maximize their profits. However, maximizing profits in a highly competitive cloud market is a huge challenge for cloud providers. In this article, a survey of profit optimization techniques is proposed to increase cloud provider profitability through service quality improvement, service pricing, energy consumption reduction, and virtual network function (VNF) deployment. The strategy of improving user service quality is discussed first, followed by the pricing strategy for cloud resources to maximize revenue. Then, this article summarizes the techniques for cloud data centers to reduce server power consumption. Finally, various heuristic algorithms for VNF deployment in\u00a0\u2026", "num_citations": "15\n", "authors": ["2184"]}
{"title": "Achieving socio-technical confidentiality using security pattern in smart homes\n", "abstract": " In this paper we discuss and address multifold security challenges involved in the implementation of remote healthcare in smart homes. These security challenges are derived from real-world, industrially relevant scenarios. Validated security techniques and mechanisms providing certain security properties can be captured and implemented in security patterns, which can be applied in order to satisfy security requirements in the smart home healthcare scenarios. The presented results are parts of our ongoing research effort aiming at the development of an integrated security framework for remote healthcare and ambient intelligence systems.", "num_citations": "15\n", "authors": ["2184"]}
{"title": "Service reliability in an HC: Considering from the perspective of scheduling with load-dependent machine reliability\n", "abstract": " Considering the fact that a server is more likely to fail if it is highly loaded, in this paper, we involve load impacts on service reliability in a heterogeneous cluster, where servers have load-dependent reliabilities and jobs have resource and execution interval demands. Specifically, each server is specified by a resource capacity and a workload limitation, i.e., the server is expected to perform reliably if its workload is less than the workload limitation. There is also a set of jobs needing to be executed on these servers. Each job is associated with a resource demand and an execution interval, i.e., the time interval that the job is planned to be executed. Our goal is to find a reliable schedule ofjobs to servers such that all servers' workload limitations are satisfied. The problem is proved to be strongly NP-complete, which implies that there is not even a pseudo-polynomial time algorithm. Hence, we try our best to find a reliable\u00a0\u2026", "num_citations": "14\n", "authors": ["2184"]}
{"title": "Bargaining game-based scheduling for performance guarantees in cloud computing\n", "abstract": " In this article, we focus on request scheduling with performance guarantees of all users in cloud computing. Each cloud user submits requests with average response time requirement, and the cloud provider tries to find a scheduling scheme, i.e., allocating user requests to limited servers, such that the average response times of all cloud users can be guaranteed. We formulate the considered scenario into a cooperative game among multiple users and try to find a Nash bargaining solution (NBS), which can simultaneously satisfy all users\u2019 performance demands. We first prove the existence of NBS and then analyze its computation. Specifically, for the situation when all allocating substreams are strictly positive, we propose a computational algorithm (CA), which can find the NBS very efficiently. For the more general case, we propose an iterative algorithm (IA), which is based on duality theory. The convergence of our\u00a0\u2026", "num_citations": "14\n", "authors": ["2184"]}
{"title": "Identifying the most influential spreaders in complex networks by an Extended Local K-Shell Sum\n", "abstract": " Identifying influential spreaders is crucial for developing strategies to control the spreading process on complex networks. Following the well-known K-Shell (KS) decomposition, several improved measures are proposed. However, these measures cannot identify the most influential spreaders accurately. In this paper, we define a Local K-Shell Sum (LKSS) by calculating the sum of the K-Shell indices of the neighbors within 2-hops of a given node. Based on the LKSS, we propose an Extended Local K-Shell Sum (ELKSS) centrality to rank spreaders. The ELKSS is defined as the sum of the LKSS of the nearest neighbors of a given node. By assuming that the spreading process on networks follows the Susceptible-Infectious-Recovered (SIR) model, we perform extensive simulations on a series of real networks to compare the performance between the ELKSS centrality and other six measures. The results show that\u00a0\u2026", "num_citations": "14\n", "authors": ["2184"]}
{"title": "Secure conjunctive multi-keyword search for multiple data owners in cloud computing\n", "abstract": " Recently, secure search over encrypted cloud data has become a hot research spot and challenging task. Some secure search schemes have been proposed to try to meet this challenge. In this paper, we propose a conjunctive multi-keyword secure search scheme for multiple data owners. To guarantee data security and system flexibility in the multiple data owners environment, we design an ingenious secure query scheme that allows each data owner to adopt randomly chosen temporary keys to build secure indexes for different data files. An authorized data user does not need to know these temporary keys of constructing indexes and can instead randomly choose another temporary query keys to encrypt query keywords while the cloud can correctly perform keywords matching over encrypted data files. Extensive experiments demonstrate the correctness and practicality of the proposed scheme.", "num_citations": "14\n", "authors": ["2184"]}
{"title": "Developing energy-aware task allocation schemes in cloud-assisted mobile workflows\n", "abstract": " Mobile cloud computing is an emerging field of research which aims to provide a platform on which intelligent and feature-rich applications are delivered to the user at any time and at anywhere. When such a cloud-assisted mobile application workflow requires the cooperation of many devices, solving the task allocation problem becomes a critical step in ensuring the energy efficiency of the mobile cloud platform. In this paper, we construct a quadratic binary program to model the task allocation problem in such scenarios. In order to overcome the poor scalability of generic quadratic program solvers, we present an implementation of the simulated annealing algorithm and a greedy autonomous offload algorithm to approximate the optimal solution. Both heuristics are tailored to solve our task allocation problem efficiently. We verify and compare our algorithms against a commercial quadratic program solver in a series\u00a0\u2026", "num_citations": "14\n", "authors": ["2184"]}
{"title": "Efficient Approaches to k Representative G-Skyline Queries\n", "abstract": " The G-Skyline (GSky) query is a powerful tool to analyze optimal groups in decision support. Compared with other group skyline queries, it releases users from providing an aggregate function. Besides, it can get much comprehensive results without overlooking some important results containing non-skylines. However, it is hard for the users to make sensible choices when facing so many results the GSky query returns, especially over a large, high-dimensional dataset or with a large group size. In this article, we investigate k representative G-Skyline (kGSky) queries to obtain a manageable size of optimal groups. The kGSky query can also inherit the advantage of the GSky query; its results are representative and diversified. Next, we propose three exact algorithms with novel techniques including an upper bound pruning, a grouping strategy, a layered optimum strategy, and a hybrid strategy to efficiently process the\u00a0\u2026", "num_citations": "13\n", "authors": ["2184"]}
{"title": "Enhance chaotic gravitational search algorithm (CGSA) by balance adjustment mechanism and sine randomness function for continuous optimization problems\n", "abstract": " The gravitational search algorithm (GSA) is a population-based meta-heuristic optimization algorithm which finds the optimal solution by the law of gravity and attraction between objects. However, as the number of iterations increases, the increase of the quality of the agents makes GSA fall into the local optimal solution more easily, which greatly reduces the exploration capability of the algorithm. Although the chaotic gravitational search algorithm (CGSA) uses chaotic maps for improving diversity to solve this problem, it still has problems with the balance of exploration and exploitation. This paper proposes the balance adjustment based chaotic gravitational search algorithm (BA-CGSA), which introduces the sine randomness function and the balance mechanism to solve the above problem. 30 benchmark functions of IEEE CEC 2014 are adopted to evaluate the performance of the proposed algorithm in terms of\u00a0\u2026", "num_citations": "13\n", "authors": ["2184"]}
{"title": "Collaborative optimization of service composition for data-intensive applications in a hybrid cloud\n", "abstract": " The multi-valued evaluations of quality of service (QoS), the complicated constraints between cloud services (CSs) and the collaborative resource assignments add many difficulties to the problem of CS composition for data-intensive applications (DiA) in a hybrid cloud (CSCD-HC). Solving the CSCD-HC problem has become a challenging task due to the uncertain QoS, the diverse hardware configurations and the flexible pricing about CSs. This paper proposes a collaborative optimization approach for CSCD-HC. This approach models a DiA as a role-based collaboration (RBC) system and employs the environments-classes, agents, roles, groups, and objects (E-CARGO) model to formalize the CSCD-HC problem with complicated constraints. To deal with the multi-valued QoS evaluations, this paper exploits the cloud model theory to analyze the performance of CSs, and presents a new method utilizing the\u00a0\u2026", "num_citations": "13\n", "authors": ["2184"]}
{"title": "An intermediate data partition algorithm for skew mitigation in spark computing environment\n", "abstract": " In the parallel computing framework of Hadoop / Spark, data skew is a common problem resulting in performance degradation. This paper proposes a key reassigning and splitting partition algorithm (SKRSP) to solve the partition skew from the source codes of Spark-core_2.11 project, which considers both the partition balance of the intermediate data and the partition balance after shuffle operators. First, we propose a step-based algorithm for sampling the input data to estimate the general key distribution of entire intermediate data. According to the types of the specific applications, we design two algorithms: hash based key reassigning algorithm (KRHP) and rang based key splitting algorithm (KSRP), which can generate appropriate strategy and implement them in shuffle phase. For the type of sort-based applications, KSRP generates the weighted bounds to split intermediate data, and for other applications\u00a0\u2026", "num_citations": "13\n", "authors": ["2184"]}
{"title": "Extreme learning machine and its applications in big data processing\n", "abstract": " The extreme learning machine (ELM) is widely used in batch learning, sequential learning, and incremental learning because of its fast and efficient learning speed, fast convergence, good generalization ability, and ease of implementation. With the development of the traditional ELM, lots of improved ELM algorithms have been proposed; meanwhile the scope of implementing the ELM has been further expanded from supervised learning, to semisupervised learning and unsupervised learning. However, due to its memory-residency, and high space and time complexity, the traditional ELM is not able to train big data fast and efficiently. Optimization strategies have been employed for the traditional ELM to solve this problem. In this chapter, we will first review ELM theories and some important variants, and then describe parallel ELM algorithms based on MapReduce and Spark in detail. Lastly, we show some\u00a0\u2026", "num_citations": "13\n", "authors": ["2184"]}
{"title": "An improved generalization of mesh-connected computers with multiple buses\n", "abstract": " Mesh-connected computers (MCCs) are a class of important parallel architectures due to their simple and regular interconnections. However, their performances are restricted by their large diameters. Various augmenting mechanisms have been proposed to enhance the communication efficiency of MCCs. One major approach is to add nonconfigurable buses for improved broadcasting. A typical example is the mesh-connected computer with multiple buses (MMB). We propose a new class of generalized MMBs, the improved generalized MMBs (IMMBs). We compare IMMBs with MMBs and a class of previously proposed generalized MMBs (GMMBs). We show the power of IMMBs by considering semigroup and prefix computations. Specifically, as our main result we show that for any constant 0<;\u03b5<;1, one can construct an N \u00bd \u00d7N \u00bd  square IMMB using which semigroup and prefix computations on N operands can\u00a0\u2026", "num_citations": "13\n", "authors": ["2184"]}
{"title": "Barrel shifter-a close approximation to the completely connected network in supporting dynamic tree structured computations\n", "abstract": " High performance computing requires high quality load distribution of processes of a parallel application over processors in a parallel computer at runtime such that both maximum load and dilation are minimized. The performance of a simple randomized tree growing algorithm on the barrel shifter and the Illiac networks is studied in this paper. The algorithm spreads tree nodes by letting them to take random walks to neighboring processors. We develop recurrence relations that characterize expected loads on all processors. We find that the performance ratio of probabilistic dilation-1 tree embedding in the barrel shifter network with N processors (a network with node degree O(log N)) is very close to that in the completely connected network of the same size. However, the hypercube network, which also has node degree log N, does not have such a capability. As a matter of factor, even the Illiac network, which is a\u00a0\u2026", "num_citations": "13\n", "authors": ["2184"]}
{"title": "Maintenance of tree structured computations on parallel and distributed computer systems\n", "abstract": " High performance parallel and distributed computing requires high quality dynamic load distribution of processes of a parallel application over processors in a parallel or a distributed computer system at runtime such that the maximum load on a processor is minimized. A simple randomized load distribution algorithm for tree structured parallel computations is studied in this paper. We analyze the average-case performance of the dynamic and randomized tree node distribution algorithm using recurrence relations that characterize expected loads on processors. Closed form solutions to these recurrence relations are also derived. Our analytical as well as numerical data show that the load distribution algorithm performs very well.", "num_citations": "13\n", "authors": ["2184"]}
{"title": "Generalized First-Fit algorithms in two and three dimensions\n", "abstract": " We investigate the two and three dimensional bin packing problems, i.e., packing a list of rectangles (boxes) into unit square (cube) bins so that the number of bins used is a minimum. A simple on-line packing algorithm for the one dimensional bin packing problem, the First-Fit algorithm, is generalized to two and three dimensions. We first give an algorithm for the two dimensional case and show that its asymptotic worse case performance ratio is . The algorithm is then generalized to the three dimensional case and its performance ratio . The second algorithm takes a parameter and we prove that by choosing the parameter properly, it has an asymptotic worst case performance bound which can be made as close as desired to 1.72=2.89 and 1.73=4.913 respectively in two and three dimensions.", "num_citations": "13\n", "authors": ["2184"]}
{"title": "System delay optimization for mobile edge computing\n", "abstract": " Mobile edge computing (MEC) has emerged as an effective paradigm that delivers cloud services and functions to edge devices, with the objective to further enhance quality of service (QoS) of terminal users by offloading their computation-intensive tasks. In this article, a multi-user and multi-server MEC system is considered and each user can choose one MEC server to execute its computation task. We try to minimize the system delay (i.e., the maximum server delay). The problem is decomposed into task offloading problem and transmit power allocation problem which are solved by matching theory and a heuristic idea, respectively. The experimental results show that the proposed algorithm can not only obtain less delay, but also generate less energy consumption compared with the decomposed computation offloading and resource allocation algorithm, the shortest distance based scheduling algorithm and the\u00a0\u2026", "num_citations": "12\n", "authors": ["2184"]}
{"title": "Features-enhanced multi-attribute estimation with convolutional tensor correlation fusion network\n", "abstract": " To achieve robust facial attribute estimation, a hierarchical prediction system referred to as tensor correlation fusion network (TCFN) is proposed for attribute estimation. The system includes feature extraction, correlation excavation among facial attribute features, score fusion, and multi-attribute prediction. Subnetworks (Age-Net, Gender-Net, Race-Net, and Smile-Net) are used to extract corresponding features while Main-Net extracts features not only from an input image but also from corresponding pooling layers of subnetworks. Dynamic tensor canonical correlation analysis (DTCCA) is proposed to explore the correlation of different targets\u2019 features in the F7 layers. Then, for binary classifications of gender, race, and smile, corresponding robust decisions are achieved by fusing the results of subnetworks with those of TCFN while for age prediction, facial image into one of age groups, and then ELM regressor\u00a0\u2026", "num_citations": "12\n", "authors": ["2184"]}
{"title": "M-Skyline: Taking sunk cost and alternative recommendation in consideration for skyline query on uncertain data\n", "abstract": " Traditional probabilistic skyline query over uncertain data returns a tuple of individual recommendations for customers. However, the uncertainty of the dataset brings the possibility that the recommendation is not correct. Once the incorrect candidate is recommended, user needs to query the skyline again (may use a higher probability threshold) and tries to find alternatives. This greatly hurts user experience for those recommendation scenarios where finding out query results to be wrong brings non-negligible sunk cost, such as spending time to visit a recommended interest point. To address this concern, we propose a novel M-Skyline query model that takes consideration of sunk cost and offers backup recommendation. Moreover, in order to optimize the query speed for finding such M-Skyline results, we devise several fast query algorithms. Extensive experiments with both real and synthetic datasets demonstrate\u00a0\u2026", "num_citations": "12\n", "authors": ["2184"]}
{"title": "Region-based compressive networked storage with lazy encoding\n", "abstract": " Existing work on distributed networked storage, although extensive, has generally focused on the recovery of global data field covering the entire network. This, while demanded by a broad range of applications, has ignored cases where only a subset of the data are needed, for example, from a local region of the network. Based on this observation and the fact that the sensor readings are correlated, this paper proposes a compressive networked storage solution. Specifically, by employing the compressive sensing (CS) theory, we present a lazy-encoding algorithm with local dissemination and a region-based reconstruction algorithm. Utilizing our local dissemination strategy, sensor readings only have to be disseminated and stored in their respective regions, which makes the dissemination cost decrease significantly. With the lazy-encoding algorithm, the readings in specified local regions are capable of being\u00a0\u2026", "num_citations": "12\n", "authors": ["2184"]}
{"title": "Inferring approximated models for systems engineering\n", "abstract": " Engineering safe and reliable systems demands rigorous approaches such as formal methods, using models. Since models are not always available, one needs to infer them from software artifacts. This paper defines a new inference approach for input-output systems that is based on FSM-based testing theory. Central to the approach is the notion of initial quotient of an FSM associated with a partial characterization set that controls the precision of this approximated model. The proposed method infers a model of a system under test by building increasingly precise quotients of it using counterexamples. Various experiments demonstrate its practical usability.", "num_citations": "12\n", "authors": ["2184"]}
{"title": "Towards security vulnerability detection by source code model checking\n", "abstract": " Security in code level is an important aspect to achieve high quality software. Various security programming guidelines are defined to improve the quality of software code. At the same time, enforcing mechanisms of these guidelines are needed. In this paper, we use source code model checking technique to check whether some security programming guidelines are followed, and correspondingly to detect related security vulnerabilities. Two SAP security programming guidelines related to logging sensitive information and Cross-Site Scripting attack are used as examples. In the case studies, Bandera Tool Set is used as source code model checker, and minimizing programmers' additional effort is set as one of the goals.", "num_citations": "12\n", "authors": ["2184"]}
{"title": "Performance evaluation of probabilistic tree embedding in cube-connected cycles\n", "abstract": " A simple randomized tree growing algorithm on cube-connected cycles networks is studied in this paper. The algorithm spreads tree nodes by letting them to take random walks to processors nearby. We develop recurrence relations that characterize expected load on each processor. These recurrence relations make it feasible to analyze the average-case performance of the dynamic and randomized tree embedding algorithm. Our main result is that cube-connected cycles with even dimensions have the same asymptotic performance as that of hypercubes in supporting tree-structured computations, while the performance of cube-connected cycles with odd dimensions are superior to that of hypercubes.", "num_citations": "12\n", "authors": ["2184"]}
{"title": "An efficiency-boosting client selection scheme for federated learning with fairness guarantee\n", "abstract": " The issue of potential privacy leakage during centralized AI\u2019s model training has drawn intensive concern from the public. A Parallel and Distributed Computing (or PDC) scheme, termed Federated Learning (FL), has emerged as a new paradigm to cope with the privacy issue by allowing clients to perform model training locally, without the necessity to upload their personal sensitive data. In FL, the number of clients could be sufficiently large, but the bandwidth available for model distribution and re-upload is quite limited, making it sensible to only involve part of the volunteers to participate in the training process. The client selection policy is critical to an FL process in terms of training efficiency, the final model\u2019s quality as well as fairness. In this article, we will model the fairness guaranteed client selection as a Lyapunov optimization problem and then a   -based method is proposed for estimation of the model\u00a0\u2026", "num_citations": "11\n", "authors": ["2184"]}
{"title": "A cache-aware social-based QoS routing scheme in Information Centric Networks\n", "abstract": " Due to the rapid expansion of Internet and the huge proliferation of users, Internet has evolved from a host-centric model to a content-oriented model. This implies the in-adaptation of current TCP/IP architecture providing the best performance to end-users and the urgency of researching future Internet architecture. In future Internet, the named data rather than traditional IP address may become the thin waist of the hourglass model of networking. Therefore, in this paper, we propose a cache-aware social-based Quality of Service (QoS) routing scheme for Named Data Networking (NDN) in Information Centric Network (ICN). Three kinds of social relationships, namely neighbors (NB), interest friends (IF) and response friends (RF) are devised to describe the relationships among nodes. Thus, when there is a failure in doing Pending Interest Table (PIT) scheme, a forwarding scheme based on social relationships is done\u00a0\u2026", "num_citations": "11\n", "authors": ["2184"]}
{"title": "Implementing molecular dynamics simulation on the Sunway TaihuLight system with heterogeneous many\u2010core processors\n", "abstract": " In various research of atom and molecule physical movements, molecular dynamics (MD) simulation is a common tool to simulate and investigate the real molecular motion. However, it introduces a significant penalty in performance, power, electricity, and running time. Consequently, once the simulation size scales up and computing demands keep growing, it comes at substantial costs in performance and energy usage. In this paper, an optimized MD implementation on the Sunway TaihuLight supercomputer with heterogeneous many\u2010core processors is developed to address the abovementioned issues. The Sunway TaihuLight is a totally independently designed and developed Chinese supercomputer with a profusely customized integration approach and a brand new many\u2010core processor, the SW26010. The computing power mainly supported by the homegrown many\u2010core SW26010 processors differs from\u00a0\u2026", "num_citations": "11\n", "authors": ["2184"]}
{"title": "Implementation and optimization of AES algorithm on the sunway taihulight\n", "abstract": " With the rapid development of information technology, the security of massive amounts of digital data has attracted huge attention in recent years. In this paper, we provide an efficient parallel implementation of the Advanced Encryption Standard (AES) algorithm, a widely used symmetrical block encryption algorithm, based on the Sunway TaihuLight. The Sunway TaihuLight is a China's independently developed heterogeneous supercomputer with peak performance over 100 PFlops. We also optimize the parallel implementation of the AES algorithm based on the Sunway TaihuLight to achieve more optimized performance. The optimization of the parallel AES algorithm in a single SW26010 node is provided. Specifically, we expand the scale to 1024 nodes and achieve the throughput of about 63.91 GB/s (511.28 Gbits/s). Our parallel implementation of the AES algorithm has great parallel scalability and the\u00a0\u2026", "num_citations": "11\n", "authors": ["2184"]}
{"title": "Enforcing security in smart homes using security patterns\n", "abstract": " Providing context-dependent security services is an important challenge in ambient intelligence. The complexity and the unbounded nature of such systems make it difficult for software developers to integrate security solutions. In order to solve this problem, in this paper we discuss and address multifold security challenges involved in the implementation of remote healthcare in smart homes using the security patterns approach. First the security challenges are derived from a real-world, industrially relevant scenario. Then it is shown how validated security techniques and mechanisms providing certain security properties can be captured and implemented in security patterns. Next security patterns are applied to satisfy security requirements in the smart home healthcare scenario. The process is exemplified thanks to a running prototype implementing the scenario.", "num_citations": "11\n", "authors": ["2184"]}
{"title": "Brain Medical Image Fusion Using L2-Norm-Based Features and Fuzzy-Weighted Measurements in 2-D Littlewood\u2013Paley EWT Domain\n", "abstract": " Computational imaging provides comprehensive and reliable information about human tissue for medical diagnosis and treatment, with medical image fusion as one of the most important technologies in the field. Empirical mode decomposition (EMD), a promising model for image processing, has been used for image fusion in some methods. However, the varying number of decomposed layers leads to problems using EMD for image fusion. In this article, we propose a fusion method for medical images incorporating    -norm-based features, a match/salience/fuzzy-weighted measure, and the 2-D Littlewood\u2013Paley empirical wavelet transform (2-D LPEWT) as new version of EMD. We first decompose medical images with LPEWT to obtain the residual component (residue) and detailed sub-images that are named as intrinsic mode functions (IMFs). Then we extract the regional features of residue with an    -norm\u00a0\u2026", "num_citations": "10\n", "authors": ["2184"]}
{"title": "A game-based price bidding algorithm for multi-attribute cloud resource provision\n", "abstract": " The pricing mechanism of cloud-computing resources is an essential issue for both cloud customers and providers, especially in the view point of multi-provider competition. Although various mechanisms for resource provision are proposed, few studies have focused on multi-attribute resource provision with the objective of improving benefits of both cloud customers and providers. To address the issue, we propose a price bidding mechanism for multi-attribute cloud-computing resource provision from the perspective of a non-cooperative game. Considering the fairness pricing competition, we propose a novel and incentive resource provision model referring to the Quality-of-Service (QoS) and the bidding price. Then, combining with the resource provision model, the problem of price bidding is formulated as a game to find a proper price for each cloud provider. We demonstrate the existence of Nash equilibrium\u00a0\u2026", "num_citations": "10\n", "authors": ["2184"]}
{"title": "A secure routing scheme for underwater acoustic networks\n", "abstract": " Secure and anonymous routing is required in many underwater acoustic network applications such as marine military. However, the characteristics of underwater acoustic networks cause existing secure scheme designed for traditional terrestrial networks to be inapplicable. This article presents a secure routing design for underwater acoustic networks. First, considering the difficulty of setting a trusted third party in underwater acoustic networks, a short signature algorithm without any online trusted third party is proposed and is used in the procedure of route setup for authentication between source and destination node pair. Analysis shows that the proposed signature scheme can resist forgery attacks effectively and improve communication security and signature efficiency. Second, a trap-door scheme in routing messages based on bilinear map is presented, which achieves anonymity of communication nodes to\u00a0\u2026", "num_citations": "10\n", "authors": ["2184"]}
{"title": "Clustering in big data\n", "abstract": " The need to understand large, complex, information-rich data sets is common to all fields of studies in this current information age. Given this tremendous amount of data, efficient and effective tools need to be present to analyze and reveal valuable knowledge that is hidden within the data. Clustering analysis is one of the popular approaches in data mining and has been widely used in big data analysis. The goal of clustering involves the task of dividing data points into homogeneous groups such that the data points in the same group are as similar as possible and data points in different groups are as dissimilar as possible. The importance of clustering is documented in pattern recognition, machine learning, image analysis, information retrieval, etc.", "num_citations": "10\n", "authors": ["2184"]}
{"title": "Self\u2010adaptation and mutual adaptation for distributed scheduling in benevolent clouds\n", "abstract": " Joint service involving several clouds is an emerging form of cloud computing. In hybrid clouds, the schedulers within 1 cloud must not only self\u2010adapt to the job arrival processes and the workload but also mutually adapt to the scheduling polices of other schedulers. However, as a combinatorial optimization problem, scheduling is challenged by the adaptation to those dynamics and uncertain behaviors of the peers. This article studies the collaboration among benevolent clouds that are cooperative in nature and willing to accept jobs from other clouds. We take advantage of machine learning and propose a distributed scheduling mechanism to learn the knowledge of job model, resource performance, and others' policies. Without explicit modeling and prediction, machine learning guides scheduling decisions based on experiences. To examine the performance of our approach, we conducted simulation using the\u00a0\u2026", "num_citations": "10\n", "authors": ["2184"]}
{"title": "Practical parallel AES algorithms on cloud for massive users and their performance evaluation\n", "abstract": " Many e\u2010business or social network servers have been constructed on cloud. On such open environments, private data of massive users have to be protected by encrypting, such as using Advanced Encryption Standard (AES), and furthermore, this process must be finished in a short time for users' better experience. This gives huge pressure on cloud servers, especially common servers, such as web servers. We urgently need an inexpensive and highly efficient method to relieve cloud servers' pressure. Fortunately, many cores of a graphics processing unit (GPU) can undertake this hard mission because of stronger computing power and lower price. The GPU environments can be virtualized on demand by cloud through the vCUDA technology. Of course, for those clouds not equipped with a GPU, a central processing unit (CPU) can still work as multithreads in parallel. Thus, in a cloud, AES can be parallelized\u00a0\u2026", "num_citations": "10\n", "authors": ["2184"]}
{"title": "S&D pattern deployment at organizational level: A prototype for remote healthcare system\n", "abstract": " The analysis of security incidents and frauds has shown that several vulnerabilities of IT systems are due to loopholes in the policies and procedures adopted by organizations as well as in their structure. Organizations have thus to address security and dependability issues by analyzing their organizational setting. In this paper, we present a methodology to support the deployment of Security & Dependability patterns according to their position in the Enterprise Architecture and the underlying system infrastructures. The methodology discriminates the pattern deployment process between recommendations and guidelines. Recommendations concretize the deployment with refined software and/or hardware related patterns, whereas guidelines specify the organizational patterns in terms of the system-to-be, proposing human-resource and/or policy solutions. To make the discussion more concrete, we illustrate the\u00a0\u2026", "num_citations": "10\n", "authors": ["2184"]}
{"title": "Distributed task migration optimization in MEC by extending multi-agent deep reinforcement learning approach\n", "abstract": " Closer to mobile users geographically, mobile edge computing (MEC) can provide some cloud-like capabilities to users more efficiently. This enables it possible for resource-limited mobile users to offload their computation-intensive and latency-sensitive tasks to MEC nodes. For its great benefits, MEC has drawn wide attention and extensive works have been done. However, few of them address task migration problem caused by distributed user mobility, which can\u2019t be ignored with quality of service (QoS) consideration. In this article, we study task migration problem and try to minimize the average completion time of tasks under migration energy budget. There are multiple independent users and the movement of each mobile user is memoryless with a sequential decision-making process, thus reinforcement learning algorithm based on Markov chain model is applied with low computation complexity. To further\u00a0\u2026", "num_citations": "9\n", "authors": ["2184"]}
{"title": "Deep end-to-end learning for price prediction of second-hand items\n", "abstract": " Recent years have witnessed the rapid development of online shopping and ecommerce websites, e.g., eBay and OLX. Online shopping markets offer millions of products for sale each day. These products are categorized into many product categories. It is crucial for sellers to correctly estimate the price of the second-hand item. State-of-the-art methods can predict the price of only one item category. In addition, none of the existing methods utilized the price range of a given second-hand item in the prediction task, as there are several advertisements for the same product at different prices. In this vein, as the first contribution, we propose a deep model architecture for predicting the price of a second-hand item based on the image and textual description of the item for different sets of item types. This proposed method utilizes a deep neural network involving long short-term memory (LSTM) and convolutional\u00a0\u2026", "num_citations": "9\n", "authors": ["2184"]}
{"title": "Multi-task allocation with an optimized quantum particle swarm method\n", "abstract": " Multi-task allocation in multi-agent systems aims to accomplish tasks efficiently and successfully, while obtaining more rewards to enhance the entire system operation at the same time. Most existing assignment methods are based on agent coalitions, which cannot balance the profit distribution and task execution success rate or ignore the coalition stability, leading to a low execution level and assignment failures. Few coalition scheduling methods exist for multi-task allocation based on a fixed agent population. In this paper, we propose an effective stability quantum particle swarm optimization (SQPSO) algorithm which includes high rewards obtaining, benefit dividing, coalition stability insuring, and a historical task mechanism for search acceleration. Secondly, we design an efficient establishment quantum particle swarm optimization (EQPSO) algorithm for coalition scheduling, which is equipped with coalition\u00a0\u2026", "num_citations": "9\n", "authors": ["2184"]}
{"title": "Distributed conditional gradient online learning for IoT optimization\n", "abstract": " Many problems in Internet of Things (IoT) can be cast as distributed optimization problems. For this reason, this paper considers a distributed online constrained optimization problem in IoT, where the local objective functions change with time. In order to solve this problem, distributed projected gradient descent methods are employed frequently. However, the computation of the projection operators is prohibitive in high-dimensional constrained optimization problem. To address the issue, we propose a distributed online learning algorithm based on the conditional gradient method over IoT systems, which avoids the costly projection steps. Moreover, when the local objective functions are strongly convex, we show that the regret bound of O(T) is achieved, where T is a time horizon. When the local objective functions are potentially non-convex, we also show that the algorithm converges to some stationary points at rate\u00a0\u2026", "num_citations": "9\n", "authors": ["2184"]}
{"title": "How to stabilize a competitive mobile edge computing environment: A game theoretic approach\n", "abstract": " There are two fundamental purposes in mobile edge computing, i.e., performance enhancement and cost reduction. By offloading computation tasks to a mobile edge cloud (MEC), a user equipment (UE), also called mobile user, mobile subscriber, or mobile device, can possibly reduce its average response time, which is the main performance measure, and can possibly reduce its average power consumption. Optimizing both performance and cost may be conflicting requirements. In this paper, we optimize the cost-performance ratio (CPR), i.e., the power-time product, which combines performance (average response time) and cost (average power consumption) into one quantity. A unique feature in mobile edge computing is the competitiveness of mobile users, who are selfish in competing for resources in a mobile edge cloud. We take a game theoretic approach to the stabilization of a competitive mobile edge\u00a0\u2026", "num_citations": "9\n", "authors": ["2184"]}
{"title": "Dynamic data allocation and task scheduling on multiprocessor systems with NVM-based SPM\n", "abstract": " Low-power and short-latency memory access is critical to the performance of chip multiprocessor (CMP) system devices, especially to bridge the performance gap between memory and CPU. Together with increased demand for low-energy consumption and high-speed memory, scratch-pad memory (SPM) has been widely adopted in multiprocessor systems. In this paper, we employ a hybrid SPM, composed of a static random-access memory and a nonvolatile memory (NVM), to replace the cache in CMP. However, there are several challenges related to the CMP that need to be addressed, including how to dynamically assign processors to application tasks and dynamically allocate data to memories. To solve these problems based on this architecture, we propose a novel dynamic data allocation and task scheduling algorithm, i.e., dynamic greedy data allocation and task scheduling (DGDATS). Experiments on\u00a0\u2026", "num_citations": "9\n", "authors": ["2184"]}
{"title": "Parallel and progressive approaches for skyline query over probabilistic incomplete database\n", "abstract": " The advanced productivity of the modern society has created a wide range of similar commodities. However, the descriptions of commodities are always incomplete. Therefore, it is difficult for consumers to make choices. In the face of this problem, skyline query is a useful tool. However, the existing algorithms are unable to address incomplete probabilistic databases. In addition, it is necessary to wait for query completion to obtain even partial results. Furthermore, traditional skyline algorithms are usually serial. Thus, they cannot utilize multi-core processors effectively. Therefore, a parallel progressive skyline query algorithm for incomplete databases is imperative, which provides answers gradually and much faster. To address these problems, we design a new algorithm that uses multi-level grouping, pruning strategies, and pruning tuple transferring, which significantly decreases the computational costs\u00a0\u2026", "num_citations": "9\n", "authors": ["2184"]}
{"title": "DemePro: DEcouple packet Marking from Enqueuing for multiple services with PROactive congestion control\n", "abstract": " Most of current Data Center Network (DCN) protocols leverage Explicit Congestion Notification (ECN) for congestion control to maintain low latency and high throughput. However, the majority of them only consider single-queue scenario in each switch port, making their performance inferior in multiple-service multiple-queue scenario. To this end, we propose DemePro, a DCN scheme for multiple-service multiple-queue scenario. In face of congestion signal, DemePro also leverages ECN for congestion notification, while decouples packet marking from enqueuing, in order to ensure fairness among multiple services. We also question the effectiveness of the congestion signal derived from the single threshold for port buffer queue length, via a set of experiments. Then, DemePro utilizes multiple thresholds for proactive congestion control, and packets are encapsulated to carry congestion extent information, in order to\u00a0\u2026", "num_citations": "9\n", "authors": ["2184"]}
{"title": "Probabilistic top-k range query processing for uncertain databases\n", "abstract": " Query processing over uncertain data is very important in many applications due to the existence of uncertainty in real-world data. In this paper, we propose a novel and important query for uncertain data, namely probabilistic top-(k, l) range (PTR) query, which retrieves l uncertain tuples that are expected to meet score range constraint [s 1, s 2] and have the maximum top-k probabilities but no less than a given probability threshold q. In order to accelerate the PTR query, we present some effective pruning techniques to reduce the search space of PTR query, which are integrated seamlessly into an efficient PTR query procedure. Extensive experiments over both real-world and synthetic datasets verify the efficiency and effectiveness of our proposed approaches.", "num_citations": "9\n", "authors": ["2184"]}
{"title": "MobiContext: A context-aware cloud-based venue recommendation framework\n", "abstract": " In recent years, recommendation systems have seen significant evolution in the field of knowledge engineering. Most of the existing recommendation systems based their models on collaborative filtering approaches that make them simple to implement. However, performance of most of the existing collaborative filtering-based recommendation system suffers due to the challenges, such as: (a) cold start, (b) data sparseness, and (c) scalability. Moreover, recommendation problem is often characterized by the presence of many conflicting objectives or decision variables, such as users' preferences and venue closeness. In this paper, we proposed MobiContext, a hybrid cloud-based bi-objective recommendation framework (BORF) for mobile social networks. The MobiContext utilizes multi-objective optimization techniques to generate personalized recommendations. To address the issues pertaining to cold start and\u00a0\u2026", "num_citations": "9\n", "authors": ["2184"]}
{"title": "An efficient energy scheduling algorithm for workflow tasks in hybrids and DVFS-enabled cloud environment\n", "abstract": " The explosive growth of energy consumption in cloud centers has become a critical issue, for going against the advocated green computing, many works focus the tasks scheduling for reducing energy dissipation. In order to obtain more energy reduction as well as maintaining the quality of service by meeting the deadlines, this paper proposes a DVFS-enabled efficient energy workflow task scheduling algorithm: DEWTS. Through merging the relatively inefficient processors byreclaiming the slack time, DEWTS can take advantage of the useful slack time once again employing DVFS technique after severs merged. Based on amount of randomly generated DAGs workflows, the experimental results show that DEWTS can reduce the total power consumption with various parallel applications as well as balancing the scheduling performance.", "num_citations": "9\n", "authors": ["2184"]}
{"title": "Design and analysis of heuristic algorithms for power-aware scheduling of precedence constrained tasks\n", "abstract": " Energy-efficient scheduling of sequential tasks with precedence constraints on multiprocessor computers with dynamically variable voltage and speed is investigated as combinatorial optimization problems. In particular, the problem of minimizing schedule length with energy consumption constraint and the problem of minimizing energy consumption with schedule length constraint are considered. Our scheduling problems contain three nontrivial sub problems, namely, precedence constraining, task scheduling, and power supplying. Each sub problem should be solved efficiently so that heuristic algorithms with overall good performance can be developed. Such decomposition of our optimization problems into three sub problems makes design and analysis of heuristic algorithms tractable. Three types of heuristic power allocation and scheduling algorithms are proposed for precedence constrained sequential tasks\u00a0\u2026", "num_citations": "9\n", "authors": ["2184"]}
{"title": "Scheduling parallel tasks on multiprocessor computers with efficient power management\n", "abstract": " In this paper, scheduling parallel tasks on multiprocessor computers with dynamically variable voltage and speed is addressed as combinatorial optimization problems. Our scheduling problems are defined such that the energy-delay product is optimized by fixing one factor and minimizing the other. It is noticed that power-aware scheduling of parallel tasks has rarely been discussed before. Our investigation in this paper makes some initial attempt to energy efficient scheduling of parallel tasks on multiprocessor computers with dynamic voltage and speed. Our scheduling problems contain three nontrivial subproblems, namely, system partitioning, task scheduling, and power supplying. The harmonic system partitioning and processor allocation scheme is used, which divides a multiprocessor computer into clusters of equal sizes and schedules tasks of similar sizes together to increase processor utilization. A three\u00a0\u2026", "num_citations": "9\n", "authors": ["2184"]}
{"title": "Managing overloaded hosts for energy-efficiency in cloud data centers\n", "abstract": " Traditional data centers are shifted toward the cloud computing paradigm. These data centers support the increasing demand for computational and data storage that consumes a massive amount of energy at a huge cost to the cloud service provider and the environment. Considerable energy is wasted to constantly operate idle virtual machines (VMs) on hosts during periods of low load. Dynamic consolidation of VMs from overloaded or underloaded hosts is an effective strategy for improving energy consumption and resource utilization in cloud data centers. The dynamic consolidation of VM from an overloaded host directly influences the service level agreements (SLAs), utilization of resources, and quality of service (QoS) delivered by the system. We proposed an algorithm, namely, GradCent, based on the Stochastic Gradient Descent technique. This algorithm is used to develop an upper CPU utilization\u00a0\u2026", "num_citations": "8\n", "authors": ["2184"]}
{"title": "Multiple local 3D CNNs for region-based prediction in smart cities\n", "abstract": " In smart cities, region-based prediction (e.g. traffic flow and electricity flow) is of great importance to city management and public safety, and it remains a daunting challenge that involves complicated spatial-temporal-related factors such as weather, holidays, events, etc. Region-based forecasting aims to predict the future situation for regions in a city based on historical data. In the existing literature, the state-of-the-art method solve region-based problems with long short-term memory (LSTM) algorithms that extract the temporal view and local convolutional neural network (CNN) algorithms that extract the spatial view (local spatial correlation via local CNN). In this paper, we propose a deep learning-based method for region-based prediction for smart cities. First, we divide the cities into regions based on the space dimension and model the situation of the cities in 3D volumes. Based on the constructed 3D volumes, we\u00a0\u2026", "num_citations": "8\n", "authors": ["2184"]}
{"title": "A two-stage attention aware method for train bearing shed oil inspection based on convolutional neural networks\n", "abstract": " As an important component of trains, rolling bearing is always faced with the defection of shed oil, which inevitably threatens the train safety. Therefore, it is of great significance to conduct defection inspection on bearing shed oil. Due to the complex structure of rolling bearings, traditional signal analysis approaches cannot detect the defections of bearing shed oil with high-efficiency and low cost. In recent years, deep learning has achieved remarkable growth and been successfully applied to various computer-vision tasks. Motivated by this fact, we propose a two-stage attention aware method to recognize defections of bearing shed oil. The proposed method is based on convolutional neural networks, can automatically learn bearing defect features, and does not need manual feature design and extraction like traditional methods. The two-stage method cascades a bearing localization stage and a defection\u00a0\u2026", "num_citations": "8\n", "authors": ["2184"]}
{"title": "Implementation and optimization of a data protecting model on the Sunway TaihuLight supercomputer with heterogeneous many\u2010core processors\n", "abstract": " With the rapid development of information technology, the security of massive amounts of digital data has attracted huge attention in recent years. The Advanced Encryption Standard (AES) algorithm and the Security Hash Algorithm 3 (SHA3) are extensively used as cryptographic algorithms for protecting the security of information. The Sunway TaihuLight, with massive heterogeneous many\u2010core SW26010 processors, has the peak performance of over 100 PFlops. To achieve high efficiency of data encryption/decryption and guarantee the data integrity for large\u2010scale applications, this paper proposes a fast and secure data protecting model using the parallel AES algorithm and the SHA3 on the Sunway TaihuLight. According to the particular computing architecture and memory hierarchy of the Sunway TaihuLight, we propose a fine\u2010grained software design for the data protecting model to fully exploit the\u00a0\u2026", "num_citations": "8\n", "authors": ["2184"]}
{"title": "Wireless sensor network MCDS construction algorithms with energy consideration for extreme environments healthcare\n", "abstract": " With the enhancement of people's health awareness, more and more users are willing to wear portable micro-health monitoring equipment and communicate with remote medicine center for real-time diagnosis. Although, under normal circumstances, users' health status can be detected at any time, in extreme circumstances, such as earthquakes, how to make the medical center monitor user data for a long time for rescue will be of great significance. In this paper, we will study the networking of portable wearable devices based on wireless sensor networks. We mainly use minimal connected dominating sets (MCDSs) to organize nodes in extreme environments effectively, form virtual backbone networks, send data to the rescue or medical personnel, and maximize network lifetime. Specifically, we propose an adverse dominator selection procedure (ADSP), where the dominators are selected by their children-independent\u00a0\u2026", "num_citations": "8\n", "authors": ["2184"]}
{"title": "An experience-based scheme for energy-SLA balance in cloud data centers\n", "abstract": " The proliferation of cloud computing has resulted in the establishment of large-scale data centers containing thousands of computing nodes and consuming enormous amounts of electrical energy. However, the low-cost and high-efficiency slogans are getting louder and louder, and the IT industry is also striving for this pursuit. Therefore, it is vital to minimizing the energy consumption for cloud providers while ensuring the quality of service for cloud users. In this paper, we propose several heuristic strategies to optimize these two metrics based on a two-level management model under a heterogeneous cloud environment. First, to detect whether a physical node is continuously overloaded, we propose an empirical forecast algorithm, which predicts the future state of the host by statistically analyzing the historical utilization data of the host. Second, we propose a weighted priority virtual machine (VM) selection\u00a0\u2026", "num_citations": "8\n", "authors": ["2184"]}
{"title": "Optimal task execution speed setting and lower bound for delay and energy minimization\n", "abstract": " The current technology trend reveals that static power consumption is growing at a faster rate than dynamic power consumption. In this paper, energy-efficient task scheduling is studied when static power consumption is a significant part of energy consumption which cannot be ignored. The problems of scheduling a set of independent sequential tasks on identical processors so that the schedule length is minimized for a given energy consumption constraint or the energy consumption is minimized for a given schedule length constraint are investigated. For a given schedule, the optimal task execution speed setting for delay and energy minimization is found analytically. Lower bounds for the minimum schedule length of a set of tasks with a given energy consumption constraint and the minimum energy consumption of a set of tasks with a given schedule length constraint are established. Our lower bounds are\u00a0\u2026", "num_citations": "8\n", "authors": ["2184"]}
{"title": "Accelerating packet classification with counting bloom filters for virtual openflow switching\n", "abstract": " The growing trend of network virtualization results in a widespread adoption of virtual switches in virtualized environments. However, virtual switching is confronted with great performance challenges regarding packet classification especially in OpenFlow-based software defined networks. This paper first takes an insight into packet classification in virtual OpenFlow switching, and points out that its performance bottleneck is dominated by flow table traversals of multiple failed mask probing for each arrived packet. Then we are motivated to propose an efficient packet classification algorithm based on counting bloom filters. In particular, counting bloom filters are applied to predict the failures of flow table lookups with great possibilities, and bypass flow table traversals for failed mask probing. Finally, our proposed packet classification algorithm is evaluated with real network traffic traces by experiments. The experimental\u00a0\u2026", "num_citations": "8\n", "authors": ["2184"]}
{"title": "Adaptive region adjustment to improve the balance of convergence and diversity in MOEA/D\n", "abstract": " The multiobjective evolutionary algorithm based on decomposition (MOEA/D), which decomposes a multiobjective optimization problem (MOP) into a number of optimization subproblems and optimizes them in a collaborative manner, becomes more and more popular in the field of evolutionary multiobjective optimization. The mechanism of balance convergence and diversity is very important in MOEA/D. In the process of optimization, the chosen solutions must be distinctive and as close as possible to the Pareto front. In this paper, we first explore the relation between subproblems and solutions. Then we propose the adaptive region adjustment strategy to balance the convergence and diversity based on the objective region partition concept. Finally, this strategy is embedded in the MOEA/D framework and then a simple but efficient algorithm is proposed. To demonstrate the effectiveness of the proposed algorithm\u00a0\u2026", "num_citations": "8\n", "authors": ["2184"]}
{"title": "UHCL-Darknet: an OpenCL-based deep neural network framework for heterogeneous multi-/many-core clusters\n", "abstract": " As the majority of popular deep neural network (DNN) frameworks focus on a closed format CUDA implementations based on one or more NVIDIA GPUs, they cannot efficiently leverage other devices in cluster mode to accelerate the training and inference of DNNs except NVIDIA GPUs. To accelerate DNNs using heterogeneous multi-/many-core clusters, we propose an OpenCL-based DNN framework called UHCL-Darknet. First, we design a unified OpenCL platform model for the heterogeneous cluster called UHCL, and an adaptive runtime system with the affinity-based dynamic scheduler for UHCL, enabling transparent utilization of a wide variety of vendor-specific OpenCL devices in the heterogeneous cluster. Then, we extend Darknet to UHCL by introducing the parallel optimization of DNNs, such as paralleling Winogrand-based convolutions and auto-tuning parameterized OpenCL kernels. The training and\u00a0\u2026", "num_citations": "8\n", "authors": ["2184"]}
{"title": "Unequal failure protection coding technique for distributed cloud storage systems\n", "abstract": " In recent years, erasure codes have become the de facto standard for data protection in large scale distributed cloud storage systems at the cost of an affordable storage overhead. However, traditional erasure coding schemes, such as Reed-Solomon codes, suffer from high reconstruction cost and I/Os. The recent past has seen a plethora of efforts to optimize the tradeoff between the reconstruction cost, I/Os and storage overhead. Quiet different from all prior studies, in this paper, our erasure coding technique makes the first attempt to take advantage of the unequal failure rates across the disks/nodes to optimize the system reliability and reconstruction performance. Specifically, our proposed technique, the Unequal Failure Protection based Local Reconstruction Code (UFP-LRC) divides the data blocks into several unequal-sized groups with local parities, assigning the data blocks stored on more failure-prone\u00a0\u2026", "num_citations": "8\n", "authors": ["2184"]}
{"title": "An efficient in-memory checkpoint method and its practice on fault-tolerant HPL\n", "abstract": " Fault tolerance is increasingly important in high-performance computing due to the substantial growth of system scale and decreasing system reliability. In-memory/diskless checkpoint has gained extensive attention as a solution to avoid the IO bottleneck of traditional disk-based checkpoint methods. However, applications using previous in-memory checkpoint suffer from little available memory space. To provide high reliability, previous in-memory checkpoint methods either need to keep two copies of checkpoints to tolerate failures while updating old checkpoints or trade performance for space by flushing in-memory checkpoints into disk. In this paper, we propose a novel in-memory checkpoint method, called self-checkpoint, which can not only achieve the same reliability of previous in-memory checkpoint methods, but also increase the available memory space for applications by almost 50 percent. To validate our\u00a0\u2026", "num_citations": "8\n", "authors": ["2184"]}
{"title": "A parallel conditional random fields model based on spark computing environment\n", "abstract": " As one of the famous probabilistic graph models in machine learning, the conditional random fields (CRFs) can merge different types of features, and encode known relationships between observations and construct consistent interpretations, which have been widely applied in many areas of the Natural Language Processing (NLP). With the high-speed development of the internet and information systems, some performance issues are certain to arise when the traditional CRFs deals with such massive data. This paper proposes SCRFs, which is a parallel optimization of CRFs based on the Resilient Distributed Datasets (RDD) in the Spark computing framework. SCRFs optimizes the traditional CRFs from these stages: First, with all features are generated in parallel, the intermediate data which will be used frequently are all cached into the memory to speed up the iteration efficiency. By removing the low\u00a0\u2026", "num_citations": "8\n", "authors": ["2184"]}
{"title": "Maxdenominator reweighted sparse representation for tumor classification\n", "abstract": " The classification of tumors is crucial for the proper treatment of cancer. Sparse representation-based classifier (SRC) exhibits good classification performance and has been successfully used to classify tumors using gene expression profile data. In this study, we propose a three-step maxdenominator reweighted sparse representation classification (MRSRC) method to classify tumors. First, we extract a set of metagenes from the training samples. These metagenes can capture the structures inherent to the data and are more effective for classification than the original gene expression data. Second, we use a reweighted regularization method to obtain the sparse representation coefficients. Reweighted regularization can enhance sparsity and obtain better sparse representation coefficients. Third, we classify the data by utilizing a maxdenominator residual error function. Maxdenominator strategy can reduce the\u00a0\u2026", "num_citations": "8\n", "authors": ["2184"]}
{"title": "Virtual resource allocation based on link interference in Cayley wireless data centers\n", "abstract": " Cayley data centers are well known patterns of completely wireless data centers (WDCs). However, low link reliability and link interference will affect the construction of virtual networks. This paper proposes a virtual resource mapping algorithm on the basis of Cayley structures. First, we analyze the characteristics of Cayley WDCs and model networks in WDCs, where a virtual network is modeled as a traditional undirected graph, while a physical topology is modeled as a directed graph. Second, we propose a virtual resource mapping and coloring algorithm based on link interference called VRMCA-LI. We build a connection interference matrix for each node and use a coloring method to avoid interference. VRMCA-LI uses the same color for the nodes that are within the transmitting angle of a sending node and whose signal-to-noise ratio is less than a threshold. These nodes with the same color cannot be allocated\u00a0\u2026", "num_citations": "8\n", "authors": ["2184"]}
{"title": "Probing high-capacity peers to reduce download times in P2P file sharing systems with stochastic service capacities\n", "abstract": " The main problem for an individual user peer in a peer-to-peer network with heterogeneous source peers is the peer selection problem, namely, switching among source peers and finally settling on one, while keeping the total time of probing and downloading to a minimum. There has been little investigation on selecting source peers with stochastic service capacities. The main contribution of this paper is to address the problem of reducing download times in peer-to-peer file sharing systems with stochastic service capacities. A precise analysis of the expected download time is given when the service capacity of a source peer is a random variable. A chunk-based switching and peer selection algorithm using the method of probing high-capacity peers is proposed and the expected download time of the algorithm is analyzed. Two subproblems of the optimal choice of the threshold of high-capacity source peers and\u00a0\u2026", "num_citations": "8\n", "authors": ["2184"]}
{"title": "A service-oriented architecture for emergency management systems\n", "abstract": " The complexity and openness of today's modern societies result in the threat of serious cascading effects when natural disasters or terrorist attacks strike. Thus, there is a high demand for state of the art IT support in the field of emergency management systems. In this paper, we identify the core requirements of future emergency management systems and present a new generation of modular, service-oriented and semantic-webbased architecture for emergency management systems. Our emergency management system offers innovative functionality in the context of distributed information sources, collaborative work environments, and consistent situation pictures.", "num_citations": "8\n", "authors": ["2184"]}
{"title": "Green task scheduling algorithms with energy reduction on heterogeneous computers\n", "abstract": " Two traditional heuristic task scheduling algorithms (STFCMEF-MS algorithm and LTFCMEF-MS algorithm) are developed to solve a multi-task scheduling problem on multiple computers to reduce energy consumption and finish required tasks before a deadline. Two new green task scheduling algorithms (STFCMEF-SA algorithm and LTFCMEF-SA algorithm) are proposed to solve the same problem. Since the energy is directly proportional to the number of instructions for each computer at a particular speed, the energy slope (a newly defined technical term) is a constant. Simulation results indicate that STFCMEF-SA algorithm and LTFCMEF-SA algorithm are more effective than STFCMEF-MS algorithm and LTFCMEF-MS algorithm in lowering energy consumption. Future work includes more theoretical analysis and more novel algorithms.", "num_citations": "8\n", "authors": ["2184"]}
{"title": "Scheduling Precedence Constrained Parallel Tasks on Multiprocessors Using the Harmonic System Partitioning Scheme.\n", "abstract": " We present an algorithm for scheduling precedence constrained parallel tasks on multiprocessors with noncontiguous processor allocation. The algorithm is called LLHm (Level-by-level and List scheduling using the Harmonic system partitioning scheme), where m\u2265 1 is a positive integer, which is a parameter for the harmonic system partitioning scheme. Three basic techniques are employed in algorithm LLHm. First, a task graph is divided into levels, and tasks are scheduled level by level to follow the precedence constraints. Second, tasks in the same level are scheduled using algorithm Hm developed in [16] for scheduling independent parallel tasks. The list scheduling method is used to implement algorithm Hm. Third, the harmonic system partitioning scheme is used for processor allocation. It is shown here that for wide task graphs and some common task size distributions, as the size of a computation and m increase, and as the task sizes become smaller, the average-case performance ratio of algorithm LLHm approaches one.", "num_citations": "8\n", "authors": ["2184"]}
{"title": "Broadcast on Clusters of SMPs with Optimal Concurrency.\n", "abstract": " Broadcast is an important collective communication for either users\u2019 programs or the underlying high-performance computing platforms. In this paper, we present a hierarchical method for broadcast over clusters of SMPs (CSMPs) connected by switches under the one-port model. A broadcast over CSMPs consists of three levels, one for a sub-broadcast in each SMP node, one for a sub-broadcast within each of switches called intra-switch broadcast, and one for a sub-broadcast among switches called interswitch broadcast. Regarding high-performance of switches, our concern focuses on interswitch broadcasts. The new inter-switch broadcast is based on Single-Source Shortest path Minimum-cost Spanning Tree (SSS-MST). In general, a broadcast over an SSSMST may not outperform due to sequential effects arisen from poor usage of bandwidth per link and nodes having receiving broadcasted messages under the one-port model. In our new algorithm, we obtain the optimal concurrency in each step of broadcasts such that as many messages as possible are forwarded simultaneously in each step of SSSMST with the optimal number of steps and minimum cost. The two heuristics, from-upto-down and from-down-to-up algorithms, are proposed to obtain this maximum concurrency using the static topological information and costs for links. Additionally, for regular programs a local update technique is applied to adapt to the dynamic changes in topology and available bandwidth per link over the underlying interconnects.", "num_citations": "8\n", "authors": ["2184"]}
{"title": "Execution cost minimization scheduling algorithms for deadline-constrained parallel applications on heterogeneous clouds\n", "abstract": " The problem of minimizing the execution monetary cost of applications on cloud computing platforms has been studied recently, and satisfying the deadline constraint of an application is one of the most important quality of service requirements. Previous method of minimizing the execution monetary cost of deadline-constrained applications was the \u201cupward\u201d approach (i.e., from exit to entry tasks) rather than combining the \u201cupward\u201d and \u201cdownward\u201d approaches. In this study, we propose monetary cost optimization algorithm (DCO/DUCO) by employing \u201cdownward\u201d and \u201cupward\u201d approaches together to solve the problem of execution cost minimization. \u201cDownward\u201d cost optimization is implemented by introducing the concept of the variable deadline-span and transferring the deadline of an application to each task. On the basis of DCO, the slack time is utilized to implement \u201cupward\u201d cost optimization without\u00a0\u2026", "num_citations": "7\n", "authors": ["2184"]}
{"title": "Enhancing tree-seed algorithm via feed-back mechanism for optimizing continuous problems\n", "abstract": " Tree-Seed Algorithm (TSA) is a novel population-based random search algorithm with its advantages in continuous optimization problems. However, there are some problems in its searching procedure. Problem (1): its balance mechanism of exploration and exploitation is implemented with a constant ST, and this fixed value is unreasonable in the random search procedure; Problem (2): the seed generation mechanism is achieved randomly without considering different searching phases based on function evaluations. To overcome these two problems, the feedback mechanism should be enhanced. Firstly, the st_TSA is proposed to solve the Problem (1); secondly, the ns_TSA is proposed to further solve the Problem (2); finally, in order to inherit these feedback mechanisms, a novel fb_TSA has been proposed and verified by standard 30 test benchmark functions from IEEE CEC 2014 with the basic TSA and its\u00a0\u2026", "num_citations": "7\n", "authors": ["2184"]}
{"title": "Attentive semantic and perceptual faces completion using self-attention generative adversarial networks\n", "abstract": " We propose an approach based on self-attention generative adversarial networks to accomplish the task of image completion where completed images become globally and locally consistent. Using self-attention GANs with contextual and other constraints, the generator can draw realistic images, where fine details are generated in the damaged region and coordinated with the whole image semantically. To train the consistent generator, i.e. image completion network, we employ global and local discriminators where the global discriminator is responsible for evaluating the consistency of the entire image, while the local discriminator assesses the local consistency by analyzing local areas containing completed regions only. Last but not least, attentive recurrent neural block is introduced to obtain the attention map about the missing part in the image, which will help the subsequent completion network to fill contents\u00a0\u2026", "num_citations": "7\n", "authors": ["2184"]}
{"title": "A fine-grained authorized keyword secure search scheme with efficient search permission update in cloud computing\n", "abstract": " With the rapid development of cloud computing, secure search has become a hot research spot, which is a promising technique that allows a data user to perform privacy-preserving keyword-based search over encrypted cloud data. In this paper, we further consider the secure search problem based on a practical application scenario that a data owner needs to grant different keyword query permissions for different data users to achieve flexible access control on outsourced encrypted data in the cloud computing environment. To address this problem, we propose a fine-grained authorized keyword secure search scheme by leveraging the ciphertext policy attribute-based encryption (ABE), which not only supports privacy-preserving keyword-based search over encrypted data, but also inherits flexible and fine-grained data privilege control properties of ABE. Moreover, our proposed scheme is able to achieve fine\u00a0\u2026", "num_citations": "7\n", "authors": ["2184"]}
{"title": "Gradient scheduling with global momentum for non-iid data distributed asynchronous training\n", "abstract": " Distributed asynchronous offline training has received widespread attention in recent years because of its high performance on large-scale data and complex models. As data are distributed from cloud-centric to edge nodes, a big challenge for distributed machine learning systems is how to handle native and natural non-independent and identically distributed (non-IID) data for training. Previous asynchronous training methods do not have a satisfying performance on non-IID data because it would result in that the training process fluctuates greatly which leads to an abnormal convergence. We propose a gradient scheduling algorithm with partly averaged gradients and global momentum (GSGM) for non-IID data distributed asynchronous training. Our key idea is to apply global momentum and local average to the biased gradient after scheduling, in order to make the training process steady. Experimental results show that for non-IID data training under the same experimental conditions, GSGM on popular optimization algorithms can achieve a 20% increase in training stability with a slight improvement in accuracy on Fashion-Mnist and CIFAR-10 datasets. Meanwhile, when expanding distributed scale on CIFAR-100 dataset that results in sparse data distribution, GSGM can perform a 37% improvement on training stability. Moreover, only GSGM can converge well when the number of computing nodes grows to 30, compared to the state-of-the-art distributed asynchronous algorithms. At the same time, GSGM is robust to different degrees of non-IID data.", "num_citations": "7\n", "authors": ["2184"]}
{"title": "JDAS: a software development framework for multidatabases\n", "abstract": " Modern software development for services computing and cloud computing software systems is no longer based on a single database but on existing multidatabases and this convergence needs new software architecture and framework design. Most current popular frameworks are not designed for multidatabases, and many practical problems in development arise. This study designs and implements a software development framework called Java data access service (JDAS) for multidatabases using the object\u2010oriented programming language Java. The JDAS framework solves related problems that arise when other frameworks are employed in practical software development with multidatabases by presenting and introducing design methods. JDAS consists of the modules of the database abstract, object relational mapping, connection pools management, configuration management, data access service, and\u00a0\u2026", "num_citations": "7\n", "authors": ["2184"]}
{"title": "Reporting l most favorite objects in uncertain databases with probabilistic reverse top-k queries\n", "abstract": " Top-k queries are widely studied for identifying a ranked set of the k most interesting objects based on the individual user preference. Reverse top-k queries are proposed from the perspective of the product manufacturer, which are essential for manufacturers to assess the potential market and impacts of their products. However, the existing approaches for reverse top-k queries are all based on the assumption that the underlying data are exact. Due to the intrinsic differences between uncertain and certain data, these methods are designed only in certain databases and cannot be applied to uncertain case directly. Motivated by this, in this paper, we firstly model the probabilistic reverse top-k queries in the context of uncertain data. Moreover, we formulate the challenging problem of processing queries that report l most favorite objects to users, where impact factor of an object is defined as the cardinality of the\u00a0\u2026", "num_citations": "7\n", "authors": ["2184"]}
{"title": "Modelling and developing co-scheduling strategies on multicore processors\n", "abstract": " On-chip cache is often shared between processes that run concurrently on different cores of the same processor. Resource contention of this type causes performance degradation to the co-running processes. Contention-aware co-scheduling refers to the class of scheduling techniques to reduce the performance degradation. Most existing contention-aware co-schedulers only consider serial jobs. However, there often exist both parallel and serial jobs in computing systems. In this paper, the problem of co-scheduling a mix of serial and parallel jobs is modelled as an Integer Programming (IP) problem. Then the existing IP solver can be used to find the optimal co-scheduling solution that minimizes the performance degradation. However, we find that the IP-based method incurs high time overhead and can only be used to solve small-scale problems. Therefore, a graph-based method is also proposed in this paper to\u00a0\u2026", "num_citations": "7\n", "authors": ["2184"]}
{"title": "Energy-efficient and high-performance processing of large-scale parallel applications in data centers\n", "abstract": " Next generation supercomputers require drastically better energy efficiency to allow these systems to scale to exaflop computing levels. Virtually all major processor vendors and companies such as AMD, Intel, and IBM are developing high-performance and highly energy-efficient multicore processors and dedicating their current and future development and manufacturing to multicore products. It is conceivable that future multicore architectures can hold dozens or even hundreds of cores on a single die [3].", "num_citations": "7\n", "authors": ["2184"]}
{"title": "An adaptive channel coordination mechanism for Vehicular Ad hoc Networks\n", "abstract": " The different types of applications in VANETs impose diversified traffic loads. Although multi-channel operations are applied in the MAC layer to improve throughput and potentially reduce the latency, the existing multi-channel approaches show some limitations to meet the changing demands of applications. In this paper, we present an adaptive channel coordination mechanism named Merak to enhance IEEE 1609.4 by adjusting the length ratio of CCH interval and SCH interval dynamically. To be specific, we model the channel interval allocation with a Markov decision process, and estimate the optimal channel interval for the current traffic load by employing a fuzzy actor-critic algorithm. The extensive experiments are conducted to observe Merak, the alternating access scheme in IEEE 1609.4 and the variable channel interval scheme (VCI). The experimental results indicate that Merak can adapt to the varying\u00a0\u2026", "num_citations": "7\n", "authors": ["2184"]}
{"title": "Energy-aware scheduling on multiprocessor platforms with devices\n", "abstract": " In this paper, we address the problem of energy-aware task scheduling on DVFS-enabled multiprocessors with DPM-enabled device(s). Given a set of frame-based tasks, we aim to derive a scheduling where the device occupation constraint is respected, all of the tasks meet the shared deadline, and the overall system energy consumption, including energy consumed on both processors and devices, is minimized. For the problem when preemption and migration are allowed, after solving the formulated optimization problem, we regard the tasks that require the same device as a single preemptive task. An Execution Time Filling (ETF) process can be applied to derive a scheduling which adopts the optimal frequency setting, then, we propose Algorithm ETFR, which achieves the optimal system energy consumption, and also Reduces the total number of preemptions and migrations. For the problem when tasks are\u00a0\u2026", "num_citations": "7\n", "authors": ["2184"]}
{"title": "An average-case analysis of online non-clairvoyant scheduling of independent parallel tasks\n", "abstract": " We analyze the average-case performance of an online non-clairvoyant scheduling algorithm for independent parallel tasks. The algorithm schedules tasks without prior knowledge of the future tasks and the execution times of the tasks that are not yet completed. By using reasonable assumptions, we find an asymptotic average-case performance bound and develop a method to calculate the bound for arbitrary probability distribution of task sizes. In particular, we show that when task sizes are uniformly distributed in the range [1.. C], an asymptotic average-case performance bound of M M-(3-(1+ 1/C) C+ 1) C-1 can be achieved, where M is the number of processors. The above asymptotic average-case performance bound achieves its maximum value when C= M, which is approximately 1/(e-2)= 1.3922112 for large M. We also present extensive numerical and simulation data to demonstrate the accuracy of our\u00a0\u2026", "num_citations": "7\n", "authors": ["2184"]}
{"title": "Joint offloading and scheduling decisions for DAG applications in mobile edge computing\n", "abstract": " Mobile edge computing (MEC) is a promising technology to support computation-intensive tasks for mobile devices which are usually associated with limited resources. Many researches from both scientific and industrial field have put focuses on MEC. However, most of them assume that in a MEC environment, the offloaded tasks are independent or that there is only one server in the MEC center. Nevertheless, in reality, tasks with dependencies take the majority and in a MEC center, there are usually multiple servers. Under this circumstance, previous methods no longer take effects. In this work, we consider offloading with precedence constraints among tasks, and try to minimize makespan over a MEC center with multiple servers. This problem becomes more complex given that a task can not start unless its predecessors are completed. To solve the problem, we jointly involve front end task offloading order and\u00a0\u2026", "num_citations": "6\n", "authors": ["2184"]}
{"title": "SCGSA: a sine chaotic gravitational search algorithm for continuous optimization problems\n", "abstract": " Gravitational search algorithm (GSA), as one of the novel meta-heuristic optimization algorithms inspired by the law of gravity and mass interactions, is however prone to local optima stagnation due to heavier gravity. Hence, an enhanced version, chaotic gravitational constants for the gravitational search algorithm (CGSA), was proposed to improve the exploration ability through various chaotic maps. In this paper, with insightful utilization of sine cosine algorithm, we put forward sine chaotic gravitational search algorithm (SCGSA) as a further step of CGSA to escape from its local optima stagnation. The experiments show remarkable results in both the speed of convergence and the ability of finding global optima in 30 benchmark functions (CEC 2014), thus proving a better balance between exploration and exploitation in SCGSA compared with CGSA.", "num_citations": "6\n", "authors": ["2184"]}
{"title": "MCtandem: an efficient tool for large-scale peptide identification on many integrated core (MIC) architecture\n", "abstract": " Tandem mass spectrometry (MS/MS)-based database searching is a widely acknowledged and widely used method for peptide identification in shotgun proteomics. However, due to the rapid growth of spectra data produced by advanced mass spectrometry and the greatly increased number of modified and digested peptides identified in recent years, the current methods for peptide database searching cannot rapidly and thoroughly process large MS/MS spectra datasets. A breakthrough in efficient database search algorithms is crucial for peptide identification in computational proteomics. This paper presents MCtandem, an efficient tool for large-scale peptide identification on Intel Many Integrated Core (MIC) architecture. To support big data processing capability, a novel parallel match scoring algorithm, named MIC-SDP (spectrum dot product), and its two-level parallelization are presented in MCtandem\u2019s design. In addition, a series of optimization strategies on both the host CPU side and the MIC side, which includes pre-fetching, optimized communication overlapping scheme, multithreading and hyper-threading, are exploited to improve the execution performance. For fair comparisons, we first set up experiments and verified the 28 fold times speedup on a single MIC against the original CPU-based implementation. We then execute the MCtandem for a very large dataset on an MIC cluster (a component of the Tianhe-2 supercomputer) and achieved much higher scalability than in a benchmark MapReduce-based programs, MR-Tandem. MCtandem is an open-source software tool implemented in C++. The source code and the parameter\u00a0\u2026", "num_citations": "6\n", "authors": ["2184"]}
{"title": "Energy-efficient functional safety design methodology using ASIL decomposition for automotive cyber-physical systems\n", "abstract": " Automotive cyber-physical systems (ACPS) are typical cyber-physical systems because of the joint interaction between the cyber part and physical part. Functional safety requirement (including response time and reliability requirements) for an ACPS function must be assured for safe driving. Auto industry is cost-sensitive, power-sensitive, and environment-friendly. Energy consumption affects the development efficiency of the ACPS and the living environment of people. This paper solves the problem of optimizing the energy consumption for an ACPS function while assuring its functional safety requirement (i.e., energy-efficient functional safety for ACPS). However, implementing minimum response time, maximum reliability, and minimum energy consumption is a conflicting problem. Consequently, solving the problem is a challenge. In this paper, we propose a three-stage design process toward energy-efficient\u00a0\u2026", "num_citations": "6\n", "authors": ["2184"]}
{"title": "McTAR: a multi-trigger checkpointing tactic for fast task recovery in MapReduce\n", "abstract": " Cloud computing and big data technologies have gained great popularity in recent years. MapReduce is still one of the most efficient and well-adopted computing paradigms for providing big data services. MapReduce applications need to be executed on cloud platform where failures are inevitable. Hadoop is the de facto implementation of MapReduce, but it deploys a coarse grained and unsatisfactory fault tolerant services. The failed tasks are rescheduled from scratch to re-execute from the very beginning, which apparently brings amount of overload for failure recovery, and the whole job would be heavily delayed as failures happen. In this paper, we propose a novel multi-trigger checkpointing approach for fast recovery of MapReduce tasks, named McTAR (a Multi-trigger Checkpointing Tactic for fAst TAsk Recovery). As a finer-grained and better fault tolerance tactic, our McTAR employs multi-trigger checkpoint\u00a0\u2026", "num_citations": "6\n", "authors": ["2184"]}
{"title": "A novel approach to rule placement in software-defined networks based on OPTree\n", "abstract": " Software-defined networks (SDNs) are a trend of research in networks. Rule placement, a common SDN operation, becomes a challenging problem due to the capacity limitation of devices in which a large number of rules need to be deployed. Prior works mostly consider rule placement in a single device. However, the position relationships between neighbor devices also have influences on rule placement and should be considered. Our basic idea is to classify the devices position relationships into two categories: the serial relationship and the parallel relationship, and we present novel strategies for rule placement based on the two different position relationships. There are two challenges of implementing our strategies: to check whether a rule is contained by a rule set or not and to check whether a rule can be merged with other rules or not. To handle the challenges, we propose a novel data structure called\u00a0\u2026", "num_citations": "6\n", "authors": ["2184"]}
{"title": "SWPepNovo: an efficient de novo peptide sequencing tool for large-scale MS/MS spectra analysis\n", "abstract": " Tandem mass spectrometry (MS/MS)-based de novo peptide sequencing is a powerful method for high-throughput protein analysis. However, the explosively increasing size of MS/MS spectra dataset inevitably and exponentially raises the computational demand of existing de novo peptide sequencing methods, which is an issue urgently to be solved in computational biology. This paper introduces an efficient tool based on SW26010 many-core processor, namely SWPepNovo, to process the large-scale peptide MS/MS spectra using a parallel peptide spectrum matches (PSMs) algorithm. Our design employs a two-level parallelization mechanism:(1) the task-level parallelism between MPEs using MPI based on a data transformation method and a dynamic feedback task scheduling algorithm,(2) the thread-level parallelism across CPEs using asynchronous task transfer and multithreading. Moreover, three\u00a0\u2026", "num_citations": "6\n", "authors": ["2184"]}
{"title": "Resource-cost-aware fault-tolerant design methodology for end-to-end functional safety computation on automotive cyber-physical systems\n", "abstract": " Automotive functional safety standard ISO 26262 aims to avoid unreasonable risks due to systematic failures and random hardware failures caused by malfunctioning behavior. Automotive functions involve distributed end-to-end computation in automotive cyber-physical systems (ACPSs). The automotive industry is highly cost-sensitive to the mass market. This study presents a resource-cost-aware fault-tolerant design methodology for end-to-end functional safety computation on ACPSs. The proposed design methodology involves early functional safety requirement verification and late resource cost design optimization. We first propose the functional safety requirement verification (FSRV) method to verify the functional safety requirement consisting of reliability and response time requirements of the distributed automotive function during the early design phase. We then propose the resource-cost-aware fault\u00a0\u2026", "num_citations": "6\n", "authors": ["2184"]}
{"title": "Online inter-datacenter service migrations\n", "abstract": " Service migration between datacenters can reduce the network overhead within a cloud infrastructure; thereby, also improving the quality of service for the clients. Most of the algorithms in the literature assume that the client access pattern remains stable for a sufficiently long period so as to amortize such migrations. However, if such an assumption does not hold, these algorithms can take arbitrarily poor migration decisions that can substantially degrade system performance. In this paper, we approach the issue of performing service migrations for an unknown and dynamically changing client access pattern. We propose an online algorithm that minimizes the inter-datacenter network, taking into account the network load of migrating a service between two datacenters, as well as the fact that the client request pattern may change \u201cquickly\u201d, before such a migration is amortized. We provide a rigorous mathematical\u00a0\u2026", "num_citations": "6\n", "authors": ["2184"]}
{"title": "Location distribution of a mobile terminal and its application to paging cost reduction and minimization\n", "abstract": " Reducing the cost of dynamic mobility management in wireless communication networks has been an interesting and important issue. It is well known that by using a selective paging method, both costs for location update and terminal paging can be reduced significantly. However, an efficient selective paging method needs the information of the location distribution of a mobile terminal. Based on our previous results on random walks among rings of cell structures, we analyze the location distribution of a mobile terminal in a paging area when a phone call arrives, where the inter-call time and the cell residence time can have arbitrary probability distributions. Our analysis is conducted for both distance-based and movement-based location management schemes, and for two different call handling models, i.e., the call plus location update model and the call without location update model. Together with our earlier\u00a0\u2026", "num_citations": "6\n", "authors": ["2184"]}
{"title": "Divide\u2010and\u2010conquer approach for solving singular value decomposition based on MapReduce\n", "abstract": " Singular value decomposition (SVD) shows strong vitality in the area of information analysis and has significant application value in most of the scientific big data fields. However, with the rapid development of Internet, the information online reveals fast growing trend. For a large\u2010scale matrix, applying SVD computation directly is both time consuming and memory demanding. There are many works available to speed up the computation of SVD based on the message passing interface model. However, to deal with large\u2010scale data processing, a MapReduce model has many advantages over a message passing interface model, such as fault tolerance, load balancing and simplicity. For a MapReduce environment, existing approaches only focus on low rank SVD approximation and tall\u2010and\u2010skinny matrix SVD computation, and there are no implementations of full rank SVD computation. In this paper, we propose a\u00a0\u2026", "num_citations": "6\n", "authors": ["2184"]}
{"title": "Lazy-Merge: A Novel Implementation for Indexed Parallel  -Way In-Place Merging\n", "abstract": " Merging sorted segments is a core topic of fundamental computer science that has many different applications, such as n-body simulation. In this research, we propose Lazy-Merge, a novel implementation of sequential in-place k-way merging algorithms, that can be utilized in their parallel counterparts. The implementation divides the k-way merging problem into t ordered and independent smaller k-way merging tasks (partitions), but each merging task includes a set of scattered ranges to be merged by an existing merging algorithm. The final merged list includes ranges with ordered elements, but the ranges themselves are not ordered. Lazy-Merge utilizes a novel usage of indexes to access the entire set of merged elements in order. Its merging time complexity is O(k log (n/k) + merge(n/p)), where k, n, and pare the number of segments, the list size and the number of processors (partitions), respectively. Here\u00a0\u2026", "num_citations": "6\n", "authors": ["2184"]}
{"title": "Scalable analytic models for performance efficiency in the cloud\n", "abstract": " This paper presents a scalable model-driven approach to quantify the availability of resources and optimal distribution of tasks over these resources, such that the average response time of tasks is minimized. To reduce the complexity of analysis and solution time, we use an integrated stochastic based approach. To achieve this, first we use clustering algorithm to group the tasks into distinct classes with similar characteristics in terms of resource and performance requirements. Second, we quantify the resource availability of cloud center among three states: active (running), idle (turned on, but not ready), and off (turned off). Third, we develop a queuing model for multiple heterogeneous multicore servers, and formulate and solve the optimal load distribution of tasks for multiple heterogeneous multicore servers in a cloud computing data centers. We derive equations that permit us to find optimal load distribution of\u00a0\u2026", "num_citations": "6\n", "authors": ["2184"]}
{"title": "GPU-based variation of parallel invasive weed optimization algorithm for 1000D functions\n", "abstract": " Considering the problems of slow convergence and easily getting into local optimum of intelligent optimization algorithms in finding the optimal solution to complex high-dimensional functions, we have proposed an improved invasive weed optimization (IIWO). Concrete adjustments include setting the newborn seeds per plant to a fixed number, changing the initial step and final step to adaptive one, and re-initializing the solution which exceeds the boundary value. Meanwhile, through applying the algorithm to the GPU platform, a parallel IIWO (PIIWO) based on GPU is obtained. The algorithm not only improves the convergence, but also strikes a balance between the global and local search capabilities. The simulation results of solving on the CEC' 2010 1000-dimensional (1000D) functions, have shown that, compared with other algorithms, our designed IIWO can yield better performance, faster convergence\u00a0\u2026", "num_citations": "6\n", "authors": ["2184"]}
{"title": "On the expected file download time of the random time-based switching algorithm in P2P networks\n", "abstract": " The expected file download time of the random time-based switching algorithm for peer selection and file downloading in a peer-to-peer (P2P) network is still unknown. The main contribution of this paper is to analyze the expected file download time of the time-based switching algorithm for file sharing in P2P networks when the service capacity of a source peer is totally correlated over time, namely, the service capacities of a source peer in different time slots are a fixed value. A recurrence relation is developed to characterize the expected file download time of the time-based switching algorithm. It is proved that for two or more heterogeneous source peers and sufficiently large file size, the expected file download time of the time-based switching algorithm is less than and can be arbitrarily less than the expected download time of the chunk-based switching algorithm and the expected download time of the\u00a0\u2026", "num_citations": "6\n", "authors": ["2184"]}
{"title": "A novel CPU-GPU cooperative implementation of a parallel two-list algorithm for the subset-sum problem\n", "abstract": " The subset-sum problem is a well-known NP-complete decision problem. Many parallel algorithms have been developed to solve the problem within a reasonable computation time, and some of them have been implemented on a GPU. However, the GPU implementations of these parallel algorithms may fail to fully utilize all the CPU cores and the GPU resources at the same time. When the GPU performs some tasks, only one CPU core is used to control the GPU, all the rest of CPU cores are in idle state, this leads to large amounts of available CPU resources are wasted. This paper proposes a novel CPU-GPU cooperative implementation of a parallel two-list algorithm to efficiently solve the subset-sum problem in a heterogeneous CPU-GPU system, which enables the efficient utilization of all the available computational resources of both CPUs and GPUs. In order to find the most appropriate task distribution ratio\u00a0\u2026", "num_citations": "6\n", "authors": ["2184"]}
{"title": "Analysis of random time-based switching for file sharing in peer-to-peer networks\n", "abstract": " The expected file download time of the randomized time-based switching algorithm for peer selection and file downloading in a peer-to-peer (P2P) network is still unknown. The main contribution of this paper is to analyze the expected file download time of the time-based switching algorithm for file sharing in P2P networks when the service capacity of a source peer is totally correlated over time, namely, the service capacities of a source peer in different time slots are a fixed value. A recurrence relation is developed to characterize the expected file download time of the time-based switching algorithm. Is is proved that for two or more heterogeneous source peers and sufficiently large file size, the expected file download time of the time-based switching algorithm is less than and can be arbitrarily less than the expected download time of the chunk-based switching algorithm and the expected download time of the\u00a0\u2026", "num_citations": "6\n", "authors": ["2184"]}
{"title": "An xacml-based security pattern to achieve socio-technical confidentiality in smart homes\n", "abstract": " In this paper we discuss and address multifold security challenges involved in the implementation of remote healthcare in smart homes. These security challenges are derived from real-world, industrially relevant scenarios. Validated security techniques and mechanisms providing certain security properties can be captured and implemented in security patterns, which can be applied in order to satisfy security requirements in the smart home healthcare scenarios. The presented results are parts of our ongoing research effort aiming at the development of an integrated security framework for remote healthcare and ambient intelligence systems.", "num_citations": "6\n", "authors": ["2184"]}
{"title": "Average-case performance analysis of online non-clairvoyant scheduling of parallel tasks with precedence constraints\n", "abstract": " We evaluate the average-case performance of three approximation algorithms for online non-clairvoyant scheduling of parallel tasks with precedence constraints. We show that for a class of wide task graphs, when task sizes are uniformly distributed in the range [1\u2026C], the online non-clairvoyant scheduling algorithm LL-SIMPLE has an asymptotic average-case performance bound of M/(M \u2212 (3 \u2212 (1 + 1/C)C+1)C \u2212 1), where M is the number of processors. For uniform probability distributions of task sizes, we present numerical and simulation data to demonstrate the accuracy of our general asymptotic average-case performance bound. We also report extensive experimental results on the average-case performance of online non-clairvoyant scheduling algorithms LL-GREEDY and LS. Algorithm LL-GREEDY has better performance than LL-SIMPLE using an improved algorithm to schedule independent tasks in\u00a0\u2026", "num_citations": "6\n", "authors": ["2184"]}
{"title": "Accelerating divisible load distribution on tree and pyramid networks using pipelined communications\n", "abstract": " Summary form only given. We propose two methods which employ pipelined communications to distribute divisible loads on tree and pyramid networks. We derive the closed form solutions to the parallel time and speedup for both methods and show that the asymptotic speedup of both methods is 6/spl beta/+1 for a complete b-ary tree network and 4/spl beta/+1 for a pyramid network, where /spl beta/ is the ratio of the time for computing a unit load to the time for communicating a unit load.", "num_citations": "6\n", "authors": ["2184"]}
{"title": "Euclidean distance transform for binary images on reconfigurable mesh-connected computers\n", "abstract": " The distance calculation in an image is a basic operation in computer vision, pattern recognition, and robotics. Several parallel algorithms have been proposed for calculating the Euclidean distance transform (EDT). Recently, Chen and Chuang proposed a parallel algorithm for computing the EDT on mesh-connected SIMD computers (1995). For an n/spl times/n image, their algorithm runs in O(n) time on a two-dimensional (2-D) n/spl times/n mesh-connected processor array. In this paper, we propose a more efficient parallel algorithm for computing the EDT on a reconfigurable mesh model. For the same problem, our algorithm runs in O(log /sup 2/n) time on a 2-D n/spl times/n reconfigurable mesh. Since a reconfigurable mesh uses the same amount of VLSI area as a plain mesh of the same size does when implemented in VLSI, our algorithm improves the result in [3] significantly.", "num_citations": "6\n", "authors": ["2184"]}
{"title": "On the impact of communication overhead on the average-case scalability of random parallel programs on multicomputers\n", "abstract": " YiPan Department of Computer Science University of Dayton, Dayton, Ohio 45469-2160, USA Phone:(937) 229-3807, Fax:(937) 229-4000 E-mail: pan@ cps. udayton. ed u", "num_citations": "6\n", "authors": ["2184"]}
{"title": "DLEA: A dynamic learning evolution algorithm for many-objective optimization\n", "abstract": " For many-objective problems, how to maintain the diversity and convergence of the distribution of the solution set over Pareto front (PF) has always been the research emphasis. In the iteration process, the state of population is critical to improve the level of evolution. Therefore, this paper will use two convergence and diversity indicators to further strengthen the usage of evolutionary state information and propose a dynamic learning strategy. In addition, a dynamic learning strategy based many-objective evolutionary algorithm (MaOEA) is proposed, called dynamic learning evolution algorithm (DLEA), which continuously changes the direction of learning: convergence and diversity in the iteration process. The purpose is to make the algorithm prefer to convergence in the early iteration and prefer to diversity when it is close to PF in the late iteration, so that the convergence and diversity of the final solution set can be\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "Dynamic planning of bicycle stations in dockless public bicycle-sharing system using gated graph neural network\n", "abstract": " Benefiting from convenient cycling and flexible parking locations, the Dockless Public Bicycle-sharing (DL-PBS) network becomes increasingly popular in many countries. However, redundant and low-utility stations waste public urban space and maintenance costs of DL-PBS vendors. In this article, we propose a Bicycle Station Dynamic Planning (BSDP) system to dynamically provide the optimal bicycle station layout for the DL-PBS network. The BSDP system contains four modules: bicycle drop-off location clustering, bicycle-station graph modeling, bicycle-station location prediction, and bicycle-station layout recommendation. In the bicycle drop-off location clustering module, candidate bicycle stations are clustered from each spatio-temporal subset of the large-scale cycling trajectory records. In the bicycle-station graph modeling module, a weighted digraph model is built based on the clustering results and\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "A Survey of Low-Energy Parallel Scheduling Algorithms\n", "abstract": " High energy consumption is one of the biggest obstacles to the rapid development of computing systems, and reducing energy consumption is quite urgent and necessary for sustainable computing. Low-energy scheduling based on Dynamic Voltage and Frequency Scaling (DVFS) is one of the most commonly used energy optimization techniques. Recent survey works have reviewed some low-energy scheduling algorithms, but there is currently no systematic review in low-energy parallel scheduling algorithms. With the increasing complexity of function requirements, many parallel applications have been executed in various sustainable computing systems. In this paper, we survey recent advances in low-energy parallel scheduling algorithms according to three scheduling styles, namely, 1) energy-efficient parallel scheduling algorithms; 2) energy-aware parallel scheduling algorithms; and 3) energy-conscious\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "Game-Based Task Offloading of Multiple Mobile Devices with QoS in Mobile Edge Computing Systems of Limited Computation Capacity\n", "abstract": " Mobile edge computing (MEC) is becoming a promising paradigm of providing computing servers, like cloud computing, to Edge node. Compared to cloud servers, MECs are deployed closer to mobile devices (MDs) and can provide high quality-of-service (QoS; including high bandwidth, low latency, etc) for MDs with computation-intensive and delay-sensitive tasks. Faced with many MDs with high QoS requirements, MEC with limited computation capacity should consider how to allocate the computing resources to MDs to maximize the number of served MDs. Besides, for each MD, he/she wants to minimize the energy consumption within an acceptance delay range. To solve these issues, we propose a Game-based Computation Offloading (GCO) algorithm including a task offloading profile of MEC and the transmission power controlling of each MD. Specifically, we propose a Greedy-Pruning algorithm to\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "Power consumption model based on feature selection and deep learning in cloud computing scenarios\n", "abstract": " High power consumption of cloud data centres is a crucial challenge in modern cloud computing. To comply with the conceptions of green computing, power consumption prediction of the computing cluster has a major role to play in these energy conservation efforts. However, due to complexity and heterogeneity in cloud computing scenarios, it is difficult to accurately predict the power consumption using conventional approaches. To this end, this study presents a power consumption model based on feature selection and deep learning to powerfully cope with low energy efficiency. Different from other methods focusing on only a few performance attributes, the proposed method takes into account up to 12 energy-related features and introduces deep neural network architecture, aiming at making full use of massive data to train model completely. In particular, this approach is composed of three main phases\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "tpSpMV: a two-phase large-scale sparse matrix-vector multiplication kernel for manycore architectures\n", "abstract": " Sparse matrix-vector multiplication (SpMV) is one of the important subroutines in numerical linear algebras widely used in lots of large-scale applications. Accelerating SpMV on multicore and manycore architectures based on Compressed Sparse Row (CSR) format via row-wise parallelization is one of the most popular directions. However, there are three main challenges in optimizing parallel CSR-based SpMV: (a) limited local memory of each computing unit can be overwhelmed by assignments to long rows of large-scale sparse matrices; (b) irregular accesses to the input vector result in expensive memory access latency; (c) sparse data structure leads to low bandwidth usage. This paper proposes a two-phase large-scale SpMV, called tpSpMV, based on the memory structure and computing architecture of multicore and manycore architectures to alleviate the three main difficulties. First, we propose the two\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "Design and analysis of three nonlinearly activated ZNN models for solving time-varying linear matrix inequalities in finite time\n", "abstract": " To obtain the superiority property of solving time-varying linear matrix inequalities (LMIs), three novel finite-time convergence zeroing neural network (FTCZNN) models are designed and analyzed in this paper. First, to make the Matlab toolbox calculation processing more conveniently, the matrix vectorization technique is used to transform matrix-valued FTCZNN models into vector-valued FTCZNN models. Then, considering the importance of nonlinear activation functions on the conventional zeroing neural network (ZNN), the sign-bi-power activation function (AF), the improved sign-bi-power AF and the tunable sign-bi-power AF are explored to establish the FTCZNN models. Theoretical analysis shows that the FTCZNN models not only can accelerate the convergence speed, but also can achieve finite-time convergence. Computer numerical results ulteriorly confirm the effectiveness and advantages of the\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "Reliable correlation tracking via dual-memory selection model\n", "abstract": " Correlation-filter-based trackers have shown favorable accuracy and efficiency in visual tracking. However, most of these trackers are prone to drift in cases of heavy occlusions and temporal tracking failures because they only maintain the short-term memory of target appearance via a highly adaptive update mode. In this paper, we propose a reliable visual tracking method based on a dual-memory selection (DMS) model to alleviate tracking drift. Considering that long-term memory is robust to heavy occlusions while short-term memory performs well in rapid appearance changes, the proposed DMS model combines these two memory patterns of the target appearance and adaptively selects a reliable memory pattern to handle the current tracking challenges via a memory selector. For each memory pattern, a memory tracker is established based on discriminative correlation filters. The short-term tracker\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "Non-clairvoyant scheduling of independent parallel tasks on single and multiple multicore processors\n", "abstract": " We investigate the problem of non-clairvoyant scheduling of independent parallel tasks on single and multiple multicore processors. For a single multicore processor, we derive an asymptotic worst-case performance bound for a non-clairvoyant offline scheduling algorithm called largest task first (LTF). The result improves our previous result on a single parallel computing system. For multiple multicore processors, we derive an asymptotic worst-case performance bound for the LTF algorithm. To the best of our knowledge, there has been little result on scheduling parallel tasks on multiple parallel computing systems. For multiple multicore processors, we also derive an asymptotic average-case performance bound for a non-clairvoyant online scheduling algorithm called random task first (RTF). The result extends our earlier result on a single parallel computing system. Extensive simulation results are also demonstrated.", "num_citations": "5\n", "authors": ["2184"]}
{"title": "HaloDPC: An improved recognition method on halo node for density peak clustering algorithm\n", "abstract": " The density peaks clustering (DPC) is known as an excellent approach to detect some complicated-shaped clusters with high-dimensionality. However, it is not able to detect outliers, hub nodes and boundary nodes, or form low-density clusters. Therefore, halo is adopted to improve the performance of DPC in processing low-density nodes. This paper explores the potential reasons for adopting halos instead of low-density nodes, and proposes an improved recognition method on Halo node for Density Peak Clustering algorithm (HaloDPC). The proposed HaloDPC has improved the ability to deal with varying densities, irregular shapes, the number of clusters, outlier and hub node detection. This paper presents the advantages of the HaloDPC algorithm on several test cases.", "num_citations": "5\n", "authors": ["2184"]}
{"title": "HCFS: a density peak based clustering algorithm employing a hierarchical strategy\n", "abstract": " Clustering, which explores the visualization and distribution of data, has recently been widely studied. Although current clustering algorithms such as DBSCAN, can detect the arbitrary-shape clusters and work well, the parameters involved in these methods are often difficult to determine. Clustering using a fast search of density peaks is a promising technique for solving this problem. However, the current methods suffer from the problem of uneven distribution within local clusters. To solve this problem, we propose a new density peak based clustering algorithm employing a hierarchical strategy, namely, HCFS, which consists mainly of two stages. In the first stage, the HCFS estimates the density and distance of each point. The points with higher density and distance are selected as candidate centers, and then subclusters centered on them are further obtained. In the second stage, considering that adjacent\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "Fast boolean queries with minimized leakage for encrypted databases in cloud computing\n", "abstract": " This research revisits the fundamental problem of processing privacy-preserving Boolean queries over outsourced databases on untrusted public clouds. Much current searchable encryption (SE) schemes try to seek an appropriate trade-off between security and efficiency, yet most of them suffer from an unacceptable query leakage due to their conjunctive/disjunctive terms that are processed individually. We show, however, this trade-off still can be deeply optimized for more security. We consider a Boolean formula as a set of deterministic finite automatons (DFAs) and propose a novel approach to running an encrypted DFA, which can be effectively and efficiently processed by the cloud. We give three constructions for conjunctive, disjunctive, and Boolean queries, respectively. Their notable advantages are single-round, highly-efficient, adaptively-secure, and leakage-minimized. A lot of experiments are made to\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "Robust precise dynamic point reconstruction from multi-view\n", "abstract": " Reconstructing precise dynamic points with multiple camera systems (MCSs) is a pivotal work in many computer vision applications, such as motion capture. However, the deviation of 2-D position leads to frequent mismatch when searching for correspondence from multi-view. This paper puts forward a two-stage framework based on passive optical motion capture system to reconstruct precise dynamic points with MCSs. Our proposed method improves the performance of calibration and matching simultaneously. In the calibration stage, the extrinsic parameters of numerous cameras are calibrated synchronously via an L-shaped frame, where the position of four reference points is optimized with multiple geometric constraints. Bundle adjustment occurs after calibration. In the reconstruction stage, we propose a novel sparse multi-view matching method called cyclical voting, which includes multiple pairs of global\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "Optimal power and performance management for heterogeneous and arbitrary cloud servers\n", "abstract": " We investigate optimal power and performance management for heterogeneous and arbitrary cloud servers in a data center. In particular, we study the problems of power-constrained performance optimization and performance-constrained power optimization in a data center with multiple heterogeneous and arbitrary servers. These problems are essential to find optimal server speeds, such that: 1) the average task response time is minimized, and that the total power consumption does not exceed certain power constraint or 2) the total power consumption is minimized, and that the average task response time does not exceed certain performance constraint. Each server is treated as a G/G/1 queuing system, whose task interarrival times and task execution requirements can have arbitrary probability distributions. Furthermore, these servers are entirely heterogeneous in terms of task interarrival time, task execution\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "Optimal load distribution for multiple classes of applications on heterogeneous servers with variable speeds\n", "abstract": " Performance and power are 2 significant issues in cloud computing. It is a critical issue on how to provide the best quality of service by consuming certain available power resource. For a given application environment and a given group of servers, optimal load distribution and optimal server speed setting can be an effective way to deal with the power\u2010performance tradeoff. The technique of variable and task\u2010type\u2013dependent server speed management can be explored to optimize the server performance and to minimize the power consumption of a server with mixed applications. In this paper, we consider the problem of optimal load distribution for multiple classes of applications on heterogeneous servers with variable speeds. Given several classes of applications characterized by their arrival rates and expected execution requirements, several heterogeneous servers characterized by their power consumption\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "Cusnmf: A sparse non-negative matrix factorization approach for large-scale collaborative filtering recommender systems on multi-GPU\n", "abstract": " Matrix factorization (MF), as one of the most accurate and scalable approaches in dimension reduction techniques, has become popular in the collaborative filter- ing (CF) recommender systems communities. Currently, Non- negative Matrix Factorization (NMF) is one of the most famous approaches for MF, due to its representative non-negativity fea- ture for CF model. However, it is non-trivial to obtain high per- formance of sparse NMF (SNMF) on Graphic Processing Units (GPU) for large-scale problems, due to the redundant large- scale intermediate data, frequent matrices manipulation, and access on the sparse rating matrix with irregular distribution non-zero entries. In this work, we propose single-thread- based SNMF, which depends on the involved feature tuples multiplication and summation, and then, we present L 2  norm regularized single-thread-based SNMF. On that basis, a novel CUDA parallelization\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "An efficient parallelization approach for large-scale sparse non-negative matrix factorization using kullback-leibler divergence on multi-GPU\n", "abstract": " Matrix factorization (MF), as one of the most accurate and scalable approaches in dimension reduction techniques, has become popular in the collaborative filtering (CF) recommender systems, social network and graph communities. Currently, Kullback-Lerbler Non-negative Matrix Factorization (KL-NMF) is one of the most famous approaches for MF, due to its representative non-negativity feature of the CF model. However, it is non-trivial to obtain high performance KL-NMF on Graphic Processing Units (GPU) for large-scale problems, due to the redundant large-scale intermediate data, frequent matrices manipulation, and access of sparse and irregular entries characteristic of KL-NMF. In this work, we propose single-thread-based KL-NMF, which depends on the involved feature tuples multiplication and summation, and then, we present L 2  norm regularized single-thread-based KL-NMF. On that basis, a novel\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "Automatic density clustering with multiple kernels for high-dimension bioinformatics data\n", "abstract": " Clustering is an effective method for data analysis and can be exploited to unknown features of data samples, its applications range from data mining to bioinformatics analysis. Several clustering approaches have been proposed in order to obtain a better trade-off between accuracy and efficiency of the clustering process. It is well-known that no existing clustering algorithm completely satisfies both accuracy and efficiency requirements, thus we propose a clustering algorithm called ADCMK (for Automatic Density Clustering with Multiple Kernels) exhibiting higher quality than the density ones proposed so far, while allowing users to cluster efficiently without determining parameters manually. The algorithm consists of learning optimal combined kernel, reducing dimensionality with the optimal kernel, automatically detecting cluster centroids with outliers test, assigning clusters and visualizing results. The proposed\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "An improved LDA multi-document summarization model based on tensorflow\n", "abstract": " Latent Dirichlet Allocation (LDA), has been recently used to automatically generate text corpora topics, and applied to sentences extraction based multi-document summarization algorithms. In this paper, we propose a novel approach to automatic generation of aspect-oriented summaries from multiple documents. Our approach is to combine the traditional summary generation algorithm and the the abstract generation algorithm based on deep learning.We employ the improved traditional summary generation algorithm to convert multiple documents into a single document, and then using the resulting single document with the deep learning method to extract the final summary. At first, we apply improved LDA model to cluster sentences in all documents. Second, We employ the extended LexRank algorithm to sort the sentences in each cluster. Third, we use extended Hedge Trimmer algorithm for sentence\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "Data\u2010aware task scheduling on heterogeneous hybrid memory multiprocessor systems\n", "abstract": " In this paper, we propose a method about task scheduling and data assignment on heterogeneous hybrid memory multiprocessor systems for real\u2010time applications. In a heterogeneous hybrid memory multiprocessor system, an important problem is how to schedule real\u2010time application tasks to processors and assign data to hybrid memories. The hybrid memory consists of dynamic random access memory and solid state drives when considering the performance of solid state drives into the scheduling policy. To solve this problem, we propose two heuristic algorithms called improvement greedy algorithm and the data assignment according to the task scheduling algorithm, which generate a near\u2010optimal solution for real\u2010time applications in polynomial time. We evaluate the performance of our algorithms by comparing them with a greedy algorithm, which is commonly used to solve heterogeneous task scheduling\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "Datapath-regular implementation and scaled technique for N= 3\u00d7 2m DFTs\n", "abstract": " Discrete Fourier transform (DFT) is used widely in almost all fields of science and engineering, and is generally calculated using the fast Fourier transform (FFT) algorithm. In this paper, we present a fast algorithm for efficiently computing a DFT of size 3\u00d72m. The proposed algorithm decomposes the DFT, obtaining one length-2m unscaled sub-DFT and two length-2m sub-DFTs scaled by constant real numbers. For efficiently computing the scaled sub-DFTs, the constant real factors are attached to twiddle factors, combining them into new twiddle factors. By using this approach, the number of real multiplications is reduced compared with existing algorithms. To obtain regular datapath, a novel implementation method is presented aiming at the implementation of the proposed algorithm and making its datapath regular like the radix-2 FFT algorithm. The method can be applied to other algorithms with L-shape butterfly\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "Cloud storage over multiple data centers\n", "abstract": " Cloud storage has become a booming trend in the last few years. Individual developers, companies, organizations, and even governments have either taken steps or at least shown great interests in data migration from self-maintained infrastructure into cloud.", "num_citations": "5\n", "authors": ["2184"]}
{"title": "A task scheduling algorithm based on replication for maximizing reliability on heterogeneous computing systems\n", "abstract": " Over the past several years, a heterogeneous computing (HC) system has become more competative as a commercial computing platform than a homogeneous system. With the growing scale of HC systems, network failures become inevitable. To achieve high performance, communication reliability should be considered while designing reliability-aware task scheduling algorithms. In this paper, we propose a new algorithm called RMSR (Replication-based scheduling for Maximizing System Reliability), which incorporates task communication into system reliability. To maximize communication reliability, an improved algorithm which searches all optimal reliability communication paths for current tasks is proposed. During the task replication phase, the task reliability threshold is determined by users and each task has dynamic replicas. Our comparative studies based on randomly generated graphs show that our\u00a0\u2026", "num_citations": "5\n", "authors": ["2184"]}
{"title": "Computing distance maps efficiently using an optical bus\n", "abstract": " This paper discusses an algorithm for finding a distance map for an image efficiently using an optical bus. The computational model considered is the arrays with a reconfigurable pipelined bus system (LARPBS), which is introduced recently based on current electronic and optical technologies. It is shown that the problem for an n \u00d7 n image can be implemented in O(log n log log n) time deterministically or in O(log n) time with high probability on an LARPBS with n 2 processors. We also show that the problem can be solved in O(log log n) time deterministically or in O(l) time with high probability on an LARPBS with n 3 processors. The algorithm compares favorably to the best known parallel algorithms for the same problem in the literature.", "num_citations": "5\n", "authors": ["2184"]}
{"title": "Fault tolerant all-to-all broadcast in general interconnection networks\n", "abstract": " With respect to scalability and arbitrary topologies of the underlying networks in multiprogramming and multithread environments, fault tolerance in acknowledged ATAB and concurrent communications become a challenge to reliable general wormhole routing multicomputers with arbitrary topologies. In this paper, the virtual ring tree (VRT) is proposed to deal with the challenge. A single startup is needed in the two proposed algorithms by a simple virtual node space, which also reduces the complexity of routing at intermediate steps of ATAB algorithms and re-beginning an ATAB, by cacheable virtual channels. The proposed algorithm can automatically handle static faults in networks.", "num_citations": "5\n", "authors": ["2184"]}
{"title": "Server configuration optimization in mobile edge computing: A cost\u2010performance tradeoff perspective\n", "abstract": " Before service providers build up an mobile edge computing (MEC) platform, an important issue that needs to be considered is the configuration of computing resources on edge servers. Since the computing resources on an edge server are limited compared with a cloud server and the service provider's deployment budget is limited, it would be unrealistic to equip all edge servers with abundant computing resources. In addition, the edge servers have different computation demands due to their different geographies. Therefore, this article investigates the problem of server configuration optimization in an MEC environment based on a given computation demand statistics of the selected deployment locations. Our strategy is to treat each edge server as an M/M/m queueing model, and then establish the performance and cost models for the system. Two optimization problems, including cost constrained performance\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "ED-ACNN: Novel attention convolutional neural network based on encoder\u2013decoder framework for human traffic prediction\n", "abstract": " Accurate human traffic prediction, as a vital component of an intelligent transportation system (ITS), can not only reduce traffic congestion and resource consumption, but also provide a foundation for other tasks, such as risk assessment and public safety. Owing to the rapid development of computing power, massive data storage, and parallelization, deep-learning techniques, especially convolutional neural networks (CNNs), have become a powerful tool for traffic-flow forecasting. However, most of these methods in the literature over-emphasize the accuracy of traffic-flow forecasting and ignore its efficiency. It is often beneficial to develop smaller models (eg, fewer model parameters) to improve efficiency. In this work, taking into account the efficiency and accuracy of the prediction, a novel attention CNN based on an encoder\u2013decoder framework, called ED-ACNN, is proposed. First, the convolutional layer is\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "TSASC: tree\u2013seed algorithm with sine\u2013cosine enhancement for continuous optimization problems\n", "abstract": " Tree\u2013seed algorithm (TSA) establishes a novel approach to solve continuous optimization problems, which is applied in many fields because of its simplicity and strength in finding optimal solutions. However, due to somewhat imbalance of its ability between exploration and exploitation in different search phases, the exploratory capability of TSA is relatively weak in optimizing multimodal and high-dimensional objective functions. To make some improvements, we propose a hybrid heuristic tree\u2013seed algorithm named TSASC by integrating two features from sine\u2013cosine algorithm. The proposed algorithm is then tested in comparison with TSA and other relevant algorithms through 30 benchmark functions from IEEE CEC 2014 and 3 constrained real engineering optimization problems. The results prove its enhanced balance between exploration and exploitation in both finding better global optimal solutions\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "A taxonomy and survey of power models and power modeling for cloud servers\n", "abstract": " Due to the increasing demand of cloud resources, the ever-increasing number and scale of cloud data centers make their massive power consumption a prominent issue today. Evidence reveals that the behaviors of cloud servers make the major impact on data centers\u2019 power consumption. Although extensive research can be found in this context, a systematic review of the models and modeling methods for the entire hierarchy (from underlying hardware components to the upper-layer applications) of the cloud server is still missing, which is supposed to cover the relevant studies on physical and virtual cloud server instances, server components, and cloud applications. In this article, we summarize a broad range of relevant studies from three perspectives: power data acquisition, power models, and power modeling methods for cloud servers (including bare-metal, virtual machine (VM), and container instances). We\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "A cost saving and load balancing task scheduling model for computational biology in heterogeneous cloud datacenters\n", "abstract": " Cloud-based scientific workflow systems can play an important role in the development of cost-effective bioinformatics analysis applications. There are differences in the cost control and performance of many kinds of servers in heterogeneous cloud data centers for bioinformatics workflows running, which can lead to imbalance between operational/maintenance management costs and quality of service of server clusters. A task scheduling model that responds to the peaks and valleys of task sequencing\u2014the number of tasks that arrive in a given unit of time\u2014is related to indicators such as cost saving, load balancing and system performance (average task wait time, average response time and throughput). This study proposes a large-scale cost-saving and load-balancing scheduling model, called HDCBS, for the optimization of system throughput. First, queuing theory is used to model each computing node as an\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Solving time-varying linear inequalities by finite-time convergent zeroing neural networks\n", "abstract": " In this paper, to solve time-varying linear inequalities much faster, on basis of zeroing neural network (ZNN), two finite-time convergent ZNN (FTCZNN) models are proposed by exploiting two novel nonlinear activation functions (AFs). The first FTCZNN model is established by using the sign-bi-power AF which is termed as FTCZNN-S for presentation convenience. The second one is established by amending the sign-bi-power AF through adding a linear term, and called FTCZNN-SL. Compared with existing ZNN models for time-varying linear inequalities, the proposed two FTCZNN models possess prominent finite-time convergence performance. In addition, theoretical analysis is given to estimate the finite-time convergence upper bounds of those two FTCZNN models. Numerical comparative results ulteriorly validate the effectiveness and dominance of two FTCZNN models for finding the solution of time-varying\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Exploiting background divergence and foreground compactness for salient object detection\n", "abstract": " In this paper, we propose an efficient and discriminative saliency method that takes advantage of background divergence and foreground compactness. Concretely, a graph is first constructed by introducing the concept of virtual node to effectively enhance the distinction between nodes along object boundaries and the similarity among object regions. A reasonable edge weight is defined by incorporating low-level features as well as deep features extracted from deep networks to measure the relationship between different regions. To remove incorrect outputs, two computational mechanisms are then developed to extract reliable background seeds and compact foreground regions, respectively. The saliency value of a node is calculated by fully considering the relationship between the corresponding node and the virtual background (foreground) node. As a result, two types of saliency maps are obtained and\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Task offloading and service migration strategies for user equipments with mobility consideration in mobile edge computing\n", "abstract": " Recently, a great number of works have focused on task offloading optimization in mobile edge computing (MEC). However, rare works involve user equipment (UE) mobility. When involving mobility in MEC, the problem becomes even harder. Even a slight movement of UE can significantly affect the strategy and overhead of the UE. Usually, the types of UE mobility can be categorized as random mobility, short-term predictable mobility, and fully known mobility, depending on whether the future location of the UE is known. In this paper, we aim to optimize task offloading and service migration for UEs with different mobility considerations. Specifically, we try to find appropriate task offloading and service migration strategies to optimize energy consumption or latency of UEs according to the characteristics of different mobility types. We conduct extensive experiments using the real world data which records the movement\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Efficient processing of top k group skyline queries\n", "abstract": " For a given multi-dimensional data set, a group skyline query returns the optimal groups not dominated by any other group of equal size. The group skyline query is a powerful tool in many applications that call for optimal groups. However, it is common to return a large number of results which make users overwhelmed since it prevents them from making quick and rational decisions. To address this problem, we first identify and formulate a top k group skyline (T k GSky) query which returns k optimal groups dominating the highest number of points in the given data set. Next, new pruning strategies are presented to reduce the search space. Then, we propose efficient algorithms by exploiting novel techniques including a grouping strategy, a hybrid strategy, and a point-based replacement strategy, respectively. Finally, we also develop an approximate algorithm to further improve the T k GSky query performance. The\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Game-based multi-MD with QoS computation offloading for mobile edge computing of limited computation capacity\n", "abstract": " Mobile edge computing (MEC) is becoming a promising paradigm of providing cloud computing capabilities to the edge network, which can serve mobile devices (MDs) with computation-intensive and delay-sensitive tasks. Facing with high requirements of many MDs, it\u2019s essential for MEC with limited computation capacity to serve more MDs with QoS. For each mobile device, it is also desirable to have a low energy consumption with an expected deadline. To solve above problems, we propose a Game-based Computation Offloading (GCO) algorithm, which includes the task offloading profile and the transmission power controlling with the method of non-cooperative game. Our mechanism maximizes the number of served MDs with deadline, as well as minimizing the energy consumption of each MD whose task is executed on MEC. Specifically, Given the allocation of transmission power, a Greedy\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Automatically detecting excavator anomalies based on machine learning\n", "abstract": " Excavators are one of the most frequently used pieces of equipment in large-scale construction projects. They are closely related to the construction speed and total cost of the entire project. Therefore, it is very important to effectively monitor their operating status and detect abnormal conditions. Previous research work was mainly based on expert systems and traditional statistical models to detect excavator anomalies. However, these methods are not particularly suitable for modern sophisticated excavators. In this paper, we take the first step and explore the use of machine learning methods to automatically detect excavator anomalies by mining its working condition data collected from multiple sensors. The excavators we studied are from Sany Group, the largest construction machinery manufacturer in China. We have collected 40 days working condition data of 107 excavators from Sany. In addition, we worked with six excavator operators and engineers for more than a month to clean the original data and mark the anomalous samples. Based on the processed data, we have designed three anomaly detection schemes based on machine learning methods, using support vector machine (SVM), back propagation (BP) neural network and decision tree algorithms, respectively. Based on the real excavator data, we have carried out a comprehensive evaluation. The results show that the anomaly detection accuracy is as high as 99.88%, which is obviously superior to the previous methods based on expert systems and traditional statistical models. View Full-Text", "num_citations": "4\n", "authors": ["2184"]}
{"title": "CUSNTF: A scalable sparse non-negative tensor factorization model for large-scale industrial applications on multi-GPU\n", "abstract": " Given a high-order, large-scale and sparse data from big data and industrial applications, how can we acquire useful patterns in a real-time and low memory overhead manner? Sparse Non-negative tensor factorization (SNTF) possesses high-order representation, non-negativity and dimension reduction inherence. Thus, SNTF has become a useful tool to represent and analyze the sparse data, which has been incorporated with extra contextual information, ie, time and location, etc, more than the matrix, which can only model the 2 ways data. However, current SNTF techniques suffer from a) non-linear time and space overhead, b) intermediate data explosion, and c) inability on GPU and multi-GPU. To address these issues, a single-thread-based SNTF is proposed, which involves the feature elements rather than on the whole factor matrices, and can avoid the forming of large-scale intermediate matrices. Then, a\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Optimal temporal partitioning of a multicore server processor for virtual machine allocation\n", "abstract": " The problem of optimal temporal partitioning of a multicore server processor for virtual machine allocation in cloud computing is addressed as multivariable optimization problems and solved algorithmically and numerically. Analytical models for virtual machines are developed, i.e., partially available multi-server systems. The problem of optimal temporal partitioning of a multicore server processor for virtual machine allocation is formulated, where the overall performance (i.e., the average task response time) of a group of virtual machines is optimized. An algorithm is developed to solve the problem numerically. The problem of optimal temporal partitioning of a multicore server processor with power consumption constraint is also formulated and solved, where the overall performance of a group of virtual machines is optimized and the total power consumption of the virtual machines does not exceed certain available\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Message response time analysis for automotive cyber\u2013physicalsystems with uncertain delay: An m/ph/1 queue approach\n", "abstract": " The analysis problem of message response time is a key and challenging problem for in-vehicle networks that has gained much research attention in recent years. The arbitrated networked control system (ANCS), which is a special cyber\u2013physicalsystem (CPS), was recently designed for scheduling or arbitrating networks in a control system. A dominant feature of this CPS is the arbitration of messages on a shared communication medium. The control applications in an ANCS are sensitive to the end-to-end delay of message responses from sensors to actuators. In this study, a multi-hierarchical flexible TDMA/fixed priority scheduling policy is first adopted to configure the bus in an ANCS, which is based on the event trigger protocol. Then, an M/PH/1 queue model with random-sized batch arrivals is used to model the control application in the ANCS, and to obtain the stationary probability for each control application\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "SDN components and OpenFlow\n", "abstract": " Today\u2019s Internet suffers from ever-increasing challenges in scalability, mobility, and security, which calls for deep innovations on network protocols and infrastructures. However, the distributed controlling mechanism, especially the bundle of control plane and the data plane within network devices, sharply restricts such evolutions. In response, the software-defined networking (SDN), an emerging networking paradigm, proposes to decouple the control and data planes, producing logically centralized controllers, simple yet efficient forwarding devices, and potential abilities in functionalities programming. This chapter presents a short yet comprehensive overview of SDN components and the OpenFlow protocol on basis of both classic and latest literatures. The topics range from fundamental building blocks, layered architectures, novel controlling mechanisms, and design principles and efforts of OpenFlow switches.", "num_citations": "4\n", "authors": ["2184"]}
{"title": "MPOPE: Multi-provider order-preserving encryption for cloud data privacy\n", "abstract": " Order-preserving encryption (OPE) has been proposed as a privacy-preserving query method for cloud computing. Existing researches of OPE diverge into two groups. One group focuses on single data provider scenarios and achieves strong security notion such as indistinguishability under ordered chosen plaintext attack (IND-OCPA). Another group of research designs multi-provider schemes and provides weaker security guarantees than those of single provider schemes. In this paper, we propose a novel security notion for multi-provider scenario, indistinguishability under multi-provider ordered chosen plaintext attack (IND-MPOPCA), which guarantees equivalent security level as IND-OCPA while hiding the frequency of plaintexts and enabling multi-provider data submissions and queries. We develop a multi-provider randomized order technique to construct our MPOPE scheme to achieve the IND\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Cooperative routing in multi-radio multi-hop wireless network\n", "abstract": " There are many recent interests on cooperative communication (CC) in wireless networks. Despite the large capacity gain of CC in small wireless networks, CC can result in severe interference in large networks and even degraded throughput. The aim of this chapter is to concurrently exploit multi-radio and multi-channel (MRMC) and CC technique to combat co-channel interference and improve the performance of multi-hop wireless network. Our proposed solution concurrently considers cooperative routing, channel assignment, and relay selection and takes advantage of both MRMC technique and spatial diversity to improve the throughput. We propose two important metrics, contention-aware channel utilization routing metric (CACU) to capture the interference cost from both direct and cooperative transmission, and traffic aware channel condition metric (TACC) to evaluate the channel load condition. Based on these metrics, we propose three algorithms for interference-aware cooperative routing, local channel adjustment, and local path and relay adaptation, respectively, to ensure high-performance communications in dynamic wireless networks. Our algorithms are fully distributed and can effectively mitigate co-channel interference and achieve cooperative diversity gain. To our best knowledge, this is the first distributed solution that supports CC in MRMC networks. Our performance studies demonstrate that our algorithms can significantly increase the aggregate throughput.", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Distributed computing for functional safety of automotive embedded systems\n", "abstract": " The architectures of modern automobiles are heterogeneous distributed integrated architectures that integrate multiple heterogeneous processing units and network buses with a central gateway. Modern automotive embedded systems combine the related characteristics of real-time, cyber-physical, mixed-criticality, and heterogeneous distributed systems; moreover, such systems must meet specific functional safety requirements based on the ISO 26262 standard that was issued in 2011. The safe operation of automobiles must also be guaranteed and the lives of civilians inside and outside vehicles protected; thus, how to coincide with the functional safety requirements from the point of computing is a challenge. The main backbone of this chapter will discuss the distributed computing for functional safety of automotive embedded systems. We first describe the architectures of automobiles and then introduce their distributed functions and systems. We also propose distributed computing models of automobiles for the aforementioned architectures and systems. For the functional safety requirements provided in ISO 26262, we discuss the corresponding issues with distributed computing for schedulability analysis, real-time scheduling, reliability, and fault tolerance.", "num_citations": "4\n", "authors": ["2184"]}
{"title": "CPU-GPU computing: Overview, optimization, and applications\n", "abstract": " Heterogeneous and hybrid computing has been heavily studied in the field of parallel and distributed computing in recent years. It can work on a single computer, or in a group of computers connected by a high-speed network. The former is the topic of this chapter. Its key points are how to cooperatively use devices that are different in performance and architecture to satisfy various computing requirements, and how to make the whole program achieve the best performance possible when executed. CPUs and GPUs have fundamentally different design philosophies, but combining their characteristics could avail better performance in many applications. However, it is still a challenge to optimize them. This chapter focuses on the main optimization strategies including \u201cpartitioning and load-balancing\u201d,\u201cdata access\u201d,\u201ccommunication\u201d, and \u201csynchronization and asynchronization\u201d. Furthermore, two applications will be\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Energy Confirmable Overlapping Target Tracking Based on Compressive Sensing in Wireless Sensor Networks.\n", "abstract": " Localization is highly critical for wireless sensor network applications. The present paper makes the following noticeable contributions. First, an energy confirmable overlapping tracking algorithm for mobile targets is proposed in wireless sensor networks. Different from most target localization algorithms based on compressive sensing, it improves localization accuracy through overlapping area and predicting regions in online tracking phase. Second, theoretical analyses suggest that grids number in an overlapping area is related to energy consumption. By exploiting a common communication schedule, we derive the compressive sensing tracking for the solution and formulate the threshold of grids number and the energy consumption. Third, our algorithm shows good scalability. Since only the network topology information around the unknown nodes is used, it can be applied to large-scale wireless sensor networks. Finally, analytical studies and simulations are provided to show that our proposed approach achieves significant tracking accuracy in four different trajectories.", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Parallel techniques for large data analysis in the new version of a futures trading evaluation service\n", "abstract": " A futures trading evaluation system is used to help investors analyze their trading history and find out the root cause of profit and loss, so that investors can learn from their past and make better decisions in the future. To analyze trading history of investors, the system processes a large volume of transaction data to calculate key performance indicators (KPI) as well as time series behavior patterns, and concludes some recommendations with the help of an expert knowledge base. This work is based on our early work of parallel techniques for large data analysis for futures trading evaluation service. In our early work, we have used the query rewriting technique to avoid joining between fact table and dimension table for OLAP aggregation queries, and used a data driven shared scanning of data method to compute KPIs for one customer. However, the query rewriting technique cannot eliminate joining for queries\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Energy-aware schedulingwith reconstruction and frequency equalization on heterogeneous systems\n", "abstract": " With the increasing energy consumption of computing systems and the growing advocacy for green computing, energy efficiency has become one of the critical challenges in high-performance heterogeneous computing systems. Energy consumption can be reduced by not only hardware design but also software design. In this paper, we propose an energy-aware scheduling algorithm with equalized frequency, called EASEF, for parallel applications on heterogeneous computing systems. The EASEF approach aims to minimize the finish time and overall energy consumption. First, EASEF extracts the set of paths from an application. Then, it reconstructs the application based on the extracted set of paths to achieve a reasonable schedule. Finally, it adopts a progressive way to equalize the frequency of tasks to reduce the total energy consumption of systems. Randomly generated applications and two real\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Tool support for secure programming by security testing\n", "abstract": " Secure Programming Guidelines help to prevent developers from introducing vulnerabilities. But being just static text to be consulted now and then, the Guidelines are difficult to integrate in the implementation phase of software development, especially when developers are under pressure of delivering software for a deadline. In this paper, we present an IDE integration of security testing and static code analysis to detect vulnerabilities and known insecure coding patterns according to Secure Programming Guidelines. While security testing tools and static analyzers exist for security professionals, similar tools to be used by software engineers who are normally non security experts are missing. This automated tool support is non-intrusive during implementation by being fully integrated in the IDE developers use, efficient to not slow down the overall implementation effort, and extensible to consider different\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "SLA-based energy aware scheduling of precedence-constrained applications on DVFS-enabled clusters\n", "abstract": " The energy aware scheduling problem has been a critical issue in high-performance clusters owing to their high operation cost, environmental impact, and low reliability. An existing technique to reduce energy consumption of applications is dynamic voltage/frequency scaling (DVFS). In this paper, we develop an energy aware scheduling algorithm called EASLA for precedence-constrained applications in the context of Service Level Agreement (SLA) on DVFS-enabled cluster systems. Due to the dependencies among tasks and makespan extension, there may be some slacks under used. The main idea of the EASLA algorithm is to distribute each slack to a set of tasks and scale frequencies down to try to minimize energy consumption. Specifically, it first finds the maximum set of independent tasks for each task, and then iteratively allocates each slack to the maximum independent set whose total energy reduction\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Molecular solutions for minimum and exact cover problems in the tile assembly model\n", "abstract": " The tile assembly model is a novel biological computing model where information is encoded in DNA tiles. It is an efficient way to solve NP-complete problems due to its scalability and parallelism. In this paper, we apply the tile assembly model to solve the minimum and exact set cover problems, which are well-known NP-complete problems. To solve the minimum set cover problem, we design a MinSetCover system composed of three parts, i.e., the seed configuration subsystem, the nondeterministic choice subsystem, and the detection subsystem. Moreover, we improve the MinSetCover system and propose a MinExactSetCover system for solving the problem of exact cover by 3-sets. Finally we analyze the computation complexity and perform a simulation experiment to verify the effectiveness and correctness of the proposed systems.", "num_citations": "4\n", "authors": ["2184"]}
{"title": "A hybrid parallel tridiagonal solver on multi-core architectures\n", "abstract": " An optimized parallel algorithm is proposed to solve the problem occurred in the process of complicated backward substitution of cyclic reduction during solving tridiagonal linear systems. Adopting a hybrid parallel model, this algorithm combines the cyclic reduction method and the partition method. This hybrid algorithm has simple backward substitution on parallel computers comparing with the cyclic reduction method. In this paper, the operation count and execution time are obtained to evaluate and make comparison for these methods. On the basis of results of these measured parameters, the hybrid algorithm using the hybrid approach with a multi-threading implementation achieves better efficiency than the other parallel methods, i.e., the cyclic reduction and the partition methods. Among them, the cyclic reduction method is previously found to be the fastest algorithm in many ways for solutions. In particular, the\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "A Queueing Theory Based Approach to QoS-Driven Adaptation for Service Discovery over MANETs\n", "abstract": " Volatility and uncertainty characterizing mobile ad hoc networks (MANETs) demand that an efficient mechanism to discover currently available services in a MANET should be provided. Consequently, many service discovery systems over MANETs have been developed. However, most of them lack theoretical modeling and analysis, as well as the leveraging of the theoretical model for optimizing system design and improving quality of service (QoS). Aiming at our service discovery system SCN4M, this paper develops an M/M+/1 model for service discovery on MANET nodes. This model is first applied to predict system behaviors such as system throughput. Then, the model is applied to find the value of a control variable. If the calculated value is set at runtime, the system will provide the optimal QoS. Furthermore, the model is used for optimizing a system's adaptive mechanism so that the system can achieve the\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Reducing download times in peer-to-peer file sharing systems with stochastic service capacities\n", "abstract": " The main problem for an individual user peer in a peer-to-peer network with heterogeneous source peers is the peer selection problem, namely, switching among source peers and finally settling on one, while keeping the total time of probing and downloading to a minimum. There has been little investigation on selecting source peers with stochastic service capacities. The main contribution of this paper is to address the problem of reducing download times in peer-to-peer file sharing systems with stochastic service capacities. A precise analysis of the expected download time is given when the service capacity of a source peer is a random variable. A chunk-based switching and peer selection algorithm using the method of probing high-capacity peers is proposed and the expected download time of the algorithm is analyzed. Two sub problems of the optimal choice of the threshold of high-capacity source peers and\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Design and performance evaluation of communication algorithms in multihop wireless networks with multiple channels\n", "abstract": " We propose and evaluate the performance of communication algorithms for the NP-hard transmission time minimisation problem on multihop wireless networks modelled by directed graphs with multiple channels. We derive a lower bound for the minimum transmission time so that our heuristic solutions can be compared with optimal schedules. We present one randomised routing algorithm and nine heuristic transmission scheduling algorithms and demonstrate by extensive simulations on random multihop wireless networks that all these transmission scheduling algorithms have average-case performance reasonably close to that of optimal schedules. Furthermore, we show that the performance of our algorithms for undirected networks is significantly better than the pipelined breadth-first search tree algorithm by exploiting more transmission concurrency. We indicate that our transmission scheduling algorithms\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "A random-walk-based dynamic tree evolution algorithm with exponential speed of convergence to optimality on regular networks\n", "abstract": " In many tree-structured parallel computations, the size and shape of a tree that represents a parallel computation is unpredictable at compile-time. The tree evolves gradually during the course of the computation. When such an application is executed on a static network, the dynamic tree evolution problem is to distribute the tree nodes to the processors of the network such that all the processors receive roughly the same amount of load and that communicating nodes are assigned to neighboring processors. The main contributions of the paper are to describe a simple random-walk-based asymptotically optimal dynamic tree evolution algorithm on regular networks and to analyze the exponential speed at which the performance ratio converges to the optimal. Our strategy is to prove that the Markov chain of a random walk on a regular network is rapidly mixing.", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Analysis of randomized load distribution for reproduction trees in linear arrays and rings\n", "abstract": " High performance computing requires high quality load distribution of processes of a parallel application over processors in a parallel computer at runtime such that both maximum load and dilation are minimized. The performance of a simple randomized load distribution algorithm that dynamically supports tree-structured parallel computations on two simple static networks, namely, linear arrays and rings, is analyzed in this paper. The algorithm spreads newly created tree nodes to neighboring processors, which actually provides randomized dilation-1 tree embedding in a static network. We develop linear systems of equations that characterize expected loads on all processors, and find their closed form solutions under the reproduction tree model, which can generate trees of arbitrary size and shape. The main contribution of the paper is to show that the above simple randomized algorithm is able to generate high\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Probabilistic analysis of cyclic packet transmission scheduling in WDM optical networks\n", "abstract": " We study the packet transmission scheduling problem with tuning delay in wavelength-division multiplexed (WDM) optical communication networks with tunable transmitters and fixed-tuned receivers. By treating the numbers of packets as random variables, we conduct probabilistic analysis of the average-case performance ratio for the cyclic packet transmission scheduling algorithm. Our numerical data as well as simulation results demonstrate that the average-case performance ratio of cyclic schedules is very close to one for reasonable system configurations and probability distributions of the numbers of packets. In particular, when the number of receivers that share a channel and/or the granularity of packet transmission are large, the average-case performance ratio approaches one. Better performance can be achieved by overlapping tuning delays with packet transmission. We derive a bound for the\u00a0\u2026", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Probabilistic performance analysis of scheduling parallel tasks with precedence constraints on mesh connected multicomputers\n", "abstract": " We investigate the problem of scheduling parallel tasks with precedence constraints on mesh connected multicomputers. It is an open problem as to whether there exists an approximation algorithm that has a finite worst-case performance ratio. We propose a simple level scheduling algorithm LL as a first attempt to solve our problem. There are three basic techniques in algorithm LL, i.e., a layer by layer scheduling strategy to handle precedence constraints, the largest-job-first algorithm to schedule tasks in the same layer, and the two dimensional buddy system for system partitioning. Algorithm LL does not have a finite worst-case performance ratio. However, its average-case performance ratio is quite acceptable. It is shown that for wide task graphs and typical task size distributions, the asymptotic average-case performance ratio of algorithm LL is about two for all probability distributions of task execution times.", "num_citations": "4\n", "authors": ["2184"]}
{"title": "Reducing cumulative errors of incremental cp decomposition in dynamic online social networks\n", "abstract": " CANDECOMP/PARAFAC (CP) decomposition is widely used in various online social network (OSN) applications. However, it is inefficient when dealing with massive and incremental data. Some incremental CP decomposition (ICP) methods have been proposed to improve the efficiency and process evolving data, by updating decomposition results according to the newly added data. The ICP methods are efficient, but inaccurate because of serious error accumulation caused by approximation in the incremental updating. To promote the wide use of ICP, we strive to reduce its cumulative errors while keeping high efficiency. We first differentiate all possible errors in ICP into two types: the cumulative reconstruction error and the prediction error. Next, we formulate two optimization problems for reducing the two errors. Then, we propose several restarting strategies to address the two problems. Finally, we test the\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Estimating user influence ranking in independent cascade model\n", "abstract": " Nowadays, hundreds of millions of people use social networks to express their opinions and communicate with their friends. It is of importance to model and estimate the user influence in social networks. Since most studies perform Monte Carlo simulation to evaluate the user influence in the independent cascade model, which leads to tremendous computational costs, we introduce a duplicate forwarding model to characterize the diffusion process in social networks, and analyze the user influences below and above the diffusion threshold theoretically. After getting the user influence ranking, we propose a Spearman-like correlation coefficient to measure the correlation between two rankings, and find the analysis results from the duplicate forwarding model achieve much better accuracy than the measurements degree, betweenness, k-core and PageRank in estimating the user influence ranking in the independent\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Coalition formation for deadline-constrained resource procurement in cloud computing\n", "abstract": " To attract more customers, a cloud provider tends to give some discounts to a customer if he/she rents a plenty of resources. Under this situation, a group of customers who need homogeneous cloud instances with various deadlines are prone to purchasing resources in a collaborative manner, i.e., using a coalition game, to reduce purchase costs. It is essential to design a mechanism that enables all customers to voluntarily and happily collaborate while ensuring that each customer pays at the lowest cost possible. To address this issue, we propose a mechanism to show collaborative interactions between customers and determine the number of service programs purchased from each provider to charge each cloud customer a minimum cost. We establish a coalition game based on multi-customer resource procurement and prove that there exists a unique optimal solution in the coalition game, while satisfying\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Heuristic Computation Offloading Algorithms for Mobile Users in Fog Computing\n", "abstract": " The investigation in this article makes the following important contributions to combinatorial optimization of computation offloading in fog computing. First, we rigorously define the two problems of optimal computation offloading with energy constraint and optimal computation offloading with time constraint. We do this in such a way that between execution time and energy consumption, we can fix one and minimize the other. We prove that our optimization problems are NP-hard, even for very special cases. Second, we develop a unique and effective approach for solving the proposed combinatorial optimization problems, namely, a two-stage method. In the first stage, we generate a computation offloading strategy. In the second stage, we decide the computation speed and the communication speeds. This method is applicable to both optimization problems. Third, we use a simple yet efficient greedy method to\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Performance analysis of nonlinear activated zeroing neural networks for time-varying matrix pseudoinversion with application\n", "abstract": " By exploiting two simplified nonlinear activation functions, two zeroing neural network (ZNN) models are designed and studied to efficiently tackle the time-varying matrix pseudoinversion problem. Compared with ZNN activated by previously presented activation functions, these two simplified finite-time ZNN (SFTZNN) models (called SFTZNN1 and SFTZNN2) not only achieve faster finite-time convergence, but also possess better robustness. In addition, the SFTZNN1 and SFTZNN2 models have simpler structure compared with the widely used sign-bi-power activated ZNN model. Theoretical analysis is presented to obtain the maximum convergence time for the SFTZNN models in ideal conditions. Besides, when external perturbations are injected into the proposed SFTZNN models, upper bounds of the steady-state residual error are theoretically calculated. Comparative simulations and one engineering\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Hierarchical pooling strategy optimization for accelerating asymptomatic covid-19 screening\n", "abstract": " Testing has been a major factor that limits our response to the COVID-19 pandemic. The method of sample pooling and group test has recently been introduced and adopted. However, it is still not clearly known how to determine the appropriate group size. In this paper, we treat asymptomatic COVID-19 screening acceleration as an optimization problem, and solve the problem using an analytical approach and an algorithmic procedure. We develop a two-level hierarchical pooling strategy for accelerating asymptomatic COVID-19 screening. In the first level, a population is divided into groups, which results in inter-group acceleration. In the second level, a group is divided into subgroups, which results in intra-group and inter-subgroup acceleration. By using our analytical methods and numerical algorithms, we determine the optimal group size and the optimal subgroup size, which minimize the total number of tests\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Analysis of energy efficiency of a parallel AES algorithm for CPU-GPU heterogeneous platforms\n", "abstract": " Encryption plays an important role in protecting data, especially data transferred on the Internet. However, encryption is computationally expensive and this leads to high energy costs. Parallel encryption solutions using more CPU/GPU cores can achieve high performance. If we consider energy efficiency to be cost effective using parallel encryption solutions at the same time, this problem can be alleviated effectively. Because many CPU/GPU cores and encryption are pervasive currently, saving energy cost by parallel encrypting has become an unavoidable problem. In this paper, we propose an energy-efficient parallel Advance Encryption Standard (AES) algorithm for CPU-GPU heterogeneous platforms. These platforms, such as the Green 500 computers, are popular in both high performance and general computing. Parallelizing AES algorithm, using both GPUs and CPUs, balances the workload between CPUs\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Multi-view correlation tracking with adaptive memory-improved update model\n", "abstract": " Recently, some researchers concentrate on applying multi-view learning to the correlation filter tracking to achieve both the efficiency and accuracy. However, most of them fail to effectively collaborate multiple views to deal with more complex environment. Moreover, their methods are prone to drift in case of long-term occlusion due to the memory loss. In this paper, we propose a novel multi-view correlation filters-based tracker for robust visual tracking. First, we present an adaptive multi-view collaboration strategy to highlight different contributions of different views by jointly considering the reliability and discrimination. Second, an effective memory-improved model update rule is introduced to avoid falling into a contaminated target model. Compared with the conventional linear interpolation update rule, it can effectively deal with long-term occlusion by improving the memory of historical models. Furthermore\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Scheduling Parallel Applications on Heterogeneous Distributed Systems\n", "abstract": " Scheduling parallel applications on heterogeneous distributed systems is a classic research area in computer science and engineering. In recent years, with the emergence and development of embedded computing, cloud computing, and cyberphysical systems (CPS), this research area has shown renewed vitality, challenges, and breakthroughs. Today, heterogeneous distributed embedded systems (eg, automotive embedded systems) and heterogeneous distributed cloud systems (eg, cloud-based services, such as Amazon EC2) are typical scenarios of heterogeneous distributed systems. As advanced heterogeneous distributed systems, CPS further enhance the existing embedded and cloud systems. Specifically, automotive CPS (ACPS) and cyber-physical cloud systems (CPCS) are two types of CPS applied to the areas of embedded computing and cloud computing, respectively. These new distributed\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "HeteroYARN: a heterogeneous FPGA-accelerated architecture based on YARN\n", "abstract": " In recent years, the heterogeneous distributed platform integrating with FPGAs to accelerate computation tasks has been widely studied to deal with the deluge of data. However, most of current works suffer from poor universality and low resource utilization that run specific algorithms with the highly customized structure. Moreover, there are still many challenges, such as data curation, task scheduling, and resource management, which further limit the scalability of a CPU-FPGA distributed platform. In this paper, we present HeteroYARN, an FPGA-accelerated heterogeneous architecture based on YARN platform, which provides resource management and programming support for computing-intensive applications using FPGAs. In particular, the HeteroYARN abstracts FPGA accelerators as general resources and provides programming APIs to utilize those accelerators easily. Our HeteroYARN simplifies the request\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "D-SRTF: Distributed shortest remaining time first scheduling for data center networks\n", "abstract": " Many recent works utilize scheduling to minimize the Flow Completion Time (FCT) in Data Center Networks (DCN), like PIAS using Shortest Job First (SJF) scheduling and pFabric using Shortest Remaining Size First (SRSF) scheduling. However, they only consider the flow size information, without consideration of available bandwidth of the network, leading to inferior performance when the network is congested. Besides, information on flow size is hard to obtain in practice. Moreover, although a centralized scheduler may have optimal scheduling decisions, it suffers from high system overhead. Therefore, a new DCN scheme is expected which is deployment-friendly and implements SRTF scheduling in a distributed manner. In this paper, we propose D-SRTF, a light-weight yet effective DCN scheme to implement SRTF scheduling. D-SRTF determines the remaining time of each flow according to the estimated\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Energy constrained scheduling of stochastic tasks\n", "abstract": " Energy-efficient scheduling of stochastic tasks is considered in this paper. The main characteristic of a stochastic task is that its execution time is a random variable whose actual value is not known in advance, but only its probability distribution. Our performance measures are the probability that the total execution time does not exceed a given bound and the probability that the total energy consumption does not exceed a given bound. Both probabilities need to be maximized. However, maximizations of the two performance measures are conflicting objectives. Our strategy is to fix one and maximize the other. Our investigation includes the following two aspects, with the purpose of maximizing the probability for the total execution time not to exceed a given bound, under the constraint that the probability for the total energy consumption not to exceed a given bound is at least certain value. First, we explore the\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "EDS: An Efficient Data Selection policy for search engine storage architectures\n", "abstract": " Caching is an effective optimization in search engine storage architectures. Many caching algorithms have been proposed to improve retrieval performance. The data selection policy of search engine cache management plays an important role, which carefully places the data in memory or other storage, such as solid state disks (SSDs). Considering that the historical query log has a guiding role for the future query, we present an Efficient Data Selection (EDS) policy for search engine cache management, which views cache media as a knapsack, and views results and posting lists as items. The best benefit of EDS can be computed by greedy algorithms. We carry out a series of experiments to study the essential factors of the data selection in different architectures, including hard disk drive (HDD), SSD, and SSD-based hybrid storage architectures. The hybrid storage architecture is a two-level cache architecture\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Velocity-aware parallel encryption algorithm with low energy consumption for streams\n", "abstract": " In the environment of cloud computing, the data produced by massive users form a data stream and need to be protected by encryption for maintaining confidentiality. Traditional serial encryption algorithms are poor in performance and consume more energy without considering the property of streams. Therefore, we propose a velocity-aware parallel encryption algorithm with low energy consumption (LECPAES) for streams in cloud computing. The algorithm parallelizes Advanced Encryption Standard (AES) based on heterogeneous many-core architecture, adopts a sliding window to stabilize burst flows, senses the velocity of streams using the thresholds of the window computed by frequency ratios, and dynamically scales the frequency of Graphics Processing Units (GPUs) to lower down energy consumption. The experiments for streams at different velocities and the comparisons with other related algorithms\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Accomplishing information consistency under OSPF in general networks\n", "abstract": " In this paper, we design an LAP based routing algorithm in General Networks (GN) to solve the problem of information consistency of the full network under OSPF with the following operations: (i) decomposing GN into one or more Single-link Networks (SNs) with the approach of depth-first walk, (ii) re-composting the SNs to a network with regular topology structure by adding links, (iii) searching the undirected complete graph of three nodes round by round until it converges to a simple network topology based on region binding, and (iv) processing different converged network topologies with different LAP based routing algorithms. The proposed algorithm is compared with Dijkstra algorithm over some random network topologies. Simulation results show that the proposed algorithm can solve the problem of information consistency of the full network under OSPF and has better performance than Dijkstra algorithm.", "num_citations": "3\n", "authors": ["2184"]}
{"title": "A hybrid skin detection model from multiple color spaces based on a dual-threshold Bayesian algorithm\n", "abstract": " As a preliminary step of many applications, skin detection serves as an irreplaceable role in image processing applications, such as face recognition, gesture recognition, web image filtering, and image retrieval systems. Combining information from multiple color spaces improves the recognition rate and reduces the error rate because the same color is represented differently in other color spaces. Consequently, a hybrid skin detection model from multiple color spaces based on a dual-threshold Bayesian algorithm (DTBA) has been proposed. In each color space, the pixels of images are divided into three categories, namely, skin, nonskin, and undetermined, when using the DTBA. Then, nearly all skin pixels are obtained by using a specific rule that combines the recognition results from multiple color spaces. Furthermore, skin texture filtering and morphological filtering are applied to the results by effectively\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "A modified multiple alignment fast Fourier transform with higher efficiency\n", "abstract": " Multiple sequence alignment (MSA) is the most common task in bioinformatics. Multiple alignment fast Fourier transform (MAFFT) is the fastest MSA program among those the accuracy of the resulting alignments can be comparable with the most accurate MSA programs. In this paper, we modify the correlation computation scheme of the MAFFT for further efficiency improvement in three aspects. First, novel complex number based amino acid and nucleotide expressions are utilized in the modified correlation. Second, linear convolution with a limitation is proposed for computing the correlation of amino acid and nucleotide sequences. Third, we devise a fast Fourier transform (FFT) algorithm for computing linear convolution. The FFT algorithm is based on conjugate pair split-radix FFT and does not require the permutation of order, and it is new as only real parts of the final outputs are required. Simulation results show\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "An iteration\u2010based hybrid parallel algorithm for tridiagonal systems of equations on multi\u2010core architectures\n", "abstract": " An optimized parallel algorithm is proposed to solve the problem occurred in the process of complicated backward substitution of cyclic reduction during solving tridiagonal linear systems. Adopting a hybrid parallel model, this algorithm combines the cyclic reduction method and the partition method. This hybrid algorithm has simple backward substitution on parallel computers comparing with the cyclic reduction method. In this paper, the operation count and execution time are obtained to evaluate and make comparison for these methods. On the basis of results of these measured parameters, the hybrid algorithm using the hybrid approach with a multi\u2010threading implementation achieves better efficiency than the other parallel methods, that is, the cyclic reduction and the partition methods. In particular, the approach involved in this paper has the least scalar operation count and the shortest execution time on a multi\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Bi-objective optimization genetic algorithm of the energy consumption and reliability for workflow applications in heterogeneous computing systems\n", "abstract": " Most recently existing studies pay too much attention on low energy consumption or execution time for tasks with precedence constraint in heterogeneous computing systems. In most cases, system reliability is more important than other performance metrics. Energy consumption and system reliability are two conflicting objectives. In this study, we present a novel bi-objective genetic algorithm (BOGA) to pursuit low energy consumption and high system reliability simultaneously. The proposed BOGA can offer the users more flexibility to submit their jobs to a data center. In the comparison with excellent algorithms multi-objective heterogeneous earliest finish time (MOHEFT) and Multi-objective Differential Evolution (MODE), BOGA is significantly better in terms of finding spread of compromise solutions.", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Modelling and optimizing bandwidth provision for interacting cloud services\n", "abstract": " Non-deterministic communication patterns among interacting Cloud services impose a challenge in determining appropriate bandwidth provision to satisfy the communication demands. This paper aims to address this challenge and develops a Communication Input-Output (CIO) model to capture data communication produced by Cloud services. The proposed model borrows the ideas from the Leontief\u2019s Input-Output Model in economy. Based on the model, this paper develops a method to determine the bandwidth provision for individual VMs that host a service. We further develop a Communication-oriented Simulated Annealing (CSA) algorithm, which takes an initial VM-to-PM mapping as input and finds the mapping with the minimal bandwidth provision and without increasing the PM usage in the initial mapping. Experiments have been conducted to evaluate the effectiveness and efficiency of the CIO\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Options detection in security protocols\n", "abstract": " The embodiments provide an apparatus for detecting configuration options including an option detector configured to receive a basic model of a security protocol and a set of options, where each option is a variation of the basic model. The option detector is configured to detect which options are configured in an implementation of at least one at least one security protocol entity based on the basic model and the set of options.", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Integration testing of communicating systems with unknown components\n", "abstract": " The verification of a modular system composed of communicating components is a difficult problem, especially when the formal specifications, i.e. models of the components are not available. Conventional testing techniques are not efficient in detecting erroneous interactions of components because interleavings of internal events are difficult to reproduce in a modular asynchronous system. The problem of detecting intermittent errors and other compositional flaws in the absence of components\u2019 models is addressed in this paper. A method for inferring a controllable approximation of communicating components through testing is elaborated. The inferred finite state models of components are used to detect compositional problems in the system through reachability analysis. To confirm a flaw in a particular component, a witness trace is used to construct a test applied to the component in isolation. The models\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Analysis of file download time in peer-to-peer networks with stochastic and time-varying service capacities\n", "abstract": " The service capacities of a source peer at different times in a peer-to-peer (P2P) network exhibit temporal correlation. Unfortunately, there is no analytical result which clearly characterizes the expected download time from a source peer with stochastic and time-varying service capacity. The main contribution of this paper is to analyze the expected file download time in P2P networks with stochastic and time-varying service capacities. The service capacity of a source peer is treated as a stochastic process. Analytical results which characterize the expected download time from a source peer with stochastic and time-varying service capacity are derived for the autoregressive model of order 1. Simulation results are presented to validate our analytical results. Numerical data are given to show the impact of the degree of correlation and the strength of noise on the expected file download time. For any chunk allocation\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Node placement analysis for overlay networks in IoT applications\n", "abstract": " The Internet of Things (IoT), which combines identification, sensing, computing, and communication technologies, is considered one of the major trends in information and communication technologies. Communication performance is critical for IoT applications. According to previous research, an internet-based overlay model is feasible for the implementation of the IoT. One important issue in the overlay routing model is the overlay node placement problem (ONPP). Once the size of overlay node set is fixed to a particular number k, the ONPP changes to k-ONPP. In this work, the IoT-based overlay node placement problem is formulized and analyzed. The major contributions of the paper include providing the time complexity of multi hop k-ONPP and its theoretical limit boundary of approximation ratio and proposing a local search algorithm. Furthermore, the time complexity and approximation ratio boundary of the\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Design and evaluation of a new approach to RAID-0 scaling\n", "abstract": " Scaling up a RAID-0 volume with added disks can increase its storage capacity and I/O bandwidth simultaneously. For preserving a round-robin data distribution, existing scaling approaches require all the data to be migrated. Such large data migration results in a long redistribution time as well as a negative impact on application performance. In this article, we present a new approach to RAID-0 scaling called FastScale. First, FastScale minimizes data migration, while maintaining a uniform data distribution. It moves only enough data blocks from old disks to fill an appropriate fraction of new disks. Second, FastScale optimizes data migration with access aggregation and lazy checkpoint. Access aggregation enables data migration to have a larger throughput due to a decrement of disk seeks. Lazy checkpoint minimizes the number of metadata writes without compromising data consistency. Using several real system\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Downlink data transmission scheduling algorithms in wireless networks\n", "abstract": " The problem of downlink data transmission scheduling in wireless networks is studied. It is pointed out that every downlink data transmission scheduling algorithm must have two components to solve the two subproblems of power assignment and transmission scheduling. Two types of downlink data transmission scheduling algorithms are proposed. In the first type, power assignment is performed before transmission scheduling. In the second type, power assignment is performed after transmission scheduling. The performance of two algorithms of the first type which use the equal power allocation method are analyzed. It is shown that both algorithms exhibit excellent worst-case performance and asymptotically optimal average-case performance under the condition that the total transmission power is equally allocated to the channels. In general, both algorithms exhibit excellent average-case performance. It is\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Performance optimization with energy constraint in heterogeneous multiple computer systems\n", "abstract": " The problem of minimizing average task response time in heterogeneous multiple computer systems with energy constraint is considered. The average task response time in an entire system of multiple computers is formulated as a function of power allocations to the computers. The average task response time is minimized subjected to the constraint that the expected energy consumption of all the computers over certain period of time does not exceed a given energy budget. The minimization problem is solved by finding an optimal power allocation to the computers. An algorithm is developed to solve our optimization problem.", "num_citations": "3\n", "authors": ["2184"]}
{"title": "SERENITY aware system development process\n", "abstract": " Traditionally, security patterns have successfully been used to describe security and dependability. In the SERENITY Project the notion of security and dependability (S&D) pattern has been extended to exact specifications of re-usable security mechanisms for Ambient Intelligence (AmI) systems. These S&D Patterns include information on the security properties satisfied by the solution and on the context conditions to be fulfilled. This chapter presents the development of applications supported by SERENITY. In the context of SERENITY we refer to these applications as Serenity-aware applications. Firstly, this chapter presents the Serenity-aware application design using S&D Artefacts. Secondly, it proposes a Java Application Programming Interface (API) to be used in the application development. And, finally, it introduces the development of an example Serenity-aware application.", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Average-case performance analysis of scheduling random parallel tasks with precedence constraints on mesh connected multicomputer systems\n", "abstract": " We investigate the problem of scheduling parallel tasks with precedence constraints on mesh connected multicomputer systems. It is still an open problem on whether there exists an approximation algorithm with finite asymptotic worst-case and/or average-case performance bound for this scheduling problem. As an early attempt to solve our problem, we propose and analyze the performance of a level-by-level scheduling algorithm LL. In fact, we solve a special case of the problem when all tasks request for square submeshes and run on a square mesh system whose size is a power of 2. There are three basic techniques in algorithm LL, i.e., the level-by-level scheduling strategy for handling precedence constraints, the largest-task-first algorithm for scheduling tasks in the same level, and the two-dimensional buddy system for system partitioning and processor allocation. Algorithm LL does not have a finite worst\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Design and analysis of asymptotically optimal randomized tree embedding algorithms in Static Networks\n", "abstract": " The problem of dynamic tree embedding in static networks is studied in this paper. We provide a unified framework for studying the performance of randomized tree embedding algorithms which allow a newly created tree node to take a random walk of short distance to reach a processor nearby. In particular, we propose simple randomized algorithms on several most common and important static networks, including d-dimensional meshes, d-dimensional tori, and hypercubes. It is shown that these algorithms, which have small constant dilation, are asymptotically optimal for embedding healthy trees. Our analysis technique is based on random walks on static networks. Hence, analytical expressions for expected load on all the processors are available.", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Fast and scalable parallel matrix computations with reconfigurable pipelined optical buses\n", "abstract": " We present fast and highly scalable parallel computations for a number of important and fundamental matrix problems on linear arrays with reconfigurable pipelined optical bus systems. These problems include computing the powers, the inverse, the characteristic polynomial, the determinant, the rank and an LU- and a QR-factorization of a matrix; multiplying a chain of matrices; and solving linear systems of equations. These computations are based on efficient implementation of the fastest sequential matrix multiplication algorithm, and are highly scalable over a wide range of system size. Such fast and scalable parallel matrix computations were not seen before on distributed memory parallel computing systems.", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Selection algorithms for anycast relay routing\n", "abstract": " Anycast has been applied widely in service discovery and replicated service. Current researches on anycast routing mainly focus on the scenario that the anycast server is the final destination in a communication session. In this paper, we explore another scenario where anycast is applied for relay routing, and addresses the problem of selecting among the anycast relay routers. After analyzing the characteristics of anycast relay routing distinguished from general anycast routing, we present three selection algorithms for anycast relay routing, namely nearest to source, nearest to destination and random selection. Based on the results of probability analysis and simulation, we compare the performance of each algorithm, analyze how the placement and the number of relay routers impact the performance of selection algorithms, and further discuss how to apply these selection algorithms and how many relay routers\u00a0\u2026", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Efficient algorithms for fault-tolerant communication in optical WDM networks\n", "abstract": " Addresses the problem of efficient communication in unreliable multi-hop optical networks supported by wavelength division multiplexing (WDM). We first define a new cost model for routing in (optical) WDM networks that is more general and realistic than the existing models. Our model takes into consideration not only the cost of wavelength access and conversion but also the cost for wavelength switching when several optical channels of the same wavelength arrive at the same node. We then propose a set of efficient algorithms in both reliable and unreliable WDM networks on the new cost model respectively for each of three important communication patterns-multiple point-to-point routing, multicast and multiple multicast.", "num_citations": "3\n", "authors": ["2184"]}
{"title": "Task migration optimization for guaranteeing delay deadline with mobility consideration in mobile edge computing\n", "abstract": " Mobile edge computing (MEC) is envisioned to integrate cloud-like capabilities into the edge of networks for improving quality of service (QoS). This makes it possible for users with resource-limited devices to execute computation-intensive tasks by offloading them to MEC nodes. Extensive works have been done for MEC. However, few of them involve user mobility. Whether to migrate task dynamically cannot be ignored when taking QoS into account. In this paper, we try to optimize task migration with user mobility consideration, in which deadlines of tasks are also involved. The problem is proved to be NP-hard. To solve it, we analyze three variants of this problem and devise a group migration (GM) algorithm with known trajectories of users. Our goal is to maximize the number of tasks whose deadlines are guaranteed. Extensive experiments are carried out, and the results confirm that GM algorithm can achieve up\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Zeroing neural network with comprehensive performance and its applications to time-varying Lyapunov equation and perturbed robotic tracking\n", "abstract": " The time-varying Lyapunov equation is an important problem that has been extensively employed in the engineering field and the Zeroing Neural Network (ZNN) is a powerful tool for solving such problem. However, unpredictable noises can potentially harm ZNN\u2019s accuracy in practical situations. Thus, the comprehensive performance of the ZNN model requires both fast convergence rate and strong robustness, which are not easy to accomplish. In this paper, based on a new neural dynamic, a novel Noise-Tolerance Finite-time convergent ZNN (NTFZNN) model for solving the time-varying Lyapunov equations has been proposed. The NTFZNN model simultaneously converges in finite time and have stable residual error even under unbounded time-varying noises. Furthermore, the Simplified Finite-te convergent Activation Function (SFAF) with simpler structure is used in the NTFZNN model to reduce model\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Stochastic Client Selection for Federated Learning with Volatile Clients\n", "abstract": " Federated Learning (FL), arising as a novel secure learning paradigm, has received notable attention from the public. In each round of synchronous FL training, only a fraction of available clients are chosen to participate and the selection decision might have a significant effect on the training efficiency, as well as the final model performance. In this paper, we investigate the client selection problem under a volatile context, in which the local training of heterogeneous clients is likely to fail due to various kinds of reasons and in different levels of frequency. Intuitively, too much training failure might potentially reduce the training efficiency, while too much selection on clients with greater stability might introduce bias, and thereby result in degradation of the training effectiveness. To tackle this tradeoff, we in this paper formulate the client selection problem under joint consideration of effective participation and fairness. Further, we propose E3CS, a stochastic client selection scheme on the basis of an adversarial bandit solution, and we further corroborate its effectiveness by conducting real data-based experiments. According to the experimental results, our proposed selection scheme is able to achieve up to 2x faster convergence to a fixed model accuracy while maintaining the same level of final model accuracy, in comparison to the vanilla selection scheme in FL.", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Incentive Mechanisms for Crowdsensing: Motivating Users to Preprocess Data for the Crowdsourcer\n", "abstract": " Crowdsensing is a popular method that leverages a crowd of sensor users to collect data. For many crowdsensing applications, the collected raw data need to be preprocessed before further analysis, and the preprocessing work is mainly done by the crowdsourcer. However, as the amount of collected data increases, this type of preprocessing approach has many disadvantages. In this article, we construct monetary-based incentive mechanisms to motivate users to preprocess the collected raw data for the crowdsourcer. For two common crowdsensing scenarios, we propose two system models, which are the single-task-multiple-participants (STMP) model and the multiple-tasks-multiple-participants (MTMP) model. In the STMP model, we design an incentive mechanism based on game theory and prove that there is a Nash equilibrium. In the MTMP model, we develop an incentive mechanism based on an auction\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Generating video animation from single still image in social media based on intelligent computing\n", "abstract": " Bringing a single still image into reality is a challenging topic in computer animation because the driven and structural information in single still image is inadequate. In this paper, we present an image animating method for enhancing single still image in social media with virtual realistic and animated motions without prior information. We imitate the interaction between the active objects in an image and their neighboring passive objects. The existing actions in the image and the virtual specified force are employed to animate the active objects. Observing that the change between two subsequent motions of the active objects derives a motion tendency, we can calculate a virtual driving force based on the motion tendency. By virtue of the virtual driving force, the stochastic motion texture is used to animate the passive objects. Finally, the convolutional neural network is employed to optimize the virtual motion\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "CoExe: an efficient co-execution architecture for real-time neural network services\n", "abstract": " End-to-end latency is sensitive for user-interactive neural network (NN) services on clouds. For periods of high request load, co-locating multiple NN requests has the potential to reduce end-to-end latency. However, current batch-based accelerators lack request-level parallelism support, leaving the queuing time non-optimized. Meanwhile, naively partitioning resources for simultaneous requests suffers from longer execution time as well as lower resource efficiency because different applications utilize separate resources without sharing. To effectively reduce the end-to-end latency for real-time NN requests, we propose CoExe architecture, equipped with a pipeline implementation of a sparsity-driven real-time co-execution model. By leveraging the non-trivial amount of sparse operations during concurrent NNs execution, the end-to-end latency is decreased by up to 12.3\u00d7 and 2.4\u00d7 over Eyeriss-like and SCNN at\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Novel fairness-aware co-scheduling for shared cache contention game on chip multiprocessors\n", "abstract": " Threads running on different cores of chip multiprocessors (CMP) can cause thread performance degradation due to contention for shared resources such as shared L2 cache. Some studies have shown that thread co-scheduling can effectively reduce contention for shared resources. However, in a multi-core system with shared caches, mutual interference between threads is unpredictable. As the number of cores increases, we are unlikely to exhaust all possible co-scheduling schemes. In this paper, a novel fairness-aware thread co-scheduling algorithm base on non-cooperative game is proposed to reduce L2 cache misses. We tried to improve the overall performance of the system by scheduling threads fairly. The originality of this work is to model thread scheduling using a non-cooperative game. The execution time of a thread varies depending on which threads are running on other cores of the same chip\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "A half-precision compressive sensing framework for end-to-end person re-identification\n", "abstract": " Compressive sensing (CS) approaches are useful for end-to-end person re-identification (Re-ID) in reducing the overheads of transmitting and storing video frames in distributed multi-camera systems. However, the reconstruction quality degrades appreciably as the measurement rate decreases for existing CS methods. To address this problem, we propose a half-precision CS framework for end-to-end person Re-ID named HCS4ReID, which efficiently recoveries detailed features of the person-of-interest regions in video frames. HCS4ReID supports half-precision CS sampling, transmitting and storing CS measurements with half-precision floats, and CS reconstruction with two measurement rates. Extensive experiments implemented on the PRW dataset indicate that the proposed HCS4ReID achieves 1.55 speedups over the single-precision counterpart on average for the CS sampling on an Intel HD Graphics\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "A parallel algorithm for bayesian text classification based on noise elimination and dimension reduction in spark computing environment\n", "abstract": " The Naive Bayesian algorithm is one of the ten classical algorithms in data mining, which is widely used as the basic theory for text classification. With the high-speed development of the Internet and information systems, huge amount of data are being produced all the time. Some problems are certain to arise when the traditional Bayesian classification algorithm addresses massive amount of data, especially without the parallel computing framework. This paper proposes an improved Bayesian algorithm INBCS, for text classification in the Spark computing environment and improves the Naive Bayesian algorithm based on a polynomial model. For the data preprocessing, this paper first proposes a parallel noise elimination algorithm, and then proposes another parallel dimension reduction algorithm based on Information Gain and TextRank computation in the Spark environment. Based on these\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "A Distributed Compressive Data Gathering Framework For Mobile Crowdsensing\n", "abstract": " Existing work on data gathering in mobile crowdsensing (MCS) usually assumes that the motion of the participants is either known or predictable via a mobility model. As such, the organizers can tell them when/where to sense, ensuring the data can be gathered from the target area with a minimized number of participants. Knowing exactly where the participants go, however, is not trivial, since the movements of the participants are in fact autonomous and random. In this paper, we investigate a common compressive data gathering framework for MCS, without trying to predict how a specific participant moves. We notice a key observation: while the participants move autonomously in the target sensing area, each trajectory itself provides a random, and thus valuable coverage for a sensing task. With compressive sensing (CS), these random trajectories can be utilized to exploit the spatio-temporal data correlation\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Real-time incremental recommendation for streaming data based on apache flink\n", "abstract": " Collaborative filtering (CF), one of the most famous methods for building recommendation systems, recommends relevant items to users or predicting ratings of users\u2019 unknown items. Matrix factorization (MF) models are well-known model to deal with predicting the rating problem. However, the recommendation system based on matrix factorization is hard to keep up with the rapidly changing real-world data. When ratings on new users or new items come, the static model can not fit well on new data. As a consequence, if the current thing does not apply, the prediction accuracy will lose. In addition, it is a significant computation cost to rebuild the model on the whole data. To capture these changes, in this paper, we construct an online-and-offline Collaborative Filtering with a multi-method model to improve the traditional CF method, called Online SGD with Offline Knowledge (OSGDO for short). Besides, we propose a\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "ISAECC: An improved scheduling approach for energy consumption constrained parallel applications on heterogeneous distributed systems\n", "abstract": " Power-aware task scheduling on processors has been a hot topic. In this paper, we study the problem of minimizing the schedule length for energy consumption constrained parallel applications on heterogeneous distributed systems. Previous work (solving this problem) adopts a policy that preassigns the minimum energy consumption for each unassigned task. Nevertheless, our analysis reveals that such a preassignment policy could be unfair, and it may not achieve an optimistic schedule length. Motivated by this, we propose a new task scheduling algorithm that suggests a weight-based mechanism to preassign energy consumption for unassigned tasks. We theoretically prove that our preassignment mechanism can guarantee the energy consumption constraint. Also, we have conducted extensive experiments based on two real parallel applications. The results consistently demonstrate that, compared to state\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Toward energy-efficiency optimization of pktgen-DPDK for green network testbeds\n", "abstract": " The packet generator (pktgen) is a fundamental module of the majority of software testers used to benchmark network protocols and functions. The high performance of the pktgen is an important feature of Future Internet Testbeds, and DPDK is a network packet accelerated platform, so we can use DPDK to improve performance. Meanwhile, green computing is advocated for in the future of the internet. Most existing efforts have contributed to improving either performance or accuracy. We, however, shifted the focus to energy-efficiency. We find that high performance comes at the cost of high energy consumption. Therefore, we started from a widely used high performance schema, deeply studying the multi-core platform, especially in terms of parallelism, core allocation, and frequency controlling. On this basis, we proposed an AFfinity-oriented Fine-grained CONtrolling (AFFCON) mechanism in order to improve\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "A multiple kernel density clustering algorithm for incomplete datasets in bioinformatics\n", "abstract": " While there are a large number of bioinformatics datasets for clustering, many of them are incomplete, i.e., missing attribute values in some data samples needed by clustering algorithms. A variety of clustering algorithms have been proposed in the past years, but they usually are limited to cluster on the complete dataset. Besides, conventional clustering algorithms cannot obtain a trade-off between accuracy and efficiency of the clustering process since many essential parameters are determined by the human user\u2019s experience. The paper proposes a Multiple Kernel Density Clustering algorithm for Incomplete datasets called MKDCI. The MKDCI algorithm consists of recovering missing attribute values of input data samples, learning an optimally combined kernel for clustering the input dataset, reducing dimensionality with the optimal kernel based on multiple basis kernels, detecting cluster centroids with the Isolation Forests method, assigning clusters with arbitrary shape and visualizing the results. Extensive experiments on several well-known clustering datasets in bioinformatics field demonstrate the effectiveness of the proposed MKDCI algorithm. Compared with existing density clustering algorithms and parameter-free clustering algorithms, the proposed MKDCI algorithm tends to automatically produce clusters of better quality on the incomplete dataset in bioinformatics.", "num_citations": "2\n", "authors": ["2184"]}
{"title": "An efficient method for optimizing PETSc on the sunway taihulight system\n", "abstract": " High performance computing platforms can bring us great benefits on processing various ubiquitous computing tasks. The Sunway TaihuLight supercomputer is a novel high performance computing platform, which is ranked No. 1 among the TOP500 list in the world. In this paper, we focus on how to optimize the Portable and Extensible Toolkit for Scientific computation (PETSc), running on supercomputers. The main motivations for this study are twofold: (i) PETSc is widely and frequently used in many scientific research fields such as biology, fusion, artificial intelligence, geosciences, etc; and (ii) the current nuclear PETSc does not fully utilize the potential of the Sunway TaighLight system, especially its powerful processor, i.e., SW26010 processor. To achieve high efficiency of PETSc, the central idea of our optimizations is to fully promote the performance of time-consuming and frequently used computation\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Experimental study of energy and time constrained task scheduling with irregular speed and power levels\n", "abstract": " We consider energy and time constrained scheduling of independent sequential tasks on a multiprocessor computer with bounded and discrete and irregular clock frequency and supply voltage and execution speed and power consumption levels. This is a very realistic power consumption model. However, it is very difficult to find useful information about the optimal solutions which are critical in evaluating the performance of heuristic algorithms. Our approach in this paper has two unique features. First, we develop algorithms that are applicable to all multiprocessor computers with bounded and discrete and irregular clock frequency and supply voltage and execution speed and power consumption levels. Second, we evaluate the performance of these algorithms on multiprocessors with a regular or close-to-regular power consumption model, for which, we have lower bounds for the optimal solutions. By using these\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Speeding Up VM Startup by Cooperative VM Image Caching\n", "abstract": " Virtual machine (VM) management is at the core of virtualized cloud data centers. Among others, how to reduce the startup delay of VMs is a key issue for improving user experience and resource utility. In this paper, we study this issue by jointly considering VM placement and VM image caching. We formulate the joint placement problem and design several joint algorithms, including both online and offline algorithms, to speed up VM startup. In our design, we adopt the cooperative caching approach, where image cache copies are shared among physical machines (PMs) so as to reduce image retrieval time. The key point of our algorithms lies in how to appropriately place VM image cache among PMs so as to speed up VM startup as much as possible. The proposed algorithms are evaluated by extensive simulations via SimGrid. The results show that our algorithms can achieve shorter startup delay in most cases\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Energy\u2010efficient fuzzy control model for GPU\u2010accelerated packet classification\n", "abstract": " As a core component of many network infrastructures, packet classification requires matching packet headers against a series of predefined rules. Its performance determines, to some extent, how fast packets can be processed. There already exists many proposals, which optimize the throughput of packet classification, but few of them take power consumption into account. To meet the requirements of green network computing, this paper focuses on energy\u2010efficient solutions that provide reasonable throughput as well. Similar to recent advancements, the graphics processing unit (GPU) is adopted to accelerate rule matching. Then, inspired by the frequency\u2010variable energy\u2010consuming model for air conditioners, a fuzzy control\u2013based energy efficiency optimizing model is proposed for GPU\u2010accelerated packet classification. As demonstrated in the evaluation experiments, when the GPU is in the idle status, the\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "DHCRF: A Distributed Conditional Random Field Algorithm on a Heterogeneous CPU-GPU Cluster for Big Data\n", "abstract": " As one of the most recognized models in machine learning, the conditional random fields (CRF) has been widely used in many applications. As the parameter estimation of CRF is highly time-consuming, how to improve the performance of CRF has received significant attention, in particular in the big data environment. To deal with large-scale data, CPU-based or GPU-based parallelization solutions have been proposed to improve performance. However, the problem is an ongoing one. In this paper, we focus on the big data environment and propose a distributed CRF on a heterogeneous CPU-GPU cluster called DHCRF. Our approach differs from previous work. Specifically, it leverages a three-stage heterogeneous Map and Reduce operation to improve the performance, making full use of CPU-GPU collaborative computing capabilities in a big data environment. Furthermore, by combining elastic data partition\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "One platform rules all: From Hadoop 1.0 to Hadoop 2.0 and Spark\n", "abstract": " In the big data era, traditional relational database systems cannot effectively handle the big volume of data due to their limited scalability. People are seeking new ways to tackle the problem of big data. After Google published its work of MapReduce, Hadoop (an open-source implementation of 192MapReduce) has risen to be the de facto standard tool for big data processing. People have applied Hadoop to various big data application scenarios, which show the power of Hadoop. However, the 1.0 version of Hadoop supports only one computing model of MapReduce, which is not efficient enough to provide higher performance.", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Contention-aware reliability management scheme for parallel tasks scheduling in heterogeneous computing systems\n", "abstract": " Energy efficiency and high system reliability are two primary measurement in modern high-performance computing. Most recent studies pay too much attention on low energy consumption or execution time for parallel tasks scheduling. In addition, these approaches are proposed for the classic scheduling model. It is increasing recognized that contention model is more realistic and be of benefit to create accurate and efficient schedules. This paper presents a contention-aware reliability management algorithm for parallel tasks scheduling in heterogeneous computing systems. Extensive experiments are performed to evaluate the results. It is demonstrated that our algorithm significant improve the system reliability.", "num_citations": "2\n", "authors": ["2184"]}
{"title": "FP-ABC: fast and parallel ABC based energy-efficiency live VM allocation policy in data centers\n", "abstract": " Virtual machine (VM) technology is one of the energy-efficiency approaches to save energy with acceptable quality of service (QoS). In our previous studies, Artificial Bee Colony (ABC) based VM allocation policy can make a good tradeoff between performance and energy consumption. However, there are two problems in state-of-the-art ABC based approaches: () how to find global optimized solutions efficiently; () how to minimize the decision time of VM allocation. To solve these two problems, the idea of simulated annealing is adopted to get a better global optimum, and the idea of gradient descent is applied to accelerate the speed of finding solution space in . Compared with state-of-the-art ABC based policies, the experimental results show that the proposed algorithm efficiently reduces energy consumption and SLA violation.", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Security and Privacy in Big Data\n", "abstract": " The term \u201cBig Data\u201d refers to the massive amounts of digital information companies and governments collect about us and our surroundings. Human beings now create 2.5 quintillion bytes of data per day. The rate of the data creation has increased so much that 90% of the data in the world today has been created in the last 2 years alone. How to securely store these massive data and how to effectively process them have been more and more important and challenging tasks. An effective method is for institutions to adopt the emerging cloud computing commercial service schema to outsource their massive data sets at remote cloud storage and computing centers. On the other hand, authorized data users can utilize the powerful computation capability of the cloud sever to search and process data. For example, a hospital creates vast data sets of patients\u2019 medical records every day, such as EMR (electronic medical records) including X-rays, electrocardiograms, clinical histories, and so on. Facing such a huge amount of data files, hospitals have to resort to third-party data storage and management centers to maintain the massive data sets. Later, authorized physicians can search and obtain individual records through public communication channels. Generally, Big Data is processed and queried on the cloud computing platform. Cloud computing, the new term for the long-dreamed of vision of computing as a utility, enables convenient, on-demand network access to a centralized pool of configurable computing resources that can be rapidly deployed with great efficiency and minimal management overhead. The amazing advantages of cloud\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Parallel Computational Fluid Dynamics: 25th International Conference, ParCFD 2013, Changsha, China, May 20-24, 2013. Revised Selected Papers\n", "abstract": " This book constitutes the refereed proceedings of the 25th International Conference on Parallel Computational Fluid Dynamics, ParCFD 2013, held in Changsha, China, in May 2013. The 35 revised full papers presented were carefully reviewed and selected from more than 240 submissions. The papers address issues such as parallel algorithms, developments in software tools and environments, unstructured adaptive mesh applications, industrial applications, atmospheric and oceanic global simulation, interdisciplinary applications and evaluation of computer architectures and software environments.", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Parallel file download in peer-to-peer networks with random service capacities\n", "abstract": " It is well known that the method of parallel downloading can be used to reduce file download times in a peer-to-peer (P2P) network. There has been little investigation on parallel download and chunk allocation for source peers with random service capacities. The main contribution of this paper is to address the problem of efficient parallel file download in P2P networks with random service capacities. A precise analysis of the expected download time is given when the service capacity of a source peer is a random variable. A general framework is developed for analyzing the expected download time of a parallel download and chunk allocation algorithm, and is applied to the analysis of several algorithms. Two chunk allocation algorithms for parallel download are proposed. It is observed that the performance of parallel download can be significantly improved by using the method of probing high-capacity peers. One\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Power assignment and transmission scheduling in wireless networks\n", "abstract": " The problem of downlink data transmission scheduling in wireless networks is studied. It is pointed out that every downlink data transmission scheduling algorithm must have two components to solve the two subproblems of power assignment and transmission scheduling. Two types of downlink data transmission scheduling algorithms are proposed. In the first type, power assignment is performed before transmission scheduling. In the second type, power assignment is performed after transmission scheduling. The performance of two algorithms of the first type which use the equal power allocation method are analyzed. It is shown that both algorithms exhibit excellent worst-case performance and asymptotically optimal average-case performance under the condition that the total transmission power is equally allocated to the channels. In general, both algorithms exhibit excellent average-case performance. It is\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Rapidly mixing random walks on hypercubes with application to dynamic tree evolution\n", "abstract": " In many tree-structured parallel computations, the size and shape of a tree that represents a parallel computation is unpredictable at compile-time. The tree evolves gradually during the course of the computation. When such an application is executed on a static network, the dynamic tree evolution problem is to distribute the tree nodes to the processors of the network such that all the processors receive roughly the same amount of load and that communicating nodes are assigned to neighboring processors. The main contribution of the paper is to describe a simple random-walk-based asymptotically optimal dynamic tree evolution algorithm on hypercubes and analyze the speed at which the performance ratio converges to the optimal. Our strategy is to prove that the Markov chain of the random walk on a hypercube is rapidly mixing.", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Average-case performance analysis and validation of online scheduling of independent parallel tasks\n", "abstract": " Summary form only given. We analyze the average-case performance of an online scheduling algorithm for independent parallel tasks. We develop a method to calculate an analytical asymptotic average-case performance bound for arbitrary probability distribution of task sizes. In particular, we show that when task sizes are uniformly distributed in the range [1..C], an asymptotic average-case performance bound of M-(3-(1+1/C)/sup C+1/)C-1 can be achieved, where M is the number of processors. We also present extensive numerical and simulation data to demonstrate the accuracy of our analytical bound.", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Parallel and Distributed Processing: 10th International IPPS/SPDP'98 Workshops, Held in Conjunction with the 12th International Parallel Processing Symposium and 9th Symposium\u00a0\u2026\n", "abstract": " This book constitutes the refereed proceedings of 10 international workshops held in conjunction with the merged 1998 IPPS/SPDP symposia, held in Orlando, Florida, US in March/April 1998. The volume comprises 118 revised full papers presenting cutting-edge research or work in progress. In accordance with the workshops covered, the papers are organized in topical sections on reconfigurable architectures, run-time systems for parallel programming, biologically inspired solutions to parallel processing problems, randomized parallel computing, solving combinatorial optimization problems in parallel, PC based networks of workstations, fault-tolerant parallel and distributed systems, formal methods for parallel programming, embedded HPC systems and applications, and parallel and distributed real-time systems.", "num_citations": "2\n", "authors": ["2184"]}
{"title": "An efficient and effective performance evaluation method for multiprogrammed multiprocessor systems\n", "abstract": " A partitionable shared memo~, multiprocessor system can be partitioned into many virtual subsystems that can be allocated to independent jobs. A multi-server queueing system model for approximating performance of partitionable multiprocessor systems is proposed in this paper. A system is specified by the number of processors, and jobs are characterized by a probability distribution of the number of processors required, a Poisson arrival process, and an exponential distribution of execution time. The first-come-first-served (FCFS) queueing discipline is analyzed. An adapted FCFS policy is also considered, which, when there are no enough processors available for large jobs in the front of the waiting queue, schedules smaller jobs behind these large jobs earlier. Performance measures reported include mean job waiting and response times, average queue length, and system utilization. Numerical data for a\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Analyzing the expected execution times of parallel programs\n", "abstract": " Due to different input data and unpredictable dynamic run time environment, the execution times of tasks within a parallel program can be treated as random variables. In this paper, we show a method for analyzing expected parallel program execution times as well as expected speedup and efficiency. For several typical classes of parallel programs, we derive very accurate closed form approximate results. Examples are also given to demonstrate the quality of our analysis.", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Solving The Traveling Salesman Problem Using Efficient Randomized Parallel Approximation Algorithms\n", "abstract": " In this paper, we combine the techniques of approximation, parallelism, and randomization to solve the traveling salesman problem, one of the most celebrated problems in computer science. We show that there is an EREW PRAM algorithm A                1 such that A                1(l)\u00a0\u2264\u00a02 OPT(l) for all TSP instances l, where A                1(l) is the length of the tour produced by A                1, and OPT(l) is the length of an optimum tour. The algorithm has time complexity O(log2\u00a0n), and uses O(n                2) processors. There is a similar CREW PRAM algorithm A                2 that uses O(n                2/log2\u00a0n) processors. Furthermore, there is a Monte Carlo CREW PRAM algorithm A                3 which, for all TSP instances l, finds a traveling salesman lour such that A                3(l)\u00a0\u2264\u00a01.5OPT(l) with probability at least 1\u00a0\u2212\u00a0(1/2                   k                ), where k is any large integer. The randomized algorithm has time complexity O(log2\u00a0n), and\u00a0\u2026", "num_citations": "2\n", "authors": ["2184"]}
{"title": "Modeling Temporal Patterns with Dilated Convolutions for Time-Series Forecasting\n", "abstract": " Time-series forecasting is an important problem across a wide range of domains. Designing accurate and prompt forecasting algorithms is a non-trivial task, as temporal data that arise in real applications often involve both non-linear dynamics and linear dependencies, and always have some mixtures of sequential and periodic patterns, such as daily, weekly repetitions, and so on. At this point, however, most recent deep models often use Recurrent Neural Networks (RNNs) to capture these temporal patterns, which is hard to parallelize and not fast enough for real-world applications especially when a huge amount of user requests are coming. Recently, CNNs have demonstrated significant advantages for sequence modeling tasks over the de-facto RNNs, while providing high computational efficiency due to the inherent parallelism. In this work, we propose HyDCNN, a novel hybrid framework based on fully Dilated\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "STT-MRAM-based Reliable Weak PUF\n", "abstract": " In recent years, micro-nano device characteristics like ferroelectrics and resistive switching are being used to build important security primitives such as Physical Unclonable Function (PUF). The micro-nano device-based hardware security primitives, although with higher security, energy efficiency, and integration density, suffer from serious reliability issues caused by process scaling. To mitigate this issue, this paper introduces a reconfigurable weak PUF based on spin-transfer torque magnetoresistive random-access memory (STT-MRAM), which adopts the crossing switches implemented with simple demultiplexes (DEMUXs) to improve the flexibility and reliability. Moreover, two algorithms, \\texttt{neighboring bit lines} and \\texttt{top-n}, are proposed to enlarge the gap between two parallel reading currents, thus further enhancing the reliability of PUF responses. Experimental results demonstrate that the proposed PUF scheme\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "Efficient Distributed Approaches to Core Maintenance on Large Dynamic Graphs\n", "abstract": " As a fundamental problem in graph analysis, core decomposition aims to compute the core numbers of vertices in a given graph. It is a powerful tool for mining important graph structures. For dynamic graphs with real-time updates of vertices/edges, core maintenance has been utilized to update the core numbers of vertices. The previous approaches to core maintenance face challenges in terms of storage and efficiency. In this paper, we investigate distributed approaches to core maintenance on a pregel-like system, which is a famous graph computing system. We first design a core decomposition algorithm to obtain core numbers of vertices in a given graph. Based on it, a distributed batch-stream combined algorithm (DBCA) is devised to efficiently maintain the core numbers when vertex/edge updates happen. In particular, we introduce a new task assignment strategy to DBCA based on diversity of the edge-cores\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "Unraveling the Mechanism of Near-Infrared Thermally Activated Delayed Fluorescence of TPA-Based Molecules: Effect of Hydrogen Bond Steric Hindrance\n", "abstract": " A recently synthesized novel molecule (named CAT-1) exhibits intriguing near-infrared (NIR) thermally activated delayed fluorescence (TADF) close to 1000 nm wavelength; however, the mechanism behind these intrinsic properties is not fully understood. Herein, we unravel that the fluorescence emission spectrum with a broad wavelength range (770\u2013950 nm) of CAT-1 is primarily induced by hydrogen bond steric hindrance based on density functional theory and Marcus theory. It is found that the hydrogen bond steric hindrance plays a critical role in inhibiting the twist of the configuration of different excited states, which leads to the minor driving force for fast electron trapping between the excited states, as well as small internal reorganization energy caused by less changed geometric configuration. Furthermore, such steric hindrance will cause a more distorted plane, resulting in a less favorable electron\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "Adams-Bashforth-Type Discrete-Time Zeroing Neural Networks Solving Time-Varying Complex Sylvester Equation With Enhanced Robustness\n", "abstract": " In this article, two Adams-Bashforth-type integration-enhanced discrete-time zeroing neural dynamic (ADTIZD) models are proposed to solve the time-varying complex Sylvester equation (TVCSE) problem in the first time. In ADTIZD models, Adams-Bashforth discrete formulas as novel discrete formulas are used, giving our ADTIZD models higher accuracy [truncation error being O(\u03c4\u2075)] but less time and space complexity than the ordinary multi-instant models. Enhanced by the integration part, the ADTIZD models can resist large additive noises, where even constant noises cannot decrease their precision. All convergence and robustness performance conclusions about our ADTIZD models are supported by rigorous theoretical proofs and numerical experiments. More comparisons between ADTIZD models and other discrete-time zeroing neural network models are shown in these experiments too. The efficacy of\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "Distributed matrix factorization based on fast optimization for implicit feedback recommendation\n", "abstract": " In big data scenarios, matrix factorization (MF) is widely used in recommendation systems as it can offer high accuracy and scalability. However, when using MF to process large-scale implicit feedback data, the following two problems arise. One is that it is difficult to effectively obtain negative feedback information, which causes relatively poor recommendation accuracy. The other is that the limited resources of a single machine make the model training inefficient, and in particular, the acquisition of negative feedback information further increases the time complexity of model training. In order to solve the above two problems, we first propose a user-activity and item-popularity weighted matrix factorization (UIWMF) recommendation algorithm, which assigns every missing data different weight based on user activity and item popularity, gets negative feedback information more realistically, and leads to better\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "How to Analyze the Neurodynamic Characteristics of Pulse-Coupled Neural Networks? A Theoretical Analysis and Case Study of Intersecting Cortical Model\n", "abstract": " The intersecting cortical model (ICM), initially designed for image processing, is a special case of the biologically inspired pulse-coupled neural-network (PCNN) models. Although the ICM has been widely used, few studies concern the internal activities and firing conditions of the neuron, which may lead to an invalid model in the application. Furthermore, the lack of theoretical analysis has led to inappropriate parameter settings and consequent limitations on ICM applications. To address this deficiency, we first study the continuous firing condition of ICM neurons to determine the restrictions that exist between network parameters and the input signal. Second, we investigate the neuron pulse period to understand the neural firing mechanism. Third, we derive the relationship between the continuous firing condition and the neural pulse period, and the relationship can prove the validity of the continuous firing\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "Projection-free Decentralized Online Learning for Submodular Maximization over Time-Varying Networks\n", "abstract": " This paper considers a decentralized online submodular maximization problem over timevarying networks, where each agent only utilizes its own information and the received information from its neighbors. To address the problem, we propose a decentralized Meta-Frank-Wolfe online learning method in the adversarial online setting by using local communication and local computation. Moreover, we show that an expected regret bound of O (", "num_citations": "1\n", "authors": ["2184"]}
{"title": "SGDTucker: A Novel Stochastic Optimization Strategy for Parallel Sparse Tucker Decomposition\n", "abstract": " Sparse Tucker Decomposition (STD) algorithms learn a core tensor and a group of factor matrices to obtain an optimal low-rank representation feature for the  H igh- O rder,  H igh- D imension, and  S parse  T ensor (HOHDST). However, existing STD algorithms face the problem of intermediate variables explosion which results from the fact that the formation of those variables, i.e., matrices Khatri-Rao product, Kronecker product, and matrix-matrix multiplication, follows the whole elements in sparse tensor. The above problems prevent deep fusion of efficient computation and big data platforms. To overcome the bottleneck, a novel stochastic optimization strategy (SGD  Tucker) is proposed for STD which can automatically divide the high-dimension intermediate variables into small batches of intermediate matrices. Specifically, SGD  Tucker only follows the randomly selected small samples rather than the whole elements, while\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "ImRP: A Predictive Partition Method for Data Skew Alleviation in Spark Streaming Environment\n", "abstract": " Spark Streaming is an extension of the core Spark engine that enables scalable, high-throughput, fault-tolerant stream processing of live data streams. It treats stream as a series of deterministic batches and handles them as regular jobs. However, for a stream job responsible for a batch, data skew (i.e., the imbalance in the amount of data allocated to each reduce task), can degrade the job performance significantly because of load imbalance. In this paper, we propose an improved range partitioner (ImRP) to alleviate the reduce skew for stream jobs in Spark Streaming. Unlike previous work, ImRP does not require any pre-run sampling of input data and generates the data partition scheme based on the intermediate data distribution estimated by the previous batch processing, in which a prediction model EWMA (Exponentially Weighted Moving Average) is adopted. To lighten the data skew, ImRP presents a novel\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "More bang for your buck: Boosting performance with capped power consumption\n", "abstract": " Achieving faster performance without increasing power and energy consumption for computing systems is an outstanding challenge. This paper develops a novel resource allocation scheme for memory-bound applications running on High-Performance Computing (HPC) clusters, aiming to improve application performance without breaching peak power constraints and total energy consumption. Our scheme estimates how the number of processor cores and CPU frequency setting affects the application performance. It then uses the estimate to provide additional compute nodes to memory-bound applications if it is profitable to do so. We implement and apply our algorithm to 12 representative benchmarks from the NAS parallel benchmark and HPC Challenge (HPCC) benchmark suites and evaluate it on a representative HPC cluster. Experimental results show that our approach can effectively mitigate memory\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "Pooling strategy optimization for accelerating asymptomatic COVID-19 screening\n", "abstract": " Testing has been a major factor that limits our response to the COVID-19 pandemic. The method of sample pooling and group test has recently been introduced. However, it is still not clearly known how to determine the appropriate group size. In this paper, we develop an analytical method and a numerical algorithm to determine the optimal group size, which minimizes the total number of tests, maximizes the speedup of the pooling strategy, and minimizes both time and cost of testing. The optimal group size is determined by the fraction of infected people and independent of the size of the population. Furthermore, both the optimal pooling size and the achieved speedup grow exponentially with the reciprocal of the fraction of infected people, a quite impressive and nontrivial result. Our method is effective in supporting faster and cheaper asymptomatic COVID-19 screening. Our research has important social implications and financial impacts. For example, if the percentage of infected people is 0.001, we can achieve speedup of almost 16, which means that months of testing time can be reduced to days, and over 93% of the testing cost can be saved. Such a result has not been available in the known literature, and is a significant progress and great advance in pooling strategy optimization for accelerating asymptomatic COVID-19 screening.", "num_citations": "1\n", "authors": ["2184"]}
{"title": "A Group-Based Buffer Management for SSD\n", "abstract": " Random writes limit the application of SSDs significantly because of their poor latency and high garbage collection overhead. Traditional page-based and block-based buffer management algorithms cannot achieve both high buffer hit ratio and good destage sequentiality at the same time. In this paper, we propose a hybrid scheme called the group-based buffer management (GBBM). To improve buffer hit ratio and decrease write/erase counts, GBBM divides buffer space into Page Region and Group Region. The frequently accessed data pages are placed at the Page Region, while infrequently accessed random written data are grouped in the Group Region. GBBM has been evaluated extensively through simulations. The write counts of GBBM show an average decrease of 12.7% compared with page-level buffer scheme. Compared with hybrid buffer management such as CBM, GBBM decreases the average write\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "Human-Interaction-aware Adaptive Functional Safety Processing for Multi-Functional Automotive Cyber-Physical Systems\n", "abstract": " The functional safety research for automotive cyber-physical systems (ACPS) has been studied in recent years; however, these studies merely consider the change in the exposure of the functional safety classification and assume that the driver\u2019s controllability in the functional safety classification is always fixed and uncontrollable. In fact, the driver\u2019s controllability is variable during the runtime phase, such that the execution process of safety-critical automotive functions is a human-interaction-aware process between the driver and ACPS. To adapt to the changes in the driver\u2019s controllability, this article studies the human-interaction-aware adaptive functional safety processing for multi-functional ACPS in two main phases. In the design phase, where the driver\u2019s controllability is fixed at the highest level (i.e., C3), we obtain the approximate optimal priority sequence of safety-critical functions without exhausting all\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "Optimal power allocation and load balancing for non-dedicated heterogeneous distributed embedded computing systems\n", "abstract": " This paper investigates on the optimal power allocation and load balancing problem encountered by heterogeneous and distributed embedded systems with mixed tasks. Given that each node has real and different urgent tasks in the majority of practical heterogeneous embedded systems, three priority disciplines are considered: dedicated jobs without priority, prioritized dedicated jobs without preemption, and prioritized dedicated jobs with preemption. A model is established for heterogeneous embedded processors with dedicated-task-dependent dynamic power and load balancing management; each processor is considered as an M/M/1 queueing sub-model with mixed generic and dedicated tasks. The processors have different levels of power consumption, and each one can employ any of the three disciplines. The objective of this study is to find an optimal load balancing (for generic tasks) and power\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "Energy and time constrained scheduling for optimized quality of service\n", "abstract": " Minimizing the total completion time has practical application in providing the best quality of service. We consider energy and time constrained task scheduling for minimized total completion time and minimized total energy consumption. We show that there is a polynomial time algorithm to find a nonpreemptive schedule with the minimum total completion time for a given total energy consumption constraint. Similarly, there is a polynomial time algorithm to find a nonpreemptive schedule with the minimum total energy consumption for a given total completion time constraint.", "num_citations": "1\n", "authors": ["2184"]}
{"title": "High-performance real-time scheduling\n", "abstract": " This chapter presents a multiple parallel applications scheduling optimization with respect to high performance and timing constraint. We first present the fairness and the whole priority scheduling algorithms from high performance and timing constraint perspectives, respectively. Thereafter, we mix these two algorithms to present the partial priority scheduling algorithm, which can satisfy the deadlines of more high-priority applications and reduce the overall schedule length of the system. The partial priority scheduling algorithm is implemented by preferentially scheduling the partial tasks of high-priority applications, and then fairly scheduling their remaining tasks with all the tasks of low-priority applications. Further, each application has different criticality levels (e.g., severity), and missing the deadlines of certain high-criticality functions may cause fatal injuries to people. Therefore, we present the multiple\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "A semantic textual similarity measurement model based on the syntactic-semantic representation\n", "abstract": " Measuring semantic textual similarity (STS) lies at the core of many applications in natural language processing (NLP). Recently, most models have considered semantic information or syntactic information, but seldom an unified model to make full use of these two kinds of information. Based on the knowledge from the trained word vectors, this paper proposes a semantic-embedded dependency tree (SEDT) model based on word2vec and glove, which can be treated as a syntactic-semantic representation. In consideration of the words in a sentence for the contribution of the semantic are different, this model extends the semantic-embedded dependency tree model to an enhanced semantic-embedded dependency tree (ESEDT). And a modified partial tree kernel (MPTK) is proposed to automatically extract the syntactic-semantic patterns in this tree. Because the syntactic information, semantic knowledge, and the\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "Information\u2010centric routing in MSN based on community detection\n", "abstract": " Mobile social network (MSN) offers a new perspective on mobile ad hoc communication since its routing principle is based on the human social relations. Although social\u2010based routing can improve routing efficiency considerably, obtaining such social information is difficult to be achieved. In information\u2010centric networking (ICN), content names reveal useful social information among users. In addition, each node stores and caches the received content to satisfy the forthcoming content requests in ICN due to in\u2010network caching. In this work, the proposed MSN routing relies on named data networking, which is a well\u2010known ICN paradigm. By the communities, which are detected based on users' interest preferences, an interest packet is delivered to the content provider based on the interest similarities among mobile users. Then, by communities, which are detected based on the nodes' encounter regularities, a data\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "An Adaptive Partition Method for Handling Skew in Spark Applications\n", "abstract": " In the parallel computing framework of Hadoop/Spark, data skew is a common problem resulting in performance degradation, such as prolonging of the entire execution time and idle resources. What lies behind this issue is partition imbalance, which causes significant differences in the amount of data processed by each reduce task. This paper proposes a key reassigning and splitting partition algorithm (SKRSP) to handle skew, which considers both the partition balance of the intermediate data and the partition balance after shuffle operator. We design two partition algorithms for different applications: the range-based key splitting partition method (KSRP) for sort operation and hash-based key reassigning partition method (KRHP) for the other operations. We implement SKRSP in Spark 2.2.0 and evaluate its performance through three benchmarks exhibiting significant data skew: Sort, Join, and PageRank. The\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "Optimal speed setting for cloud servers with mixed applications\n", "abstract": " The technique of workload dependent dynamic power management can dynamically and flexibly adjust power and speed according to the current workload. It has been well recognized that improving server performance and reducing energy consumption can be achieved by employing the technique of workload dependent dynamic power management. It is an effective way to deal with the power and performance tradeoff for cloud servers. In this study, applications are divided into different classes, which have different characteristics. The server speed is different in processing tasks from different types. Hence, we explore the technique of variable and task type dependent server speed management to optimize the server performance and to minimize the power consumption of a server with mixed applications. This is also a kind of workload-dependent dynamic power and speed management to deal with the power\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "A novel graph structure for salient object detection based on divergence background and compact foreground\n", "abstract": " In this paper, we propose an efficient and discriminative model for salient object detection. Our method is carried out in a stepwise mechanism based on both divergence background and compact foreground cues. In order to effectively enhance the distinction between nodes along object boundaries and the similarity among object regions, a graph is constructed by introducing the concept of virtual node. To remove incorrect outputs, a scheme for selecting background seeds and a method for generating compactness foreground regions are introduced, respectively. Different from prior methods, we calculate the saliency value of each node based on the relationship between the corresponding node and the virtual node. In order to achieve significant performance improvement consistently, we propose an Extended Manifold Ranking (EMR) algorithm, which subtly combines suppressed / active nodes and mid-level information. Extensive experimental results demonstrate that the proposed algorithm performs favorably against the state-of-art saliency detection methods in terms of different evaluation metrics on several benchmark datasets.", "num_citations": "1\n", "authors": ["2184"]}
{"title": "Design and analysis of parallel file downloading algorithms in peer-to-peer networks\n", "abstract": " It is well known that the method of parallel downloading can be used to reduce file download times in a peer-to-peer (P2P) network. There has been little investigation on parallel download and chunk allocation for source peers with random service capacities. The main contribution of this paper is to address the problem of efficient parallel file download in P2P networks with random service capacities. A precise analysis of the expected download time is given when the service capacity of a source peer is a random variable. A general framework is developed for analyzing the expected download time of a parallel download and chunk allocation algorithm, and is applied to the analysis of several algorithms. Two chunk allocation algorithms for parallel download are proposed. It is observed that the performance of parallel download can be significantly improved by using the method of probing high-capacity\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "Security testing for software applications\n", "abstract": " A mapping engine may be used to determine an attack model enumerating software attacks, the software attacks being represented by linked attack components, and may be used to determine a software architecture to be tested, the software architecture being represented by linked architectural components in an architecture diagram. The mapping engine may then associate each attack component and each architectural component with at least one attack tag characterizing attack requirements. A global test plan generator may be used to determine an attack test model, including associating attack components with corresponding architectural components, based on associated attack tags, and may thus generate attack test workflows from the attack test model, to thereby test the software architecture.", "num_citations": "1\n", "authors": ["2184"]}
{"title": "Communication analysis and performance prediction of parallel applications on large-scale machines\n", "abstract": " With the development of high performance computers, communication performance is a key factor affecting the performance of HPC applications. Communication patterns can be obtained by analyzing communication traces. However, existing approaches to generating communication traces need to execute the entire parallel applications on full-scale systems that are time-consuming and expensive. Furthermore, for designers of large-scale parallel computers, it is greatly desired that performance of a parallel application can be predicted at the design phase. Despite previous efforts, it remains an open problem to estimate sequential computation time in each process accurately and efficiently for large-scale parallel applications on non-existing target machines. In this chapter, we will introduce a novel technique for performing fast communication trace collection for large-scale parallel applications and an automatic\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "A performance-efficient and datapath-regular implementation of modified split-radix fast Fourier transform\n", "abstract": " Discrete Fourier transform (DFT) finds various applications in signal processing, image processing, artificial intelligent, and fuzzy logic etc. DFT is often computed efficiently with Fast Fourier transform (FFT). The modified split radix FFT (MSRFFT) algorithm implements a length-N= 2 m DFT achieving a reduction of arithmetic complexity compared to split-radix FFT (SRFFT). In this paper, a simplified algorithm is proposed for the MSRFFT algorithm, reducing the number of real coefficients evaluated from 5/8N-2 to 15/32N-2 and the number of groups of decomposition from 4 to 3. A implementation approach is also presented. The approach makes data-path of the MSRFFT regular similar to that of the radix-2 FFT algorithm. The experimental results show that (1) MSRFFT consumes less time on central processing units (CPUs) with sufficient cache than existing algorithms;(2) the proposed implementation method can save\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "A VLSI implementation of an SM4 algorithm resistant to power analysis\n", "abstract": " SM4 is a block cipher proposed by the Chinese government. Strengthening the research and extension of SM4 is significant to the development and promotion of Chinese cryptography standards. To date, research relevant to SM4 is rare. Thus, we propose the implementation of an SM4 algorithm resistant to power analysis. Ideally, a secure masking scheme is used for the SM4 cipher, which is particularly suited for implementation in the application specific integrated circuit. Moreover, the mask scheme in our chip implementation process is improved to make SM4 safer. Simulation results confirm that the use of counteractive measures resistant to power analysis is credible.", "num_citations": "1\n", "authors": ["2184"]}
{"title": "An Optimal Reduce Placement Algorithm for Data Skew Based on Sampling\n", "abstract": " For frequent disk I/O and big data transmissions among different racks and physical nodes, the intermediate data communication has become the biggest performance bottle-neck in most running Hadoop systems. This paper proposes a reduce placement algorithm called CORP to schedule related map and reduce tasks on the near nodes or clusters or racks for the data locality. Since the number of keys cannot be counted until the input data are processed by map tasks, this paper firstly provides a sampling algorithm based on reservoir sampling to achieve the distribution of the keys in intermediate data. Through calculating the distance and cost matrices among the cross node communication,\u00a0the related map and reduce tasks can be scheduled to relatively near physical nodes for data locality. Experimental results show that CORP can not only improve the balance of reduce tasks effectively, but also\u00a0\u2026", "num_citations": "1\n", "authors": ["2184"]}
{"title": "Cluster-Distribute-Align-Merge: A General Algorithm to Speed Up Multiple Sequence Alignment on Multi-Core Computers\n", "abstract": " We present a general algorithm to speed up multiple sequence alignment on modern multi-core computers. This algorithm is implemented in a software called CDAM. By clustering, CDAM partitions a large-scale alignment problem into smaller and more tractable sub-problems, which can be solved by existing alignment algorithms in parallel. The aligned clusters are then merged to form a solution to the original alignment problem. By performance evaluation on an 8-core computer using the classical benchmarks, BAliBASE, PREFAB, IRMBASE, and OXBench, and twenty-eight artificially generated datasets, it is shown that CDAM provides significant performance improvement with reasonable loss of accuracy. In some cases, a gain in accuracy is observed. The CDAM program, source code, and test data are freely available for academic users at http://aca.hnu.cn/CDAM/.", "num_citations": "1\n", "authors": ["2184"]}
{"title": "A Novel Task Scheduling Scheme in Heterogeneous Computing Systems Using Chemical Reaction Optimization\n", "abstract": " The task scheduling problem is normally an NP-hard problem. A chemical reaction optimization (CRO) is a new meta-heuristic optimization method, which has demonstrated its capability in solving NP-hard optimization problems. In this paper, a novel CRO algorithm for task scheduling (NCROTS) is proposed on heterogeneous computing systems. Over the real-world problems with various characteristics and randomly generated graphs, the simulation results show that the proposed NCROTS algorithm significantly improves the schedule quality (makespan), compared with two existing solutions (GA and HEFT).", "num_citations": "1\n", "authors": ["2184"]}
{"title": "Average-Case Performance Evaluation of Online Algorithms for Routing and Wavelength Assignment in WDM Optical Networks\n", "abstract": " We investigate the problem of online routing and wavelength assignment and the related throughput maximization problem in wavelength division multiplexing optical networks. It is pointed out that these problems are highly inapproximable. We evaluate the average-case performance of several online algorithms, which have no knowledge of future arriving connection requests when processing the current connection request. Our experimental results on a wide range of optical networks demonstrate that the average-case performance of these algorithms is very close to optimal.", "num_citations": "1\n", "authors": ["2184"]}
{"title": "A Lower Bound for Power-Aware Task Scheduling on Multiprocessor Computers.\n", "abstract": " We address task scheduling on multiprocessor computers with dynamically variable voltage and speed as a combinatorial optimization problem. We define the problem of minimizing schedule length with energy consumption constraint on multiprocessor computers. We derive a lower bound for the optimal schedule length for the problem of minimizing schedule length with energy consumption constraint.", "num_citations": "1\n", "authors": ["2184"]}
{"title": "Performance evaluation of heuristic algorithms for wavelength assignment in WDM optical networks\n", "abstract": " Given a set of connection requests in a WDM optical network and a designated lightpath for each connection request, the wavelength assignment problem is to assign a wavelength to each lightpath in such a way that lightpaths sharing common links are assigned different wavelengths and the number of wavelengths used is minimized. The main result of the paper is to show that there exist simple heuristic wavelength assignment algorithms whose average-case performance is very close to the optimum. Our strategy is to convert wavelength assignment on an optical network with randomly generated connection requests into vertex coloring on a random lightpath graph.", "num_citations": "1\n", "authors": ["2184"]}
{"title": "New addressing schemes for pipelined optical buses\n", "abstract": " The coincident pulse technique is generalized for the purpose of deriving compact addressing schemes for pipelined optical buses. Based on this new technique, several new addressing schemes are presented. Compared with the previously proposed addressing scheme, the new schemes significantly improve the utilization of the bandwidth of optical waveguides and the scalability of a pipelined optical bus.", "num_citations": "1\n", "authors": ["2184"]}
{"title": "An analytical model for approximating performance of partitionable multiprocessor systems\n", "abstract": " A shared memory multiprocessor contains many processors which are able to carry out computations independently by retrieving instructions and data from a common centralized or decentralized memory system equally accessible by all processors. Processors synchronize their activities and com-municate with each other through shared variables. Proces-sors are connected to the global memory system using a processor-memory interconnection network (see Figure 1), eg, a crossbar network, one or more common buses, and a multistage interconnection network. The class of shared memory multiprocessors is exemplified by CMU Cm* and C. mmp, ELXSI 6400, Encore Multimax, FLEX/32, Hector,", "num_citations": "1\n", "authors": ["2184"]}