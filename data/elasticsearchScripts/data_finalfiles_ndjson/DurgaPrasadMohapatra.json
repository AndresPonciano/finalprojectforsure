{"title": "Test case generation based on use case and sequence diagram\n", "abstract": " We present a comprehensive test case generation technique from UML models. We use the features in UML 2.0 sequence diagram including conditions, iterations, asynchronous messages and concurrent components. In our approach, test cases are derived from analysis artifacts such as use cases, their corresponding sequence diagrams and constraints specified across all these artifacts. We construct Use case Dependency Graph (UDG) from use case diagram and Concurrent Control Flow Graph (CCFG) from corresponding sequence diagrams for test sequence generation. We focus testing on sequences of messages among objects of use case scenarios. Our testing strategy derives test cases using full predicate coverage criteria. Our proposed test case generation technique can be used for integration and system testing accommodating the object message and condition information associated with the use case scenarios. The test cases thus generated are suitable for detecting synchronization and dependency of use cases and messages, object interaction and operational faults. Finally, we have made an analysis and comparison of our approach with existing approaches, which are based on other coverage criterion through an example.", "num_citations": "107\n", "authors": ["475"]}
{"title": "Automatic test data generation for data flow testing using particle swarm optimization\n", "abstract": " Automatic test case generation is a major problem in software testing. Evolutionary structural testing is an approach to automatically generate test cases that uses a Genetic Algorithm (GA) which is guided by the data flow dependencies in the program to search for test data to cover the def-use association. The Particle Swarm Optimization (PSO) approach is a swarm intelligence technique which can be used to generate test data automatically. We have proposed an algorithm to generate test cases using PSO for data flow testing. We have simulated both the evolutionary and swarm intelligence techniques. From the experiments it has been observed that PSO outperforms GA in 100% def-use coverage percentage.", "num_citations": "77\n", "authors": ["475"]}
{"title": "Test Case Generation Based on State and Activity Models.\n", "abstract": " We propose a novel testing technique for object-oriented programs. Based on the state and activity models of a system, we construct an intermediate representation, which we have named state-activity diagram (SAD). We generate test cases to achieve state-activity coverage of SADs. We have empirically evaluated the effectiveness of our approach. The results show that the proposed technique could detect seeded integration testing faults which could not be detected by the related approaches.", "num_citations": "67\n", "authors": ["475"]}
{"title": "Test case generation from Behavioral UML Models\n", "abstract": " We propose an integrated approach to generate test cases from UML sequence and activity diagrams. We first transform these UML diagrams into a graph. Then, we propose an algorithm to generate test scenarios from the constructed graph. Next, the necessary information for test case generation, such as method-activity sequence, associated objects, and constraint conditions are extracted from test scenario. Our approach reduces the number of test cases and still achieves adequate test coverage. We achieve message-activity path coverage and category partitioning method for each predicate conditions found in the specific path of the design model.", "num_citations": "62\n", "authors": ["475"]}
{"title": "Automatic test case generation from UML state chart diagram\n", "abstract": " More than 50% of software development effort is spent in testing phase in a typical software development project. Test case design as well as execution consumes a lot of time. So automated generation of test cases is highly required. We present a testing methodology to test object oriented software based on UML state chart diagrams. In our approach we apply function minimization technique and generate test cases automatically from UML state chart diagrams. Here, first the state chart diagram is constructed. Then the diagram is traversed. Here, we perform a DFS to select the associated predicates. After selecting the predicates, we guess an initial dataset. These conditional predicates are, then transformed to generate test cases automatically. Our technique achieves adequate test coverage without unduly increasing the number of test cases. Our approach achieves many important coverage like state coverage, transition coverage, transition pair coverage etc.. This paper also describes how minimization technique is used in testing.", "num_citations": "60\n", "authors": ["475"]}
{"title": "A novel approach for test case generation from UML activity diagram\n", "abstract": " Software testing approaches are mainly divided into three types i.e. code based testing, specification based testing and model based testing. In model based testing, the testing can be started from the design process at the beginning phase. So, early detection of faults can be achieved by using this approach. An approach for the generation of test cases from UML (Unified Modelling Language) activity diagram using genetic algorithm has been presented in this paper. Early detection of faults can be achieved by this approach and will certainly reduce the time, cost and effort of the developer to a large extent. We propose a model to generate an Activity Flow Table (AFT) from an Activity Diagram and then convert it to Activity Flow Graph (AFG). Coverage criteria are very important in test case generation. By using activity coverage criterion we traverse the AFG and the test paths are generated. Finally, we generate the\u00a0\u2026", "num_citations": "56\n", "authors": ["475"]}
{"title": "A novel approach of test case generation for concurrent systems using UML Sequence Diagram\n", "abstract": " Testing concurrency is difficult yet important. Because of arbitrary interference of concurrent objects, test case explosion becomes a major problem in testing concurrent systems. Synchronization and Deadlock being the two key features of concurrent systems make the systematic testing of concurrent systems a tedious task. In this paper we present a novel approach of generating test cases for concurrent systems with the help of UML Sequence Diagram. Our approach consists of transferring the Sequence Diagram into a Concurrent Composite Graph (CCG). The CCG is traversed by an effective graph traversing technique like BFS (Breath-First-Technique) and DFS (Depth-First-search) using message sequence path criteria to generate the test cases for concurrent systems. The proposed approach is applied to concurrent systems for test case generation and found to be very effective in controlling the test case\u00a0\u2026", "num_citations": "56\n", "authors": ["475"]}
{"title": "A novel approach for scenario-based test case generation\n", "abstract": " Testing of software is a time-consuming activity which requires a great deal of planning and resources. Model-based testing is gaining importance as a research issue. In scenario-based testing, test scenarios are used for generating test cases, test drivers etc. UML is widely used to describe analysis and design specifications of software development. UML models are important source of information for test case design. UML activity diagrams describe the realization of the operation in design phase and also support description of parallel activities and synchronization aspects involved in different activities perfectly. In this paper we generate test scenarios from activity diagrams, which achieve test adequacy criteria perfectly. Finally we generate test cases by analyzing the respective sequence and class diagrams of each scenario, which achieves maximum path coverage criteria. Also in our approach, the cost of test\u00a0\u2026", "num_citations": "55\n", "authors": ["475"]}
{"title": "An overview of slicing techniques for object-oriented programs\n", "abstract": " Durga Prasad Mohapatra, Rajib Mall and Rajeev Kumar1 Department of Computer Science and Engineering Indian Institute of Technology Kharagpur Kharagpur, WB 721 302, India E-mail:{durga, rajib, rkumar}@ cse. iitkgp. ernet. in", "num_citations": "46\n", "authors": ["475"]}
{"title": "Automatic test case generation using sequence diagram\n", "abstract": " Software Testing plays an important role in Software development because it can minimize the development cost. We Propose a Technique for Test Sequence Generation using UML Model Sequence Diagram.UML models give a lot of information that should not be ignored in testing. In This paper main features extract from Sequence Diagram after that we can write the Java Source code for that Features According to ModelJunit Library. ModelJUnit is an extended library of Junit Library. By using that Source code we can Generate Test Case Automatic and Test Coverage. This paper describes a systematic Test Case Generation Technique performed on model based testing (MBT) approaches By Using Sequence Diagram.", "num_citations": "42\n", "authors": ["475"]}
{"title": "Computational Intelligence in Data Mining-Volume 3\n", "abstract": " The contributed volume aims to explicate and address the difficulties and challenges for the seamless integration of two core disciplines of computer science, ie, computational intelligence and data mining. Data Mining aims at the automatic discovery of underlying non-trivial knowledge from datasets by applying intelligent analysis techniques. The interest in this research area has experienced a considerable growth in the last years due to two key factors:(a) knowledge hidden in organizations\u2019 databases can be exploited to improve strategic and managerial decision-making;(b) the large volume of data managed by organizations makes it impossible to carry out a manual analysis. The book addresses different methods and techniques of integration for enhancing the overall goal of data mining. The book helps to disseminate the knowledge about some innovative, active research directions in the field of data mining\u00a0\u2026", "num_citations": "41\n", "authors": ["475"]}
{"title": "Computing dynamic slices of concurrent object-oriented programs\n", "abstract": " We propose a novel dynamic program slicing technique for concurrent object-oriented programs. Our technique uses a Concurrent System Dependence Graph (CSDG) as the intermediate program representation. We mark and unmark the edges in the CSDG appropriately as and when the dependencies arise and cease during run-time. We mark an edge when its associated dependence exists and unmark an edge when the dependence ceases to exist. Our approach eliminates the use of trace files. Another advantage of our approach is that when a request for a slice is made, it is already available. This appreciably reduces the response time of slicing commands.", "num_citations": "38\n", "authors": ["475"]}
{"title": "Distributed dynamic slicing of Java programs\n", "abstract": " We propose a novel dynamic slicing technique for distributed Java programs. We first construct the intermediate representation of a distributed Java program in the form of a set of Distributed Program Dependence Graphs (DPDG). We mark and unmark the edges of the DPDG appropriately as and when dependencies arise and cease during run-time. Our algorithm can run parallely on a network of computers, with each node in the network contributing to the dynamic slice in a fully distributed fashion. Our approach does not require any trace files to be maintained. Another advantage of our approach is that a slice is available even before a request for a slice is made. This appreciably reduces the response time of slicing commands. We have implemented the algorithm in a distributed environment. The results obtained from our experiments show promise.", "num_citations": "35\n", "authors": ["475"]}
{"title": "Dynamic slicing of distributed object-oriented programs\n", "abstract": " Program slicing is a decomposition technique that deals with extracting those statements relevant to a particular computation. The authors propose a novel algorithm for computing dynamic slice of distributed object-oriented programs. The proposed algorithm incorporates graph colouring strategy to compute slice. But to achieve the goal efficiently, the authors have contradicted some key constraints of the traditional graph colouring technique. The state restriction of the slicing criterion is also considered along with dependence analysis while computing slice. The advantage of the proposed algorithm is that it is efficient and faster than the existing algorithms.", "num_citations": "32\n", "authors": ["475"]}
{"title": "A survey on model based test case prioritization\n", "abstract": " Regression testing is the process of validating modifications introduced in a system during software maintenance. As the test suite size is very large, system retesting consumes large amount of time and computing resources. This issue of retesting of software systems can be handled using a good test case prioritization technique. A prioritization technique schedules the test cases for execution so that the test cases with higher priority executed before lower priority. The objective of test case prioritization is to detect fault as early as possible. Test case prioritization becomes a challenge in Component-based Software System (CBSS) which facilitates development of complex systems by integrating the reusable components. CBSS has emerged as an approach that offers rapid development of system using fewer resources and effort. The core idea of reuse and reducing the development costs can be achieved if the components offer reliable services. Thus, integration of components and testing become an important phase in CBSS. Integration of components involves understanding communication and coordination between the components. Developers do not provide the sufficient information on these components. As a result of this, understanding of component interactions while integrating these components becomes a challenge. Testing components is a challenging area of research. There have been troubles integrating the components. This in turn affects the quality and reliability of the software. Our research aims at analysing the existing test case prioritization techniques in code based, requirement based and model based prioritization\u00a0\u2026", "num_citations": "29\n", "authors": ["475"]}
{"title": "Dynamic slicing of aspect-oriented programs\n", "abstract": " Rajeev Kumar and Rajib Mall Department of CSE Indian Institute of Technology Kharagpur-721302, India E-mail:{rkumar, rajib}@ cse. iitkgp. ernet. in", "num_citations": "28\n", "authors": ["475"]}
{"title": "Computational Intelligence in Data Mining-Volume 3: Proceedings of the International Conference on CIDM, 20-21 December 2014\n", "abstract": " The contributed volume aims to explicate and address the difficulties and challenges for the seamless integration of two core disciplines of computer science, ie, computational intelligence and data mining. Data Mining aims at the automatic discovery of underlying non-trivial knowledge from datasets by applying intelligent analysis techniques. The interest in this research area has experienced a considerable growth in the last years due to two key factors:(a) knowledge hidden in organizations\u2019 databases can be exploited to improve strategic and managerial decision-making;(b) the large volume of data managed by organizations makes it impossible to carry out a manual analysis. The book addresses different methods and techniques of integration for enhancing the overall goal of data mining. The book helps to disseminate the knowledge about some innovative, active research directions in the field of data mining, machine and computational intelligence, along with some current issues and applications of related topics.", "num_citations": "25\n", "authors": ["475"]}
{"title": "MODEL BASED OBJECT-ORIENTED SOFTWARE TESTING.\n", "abstract": " Testing is an important phase of quality control in Software development. Software testing is necessary to produce highly reliable systems. The use of a model to describe the behavior of a system is a proven and major advantage to test. In this paper, we focus on model-based testing. The term model-based testing refers to test case derivation from a model representing software behavior. We discuss model-based approach to automatic testing of object oriented software which is carried out at the time of software development. We review the reported research result in this area and also discuss recent trends. Finally, we close with a discussion of where model-based testing fits in the present and future of software engineering.", "num_citations": "24\n", "authors": ["475"]}
{"title": "Prioritizing test scenarios from UML communication and activity diagrams\n", "abstract": " Due to the large size and complexity of software, exhaustive testing becomes impossible. Hence, testing must be done in an optimized way keeping in mind factors, such as requirements of the customer, cost and time. For this, there is a need to generate test cases and exercise them to gain maximum throughput by uncovering defects. Test case/scenario prioritization is a well known and efficient technique to ensure the software quality. Prioritization of test scenarios helps in early detection of bugs. In this paper, we present an integrated approach and a prioritization technique to generate cluster-level test scenarios from UML communication and activity diagrams. In our approach, we first construct a tree representation of communication diagrams, and then a tree representation of activity diagrams. We convert them into an intermediate tree named as COMMACT tree. We, then carry out a post-order traversal\u00a0\u2026", "num_citations": "23\n", "authors": ["475"]}
{"title": "Risk analysis: a guiding force in the improvement of testing\n", "abstract": " The authors propose a state\u2010based risk assessment methodology at the analysis and design stage of Software Development Life Cycle. First, a method is proposed to estimate the risk for various states of a component within a scenario and then, the risk for the whole scenario is estimated. The key data needed for risk assessment are complexity and severity. An Inter\u2010Component State\u2010Dependence Graph is introduced to estimate the complexity for a state of a component within a system. The severity for a component within a scenario is decided based on three hazard techniques: Functional Failure Analysis, Software Failure Mode and Effect Analysis and Software Fault Tree Analysis. The risk for a scenario is estimated based on the risk of interacting components in various states within the scenario and State COllaboration TEst Model of the scenario. Finally, the system risk is estimated based on two inputs\u00a0\u2026", "num_citations": "23\n", "authors": ["475"]}
{"title": "Model based test case prioritization for testing component dependency in cbsd using uml sequence diagram\n", "abstract": " Software maintenance is an important and costly activity of the software development lifecycle. To ensure proper maintenance the software undergoes regression testing. It is very inefficient to re execute every test case in regression testing for small changes. Hence test case prioritization is a technique to schedule the test case in an order that maximizes some objective function. A variety of objective functions are applicable, one such function involves rate of fault detection-a measure of how quickly faults are detected within the testing process. Early fault detection can provide a faster feedback generating a scope for debuggers to carry out their task at an early stage. In this paper we propose a method to prioritize the test cases for testing component dependency in a Component Based Software Development (CBSD) environment using Greedy Approach. An Object Interaction Graph (OIG) is being generated from the UML sequence diagrams for interdependent components. The OIG is traversed to calculate the total number of inter component object interactions and intra component object interactions. Depending upon the number of interactions the objective function is calculated and the test cases are ordered accordingly. This technique is applied to components developed in Java for a software system and found to be very effective in early fault detection as compared to non-prioritize approach.", "num_citations": "22\n", "authors": ["475"]}
{"title": "Multi-objective test prioritization via a genetic algorithm\n", "abstract": " It is a challenging job for the software industry to release a product with the right quality level at the right time. There are some components within a software system that are more critical to the system\u2019s operation than others. Faults in components with high criticality are responsible directly or indirectly for causing high failure rate of the overall system compared to same faults in components with low criticality. Estimating the criticality of a component at the design level and focusing test effort per component based on the estimated criticality of the component helps to improve the reliability of a system within the available test resources. The objective is to identify the criticality level of a component at the design level and make a better test plan so that the high-critical components would be tested more completely and rigorously than other less-critical components. We first propose a method to estimate the criticality\u00a0\u2026", "num_citations": "21\n", "authors": ["475"]}
{"title": "A model based prioritization technique for component based software retesting using uml state chart diagram\n", "abstract": " Regression testing is the process of testing a modified system using the old test suite. As the test suite size is large, system retesting consumes large amount of time and computing resources. This issue of retesting of software systems can be handled using a good test case prioritization technique. A prioritization technique schedules the test cases for execution so that the test cases with higher priority executed before lower priority. The objective of test case prioritization is to detect fault as early as possible so that the debuggers can begin their work earlier. In this paper we propose a new prioritization technique to prioritize the test cases to perform regression testing for Component Based Software System (CBSS). The components and the state changes for a component based software systems are being represented by UML state chart diagrams which are then converted into Component Interaction Graph (CIG) to\u00a0\u2026", "num_citations": "21\n", "authors": ["475"]}
{"title": "A survey on test case generation from UML model\n", "abstract": " Testing is an important phase of software development, to maintain the quality control and reliability of the end products. Recent approach has been taken by the researcher to use UML models for test case generation. Various works has been done on test case generation for concurrent and nonconcurrent systems. In case of concurrent system group of activities are executed simultaneously where as in case of nonconcurrent system the activities are executed sequentially. Some of the work has also been done for generating test cases from combinational UML models. In this paper we have gone through a survey on test case generation from UML models. Our works focus on finding the existing process of test case generation from UML model/s for concurrent as well as nonconcurrent systems. This paper will make help to the researcher interested in the field of test case generation from UML model to find out what work has been done in their interested field. We have gone through 15 articles which have been published in the time span of 2005-2010.", "num_citations": "21\n", "authors": ["475"]}
{"title": "An improved distributed concolic testing approach\n", "abstract": " Distributed concolic testing (DCT) for complex programs takes a remarkable computational time. Also, the achieved modified condition/decision coverage (MC/DC) for such programs is often inadequate. We propose an improved DCT approach that reduces the computational time and simultaneously enhanced the MC/DC. We have named our approach SMCDCT (scalable MC/DC percentage calculator using DCT). Our experimental study on forty\u2010five C programs indicates 6.62% of average increase in MC/DC coverage. Copyright \u00a9 2016 John Wiley & Sons, Ltd.", "num_citations": "20\n", "authors": ["475"]}
{"title": "An edge marking technique for dynamic slicing of object-oriented programs\n", "abstract": " We propose a new dynamic slicing technique for object-oriented programs that is more efficient than the related algorithms. We use an extended system dependence graph (ESDG) as the intermediate program representation. Our dynamic slicing algorithm is based on marking and unmarking the edges in the ESDG as and when dependencies arise and cease during runtime.", "num_citations": "20\n", "authors": ["475"]}
{"title": "A node-marking technique for dynamic slicing of aspect-oriented programs\n", "abstract": " We propose an efficient dynamic slicing technique for aspect-oriented programs. We use a dependence- based intermediate program representation called extended aspect-oriented system dependence graph (EASDG) to represent aspect-oriented software. The EASDG of an aspect-oriented program consists of a system dependence graph (SDG) for non-aspect code, a group of dependence graphs for aspect code and some additional dependence edges used to connect the system dependence graph for non-aspect code to the dependence graphs for aspect code. Our dynamic slicing algorithm is based on marking and unmarking of the executed nodes in EASDG appropriately during run-time. In our approach, we do not use any trace file to store the execution history. Also, our approach does not create any additional nodes during run-time. We use the term node and vertex interchangeably in this paper.", "num_citations": "19\n", "authors": ["475"]}
{"title": "Dynamic slicing of object-oriented programs\n", "abstract": " DSpace at My University: Dynamic Slicing of Object-Oriented Programs Skip navigation DSpace logo Home Browse Communities & Collections Browse Items by: Issue Date Author Title Subject Sign on to: My DSpace Receive email updates Edit Profile DSpace JSPUI DSpace preserves and enables easy and open access to all types of digital content including text, images, moving images, mpegs and data sets Learn More DSpace logo 1.DSpace at My University 2. Ph.D Theses of IIT Kharagpur 3.Computer Science & Engineering 4.Dynamic Slicing of Object-Oriented Programs Please use this identifier to cite or link to this item: http://www.idr.iitkgp.ac.in/xmlui/handle/123456789/5173 Title: Dynamic Slicing of Object-Oriented Programs Authors: Mohapatra, Durga Prasad Keywords: Communication Issues Algorithm Edge Marking Dynamic Slicing Node Marking Dynamic Slicing Extended System Dependence Graph : 't \u2026", "num_citations": "19\n", "authors": ["475"]}
{"title": "Enhanced modified condition/decision coverage using exclusive-nor code transformer\n", "abstract": " In regulated domains such as aerospace and safety critical domains, software quality assurance is subjected to strict regulations such as the DO-178B standard. MC/DC is a white box software testing criteria aiming to prove all the conditions involved in a predicate that can influence the predicate value in the desired way. Though MC/DC is a coverage criterion, existing automated test data generation approaches like CONCOLIC testing do not support MC/DC. In this paper, we propose an automated technique to generate a test suite that helps in achieving an increase in MC/DC coverage of a program under test. We use code transformation technique which consists of two steps: identification of predicates and generation of empty true-false if-else statements. The empty conditional statements are based on the concepts of exclusive nor (X-NOR) operations. This transformed program is inserted into the CREST TOOL\u00a0\u2026", "num_citations": "18\n", "authors": ["475"]}
{"title": "Minimal testcase generation for object-oriented software with state charts\n", "abstract": " Today statecharts are a de facto standard in industry for modeling system behavior. Test data generation is one of the key issues in software testing. This paper proposes an reduction approach to test data generation for the state-based software testing. In this paper, first state transition graph is derived from state chart diagram. Then, all the required information are extracted from the state chart diagram. Then, test cases are generated. Lastly, a set of test cases are minimized by calculating the node coverage for each test case. It is also determined that which test cases are covered by other test cases. The advantage of our test generation technique is that it optimizes test coverage by minimizing time and cost. The present test data generation scheme generates test cases which satisfy transition path coverage criteria, path coverage criteria and action coverage criteria. A case study on Railway Ticket Vending Machine (RTVM) has been presented to illustrate our approach.", "num_citations": "18\n", "authors": ["475"]}
{"title": "Automated test case generation and its optimization for path testing using genetic algorithm and sampling\n", "abstract": " Software testing is an important activity of the software development process, and automated test case generation contributes to reduce cost and time efforts. In this paper, we have used genetic algorithm to optimize the test cases that are generated using the category-partition and test harness patterns. In order to investigate the effectiveness of the approach, a graph is derived using category-partition and genetic algorithm is used to optimize the test cases to cover the entire possible path. The optimal test suites are devised by the method of sampling statistics.", "num_citations": "18\n", "authors": ["475"]}
{"title": "Test case design using conditioned slicing of activity diagram\n", "abstract": " For testing software, test case generation is the most important part. The automation of specification based test case generation needs formal or semi formal specification. As a semiformal modeling, UML is widely used to describe analysis and design specification by both academia and industry. Thus UML models become the sources of test case generation naturally. This paper proposes a method to generate test cases from UML activity diagrams. We have proposed conditioned slicing as a general slicing framework for test case generation from activity diagrams. Our method first builds a flow dependence graph from an ordinary UML activity diagram and then applies conditioned slicing on a predicate node of the graph, to generate test cases. It minimizes the number of test cases generated while deriving all practically useful test cases. The effectiveness of a test case is based on how well the test covers and exercises the modeled behaviors. Our proposed method satisfies high path coverage criterion.", "num_citations": "17\n", "authors": ["475"]}
{"title": "Test case generation for concurrent system using UML combinational diagram\n", "abstract": " The unreasonable interference of concurrent threads makes the testing activity for concurrent systems a difficult task. Test case explosion is the major problem in concurrency testing and make an interruption in systematic testing of concurrent systems. In this paper we propose an approach of generating test cases from combinational UML models. In our approach Activity Diagram (AD) and Sequence Diagram (SD) are used to model a system. The AD has converted into a graph called Activity Graph (AG) and SD into a graph called Sequence Graph (SG). Finally AG and SG are combined to form a graph called Activity Sequence Graph (ASG). The ASG is traversed using a traversing algorithm to generate the test cases. After comparing the test cases generated from ASG with the test cases generated from AG and SG, it is found that the test cases generated from ASG gives a better coverage when compared with the test cases from single modelling graph. The test cases are generated by controlling the test case explosion and are useful for controlling synchronization fault, loop fault, as well as scenario faults and interaction faults.", "num_citations": "16\n", "authors": ["475"]}
{"title": "J3 model: a novel framework for improved modified condition/decision coverage analysis\n", "abstract": " In the real-time systems and safety critical domains, software quality assurance adheres to protocols such as DO-178C standard. Regarding these issues, concolic testing generates test cases that can attain high coverage using an augmented approach based on Modified Condition/Decision Coverage (MC/DC). In this paper, we propose a framework to compute MC/DC percentage for test case generation. To achieve an increase in MC/DC, we transform the input Java program, J, into its transformed version, J\u2032, using Java Program Code Transformer (JPCT). Then, we use JCUTE tool to generate test cases. At last, we use Java Coverage Analyzer (JCA) to compute MC/DC percentage. The Java program code transformer adds additional empty nested if-else conditional statements for each decision that causes variation in MC/DC percentage. In later step, these extra conditional statements get stripped-off. This\u00a0\u2026", "num_citations": "15\n", "authors": ["475"]}
{"title": "Automated test case generation and optimization: a comparative review\n", "abstract": " Software testing is the primary phase, which is performed during software development and it is carried by a sequence of instructions of test inputs followed by expected output. Evolutionary algorithms are most popular in the computational field based on population. The test case generation process is used to identify test cases with resources and also identifies critical domain requirements. The behavior of bees is based on population and evolutionary method. Bee Colony algorithm (BCA) has gained superiority in comparison to other algorithms in the field of computation. The Harmony Search (HS) algorithm is based on the enhancement process of music. When musicians compose the harmony through different possible combinations of the music, at that time the pitches are stored in the harmony memory and the optimization can be done by adjusting the input pitches and generate the perfect harmony. Particle Swarm Optimization (PSO) is an intelligence based meta-heuristic algorithm where each particle can locate their source of food at different position.. In this algorithm, the particles will search for a better food source position in the hope of getting a better result. In this paper, the role of Artificial Bee Colony, particle swarm optimization and harmony search algorithms are analyzed in generating random test data and optimized those test data. Test case generation and optimization through bee colony, PSO and harmony search (HS) algorithms which are applied through a case study, ie, withdrawal operation in Bank ATM and it is observed that these algorithms are able to generate suitable automated test cases or test data in a client manner\u00a0\u2026", "num_citations": "15\n", "authors": ["475"]}
{"title": "A firefly algorithm based approach for automated generation and optimization of test cases\n", "abstract": " Revised: 10/Jul/2016 Accepted: 16/Aug/2016 Published: 31/Aug/2016 Abstract-Software testing requires functional and non functional test cases with the values of test data. Automated testing are a method to generate the test cases with test data automatically. Optimality of test case is required for fastest data generation. Test case optimization through search based techniques is used to optimize and generate optimal test cases from the set of data values. Firefly Algorithm (FA) is a bio-inspired, evolutionary, meta-heuristic algorithm based on mating or flashing behavior of fireflies. In this paper the role of Firefly meta-heuristic search technique which is analyzed to generate and optimize random test cases with test data by applying in a case study, ie, a withdrawal method in Bank ATM and it is observed that this algorithm is able to generate suitable automated test cases as well as test data. In this case the test case generation is very efficient and effective. This paper further, gives the brief details about the Firefly method which is used for test case generation and optimization.", "num_citations": "15\n", "authors": ["475"]}
{"title": "Test case creation from UML sequence diagram: a soft computing approach\n", "abstract": " Unified modeling language (UML) is used to design the tests in various levels of testing. To create the test cases from the source code using traditional methods is becoming very difficult and cumbersome in cluster levels. UML artifacts provide a lot of facts which help the user to navigate through the flaws from the designed documents. In this work, we propose a method for creating the test cases using sequence diagram of UML models. As the testing can be started from the design process at the beginning phase, we preferred this approach. We proposed a model to generate a sequence flow chart (SFC) from sequence diagram and then tried to convert it to message control flow graph (MCFG). By using message sequence path coverage criterion, we traversed the MCFG and the test paths are generated. The test cases from these paths are created subsequently. Finally, genetic algorithm has been applied to\u00a0\u2026", "num_citations": "15\n", "authors": ["475"]}
{"title": "Making a concolic tester achieve increased MC/DC\n", "abstract": " Concolic testing techniques do not necessarily aim to achieve a specific MC/DC coverage. On the other hand, MC/DC is considered as a standard and a strong test coverage criterion. It is mandated for many categories of applications such as safety critical software. We present an automated code transformation technique that can be used as a front end to a concolic tester for achieving high MC/DC. Our experimentation on seventeen moderately complex programs shows that our approach achieves higher MC/DC over traditional concolic tester on the average by 24.84\u00a0%, for the code we tested.", "num_citations": "14\n", "authors": ["475"]}
{"title": "A survey of computational intelligence approaches for software reliability prediction\n", "abstract": " Computational Intelligence has been known to be very useful in predicting software reliability. In this paper, two kinds of investigations are performed. First, we provide a systematic review of Software Reliability Prediction studies with consideration of various metrics, methods and CI techniques (including fuzzy logic, neural networks, genetic algorithms). Second, reliability prediction and data collection with the help of various available tools are discussed. The overall idea of this paper is to present, analyze, investigate, compare and discuss software reliability prediction with various CI techniques and tools and their advantages and disadvantages.", "num_citations": "14\n", "authors": ["475"]}
{"title": "An efficient technique for dynamic slicing of concurrent Java programs\n", "abstract": " Program slice has many applications such as program debugging, testing, maintenance and complexity measurement. We propose a new dynamic program slicing technique for concurrent Java programs that is more efficient than the related algorithms. We introduce the notion of Concurrent Program Dependence Graph (CPDG). Our algorithm uses CPDG as the intermediate representation and is based on marking and unmarking the edges in the CPDG as and when the dependencies arise and cease during run-time. Our approach eliminates the use of trace files and is more efficient than the existing algorithms.", "num_citations": "14\n", "authors": ["475"]}
{"title": "Model based test case prioritization using UML behavioural diagrams and association rule mining\n", "abstract": " In software development life cycle, maximum effort is spent on the maintenance phase. This is due to the retesting carried out in this phase to ensure that any moderation made to the system under test (SUT) does not hamper the unchanged components of the SUT. This retesting is a part of regression testing which is performed in the maintenance phase. But in the retesting approach, all the old test cases are re-executed which leads to increase in cost and time of testing. So, test case prioritization technique is widely used to overcome this problem i.e. to keep the testing cost and time down. Test case prioritization techniques schedule the test cases for regression testing in an order that improves rate of fault detection, coverage percentage etc. To improve the fault detection rate, we propose an approach for prioritizing the test cases by using multiple modified functions and association rule mining. Since,\u00a0we\u00a0\u2026", "num_citations": "13\n", "authors": ["475"]}
{"title": "A slice-based change impact analysis for regression test case prioritization of object-oriented programs\n", "abstract": " Test case prioritization focuses on finding a suitable order of execution of the test cases in a test suite to meet some performance goals like detecting faults early. It is likely that some test cases execute the program parts that are more prone to errors and will detect more errors if executed early during the testing process. Finding an optimal order of execution for the selected regression test cases saves time and cost of retesting. This paper presents a static approach to prioritizing the test cases by computing the affected component coupling (ACC) of the affected parts of object-oriented programs. We construct a graph named affected slice graph (ASG) to represent these affected program parts. We determine the fault-proneness of the nodes of ASG by computing their respective ACC values. We assign higher priority to those test cases that cover the nodes with higher ACC values. Our analysis with mutation faults shows that the test cases executing the fault-prone program parts have a higher chance to reveal faults earlier than other test cases in the test suite. The result obtained from seven case studies justifies that our approach is feasible and gives acceptable performance in comparison to some existing techniques.", "num_citations": "13\n", "authors": ["475"]}
{"title": "Skewness-based min-min max-min heuristic for grid task scheduling\n", "abstract": " Skewness plays a very important role in task scheduling. It measures the degree of asymmetry in a data set.Moreover, the data set may be positively skewed or negatively skewed. The quartile coefficient of skewness lies in between -1 to 1. If the quartile coefficient is in between -1 to 0, then the data set is negatively skewed. Otherwise, it is positively skewed. Min-Min and Max-Min heuristic underperforms if the data set is positively skewed and negative skewed respectively. In order to overcome this problem, we have proposed a hybrid heuristic called Skewness-Based Min-Min Max-Min (SBM2). This heuristic selects one of the heuristics (Min-Min or Max-Min)based on the skewness value. It can be calculated using three factors: first quartile, second quartile (or median) and third quartile. Simulation results show that the proposed hybrid heuristic minimizes the makespan and handle the skewed data set.", "num_citations": "13\n", "authors": ["475"]}
{"title": "Prioritizing test cases using business criticality test value\n", "abstract": " Software maintenance is an important and costly activity of the software development lifecycle. Regression testing is the process of validating modifications introduced in a system during software maintenance. It is very inefficient to re-execute every test case in regression testing for small changes. This issue of retesting of software systems can be handled using a good test case prioritization technique. A prioritization technique schedules the test cases for execution so that the test cases with higher priority executed before lower priority. The objective of test case prioritization is to detect fault as early as possible. Early fault detection can provide a faster feedback generating a scope for debuggers to carry out their task at an early stage. Model Based Prioritization has an edge over Code Based Prioritization techniques. The issue of dynamic changes that occur during the maintenance phase of software development can only be addressed by maintaining statistical data for system models, change models and fault models. In this paper we present a novel approach for test case prioritization by evaluating the Business Criticality Value (BCV) of the various functions present in the software using the statistical data. Then according to the business criticality value of various functions present in the change and fault model we prioritize the test cases are prioritized.", "num_citations": "13\n", "authors": ["475"]}
{"title": "Elements of Discrete Mathematics A Computer Oriented Approach\n", "abstract": " Digital Library preserves and enables easy and open access to all types of digital content including text, images, moving images, mpegs and data sets and make it available to the entire scholarly community in open access.", "num_citations": "13\n", "authors": ["475"]}
{"title": "A novel approach for optimized test case generation using activity and collaboration diagram\n", "abstract": " Testing is the process of building confidence of the programmer that shows, the software does what it is intended to do, which in turn improves the reliability of the software. And automation of software testing process helps in achieving it with reduced cost and time. Test case generation is one part of the testing process with description of a test and independent of designed system, intended to find errors. The advantage of generation of test cases from specifications and design is that they can be available during early phase of the software development life cycle and there is no need to wait for development of codes to test the software. Additionally early test case generation reduces errors, inconsistencies and ambiguities, during the life cycle, because developers can use test cases to control their program to conform to the software specification. In this paper we have applied Constraint-based Genetic Algorithm technique to generate optimized test cases from UML Activity diagram and Collaboration diagram. Our proposed approach is more effective, which uncovers more number of errors, by using combinatorial optimization technique such as genetic algorithm with transition coverage, a test adequacy criterion as a constraint. We have defined an error minimization technique in our approach, which works as a basic principle for optimized test case generation. That means the generated test case have lower chance of presence of errors, by discarding the rest. The proposed approach is discussed by considering ATM cash withdrawal as a case study.", "num_citations": "13\n", "authors": ["475"]}
{"title": "Model driven test case optimization of UML combinational diagrams using hybrid bee colony algorithm\n", "abstract": " To detect faults or errors for designing the quality software, software testing tool is used. Testing manually is an expensive and time taking process. To overcome this problem automated testing is used. Test case generation is a vital concept used in software testing which can be derived from requirements specification. Automation of test cases is a method where it can generate the test cases and test data automatically by using search based optimization technique. Model-driven testing is an approach that represents the behavioral model and also encodes the system behavior with certain conditions. Generally, the model consists of a set of objects that defined through variables and object relationships. This piece of work is used to generate the automated optimized test cases or test data with the possible test paths from combinational system graph. A hybrid bee colony algorithm is proposed in this paper for generating and optimizing the test cases from combinational UML diagrams.", "num_citations": "12\n", "authors": ["475"]}
{"title": "Model based test case prioritization using association rule mining\n", "abstract": " Regression testing has gained importance due to increase in frequency of change requests made for software during maintenance phase. The retesting criteria of regression testing leads to increasing cost and time. Prioritization is an important procedure during regression testing which makes the debugging easier. This paper discusses a novel approach for test case prioritization using Association Rule Mining (ARM). In this paper, the system under test is modelled using UML Activity Diagram (AD) which is further converted into an Activity Graph (AG). A historical data store is maintained to keep details about the system which revealing more number of faults. Whenever a change is made in the system, the frequent patterns of highly affected nodes are found out. These frequent patterns reveal the probable affected nodes i.e. used to prioritize the test cases. This approach effectively prioritizes the test cases\u00a0\u2026", "num_citations": "12\n", "authors": ["475"]}
{"title": "A unique aspect-oriented program slicing technique\n", "abstract": " The Aspect-oriented programming is a different type of programming methodology, than that of Object-oriented programming. But while coming to slicing, many researchers have treated AOP slicing similar to OOP slicing. We have introduced a different approach to slice an AOP, where we have proposed an algorithm that compute slices depending upon the slice point location in the program. Also the program slices computed by many researchers are not fully executable. The main aim of our approach is to create an executable slice. In this paper we have used AspectJ to find the dynamic information of the target program. In this paper we have also shown comparison of our work with some others.", "num_citations": "12\n", "authors": ["475"]}
{"title": "Regression test suite minimization using integer linear programming model\n", "abstract": " Software testers always face the dilemma of whether to retest the software with all the test cases or select a few of them on the basis of their fault detection ability. This paper introduces a novel approach to minimizing the test suite as an integer linear programming problem with optimal results. The minimization method uses the cohesion values of the program parts affected by the changes made to the program. The hypothesis is that the program parts with low cohesion values are more prone to errors. This assumption is validated on the mutation fault detection ability of the test cases. The experimental study carried out on 30 programs evaluates the effectiveness and usefulness of the proposed framework. The experimental results show that the minimized test suite can efficiently reveal the errors and ensure acceptable software quality. Copyright \u00a9 2017 John Wiley & Sons, Ltd.", "num_citations": "11\n", "authors": ["475"]}
{"title": "Software Reliability Prediction using Fuzzy Min-Max Algorithm and Recurrent Neural Network Approach.\n", "abstract": " Fuzzy Logic (FL) together with Recurrent Neural Network (RNN) is used to predict the software reliability. Fuzzy Min-Max algorithm is used to optimize the number of the kgaussian nodes in the hidden layer and delayed input neurons. The optimized recurrent neural network is used to dynamically reconfigure in real-time as actual software failure. In this work, an enhanced fuzzy min-max algorithm together with recurrent neural network based machine learning technique is explored and a comparative analysis is performed for the modeling of reliability prediction in software systems. The model has been applied on data sets collected across several standard software projects during system testing phase with fault removal. The performance of our proposed approach has been tested using distributed system application failure data set.", "num_citations": "11\n", "authors": ["475"]}
{"title": "Generating prioritized test sequences using firefly optimization technique\n", "abstract": " The aim of this study is to propose an algorithm for generating minimal test sequences by applying Firefly optimization technique. In this study, we use state machine diagram for the behavioral specification of software. This paper generates the important test sequences for composite states in the state machine diagram under consideration. The generated test sequences are then prioritized based on a software coverage criterion. The use of firefly technique results in efficient prioritization of the generated test sequences.", "num_citations": "11\n", "authors": ["475"]}
{"title": "Model based test case generation from uml sequence and interaction overview diagrams\n", "abstract": " Test case generation is the most crucial job of testing paradigm. Unified Modelling Language (UML) model, give a lot of information for testing which is accepted widely by both the academia and industry. By using UML artifacts the early detection of faults can be achieved during designing while the architectural overview of the software is considered. Using a specific diagram of UML certainly helpful in detecting the flaws. But combining different UML components, more test cases can be generated and different types of faults can be captured by reducing the redundants. In this paper, we propose a method using Sequence Diagram (SD) and Interaction Overview Diagram (IOD) to generate the test cases. An intermediate graph is generated known as Sequence Interaction Graph (SIG) by combining Message Sequence Dependency Graph (MSDG) generated from the sequence diagram and Interaction Graph\u00a0\u2026", "num_citations": "11\n", "authors": ["475"]}
{"title": "Context sensitive dynamic slicing of concurrent aspect-oriented programs\n", "abstract": " This paper presents a context-sensitive dynamic slicing technique for concurrent AOPs having multiple threads. To effectively represent the concurrent AOP, we propose an intermediate graph called Multithreaded Aspect-Oriented Dependence Graph (MAODG). Based on this intermediate representation, we design a precise and accurate dynamic slicing algorithm for concurrent AOPs. This algorithm takes the MAODG of the concurrent AOP and a slicing criterion as input and computes the dynamic slice for the given concurrent AOP.", "num_citations": "11\n", "authors": ["475"]}
{"title": "Intelligent computing, networking, and informatics\n", "abstract": " The proceedings of the International Conference on Advanced Computing, Networking, and Informatics (ICACNI 2013), at Central Institute of Technology Raipur, Chhattisgarh, India during 12\u201314 June record scientific and engineering progress in both theoretical and applied sections of Computer Science and related fields. The proceedings contain technical articles, reports, and case studies on computing, networking, and informatics. Along with these main tracks, there were two special sessions organized for recording specific advancements in the domains of image and video processing and biometric security. The conference also sported a special industrial track to mark the relevant research achievements from the industry. Out of 458 articles received for consideration for publication, 135 have been selected through a single-blind peer review process. Each article has been reviewed by at least two reviewers. Academicians, scholars, industry professionals, and practitioners have contributed to this conference by submitting their valuable research works, which has led this conference to a success. A dedicated committee of several professors and academicians from premier institutes, such as the IITs and the NITs, has served to manifest the conference successful. We sincerely thank all our chairs and committees. We are grateful to the reviewers who, despite their busy schedules, have supported us by providing review reports within the stipulated time. We would like to thank Central Institute of Technology Raipur for organizing and providing the venue for the conference. Our hearty thanks go to the Department of Computer Science and\u00a0\u2026", "num_citations": "11\n", "authors": ["475"]}
{"title": "Generation and optimization of test cases for object-oriented software using state chart diagram\n", "abstract": " The process of testing any software system is an enormous task which is time consuming and costly. The time and required effort to do sufficient testing grow, as the size and complexity of the software grows, which may cause overrun of the project budget, delay in the development of software system or some test cases may not be covered. During SDLC (software development life cycle), generally the software testing phase takes around 40-70% of the time and cost. State-based testing is frequently used in software testing. Test data generation is one of the key issues in software testing. A properly generated test suite may not only locate the errors in a software system, but also help in reducing the high cost associated with software testing. It is often desired that test data in the form of test sequences within a test suite can be automatically generated to achieve required test coverage. This paper proposes an optimization approach to test data generation for the state-based software testing. In this paper, first state transition graph is derived from state chart diagram. Then, all the required information are extracted from the state chart diagram. Then, test cases are generated. Lastly, a set of test cases are minimized by calculating the node coverage for each test case. It is also determined that which test cases are covered by other test cases. The advantage of our test generation technique is that it optimizes test coverage by minimizing time and cost. The proposed test data generation scheme generates test cases which satisfy transition path coverage criteria, path coverage criteria and action coverage criteria. A case study on Automatic Ticket Machine\u00a0\u2026", "num_citations": "11\n", "authors": ["475"]}
{"title": "Prioritizing Program elements: A pretesting effort to improve software quality\n", "abstract": " Improving the efficiency of a testing process is a challenging task. Prior work has shown that often, a small number of bugs account for the majority of the reported software failures; and often, most bugs are found in a small portion of the source code of a program.  First, prioritizing the code elements according to their criticality and then conducting testing, will promote to reveal the important bugs at the early phase of testing. Keeping it in view, we propose an efficient test effort prioritization method that give a chance to the tester to focus more on the parts of the source code that are highly influenced towards the system failures or in which, the failures have high impact on the system. We consider five important factors such as influence towards system failures, average execution time, structural complexity, severity, and business value associated with a component and estimates the criticality of the component within a system. We have experimentally proved that our proposed test effort prioritization approach is effective in revealing important bugs at the early phase of testing as it is linked to external measure of defect severity and business value, internal measure of frequency, complexity, and coupling.", "num_citations": "11\n", "authors": ["475"]}
{"title": "GECOJAP: A novel source-code preprocessing technique to improve code coverage\n", "abstract": " Safety critical standards such as DO178B/DO178C/ RTCA (Radio Technical Commission for Aeronautics) mandates coverage based testing in Aerospace applications. These standards mandate Level A certification for Modified Condition/Decision Coverage (MC/DC). To perform exhaustive and rigorous testing, concolic testing is used in the testing phase of the software development life cycle. But, still some concolic testers need to improve their performance, so that they can achieve higher coverage. We present an automated Java code transformation technique that can be used as a front-end to concolic testing tool for achieving high coverage. We have developed our tool using four modules. The tool named GEaring COverage for JAva Program (GECOJAP) for implementation of our approach. The first module shows a source code preprocessing technique called JEX-NCT (Java Exclusive-NOR Code Transformer\u00a0\u2026", "num_citations": "10\n", "authors": ["475"]}
{"title": "Dynamic slicing of distributed Aspect-Oriented Programs: A context-sensitive approach\n", "abstract": " This paper presents a dynamic parallel context-sensitive slicing algorithm for distributed AOPs. The context-sensitivity makes the computed slice more precise and accurate. We introduce parallelism in our algorithm to make slice computation faster. We have developed a tool called D-AspectJ slicer to compute dynamic slices for distributed AOPs. The proposed slicing technique is compared with two other related existing techniques using ten case studies. The experimentation shows that our proposed slicing algorithm generates smaller slices in less time as compared to other two existing algorithms.", "num_citations": "10\n", "authors": ["475"]}
{"title": "An approach for computing dynamic slice of concurrent aspect-oriented programs\n", "abstract": " We propose a dynamic slicing algorithm to compute the slice of concurrent aspect-oriented programs. We use a dependence based intermediate program representation called Concurrent Aspect-oriented System Dependence Graph (CASDG) to represent a concurrent aspect-oriented program. The CASDG of an aspect-oriented program consists of a system dependence graph (SDG) for the non-aspect code, a group of dependence graphs for aspect code and some additional dependence edges used to connect the system dependence graph for the non-aspect code to dependence graph for aspect code. The proposed dynamic slicing al-gorithm is an extended version of NMDS algorithm for concurrent object-oriented programs, which is based on marking and unmarking of the executed nodes in CASDG appropriately during run-time.", "num_citations": "10\n", "authors": ["475"]}
{"title": "Test case generation for concurrent object-oriented systems using combinational UML models\n", "abstract": " Software testing is an important phase of software development to ensure the quality and reliability of the software. Due to some limitations of code based testing method, the researcher has been taken a new method to work upon UML model based testing. It is found that different UML model is having different coverage and capable of detecting different kinds of faults. Here we have taken combinational UML models to have better coverage and fault detection capability. Testing concurrent system is difficult task because due to concurrent interaction among the threads and the system results in test case explosion. In this paper we have presented an approach of generating test cases for concurrent systems using combinational UML models ie sequence diagram and activity diagram. Then a Sequence-Activity Graph (SAG) is constructed from these two diagrams. Then that graph is traversed to generate test cases which are able to minimize test case explosion.", "num_citations": "10\n", "authors": ["475"]}
{"title": "Source code prioritization using forward slicing for exposing critical elements in a program\n", "abstract": " Even after thorough testing, a few bugs still remain in a program with moderate complexity. These residual bugs are randomly distributed throughout the code. We have noticed that bugs in some parts of a program cause frequent and severe failures compared to those in other parts. Then, it is necessary to take a decision about what to test more and what to test less within the testing budget. It is possible to prioritize the methods and classes of an object-oriented program according to their potential to cause failures. For this, we propose a program metric called influence metric to find the influence of a program element on the source code. First, we represent the source code into an intermediate graph called extended system dependence graph. Then, forward slicing is applied on a node of the graph to get the influence of that node. The influence metric for a method m in a program shows the number of\u00a0\u2026", "num_citations": "10\n", "authors": ["475"]}
{"title": "Generation of Test Scenarios Using Activity Diagram\n", "abstract": " Testing of software is a time-consuming activity which requires a great deal of planning and resources. In scenario-based testing, test scenarios are used for generating test cases, test drivers etc. UML is widely used to describe analysis and design specifications of software development. UML activity diagrams describe the realization of the operation in design phase and also support description of parallel activities and synchronization aspects involved in different activities perfectly. Therefore, test scenarios generated from activity diagrams will achieve test adequacy criteria perfectly. Handling parallel activities represented by fork-join pairs present in activity diagrams is also very difficult. Our approach generates test scenarios from UML activity diagrams, where the design is reused to avoid the cost of test model creation. This approach generates test scenarios from activity diagrams containing forkjoin pairs and also handles the complicacy of the fork-join pairs. A prototype tool has been developed to support the approach.", "num_citations": "10\n", "authors": ["475"]}
{"title": "Forecasting and trading strategy for the foreign exchange market\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "10\n", "authors": ["475"]}
{"title": "Effective software fault localization using a back propagation neural network\n", "abstract": " Effective fault localization is an essential\u00a0requirement of the software\u00a0development process. Back propagation neural network can be used for localizing the faults\u00a0effectively and efficiently. Existing\u00a0NN-based fault localization techniques take statement invocation information in binary terms to train the network. In this paper, we have proposed an efficient approach for fault localization using back propagation neural network and we have used the actual number of times the statement is executed to train the network. We have investigated our approach on Siemens suite. Results show that on an average there is 35% increase in the effectiveness over existing BPNN.", "num_citations": "9\n", "authors": ["475"]}
{"title": "An automated analysis of the branch coverage and energy consumption using concolic testing\n", "abstract": " The energy consumption of computer systems has become an important economic and environmental issue. Many researchers have focused on the energy consumption of hardware, but what about the software? Software energy consumption is widely adopted for Green computation of practical experimentation in research laboratories. But current researchers fail to build a consistent concept base for software energy consumption of critical applications. While branch coverage and concolic testing are very critical practices to validate the safety critical systems, very little effort is given to measure their energy consumption. The computation of the energy consumption of these techniques is an important issue in Green IT and Green Software Engineering. The contribution of this paper is to automate the computation and analysis of the energy consumption of the testing technique while enhancing the branch\u00a0\u2026", "num_citations": "9\n", "authors": ["475"]}
{"title": "Sentiment analysis for Odia language using supervised classifier: an information retrieval in Indian language initiative\n", "abstract": " Odisha state is in the eastern part of India and its language, Odia (                                    ) is the mother tongue and used by more than 40 million people of Odisha for writting. It is the tenth largest language as scheduled in the constitution part-VIII of India. Odisha has very old history and rich culture; its heritages are present in form Odia language text. So to mine and extract useful information of this language sentiment analysis has been used. Sentiment analysis technique is used for identifying the emotions behind the given text to understand the attitude, opinion and emotions expressed in the language. This paper investigates Sentiment analysis of Odia text using supervised classification techniques. We applied simple Naive Bayes (NB), Logistic Regression and SVM on Odia text and evaluate its effect. This system takes the Odia movie reviews and gives you the unbiased sentiments of the people in\u00a0\u2026", "num_citations": "9\n", "authors": ["475"]}
{"title": "Prediction strategy for software reliability based on recurrent neural network\n", "abstract": " Recurrent Neural Network (RNN) has been known to be very useful in predicting software reliability. In this paper, we propose a model that explores the applicability of Recurrent Neural Network with Back-propagation Through Time (RNNBPTT) learning to predict software reliability. The model has been applied on data sets collected across several standard software projects during system testing phase. Though the procedure is relatively complicated, the results depicted in this work suggest that RNN exhibits an accurate and consistent behavior in reliability prediction.", "num_citations": "9\n", "authors": ["475"]}
{"title": "ACCo: a novel approach to measure cohesion using hierarchical slicing of Java programs\n", "abstract": " Maintainability of program parts refers to the ease with which these parts can be modified. Many existing metrics of internal quality attributes such as cohesion, coupling, etc. have been used in this regard. Cohesiveness among program parts is considered as a strong measure for the maintainability of object-oriented components and to predict the probability of being erroneous. Our objective is to propose a novel graph-based cohesion metric to measure the maintainability of different program parts in an object-oriented program and predict their fault proneness. We compute the cohesion of the sliced component as a measure to predict its correctness and preciseness. In addition, we wish to theoretically validate the proposed technique against the existing guidelines of cohesion measurement and compare it with some existing techniques. We propose a new cohesion metric named affected component\u00a0\u2026", "num_citations": "9\n", "authors": ["475"]}
{"title": "A Novel Approach for Computing Dynamic Slices of Aspect-Oriented Programs\n", "abstract": " We propose a dynamic slicing algorithm to compute the slices of aspect-oriented programs. We use a dependence based intermediate program representation called Aspect System Dependence Graph (AOSG) to represent aspect-oriented programs. Then, we propose the dynamic slicing algorithm for AOPs, which is an extended version of EMDS algorithm for object-oriented programs. Our algorithm is based on marking and unmarking of the edges of AOSG appropriately during runtime.", "num_citations": "9\n", "authors": ["475"]}
{"title": "Model-based test-case generation for Simulink/Stateflow using dependency graph approach\n", "abstract": " Testing is an ultimate phase of product life cycle to which particular attention is paid, namely when dependability is of great importance. Modeling technology has been introduced into the software testing field. However how to carry through the testing modeling effectively is still a difficulty. Based on the combination of simulation modeling technology and dependability we have proposed an approach to generate test cases. In our approach, first, the system is modeled in MATLAB using Simulink/ Stateflow tool. After the model creation we verify that system and generate a dependency graph of that system. From that graph we generate test sequences.", "num_citations": "9\n", "authors": ["475"]}
{"title": "A novel approach for dynamic slicing of distributed object-oriented programs\n", "abstract": " Program slicing has many applications such as program debugging, testing and maintenance. We propose a new dynamic slicing technique for distributed object-oriented programs. We introduce the notion of Distributed Program Dependence Graph (DPDG). Our dynamic slicing technique uses DPDG as the intermediate program representation and is based on marking and unmarking the edges in the DPDG as and when the dependencies arise and cease during run-time. Our approach eliminates the use of trace files and is more efficient than the existing algorithms.", "num_citations": "9\n", "authors": ["475"]}
{"title": "Validating object-oriented software at design phase by achieving MC/DC\n", "abstract": " This paper deals with a new technique for validating object-oriented software at design phase of project development. There are several modeling diagrams used at design phase of Software Development Life Cycle. But in this paper, we focus on UML Activity Diagram. In our work, first we construct the UML activity diagram for the given system using ArgoUML. Then, the XML (\u201cEXtensible Markup Language\u201d) code is generated for the constructed activity diagram. Next, this XML code is translated to XSD (\u201cXML Schema Definition\u201d) code. This XSD code is given as input to JAXB (\u201cJava Architecture for XML Binding\u201d), which generates the Java template. Then, this Java template is instrumented to a complete Java program with minimal manual effort. Next, we carryout concolic testing of this Java code using jCUTE. This tool generates test cases by taking the Java program as input. Then, the obtained test suite\u00a0\u2026", "num_citations": "8\n", "authors": ["475"]}
{"title": "Automatic generation and optimization of test data using harmony search algorithm\n", "abstract": " Software testing is the primary phase, which is performed during software development and it is carried by a sequence of instructions of test inputs followed by expected output. The Harmony Search (HS) algorithm is based on the improvisation process of music. In comparison to other algorithms, the HSA has gain popularity and superiority in the field of evolutionary computation. When musicians compose the harmony through different possible combinations of the music, at that time the pitches are stored in the harmony memory and the optimization can be done by adjusting the input pitches and generate the perfect harmony. The test case generation process is used to identify test cases with resources and also identifies critical domain requirements. In this paper, the role of Harmony search meta-heuristic search technique is analyzed in generating random test data and optimized those test data. Test data are generated and optimized by applying in a case study ie a withdrawal task in Bank ATM through Harmony search. It is observed that this algorithm generates suitable test cases as well as test data and gives brief details about the Harmony search method. It is used for test data generation and optimization.", "num_citations": "8\n", "authors": ["475"]}
{"title": "Advanced Computing, Networking and Informatics-Volume 2: Wireless Networks and Security Proceedings of the Second International Conference on Advanced Computing, Networking and\u00a0\u2026\n", "abstract": " Advanced Computing, Networking and Informatics are three distinct and mutually exclusive disciplines of knowledge with no apparent sharing/overlap among them. However, their convergence is observed in many real world applications, including cyber-security, internet banking, healthcare, sensor networks, cognitive radio, pervasive computing amidst many others. This two-volume proceedings explore the combined use of Advanced Computing and Informatics in the next generation wireless networks and security, signal and image processing, ontology and human-computer interfaces (HCI). The two volumes together include 148 scholarly papers, which have been accepted for presentation from over 640 submissions in the second International Conference on Advanced Computing, Networking and Informatics, 2014, held in Kolkata, India during June 24-26, 2014. The first volume includes innovative computing techniques and relevant research results in informatics with selective applications in pattern recognition, signal/image processing and HCI. The second volume on the other hand demonstrates the possible scope of the computing techniques and informatics in wireless communications, networking and security.", "num_citations": "8\n", "authors": ["475"]}
{"title": "Genetic algorithm-based approach for adequate test data generation\n", "abstract": " Software testing is an important phase in software development. It involves two activities, test data generation and test execution. Test data generation is a NP-complete problem as we have to find a lot of test data to validate our system. Also those test data should be adequate in nature. In this paper, we present a method to generate test data automatically from initial test data and then testing these test data against the software under test (SUT) for adequacy criteria. First, we generate a test data set randomly. Then, we apply genetic algorithm to find a better test data set iteratively. We stop at the position where our test data set satisfies the stopping condition or it completed maximum iterations. We test the generated test data against the software to check its adequacy. The test data generated by our approach are more capable of finding the synchronization and loop faults. A case study is given to illustrate our\u00a0\u2026", "num_citations": "8\n", "authors": ["475"]}
{"title": "A survey of regression testing in SOA\n", "abstract": " Service-Oriented Architecture (SOA) has changed the way business enterprises get aligned with technology with a very fast pace keeping the demand of re-alignment time very short. Testing of services becomes equally important in SOA implementation in the context of enterprise architecture, business re-alignment and so on maintaining quality. Unit and integration testing though holds a key testing strategy but regression test becomes inevitable when services are orchestrated, choreographed and bound dynamically as per the change in requirement as well as when services are upgraded. In this paper a survey work has been done for regression testing method for SOA. Here the changed scenario of implementation of SOA enabled applications has been considered.", "num_citations": "8\n", "authors": ["475"]}
{"title": "Schedulability analysis of task scheduling in multiprocessor real-time systems using EDF algorithm\n", "abstract": " Task scheduling in real-time systems is a concept by which we can schedule the tasks according to their priorities. In hard real-time systems, the task scheduling is more important due to the chance of system failure. We discuss EDF task scheduling which is an optimal technique for the uniprocessor systems. The existing result of the QPA algorithm was applied on the uniprocessor system to check the schedulability of the tasks in uniprocessor system. We have extended the QPA algorithm to check the schedulability of the task sets in multiprocessor systems. Our algorithm is based on QPA algorithm and the utilization balanced algorithm. The proposed algorithm checks the absolute deadlines much faster than the existing QPA algorithm for uniprocessor real-time systems.", "num_citations": "8\n", "authors": ["475"]}
{"title": "Reliability improvement based on prioritization of source code\n", "abstract": " Even after thorough testing of a program, usually a few bugs still remain. These residual bugs are randomly distributed through out the code. It is observed that bugs in some parts of a program can cause more frequent and more severe failures compared to those in other parts. So, it is possible to prioritize the program elements at the time of testing according to their potential to cause failures. Based on this idea, we have proposed a metric to compute the influence of an object in an object-oriented program. Influence of an element indicates the potential of the element to cause failures. The intensity with which each element is tested is proportionate to its influence value. We have conducted experiments to compare our scheme with related schemes. The results establish that the failure rate can indeed be minimized using our scheme when the software is executed for some duration after the completion of\u00a0\u2026", "num_citations": "8\n", "authors": ["475"]}
{"title": "Biotoxicity of mercury to Chlorella vulgaris as influenced by amino acids\n", "abstract": " The toxicity of mercury ion, on Chlorella vulgaris, is largely influenced by amino acids. Five amino acids, namely alanine, asparagine, glutamic acid, cysteine and histidine, were added separately to the medium containing static dose of mercury. Survival (%) of the alga was reduced with the increasing concentrations of mercury. Of these five amino acids, cysteine was found to be the most effective while alanine and glutamic acid were the least effective on reducing the toxic effect of mercury on the alga measured in terms of growth, chlorophyll and protein content.               The order of detoxification was Alanine < Glutamate < Asparargine < Histidine < Cysteine. Amino acids form ligands with Hg2+ making it less toxic to the alga and produce an additional source of energy for growth and development.", "num_citations": "8\n", "authors": ["475"]}
{"title": "An SVM-based ensemble approach for intrusion detection\n", "abstract": " The objective of this article is to develop an intrusion detection model aimed at distinguishing attacks in the network. The aim of building IDS relies on upon preprocessing of intrusion data, choosing most relevant features and in the plan of an efficient learning algorithm that properly groups the normal and malicious examples. In this experiment, the detection model uses an ensemble approach of supervised (SVM) and unsupervised (K-Means) to detect the patterns. This technique first divides the data and forms two clusters as per K-Means and labels the clusters using the Support Vector Machine (SVM). The parameters of K-Means and SVM are tuned and optimized using an intrusion dataset. The SVM provides up to 88%, and K-Means provides up to 83% accuracy individually. However, the ensemble of K-Means and SVM provides more than 99% on three benchmarked datasets in less time. The SVM only\u00a0\u2026", "num_citations": "7\n", "authors": ["475"]}
{"title": "Scaling modified condition/decision coverage using distributed concolic testing for Java programs\n", "abstract": " Object-Oriented languages such as Java language introduce advantageous features which overcome the demerits of procedural languages to some extent. Therefore, Java language is now going to be used by the industries to develop their critical safety system software products. In this paper, we propose some code transformation methodologies, which are implemented in Java language to test Java written code. We apply Java Distributed Concolic testing technique to improve the code coverage, which is more powerful than non-distributed concolic testing in terms of speed of test case generation. We develop a Java coverage analyzer according to the test cases produced by Java distributed concolic testers. This version of the MC/DC analyzer is more powerful than that of procedural languages. Our core idea is to integrate the existing and developed modules to produce a single tool for measuring MC/DC score\u00a0\u2026", "num_citations": "7\n", "authors": ["475"]}
{"title": "Code refactoring using slice-based cohesion metrics and aspect-oriented programming\n", "abstract": " Software restructuring is essential for maintaining software quality. It is a usual practice that we first design the software and then go for coding. After coding, if there is any change in the requirement or if the output is incorrect, then we have to modify the code again. For each small code modification, it is not feasible to alter the design. These minor changes made to the code causes decay in the software design. Software refactoring is used to restructure the code to improve the design and quality of the software. In this paper, we propose an approach for performing code refactoring. We use slice-based cohesion metrics to identify the target methods that require refactoring. After identifying the target methods, we use program slicing to divide the target method into two parts. Finally, we use the concept of aspects to alter the code structure in a manner that does not change the external behaviour of the original module.", "num_citations": "7\n", "authors": ["475"]}
{"title": "FTMXT: Fault-Tolerant Immediate Mode Heuristics in Computational Grid\n", "abstract": " Fault tolerance plays a key role in computational grid. It enables a system to work smoothly in the presence of one or more failure components. The components are failing due to some unavoidable reasons like power failure, network failure, system failure, etc. In this chapter, we address the problem of machine failure in computational grid. The proposed system model uses the round trip time to detect the failure, and it uses the checkpointing strategy to recover from the failure. This model is applied to the traditional immediate mode heuristics such as minimum execution time (MET) and minimum completion time (MCT) (defined as MXT). The proposed Fault-Tolerant MET (FTMET) and Fault-Tolerant MCT (FTMCT) heuristics (defined as FTMXT) are simulated using MATLAB. The experimental results are discussed and compared with the traditional heuristics. The results show that the proposed approaches\u00a0\u2026", "num_citations": "7\n", "authors": ["475"]}
{"title": "Evaluation of software understandability using rough sets\n", "abstract": " Understandability is one of the important characteristics of software quality, because it may influence the maintainability of the software. Cost and reuse of the software is also affected by understandability. In order to maintain the software, the programmers need to properly understand the source code. The understandability of the source code depends upon the psychological complexity of the software, and it requires cognitive abilities to understand the source code. The understandability of source code is getting affected by so many factors. In this paper, we have taken different factors in an integrated view. We have chosen rough set approach to calculate the understandability based on outlier detection. Generally, the outlier is having an abnormal behavior. Here, we have taken that outlier may be easily understandable or difficult to understand. Here, we have taken a few factors, which affect\u00a0\u2026", "num_citations": "7\n", "authors": ["475"]}
{"title": "GA based test case generation approach for formation of efficient set of dynamic slices\n", "abstract": " Automated test case generation is an efficient approach for software testing. Slicing of program provides ease to testability and enhances debugging capacity. To generate the dynamic slice, slicing criterion is required in which the input data parameter is the essential component. Most of the research work focuses on deriving the input by random consideration but it simply takes a longest period of time to generate slices that provides the path coverage of Unit Under Test (UUT). This paper generates the optimal test cases by using Genetic Algorithm (GA) and Control Flow Graph (CFG), these test cases cover all the independent path present in the CFG. The optimal test cases are supplied as input component of the dynamic slicing criteria. So the dynamic slice criteria that use these optimal test cases as the input generates the efficient dynamic slice set that is helpful in efficient testing and efficient debugging. Here two approaches, first the dynamic slice using node marking and the second by using relevant sets are discussed according to optimal test cases as input component.", "num_citations": "7\n", "authors": ["475"]}
{"title": "A novel methodology for software risk assessment at architectural level using UML diagrams\n", "abstract": " Risk assessment at an early stage can be used as a guideline for both developers and testers during software development life cycle (SDLC). In order to improve the quality of a software product and save the cost and time during SDLC, the risk associated with a system at an early stage should be analyzed. We propose a reliability-based risk assessment methodology at the analysis stage of SDLC. Our proposed method estimates the risk through the analysis of UML models: sequence diagrams and statechart diagrams. First, we propose a method to estimate the risk factors for various states of a component within a scenario. The key data needed for risk assessment are complexity and severity. An Inter-Component State Dependence Graph (ISDG) is introduced to estimate the complexity for a state of a component in a system. The severity for a component within a scenario is decided based on three hazard\u00a0\u2026", "num_citations": "7\n", "authors": ["475"]}
{"title": "Software fault localization using BP neural network based on function and branch coverage\n", "abstract": " Software failure is inevitable with the increase in scale and complexity of the software. Existing fault localization techniques based on neural networks take statement coverage information and test case execution results into account to train the network. In this paper, we propose an effective approach for fault localization based on back-propagation neural network which utilizes branch and function coverage information along with test case execution results to train the network. We investigated our approach using Siemens suite. Our experimental result shows that our proposed approach performs on average 23.50\u201344.27% better than existing fault localization techniques.", "num_citations": "6\n", "authors": ["475"]}
{"title": "An approach for dynamic web application testing using MBT\n", "abstract": " Nowadays, web applications play a significant role in the success of the business. Web applications have grown very fast in the current market. They bring new challenges for the researchers in the area of testing, such as heterogeneous representation, dynamic behavior, data flow mechanism, control flow mechanism and some more issues relevant to web applications. This paper presents an approach for model-based dynamic web application testing. This approach considers server side scripting language to test the functional requirements of the web applications. In this approach, first the implicit class object tags are extracted from JSP pages, and the JSP Flow Graph (JFG) is constructed for tracing the requirements using the proposed algorithm JTSG. Then, the test scenarios and concrete test cases are generated for the given web application.", "num_citations": "6\n", "authors": ["475"]}
{"title": "Generating and evaluating effectiveness of test sequences using state machine\n", "abstract": " The aim of this paper is to generate test sequences for object-oriented software with composite states using state machines. This experimental work in software testing focuses on generating test sequences using the proposed algorithm called SMTSG (State Machine to Test Sequence Generation). This work also describes the effectiveness of test sequences by using mutation analysis. Our approach considers nine types of state faults for checking the efficiency of the generated test sequences. The effectiveness of the prioritized test sequences is shown using Average Percentage Fault Detection (APFD) metric. The experimental results show that the test sequences generated using our proposed approach are more efficient than the existing approaches.", "num_citations": "6\n", "authors": ["475"]}
{"title": "Green-JEXJ: A new tool to measure energy consumption of improved concolic testing\n", "abstract": " Green Computing is a solution for environment sustainability, where any part of computer does not pollute the environment system. The main focus of Green Computing is to reduce harmful material used in computers, boost the energy efficiency and create recyclability of waste. Now a days energy consumption of software is very interesting research area. Green Software Testing deals with applying Green Computing technique on software testing. In this paper, we developed a tool to measure energy consumption of improved concolic testing. We have named our tool as Green-JEXJ (Green JEXNCT JCUTE). We have developed Green-JEXJ in Java language with a nice Graphical User Interface (GUI). The GUI provides 100% augmented testing technique on Green-JEXJ. Our proposed method achieves 7.45% of average increase in branch coverage for some sample programs. The average difference of energy\u00a0\u2026", "num_citations": "6\n", "authors": ["475"]}
{"title": "SMCDCT: a framework for automated MC/DC test case generation using distributed concolic testing\n", "abstract": " In this paper we propose a framework to compute MC/DC percentage for distributed test case generation. MC/DC stands for Modified Condition/Decison Coverage [1]. This approach uses several client nodes to generate the non-redundant test cases in a distributed and scalable manner. To achieve an increase in MC/DC, we transform the input C program, P, into its transformed version, P                 \u2032, using Ex-NCT. A coverage analyzer accepts P along with the generated test cases as input from SCORE framework and outputs the MC/DC percentage. The experimental studies show that SMCDCT approach achieves 6.5 % (approx.) of average increase in MC/DC. This increase in MC/DC percentage is achieved in an average computation time of 7.1622715 seconds.", "num_citations": "6\n", "authors": ["475"]}
{"title": "A service-oriented architecture (SOA) framework component for verification of choreography\n", "abstract": " Service-Oriented Architecture (SOA) is a paradigm that encourages organization to understand, how their information technology infrastructure capabilities can be organized to achieve business goals? SOA promises a challenging generation of information systems application based on a new set of standards for enabling self describing, interoperable web services. The web service composition supports choreography in SOA. The web service composition is mainly managed through orchestration and choreography of services. In this paper, we propose a Framework for Service Choreography (FSC) to control the business processes in SOA to reduce complexity in web service composition. To address choreography security issues while passing messages between the services choreographed in SOA, we also propose a Verification Model (VM) using Security Assertions Markup Language (SAML 2.0) to\u00a0\u2026", "num_citations": "6\n", "authors": ["475"]}
{"title": "FTM2: Fault Tolerant Batch Mode Heuristics in Computational Grid\n", "abstract": " Task scheduling is a complicated work in a grid computing environment because the resources are extremely unpredictable. In addition, there are many resources with varying functionalities. More importantly both resources and users are generally in different domains. They may join or leave at any period of time due to administrative reason, network failure or machine failure. It may degrade the performance of computational grid. So, we need a fault tolerant approach to work smoothly in the presence of failure. In this paper, we address the problem of machine failure in computational grid. The proposed system model uses the Round Trip Time (RTT) to detect the failure and the checkpointing strategy to recover from the failure. This model is applied to the traditional batch mode heuristics such as Min-Min and Max-Min. The proposed Fault Tolerant Min-Min (FTMin-Min) heuristic and Fault Tolerant Max-Min\u00a0\u2026", "num_citations": "6\n", "authors": ["475"]}
{"title": "Slicing-based test case generation using UML 2.0 sequence diagram\n", "abstract": " We present a novel test case generation technique using the features of UML 2.0 sequence diagrams. First, we construct the UML sequence diagram of a system. Then, we construct message dependency graph (MDG) from the sequence diagram (SD) and select conditional predicates by traversing MDG. Then, we compute slices corresponding to each conditional predicate. Finally, we generate test cases with respect to a given slicing criterion. Our testing strategy derives test cases using slice test coverage, high path coverage and full predicate coverage criteria. Here, we focus on testing of sequences of messages among objects of use case scenarios. Our technique can be used for system and cluster level testing accommodating the object message and condition information. Thus, our test cases are suitable for detecting object interactions and operational faults. Finally, we have made an analysis and\u00a0\u2026", "num_citations": "6\n", "authors": ["475"]}
{"title": "Intelligent Computing, Networking, and Informatics: Proceedings of the International Conference on Advanced Computing, Networking, and Informatics, India, June 2013\n", "abstract": " This book is composed of the Proceedings of the International Conference on Advanced Computing, Networking, and Informatics (ICACNI 2013), held at Central Institute of Technology, Raipur, Chhattisgarh, India during June 14\u201316, 2013. The book records current research articles in the domain of computing, networking, and informatics. The book presents original research articles, case-studies, as well as review articles in the said field of study with emphasis on their implementation and practical application. Researchers, academicians, practitioners, and industry policy makers around the globe have contributed towards formation of this book with their valuable research submissions.", "num_citations": "6\n", "authors": ["475"]}
{"title": "Generation of branch coverage test data for simulink/stateflow models using crest tool\n", "abstract": " Automated test suite generation is an optimization technique to reduce test effort and duration. Software Testing has traditionally been one of the main techniques contributing to high software quality and dependability. Testing performance consumes about 50% of software development resources, so any methods aiming at reducing software-testing costs are likely to reduce software development costs. So an automated generation of test cases is highly required. Modelling technology has been introduced into the software testing field. Even though how to perform the testing is difficult task, in this approach we are testing using simulation modelling and by using testing methods we are generating MC/DC test cases. In our approach, the first system is modelled in MATLAB using Simulink/Stateflow tool. After that we are generating code from the Simulink/Stateflow models. We use that code to generate the test data using Concolic tester CREST Tool. Concolic testing is used in avionics systems in an efficient way.", "num_citations": "6\n", "authors": ["475"]}
{"title": "Application of hierarchical slicing to regression test selection of Java programs\n", "abstract": " In this paper, first we propose a new slicing method to decompose a Java program into packages, classes, methods and statements that are affected due to the modification in the program. The decomposition is based on the hierarchical characteristic of Java. Then, by mapping these decompositions with the existing test suite, we derive a new test suite and add some new test cases, if necessary, to retest the modified program. We have proposed an intermediate representation of the Java program by considering all the possible dependencies among the program parts. This intermediate representation is used to identify the program constructs that are possibly affected by the change in the program. The packages, classes, methods, and statements thus affected are identified by traversing the intermediate graph, first in the forward direction and then in the backward direction. The test cases covering these affected parts of the program are then selected to retest the program.", "num_citations": "6\n", "authors": ["475"]}
{"title": "Dynamic slicing of concurrent AspectJ programs: An explicit context\u2010sensitive approach\n", "abstract": " This paper presents a context\u2010sensitive dynamic slicing technique for the concurrent and aspectized programs. To effectively represent the concurrent aspect\u2010oriented programs, we propose an intermediate graph called the multithreaded aspect\u2010oriented dependence graph (MAODG). The MAODG is a dynamic graph generated from the execution trace of a given program with respect to a particular set of values given as an input. Interference dependencies between the statements are shown by a distinguished edge called the interference dependence edge in the MAODG. Based on this intermediate representation, we propose a precise and accurate dynamic slicing algorithm for the concurrent aspect\u2010oriented programs implemented using AspectJ. The proposed dynamic slicing algorithm is implemented in a slicing tool developed using the ASM framework. Several open source programs are studied and\u00a0\u2026", "num_citations": "5\n", "authors": ["475"]}
{"title": "Test case generation for concurrent systems using uml activity diagram\n", "abstract": " Concurrency problems, such as deadlocks, should be identified before the design process begins. This is very difficult as larger and more complex concurrent systems are being developed. Here we propose an approach, based on the analysis of Unified Modelling Language (UML) that represents the behavioural properties of the system. In this work, we have presented an approach for generating a minimum test suite with maximum coverage. It builds an Input/Output Activity Diagram (IOAD) using UML activity diagram which helps to remove deadlock and reduce complexity in solving complex concurrent systems. It is also user friendly and generates effective test cases.", "num_citations": "5\n", "authors": ["475"]}
{"title": "Java-HCT: An approach to increase MC/DC using hybrid concolic testing for Java programs\n", "abstract": " Modified Condition / Decision Coverage (MC/DC) is the second strongest coverage criterion in white-box testing. According to DO178C/RTCA criterion it is mandatory to achieve Level A certification for MC/DC. Concolic testing is the combination of Concrete and Symbolic execution. It is a systematic technique that performs symbolic execution but uses randomly-generated test inputs to initialize the search and to allow the tool to execute programs when symbolic execution fails. In this paper, we extend concolic testing by computing MC/DC using the automatically generated test cases. On the other hand Feedback-Directed Random Test Generation builds inputs incrementally by randomly selecting a method call to apply and find arguments from among previously-constructed inputs. As soon as the input is built, it is executed and checked against a set of contracts and filters. In our proposed work, we combine\u00a0\u2026", "num_citations": "5\n", "authors": ["475"]}
{"title": "Software Reliability Assessment using Neural Networks of Computational Intelligence Based on Software Failure Data\n", "abstract": " The computational intelligence approach using Neural Network (NN) has been known to be very useful in predicting software reliability. Software reliability plays a key role in software quality. In order to improve accuracy and consistency of software reliability prediction, we propose the applicability of Feed Forward Back-Propagation Network (FFBPN) as a model to predict software reliability. The model has been applied on data sets collected across several standard software projects during system testing phase with fault removal. Unlike most connectionist models, our model attempt to compute average error (AE), the root mean square error (RMSE), normalized root mean square error (NRMSE), mean absolute error (MAE) simultaneously. A comparative study among the proposed feed-forward neural network with some traditional parametric software reliability growth model\u2019s performance is carried out. The results indicated in this work suggest that FFBPN model exhibit an accurate and consistent behavior in reliability prediction.", "num_citations": "5\n", "authors": ["475"]}
{"title": "Test case prioritization using association rule mining and business criticality test value\n", "abstract": " Regression Testing plays a vital role for the improvement in quality of product during software maintenance phase. This phase ensures that modification made to the system under test doesn\u2019t adversely affect the performance of the existing features. Hence regression testing incurs more cost and time. Test case prioritization, which is one of the techniques of regression testing, is an efficient technique to minimize the cost and time of testing. In this paper, the author has proposed an approach for test case prioritization by maintaining information of previous and current release of the project in a repository. To represent the behavioral aspect of the system, it is modeled using both UML activity and sequence diagram. Then frequent pattern is generated by applying Association Rule Mining on the information stored in the repository. Finally the prioritization is carried out using the generated frequent patterns and\u00a0\u2026", "num_citations": "5\n", "authors": ["475"]}
{"title": "Dynamic slicing of feature-oriented programs\n", "abstract": " We intend to suggest a dynamic slicing algorithm for feature-oriented programs. We have named our algorithm Execution Trace file Based Dynamic Slicing (ETBDS) algorithm. The ETBDS algorithm constructs an intermediate program representation known as Dynamic Feature-Oriented Dependence Graph (DFDG) based on various dependences exist amongst the program statements. We use an execution trace file to keep the execution history of the program. The dynamic slice is computed by first performing breadth-first or depth-first traversal on the DFDG and then mapping out the resultant nodes to the program statements.", "num_citations": "5\n", "authors": ["475"]}
{"title": "Test case generation and prioritization based on UML behavioral models.\n", "abstract": " Test case prioritization (TCP) techniques have been proven to be beneficial for improving testing activities. Prioritized test suites are found using different techniques of prioritization. While code coverage based prioritization techniques are found to be used by most scholars, test case prioritization based on UML behavioral models has not been given much attention so far. We propose a novel approach for generating and prioritizing test cases using UML sequence and interaction overview diagrams. First, we convert the interaction overview diagram to interaction Graph (IG) and sequence diagram to Message Sequence Dependency Graph (MSDG). An intermediate graph known as Sequence Interaction Graph (SIG) is generated by combining MSDG and IG. From SIG, we generate the test scenarios and subsequently the test cases. For test case prioritization, the first task is to convert the SIG into another graph\u00a0\u2026", "num_citations": "5\n", "authors": ["475"]}
{"title": "Automated slicing of aspect-oriented programs using bytecode analysis\n", "abstract": " Program slicing has numerous applications in software engineering activities like debugging, testing, maintenance, model checking etc. The main objective of this paper is to automate the generation of System Dependency Graphs (SDG) for aspect-oriented programs to efficiently compute accurate slices. The construction of SDG is automated by analysing the byte code of aspect-oriented programs that incorporates the representation of aspect-oriented features. After constructing the SDG, we propose a slicing algorithm that uses the intermediate graph and computes slices for a given AOP. To implement our proposed slicing technique, we have developed a prototype tool that takes an AOP as input and compute its slices using our proposed slicing algorithm. To evaluate our proposed technique, we have considered some case studies by taking open source projects. The comparative study of our proposed slicing\u00a0\u2026", "num_citations": "5\n", "authors": ["475"]}
{"title": "Test Scenarios Generation using Path Coverage\n", "abstract": " Testing is one of the very important component of software development process. Properly generated test sequences may not only locate the defects in software, but also help in reducing the high cost associated with software testing. It is often desired that test sequences should be automatically generated to achieve required test coverage. Automatic test sequence generation is a major problem in software testing. The aim of this study is to generate test sequences for source code using ModelJunit. ModelJUnit is a extended library of JUnit. We have generate automatic test sequences and some testing criterion coverage such as node coverage, edge coverage and edge pair coverage. This paper describes a systematic test sequence generation technique using the path based approach.", "num_citations": "5\n", "authors": ["475"]}
{"title": "Code-based prioritization: a pre-testing effort to minimize post-release failures\n", "abstract": " Improving the efficiency of the testing process is a challenging goal. Prior work has shown that often a small number of errors account for the majority of software failures; and often, most errors are found in a small portion of a source code. We argue that prioritizing code elements before conducting testing can help testers focus their testing effort on the parts of the code most likely to expose errors. This can, in turn, promote more efficient testing of software. Keeping this in view, we propose a testing effort prioritization method to guide tester during software development life cycle. Our approach considers five factors of a component such as Influence value, Average execution time, Structural complexity, Severity and Value as inputs and produce the priority value of the component as an output. Once all components of a program have been prioritized, testing effort can be apportioned so that the components\u00a0\u2026", "num_citations": "5\n", "authors": ["475"]}
{"title": "A scheme to prioritize classes at the early stage for improving observable reliability\n", "abstract": " While testing a program using a test suite of finite size, testing the frequently used classes more thoroughly within the testing budget would lead to higher observable reliability compared to testing all classes uniformly. To achieve this, we first propose a technique to prioritize classes at the design stage according to their impact on the overall reliability of the system. The priority value for a class is calculated based on UML diagrams (Use Case and Sequence diagrams) and operational profile of the system. Then we propose a genetic algorithm-based technique to select test cases for a test suite out of a large pool of test cases such that the intensity with which each class is tested is proportionate to its priority value and the test suite is optimal under other constraints.", "num_citations": "5\n", "authors": ["475"]}
{"title": "Test case generation and optimization of object-oriented software using UML behavioral models\n", "abstract": " Testing guarantees the quality of software to be developed in terms of presence of bugs or errors. Testing can be separated into two categories such as White Box and Black Box testing. White box testing is done through detail analysis of program structure where as black box methodology deals with specification and design document i.e. without program details. Thus black box testing methodology holds major advantages, as tester can generate the test cases before code is developed, using specification and design document. Off the late, Object-Oriented program have changed the scenario of software development industry in terms of software development and its supporting technology. The object-oriented features like inheritance and encapsulation has made it easy and suitable confined to design. The inheritance feature encourages to re-use the developed components where as the encapsulation conceals the details from others. And other features of object-oriented program like polymorphism, data abstraction and modularity have increased its richness. However these features have increased the job of software tester. Special attraction are needed to look into these features while testing is carried out.", "num_citations": "5\n", "authors": ["475"]}
{"title": "MC/DC guided test sequence prioritization using firefly algorithm\n", "abstract": " Optimization of the regression testing process has been playing an important role in developing quality software. Still, it is difficult to achieve satisfactory results on the generation of non-redundant and optimized test sequences. There are many optimization techniques applied to regression testing. Firefly algorithm (FA) has gained its popularity as an optimization technique to provide better solutions in the areas of science and engineering. But, the original FA needs to have a better or modified objective function. This work uses FA with an improvised objective function to generate optimal test paths guided by \u201cModified Condition/Decision Coverage\u201d (MC/DC) criteria in the form of a guided matrix. This matrix is built with MC/DC influence values that we obtained from the predicate nodes of \u201ccontrol flow graph\u201d (CFG). This guided matrix also helps in measuring the fault-finding potential of a node. It also helps in\u00a0\u2026", "num_citations": "4\n", "authors": ["475"]}
{"title": "Test scenario prioritization for object-oriented systems using UML diagram\n", "abstract": " The exponential growth in the complexity of product requirements has raised the importance of software testing. Software change management is one of the major challenge and regression testing provides a solution in this regard. Regresion testing is performed to find out the effect of the modified component on the other components present in the application. Here, a behavioural model i.e. an UML State Machine Diagram (SMD) is used to model the system requirements. Further, an intermediate State Machine Graph (SMG) is constructed from SMD. The test scenarios are generated by identifying the paths those are linearly independent of each other. These test scenarios are validated for code coverage using dynamic program analysis technique. Then, by traversing the SMG, nodes are identified those got affected due to the different change carried away in the software. A repository is maintained to store\u00a0\u2026", "num_citations": "4\n", "authors": ["475"]}
{"title": "Firefly optimization technique based test scenario generation and prioritization\n", "abstract": " Abstract Model-based testing shows a significant role-play in the area of software testing. This paper presents a new automatic test scenarios generation technique using UML state machine diagram having composite states. The intention of this research is to generate test scenarios for concurrent and composite states in state machines using the proposed algorithm SMToTSG (State Machine To Test Scenarios Generation). We have prioritized the test scenarios using Firefly optimization algorithm. We have used state-based coverage criteria such as state, transition, transition pair coverage to evaluate the efficiency of the proposed algorithm. The proposed approach is useful for feasible test scenario generation. Generating exhaustive test scenarios for all concurrent interdependent sequences is very difficult. In this paper, we generate the important test scenarios in the presence of concurrency in composite models. After prioritization, we apply Average Percentage Fault Detection (APFD) metric to calculate the efficiency of the prioritized test scenarios.", "num_citations": "4\n", "authors": ["475"]}
{"title": "Computing dynamic slices of feature--oriented programs using execution trace file\n", "abstract": " Feature-Oriented Programming (FOP) is a general paradigm for synthesizing programs in software product lines. A family of software systems constitutes a software product line (SPL). The unique characteristics of feature-oriented programs such as mixin layers, refinements of classes, refinements of constructors, constants, refinements, etc. pose special difficulties in the slicing of these programs. This paper proposes a dynamic slicing algorithm for feature-oriented programs. The algorithm is named Execution Trace File Based Feature-Oriented Dynamic Slicing (ETBFODS) algorithm. The ETBFODS algorithm uses a dependence based representation called Dynamic Feature Composition Dependence Graph (DFCDG) and an execution trace file to store execution history of the program for a given input. The dynamic slice is computed by traversing the DFCDG in breadth--first or depth-first wise and then mapping the\u00a0\u2026", "num_citations": "4\n", "authors": ["475"]}
{"title": "Computational intelligence in data mining\u2014volume 1: Proceedings of the international conference on cidm, 5-6 december 2015\n", "abstract": " The book is a collection of high-quality peer-reviewed research papers presented in the Second International Conference on Computational Intelligence in Data Mining (ICCIDM 2015) held at Bhubaneswar, Odisha, India during 5\u20136 December 2015. The two-volume Proceedings address the difficulties and challenges for the seamless integration of two core disciplines of computer science, ie, computational intelligence and data mining. The book addresses different methods and techniques of integration for enhancing the overall goal of data mining. The book helps to disseminate the knowledge about some innovative, active research directions in the field of data mining, machine and computational intelligence, along with some current issues and applications of related topics.", "num_citations": "4\n", "authors": ["475"]}
{"title": "Measures for predicting software reliability using time recurrent neural networks with back-propagation\n", "abstract": " Recurrent Neural Network (RNN) has been known to be very useful in predicting software reliability. A number of parametric models and reliability growth models, have been proposed, but developing a model that can predict reliability in all types of data sets, in any environment, and at any phase of software development is still a challenge. In this paper, we propose a model that explores the applicability of Recurrent Neural Network with Back- propagation Through Time (RNNBPTT) learning rule to predict software reliability. The detailed procedure of reliability prediction using recurrent neural networks is explained. The model has been applied on data sets collected across several standard software projects during system testing phase with fault removal. Though the procedure is relatively complicated, the results depicted in this work suggest that Fully Recurrent Neural Networks (FRNN) exhibits an accurate and\u00a0\u2026", "num_citations": "4\n", "authors": ["475"]}
{"title": "Model-based test-suite minimization using modified condition/decision coverage (mc/dc)\n", "abstract": " Testing is very expensive for high-assurance software, like commercial aircraft systems, weapon research, weather forecast, earthquake forecast, and software used for safety critical system. A small and simple flaw in the end product can be enough for destroying the entire effort of the developer with a huge unrecoverable damage to the society. For this reason, Federal Aviation Administration\u2019s requirement is that, the test-suites should be comprises of Modified Condition/Decision Coverage (MC/DC) adequate. By using logic coverage criteria lots of flaws can be removed for safety critical software. MC/DC was proposed by NASA, and had been widely accepted in the field of testing. MC/DC is an effective verification technique, and helps to uncover safety faults. It is a challenge to minimize the number of test-suites when there is a partial change in the software. This can be achieved by using models. Unified Modeling\u00a0\u2026", "num_citations": "4\n", "authors": ["475"]}
{"title": "ABCE: a novel framework for improved branch coverage analysis\n", "abstract": " The software testing practices generate test cases manually, that affects both the effectiveness and efficiency. In aerospace and safety critical domains, software quality assurance is strict to rules and regulations such as DO-178B standard. To resolve these issues, concolic testing generates test suite that can attain high coverage using an automated technique based on Branch Coverage. In this paper, we propose a framework to compute branch coverage percentage for test case generation. To achieve an increase in branch coverage, we transform the input Java program, P, into its transformed version, Pt, using JPCT. Then we use JCUTE to generate test cases and find branch coverage percentage. Our experimental studies on branch coverage percentage consists of two steps: the first observation is made without using Java program code transformer, the second observation is made by using Java program code\u00a0\u2026", "num_citations": "4\n", "authors": ["475"]}
{"title": "Functionality testing of object-oriented software using UML state machine diagram\n", "abstract": " This paper proposed automatic test scenario generation technique using UML state machine diagram. We have considered the state machine diagram as input for our proposed parser named XMLtoTS, which generates the Control Flow Graph (CFG) of the system. In this paper, we have proposed algorithm SMTSGA (State Machine to Test Scenario Generation Algorithm) for generating test scenarios. Proposed algorithm SMTSGA generate all test scenarios. The generation of test scenarios is important for test case generation of the system. We have used this process during the design phase of the software development prior the actual testing phase to reduce the cost of and time of testing and later it will also require less effort for testing of the system.", "num_citations": "3\n", "authors": ["475"]}
{"title": "Model driven approach for test data optimization using activity diagram based on cuckoo search algorithm\n", "abstract": " Model-driven testing is a method to verify the requirement specification of the system through UML models. Cuckoo search (CS) algorithm is based on the brooding characteristics of cuckoo birds. The test case generation process is used to identify the test cases with resources with critical domain requirements. This proposed paper emphasizing on the generation and optimization of test cases or test data using cuckoo search technique through a case study, ie, the withdrawal operation in a Bank ATM and it also describes the generation of test cases from UML behavioral diagram like activity diagram, possible test paths are also generated through activity diagram graph.", "num_citations": "3\n", "authors": ["475"]}
{"title": "A framework for generating prioritised test scenarios using firefly optimisation technique\n", "abstract": " The intention of this research is to generate test scenarios for concurrent and composite states in state machines using firefly optimisation algorithm. We have used state-based coverage criterion such as state coverage, transition coverage, transition pair coverage, etc. to evaluate the efficiency of our proposed algorithm. The proposed approach is useful for feasible test scenario generation. Generating exhaustive test scenarios for all concurrent interdependent sequences is exponential in size. As a result, in this paper, we find the important test scenarios in the presence of concurrency in composite models.", "num_citations": "3\n", "authors": ["475"]}
{"title": "Test case prioritization using UML state chart diagram and end-user priority\n", "abstract": " The intangible behaviour of software has given rise to various challenges in the field of testing software. One of the major challenges is to efficiently carry out regression testing. Regression testing is performed to ensure that any modifications in one component of the software do not adversely affect the other components. But, the retesting of test cases during regression testing increases the testing time and leads to delayed delivery of the software product. In this paper, a dynamic model, i.e. UML state chart diagram, is used for system modelling. Further, the UML state chart diagram is converted into an intermediate representation, i.e. State Chart Graph (SCG). The SCG is traversed to identify the affected nodes due to certain modification in the software. This information, about the affected nodes, is periodically stored in a historical data store across different\u00a0versions of the software. Next time, when regression\u00a0\u2026", "num_citations": "3\n", "authors": ["475"]}
{"title": "AUTOMATIC GENERATION AND OPTIMIZATION OF COURSE TIMETABLE USING A HYBRID APPRAOCH\n", "abstract": " Course timetable generation problem is a NP-hard problem where we have to take care of different constraints. Optimization problem is a technique of finding an alternative solution having cost effective or highly achievable performance subjected to given constraints, Optimization aims at maximizing desired factors and minimizing or reducing the undesired factors. This paper focuses the hybrid approach produced by combining the concept of Bee colony Optimization (BCO) and Firefly Algorithm (FA) collectively termed as BCFA for finding the optimal solutions of course time table. There are three objectives for construction of the paper, first objective is to get an overview on timetabling problem, second objective is the BCFA and its variations with other timetable generation algorithms and the third objective is to compare the result of BCFA with other evolutionary algorithms. The proposed approach aims at\u00a0\u2026", "num_citations": "3\n", "authors": ["475"]}
{"title": "Measuring MC/DC at design phase using UML sequence diagram and concolic testing\n", "abstract": " This work describes Modified Condition/ Decision Coverage (MC/DC) criterion for performing testing of the interactions among a set of collaborating objects. This criterion is based on UML Sequence Diagrams. The sequences of Synchronized and Asynchronized messages in the sequence diagrams are used to define the code coverage goals for the family of criteria. In this paper, first we design an UML Sequence Diagram. XML produces XMI code for the designed UML Sequence Diagram. Next, JAXB converts the XMI code into Java code. To generate test cases using concolic testing for the Java program which is derived from the UML Sequence Diagram, we have used jCUTE. These test cases are then supplied to COPEPCA (COverage PErcentage CAlculator) to measure MC/DC%.", "num_citations": "3\n", "authors": ["475"]}
{"title": "ACO based embedded system testing using UML activity diagram\n", "abstract": " This paper proposed a model-based technique for test scenario generation using Activity Diagram (AD). We transform an AD specification into an intermediate graph called Activity Interaction Graph (AIG) using the proposed parser. After that, we apply combination of BFS and DFS algorithms for generating test scenarios. Then, we apply an algorithm called ACOToTSP (Ant Colony Optimization for Test Scenarios Prioritization) algorithm on the generated test scenarios with respect to some decision and concurrent criteria, for prioritizing the test scenarios. This approach generates test scenarios according to forks, Joins, and merge point's strength in the activity diagram.", "num_citations": "3\n", "authors": ["475"]}
{"title": "A graph-based dynamic slicing of distributed aspect-oriented software\n", "abstract": " Distributed computing has become very popular these days due to its speed, accuracy and fault tolerance capability. In this pa-per, we have considered the distributed Aspect-Oriented Programs (AOPs) where message passing and synchronization are handled by Aspects. In this paper, we present a parallel dynamic slicing algorithm for distributed AOPs. We introduce parallelism into our slicing algorithm to make the slice computation process much faster. Our algorithm is implemented on our developed tool, called DDG generator, to generate the required intermediate graphs for distributed AOPs. The proposed slicing technique is compared with one related existing technique using three case studies. The experimental results show that our proposed slicing algorithm generates precise slices in less time as compared to the existing algorithm.", "num_citations": "3\n", "authors": ["475"]}
{"title": "MM-path Approach for Integration Testing of Aspect-Oriented Programs\n", "abstract": " We suggest a technique to perform integration testing of Aspect-Oriented Programs (AOPs) using Module to Module path (MM-path). First, we construct a control flow graph (CFG) of the program annotating each edge with messages and identify the source nodes and sink nodes in each module. Then, we find out the feasible execution paths and design the test cases randomly. For each test case, the sequence diagram is designed to depict the order of message exchanges. From the sequence diagram, the MM-path is designed. These MM-paths are used for testing during integration of various modules.", "num_citations": "3\n", "authors": ["475"]}
{"title": "An Empirical Analysis of Software Reliability Prediction Through Reliability Growth Model Using Computational Intelligence\n", "abstract": " The objective of this paper is to predict software reliability using non-parametric neural network of computational intelligence                      (CI). The study uses data sets containing failure history such as number of failures, failure time interval etc. In this paper, we explore the applicability of feed-forward neural network with back-propagation training as a reliability growth model for software reliability prediction. The prediction result is compared with that of traditional parametric software reliability growth models. The results described in the proposed model exhibits an accurate and consistent behavior in reliability prediction. The experimental results demonstrate that the proposed model provides a significant difference respect to accuracy and consistency.", "num_citations": "3\n", "authors": ["475"]}
{"title": "Generation and Prioritization of test sequences using UML activity diagram\n", "abstract": " Software testing is one of the most important part in software development life cycle. Generation of test sequences which is essential for software testing is one of the challenging task. Testing can be done either manually or automatically. Automated testing is better than manual testing as it reduces cost as well as time. UML activity diagram are used to show the workflow of dynamic and behavioural aspects of the software system. Test sequences can be generated using the UML activity diagram and different prioritization techniques can be applied to select the effective paths. In this project, first we generate test sequences using the activity diagram. Then, we prioritize test sequences using Ant colony optimization. We have implemented the proposed algorithm. We have compared the proposed prioritization technique with the existing prioritization technique. Experimental results shows that our result is better than that of the existing technique.", "num_citations": "3\n", "authors": ["475"]}
{"title": "A Novel Methodology For Test Scenario Generation Based On Control Flow Analysis Of Uml 2. X Sequence Diagrams\n", "abstract": " Now a days UML is widely used for preparing design documents. It helps to specify, construct, visualize and document artifacts of software systems. This paper presents an approach to test the software in the early stage (design phase) of software development life cycle, so that it can help the software testers in the later stages. This paper focuses on generating test scenarios from UML 2. x Sequence diagrams. The most challenging problem in generating test scenarios from UML 2. x sequence diagram is the presence of fragments such as alt, loop, break, par, opt etc. We propose an intermediate control flow graph in a testable form named Sequence Control Flow Graph (SCFG) resulting from the control flow analysis of UML 2. x sequence diagrams. We also propose a systematic approach named Sequence Test Scenario Generation Algorithm (STSGA) for generating test scenarios from UML 2. x Sequence diagrams. The test scenarios generated by our approach are suitable for detection of scenario faults, use case dependency and system testing.", "num_citations": "3\n", "authors": ["475"]}
{"title": "Generating test data for path coverage based testing using genetic algorithms\n", "abstract": " In this paper, we have developed an approach to generate test data for path coverage based testing using genetic algorithm. We have used control flow graph and cyclomatic complexity of the example program to find out the number of feasible paths present in the program and compared it with the actual number of paths covered by genetic algorithm. We have used genetic algorithm for generating test data automatically. We have shown that our algorithm is giving cent percent coverage, successfully covering all feasible paths. In our approach, we have observed that genetic algorithm is much more effective in generating test data within less time period, giving better coverage.", "num_citations": "3\n", "authors": ["475"]}
{"title": "A novel approach for test case prioritization using business criticality test value\n", "abstract": " Software maintenance is an important and costly activity of the software development lifecycle. Regression testing is the process of validating modifications introduced in a system during software maintenance. It is very inefficient to reexecute every test case in regression testing for small changes. This issue of retesting of software systems can be handled using a good test case prioritization technique. A prioritization technique schedules the test cases for execution so that the test cases with higher priority executed before lower priority. The objective of test case prioritization is to detect fault as early as possible. Early fault detection can provide a faster feedback generating a scope for debuggers to carry out their task at an early stage. Model Based Prioritization has an edge over Code Based Prioritization techniques. The issue of dynamic changes that occur during the maintenance phase of software development can only be addressed by maintaining statistical data for system models, change models and fault models. In this paper we present a novel approach for test case prioritization by evaluating the Business Criticality Value (BCV) of the various functions (functional and nonfunctional) present in the software using the statistical data. Then according to the business criticality value of various functions present in the change and fault model we prioritize the test cases are prioritized.", "num_citations": "3\n", "authors": ["475"]}
{"title": "UML Based Web Service Regression Testing Using Test Cases: A Case Study\n", "abstract": " Web services represent the class of Service Oriented Architecture (SOA) based applications with a hugely diversified domain. Web service regression testing presents a set of challenges to the tester which need to be overcome in order to provide a reliable performance of the desired application. Code based regression testing approaches present a lot of difficulties as the tester needs to know the code which is in most cases not possible. In this paper, we address a UML based regression testing method independent of the code using test cases generated from use cases in the context of a case study.", "num_citations": "3\n", "authors": ["475"]}
{"title": "Generating testcases for concurrent systems using UML state chart diagram\n", "abstract": " Communication and concurrency are the major factors needed for the construction of a concurrent system. In concurrent environment systematic testing becomes a complex task. Generating test cases in concurrent environment is a difficult task because of arbitrary meddling of the concurrent thread. The interference of the concurrent thread may lead to a deadlock. In this paper we propose a methodology to generate the test cases for the conformance of deadlock in concurrent systems using UML State Chart Diagram. For system specification we have used the UML State Chart Diagram, from which event tree is generated. Along with a case study an algorithm is proposed to generate the test suite and confirm whether it is free from deadlock.", "num_citations": "3\n", "authors": ["475"]}
{"title": "Generation of test cases using uml sequence diagram in a system with communication deadlock\n", "abstract": " An environment in which different processors communicate with each other speeding up computation and improving the data availability is called as distributed environment. Communication and concurrency are the major issues of the distributed environment. Different processors try to communicate with each other avoiding deadlock. The resource contention which is introduced by the concurrent process in distributed computational environment gives rise to deadlock problem. In this paper an effort has been made by the authors to represent deadlock situations with the help of graph. An algorithm is devised to reveal deadlock has occurred. A real time banking system is depicted setting out to be an example. Test cases for the communication deadlock and the UML Sequence Diagram are laid out from the real time example.", "num_citations": "3\n", "authors": ["475"]}
{"title": "Slicing java server pages application\n", "abstract": " We propose an efficient technique for slicing web applications. First we construct the system dependence graph for a web application and then perform backward slicing on that graph corresponding to a given slicing criterion. We use Java server pages for the web application.", "num_citations": "3\n", "authors": ["475"]}
{"title": "A novel approach for test case generation using activity diagram\n", "abstract": " Testing is an important part of quality assurance in the software development life cycle. As the complexity and size of software grow, more and more time and man power are required for testing the software. Manual testing is very much labor-intensive and error-prone. So there is a pressing need to develop the automatic testing strategy. Test case generation is the most important part of the testing efforts. Test cases can be designed based on source code but this makes test case generation difficult for testing at cluster level. Therefore, it is required to generate test cases automatically from the design documents. Also this approach holds an added advantage of obtaining test cases early in the software development life cycle (SDLC), there by making test planning more effective. Our approach first constructs the activity diagram for the given problem and then randomly generates initial test cases, for a program under testing (PUT). Then, by running the program with the generated test cases, we can get the corresponding program execution traces (PET). Next, we compare these traces with the constructed activity diagram according to the specific coverage criteria. We use a rule based frame work to generate a reduced test case set, which meets the test adequacy criteria. Advantage of our approach is that it achieves maximum path coverage.", "num_citations": "3\n", "authors": ["475"]}
{"title": "A Review on Scalable Learning Approches on Intrusion Detection Dataset\n", "abstract": " There has been much excitement recently about Big Data and the dire need for data scientists who possess the ability to extract meaning from it. Data scientists, meanwhile, have been doing science with voluminous data for years, without needing to brag about how big it is. But, now those large, complex datasets should process smartly. As a result, it improves productivity by reducing the computational process. As a result, Big Data analytics takes a vital role in intrusion detection. It provides tools to support structured, unstructured, and semi-structured data for analytics. Also, it offers scalable machine learning algorithms for fast processing of data using machine learning approach. It also provides tools to visualize a large amount of data in a practical way that motivates us to implement our model using scalable machine learning approach. In this work, we describe a scalable machine learning algorithm for\u00a0\u2026", "num_citations": "2\n", "authors": ["475"]}
{"title": "Predicting software reliability using computational intelligence techniques: a review\n", "abstract": " Software measurement is yet in an infant stage. There is hardly any efficient quantitative method to represent software reliability. The existing methods are not generic and have many limitations. Various techniques could be used to enhance software reliability. However, one has to not only balance time but also cater to budget constraints. Computational Intelligence (CI) techniques that have been explored for software reliability prediction have shown remarkable results. In this paper, the applications of CI techniques for software reliability prediction are surveyed and an evaluation based on some selected performance criteria is presented.", "num_citations": "2\n", "authors": ["475"]}
{"title": "Progress in Advanced Computing and Intelligent Engineering: Proceedings of ICACIE 2016, Volume 2\n", "abstract": " This volume contains the papers presented at International Conference on Advanced Computing and Intelligent Engineering (ICACIE 2016) that was held during December 23\u201325, 2016, at the CV Raman College of Engineering, Bhubaneswar, India (www. icacie. com). There were 638 submissions and each qualified submission was reviewed by a minimum of two Technical Program Committee members using the criteria of relevance, originality, technical quality, and presentation. The committee accepted and published in proceedings 136 full papers for oral presentation at the conference and the overall acceptance rate is 21.32%.ICACIE is an initiative focusing on research and applications on several topics of advanced computing and intelligent engineering. The focus was also to present state-of-the-art scientific results, disseminate modern technologies, and promote collaborative research in advanced\u00a0\u2026", "num_citations": "2\n", "authors": ["475"]}
{"title": "Measuring Hit Ratio Metric for SOA-Based Application Using Black-Box Testing\n", "abstract": " In our proposed work, we discuss how to generate test cases automatically for BPEL processes to compute Hit Ratio percentage of an SOA application. First, we design an SOA-based application using OpenEsb tool. That application is supplied to code converter to get XML code of the designed application. Then, we have supplied this XML code to Tcases tool to generate test cases according to black-box testing technique. These test cases are supplied to Hit Ratio Calculator to compute Hit Ratio percentage. On an average of four SOA-based applications, we achieved Hit Ratio percentage as 63.94%.", "num_citations": "2\n", "authors": ["475"]}
{"title": "Hierarchical regression test case selection using slicing\n", "abstract": " In this paper, we propose a novel regression test case selection approach by decomposing an object-oriented (OO) program into packages, classes, methods and statements that are affected by some modification made to the program. This decomposition is based on the proposed hierarchical slicing of an OO program. By mapping these decompositions to the existing test suite, we select a new reduced regression test suite and add some new test cases, if necessary, to retest the modified program. We apply hierarchical slicing on a suitable intermediate graph proposed for representing an OO program. This intermediate graph representation corresponds to all the possible dependences among the different parts of an OO program. We improve the scalability of the intermediate graph to a considerable extent by identifying and removing the redundant edges from the graph and thus detect the affected program parts\u00a0\u2026", "num_citations": "2\n", "authors": ["475"]}
{"title": "Information retrieval in the context of checking semantic similarity in web: Vision of future web\n", "abstract": " Objective: This work discusses about web search based on content present in the web page. Web 3.0 in this field has been a major invention done till this date. Yet semantic web proposes to be a good choice for its enhancement towards searches based on intent of user. There has been lots of techniques proposed so far still methods are been searched based on this concept. Methods: Surfing the internet for relevant information as needed by the user has therefore become an issue for users. In order to overcome the problem of information deluge for relevant information retrieval, there is a need to devise a way to search data based on user\u2019s intent. This is where semantic search comes into play. Findings: In order to improve quality of search correctness, semantic search tries to interpret the context of data provided along with user\u2019s intent, location from where that has been looked for, variation of words etc. As a part of our work we have proposed a model using natural language processing that aims to classify data based on semantic relevance to user query. The well-known concept of NLP permits the machines to derive the purpose or the meaning meant by humans or natural language input. The aim is to provide exact needed result to the user in place of making him to look for it all over the URLs given as result.", "num_citations": "2\n", "authors": ["475"]}
{"title": "Forward Dynamic Slicing of Web Applications\n", "abstract": " We present a technique to compute dynamic slices for web applications using forward slicing approach. In our work, we have considered JSP (JavaServer Pages) based web applications. The slicing technique can efficiently be applied using an intermediate representation of a web application. We have proposed a graph called Web Dependence Graph (WDG) as the intermediate representation to correctly represent web applications. We have named our technique Web Application Forward Dynamic Slicing (WAFDS) Algorithm. The WAFDS algorithm first constructs the WDG. Then, the web application is executed for a given input, specified in slicing criteria, and the nodes in WDG resembling the executed statements are marked. Finally, the WDG is traversed in forward direction only along the marked nodes. The traversal is started from the desired point specified in the slicing criterion. The statements\u00a0\u2026", "num_citations": "2\n", "authors": ["475"]}
{"title": "Slicing Aspect-oriented program Hierarchically\n", "abstract": " While developing a software system, the complexity in describing a problem should be reduced. This can be done by separating the concern in a clean and explicit way. Each of the concern can be addressed by partitioning a software system into modules. Concerns are clearly identifiable with a special linguistic construct called Aspects, which has been introduced by a new programming paradigm known as aspect-oriented programming. No doubt aspect-oriented programming brings lots of opportunities for the software developer. On the other hand, it is very difficult for analysing those programs for different software engineering activities. In such scenario, slicing plays a vital role. This paper proposes an approach to compute the dynamic slices of aspect-oriented programs. In our approach, we have introduced different level dependence graphs, such as aspectoriented statement level dependence graph, aspect-oriented method level dependence graph, aspect-oriented AC weaving level dependence graph, aspect-oriented package level dependence graph to represent an aspect-oriented program under consideration. Then, we apply aspect-oriented reverse hierarchical dynamic slicing algorithm on the intermediate program representation to compute the dynamic slices. Our algorithm traverses the dependence edges starting from the slicing node in a reverse hierarchical manner to list the reached node, which constitute the dynamic slice of the aspect-oriented program under consideration. This approach is advantageous as it constructs the graph and computes the dynamic slices level wise. At a particular instance the level dependence graph\u00a0\u2026", "num_citations": "2\n", "authors": ["475"]}
{"title": "A novel technique for static slicing of SoaML sevice interface diagram\n", "abstract": " We present a novel technique for static slicing of SoaML Service Interface Diagram. In this technique, a Service Interface Diagram is converted into an intermediate representation which we have named as Service Interface Dependency Graph(SIDG). The SIDG identifies Service Call Dependency and Composite Dependency from Service Interface Diagram. Giving slicing criterion as input, our aglorithm traverses the SIDG and identifies affected service interface nodes. The novelty of our work lies in computation of slice based on SIDG and its dependencies induced within SIDG.", "num_citations": "2\n", "authors": ["475"]}
{"title": "Intermediate mode scheduling in computational grid\n", "abstract": " Mode of Scheduling plays the key role in Grid Scheduling. It is of two types, immediate and batch mode. Immediate mode takes one by one task in a sequence. But the batch mode takes in a random sequence. So, task assignment is mainly based on the mode selection. The task may be assigned to the resource as soon as arrive or in a batch. In this paper, we have introduced a new mode of heuristic called as intermediate mode (or Multi-\u03b6 batch mode). This mode considers the random arrival of task in a multi-batch sequence. Alternatively, arrivals of tasks are unknown in this mode. Here, we have taken a range of task arrival for simplicity. This mode is introduced to be a part of the real life aspects. The two existing batch mode heuristics: Min-Min and Max-Min are experimented with intermediate mode scheduling. We have taken two performance measures, makespan and resource utilization to evaluate the\u00a0\u2026", "num_citations": "2\n", "authors": ["475"]}
{"title": "X-DualMake: Novel Immediate Mode Scheduling Heuristics in Computational Grids\n", "abstract": " Scheduling is an important aspect in grid computing. Now-a-days, the computational grids are the important platform for job scheduling. The performance of the computational grids can be improved using an efficient scheduling heuristic. In job scheduling, a user submits the job to the grid resource broker. Then the broker is responsible for dividing the job into a number of tasks. Moreover, it also maps the tasks and the resources to find the perfect match. The primary goal of scheduling is to minimize the processing time and maximize the resource utilization. In this paper, we have proposed three immediate mode heuristics such as First-DualMake, Best-DualMake and Worst-DualMake (named as XDualMake).These heuristic are scheduled based on the resource idle time. We have also presented five existing heuristics such as MET, MCT, OLB, KPB and SA. The eight heuristics are simulated and the experimental results are discussed. The heuristics are compared using two performance measures makespan and resource utilization.", "num_citations": "2\n", "authors": ["475"]}
{"title": "SOA testing perspective model for regression testing\n", "abstract": " Service-Oriented Architecture (SOA) supports loose-coupling and interoperability, where services communicate with each-other through message exchanging protocol and interfaces. SOA supports vendor diversity. In order to full-fill the vendor need, service composition is considered as a key process. Regression testing is inevitable to assure the quality of SOA based applications during their evolution. This paper defines a regression testing process which helps us in regression testing of complex SOA based applications. We also propose an SOA testing perspective model. Here we divide SOA testing perspective model into three parts: Service developer perspective, Service tester perspective and Service provider perspective. The Proposed model also focuses on service validity when the service is going to register in the Universal Description and Discovery Integration (UDDI).", "num_citations": "2\n", "authors": ["475"]}
{"title": "Dynamic slicing of UML communication diagram\n", "abstract": " We propose a new technique for dynamic slicing of the UML communication models. In this technique, we use UML 2.0 communication diagram for representing the dynamic behavior of the system. First, the communication diagram is transformed into an intermediate representation which we named Communication Dependence Graph (CoDG). Next, we propose a dynamic slicing algorithm which traverses the graph for a given slicing criterion and produces the slice. The algorithm is based on marking and unmarking the edges of CoDG when dependencies between messages arise and cease at runtime. Dynamic behavior is represented by two diagrams namely sequence diagram and communication diagram. The novelty of our approach is that we use the communication diagram of UML model for representing the dynamic nature of the system. The advantage of using communication diagram is that it emphasizes\u00a0\u2026", "num_citations": "2\n", "authors": ["475"]}
{"title": "Architectural Aspect-Oriented Dynamic Slicing\n", "abstract": " A novel approach for dynamic slicing of aspect-oriented software based on UML 2.0 sequence diagrams is discussed in this paper. To represent the classes, aspects, pointcuts and advices in a single intermediate graph is quite difficult and complex in nature. Firstly, we construct an UML sequence diagram representing all relevant information and interaction between the classes, aspects, pointcuts, join points and advices. Then, an intermediate representation termed as Aspect Model Dependency Graph (AMDG) is constructed from the UML sequence diagram. The concept of program slicing in UML models is introduced as a mean to support software maintenance through understanding, querying, and analysis. For a given slicing criterion, our proposed dynamic slicing algorithm traverses the constructed AMDG to identify the parts that are directly or indirectly affected during the execution, by marking and unmarking\u00a0\u2026", "num_citations": "2\n", "authors": ["475"]}
{"title": "Test Case Generation from UML Interaction Diagrams\n", "abstract": " We propose a method to generate test cases using UML sequence diagram (SD) and interaction overview diagram (IOD). Our work considers interaction operators of UML 2.0 sequence diagram like alt, loop, par to generate test cases. First, we construct the SD and IOD for the given problem. Next, we develop an intermediate graph, named UML Interaction Graph (UIG). From the generated UIG, we generate different test cases, for represent different scenarios. The generated test cases achieve message path coverage.", "num_citations": "2\n", "authors": ["475"]}
{"title": "A graph coloring approach to slicing of object-oriented programs\n", "abstract": " The wide spread interest in slicing of object-oriented software has led to the birth of number of algorithms. Nowadays, slicing of object-oriented programs has picked up the momentum as most of the real world programs are object-oriented in nature. The algorithms which are available of-the-self, address different issues in their own ways. In this paper, we propose a new algorithm which incorporates graph coloring technique. But in order to compute the dynamic slice, we have contradicted some key constraints of graph coloring algorithm. The advantage of our algorithm is that it is faster and the process of computing slice can be optimized further.", "num_citations": "2\n", "authors": ["475"]}
{"title": "Interprocedural slicing of generic programs\n", "abstract": " This paper proposes a novel static slicing technique for object-oriented programs which are generic in nature. Many algorithms have been proposed so far for object-oriented programs. There are also few algorithms which describe slicing of inter-procedural object-oriented programs. But till date there is no algorithm proposed so far for slicing of object-oriented programs which are generic in nature. In this paper we describe an algorithm for slicing of inter-procedural generic program written in C++. But this technique can be applied to any programs which are generic in nature and written in any other languages like Ada, Eiffel, and J2SE etc.", "num_citations": "2\n", "authors": ["475"]}
{"title": "A node-marking technique for slicing concurrent object-oriented programs\n", "abstract": " We propose an efficient technique for slicing object-oriented programs. We use a dependence based intermediate program representation, which we have named Concurrent System Dependence Graph (CSDG) to represent object-oriented programs. The CSDG is an arcclassified digraph that represents various dependences like synchronization and communication dependences between statements. Our slicing algorithm marks and unmarks the executed nodes of CSDG appropriately during run time.", "num_citations": "2\n", "authors": ["475"]}
{"title": "Use of Manganic Ferrihydrite to treat As (V) contaminated water\n", "abstract": " The As(V) removal efficiency of Manganic Ferrihydrite, having a different mole ratio to Fe-Mn, were evaluated. The As(V) removal efficiency of the adsorbent increased with the increase in Mn up to 40\u201360 mole% in the Ferrihydrite. Thereafter, further increase in the Mn concentration showed an opposite trend. The adsorption efficiency was constant at pH range of 6\u20137 whereas the efficiency slightly decreased at > pH 7. Adsorption studies were also carried out varying the adsorbent and the adsorbate concentrations, respectively. The adsorption process followed both Freundlich's and Langmuir's adsorption isotherm models. The maximum theoretical uptake was calculated using the two investigated models. Since adsorption efficiency showed better results when the Mn concentration was 40\u201360 mole%, Manganic Ferrihydrite compound (Fe:Mn ratio 1:1) was used to conclude the experiments. The adsorption kinetics\u00a0\u2026", "num_citations": "2\n", "authors": ["475"]}
{"title": "A Novel Approach for Static Slicing of Inter-Procedural Programs\n", "abstract": " We propose a novel static slicing algorithm for inter-procedural programs. We use the system dependence graph (SDG) as the intermediate representation. We have implemented our algorithm by using file structures to handle all the statements that compute the static slice.", "num_citations": "2\n", "authors": ["475"]}
{"title": "An Ensemble-Based Scalable Approach for Intrusion Detection Using Big Data Framework\n", "abstract": " In this study, we set up a scalable framework for large-scale data processing and analytics using the big data framework. The popular classification methods are implemented, tuned, and evaluated by using intrusion datasets. The objective is to select the best classifier after optimizing the hyper-parameters. We observed that the decision tree (DT) approach outperforms compared with other methods in terms of classification accuracy, fast training time, and improved average prediction rate. Therefore, it is selected as a base classifier in our proposed ensemble approach to study class imbalance. As the intrusion datasets are imbalanced, most of the classification techniques are biased toward the majority class. The misclassification rate is more in the case of the minority class. An ensemble-based method is proposed by using K-Means, RUSBoost, and DT approaches to mitigate the class imbalance problem\u00a0\u2026", "num_citations": "1\n", "authors": ["475"]}
{"title": "Software Fault Prediction Using Random Forests\n", "abstract": " In this paper, we present a software fault prediction model using random forests. Software fault prediction identifies the faulty regions in a software product early in its lifecycle and hence improves the quality attributes such as reliability of the software. Random forest is an ensemble learning method for classification. Random forests contain many of decision trees and the result is the function of these decision trees. The proposed approach is applied on software defect prediction datasets collected from PROMISE software engineering repository and evaluated the performance using precision, recall, accuracy, and F-measure. The results of random forest model are compared with other models such as support vector machines, backpropagation neural networks, decision trees. Based on comparison, it is observed that random forest model is superior to the other models.", "num_citations": "1\n", "authors": ["475"]}
{"title": "A Self-trained Support Vector Machine Approach for Intrusion Detection\n", "abstract": " Intrusion refers\u00a0to a set of attempts to compromise the confidentiality,\u00a0integrity and availability (CIA) of the information system. Intrusion detection is the process of identifying\u00a0such violations by analyzing the malicious attempts. Intrusion detection system is used to automate the intrusion detection process just in time or real-time and alert the system administrator for mitigating such efforts. Many researchers have been proposed several detection approaches in this context. In this paper, we adopt a semi-supervised learning-based support vector machine (SVM) approach for mitigating such malicious efforts. The proposed approach improves the learning process and the detection accuracy as compared to the standard SVM approach. Moreover, it requires less amount of labeled training data during the learning process. Our approach iteratively trains the labeled data, predicts the unlabeled data and further retrains the\u00a0\u2026", "num_citations": "1\n", "authors": ["475"]}
{"title": "An incremental malware detection model for meta-feature API and system call sequence\n", "abstract": " In this technical world, the detection of malware variants is getting cumbersome day by day. Newer variants of malware make it even tougher to detect them. The enormous amount of diversified malware enforced us to stumble on new techniques like machine learning. In this work, we propose an incremental malware detection model for meta-feature API and system call sequence. We represent the host behaviour using a sequence of API calls and system calls. For the creation of sequential system calls, we use NITRSCT (NITR System call Tracer) and for sequential API calls, we generate a list of anomaly scores for each API call sequence using Numenta Hierarchical Temporal Memory (N-HTM). We have converted the API call sequence into six meta-features that narrates its influence. We do the feature selection using a correlation matrix with a heatmap to select the best meta-features. An incremental malware\u00a0\u2026", "num_citations": "1\n", "authors": ["475"]}
{"title": "ELM-MVD: An Extreme Learning Machine Trained Model for Malware Variants Detection\n", "abstract": " Malware variants are expanding at a fast pace and detecting them is a critical problem. According to surveys from McAfee, over 50% of the newly recognized malware are variants of earlier ones. Huge amount of miscellaneous malware variants compelled researchers to find a better model for detecting them. In this work, we propose an extreme learning machine trained model (ELM- MVD) for malware variants detection. We use the dataset comprising benign and malware executable names along with their features represented as a triplet of system calls. Along with that, we demonstrate that features in the form of a triplet vector are optimal while training a model. Feature reduction is done using an alternating direction method of multipliers (ADMM) technique. Finally, training is done on the ELM-MVD model and achieve 99.3% accuracy and 0.003\u00a0s detection speed.", "num_citations": "1\n", "authors": ["475"]}
{"title": "Automated Software Testing: Foundations, Applications and Challenges\n", "abstract": " This book covers both theory and applications in the automation of software testing tools and techniques for various types of software (eg object-oriented, aspect-oriented, and web-based software). When software fails, it is most often due to lack of proper and thorough testing, an aspect that is even more acute for object-oriented, aspect-oriented, and web-based software. Further, since it is more difficult to test distributed and service-oriented architecture-based applications, there is a pressing need to discuss the latest developments in automated software testing. This book discusses the most relevant issues, models, tools, challenges, and applications in automated software testing. Further, it brings together academic researchers, scientists, and engineers from a wide range of industrial application areas, who present their latest findings and identify future challenges in this fledging research area.", "num_citations": "1\n", "authors": ["475"]}
{"title": "Regression testing of object-oriented systems using UML state machine diagram and sequence diagram\n", "abstract": " The software requirements are modelled using UML state machine diagram and UML sequence diagram. The different features of both the diagrams are combined and an intermediate graph, i.e., state sequence graph (SSG) is generated. The affected nodes, due to different changes in the past versions of the applications are stored for further analysis. Whenever, a new version of the software is developed, and it is under regression testing, test scenario prioritisation is carried out by finding the frequent pattern from the stored modification history. Different other factors like number of message passing, number of state changes etc. also contribute in prioritising the test cases. The proposed approach is applied on different case studies and the results are recorded. This approach is found to be very efficient when evaluated using prioritisation metric and compared with other related work.", "num_citations": "1\n", "authors": ["475"]}
{"title": "Computing Dynamic Slices of Concurrent Feature-Oriented Programs\n", "abstract": " This paper proposes a dynamic slicing algorithm for concurrent feature-oriented programs. The algorithm is named concurrent feature-oriented node-marking dynamic slicing (CFNMDS) algorithm. The proposed dynamic slicing technique uses a dependence based intermediate representation named concurrent composite feature dependence graph (CCFDG). It is based on marking and unmarking of the executed nodes in CCFDG appropriately during runtime. Ten standard open source product lines have been taken to experiment the proposed CFNMDS algorithm. Jak codes and feature-oriented models have been developed for these product lines. The advantage of the proposed approach is that no trace file is used to store execution history of the program. Also, no extra nodes are created during runtime in the proposed approach. Creation of extra nodes leads to take more time for marking and\u00a0\u2026", "num_citations": "1\n", "authors": ["475"]}
{"title": "Schedulability analysis of Rate Monotonic Algorithm using Improved Time Demand Analysis for Multiprocessor Environment\n", "abstract": " Real-Time Monotonic algorithm (RMA) is a widely used static priority scheduling algorithm. For application of RMA at various systems, it is essential to determine the system\u2019s feasibility first. The various existing algorithms perform the analysis by reducing the scheduling points in a given task set. In this paper we propose a schedubility test algorithm, which reduces the number of tasks to be analyzed instead of reducing the scheduling points of a given task. This significantly reduces the number of iterations taken to compute feasibility. This algorithm can be used along with the existing algorithms to effectively reduce the high complexities encountered in processing large task sets. We also extend our algorithm to multiprocessor environment and compare number of iterations with different number of processors. This paper then compares the proposed algorithm with existing algorithm. The expected results show that the proposed algorithm performs better than the existing algorithms.", "num_citations": "1\n", "authors": ["475"]}
{"title": "Model-based Test Case Prioritization\n", "abstract": " Accepted: 16/Oct/2018, Published: 31/Oct/2018 Abstract-The efficiency of Software testing can be improved by scheduling the test cases using test case prioritization technique (TCP). A novel test case prioritization approach is proposed to schedule the execution of test cases in testing process of software development. Our approach prioritizes the test cases generated from UML Sequence diagram. The major objective of our TCP approach is to achieve high rate of fault detection and test coverage. In this paper, an intermediate graph is created form UML sequence diagram to generate the message sequence paths. We calculate the weights of each node of the graph according to the affecting nodes using forward slice and edge using information flow model. Then the weights of test paths which are generated from sequence diagram are calculated by adding the weights of associated nodes and edges. According to the weights of corresponding test paths the test cases are prioritized. The obtained results indicate that the proposed technique is effective in prioritizing the test cases by the Average Percentage of Fault Detection (APFD) metric to estimate the performance of our proposed approach. The result of our proposed approach is compared with the result of traditional approach using APFD for some selected software. Finally, our proposed prioritization approach is also compared with some available related work.", "num_citations": "1\n", "authors": ["475"]}
{"title": "Reduced energy consumption for MC/DC testing\n", "abstract": " After deployment, testing and validation techniques have become an important requirement for the reliability of software. However, these techniques do not measure energy that they consume, which is also an important parameter for software systems with short energy budgets. In this paper, we propose a new energy conservation technique. This novel technique does not affect the coverage percentage, but reduces the energy consumption. Energy conservation is based on test case minimisation technique according to modified condition/decision coverage (MC/DC) requirements. Our experimental study shows that, as compared to existing work, our proposed approach achieves less energy consumption. On an average of five programs, we save 40.8% energy consumption.", "num_citations": "1\n", "authors": ["475"]}
{"title": "HiRSA: computing hit ratio for SOA-based applications through Tcases\n", "abstract": " In this article, we propose a novel method for black-box test case generation for business process execution language (BPEL) processes. We also propose a method to compute hit ratio percentage metric. We also compute the total time taken for test case generation and the speed of test case generation. We design the service-oriented architecture (SOA)-based applications using OpenESB tool. We have developed a code converter to generate Tcases compatible .xml code because the OpenESB generated .xml code is incompatible with Tcases input framework. After that, we compute the hit ratio percentage with the help of Hit Ratio Calculator. We have experimented with 12 SOA-based applications, on an average, we achieve 62.78% of hit ratio with an average time of 873.08 ms and speed of 32.41 \u2248 32 test cases per second.", "num_citations": "1\n", "authors": ["475"]}
{"title": "An efficient code coverage technique for UML StateChart Diagram\n", "abstract": " In the proposed work, we present our developed tool to compute code coverages such as Branch Coverage and MC/DC of UML StateChart diagram. It is a chain integration of three public available tools (IBM RSA, JAXB, and jCUTE) and two tools developed by us. First, we design the UML StateChart diagram using IBM RSA and generate the XML code. Then, we convert this XML code into Java code using JAXB. But the generated Java code is not compatible with the concolic tester. So, we develop a module to generate compatible Java code for the concolic tester and named as JCJCG (jCUTE Compatible Java Code Generator). Subsequently, we run the compatible Java code on jCUTE and generate test cases and branch coverage percentage. We compute MC/DC% of the diagram through our developed tool COPECA (Coverage Percentage Calculator) by passing the Java code and generated test cases from\u00a0\u2026", "num_citations": "1\n", "authors": ["475"]}
{"title": "Green-J                                                       3 Model: a novel approach to measure energy consumption of modified condition/decision coverage using concolic testing\n", "abstract": " The power and energy consumption of computer systems have posed challenges to the environment. Few researchers focused on energy consumption of software, some have measured the energy consumption of hardware. Software energy consumption deals with amount of power consumed over time for a particular software. We know that, software testing is now moving towards automation. We use different testing tools to perform testing on programs and software. We propose our approach in regards to contribute in the field of Green Software Testing. Modified condition/decision coverage and concolic testing are very critical practices in Aerospace and Nuclear safety critical systems. However, these methodologies do not take into consideration the amount of energy and power consumptions, which is an important issue in Green Software Testing. In this article, we propose an energy consumption analysis for\u00a0\u2026", "num_citations": "1\n", "authors": ["475"]}
{"title": "Computational Intelligence in Data Mining: Proceedings of the International Conference on CIDM, 10-11 December 2016\n", "abstract": " The book presents high quality papers presented at the International Conference on Computational Intelligence in Data Mining (ICCIDM 2016) organized by School of Computer Engineering, Kalinga Institute of Industrial Technology (KIIT), Bhubaneswar, Odisha, India during December 10\u201311, 2016. The book disseminates the knowledge about innovative, active research directions in the field of data mining, machine and computational intelligence, along with current issues and applications of related topics. The volume aims to explicate and address the difficulties and challenges that of seamless integration of the two core disciplines of computer science.", "num_citations": "1\n", "authors": ["475"]}
{"title": "Schedulability analysis for rate-monotonic algorithm in parallel real-time systems\n", "abstract": " Content Rate-Monotonic algorithm (RMA) is a widely used static priority scheduling algorithm. For application of RMA on various systems, first it is essential to determine the system\u2019s feasibility. Various existing algorithms perform the analysis by reducing the scheduling points in a given task set. In this paper, we develop an algorithm to compute the RMA schedulability in a parallel real-time system. We discuss the bottlenecks of serial execution and show that the parallel algorithm to overcomes these limitation. The proposed algorithm is parallelized using OpenMP. The results obtained show the improvement due to the use of parallel algorithm in a multiprocessor environment.", "num_citations": "1\n", "authors": ["475"]}
{"title": "Interprocedural Conditioned Slicing\n", "abstract": " A technique, named Node Marking Conditioned Slicing (NMCS) algorithm, has been proposed to compute conditioned slices for interprocedural programs. First, the System Dependence Graph (SDG) is constructed as an intermediate representation of a given program. Then, NMCS algorithm selects the nodes satisfying a given condition by marking process and computes the conditioned slices for each variable at each statement during marking process. A stack has been used in NMCS algorithm to preserve the context in which a method is called. Some edges of SDG have been labeled to signify which statement calls a method.", "num_citations": "1\n", "authors": ["475"]}
{"title": "Measuring Hit ratio of Software Systems using UML Sequence Diagram\n", "abstract": " In this proposed work, we discuss how to generate test cases automatically from UML sequence diagram to compute Hit Ratio percentage of software systems. First, we construct the sequence diagram of the given software using ArgoUML tool. This sequence diagram is supplied to code converter to get XML code of the designed software. Then, we supply this XML code to Tcases tool to generate test cases according to black-box testing technique. These test cases are supplied to Hit Ratio Calculator to compute Hit Ratio percentage of the software system for five case studies comprise of twenty three sequence diagrams, on an average, we achieved 69.69 % Hit Ratio percentage.", "num_citations": "1\n", "authors": ["475"]}
{"title": "COLT: Extending Concolic testing to measure LCSAJ Coverage\n", "abstract": " In this paper, we propose a method for generating efficient test cases, that ensure the adequacy of software testing using appropriate software metrics such as Branch Coverage and Linear Code Sequence And Jump (LCSAJ). Now a days, automated testing is essential for software testing industries which saves time as well as cost. CONCOLIC testing generates test cases, these test cases can compute code coverage in an automated manner. Since, there exists no such concolic testing approach that computes LCSAJ, therefore in this paper we extend concolic testing to measure LCSAJ coverage. We have used CREST tool to generate test cases. We have developed LCSAJ coverage Analyzer that accepts test cases generated by CREST along with the input C program, and produces LCSAJ Coverage percentage. We have conducted our experiment for fifteen C programs. On an average, for fifteen C programs, we\u00a0\u2026", "num_citations": "1\n", "authors": ["475"]}
{"title": "Proceedings of 3rd International Conference on Advanced Computing, Networking and Informatics: ICACNI 2015, Volume 1\n", "abstract": " It is indeed a pleasure to receive overwhelming response from researchers of premier institutes of the country and abroad for participating in the 3rd International Conference on Advanced Computing, Networking, and Informatics (ICACNI 2015), which makes our endeavor successful. The conference organized by School of Computer Engineering, KIIT University, India during 23\u201325 June 2015 certainly marks a success toward bringing researchers, academicians, and practitioners in the same platform. We have received more than 550 articles and very stringently have selected through peer review 132 best articles for presentation and publication. We could not accommodate many promising works as we tried to ensure the quality. We are thankful to have the advice of dedicated academicians and experts from industry to organize the conference in good shape. We thank all people participating and submitting their\u00a0\u2026", "num_citations": "1\n", "authors": ["475"]}
{"title": "Analysis of Java programs using Joana and Java SDG API\n", "abstract": " JOANA (Java Object-sensitive Analysis) and Java SDG API are analysis frameworks available for analyzing Java programs for different applications. Now a days, the continuous evolution of the customer expectations and requirements has resulted in the increase of size of the software. Due to which the difficulties in maintaining software are increasing. Both Joana and Java SDG API consist of a variety of analysis techniques based on dependence graph generation and computation of slices of an input program. In this paper, we make a comparative analysis study on the effectiveness and efficiency of both these above mentioned analysis frameworks in generating the corresponding intermediate dependence graph and computing slices. The analysis is based on the bytecode of the program under consideration. The experimental analysis shows that Joana can be extended for various diverse applications.", "num_citations": "1\n", "authors": ["475"]}
{"title": "Model Based Test Case Generation and Optimization Using Intelligent Optimization Agent\n", "abstract": " Test case optimization is one of the techniques which efficiently manage the exponential growth in time and cost of testing. But in many times the researchers compromise with the code coverage while going for optimization. In this paper, the test suite is optimized using Intelligent Optimization Agent (IOA) while the keeping the percentage of code coverage unchanged. First the System Under Test (SUT) is modelled using UML Activity Diagram (AD) and converted into an Activity Graph (AG). Then the optimized path is found out in AD by using IOA and cost attributes. Then suitable algorithms are proposed to remove the redundant nodes in the optimized path. IOA is an agent based approach as compared to Hybrid Genetic Algorithm (HGA) in Intelligent Test Optimization Agent (ITOA).The proposed approach is found to be effective when compared with other optimization techniques like Genetic Algorithm (GA\u00a0\u2026", "num_citations": "1\n", "authors": ["475"]}
{"title": "AUTOMATED TEST CASE GENERATION USING UML USE CASE DIAGRAM AND ACTIVITY DIAGRAM.\n", "abstract": " Testing plays a major role for improving the quality of a software product. Due to its iterative and incremental nature it needs special attention. Test case generation is one of the complex activities carried out during testing phase. Generating test cases in the early phases of development life cycle works like a catalyst for model based testing and at the same time efficiently manages time and resources. This paper describes a novel approach for test case generation from UML Activity Diagram (AD) and Use Case Diagram (UCD). At first UCD and AD are converted into Use Case Graph (UCG) and Activity Graph (AG) respectively. The AG and UCG are integrated to form a combined graph called Activity Use Case Graph (AUCG). The AUCG is further traversed to generate test cases. Test cases generated using the combined approach is capable of detecting more number of faults as compared to individual models while\u00a0\u2026", "num_citations": "1\n", "authors": ["475"]}
{"title": "Data Flow Testing of CGI Based Web Applications\n", "abstract": " The functionality of most programs is delivered in terms of data. The values are somehow received by variables, which represent data and these values are used in computation of values for other variables. Data flow testing focuses on variable definition and variable usage. One of the fastest growing and most wide-spread application domains is the web application domain. The wide acceptance of Internet Technology requires sophisticated and high quality web applications. There are some sorts of entry forms that are provided by many web pages. These web pages require the user to supply input to the forms and click on the button or image. Sometimes, this program (commonly known as CGI program) is just an interface to an existing database, massaging user input into a database understandable format and massaging the database's output into the web browser understandable format (usually HTML). In this\u00a0\u2026", "num_citations": "1\n", "authors": ["475"]}
{"title": "A Regression Test Selection Technique for SOA Based Applications\n", "abstract": " Service Oriented Architecture (SOA) based application can be composed of heterogeneous self- contained independent services on the web. These applications are usually modified to fix bugs or to  enhance their functionality. These modifications are quick and they should be supported by rapid  verification. Regression Test (RT) is essential to ensure that modifications do not result in adverse  effects. Regression Test Selection (RTS), one of the cheapest techniques, aims at decreasing cost of  carrying out RT. This paper presents a Control Flow Graph (CFG) based approach that makes it feasible to  apply a safe RTS technique to SOA based applications or services in an end-to-end manner. Safe RTS  technique guarantees that no modification revealing tests will be left unselected. A simplified navigational  subsystem that involves 3 services, is used to elicit our approach.", "num_citations": "1\n", "authors": ["475"]}
{"title": "Automated Graphical User Interface Regression Testing\n", "abstract": " Regression testing is performed after software modification to find out the correctness and quality of any software product. The modification is either corrective or adaptive. Normally in regression testing, we have to rerun the existing test cases or test scripts on the modified product. In this paper we are generating test scripts, test cases automatically for performing regression testing of graphical user interfaces. We have taken three example applications and used the capture and replay feature of the automated tool to capture the event sequences and generate test scripts automatically.", "num_citations": "1\n", "authors": ["475"]}
{"title": "Measuring Coverage Percentage for C Programs using Code Slicer and CREST Tool\n", "abstract": " Augmented test suite generation is a technique to minimise test effort and duration. Modified condition and decision coverage (MC/DC) is a white box software testing criteria targeting to prove all the conditions involved in a predicate which can influence the predicate value in an efficient way. The coverage analysis is a structural testing method, which helps to remove gaps in a test suite and determines when to stop testing. In this paper, we propose an augmented method to generate a test suite that helps in measuring coverage percentage of a program. We propose a technique which consists of mainly three modules. The crest module is a program slicer, who accepts a program written in C language and uses some slicing criteria results an executable sliced program. The second module is the CREST tool (CONCOLIC tester) which accepts the executable C sliced program as an input. The CREST tool drives to generate the test suite. The third module is Coverage Analyser (CA) to compute the coverage percentage. Our technique helps to achieve the coverage percentage with time taken to execute the program.", "num_citations": "1\n", "authors": ["475"]}
{"title": "Slicing XML documents using dependence graph\n", "abstract": " Program Slicing is a popular technique that assists in various software maintenance activities like debugging, program comprehension and regression testing. It is a decomposition technique used for the extraction of program statements affecting the values computed at some point of interest. We propose a technique for computing slices of XML documents. Given a valid XML document, we produce a new XML document (a slice) containing the relevant information in the original XML document according to some criterion. We output a new DTD such that the computed slice is valid with respect to this DTD. Our technique first slices the associated DTD and the DTD slice is used as a slicing criterion in order to produce the associated XML slice.", "num_citations": "1\n", "authors": ["475"]}
{"title": "Computing Dynamic Slices of Object-Oriented Programs using Dependency Information\n", "abstract": " Now a days, object-oriented programs are becoming very popular amongst the developers and hence almost all software are designed using the object-oriented paradigm. Advanced features of object-oriented programming has made it complicated to understand, test, debug and maintain. To better manage these software, slicing techniques have been proved to be quite efficient. This paper proposed an algorithm for dynamic slicing of object-oriented software. It uses SDG (System Dependence Graph) and DG (Dynamic Graph) as the intermediate program representation while computing the dynamic slices. In this paper dynamic slicing algorithm is based on traversing through the outgoing control dependence edges and incoming data dependence edges of Dynamic Graph. The major advantage of the proposed algorithm is that the time required to compute the dynamic slice of the objectoriented programs is directly proportional to the number of dependencies (control and/or data) arising during the run time. Also the proposed algorithm depends on the numbers of nodes present in the intermediate program representation.", "num_citations": "1\n", "authors": ["475"]}
{"title": "A Self Analysing and Reliable SOA Model.\n", "abstract": " Service Oriented Architecture (SOA) provides a new way of application development by using existing services. The required services are collected and loosely composed to meet the user\u2019s specification, where the architecture of SOA is dynamic that is, it can change dynamically at run time to meet the new requirements. This paper proposes an architecture which has the capability to analyze the developed services by comparing the user\u2019s requirements. Finding a method for testing the accuracy of a service is a challenge always. The architecture provides a unified way of self analysis which evaluates the perfectness of developed service, before its delivery, and to find out its accuracy. This calculated perfectness is stored in the service profile of that service. The database is maintained for each service which helps for searching a required service to meet user\u2019s specification and for composition of a new service. When this self analysis of the developed service does not satisfy to meet the user\u2019s requirement because of not satisfying any conditions, it generates the fault. Fault is handled to provide the required correctness for composition of the service by detecting the services responsible for those faults. The architecture provides both reliability and analysis capability by handling fault and by searching a service based on accuracy which provides reliable delivery of service.", "num_citations": "1\n", "authors": ["475"]}
{"title": "A parallel algorithm for dynamic slicing of distributed Java programs in non-DSM systems\n", "abstract": " We propose a parallel algorithm for dynamic slicing of distributed Java programs in non-Distributed Shared Memory (DSM) systems. Given a distributed Java program, we first construct an intermediate representation in the form of a Distributed Program Dependence Graph (DPDG). We mark and unmark the edges of the DPDG appropriately as and when dependencies arise and cease during run-time. Our algorithm can run parallely on a network of computers, so that each node in the network contributes to the dynamic slice by computing its local portion of the global slice in a fully distributed fashion.", "num_citations": "1\n", "authors": ["475"]}
{"title": "A novel approach for computing dynamic slices of object-oriented programs with conditional statements\n", "abstract": " We propose a dynamic program slicing technique for object-oriented programs. We introduce the notion of compact dynamic dependence graph (CDDG) which is used as the intermediate program representation. Our dynamic slicing algorithm is based on the CDDG. We show that our algorithm is more time and space efficient than the existing ones. The worst case space complexity of our algorithm is O(n), where n is the number of statements of the program.", "num_citations": "1\n", "authors": ["475"]}