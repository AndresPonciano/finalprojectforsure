{"title": "Cost-directed refactoring for parallel Erlang programs\n", "abstract": " This paper presents a new programming methodology for introducing and tuning parallelism in Erlang programs, using source-level code refactoring from sequential source programs to parallel programs written using our skeleton library, Skel. High-level cost models allow us to predict with reasonable accuracy the parallel performance of the refactored program, enabling programmers to make informed decisions about which refactorings to apply. Using our approach, we demonstrate easily obtainable, significant and scalable speedups of up to 21 on a 24-core machine over the sequential code.", "num_citations": "54\n", "authors": ["808"]}
{"title": "The ParaPhrase Project: Parallel Patterns for Adaptive Heterogeneous Multicore Systems\n", "abstract": " This paper describes the ParaPhrase project, a new 3-year targeted research project funded under EU Framework 7 Objective 3.4 (Computer Systems), starting in October 2011. ParaPhrase aims to follow a new approach to introducing parallelism using advanced refactoring techniques coupled with high-level parallel design patterns. The refactoring approach will use these design patterns to restructure programs defined as networks of software components into other forms that are more suited to parallel execution. The programmer will be aided by high-level cost information that will be integrated into the refactoring tools. The implementation of these patterns will then use a well-understood algorithmic skeleton approach to achieve good parallelism. A key ParaPhrase design goal is that parallel components are intended to match heterogeneous architectures, defined in terms of CPU/GPU combinations, for\u00a0\u2026", "num_citations": "51\n", "authors": ["808"]}
{"title": "Paraforming: forming parallel haskell programs using novel refactoring techniques\n", "abstract": " Enabling programmers to \u201cthink parallel\u201d is critical if we are to be able to effectively exploit future multicore/manycore architectures. This paper introduces paraforming: a new approach to constructing parallel functional programs using formally-defined refactoring transformations. We introduce a number of new refactorings for Parallel Haskell that capture common parallel abstractions, such as divide-and-conquer and data parallelism, and show how these can be used by HaRe, the Haskell Refactorer. Using a paraforming approach, we are able to easily obtain significant and scalable speedups (up to 7.8 on an 8-core machine).", "num_citations": "35\n", "authors": ["808"]}
{"title": "Tool support for refactoring Haskell programs\n", "abstract": " This thesis is concerned with the investigation and implementation of a number of refactorings for Haskell. The refactorings are themselves written in Haskell [108], and implemented using the framework of HaRe, the Haskell Refactorer [68]. This chapter is aimed to give an overview of this thesis. In particular, Refactoring in general is described in Section 1.1 (Page 1); Section 1.2 (Page 6) describes what it means to refactor functional languages, including giving a brief overview of Haskell in Section 1.2. 1 (Page 6). We then given an overview of the refactorings outlined in this thesis in Section 1.3 (Page 13); the contributions of the thesis are given in Section 1.4 (Page 13); finally, a summary of the proceeding chapters is given in Section 1.5 (Page 16).", "num_citations": "33\n", "authors": ["808"]}
{"title": "Paraphrasing: Generating parallel programs using refactoring\n", "abstract": " Refactoring is the process of changing the structure of a program without changing its behaviour. Refactoring has so far only really been deployed effectively for sequential programs. However, with the increased availability of multicore (and, soon, manycore) systems, refactoring can play an important role in helping both expert and non-expert parallel programmers structure and implement their parallel programs. This paper describes the design of a new refactoring tool that is aimed at increasing the programmability of parallel systems. To motivate our design, we refactor a number of examples in C, C++ and Erlang into good parallel implementations, using a set of formal pattern rewrite rules.", "num_citations": "32\n", "authors": ["808"]}
{"title": "RPL: A Domain-Specific Language for Designing and Implementing Parallel C++ Applications\n", "abstract": " Parallelising sequential applications is usually a very hard job, due to many different ways in which an application can be parallelised and a large number of programming models (each with its own advantages and disadvantages) that can be used. In this paper, we describe a method to semi-automatically generate and evaluate different parallelisations of the same application, allowing programmers to find the best parallelisation without significant manual reengineering of the code. We describe a novel, high-level domain-specific language, Refactoring Pattern Language (RPL), that is used to represent the parallel structure of an application and to capture its extra-functional properties (such as service time). We then describe a set of RPL rewrite rules that can be used to generate alternative, but semantically equivalent, parallel structures (parallelisations) of the same application. We also describe the RPL Shell\u00a0\u2026", "num_citations": "27\n", "authors": ["808"]}
{"title": "Agricultural reform: more efficient farming using advanced parallel refactoring tools\n", "abstract": " Modern multicore systems offer huge computing potential. Exploiting large parallel systems is still a very challenging task, however, especially as many software developers still use overly-sequential programming models. refactoring tool support that allows the programmer to introduce and tune parallelism in an easy and effective way, exploiting high-level parallel patterns such as farms and pipelines. Using our approach, we achieve speedups of up to 21 on a 24-core shared-memory system for a number of realistic use-cases.", "num_citations": "20\n", "authors": ["808"]}
{"title": "A language-independent parallel refactoring framework\n", "abstract": " Recent trends towards increasingly parallel computers mean that there needs to be a seismic shift in programming practice. The time is rapidly approaching when most programming will be for parallel systems. However, most programming techniques in use today are geared towards sequential, or occasionally small-scale parallel, programming. While refactoring has so far mainly been applied to sequential programs, it is our contention that refactoring can play a key role in significantly improving the programmability of parallel systems, by allowing the programmer to apply a set of well-defined transformations in order to parallelise their programs. In this paper, we describe a new language-independent refactoring approach that helps introduce and tune parallelism through high-level design patterns targeting a set of well-specified parallel skeletons. We believe this new refactoring process is the key to allowing\u00a0\u2026", "num_citations": "14\n", "authors": ["808"]}
{"title": "Finding Parallel Functional Pearls: Automatic Parallel Recursion Scheme Detection in Haskell Functions via Anti-Unification\n", "abstract": " This paper describes a new technique for identifying potentially parallelisable code structures in functional programs. Higher-order functions enable simple and easily understood abstractions that can be used to implement a variety of common recursion schemes, such as maps and folds over traversable data structures. Many of these recursion schemes have natural parallel implementations in the form of algorithmic skeletons. This paper presents a technique that detects instances of potentially parallelisable recursion schemes in Haskell 98 functions. Unusually, we exploit anti-unification to expose these recursion schemes from source-level definitions whose structures match a recursion scheme, but which are not necessarily written directly in terms of maps, folds, etc. This allows us to automatically introduce parallelism, without requiring the programmer to structure their code a priori in terms of specific higher\u00a0\u2026", "num_citations": "13\n", "authors": ["808"]}
{"title": "Using program shaping and algorithmic skeletons to parallelise an evolutionary multi-agent system in Erlang\n", "abstract": " This paper considers how to use program shaping and algorithmic skeletons to parallelise a multi-agent system that is written in Erlang. Program shaping is the process of transforming a program to better enable the introduction of parallelism. Whilst algorithmic skeletons abstract away the low-level aspects of parallel programming that often plague traditional techniques, it is not always easy to introduce them into an arbitrary program, especially one that has not been written with parallelism in mind. Amongst other issues, data may not always be in a compatible format, function calls may need to be replicated to support alternative uses, side-effects may need to be isolated, or there may be dependencies between functions and data that obstruct the introduction of parallelism. Program shaping can be used to transform such code to a form that allows skeletons to be more easily introduced. In this paper, we present a series of generic program shaping rewrite rules, provide their implementation as refactorings, and show how they can be used to parallelise an Evolutionary Multi-Agent System (MAS) written in Erlang. We show that we can significantly speed up this application, obtaining super-linear speedups of over 70 times the original sequential performance on a 64-core shared-memory machine.", "num_citations": "13\n", "authors": ["808"]}
{"title": "Mapping parallel programs to heterogeneous CPU/GPU architectures using a Monte Carlo Tree Search\n", "abstract": " The single core processor, which has dominated for over 30 years, is now obsolete with recent trends increasing towards parallel systems, demanding a huge shift in programming techniques and practices. Moreover, we are rapidly moving towards an age where almost all programming will be targeting parallel systems. Parallel hardware is rapidly evolving, with large heterogeneous systems, typically comprising a mixture of CPUs and GPUs, becoming the mainstream. Additionally, with this increasing heterogeneity comes increasing complexity: not only does the programmer have to worry about where and how to express the parallelism, they must also express an efficient mapping of resources to the available system. This generally requires in-depth expert knowledge that most application programmers do not have. In this paper we describe a new technique that derives, automatically, optimal mappings for an\u00a0\u2026", "num_citations": "12\n", "authors": ["808"]}
{"title": "Easy composition of symbolic computation software using SCSCP: a new Lingua Franca for symbolic computation\n", "abstract": " We present the results of the first four years of the European research project SCIEnce\u2014Symbolic Computation Infrastructure in Europe (http://www.symbolic-computing.org), which aims to provide key infrastructure for symbolic computation research. A primary outcome of the project is that we have developed a new way of combining computer algebra systems using the Symbolic Computation Software Composability Protocol (SCSCP), in which both protocol messages and data are encoded in the OpenMath format. We describe the SCSCP middleware and APIs, outline implementations for various Computer Algebra Systems (CAS), and show how SCSCP-compliant components may be combined to solve scientific problems that cannot be solved within a single CAS, or may be organised into a system for distributed parallel computations. Additionally, we present several domain-specific parallel skeletons that\u00a0\u2026", "num_citations": "12\n", "authors": ["808"]}
{"title": "Lapedo : hybrid skeletons for programming heterogeneous multicore machines in Erlang\n", "abstract": " We describe Lapedo, a novel library of hybrid parallel skeletons for programming heterogeneous multi-core/many-core CPU/GPU systems in Erlang. Lapedo\u2019s skeletons comprise a mixture of CPU and GPU components, allowing skeletons to be flexibly and dynamically mapped to available resources, with all of the low-level tedious code to divide work between CPUs and GPUs, transfer the data between the main and GPU memory and offload computations to the GPUs provided by the library. We evaluate the effectiveness of Lapedo on three realistic use cases from different domains, demonstrating significant improvements in speedups compared to CPU-only and GPU-only executions.", "num_citations": "11\n", "authors": ["808"]}
{"title": "Towards semi-automatic data-type translation for parallelism in Erlang\n", "abstract": " As part of ongoing research into programmer-in-the-loop parallelisation, we are studying the problem of automatically introducing alternative data structures to support parallelism. Our goal is to make it easier to produce the best parallelisation for some given program, or even to make parallelisation feasible. We use a refactoring approach to choose and introduce these transformations for specific algorithmic skeletons, structured forms of parallelism that capture common patterns of parallelism.", "num_citations": "5\n", "authors": ["808"]}
{"title": "Ever-decreasing circles: a skeleton for parallel orbit calculations in Eden\n", "abstract": " The Orbit algorithm is widely used in symbolic computation, allowing the exploration of a solution space given some initial starting values and a number of mathematically-defined generators. In this paper, we consider how the Orbit algorithm can be encoded in Haskell, and thence how a parallel skeleton can be developed to cover a variety of Orbit calculations, using the Eden parallel dialect of Haskell. Our results with a synthetic benchmark on a modern multicore machine clearly demonstrate the potential of this skeleton to allow simple but effective parallel implementation of the Orbit algorithm, giving relative speedups of up to 8.295 on eight cores. They also demonstrate that a workpool implementation is more effective than a task farm for larger problem sizes, since better task distribution can be achieved. On eight cores, we achieve speedups of up to 8.295 for the workpool, versus 7.851 for the task farm, with a 9% reduction in runtime for the workpool.", "num_citations": "5\n", "authors": ["808"]}
{"title": "Refactoring GrPPI: generic refactoring for generic parallelism in C++\n", "abstract": " The Generic Reusable Parallel Pattern Interface (GrPPI) is a very useful abstraction over different parallel pattern libraries, allowing the programmer to write generic patterned parallel code that can easily be compiled to different backends such as FastFlow, OpenMP, Intel TBB and C++ threads. However, rewriting legacy code to use GrPPI still involves code transformations that can be highly non-trivial, especially for programmers who are not experts in parallelism. This paper describes software refactorings to semi-automatically introduce instances of GrPPI patterns into sequential C++ code, as well as safety checking static analysis mechanisms which verify that introducing patterns into the code does not introduce concurrency-related bugs such as race conditions. We demonstrate the refactorings and safety-checking mechanisms on four simple benchmark applications, showing that we are able to obtain\u00a0\u2026", "num_citations": "3\n", "authors": ["808"]}
{"title": "A hybrid approach to parallel pattern discovery in C++\n", "abstract": " Parallel pattern libraries offer a strong combination of abstraction and performance. However, discovering places in sequential code where parallel patterns should be introduced is still highly non-trivial, often requiring expert manual analysis and profiling. We present a hybrid discovery technique to detect instances of parallel patterns in sequential code. This employs both static and dynamic trace-based analysis, together with hotspot detection. We evaluate our pattern discovery mechanism on a number of representative benchmarks. We evaluate the performance of the resulting parallelised benchmarks on a 24-core parallel machine.", "num_citations": "3\n", "authors": ["808"]}
{"title": "Type-Driven Verification of Non-functional Properties\n", "abstract": " Energy, Time and Security (ETS) properties of programs are becoming increasingly prioritised by developers, especially where applications are running on ETS sensitive systems, such as embedded devices or the Internet of Things. Moreover, developers currently lack tools and language properties to allow them to reason about ETS. In this paper, we introduce a new contract specification framework, called Drive, which allows a developer to reason about ETS or other non-functional properties of their programs as first-class properties of the language. Furthermore, we introduce a contract specification language, allowing developers to reason about these first-class ETS properties by expressing contracts that are proved correct by an underlying formal type system. Finally, we show our contract framework over a number of representable examples, demonstrating provable worst-case ETS properties.", "num_citations": "3\n", "authors": ["808"]}
{"title": "Using erlang skeletons to parallelise realistic medium-scale parallel programs\n", "abstract": " This paper shows how the Erlang skeleton library, Skel, can be used to parallelise the Discrete Haar Wavelet Transform application. The Discrete Haar Wavelet Transform is a very important wavelet transformation, which is heavily used in image and signal processing. Using the Skeleton version of the application, we were able to achieve speedups of 16.63 on a 24-core shared memory machine. This demonstrates that, with relatively little effort, the Skel library can be used for parallelisation of Erlang applications, obtaining very good speedups.", "num_citations": "3\n", "authors": ["808"]}
{"title": "Space Exploration using Parallel Orbits: a Study in Parallel Symbolic Computing.\n", "abstract": " Orbit enumerations represent an important class of mathematical algorithms which is widely used in computational discrete mathematics. In this paper, we present a new shared-memory implementation of a generic Orbit skeleton in the GAP computer algebra system [5, 6]. By defining a skeleton, we are easily able to capture a wide variety of concrete Orbit enumerations that can exploit the same underlying parallel implementation. We also propose a generic cost model for predicting the speedups that our Orbit skeleton will deliver for a given application on a given parallel system. We demonstrate the scalability of our implementation on a 64-core shared-memory machine. Our results show that we are able to obtain good speedups over sequential GAP programs (up to 36 on 64 cores).", "num_citations": "3\n", "authors": ["808"]}
{"title": "Skel: A streaming process-based skeleton library for Erlang\n", "abstract": " Skel: A Streaming Process-based Skeleton Library for Erlang Page 1 Skel: A Streaming Process-based Skeleton Library for Erlang Archibald Elliott1 Christopher Brown1 Marco Danelutto2 Kevin Hammond1 Email: ashe@st-andrews.ac.uk 1School of Computer Science, University of St Andrews, Scotland, UK. 2Dept. Computer Science, University of Pisa, Pisa, Italy. IFL 2012 - Oxford Page 2 This Talk \u25b6 Why we need Parallelism \u25b6 Skeletons are good Abstractions \u25b6 Skeletons in Erlang \u25b6 skel\u2019s good Speedups Page 3 The Vision 1. The single-core processor is almost completely obsolete 2. Hardware systems are rapidly moving towards many- and mega-core By 2019 there will be millions of cores in home desktop machines \u2013 Joe Armstrong 3. Software systems are still not ready: \u25ba Programming languages have not caught up \u25ba Software practices have not caught up \u25ba Programmers have not caught up 4. We need \u2026", "num_citations": "3\n", "authors": ["808"]}
{"title": "Timing properties and correctness for structured parallel programs on x86-64 multicores\n", "abstract": " This paper determines correctness and timing properties for structured parallel programs on x86-64 multicores. Multicore architectures are increasingly common, but real architectures have unpredictable timing properties, and commonly used relaxed-memory concurrency models mean that even functional correctness is not obvious. This paper takes a rigorous approach to correctness and timing properties, examining common locking protocols from first principles, and extending this through queues to structured parallel constructs. We prove functional correctness and derive simple timing models, extending these for the first time from low-level machine operations to high-level parallel patterns. Our derived high-level timing models for structured parallel programs allow us to accurately predict upper bounds on program execution times on x86-64 multicores.", "num_citations": "2\n", "authors": ["808"]}
{"title": "Improving Your CASH Flow: The Computer Algebra SHell\n", "abstract": " This paper describes CASH (the Computer Algebra SHell), a new interface that allows Haskell programmers to access the complete functionality of a number of computer algebra systems directly and interactively. Using CASH, Haskell programmers can access previously-unavailable mathematical software. Additionally, users of computer algebra systems can exploit the rapidly growing Haskell code base and its rich set of libraries. In particular, CASH provides a simple and effective interface for users of computer algebra systems to parallelise their algorithms using domain-specific skeletons written in Haskell.", "num_citations": "2\n", "authors": ["808"]}
{"title": "A trustworthy framework for resource-aware embedded programming\n", "abstract": " Systems with non-functional requirements, such as Energy, Time and Security (ETS), are of increasing importance due to the proliferation of embedded devices with limited resources such as drones, wireless sensors, and tablet computers. Currently, however, there are little to no programmer supported methodologies or frameworks to allow them to reason about ETS properties in their source code. Drive is one such existing framework supporting the developer by lifting non-functional properties to the source-level through the Contract Specification Language (CSL), allowing non-functional properties to be first-class citizens, and supporting programmer-written code-level contracts to guarantee the non-functional specifications of the program are met. In this paper, we extend the Drive system by providing rigorous implementations of the underlying proof-engine, modeling the specification of the annotations and\u00a0\u2026", "num_citations": "1\n", "authors": ["808"]}
{"title": "Mini Thesis-Refactoring Functional Programs\n", "abstract": " Refactoring is a source-to-source program transformation approach, which changes the internal structure and organisation of a program without changing the program\u2019s behaviour. Refactoring is a well established practice, and is regarded as a well-disciplined approach to cleaning up code. Refactoring focuses on the structural changes of a program, strictly preserving functionality. Preserving functionality guarantees that refactoring does not introduce any new bugs (or remove any old ones) or invalidate any existing tests. The aim of this project is to explore refactorings for functional programs. This will be done using the Haskell language and building upon existing research on HaRe, the Haskell Refactorer.This mini-thesis summarises our work so far. First, it introduces the notions of program refactoring, functional programming and refactoring functional programs, and presents some work related to this research\u00a0\u2026", "num_citations": "1\n", "authors": ["808"]}