{"title": "Choosing software metrics for defect prediction: an investigation on feature selection techniques\n", "abstract": " The selection of software metrics for building software quality prediction models is a search\u2010based software engineering problem. An exhaustive search for such metrics is usually not feasible due to limited project resources, especially if the number of available metrics is large. Defect prediction models are necessary in aiding project managers for better utilizing valuable project resources for software quality improvement. The efficacy and usefulness of a fault\u2010proneness prediction model is only as good as the quality of the software measurement data. This study focuses on the problem of attribute selection in the context of software quality estimation. A comparative investigation is presented for evaluating our proposed hybrid attribute selection approach, in which feature ranking is first used to reduce the search space, followed by a feature subset selection. A total of seven different feature ranking techniques are\u00a0\u2026", "num_citations": "283\n", "authors": ["1975"]}
{"title": "A comparative study of ensemble feature selection techniques for software defect prediction\n", "abstract": " Feature selection has become the essential step in many data mining applications. Using a single feature subset selection method may generate local optima. Ensembles of feature selection methods attempt to combine multiple feature selection methods instead of using a single one. We present a comprehensive empirical study examining 17 different ensembles of feature ranking techniques (rankers) including six commonly-used feature ranking techniques, the signal-to-noise filter technique, and 11 threshold-based feature ranking techniques. This study utilized 16 real-world software measurement data sets of different sizes and built 13,600 classification models. Experimental results indicate that ensembles of very few rankers are very effective and even better than ensembles of many or all rankers.", "num_citations": "104\n", "authors": ["1975"]}
{"title": "How many software metrics should be selected for defect prediction?\n", "abstract": " A software practitioner is interested in the solution to \u201cfor a given project, what is the minimum number of software metrics that should be considered for building an effective defect prediction model?\u201d During the development life cycle various software metrics are collected for different reasons. In the case of a metricsbased defect prediction model, an intelligent selection of software metrics prior to building defect predictors is likely to improve model performance. This study utilizes the proposed threshold-based feature selection technique to remove irrelevant and redundant software metrics (aka features or attributes). A comparative investigation is presented for evaluating the size of the selected feature subsets. The case study is based on software measurement data obtained from a real-world project, and the defect predictors are trained using three commonly used classifiers. The empirical case study results demonstrate that an effective defect predictor can be built with only three metrics; and moreover, model performances improved when over 98.5% of the software metrics were eliminated.", "num_citations": "72\n", "authors": ["1975"]}
{"title": "A comparative study of threshold-based feature selection techniques\n", "abstract": " Given high-dimensional software measurement data, researchers and practitioners often use feature (metric) selection techniques to improve the performance of software quality classification models. This paper presents our newly proposed threshold-based feature selection techniques, comparing the performance of these techniques by building classification models using five commonly used classifiers. In order to evaluate the effectiveness of different feature selection techniques, the models are evaluated using eight different performance metrics separately since a given performance metric usually captures only one aspect of the classification performance. All experiments are conducted on three Eclipse data sets with different levels of class imbalance. The experiments demonstrate that the choice of a performance metric may significantly influence the results. In this study, we have found four distinct patterns\u00a0\u2026", "num_citations": "55\n", "authors": ["1975"]}
{"title": "Software measurement data reduction using ensemble techniques\n", "abstract": " Software defect prediction models are used to identify program modules that are high-risk, or likely to have a high number of faults. These models are built using software metrics which are collected during the software development process. Various techniques and approaches have been created for improving fault predictions. One of these is feature (metric) selection. Choosing the most important features is important to improve the effectiveness of defect predictors. However, using a single feature subset selection method may generate local optima. Ensembles of feature selection methods attempt to combine multiple feature selection methods instead of using a single one. In this paper, we present a comprehensive empirical study examining 17 different ensembles of feature ranking techniques (rankers) including six commonly used feature ranking techniques, the signal-to-noise filter technique, and 11 threshold\u00a0\u2026", "num_citations": "48\n", "authors": ["1975"]}
{"title": "An empirical investigation of filter attribute selection techniques for software quality classification\n", "abstract": " Attribute selection is an important activity in data preprocessing for software quality modeling and other data mining problems. The software quality models have been used to improve the fault detection process. Finding faulty components in a software system during early stages of software development process can lead to a more reliable final product and can reduce development and maintenance costs. It has been shown in some studies that prediction accuracy of the models improves when irrelevant and redundant features are removed from the original data set. In this study, we investigated four filter attribute selection techniques, automatic hybrid search (AHS), rough sets (RS), Kolmogorov-Smirnov (KS) and probabilistic search (PS) and conducted the experiments by using them on a very large telecommunications software system. In order to evaluate their classification performance on the smaller subsets of\u00a0\u2026", "num_citations": "48\n", "authors": ["1975"]}
{"title": "Metric selection for software defect prediction\n", "abstract": " Real-world software systems are becoming larger, more complex, and much more unpredictable. Software systems face many risks in their life cycles. Software practitioners strive to improve software quality by constructing defect prediction models using metric (feature) selection techniques. Finding faulty components in a software system can lead to a more reliable final system and reduce development and maintenance costs. This paper presents an empirical study of six commonly used filter-based software metric rankers and our proposed ensemble technique using rank ordering of the features (mean or median), applied to three large software projects using five commonly used learners. The classification accuracy was evaluated in terms of the AUC (Area Under the ROC (Receiver Operating Characteristic) Curve) performance metric. Results demonstrate that the ensemble technique performed better overall\u00a0\u2026", "num_citations": "47\n", "authors": ["1975"]}
{"title": "A survey of stability analysis of feature subset selection techniques\n", "abstract": " With the proliferation of high-dimensional datasets across many application domains in recent years, feature selection has become an important data mining task due to its capability to improve both performance and computational efficiencies. The chosen feature subset is important not only due to its ability to improve classification performance, but also because in some domains, knowing the most important features is an end unto itself. In this latter case, one important property of a feature selection method is stability, which refers to insensitivity (robustness) of the selected features to small changes in the training dataset. In this survey paper, we discuss the problem of stability, its importance, and various stability measures used to evaluate feature subsets. We place special focus on the problem of stability as it applies to subset evaluation approaches (whether they are selected through filter-based subset techniques\u00a0\u2026", "num_citations": "40\n", "authors": ["1975"]}
{"title": "A comparative study of filter-based feature ranking techniques\n", "abstract": " One factor that affects the success of machine learning is the presence of irrelevant or redundant information in the training data set. Filter-based feature ranking techniques (rankers) rank the features according to their relevance to the target attribute and we choose the most relevant features to build classification models subsequently. In order to evaluate the effectiveness of different feature ranking techniques, a commonly used method is to assess the classification performance of models built with the respective selected feature subsets in terms of a given performance metric (e.g., classification accuracy or misclassification rate). Since a given performance metric usually can capture only one specific aspect of the classification performance, it may be unable to evaluate the classification performance from different perspectives. Also, there is no general consensus among researchers and practitioners regarding\u00a0\u2026", "num_citations": "32\n", "authors": ["1975"]}
{"title": "Stability analysis of feature ranking techniques on biological datasets\n", "abstract": " One major problem faced when analyzing DNA microarrays is their high dimensionality (large number of features). Therefore, feature selection is a necessary step when using these datasets. However, the addition or removal of instances can alter the subsets chosen by a feature selection technique. The ideal situation is to choose a feature selection technique that is robust (stable) to changes in the number of instances, with selected features changing little even when instances are added or removed. In this study we test the stability of nineteen feature selection techniques across twenty- six datasets with varying levels of class imbalance. Our results show that the best choice of technique depends on the class balance of the datasets. The top performers are Deviance for balanced datasets, Signal to Noise for slightly unbalanced datasets, and AUC for unbalanced datasets. SVM-RFE was the least stable feature\u00a0\u2026", "num_citations": "26\n", "authors": ["1975"]}
{"title": "High-dimensional software engineering data and feature selection\n", "abstract": " Software metrics collected during project development play a critical role in software quality assurance. A software practitioner is very keen on learning which software metrics to focus on for software quality prediction. While a concise set of software metrics is often desired, a typical project collects a very large number of metrics. Minimal attention has been devoted to finding the minimum set of software metrics that have the same predictive capability as a larger set of metrics - we strive to answer that question in this paper. We present a comprehensive comparison between seven commonly-used filter-based feature ranking techniques (FRT) and our proposed hybrid feature selection (HFS) technique. Our case study consists of a very high-dimensional (42 software attributes) software measurement data set obtained from a large telecommunications system. The empirical analysis indicates that HFS performs better\u00a0\u2026", "num_citations": "22\n", "authors": ["1975"]}
{"title": "An Empirical Study of Software Metrics Selection Using Support Vector Machine.\n", "abstract": " The objective of feature selection is to identify irrelevant and redundant features, which can then be discarded from the analysis. Reducing the number of metrics (features) in a data set can lead to faster software quality model training and improved classifier performance. In this study we focus on feature ranking using linear Support Vector Machines (SVM) which is implemented in WEKA. The contribution of this study is to provide an extensive empirical evaluation of SVM rankers built from imbalanced data. Should the features be removed at each iteration? What should the recommended value be for the tolerance parameter? We address these and other related issues in this work.", "num_citations": "21\n", "authors": ["1975"]}
{"title": "Mining data from multiple software development projects\n", "abstract": " A large system often goes through multiple software project development cycles, in part due to changes in operation and development environments. For example, rapid turnover of the development team between releases can influence software quality, making it important to mine software project data over multiple system releases when building defect predictors. Data collection of software attributes are often conducted independent of the quality improvement goals, leading to the availability of a large number of attributes for analysis. Given the problems associated with variations in development process, data collection, and quality goals from one release to another emphasizes the importance of selecting a best-set of software attributes for software quality prediction. Moreover, it is intuitive to remove attributes that do not add to, or have an adverse effect on, the knowledge of the consequent model. Based on real\u00a0\u2026", "num_citations": "18\n", "authors": ["1975"]}
{"title": "Stability of filter-and wrapper-based software metric selection techniques\n", "abstract": " For most software systems, some of the software metrics collected during the software development cycle may contain redundant information, provide no information, or may have an adverse effect on prediction models built with these metrics. An intelligent selection of software metrics (features) using feature selection techniques (which reduce the feature subset to an optimal size) prior to building defect prediction models may improve the final defect prediction results. While some feature selection techniques consider each feature individually, feature subset selection evaluates entire feature subsets and thus can help remove redundant features. Unfortunately, feature subset selection may have the problem of selecting different features from similar datasets. This paper addresses the question of which feature subset selection methods are stable in the face of changes to the data (here, the addition or removal of\u00a0\u2026", "num_citations": "16\n", "authors": ["1975"]}
{"title": "Measuring robustness of feature selection techniques on software engineering datasets\n", "abstract": " Feature Selection is a process which identifies irrelevant and redundant features from a high-dimensional dataset (that is, a dataset with many features), and removes these before further analysis is performed. Recently, the robustness (e.g., stability) of feature selection techniques has been studied, to examine the sensitivity of these techniques to changes in their input data. In this study, we investigate the robustness of six commonly used feature selection techniques as the magnitude of change to the datasets and the size of the selected feature subsets are varied. All experiments were conducted on 16 datasets from three real-world software projects. The experimental results demonstrate that Gain Ratio shows the least stability on average while two different versions of ReliefF show the most stability. Results also show that making smaller changes to the datasets has less impact on the stability of feature ranking\u00a0\u2026", "num_citations": "15\n", "authors": ["1975"]}
{"title": "A novel dataset-similarity-aware approach for evaluating stability of software metric selection techniques\n", "abstract": " Software metric (feature) selection is an important pre-processing step before building software defect prediction models. Although much research has been done analyzing the classification performance of feature selection methods, fewer works have focused on their stability (robustness). Stability is important because feature selection methods which reliably produce the same results despite changes to the data are more trustworthy. Of the papers studying stability, most either compare the features chosen from different random subsamples of the dataset or compare each random subsample with the original dataset. These either result in an unknown degree of overlap between the subsamples, or comparing datasets of different sizes. In this work, we propose a fixed-overlap partition algorithm which generates a pair of subsamples with the same number of instances and a specified degree of overlap. We\u00a0\u2026", "num_citations": "14\n", "authors": ["1975"]}
{"title": "A study of software metric selection techniques: stability analysis and defect prediction model performance\n", "abstract": " Software metrics (features or attributes) are collected during the software development cycle. Metric selection is one of the most important preprocessing steps in the process of building defect prediction models and may improve the final prediction result. However, the addition or removal of program modules (instances or samples) can alter the subsets chosen by a feature selection technique, rendering the previously-selected feature sets invalid. Very limited research have been done considering both stability (or robustness) and defect prediction model performance together in the software engineering domain, despite the importance of both aspects when choosing a feature selection technique. In this paper, we test the stability and classification model performance of eighteen feature selection techniques as the magnitude of change to the datasets and the size of the selected feature subsets are varied. All\u00a0\u2026", "num_citations": "12\n", "authors": ["1975"]}
{"title": "Improved variable and value ranking techniques for mining categorical traffic accident data\n", "abstract": " The ever increasing size of datasets used for data mining and machine learning applications has placed a renewed emphasis on algorithm performance and processing strategies. This paper addresses algorithms for ranking variables in a dataset, as well as for ranking values of a specific variable. We propose two new techniques, called Max Gain (MG) and Sum Max Gain Ratio (SMGR), which are well-correlated with existing techniques, yet are much more intuitive. MG and SMGR were developed for the public safety domain using categorical traffic accident data. Unlike the typical abstract statistical techniques for ranking variables and values, the proposed techniques can be motivated as useful intuitive metrics for non-statistician practitioners in a particular domain. Additionally, the proposed techniques are generally more efficient than the more traditional statistical approaches.", "num_citations": "11\n", "authors": ["1975"]}
{"title": "Variable selection and ranking for analyzing automobile traffic accident data\n", "abstract": " Variable ranking and feature selection are important concepts in data mining and machine learning. This paper introduces a new variable ranking technique named Sum Max Gain Ratio (SMGR). The new technique is evaluated within the domain of traffic accident data and against a more generalized dataset. In certain cases, SMGR is empirically shown to provide similar results to established approaches with significantly better runtime performance.", "num_citations": "11\n", "authors": ["1975"]}
{"title": "An empirical investigation on wrapper-based feature selection for predicting software quality\n", "abstract": " The basic measurements for software quality control and management are the various project and software metrics collected at various states of a software development life cycle. The software metrics may not all be relevant for predicting the fault proneness of software components, modules, or releases. Thus creating the need for the use of feature (software metric) selection. The goal of feature selection is to find a minimum subset of attributes that can characterize the underlying data with results as well as, or even better than the original data when all available features are considered. As an example of inter-disciplinary research (between data science and software engineering), this study is unique in presenting a large comparative study of wrapper-based feature (or attribute) selection techniques for building defect predictors. In this paper, we investigated thirty wrapper-based feature selection methods to remove\u00a0\u2026", "num_citations": "10\n", "authors": ["1975"]}
{"title": "An empirical study on the stability of feature selection for imbalanced software engineering data\n", "abstract": " In software quality modeling, software metrics are collected during the software development cycle. However, not all metrics are relevant to the class attribute (software quality). Metric (feature) selection has become the cornerstone of many software quality classification problems. Selecting software metrics that are important for software quality classification is a necessary and critical step before the model training process. Recently, the robustness (e.g., stability) of feature selection techniques has been studied, to examine the sensitivity of these techniques to changes (adding/removing program modules to/from their dataset). This work provides an empirical study regarding the stability of feature selection techniques across six software metrics datasets with varying levels of class balance. In this work eighteen feature selection techniques are evaluated. Moreover, three factors, feature subset size, degree of\u00a0\u2026", "num_citations": "10\n", "authors": ["1975"]}
{"title": "A Novel Hybrid Search Algorithm for Feature Selection.\n", "abstract": " Data mining is the exploration and analysis of large datasets for discovering hidden knowledge and patterns. The various techniques from the field of data mining have been successfully applied to a variety of domains. An important area of data mining and machine learning is feature selection. The goal of feature selection is to find a minimum set of features (attributes) such that the reduced dataset characterizes the data similarly as the original dataset without significantly reducing the accuracy of the classifier. We propose a new feature selection algorithm called Automatic Hybrid Search (AHS) that generates consistent feature subsets and is a hybrid of the filter and the wrapper models. Our experiments have shown that AHS performed well at feature selection with a relatively lower runtime cost, a smaller size of the selected feature subset, and a lower error rate than the more traditional approaches such as exhaustive search, heuristic search, and probabilistic search. The findings suggest that AHS is more sensitive to the number of features than to the number of instances in the dataset.", "num_citations": "10\n", "authors": ["1975"]}
{"title": "On the stability of feature selection methods in software quality prediction: an empirical investigation\n", "abstract": " Software quality modeling is the process of using software metrics from previous iterations of development to locate potentially faulty modules in current under-development code. This has become an important part of the software development process, allowing practitioners to focus development efforts where they are most needed. One difficulty encountered in software quality modeling is the problem of high dimensionality, where the number of available software metrics is too large for a classifier to work well. In this case, many of the metrics may be redundant or irrelevant to defect prediction results, thereby selecting a subset of software metrics that are the best predictors becomes important. This process is called feature (metric) selection. There are three major forms of feature selection: filter-based feature rankers, which uses statistical measures to assign a score to each feature and present the user with a ranked\u00a0\u2026", "num_citations": "9\n", "authors": ["1975"]}
{"title": "A Study on First Order Statistics-Based Feature Selection Techniques on Software Metric Data.\n", "abstract": " Software quality is an important attribute of software products, especially for high-assurance and mission-critical systems. One effective way to produce a high quality software product is to build software quality prediction models which use software metrics collected during the course of software development to identify potentially faultprone modules. Feature selection can be used to determine which software metrics (which act as features) are most useful for constructing these models. In this paper, we investigate seven first order statistics-based feature selection techniques, evaluating both their stability (ability to produce consistent feature subsets even in the face of changes to the data) and classification performance (ability to select software metrics which are useful for building accurate models) in the context of software quality estimation by testing them on data from a very large telecommunications software\u00a0\u2026", "num_citations": "9\n", "authors": ["1975"]}
{"title": "A comparative study on the stability of software metric selection techniques\n", "abstract": " In large software projects, software quality prediction is an important aspect of the development cycle to help focus quality assurance efforts on the modules most likely to contain faults. To perform software quality prediction, various software metrics are collected during the software development cycle, and models are built using these metrics. However, not all features (metrics) make the same contribution to the class attribute (e.g., faulty/not faulty). Thus, selecting a subset of metrics that are relevant to the class attribute is a critical step. As many feature selection algorithms exist, it is important to find ones which will produce consistent results even as the underlying data is changed, this quality of producing consistent results is referred to as \"stability.\" In this paper, we investigate the stability of seven feature selection techniques in the context of software quality classification. We compare four approaches for varying the\u00a0\u2026", "num_citations": "6\n", "authors": ["1975"]}
{"title": "Exploring filter-based feature selection techniques for software quality classification\n", "abstract": " The quality of software products can be estimated and improved by building software quality classification models. The predictive accuracy of the software quality classification models is usually affected by two factors: the learning model(s) used in classification and the quality of the data. This study examined both influencing factors, but we concentrated more on the quality of the data by selecting a subset of relevant features for building classification models. We investigated four filter-based feature selection techniques in a case study on a very large telecommunications software system. The empirical results demonstrated that by applying attribute selection we can build classification models with prediction accuracy comparable to or even better than those built with a complete set of attributes, even though the smaller subset of attributes had less than 15% of the complete set of attributes.", "num_citations": "6\n", "authors": ["1975"]}
{"title": "Stability and classification performance of feature selection techniques\n", "abstract": " Feature selection techniques can be evaluated based on either model performance or the stability (robustness) of the technique. The ideal situation is to choose a feature selection technique that is robust to change, while also ensuring that models built with the selected features perform well. One domain where feature selection is especially important is software defect prediction, where large numbers of metrics collected from previous software projects are used to help engineers focus their efforts on the most faulty modules. This study presents a comprehensive empirical examination of seven filter-based feature ranking techniques (rankers) applied to nine real-world software measurement datasets of different sizes. Experimental results demonstrate that signal-to-noise ranker performed moderately in terms of robustness and was the best ranker in terms of model performance. The study also shows that although\u00a0\u2026", "num_citations": "6\n", "authors": ["1975"]}
{"title": "Performance comparison of location areas and reporting centers under aggregate movement behavior mobility models\n", "abstract": " Location management deals with how to track mobile users within the cellular network. It consists of two basic operations: location update and paging. The total location management cost is the sum of the location update cost and the paging cost. Location areas and reporting centers are two popular location management schemes. The motivation for the study is the observation that the location update cost difference between the reporting centers scheme and the location areas scheme is small whereas the paging cost in the reporting centers scheme is larger than that in the location areas scheme. The paper compares the performance of the location areas scheme and the reporting centers scheme under aggregate movement behavior mobility models by simulations. Simulation results show that the location areas scheme performs about the same as the reporting centers scheme in two extreme cases, that is, when\u00a0\u2026", "num_citations": "6\n", "authors": ["1975"]}
{"title": "A comparative study on data perturbation with feature selection\n", "abstract": " As a major concern in designing various data mining applications, privacy preservation has become a critical component seeking a trade-off between mining utilities and protecting sensitive information. Data perturbation or distortion is a widely used approach for privacy protection. Either by adding noises or matrix decomposition methods, many algorithms were developed based on the simulation of attacker\u2019s behaviors. Most of them are complicated and computationally infeasible on dataset with huge attribute space. In addition, the real-world data tend to be inconsistent, redundant and consist of irrelevant part to target information. Executing algorithms on such data is costly and ineffective. Data preprocessing routines attempt to smooth out noise while identifying outliers, and correct inconsistencies in the data. One of the most important data preprocessing techniques is feature selection. In this paper, we intensively studied Singular Value Decomposition (SVD) based data distortion strategy and feature selection techniques, and conducted experiments to explore how feature selection approaches should be used and better serve for privacy preservation purpose. Sparsified Singular Value Decomposition (SSVD) and filter based feature selection are used for data distortion and reducing feature space. We propose a modified version of Exponential Threshold Strategy (ETS) as our threshold function for matrix sparsification. Some metrics are used to measure data distortion level. We also proposed a novel algorithm to compute rank and gave its lower running time bound. The mining utility of distorted data is tested with a well known Classifier\u00a0\u2026", "num_citations": "5\n", "authors": ["1975"]}
{"title": "Data mining to improve traffic safety\n", "abstract": " The ever increasing size of datasets used for data mining and machine learning applications has placed a renewed emphasis on algorithm performance and processing strategies. This research addresses algorithms for ranking variables in a dataset, as well as for ranking values of a specific variable. We propose two new techniques, called Max Gain (MG) and Sum Max Gain Ratio (SMGR), which are well-correlated with existing techniques, yet are much more intuitive. MG and SMGR were developed for the public safety domain using categorical traffic accident data. Unlike the typical abstract statistical techniques for ranking variables and values, the proposed techniques can be motivated as useful intuitive metrics for non-statistician practitioners in a particular domain. Additionally, the developed techniques are generally more efficient than the more traditional statistical approaches.", "num_citations": "5\n", "authors": ["1975"]}
{"title": "Measuring stability of feature selection techniques on real-world software datasets\n", "abstract": " In the practice of software quality estimation, superfluous software metrics often exist in data repositories. In other words, not all collected software metrics are useful or make equal contributions to software defect prediction. Selecting a subset of features that are most relevant to the class attribute is necessary and may result in better prediction. This process is called feature selection. However, the addition or removal of instances can alter the subsets chosen by a feature selection technique, rendering the previously-selected feature sets invalid. Thus, the robustness (e.g., stability) of feature selection techniques must be studied to examine the sensitivity of these techniques to changes in their input data (the addition or removal of instances). In this study, we test the stability of 18 feature selection techniques as the magnitude of change to the datasets and the size of the selected feature subsets are varied. All\u00a0\u2026", "num_citations": "4\n", "authors": ["1975"]}
{"title": "Measuring stability of threshold-based feature selection techniques\n", "abstract": " Feature selection has been applied in many domains, such as text mining and software engineering. Ideally a feature selection technique should produce consistent outputs regardless of minor variations in the input data. Researchers have recently begun to examine the stability (robustness) of feature selection techniques. The stability of a feature selection method is defined as the degree of agreement between its outputs to randomly-selected subsets of the same input data. This study evaluated the stability of 11 threshold-based feature ranking techniques (rankers) when applied to 16 real-world software measurement datasets of different sizes. Experimental results demonstrate that AUC (Area Under the Receiver Operating Characteristic Curve) and PRC (Area Under the Precision-Recall Curve) performed best among the 11 rankers.", "num_citations": "4\n", "authors": ["1975"]}
{"title": "Stability of Three Forms of Feature Selection Methods on Software Engineering Data.\n", "abstract": " One of the major challenges when working with software metrics datasets is that some metrics may be redundant or irrelevant to software defect prediction. This may be addressed using feature (metric) selection, which chooses an appropriate subset of features for use in downstream computation. There are three major forms of feature selection: filter-based feature rankers, which uses statistical measures to assign a score to each feature and present the user with a ranked list; filter-based subset evaluation, which uses statistical measures on feature subsets to find the best choice; and wrapper-based subset selection, which builds classification models using different subsets to find the one which maximizes performance. Software practitioners are interested in which feature selection methods are best at providing the most stable feature subset in the face of changes to the data (here, the addition or removal of instances). In this study we select feature subsets using fifteen feature selection methods and then use our newly proposed Average Pairwise Tanimoto Index (APTI) to evaluate the stability of feature selection methods. We evaluate the stability of feature selection methods on a pair of subsamples generated by fixed-overlap partitions algorithm. Four different levels of overlap are considered in this study. Four software metric datasets from a real-world software project are used in this study. Results demonstrate that ReliefF (RF) is the most stable feature selection method and wrapper based feature subset selection shows least stability. In addition, as the overlap of partitions increased, the stability of the feature selection strategies increased.", "num_citations": "3\n", "authors": ["1975"]}
{"title": "Choosing the Best Classification Performance Metric for Wrapper-based Software Metric Selection for Defect Prediction.\n", "abstract": " Software metrics and fault data are collected during the software development cycle. A typical software defect prediction model is trained using this collected data. Therefore the quality and characteristics of the underlying software metrics play an important role in the efficacy of the prediction model. However, superfluous software metrics often exist. Identifying a small subset of metrics becomes an essential task before building defect prediction models. Wrapper-based feature (software metric) subset selection uses a classifier to discover which feature subsets are most useful. To the best of our knowledge, no previous work has examined how the choice of performance metric within wrapper-based feature selection will affect classification performance. In this paper, we used five wrapper-based feature selection methods to remove irrelevant and redundant features. These five wrappers vary based on the choice of performance metric (Overall Accuracy (OA), Area Under ROC (Receiver Operating Characteristic) Curve (AUC), Area Under the Precision-Recall Curve (PRC), Best Geometric Mean (BGM), and Best Arithmetic Mean (BAM)) used in the model evaluation process. The models are trained using the logistic regression learner both inside and outside wrappers. The case study is based on software metrics and defect data collected from a real world software project. The results demonstrate that BAM is the best performance metric used within the wrapper. Moreover, comparing to models built with full datasets, the performances of defect prediction models can be improved when metric subsets are selected through a wrapper subset selector.", "num_citations": "3\n", "authors": ["1975"]}
{"title": "Categorical Data Transformation Methods for Neural Networks.\n", "abstract": " Data mining is the process of analyzing and exploring large dataset from different perspectives in order to extract hidden predictive and useful informationinformation that can be used to increase revenue, cut costs, or both. There is a need to pre-process the data to make it easier to mine for knowledge. Data preprocessing includes data cleaning, data transformation and data reduction. This study addresses data transformation, which transformed categorical data to numerical data. In this paper, we proposed a data transformation method, information probability, and used neural network to predict motor vehicle injury accident with information probability in traffic safety domain. Experimental results show the significant improvement achieved by the proposed method. Accurate results of such data analysis can be useful for traffic safety engineer or policy maker to set up preventive countermeasure.", "num_citations": "3\n", "authors": ["1975"]}
{"title": "A Study on Software Metric Selection for Software Fault Prediction\n", "abstract": " For most software systems, superfluous software metrics are often collected. Sometimes, metrics that are collected may be redundant or irrelevant to fault prediction results. Feature (software metric) selection helps separating relevant software metrics from irrelevant or redundant ones, thereby identifying the small set of software metrics that are best predictors of fault proneness for new components, modules, or releases. In this study, we compare three forms of feature selection techniques (filter-and wrapper-based subset evaluators along with two search techniques (Best First (BF) and Greedy Stepwise (GS)), and feature ranking on four datasets from a real world software project. Five learners are used to build fault prediction models with the selected software metrics. Each model is assessed using the Area Under the Receiver Operating Characteristic Curve (AUC). We find that wrapper-based subset evaluators\u00a0\u2026", "num_citations": "1\n", "authors": ["1975"]}
{"title": "An empirical study on wrapper-based feature selection for software engineering data\n", "abstract": " Software metrics give valuable information for understanding and predicting the quality of software modules, and thus it is important to select the right software metrics for building software quality classification models. In this paper we focus on wrapper-based feature (metric) selection techniques, which evaluate the merit of feature subsets based on the performance of classification models. We seek to understand the relationship between the internal learner used inside wrappers and the external learner for building the final classification model. We perform experiments using four consecutive releases of a very large telecommunications system, which include 42 software metrics (and with defect data collected for every program module). Our results demonstrate that (1) the best performance is never found when the internal and external learner match, (2)the best performance is usually found by using NB (Na\u00efve\u00a0\u2026", "num_citations": "1\n", "authors": ["1975"]}
{"title": "Xdiff+ a visualization system for XML documents and Schemata\n", "abstract": " We describe Xdiff+, a system for visualizing the conformance of XML documents to a DTD. The system is based on a set of algorithms to compute the distance between a document and a schema. The system includes a GUI that allows the user to visualize how an XML document can be edited to conform to a schema with the minimum cost. Real data-sets have been used to demonstrate the use of the system.", "num_citations": "1\n", "authors": ["1975"]}
{"title": "Performance comparison of location areas and reporting centres under individualised mobility models\n", "abstract": " Location areas and reporting centres are two classical and popular location management schemes in cellular networks. To the best of our knowledge, no performance comparison between reporting centres and location areas has been reported in literature. The paper compares the performance of the location areas scheme and the reporting centres scheme in terms of the paging and update cost. Given a set of reporting centres, the paper describes how to derive the location areas from the reporting centres, and claims that the paging cost in the derived location areas scheme is much smaller than that in the original reporting centres scheme whereas the update cost difference between two schemes is small. Simulations under various mobility models and incoming call arrival rates support the claim.", "num_citations": "1\n", "authors": ["1975"]}