{"title": "Zyzzyva: speculative byzantine fault tolerance\n", "abstract": " We present Zyzzyva, a protocol that uses speculation to reduce the cost and simplify the design of Byzantine fault tolerant state machine replication. In Zyzzyva, replicas respond to a client's request without first running an expensive three-phase commit protocol to reach agreement on the order in which the request must be processed. Instead, they optimistically adopt the order proposed by the primary and respond immediately to the client. Replicas can thus become temporarily inconsistent with one another, but clients detect inconsistencies, help correct replicas converge on a single total ordering of requests, and only rely on responses that are consistent with this total order. This approach allows Zyzzyva to reduce replication overheads to near their theoretical minimal.", "num_citations": "775\n", "authors": ["532"]}
{"title": "Making Byzantine fault tolerant systems tolerate Byzantine faults\n", "abstract": " This paper argues for a new approach to building Byzantine fault tolerant replication systems. We observe that although recently developed BFT state machine replication protocols are quite fast, they don\u2019t tolerate Byzantine faults very well: a single faulty client or server is capable of rendering PBFT, Q/U, HQ, and Zyzzyva virtually unusable. In this paper, we (1) demonstrate that existing protocols are dangerously fragile,(2) define a set of principles for constructing BFT services that remain useful even when Byzantine faults occur, and (3) apply these principles to construct a new protocol, Aardvark. Aardvark can achieve peak performance within 40% of that of the best existing protocol in our tests and provide a significant fraction of that performance when up to f servers and any number of clients are faulty. We observe useful throughputs between 11706 and 38667 requests per second for a broad range of injected faults.", "num_citations": "475\n", "authors": ["532"]}
{"title": "Depot: Cloud storage with minimal trust\n", "abstract": " This article describes the design, implementation, and evaluation of Depot, a cloud storage system that minimizes trust assumptions. Depot tolerates buggy or malicious behavior by any number of clients or servers, yet it provides safety and liveness guarantees to correct clients. Depot provides these guarantees using a two-layer architecture. First, Depot ensures that the updates observed by correct nodes are consistently ordered under Fork-Join-Causal consistency (FJC). FJC is a slight weakening of causal consistency that can be both safe and live despite faulty nodes. Second, Depot implements protocols that use this consistent ordering of updates to provide other desirable consistency, staleness, durability, and recovery properties. Our evaluation suggests that the costs of these guarantees are modest and that Depot can tolerate faults and maintain good availability, latency, overhead, and staleness even when\u00a0\u2026", "num_citations": "383\n", "authors": ["532"]}
{"title": "BAR fault tolerance for cooperative services\n", "abstract": " This paper describes a general approach to constructing cooperative services that span multiple administrative domains. In such environments, protocols must tolerate both Byzantine behaviors when broken, misconfigured, or malicious nodes arbitrarily deviate from their specification and rational behaviors when selfish nodes deviate from their specification to increase their local benefit. The paper makes three contributions:(1) It introduces the BAR (Byzantine, Altruistic, Rational) model as a foundation for reasoning about cooperative services;(2) It proposes a general three-level architecture to reduce the complexity of building services under the BAR model; and (3) It describes an implementation of BAR-B the first cooperative backup service to tolerate both Byzantine users and an unbounded number of rational users. At the core of BAR-B is an asynchronous replicated state machine that provides the customary\u00a0\u2026", "num_citations": "383\n", "authors": ["532"]}
{"title": "Making geo-replicated systems fast as possible, consistent when necessary\n", "abstract": " Online services distribute and replicate state across geographically diverse data centers and direct user requests to the closest or least loaded site. While effectively ensuring low latency responses, this approach is at odds with maintaining cross-site consistency. We make three contributions to address this tension. First, we propose RedBlue consistency, which enables blue operations to be fast (and eventually consistent) while the remaining red operations are strongly consistent (and slow). Second, to make use of fast operation whenever possible and only resort to strong consistency when needed, we identify conditions delineating when operations can be blue and must be red. Third, we introduce a method that increases the space of potential blue operations by breaking them into separate generator and shadow phases. We built a coordination infrastructure called Gemini that offers RedBlue consistency, and we report on our experience modifying the TPC-W and RUBiS benchmarks and an online social network to use Gemini. Our experimental results show that RedBlue consistency provides substantial performance gains without sacrificing consistency.", "num_citations": "352\n", "authors": ["532"]}
{"title": "BAR gossip\n", "abstract": " Gossip relies on verifiable pseudo-random partner selection to eliminate non-determinism that can be used to game the system while maintaining the robustness and rapid convergence of traditional gossip. A novel fair enough exchange primitive entices cooperation among selfish nodes on short timescales, avoiding the need for long-term node reputations. Our initial experience provides evidence for BAR Gossip\u2019s robustness. Our BAR-tolerant streaming application provides over 99% convergence for broadcast updates when all clients are selfish but not colluding, and over 95% convergence when up to 40% of clients collude while the rest follow the protocol. BAR Gossip also performs well when the client population consists of both selfish and Byzantine nodes, achieving over 93% convergence even when 20% of the nodes are Byzantine.", "num_citations": "295\n", "authors": ["532"]}
{"title": "Upright cluster services\n", "abstract": " The UpRight library seeks to make Byzantine fault tolerance (BFT) a simple and viable alternative to crash fault tolerance for a range of cluster services. We demonstrate UpRight by producing BFT versions of the Zookeeper lock service and the Hadoop Distributed File System (HDFS). Our design choices in UpRight favor simplifying adoption by existing applications; performance is a secondary concern. Despite these priorities, our BFT Zookeeper and BFT HDFS implementations have performance comparable with the originals while providing additional robustness.", "num_citations": "265\n", "authors": ["532"]}
{"title": "Zyzzyva: Speculative byzantine fault tolerance\n", "abstract": " A longstanding vision in distributed systems is to build reliable systems from unreliable components. An enticing formulation of this vision is Byzantine Fault-Tolerant (BFT) state machine replication, in which a group of servers collectively act as a correct server even if some of the servers misbehave or malfunction in arbitrary (\u201cByzantine\u201d) ways. Despite this promise, practitioners hesitate to deploy BFT systems, at least partly because of the perception that BFT must impose high overheads. In this article, we present Zyzzyva, a protocol that uses speculation to reduce the cost of BFT replication. In Zyzzyva, replicas reply to a client's request without first running an expensive three-phase commit protocol to agree on the order to process requests. Instead, they optimistically adopt the order proposed by a primary server, process the request, and reply immediately to the client. If the primary is faulty, replicas can become\u00a0\u2026", "num_citations": "259\n", "authors": ["532"]}
{"title": "All about eve: Execute-verify replication for multi-core servers\n", "abstract": " This paper presents Eve, a new Execute-Verify architecture that allows state machine replication to scale to multi-core servers. Eve departs from the traditional agree-execute architecture of state machine replication: replicas first execute groups of requests concurrently and then verify that they can reach agreement on a state and output produced by a correct replica; if they can not, they roll back and execute the requests sequentially. Eve minimizes divergence using application-specific criteria to organize requests into groups of requests that are unlikely to interfere. Our evaluation suggests that Eve\u2019s unique ability to combine execution independence with nondetermistic interleaving of requests enables highperformance replication for multi-core servers while tolerating a wide range of faults, including elusive concurrency bugs.", "num_citations": "197\n", "authors": ["532"]}
{"title": "Sok: The evolution of sybil defense via social networks\n", "abstract": " Sybil attacks in which an adversary forges a potentially unbounded number of identities are a danger to distributed systems and online social networks. The goal of sybil defense is to accurately identify sybil identities. This paper surveys the evolution of sybil defense protocols that leverage the structural properties of the social graph underlying a distributed system to identify sybil identities. We make two main contributions. First, we clarify the deep connection between sybil defense and the theory of random walks. This leads us to identify a community detection algorithm that, for the first time, offers provable guarantees in the context of sybil defense. Second, we advocate a new goal for sybil defense that addresses the more limited, but practically useful, goal of securely white-listing a local region of the graph.", "num_citations": "193\n", "authors": ["532"]}
{"title": "Flightpath: Obedience vs. choice in cooperative services\n", "abstract": " We present FlightPath, a novel peer-to-peer streaming application that provides a highly reliable data stream to a dynamic set of peers. We demonstrate that FlightPath reduces jitter compared to previous works by several orders of magnitude. Furthermore, FlightPath uses a number of run-time adaptations to maintain low jitter despite 10% of the population behaving maliciously and the remaining peers acting selfishly. At the core of FlightPath's success are approximate equilibria. These equilibria allow us to design incentives to limit selfish behavior rigorously, yet they provide sufficient flexibility to build practical systems. We show how to use an \u03b5-Nash equilibrium, instead of a strict Nash, to engineer a live streaming system that uses bandwidth efficiently, absorbs flash crowds, adapts to sudden peer departures, handles churn, and tolerates malicious activity.", "num_citations": "120\n", "authors": ["532"]}
{"title": "Musketeer: all for one, one for all in data processing systems\n", "abstract": " Many systems for the parallel processing of big data are available today. Yet, few users can tell by intuition which system, or combination of systems, is\" best\" for a given workflow. Porting workflows between systems is tedious. Hence, users become\" locked in\", despite faster or more efficient systems being available. This is a direct consequence of the tight coupling between user-facing front-ends that express workflows (eg, Hive, SparkSQL, Lindi, GraphLINQ) and the back-end execution engines that run them (eg, MapReduce, Spark, PowerGraph, Naiad).", "num_citations": "119\n", "authors": ["532"]}
{"title": "Automating the Choice of Consistency Levels in Replicated Systems.\n", "abstract": " Online services often use replication for improving the performance of user-facing services. However, using replication for performance comes at a price of weakening the consistency levels of the replicated service. To address this tension, recent proposals from academia and industry allow operations to run at different consistency levels. In these systems, the programmer has to decide which level to use for each operation. We present SIEVE, a tool that relieves Java programmers from this error-prone decision process, allowing applications to automatically extract good performance when possible, while resorting to strong consistency whenever required by the target semantics. Taking as input a set of application-specific invariants and a few annotations about merge semantics, SIEVE performs a combination of static and dynamic analysis, offline and at runtime, to determine when it is necessary to use strong consistency to preserve these invariants and when it is safe to use causally consistent commutative replicated data types (CRDTs). We evaluate SIEVE on two web applications and show that the automatic classification overhead is low.", "num_citations": "100\n", "authors": ["532"]}
{"title": "Exploring the design space of social network-based Sybil defenses\n", "abstract": " Recently, there has been significant research interest in leveraging social networks to defend against Sybil attacks. While much of this work may appear similar at first glance, existing social network-based Sybil defense schemes can be divided into two categories: Sybil detection and Sybil tolerance. These two categories of systems both leverage global properties of the underlying social graph, but they rely on different assumptions and provide different guarantees: Sybil detection schemes are application-independent and rely only on the graph structure to identify Sybil identities, while Sybil tolerance schemes rely on application-specific information and leverage the graph structure and transaction history to bound the leverage an attacker can gain from using multiple identities. In this paper, we take a closer look at the design goals, models, assumptions, guarantees, and limitations of both categories of social\u00a0\u2026", "num_citations": "61\n", "authors": ["532"]}
{"title": "Zyzzyva: speculative byzantine fault tolerance\n", "abstract": " Zyzzyva recognizes that this condition is stronger than required. Instead, Zyzzyva enforces the weaker condition: a correct client only acts on replies that are stable. This change allows us to move the output commit from the servers to the client, which in the optimized case allows servers to avoid expensive all-to-all communication that they would otherwise require to ensure the stronger condition. Leveraging the client in this way allows us to minimize server overheads and maximize throughputs in the optimized, failure-free case. As a result, Zyzzyva\u2019s peak measured throughput of over 86K requests/second on 3.0 GHz Pentium-IV machines makes it feasible to utilize BFT replication in a broad range of demanding services. Despite this aggressive optimization to the fault-free case, Zyzzyva retains good performance of over 82K requests/second even when up to f backup replicas crash. In fact, Zyzzyva\u2019s replication\u00a0\u2026", "num_citations": "54\n", "authors": ["532"]}
{"title": "Tardis: A branch-and-merge approach to weak consistency\n", "abstract": " This paper presents the design, implementation, and evaluation of TARDiS (Transactional Asynchronously Replicated Divergent Store), a transactional key-value store explicitly designed for weakly-consistent systems. Reasoning about these systems is hard, as neither causal consistency nor per-object eventual convergence allow applications to deal satisfactorily with write-write conflicts. TARDiS instead exposes as its fundamental abstraction the set of conflicting branches that arise in weakly-consistent systems. To this end, TARDiS introduces a new concurrency control mechanism: branch-on-conflict. On the one hand, TARDiS guarantees that storage will appear sequential to any thread of execution that extends a branch, keeping application logic simple. On the other, TARDiS provides applications, when needed, with the tools and context necessary to merge branches atomically, when and how applications\u00a0\u2026", "num_citations": "48\n", "authors": ["532"]}
{"title": "BAR primer\n", "abstract": " Byzantine and rational behaviors are increasingly recognized as unavoidable realities in todaypsilas cooperative services. Yet, how to design BAR-tolerant protocols and rigorously prove them strategy proof remains somewhat of a mystery: existing examples tend either to focus on unrealistically simple problems or to want in rigor. The goal of this paper is to demystify the process by presenting the full algorithmic development cycle that, starting from the classic synchronous repeated terminating reliable broadcast (R-TRB) problem statement, leads to a provably BAR-tolerant solution. We show i) how to express R-TRB as a game; ii) why the strategy corresponding to the optimal Byzantine fault tolerant algorithm of Dolev and strong does not guarantee safety when non-Byzantine players behave rationally; iii) how to derive a BAR-tolerant R-TRB protocol: iv) how to prove rigorously that the protocol ensures safety in the\u00a0\u2026", "num_citations": "44\n", "authors": ["532"]}
{"title": "On the (limited) power of non-equivocation\n", "abstract": " In recent years, there have been a few proposals to add a small amount of trusted hardware at each replica in a Byzantine fault tolerant system to cut back replication factors. These trusted components eliminate the ability for a Byzantine node to perform equivocation, which intuitively means making conflicting statements to different processes.", "num_citations": "42\n", "authors": ["532"]}
{"title": "BFT: The time is now\n", "abstract": " Data centers strive to provide reliable access to the data and services that they host. This reliable access requires the hosted data and services hosted by the data center to be both consistent and available. Byzantine fault tolerance (BFT) replication offers the promise of services that are consistent and available despite arbitrary failures by a bounded number of servers and an unbounded number of clients.", "num_citations": "40\n", "authors": ["532"]}
{"title": "Seeing is believing: A client-centric specification of database isolation\n", "abstract": " This paper introduces the first state-based formalization of isolation guarantees. Our approach is premised on a simple observation: applications view storage systems as black-boxes that transition through a series of states, a subset of which are observed by applications. Defining isolation guarantees in terms of these states frees definitions from implementation-specific assumptions. It makes immediately clear what anomalies, if any, applications can expect to observe, thus bridging the gap that exists today between how isolation guarantees are defined and how they are perceived. The clarity that results from definitions based on client-observable states brings forth several benefits. First, it allows us to easily compare the guarantees of distinct, but semantically close, isolation guarantees. We find that several well-known guarantees, previously thought to be distinct, are in fact equivalent, and that many previously\u00a0\u2026", "num_citations": "39\n", "authors": ["532"]}
{"title": "Defending against large-scale crawls in online social networks\n", "abstract": " Thwarting large-scale crawls of user profiles in online social networks (OSNs) like Facebook and Renren is in the interest of both the users and the operators of these sites. OSN users wish to maintain control over their personal information, and OSN operators wish to protect their business assets and reputation. Existing rate-limiting techniques are ineffective against crawlers with many accounts, be they fake accounts (also known as Sybils) or compromised accounts of real users obtained on the black market.", "num_citations": "38\n", "authors": ["532"]}
{"title": "The paxos register\n", "abstract": " We introduce the Paxos register to simplify and unify the presentation of Paxos-style consensus protocols. We use our register to show how Lamport's Classic Paxos and Castro and Liskov's Byzantine Paxos are the same consensus protocol, but for different failure models. We also use our register to compare and contrast Byzantine Paxos with Martin and Alvisi's fast Byzantine consensus. The Paxos register is a write-once register that exposes two important abstractions for reaching consensus: (i) read and write operations that capture how processes in Paxos protocols propose and decide values and (ii) tokens that capture how these protocols guarantee agreement despite partial failures. We encapsulate the differences of several Paxos-style protocols in the implementation details of these abstractions.", "num_citations": "31\n", "authors": ["532"]}
{"title": "Theory of BAR games\n", "abstract": " Distributed systems are increasingly deployed over Multiple Administrative Domains (MADs) in which no single authority has control over all participating nodes. Traditionally, nodes in distributed systems deviate from their specification because they are broken (eg, due to bugs, hardware failures, configuration errors, or even malicious attacks). MAD systems add a new dimension: without a central administrator ensuring that each unbroken node follows the assigned protocol, a node may deviate because it is selfish and intent on maximizing its utility. Byzantine Fault Tolerance (BFT)[7] handles broken nodes well. However, the Byzantine model classifies all deviations as faults and requires a bound on the number of faults; this bound is untenable when all nodes may be broken or selfish. Conversely, game-theoretic models [11] handle selfish nodes well. However, these models are often vulnerable to arbitrary\u00a0\u2026", "num_citations": "28\n", "authors": ["532"]}
{"title": "Geo-replication: Fast if possible, consistent if necessary\n", "abstract": " Geo-replicated storage systems are at the core of current Internet services. Unfortunately, there exists a fundamental tension between consistency and performance for offering scalable geo-replication. Weakening consistency semantics leads to less coordination and consequently a good user experience, but it may introduce anomalies such as state divergence and invariant violation. In contrast, maintaining stronger consistency precludes anomalies but requires more coordination. This paper discusses two main contributions to address this tension. First, RedBlue Consistency enables blue operations to be fast (and weakly consistent) while the remaining red operations are strongly consistent (and slow). We identify sufficient conditions for determining when operations can be blue or must be red. Second, Explicit Consistency further increases the space of operations that can be fast by restricting the concurrent execution of only the operations that can break application-defined invariants. We further show how to allow operations to complete locally in the common case, by relying on a reservation system that moves coordination off the critical path of operation execution.", "num_citations": "21\n", "authors": ["532"]}
{"title": "Matrix signatures: From macs to digital signatures in distributed systems\n", "abstract": " We present a general implementation for providing the properties of digital signatures using MACs in a system consisting of any number of untrusted clients and n servers, up to f of which are Byzantine. At the heart of the implementation is a novel matrix signature that captures the collective knowledge of the servers about the authenticity of a message. Matrix signatures can be generated or verified by the servers in response to client requests and they can be transmitted and exchanged between clients independently of the servers. The implementation requires that no more than one third of the servers be faulty, which we show to be optimal. The implementation places no synchrony requirements on the communication and only require fair channels between clients and servers.", "num_citations": "21\n", "authors": ["532"]}
{"title": "Visigoth fault tolerance\n", "abstract": " We present a new technique for designing distributed protocols for building reliable stateful services called Visigoth Fault Tolerance (VFT). VFT introduces the Visigoth model, which makes it possible to calibrate the timing assumptions of a system using a threshold of slow processes or messages, and also to distinguish between non-malicious arbitrary faults and correlated attack scenarios. This enables solutions that leverage the characteristics of data center systems, namely their secure environment and predictable performance, in order to allow replicated systems to be more efficient with respect to the utilization of resources than those designed under asynchrony and Byzantine assumptions, while avoiding the need to make a system synchronous, or to restrict failure modes to silent crashes. We implemented a VFT protocol for a state machine replication library, and ran several benchmarks. Our evaluation\u00a0\u2026", "num_citations": "20\n", "authors": ["532"]}
{"title": "Limiting large-scale crawls of social networking sites\n", "abstract": " Online social networking sites (OSNs) like Facebook and Orkut contain personal data of millions of users. Many OSNs view this data as a valuable asset that is at the core of their business model. Both OSN users and OSNs have strong incentives to restrict large scale crawls of this data. OSN users want to protect their privacy and OSNs their business interest. Traditional defenses against crawlers involve rate-limiting browsing activity per user account. These defense schemes, however, are vulnerable to Sybil attacks, where a crawler creates a large number of fake user accounts. In this paper, we propose Genie, a system that can be deployed by OSN operators to defend against Sybil crawlers. Genie is based on a simple yet powerful insight: the social network itself can be leveraged to defend against Sybil crawlers. We first present Genie's design and then discuss how Genie can limit crawlers while allowing\u00a0\u2026", "num_citations": "19\n", "authors": ["532"]}
{"title": "Communities, random walks, and social sybil defense\n", "abstract": " Sybil attacks, in which an adversary forges a potentially unbounded number of identities, are a danger to distributed systems and online social networks. The goal of sybil defense is to accurately identify sybil identities.This article surveys the evolution of sybil defense protocols that leverage the structural properties of the social graph underlying a distributed system to identify sybil identities. We make two main contributions. First, we clarify the deep connection between sybil defense and the theory of random walks. This leads us to identify a community detection algorithm that, for the first time, offers provable guarantees in the context of sybil defense. Second, we advocate a new goal for sybil defense that addresses the more limited, but practically useful, goal of securely white-listing a local region of the graph.", "num_citations": "11\n", "authors": ["532"]}
{"title": "Regret freedom isn\u2019t free\n", "abstract": " Cooperative, peer-to-peer (P2P) services\u2014distributed systems consisting of participants from multiple administrative domains (MAD)\u2014must deal with the threat of arbitrary (Byzantine) failures while incentivizing the cooperation of potentially selfish (rational) nodes that such services rely on to function. This paper investigates how to specify conditions (i.e., a solution concept) for rational cooperation in an environment that also contains Byzantine and obedient peers. We find that regret-free approaches\u2014which, inspired by traditional Byzantine fault tolerance, condition rational cooperation on identifying a strategy that proves a best response regardless of how Byzantine failures occur\u2014are unattainable in many fault-tolerant distributed systems. We suggest an alternative regret-braving approach, in which rational nodes aim to best respond to their expectations regarding Byzantine failures: the chosen strategy\u00a0\u2026", "num_citations": "11\n", "authors": ["532"]}
{"title": "Model checking Nash equilibria in mad distributed systems\n", "abstract": " We present a symbolic model checking algorithm for verification of Nash equilibria in finite state mechanisms modeling multiple administrative domains (MAD) distributed systems. Given a finite state mechanism, a proposed protocol for each agent and an indifference threshold for rewards, our model checker returns PASS if the proposed protocol is a Nash equilibrium (up to the given indifference threshold) for the given mechanism, FAIL otherwise. We implemented our model checking algorithm inside the NuSMV model checker and present experimental results showing its effectiveness for moderate size mechanisms.", "num_citations": "9\n", "authors": ["532"]}
{"title": "UpRight Fault Tolerance\n", "abstract": " Experiences with computer systems indicate an inconvenient truth: computers fail and they fail in interesting ways.  Although using redundancy to protect against fail-stop failures is common practice, non-fail-stop computer and network failures occur for a variety of reasons including power outage, disk or memory corruption, NIC malfunction, user error, operating system and application bugs or misconfiguration, and many others. The impact of these failures can be dramatic, ranging from service unavailability to stranding airplane passengers on the runway to companies closing. While high-stakes embedded systems have embraced Byzantine fault tolerant techniques, general purpose computing continues to rely on techniques that are fundamentally crash tolerant.  In a general purpose environment, the current best practices response to non-fail-stop failures can charitably be described as pragmatic: identify a root cause and add checksums to prevent that error from happening again in the future. Pragmatic responses have proven effective for patching holes and protecting against faults once they have occurred; unfortunately the initial damage has already been done, and it is difficult to say if the patches made to address previous faults will protect against future failures. We posit that an end-to-end solution based on Byzantine fault tolerant (BFT) state machine replication is an efficient and deployable alternative to current ad hoc approaches favored in general purpose computing.  The replicated state machine approach ensures that multiple copies of the same deterministic application execute requests in the same order and provides end-to-end\u00a0\u2026", "num_citations": "8\n", "authors": ["532"]}
{"title": "Minimizing coordination in replicated systems\n", "abstract": " Replication has been widely adopted to build highly scalable services, but this goal is often compromised by the coordination required to ensure application-specific properties such as state convergence and invariant preservation. In this paper, we propose a principled mechanism to minimize coordination in replicated systems via the following components: a) a notion of restriction over pairs of operations, which captures the fact that the two operations must be ordered wrt each other in any partial order; b) a generic consistency model which, given a set of restrictions, requires those restrictions to be met in all admissible partial orders; c) principles for identifying a minimal set of restrictions to ensure the above properties; and d) a coordination service that dynamically maps restrictions to the most efficient coordination protocols. Our preliminary experience with example applications shows that we are able to determine\u00a0\u2026", "num_citations": "7\n", "authors": ["532"]}
{"title": "Model checking coalition nash equilibria in mad distributed systems\n", "abstract": " We present two OBDD based model checking algorithms for the verification of Nash equilibria in finite state mechanisms modeling Multiple Administrative Domains (MAD) distributed systems with possibly colluding agents (coalitions) and with possibly faulty or malicious nodes (Byzantine agents). Given a finite state mechanism, a proposed protocol for each agent and the maximum sizes                 f for Byzantine agents and q for agents collusions, our model checkers return Pass if the proposed protocol is an \u03b5-f-q-Nash equilibrium, i.e. no coalition of size up to q may have an interest greater than \u03b5 in deviating from the proposed protocol when up to f Byzantine agents are present, Fail otherwise. We implemented our model checking algorithms within the NuSMV model checker: the first one explicitly checks equilibria for each coalition, while the second represents symbolically all coalitions. We present\u00a0\u2026", "num_citations": "7\n", "authors": ["532"]}
{"title": "Making Byzantine Fault Tolerant Systems Tolerate Byzantine Faults\n", "abstract": " This paper argues for a new approach to building Byzantine fault tolerant systems. We observe that although recently developed BFT state machine replication protocols are quite fast, they don\u2019t actually tolerate Byzantine faults very well: a single faulty client or server is capable of rendering PBFT, Q/U, HQ, and Zyzzyva virtually unusable. In this paper, we (1) demonstrate that existing protocols are dangerously fragile,(2) define a set of principles for constructing BFT services that remain useful even when Byzantine faults occur, and (3) apply these new principles to construct a new protocol, Aardvark, which can achieve peak performance within 25% of that of the best existing protocol in our tests and which provides a significant fraction of that performance when the network is well behaved and up to f servers and any number of clients are faulty. We observe useful throughputs between 11706 and 38667 for a broad range of injected faults.", "num_citations": "4\n", "authors": ["532"]}
{"title": "The game of Paxos\n", "abstract": " We introduce the Game of Paxos to simplify the presentation of Paxos-style consensus protocols. We use this game to show how Lamport\u2019s Paxos and Castro and Liskov\u2019s PBFT are the same consensus protocol, but for different failure models. In this game, players try to store some value in a write-once register and quit only when they learn the register\u2019s final value. The write-once register contains two novel abstractions:(i) a Paxos register that captures how processes in both Paxos and PBFT propose and decide values and (ii) tokens that capture how these protocols guarantee agreement despite partial failures. We encapsulate the differences between Paxos and PBFT in the implementation details of these abstractions.", "num_citations": "4\n", "authors": ["532"]}
{"title": "Quality measures for phylogenetic networks\n", "abstract": " Phylogenies\u2014the evolutionary histories of groups of organisms\u2014are one of the most widely used tools throughout the life sciences, as well as objects of research within systematics, evolutionary biology, epidemiology, etc. Almost every tool devised to date to reconstruct phylogenies produces phylogenetic trees; yet it is widely understood and accepted that trees oversimplify the evolutionary histories of many groups of organisms, most prominently bacteria (because of lateral transfer of genes between different species) and plants (because of hybrid speciation). In order to develop a comparable toolkit of algorithms to reconstruct and analyze phylogenetic networks, we must start with measures of quality. In this paper, we address the quality issue in terms of topological accuracy (the preferred criterion, but one usually limited to simulation studies) and of parsimony scores (a surrogate criterion in widespread use\u00a0\u2026", "num_citations": "4\n", "authors": ["532"]}
{"title": "Seeing is believing: A unified model for consistency and isolation via states\n", "abstract": " This paper introduces a unified model of consistency and isolation that minimizes the gap between how these guarantees are defined and how they are perceived. Our approach is premised on a simple observation: applications view storage systems as black-boxes that transition through a series of states, a subset of which are observed by applications. For maximum clarity, isolation and consistency guarantees should be expressed as constraints on those states. Instead, these properties are currently expressed as constraints on operation histories that are not visible to the application. We show that adopting a state-based approach to expressing these guarantees brings forth several benefits. First, it makes it easier to focus on the anomalies that a given isolation or consistency level allows (and that applications must deal with), rather than those that it proscribes. Second, it unifies the often disparate theories of isolation and consistency and provides a structure for composing these guarantees. We leverage this modularity to apply to transactions (independently of the isolation level under which they execute) the equivalence between causal consistency and session guarantees that Chockler et al. had proved for single operations. Third, it brings clarity to the increasingly crowded field of proposed consistency and isolation properties by winnowing spurious distinctions: we find that the recently proposed parallel snapshot isolation introduced by Sovran et al. is in fact a specific implementation of an older guarantee, lazy consistency (or PL-2+), introduced by Adya et al.", "num_citations": "3\n", "authors": ["532"]}
{"title": "Department of Computer Science and Technology\n", "abstract": " Note: This was due to appear in the March 2001 special issue on programmable switches and routers. Due to extensive delays on the part of the editors it will now appear in a later issue.", "num_citations": "3\n", "authors": ["532"]}
{"title": "Depot: Cloud storage with minimal trust (extended version)\n", "abstract": " The paper describes the design, implementation, and evaluation of Depot, a cloud storage system that minimizes trust assumptions. Depot tolerates buggy or malicious behavior by any number of clients or servers, yet it provides safety and liveness guarantees to correct clients. Depot provides these guarantees using a two-layer architecture. First, Depot ensures that the updates observed by correct nodes are consistently ordered under Fork-Join-Causal consistency (FJC). FJC is a slight weakening of causal consistency that can be both safe and live despite faulty nodes. Second, Depot implements protocols that use this consistent ordering of updates to provide other desirable consistency, staleness, durability, and recovery properties. Our evaluation suggests that the costs of these guarantees are modest and that Depot can tolerate faults and maintain good availability, latency, overhead, and staleness even when significant faults occur.", "num_citations": "3\n", "authors": ["532"]}
{"title": "The magazine archive includes every article published in Communications of the ACM for over the past 50 years.\n", "abstract": " A longstanding vision in distributed systems is to build reliable systems from unreliable components. An enticing formulation of this vision is Byzantine fault-tolerant (BFT) state machine replication, in which a group of servers collectively act as a correct server even if some of the servers misbehave or malfunction in arbitrary (\" Byzantine\") ways. Despite this promise, practitioners hesitate to deploy BFT systems at least partly because of the perception that BFT must impose high overheads.In this article, we present Zyzzyva, a protocol that uses speculation to reduce the cost of BFT replication. In Zyzzyva, replicas reply to a client's request without first running an expensive three-phase commit protocol to agree on the order to process requests. Instead, they optimistically adopt the order proposed by a primary server, process the request, and reply immediately to the client. If the primary is faulty, replicas can become temporarily inconsistent with one another, but clients detect inconsistencies, help correct replicas converge on a single total ordering of requests, and only rely on responses that are consistent with this total order. This approach allows Zyzzyva to reduce replication overheads to near their theoretical minima and to achieve throughputs of tens of thousands of requests per second, making BFT replication practical for a broad range of demanding services.", "num_citations": "3\n", "authors": ["532"]}
{"title": "All about Eve: Execute-verify replication for multicore servers (extended version)\n", "abstract": " This paper presents Eve, a new Execute-Verify architecture that allows state machine replication to scale to multi-core servers. Eve departs from the traditional agree-execute architecture of state machine replication: replicas first execute groups of requests concurrently and then verify that they can reach agreement on a state and output produced by a correct replica; if they can not, they roll back and execute the requests sequentially. Eve minimizes divergence using application-specific criteria to organize requests into groups of requests that are unlikely to interfere. Our evaluation suggests that Eve\u2019s unique ability to combine execution independence with nondetermistic interleaving of requests enables highperformance replication for multi-core servers while tolerating a wide range of faults, including elusive concurrency bugs.", "num_citations": "2\n", "authors": ["532"]}
{"title": "Matrix signatures: From macs to digital signatures\n", "abstract": " We present the first general implementation to provide the properties of digital signature using MACs in a system consisting of any number of untrusted clients and n servers, up to f of which are Byzantine. At the heart of the implementation is a novel matrix signature that captures the collective knowledge of the servers about the authenticity of a message. Matrix signatures can be generated or verified by the servers in response to client requests and they can be transmitted and exchanged between clients independently of the servers. The implementation requires that no more than one third of the servers be faulty, which we show to be optimal. The implementation places no synchrony requirements on the communication and only require fair channels between clients and servers.", "num_citations": "2\n", "authors": ["532"]}
{"title": "Probably Right, Probably on Time: An Analysis of CAN in the Presence of Host and Network Faults [C]\n", "abstract": " Safety-critical real-time systems that operate in electromagnetically noisy environments must be designed to withstand electromagnetic interference. Typically, networked systems handle this issue by retransmitting corrupted messages and by replicating critical processes on independent hosts. However, there exists a fundamental tradeoff between the two techniques: to increase a system\u2019s resiliency to message retransmissions without violating any deadlines, a low bus load is favorable; whereas adding replicas requires more messages to be sent, which in turn increases the bus load. This paper presents our ongoing work on a probabilistic analysis that quantifies this tradeoff in CAN-based systems, which enables system designers to select an optimal number of replicas that maximizes the probability of a correct and timely operation of a distributed real-time system. I. IntroductionAutomotive embedded systems are surrounded by spark plugs and electric motors. Industrial embedded systems may be deployed in close vicinity to high-power machinery. Robots may need to operate in environments exposed to hard radiation. All of the above are examples of safety-critical real-time systems that are susceptible to electromagnetic interference (EMI) and must be designed to withstand its effects; including hangs, crashes, or incorrect outputs (node faults), and, in networked systems, also corrupted messages (transmission faults)[1, 4]. Presently, networked systems tolerate transmission faults by retransmitting corrupted messages (eg, CAN controllers automatically retransmit a message if any host connected to the bus reports a transmission fault). Node\u00a0\u2026", "num_citations": "1\n", "authors": ["532"]}
{"title": "Tardis: Transactional storage with parallel worlds\n", "abstract": " Geo-replication is an increasingly common requirement for computing services which desire low latency and high availability across the globe. In these services, replicas serve requests locally and independently. The lack of synchronisation across sites guarantees good performance but often comes at the cost of consistency; many recent research efforts, as a result, exhibit a race to redefine consistency and expressiveness in search of systems that are scalable and available. Most of these systems allow for independent, possibly conflicting, executions across geographically distinct sites, but all stop short of allowing locally conflicting operations: the local storage is viewed as a sequential black box. Using these systems then presents two main drawback. First, each replica, upon detecting write-write conflicts, greedily merges conflicting operations so as to never expose multiple values of an object and preserve the\u00a0\u2026", "num_citations": "1\n", "authors": ["532"]}
{"title": "Distributed computing in sosp and osdi\n", "abstract": " SOSP, the ACM Symposium on Operating Systems Principles, and OSDI, the USENIX Symposium no Operating System Design and Implementation, are \"the world's premier forum for researches, developers, programmers, vendors, and teachers of operating systems technology\" according to the SOSP home page. While it may seem odd to discuss operating systems conferences in a column dedicated to distributed computing, the proceedings of the last few SOSP and OSDI's have included numerous papers focused on topics more traditionally associated with distributed computing---primarily transactions, Byzantine fault tolerance, and large distributed systems. In this article we highlight papers from the last 3 years of SOSP and OSDI that are especially relevant to the distributed computing community, identifying areas where the distributed computing community was clearly ahead of its time and others where it was\u00a0\u2026", "num_citations": "1\n", "authors": ["532"]}
{"title": "Position paper: BFT: The time is now\n", "abstract": " Data centers strive to provide reliable access to the data and services that they host. This reliable access requires the hosted data and services hosted by the data center to be both consistent and available. Byzantine fault tolerance (BFT) replication offers the promise of services that are consistent and available despite arbitrary failures by a bounded number of servers and an unbounded number of clients. The thesis of this position paper is simple: BFT is on the verge of becoming a practical reality\u2014but clearing the last hurdles will require to rethink, once again, how BFT systems must be designed and implemented. Three fundamental trends support our thesis that widespread adoption of Byzantine fault tolerance is at hand.First, falling hardware costs and the increased value and importance of services are making significant non-BFT replication a standard commercial practice [5, 12, 13]. Although fault tolerance has long been an after-thought for non-critical applications, it is becoming increasingly worthwhile to use hardware generously to defend against component failures and geographic catastrophes [20]. For example, the Google file system (GFS) relies on three-way replication as a way to protect data from crash failures [13]. Second, in systems where both reliability and availability are important properties, crash tolerance is not enough. Byzantine faults are a frequent occurrence in the wild, manifesting themselves as disks that do not operate in a fail-stop manner [4], file systems that implement inadequate actions to recover from disk faults [22], file systems with bugs in their crash recovery code [25, 26], human errors [14, 21], or processors\u00a0\u2026", "num_citations": "1\n", "authors": ["532"]}
{"title": "Information Theoretically Secure Byzantine Paxos\n", "abstract": " We present Information Theoretically secure Byzantine Paxos (IT ByzPaxos), the first deterministic asynchronous Byzantine consensus protocol that is provably secure despite a computationally unbounded adversary. Previous deterministic asynchronous algorithms for Byzantine consensus rely on unproven number theoretic assumptions (ie, digital signatures) to maintain agreement. IT ByzPaxos instead uses secret sharing techniques that are information theoretically secure to ensure that all correct processes agree. Our protocol guarantees safety in an asynchronous system and provides progress under eventual synchrony. IT ByzPaxos matches the 3f+ 1 lower bound on the number of processes for Byzantine consensus.", "num_citations": "1\n", "authors": ["532"]}