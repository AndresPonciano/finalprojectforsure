{"title": "Software defect prediction analysis using machine learning algorithms\n", "abstract": " Software Quality is the most important aspect of a software. Software Defect Prediction can directly affect quality and has achieved significant popularity in last few years. Defective software modules have a massive impact over software's quality leading to cost overruns, delayed timelines and much higher maintenance costs. In this paper we have analyzed the most popular and widely used Machine Learning algorithms - ANN (Artificial Neural Network), PSO(P article Swarm Optimization), DT (Decision Trees), NB(Naive Bayes) and LC (Linear classifier). The five algorithms were analyzed using KEEL tool and validated using k-fold cross validation technique. Datasets used in this research were obtained from open source NASA Promise dataset repository. Seven datasets were selected for defect prediction analysis. Classification was performed on these 7 datasets and validated using 10 fold cross validation. The\u00a0\u2026", "num_citations": "44\n", "authors": ["101"]}
{"title": "Software defect prediction using supervised learning algorithm and unsupervised learning algorithm\n", "abstract": " Software defect prediction has recently attracted attention of many software quality researchers. One of the major areas in current project management software is to effectively utilize resources to make meaningful impact on time and cost. A pragmatic assessment of metrics is essential in order to comprehend the quality of software and to ensure corrective measures. Software defect prediction methods are majorly used to study the impact areas in software using different techniques which comprises of neural network (NN) techniques, clustering techniques, statistical method and machine learning methods. These techniques of Data mining are applied in building software defect prediction models which improve the software quality. The aim of this paper is to propose various classification and clustering methods with an objective to predict software defect. To predict software defect we analyzed classification and\u00a0\u2026", "num_citations": "33\n", "authors": ["101"]}
{"title": "Prediction Models for Identification and Diagnosis of Tomato Plant Diseases\n", "abstract": " Through the ages, pests and plant diseases have remained a constant threat to the quality and quantity of overall crop production. Hence, their timely and accurate identification could greatly extenuate the economic losses worldwide, also denigrating the harmful impact of fertilizers and pesticides on the environment. Once the correct disease is identified, conforming to the characteristic symptoms, proper control measures can be applied. The concept of Precision Agriculture necessitates the timely automation of dominant and crucial agricultural processes by applying the techniques of computational intelligence in the agriculture domain, Machine Learning and Computer Vision being the most researched and implemented technologies. This paper presents a survey on the current techniques and prediction models, based on Image processing and the role of Internet of Things (IoT), being applied for identification\u00a0\u2026", "num_citations": "22\n", "authors": ["101"]}
{"title": "Agile methodologies in software maintenance: A systematic review\n", "abstract": " Agile Methodologies has been gaining popularity since 2000. The Software Maintenance phase of software lifecycle is the most expensive and tedious in nature and use of Agile methodologies helps in maintaining software over time in flexible and iterative manner. This study reviews several papers with different case studies to evaluate the performance and quality of software using agile methodologies. In this study, more than 30 research studies are investigated which are conducted between 2001 and 2015 and have been categorized according to the publication year, datasets, tools, type of techniques etc. This will be the first review paper on the use of the Agile in software maintenance which will help the researchers and encourages companies and beginners to adopt these methodologies to gain software quality. This study would also be helpful to professional academicians to identify the current trends and future gaps in the field of agile methodologies.", "num_citations": "22\n", "authors": ["101"]}
{"title": "Sequencing of refactoring techniques by Greedy algorithm for maximizing maintainability\n", "abstract": " Software maintainability is the ease with which a software system can be modified to correct faults, improve performance or other attributes of the source code. Bad smells are symptoms of deeper problem that indicates the need for refactoring which is the process of changing internal structure of the software without affecting its external attributes. Applying different refactoring techniques in different parts of a code results in changed maintainability value every time. Therefore, sequence in which refactoring should be applied is important so that optimal results can be obtained. In this study, we have proposed an approach for evaluating sequence of refactoring by with the help of greedy algorithm. The algorithm selects locally optimal solution at each stage with the hope of finding global optimal solution. Different sequences are generated and applied to the source code to calculate sum of software maintainability\u00a0\u2026", "num_citations": "18\n", "authors": ["101"]}
{"title": "Recent advancements in multimedia big data computing for IoT applications in precision agriculture: opportunities, issues, and challenges\n", "abstract": " This chapter aims to present a survey on the existing techniques and architectures of Multimedia Big Data (MMBD) computing for Internet of Things (IoT) applications in Precision Agriculture, along with the opportunities, issues, and challenges it poses in the context. As a consequence of the digital revolution and ease of availability of electronic devices, a massive amount of data is being acquired from a variety of sources. On one hand, this overwhelming quantity of multimedia data poses several challenges, from its storage to transmission, and on the other, it presents an opportunity to provide an insight into the business trends, intelligence and render rich decision support. One of the key applications of MMBD Computing is Precision Agriculture. The chapter focuses on major agricultural applications, cyber-physical systems for smart farming, multimedia data collection approaches, and various IoT sensors\u00a0\u2026", "num_citations": "17\n", "authors": ["101"]}
{"title": "Deep learning-based mobile application for plant disease diagnosis: A proof of concept with a case study on tomato plant\n", "abstract": " With the increasing computational power, areas such as machine learning, image processing, deep learning, etc. have been extensively applied in agriculture. This chapter investigates the applications of the said areas and various prediction models in plant pathology for accurate classification, identification, and quantification of plant diseases. The authors aim to automate the plant disease identification process. To accomplish this objective, CNN has been utilized for image classification. Research shows that deep learning architectures outperform other machine learning tools significantly. To this effect, the authors have implemented and trained five CNN models, namely Inception ResNet v2, VGG16, VGG19, ResNet50, and Xception, on PlantVillage dataset for tomato leaf images. The authors analyzed 18,160 tomato leaf images spread across 10 class labels. After comparing their performance measures\u00a0\u2026", "num_citations": "17\n", "authors": ["101"]}
{"title": "Dynamic metrics are superior than static metrics in maintainability prediction: An empirical case study\n", "abstract": " Software metrics help us to make meaningful estimates for software products and guide us in taking managerial and technical decisions like budget planning, cost estimation, quality assurance testing, software debugging, software performance optimization, and optimal personnel task assignments. Many design metrics have proposed in literature to measure various constructs of Object Oriented (OO) paradigm such as class, coupling, cohesion, inheritance, information hiding and polymorphism and use them further in determining the various aspects of software quality. However, the use of conventional static metrics have found to be inadequate for modern OO software due to the presence of run time polymorphism, templates class, template methods, dynamic binding and some code left unexecuted due to specific input conditions. This gap gave a cue to focus on the use of dynamic metrics instead of traditional\u00a0\u2026", "num_citations": "17\n", "authors": ["101"]}
{"title": "An empirical investigation of evolutionary algorithm for software maintainability prediction\n", "abstract": " Software maintenance is one of the tedious as well as costly phases in the software development life cycle. It starts immediately after the software product is delivered to the customer and ends when the product is no longer in use. There are various activities carried out during software maintenance phase such as the addition of new features, deletion of obsolete features, correction of errors, adaption to new environment etc. Software maintainability is the quality attribute of the software product which determines the ease with which these modifications can be performed. If we can predict the maintainability accurately, cost and time associated with the maintenance activity can be highly reduced. The main aim of this study is to propose the use of evolutionary technique particularly genetic algorithm for the software maintainability prediction and compare its performance with various machine leaning techniques such\u00a0\u2026", "num_citations": "16\n", "authors": ["101"]}
{"title": "Application of convolutional neural networks for evaluation of disease severity in tomato plant\n", "abstract": " For food security in future, precise measurements of disease incidence and severity are crucial for suitable treatments and adopting preventive measures. In this paper, the authors have implemented three well known CNN models, namely, AlexNet, SqueezeNet and Inception V3, for evaluating disease severity in Tomato Late Blight disease. The images utilized were selected from the PlantVillage dataset and separated into three stages (early, middle and end) of disease severity. The CNN architectures were implemented in two different modes, i.e. transfer learning and feature extraction (where the extracted feature set was used to train a multiclass SVM). As compared to the other two networks, AlexNet achieved the highest accuracy in both approaches, 89.69% and 93.4% respectively.", "num_citations": "15\n", "authors": ["101"]}
{"title": "Exploring capsule networks for disease classification in plants\n", "abstract": " The overarching goal of smart farming is to develop innovative solutions for future sustainability of humankind. Crop protection from biological/non-biological factors is a major hindrance for food security, plant diseases being one of the foremost challenges. Not only, plant diseases destroy the crops or diminish their overall quality, use of pesticides for their treatment renders the soil contaminated, which after a time becomes unsuitable for sowing and planting. Potato is a key crop and a major source of livelihood for a vast population. In this study, the authors have implemented capsule networks for classification of potato diseases, and compared the performance with few popular pretrained CNN models, namely ResNet18, VGG16 and GoogLeNet, implemented via transfer learning. Colored images of healthy as well as diseased leaf images were employed from the PlantVillage dataset and used for training the\u00a0\u2026", "num_citations": "13\n", "authors": ["101"]}
{"title": "Prioritization of code restructuring for severely affected classes under release time constraints\n", "abstract": " Bad smells help us to look deeper into the problem as they are threat to design principles and quality of software. Redesigning helps us in restructuring code without any change in its external behavior. It is not feasible to restructure each class of the software due release time constraints. Therefore, there is a need to prioritize classes so that effort and quality can be improved. In this study, we have proposed a framework based on the combination of C & K metric suite and eleven types of bad smells. A new metric, Quality Decline Factor (QDF), has been proposed which identify the severity of the classes and helps the software maintenance team to focus only on severely affected code. Pareto analysis is also valid in this study which states that 80% of the code quality can be improved by providing redesigning treatments to 20% of the severely affected code. This study will reduce the work of software maintenance\u00a0\u2026", "num_citations": "12\n", "authors": ["101"]}
{"title": "Application of extreme learning machine in plant disease prediction for highly imbalanced dataset\n", "abstract": " Plant diseases are responsible for global economic losses due to degradation in the quality and productivity of plants. Therefore, plant disease prediction has become an essential area of research for agricultural scientists. The current study implements Extreme Learning Machine (ELM) algorithm for plant disease prediction based on a dataset collected in real time scenario namely Tomato Powdery Mildew Disease (TPMD) dataset. Since, the collected TPMD dataset was imbalanced thus; various resampling techniques namely Importance Sampling (IMPS), Synthetic Minority Over-sampling Technique (SMOTE), Random under Sampling (RUS), and Random over Sampling (ROS) have been used here for balancing the dataset before using it in the specified prediction model. ELM models have been developed for each of the balanced TPMD datasets obtained from these resampling techniques as well as for the\u00a0\u2026", "num_citations": "11\n", "authors": ["101"]}
{"title": "Hybrid SVM-LR Classifier for Powdery Mildew Disease Prediction in Tomato Plant\n", "abstract": " Tomato plant suffers from various severe diseases; powdery mildew being one of them. Weather conditions play a significant role in the development of powdery mildew disease in tomato plant which in turn reduces the growth of tomato fruit. Hence, an accurate and timely detection of powdery mildew is necessary to extenuate the economic losses caused by the disease. This paper aims to develop a hybrid of Support Vector Machine (SVM) and Logistic Regression (LR) algorithm to predict powdery mildew disease in tomato plant. SVM is used to minimize the noise in data before the data is fed to LR classifier. Noise reduction is done using SVM classifier with the help of Adaptive Sampling based Noise Reduction (ANR) method. A real life Tomato Powdery Mildew Disease (TPMD) dataset has been used in this study to develop a prediction model using the proposed method. SVM and LR algorithms have also been\u00a0\u2026", "num_citations": "11\n", "authors": ["101"]}
{"title": "Software maintainability prediction using an enhanced random forest algorithm\n", "abstract": " Now-a-days, software maintainability has become one of the significant quality-assessing attributes for any software system. Current study presents an enhanced-RFA (Random Forest Algorithm) approach for Software Maintainability Prediction. The proposed approach combines Random Forest (RF) algorithm with three prevalent feature selection techniques namely Chi-Squared, RF and Linear Correlation Filter along with a re-sampling technique intended to improve the prediction accuracy of basic RF algorithm. Enhanced- RFA is applied on two commercially available datasets, QUES and UIMS and performance is evaluated on the basis of R2. Results indicate that the proposed approach performs significantly better than RFA for both the datasets with an improvement in R2 values equal to 69.50%, 65.57% & 69.40% for QUES and 31.90%, 44.94% & 51.81% for UIMS using chisquared, RF and linear\u00a0\u2026", "num_citations": "10\n", "authors": ["101"]}
{"title": "Assessing Cross-Project Technique for Software Maintainability Prediction\n", "abstract": " Software Maintainability refers to the ease with which software maintenance activities like correction of faults, deletion of obsolete code, addition of new code etc. can be carried out to adapt to the modified environment. Predicting maintainability in early stages of development helps in reducing the cost of maintenance and ensures optimum utilization of resources. Sometimes, it becomes difficult to train prediction models using historical data of the same dataset for which the model is being developed because of the unavailability of sufficient amount of training data, in turn making a way for Cross-Project technique for Software Maintainability Prediction (CPSMP). In order to evaluate the proposed CPSMP technique, QUES dataset is used as training set and UIMS dataset is used as test set in this study with 19 different regression modelling methods. Performance of CPSMP model is evaluated using Root Mean Square\u00a0\u2026", "num_citations": "7\n", "authors": ["101"]}
{"title": "A systematic literature survey of software metrics, code smells and refactoring techniques\n", "abstract": " Software refactoring is a process to restructure an existing software code while keeping its external behavior the same. Currently, various refactoring techniques are being used to develop more readable and less complex codes by improving the non-functional attributes of software. Refactoring can further improve code maintainability by applying various techniques to the source code, which in turn preserves the behavior of code. Refactoring facilitates bug removal and extends the capabilities of the program. In this paper, an exhaustive review is conducted regarding bad smells present in source code, applications of specific refactoring methods to remove that bad smell and its effect on software quality. A total of 68 studies belonging to 32 journals, 31 conferences, and 5 other sources that were published between the years 2001 and 2019 were shortlisted. The studies were analyzed based on of bad smells identified, refactoring techniques used, and their effects on software metrics. We found that\" long method\",\" feature envy\", and\" data class\" bad smells were identified or corrected in the majority of studies.\" Feature envy\" smell was detected in 36.66% of the total shortlisted studies. Extract class refactoring approach was used in 38.77% of the total studies, followed by the move method and extract method techniques that were used in 34.69% and 30.61% of the total studies, respectively. The effects of refactoring on complexity and coupling metrics of software were also analyzed in the majority of studies, ie, 29 studies each. Interestingly, the majority of selected studies (41%) used large open source datasets written in Java language instead of\u00a0\u2026", "num_citations": "6\n", "authors": ["101"]}
{"title": "Predicting maintainability of open source software using Gene Expression Programming and bad smells\n", "abstract": " Software maintenance phase of Software Development Lifecycle (SDLC) is the most expensive and complex phase that requires nearly 60-70% of the total project cost. Due to this, many software fails to get repair within real time constraint. Ascribe to technology advancements and changing requirements, software must be well developed and maintained to get adapted. Hence, it is necessary to predict software maintainability in the early phases of the lifecycle so that optimization of resources can be possible and cost can be reduced. Software Maintainability is the quality attribute of software product that explains the ease with which modifications can be performed. The main focus in this study is to propose the use of Gene Expression Programming (GEP) for the software maintainability prediction and measure its performance with various machine leaning techniques such as Decision Tree Forest, Support Vector\u00a0\u2026", "num_citations": "6\n", "authors": ["101"]}
{"title": "Implementation of CNNs for Crop Diseases Classification: A Comparison of Pre-trained Model and Training from Scratch\n", "abstract": " In recent times, the machine learning field has become very progressive and has given impressive results, through the development of advanced Convolutional Neural Networks (CNN). These models simulate the biological behavior of the human-beings, especially, in dealing with the image recognition tasks. To train a deep CNN from scratch, a massive amount of labeled training samples are required that make the training process difficult. Also, the results have not converged properly and become overfitted in nature. Data augmentation is applied to overcome this issue of overfitting. An optimistic substitution is to use the pre-trained networks, prepared previously over a large dataset such as ImageNet. This kind of CNNs can also be deployed using their two alternative approaches, namely, feature extraction and fine-tuning of the pre-trained model. In this paper, 1296 leaf images of bean crops were used to perform the experiment that classifies the diseased or healthy leaf. In order to show the variation in the performance of the CNNs, the network has trained from scratch as well as using pre-trained networks. Experimental results showed that training from scratch performs worst (70% accuracy) over small training data and pre-trained networks (97.06%) gave far better results compared to the previous one. It is observed that the use of pre-trained networks with the tuning of hyperparameters is an optimal choice for training, for small training data set.", "num_citations": "5\n", "authors": ["101"]}
{"title": "Empirical evaluation of Map Reduce based hybrid approach for problem of imbalanced classification in big data\n", "abstract": " Imbalanced datasets are the ones with uneven distribution of classes that deteriorates classifier's performance. In this paper, SVM classifier is combined with K-Means clustering approach and a hybrid approach, Hy_SVM_KM is introduced. The performance of proposed method is also empirically evaluated using Accuracy and FN Rate measure and compared with existing methods like SMOTE. The results have shown that the proposed hybrid technique has outperformed traditional machine learning classifier SVM in mostly datasets and have performed better than known pre-processing technique SMOTE for all datasets. The goal of this article is to extend capabilities of popular machine learning algorithms and adapt it to meet the challenges of imbalanced big data classification. This article can provide a baseline study for future research on imbalanced big datasets classification and provides an efficient\u00a0\u2026", "num_citations": "5\n", "authors": ["101"]}
{"title": "Recent advancements in image-based prediction models for diagnosis of plant diseases\n", "abstract": " India plays a significant role in the world as a major contributor to the overall food industry. Farming being a major occupation, crop protection from plant diseases has become a serious concern. The occurrence of plant diseases is hugely dependent on environmental factors which are uncontrollable. Ongoing agricultural research and the advanced computational technologies can be coalesced to determine an effective solution, which can improve the yield and result in better harvests. The objective is to minimize the economic and production losses. Researchers have developed several modeling techniques, viz. Artificial Neural Networks (ANN), Support Vector Machines (SVM), and Deep Learning for prediction and preferably early detection of diseases in plants. Mostly, images of the diseased plant are given as input to these prediction models. Early detection leads to minimizing the pesticide usage\u00a0\u2026", "num_citations": "4\n", "authors": ["101"]}
{"title": "Benchmarking framework for class imbalance problem using novel sampling approach for big data\n", "abstract": " The traditional techniques of machine learning always need to be strengthened for dealing with cosmic nature of big data for systematic and methodical learning. The unbalanced distribution of classes in big data, popularly known as imbalanced big data chases the problem of learning to a much higher level. The conventional methods are being progressively modified to handle and curtail the problem of learning from imbalanced datasets in the context of big data at the data level and algorithmic level. In the current study, a cluster heads based data level sampling solution which inherits edge of K-Means and Fuzzy C-Means clustering approaches is applied. The proposed approach is evaluated with three different classifiers namely Support Vector Machines, Decision Tree and k-Nearest Neighbor and compared with conventional SMOTE algorithm. The experiment has shown promising results with an\u00a0\u2026", "num_citations": "4\n", "authors": ["101"]}
{"title": "A quality enhancement through defect reduction using refactoring operation\n", "abstract": " Refactoring is widely used technique to enhance overall quality of an existing software system by changing its internal structure without modifying its external behavior. Although, it is difficult to implement the refactoring manually, it helps to reduce the defects in the existing software. Three main types of design defects are investigated in the current study namely blob, Spaghetti Code (SC) and Functional Decomposition (FD) by applying specific rule which are based on the combination of Object-Oriented (OO) metrics and their threshold values. Further, study also suggests a novel approach to minimize the defects and improve the quality of software system by applying specific refactoring operations into the code. Five large open source projects JDATEPICKER, JXLS, JTDS, JFREECHART and JHOTDRAW were used for the empirical evaluation of the suggested approach. Results show that the refactoring is very\u00a0\u2026", "num_citations": "4\n", "authors": ["101"]}
{"title": "Determination of optimum refactoring sequence using A\u2217 algorithm after prioritization of classes\n", "abstract": " Bad smells are the surface indication of deeper problem into source code; therefore, they need to be identified as early as possible without compromising on the quality of the software. This lead towards the requirement of refactoring that is the process used in improving the internal attributes like maintainability of the software without affecting its external attributes. Hence, to enhance quality in terms of maintainability refactoring should be done in a controlled and iterative manner. In this study, we have proposed a method that will help researchers and developers to generate a refactoring sequence in advance with the help of heuristic search A* algorithm. We have chosen one class of an open source project with the help of prioritization technique to illustrate the generation of the sequence. A* algorithm helps in finding an appropriate sequence which has maximum value of maintainability by choosing a path of\u00a0\u2026", "num_citations": "4\n", "authors": ["101"]}
{"title": "Assessment of optimum refactoring sequence to improve the software quality of object-oriented software\n", "abstract": " Software Maintenance is the most expensive phase of Software Development Lifecycle (SDLC) and therefore requires maximum effort and time. Any modification in the source code also introduces some bad smell which may be harmful for the design of the source code. These bad smells get accumulated with every phase of the SDLC if not corrected timely, therefore, they need to be removed as early as possible with the help of refactoring which improves the internal attributes of the software without affecting the external attributes. In order to complete the software under time and budget constraints, authors have attempted to determine the optimum sequence of refactoring technique (RT) in advance so that maintenance team can directly apply them in order to remove the bad smell which further enhances the quality of the software. Authors have applied different types of Hill- Climbing algorithms. Results shows that\u00a0\u2026", "num_citations": "3\n", "authors": ["101"]}
{"title": "PLANT DISEASE DETECTION FOR HIGH DIMENSIONAL IMBALANCED DATASET USING AN ENHANCED DECISION TREE APPROACH\n", "abstract": " The purpose of the research is to find a robust and efficient model for plant disease detection. Therefore, the current study proposes an enhanced-DTC (Decision Tree Classifier) approach for high dimensional imbalanced dataset in plant disease diagnosis. In this approach, instead of just using traditional decision tree algorithm, its capabilities are enhanced with Random Over (RO) sampling method for class balancing and three well-known feature selection techniques, ie, Consistency (Cons), Correlation-based Feature Selection (CFS), and Random Forest Importance (RFI) filter for dimensionality reduction. The proposed methodology aims to enhance the performance of the five most commonly used decision tree algorithms, namely, C4. 5, Classification and Regression Tree (CART), Bagging CART (Bag-CART), Partial Decision Tree (PART-DT), and Boosted C5. 0 (B-C5. 0). Results specify that the enhanced-DTC approach performs superior to the existing decision tree algorithms for the multiclass Soybean Large (SBL) dataset. It has been observed that the enhanced-DTC approach with both RFI and C4. 5 method performed the best with an Accuracy (ACC) of 98.10% and Area Under Curve (AUC) of 97.79%. A real-time application of the proposed model can be used by the agricultural experts to take preventive measures in the most sensitive areas that are prone to a particular disease. Hence, timely intervention would help in reducing the loss in productivity of plants which will further benefit the global economy, agricultural production, and the food industry.", "num_citations": "3\n", "authors": ["101"]}
{"title": "Statistical analysis of machine learning techniques for predicting powdery mildew disease in tomato plants\n", "abstract": " Powdery mildew is a dangerous disease that reduces the quality and the yield of tomato fruit rapidly. Its early prediction is a prior requirement for obtaining good quality fruit. Therefore, in this study, the best classifier amongst various classifiers has been discovered using different machine learning algorithms. This classifier can precisely classify whether the meteorological conditions of a particular day are conducive to the development of powdery mildew disease or not. Tomato powdery mildew disease dataset has been tested using various performance measures and the results computed for all the classifiers are promising. Friedman test has been used to rank multiple classifiers and post hoc analysis has also been done using the Nemenyi test. It has been observed in comparison that 62.05% of the total pairs of classifiers perform significantly different from each other, and medium Gaussian support vector\u00a0\u2026", "num_citations": "2\n", "authors": ["101"]}
{"title": "Software maintainability prediction of open source datasets using least squares support vector machines\n", "abstract": " Software Maintainability (SM), being one of the priciest and tedious phases of any software development life cycle, has drawn the attention of various researchers over the years. SM measures the ease of carrying out maintenance activities such as repair and improvement of software code as per the changing needs of the customer and should be predicted well in advance. The current study implements the Least Squares Support Vector Machines (LS-SVM) algorithm for SM Prediction (SMP) on six open source datasets, namely Abdera, Ivy, jEdit, Log4j, Poi, and Rave. MAE, RMSE, and MMRE are considered as the prediction accuracy measures to evaluate the performance. Results indicate that LS-SVM is a potentially viable tool for predicting maintainability. Best results are obtained with jEdit dataset having minimum values for MAE, RMSE, and MMRE, i.e. 20.38, 46.97, and 1.02, respectively; jEdit having high\u00a0\u2026", "num_citations": "2\n", "authors": ["101"]}
{"title": "Investigating optimum refactoring sequence using hill-climbing algorithm\n", "abstract": " The surface indication of a deeper problem in the source code is bad smells that required to be removed as soon as possible. Not all smells are harmful, but if ignored, they automatically become faults which will further deteriorate the quality of the software. Therefore, this damage can be prevented with the help of refactoring that changes the internal attributes without affecting its external behavior. Every class of the source code contains numerous types of bad smells; therefore, more than one refactoring technique needs to be applied to clean the code. In this paper, we have tried to figure out the most optimum refactoring sequence that should be applied in a critically affected class of an open-source software (OSS), jTDS, to maximize its maintainability value with minimal effort. The results indicate improvement in maintainability value by 14.06% after the application of refactoring techniques. This study would be\u00a0\u2026", "num_citations": "2\n", "authors": ["101"]}
{"title": "Impact of Hyperparameter Tuning on Deep Learning Based Estimation of Disease Severity in Grape Plant\n", "abstract": " Accurate and quantitative estimation of disease severity in plants is a complex task, even for experienced agronomists and plant pathologists, where incorrect evaluation might lead to the inappropriate use of pesticides. In this paper, the authors have utilized two Convolutional Neural Networks (CNN), namely, AlexNet and ResNet18, for assessing the disease severity in Grape plant. The images for Isariopsis Leaf Spot disease in Grape plant, also known as Leaf Blight, were taken from the PlantVillage dataset, divided into three categories of severity stages (early, middle & end) and used for training the CNN models, via the transfer learning approach. The effects of fine-tuning the hyperparameters such as mini-batch size, epochs and data augmentation were also observed and analysed. For performance comparison, measures such as classification accuracy, mean F1-score, mean precision, mean recall, validation\u00a0\u2026", "num_citations": "2\n", "authors": ["101"]}
{"title": "Application of Evolutionary Particle Swarm Optimization Algorithm in Test Suite Prioritization\n", "abstract": " Regression testing is a software verification activity carried out when the software is modified during maintenance phase. To ensure the correctness of the updated software it is suggested to execute the entire test suite again but this would demand large amount of resources. Hence, there is a need to prioritize and execute the test cases in such a way that changed software is tested with maximum coverage of code in minimum time. In this work, Particle Swarm Optimization (PSO) algorithm is used to prioritize test cases based on three benchmark functions Sphere, Rastrigin and Griewank. The result suggests that the test suites are prioritized in least time when Griewank is used as benchmark function to calculate the fitness. This approach approximately saves 80% of the testing efforts in terms of time and manpower since only 1/5 of the prioritized test cases from the entire test suite need to be executed.", "num_citations": "2\n", "authors": ["101"]}
{"title": "Evaluation of instance-based feature subset selection algorithm for maintainability prediction\n", "abstract": " An essential attribute of the software quality is maintainability which incurs almost 60-70% of total project cost. Since software maintainability prediction is a complicated process; estimating maintainability in the prior phases of software development lifecycle (SDLC) is advantageous. Further, it helps in building economical software and improving resource planning well in advance. Software metrics are strongly correlated with software maintainability as they help in examining the structural quality and characteristics of a software. Feature subset selection (FSS) is an important data preprocessing technique used in data mining. It involves determining a subset of notable features for building a prediction model. All software metrics are not equally relevant; hence, using all of them for predicting maintainability will significantly increase time, budget and effort. Thus, to achieve best maintainability prediction results with a\u00a0\u2026", "num_citations": "2\n", "authors": ["101"]}
{"title": "Prediction of Software Maintainability using Neural Networks\n", "abstract": " Software maintenance is an important aspect of software quality as it is the most expensive activity in the development lifecycle of a software. Hence, in the recent past many researchers have shown an increasing interest in predicting the most accurate model for maintainability of a software. In this paper, the three models have been proposed which are quantitatively compared to each other. The proposed models are Group Method of Data Handling (GMDH), General Regression Neural Network (GRNN) and Probabilistic Neural Network (PNN). In this study, an open source software with two versions was used in order to calculate the CHANGE which is defined as the number of lines of code which are modified, added or deleted from version 1 to version 2 of the software. Based on this study, it was concluded that General Regression Neural Network (GRNN) is the best neural model for prediction of software maintainability. Hence, it can be used an alternative to the other existing models by the companies to maintain their software as it predicts software maintainability more accurately than other alternative neural networks.", "num_citations": "2\n", "authors": ["101"]}
{"title": "A modified label propagation algorithm for community detection in attributed networks\n", "abstract": " Community detection is an important problem in network science that discovers highly clustered groups of nodes having similar properties. Label propagation algorithm (LPA) is one of the popular clustering techniques that has attracted much attention due to its efficiency and non-dependence on parameters. Despite its advantages, an important limitation of LPA is the randomness in grouping nodes that leads to instability and the formation of large communities. In this study, we propose four variants based on LPA to overcome the random community allocation problem, henceforth generating better clusters. These variants utilize link strength and node attribute information to enhance the quality of detected communities. Furthermore, the proposed variants require no parameter for categorical attributes and only one parameter (constant for all the networks) for continuous attributes. Finally, the best results are obtained\u00a0\u2026", "num_citations": "1\n", "authors": ["101"]}
{"title": "Application of AO* Algorithm in Recognizing the Optimum Refactoring sequence for examining the effect on Maintainability: An Empirical Study\n", "abstract": " Bad smells are an indication of deeper problems in source code that need to be identified in order to decrease the accumulation effect in the SDLC which implies that at each stage smells may transform into bugs, faults or even failure of the working software resulting in loss of efforts. Refactoring, on the other hand, helps in removal of smells without affecting the external attributes of the software. Nowadays, researchers are focusing on the detection of optimum refactoring sequences well in advance so that software maintenance cost can be reduced and subsequently the efforts may minimize. In this paper, authors have identified a total of eleven bad smells present in the critically affected class selected on the basis of prioritization technique. After that, an attempt have been made to find optimum refactoring technique sequence using AO* algorithm which will eliminate identified bad smells and thereby helping the\u00a0\u2026", "num_citations": "1\n", "authors": ["101"]}
{"title": "Application of machine learning algorithms for code smell prediction using object-oriented software metrics\n", "abstract": " Code smells are generally not considered as bugs; instead, they point out certain shortcomings in the software design or code. Identification of code smell is a necessary step for improving the software quality and reducing the maintenance effort. In this study, we introduce a bad smell prediction technique based on object-oriented software metrics that use Decision Tree (DT) and Random Forest (RF) machine learning algorithm. An open-source project, namely JHOTDRAW, was used as our dataset, for which values of object-oriented software metrics were calculated. Two feature selection methods-Random Forest Importance (RFI) and Information Gain (IG) were applied to extract the most relevant attributes for the prediction of code smells, namely, Feature envy, Dispersed coupling, refused parent bequest, and God class. The random-search algorithm was used to tune the parameters of Random Forest and\u00a0\u2026", "num_citations": "1\n", "authors": ["101"]}
{"title": "Stepping towards dynamic measurement for object oriented software\n", "abstract": " Software metrics are very helpful in measuring the different aspects of software like cohesion, coupling, polymorphism, inheritance etc. The objective of measuring software metrics are quality assurance, defect prediction, maintainability prediction, cost estimation, debugging, etc. Many authors proposed the use of static metrics for the software maintainability prediction (SMP) and were successful, but static metrics don't take into account the run-time behavior of software. Hence, to capture this dynamic behavior, dynamic metrics are necessary to be evaluated. This paper presents the empirical investigation of dynamic metrics for SMP and also compares them with static metrics. Six machine learning algorithms are used to build the prediction models for both the static and dynamic metrics. The performance of all models is compared using prevalent accuracy measures. Results show that dynamic metrics perform better\u00a0\u2026", "num_citations": "1\n", "authors": ["101"]}
{"title": "A Survey on Modeling and Simulation of Cloud Computing Environments\n", "abstract": " Cloud computing is a recent advancement in era of technologies wherein IT infrastructure, software, resources and applications are provided as\" services\" to the end-users under a pay-per-use based payment model. Based on the customer requirements, not only services can be offered to them but their dynamic needs can also be fulfilled. It basically provides an opportunity to dynamically scale the computing resources for applications. The application services which are hosted under Cloud computing model have various complex provisioning, composition, configuration, and deployment requirements. With the cloud computing ability to provide users dynamically scalable applications, providing the platform to share resources over the internet and avoid large expenses, cloud computing has recently emerged as a promising hosting platform. In this study an effort has been made to survey and explore various\u00a0\u2026", "num_citations": "1\n", "authors": ["101"]}
{"title": "Adaptive nuero fuzzy interference system ANFIS\n", "abstract": " Software could be called as heartbeat of today technology. In order to make our software pace with the modern day expansion, it must be inevitable to changes. Enhancements and defects can be stated as two major reasons for software change. Software maintainability refers to the degree to which software can be understood, corrected or enhanced. Maintainability of software accounts for more than any other Software engineering activity. The aim of the paper is to present a study based on the experimental analysis to show that ANFIS can more accurately predict maintainability as compared to other models. Predicting the maintainability accurately using ANFIS has got its benefits in now a day\u2019s risk sensitive business with economic environment where software holds the most valuable assets, may it be transaction processing (governmental or banking service), manufacturing automation (chemicals, automation) or any other industry.", "num_citations": "1\n", "authors": ["101"]}