{"title": "KIDS: A semiautomatic program development system\n", "abstract": " The Kestrel Interactive Development System (KIDS), which provides automated support for the development of correct and efficient programs from formal specifications, is described. The system has components for performing algorithm design, deductive inference, program simplification, partial evaluation, finite differencing optimizations, data type refinement, compilation, and other development operations. Although their application is interactive, all of the KIDS operations are automatic except the algorithm design tactics, which require some interaction at present. Dozens of programs have been derived using the system, and it is believed that KIDS could be developed to the point where it becomes economical to use for routine programming. To illustrate the use of KIDS, the author traces the derivation of an algorithm for enumerating solutions to the k-queens problem. The initial algorithm that KIDS designed takes\u00a0\u2026", "num_citations": "648\n", "authors": ["1702"]}
{"title": "Top-down synthesis of divide-and-conquer algorithms\n", "abstract": " A top-down method is presented for the derivation of algorithms from a formal specification of a problem. This method has been implemented in a system called cypress. The synthesis process involves the top-down decomposition of the initial specification into a hierarchy of specifications for subproblems. Synthesizing programs for each of these subproblems results in the composition of a hierarchically structured program. The initial specification is allowed to be partial in that some or all of the input conditions may be missing. cypress completes the specification and produces a totally correct applicative program. Much of cypress' knowledge comes in the form of \u2018design strategies\u2019 for various classes of algorithms. The structure of a class of divide-and-conquer algorithms is explored and provides the basis for several design strategies. Detailed derivations of mergesort and quicksort algorithms are presented.", "num_citations": "244\n", "authors": ["1702"]}
{"title": "Research on knowledge-based software environments at Kestrel Institute\n", "abstract": " We present a summary of the CHI project conducted at Kestrel Institute through mid-1984. The objective of this project was to perform research on knowledge-based software environments. Toward this end, key portions of a prototype environment, called CHI, were built that established the feasibility of this approach. One result of this research was the development of a wide-spectrum language that could be used to express all stages of the program development process in the system. Another result was that the prototype compiler was used to synthesize itself from very-high-level description of itself. In this way the system was bootstrapped. We describe the overall nature of the work done on this project, give highlights of implemented prototypes, and describe the implications that this work suggests for the future of software engineering. In addition to this historical perspective, current research projects at Kestrel\u00a0\u2026", "num_citations": "211\n", "authors": ["1702"]}
{"title": "KIDS: A knowledge-based software development system\n", "abstract": " The Kestrel Interactive Development System (KIDS) provides knowledge-based support for the derivation of correct and efficient programs from formal specifications. We trace the use of KIDS in deriving an algorithm for solving a problem arising from the design of sonar and radar signals. This derivation illustrates algorithm design, a generalized form of deductive inference, program simplification, finite differencing optimization, partial evaluation, case analysis, and data type refinement. All of the KIDS operations are automatic except the algorithm design tactics which presently require some interaction. Dozens of programs have been derived using the KIDS environment and we believe that it could be developed to the point where it can be used for routine programming.", "num_citations": "191\n", "authors": ["1702"]}
{"title": "Algorithm theories and design tactics\n", "abstract": " Algorithm theories represent the structure common to a class of algorithms, such as divide-and-conquer or backtrack. An algorithm theory for a class A provides the basis for design tactics\u2014specialized methods for designing A-algorithms from formal problem specifications. We illustrate this approach with recent work on the theory of global search algorithms and briefly mention several others. Several design tactics have been implemented in the kids/cypress system and have been used to semiautomatically derive many algorithms.", "num_citations": "132\n", "authors": ["1702"]}
{"title": "Structure and design of global search algorithms\n", "abstract": " Global search is an enumerative approach to problem solving that generalizes the computational paradigms of binary search, backtracking, branch-and-bound, heuristic search, constraint satisfaction, and others. The structure common to global search algorithms is formalized as a theory that provides the basis for a design tactic that prescribes how to construct a correct global search algorithm from a given formal specification of a problem. Global search theory uses the concept of necessary conditions on the existence of feasible or optimal solutions in order to account for such well-known programming concepts as incorporating a constraint into a generator, pruning of branches in backtracking, and pruning via lower bound functions and dominance relations in branch-and-bound. The theory and tactic are illustrated by application to the problem of 0, 1-integer linear programming. The design tactic has been implemented in the KIDS system and used to design dozens of algorithms.", "num_citations": "125\n", "authors": ["1702"]}
{"title": "Constructing specification morphisms\n", "abstract": " Specification morphisms underlie the refinement of algebraic specifications and provide the logical foundations for algorithm and data structure design. We present four techniques for formally, even mechanically, constructing specification morphisms. The first two techniques, verifying a manually constructed signature morphism and composition of specification morphisms are well-known. The remaining two techniques exploit the axioms of the source specification to help infer the translation of sort and function symbols from the source specification. The third, unskolemization, finds the translation of a function symbol by replacing occurrences of it in an axiom by an existentially quantified variable. A constructive proof of the translated axiom yields a witness to the existential that serves as the desired translation of the function symbol. The fourth technique, connections between specifications, allows the transfer of\u00a0\u2026", "num_citations": "109\n", "authors": ["1702"]}
{"title": "Applications of a strategy for designing divide-and-conquer algorithms\n", "abstract": " A strategy for designing divide-and-conquer algorithms that was originally presented in a previous article is extended and applied to several new problems. The extension involves techniques for modifying the original specification based on specific kinds of failures that can occur during the design process. We derive several divide-and-conquer algorithms that are substantially more efficient than previously known algorithms. This paper also emphasizes the naturalness with which divide-and-conquer algorithms can be transformed into a parallel format. One problem explored is to find the maximum sum over all rectangular subregions of a given matrix of integers. For an n \u00d7 n matrix there is a straightforward O(n6) enumeration algorithm. We derive a O(n3) divide-and-conquer algorithm, then show that it can be executed in O(log2n) time in parallel and, furthermore, with pipelining of inputs it can be executed with O(1\u00a0\u2026", "num_citations": "102\n", "authors": ["1702"]}
{"title": "Random trees and the analysis of branch and bound procedures\n", "abstract": " Branch and bound procedures are the most efficient known means for solving many NP-hard problems A special class of branch and bound procedures called relaxation-gutded procedures ig presented. While for some branch and bound procedures a worst-case complexity bound is known, the average case complexity is usually unknown, despite the fact that it may g~ ve more useful information about the performance of the algorithm. A random process which generates labeled trees is introduced as a model of the kind of trees that a relaxatlon-gutded procedure generates over random instances of a problem Results concerning the expected time and space complexity of searching these random trees are derived with respect to several search strategies. The best-bound search strategy is shown to be optimal in both time and space. These results are illustrated by data from random traveling salesman instances\u00a0\u2026", "num_citations": "97\n", "authors": ["1702"]}
{"title": "Transformational approach to transportation scheduling\n", "abstract": " The authors have used KIDS (Kestrel Interactive Development System) to derive extremely fast and accurate transportation schedulers from formal specifications. As test data, strategic transportation plans which are generated by US government planners are used. In one such problem, the derived scheduler was able to schedule 15,460 individual movement requirements in 71 cpu seconds. The computed schedules use relatively few resources and satisfy all specified constraints. The speed of this scheduler derives from the synthesis of strong problem-specific constraint checking and constraint propagation code.< >", "num_citations": "87\n", "authors": ["1702"]}
{"title": "Toward a classification approach to design\n", "abstract": " This paper addresses the problem of how to construct refinements of specifications formally and incrementally. The key idea is to use a taxonomy of abstract design concepts, each represented by a design theory An abstract design concept is applied by constructing a specification morphism from its design theory to a requirement specification. Procedures for propagating constraints, computing colimits, and constructing specification morphisms provide computational support for this approach. Although we conjecture that classification generally applies to the incremental application of knowledge represented in a taxonomy of design theories, this paper mainly focuses on algorithm design theories and presents several examples of design by classification.", "num_citations": "83\n", "authors": ["1702"]}
{"title": "The design of divide and conquer algorithms\n", "abstract": " The structure common to a class of divide and conquer algorithms is represented by a program scheme. A theorem is presented which relates the functionality of a divide and conquer algorithm to its structure and the functionalities of its subalgorithms. Several strategies for designing divide and conquer algorithms arise from this theorem and they are used to formally derive algorithms for sorting a list of numbers, forming the cartesian product of two sets, and finding the convex hull of a set of planar points.", "num_citations": "72\n", "authors": ["1702"]}
{"title": "Mechanizing the development of software\n", "abstract": " This paper presents a mechanizable framework for software development by re nement. The framework is based on a category of speci cations. The key idea is representing knowledge about programming concepts, such as algorithm design, datatype re nement, and expression simpli cation, by means of taxonomies of speci cations and morphisms. Examples are drawn from working systems Specware, Designware, and Planware.", "num_citations": "68\n", "authors": ["1702"]}
{"title": "Planware-domain-specific synthesis of high-performance schedulers\n", "abstract": " Planware is a domain-specific generator of high-performance scheduling software, currently being developed at the Kestrel Institute. Architecturally, Planware is an extension of the Specware system with domain-independent and domain-dependent parts. The domain-independent part includes a general algorithm design facility (including mechanisms to synthesize global-search and constraint propagation algorithms), as well as support for theorem-proving and witness finding. The domain-dependent part includes scheduling domain knowledge and architecture representations, and other domain-specific refinement knowledge that relates the scheduling domain to general algorithm design and data type refinement. Using Planware, the user interactively specifies a problem and then the system automatically generates a formal specification and refines it.", "num_citations": "67\n", "authors": ["1702"]}
{"title": "The synthesis of LISP programs from examples: A survey\n", "abstract": " A. Introduction For some kinds of programs at least, a few well chosen examples of input and output behavior can convey quite clearly to a human what program is intended. The automatic construction of programs from the information contained in a small set of input/output pairs has received much attention recently, especially in the LISP language. The user of such an automatic programming system supplies a sequence of input-output (I/O) pairs< x, y>,< x, y>,...,< x \u201ey,>. The system tries to obtain enough information from the examples to infer the target programs behavior on the full domain of inputs. For example, if a user inputs the sequence< nil, nil>,<(a),(a)>,<(ab),(ba)>,<(abc),(cba)> then the system should return a program such as", "num_citations": "63\n", "authors": ["1702"]}
{"title": "Derived preconditions and their use in program synthesis\n", "abstract": " In this paper we pose and begin to explore a deductive problem more general than that of finding a proof that a given goal formula logically follows from a given set of hypotheses. The problem is most simply stated in the propositional calculus: given a goal A and hypothesis H we wish to find a formula P, called a precondition, such that A logically follows from P \u2227 H. A precondition provides any additional conditions under which A can be shown to follow from H. A slightly more complex definition of preconditions in a first-order theory is given and used throughout the paper. A formal system based on natural deduction is presented in which preconditions can be derived. A number of examples are then given which show how derived preconditions are used in a program synthesis method we are developing. These uses include theorem proving, formula simplification, simple code generation, the completion of\u00a0\u2026", "num_citations": "61\n", "authors": ["1702"]}
{"title": "Composition and refinement of behavioral specifications\n", "abstract": " This paper presents a mechanizable framework for specifying, developing, and reasoning about complex systems. The framework combines features from algebraic specifications, abstract state machines, and refinement calculus, all couched in a categorical setting. In particular, we show how to extend algebraic specifications to evolving specifications (especs) in such a way that composition and refinement operations extend to capture the dynamics of evolving, adaptive, and self-adaptive software development, while remaining efficiently computable. The framework is partially implemented in the Epoxi system.", "num_citations": "52\n", "authors": ["1702"]}
{"title": "Integrity Constraint Reformulation for Efficient Validation.\n", "abstract": " Constraint validation has bcc? n difficult to implement efficiently. The major reason for this difficulty lies in the state-dependent nature of integrity constraints and the rt~ quiremcnt of both high-level spc&fication and cfficirnt runtimc cnforccmcnt. In this paper, we propose a constraint reformulation approach to rfficicnt constraint validation. We also demonstrate how this knowledge-basrd constraint rcfornmlation can be naturally accomplished in the gcncral framework of problem reformulation with the technique of antecedent derivation. We formalize thr reformulation of an integrity constraint as a tree-starch process where the search space is thtr set of all semantic-equivalent alternatives of the original constraint. We also develop control strategies and mcta-level rules for carrying out the search c? fficicntly. The major contribution of this work is a new promising approach to cfficirnt constraint validatiun and a general framework to accomplish it.", "num_citations": "48\n", "authors": ["1702"]}
{"title": "Derivation of glue code for agent interoperation\n", "abstract": " Getting agents to communicate requires translating the data structures of the sender (the source representation) to the format required by the receiver (the target representation). Assuming that there is a formal theory of the semantics of the two formats, which explains both their meanings in terms of a neutral topic domain, we can cast the translation problem as solving higher-order functional equations. Some simple rules and strategies apparently suffice to solve these equations automatically. The strategies may be summarized as: decompose complex expressions, replacing topic-domain expressions with source-domain expressions when necessary. A crucial issue is getting the required formal theories of the source and target domains. We believe it is sufficient to find partial formalizations that grow as necessary.", "num_citations": "46\n", "authors": ["1702"]}
{"title": "Software development by refinement\n", "abstract": " This paper presents an overview of the technical foundations and current directions of Kestrel\u2019s approach to mechanizing software development. The approach emphasizes machine-supported refinement of property-oriented specifications to code, based on a category of higher-order specifications. A key idea is representing knowledge about programming concepts, such as algorithm design, and datatype refinement by means of taxonomies of abstract design theories and refinements. Concrete refinements are generated by composing library refinements with a specification.               The framework is partially implemented in the research systems Specware, Designware, Epoxi, and Planware. Specware provides basic support for composing specifications and refinements via colimit, and for generating code via logic morphisms. Specware is intended to be general-purpose and has found use in industrial\u00a0\u2026", "num_citations": "46\n", "authors": ["1702"]}
{"title": "Designware: Software development by refinement\n", "abstract": " This paper presents a mechanizable framework for software development by refinement. The framework is based on a category of higher-order specifications. The key idea is representing knowledge about programming concepts, such as algorithm design, datatype refinement, and expression simplification, by means of taxonomies of specifications and morphisms.               The framework is partially implemented in the research systems Specware, Designware, and Planware. Specware provides basic support for composing specifications and refinements via colimit, and for generating code via logic morphisms. Specware is intended to be general-purpose and has found use in industrial settings. Designware extends Specware with taxonomies of software design theories and support for constructing refinements from them. Planware builds on Designware to provide highly automated support for requirements\u00a0\u2026", "num_citations": "45\n", "authors": ["1702"]}
{"title": "Overcoming Ontology Mismatches in Transactions with Self-Describing Service Agents.\n", "abstract": " One vision of the \u201cSemantic Web\u201d of the future is that software agents will interact with each other using formal metadata that reveal their interfaces. We examine one plausible paradigm, where agents provide service descriptions that tell how they can be used to accomplish other agents\u2019 goals. From the point of view of these other agents, the problem of deciphering a service description is quite similar to the standard AI planning problem, with some interesting twists. Two such twists are the possibility of having to reconcile contradictory ontologies\u2014or conceptual frameworks\u2014used by the agent, and having to rearrange the data structures of a message-sending agent so they match the expectations of the recipient. We argue that the former problem requires human intervention and maintenance, but that the latter can be fully automated.", "num_citations": "39\n", "authors": ["1702"]}
{"title": "Synthesis of high-performance transportation schedulers\n", "abstract": " This report describes our research on transportation planning and scheduling supported by the ARPA/Rome Lab Planning Initiative (ARPI). The main goal of this project was to develop generic tools to support the construction of exible, high-performance planning and scheduling software. Our technical approach is based on program transformation technology which allows the systematic machine-supported development of software from requirement speci cations. The development process can produce highly e cient code along with a proof of the code's correctness.We have used KIDS (Kestrel Interactive Development System) to derive extremely fast and accurate transportation schedulers from formal speci cations. As test data we use strategic transportation plans which are generated by US government planners. A typical problem, with 10,000 movement requirements, takes the derived scheduler 1 {3 minutes to solve, compared with 2.5 hours for a deployed feasibility estimator (JFAST) and 36 hours for deployed schedulers (FLOGEN, ADANS). The computed schedules use relatively few resources and satisfy all speci ed constraints. The speed of this scheduler is due to the synthesis of strong constraint checking and constraint propagation code.", "num_citations": "37\n", "authors": ["1702"]}
{"title": "RACE: Reconfigurable and adaptive computing environment\n", "abstract": " The Reconfigurable Adaptive Computing Environment (RACE) is a complete environment for reconfigurable computing. The RACE system provides the ability for run-time reconfiguration as well as multiple, simultaneous applications. A hardware library is the key part of the computing environment, allowing for the quick simulation of applications and hardware-software co-execution. Time-consuming functions can be specified in VHDL and added to the hardware library, which are then linked into a user's C program for hardware execution of the functions. The RACE hardware consists of a DMA interface and five Xilinx XC4013 FPGAs, providing approximately 52,000 gates of logic.", "num_citations": "35\n", "authors": ["1702"]}
{"title": "Formal derivation of concurrent garbage collectors\n", "abstract": " Concurrent garbage collectors are notoriously difficult to implement correctly. Previous approaches to the issue of producing correct collectors have mainly been based on posit-and-prove verification or on the application of domain-specific templates and transformations. We show how to derive the upper reaches of a family of concurrent garbage collectors by refinement from a formal specification, emphasizing the application of domain-independent design theories and transformations. A key contribution is an extension to the classical lattice-theoretic fixpoint theorems to account for the dynamics of concurrent mutation and collection.", "num_citations": "34\n", "authors": ["1702"]}
{"title": "Structure and design of problem reduction generators\n", "abstract": " In this paper we present an axiomatic theory for a class of algorithms, called problem reduction generators, that includes dynamic programming, general branch-and-bound, and game tree search as special cases. This problem reduction theory is used as the basis for a mechanizable design tactic that transforms formal speci cations into problem reduction generators. The theory and tactic are illustrated by application to the problem of enumerating optimal binary search trees.", "num_citations": "34\n", "authors": ["1702"]}
{"title": "A generative approach to aspect-oriented programming\n", "abstract": " Aspect-Oriented Software Development (AOSD) offers new insights and tools for the modular development of systems with cross-cutting features. Current tool support for AOSD is provided mainly in the form of code-level constructs. This paper presents a way to express cross-cutting features as logical invariants and to use generative techniques to produce the kind of code that is usually written manually in AOSD. In order to state invariants that express cross-cutting features, we often need to reify certain extra-computational values such as history or the runtime call stack. The generative approach is illustrated by a variety of examples.", "num_citations": "32\n", "authors": ["1702"]}
{"title": "Generating programs plus proofs by refinement\n", "abstract": " We advocate an automated refinement approach to developing programs and their proofs. The approach is partially embodied in the Specware system [6] which has found industrial and government applications. Our view is that the future of software engineering lies in the tight integration of synthesis and analysis processes.", "num_citations": "27\n", "authors": ["1702"]}
{"title": "Post-Implementation Experience With Computerassisted Nurse Scheduling In A Large Hospital\n", "abstract": " This paper discusses three years experience in computer-assisted scheduling of nursing personnel at the Jewish Hospital of St Louis. A computer-based system was developed and implemented to enable a single staffing coordinator to produce monthly schedules for all medical and surgical units in the hospital. Performance after implementation met all design standards. Level of satisfaction with the system was high. A review of performance of the system in its third year of operation, however, identified several problems which had emerged. Many of the difficulties experienced are typically encountered in conversions from manual to computerized operations. Some were more specific to the hospital environment, the scheduling problem itself, and the structure of the scheduling algorithm. An understanding of this experience should be helpful in planning implementation and maintenance of other systems in similar\u00a0\u2026", "num_citations": "27\n", "authors": ["1702"]}
{"title": "Guarded transitions in evolving specifications\n", "abstract": " We represent state machines in the category of specifications, where assignment statements correspond exactly to interpretations between theories [7][8]. However, the guards on an assignment require a special construction. In this paper we raise guards to the same level as assignments by treating each as a distinct category over a shared set of objects. A guarded assignment is represented as a pair of arrows, a guard arrow and an assignment arrow. We give a general construction for combining arrows over a factorization system, and show its specialization to the category of specifications. This construction allows us to define the fine structure of state machine morphisms with respect to guards. Guards define the flow of control in a computation, and how they may be translated under refinement is central to the formal treatment of safety, liveness, concurrency, and determinism.", "num_citations": "24\n", "authors": ["1702"]}
{"title": "A high-level derivation of global search algorithms (with constraint propagation)\n", "abstract": " In this paper we describe the formal derivation of a transportation scheduling algorithm. The algorithm is based on the concepts of global search and constraint propagation and was originally derived using kids (Kestrel Interactive Development System). The emphasis in this paper is on clarity of the overall derivation and on expressing concepts at a level of abstraction that permits significant reuse of concepts, laws, inference patterns, etc.", "num_citations": "24\n", "authors": ["1702"]}
{"title": "Synthesis of planning and scheduling software\n", "abstract": " This report describes our research on transportation planning and scheduling supported by the ARPA/Rome Lab Planning Initiative (ARPI). The main goal of this project was to develop generic tools to support the construction of flexible, highperformance planning and scheduling software. Our technical approach is based on program transformation technology which allows machine-supported development of software from requirement specifications. The development process produces code that is correct by construction and which can be highly efficient. We have used KIDS (Kestrel Interactive Development System) to derive extremely fast and accurate transportation schedulers from formal specifications. As test data we use strategic transportation plans which are generated by US government planners. A typical problem, with 10: 000 movement requirements, takes the derived scheduler 1-3 minutes to solve\u00a0\u2026", "num_citations": "24\n", "authors": ["1702"]}
{"title": "A Problem Reduction Approach to Program Synthesis.\n", "abstract": " Program synthesis is the transformation of a specification of a user's problem into a computer program. A problem reduction approach to program synthesis is presented. During synthesis the user's problem is decom posed in a top-down manner into a hierarchy of subprob lems. with directly solveable subproblems at the bottom. Solving these subproblems results in the bottom-up com position of a program whose structure reflects the subproblem hierarchy. The program is guaranteed to satisfy the specification and to terminate on all legal inputs. We illustrate this approach by presenting the knowledge needed to synthesize a class of divide and conquer algo rithms and by deriving a Merge sort algorithm.", "num_citations": "23\n", "authors": ["1702"]}
{"title": "Composition by colimit and formal software development\n", "abstract": " Goguen emphasized long ago that colimits are how to compose systems [7]. This paper corroborates and elaborates Goguen\u2019s vision by presenting a variety of situations in which colimits can be mechanically applied to support software development by refinement. We illustrate the use of colimits to support automated datatype refinement, algorithm design, aspect weaving, and security policy enforcement.", "num_citations": "22\n", "authors": ["1702"]}
{"title": "Synthesis of efficient constraint-satisfaction programs\n", "abstract": " In this paper we describe the framework we have developed in KIDS (Kestrel Interactive Development System) for generating efficient constraint satisfaction programs. We have used KIDS to synthesise global search scheduling programs that have proved to be dramatically faster than other programs running the same data. We focus on the underlying ideas that lead to this efficiency. The key to the efficiency is the reduction of the size of the search space by an effective representation of sets of possible solutions (solution spaces) that allows efficient constraint propagation and pruning at the level of solution spaces. Moving to a solution space representation involves a problem reformulation. Having found a solution to the reformulated problem, an extraction phase extracts solutions to the original problem. We show how constraints from the original problem can be automatically reformulated and specialised in order\u00a0\u2026", "num_citations": "22\n", "authors": ["1702"]}
{"title": "Toward practical applications of software synthesis\n", "abstract": " Formal methods are usually conceived as a way to obtain veri ably correct software, so many researchers have focused on applications requiring error-free code, such as safety-critical subsystems. There may be other paths to the ultimate success of formal methods. We argue that mechanized synthesis tools can have an impact in the production of high-performance algorithms. This thesis is supported by our work on the synthesis of transportation scheduling algorithms.", "num_citations": "21\n", "authors": ["1702"]}
{"title": "Knowledge-based software development tools\n", "abstract": " We describe some of the experimental knowledge-based software development tools under development at Kestrel Institute. In particular, systems for automatically performing algorithm design, deductive inference, finite differencing, and data structure selection are discussed. A detailed case study is presented that shows how these systems could cooperate in supporting the transformation of a formal specification into efficient code. The example treated is a schedule optimization problem.Descriptors:", "num_citations": "20\n", "authors": ["1702"]}
{"title": "Classification approach to design\n", "abstract": " A brief introduction to KIDS (Kestrel Interactive Development System) and an overview of recent results on the synthesis of high-performance transportation scheduling algorithms was given. The main part of the talk addressed the problem of how to construct refinements of specifications formally and incrementally. The idea is to use a taxonomy of abstract design concepts, each represented by a design theory. An abstract design concept is applied by constructing a specification morphism from its design theory to a requirement specification. Procedures for computing colimits and for constructing specification morphisms provide computational support for this approach. Although the classification approach applies to the incremental application of any of knowledge formally represented in a hierarchy of theories, the talk focused on a hierarchy of algorithm design theories and derivation of", "num_citations": "19\n", "authors": ["1702"]}
{"title": "ITAS: A Portable, Interactive Transportation Scheduling Tool Using a Search Engine Generated from Formal Specifications.\n", "abstract": " In a joint project, BBN and Kestrel Institute have developed a prototype of a mixed-initiative scheduling system called ITAS (In-Theater Airlift Scheduler) for the US Air Force, Pacific Command. The system was built in large part using the KIDS (Kestrel Interactive Development System) program synthesis tool. In previous work for the ARPA/Rome Laboratory Planning Initiative (ARPI), Kestrel has used their program transformation technology to derive extremely fast and accurate transportation schedulers from formal specifications, as much as several orders of magnitude faster than currently deployed systems. The development process can produce highly efficient code along with a proof of the code\u2019s correctness. This paper describes the current prototype ITAS system and its scheduling algorithm, as a concrete example of a generated scheduling working on a real problem. We outline the generalized search algorithm in order to promote and facilitate comparison with other constraint-based scheduling systems. The overall system includes a database and interactive interface that allows users to control shape of the schedule produced in a number of ways. ITAS runs on a Macintosh PowerbookTM notebook computer, for reasons of portability.", "num_citations": "17\n", "authors": ["1702"]}
{"title": "Automating the design of algorithms\n", "abstract": " This paper has two roughly independent parts. The first is devoted to the automation of program construction. The Kestrel Interactive Development System (KIDS) provides knowledge-based support for the derivation of correct and efficient programs from specifications. We trace the use of KIDS in deriving a scheduling algorithm. The derivation illustrates algorithm design, deductive inference, simplification, finite differencing, partial evaluation, data type refinement, and other techniques. All of the KIDS operations are automatic except the algorithm design tactics which require some interaction at present. Dozens of programs have been derived using the KIDS environment.             The second part discusses the theory of algorithm design used in KIDS. Concepts include problem theories, algorithm theories, program schemes as parameterized theories, design as interpretation between theories (theory\u00a0\u2026", "num_citations": "15\n", "authors": ["1702"]}
{"title": "Colimits for concurrent collectors\n", "abstract": " This case study applies techniques of formal program development by specification refinement and composition to the problem of concurrent garbage collection. The specification formalism is mainly based on declarative programming paradigms, the imperative aspect is dealt with by using monads. We also sketch the use of temporal logic in connection with monadic specifications.", "num_citations": "14\n", "authors": ["1702"]}
{"title": "Customer recipient list reorder feature for on-line transactions\n", "abstract": " An on-line editable recipient list is provided to a customer to enhance a reorder process for a list of recipients. The recipient list contains a list of recipients who received products previously ordered by the customer and delivered to the recipients possibly in association with a periodic event (eg, a holiday). An interactive feature is provided for reordering all the same products for all the same recipients as last year. The customer can start with this list and shop on-line for the customers on the list. In one case, the customer reorders the same products as last year for some recipients on the list, and shops-for new products for other recipients on the list. In one such case, the customer can add, delete and modify recipients from last year's list.", "num_citations": "13\n", "authors": ["1702"]}
{"title": "Derivation of parallel sorting algorithms\n", "abstract": " Parallel algorithms can be derived from formal problem specifications by applying a sequence of transformations that embody information about algorithms, data structures, and optimization techniques. The KIDS system provides automated support for this approach to algorithm design. This paper carries through the salient parts of a formal derivation for a well-known parallel sorting algorithm \u2014 Batcher\u2019s Even-Odd sort. The main difficulty lies in building up the problem domain theory within which the algorithm is inferred.", "num_citations": "13\n", "authors": ["1702"]}
{"title": "The Structure of Divide and Conquer Algorithms.\n", "abstract": " The structure of divide and conquer algorithms is represented by program schemes which provide a kind of normal-form for expressing these algorithms. A theorem relating the correctness of a divide and conquer algorithm to the correctness of its subalgorithms is given. Several strategies for designing divide and conquer algorithms for sorting a list of numbers, evaluating a propositional formula, and forming the cartesian product of two sets. AuthorDescriptors:", "num_citations": "13\n", "authors": ["1702"]}
{"title": "A production rule mechanism for generating LISP code\n", "abstract": " Production rule schemas are given which hold the basic information necessary for coding recursive loops and branches in LISP. Information from the user concerning the desired program is used to instantiate the schemas to yield production rules, and then these rules generate executable code in a strictly syntactic fashion. Emphasis is placed on decomposing the synthesis problem into a hierarchy of tasks which can each be solved by application of a schema. The method is demonstrated by showing how programs can be synthesized from examples of their input-output behaviors.", "num_citations": "13\n", "authors": ["1702"]}
{"title": "Synthesis of fast programs for maximum segment sum problems\n", "abstract": " It is well-known that a naive algorithm can often be turned into an efficient program by applying appropriate semantics-preserving transformations. This technique has been used to derive programs to solve a variety of maximum-sum programs. One problem with this approach is that each problem variation requires a new set of transformations to be derived. An alternative approach to generation combines problem specifications with flexible algorithm theories to derive efficient algorithms. We show how this approach can be implemented in Haskell and applied to solve constraint satisfaction problems. We illustrate this technique by deriving programs for three varieties of maximum-weightsum problem. The derivations of the different programs are similar, and the resulting programs are asymptotically faster in practice than the programs created by transformation.", "num_citations": "12\n", "authors": ["1702"]}
{"title": "Synthesis of propositional satisfiability solvers\n", "abstract": " Development of system software by refinement has been extensively studied, and few larger scale case studies has been carried out. Most refinement approaches havse relied on manual construction of ad-hoc non-reusable refinements that are subjected to post-hoc verification. The problem with this approach is that the incremental cost of adapting to changing requirements is too high for this to be practical. Our belief is that refinement technology will only become feasible when most, if not all, refinements are generated correctly rather than constructed manually.We recently carried out a case study of the automated synthesis of high-performance solvers for the propositional satisfiability problem (SAT). In the end we generated a small family of solvers. With the exception of the introduction of control heuristics, which is a manual step, all refinements were automatically generated using representations of design knowledge in a library. The library design knowledge had large overlaps with the knowledge used to generate high-performance transportation scheduling algorithms and others.", "num_citations": "12\n", "authors": ["1702"]}
{"title": "Planware II: Synthesis of schedulers for complex resource systems\n", "abstract": " Planware is an integrated development environment for the domain of complex planning and scheduling systems. Its design and implementation aim at supporting the entire planning and scheduling process including domain analysis and knowledge acquisition; application development and testing; and mixed-initiative, human-in-the-loop, plan and schedule computation. Based on principles of automatic software synthesis, Planware addresses the problem of maintaining the synchronization between evolving specifications, and the corresponding system implementation. Planware automatically generates optimized and specialized planning and scheduling code from high-level models of complex problems. Resources and tasks are uniformly modeled using a hierarchical state machine formalism that represents activities as states, and includes constructs for expressing constraints on states and transitions. The generator analyzes the state machine models to instantiate program schemas generating concrete implementations of backtrack search and constraint propagation algorithms. Coordination between resources and tasks is achieved through the use of services: tasks require services, and resources provide services. Planware\u2019s scheduler generator component matches providers with requesters, and automatically generates the code necessary to verify and enforce, at schedule computation time, the service constraints imposed in the model. Planware\u2019s user interface is based on Sun\u2019s NetBeans platform and provides integrated graphic and text editors for modeling complex resource systems, automatically generating batch schedulers, and\u00a0\u2026", "num_citations": "12\n", "authors": ["1702"]}
{"title": "Synthesis of schedulers for planned shutdowns of power plants\n", "abstract": " We describe the synthesis of efficient schedulers for planned shutdowns of power plants for refueling and maintenance (outages), using an automated programming tool, KIDS. Currently, the utility industry has no automated tools to generate schedules that are both safe and resource-efficient. We focused on safety constraints since they are critical in this application. There are several aspects of this project that go beyond previous applications of KIDS to scheduling problems. First, scheduling of outages of power plants has a planning-like character since the scheduler needs to represent and maintain the complex state of the plant at all times considered during the scheduling process. Second, the particular safety constraints we considered required scheduling a pool of resources in the presence of time windows on each activity. To our knowledge the control and data structures that we developed for handling such a\u00a0\u2026", "num_citations": "12\n", "authors": ["1702"]}
{"title": "On the design of generate-and-test algorithms: subspace generators\n", "abstract": " On the design of generate-and-test algorithms: subspace generators | The IFIP TC2/WG 2.1 Working Conference on Program specification and transformation ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleProceedingsThe IFIP TC2/WG 2.1 Working Conference on Program specification and transformationOn the design of generate-and-test algorithms: subspace generators ARTICLE On the design of generate-and-test algorithms: subspace generators Share on Author: DR Smith profile image DR Smith View Profile Authors Info & Affiliations Publication: The IFIP TC2/WG 2.1 Working Conference on Program specification and \u2026", "num_citations": "12\n", "authors": ["1702"]}
{"title": "Top-Down Synthesis of Simple Divide and Conquer Algorithms.\n", "abstract": " A new method is presented for the deductive synthesis of computer programs. The method takes as given a formal specification of a users problem. The specification is allowed to be incomplete in that some or all of the input conditions may be omitted. A completed specification plus a computer program are produced by the method. Synthesis involves the top-down decomposition of the users problem into a hierarchy of subproblems. Solving each of these subproblems results in the synthesis of a hierarchically structured program. The program is guaranteed to satisfy the completed specification and to terminate on all legal inputs. In this paper we present a framework for a top-down synthesis process, explore the structure of a class of divide and conquer algorithms, and present a method for the top-down synthesis of algorithms in this class. Detailed derivations of four sorting algorithms are presented. AuthorDescriptors:", "num_citations": "12\n", "authors": ["1702"]}
{"title": "Composition and refinement of evolving specifications\n", "abstract": " We represent state machines in the category of specifications, where assignment statements correspond exactly to in terpretations between theories [6, 9]. However, the guards on an assignment require a special construction. In this paperweraise guards to the same level as assignments by treating each as a distinct category over a shared set of objects. A guarded assignment is represented as a pair of arrows, a guard arrow and an assignment arrow. We give a general construction for combining arrows over a factorization system, and show its specialization to the category of specifications. This construction allows us to define the fine structure of state machine morphisms with respect to guards. Guards define the flow of control in a computation, and how they maybe translated under refinement is central to the formal treatment of safety, liveness, concurrency, and determinism.", "num_citations": "11\n", "authors": ["1702"]}
{"title": "Track assignment in an air traffic control system: a rational reconstruction of system design.\n", "abstract": " This paper summarizes our application of the KIDS system to a larger-scale problem drawn from the domain of Air Traffic Control. Hughes Aircraft supplied us with a natural language specification of the Track Assignment (T4) portion of an Air Traffic Control System. We formalized this specification as a domain theory and derived programs within this theory. The derived code is comparable to ADA code that was produced by conventional means. 4", "num_citations": "11\n", "authors": ["1702"]}
{"title": "Finite map spaces and quarks: Algebras of program structure\n", "abstract": " We present two algebras that unify the disparate software composition models of Feature-Oriented Programming and Aspect-Oriented Programming. In one algebra, a finite map space underlies program synthesis, where adding finite maps and modifying their contents are fundamental operations. A second and more general algebra uses quarks, a construct that represents both expressions and their transformations. Special cases of our algebras correspond to existing systems and languages, and thus can serve as a foundation for next-generation tools and languages for feature-based program synthesis.", "num_citations": "10\n", "authors": ["1702"]}
{"title": "Reasoning by cases and the formation of conditional programs\n", "abstract": " Reasoning by cases, a natural feature of human reasoning, has been difficult to formulate so that it can be performed naturally when needed. Several difficulties arise:(1) how to motivate the use of reasoning by cases when and only when needed,(2) how to determine an appropriate analysis of the goal into cases, and (3) how to carry out the deduction in each case and combine the results. In this paper we focus on how reasoning by cases can be naturally accomplished in the framework of derived antecedents (Smith 1982). Our main technical contributions are (1) a set of strategies that draw on the context of a deduction to provide an appropriate case analysis for a goal, and (2) inference rules for carrying out reasoning by cases and forming conditional terms for the existentially quantified variables in the initial goal.", "num_citations": "10\n", "authors": ["1702"]}
{"title": "Aspects as invariants\n", "abstract": " Aspect-Oriented Programming (AOP) offers new insights and tools for the modular development of systems with crosscutting features. Current tool support for AOP is provided mainly in the form of code-level constructs. This paper presents a way to express crosscutting features as logical invariants and then to generate the kind of code that is usually produced from manually written aspects. In order to state invariants that express crosscutting features, we often need to reify certain extra-computational values such as history or the runtime call stack. The invariant approach is illustrated by a variety of examples.", "num_citations": "9\n", "authors": ["1702"]}
{"title": "Requirement enforcement by transformation automata\n", "abstract": " The goal of this work is to treat safety and security policies as requirements to be composed in an aspectual style with a developing application. Policies can be expressed either logically or by means of automata. We introduce the concept of transformation automaton, which is an automaton whose transitions are labeled with program transformations. A transformation automaton is applied to a target program by a sound static analysis procedure. The effect is to perform a global transformation that enforces the specified policy. The semantic effect of this global transformation is explored.", "num_citations": "9\n", "authors": ["1702"]}
{"title": "Toward the synthesis of constraint propagation algorithms\n", "abstract": " Within the last decade logic programming has developed into constraint logic programming. One motivation for this development has been the need to handle richer data structures in a manner consistent with the nondeterministic and relational style of logic programming. It was realized early on that ordinary unification was equation solving over trees. From there it was a natural step to allow equation solving over more complex structures (e.g. lists, booleans, integers) and further to allow constraint solving in various theories (e.g. monoids, boolean algebras, real closed fields). From another point of view, constraint logic programming languages, such as PROLOG III [2], CLP(R) [5], and CHIP [4], can be seen as attempts to integrate the best features of logic programming and work on constraint satisfaction algorithms in Artificial Intelligence and Operations Research. See [1] for an overview of constraint logic\u00a0\u2026", "num_citations": "9\n", "authors": ["1702"]}
{"title": "On the computational complexity of branch and bound search strategies\n", "abstract": " Many important problems in operations research, artificial intelligence, combinatorial algorithms, and other areas seem to require search in order to find an optimal solution. A branch and bound procedure, which imposes a tree structure on the search, is often the most efficient known means for solving these problems. While for some branch and bound algorithms a worst case complexity bound is known, the average case complexity is usually unknown despite the fact that it gives more information about the performance of the algorithm. In this dissertation the branch and bound method is discussed and a probabilistic model of its domain is given, namely a class of trees with an associated probability measure. The best bound first and depth-first search strategies are discussed and results on the expected time and space complexity of these strategies are present-1 and compared. The best-bound search strategy is\u00a0\u2026", "num_citations": "9\n", "authors": ["1702"]}
{"title": "Synthesis of constraint algorithms\n", "abstract": " Constraint propagation is one of the key operations on constraints in Constraint Programming. In a constraint program, a constraint set partially characterizes objects of interest and their relationships. As committments are made that further characterize some object, we want to infer consequences of those committments and add those consequences as new constraints. E ciency concerns drive us to look closely at the representation of constraints, inference procedures for solving constraints and deriving consequences, and the capture of inferred consequences as new constraints. We report here on our current e orts at developing automated methods for deriving problem-speci c constraint propagation code. This e ort is part of a broader development of automated tools for transforming formal speci cations into e cient and correct programs. The KIDS system 8] serves as the testbed for our experiments and provides tools for performing deductive inference, algorithm design, expression simplication, nite di erencing, partial evaluation, data type re nement, and other transformations. We have used KIDS to derive over 60 algorithms for a wide variety of application domains, including scheduling, combinatorial design, sorting and searching, computational geometry, pattern matching, and mathematical programming.A transportation scheduling application motivated our constraint propagation work 7]. We used KIDS semiautomatically to derive a global search (backtrack) scheduler. The derivation included inferring pruning conditions and deriving constraint propagation code. The resulting code is given in 7] and has proved to be dramatically faster than\u00a0\u2026", "num_citations": "8\n", "authors": ["1702"]}
{"title": "Model validation in Planware\n", "abstract": " Planware II is an integrated development environment for the domain of complex planning and scheduling systems. At its core is a model-based generator for planning and scheduling applications. Its design and implementation aim at supporting the entire planning and scheduling process including domain analysis and knowledge acquisition; application development and testing; and mixed-initiative, human-in-theloop, plan and schedule computation. Based on principles of automatic software synthesis, Planware addresses the problem of maintaining the synchronization between a dynamic model describing the problem, and the corresponding system implementation. Planware automatically generates optimized and specialized planning and scheduling code from high-level models of complex problems. Resources and tasks are uniformly modeled using a hierarchical state machine formalism that represents activities as states, and includes constructs for expressing constraints on states and transitions. A resource model represents all possible sequences of activities this resource can execute. Figure 1 shows a simple problem description with 3 resources\u2013Aircraft, Crew, and Airport; and a top-level task representing a movement requirement. A schedule or plan will be composed of concrete activity sequences that can be generated by simulating the execution, or trace, of these state machines. For example, a sequence [Idle, Transporting, Unloading, Returning, Idle] represents a valid sequence of activities for the Aircraft resources. Figure 2 and 3 shows parts of the source code for the Aircraft resource. The model-based generator analyzes the\u00a0\u2026", "num_citations": "7\n", "authors": ["1702"]}
{"title": "Comprehension by derivation [software system comprehension]\n", "abstract": " We argue that to comprehend a software system is to have a handle on its requirements, specifications, and design decisions. These kinds of information support the reuse of system code for a variety of purposes and support its ongoing extension, migration, and evolution. Our work at Kestrel Institute has focused on ways to mechanize the development and evolution of software from formal specifications. By-products of such a process include formal records of design decisions and proofs, as well as executable code. In this approach, reuse can take place at non-code levels, including domain theories, specifications, and design knowledge. Evolution takes place by modifying requirements, specifications, or design decisions, and then reusing previous design structures. When restricted to particular application domains, the generation of correct-by-construction code from specifications can be completely automatic.", "num_citations": "7\n", "authors": ["1702"]}
{"title": "Synthesis of Power Plant Outage Schedulers.\n", "abstract": " We describe the synthesis of efficient schedulers for planned shutdowns of power plants for refueling and maintenance outages, using an automated programming tool, KIDS. Currently, the utility industry has no automated tools to generate schedules that are both safe and resource-efficient. We focused on safety constraints since they are critical in this application. There are several aspects of this project that go beyond previous applications of KIDS to scheduling problems. First, scheduling of outages of power plants has a planning-like character since the scheduler needs to represent and maintain the complex state of the plant at all times considered during the scheduling process. Second, the particular safety constraints we considered required scheduling a pool of resources in the presence of time windows on each activity. To our knowledge the control and data structures that we developed for handling such a pool are novel. In terms of design knowledge, the outage scheduling problem is modeled as a constraint satisfaction problem and the synthesized algorithm is an instance of global search with constraint propagation. The derivation of specialized representations for the constraints to perform efficient propagation is a key aspect of our approach. In addition, finite differencing complements constraint propagation by efficiently maintaining the sate of the world.Descriptors:", "num_citations": "7\n", "authors": ["1702"]}
{"title": "Toward the synthesis of constraint solvers\n", "abstract": " We develop a basic mathematical framework for specifying and formally designing highperformance constraint solving algorithms. The framework is based on concepts from abstract interpretation which generalizes earlier work on a Galois Connection-based model of Global Search algorithms. The main focus is on how to use the framework to automate the calculations necessary to construct a correct, high-performance solver. We present here the foundations for generating customized/native solvers for specified constraint satisfaction problems. Our thesis is that a native solver can always be generated for a constraint problem that outperforms a reduction to an existing solver.", "num_citations": "6\n", "authors": ["1702"]}
{"title": "Theory and techniques for synthesizing efficient breadth-first search algorithms\n", "abstract": " Although Breadth-First Search (BFS) has several advantages over Depth-First Search (DFS) its prohibitive space requirements have meant that algorithm designers often pass it over in favor of DFS. To address this shortcoming, we introduce a theory of efficient BFS (EBFS), along with a simple recursive program schema for carrying out the search. The theory is based on dominance relations, a long standing technique from the field of search algorithms. We also show that greedy and greedy-like algorithms form a very useful and important sub-category of EBFS. Finally, we show how the EBFS class can be used for semi-automated program synthesis by introducing some techniques for demonstrating that a given problem is solvable by EBFS. We illustrate our approach on several examples.", "num_citations": "6\n", "authors": ["1702"]}
{"title": "A class of greedy algorithms and its relation to greedoids\n", "abstract": " A long-standing problem in algorithm design has been to characterize the class of problems for which greedy algorithms exist. Many greedy problems can be described using algebraic structures called matroids, which were later generalized to greedoids. Once in this form, the original problem can be solved using Edmonds\u2019 Greedy Algorithm. However there are several practical problems with greedy solutions that either do not have a greedoid representation (e.g. Activity Selection) or for which none is known (e.g. Huffman Coding). This paper presents a new characterization of greedy problems that is strictly more general than greedoids, in that it includes all greedoids, as well as problems such as Activity Selection and Huffman Coding. Unlike matroids, our characterization is an axiomatization of a form of Branch and Bound Search, where greediness is associated with the existence of an appropriate\u00a0\u2026", "num_citations": "6\n", "authors": ["1702"]}
{"title": "Evolving specification engineering\n", "abstract": " The motivation for this work is to support a natural separation of concerns during formal system development. In a development-by-refinement context, we would like to be able to first treat basic functionality and normal-case behavior, and then later add in complicating factors such as physical limitations (memory, time, bandwidth, hardware reliability, and so on) and security concerns. Handling these complicating factors often does not result in a refinement, since safety or liveness properties may not be preserved. We extend our earlier work on evolving specifications (1) to allow the preservation of both safety and liveness properties under refinement, and (2) to explore a more general notion of refinement morphism to express the introduction of complicating factors.", "num_citations": "6\n", "authors": ["1702"]}
{"title": "Formal derivation of agent interoperation code\n", "abstract": " The goal of this note is to explore the formal derivation of glue code\" that translates between the data o ered by one agent and the required data of another. We have worked a number of example problems drawn from the CAMPS airlift scheduling domain 1.As a typical example, we are given a scheduling agent MP that produces an airlift schedule for each aircraft, the schedule gives the sequences of ights that it makes. We also have an agent CM that requires what is known as a commitment matrix the number and type of aircraft that are committed ie not free for allocation over time. The problem is to derive a translator f from schedules to commitment matrices. This problem has features of translation and summarization of data.", "num_citations": "6\n", "authors": ["1702"]}
{"title": "A design for an automatic programming system\n", "abstract": " The algorithm design problem is concerned with the construction of an algorithm satisfying a given specification of a problem. We present an overview of a system, called NAPS, which designs Algorithms in a top-down manner. Given a formal specification of a problem NAPS produces a top level algorithm plue specifications for any necessary subalgorithms. The specifications for the subalgorithms are produced in such a way that the top level algorithm will satisfy the original specifications if and only if subalgorithms can be built which satisfy the subalgorithms specifications.", "num_citations": "6\n", "authors": ["1702"]}
{"title": "Method and system for self-adaptive code\n", "abstract": " The present invention allows the design and utilization of \u201cspecification-carrying software.\u201d In the described embodiment, software is extended with comments in a generic specification language, or with Floyd-Hoare annotations, although other types of specifications can be used. Specifications preferably are extended with executable (partial) implementations, or abstract, but verifiable behaviors.", "num_citations": "5\n", "authors": ["1702"]}
{"title": "Theory and techniques for synthesizing a family of graph algorithms\n", "abstract": " Although Breadth-First Search (BFS) has several advantages over Depth-First Search (DFS) its prohibitive space requirements have meant that algorithm designers often pass it over in favor of DFS. To address this shortcoming, we introduce a theory of Efficient BFS (EBFS) along with a simple recursive program schema for carrying out the search. The theory is based on dominance relations, a long standing technique from the field of search algorithms. We show how the theory can be used to systematically derive solutions to two graph algorithms, namely the Single Source Shortest Path problem and the Minimum Spanning Tree problem. The solutions are found by making small systematic changes to the derivation, revealing the connections between the two problems which are often obscured in textbook presentations of them.", "num_citations": "4\n", "authors": ["1702"]}
{"title": "Cost-based learning for planning\n", "abstract": " Most learning in planners to date has been focused on speedup learning. Recently the focus has been more on learning to improve plan quality. We introduce a different dimension: learning not just from failed plans, but learning from inefficient plans. We call this cost-based learning (CBL). CBL can be used to improve both plan quality and provide speedup learning. We show how cost-based learning can also be used to learn plan rewrite rules that can be used to rewrite an inefficient plan to an efficient one, in the style of Planning by Rewriting (PbR). We do this by making use of dominance relations. Additionally, the learned rules are compact and do not rely on state information so they are fast to match.", "num_citations": "4\n", "authors": ["1702"]}
{"title": "Form factors: A design method to support the selection of structural concepts\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "4\n", "authors": ["1702"]}
{"title": "Kids\n", "abstract": " FOR TEENS & TWEENS FOR ADULTS FOR KIDS Page 1 Ancient Egypt Ancient Egypt Ancient Lives: Daily Life in Egypt of the Pharaohs Romer Cleopatra: A Life Schiff Cleopatra\u2019s Daughter Moran Cries from the Lost Island Gear Death Comes as the End Christie The Great Pyramid Hoax Creighton King Tutankhamun: The Treasures of the Tomb Hawass Pharaoh Smith The Son of Light Jacq The Story of Egypt Fletcher A Thousand Ships Haynes When Women Ruled the World: Six Queens of Egypt Cooney Amulet Keepers Northrop Ancient Egyptian Art Hodge Blast Back! Ancient Egypt Ohlin Cleo and Cornelius Nicholson The Clue in the Papyrus Scroll Garretson The Curse of Time Lay The Egypt Game Snyder Egyptian Mythology Broyles The Genius of the Ancient Egyptians Newland I am the Mummy Heb-Nefert Bunting Mummies in the Morning Osborne Mummies, Pyramids, and Pharaohs Gibbons The Mummy\u2019s \u2026", "num_citations": "4\n", "authors": ["1702"]}
{"title": "Scheduling an asynchronously shared resource\n", "abstract": " This note describes one aspect of our exploration of the machine synthesis of scheduling, algorithms [1, 2]. The approach involves several stages. The first step is to develop a formal model of the scheduling domain, called a domain theory. Second, the constraints, objectives, and preferences of a particular scheduling problem are formally stated within the language of the domain theory as a problem specification. Finally, an executable scheduler is produced semi-antomatically by applying a sequence of transformations to the problem specification. The transformations embody programming knowledge about algorithms, data structures, program optimization techniques, etc. The result of the transformation process is executable code that is correct by construction. Furthermore, the resulting code can be extremely efficient. In this note we focus on scheduling a class of resources that we call AsynchronousIy Shared\u00a0\u2026", "num_citations": "4\n", "authors": ["1702"]}
{"title": "Automating the development of software\n", "abstract": " The Kestrel Interactive Development System (KIDS) provides knowledge-based support for the derivation of correct and efficient programs from formal specifications. We trace the use of KIDS in deriving an algorithm for solving a problem arising from the design of radar and sonar signals. This derivation illustrates algorithm design, a generalized form of deductive inference, program simplification, finite differencing optimizations, partial evaluation, case analysis, and data type refinement. All of the KIDS operations are automatic except the algorithm design tactics which require some interaction at present. Dozens of programs have been derived using the KIDS environment and we believe that it can be developed to the point that it can be used for routine programming.", "num_citations": "4\n", "authors": ["1702"]}
{"title": "Aluminum hydroxide: evaluation of two dosage forms and two dosing schedules in reducing intestinal phosphate absorption\n", "abstract": " A crossover, randomized, eight-week trial using eight adult volunteers was undertaken to (1) determine the efficacy of aluminum hydroxide in decreasing gastrointestinal phosphate absorption, (2) compare the effectiveness of \u201cwith meal\u201d and \u201cbetween meal\u201d dosing schedules, and (3) compare the effectiveness of the capsule and liquid dosage forms.         Four treatments, each with a daily dose of approximately 6 g, were taken on a three-times-a-day regimen. The effectiveness of the treatment regimens was measured by using two variables: the decrease in total urinary phosphorus excretion, and the increase in the percent tubular reabsorption of phosphorus (TRP).         Aluminum hydroxide treatment produced a significant change in urinary phosphorus excretion (p < 0.0005) and in percent TRP (p < 0.0005). For the study population, total urinary phosphorus excretion was the determining factor in changing the\u00a0\u2026", "num_citations": "4\n", "authors": ["1702"]}
{"title": "Method and apparatus for determining colimits of hereditary diagrams\n", "abstract": " A computer-implemented method and system for determining colimits of hereditary diagrams. A user specifies a diagram of diagram and specifies performance of a colimit operation. Once the colimit is performed, the name of the colimit is added to the hereditary diagram. The described embodiment supports diagrams of diagrams, also called hierarchical diagrams.", "num_citations": "3\n", "authors": ["1702"]}
{"title": "The role of witness-finding in software synthesis\n", "abstract": " I\u2019d like to briefly outline my experience in using witness-finding in a variety of roles during software synthesis, including as a special case the extraction of whole programs as witnesses. The effort may be seen as attempting to develop more encompassing frameworks for generating software, motivated by the desire to synthesize larger, more complex applications.", "num_citations": "3\n", "authors": ["1702"]}
{"title": "Comparison of Theoretical Ocean Diffusion Models\n", "abstract": " Since several diffusion equations exist for describing horizontal diffusion from a point-source release of material in the ocean, a comparison of these equations was made in order to determine the one which would give the most conservative answers for purposes of evaluation of radiological hazards. This comparison can be made in terms of the maximum spatial and temporal coordinates of a given concentration. In so doing it is found that these coordinates can be expressed in terms of the ratio of the initial concentration to the given concentration raised to some power. Equations were derived for the case of a continuous release and a similar analysis was made for the equilibrium situation. AuthorDescriptors:", "num_citations": "3\n", "authors": ["1702"]}
{"title": "Synthesis of Greedy Algorithms Using Dominance Relations.\n", "abstract": " What are dominance relations? Enables the comparison of one partial solution with another to determine if one of them can be discarded Given \u0302z and \u0302z if the best possible solution in \u0302z is better than the best possible solution in \u0302z then \u0302z can be discarded", "num_citations": "2\n", "authors": ["1702"]}
{"title": "Tactical synthesis of efficient global search algorithms\n", "abstract": " Algorithm synthesis transforms a formal specification into an efficient algorithm to solve a problem. Algorithm synthesis in Specware combines the formal specification of a problem with a high-level algorithm strategy. To derive an efficient algorithm, a developer must define operators that refine the algorithm by combining the generic operators in the algorithm with the details of the problem specification. This derivation requires skill and a deep understanding of the problem and the algorithmic strategy. In this paper we introduce two tactics to ease this process. The tactics serve a similar purpose to tactics used for determining indefinite integrals in calculus, that is suggesting possible ways to attack the problem.", "num_citations": "2\n", "authors": ["1702"]}
{"title": "Toward automated software development\n", "abstract": " The ASE conference series is rooted in the 1981 Knowledge-Based Software Assistant (KBSA) document [1] and the ensuing US Air Force Rome Labs research program. KBSA addressed automated tool support for the entire software lifecycle, including project management, requirements, specifications, code generation, and evolution. A core goal of KBSA and ASE is the automated generation of code from requirement-level specifications, which promises benefits in three directions:(1) High Assurance-generation of correct code, as well as certification information as a by-product,(2) Productivity through automation, and (3) High Performance through machine application of best-practice design knowledge. Benefits should also include lowering of the cost of lifecycle ownership, due to automated treatment of evolving requirements. This talk lays out a more modern unifying framework for automated software\u00a0\u2026", "num_citations": "2\n", "authors": ["1702"]}
{"title": "Towards the industrial scale development of custom static analyzers\n", "abstract": " This paper presents a high level overview of a tech-nology called CodeHawk whose purpose is to support verification of software properties. Today\u2019s commercially available static analysis tools identify potential runtime and vulnerability problems based on properties described in the semantics of the programming language. While CodeHawk will detect those classes of problems, it is distinguished by the user\u2019s ability to generate high performance static analyzers for the verification of application-specific properties. Today\u2019s static analyzers may also trade off assurance and flexibility for speed in handling very large code sets. Our goal with CodeHawk is to handle industrial sized code sets with the highest speed in the industry among those offering 100% verification assurance. CodeHawk\u2019s customizability opens up additional uses of the core technology beyond detecting runtime or vulnerability exposures. In this paper we describe one such use, namely static analysis in support of optimized dynamic analysis.", "num_citations": "2\n", "authors": ["1702"]}
{"title": "Toward automated enforcement of error-handling policies\n", "abstract": " Modern systems are prone to failure due to poor handling of errors that might arise. We report on a design for a tool called HandlErr that allows system developers (1) to state error-handling policies in a modular class-like notation, and (2) to automatically enforce those policies throughout the system code. The enforcement mechanisms are based on recently developed scalable and conservative static analysis algorithms. When static analysis cannot provide enough information about the applicability of a policy at a program point, then runtime monitoring code is inserted and the error-handling policy is applied based on runtime information.", "num_citations": "2\n", "authors": ["1702"]}
{"title": "Software productivity through automation and design knowledge\n", "abstract": " Dramatic increases in software productivity can be brought about by (re) use of software design knowledge and automated composition and refinement. There is evidence that a key reason for the complexity and inertia of large-scale systems is that the number of dependencies in code grows superlinearly with code size. Productivity can be increased by working with software parts that are relatively free of dependencies. This implies the use of modularity and abstraction. We advocate the development of software systems from specifications (formal statements of functional and quality-of-service requirements) and design factors (representations of abstract design knowledge) by means of automated composition, refinement, and analysis.", "num_citations": "2\n", "authors": ["1702"]}
{"title": "Automatic Synthesis of Planners and Schedulers..\n", "abstract": " This report describes our research on the transformational development of transportation plans and schedules. Our approach to developing scheduling software involves several stages. The first step is to develop a formal model of the transportation scheduling domain, called a domain theory. Second, the constraints, objectives, and preferences of a particular scheduling problem are stated within a domain theory as a problem specification. Finally, an executable scheduler is produced semi-automatically by applying a sequence of transformations to the problem specification. The transformations embody programming knowledge about algorithms, data structures, program optimization techniques, etc. The result of the transformation process is executable code that is consistent with the given problem specification. Furthermore, the resulting code can be extremely efficient.Descriptors:", "num_citations": "2\n", "authors": ["1702"]}
{"title": "A transformational approach applied to outage management of nuclear power plants\n", "abstract": " We report on a successful project for transference of advanced planning and scheduling technology for outage management, a collaboration between Rome Laboratory, the Electrical Power Research Institute, Kaman Science, and Kestrel Institute, as part of DOD's dual use program. The main goal of the project was to evaluate the use of transformational approaches and AI technology to solve real world planning and scheduling problems involving complex constraints. ROMAN (Rome Lab Outage Manager) is the prototype system that was developed as a result of this project. ROMAN's main innovation compared to the current state of the art outage management tools is its integrated approach to outage management automatically enforcing safety constraints during the planning and scheduling phase. Another innovative aspect of ROMAN is its generation of more robust schedules that are feasible over time\u00a0\u2026", "num_citations": "2\n", "authors": ["1702"]}
{"title": "Performance estimation for a knowledge-based software assistant\n", "abstract": " The long-term goal of a Performance Estimator Assistant (PEA) is to aid in the creation and maintenance of programs that meet their performance requirements or are generally efficient in their use of computational resources. The principal function of the PEA is to guide implementation decisions that will effect the ultimate performance of the system by generating and reasoning about performance estimates for expressions ranging from very high-level specifications to low-level code. The short-term goals for PEA capabilities are identified as symbolic evaluation, data structure analysis and advice, and subroutine and module decomposition advice. (Author)", "num_citations": "2\n", "authors": ["1702"]}
{"title": "Vulnerabilities in bytecode removed by analysis, nuanced confinement and diversification (VIBRANCE)\n", "abstract": " The VIBRANCE tool starts with a vulnerable Java application and automatically hardens it against SQL injection, OS command injection, file path traversal, numeric errors, denial of service, and other attacks. For a large class of attacks, the protection added by VIBRANCE blocks the attacks and safely continues execution.Descriptors:", "num_citations": "1\n", "authors": ["1702"]}
{"title": "Handling uncertainty in job-shop scheduling\n", "abstract": " We discuss our proposed approach to handling uncertainty and constraints in job-shop scheduling. Specifically we deal with uncertainty in the duration of a task, as well as constraints on task completion time, task separation, etc. We discuss both offline and adaptive scheduling strategies. Our approach is to synthesize fast schedulers that handle uncertainty by calculating them from formal specifications.", "num_citations": "1\n", "authors": ["1702"]}
{"title": "Specification-Carrying Software: Evolving Specifications for Dynamic System Composition\n", "abstract": " EPOXI Evolutionary Programming Over Explicit Interfaces builds on the advanced mathematical foundation to enable the design and evolution of large-scale, heterogeneous, distributed, time-critical systems. The guiding philosophy of EPOXI is refinement of requirement specifications into code that is correct by construction. EPOXI emphasizes the support for design operations that establish or preserve required properties of the target system software. Refinement and coordination of changes to the software system were by means of formal change specifications, propagation of constraints through an architecture, gauges to measure component compliance and synthesis of glue-code to assure complianceinteroperability.Descriptors:", "num_citations": "1\n", "authors": ["1702"]}
{"title": "Generic Tools for Transportation Planning and Scheduling.\n", "abstract": " This report describes our research on transportation planning and scheduling supported by the ARPARome Lab Planning Initiative ARPI. The main goal of this project was to develop generic tools to support the construction of flexible, high-performance planning and scheduling software. Our technical approach is based on program transformation technology that allow the systematic machine-supported development of software from requirement specifications. The development process can produce highly efficient code along with a proof of the code1s correctness. We have used KIDS Kestrel Interactive Development System to derive extremely fast and accurate transportation schedulers from formal specifications. As test data, we use strategic transportation plans that are generated by US government planners. A typical problem with 1O, OOO movement requirements takes the derived scheduler 1-3 minutes to solve compared with 2.5 hours for a deployed feasibility estimator JFAST and 36 hours fbr deployed schedulers FLOGEN, ADANS. The computed schedules use relatively few resources and satisfy all specified constraints. The speed of this scheduler is due to the synthesis of strong constraint checking and constraint propagation code.Descriptors:", "num_citations": "1\n", "authors": ["1702"]}
{"title": "Another proof of the modularization theorem\n", "abstract": " Proof: The trick is to create an injective variant of g, called g\u2217, by requiring that g\u2217= g except when g maps two symbols p, q to the same symbol, in which case g\u2217 maps p and q to fresh symbols. The effect of identifying p and q can be added back in via an axiom of the form p= q; ie the identities in Id (g). g (J)\u22a3 g (\u03c6)=\u21d2 see above g\u2217(J) J g\u2217(Id (g))\u22a3 g\u2217(\u03c6)=\u21d2 applying Proposition 1 g\u2217\u2212 1 (g\u2217(J) J g\u2217(Id (g)))\u22a3 g\u2217\u2212 1 (g\u2217(\u03c6))\u2261 simplifying", "num_citations": "1\n", "authors": ["1702"]}
{"title": "A theoretical basis for software evolution\n", "abstract": " We describe an approach to software evolution that uses the same tools and techniques that have been successfully used in the transformational development of software (eg, in KIDS [Smith 90]). We obtain an integrated view of software development and evolution by considering what is preserved and what is changed by each process. Software development is a sequence of transformations which preserve functionality but usually change some intensional property such as performance. Software evolution is a dual process in which\" evolution\" transformations change functionality but preserve properties such as well-formedness and internal consistency.", "num_citations": "1\n", "authors": ["1702"]}
{"title": "Representation of Discrete Optimization Problems by Discrete Dynamic Programs.\n", "abstract": " This paper investigates the conditions under which a discrete optimization problem can be formulated as a dynamic program. Following the terminology of Karp and Held 1967, a discrete optimization problem is formalized as a discrete decision problem and the class of dynamic programs is formalized as a sequential decision process. Necessary and sufficient conditions for the representation in two different senses of a discrete decision problem by a sequential decision process are established. In the first sense a strong representation the set of all optimal solutions to the discrete optimization problem is obtainable from the solution of the functional equations of dynamic programming. In the second sense a weak representation a nonempty subset of optimal solutions is obtainable from the solution of the functional equations of dynamic programming. It is shown that the well known principle of optimality corresponds to a strong representation. A more general version of the principle of optimality is given which corresponds to a weak representation of a discrete decision problem by a sequential decision process. We also show that the class of strongly representable discrete decision problems is equivalent to the class of sequential decision processes which have cost functions satisfying a strict monotonicity condition. Also a new derivation is given of the result that the class of weakly representable discrete decision problems is equivalent to the class of sequential decision processes which have a cost function satisfying a monotonicity condition. AuthorDescriptors:", "num_citations": "1\n", "authors": ["1702"]}
{"title": "The rejected medical school applicant: sex differences in attitudes and outcomes.\n", "abstract": " The rejected medical school applicant: sex differences in attitudes and outcomes. - Abstract - Europe PMC Sign in or create an account https://orcid.org Europe PMC Menu About About Europe PMC Preprints in Europe PMC Funders Joining Europe PMC Governance Roadmap Outreach Tools Tools overview ORCID article claiming Journal list Grant finder External links service RSS feeds Annotations Annotations submission service Developers Developer resources Articles RESTful API Grants RESTful API API use cases SOAP web service Annotations API OAI service Bulk downloads Developers Forum Help Help using Europe PMC Search syntax reference Contact us Contact us Helpdesk Feedback Twitter Blog Tech blog Developer Forum Europe PMC plus Search worldwide, life-sciences literature Search Advanced Search Recent history Saved searches Abstract The rejected medical school applicant: sex \u2026", "num_citations": "1\n", "authors": ["1702"]}
{"title": "Phytoremediation: harvesting toxic or unwanted, materials\n", "abstract": " The idea to take full advantage of different organisms to benefit human desires defines, in a simplistic manner, the ideology of agroecology. Agroecology in terms of this paper is an ideal that incorporates a wide variety of sciences including crop science, soil science, weed science as well as entomology, microbiology, and even geography. With the understanding of the biology, life history, and physiology of different organisms, and how those organisms interact with respect to other organisms, as well as the environment in which they live, a person may then find beneficial uses for those organisms. Case in point, phytoremediation.Phytoremediation is the use of certain plants to withdrawal chemicals, compounds, and heavy metals from the soil. Knowledge of these plants, and specifically their biology, has allowed for innovative techniques to reclaim contaminated soil sites. Not all plants have the same capability to\u00a0\u2026", "num_citations": "1\n", "authors": ["1702"]}