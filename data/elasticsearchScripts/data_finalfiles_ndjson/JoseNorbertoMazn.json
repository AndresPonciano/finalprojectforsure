{"title": "An MDA approach for the development of data warehouses\n", "abstract": " Different modeling approaches have been proposed to overcome every design pitfall of different data warehouse (DW) components. However, most of them offer partial solutions that deal only with isolated aspects of the DW and do not provide developers with an integrated and standard framework for designing all DW relevant components, such as ETL processes, data sources, DW repository and so on. To overcome this problem, this paper describes how to align the whole DW development process with a Model Driven Architecture (MDA) framework. We then focus on describing one part of it: an MDA approach for the development of the DW repository, because it is the cornerstone of any DW system. Therefore, we describe how to build the different MDA models for the DW repository by using an extension of the Unified Modeling Language (UML) and the Common Warehouse Metamodel (CWM). Transformations\u00a0\u2026", "num_citations": "248\n", "authors": ["582"]}
{"title": "Smart destinations and the evolution of ICTs: a new scenario for destination management?\n", "abstract": " The impact of information and communication technologies (ICTs) on tourism and their foreseeable future evolution seem to be shaping a new scenario for destination management. This new context has given rise to the need for new management models. One of these models is the emerging smart tourism destination (STD), although it requires greater conceptual precision in order to become a new paradigm for destination management. This paper proposes a systemic model for STDs which facilitates the interpretation of the role of ICTs in the management of tourism destinations. Accordingly, the Delphi technique has been applied so as to determine the opinion of experts regarding the feasibility of the STD approach, its advantages and limitations and also the size of the impact of ICTs on the management and marketing of tourism destinations. This prospective exercise highlights the intensification of the impact of\u00a0\u2026", "num_citations": "192\n", "authors": ["582"]}
{"title": "A model-driven goal-oriented requirement engineering approach for data warehouses\n", "abstract": " The development of a data warehouse has been traditionally guided by an in-depth analysis of the underlying operational data sources, thus overlooking an explicit development phase in which information requirements of decision makers are addressed. This scenario has prompted that the deployed data warehouse often fails in delivering the expected support of the decision making process. To overcome this problem, we propose to use the i* modeling framework and the model driven architecture (MDA) in order to describe (i) how to model goals and information requirements for data warehouses, and (ii) how to derive a conceptual multidimensional model that provides the required information to support the decision making process.", "num_citations": "192\n", "authors": ["582"]}
{"title": "Fusion cubes: Towards self-service business intelligence\n", "abstract": " Self-service business intelligence is about enabling non-expert users to make well-informed decisions by enriching the decision process with situational data, ie, data that have a narrow focus on a specific business problem and, typically, a short lifespan for a small group of users. Often, these data are not owned and controlled by the decision maker; their search, extraction, integration, and storage for reuse or sharing should be accomplished by decision makers without any intervention by designers or programmers. The goal of this paper is to present the framework we envision to support self-service business intelligence and the related research challenges; the underlying core idea is the notion of fusion cubes, ie, multidimensional cubes that can be dynamically extended both in their schema and their instances, and in which situational data and metadata are associated with quality and provenance annotations.", "num_citations": "155\n", "authors": ["582"]}
{"title": "Reconciling requirement-driven data warehouses with data sources via multidimensional normal forms\n", "abstract": " Successful data warehouse (DW) design needs to be based upon a requirement analysis phase in order to adequately represent the information needs of DW users. Moreover, since the DW integrates the information provided by data sources, it is also crucial to take these sources into account throughout the development process to obtain a consistent reconciliation of data sources and information needs. In this paper, we start by summarizing our approach to specify user requirements for data warehouses and to obtain a conceptual multidimensional model capturing these requirements. Then, we make use of the multidimensional normal forms to define a set of Query/View/Transformation (QVT) relations to assure that the conceptual multidimensional model obtained from user requirements agrees with the available data sources that will populate the DW. Thus, we propose a hybrid approach to develop DWs, i.e\u00a0\u2026", "num_citations": "146\n", "authors": ["582"]}
{"title": "A survey on summarizability issues in multidimensional modeling\n", "abstract": " The development of a data warehouse (DW) system is based on a conceptual multidimensional model, which provides a high level of abstraction in accurately and expressively describing real-world situations. Once this model is designed, the corresponding logical representation must be obtained as the basis of the implementation of the DW according to one specific technology. However, even though a good conceptual multidimensional model is designed underneath a DW, there is a semantic gap between this model and its logical representation. In particular, this gap complicates an adequate treatment of summarizability issues, which in turn may lead to erroneous results of data analysis tools. Research addressing this topic has produced only partial solutions, and individual terminology used by different parties hinders further progress. Consequently, based on a unifying vocabulary, this survey sheds light on (i\u00a0\u2026", "num_citations": "134\n", "authors": ["582"]}
{"title": "BPMN-based conceptual modeling of ETL processes\n", "abstract": " Business Intelligence (BI) solutions require the design and implementation of complex processes (denoted ETL) that extract, transform, and load data from the sources to a common repository. New applications, like for example, real-time data warehousing, require agile and flexible tools that allow BI users to take timely decisions based on extremely up-to-date data. This calls for new ETL tools able to adapt to constant changes and quickly produce and modify executable code. A way to achieve this is to make ETL processes become aware of the business processes in the organization, in order to easily identify which data are required, and when and how to load them in the data warehouse. Therefore, we propose to model ETL processes using the standard representation mechanism denoted BPMN (Business Process Modeling and Notation). In this paper we present a BPMN-based metamodel for\u00a0\u2026", "num_citations": "92\n", "authors": ["582"]}
{"title": "Automatic generation of ETL processes from conceptual models\n", "abstract": " Data warehouses (DW) integrate different data sources in order to give a multidimensional view of them to the decision-maker. To this aim, the ETL (Extraction, Transformation and Load) processes are responsible for extracting data from heterogeneous operational data sources, their transformation (conversion, cleaning, standardization, etc.), and its load in the DW. In recent years, several conceptual modeling approaches have been proposed for designing ETL processes. Although these approaches are very useful for documenting ETL processes and supporting the designer tasks, these proposals fail to give mechanisms to carry out an automatic code generation stage. Such a stage should be required to both avoid fails and save development time in the implementation of complex ETL process. Therefore, in this paper we define an approach for the automatic code generation of ETL processes. To this aim, we\u00a0\u2026", "num_citations": "88\n", "authors": ["582"]}
{"title": "A model-driven framework for ETL process development\n", "abstract": " ETL processes are the backbone component of a data warehouse, since they supply the data warehouse with the necessary integrated and reconciled data from heterogeneous and distributed data sources. However, the ETL process development, and particularly its design phase, is still perceived as a time-consuming task. This is mainly due to the fact that ETL processes are typically designed by considering a specific technology from the very beginning of the development process. Thus, it is difficult to share and reuse methodologies and best practices among projects implemented with different technologies. To the best of our knowledge, no attempt has been yet dedicated to harmonize the ETL process development by proposing a common and integrated development strategy. To overcome this drawback, in this paper, a framework for model-driven development of ETL processes is introduced. The benefit of\u00a0\u2026", "num_citations": "81\n", "authors": ["582"]}
{"title": "A hybrid model driven development framework for the multidimensional modeling of data warehouses!\n", "abstract": " Developing a multidimensional (MD) model of a data warehouse (DW) is a highly complex, prone to fail, and time consuming task, due to the fact that (i) the information needs of decision makers and the available operational data sources that will populate the DW must both be considered in a conceptual MD model, and (ii) complex mappings must be performed to obtain an implementation of this conceptual MD model. However, no significant effort has been made to take these issues into account in a systematic, well structured and comprehensive development process. To overcome the lack of such a process, a framework based on the Model Driven Architecture (MDA) is proposed for the development of a hybrid MD model at the conceptual level and for the automatic derivation of its logical representation. Also, a running example is shown throughout this paper.", "num_citations": "66\n", "authors": ["582"]}
{"title": "Using ontologies for the design of data warehouses\n", "abstract": " Obtaining an implementation of a data warehouse is a complex task that forces designers to acquire wide knowledge of the domain, thus requiring a high level of expertise and becoming it a prone-to-fail task. Based on our experience, we have detected a set of situations we have faced up with in real-world projects in which we believe that the use of ontologies will improve several aspects of the design of data warehouses. The aim of this article is to describe several shortcomings of current data warehouse design approaches and discuss the benefit of using ontologies to overcome them. This work is a starting point for discussing the convenience of using ontologies in data warehouse design.", "num_citations": "63\n", "authors": ["582"]}
{"title": "Extending OCL for OLAP querying on conceptual multidimensional models of data warehouses\n", "abstract": " The development of data warehouses begins with the definition of multidimensional models at the conceptual level in order to structure data, which will facilitate decision makers with an easier data analysis. Current proposals for conceptual multidimensional modelling focus on the design of static data warehouse structures, but few approaches model the queries which the data warehouse should support by means of OLAP (on-line analytical processing) tools. OLAP queries are, therefore, only defined once the rest of the data warehouse has been implemented, which prevents designers from verifying from the very beginning of the development whether the decision maker will be able to obtain the required information from the data warehouse. This article presents a solution to this drawback consisting of an extension to the object constraint language (OCL), which has been developed to include a set of predefined\u00a0\u2026", "num_citations": "62\n", "authors": ["582"]}
{"title": "Modelling ETL processes of data warehouses with UML activity diagrams\n", "abstract": " Extraction-transformation-loading (ETL) processes play an important role in a data warehouse (DW) architecture because they are responsible of integrating data from heterogeneous data sources into the DW repository. Importantly, most of the budget of a DW project is spent on designing these processes since they are not taken into account in the early phases of the project but once the repository is deployed. In order to overcome this situation, we propose using the unified modelling language (UML) to conceptually model the sequence of activities involved in ETL processes from the beginning of the project by using activity diagrams (ADs). Our approach provides designers with easy-to-use modelling elements to capture the dynamic aspects of ETL processes.", "num_citations": "61\n", "authors": ["582"]}
{"title": "La influencia de las redes sociales en el aprendizaje colaborativo\n", "abstract": " Actualmente las redes sociales representan un mecanismo para que un conjunto de personas puedan potenciar su comunicaci\u00f3n, cooperar entre ellas en tareas comunes y sentirse parte de una comunidad. Estas caracter\u00edsticas hacen pensar que su uso ser\u00eda conveniente en entornos educativos con el fin de potenciar diversos aspectos como: participaci\u00f3n del alumnado en el proceso de aprendizaje, aprendizaje aut\u00f3nomo, interacci\u00f3n y motivaci\u00f3n de los alumnos, creatividad del estudiante y la creaci\u00f3n de redes de colaboraci\u00f3n e intercambio con continuidad espacio-temporal. Sin embargo, el uso de redes sociales en la docencia universitaria, plantea diversas cuestiones: \u00bffavorece el uso de las redes sociales el trabajo colaborativo?, \u00bfinteract\u00faan los estudiantes para mejorar el aprendizaje?, \u00bfes un mecanismo apropiado para mejorar la comunicaci\u00f3n?, \u00bfse desarrollan nuevos roles del profesor o estudiante?. En este art\u00edculo se pretenden resolver estas cuestiones y estudiar el impacto de las redes sociales, en concreto Facebook, en la ense\u00f1anza universitaria", "num_citations": "58\n", "authors": ["582"]}
{"title": "Towards comprehensive requirement analysis for data warehouses: Considering security requirements\n", "abstract": " Data warehouse (DW) systems integrate data from heterogeneous sources and are used by decision makers to analyze the status and the development of an organization. Traditionally, requirement analysis approaches for DWs have focused purely on information needs of decision makers, without considering other kinds of requirements such as security or performance. But modeling these issues in the early stages of the development is a cornerstone for building a DW that satisfies user expectations. In this paper, we define the two kinds of requirements for data warehousing as information and quality-of-service requirements and combine them in a comprehensive approach based on MDA (model driven architecture). This allows a separation of concerns to model requirements without losing the connection between information and quality-of-service, also in the following conceptual or logical design stages. Finally\u00a0\u2026", "num_citations": "57\n", "authors": ["582"]}
{"title": "Ten Years of Rich Internet Applications: A Systematic Mapping Study, and Beyond\n", "abstract": " BACKGROUND. The term Rich Internet Applications (RIAs) is generally associated with Web applications that provide the features and functionality of traditional desktop applications. Ten years after the introduction of the term, an ample amount of research has been carried out to study various aspects of RIAs. It has thus become essential to summarize this research and provide an adequate overview. OBJECTIVE. The objective of our study is to assemble, classify, and analyze all RIA research performed in the scientific community, thus providing a consolidated overview thereof, and to identify well-established topics, trends, and open research issues. Additionally, we provide a qualitative discussion of the most interesting findings. This work therefore serves as a reference work for beginning and established RIA researchers alike, as well as for industrial actors that need an introduction in the field, or seek pointers to\u00a0\u2026", "num_citations": "55\n", "authors": ["582"]}
{"title": "A conceptual modeling approach for OLAP personalization\n", "abstract": " Data warehouses rely on multidimensional models in order to provide decision makers with appropriate structures to intuitively analyze data with OLAP technologies. However, data warehouses may be potentially large and multidimensional structures become increasingly complex to be understood at a glance. Even if a departmental data warehouse (also known as data mart) is used, these structures would be also too complex. As a consequence, acquiring the required information is more costly than expected and decision makers using OLAP tools may get frustrated. In this context, current approaches for data warehouse design are focused on deriving a unique OLAP schema for all analysts from their previously stated information requirements, which is not enough to lighten the complexity of the decision making process. To overcome this drawback, we argue for personalizing multidimensional models\u00a0\u2026", "num_citations": "47\n", "authors": ["582"]}
{"title": "A personalization process for spatial data warehouse development\n", "abstract": " Spatial data warehouses (SDW) rely on extended multidimensional (MD) models in order to provide decision makers with appropriate structures to intuitively explore spatial data by using different analysis techniques such as OLAP (On-Line Analytical Processing) or data mining. Current development approaches are focused on defining a unique and static Spatial multidimensional (SMD) schema at the conceptual level over which all decision makers fulfill their current spatial information needs. However, considering the required spatiality for each decision maker is likely to derive in a potentially misleading SMD schema (even if a departmental DW or data mart is being defined). Furthermore, spatial needs of each decision maker could change over time or depending on the context, thus requiring the SMD schema to be continuously updated with changes that can hamper decision making. Therefore, if a unique and\u00a0\u2026", "num_citations": "44\n", "authors": ["582"]}
{"title": "A BPMN-based design and maintenance framework for ETL processes\n", "abstract": " Business Intelligence (BI) applications require the design, implementation, and maintenance of processes that extract, transform, and load suitable data for analysis. The development of these processes (known as ETL) is an inherently complex problem that is typically costly and time consuming. In a previous work, the authors have proposed a vendor-independent language for reducing the design complexity due to disparate ETL languages tailored to specific design tools with steep learning curves. Nevertheless, the designer still faces two major issues during the development of ETL processes:(i) how to implement the designed processes in an executable language, and (ii) how to maintain the implementation when the organization data infrastructure evolves. In this paper, the authors propose a model-driven framework that provides automatic code generation capability and ameliorate maintenance support of our\u00a0\u2026", "num_citations": "42\n", "authors": ["582"]}
{"title": "An MDA Approach for Goal-oriented Requirement Analysis in Web Engineering.\n", "abstract": " Web designers usually ignore how to model real user expectations and goals, mainly due to the large and heterogeneous audience of the Web. This fact leads to websites which are difficult to comprehend by visitors and complex to maintain by designers. In order to ameliorate this scenario, an approach for using the i* modeling framework in Web engineering has been developed in this paper. Furthermore, due to the fact that most of the existing Web engineering approaches do not consider how to derive conceptual models of the Web application from requirements analysis we also propose the use of MDA (Model Driven Architecture) in Web engineering for:(i) the definition of the requirements of a Web application in a Computational Independent Model (CIM),(ii) the description of Platform Independent Models (PIMs), and (iii) the definition of a set of QVT (Query/View/Transformation) transformations for the\u00a0\u2026", "num_citations": "41\n", "authors": ["582"]}
{"title": "A requirement analysis approach for using i* in web engineering\n", "abstract": " Web designers usually ignore how to model real user expectations and goals, mainly due to the large and heterogeneous audience of the Web. This fact leads to websites which are difficult to comprehend by visitors and complex to maintain by designers. In order to ameliorate this scenario, an approach for using the i* modeling framework in Web engineering has been developed in this paper. Furthermore, we also present a traceability approach for obtaining different kind of design artifacts tailored to a specific Web modeling method. Finally, we include a sample of our approach in order to show its applicability and we describe a prototype tool as a proof of concept of our research.", "num_citations": "40\n", "authors": ["582"]}
{"title": "ETL process modeling conceptual for data warehouses: a systematic mapping study\n", "abstract": " BACKGROUND: A data warehouse (DW) is an integrated collection of subject-oriented data in the support of decision making. Importantly, the integration of data sources is achieved through the use of ETL (Extract, Transform, and Load) processes. It is therefore extensively recognized that the appropriate design of the ETL processes are key factors in the success of DW projects. OBJECTIVE: We assess existing research proposals about ETL process modeling for data warehouse in order to identify their main characteristics, notation, and activities. We also study if these modeling approaches are supported by some kind of prototype or tool. METHOD: We have undertaken a systematic mapping study of the research literature about modeling ETL processes. A mapping study provides a systematic and objective procedure for identifying the nature and extent of the available research by means of research questions\u00a0\u2026", "num_citations": "39\n", "authors": ["582"]}
{"title": "A model driven modernization approach for automatically deriving multidimensional models in data warehouses\n", "abstract": " Data warehouses integrate several operational sources to provide a multidimensional (MD) analysis of data. Therefore, the development of a data warehouse claims for an in-depth analysis of these data sources. Several approaches have been presented to obtain multidimensional structures from data sources in order to guide this development. However, these approaches assume that a wide documentation of the data sources is available and only provide informal guidelines to support the discovery of MD elements. Therefore, this task may become highly difficult for complex and large data sources (e.g. legacy systems). To overcome these problems, we consider the development of the data warehouse as a modernization scenario that addresses the analysis of the available data sources, thus discovering MD structures to either derive a data-driven conceptual MD model or reconcile a requirement-driven\u00a0\u2026", "num_citations": "39\n", "authors": ["582"]}
{"title": "A family of experiments to validate measures for UML activity diagrams of ETL processes in data warehouses\n", "abstract": " In data warehousing, Extract, Transform, and Load (ETL) processes are in charge of extracting the data from the data sources that will be contained in the data warehouse. Their design and maintenance is thus a cornerstone in any data warehouse development project. Due to their relevance, the quality of these processes should be formally assessed early in the development in order to avoid populating the data warehouse with incorrect data. To this end, this paper presents a set of measures with which to evaluate the structural complexity of ETL process models at the conceptual level. This study is, moreover, accompanied by the application of formal frameworks and a family of experiments whose aim is to theoretical and empirically validate the proposed measures, respectively. Our experiments show that the use of these measures can aid designers to predict the effort associated with the maintenance tasks of\u00a0\u2026", "num_citations": "38\n", "authors": ["582"]}
{"title": "Solving summarizability problems in fact-dimension relationships for multidimensional models\n", "abstract": " Multidimensional analysis allows decision makers to efficiently and effectively use data analysis tools, which mainly depend on multidimensional (MD) structures of a data warehouse such as facts and dimension hierarchies to explore the information and aggregate it at different levels of detail in an accurate way. A conceptual model of such MD structures serves as abstract basis of the subsequent implementation according to one specific technology. However, there is a semantic gap between a conceptual model and its implementation which complicates an adequate treatment of summarizability issues, which in turn may lead to erroneous results of data analysis tools and cause the failure of the whole data warehouse project. To bridge this gap for relationships between facts and dimension, we present an approach at the conceptual level for (i) identifying problematic situations in fact-dimension relationships,(ii\u00a0\u2026", "num_citations": "36\n", "authors": ["582"]}
{"title": "A business-oriented approach to data warehouse development\n", "abstract": " Several surveys have indicated that many data warehouses fail to meet business objectives or are outright failures. One reason for this is that requirement engineering is typically overlooked in real projects. This paper addresses data warehouse design from a business perspective by highlighting business strategy analysis, alignment between data warehouse objectives and a firm's strategy, goal-oriented information requirements' modelling and how an underlying multidimensional data warehouse model may be derived. A set of guidelines is provided allowing developers to design a data warehouse aligned with a prevailing business strategy. A classic case study is presented.", "num_citations": "35\n", "authors": ["582"]}
{"title": "A model-driven heuristic approach for detecting multidimensional facts in relational data sources\n", "abstract": " Facts are multidimensional concepts of primary interests for knowledge workers because they are related to events occurring dynamically in an organization. Normally, these concepts are modeled in operational data sources as tables. Thus, one of the main steps in conceptual design of a data warehouse is to detect the tables that model facts. However, this task may require a high level of expertise in the application domain, and is often tedious and time-consuming for designers. To overcome these problems, a comprehensive model-driven approach is presented in this paper to support designers in: (1) obtaining a CWM model of business-related relational tables, (2) determining which elements of this model can be considered as facts, and (3) deriving their counterparts in a multidimensional schema. Several heuristics \u2013based on structural information derived from data sources\u2013 have been defined to this\u00a0\u2026", "num_citations": "30\n", "authors": ["582"]}
{"title": "A set of QVT relations to assure the correctness of data warehouses by using multidimensional normal forms\n", "abstract": " It is widely accepted that a requirement analysis phase is necessary to develop data warehouses (DWs) which adequately represent the information needs of DW users. Moreover, since the DW integrates the information provided by data sources, it is also crucial to take these sources into account throughout the development process to obtain a consistent representation. In this paper, we use multidimensional normal forms to define a set of Query/View/Transformation (QVT) relations to assure that the DW designed from user requirements agrees with the available data sources that will populate the DW. Thus, we propose a hybrid approach to develop DWs, i.e., we firstly obtain the conceptual schema of the DW from user requirements and then we verify and enforce its correctness against data sources by using a set of QVT relations based on multidimensional normal forms.", "num_citations": "30\n", "authors": ["582"]}
{"title": "Open business intelligence: on the importance of data quality awareness in user-friendly data mining\n", "abstract": " Citizens demand more and more data for making decisions in their daily life. Therefore, mechanisms that allow citizens to understand and analyze linked open data (LOD) in a user-friendly manner are highly required. To this aim, the concept of Open Business Intelligence (OpenBI) is introduced in this position paper. OpenBI facilitates non-expert users to (i) analyze and visualize LOD, thus generating actionable information by means of reporting, OLAP analysis, dashboards or data mining; and to (ii) share the new acquired information as LOD to be reused by anyone. One of the most challenging issues of OpenBI is related to data mining, since non-experts (as citizens) need guidance during preprocessing and application of mining algorithms due to the complexity of the mining process and the low quality of the data sources. This is even worst when dealing with LOD, not only because of the different kind of links\u00a0\u2026", "num_citations": "28\n", "authors": ["582"]}
{"title": "Bridging the semantic gap in OLAP models: platform-independent queries\n", "abstract": " The development of data warehouses is based on a three-stage process that starts specifying both the static and dynamic properties of on-line analytical processing (OLAP) applications by means of an intuitive, semantically rich abstraction, namely the conceptual model. Then, developers design its logical counterpart where platform-specific details such as performance or storage are also considered. Nevertheless, it is well known the existence of a semantic gap between the conceptual and logical levels that decreases the feasibility of their mapping. In order to bridge this gap, we propose the use of conceptual OLAP queries, ie, platform-independent, that can be automatically traced to their logical implementation in a coherent and integrated way. For this aim, in this paper, we focus on describing the specification of an OLAP algebra at the conceptual level by using the object-constraint language (OCL). Its\u00a0\u2026", "num_citations": "28\n", "authors": ["582"]}
{"title": "Model-driven metadata for OLAP cubes from the conceptual modelling of data warehouses\n", "abstract": " The development of a data warehouse is based on the definition of a conceptual multidimensional model. This model is used to obtain the required database metadata for implementing the data- warehouse repository. Surprisingly, current approaches for multidimensional modelling overlook the necessity of generating additional data-cube metadata to allow end-user tools to query the data warehouse. To overcome this situation, we propose an approach based on \u201cmodel-driven engineering\u201d techniques in order to automatically derive both kinds of metadata in a systematic and integrated way. Specifically, in this paper, we describe how to obtain the data-cube metadata for \u201con-line analytical processing\u201d (OLAP) tools. As a proof of concept, our approach has been implemented in the Eclipse development platform, thus showing its feasibility.", "num_citations": "25\n", "authors": ["582"]}
{"title": "Smart Tourism. Un estudio de mapeo sistem\u00e1tico\n", "abstract": " El concepto turismo inteligente o \u201cSmart Tourism\u201d se ha convertido en un t\u00e9rmino de moda ampliamente utilizado por investigadores y profesionales de distintas disciplinas. No obstante, es un concepto que contiene distintos interrogantes que deben ser resueltos para avanzar en el conocimiento cient\u00edfico del tema. Con esta motivaci\u00f3n, este art\u00edculo contabiliza y categoriza la producci\u00f3n cient\u00edfica asociada, aplicando un estudio de mapeo sistem\u00e1tico, novedoso en el \u00e1mbito del turismo. Los resultados obtenidos se combinan para dar respuesta a un conjunto de preguntas de investigaci\u00f3n, siguiendo para ello una estrategia o protocolo fundamentado en un proceso sistem\u00e1tico de revisi\u00f3n de la producci\u00f3n cient\u00edfica.", "num_citations": "24\n", "authors": ["582"]}
{"title": "Open Data y turismo. Implicaciones para la gesti\u00f3n tur\u00edstica en ciudades y destinos tur\u00edsticos inteligentes\n", "abstract": " La irrupci\u00f3n de Internet y el progresivo despliegue de las tecnolog\u00edas de la informaci\u00f3n y comunicaci\u00f3n (TIC), ha generado interesantes oportunidades para la planificaci\u00f3n y gesti\u00f3n de las ciudades y destinos tur\u00edsticos del siglo XXI. En este escenario, los entornos urbanos producen una gran cantidad de datos como consecuencia directa del uso intensivo de las TIC. Este trabajo se aproxima al concepto de Open Data desde dos hip\u00f3tesis. Por una parte, que su aplicaci\u00f3n en el \u00e1mbito del turismo puede generar un ecosistema innovador que mejore la experiencia tur\u00edstica, gracias al dise\u00f1o de productos y servicios TIC. Y por otra, que su grado actual de aplicaci\u00f3n en turismo es bajo y necesita de medidas de apoyo. Con el fin de corroborarlas, se plantean dos objetivos. En primer lugar, y desde una vertiente te\u00f3rico-conceptual, profundizar en la terminolog\u00eda de Open Data, conceptos relacionados y sus implicaciones para la gesti\u00f3n tur\u00edstica. En segundo lugar, conocer su grado de aplicaci\u00f3n actual en el turismo, para proponer recomendaciones que favorezcan su uso. Con este fin, se analizan los conjuntos de datos abiertos en turismo de las ciudades de la Red Espa\u00f1ola de Ciudades Inteligentes (RECI). Este trabajo constituye un punto de partida en la investigaci\u00f3n de las relaciones entre Open Data y turismo.", "num_citations": "22\n", "authors": ["582"]}
{"title": "The university as an open data ecosystem\n", "abstract": " Lately, the University of Alicante (Spain) started the OpenData4U project in order to create a methodology to easily develop open data portals for universities. Within this project, the open data portal of the University of Alicante was launched (http://datos.ua.es), which allowed us to develop a set of best practices in the implantation of an open data ecosystem for universities to foster reusing of Public Sector Information. The main aim of this paper is to describe our experience at the opening data process at the University of Alicante, as well as enumerating novel opportunities for social and economic impact in which a university could be a driving force.", "num_citations": "22\n", "authors": ["582"]}
{"title": "Enriching data warehouse dimension hierarchies by using semantic relations\n", "abstract": " Data warehouse dimension hierarchies are of paramount importance in OLAP (On-Line Analytical Processing) tools to support the decision-making process, since they allow the analysis of data at different levels of detail (i.e. levels of aggregation). This is why it is crucial to capture adequate hierarchies in the requirement analysis stage. However, operational sources may not be able to supply enough data to construct every level of these hierarchies. In this paper, we propose the application of semantic relations among WordNet concepts to enrich hierarchies by adding the required levels of aggregation. Decision makers will thus be able to achieve their information needs for analysis.", "num_citations": "22\n", "authors": ["582"]}
{"title": "Applying transformations to model driven data warehouses\n", "abstract": " In the past few years, several conceptual approaches have been proposed for the specification of the main multidimensional (MD) properties of the data warehouse (DW) repository. However, these approaches often fail in providing mechanisms to univocally and automatically derive a logical representation of the MD conceptual model. To overcome this limitation, we present an approach to align the MD modeling of the DW repository with the Model Driven Architecture (MDA) by formally defining a set of Query/View/Transformation (QVT) transformation rules which allow us to obtain a logical representation of the MD conceptual model in an automatic way. Finally, we show how to implement our approach in an MDA-compliant commercial tool.", "num_citations": "21\n", "authors": ["582"]}
{"title": "Dawara: An eclipse plugin for using i* on data warehouse requirement analysis\n", "abstract": " In this paper, we have extended the i* framework for data warehouses and we have combined it with our model driven architecture (MDA) framework for the development of data warehouses. Specifically, our framework establishes a set of formal transformations between a requirement model and a conceptual multidimensional model via the QVT (query/view/transformation) language. Such transformations assure the traceability between requirements and the necessary multidimensional elements, because the goal model conceptualizes why certain multidimensional elements are required by decision makers to satisfy their information needs. The main advantage is that the conceptual multidimensional model meets every goal and requirement defined in the requirement model. To support our approach, the profiling mechanism of the Unified Modeling Language (UML) has been used to adapt i* to the data\u00a0\u2026", "num_citations": "19\n", "authors": ["582"]}
{"title": "A goal-oriented approach for optimizing non-functional requirements in web applications\n", "abstract": " Web design methodologies should be able to provide a requirements analysis stage to consider the large and heterogeneous audience of Web applications. In this stage, non-functional requirements (NFRs) should be addressed in order to improve the quality of the Web application perceived by users. To this aim, different configurations of requirements could be implemented depending on the NFRs preferred by the Web user. Furthermore, prioritizing and making tradeoffs between NFRs is crucial for satisfying the audience of Web applications. Therefore, this work presents an algorithm based on the Pareto optimal approach to evaluate and select the optimal configuration of requirements for a Web application. To do this, the NFRs are maximized according to a priority list provided by the audience. Our approach is illustrated with a running example.", "num_citations": "17\n", "authors": ["582"]}
{"title": "Evaluating different i*-based approaches for selecting functional requirements while balancing and optimizing non-functional requirements: A controlled experiment\n", "abstract": " ContextA relevant question in requirements engineering is which set of functional requirements (FR) to prioritize and implement, while keeping non-functional requirements (NFR) balanced and optimized.ObjectiveWe aim to provide empirical evidence that requirement engineers may perform better at the task of selecting FRs while optimizing and balancing NFRs using an alternative (automated) i* post-processed model, compared to the original i* model.MethodWe performed a controlled experiment, designed to compare the original i* graphical notation, with our post-processed i* visualizations based on Pareto efficiency (a tabular and a radar chart visualization). Our experiment consisted of solving different exercises of various complexity for selecting FRs while balancing NFR. We considered the efficiency (time spent to correctly answer exercises), and the effectiveness (regarding time: time spent to solve\u00a0\u2026", "num_citations": "16\n", "authors": ["582"]}
{"title": "Towards a data quality model for open data portals\n", "abstract": " Data that can be reused and redistributed without any restriction is called Open Data. These two features make its quality can be greatly affected. To date, the most used quality criteria of Open Data are those established in the 5-Stars Model. This article aims to extend this model and corroborate the existence of specific quality criteria for Open Data and its corresponding measurement mechanisms. We propose a new Quality Model for Open Data portals which is exposed from two points of view: qualitative and quantitative. To illustrate the use of this model, we implemented a study case based on real open data about Municipality of Perez Zeledon in Costa Rica, which was evaluated with the qualitative model.", "num_citations": "16\n", "authors": ["582"]}
{"title": "Enabling non-expert users to apply data mining for bridging the big data divide\n", "abstract": " Non-expert users find complex to gain richer insights into the increasingly amount of available heterogeneous data, the so called big data. Advanced data analysis techniques, such as data mining, are difficult to apply due to the fact that (i) a great number of data mining algorithms can be applied to solve the same problem, and (ii) correctly applying data mining techniques always requires dealing with the inherent features of the data source. Therefore, we are attending a novel scenario in which non-experts are unable to take advantage of big data, while data mining experts do: the big data divide. In order to bridge this gap, we propose an approach to offer non-expert miners a tool that just by uploading their data sets, return them the more accurate mining pattern without dealing with algorithms or settings, thanks to the use of a data mining algorithm recommender. We also incorporate a previous task to help\u00a0\u2026", "num_citations": "16\n", "authors": ["582"]}
{"title": "Linked open data mining for democratization of big data\n", "abstract": " Data is everywhere, and non-expert users must be able to exploit it in order to extract knowledge, get insights and make well-informed decisions. The value of the discovered knowledge from big data could be of greater value if it is available for later consumption and reusing. In this paper, we present an infrastructure that allows non-expert users to (i) apply user-friendly data mining techniques on big data sources, and (ii) share results as Linked Open Data (LOD). The main contribution of this paper is an approach for democratizing big data through reusing the knowledge gained from data mining processes after being semantically annotated as LOD, then obtaining Linked Open Knowledge. Our work is based on a model-driven viewpoint in order to easily deal with the wide diversity of open data formats.", "num_citations": "15\n", "authors": ["582"]}
{"title": "Development of secure XML data warehouses with QVT\n", "abstract": " ContextData warehouses are systems which integrate heterogeneous sources to support the decision making process. Data from the Web is becoming increasingly more important as sources for these systems, which has motivated the extensive use of XML to facilitate data and metadata interchange among heterogeneous data sources from the Web and the data warehouse. However, the business information that data warehouses manage is highly sensitive and must, therefore, be carefully protected. Security is thus a key issue in the design of data warehouses, regardless of the implementation technology. It is important to note that the idiosyncrasy of the unstructured and semi-structured data requires particular security rules that have been specifically tailored to these systems in order to permit their particularities to be captured correctly. Unfortunately, although security issues have been considered in the\u00a0\u2026", "num_citations": "15\n", "authors": ["582"]}
{"title": "An MDA Approach and QVT Transformations for the Integrated Development of Goal-Oriented Data Warehouses and Data Marts\n", "abstract": " To customize a data warehouse, many organizations develop concrete data marts focused on a particular department or business process. However, the integrated development of these data marts is an open problem for many organizations due to the technical and organizational challenges involved during the design of these repositories as a complete solution. In this article, the authors present a design approach that employs user requirements to build both corporate data warehouses and data marts in an integrated manner. The approach links information requirements to specific data marts elicited by using goal-oriented requirement engineering, which are automatically translated into the implementation of corresponding data repositories by means of model-driven engineering techniques. The authors provide two UML profiles that integrate the design of both data warehouses and data marts and a set of QVT\u00a0\u2026", "num_citations": "15\n", "authors": ["582"]}
{"title": "Using web-based personalization on spatial data warehouses\n", "abstract": " Spatial data warehouses (SDW) rely on extended multidimensional (MD) models in order to provide decision makers with appropriate structures to intuitively analyse spatial data. Several SDW development approaches provide a conceptual modeling and some guidelines in order to obtain logical schemas. However, there are two main drawbacks (i) spatial modeling is still complex for providing each decision maker with their own information needs, and (ii) SDW may be potentially large and spatial structures become increasingly complex to be analysed at a glance. Thus, representing and acquiring the required spatial information is more costly than expected and decision makers may get frustrated during the analysis. On the other hand, Web Engineering address similar problems (heterogeneous audience, different data sources and increasing amount and complexity of information) by using personalization rules\u00a0\u2026", "num_citations": "15\n", "authors": ["582"]}
{"title": "Measures for ETL processes models in data warehouses\n", "abstract": " In data warehousing, ETL (Extract, Transform, and Load) processes take charge of extracting the data from data sources that would be contained in the data warehouse. Due to their relevance, the quality of these processes should be formally assessed since the early stages of development, in order to avoid making bad decisions as a result of incorrect data. In this paper, a set of measures to evaluate the structural complexity of ETL process models at conceptual level is presented. Moreover, this study is accompanied by four experiments whose aim is the empirical validation of the proposed measures. The main advantage of this approach is the early evaluation of ETL process models. This early evaluation support designers in their maintenance tasks. This proposal is based on UML (Unifield Modeling Language) activity diagrams for modeling ETL processes and the adoption of the FMESP (Framework for the\u00a0\u2026", "num_citations": "15\n", "authors": ["582"]}
{"title": "Systematic review and comparison of modeling ETL processes in data warehouse\n", "abstract": " In a Data Warehouse (DW), ETL processes (Extraction, Transformation, Load) are responsible for extracting, transforming and loading data from the data sources into the DW. A good design of these processes in the early stages of a DW project is essential to avoid making bad decisions as a result of incorrect data. In this paper, we apply the method of systematic review to identify, extract and analyze the main proposals on modeling conceptual ETL processes for DWs. The main proposals are identified and compared based on the features, activities and notation of ETL processes. Finally we conclude the study by reflecting on the approaches being studied and providing an updated framework for future research.", "num_citations": "14\n", "authors": ["582"]}
{"title": "Smart tourism. A study on systematic mapping\n", "abstract": " The emergence of the Internet and information and communication technologies (ICTs) has generated a revolution of the tourism industry (Buhalis and Law, 2008), modifying the way in which tourism products and services are distributed (Werthner and Klein, 1999), and the structure and strategy of the business (Porter, 2001). In the same way, the behaviour of tourists has modified thanks to their empowerment through ICTs. Now they have become both producers and consumers of experiences through the use of social networks and the different Web 2.0 platforms (Buhalis and Licata, 2002). Tourists are now hyper-connected and multichannel. They stay connected to their mobile devices and use TICs in all of the stages of their trip (Zheng Xiang, Magnini, and Fesenmaier, 2015; Buhalis and Foerste, 2014). In short, a new tourism scenario has emerged which must be adapted to. Within this context, destinations are faced with important challenges. Basically, the need to understand that the traditional way of offering and designing services and products has changed (Ivars-Baidal, Celdr\u00e1n-Bernabeu and Vera-Rebollo, 2017). Now, the digital tourist consumes and generates experiences thanks to co-creation processes which are supported by social networks, apps, inspiring videos, forums, online sales platforms or blogs, etc.(Buhalis and Amaranggana, 2015; Neuhofer, Buhalis, and Ladkin, 2015). In order to confront these conditioning factors, both destinations and tourism companies must implement permeable and modular action strategies by applying updated management approaches that are in tune with the evolution of traditional tourism\u00a0\u2026", "num_citations": "13\n", "authors": ["582"]}
{"title": "A set of experiments to consider data quality criteria in classification techniques for data mining\n", "abstract": " A successful data mining process depends on the data quality of the sources in order to obtain reliable knowledge. Therefore, preprocessing data is required for dealing with data quality criteria. However, preprocessing data has been traditionally seen as a time-consuming and non-trivial task since data quality criteria have to be considered without any guide about how they affect the data mining process. To overcome this situation, in this paper, we propose to analyze the data mining techniques to know the behavior of different data quality criteria on the sources and how they affects the results of the algorithms. To this aim, we have conducted a set of experiments to assess three data quality criteria: completeness, correlation and balance of data. This work is a first step towards considering, in a systematic and structured manner, data quality criteria for supporting and guiding data miners in obtaining\u00a0\u2026", "num_citations": "13\n", "authors": ["582"]}
{"title": "WITHDRAWN: Designing OLAP schemata for data warehouses from conceptual models with MDA\n", "abstract": " The development of data warehouses should be driven by technology-independent conceptual multidimensional models, which are the basis for the implementation of the data warehouse database schema according to a specific technology. Most current research focuses on the (automatic) derivation of database schemata from these conceptual models, but they neglect the automatic derivation of OLAP metadata in a way that is integrated with the database schema. However, such integration is extremely important, since it allows end-user tools to query the database schema of the data warehouse correctly and reduces both development time and costs. This paper proposes a model-transformation architecture, with which to apply a set of data mappings. These mappings allow designers to effortlessly obtain various types of OLAP metadata during the derivation of the database schema from the conceptual\u00a0\u2026", "num_citations": "13\n", "authors": ["582"]}
{"title": "Extracting models from web API documentation\n", "abstract": " In order to develop web mashups, designers need an in-depth understanding of each Web API they are using. However, Web API documentation is rather heterogeneous, represented by big HTML files or collection of files in which it is difficult to identify elements such as API methods and how they can be invoked. Models have been widely recognized as first-citizen artifacts for documenting software applications, abstracting from implementation details, thus becoming good candidates to raise the level of automation of web mashup development. In this paper we present an approach for extracting models from Web API documentation. Our contributions are (i) a metamodel for standardizing the information extracted from Web APIs documentation; and (ii) a method for the extraction of models by parsing HTML files containing the Web API documentation, discovering useful data, and automatically generating\u00a0\u2026", "num_citations": "12\n", "authors": ["582"]}
{"title": "Development of a Knowledge Base for Enabling Non-expert Users to Apply Data Mining Algorithms.\n", "abstract": " Non-expert users find complex to gain richer insights into the increasingly amount of available data. Advanced data analysis techniques, such as data mining, are difficult to apply due to the fact that (i) a great number of data mining algorithms can be applied to solve the same problem, and (ii) correctly applying data mining techniques always requires dealing with the data quality of sources. Therefore, these non-expert users must be informed about what data mining techniques and parameters-setting are appropriate for being applied to their sources according to their data quality. To this aim, we propose the construction of an automatic recommender built using a knowledge base which contains information about previously solved data mining tasks. The construction of the knowledge base is a critical step in the recommender design. We propose a model-driven approach for the development of a knowledge base, which is automatically fed by a Taverna workflow. Experiments are conducted to show the feasibility of our knowledge base as a resource in an online educational platform, in which instructors of e-learning courses are non-expert data miners who need to discover how their courses are used in order to make informed decisions to improve them.", "num_citations": "11\n", "authors": ["582"]}
{"title": "RETRACTED: Model-driven development of OLAP metadata for relational data warehouses\n", "abstract": " We propose a model-transformation architecture with which to obtain both the database schema of a data warehouse and the required OLAP metadata for end-user tools to intuitively query the underlying schema. The main benefit that this architecture provides is a set of mappings that will allow designers to effortlessly obtain various types of OLAP metadata for several kinds of tools and users during the simultaneous generation of the database schema. Both processes are automatic and integrated. As a proof of concept, our approach is implemented in the Eclipse Modelling Framework, thus showing its feasibility and usefulness.", "num_citations": "11\n", "authors": ["582"]}
{"title": "Modeling Web logs to enhance the analysis of Web usage data\n", "abstract": " Web log files store data related to the use of a website. Analyzing these data in detail is therefore crucial for improving the user browsing experience. However, usually Web log data are stored in flat files in different formats which hinders their analysis, thus obliging to use specific Web log analysis tools. In this context, approaches for structuring Web log data to better analyze them are highly required. To this aim, in this paper we propose a metamodel for Web log data in order to unify features of every available format at the same time that unnecessary technical details are omitted. This metamodel supports the design of Web log models regardless the format of the Web log files. A set of guidelines have been also proposed to define a multidimensional schema of a data warehouse from our Web log model to be used in advanced analysis tools such as OLAP (OnLine Analytical Processing) or data mining tools in order\u00a0\u2026", "num_citations": "11\n", "authors": ["582"]}
{"title": "Applying the i* framework to the development of data warehouses\n", "abstract": " Data warehouse design has been traditionally guided by an in-depth analysis of the underlying operational data sources, thus over-looking an explicit stage in which information requirements of decision makers are addressed. This scenario has prompted that the deployed data warehouse often fails in delivering the expected support of the decision making process. To overcome this problem, we propose to use the i* framework for modeling goals and requirements within our model driven architecture (MDA) approach for the development of data warehouses. Our current and short term research also includes the reconciliation between information requirements and data sources, and the modeling of quality-of-service requirements (e.g., security). Finally, an Eclipse-based tool is being implemented as a proof of concept of our research.", "num_citations": "11\n", "authors": ["582"]}
{"title": "Quality and maturity model for open data portals\n", "abstract": " Open Government concept is experiencing an upswing. Open Government is based on three concepts (transparency, participation and collaboration) that require accessing data. To provide this access, Open Data Portals are being implemented around the world by every kind of organizations, mainly in the public sector. The aim of an Open Data Portal is exposing data in such a way that reusing is facilitated. Therefore, it is necessary to define a quality and maturity model to evaluate the characteristics of an Open Data Portal, considering different factors that can contribute to reusing potential, such like visualization, usability, granularity, data integration, reputation, relevancy, availability and reutilization. Also, effectively promoting data reusing implies setting specific norms to promote standardization among institutions, ministries and central governments' offices into the same country. This paper presents a formal\u00a0\u2026", "num_citations": "10\n", "authors": ["582"]}
{"title": "Webred: A model-driven tool for web requirements specification and optimization\n", "abstract": " In this paper we present the WebREd-Tool, a set of Eclipse plugins that have been developed to assist the designer in the early phases of a Web application development process. With the WebREd-Tool, the designer can specify the Web application requirements by using the i* goal-oriented framework. The WebREd-Tool assists the designer to compare different configurations of functional requirements, while balancing and optimizing non-functional requirements. The underlying algorithm to support this is based on the Pareto efficiency, but to help the designer to better assess and compare each configuration, the WebREd-Tool is also able to visualize each configurations using a radar-chart.", "num_citations": "10\n", "authors": ["582"]}
{"title": "Model-driven data mining engineering: from solution-driven implementations to \u2018composable\u2019conceptual data mining models\n", "abstract": " Data mining  lacks a   general    modelling architecture  allowing analysts to consider and interpret it as a truly   software-engineering process  , which would be beneficial for a wide spectrum of modern application scenarios. Bearing this in mind, in this paper, we propose an innovative   model-driven engineering approach of data mining  whose main goal consists in overcoming well-recognised limitations of actual approaches. The cornerstone of our proposal relies on the definition of a set of suitable   model transformations  which are able to automatically generate both the data under analysis, which are deployed via well-consolidated   data warehousing  technology and the   analysis models  for the target data mining tasks, which are tailored to a specific   data-mining/analysis platform  . These modelling tasks are now entrusted to the model-transformation scaffolds and rely on top of a well-defined reference\u00a0\u2026", "num_citations": "10\n", "authors": ["582"]}
{"title": "Modelos de weaving para trazabilidad de requisitos web en a-ooh\n", "abstract": " En este art\u00edculo, se presenta una propuesta con base en MDWE (Model Driven Web Engineering) para soportar trazabilidad (elemento-a-elemento) aplicando modelos weaving. El m\u00e9todo de dise\u00f1o", "num_citations": "10\n", "authors": ["582"]}
{"title": "Desarrollo de modelos multidimensionales de almacenes de datos basado en MDA: del an\u00e1lisis de requisitos al modelo l\u00f3gico\n", "abstract": " Un almac\u00e9n de datos se describe como una colecci\u00f3n de datos hist\u00f3ricos que suministra la informaci\u00f3n necesaria para apoyar el proceso de toma de decisiones en una organizaci\u00f3n. El desarrollo de un almac\u00e9n de datos se basa en el dise\u00f1o de un modelo conceptual que tenga en cuenta tanto los requisitos de informaci\u00f3n de usuario como las fuentes de datos operacionales. A partir de este modelo conceptual, se obtiene un modelo l\u00f3gico basado en una tecnolog\u00eda de bases de datos concreta que gu\u00ede la implementaci\u00f3n. Sin embargo, las propuestas actuales no definen mecanismos para estructurar de manera sistem\u00e1tica el desarrollo del almac\u00e9n de datos, convirti\u00e9ndolo en una tarea compleja que consume mucho tiempo y es f\u00e1cilmente susceptible a errores. Para solventar estas deficiencias, este art\u00edculo propone el uso de MDA en el dise\u00f1o de almacenes de datos.", "num_citations": "10\n", "authors": ["582"]}
{"title": "Framework for prioritization of open data publication: an application to smart cities\n", "abstract": " Public Sector Information is considered to play a fundamental role in the growth of the knowledge economy and improvements in society. Given the difficulty in publishing and maintaining all available data, due to budget constraints, institutions need to select which data to publish, giving priority to data most likely to generate social and economic impact. Priority of publication could become an even more significant problem in Smart Cities: as huge amounts of information are generated from different domains, the way data is prioritized and thus reused, could be a determining factor in promoting, among others, new and sustainable business opportunities for local entrepreneurs, and to improve citizen quality of life. However, people in charge of prioritizing which data to publish through open data portals, such as Chief Data Officers (CDOs), do not have available any specific support in their decision-making process. In\u00a0\u2026", "num_citations": "9\n", "authors": ["582"]}
{"title": "Reusing open data for learning database design\n", "abstract": " This paper describes an experience based on reusing open data through project-based learning within the ARA (Alto Rendimiento Acad\u00e9mico or High Academic Performance) group taught in the degree in Computer Engineering at the University of Alicante (Spain) during 2012/2013 and 2013/2014. Openness philosophy implies that huge amount of data is available to students in tabular format, ready for reusing. In our teaching experience, students propose an original scenario where different open data can be reused to a specific goal. Then, it is proposed to design a database in order to manage this data in the envisioned scenario. Open data in the subject helps in instilling a creative and entrepreneur attitude in students, as well as encourages autonomous and lifelong learning. Surveys made to students at the end of each year shown that reusing open data within project-based learning methodologies makes\u00a0\u2026", "num_citations": "9\n", "authors": ["582"]}
{"title": "Goal oriented requirements engineering in data warehouses: A comparative study\n", "abstract": " Data warehouses provide historical information about the organization that needs to be analyzed by the decision makers; therefore, it is essential to develop them in the context of a strategic business plan. In recent years, a number of engineering approaches for goal-oriented requirements have been proposed, which can obtain the information requirements of a data warehouse using traditional techniques and the objectives of the modeling. This paper provides an overview and a comparative study of the treatment of the requirements in the existing approaches to serve as a starting point for further research.", "num_citations": "9\n", "authors": ["582"]}
{"title": "Big Data and Smart Tourism Destinations: Challenges and opportunities from an industry perspective\n", "abstract": " The main objective of this paper is to carry out an in-depth study of what is known about the Big Data technology used in the planning and management of tourism within the new smart tourism destination (STD) approach, given the capacity of these destinations to generate huge amounts of data thanks to their advanced technological infrastructure. To this end, scientific literature concerning the STD approach is analysed, along with the Big Data technology, whereby some of the most typical cases that can be applied to tourism are recorded. To determine the strengths and weaknesses of this technology in companies and tourist destinations from a broader perspective, and thanks to the close collaboration with the Valencian Institute of Tourist Technologies (Invat. tur), the viewpoint of the entrepreneurs and experts is also provided by analysing 200 online questionnaires, mainly given to tourism companies in the Valencian Community, and a total of 13 in-depth interviews carried out with well-known experts and executives from the Spanish tourism and technology sector. Finally, the paper puts forward key lines of work related to the STD operational development and the use of the Big Data technology in them.", "num_citations": "8\n", "authors": ["582"]}
{"title": "Towards the Automatic Generation of Analytical End-User Tools Metadata for Data Warehouses\n", "abstract": " Multidimensional models are used to obtain the required database metadata for implementing the data warehouse. Surprisingly, current approaches for multidimensional modelling overlook the necessity of additional data-cube metadata to allow end-user tools to query the data warehouse. To overcome this situation, we propose the use of the Model Driven Architecture (MDA) in order to automatically derive both kinds of metadata in a systematic and integrated way.", "num_citations": "8\n", "authors": ["582"]}
{"title": "Metodolog\u00eda \u00e1gil en el dise\u00f1o e implantaci\u00f3n de un M\u00e1ster en Ingenier\u00eda Inform\u00e1tica\n", "abstract": " Tras la vor\u00e1gine de las renovaciones y nuevos dise\u00f1os de todas las titulaciones universitarias, llegan momentos de calma, de an\u00e1lisis y de reflexi\u00f3n. Los m\u00e1steres caracterizar\u00e1n a las universidades. Y aunque el M\u00e1ster en Ingenier\u00eda Inform\u00e1tica sigue unas fichas comunes, debe imbricarse con la universidad y el contexto social en el que se implanta. En este art\u00edculo se hace uso de los conceptos de las metodolog\u00edas \u00e1giles para describir el proceso de dise\u00f1o e implantaci\u00f3n del M\u00e1ster en Ingenier\u00eda Inform\u00e1tica de la Escuela Polit\u00e9cnica Superior de la Universidad de Alicante. Desde su implantaci\u00f3n este M\u00e1ster ha seguido un proceso de mejora continua, identificando, en cada curso, los posibles aspectos de mejora a partir de la informaci\u00f3n recogida durante los cursos anteriores y las propuestas para realizar dichas mejoras para los cursos siguientes. Se pretende en este art\u00edculo describir las experiencias, lecciones aprendidas y futuros pasos encaminados a afianzar este proceso de mejora continua del M\u00e1ster en Ingenier\u00eda Inform\u00e1tica.", "num_citations": "7\n", "authors": ["582"]}
{"title": "Web and requirements engineering\n", "abstract": " In the last decade, the number and complexity of Web-based software systems and the amount of information they offer have been continuously growing. In the context of Software Engineering, design methods and methodologies were introduced to provide mechanisms to develop these complex Web applications and Rich Internet Applications (RIAs) in a systematic way. Most of these methodologies focus on implementation and neglect other tasks such as requirement analysis and quality management. However, in the development of traditional (non-Web) applications both practitioners and process experts regard requirements engineering as a phase of crucial relevance in the development process. It is well-known that the most common and time-consuming errors as well as the most expensive ones to repair, are errors that arise from inadequate engineering of requirements. Therefore, although the relevance of\u00a0\u2026", "num_citations": "7\n", "authors": ["582"]}
{"title": "Model-driven adaptation of question answering systems for ambient intelligence by integrating restricted-domain knowledge\n", "abstract": " Ambient Intelligence (AmI) requires Question Answering (QA) systems for providing intuitive interfaces to state natural language questions and obtaining precise answers related to some specific topic. Therefore, adapting QA systems to new restricted domains is an increasingly necessity for these systems to be applied in AmI environments. Unfortunately, research addressing adaptation of QA systems to new domains has two main drawbacks: (i) QA systems are manually tuned, which requires a huge effort in time and cost, and (ii) tuning of QA systems depends on the specific representation scheme of the restricted-domain knowledge, thus hinders incorporation of new resources into the system. To overcome these drawbacks, this paper presents a novel approach based on model-driven development in order to seamlessly integrate textual information and knowledge resources to automatically and effortlessly\u00a0\u2026", "num_citations": "7\n", "authors": ["582"]}
{"title": "Publicando datos abiertos considerando criterios de calidad\n", "abstract": " Los datos abiertos son considerados un mecanismo de democratizaci\u00f3n en el acceso a la informaci\u00f3n generada por organizaciones del sector p\u00fablico y para el desarrollo de servicios digitales generados por el sector infomediario. Sin embargo, esta tendencia ha presentado algunas barreras que van desde la calidad insuficiente de los datos publicados hasta la falta de mantenimiento de los portales donde se publican. Esta investigaci\u00f3n realiza un an\u00e1lisis del estado de la cuesti\u00f3n en el \u00e1mbito de los datos abiertos, as\u00ed como de los est\u00e1ndares internacionales y buenas pr\u00e1cticas de calidad de datos con el fin de proponer un marco de referencia que posibilite la publicaci\u00f3n de datos abiertos con un nivel de calidad adecuado. El marco de referencia fue validado utilizando un caso de estudio mediante la metodolog\u00eda de investigaci\u00f3n en acci\u00f3n.", "num_citations": "6\n", "authors": ["582"]}
{"title": "Impact analysis of goal-oriented requirements in web engineering\n", "abstract": " Due to the continuous changes and heterogeneous audience of the Web, a requirement engineering stage is crucial for Web development. Importantly, this stage should consider that Web applications are more likely to rapidly evolve during the development process, thus leading to inconsistencies among requirements. Therefore, Web developers need to know dependencies among requirements to ensure that Web applications finally satisfy the audience. The understanding of requirement dependencies also helps in better managing and maintaining Web applications. In this work, an algorithm has been defined in order to deal with dependencies among functional and non-functional requirements to understand which is the impact of making changes when developing a Web application.", "num_citations": "6\n", "authors": ["582"]}
{"title": "Systematic Mapping of Open Data Studies: Classification and Trends From a Technological Perspective\n", "abstract": " The objective of this paper is to classify and analyse all research on open data performed in the scientific community from a technological viewpoint, providing a detailed exploration based on six key facets: publication venue, impact, subject, domain, life-cycle phases and type of research. This paper therefore provides a consolidated overview of the open data arena that allows readers to identify well-established topics, trends, and open research issues. Additionally, we provide an extensive qualitative discussion of the most interesting findings to pave the way for future research. Our first identification phase resulted in 893 relevant peer-reviewed articles, published between 2006 and 2019 in a wide variety of venues. Analysis of the results shows that open data research grew slowly from 2006 but increased significantly as from 2009. In 2019, research interest in open data from a technological perspective overall\u00a0\u2026", "num_citations": "5\n", "authors": ["582"]}
{"title": "Evaluating the use of pareto efficiency to optimize non-functional requirements satisfaction in i* modeling\n", "abstract": " Due to the large, heterogeneous audience of Web applications, and its rapidly changing expectations, holistic requirement analysis approaches are crucial to ensure the success of Web engineering projects. To increase the quality of resulting Web applications, non-functional requirements (NFRs) must be considered. Satisfying them is a non-trivial task that depends on making decisions about which functional requirements (FRs) to implement, and how to prioritize the NFRs. A satisfactory solution is a trade-off, where competing NFRs must be balanced. In this paper, we outline how the Pareto efficiency can complement a goal-oriented requirement analysis modelling to evaluate and select optimal configurations of requirements for a Web application, while NFRs are balanced and maximized according to a priority list. We hereby focus on an empirical evaluation to verify whether our Pareto method improves the\u00a0\u2026", "num_citations": "5\n", "authors": ["582"]}
{"title": "A Conceptual modeling personalization framework for OLAP\n", "abstract": " OLAP (On-line Analytical Processing) technologies rely on multidimensional models to provide decision makers with appropriate structures allowing them to intuitively analyze data. However, these multidimensional models may be potentially large, thus becoming too complex to be understood at a glance. Current approaches for OLAP design are focused on providing analysts with a single multidimensional schema derived from their previously stated information requirements, but this is not sufficient to lighten the complexity of the decision making process. To overcome this drawback, the authors propose personalizing multidimensional models for OLAP technologies according to the continuously changing user characteristics, context, requirements and behavior. In this paper, they present a new approach for personalizing OLAP systems at the conceptual level based on the underlying multidimensional model, a\u00a0\u2026", "num_citations": "5\n", "authors": ["582"]}
{"title": "Dealing with dependencies among functional and non-functional requirements for impact analysis in web engineering\n", "abstract": " Due to the dynamic nature of the Web as well as its heterogeneous audience, web applications are more likely to rapidly evolve leading to inconsistencies among requirements during the development process. With the purpose to deal with these inconsistencies, web developers need to know dependencies among requirements considering that the understanding of these dependencies helps in better managing and maintaining web applications. In this paper, an algorithm has been defined and implemented in order to analyze dependencies among functional and non-functional requirements (in a goal-oriented approach) for understanding which is the impact derived from a change during the Model-Driven Web Engineering process. This Impact Analysis would support web developer in selecting requirements to be implemented ensuring that web applications finally satisfy the audience.", "num_citations": "5\n", "authors": ["582"]}
{"title": "Introduction to the special issue of Business Intelligence and the Web\n", "abstract": " La presente simulazione \u00e8 stata realizzata sulla base delle regole riportate nel DM 598/2018 e allegata Tabella A. Cineca non si assume alcuna responsabilit\u00e0 in merito all\u2019uso che il diretto interessato o terzi faranno della simulazione. Si specifica inoltre che la simulazione contiene calcoli effettuati con dati e algoritmi di pubblico dominio e deve quindi essere considerata come un mero ausilio al calcolo svolgibile manualmente o con strumenti equivalenti. Informazioni sui dati: vengono considerati tutti i prodotti in stato definitivo. Per i prodotti indicizzati wos/scopus, l\u2019anno di riferimento e la tipologia sono quelli riportati in banca-dati.", "num_citations": "5\n", "authors": ["582"]}
{"title": "Levels for conceptual modeling\n", "abstract": " Usually object types are organized in taxonomies by means of a specialization relation (also called subtyping or isa) \u2018implemented\u2019 by means of inheritance. This paper proposes a (non-incompatible) alternative to taxonomies that relies on three primitives: grounding, a specific kind of factual existential dependence, extensional atemporal parthood, and existence at a time. On the basis of these relations, specific, generic, and compositional grounding relations between object types are introduced. By clearly separating the objects from the substrata on which they are grounded, these grounding relations allow to stratify object types in levels and to manage inheritance in a flexible way. In particular, this approach helps to avoid isa overloading and to overcome some classical difficulties related to inheritance, e.g. attribute overriding, attribute hiding, or dynamic and multiple classification and specialization, that\u00a0\u2026", "num_citations": "5\n", "authors": ["582"]}
{"title": "Model-driven development of multidimensional models from web log files\n", "abstract": " Analyzing Web log data is important in order to study the usage of a website. Even though some approaches propose data warehousing techniques for structuring the Web log data into a multidimensional model, they present two main drawbacks: (i) they are based on informal guidelines and must be manually applied; and (ii) they consider data tailored to a specific Web log format, thus being restricted to specific analysis tools. To overcome these limitations, we present a model-driven approach for obtaining a conceptual multidimensional model from Web log data in a comprehensive, integrated and automatic manner. This approach consists of the following steps: (i) obtaining a conceptual model of the Web log data based on a unified metamodel, (ii) deriving a multidimensional model from this Web log model by formally defining a set of QVT (Query/View/Transformation) transformation rules.", "num_citations": "5\n", "authors": ["582"]}
{"title": "Model-driven reverse engineering for data warehouse design\n", "abstract": " Data warehouses integrate several operational sources to provide a multidimensional analysis of data, thus improving the decision making process. Therefore, an in-depth analysis of these data sources is crucial for data warehouse development. Traditionally, this analysis has been based on a set of informal guidelines or heuristics to support the manually discovery of multidimensional elements on a well-known documentation. Therefore, this task may become highly tedious and prone to fail. In this paper, MDA (Model Driven Architecture) is used to design a reverse engineering process in which the following tasks are performed (i) obtain a logical representation of data sources (ii) mark this logical representation with multidimensional concepts, and (iii) derive a conceptual multidimensional model from the marked model.", "num_citations": "5\n", "authors": ["582"]}
{"title": "Integrating the development of data mining and data warehouses via model-driven engineering\n", "abstract": " Data mining is one of the most important analysis techniques to automatically extract knowledge from large amount of data. Nowadays, data mining is based on low-level specifications of the employed techniques typically bounded to a specific analysis platform. Therefore, data mining lacks a modelling architecture that allows analysts to consider it as a truly software-engineering process. Bearing in mind this situation, we propose a model-driven approach which is based on (i) a conceptual modelling framework for data mining, and (ii) a set of model transformations to automatically generate both the data under analysis (that is deployed via data-warehousing technology) and the analysis models for data mining (tailored to a specific platform). Thus, analysts can concentrate on understanding the analysis problem via conceptual data-mining models instead of wasting efforts on low-level programming tasks related to the underlying-platform technical details. These time consuming tasks are now entrusted to the model-transformations scaffolding. The feasibility of our approach is shown by means of a hypothetical data-mining scenario where a time series analysis is required.", "num_citations": "5\n", "authors": ["582"]}
{"title": "Desarrollo de almacenes de datos dirigido por modelos\n", "abstract": " Esta contribuci\u00f3n presenta una descripci\u00f3n de las l\u00edneas de investigaci\u00f3n que el grupo IWAD (Ingenier\u00eda Web y Almacenes de Datos) de la Universidad de Alicante, est\u00e1 realizando en el campo de los almacenes de datos (ADs). La investigaci\u00f3n se basa en el modelado conceptual como piedra angular para el desarrollo del AD. Actualmente, se estudian diversos est\u00e1ndares del OMG (Object Management Group) y su aplicabilidad al dise\u00f1o del repositorio del AD, las aplicaciones para la explotaci\u00f3n del AD como las herramientas OLAP (On-Line Analytical Processing) o de miner\u00eda de datos, la incorporaci\u00f3n de seguridad y m\u00e9tricas de calidad a los modelos conceptuales, as\u00ed como la transformaci\u00f3n e implementaci\u00f3n de estos modelos en distintas plataformas.", "num_citations": "5\n", "authors": ["582"]}
{"title": "Open Data and tourism. Implications for tourism management in Smart Cities and Smart Tourism Destinations.\n", "abstract": " The emergence of the Internet and the spread of information and communication communication Subject Category: Techniques, Methodologies and Equipment", "num_citations": "4\n", "authors": ["582"]}
{"title": "Towards Semantic Assessment of Summarizability in Self-service Business Intelligence\n", "abstract": " Traditional Business Intelligence solutions allow decision makers to query multidimensional data cubes by using OLAP tools, thus ensuring summarizability, which refers to the possibility of accurately computing aggregation of measures along dimensions. With the advent of the Web of Open Data, new external sources have been used in Self-service Business Intelligence for acquiring more insights through ad-hoc multidimensional open data cubes. However, as these data cubes rely upon unknown external data, decision makers are likely to make meaningless queries that lead to summarizability problems. To overcome this problem, in this paper, we propose a framework that automatically extracts multidimensional elements from SPARQL query logs and creates a knowledge base to detect semantic correctness of summarizability.", "num_citations": "4\n", "authors": ["582"]}
{"title": "Investigaci\u00f3n e Innovaci\u00f3n Educativa en Docencia Universitaria. Retos, Propuestas y Acciones\n", "abstract": " Humanidades II ha llevado a cabo una revisi\u00f3n de esta titulaci\u00f3n sobre la base de los resultados alcanzados en la Red del curso anterior Seguimiento del Grado en Humanidades. Esta Red se centr\u00f3 en el an\u00e1lisis de los informes de la Comisi\u00f3n", "num_citations": "4\n", "authors": ["582"]}
{"title": "Un enfoque de ingenier\u00eda de requerimientos basada en el alineamiento de almacenes de datos y la estrategia del negocio\n", "abstract": " Garantizar que los almacenes de datos est\u00e9n alineados a la estrategia del negocio es primordial para su \u00e9xito, ya que estos son utilizados por los gerentes del negocio con el fin de analizar los datos estrat\u00e9gicos de la organizaci\u00f3n. En este trabajo presentamos un enfoque de ingenier\u00eda de requerimientos orientado al negocio que alinea el Almac\u00e9n de Datos a su plan estrat\u00e9gico. El proceso se describe mediante un conjunto de directrices que incluyen: el an\u00e1lisis VMOST para obtener los objetivos desde los usuarios, el modelo BMM para comprobar que los objetivos definidos est\u00e9n alineados con la estrategia, el modelado de objetivos por medio de i* con el fin de obtener los requerimientos de informaci\u00f3n del Almac\u00e9n de Datos, y el modelado multidimensional mediante un perfil UML. Se presenta un estudio de caso para mostrar el proceso completo.", "num_citations": "4\n", "authors": ["582"]}
{"title": "Towards the development of a knowledge base for realizing user-friendly data mining\n", "abstract": " Initiatives as open data, make available more and more data to everybody, thus fostering new techniques for enabling non-expert users to analyse data in an easier manner. Data mining techniques allow acquiring knowledge from available data but it requires a high level of expertise in both preparing data sets and selecting the right mining algorithm. This paper is a first step towards a user-friendly data mining approach in which a knowledge base is created with the aim of guiding non-expert users in obtaining reliable knowledge from data sources.", "num_citations": "4\n", "authors": ["582"]}
{"title": "Model-driven development for adapting question answering systems to restricted domains\n", "abstract": " A Question Answering (QA) system must provide concise answers from large collections of documents to questions stated by the user in natural language. However, although many QA systems for open domain exist, its adaptation for restricted domains (such as those of healthcare, agriculture, transportation, or science) is a far from trivial task. The principal problem is that domain experts ask more precise questions (and expect more precise answers), including specific terminology, and this is costly to integrate into a QA system. To overcome this drawback, this paper presents an innovative approach based on model-driven software development. It uses restricted-domain resources to automatically and effortlessly adapt open-domain QA systems in order to make them useful in restricted-domain scenarios. Finally, a set of experiments has been carried out to show the approach's applicability.", "num_citations": "4\n", "authors": ["582"]}
{"title": "Influencia de los estilos de aprendizaje en el uso de redes sociales para docencia\n", "abstract": " Debido a los cambios que el Espacio Europeo de Educaci\u00f3n Superior introduce al potenciar las horas de trabajo no presencial, se hacen necesarios nuevos mecanismos para posibilitar una mejor comunicaci\u00f3n y cooperaci\u00f3n en el proceso de aprendizaje. Las redes sociales, como Facebook, pueden suministrar estos mecanismos, pero su uso satisfactorio para la docencia puede verse afectado en gran medida por el estilo de aprendizaje de los alumnos. Por lo tanto, este art\u00edculo plantea la necesidad de estudiar la influencia de los diferentes estilos de aprendizaje en la docencia no presencial mediante el uso de redes sociales con el fin de incrementar el rendimiento de los alumnos. Concretamente, la hip\u00f3tesis de partida de este trabajo es que el uso de una red social como Facebook por parte de un grupo de estudiantes con diferentes estilos de aprendizaje puede hacer que el rendimiento global mejore. Con la finalidad de corroborar esta hip\u00f3tesis se han propuesto una serie de experimentos llevados a cabo en la asignatura Dise\u00f1o y Programaci\u00f3n Avanzada de Aplicaciones impartida en Ingenier\u00eda Inform\u00e1tica de la Universidad de Alicante, cuya realizaci\u00f3n, resultados y discusi\u00f3n se muestran en este art\u00edculo.", "num_citations": "4\n", "authors": ["582"]}
{"title": "Model-driven knowledge-based development of expected answer type taxonomies for restricted domain question answering\n", "abstract": " A Question Answering (QA) system must provide concise answers from large collections of documents to questions stated by the user in natural language. Importantly, a question should be correctly classified by means of a predefined taxonomy in order to determine which is the Expected Answer Type (EAT), thus reducing the searching space over documents, while a right answer is obtained. Designing a proper EAT taxonomy is even more crucial in restricted domain QA, since domain experts use specific terminology, thus asking more precise questions and expecting more precise answers. This paper presents a novel model-driven approach in order to ameliorate the task of designing restricted-domain EAT taxonomies by using heterogeneous knowledge resources and collection of documents. To show the applicability of our approach, a set of experiments has been carried out by defining a new EAT\u00a0\u2026", "num_citations": "4\n", "authors": ["582"]}
{"title": "Applying MDA to integrate mining techniques into data warehouses: a time series case study\n", "abstract": " Data mining is one of the most important analysis techniques to automatically extract knowledge from large amount of data. Nowadays, data mining is based on low-level specifications of the employed techniques typically bounded to a specific analysis platform. Therefore, data mining lacks a modelling architecture that allows analysts to consider it as a truly software-engineering process. Bearing in mind this situation, we propose a modeldriven approach which is based on (i) a conceptual modelling framework for data mining, and (ii) a set of model transformations to automatically generate both the data under analysis (that is deployed via data-warehousing technology) and the analysis models for data mining (tailored to a specific platform). Thus, analysts can concentrate on understanding the analysis problem via conceptual data-mining models instead of wasting efforts on low-level programming tasks related to the underlying-platform technical details. These tasks are now entrusted to the model-transformations scaffolding. The feasibility of our approach is shown by means of a hypothetical data-mining scenario where a time series analysis is required.", "num_citations": "4\n", "authors": ["582"]}
{"title": "S3Mining: A model-driven engineering approach for supporting novice data miners in selecting suitable classifiers\n", "abstract": " Data mining has proven to be very useful in order to extract information from data in many different contexts. However, due to the complexity of data mining techniques, it is required the know-how of an expert in this field to select and use them. Actually, adequately applying data mining is out of the reach of novice users which have expertise in their area of work, but lack skills to employ these techniques. In this paper, we use both model-driven engineering and scientific workflow standards and tools in order to develop named S3Mining framework, which supports novice users in the process of selecting the data mining classification algorithm that better fits with their data and goal. To this aim, this selection process uses the past experiences of expert data miners with the application of classification techniques over their own datasets. The contributions of our S3Mining framework are as follows: (i) an approach to\u00a0\u2026", "num_citations": "3\n", "authors": ["582"]}
{"title": "Developing a data map for opening public sector information\n", "abstract": " One of the key issues in developing an open data portal is detecting, selecting, classifying and prioritizing the data of the organization to be opened. It is not a trivial task since organizations (as universities) are rather complex (in terms of staff and existing information systems) and furthermore, data from universities has a rather heterogeneous nature. This paper introduces the \u201cdata map\u201d concept as a means to support carrying out this process. A data map aims to help in improving the process of opening data, reaching a high level of automation by considering the required metadata and semantics.", "num_citations": "3\n", "authors": ["582"]}
{"title": "Creaci\u00f3n autom\u00e1tica de sistemas de b\u00fasqueda de respuestas en dominios restringidos\n", "abstract": " Los sistemas de b\u00fasqueda de respuestas (BR) se pueden considerar como potenciales sucesores de los buscadores tradicionales de informaci\u00f3n en la Web. Para que sean precisos deben adaptarse a dominios concretos mediante el uso de recursos sem\u00e1nticos adecuados. La adaptaci\u00f3n no es una tarea trivial, ya que deben integrarse e incorporarse a sistemas de BR existentes varios recursos heterog\u00e9neos relacionados con un dominio restringido. Se presenta la herramienta Maraqa, cuya novedad radica en el uso de t\u00e9cnicas de ingenier\u00eda del software, como el desarrollo dirigido por modelos, para automatizar dicho proceso de adaptaci\u00f3n a dominios restringidos. Se ha evaluado Maraqa mediante una serie de experimentos (sobre el dominio agr\u00edcola) que demuestran su viabilidad, mejorando en un 29, 5% la precisi\u00f3n del sistema adaptado.", "num_citations": "3\n", "authors": ["582"]}
{"title": "A model-driven approach for enforcing summarizability in multidimensional modeling\n", "abstract": " The development of a data warehouse system is based on a conceptual multidimensional model, which provides a high level of abstraction in the accurate and expressive description of real-world situations. Once this model has been designed, the corresponding logical representation must be obtained as the basis of the implementation of the data warehouse according to one specific technology. However, there is a semantic gap between the dimension hierarchies modeled in a conceptual multidimensional model and its implementation. This gap particularly complicates a suitable treatment of summarizability issues, which may in turn lead to erroneous results from business intelligence tools. Therefore, it is crucial not only to capture adequate dimension hierarchies in the conceptual multidimensional model of the data warehouse, but also to correctly transform these multidimensional structures in a\u00a0\u2026", "num_citations": "3\n", "authors": ["582"]}
{"title": "Towards a model-driven framework for web usage warehouse development\n", "abstract": " Analyzing the usage of a website is a key issue for a company to improve decision making regarding the business processes related to the website, or the evolution of the own website. To study the Web usage we need advanced data analysis tools which require the development of a data warehouse to structure data in a multidimensional model. In this paper, we describe two possible scenarios that could arise and we claim that a model-driven approach would be useful for obtaining a multidimensional model in a comprehensive and structured way. This model will drive the development of a data warehouse in order to enhance the analysis of Web usage data: the Web usage warehouse.", "num_citations": "3\n", "authors": ["582"]}
{"title": "Usos de redes sociales para mejorar el rendimiento de los alumnos con diferentes niveles de aprendizaje\n", "abstract": " Debido a los cambios que el Espacio Europeo de Educaci\u00f3n Superior introduce al potenciar las horas de trabajo no presencial, se hacen necesarios nuevos mecanismos para posibilitar una mejor comunicaci\u00f3n y cooperaci\u00f3n en el proceso de aprendizaje. Las redes sociales, como Facebook, pueden suministrar estos mecanismos, pero su uso satisfactorio para la docencia puede verse afectado en gran medida por el estilo de aprendizaje de los alumnos. Este art\u00edculo plantea la necesidad de estudiar la influencia de los diferentes estilos de aprendizaje en la docencia no presencial mediante el uso de redes sociales con el fin de incrementar el rendimiento de los alumnos. Cabe destacar que este art\u00edculo describe el proyecto \u201cLas redes sociales y su relaci\u00f3n con los estilos de aprendizaje\u201d a realizar dentro del programa de Redes de Investigaci\u00f3n en Docencia Universitaria del Instituto de Ciencias de la Educaci\u00f3n de la Universidad de Alicante.", "num_citations": "3\n", "authors": ["582"]}
{"title": "Towards A Model-Driven Engineering Approach of Data Mining.\n", "abstract": " Nowadays, data mining is based on low-level speci cations of the employed techniques typically bounded to a speci c analysis platform. Therefore, data mining lacks a modelling architecture that allows analysts to consider it as a truly software-engineering process. Here, we propose a model-driven approach based on (i) a conceptual modelling framework for data mining, and (ii) a set of model transformations to automatically generate both the data under analysis (via datawarehousing technology) and the analysis models for data mining (tailored to a speci c platform). Thus, analysts can concentrate on the analysis problem via conceptual data-mining models instead of low-level programming tasks related to the underlying-platform technical details. These tasks are now entrusted to the model-transformations scaffolding.", "num_citations": "3\n", "authors": ["582"]}
{"title": "New neighborhood based classification rules for metric spaces and their use in ensemble classification\n", "abstract": " The k-nearest-neighbor rule is a well known pattern recognition technique with very good results in a great variety of real classification tasks. Based on the neighborhood concept, several classification rules have been proposed to reduce the error rate of the k-nearest-neighbor rule (or its time requirements). In this work, two new geometrical neighborhoods are defined and the classification rules derived from them are used in several real data classification tasks. Also, some voting ensembles of classifiers based on these new rules have been tested and compared.", "num_citations": "3\n", "authors": ["582"]}
{"title": "Ingenier\u00eda inversa dirigida por modelos para el dise\u00f1o de almacenes de datos.\n", "abstract": " Los almacenes de datos integran diversas fuentes de datos operacionales con el fin de obtener una visi\u00f3n multidimensional de las mismas, suministrando as\u00ed la informaci\u00f3n apropiada para mejorar el proceso de toma de decisiones. Por tanto, el an\u00e1lisis de las fuentes de datos operacionales resulta fundamental para conseguir un modelo conceptual multidimensional que gu\u00ede el proceso de desarrollo del almac\u00e9n de datos de manera satisfactoria. Tradicionalmente, este an\u00e1lisis se ha apoyado en la aplicaci\u00f3n, poco automatizada, de gu\u00edas de dise\u00f1o sobre la documentaci\u00f3n de las fuentes de datos, lo que hace que la tarea del dise\u00f1ador resulte muy tediosa y sensible a errores. En este art\u00edculo se plantea el uso de MDA (Model Driven Architecture) para realizar un proceso de ingenier\u00eda inversa que conste de las siguientes tareas:(i) obtener una representaci\u00f3n l\u00f3gica de la propia implementaci\u00f3n de las fuentes\u00a0\u2026", "num_citations": "3\n", "authors": ["582"]}
{"title": "Model-based Generation of Web Application Programming Interfaces to Access Open Data\n", "abstract": " In order to facilitate the reusing of open data from open data platforms\u2019 catalogs, Web Application Programming Interfaces (APIs) are an important mechanism for reusers. However, there is a lack of suitable Web APIs to access data from open data platforms. Moreover, in most cases, the currently available APIs only allow to access catalog\u2019s metadata or to download entire data resources (ie coarse-grain access to data), hampering the reuse of data. Therefore, we propose a model-based approach to automatically generate Web APIs from open data. Our generated Web APIs facilitate the access and reuse of specific data (ie, providing fine-grain or query-level access to data), which will result in many societal and economic benefits such as transparency and innovation. With this approach we address open data publishers which will be able to include aWeb API within their data, but also open data reusers in case of\u00a0\u2026", "num_citations": "2\n", "authors": ["582"]}
{"title": "Using Semantic Web technologies in the development of data warehouses: A systematic mapping\n", "abstract": " The exploration and use of Semantic Web technologies have attracted considerable attention from researchers examining data warehouse (DW) development. However, the impact of this research and the maturity level of its results are still unclear. The objective of this study is to examine recently published research articles that take into account the use of Semantic Web technologies in the DW arena with the intention of summarizing their results, classifying their contributions to the field according to publication type, evaluating the maturity level of the results, and identifying future research challenges. Three main conclusions were derived from this study: (a) there is a major technological gap that inhibits the wide adoption of Semantic Web technologies in the business domain;(b) there is limited evidence that the results of the analyzed studies are applicable and transferable to industrial use; and (c) interest in\u00a0\u2026", "num_citations": "2\n", "authors": ["582"]}
{"title": "Modelo de calidad y madurez para portales de datos abiertos\n", "abstract": " El concepto de Gobierno Abierto est\u00e1 evolucionando, y est\u00e1 basado en tres t\u00f3picos (transparencia, participaci\u00f3n y colaboraci\u00f3n) que requieren acceso a datos. Para proveer este acceso, cientos de portales de datos abiertos est\u00e1n siendo implementados alrededor del mundo por todo tipo de organizaciones, principalmente en el sector p\u00fablico. El objetivo de un portal de datos abiertos es presentar datos de manera que se facilite su reutilizaci\u00f3n; por lo tanto, es necesario definir un modelo de calidad y madurez para evaluar las caracter\u00edsticas de un portal de datos abiertos, considerando diferentes factores que pueden contribuir a potenciarle, tales como la visualizaci\u00f3n, la usabilidad, la granularidad, la integraci\u00f3n de datos, la reputaci\u00f3n de sus fuentes, su relevancia, la disponibilidad y la capacidad de reutilizaci\u00f3n en s\u00ed. Adem\u00e1s, una promoci\u00f3n efectiva de la reutilizaci\u00f3n de datos implica establecer normas espec\u00edficas para promover la estandarizaci\u00f3n entre instituciones, ministerios y oficinas de gobierno dentro del mismo pa\u00eds. Este art\u00edculo presenta una propuesta formal para estandarizar y evaluar-basado en criterio experto-la calidad y la madurez de un portal de datos abiertos.", "num_citations": "2\n", "authors": ["582"]}
{"title": "Supporting open dataset publication decisions based on Open Source Software reuse\n", "abstract": " Publishing and maintaining open data is a costly task for public institutions, that becomes even more challenging in the context of Smart Cities, where large amounts of varied data are generated from different domains. To optimize resources, they should prioritize the publication and maintenance of datasets most likely to generate social and economic impact. However, there is currently a lack of decision-support tools to help public sector data publishers to evaluate datasets on the light of their particular reuse goals. In this paper, we propose to suggest to data publishers the dataset categories with most potential impact, based on the impact of already published datasets of the same category. To measure impact, we propose a set of indicators based on the amount and quality of Open Source Software projects that use datasets. To aggregate indicators according to specific reuse goals, we provide an Analytic-Hierarchy-Process based tool.", "num_citations": "2\n", "authors": ["582"]}
{"title": "Requirements taxonomy for automatic detection of data mining techniques for non-expert users\n", "abstract": " Carrying out an extracting knowledge process is already a complex task, made most often by expert users. But in this world increasingly full of data, it is necessary to extend that possibility to non-expert users. To do this, novel methods to identify their needs in a transparent manner are needed. This article presents a taxonomy of requirements introduced with the aim of identifying that data mining technique to be used by non-expert users depending on their initial expectations. The taxonomy was validated by architects to analyze data related to the spatial formation of land value in regions of the province of Alicante, Spain. The results show its relevance. This proposal can be extended in future work.", "num_citations": "2\n", "authors": ["582"]}
{"title": "Requirements Engineering in the Development Process of Web Systems: A Systematic Literature Review\n", "abstract": " Requirements Engineering (RE) is the first phase in the software development process during which designers attempt to fully satisfy users' needs. Web Engineering (WE) methods should consider adapting RE to the Web's large and diverse user groups. The objective of this work is to classify the literature with regard to the RE applied in WE in order to obtain the current \"state-of-the-art\". The present work is based on the Systematic Literature Review (SLR) method proposed by Kitchenham; we have reviewed publications from ACM, IEEE, Science Direct, DBLP and World Wide Web. From a population of 3059 papers, we identified 14 primary studies, which provide information concerning RE when used in WE methods.", "num_citations": "2\n", "authors": ["582"]}
{"title": "Requirements Engineering in the Development Process of Web Systems: A Systematic Literature Review\n", "abstract": " Requirements Engineering (RE) is the first phase in the software development process during which designers attempt to fully satisfy users\u2019 needs. Web Engineering (WE) methods should consider adapting RE to the Web\u2019s large and diverse user groups. The objective of this work is to classify the literature with regard to the RE applied in WE in order to obtain the current \u201cstate-of-the-art\u201d. The present work is based on the Systematic Literature Review (SLR) method proposed by Kitchenham; we have reviewed publications from ACM, IEEE, Science Direct, DBLP and World Wide Web. From a population of 3059 papers, we identified 14 primary studies, which provide information concerning RE when used in WE methods.", "num_citations": "2\n", "authors": ["582"]}
{"title": "Reutilizaci\u00f3n de datos abiertos en el aprendizaje de dise\u00f1o de bases de datos a trav\u00e9s de proyectos\n", "abstract": " En este art\u00edculo se describe una metodolog\u00eda innovadora basada en el uso de datos abiertos para el aprendizaje, a trav\u00e9s de proyectos, de una asignatura de dise\u00f1o de bases de datos en un grado universitario. Esta metodolog\u00eda se aplica en un caso de estudio: la experiencia docente en el grupo de Alto Rendimiento Acad\u00e9mico (ARA) de la asignatura \u201cDise\u00f1o de Base de Datos\u201d del Grado en Ingenier\u00eda Inform\u00e1tica de la Universidad de Alicante en los cursos 2012/2013, 2013/2014 y 2014/2015. La filosof\u00eda de datos abiertos permite que est\u00e9n a disposici\u00f3n del alumnado una ingente cantidad de datos, listos para su reutilizaci\u00f3n y explotaci\u00f3n. En nuestra experiencia docente, el alumnado propone un escenario original donde diferentes datos abiertos puedan reutilizarse para una finalidad y utilidad concreta. Luego, se propone dise\u00f1ar una base de datos que permita la gesti\u00f3n de estos datos en el escenario propuesto. El uso de datos abiertos en la asignatura ha posibilitado inculcar en el alumnado una actitud creativa y emprendedora, a la vez que se fomenta el aprendizaje aut\u00f3nomo y permanente (lifelong learning). Las encuestas realizadas al alumnado al final de cada curso acad\u00e9mico han demostrado que el uso de datos abiertos integrados en metodolog\u00edas de aprendizaje basado en proyectos hace que los estudiantes tengan m\u00e1s motivaci\u00f3n a la hora de afrontar la asignatura, y que \u00e9stos valoren de forma muy positiva el uso de datos reales en asignaturas de este tipo.", "num_citations": "2\n", "authors": ["582"]}
{"title": "Voice and movement in circle with body percussion. Facilitation in learning observed in voice BAPNE\u00ae method and in circlesongs teaching\n", "abstract": " The proposal of this study reported here by Elisa Pezzuto, currently post graduate student in ethnomusicology, and by Alberto Quarello, teacher and manager of the vocal department of the voice BAPNE\u00ae method inside of BAPNE\u00ae method, is about music education; this study highlights how the use of a choral activity called circlesinging can help giving, in a really short time, the comprehension of many technical factors both in vocal and musical field increasing at the same time the rapidity in learning and enhancing the attention level using specific exercises to stimulate the development of multiple intelligence on the basis of Howard Gardner theory. The scientific basis in wich this argument has been observed is provided by the direct experience of Alberto Quarello, who led many workshops about this since 2006 until now meeting and working with more than five thousand people with deeply different backgrounds. Because this study is essentially about choral didactics, it is also fundamental the contribution of the musicological and ethnomusicological research about the analysis on the development of musical intelligence.", "num_citations": "2\n", "authors": ["582"]}
{"title": "Weaving aspect-orientation into web modeling languages\n", "abstract": " While buildingWeb applicationmodels fromscratch iswell-supported, reuse in Web application modeling is still in its infancy. A promising approach in this respect is aspect-oriented modeling to separate certain concerns from the base application, typically cross-cutting ones, and reuse them in various applications. A few Web modeling languages targeting the design phase have been already equippedwith aspect-orientation.However, languages for the early phases of Web modeling lack such support, but especially these phases would tremendously benefit from aspect-orientation. Moreover, all the existing solutions are tailored to a specific modeling language. To improve this situation, we consider aspectorientation itself as an aspect. This allows us to weave aspect-oriented language features into already existing Web modeling languages. We introduce a generic metamodel module comprising the main\u00a0\u2026", "num_citations": "2\n", "authors": ["582"]}
{"title": "Datos abiertos en el aprendizaje a trav\u00e9s de proyectos\n", "abstract": " En este art\u00edculo se describe una experiencia docente basada en el uso de datos abiertos para el aprendizaje, a trav\u00e9s de proyectos, en el grupo ARA (Alto Rendimiento Acad\u00e9mico) de la asignatura \u201cDise\u00f1o de Base de Datos\u201d del Grado en Ingenier\u00eda Inform\u00e1tica de la Universidad de Alicante en el curso 2012/2013. La filosof\u00eda de datos abiertos permite que est\u00e9n a disposici\u00f3n del alumnado una ingente cantidad de datos en formato tabular, listos para su reutilizaci\u00f3n. En nuestra experiencia docente, el alumnado propone un escenario original donde diferentes datos abiertos puedan usarse para una finalidad y utilidad concreta. Luego, se propone dise\u00f1ar una base de datos que permita la gesti\u00f3n de estos datos. El uso de datos abiertos en la asignatura ha posibilitado inculcar en el alumnado una actitud creativa y emprendedora, a la vez que se fomenta el aprendizaje aut\u00f3nomo. Se presenta tambi\u00e9n los resultados de una encuesta realizada al alumnado al final del curso con el fin de evaluar la experiencia docente.", "num_citations": "2\n", "authors": ["582"]}
{"title": "Gu\u00eda de dise\u00f1o basada en el Modelo de Motivaci\u00f3n del Negocio BMM* para la mejora del alineamiento entre el Almac\u00e9n de Datos y la Estrategia del Negocio.\n", "abstract": " Garantizar que los almacenes de datos est\u00e9n alineados a la estrategia del negocio es primordial para su \u00e9xito, ya que \u00e9stos son utilizados por los sistemas de apoyo a la toma de decisiones con el fin lograr el plan estrat\u00e9gico de la organizaci\u00f3n. En este contexto, el grupo de investigaci\u00f3n Lucentia se ha preocupado por dise\u00f1ar AD en el contexto organizacional, por lo que lleva tiempo desarrollando y mejorando una propuesta de ingenier\u00eda de requisitos para AD. En este trabajo mejoramos la propuesta actual presentando una gu\u00eda de alineamiento que considera, la misi\u00f3n y visi\u00f3n del negocio de tal manera de estar en concordancia con:(i) los objetivos (obtenidas desde los analistas de informaci\u00f3n),(ii) los cursos de acci\u00f3n (estrategias y t\u00e1cticas desde donde se seleccionan las decisiones, las tareas y recursos para obtener los requerimientos de informaci\u00f3n del AD),(iii) y las reglas del negocio que permiten el logro de los objetivos definidos. De esta manera se permite la verificaci\u00f3n y validaci\u00f3n del alineamiento entre los requisitos de informaci\u00f3n del AD a la estrategia organizacional Se presenta un caso de estudio que muestra el proceso completo. Los aportes de la investigaci\u00f3n se detallan en la secci\u00f3n final. Palabras Claves: almac\u00e9n de datos, gu\u00eda de alineamiento, modelado de objetivos, an\u00e1lisis de requisitos.", "num_citations": "2\n", "authors": ["582"]}
{"title": "Una Aproximaci\u00f3n basada en i* para el an\u00e1lisis de Requisitos de Seguridad en Almacenes de Datos\n", "abstract": " Las propuestas de an\u00e1lisis de requisitos para almacenes de datos (AD) se centran \u00fanicamente en las necesidades de informaci\u00f3n de los usuarios, sin tener en cuenta otro tipo de requisitos como la seguridad o el rendimiento. Sin embargo, el modelado de estos aspectos en etapas tempranas del desarrollo es fundamental para obtener un AD que satisfaga las expectativas del usuario. En este art\u00edculo, se definen dos tipos de requisitos a considerar en el dise\u00f1o del AD: requisitos de informaci\u00f3n y de calidad de servicio. Estos requisitos se definen dentro del marco de MDA (Model Driven Architecture), lo que permite su traceability hacia etapas posteriores de dise\u00f1o conceptual y l\u00f3gico. Cabe destacar que este art\u00edculo se centra en proponer un modelo de requisitos de seguridad (como un tipo concreto de requisitos de calidad de servicio), as\u00ed como un proceso en tres fases para su modelado conjuntamente con los requisitos de informaci\u00f3n.", "num_citations": "2\n", "authors": ["582"]}
{"title": "Model-Driven Development of Web APIs to Access Integrated Tabular Open Data\n", "abstract": " More and more governments around the world are publishing tabular open data, mainly in formats such as CSV or XLS(X). These datasets are mostly individually published, i.e. each publisher exposes its data on the Web without considering potential relationships with other datasets (from its own or from other publishers). As a result, reusing several open datasets together is not a trivial task, thus requiring mechanisms that allow data consumers (as software developers or data scientists) to integrate and access tabular open data published on the Web. In this paper, we propose a model-driven approach to automatically generate Web APIs that homogeneously access multiple integrated tabular open datasets. This work focuses on data that can be integrated by means of join and union operations. As a first step, our approach detects unionable and joinable tabular open data by using a table similarity measure\u00a0\u2026", "num_citations": "1\n", "authors": ["582"]}
{"title": "Defining a Master Data Management approach for increasing open data understandability\n", "abstract": " Reusing open data is an opportunity for eSociety to create value through the development of novel data-intensive IT services and products. However, reusing open data is hampered by lack of data understandability. Actually, accessing open data requires additional information (i.e., metadata) that describes its content in order to make it understandable: if open data is misinterpreted ambiguities and misunderstandings will discourage eSociety for reusing it. In addition, services and products created by using incomprehensible open data may not generate enough confidence in potential users, thus becoming unsuccessful. Unfortunately, in order to improve the comprehensibility of the data, current proposals focus on creating metadata when open data is being published, thus overlooking metadata coming from data sources. In order to overcome this gap, our research proposes a framework to consider data\u00a0\u2026", "num_citations": "1\n", "authors": ["582"]}
{"title": "Knowledge Spring Process\n", "abstract": " Data is everywhere, and non-expert users must be able to exploit it in order to extract knowledge, get insights and make well-informed decisions. The value of the discovered knowledge could be of greater value if it is available for later consumption and reusing. In this paper, we present the first version of the Knowledge Spring Process, an infrastructure that allows non-expert users to (i) apply user-friendly data mining techniques on open data sources, and (ii) share results as Linked Open Data (LOD). The main contribution of this paper is the concept of reusing the knowledge gained from data mining processes after being semantically annotated as LOD, then obtaining Linked Open Knowledge. Our Knowledge Spring Process is based on a model-driven viewpoint in order to easier deal with the wide diversity of open data formats.", "num_citations": "1\n", "authors": ["582"]}
{"title": "Aproximaciones en ingenier\u00eda web para el an\u00e1lisis de requisitos: una revisi\u00f3n sistem\u00e1tica de la literatura\n", "abstract": " La tecnolog\u00eda aplicada al desarrollo de software en ingenier\u00eda Web (WE) enfrenta continuos cambios, lo cual implica un esfuerzo extra por parte de los analistas, desarrolladores y dise\u00f1adores en el dise\u00f1o y mantenimiento de las aplicaciones Web. En este contexto, definir los requisitos (funcionales y no-funcionales) que el sistema debe cumplir para satisfacer las necesidades de los usuarios es una tarea compleja. En este art\u00edculo se presenta una revisi\u00f3n sistem\u00e1tica de la literatura con el fin de obtener:(i) el estado del arte actual sobre aproximaciones sistem\u00e1ticas para el modelado, an\u00e1lisis y especificaci\u00f3n de requisitos en ingenier\u00eda Web y (ii) una base conceptual para proponer \u00e1reas de investigaci\u00f3n.", "num_citations": "1\n", "authors": ["582"]}
{"title": "Report of the international workshop on business intelligence and the web: BEWEB 2011\n", "abstract": " The 2nd International Workshop on Business intelligencE and the WEB (BEWEB) was co-located with the EDBT/ICDT 2011 Joint Conference in Uppsala (Sweden) on March 25, 2011. BEWEB intends to be an international forum for researchers and practitioners to exchange ideas on how to leverage the huge amount of data that is available on the Web in BI applications and on how to apply Web engineering methods and techniques to the design of BI applications. This report summarizes the 2011 edition of BEWEB.", "num_citations": "1\n", "authors": ["582"]}
{"title": "Las redes sociales y su relaci\u00f3n con los estilos de aprendizaje\n", "abstract": " Debido a los cambios que el Espacio Europeo de Educaci\u00f3n Superior introduce al potenciar las horas de trabajo no presencial, se hacen necesarios nuevos mecanismos para posibilitar una mejor comunicaci\u00f3n y cooperaci\u00f3n en el proceso de aprendizaje. Las redes sociales, como Facebook, pueden suministrar estos mecanismos, pero su uso satisfactorio para la docencia puede verse afectado en gran medida por el estilo de aprendizaje de los alumnos. Por lo tanto, este art\u00edculo plantea la necesidad de estudiar la influencia de los diferentes estilos de aprendizaje en la docencia no presencial mediante el uso de redes sociales con el fin de incrementar el rendimiento de los alumnos. Concretamente, la hip\u00f3tesis de partida de este trabajo es que el uso de una red social como Facebook por parte de un grupo de estudiantes con diferentes estilos de aprendizaje puede hacer que el rendimiento global mejore. Con la finalidad de corroborar esta hip\u00f3tesis se han propuesto una serie de experimentos llevados a cabo en la asignatura Dise\u00f1o y Programaci\u00f3n Avanzada de Aplicaciones impartida en Ingenier\u00eda Inform\u00e1tica de la Universidad de Alicante, cuya realizaci\u00f3n, resultados y discusi\u00f3n se muestran en este art\u00edculo.", "num_citations": "1\n", "authors": ["582"]}
{"title": "Foreword: First International Workshop on the Web and Requirements Engineering\n", "abstract": " The International Workshop on the Web and Requirements Engineering (WeRE) was held in conjunction with the 18 th  International IEEE Requirements Engineering Conference (RE'10) in Sydney (Australia) on September 28 2010. WeRE intends to be an international forum for exchanging ideas on both using Web technologies as a platform in the requirements engineering field, and applying requirements engineering in the development and use of websites. Papers focused on new domains and new experiences with the connection between requirements engineering and the Web were presented in WeRE.", "num_citations": "1\n", "authors": ["582"]}
{"title": "A model driven process for spatial data sources and spatial data warehouses reconcilation\n", "abstract": " Since the data warehouse integrates the information provided by data sources, it is crucial to reconcile these sources with the information requirements of decision makers. It is specially true when novel types of data and metadata are stored in the data sources, e.g. spatial issues. In this way, spatial requirements have to be conformed with the available spatial metadata in order to obtain a data warehouse that, at the same time, satisfies decision maker spatial needs and do not attempt against the available metadata stored in the data sources. Therefore, in this paper, we have based on multidimensional forms and some spatial and geometric considerations to define a set of Query/View/Transformation (QVT) relations to formally define a set of rules that help designers in this tedious and prone-to-fail task. The novelty of our approach is to consider an hybrid viewpoint to develop spatial data warehouses (SDW\u00a0\u2026", "num_citations": "1\n", "authors": ["582"]}
{"title": "Modelo de Requisitos Y Modelo de Dominio, Trazabilidad Mediante Modelos de Weaving.\"\n", "abstract": " Las aproximaciones sistem\u00e1ticas para el modelado, an\u00e1lisis y especificaci\u00f3n de requisitos en ingenier\u00eda Web basadas en una arquitectura dirigida por modelos (Model-Driven Architecture, MDA) carecen de soporte para trazabilidad entre los modelos conceptuales, le dan poca relevancia, no la incluyen por completo o sus respectivas t\u00e9cnicas est\u00e1n pobremente aplicadas en el campo de la ingenier\u00eda Web. En este trabajo, se presenta una propuesta mediante el uso de los modelos de weaving para soportar la trazabilidad entre el modelo de requisitos y modelo de dominio, ambos, modelos conceptuales del m\u00e9todo A-OOH (Adaptive-Object Oriented Hipermedia).", "num_citations": "1\n", "authors": ["582"]}
{"title": "Hacia la consideraci\u00f3n de aspectos de calidad de datos en procesos de miner\u00eda: el caso de las t\u00e9cnicas de clasificaci\u00f3n\n", "abstract": " El \u00e9xito en la b\u00fasqueda de conocimiento a partir de grandes cantidades de datos radica en la calidad de los mismos. Hasta ahora los aspectos de calidad de los datos se han enfocado principalmente a la limpieza de los datos: detecci\u00f3n de duplicados, valores at\u00edpicos, perdidos, incompletos o conflictos en instancias, entre otros. En este trabajo se presenta un caso de estudio que nos ha permitido determinar ciertos aspectos de calidad que pueden mejorar la expectativa de \u00e9xito en el an\u00e1lisis evitando resultados err\u00f3neos, incorrectos o poco fiables. Este es un primer paso hacia la consideraci\u00f3n de manera sistem\u00e1tica y estructurada de criterios de calidad espec\u00edficos para miner\u00eda de datos que ayude al minero de datos en sus objetivos.", "num_citations": "1\n", "authors": ["582"]}
{"title": "El Alineamiento de Objetivos de la Organizaci\u00f3n como propuesta para el An\u00e1lisis de Requisitos en Almacenes de Datos\n", "abstract": " Garantizar que los Almacenes de Datos proporcionen apoyo al desarrollo de la estrategia de la organizaci\u00f3n es fundamental para el \u00e9xito del negocio. En este sentido, las organizaciones deben centrar sus objetivos en la misi\u00f3n, visi\u00f3n, y plan estrat\u00e9gico durante el proceso de obtenci\u00f3n de requisitos. A partir de experiencias revisadas, observamos un gran n\u00famero de Almacenes de Datos desarrollados que podr\u00edan considerarse exitosos, desde la perspectiva de la inteligencia de negocios, sin embargo, dentro de la organizaci\u00f3n fueron clasificados como fracaso, entre otras causas, debido a que los objetivos obtenidos no est\u00e1n alineados con la estrategia del negocio. En este art\u00edculo se presenta una propuesta para obtener un modelo de an\u00e1lisis de requisitos, que complementa el trabajo desarrollado por el grupo de investigaci\u00f3n Lucentia, integrando: las necesidades de los usuarios, el modelado de objetivos para el Almac\u00e9n de Datos, y el alineamiento de estos con la estrategia del negocio. Se presentan un caso de estudio que muestra el proceso completo.", "num_citations": "1\n", "authors": ["582"]}
{"title": "Using the magnet metaphor for multivariate visualization in Software management\n", "abstract": " This paper presents SoftMagnet, a new multivariate analysis model for controlling and managing the processes of software project development. SoftMagnet uses metaphors and visual representation techniques to explore several key indicators in order to support problem detection and resolution. The resulting visualization addresses diverse management tasks, such as tracking of deviations from the plan, analysis of patterns of failure detection and correction, overall assessment of change management policies, and estimation of product quality. The proposed visualization uses a metaphor with magnets along with various interactive techniques to represent information concerning the software development process and to deal efficiently with multivariate visual queries. This paper shows the final implementation of SoftMagnet in JavaFX with data of a real project as well as the results of testing the tool with the aforementioned data.", "num_citations": "1\n", "authors": ["582"]}
{"title": "Data Warehousing Meets MDA\n", "abstract": " Multidimensional (MD) models are the cornerstone of data warehouse (DW) systems since they allow users to better understand data for decision support, while the performance is improved. MD modeling consists of several phases in the same way as traditional database design: conceptual, logical and physical. In this paper, we argue that designing a conceptual MD model of a DW and deriving its logical representation are very complex, prone to fail, and time consuming tasks. Specifically, two main issues must be considered:(i) the joint analysis of both, information needs of decision makers, and the available operational data sources that will populate the DW, in order to obtain a conceptual MD model, and (ii) the development of formal and automatic transformations between the conceptual and logical design phases. However, no significant effort has been done to take into account these issues in a systematic\u00a0\u2026", "num_citations": "1\n", "authors": ["582"]}
{"title": "Modelado de Requisitos de Seguridad para Almacenes de Datos.\n", "abstract": " Las propuestas de an\u00e1lisis de requisitos para almacenes de datos (AD) se centran \u00fanicamente en las necesidades de informaci\u00f3n de los usuarios, sin tener en cuenta otro tipo de requisitos como la seguridad o el rendimiento. Sin embargo, el modelado de estos aspectos en etapas tempranas del desarrollo es fundamental para obtener un AD que satisfaga las expectativas del usuario. En este art\u0131culo, se definen dos tipos de requisitos a considerar en el diseno del AD: requisitos de informaci\u00f3n y de calidad de servicio. Estos requisitos se definen dentro del marco de MDA (Model Driven Architecture), lo que permite su trazabilidad hacia etapas posteriores de diseno conceptual y l\u00f3gico. Cabe destacar que este art\u0131culo se centra en proponer un modelo de requisitos de seguridad (como un tipo concreto de requisitos de calidad de servicio), as\u0131 como un proceso en tres fases para su modelado conjuntamente con los requisitos de informaci\u00f3n.", "num_citations": "1\n", "authors": ["582"]}
{"title": "Requirements in web engineering: A systematic literature review\n", "abstract": " Requirements engineering is one of the most crucial phases in software development in which designers can attempt to fully satisfy users\u2019 needs, and an effective definition of requirements both contributes towards making the right design decisions and helps to support change management, thus improving the quality of the final software product. Web engineering methods should consider a requirement engineering phase that suits the Web\u2019s large heterogeneous user community. The objective of this work is to classify the literature with regard to the requirements engineering applied in the Web domain, with which has allowed us to formally obtain the current state-of-the-art. The present work is based on the systematic literature review method proposed by Barbara Kitchenham, we reviewed publications from ACM, IEEE Computer Society Digital Library, Science Direct, DBLP and World Wide Web. From a\u00a0\u2026", "num_citations": "1\n", "authors": ["582"]}