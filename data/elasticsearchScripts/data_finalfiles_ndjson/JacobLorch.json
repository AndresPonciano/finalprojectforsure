{"title": "FARSITE: Federated, available, and reliable storage for an incompletely trusted environment\n", "abstract": " Farsite is a secure, scalable file system that logically functions as a centralized file server but is physically distributed among a set of untrusted computers. Farsite provides file availability and reliability through randomized replicated storage; it ensures the secrecy of file contents with cryptographic techniques; it maintains the integrity of file and directory data with a Byzantine-fault-tolerant protocol; it is designed to be scalable by using a distributed hint mechanism and delegation certificates for pathname translations; and it achieves good performance by locally caching file data, lazily propagating file updates, and varying the duration and granularity of content leases. We report on the design of Farsite and the lessons we have learned by implementing much of that design.", "num_citations": "1311\n", "authors": ["662"]}
{"title": "A Comparison of File System Workloads.\n", "abstract": " In this paper, we describe the collection and analysis of file system traces from a variety of different environments, including both UNIX and NT systems, clients and servers, and instructional and production systems. Our goal is to understand how modern workloads affect the ability of file systems to provide high performance to users. Because of the increasing gap between processor speed and disk latency, file system performance is largely determined by its disk behavior. Therefore we primarily focus on the disk I/O aspects of the traces. We find that more processes access files via the memory-map interface than through the read interface. However, because many processes memory-map a small set of files, these files are likely to be cached. We also find that file access has a bimodal distribution pattern: some files are written repeatedly without being read; other files are almost exclusively read. We develop a new metric for measuring file lifetime that accounts for files that are never deleted. Using this metric, we find that the average block lifetime for some workloads is significantly longer than the 30-second write delay used by many file systems. However, all workloads show lifetime locality: the same files tend to be overwritten multiple times.", "num_citations": "777\n", "authors": ["662"]}
{"title": "Improving dynamic voltage scaling algorithms with PACE\n", "abstract": " This paper addresses algorithms for dynamically varying (scaling) CPU speed and voltage in order to save energy. Such scaling is useful and effective when it is immaterial when a task completes, as long as it meets some deadline. We show how to modify any scaling algorithm to keep performance the same but minimize expected energy consumption. We refer to our approach as PACE (Processor Acceleration to Conserve Energy) since the resulting schedule increases speed as the task progresses. Since PACE depends on the probability distribution of the task's work requirement, we present methods for estimating this distribution and evaluate these methods on a variety of real workloads. We also show how to approximate the optimal schedule with one that changes speed a limited number of times. Using PACE causes very little additional overhead, and yields substantial reductions in CPU energy\u00a0\u2026", "num_citations": "531\n", "authors": ["662"]}
{"title": "A five-year study of file-system metadata\n", "abstract": " For five years, we collected annual snapshots of file-system metadata from over 60,000 Windows PC file systems in a large corporation. In this article, we use these snapshots to study temporal changes in file size, file age, file-type frequency, directory size, namespace structure, file-system population, storage capacity and consumption, and degree of file modification. We present a generative model that explains the namespace structure and the distribution of directory sizes. We find significant temporal trends relating to the popularity of certain file types, the origin of file content, the way the namespace is used, and the degree of variation among file systems, as well as more pedestrian changes in size and capacities. We give examples of consequent lessons for designers of file systems and related software.", "num_citations": "490\n", "authors": ["662"]}
{"title": "Software strategies for portable computer energy management\n", "abstract": " Limiting the energy consumption of computers, especially portables, is becoming increasingly important. Thus, new energy-saving computer components and architectures have been and continue to be developed. Many architectural features have both high-performance and low-power modes, with the mode selection under software control. The problem is to minimize energy consumption while not significantly impacting the effective performance. We group the software control issues as follows: transition, load-change, and adaptation. The transition problem is deciding when to switch to low-power, reduced-functionality modes. The load-change problem is determining how to modify the load on a component so that it can make further use of its low-power modes. The adaptation problem is determining how to create software that allows components to be used in novel, power-saving ways. We survey implemented\u00a0\u2026", "num_citations": "416\n", "authors": ["662"]}
{"title": "Enabling Security in Cloud Storage SLAs with CloudProof.\n", "abstract": " Several cloud storage systems exist today, but none of them provide security guarantees in their Service Level Agreements (SLAs). This lack of security support has been a major hurdle for the adoption of cloud services, especially for enterprises and cautious consumers. To fix this issue, we present CloudProof, a secure storage system specifically designed for the cloud. In CloudProof, customers can not only detect violations of integrity, write-serializability, and freshness, they can also prove the occurrence of these violations to a third party. This proof-based system is critical to enabling security guarantees in SLAs, wherein clients pay for a desired level of security and are assured they will receive a certain compensation in the event of cloud misbehavior. Furthermore, since CloudProof aims to scale to the size of large enterprises, we delegate as much work as possible to the cloud and use cryptographic tools to allow customers to detect and prove cloud misbehavior. Our evaluation of CloudProof indicates that its security mechanisms have a reasonable cost: they incur a latency overhead of only\u223c 15% on reads and writes, and reduce throughput by around 10%. We also achieve highly scalable access control, with membership management (addition and removal of members\u2019 permissions) for a large proprietary software with more than 5000 developers taking only a few seconds per month.", "num_citations": "354\n", "authors": ["662"]}
{"title": "Donnybrook: Enabling large-scale, high-speed, peer-to-peer games\n", "abstract": " Without well-provisioned dedicated servers, modern fast-paced action games limit the number of players who can interact simultaneously to 16-32. This is because interacting players must frequently exchange state updates, and high player counts would exceed the bandwidth available to participating machines. In this paper, we describe Donnybrook, a system that enables epic-scale battles without dedicated server resources, even in a fast-paced game with tight latency bounds. It achieves this scalability through two novel components. First, it reduces bandwidth demand by estimating what players are paying attention to, thereby enabling it to reduce the frequency of sending less important state updates. Second, it overcomes resource and interest heterogeneity by disseminating updates via a multicast system designed for the special requirements of games: that they have multiple sources, are latency-sensitive\u00a0\u2026", "num_citations": "244\n", "authors": ["662"]}
{"title": "Matchmaking for online games and other latency-sensitive P2P systems\n", "abstract": " The latency between machines on the Internet can dramatically affect users' experience for many distributed applications. Particularly, in multiplayer online games, players seek to cluster themselves so that those in the same session have low latency to each other. A system that predicts latencies between machine pairs allows such matchmaking to consider many more machine pairs than can be probed in a scalable fashion while users are waiting. Using a far-reaching trace of latencies between players on over 3.5 million game consoles, we designed Htrae, a latency prediction system for game matchmaking scenarios. One novel feature of Htrae is its synthesis of geolocation with a network coordinate system. It uses geolocation to select reasonable initial network coordinates for new machines joining the system, allowing it to converge more quickly than standard network coordinate systems and produce\u00a0\u2026", "num_citations": "225\n", "authors": ["662"]}
{"title": "TrInc: Small Trusted Hardware for Large Distributed Systems.\n", "abstract": " A simple yet remarkably powerful tool of selfish and malicious participants in a distributed system is \u201cequivocation\u201d: making conflicting statements to others. We present TrInc, a small, trusted component that combats equivocation in large, distributed systems. Consisting fundamentally of only a non-decreasing counter and a key, TrInc provides a new primitive: unique, once-in-alifetime attestations.We show that TrInc is practical, versatile, and easily applicable to a wide range of distributed systems. Its deployment is viable because it is simple and because its fundamental components\u2014a trusted counter and a key\u2014are already deployed in many new personal computers today. We demonstrate TrInc\u2019s versatility with three detailed case studies: attested append-only memory (A2M), PeerReview, and BitTorrent. We have implemented TrInc and our three case studies using real, currently available trusted hardware. Our evaluation shows that TrInc eliminates most of the trusted storage needed to implement A2M, significantly reduces communication overhead in PeerReview, and solves an open incentives issue in BitTorrent. Microbenchmarks of our TrInc implementation indicate directions for the design of future trusted hardware.", "num_citations": "209\n", "authors": ["662"]}
{"title": "PACE: A new approach to dynamic voltage scaling\n", "abstract": " By dynamically varying CPU speed and voltage, it is possible to save significant amounts of energy while still meeting prespecified soft or hard deadlines for tasks; numerous algorithms have been published with this goal. We show that it is possible to modify any voltage scaling algorithm to minimize energy use without affecting perceived performance and present a formula to do so optimally. Because this formula specifies increased speed as the task progresses, we call this approach PACE (Processor Acceleration to Conserve Energy). This optimal formula depends on the probability distribution of the task's work requirement and requires that the speed be varied continuously. We therefore present methods for estimating the task work distribution and evaluate how effective they are on a variety of real workloads. We also show how to approximate the optimal continuous schedule with one that changes speed a\u00a0\u2026", "num_citations": "180\n", "authors": ["662"]}
{"title": "Can the fractal dimension of images be measured?\n", "abstract": " Fractal dimension is a popular parameter for explaining certain phenomena and for describing natural textures. The problem of estimating the fractal dimension of a profile or an image is more difficult and devious than theory suggests. This paper studies the accuracy and robustness of two common estimators of fractal dimension (box counting and the variation method) using two types of data (Brownian and Takagi). Poor results are demonstrated from applying theory directly, called naive estimation. Data is then interpreted in the most optimistic way possible by matching the estimator to the known fractal dimension. Experiments quantify the effects of resolution, or fineness of sampling, and quantization, or rounding of sampled values. Increasing resolution enhances the estimators when true dimension, D, is large, but may, possibly due to quantization effect, degrade estimators when D is small. Quantization simply\u00a0\u2026", "num_citations": "154\n", "authors": ["662"]}
{"title": "Leveraging legacy code to deploy desktop applications on the web.\n", "abstract": " Xax is a browser plugin model that enables developers to leverage existing tools, libraries, and entire programs to deliver feature-rich applications on the web. Xax employs a novel combination of mechanisms that collectively provide security, OS-independence, performance, and support for legacy code. These mechanisms include memory-isolated native code execution behind a narrow syscall interface, an abstraction layer that provides a consistent binary interface across operating systems, system services via hooks to existing browser mechanisms, and lightweight modifications to existing tool chains and code bases. We demonstrate a variety of applications and libraries from existing code bases, in several languages, produced with various tool chains, running in multiple browsers on multiple operating systems. With roughly two person-weeks of effort, we ported 3.3 million lines of code to Xax, including a PDF viewer, a Python interpreter, a speech synthesizer, and an OpenGL pipeline.", "num_citations": "128\n", "authors": ["662"]}
{"title": "The SMART way to migrate replicated stateful services\n", "abstract": " Many stateful services use the replicated state machine approach for high availability. In this approach, a service runs on multiple machines to survive machine failures. This paper describes SMART, a new technique for changing the set of machines where such a service runs, ie, migrating the service. SMART improves upon existing techniques in three important ways. First, SMART allows migrations that replace non-failed machines. Thus, SMART enables load balancing and lets an automated system replace failed machines. Such autonomic migration is an important step toward full autonomic operation, in which administrators play a minor role and need not be available twenty-four hours a day, seven days a week. Second, SMART can pipeline concurrent requests, a useful performance optimization. Third, prior published migration techniques are described in insufficient detail to admit implementation, whereas\u00a0\u2026", "num_citations": "108\n", "authors": ["662"]}
{"title": "Lossless recovery for computer systems with map assisted state transfer\n", "abstract": " Described are systems and techniques for losslessly restarting subsystems in a distributed file system. By partitioning functionality and logging appropriately across the kernel and user-level boundaries on a client, the user-level subsystem may be made losslessly restartable. In particular, a map assisted state transfer may include receiving one or more state updates, marshaling one or more active data-structures into a marshaled shadow, applying the received state updates to the marshaled shadow and re-instantiating the active data-structures by unmarshaling the marshaled shadow.", "num_citations": "95\n", "authors": ["662"]}
{"title": "Deterministic multiprocessor computer system\n", "abstract": " A virtual machine monitor (VMM) is configured to enforce deterministic execution of virtual machines in a multiprocessor machine. The VMM is configured to ensure that any communication by physical processors via shared memory is deterministic. When such VMMs are implemented in a distributed environment of multiprocessor machines coupled via a logical communication link, non-deterministic server applications running on virtual machines using the VMM may be replicated.", "num_citations": "84\n", "authors": ["662"]}
{"title": "Reducing processor power consumption by improving processor time management in a single-user operating system\n", "abstract": " The CPU is one of the major power consumers in a portable computer, and considerable power can be saved by turning off the CPU when it is not doing useful work. In Apple's MacOS, however, idle time is often converted to busy waiting, and generally it is very hard to tell when no useful computation is occurring. In this paper, we suggest several heuristic techniques for identifying this condition, and for temporarily putting the CPU in a low-power state. These techniques include turning off the processor when all processes are blocked, turning off the processor when processes appear to be busy waiting, and extending real time process sleep periods. We use trace-driven simulation, using processor run interval traces, to evaluate the potential energy savings and performance impact. We find that these techniques save considerable amounts of processor energy (as much as 66%), while having very little performance\u00a0\u2026", "num_citations": "83\n", "authors": ["662"]}
{"title": "Efficient changing of replica sets in distributed fault-tolerant computing system\n", "abstract": " A distributed computing system can be operated in a fault tolerant manner using a set of computing devices. A set of computing devices can tolerate a number of failures by implementing identical replicas of a state machine and selecting proposals. The set of computing devices participating in the distributed computing system by hosting replicas can be modified by adding or removing a computing device from the set, or by specifying particular computing devices for participation. Changing the participating computing devices in the set increases fault tolerance by replacing defective devices with operational devices, or by increasing the amount of redundancy in the system.", "num_citations": "82\n", "authors": ["662"]}
{"title": "Scheduling techniques for reducing processor energy use in MacOS\n", "abstract": " The CPU is one of the major power consumers in a portable computer, and considerable power can be saved by turning off the CPU when it is not doing useful work. In Apple's MacOS, however, idle time is often converted to busy waiting, and generally it is very hard to tell when no useful computation is occurring. In this paper, we suggest several heuristic techniques for identifying this condition, and for temporarily putting the CPU in a low\u2010power state. These techniques include turning off the processor when all processes are blocked, turning off the processor when processes appear to be busy waiting, and extending real time process sleep periods. We use trace\u2010driven simulation, using processor run interval traces, to evaluate the potential energy savings and performance impact. We find that these techniques save considerable amounts of processor energy (as much as 66%), while having very little\u00a0\u2026", "num_citations": "81\n", "authors": ["662"]}
{"title": "A complete picture of the energy consumption of a portable computer\n", "abstract": " High battery lifetime is important to the usability and acceptance of portable computers. In order to develop strategies to minimize power consumption, designers need a good picture of the total power consumption of a system. For this purpose, we indicate the power consumptions of a set of portable computers and how they are broken down among the components of those computers. Then, we use user pro les to show how the use of powersaving features currently implemented serves to reduce these power consumptions by 35 {56%. We also show how these power-saving features a ect the breakdown of overall power consumption, so that we can evaluate how successful certain new software techniques and hardware changes would be at reducing power consumption. The results of this paper point out the most promising avenues for further work in the reduction of power consumption, and indicate some strategies that can provide an immediate power bene t to the class of machines studied.", "num_citations": "81\n", "authors": ["662"]}
{"title": "Network application performance enhancement using speculative execution\n", "abstract": " A speculative web browser engine may enable providing transmission of content between a server and a client prior to a user-initiated request for the content hidden in imperative code (event handlers), which may reduce user-perceived latency when the user initiates the imperative code. In some aspects, a speculative browser state may be created from an actual browser state and used to run the event handlers. The event handlers may be modified to direct actions of the event handler to update the speculative browser state. Speculative content may be transmitted between the server and the client in response to an execution of the modified code. The speculative content may be stored in a cache and made readily available for use when the user initiates the event handler and finds that the desired content has already been fetched.", "num_citations": "80\n", "authors": ["662"]}
{"title": "Operating system modifications for task-based speed and voltage\n", "abstract": " This paper describes RightSpeed, a task-based speed and voltage scheduler for Windows 2000. It takes advantage of the ability of certain processors, such as those from Transmeta and AMD, to dynamically change speed and voltage and thus to save energy while running more slowly. RightSpeed uses PACE, an algorithm that computes the most energy efficient way to meet task deadlines with high probability. Since most applications do not provide enough data about tasks, such as task deadlines, for PACE to work, RightSpeed uses simple and efficient heuristics to automatically detect task characteristics for such applications. RightSpeed has only 1.2% background overhead and its operations take only a few microseconds each. It even performs PACE calculation, which is quite complicated, in only 4.4 \u00b5s on average due to our extensive optimizations. RightSpeed is effective at meeting performance targets set\u00a0\u2026", "num_citations": "79\n", "authors": ["662"]}
{"title": "Isolation environment-based information access\n", "abstract": " In an embodiment of isolation environment-based information access, programs\u2014including operating systems and applications\u2014running on a computing-based device can be isolated in an environment such as a virtual machine. Information including commands and/or data transmitted between the computing-based device and the program (s) being run, as well as information associated with the program (s) and the computing-based device, is accessed without being detected by the program (s). In one implementation, the information includes state information as well as commands and/or data\u2014including sensitive information, such as usernames and passwords. In another implementation, the information can be used to secretly access the program (s).", "num_citations": "71\n", "authors": ["662"]}
{"title": "Composing OS extensions safely and efficiently with Bascule\n", "abstract": " Library OS (LibOS) architectures implement the OS personality as a user-mode library, giving each application the flexibility to choose its LibOS. This approach is appealing for many reasons, not least the ability to extend or customise the LibOS. Recent work with Drawbridge [29] showed that an existing commodity OS (Windows 7) could be refactored to produce a LibOS while retaining application compatibility.", "num_citations": "54\n", "authors": ["662"]}
{"title": "The VTrace tool: building a system tracer for Windows NT and Windows 2000\n", "abstract": " This article describes the techniques used to construct VTrace, a system tracer for Windows NT and Windows 2000. VTrace collects data about processes, threads, messages, disk operations, network operations, and devices. The technique uses a DLL loaded into the address space of every process to intercept Win32 system calls; establishes hook functions for Windows NT kernel system calls; modifies the context switch code in memory to log context switches; and uses device filters to log accesses to devices. riting a tracer for an operating system can be a nightmare. The size and complexity of an operating system complicates debugging, and it's especially tricky to debug code that runs before the system has fully started up. Many runs require rebooting the computer, and failed runs can require reinstalling the operating system or even reformatting the hard drive. Writing a tracer for Windows NT\u00ae and Windows\u00ae\u00a0\u2026", "num_citations": "53\n", "authors": ["662"]}
{"title": "Method and apparatus for thwarting traffic analysis in online games\n", "abstract": " The subject disclosure relates to a method and apparatus for routing data in a network-based computer game via proxy computers. The method and system includes a set of techniques that utilizes the proxy computers to thwart traffic analysis in high-speed games while continuing to satisfy the games' latency requirements. The method and apparatus facilitates thwarting multiple classes of traffic analysis, including inspection of unencrypted header fields, observation of packet size, correlation of packet timing, and collusion among players. A matchmaking system for matching players in a network-based computer game in a manner that resists traffic analysis is also provided.", "num_citations": "51\n", "authors": ["662"]}
{"title": "Security service level agreements with publicly verifiable proofs of compliance\n", "abstract": " Techniques are described herein that are capable of providing security guarantees in security service level agreements (SLAB). For instance, a security SLA may specify a level of service to be provided to a user with respect to at least one security property (eg, confidentiality, integrity, write-serialization, read freshness, etc.). Attestations may be used to prove occurrence (or non-occurrence) of violations of security properties in a manner that is universally verifiable, eg, by third parties. An attestation is an indicator that is generated by a user to certify that the user makes a request (eg, get request or put request) or an indicator that is generated by a cloud service provider to certify that the cloud service provider accurately fulfills a request of a user. A security SLA may specify a payment to be made to a user in response to an occurrence of a violation of a security property.", "num_citations": "48\n", "authors": ["662"]}
{"title": "Operating systems techniques for reducing processor energy consumption\n", "abstract": " In the last decade, limiting computer energy consumption has become a pervasive goal in computer design, largely due to growing use of portable and embedded computers with limited battery capacities. This work concerns ways to reduce processor energy consumption, since the processor consumes much of a computer's energy. Our specific contributions are as follows.", "num_citations": "48\n", "authors": ["662"]}
{"title": "Using user interface event information in dynamic voltage scaling algorithms\n", "abstract": " Increasingly, mobile computers use dynamic voltage scaling (DVS) to reduce CPU voltage and speed and thereby increase battery life. To determine how to change voltage and speed when responding to user interface events, we analyze traces of real user workloads. We evaluate a new heuristic for inferring when user interface tasks complete and find it is more efficient and nearly as effective as other approaches. We compare DVS algorithms and find that for a given performance level, the PACE algorithm uses the least energy and the Stepped algorithm uses the second least. We find that different types of user interface event (mouse movements, mouse clicks, and keystrokes) trigger tasks with significantly different CPU use, suggesting one should use different speeds for different event types. We also find differences in CPU use between categories of the same event type, e.g., between pressing spacebar and\u00a0\u2026", "num_citations": "47\n", "authors": ["662"]}
{"title": "Scaling Peer-to-Peer Games in Low-Bandwidth Environments.\n", "abstract": " In peer-to-peer multiplayer games, each peer must send periodic updates of its objects to other peers. Since typical broadband users have little upload bandwidth, updates to each player will be infrequent when there are many players in the game. This leads to choppy and unsatisfying gameplay. Therefore, we propose three techniques to compensate for low upload bandwidth in peer-to-peer games: focus sets, pairwise rapid agreement, and guidable AI. To test these techniques, we implement them and conduct a user study that evaluates the resulting game. We find that our techniques make a game played with low bandwidth significantly more fun than existing techniques, and nearly as much fun as one played on a LAN. Thus, they enable an order of magnitude more players than existing techniques.", "num_citations": "38\n", "authors": ["662"]}
{"title": "Continuous tamper-proof logging using tpm 2.0\n", "abstract": " Auditing system logs is an important means of ensuring systems\u2019 security in situations where run-time security mechanisms are not sufficient to completely prevent potentially malicious activities. A fundamental requirement for reliable auditing is the integrity of the log entries. This paper presents an infrastructure for secure logging that is capable of detecting the tampering of logs by powerful adversaries residing on the device where logs are generated. We rely on novel features of trusted hardware (TPM) to ensure the continuity of the logging infrastructure across power cycles without help from a remote server. Our infrastructure also addresses practical concerns including how to handle high-frequency log updates, how to conserve disk space for storing logs, and how to efficiently verify an arbitrary subset of the log. Importantly, we formally state the tamper-proofness guarantee of our infrastructure and verify\u00a0\u2026", "num_citations": "36\n", "authors": ["662"]}
{"title": "Apple Macintosh's energy consumption\n", "abstract": " Much of a portable computer's utility depends on how long it can run off the battery. We measure Apple Macintosh's current power consumption (and how much of that power goes to each system component) using built-in measuring tools.", "num_citations": "35\n", "authors": ["662"]}
{"title": "Leveraging remote server pools for client applications\n", "abstract": " Techniques for enabling client computing devices to leverage remote server pools for increasing the effectiveness of applications stored on the client computing device are described herein. In some instances, the server pools comprise a \u201ccloud\u201d,\u201ccluster\u201d or \u201cdata center\u201d that comprises hundreds or thousands of servers connected together by a network that has an extremely low latency and high bandwidth relative to the network through which the client computing device connects to the server pool. The client computing device may request that the server pool perform a certain task for an application whose canonical state resides on the client. After computation of a result of the task, a server of the server pool then provides the result to the client. By doing so, the techniques dramatically increase the amount of resources working on the request of the client and, hence, dramatically increase the speed and effectiveness\u00a0\u2026", "num_citations": "34\n", "authors": ["662"]}
{"title": "Reducing bandwidth requirements for peer-to-peer gaming based on importance of remote objects to a local player\n", "abstract": " Techniques enable the reduction of bandwidth requirements for peer-to-peer gaming architectures. In some embodiments, these techniques allow differentiation among players to decide which players should receive continuous updates and which should receive periodic updates. For those gaming systems receiving periodic updates, guided artificial intelligence is employed to simulate activity of a game object based on guidance provided by the periodic updates. Conversely, for those gaming systems receiving continuous updates, the continuous updates may be employed to update the activity of the game object rather than simulating the activity.", "num_citations": "33\n", "authors": ["662"]}
{"title": "Tardigrade: Leveraging lightweight virtual machines to easily and efficiently construct fault-tolerant services\n", "abstract": " Many services need to survive machine failures, but designing and deploying fault-tolerant services can be difficult and error-prone. In this work, we present Tardigrade, a system that deploys an existing, unmodified binary as a fault-tolerant service. Tardigrade replicates the service on several machines so that it continues running even when some of them fail. Yet, it keeps the service states synchronized so clients see strongly consistent results. To achieve this efficiently, we use lightweight virtual machine replication. A lightweight virtual machine is a process sandboxed so that its external dependencies are completely encapsulated, enabling it to be migrated across machines. To let unmodified binaries run within such a sandbox, the sandbox also contains a library OS providing the expected API. We evaluate Tardigrade\u2019s performance and demonstrate its applicability to a variety of services, showing that it can convert these services into fault-tolerant ones transparently and efficiently.", "num_citations": "28\n", "authors": ["662"]}
{"title": "Collection ordering for replicated state machines\n", "abstract": " A replicated state machine with N replica servers may be configured to tolerate a count of F faults. A first operation (of a first ordering type) executes when a first quorum of correctly functioning replicas is available. A second operation (also of the first operation type) executes when a second quorum of correctly functioning replicas is available. A third operation (of a second ordering type) executes when a third quorum of correctly functioning replicas are available. The operations are executed by the replicated state machine such that:(1) the replicated state machine does not guarantee operational ordering between the first operation and the second operation;(2) the replicated state machine guarantees ordering between the first operation and the third operation; and (3) the replicated state machine guarantees ordering between the second operation and the third operation.", "num_citations": "28\n", "authors": ["662"]}
{"title": "Energy consumption of Apple Macintosh computers\n", "abstract": " The utility of a portable computer is critically dependent on the period it can be used while running off the battery. In this paper, we present a study of power consumption in Apple Macintosh computers. We measure the existing power consumption for each system component using built-in measuring tools. Since total power consumption is a function of user workload, we use eight user workload traces to determine power use as observed in practice. Apple currently implements some powersaving features, and the effectiveness of those features is estimated; we find typical power savings of 41\u201366%. After the use of basic power-saving techniques, we find that the major power users are the backlight (25\u201326%), the CPU (9\u201325%), the display (4\u201317%), the video circuitry (6\u201310%), and the hard drive (4\u20139%). We then evaluate possible changes in system hardware and software with regard to the power savings they might offer.", "num_citations": "28\n", "authors": ["662"]}
{"title": "Executing native-code applications in a browser\n", "abstract": " Techniques for leveraging legacy code to deploy native-code desktop applications over a network (eg, the Web) are described herein. These techniques include executing an application written in native code within a memory region that hardware of a computing device enforces. For instance, page-protection hardware (eg, a memory management unit) or segmentation hardware may protect this region of memory in which the application executes. The techniques may also provide a narrow system call interface out of this memory region by dynamically enforcing system calls made by the application. Furthermore, these techniques may enable a browser of the computing device to function as an operating system for the native-code application. These techniques thus allow for execution of native-code applications on a browser of a computing device and, hence, over the Web in a resource-efficient manner and without\u00a0\u2026", "num_citations": "23\n", "authors": ["662"]}
{"title": "Network coordinate systems using IP information\n", "abstract": " Systems and methods that improve predictions of network latency in network coordinate systems (NCS) based on combining Internet topology information therewith. Topology information can be incorporated into the NCS by system/methodologies represented by geographic bootstrapping; autonomous system (AS) correction; history prioritization; symmetric updates or a combination thereof. Such can improve latency estimation between nodes when using a virtual coordinate system based on latency measurements between nodes.", "num_citations": "19\n", "authors": ["662"]}
{"title": "Trusted hardware component for distributed systems\n", "abstract": " Techniques for utilizing trusted hardware components for mitigating the effects of equivocation amongst participant computing devices of a distributed system are described herein. For instance, a distributed system employing a byzantine-fault-resilient protocol\u2014that is, a protocol intended to mitigate (eg, tolerate, detect, isolate, etc.) the effects of byzantine faults\u2014may employ the techniques. To do so, the techniques may utilize a trusted hardware component comprising a non-decreasing counter and a key. This hardware component may be \u201ctrusted\u201d in that the respective participant computing device cannot modify or observe the contents of the component in any manner other than according to the prescribed procedures, as described herein. Furthermore, the trusted hardware component may couple to the participant computing device in any suitable manner, such as via a universal serial bus (USB) connection or\u00a0\u2026", "num_citations": "17\n", "authors": ["662"]}
{"title": "Don't lose sleep over availability: The GreenUp decentralized wakeup service\n", "abstract": " Large enterprises can save significant energy and money by putting idle desktop machines to sleep. Many systems that let desktops sleep and wake them on demand have been proposed, but enterprise IT departments refuse to deploy them because they require special hardware, disruptive virtualization technology, or dedicated per-subnet proxies, none of which are cost-effective. In response, we devised GreenUp, a minimal software-only system that allows any machine to act as a proxy for other sleeping machines in its subnet. To achieve this, GreenUp uses novel distributed techniques that spread load through randomization, efficiently synchronize state within a subnet, and maintain a minimum number of proxies despite the potential for correlated sleep times. In this paper, we present the details of GreenUp\u2019s design as well as a theoretical analysis demonstrating its correctness and efficiency, using empirically-derived models where appropriate. We also present results and lessons from a seven-month live deployment on over 100 machines; a larger deployment on~ 1,100 machines is currently ongoing.", "num_citations": "13\n", "authors": ["662"]}
{"title": "Zero-effort payments: Design, deployment, and lessons\n", "abstract": " This paper presents Zero-Effort Payments (ZEP), a seamless mobile computing system designed to accept payments with no effort on the customer's part beyond a one-time opt-in. With ZEP, customers need not present cards nor operate smartphones to convey their identities. ZEP uses three complementary identification technologies: face recognition, proximate device detection, and human assistance. We demonstrate that the combination of these technologies enables ZEP to scale to the level needed by our deployments.", "num_citations": "11\n", "authors": ["662"]}
{"title": "The Utility Coprocessor: Massively Parallel Computation from the Coffee Shop.\n", "abstract": " UCop, the \u201cutility coprocessor,\u201d is middleware that makes it cheap and easy to achieve dramatic speedups of parallelizable, CPU-bound desktop applications using utility computing clusters in the cloud. To make UCop performant, we introduced techniques to overcome the low available bandwidth and high latency typical of the networks that separate users\u2019 desktops from a utility computing service. To make UCop economical and easy to use, we devised a scheme that hides the heterogeneity of client configurations, allowing a single cluster to serve virtually everyone: in our Linux-based prototype, the only requirement is that users and the cluster are using the same major kernel version. This paper presents the design, implementation, and evaluation of UCop, employing 32\u201364 nodes in Amazon EC2, a popular utility computing service. It achieves 6\u201311\u00d7 speedups on CPU-bound desktop applications ranging from video editing and photorealistic rendering to strategy games, with only minor modifications to the original applications. These speedups improve performance from the coffee-break timescale of minutes to the 15\u201320 second timescale of interactive performance.", "num_citations": "11\n", "authors": ["662"]}
{"title": "Partitioned artificial intelligence for networked games\n", "abstract": " Partitioned artificial intelligence (AI) for networked gaming. An exemplary system splits the AI into a computationally lightweight server-side component and a computationally intensive client-side component to harness the aggregate computational power of numerous gaming clients. Aggregating resources of many, even thousands of client machines enhances game realism in a manner that would be prohibitively expensive on the central server. The system is tolerant of latency between server and clients. Deterministic and stateless client-side components enable rapid handoff, preemptive migration, and replication of the client-side AI to address problems of client failure and game exploitation. The partitioned AI can support tactical gaming navigation, a challenging task to offload because of sensitivity to latency. The tactical navigation AI calculates influence fields partitioned into server-side and client-side\u00a0\u2026", "num_citations": "8\n", "authors": ["662"]}
{"title": "Automatic commutativity detection for generalized paxos\n", "abstract": " Synchronized devices comprising a distributed system attempt to agree on a compatible sequence of commands to execute. Each device in the distributed system may act as a proposer, acceptor, or a learner. Each proposer proposes a command for each device to execute. The acceptors either accept or reject the proposed commands. The learners keep track of the proposed commands and determine, using a transactional substrate, whether the acceptors have a accepted sequences of commands that commute with respect to one another. Once the learners have determined that a quorum of acceptors have accepted sequences of commands that commute with respect to one another the accepted commands are executed by each device in the distributed system.", "num_citations": "8\n", "authors": ["662"]}
{"title": "Enhancing game-server AI with distributed client computation\n", "abstract": " In the context of online role-playing games, we evaluate offloading AI computation from game servers to game clients. In this way, the aggregate resources of thousands of participating client machines can enhance game realism in a way that would be prohibitively expensive on a central server. Because offloading can add significant latency to a computation normally executing within a game server\u2019s main loop, we introduce the mechanism of AI partitioning: splitting an AI into a high-frequency but computationally simple component on the server, and a lowfrequency but computationally intensive component offloaded to a client. By designing the client-side component to be stateless and deterministic, this approach also facilitates rapid handoff, preemptive migration, and replication, which can address the problems of client failure and exploitation. To explore this approach, we develop an improved AI for tactical navigation, a challenging task to offload because it is highly sensitive to latency. Our improvement is based on calculating influence fields, partitioned into server-side and client-side components by means of a Taylor series approximation. Experiments on a Quake-based prototype demonstrate that this approach can substantially improve the AI\u2019s abilities, even with server-clientserver latencies up to one second.", "num_citations": "8\n", "authors": ["662"]}
{"title": "Realizing the fault-tolerance promise of cloud storage using locks with intent\n", "abstract": " Cloud computing promises easy development and deployment of large-scale, fault tolerant, and highly available applications. Cloud storage services are a key enabler of this, because they provide reliability, availability, and fault tolerance via internal mechanisms that developers need not reason about. Despite this, challenges remain for distributed cloud applications developers. They still need to make their code robust against failures of the machines running the code, and to reason about concurrent access to cloud storage by multiple machines.", "num_citations": "7\n", "authors": ["662"]}
{"title": "Reducing bandwidth requirements for peer-to-peer gaming based on error difference between actual game object state and simulated game object state being below an error threshold\n", "abstract": " Techniques enable the reduction of bandwidth requirements for peer-to-peer gaming architectures. In some embodiments, these techniques allow differentiation among players to decide which players should receive continuous updates and which should receive periodic updates. For those gaming systems receiving periodic updates, guided artificial intelligence is employed to simulate activity of a game object based on guidance provided by the periodic updates. Conversely, for those gaming systems receiving continuous updates, the continuous updates may be employed to update the activity of the game object rather than simulating the activity.", "num_citations": "7\n", "authors": ["662"]}
{"title": "Decentralized sleep management\n", "abstract": " Techniques for employing a decentralized sleep management service are described herein. In some instances, each computing device of a group of computing devices periodically shares information about itself with each other computing device of the group. With this information, each computing device within the group that is awake and capable of managing other devices selects a subset of devices to probe. The devices then probe this subset to determine whether the probed devices are asleep. In response to identifying a sleeping device, the probing device takes over management of the sleeping device. Managing the sleeping device involves informing other devices of the group that the sleeping device is being managed, in addition to monitoring requests for services on the sleeping device. In response to receiving a valid request for a service hosted by the sleeping device, the managing device awakens the\u00a0\u2026", "num_citations": "6\n", "authors": ["662"]}
{"title": "Building vtrace, a tracer for windows nt and windows 2000\n", "abstract": " In order to conduct accurate simulations of new approaches to energy management, we needed to collect detailed, time-stamped traces of several diverse types of activity on Windows NT and Windows 2000. For this purpose, we wrote VTrace, which collects data about processes, threads, messages, disk operations, network operations, the keyboard, the mouse, and the cursor. Building this tool required a large number of special techniques, which we describe in this paper. These techniques included using a DLL loaded into the address space of every process to intercept Win32 system calls; establishing hook functions for Windows NT kernel system calls; modifying the context switch code in memory to log context switches despite inadequate operating system support; and using device filters to log accesses to devices such as file systems, disk partitions, network transport layers, and the keyboard. We also describe related issues, such as where we found the necessary information, and how to debug a tracing tool that is intimately connected to the operating system kernel. Finally, since VTrace was originally written for Windows NT but later modified and extended to run with Windows 2000, we briefly discuss some of the changes required for Windows 2000.", "num_citations": "6\n", "authors": ["662"]}
{"title": "Hardware protection for differential privacy\n", "abstract": " This document relates to hardware protection of differential privacy techniques. One example obtains multiple instances of encrypted telemetry data within a secure enclave and processes the encrypted telemetry data to obtain multiple instances of unencrypted telemetry data. The example also processes, within the secure enclave, the multiple instances of unencrypted telemetry data to obtain a perturbed aggregate. The example also releases the perturbed aggregate from the secure enclave.", "num_citations": "5\n", "authors": ["662"]}
{"title": "Enforcing deterministic execution of threads of guest operating systems running in a virtual machine hosted on a multiprocessor machine\n", "abstract": " A virtual machine monitor (VMM) is configured to enforce deterministic execution of virtual machines in a multiprocessor machine. The VMM is configured to ensure that any communication by physical processors via shared memory is deterministic. When such VMMs are implemented in a distributed environment of multiprocessor machines coupled via a logical communication link, non-deterministic server applications running on virtual machines using the VMM may be replicated.", "num_citations": "5\n", "authors": ["662"]}
{"title": "Seamless customer identification\n", "abstract": " This paper proposes seamless customer identification (SCI), a means to identify physically present customers without any effort on customers\u2019 part beyond a one-time opt-in. With SCI, customers need not present cards or operate smartphones to convey their identities. So, stores can provide personalized shopping experiences at any time, not just at check-out. SCI uses two complementary technologies: device detection and face recognition. Device detection identifies customers by detecting their phones through low-power wireless discovery, in our case using Bluetooth Low Energy (BLE). Face recognition recognizes customers by matching pictures captured during registration with images captured by a store camera. Device detection makes face recognition feasible by limiting the number of potential customers, while face recognition provides directional information that device detection lacks. Together, these technologies provide an ordering of likely candidates to a store employee, who makes the final determination of identity. We have designed and built SCI, and demonstrated its usefulness in an application called Zero-Effort Payments (ZEP). ZEP uses SCI to let customers effortlessly make small purchases at a coffee stand. We conducted two real-world deployments of ZEP on actual customers: a two-day deployment during a technology fair and a four-month deployment in our building. Across both deployments, 274 customers made 705 purchases using ZEP. Through these deployments and other experiments, we demonstrate how our techniques make seamless customer identification feasible and practical.", "num_citations": "4\n", "authors": ["662"]}
{"title": "Task-based speed and voltage scheduling on windows 2000\n", "abstract": " This paper describes RightSpeed, a task-based speed and voltage scheduler for Windows 2000. It takes advantage of the ability of certain processors, such as those from Transmeta and AMD, to dynamically change speed and voltage and thus to save energy while running more slowly. Right-Speed uses PACE, an algorithm that computes the most energy efficient way to meet task deadlines with high probability. Since most applications do not provide enough data about tasks, such as task deadlines, for PACE to work, Right-Speed uses simple and efficient heuristics to automatically detect task characteristics for such applications. We show that RightSpeed has only 1.2% background overhead and its operations take only a few microseconds each. It even performs PACE calculation, which is quite complicated, in only 4.4 s on average due to our extensive optimizations. We show that RightSpeed is effective at meeting performance targets set by applications to within 1.5%. We show that although the PACE calculator does not save energy for the current generation of processors due to their limited range of worthwhile speed and voltage settings, we expect future processors to have greater such ranges, enabling PACE to reduce CPU energy consumption by 6.1\u20138.7% relative to the best standard algorithm. Finally, we show that with PACE, giving a processor the ability to run at additional, higher speeds and voltages reduces overall energy consumption.", "num_citations": "3\n", "authors": ["662"]}
{"title": "Feasibility of a serverless distributed file system deployed on an existing set of desktop pcs\n", "abstract": " We consider an architecture for a serverless distributed file system that does not assume mutual trust among the client computers. The system provides security, availability, and reliability by distributing multiple encrypted replicas of each file among the client machines. To assess the feasibility of deploying this system on an existing desktop infrastructure, we measure and analyze a large set of client machines in a commercial environment. In particular, we measure and report results on disk usage and content; file activity; and machine uptimes, lifetimes, and loads. We conclude that the measured desktop infrastructure would passably support our proposed system, providing availability on the order of one unfilled file request per user per thousand days.", "num_citations": "3\n", "authors": ["662"]}
{"title": "Fast, non-write-cycle-limited persistent memory for secure containers\n", "abstract": " Techniques for providing fast, non-write-cycle-limited persistent memory within secure containers, while maintaining the security of the secure containers, are described herein. The secure containers may reside within respective computing devices (eg, desktop computers, laptop computers, etc.) and may include both volatile storage (eg, Random Access Memory (RAM), etc.) and non-volatile storage (NVRAM, etc.). In addition, the secure containers may couple to auxiliary power supplies that are located externally thereto and that power the secure containers at least temporarily in the event of a power failure. These auxiliary power supplies may be implemented as short-term power sources, such as capacitors, batteries, or any other suitable power supplies.", "num_citations": "2\n", "authors": ["662"]}
{"title": "Ad stalking defense\n", "abstract": " Techniques are described to mitigate ad stalking and other user concerns resulting from user-targeted advertising. A user may be informed of advertising information by a process in which an advertising server receives a request for an ad. The request may have been generated in response to a user request for a landing web page. An ad may be selected based on user information available to the advertising server, where the user information is associated with the user and describes behavior and/or attributes and/or preferences associated with the user. Text about how the ad was selected may be incorporated into the ad. Such text may describe the user information used to select the ad. The selection-disclosing text may be incorporated in the ad in a form that is displayable to the user by a browser. The ad may then be transmitted for display in the landing web page.", "num_citations": "2\n", "authors": ["662"]}
{"title": "Using user interface event information in dynamic voltage scaling\n", "abstract": " Increasingly, mobile computers are using dynamic voltage scaling (DVS) to increase their battery life. We analyze traces of real user workloads to determine how DVS algorithms should treat tasks triggered by user interface events. We compare different DVS algorithms and find that for a given level of performance, Lorch et al.''s PACE (Processor Acceleration to Conserve Energy) algorithm always uses the least energy and the Stepped algorithm always uses the second least. The Stepped algorithm increases speed at a constant rate, while PACE increases speed according to an energy-minimizing schedule derived from the probability distribution of a task''s CPU requirement. We find that different types of user interface event (mouse movements, mouse clicks, and keystrokes) trigger tasks with significantly different CPU requirements, suggesting that DVS algorithms should use different speeds for these different\u00a0\u2026", "num_citations": "2\n", "authors": ["662"]}
{"title": "Detecting and managing sleeping computing devices\n", "abstract": " A method, system, and one or more computer-readable storage media for detecting sleeping computing devices are provided herein. The method includes querying, via a computing device, a system neighbor table of the computing device to determine whether a target computing device is reachable and, if the target computing device is unreachable, sending a neighbor discovery packet to the target computing device. The method also includes re-querying the system neighbor table to determine whether the target computing device is reachable and, if the target computing device is unreachable, determining whether the target computing device has been determined to be unreachable at least a specified number of times in a row. The method further includes determining that the target computing device is manageable if the target computing device has been determined to be unreachable at least the specified\u00a0\u2026", "num_citations": "1\n", "authors": ["662"]}
{"title": "GreenUp: A decentralized system for making sleeping machines available\n", "abstract": " Large enterprises can save significant energy and money by putting idle desktop machines to sleep. Many systems that let desktops sleep and wake them on demand have been proposed, but enterprise IT departments refuse to deploy them because they require special hardware, disruptive virtualization technology, or dedicated per-subnet proxies, none of which are cost-effective. In response, we devised GreenUp, a minimal software-only system that allows any machine to act as a proxy for other sleeping machines in its subnet. To achieve this, GreenUp uses novel distributed techniques that spread load through randomization, efficiently synchronize state within a subnet, and maintain a minimum number of proxies despite the potential for correlated sleep times. In this paper, we present the details of GreenUp\u2019s design as well as a theoretical analysis demonstrating its correctness and efficiency, using empirically-derived models where appropriate. We also present results and lessons from a seven-month live deployment on over 100 machines; a larger deployment on~ 1,100 machines is currently ongoing.", "num_citations": "1\n", "authors": ["662"]}