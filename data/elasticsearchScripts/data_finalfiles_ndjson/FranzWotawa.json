{"title": "A survey on software fault localization\n", "abstract": " Software fault localization, the act of identifying the locations of faults in a program, is widely recognized to be one of the most tedious, time consuming, and expensive - yet equally critical - activities in program debugging. Due to the increasing scale and complexity of software today, manually locating faults when failures occur is rapidly becoming infeasible, and consequently, there is a strong demand for techniques that can guide software developers to the locations of faults in a program with minimal human intervention. This demand in turn has fueled the proposal and development of a broad spectrum of fault localization techniques, each of which aims to streamline the fault localization process and make it more effective by attacking the problem in a unique way. In this article, we catalog and provide a comprehensive overview of such techniques and discuss key issues and concerns that are pertinent to software\u00a0\u2026", "num_citations": "741\n", "authors": ["1033"]}
{"title": "Model-based diagnosis of hardware designs\n", "abstract": " The state of the art in hardware design is the use of hardware description languages such as VHDL. The designs are tested by simulating them and comparing their output to that prescribed by the specification. A significant part of the design effort is spent on detecting unacceptable deviations from this specification and subsequently localizing the sources of such faults. In this paper, we describe an approach to employ model-based diagnosis for fault detection and localization in very large VHDL programs, by automatically generating the diagnosis model from the VHDL code and using observations about the program behavior to derive possible fault locations from the model. In order to achieve sufficient performance for practical applicability, we have developed a representation that provides a highly abstracted view of programs and faults, but is sufficiently detailed to yield substantial reductions in the fault\u00a0\u2026", "num_citations": "258\n", "authors": ["1033"]}
{"title": "A variant of Reiter's hitting-set algorithm\n", "abstract": " In this paper we introduce a variant of Reiter's hitting-set algorithm. This variant produces a hitting-set tree instead of an acyclic directed graph. As an advantage some subset checks necessary for reducing the graph during search can be avoided.", "num_citations": "143\n", "authors": ["1033"]}
{"title": "Diagnosing tree-structured systems\n", "abstract": " This paper introduces the TREE/TREE\u2217 algorithm for computing minimal diagnoses for tree-structured systems. Diagnoses are computed by descending into the tree, enumerating the input combinations that might be responsible for a given incorrect observation, and combining the diagnoses for the subtrees generating these inputs into diagnoses for the whole system. Algorithm TREE diagnoses systems containing functional components and algorithm TREE\u2217 diagnoses more general constraint-based components. We prove soundness and correctness of the algorithms and show experimental results that indicate that they compare favorably to Reiter's hitting-set-based algorithm and El Fattah and Dechter's SAB. Extensions of the algorithms such as use of fault modes are discussed.", "num_citations": "106\n", "authors": ["1033"]}
{"title": "On the relationship between model-based debugging and program slicing\n", "abstract": " Program slicing is a general, widely-used, and accepted technique applicable to different software engineering tasks including debugging, whereas model-based diagnosis is an AI technique originally developed for finding faults in physical systems. During the last years it has been shown that model-based diagnosis can be used for software debugging. In this paper we discuss the relationship between debugging using a dependency-based model and program slicing. As a result we obtain that slices of a program in a fault situation are equivalent to conflicts in model-based debugging.", "num_citations": "105\n", "authors": ["1033"]}
{"title": "Automatic software bug triage system (bts) based on latent semantic indexing and support vector machine\n", "abstract": " A bug triage system is used for validation and allocation of bug reports to the most appropriate developers. An automatic bug triage system may reduce the software maintenance time and improve its quality by correct and timely assignment of new bug reports to the appropriate developers. In this paper, we present the techniques behind an automatic bug triage system, which is based on the categorization of bug reports. In order to obtain an automatic bug triage system we used these techniques and performed comparative experiments. We downloaded 1,983 resolved bug reports along with the developer activity data from the Mozilla open source project. We extracted the relevant features like report title, report summary etc., from each bug report, and extracted developer's name who resolved the bug reports from the developers activity data. We processed the extracted textual data, and obtained the term-to\u00a0\u2026", "num_citations": "96\n", "authors": ["1033"]}
{"title": "Debugging functional programs\n", "abstract": " In this paper, we use a logic-based system description for a simple (non-logic) functional language to examine the ways in which a diagnosis system can use its system description to improve debugging performance. The key concept is that the notion of expression replacement, which is the basis for repairing a program, can also serve as a fundamental heuristic for searching the source of an error. We formally define replacements in terms of fault modes, explicitly define a replacement order, and use the replacement heuristic for finding diagnoses. Finally, we incorporate the use of multiple test cases and discuss their use in discriminating between diagnoses.", "num_citations": "79\n", "authors": ["1033"]}
{"title": "Model-based diagnosis or reasoning from first principles\n", "abstract": " Although the basics of model-based diagnosis are well known, creating appropriate domain-specific models is still a challenge. Nevertheless, empirical results show that model-based diagnosis techniques are now appropriate for medium-size real-world problems.", "num_citations": "77\n", "authors": ["1033"]}
{"title": "Detecting and locating faults in the control software of autonomous mobile robots.\n", "abstract": " Research on diagnosis has a long history in artificial intelligence which includes work dealing with diagnosis and repair of autonomous systems like space probes and software debugging. In this paper we extend previous work by introducing modeling principles for software architectures that allow to detect and locate failures of the robot\u2019s control software. Failure detection is based on observers, ie, software that monitors the behavior of the control software. Localization is based on a model of the architecture and uses model-based diagnosis for computing the failure causes. Moreover, we introduce an algorithm for repairing the software and discuss first experimental results of our implementation.", "num_citations": "69\n", "authors": ["1033"]}
{"title": "Automated source-level error localization in hardware designs\n", "abstract": " Recent achievements in formal verification techniques allow for fault detection even in large real-world designs. Tool support for localizing the faulty statements is critical, because it reduces development time and overall project costs. Automated source-level debugging and a new and novel debugging model allow for source-level debugging of large VHDL designs at the granularity of statements and expressions. This technique is fully automated and does not require that an engineer be familiar with formal verification techniques.", "num_citations": "63\n", "authors": ["1033"]}
{"title": "Modeling Java programs for diagnosis\n", "abstract": " A key advantage of model-based diagnosis is the ability to use a generic model for the production of system descriptions that can be used to derive diagnoses for differently structured individual systems from a domain. This advantage is nowhere more apparent than in the software error diagnosis (or debugging) area, where given a model, system descriptions can be automatically derived from source code. However, effective models for diagnosing programs have so far been limited to special-purpose languages. We describe a value-based model for Java programs that enables us to explicitly deal with imperative program execution (including loop execution), and compare the results to those obtained by using program slicing, a traditional technique from the software debugging community, and a simple dependency-based model for Java.", "num_citations": "63\n", "authors": ["1033"]}
{"title": "Real-time diagnosis and repair of faults of robot control software\n", "abstract": " Faults in hardware and software are not totally avoidable not even if the components are carefully designed, implemented and tested. In this paper we present a solution for detection, localization and repair of faults in the control software for autonomous mobile robots. The presented diagnosis system uses model-based diagnosis for fault detection and localization. Furthermore, we present a method which enables the robot control software to recover from located faults. The novelty of our approach is that fault localization and repair takes place at runtime. Moreover, we present experimental results of the proposed diagnosis system obtained in the RoboCup Middle-Size scenario.", "num_citations": "60\n", "authors": ["1033"]}
{"title": "The route to success\u2014A performance comparison of diagnosis algorithms\n", "abstract": " Diagnosis, ie, the identification of root causes for failing or unexpected system behavior, is an important task in practice. Within the last three decades, many different AI-based solutions for solving the diagnosis problem have been presented and have been gaining in attraction. This leaves us with the question of which algorithm to prefer in a certain situation. In this paper we contribute to answering this question. In particular, we compare two classes of diagnosis algorithms. One class exploits conflicts in their search, ie, sets of system components whose correct behavior contradicts given observations. The other class ignores conflicts and derives diagnoses from observations and the underlying model directly. In our study we use different reasoning engines ranging from an optimized Horn-clause theorem prover to general SAT and constraint solvers. Thus we also address the question whether publicly available general reasoning engines can be used for an efficient diagnosis.", "num_citations": "55\n", "authors": ["1033"]}
{"title": "Testing methods used in the automotive industry: Results from a survey\n", "abstract": " About 90% of all the current car innovations are based on electronics and software. The software used in a car has increased a lot reaching the size of 100 Million lines of code. Therefore, testing of automotive software has become a very critical task. In this paper we report on a questionnaire survey we carried out asking for information about testing activities within the automotive industry. We report on testing and test automation methods and tools in current use. In the survey we distinguished the different fields in the automotive industry where software development happens, ie, research, pre-development, and series development. In addition we also discuss the opinions of the survey participants to various outlook topics.", "num_citations": "52\n", "authors": ["1033"]}
{"title": "Model-based debugging of Java programs\n", "abstract": " Model-based reasoning is a central concept in current research into intelligent diagnostic systems. It is based on the assumption that sources of incorrect behavior in technical devices can be located and identified via the existence of a model describing the basic properties of components of a certain application domain. When actual data concerning the misbehavior of a system composed from such components is available, a domain-independent diagnosis engine can be used to infer which parts of the system contribute to the observed behavior. This paper describes the application of the model-based approach to the debugging of Java programs written in a subset of Java. We show how a simple dependency model can be derived from a program, demonstrate the use of the model for debugging and reducing the required user interactions, give a comparison of the functional dependency model with program slicing, and finally discuss some current research issues.", "num_citations": "49\n", "authors": ["1033"]}
{"title": "Spectrum Enhanced Dynamic Slicing for better Fault Localization.\n", "abstract": " Debugging consumes a considerable amount of time in software engineering, but it is rarely automated. In this paper, we focus on improving existing fault localization techniques. Spectrumbased fault localization (SFL) and slicing-hitting-set-computation (SHSC) are two techniques based on program execution traces. Both techniques come with small computational overhead and aid programmers to faster identify possible locations of faults. However, they have disadvantages: SHSC results in an undesirable high ranking of statements which are executed in many test cases, such as constructors. SFL operates on block level. Therefore, it cannot provide fine-grained results. We combine SHSC with SFL in order to eliminate these disadvantages. Our objective is to improve the ranking of faulty statements so that they allow for better fault localization than when using the previously mentioned methods separately. We show empirically that the resulting approach reduces the number of statements a programmer needs to check manually. In particular, we gain improvements of about 50% percent for SHSC and 25% for SFL.", "num_citations": "47\n", "authors": ["1033"]}
{"title": "Fault localization based on dynamic slicing and hitting-set computation\n", "abstract": " Slicing is an effective method for focusing on relevant parts of a program in case of a detected misbehavior. Its application to fault localization alone and in combination with other methods has been reported. In this paper we combine dynamic slicing with model-based diagnosis, a method for fault localization, which originates from Artificial Intelligence. In particular, we show how diagnosis, i.e., root causes, can be extracted from the slices for erroneous variables detected when executing a program on a test suite. We use these diagnoses for computing fault probabilities of statements that give additional information to the user. Moreover, we present an empirical study based on our implementation JSDiagnosis and a set of Java programs of various size from 40 to more than 1,000 lines of code.", "num_citations": "47\n", "authors": ["1033"]}
{"title": "Improving robustness of mobile robots using model-based reasoning\n", "abstract": " Retaining functionality of a mobile robot in the presence of faults is of particular interest in autonomous robotics. From our experiences in robotics we know that hardware is one of the weak points in mobile robots. In this paper we present the foundations of a system that automatically monitors the driving device of a mobile robot. In case of a detected fault, e.g., a broken motor, the system automatically reconfigures the robot in order to still allow to reach a certain position. The described system is based on a generalized model of the motion hardware. High-level control like path-planner only to change its behavior in case of a serious damage. The high-level control system remains the same. In the paper we present the model and the foundations of the diagnosis and reconfiguration system.", "num_citations": "44\n", "authors": ["1033"]}
{"title": "Debugging of Java programs using a model-based approach\n", "abstract": " Model-based diagnosis is a successful AI technique for diagnosing physical systems but faces new challenges when applied to finding faults in software, ie, debugging. Previous work has mostly dealt with modeling the behavior of programming languages with exploitable special properties: logic, concurrent, or functional. This paper presents a model that is usable for the representation of imperative programming languages at an abstract level as part of a project for developing a model-based debugging system for Java. The representation is discussed and compared to other debugging representations.", "num_citations": "44\n", "authors": ["1033"]}
{"title": "Model-based reconfiguration\n", "abstract": " Knowledge-based configuration is both a successful application domain for AI techniques and and an active research area. An open issue in many practical domains is that of reconfiguration, typically exhibited by legacy systems that are to be extended, upgraded or simply altered. Standard configuration techniques are not necessarily suited to this task. We discuss the use of a diagnosis approach to reconfiguration. We present the differing application and representation requirements, develop a representation that is suitable for expressing the information about the required and configurable functionalities from the diagnosis point of view, present an example and discuss our experiences.", "num_citations": "44\n", "authors": ["1033"]}
{"title": "From neural networks to qualitative models in environmental engineering\n", "abstract": " As an alternative to physical models, artificial neural networks (ANNs) are a valuable forecast tool in environmental sciences. They can be used effectively due to their learning capabilities and their low computational costs. Once all relevant variables of the system are identified and put into the network, it works quickly and accurately. However, one of the major shortcomings of neural networks is that they do not reveal causal relationships between major system components and thus are unable to improve the explicit knowledge of the user. Another problem is due to the fact that reasoning is only done from the inputs to the outputs. In cases where the opposite is requested (i.e., deriving inputs leading to a given output), neural networks can hardly be used. To overcome these problems, we introduce a novel approach for deriving qualitative information out of neural networks. Some of the resulting rules can directly be\u00a0\u2026", "num_citations": "41\n", "authors": ["1033"]}
{"title": "A Value-Based Diagnosis Model for Java Programs \u0403\n", "abstract": " A key advantage of model-based diagnosis is the ability to use a generic model for the production of system descriptions that can be used to derive diagnoses for differently structured individual systems from a domain. This advantage is nowhere more apparent than in the software error diagnosis (or debugging) area, where given a model, system descriptions can be automatically derived from source code. However, effective models for diagnosing programs have so far been limited to special-purpose languages. We describe a value-based model for Java programs that enables us to explicitly deal with imperative program execution (including loop execution), and compare the outcome of our approach to the results obtained by using program slicing, a traditional technique from the software debugging community, and a simple dependencybased model for Java.", "num_citations": "41\n", "authors": ["1033"]}
{"title": "Using constraints for equivalent mutant detection\n", "abstract": " In mutation testing the question whether a mutant is equivalent to its program is important in order to compute the correct mutation score. Unfortunately, answering this question is not always possible and can hardly be obtained just by having a look at the program's structure. In this paper we introduce a method for solving the equivalent mutant problem using a constraint representation of the program and its mutant. In particularly the approach is based on distinguishing test cases, i.e., test inputs that force the program and its mutant to behave in a different way. Beside the foundations of the approach, in this paper we also present the algorithms and first empirical results.", "num_citations": "40\n", "authors": ["1033"]}
{"title": "Debugging hardware designs using a value-based model\n", "abstract": " In this paper we describe the use of model-based diagnosis for locating bugs in hardware designs. Nowadays hardware designs are written in a programming language. We restrict our view to hardware designs written in a subset of the commonly used hardware description language VHDL. This subset includes all synthesize-able (register transfer level (RTL)) programs, i.e., programs that can be automatically converted into a gate level representation. Therefore almost all VHDL programs are RTL programs. We show the conversion of VHDL programs into a logical representation. This representation is a model that can be directly used by a model-based diagnosis engine for computing diagnoses. The resulting diagnoses are mapped back to the VHDL code fragments of the original program explaining a misbehavior. In addition, we specify some rules optimizing the obtained results. We further present\u00a0\u2026", "num_citations": "39\n", "authors": ["1033"]}
{"title": "Constraint-based Debugging of Spreadsheets.\n", "abstract": " Despite being staggeringly error prone, spreadsheets can be viewed as a highly flexible end-users programming environment. As a consequence, spreadsheets are widely adopted for decision making by end-users, and may have a serious economical impact for the business. Hence, approaches for aiding the process of pinpointing the faulty cells in a spreadsheet are of great value. In this paper we present a constrainbased approach for debugging spreadsheets. We coin the approach Con-Bug. Essentially, the approach takes as input a (faulty) spreadsheet and a test case that reveals the fault (a test case specifies values for the input cells as well as the expected values for the output cells) and computes a set of diagnosis candidates for the debugging problem we are trying to solve. To compute the set of diagnosis candidates we convert the spreadsheet and test case to a constraint satisfaction problem (CSP), modeled using the state-of-the-art constraint solver MINION. We use a case study, in particular using a spreadsheet taken from the well-known EUSES Spreadsheet Corpus, to better explain the different phases of the approach as well as to measure the efficiency of ConBug. We conclude that ConBug can be of added value for the end user in order to pinpoint faulty cells.", "num_citations": "37\n", "authors": ["1033"]}
{"title": "A survey of intelligent debugging\n", "abstract": " Automated debugging systems have a long history with interesting results produced by research prototypes and deployed applications. We present an overview of Artificial Intelligence approaches to the development of intelligent debugging systems. These systems range from tutoring systems that possess detailed knowledge about the individual programs as well as about typical programmer errors occurring in exactly these programs, over Bayesian Net formalisms that employ statistical results about error reports, to traditional debugging approaches such as Algorithmic (or Declarative) Debugging. Finally, we examine the more recent use of model\u2010based diagnosis principles as a basis for software debugging research. We illustrate the potential of model\u2010based reasoning by discussing several models (differing in expressivity and assumptions on language semantics) that are currently in various stages of\u00a0\u2026", "num_citations": "37\n", "authors": ["1033"]}
{"title": "Automated debugging based on a constraint model of the program and a test case\n", "abstract": " Debugging, i.e., fault localization, in case of a detected failure is a time consuming and intricate task. The automation or at least partial automation of debugging is therefore highly desired. In this paper, we discuss some of the most recent approaches for debugging namely spectrum-based, slicing-based, and model-based debugging. We focus on the latter, and introduce the underlying theory as well as discuss empirical results obtained from our implementation. The model-based approach we present in this paper relies on a constraint representation of a program that is equivalent to the original program in terms of the input-output behavior under some reasonable assumptions. By using constraints for representing programs and subsequently test cases we are able to state the debugging problem as a constraint satisfaction problem that can be effectively solved using a todays constraint solver. The given empirical\u00a0\u2026", "num_citations": "36\n", "authors": ["1033"]}
{"title": "Model-based fault diagnosis and reconfiguration of robot drives\n", "abstract": " Modern drives of mobile robots are complex machines. Because of this complexity, as well as of wear and aging of components, faults occurs in such systems quite frequently at runtime. In order to use such drives in truly autonomous robots it is desirable that the robot is able to automatically react to such faults. Therefore, the robot needs reasoning and reconfiguration capabilities in order to be able to detect, localize and repair such faults on-line. In this paper we propose a model-based diagnosis and reconfiguration framework which allows an autonomous robot to detect and compensate faults in its drive. Moreover, we present an implementation for a real robot platform. Finally, we report experimental results which shows that the proposed framework is able to correctly cope with injected faults in the drive hardware, like broken motors.", "num_citations": "35\n", "authors": ["1033"]}
{"title": "Xss pattern for attack modeling in testing\n", "abstract": " Security issues of web applications are still a current topic of interest especially when considering the consequences of unintended behaviour. Such services might handle sensitive data about several thousands or millions of users. Hence, exploiting services or other undesired effects that cause harm on users has to be avoided. Therefore, for software developers of such applications one of the major tasks in providing security is to embed testing methodologies into the software development cycle, thus minimizing the subsequent damage resulting in debugging and time intensive upgrading. Model-based testing evolved as one of the methodologies which offer several theoretical and practical approaches in testing the system under test (SUT) that combine several input generation strategies like mutation testing, using of concrete and symbolic execution etc. by putting the emphasis on specification of the model of an\u00a0\u2026", "num_citations": "34\n", "authors": ["1033"]}
{"title": "Fault detection in multi-threaded C++ server applications\n", "abstract": " Due to increasing demands in processing power on the one hand, but the physical limit on CPU clock speed on the other hand, multi-threaded programming is becoming more important in current applications. Unfortunately, multi-threaded programs are prone to programming mistakes that result in hard to find defects, mainly race-conditions and deadlocks. The need for tools that help finding these faults is immanent, but currently available tools are either difficult to use because of the need for annotations, unable to cope with more than a few 10 kLOC, or issue too many false warnings. This paper describes experiments with the freely available tool Helgrind and results obtained by using it for debugging a server application comprising 500 kLOC. We present improvements to the runtime analysis of C++ programs that result in a dramatic reduction of false warnings.", "num_citations": "34\n", "authors": ["1033"]}
{"title": "Attack pattern-based combinatorial testing\n", "abstract": " The number of potential security threats rises with the increasing number of web applications, which cause tremendous financial and existential implications for developers and users as well. The biggest challenge for security testing is to specify and implement ways in order to detect potential vulnerabilities of the developed system in a never ending quest against new security threats but also to cover already known ones so that a program is suited against typical attack vectors. For these purposes many approaches have been developed in the area of model-based security testing in order to come up with solutions for real-world application problems. These approaches provide theoretical background as well as practical solutions for certain security issues. In this paper, we partially rely on previous work but focus on the representation of attack patterns using UML state diagrams. We extend previous work in\u00a0\u2026", "num_citations": "33\n", "authors": ["1033"]}
{"title": "Asynchronous input-output conformance testing\n", "abstract": " This paper studies model-based input-output conformance testing in the presence of queues. Normally, it is assumed that a test case communicates synchronously with an implementation under test. This causes some challenges in practice, since testing is often conducted asynchronously. In an asynchronous environment messages between a tester and the implementation are queued. This may lead to incorrect verdicts. In this paper we show how one can guarantee correct verdicts in the asynchronous case for a large set of implementations. If choices between inputs and outputs are restricted to internal choices with respect to an implementation one can use the observation of quiescence as a handshake between a test case and the implementation. Such a handshake allows us to test for input-output conformance in the context of queues. In addition, the input-enabledness assumption on implementations is\u00a0\u2026", "num_citations": "33\n", "authors": ["1033"]}
{"title": "Potential of heterogeneity in collective behaviors: A case study on heterogeneous swarms\n", "abstract": " Research in swarm robotics and collective behaviors is often focused on homogeneous swarms. However, heterogeneity in behaviors can be advantageous as we know, for example, from studies on social insects. Our objective is to study the hypothesis that there are potential advantages of heterogeneous swarms over homogeneous swarms in an aggregation scenario inspired by behaviors of juvenile honeybees. Even without task switching \u2013 that is, with predefined, static roles for certain swarm fractions \u2013 we find in our case study that heterogeneous swarms can outperform homogeneous swarms for a predetermined set of basic behaviors. We use methods of evolutionary computation to define behaviors imitating those found in honeybees (random walkers, wall followers, goal finders, immobile agents) and also to find well-adapted swarm fractions of different predetermined behaviors. Our results show\u00a0\u2026", "num_citations": "31\n", "authors": ["1033"]}
{"title": "Attack pattern-based combinatorial testing with constraints for web security testing\n", "abstract": " Security testing of web applications remains a major problem of software engineering. In order to reveal vulnerabilities, manual and automatic testing approaches use different strategies for detection of certain kinds of inputs that might lead to a security breach. In this paper we compared a state-of-the-art manual testing tool with an automated one that is based on model-based testing. The first tool requires user input from the tester whereas the second one reduces the necessary amount of manual manipulation. Both approaches depend on the corresponding test case generation technique and its produced inputs are executed against the system under test (SUT). For this case we enhance a novel technique, which combines a combinatorial testing technique for input generation and a model-based technique for test execution. In this work the input parameter modelling is improved by adding constraints to generate\u00a0\u2026", "num_citations": "31\n", "authors": ["1033"]}
{"title": "Security testing based on attack patterns\n", "abstract": " Testing for security related issues is an important task of growing interest due to the vast amount of applications and services available over the internet. In practice testing for security often is performed manually with the consequences of higher costs, and no integration of security testing with today's agile software development processes. In order to bring security testing into practice, many different approaches have been suggested including fuzz testing and model-based testing approaches. Most of these approaches rely on models of the system or the application domain. In this paper we suggest to formalize attack patterns from which test cases can be generated and even executed automatically. Hence, testing for known attacks can be easily integrated into software development processes where automated testing, e.g., for daily builds, is a requirement. The approach makes use of UML state charts. Besides\u00a0\u2026", "num_citations": "31\n", "authors": ["1033"]}
{"title": "Debugging VHDL designs using model-based reasoning\n", "abstract": " The application of formal methods in software engineering and hardware design has become an important field of research. It aims at minimizing time to market and reduce the overall development costs. While formal verification, e.g. model-checking, is widely used, methods for helping programmers or engineers in locating and fixing faults within a hardware design or software are rarely available. In this paper we describe part of the advanced diagnosis and measurement selection capabilities of the model-based diagnosis tool VHDLDIAG designed for (semi)automatically locating bugs in VHDL programs. VHDL is an Ada-like and widely used hardware description language. VHDL programs are converted into logical descriptions which are then used by a diagnosis engine for detecting the parts of the program responsible for an observed misbehavior. The results of diagnosis, i.e. the malfunctioning program\u00a0\u2026", "num_citations": "29\n", "authors": ["1033"]}
{"title": "Ontology-based test generation for automated and autonomous driving functions\n", "abstract": " Context: Ontologies are known as a formal and explicit conceptualization of entities, their interfaces, behaviors, and relationships. They have been applied in various application domains such as autonomous driving where ontologies are used for decision making, traffic description, auto-pilot etc. It has always been a challenge to test the corresponding safety-critical software systems in autonomous driving that have been playing an increasingly important role in our daily routines.Objective: Failures in these systems potentially not only cause great financial loss but also the loss of lives. Therefore, it is vital to obtain and cover as many as critical driving scenarios during auto drive testing to ensure that the system can always reach a fail-safe state under different circumstances.Method: We outline a general framework for testing, verification, and validation for automated and autonomous driving functions. The introduced\u00a0\u2026", "num_citations": "28\n", "authors": ["1033"]}
{"title": "Chatbot-based Tourist Recommendations Using Model-based Reasoning.\n", "abstract": " Chatbots have gained increasing importance for research and practice with a lot of applications available today including Amazon\u2019s Alexa or Apple\u2019s Siri. In this paper, we present the underlying methods and technologies behind a Chatbot for e-tourism that allows people textually communicate with the purpose of booking hotels, planning trips, and asking for interesting sights worth being visit. In particular, we show how model-based reasoning can be used for enhancing user experience during a chat, eg, in cases where too many possible selections are available or where user preferences are too restricted causing inconsistencies and as a consequence not possible answers to be provided. Besides the underlying foundations, we provide a use case from the intended tourism domain to show how such a model-based chatbot effectively can be used in practice.", "num_citations": "27\n", "authors": ["1033"]}
{"title": "Using ontologies for test suites generation for automated and autonomous driving functions\n", "abstract": " In this paper, we outline a general automated testing approach to be applied for verification and validation of automated and autonomous driving functions. The approach makes use of ontologies of environment the system under test is interacting with. Ontologies are automatically converted into input models for combinatorial testing, which are used to generate test cases. The obtained abstract test cases are used to generate concrete test scenarios that provide the basis for simulation used to verify the functionality of the system under test. We discuss the general approach including its potential for automation in the automotive domain where there is growing need for sophisticated verification based on simulation in case of automated and autonomous vehicles.", "num_citations": "26\n", "authors": ["1033"]}
{"title": "Model-Based Program Debugging and Repair.\n", "abstract": " The current state of the art in integrated circuit design is based on the use of special hardware design languages such as VHDL. In the context of the development of an intelligent, knowledge-based debugging aid for VHDL programs, we are dealing with analysis and diagnosis of a subset of VHDL (which is similar to conventional concurrent programming languages). We present an adaptation of conventional model-based diagnosis methods to the debugging of VHDL expressions and signal assignments. The examination of possible faults in VHDL expressions leads to the use of fault models (ie, a representation of typical errors) as an aid to focusing, and as a basis for proposing repair actions for small errors in these programs.", "num_citations": "26\n", "authors": ["1033"]}
{"title": "On the use of mutations and testing for debugging\n", "abstract": " Tools for automated fault localization usually generate too many bug candidates depending on the underlying technique. Hence, more information is required in order to further restrict the number of bug candidates. Approaches that rely on specific knowledge of the program to be debugged, such as variable values at specific positions in the source code, are not easily accessible for users especially in the case of software maintenance. In order to avoid this problem, we suggest integrating testing to restrict the number of bug candidates. In particular, we propose computing possible corrections of the program and from this distinguishing test cases. A distinguishing test case is a test that reveals different output values for two program variants given the same input values. Besides the formal definitions and algorithms, we extend the first empirical results of our approach in this paper. The obtained empirical results show\u00a0\u2026", "num_citations": "25\n", "authors": ["1033"]}
{"title": "Automatically extracting mock object behavior from design by contract\u2122 specification for test data generation\n", "abstract": " Test data generation is an important task in the process of automated unit test generation. Random and heuristic approaches are well known for test input data generation. Unfortunately, in the presence of complex pre-conditions especially in the case of non-primitive data types those approaches often fail. A promising technique for generating an object that exactly satisfies a given pre-condition is mocking, ie, replacing the concrete implementation with an implementation only considering the necessary behavior for a specific test case. In this paper we follow this technique and present an approach for automatically deriving the behavior of mock objects from given Design by Contract\u2122 specifications. The generated mock objects behave according to the Design by Contract\u2122 specification of the original class. Furthermore, we make sure that the observed behavior of the mock object satisfies the pre-condition of the\u00a0\u2026", "num_citations": "25\n", "authors": ["1033"]}
{"title": "On the compilation of programs into their equivalent constraint representation\n", "abstract": " Ideally intelligent systems should provide self-reasoning and reflection capabilities in order to react on internal faults as well as on unexpected interaction with their environment. Reflection capabilities are highly recommended for systems with strong robustness constraints, like space exploration probes or even mobile robots. A scenario, for example, is a robot that although having a broken engine, should reach a certain position. Without self-reasoning or reflection such a robot would simple fail to reach its goal. Another example would be a robot where the software fails because of a bug. In this situation a robot should recover and ideally repair itself. Note that even exhaustive testing does not prevent a program from containing bugs which might cause an unexpected behavior in certain situations. In this paper we do not focus on whole systems which comprise hardware and software. Instead we are discussing how to represent programs to allow for reflection which can be used for enhancing the system with debugging functionality. In the context of this paper debugging is defined as fault localization given a certain test-case. We do not take care of verification and test-case generation which is used for fault detection and repair. In order to compute the fault location we follow the model-based diagnosis approach (22) but do not rely on logical models but use constraints instead for representing programs. The obtained constraint representation can be directly used for computing diagnosis, eg, by using specialized diagnosis algorithms like the one described in (12; 25; 26).Although, reflection and debugging capabilities are a desired functionality of\u00a0\u2026", "num_citations": "25\n", "authors": ["1033"]}
{"title": "Applying model-based diagnosis to software debugging of concurrent and sequential imperative programming languages\n", "abstract": " Applying Model-Based Diagnosis to Software Debugging of Concurrent and Sequential Imperative Programming Languages \u2014 Graz University of Technology Skip to main navigation Skip to search Skip to main content Graz University of Technology Logo English Deutsch Home Persons Research Units Research Outputs Projects Activities Prizes Press / Media Search by expertise, name or affiliation Applying Model-Based Diagnosis to Software Debugging of Concurrent and Sequential Imperative Programming Languages Franz Wotawa Institute of Software Technology (7160) Research output: Thesis \u203a Doctoral Thesis Overview Original language English Publication status Published - 1996 Cite this APA Standard Harvard Vancouver Author BIBTEX RIS Wotawa, F. (1996). Applying Model-Based Diagnosis to Software Debugging of Concurrent and Sequential Imperative Programming Languages. Applying Model-\u2026", "num_citations": "25\n", "authors": ["1033"]}
{"title": "A novel industry grade dataset for fault prediction based on model-driven developed automotive embedded software\n", "abstract": " In this paper, we present a novel industry dataset on static software and change metrics for Matlab/Simulink models and their corresponding auto-generated C source code. The data set comprises data of three automotive projects developed and tested accordingly to industry standards and restrictive software development guidelines. We present some background information of the projects, the development process and the issue tracking as well as the creation steps of the dataset and the used tools during development. A specific highlight of the dataset is a low measurement error on change metrics because of the used issue tracking and commit policies.", "num_citations": "24\n", "authors": ["1033"]}
{"title": "Introducing alias information into model-based debugging\n", "abstract": " Model-based diagnosis applied to computer programs has been studied for several years. Although there are still weaknesses in the used models, especially on dealing with dynamic data structures, the approach has been proven useful for automatic debugging. The weaknesses stem from the fact that heap objects are modeled without considering alias information. Our approach extends the modeling process with a static points-to analysis that reveals the structure and relations between heap objects. This points-to information is then used to improve existing value-based models for Java programs such that the diagnosis engine is able to differentiate between separate data structures. With this extension the set of diagnoses can be reduced for certain types of programs.", "num_citations": "23\n", "authors": ["1033"]}
{"title": "Chatbot testing using AI planning\n", "abstract": " Chatbots, i.e., systems that can interact with humans in a more appropriate way using natural language, have been of increasing importance. This is due the fact of the availability of computational means for natural language interaction between computers and humans that are becoming closer to the interaction between humans alone. Consequently, there are more and more chatbots available that are intended to support humans organizing tasks or making decisions. In this paper, we focus on how to verify the communication capabilities provided by chatbots. In particular, we introduce an automated approach for generating communication sequences and carrying them out. The approach is based on AI planning where each action can be assumed to be a certain question that is given to the chatbot. The answer of the chatbot should make the action post-condition true, in order to proceed with the plan. In cases of\u00a0\u2026", "num_citations": "22\n", "authors": ["1033"]}
{"title": "Evaluation of the IPO-family algorithms for test case generation in web security testing\n", "abstract": " Security testing of web applications remains a major problem of software engineering. In order to reveal vulnerabilities, testing approaches use different strategies for detection of certain kinds of inputs that might lead to a security breach. Such approaches depend on the corresponding test case generation technique that are executed against the system under test. In this work we examine how two of the most popular algorithms for combinatorial test case generation, namely the IPOG and IPOG-F algorithms, perform in web security testing. For generating comprehensive and sophisticated testing inputs we have used input parameter modelling which includes also constraints between the different parameter values. To handle the test execution, we make use of a recently introduced methodology which is based on model-based testing. Our evaluation indicates that both algorithms generate test inputs that succeed in\u00a0\u2026", "num_citations": "22\n", "authors": ["1033"]}
{"title": "ConDiag-computing minimal diagnoses using a constraint solver\n", "abstract": " ConDiag - Computing minimal diagnoses using a constraint solver \u2014 Graz University of Technology Skip to main navigation Skip to search Skip to main content Graz University of Technology Logo English Deutsch Home Persons Research Units Research Outputs Projects Activities Prizes Press / Media Search by expertise, name or affiliation ConDiag - Computing minimal diagnoses using a constraint solver Iulia-Dana Nica, Franz Wotawa Institute of Software Technology (7160) Research output: Contribution to conference \u203a Poster Overview Original language English Publication status Published - 2012 Event International Workshop on Principles of Diagnosis - Great Malvern, United Kingdom Duration: 31 Jul 2012 \u2192 3 Aug 2012 Conference Conference International Workshop on Principles of Diagnosis Country United Kingdom City Great Malvern Period 31/07/12 \u2192 3/08/12 Fields of Expertise Sonstiges Cite this \u2026", "num_citations": "22\n", "authors": ["1033"]}
{"title": "From conflicts to diagnoses: An empirical evaluation of minimal hitting set algorithms\n", "abstract": " Using appropriate models, minimal hitting sets of a set of conflict sets can provide a sound foundation for diagnostic reasoning. Related diagnoses can explain encountered inconsistencies between expected and experienced behavior, so that a multitude of algorithms for computing such diagnoses have been developed. Motivated by a lack of a comparative study, in this paper, we evaluate a selection of relevant algorithms in the context of synthetic and real-world test scenarios.", "num_citations": "22\n", "authors": ["1033"]}
{"title": "On the complexity of program debugging using constraints for modeling the program\u2019s syntax and semantics\n", "abstract": " The use of model-based diagnosis for automated program debugging has been reported in several publications. The quality of the obtained results in terms of debugging accuracy is good. Unfortunately, most of the proposed models and techniques have very high computational needs. In this paper we focus on giving an explanation for the high computational needs of debugging. In particular, we propose a constraint representation of programs whose behavior is equivalent to the original programs. We further analyze the constraint representation to obtain its hypertree width, which is an indicator for the complexity of the corresponding constraint satisfaction problem. As constraint-based debugging is equivalent to constraint solving, the hypertree width is also an indicator for the debugging complexity. We further show that it is possible to construct arbitrarily complex programs such that their hypertree width\u00a0\u2026", "num_citations": "22\n", "authors": ["1033"]}
{"title": "Coupling CSP decomposition methods and diagnosis algorithms for tree-structured systems\n", "abstract": " Decomposition methods are used to convert general constraint satisfaction problems into an equivalent tree-structured problem that can be solved more effectively. Recently, diagnosis algorithms for tree-structured systems have been introduced, but the prerequisites of coupling these algorithms to the outcome of decomposition methods have not been analyzed in detail, thus limiting their diagnostic applicability. In this paper we generalize the TREE* algorithm and show how to use hypertree decomposition outcomes as input to the algorithm to compute the diagnoses of a general diagnosis problem.", "num_citations": "22\n", "authors": ["1033"]}
{"title": "A teleo-reactive architecture for fast, reactive and robust control of mobile robots\n", "abstract": " One of the elementary tasks of an autonomous mobile robot is the execution of different behavior patterns in order to fulfill a given task. The complexity of this problem is especially high if the robot operates in a dynamic, unpredictable environment and requires the parallel control of multiple actuators. In this paper we present a novel architecture for robust and fast mobile robot control. The architecture is based on Teleo-Reactive Programs. We discuss the benefits and drawbacks of such programs, extend the basic definition for the parallel control of multiple actuators, and propose a new language and a compiler for extended Teleo-Reactive Programs. These tools simplify the creation of new behavior patterns and increase the runtime performance. Finally, we discuss implementation issues of the architecture when applying it to RoboCup Middle-Size soccer robots.", "num_citations": "21\n", "authors": ["1033"]}
{"title": "VHDLDIAG+: Value-level diagnosis of VHDL programs\n", "abstract": " We describe the application of model-based diagnosis to the debugging of VHDL programs. In our previous work in VHDL-based software diagnosis, we have relied upon a very abstract representation to make it possible to diagnose fullsized applications (up to 1MLOC) at the cost of reduced discrimination between diagnoses. This paper describes a more detailed representation for VHDL programs that explicitly reasons about the computation of variable and signal values, making it possible to examine the internal workings of VHDL processes to find a more exact cause of the errors in a program. The higher computational effort involved requires that the new representation be used as a refinement in tandem with the older, more abstract representation. Models for the full VHDL language extent are currently being developed. The implementation is being applied to test problems.", "num_citations": "21\n", "authors": ["1033"]}
{"title": "PURITY: a Planning-based secURITY testing tool\n", "abstract": " Despite sophisticated defense mechanisms security testing still plays an important role in software engineering. Because of their latency, security flaws in web applications always bear the risk of being exploited sometimes in the future. In order to avoid potential damage, appropriate prevention measures should be incorporated in time and in the best case already during the software development cycle. In this paper, we contribute to this this goal and present the PURITY tool for testing web applications. PURITY executes test cases against a given website. It detects whether the website is vulnerable against some of the most common vulnerabilities, i.e., SQL injections and cross-site scripting. The goal is to resemble a malicious activity by following typical sequences of actions potentially leading to a vulnerable state. The test execution proceeds automatically. In contrast to other penetration testing tools, PURITY\u00a0\u2026", "num_citations": "20\n", "authors": ["1033"]}
{"title": "Combining hypertree, bicomp, and hinge decomposition.\n", "abstract": " Solving Constraint Satisfaction Problems (CSP) is in general NP-complete. If the structure of the CSP is a tree, then the computation can be done very effectively in a backtrack-free manner. There are several methods for converting CSPs in their treestructured equivalent, eg, hinge decomposition. More recently hypertree decomposition was developed and proved to subsume all other previously developed structure-based decomposition methods. In this paper we report recent results of a hypertree-decomposition implementation. We further have combined hypertree decomposition, biconnected component decomposition (bicomp), and hinge decomposition to improve running time and to make hypertree decomposition applicable on larger CSP instances. The formal requirements and the empirical results of the combined algorithms are reported. both BICOMP and HINGE are weaker than hypertree decomposition with respect to their width. Our experimental results show that for some instances this combi-nation of decomposition methods lead to a substantial improvement of running time. In order to combine the approaches we introduce an unified framework and describe the combination process in detail. Without restricting generality we assume that the hypergraphs of the CSPs are connected and reduced. Note that the connected sub-hypergraphs of such an unconnected hypergraph can be solved inde-pendently.", "num_citations": "20\n", "authors": ["1033"]}
{"title": "Failure Mode and Effect Analysis for Abductive Diagnosis.\n", "abstract": " Diagnosis, ie, fault localization in case of observing an unexpected behavior, is an important practical problem. During the past decades researchers have suggested several approaches for using models of the systems directly for identifying the root causes of failure. This model-based diagnosis approaches are either based on retaining consistency or on abduction. Despite their advantages both approaches are only rarely used in practical applications. In this paper, we focus on bringing abductive diagnosis closer to its application. In particular, we describe how failure mode and effect analysis, a technique of growing interest in applications, can be directly mapped to abductive diagnosis models. We discuss the basic foundations, and also problems that occur and how to deal with them. A direct conversion of FMEAs to abductive diagnosis problems would increase the use of abduction in practice because of avoiding writing logical theories directly.", "num_citations": "19\n", "authors": ["1033"]}
{"title": "Improving test case generation from UML statecharts by using control, data and communication dependencies\n", "abstract": " Dependence relations have been used in slicing of programs in order to remove statements that do not influence certain criteria of interest. More recently, slicing has also been applied at the specification level in order to obtain a reduced model pertinent to the selected criteria. Such models have been used for different verification and validation activities. In this article we present an approach that uses control, data and communication dependences in order to enhance test purposes with refuse transitions. A test purpose represents an abstraction of the original model describing a scenario of interest, which should be tested. The refuse transitions are used during the test case generation process in order to limit the state space being searched. As automating test case generation activities is of great importance the generation of the test purposes and of the test cases consequently is fully automatic. We have evaluated\u00a0\u2026", "num_citations": "19\n", "authors": ["1033"]}
{"title": "Functional SOA testing based on constraints\n", "abstract": " In the fierce competition on today's software market, Service-Oriented Architectures (SOAs) are an established design paradigm. Essential concepts like modularization, reuse, and the corresponding IP core business are inherently supported in the development and operation of SOAs that offer flexibility in many aspects and thus optimal conditions also for heterogeneous system developments. The intrinsics of large and complex SOA enterprises, however, require us to adopt and evolve our verification technology, in order to achieve expected software quality levels. In this paper, we contribute to this challenge by proposing a constraint based testing approach for SOAs. In our work, we augment a SOA's BPEL business model with pre- and postcondition contracts defining essential component traits, and derive a suite of feasible test cases to be executed after assessing its quality via corresponding coverage criteria\u00a0\u2026", "num_citations": "19\n", "authors": ["1033"]}
{"title": "Robust plan execution using model-based reasoning\n", "abstract": " Autonomous mobile robots perform more tasks with increasing complexity, like exploring other planets. In order to be able to perform such tasks they have to have capabilities for planning and reasoning. For the calculation of a plan for a given goal there exist a number of suitable  algorithms. However, if such a plan is executed on an autonomous mobile robot in a dynamic environment, a number of problems are likely to occur. Apart from the problems caused by the assumption used in the planning phase, problems arise though inaccurate sensing, acting and events that are  not under the control of the robot. All these problems have in common that they cause an inconsistency between the intentions of the plan and the observed world. In this paper we propose model-based diagnosis as a method for the detection and categorization of such inconsistencies. The obtained  knowledge about failures in plan\u00a0\u2026", "num_citations": "19\n", "authors": ["1033"]}
{"title": "Local maximum ozone concentration prediction using soft computing methodologies\n", "abstract": " The prediction of ozone levels is an important task because this toxic gas can produce harmful effects to the population health especially of children. This article describes the application of the Fuzzy Inductive Reasoning methodology and a Recurrent Neural Network (RNN) approach, the Long Short Term Memory (LSTM) architecture, to a signal forecasting task in an environmental domain. More specifically, we have applied FIR and LSTM to the prediction of maximum ozone(O3) concentrations in the East Austrian region. In this article the results of FIR and LSTM on this task are compared with those obtained previously using other types of neural networks (Multilayer Perceptrons (MLPs), Elman Networks (ENs) and Modified Elman Networks (MENs)). The performance of the best LSTM networks inferred are equivalent to the best FIR models identified and both are slightly better than the other Neural\u00a0\u2026", "num_citations": "19\n", "authors": ["1033"]}
{"title": "Simultate: A toolset for fault injection and mutation testing of simulink models\n", "abstract": " The advantages of fault injection techniques and related methodologies like mutation testing have been gaining in attention also from industry, as is evident from the advent of standards like ISO 26262 that suggest to use corresponding approaches for verifying an automotive system's safety aspects. Aside a well-established theoretical background, the availability of tools is a key issue in order to leverage fault injection for the development of industrial, possibly safety-critical applications, e.g., in an automotive context. We propose the corresponding open source toolset SIMULTATE for injecting faults and performing mutation testing for Simulink models. For complementing the provided mutation/fault injection operators, it allows a user to define her own ones within Matlab and further provides a Python interface for easily deriving mutants where she can also focus the scope to desired model parts only. Controlling the\u00a0\u2026", "num_citations": "18\n", "authors": ["1033"]}
{"title": "Does testing help to reduce the number of potentially faulty statements in debugging?\n", "abstract": " Tools for automated fault localization usually generate too many bug candidates depending on the underlying technique. Hence, further information is required in order to further restrict the bug candidates. Approaches that rely on specific knowledge of the program to be debugged like variable values at specific position in the source code, are not easily accessible for users especially in case of software maintenance. In order to avoid this problem we suggest to integrate testing for restricting the number of bug candidates. In particular, we suggest to compute possible corrections of the program and from this, distinguishing test cases. A distinguishing test case is a test that reveals different output values for two given program variants, given the same input values. Besides the formal definitions and algorithms, we present the first empirical results of our approach. The use of mutations and distinguishing test\u00a0\u2026", "num_citations": "18\n", "authors": ["1033"]}
{"title": "Program File Bug Fix Effort Estimation Using Machine Learning Methods for OSS.\n", "abstract": " Accurate effort estimation model plays an important role in software maintenance and software project management. Most of the effort estimation models are related to commercial or closed software systems, whereas it is difficult to develop an effort estimation model for open source software system (OSS). Reasons may be the inherent complexity of OSS, the large number of software developers or contributors and the absence of effort data. Most of the OSS systems do not maintain effort data, while this data is required to develop and validate the effort estimation model. In this paper we present the bug fix effort estimation model for open source software system. This paper is divided into two parts; in the first part we present a heuristic approach to mine the effort data from the developers or contributors activity logs. In the second part, we present six different effort estimation models, which are based on statistical regression and machine learning (ML) methods. To develop the effort estimation model, we used a set of metrics as estimators along with the bug fix effort data, which is obtained in the first part. The set of metrics are obtained from program files, source code changes and CVS log. To perform experiments we selected the Mozilla open source project and downloaded bug fix reports along with bug fix activity data from the corresponding bugzilla server. We also downloaded source files revisions and CVS log data from CVS repository. Furthermore, we compared the outcome of the different effort models using several evaluation criteria. The results show that the machine learning models are better compared to the statistical regression model\u00a0\u2026", "num_citations": "18\n", "authors": ["1033"]}
{"title": "Plan it! automated security testing based on planning\n", "abstract": " Testing of web applications for common vulnerabilities still represents a major challenge in the area of security testing. The objective here is not necessarily to find new vulnerabilities but to ensure that the web application handles well-known attack patterns in a reliable way. Previously developed methods based on formalizing attack patterns contribute to the underlying challenge. However, the adaptation of the attack models is not easy and requires substantial effort. In order to make modeling easier we suggest representing attacks as a sequence of known actions that have to be carried out in order to be successful. Each action has some pre conditions and some effects. Hence, we are able to represent testing in this context as a planning problem where the goal is to break the application under test. In the paper, we discuss the proposed planning based testing approach, introduce the underlying concepts\u00a0\u2026", "num_citations": "17\n", "authors": ["1033"]}
{"title": "Debugging spreadsheets: A CSP-based approach\n", "abstract": " Despite being staggeringly error prone, spreadsheets can be viewed as a highly flexible end-users programming environment. As a consequence, spreadsheets are widely adopted for decision making, and may have a serious economical impact for the business. Hence, approaches for aiding the process of pinpointing the faulty cells in a spreadsheet are of great value. We present a constrain-based approach, CONBUG, for debugging spreadsheets. The approach takes as input a (faulty) spreadsheet and a test case that reveals the fault and computes a set of diagnosis candidates for the debugging problem we are trying to solve. To compute the set of diagnosis candidates we convert the spreadsheet and test case to a constraint satisfaction problem. From our experimental results, we conclude that CONBUG can be of added value for the end user to pinpoint faulty cells.", "num_citations": "17\n", "authors": ["1033"]}
{"title": "Diagnosis and repair of dependent failures in the control system of a mobile autonomous robot\n", "abstract": " Detecting, locating and repairing faults is a hard task. This holds especially in cases where dependent failures occur in practice. In this paper we present a methodology which is capable of handling dependent failures. For this purpose we extend the model-based diagnosis approach by explicitely representing knowledge about such dependencies which are stored in a failure dependency graph. Beside the theoretical foundations we present algorithms for computing diagnoses and repair actions that are based on these extensions. Moreover, we introduce a case study which makes use of a larger control program of an autonomous and mobile robot. The case study shows that the proposed approach can be effectively used in practice.", "num_citations": "17\n", "authors": ["1033"]}
{"title": "Impact analysis of SCRs using single and multi-label machine learning classification\n", "abstract": " In case of resolved software change requests (SCRs), the names of impacted source files are known. In this paper, we tackle the question whether it is possible to use this information in order to predict the files that have to be changed whenever a new SCR is received. In order to provide a solution, we present two different approaches, which are based on automatic text classification of SCRs. First, we use Latent Semantic Indexing (LSI) to index the key terms of SCRs. Then, for classification we use two different approaches of machine learning ie, single and multi label classification. We applied our approaches on the SCR's data of Gnome, Mozilla and Eclipse OSS projects. Our initial experimental results are promising, the obtained maximum precision values for single and multi label classification are 58.2% and 47.1% respectively. Furthermore, in case of single and multilabel classification, the maximum attained\u00a0\u2026", "num_citations": "17\n", "authors": ["1033"]}
{"title": "Fundamentals of debugging using a resolution calculus\n", "abstract": " Detecting and localizing a fault within a program is a non-trivial and time consuming task. Most of the efforts spent for automating the task have focused on fault detection. In this paper we shift the focus on fault localization. We introduce a resolution calculus that allows for representing the program\u2019s behavior based on correctness assumptions. The fault localization task is reduced to finding consistent assumptions which are represented as a non-monotonic reasoning process where efficient algorithms exist. Finally, we compare our approach with a previous approach to fault localization that is based on trace analysis. As a result we can show that our approach is less sensitive to search assumptions.", "num_citations": "17\n", "authors": ["1033"]}
{"title": "Local maximum ozone concentration prediction using neural networks\n", "abstract": " This paper describes the use of Artificial Neural Networks (ANNs) for the short term prediction of maximum ozone concentrations in the East Austrian region. Various Multilayer Perceptron topologies (MLPs), Elman Networks (EN) and Modified Elman Networks (MEN) were tested. The individual models used ozone, temperature, cloud cover and wind data taken from the summer months from 1995 and 1996. The achieved results were satisfactory. Comparisons with alternative models showed that the neural approaches used in this study were superior.", "num_citations": "17\n", "authors": ["1033"]}
{"title": "Genetic algorithm-based test parameter optimization for ADAS system testing\n", "abstract": " In this paper, we outline the use of a genetic algorithm for test parameter optimization in the context of autonomous and automated driving. Our approach iteratively optimizes test parameters to aim at obtaining critical scenarios that form the basis for virtual verification and validation of Advanced Driver Assistant Systems (ADAS). We consider a test scenario to be critical if the underlying parameter set causes a malfunction of the system equipped with the ADAS function (i.e., near crash or crash of the vehicle). For evaluating the effectiveness of our approach, we set up an automated simulation framework, where we simulated the Euro NCAP car-to-car rear scenario. To assess the criticality of each test scenario we rely on time-to-collision (TTC), which is a well-known and often used time-based safety indicator for recognizing rear-end conflicts. Our genetic algorithm approach showed a higher chance to generate a\u00a0\u2026", "num_citations": "16\n", "authors": ["1033"]}
{"title": "Testing autonomous and highly configurable systems: Challenges and feasible solutions\n", "abstract": " Proving techniques and methods for safety critical systems in order to ensure a certain behavior as well as their corresponding safety requirements has still been a challenge for many years. Although the current situation in many areas like the automotive industry has improved a lot, new challenges are in sight especially when considering autonomous and adaptive systems approaching. Such systems have to reason about the current state and stimuli from their environment without humans in the loop or are allowed to change their behavior over time. Such systems induce new requirements for quality assurance and in particular testing. Here the focus has to be on providing guarantees of a wanted behavior before deployment of the systems even in case of changes or failures that might arise at runtime. In this paper, we discuss the underlying challenges and potential feasible solutions. In addition, we\u00a0\u2026", "num_citations": "16\n", "authors": ["1033"]}
{"title": "Conformance testing of hybrid systems with qualitative reasoning models\n", "abstract": " Embedded systems are of growing importance in industry. For example, in a today's vehicle a huge number of embedded and communicating systems can be found. Exhaustive testing of such systems is a requirement, because changes after delivery and use are expensive and sometimes even impossible. In this paper we propose the use of qualitative models, which are an abstraction of quantitative physical models, for test case generation and test execution. In particular, we show how Simulink models from which control programs are automatically extracted can be tested with respect to qualitative models. Since Simulink models are heavily used in industry, the approach is of practical interest.", "num_citations": "16\n", "authors": ["1033"]}
{"title": "ENVIRONMENTAL DECISION SUPPORT SYSTEMS BASED ON MODELS AND MODEL-BASED REASONING.\n", "abstract": " Decision trees and role-based systems including variants based on propositional and fuzzy logic have been the method of choice for knowledge representation in many applications of environmental decision support systems. Reasons are the ease of use, the capability of representing uncertainty, and the fast computation of results at runtime when using decision trees, rule-based systems, or other similar means for knowledge representation. Unfortunately there are drawbacks related with these modeling paradigms. For example, the cause-effect relationships between quantities am not captured correctly. The resulting model is well appropriated for a certain purpose but can hardly be re-used. Moreover, maintaining the knowledge base can be an intricate task. This paper is focused on the problems related to role-based systems in the context of environmental decision support systems using an example from the\u00a0\u2026", "num_citations": "15\n", "authors": ["1033"]}
{"title": "Java's alternatives and the limitations of Java when writing cross-platform applications for mobile devices in the medical domain\n", "abstract": " In this paper we discuss alternatives to Java ME when writing medical applications for mobile devices across multiple platforms. The Java virtual machine, which runs Java programs, is not available for the majority of handheld devices, such as palm PDAs, Windows Mobile based devices, or the Apple iPhone. As well as this, we conclude that full GUI interaction, such as the interaction provided by Java programs, is not an absolute requirement to make a program useful, and we developed an HTML-based medical information application to illustrate this. This program displays various sample patient parameters to the user in graph form, and was tested on multiple platforms and operating systems to demonstrate its platform/OS independence and usefulness.", "num_citations": "15\n", "authors": ["1033"]}
{"title": "How to debug sequential code by means of constraint representation\n", "abstract": " In this paper we discuss a model-based diagnosis approach to the debugging of sequential programs which is based on expressing the program semantics by a constraint representation. We formalize this representation and prove its equivalence with respect to the semantics of the programming language, and we frame the debugging process as a constraint satisfaction problem (CSP). We identify two main advantages of a constraint representation of sequential programs. First, the constraint representation allows for a straightforward integration of program annotations like pre-and post-conditions and invariants. We show that the integration of those additional specifications can improve the diagnostic precision by eliminating diagnoses. Second, we can benefit from the extensive research work which has already been done on CSPs. In particular, we propose to derive a metrics for the complexity of debugging from the structural decomposition properties obtained for the corresponding CSP. We classify the complexity of the diagnosis problem by using the hypertree width of the hypergraph for the CSP, and we report experimental results concerning the hypertree width for a set of programs.", "num_citations": "15\n", "authors": ["1033"]}
{"title": "Deriving qualitative rules from neural networks\u2013a case study for ozone forecasting\n", "abstract": " As alternative to physical models, neural networks are a valuable forecast tool in environmental sciences. They can be used effectively due to their learning capabilities and their low computational costs. As far as the relevant variables of the system are measured and put into the network, it works fast and accurately. However, one of the major shortcomings of neural networks is that they do not reveal causal relationships between major system components and thus are unable to improve the explicit knowledge of the user. To overcome this problem, we introduce an approach for deriving qualitative informations out of neural networks. Some of the resulting rules can be directly used by a qualitative simulator for producing possible future scenarios. Because of the explicit representation of knowledge the rules should be easier to understand and can be used as starting point for creating models wherever a physical\u00a0\u2026", "num_citations": "15\n", "authors": ["1033"]}
{"title": "On the industrial application of combinatorial testing for autonomous driving functions\n", "abstract": " The growing importance of automated and autonomous driving systems becomes more and more visible in the industrial domain as well as in research. Validation and verification of autonomous driving functions is one of the grand challenges in autonomous vehicle development. Virtual validation using simulation has been widely discussed and proposed as a method to solve the challenge. Furthermore, scenario-based approaches have been considered as proper methods combined with virtual validation in order to identify critical scenarios. In this paper, we discuss a method for testing automated and autonomous driving functions using ontologies and combinatorial testing that is able to automate test case generation. Moreover, we report on the application of the method at the industrial level. There we depict the comprehensive application process from the construction of the ontology to test suite execution in\u00a0\u2026", "num_citations": "14\n", "authors": ["1033"]}
{"title": "Fstaxis algorithm: Bio-inspired emergent gradient taxis\n", "abstract": " This article presents a novel bio-inspired emergent gradient taxis principle for robot swarms. The underlying communication method was inspired by slime mold and fireflies. Nature showcases a number of simple organisms which can display complex behavior in various aspects of their lives such as signaling, foraging, mating etc. Such decentralized behaviors at the organism level gives rise to an emergent intelligence such as in bees, slime mold, fireflies etc. Chemo taxis and photo taxis are known to be abilities exhibited by simple organisms without elaborate sensory and actuation capabilities. Our novel algorithm combines the underlying principles of slime mold and fireflies to achieve gradient taxis purely based on neighbor-to-neighbor communication. In this article, we present a model of the algorithm and test the algorithm in a multiagent simulation environment.", "num_citations": "14\n", "authors": ["1033"]}
{"title": "SOA Grey Box Testing--A Constraint-Based Approach\n", "abstract": " Service-Oriented Architectures (SOAs) offer attractive advantages in respect of reusability, interoperability and dynamics, and are nowadays widely accepted in industry. Achieving established software quality levels also with SOAs, while mandatory, is challenging, as, for instance, a SOA's dynamics and heterogeneity exacerbate verification issues like observability, controllability, and distribution. Regarding verification, we thus have to evolve available technology in order to enable the assessment of essential functional and non-functional system properties, including correctness, performance, stability, robustness and scalability. Adopting a model-based grey box testing approach that can exploit mixed description levels for individual (possibly 3 rd  party) services promises the required flexibility for successful development workflows. In this paper, we propose such a testing approach that, considering a SOA model\u00a0\u2026", "num_citations": "14\n", "authors": ["1033"]}
{"title": "Model-based reasoning for self-adaptive systems\u2013theory and practice\n", "abstract": " Internal faults but also external events, or misinterpretations of sensor inputs as well as failing actuator actions make developing dependable systems a demanding task. This holds especially in the case where systems heavily interact with their environment. Even in case that the most common faults can be handled, it is very unlikely to capture all possible faults or interaction patterns at development time. As a consequence self-adaptive systems that respond to certain unexpected actions and observations at runtime are required. A pre-requisite for such system behavior is that the system itself has knowledge about itself and its objectives, which can be used for adapting its behavior autonomously. In order to provide a methodology for such systems we propose the use of model-based reasoning as foundation for adaptive systems. Besides lying out the basic principles, which allow for assurance of\u00a0\u2026", "num_citations": "14\n", "authors": ["1033"]}
{"title": "Adaptive autonomous systems\u2013from the system\u2019s architecture to testing\n", "abstract": " Autonomous systems have to deal with situations where external events or internal faults lead to states, which have not been considered during development. As a consequence such systems have to have knowledge about themselves, which has to be used to reason about adaptions in order to fulfill a given goal. In this paper we present a control architecture that combines a the sense-plan-act paradigm and model-based reasoning. The latter is used to identify internal faults. Beside discussing the control architecture we also briefly explain advantages of model-based diagnosis where there is a shift from providing control programs to developing models. Consequently, testing of models becomes an issue. Therefore, we also introduce basic definitions related to testing models for diagnosis and discuss the involved challenges.", "num_citations": "14\n", "authors": ["1033"]}
{"title": "Analysing bug prediction capabilities of static code metrics in open source software\n", "abstract": " Open Source Softwares provide a rich resource of empirical research in software engineering. Static code metrics are a good indicator of software quality and maintainability. In this work we have tried to answer the question whether bug predictors obtained from one project can be applied to a different project with reasonable accuracy. Two open source projects Firefox and Apache HTTP Server (AHS) are used for this study. Static code metrics are calculated for both projects using in-house software and the bug information is obtained from bug databases of these projects. The source code files are classified as clean or buggy using the Decision tree classifier. The classifier is trained on metrics and bug data of Firefox and tested on Apache HTTP Server and vice versa. The results obtained vary with different releases of these projects and can be as good as 92 % of the files correctly classified and as poor as\u00a0\u2026", "num_citations": "14\n", "authors": ["1033"]}
{"title": "Towards automated online diagnosis of robot navigation software\n", "abstract": " Navigation software of autonomous mobile robots comprises a number of software modules that typically interact in a very complex way. Their proper interaction and the robustness of each single module strongly influence the safety during navigation in the field. Particularly in unstructured environments, unforeseen situations are likely to occur causing erroneous behaviors of the robot. The proper handling of such situations requires an understanding of cause and effect within the complex interactions of the system.               In this paper we present a method for the automatic modeling of navigation software components and their interactions by observing their communication patterns. The learned model is used online for model-based reasoning (MBR) in order to increase system robustness during runtime.               We evaluated the approach on three different robot systems whose software components are\u00a0\u2026", "num_citations": "14\n", "authors": ["1033"]}
{"title": "Computing diagnosis efficiently: A fast theorem prover for propositional horn theories\n", "abstract": " In this paper we introduce a fast theorem prover for propositional Horn theories that allows for adding and removing assumptions in a very efficient way by employing a dependency structure to record the impacts of adding specific assumptions. Moreover, we present an extensive empirical evaluation of our algorithm by applying an incremental approach to compute all single fault diagnoses of industrial-sized problems.", "num_citations": "14\n", "authors": ["1033"]}
{"title": "Performance comparison of two search-based testing strategies for ADAS system validation\n", "abstract": " In this paper, we compare the performance of a genetic algorithm for test parameter optimization with simulated annealing and random testing. Simulated annealing and genetic algorithm both represent search-based testing strategies. In the context of autonomous and automated driving, we apply these methods to iteratively optimize test parameters, to aim at obtaining critical scenarios that form the basis for virtual verification and validation of Advanced Driver Assistant System (ADAS). We consider a test scenario to be critical if the underlying parameter set causes a malfunction of the system equipped with the ADAS function (i.e., near-crash or crash of the vehicle). To assess the criticality of each test scenario we rely on time-to-collision (TTC), which is a well-known and often used time-based safety indicator for recognizing rear-end conflicts. For evaluating the performance of each testing strategy, we set\u00a0\u2026", "num_citations": "13\n", "authors": ["1033"]}
{"title": "Quality assurance methodologies for automated driving\n", "abstract": " For safety critical systems like cars, trains, or airplanes quality assurance methods and techniques are crucial for preventing situations that may harm people. The case of automated driving represents the next level of safety critical systems where additional challenges arise. This includes the question of how to assure that artificial intelligence and machine learning based systems fulfill safety criticality requirements under all potential conditions and situations that may emerge during operation. In this paper, we first review simulation-based verification and validation methods for such systems and afterwards discuss necessary requirements and future research challenges that have to be solved in order to bring automated driving into practice without compromising safety requirements.", "num_citations": "13\n", "authors": ["1033"]}
{"title": "Test-suite reduction does not necessarily require executing the program under test\n", "abstract": " Removing redundancies from test-suites is an important task of software testing in order to keep test-suites as small as possible, but not to harm the test-suite's fault detection capabilities. A straightforward algorithm for test-suite reduction would select elements of the test-suite randomly and remove them if and only if the reduced test-suite fulfills the same or similar coverage or mutation score. Such algorithms rely on the execution of the program and the repeated computation of coverage or mutation score. In this paper, we present an alternative approach that purely relies on a model learned from the original test-suite without requiring the execution of the program under test. The idea is to remove those tests that do not change the learned model. In order to evaluate the approach we carried out an experimental study showing that reductions of 60-99% are possible while still keeping coverage and mutation score\u00a0\u2026", "num_citations": "13\n", "authors": ["1033"]}
{"title": "On error-class distribution in automotive model-based software\n", "abstract": " Software fault prediction promises to be a powerful tool in supporting test engineers upon their decision where to define testing hotspots. However, there are limitations on a cross project prediction and a lack of reports upon application to industrial software, as well as the power of metrics to represent bugs. In this paper, we present a novel analysis based upon faults discovered in model-based automotive software projects and their relationship to metrics used to perform fault prediction. Using our previously released dataset on software metrics, we report bug classes discovered during heavy testing of those automotive software. As the software has been developed following strict coding and development guidelines, we present the results based on a comparison between the discovered error classes and those which might derive a reduced potential error set. Using the three projects from our dataset we determine if\u00a0\u2026", "num_citations": "13\n", "authors": ["1033"]}
{"title": "Using dependency relations to improve test case generation from UML statecharts\n", "abstract": " In model-based testing the size of the used model has a great impact on the time for computing test cases. In model checking, dependence relations have been used in slicing of specifications in order to obtain reduced models pertinent to criteria of interest. In specifications described using state based formalisms slicing involves the removal of transitions and merging of states thus obtaining a structural modified specification. Using such a specification for model based test case generation where sequences of transitions represent test cases might provide traces that are not valid on a correctly behaving implementation. In order to avoid such trouble, we suggest the use of control, data and communication dependences for identifying parts of the model that can be excluded so that the remaining specification can be safely employed for test case generation. This information is included in test purposes which are then\u00a0\u2026", "num_citations": "13\n", "authors": ["1033"]}
{"title": "Automatic classification of software change request using multi-label machine learning methods\n", "abstract": " Automatic text classification of the software change request (CR) can be used for automating impact analysis, bug triage and effort estimation. In this paper, we focus on the automation of the process for assigning CRs to developers and present a solution that is based on automatic text classification of CRs. In addition our approach provides the list of source files, which are required to be modified and an estimate for the time required to resolve a given CR. To perform experiments, we downloaded the set of resolved CRs from the OSS project's repository for Mozilla. We labeled each CR with multiple labels i.e., the developer name, the list of source files, and the time spent to resolve the CR. To train the classifier, our approach applies the Problem Transformation and Algorithm Adaptation methods of multi-label machine learning to the multi-labeled CR data. With this approach, we have obtained precision levels up to\u00a0\u2026", "num_citations": "13\n", "authors": ["1033"]}
{"title": "Software change classification using hunk metrics\n", "abstract": " Change management is a challenging task in software maintenance. Changes are made to the software during its whole life. Some of these changes introduce errors in the code which result in failures. Software changes are composed of small code units called hunks, dispersed in source code files. In this paper we present a technique for classifying software changes based on hunk metrics. We classify individual hunks as buggy or bug-free, thus we provide an approach for bug prediction at the smallest level of granularity. We introduce a set of hunk metrics and build classification models based on these metrics. Classification models are built using logistic regression and random forests. We evaluated the performance of our approach on 7 open source software projects. Our classification approach can classify hunks as buggy or bug free with 81 percent accuracy, 77 percent buggy hunk precision and 67 percent\u00a0\u2026", "num_citations": "13\n", "authors": ["1033"]}
{"title": "Debugging synthesizeable VHDL programs\n", "abstract": " This paper describes the use of model-based diagnosis for locating bugs in hardware designs. We restrict our view to hardware designs written in a subset of the commonly used hardware description language VHDL. This subset includes all synthesizeable (register transfer level) programs. This are programs which can be automatically converted into a gate level description without changing their behavior. Therefore almost all VHDL programs are elements of this subset. We show the conversion of VHDL programs into a logical representation. Take this representation and apply model-based diagnosis. The resulting diagnoses are mapped back to the VHDL code fragments of the original program explaining misbehaviors. Finally, we specify some rules optimizing the obtained results. We further present some arguments showing that the proposed debugging technique scales up to large designs.", "num_citations": "13\n", "authors": ["1033"]}
{"title": "Automated generation of (F) LTL oracles for testing and debugging\n", "abstract": " For being able to draw on automated reasoning that helps us in improving the quality of some software artifact or cyber-physical system, we have to express desired system traits in precise formal requirements. Verifying that a system adheres to these requirements allows us then to gain the crucial level of confidence in its capabilities and quality. Complementing related methods like model checking or runtime monitors, for testing and most importantly debugging recognized problems, we would certainly be interested in automated oracles. These oracles would allow us to judge whether observed (test) data really adhere to desired properties, and also to derive program spectra that have been shown to be an effective reasoning basis for debugging purposes. In this paper, we show how to automatically derive such an oracle as a dedicated satisfiability encoding that is specifically tuned to the considered test data at\u00a0\u2026", "num_citations": "12\n", "authors": ["1033"]}
{"title": "Planning the attack! or how to use ai in security testing?\n", "abstract": " Testing is one effective method for quality assurance. Generating and executing tests is a labor consuming task and there has been a lot of effort spent in test automation where the focus has been mainly on functional or penetration testing but not specifically on security testing. In this paper, we discuss two already introduced approaches for automated security testing that are based on AI planning. The approaches map attack models and security protocol definitions to AI planning problems in order to generate test cases. Furthermore, utilizing plan execution together with generated plans allows also for automating the test execution. The objective of the paper is to further stimulate research in this field. Thus we not only discuss the foundations behind and their applications, but also outline challenges and further research directions.", "num_citations": "12\n", "authors": ["1033"]}
{"title": "An abductive diagnosis and modeling concept for wind power plants\n", "abstract": " The number and complexity of industrial wind turbine installations have increased significantly over the last decades. As maintenance costs are high and down-times lead to substantial revenue loss, increasing the reliability and optimizing the maintenance process are crucial tasks from an industrial perspective. However, many of the proposed diagnosis systems merely focus on parts of the turbine or only locate a portion of the faults. Model-based diagnosis has been applied successfully in industrial settings and further provides a solid theoretical background. Therefore, we propose a model-based approach depending on automatically retrieved health variables and on an extensive expert knowledge on specific component-oriented failure modes as well as their effects on measurable signals. As the expert assessment provides causal links between faults and their manifestations, we formally create a Propositional\u00a0\u2026", "num_citations": "12\n", "authors": ["1033"]}
{"title": "Model based test case generation for distributed embedded systems\n", "abstract": " As test case creation activities consume an increasing amount of resources allocated to software development projects, the need to automate this task as much as possible becomes more and more stringent. In this article we report on the application of academic test case generation tools in an industrial context. We present an approach to generate test cases from reactive distributed systems specified as asynchronously communicating UML statecharts. We employ two approaches for the generation process. The first one is fully automated and generates test cases aimed at transition coverage. The second one requires the intervention of the tester in order to annotate states and/or transitions partially describing a test scenario. It is the job of the tool to compute test cases pertaining to the specified test scenario.", "num_citations": "12\n", "authors": ["1033"]}
{"title": "Fault prediction capability of program file's logical-coupling metrics\n", "abstract": " Frequent changes in logically coupled source files induced bugs in software. Metrics have been used to identify source files which are logically coupled. In this paper, we propose an approach to compute a set of eight metrics, which measure logical-couplings among source files. We compute these metrics using the historical data of software changes which are related to the fixing of post release bugs. To validate that our propose set of metrics is highly correlated with the number bugs and are more capable to construct a bug prediction model, we performed an experiment. Our experimental results show that our propose set of metrics is highly correlated with the number of bugs, and hence can be used to construct a bug prediction model. In our experiment, the obtained accuracy of our bug predictor model is 97%.", "num_citations": "12\n", "authors": ["1033"]}
{"title": "Bridging the Gap Between Slicing and Model-based Diagnosis.\n", "abstract": " Fault localization is considered an important and difficult task in the software engineering process. In the last decades several approaches to fault localization have been published. Some of them are based on either static or dynamic program slicing. In this paper, we present an approach that combines program slicing with the computation of hitting sets. Hitting sets are used in model-based diagnosis to compute diagnoses from conflicting assumptions. We introduce the underlying definitions and algorithms of the approach, and show that the combination of slicing and hitting set computation reduces the number of statement to be considered. The presented approach does not rely on a specific slicing methodology and can be used in combination with static or dynamic slicing.", "num_citations": "12\n", "authors": ["1033"]}
{"title": "On the fly\u201d input output conformance verification\n", "abstract": " \u201cON THE FLY\u201d INPUT OUTPUT CONFORMANCE VERIFICATION Martin Weiglhofer Competence Network Softnet Austria Institute for Software Technology Graz University of Technology 8010 Graz, Austria weiglhofer@ist.tugraz.at Franz Wotawa Institute for Software Technology Graz University of Technology 8010 Graz, Austria wotawa@ist.tugraz.at ABSTRACT This paper shows how to use an on-the-\ufb02y veri\ufb01cation algo- rithm, that veri\ufb01es the equivalence of labeled transition sys- tems, for the veri\ufb01cation of the input output conformance (ioco) of input output labeled transition systems. Since ioco is usually used for testing there are several requirements on the input output labeled transition system (IOLTS) that are used for test generation. We show how to take care of these requirements during the on-the-\ufb02y veri\ufb01cation. Thus the presented approach can be applied to IOLTSs that do not initially ful\ufb01ll these requirements. \u2026", "num_citations": "12\n", "authors": ["1033"]}
{"title": "Comparing two models for software debugging\n", "abstract": " This paper extends previous work on the representation and analysis of Java programs for diagnosis in a new direction by providing a description and analysis of the issues arising from handling object references in dependency-based models of Java programs. We empirically compare dependency-based models with a value-based model using a set of example programs in terms of required user interaction (questions put to the user) and examine and incorporate specific interesting error categories. Apart from being based on experience with an actual implementation of the various models, the model extensions and analysis deal with aliasing, an issue that the programming language community has been examining for a long time, and that is also crucial to object-orientedness.", "num_citations": "12\n", "authors": ["1033"]}
{"title": "New directions in debugging hardware designs\n", "abstract": " This paper introduces a new approach in the debugging of hardware designs. The design is given as a VHDL program and converted in a component connection model. The conversion is similar to the synthesis of register transfer into gate level programs. The resulting model is directly used for locating faults within the design. To do this, we propose the application of model-based diagnosis. The advantage of this approach is its degree of automation and that it can be applied even on today\u2019s mid-size to large size programs.", "num_citations": "12\n", "authors": ["1033"]}
{"title": "From ontologies to input models for combinatorial testing\n", "abstract": " Ordinary tools for computing combinatorial test suites rely on simple input models comprising variables together with their domains and constraints limiting possible combinations. Modeling for combinatorial testing requires to represent the input domain of the application in a way such that it fits to the combinatorial testing input model. Depending on the application\u2019s domain this mapping ranges from trivial to more complicated. In this paper, we focus on modeling for combinatorial testing in cases the application\u2019s domain can be represented in form of an ontology, i.e., concepts and their relationships. We formally introduce the notation of ontology we rely on in this paper, and show how such ontologies can be automatically mapped to a combinatorial testing input model. We discuss the algorithm and show its properties.", "num_citations": "11\n", "authors": ["1033"]}
{"title": "Model-based testing-from safety to security\n", "abstract": " Objects of Research\u25b6 model-based testing\u25b6 SQL injection\u25b6 black-box testing\u25b6 white-box testing\u25b6 fuzzing\u25b6 mutation testing", "num_citations": "11\n", "authors": ["1033"]}
{"title": "Mining effort data from the oss repository of developer's bug fix activity\n", "abstract": " During the evolution of any software, efforts are made to fix bugs or to add new features in software. In software engineering, previous history of effort data is required to build an effort estimation model, which estimates the cost and complexity of any software. Therefore, the role of effort data is indispensable to build state-of-the-art effort estimation models. Most of the Open Source Software does not maintain any effort related information. Consequently there is no state-of-the-art effort estimation model for Open Source Software, whereas most of the existing effort models are for commercial software. In this paper we present an approach to build an effort estimation model for Open Source Software. For this purpose we suggest to mine effort data from the history of the developer\u2019s bug fix activities. Our approach determines the actual time spend to fix a bug, and considers it as an estimated effort.Initially, we use the developer\u2019s bug-fix-activity data to construct the developer\u2019s activity log-book. The log-book is used to store the actual time elapsed to fix a bug. Subsequently, the log-book information is used to mine the bug fix effort data. Furthermore, the developer\u2019s bug fix activity data is used to define three different measures for the developer\u2019s contribution or expertise level. Finally, we used the bug-fix-activity data to visualize the developer\u2019s collaborations and the involved source files. In order to perform an experiment we selected the Mozilla open source project and downloaded 93,607 bug reports from the Mozilla project bug tracking system i.e., Bugzilla. We also downloaded the available CVS-log data from the Mozilla project repository. In this study\u00a0\u2026", "num_citations": "11\n", "authors": ["1033"]}
{"title": "Empirical evaluation of hunk metrics as bug predictors\n", "abstract": " Reducing the number of bugs is a crucial issue during software development and maintenance. Software process and product metrics are good indicators of software complexity. These metrics have been used to build bug predictor models to help developers maintain the quality of software. In this paper we empirically evaluate the use of hunk metrics as predictor of bugs. We present a technique for bug prediction that works at smallest units of code change called hunks. We build bug prediction models using random forests, which is an efficient machine learning classifier. Hunk metrics are used to train the classifier and each hunk metric is evaluated for its bug prediction capabilities. Our classifier can classify individual hunks as buggy or bug-free with 86 % accuracy, 83 % buggy hunk precision and 77% buggy hunk recall. We find that history based and change level hunk metrics are better predictors of\u00a0\u2026", "num_citations": "11\n", "authors": ["1033"]}
{"title": "Modeling State in Software Debugging of VHDL-RTL Designs-A Model-based Diagnosis Approach\n", "abstract": " Modeling State in Software Debugging of VHDL-RTL Designs - A Model-based Diagnosis Approach \u2014 Graz University of Technology Skip to main navigation Skip to search Skip to main content Graz University of Technology Logo English Deutsch Home Persons Research Units Research Outputs Projects Activities Prizes Press / Media Modeling State in Software Debugging of VHDL-RTL Designs - A Model-based Diagnosis Approach Franz Wotawa, Bernhard Peischl Institute of Software Technology (7160) Research output: Chapter in Book/Report/Conference proceeding \u203a Conference contribution \u203a Research \u203a peer-review Overview Projects (1) Original language English Title of host publication Proceedings of the Fifth International Workshop on Automated Debugging (AADEBUG) Publisher . Pages 197-210 Publication status Published - 2003 Event International Workshop on Automated Debugging - Ghent, \u2026", "num_citations": "11\n", "authors": ["1033"]}
{"title": "On the relationship between model-based debugging and programm mutation\n", "abstract": " In this paper we discuss the relationship between program mutation and model-based diagnosis applied to locate and fix bugs in programs. We show that the time required to search for single faults is smaller in model-based diagnosis than in general program mutation. We use this result to speed up program mutation for debugging and develop a procedure that combines both approaches. Moreover, we show that a suitable model can deliver results that are as expressive as the results obtained by program mutation. This is done by introducing a fault mode \u042a \u0428\u0424 for components associated with statements and expressions.", "num_citations": "11\n", "authors": ["1033"]}
{"title": "JADE-AI Support for Debugging Java Programs.\n", "abstract": " Model-based diagnosis is a successful AI technique for locating and identifying faults in technical systems. Extending previous research on model-based diagnosis support for fault search in technical designs, we are building a model-based debugger for Java programs to provide intelligent support for the programmer trying to locate the source of an error. By using one or more models derived from the source code of the program without additional specifications except the Java semantics, the debugger guides the user (ie, developer) towards potential sources for incorrect program behaviors, ie, bugs.", "num_citations": "11\n", "authors": ["1033"]}
{"title": "Reconfiguration using model-based diagnosis\n", "abstract": " Knowledge-based configuration is a successful application domain for AI techniques. An open issue in many practical domains is that of reconfiguration, typically exhibited by legacy systems that are to be extended, upgraded or simply altered. We discuss the use of a diagnosis approach to reconfiguration. We present the differing application and representation requirements, develop a representation that is suitable for expressing the information about the required and configurable functionalities from the diagnosis point of view, present an example and discuss our experiences.", "num_citations": "11\n", "authors": ["1033"]}
{"title": "Security testing for chatbots\n", "abstract": " Services like chatbots that provide information to customers in real-time are of increasing importance for the online market. Chatbots offer an intuitive interface to answer user requests in an interactive manner. The inquiries are of wide-range and include information about specific goods and services but also financial issues and personal advices. The notable advantages of these programs are the simplicity of use and speed of the search process. In some cases, chatbots have even surpassed classical web, mobile applications, and social networks. Chatbots might have access to huge amount of data or personal information. Therefore, they might be a valuable target for hackers, and known web application vulnerabilities might be a security issue for chatbots as well. In this paper, we discuss the challenges of security testing for chatbots. We provide an overview about an automated testing approach adapted to\u00a0\u2026", "num_citations": "10\n", "authors": ["1033"]}
{"title": "SOA testing via random paths in BPEL models\n", "abstract": " Service oriented architectures (SOAs) allow for interesting and flexible software designs for complex problems. Such complex designs, however, require us to pay special attention to ensuring their quality. Extending earlier work on a testing and diagnosis concept for SOAs, we report in this paper on our first experience regarding an experimental setup with a test case generation algorithm based on random path selection, in contrast to our earlier work being based on considering all paths in a SOA's BPEL process description.", "num_citations": "10\n", "authors": ["1033"]}
{"title": "Abstracting timing information in UML state charts via temporal ordering and LOTOS\n", "abstract": " As testing of software systems becomes more and more important and expensive, there is a trend to automate as much as possible of this task. This article is intended as an attempt to breach the gap between academic model-based testing tools and their usage in industry. This is done by allowing the specification of a system in a widely accepted industry notation (UML state charts) and via a behind the scene transformation providing a formal representation of the system using the formal language LOTOS. As a byproduct of the transformation a formal semantics of UML state charts is given. An interesting class of software systems well suited for the application are distributed timed control oriented systems. As LOTOS contains no timing constructs, the timing information in the system is automatically abstracted by preserving the execution order of the timeout transitions.", "num_citations": "10\n", "authors": ["1033"]}
{"title": "On the use of abduction as an alternative to decision trees in environmental decision support systems\n", "abstract": " Although decision trees are frequently used in environmental decision support systems they have shortcomings. In case of an available model decision trees have to be constructed manually from the model. Moreover, not all knowledge is represented in the decision tree. In order to overcome this issues we propose the use of abductive reasoning directly applied to the available cause-effect model. In particular we introduce the abduction problem, i.e., the problem of finding a cause for observed effects, show how this problem can be extended in order to allow distinguishing between competing explanations, and discuss the integration of testing and repair actions within the framework. The latter is especially important in case of environmental decision support systems.", "num_citations": "10\n", "authors": ["1033"]}
{"title": "Debugging VHDL designs: Introducing multiple models and first empirical results\n", "abstract": " Debugging is a time-consuming task. This holds especially for large programs that are usually written by different groups of programmers. An example for this observation is the hardware design domain. Nowadays hardware designs are written in special hardware description language, e.g., VHDL, by groups which work in different companies and places. Moreover, there is a high pressure for completing the system in time with a very high quality because of the huge costs for correcting a bug after manufacturing the circuit. In order to decrease time for debugging we introduce an approach for diagnosis of VHDL hardware designs and present first empirical results. In contrast to other debugging approaches we make use of model-based diagnosis which is a general diagnosis approach. The models we use are logical descriptions of the syntax and semantics of a VHDL program that can be automatically\u00a0\u2026", "num_citations": "10\n", "authors": ["1033"]}
{"title": "Locating bugs in Java programs\u2014first results of the Java diagnosis experiments project\n", "abstract": " This paper describes the use of model-based reasoning for locating bugs in Java programs. Model-based diagnosis is a technology that uses a declarative, generic description of the behavior of the components occurring in a domain to construct a model of the overall system which can then be used at the desired level of abstraction to predict a system\u2019s behavior and derive assumptions about which parts of the system are incorrect. This approach is particularly enticing when applied to software since the model can be constructed from the program automatically. However, the actual choice of models poses interesting challenges. We show a simple model based on dependencies that can be used to diagnose very large programs, and walk through an example debugging session.", "num_citations": "10\n", "authors": ["1033"]}
{"title": "Testing TLS using planning-based combinatorial methods and execution framework\n", "abstract": " The TLS protocol is the standard for secure Internet communication between two parties. Unfortunately, there have been recently successful attacks like DROWN, ROBOT, or BREACH that indicate the necessity for thoroughly testing TLS implementations. In our research work, we focus on automated test case generation and execution for the TLS security protocol, where the aim is to combine planning with combinatorial methods for providing test cases that ideally also reveal previously unknown attacks. This is made feasible by creating appropriate input parameter models for different messages that can appear in a TLS message sequence. In this paper, we present the resulting test case generation and execution framework together with the corresponding test oracle. Furthermore, we discuss in detail empirical results obtained via testing different TLS implementations.", "num_citations": "9\n", "authors": ["1033"]}
{"title": "Reasoning from first principles for self-adaptive and autonomous systems\n", "abstract": " Model-based reasoning or reasoning from first principles is a well-known method for performing various tasks including diagnosis from systems\u2019 models directly. In this chapter, we will first discuss the basic principles and algorithms of model-based reasoning relying on the system models of the correct behavior as well as fault models. Afterwards, we discuss how to provide models including a discussion of the use abstraction. We further extend the basic foundations allowing model-based diagnosis to be applied to self-adaptive systems including fail-operational system. Beside the system architecture comprising monitoring capabilities, we show how to integrate a model-based diagnosis engine enabling the system for reasoning about its internal fault state and for taking appropriate repair or compensating actions after fault localization. We illustrate the underlying concepts using an autonomous mobile robot\u00a0\u2026", "num_citations": "9\n", "authors": ["1033"]}
{"title": "Testing self-adaptive systems using fault injection and combinatorial testing\n", "abstract": " Verifying and validating systems that can adapt their behavior at runtime is still a research challenge that deserves great attention. In order to assure a certain behavior, we might prove that a self-adaptive system always fulfills certain properties, e.g., always behaving as specified in a given range. Such verification and validation techniques, however, assume the good case, i.e., that the system's environment is working as expected, i.e., that no fault occurs. In this paper, we relax this assumption, and consider testing self-adaptive systems in case of faults. In particular, we show how fault injection techniques and combinatorial testing can be used together for generating tests for self-adaptive systems.", "num_citations": "9\n", "authors": ["1033"]}
{"title": "Aiana: An ai planning system for test data generation\n", "abstract": " Testing object oriented software is even for human beings a challenging task. Automating it is therefore very helpful for developers but by no means trivial. In this paper we present AIana, an approach for automatically generating complex objects used as test input data that satisfy a given precondition in terms of Design by Contract\u2122 specification. AIana transforms the existing Design by Contract\u2122 specification of the parameter type and the precondition of the method under test to PDDL (plan domain description language). Based on it, existing AI planners can be used to create a plan, ie, a method sequence that transforms the object to the goal state. The goal state is given by the precondition of the method under test. AIana is evaluated on two case studies: a student developed stack based calculator, and a real-world event based application developed by our industry partner. AIana outperforms a random approach\u00a0\u2026", "num_citations": "9\n", "authors": ["1033"]}
{"title": "Abductive Reasoning in Environmental Decision Support Systems.\n", "abstract": " Decision trees and rule-based system including variants based on propositional and fuzzy logic have been the method of choice in many applications of environmental decision support systems. Reasons are the ease of use, the capability of representing uncertainty, and the fast computation of results at runtime when using decision trees or other similar means for knowledge representation. Unfortunately there are drawbacks related with these modeling paradigms. For example, the cause-effect relationships between quantities are not captured correctly. The resulting model is well appropriated for a certain purpose but can hardly be re-used. Moreover, maintaining the knowledge base can be an intricate task. In this paper we focus on the problems related with decision trees in the context of environmental decision support systems using an example from the domain. We further present abductive reasoning as an alternative for modeling and show how these technique can be easily implemented using existing techniques.", "num_citations": "9\n", "authors": ["1033"]}
{"title": "Test purpose generation in an industrial application\n", "abstract": " Nowadays test engineers use various strategies for the design of test cases. Among others, test cases are designed on basis of structural coverage criteria or test cases are related to specific fault models. In this paper we evaluate these two techniques for test purpose design. We present a heuristic algorithm for the extraction of test cases from TGV's output, ie, the test process. We discuss the problem of overlapping test purposes and illustrate improvements in terms of test execution time and in terms of number of test cases when minimizing this overlap. Furthermore, we present different strategies for the generation of fault-based test purposes. For our evaluation we apply the presented techniques to a Session Initiation Protocol (SIP) Registrar specification. All extracted test cases are executed against a commercial and an open source implementation of such a SIP Registrar.", "num_citations": "9\n", "authors": ["1033"]}
{"title": "Error traces in model-based debugging of hardware description languages\n", "abstract": " In this article we address the fault localization problem in HDLs, particularly in VHDL designs. Our approach relies on the model-based diagnosis paradigm and, unlike to other approaches that rely on the design's gate-level representation, we accurately represent the program's syntax and semantics in a debugging model. This detailed modeling approach, however, may cause scalability problems for larger designs, thus reducing the model's complexity and size is a crucial issue. Creating a debugging model specifically for a given test case in terms of its execution trace is, although tractable in terms of the model's size, uneligible for source level debugging. We illustrate this result by a simple example and relate it to similar findings in the area of program slicing. Moreover, we present a solution to this problem and discuss implications on software debugging by means of our recent empirical results.", "num_citations": "9\n", "authors": ["1033"]}
{"title": "Abstract model refinement for model-based program debugging\n", "abstract": " Automatic debugging of software has been an ac-tive research area for several years. We analyze an existing model-based approach for debugging and highlight its deficiencies regarding the reported faults. To overcome these deficiencies we present a new model that is extended with abstract infor-mation. The used abstraction is based on predicate abstraction, a method developed for abstract model checking of software. The abstract information in the model adapts itself as necessary in an automatic refinement process. Our new model produces bet-ter results than existing models as we show with a running example. 1", "num_citations": "9\n", "authors": ["1033"]}
{"title": "From the real world to its qualitative representation-Practical lessons learned\n", "abstract": " In this paper we discuss problems related to extracting qualitative knowledge from sensor inputs of the real physical world. We assume that the required knowledge is represented as facts that can be either true or false in a certain situation. Assigning truth values based on perceptions causes problems because of unreliable sensory inputs or interactions of objects in the real world. We address these problems by using the concept of predicate hysteresis and present experimental results when using hysteresis in robotics. The results indicate an improvement of the overall assignment of truth values.", "num_citations": "9\n", "authors": ["1033"]}
{"title": "Fuzzy inductive reasoning for the prediction of maximum ozone concentration\n", "abstract": " Fuzzy inductive reasoning for the prediction of maximum ozone concentration \u2014 Graz University of Technology Skip to main navigation Skip to search Skip to main content Graz University of Technology Logo English Deutsch Home Persons Research Units Research Outputs Projects Activities Prizes Press / Media Search by expertise, name or affiliation Fuzzy inductive reasoning for the prediction of maximum ozone concentration Franz Wotawa, Pilar Gom\u00e9z, Angela Nebot, Francisco Mugica Institute of Software Technology (7160) Research output: Chapter in Book/Report/Conference proceeding \u203a Conference paper Overview Original language English Title of host publication European Simulation Symposium Publisher . Pages ?-? Publication status Published - 2001 Event European Simulation Symposium - Marseilles, France Duration: 18 Oct 2001 \u2192 20 Oct 2001 Conference Conference European Simulation \u2026", "num_citations": "9\n", "authors": ["1033"]}
{"title": "Model-based reasoning\n", "abstract": " Model-based reasoning | AI Communications ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search AI Communications Periodical Home Latest Issue Archive Authors Affiliations Award Winners More HomeBrowse by TitlePeriodicalsAI CommunicationsVol. , No. -2Model-based reasoning article Model-based reasoning Share on Author: Franz Wotawa Institut f\u00fcr Informationssysteme, Technische Universit\u00e4t Wien, Paniglgasse 16, A-1040 Wien, Austria E-mail: [email protected] Institut f\u00fcr Informationssysteme, Technische Universit\u00e4t Wien, Paniglgasse 16, A-1040 Wien, Austria E-mail: [email protected] View Profile Authors Info & Affiliations AI CommunicationsVolume 12Issue 1-2January 1999 pp 1\u20133 Published:01 \u2026", "num_citations": "9\n", "authors": ["1033"]}
{"title": "Exploiting observations from combinatorial testing for diagnostic reasoning\n", "abstract": " Assessing the correctness of a system is not an easy feat and usually we use a variety of techniques and tools in such a process\u2014ranging from formal methods via testing concepts to diagnostic reasoning. In this manuscript, we discuss how to integrate combinatorial testing and model-based diagnosis, where we aim to exploit data obtained from multiple behavioral observations derived via combinatorial testing in order to characterize evident problems in the considered system. In particular, we combine the conflicts obtained for all failed test runs, and discuss the effects achieved in this non-monotonic diagnostic process.", "num_citations": "8\n", "authors": ["1033"]}
{"title": "Fully automated compiler testing of a reasoning engine via mutated grammar fuzzing\n", "abstract": " A reasoning engine infers logical consequences from a set of fixed axioms and observations. However, before it can make an inference, it must compile the axioms and observations which are given in a predefined format. Any attempt to test the correctness of a reasoning engine assumes that it compiles inputs correctly, but that may not be the case. In this work, we implement a mutated grammar fuzzer to automatically generate tests for the compilation stage of Assumption-based Truth Maintenance System (ATMS), a reasoning engine for model-based diagnosis. We also implement a recognizer as an oracle and automatically evaluate the correctness of compiler output. We automatically generate, execute, and evaluate more than a million tests in two weeks. We show that while tests generated from the true grammar of ATMS find no faults, tests generated from mutated grammars uncover an important fault in the\u00a0\u2026", "num_citations": "8\n", "authors": ["1033"]}
{"title": "On Using an I/O Model for Creating an Abductive Diagnosis Model via Combinatorial Exploration, Fault Injection, and Simulation.\n", "abstract": " In practice, we often lack a detailed diagnostic model and also the data (or resources) to create it. Obviously, this is quite a hurdle for deploying automated diagnostic reasoning. In order to overcome it, we proposed in recent work to employ a combinatorial behavior exploration concept for automatically generating an abductive diagnosis model. In the proposed approach, we basically compare correct and faulty behavior that we derive by drawing on fault injection and simulation techniques. We then aggregate data about which specific sets of faults would lead to these or those deviations in the behavior, and finally encode them in an abductive diagnosis model. Since the behavioral space as resulting from the individual domains for the various inputs, system parameters, and injected faults tends to be rather huge, we proposed first concepts to explore it combinatorially. In this manuscript, we delve deeper into the question of how to efficiently explore sequential system behavior in such an approach. That is, while we initially assumed that a user creates a finite alphabet of representative sequences to be covered, in this paper we investigate the use of an abstract input or I/O model to derive such an alphabet, and discuss resulting opportunities and ramifications for the concept.", "num_citations": "8\n", "authors": ["1033"]}
{"title": "Model-Based Diagnosis Meets Combinatorial Testing For Generating an Abductive Diagnosis Model.\n", "abstract": " The diagnostic model is certainly a key element for any model-based diagnosis process. Experience shows though that in practice we often have no such model available for one or the other reason. The consequence for many projects is thus that we cannot draw on diagnosis processes when tackling problems. In this paper, we show how to improve available automated processes for deriving a diagnostic model from the standard simulation models that we usually create during development. We delve in particular into the question how research in the context of combinatorial testing and fault injection can help to improve the process, and consider several questions that arise.", "num_citations": "8\n", "authors": ["1033"]}
{"title": "Planning-based security testing of the ssl/tls protocol\n", "abstract": " With a growing amount of transferred data in an interconnected world, the insurance of a secure communication between two peers becomes a critical task in the software industry. A leak of critical data can cause tremendous costs in a financial, social but also political manner. For this sake, cryptographic protocols are implemented and regulate the data transfer, thus ensuring the safety of transferred data between two peers. The widespread security protocol SSL/TLS provides the mechanisms for this request, however, not without drawbacks since several security leaks have been identified up to now. Since vulnerabilities act as a starting point for a potential malicious action, the identification of such leaks is of highest priority. In this paper a novel testing approach is presented, which adapts planning for security testing of cryptographic protocols. The whole approach is implemented in one testing framework. Its\u00a0\u2026", "num_citations": "8\n", "authors": ["1033"]}
{"title": "On the automation of security testing\n", "abstract": " Due to the still increasing interconnectedness of systems it is very much important to further strengthen activities towards assuring security requirements of those systems. Quality assurance methods like coding guidelines with a focus on security related issues, and static analysis tools are necessary but not sufficient because of the fact that security is a system property. Therefore, it is important to also perform system tests focusing on security threads. When carrying out in a manual way testing is very labor intensive and the question arise whether it is possible to automate security testing? In this paper we take up this question, discuss the underlying challenges, and introduce current work dealing with the automation of security testing. In particular, we present work on using combinatorial testing and AI planning for detecting vulnerabilities in systems. In addition, we discuss shortcomings of the present approaches\u00a0\u2026", "num_citations": "8\n", "authors": ["1033"]}
{"title": "Finding explanations: an empirical evaluation of abductive diagnosis algorithms\n", "abstract": " Abductive inference provides consistent explanations for observable effects and has been of special interest in the context of diagnosis. The abduction problem is in general NP-hard, thus, there is a high motivation to derive solutions efficiently for practical instances. In this paper, we focus on propositional abduction in the framework of model-based diagnosis. We review four algorithms to compute explanations: one employs an ATMS to derive diagnoses and the others are con ict-directed methods based on an unsatisfiable reformulation of the abductive system description. In an empirical evaluation we compare the different approaches on practical examples. Our experiments indicate that the ATMS provides the best performance results for the majority of problems.", "num_citations": "8\n", "authors": ["1033"]}
{"title": "On classification and modeling issues in distributed model-based diagnosis\n", "abstract": " With model-based diagnosis, diagnoses for occurring faults can be directly computed from a given system model and actual observations about system behavior. Model-based diagnosis has been successfully accommodated to several purposes, including the diagnosis of space probes and configuration knowledge bases. Recent research includes extensions for distributed systems, motivated by the ever-growing system complexity and inherently distributed domains like service-oriented architectures. Previous work in this context lacks however a detailed analysis and classification approach that considers essential underlying issues like diagnosis architecture, utilized models, and abstract requirements that might stem from the application domain. In this paper, we will show an analysis of distributed system diagnosis and a characterization in the three dimensions mentioned.", "num_citations": "8\n", "authors": ["1033"]}
{"title": "Diagnosing dependent failures in the hardware and software of mobile autonomous robots\n", "abstract": " Previous works have proposed to apply model-based diagnosis (MBD) techniques to detect and locate faults in the control software of mobile autonomous robots at runtime. The localization of faults at the level of software components enables the autonomous repair of the system by restarting failed components. Unfortunately, classical MBD approaches assume that components fail independently. In this paper we show that dependent failures are very common in this application domain and we propose the concept of diagnosis environments (DEs) in order to tackle the arising problems. We provide an algorithm for the computation of DEs and present the results of case studies.", "num_citations": "8\n", "authors": ["1033"]}
{"title": "Using Model-Based Reasoning for Locating Faults in VHDL Designs\n", "abstract": " Model-based reasoning has seen successful application in hardware oriented and physical domains and many models of physical devices are currently available. In the software domain is still ongoing work. In this paper we describe two kinds of models for programs which are used for locating faults in VHDL designs, suitable for embedding into the VHDL development process and with the actual system description automatically derivable from the code of the program under scrutiny.", "num_citations": "8\n", "authors": ["1033"]}
{"title": "Locating bugs in Java programs\u2013first results of the Java Diagnosis Experiments (Jade) project\n", "abstract": " This paper describes the use of model-based reasoning for locating bugs in Java programs. Model-based diagnosis is a technology that uses a declarative, generic description of the behavior of the components occurring in a domain to construct a model of the overall system which can then be used at the desired level of abstraction to predict a system\u2019s behavior and derive assumptions about which parts of the system are incorrect. This approach is particularly enticing when applied to software since the model can be constructed from the program automatically. However, the actual choice of models poses interesting challenges. We show a simple model based on dependencies that can be used to diagnose very large programs, and walk through an example debugging session.", "num_citations": "8\n", "authors": ["1033"]}
{"title": "A model-based tool for finding faults in hardware designs\n", "abstract": " The state of the art in integrated circuit design is the use of special hardware description languages such as VHDL. The designs programmed in VHDL are refined up to the point where the physical realization of the new circuit or board can be created automatically. Before that stage is reached, the designs are tested by simulating them and comparing their output to that prescribed by the specification. A significant part of the design effort is taken up by detection of unacceptable deviations from this specification and the correction of such faults. This paper deals with the development of VHDLDIAG, a knowledge-based design aid for VHDL programs, with the goal of reducing time spent in fault detection and localization in very large designs (hundreds of thousands of lines of code). Size and variability of these programs makes it infeasible in practice to use techniques based on a detailed representation of\u00a0\u2026", "num_citations": "8\n", "authors": ["1033"]}
{"title": "Planning-based security testing of web applications\n", "abstract": " Web applications are deployed on machines around the globe and offer almost universal accessibility. The systems ensure functional interconnectivity between different components on a 24/7 basis. One of the most important requirements represents data confidentiality and secure authentication. However, implementation flaws and unfulfilled requirements can result in security leaks that can be eventually exploited by a malicious user. Here different testing methods are applied in order to detect software defects and prevent unauthorized access in advance. Automated planning and scheduling provides the possibility to specify a specific problem and to generate plans, which in turn guide the execution of a program. In this paper, a planning-based approach is introduced for modeling and testing of web applications. The specification offers a high degree of extendibility and configurability but overcomes the limits of\u00a0\u2026", "num_citations": "7\n", "authors": ["1033"]}
{"title": "Combining combinatorial testing and metamorphic testing for testing a logic-based non-monotonic reasoning system\n", "abstract": " Combinatorial testing has proven to be a very valuable testing technique for automated generation of test suites given the domain of the inputs and the configuration parameters. In order to fully automate combinatorial testing, however, there is a need for an automated test oracle. In case of testing logic-based non-monotonic reasoning systems, we show how to generate test cases and how to make use of metamorphic testing in order to provide a test oracle. The combined testing method allows for complete test automation. We further discuss first experimental results obtained for an implementation of an assumption-based truth maintenance system implementing basic non-monotonic reasoning capabilities.", "num_citations": "7\n", "authors": ["1033"]}
{"title": "A formal TLS handshake model in LNT\n", "abstract": " Testing of network services represents one of the biggest challenges in cyber security. Because new vulnerabilities are detected on a regular basis, more research is needed. These faults have their roots in the software development cycle or because of intrinsic leaks in the system specification. Conformance testing checks whether a system behaves according to its specification. Here model-based testing provides several methods for automated detection of shortcomings. The formal specification of a system behavior represents the starting point of the testing process. In this paper, a widely used cryptographic protocol is specified and tested for conformance with a test execution framework. The first empirical results are presented and discussed.", "num_citations": "7\n", "authors": ["1033"]}
{"title": "Quantification and Analysis of the Resilience of Two Swarm Intelligent Algorithms.\n", "abstract": " Nature showcases swarms of animals performing various complex tasks efficiently where capabilities of individuals alone in the swarm are often quite limited. Swarm intelligence is observed when agents in the swarm follow simple rules which enable the swarm to perform certain complex tasks. This decentralized approach of nature has inspired the artificial intelligence community to apply this approach to engineered systems. Such systems are said to have no single point of failure and thus tend be more resilient. The aim of this paper is to put this notion of resilience to the test and quantify the robustness of two swarm algorithms, namely \u201cswarmtaxis\u201d and \u201cFSTaxis\u201d. The first simulation results of the effects of introducing an impairment in agent-to-agent interactions in these two swarm algorithms are presented in this paper. While the FSTaxis algorithm shows a much higher resilience to agent-to-agent communication failure, both the FSTaxis and swarmtaxis algorithms are found to have a non-zero tolerance towards such failures.", "num_citations": "7\n", "authors": ["1033"]}
{"title": "SAT-Based Abductive Diagnosis.\n", "abstract": " Increasing complexity and magnitude of technical systems demand an accurate fault localization in order to reduce maintenance costs and system down times. Resting on solid theoretical foundations, model-based diagnosis provides techniques for root cause identification by reasoning on a description of the system to be diagnosed. Practical implementations in industries, however, are sparse due to the initial modeling effort and the computational complexity. In this paper, we utilize a mapping function automating the modeling process by converting fault information available in practice into propositional Horn logic sentences to be used in abductive model-based diagnosis. Furthermore, the continuing performance improvements of SAT solvers motivated us to investigate a SAT-based approach to abductive diagnosis. While an empirical evaluation did not indicate a computational benefit over an ATMS-based algorithm, the potential to diagnose more expressive models than Horn theories encourages future research in this area.", "num_citations": "7\n", "authors": ["1033"]}
{"title": "On the computational feasibility of abductive diagnosis for practical applications\n", "abstract": " Increasing complexity of physical systems demands an accurate fault localization in order to reduce maintenance costs. Model-based diagnosis has been proposed as an AI-based method to derive root causes from a system model and observable anomalies. Though relying on a strong theoretical background, practical applications of model-based diagnosis are often prevented by the initial modeling effort and complexity of diagnosis algorithms. In this paper, we focus on both aspects and present an approach that converts the fault information available in practice into propositional Horn logic sentences to be used in abductive diagnosis. It is well known that abductive diagnosis based on propositional Horn theories has exponential complexity in general. However, in our case the obtained logical sentences belong to a subset of propositional Horn logic that is tractable, namely definite Horn theories. In particular, we\u00a0\u2026", "num_citations": "7\n", "authors": ["1033"]}
{"title": "Automated debugging of Verilog designs\n", "abstract": " In this article we report on novel insights in model-based software debugging of hardware description languages (HDLs). Today's simulation driven working process emphasizes the need for exploiting test suites not only for detecting but also for localizing the root cause of misbehavior. We discuss the modeling approaches for the various artifacts of the Verilog hardware description language (blocking and non-blocking statements, expressions, execution ordering) and present a novel model incorporating test suites. The evaluation of our approach on the well-known ISCAS89 benchmarks concerning single and double-fault diagnoses clearly indicates that incorporating test suites into the fault localization technique (and development process) considerably improves the accuracy of the obtained diagnosis candidates.", "num_citations": "7\n", "authors": ["1033"]}
{"title": "EqMutDetect\u2014A tool for equivalent mutant detection in embedded systems\n", "abstract": " Removing faults in the software of embedded systems, after deployment, is at least expensive because of the required actions like calling back cars to workshops in order to perform a software update. Therefore verification and validation techniques are especially important in the embedded system domain. Mutation testing is a method for evaluating test suites of programs via injecting faults and checking whether there exists a test case that catches the induced misbehavior. An important problem in mutation testing is the detection of equivalent mutants, i.e., injected faults that lead to exactly the same behavior. In case equivalent mutants cannot be distinguished, the evaluation result of a test suite, measured as mutation score, is wrong. Therefore, we focus on equivalent mutant detection in this paper. In particular we present a method that relies on a constraint representation of a program and its mutant, and a\u00a0\u2026", "num_citations": "7\n", "authors": ["1033"]}
{"title": "Category partition method and satisfiability modulo theories for test case generation\n", "abstract": " In this paper we focus on test case generation for large database applications in the telecommunication industry domain. In particular, we present an approach that is based on the Category Partition Method and uses the SMT solver Z3 for automatically generating input test data values for the obtained test cases. For the generation process, we make use of different test case generation strategies. First initial results show that the one based on genetic programming delivers the fewest number of test cases while retaining choice coverage. Moreover, the obtained results indicate that the presented approach is feasible for the intended application domain.", "num_citations": "7\n", "authors": ["1033"]}
{"title": "Synthesize it: from design by contract to meaningful test input data\n", "abstract": " Generating test input data is a complex task and nowadays mostly tackled with random approaches. Random testing of methods, which take non primitive data types as parameters, e.g. objects encapsulating database interactions, is a vain endeavor. Especially, if the precondition of the method under test (MUT) requires a particular object state of the method's parameters, random approaches rarely succeed. In this paper we present a technique to automatically synthesize implementations for the parameters of a MUT from a given Design by Contract specification. These implementations behave as described by the Design by Contract specification, but do not interact with their environment (e.g. database, network and file system). Furthermore, we can set the initial state of the synthesized implementations to the state required by the MUT's precondition. Besides a formal discussion of our approach we present results\u00a0\u2026", "num_citations": "7\n", "authors": ["1033"]}
{"title": "On the use of specification knowledge in program debugging\n", "abstract": " In this paper we present an approach that relies on the representation of the debugging problem as a constraint satisfaction problem. We show how arbitrary sequential programs together with specification knowledge like invariants can be represented as a set of constraints. We provide a formalization of the constraint representation and of the diagnosis problem which clarifies and improves previously published ideas. We also correct a flaw in a previously published paper which could lead to undesired diagnostic results. Moreover, based on the constraint representation we explain how to use a fast constraint solver, which is freely available, for computing diagnoses. Using such a constraint solver we obtain first experimental results for a set of Java programs. The results indicate that the use of specification knowledge reduces the number of diagnoses substantially. This shows that the integration of specifications like pre-and postconditions or invariants, which can be provided as annotations in the program, can significantly help to make model-based debugging applicable in practice.", "num_citations": "7\n", "authors": ["1033"]}
{"title": "Program file bug fix effort estimation using machine learning methods for open source software Projects\n", "abstract": " The bug fix effort estimation model for open source software system plays an important role in software quality assurance and software project management. Most of the effort estimation models are related to commercial or closed software systems, whereas it is difficult to develop an effort estimation model for open source software systems (OSS). Reasons may be the large number of source files, and the large number of software developers and contributors. In case of OSS, the developers and contributors are randomly distributed throughout the world. It is complicated to obtain the actual time spent by each developer or contributor to fix a bug. To overcome these issues we have applied a heuristic approach, which estimates the actual bug fix time. The total time spent to fix a bug is considered as bug fix effort. To perform experiments we selected the Mozilla open source project and extracted the bug fix activity data from the corresponding bugzilla server and downloaded source files revisions from CVS repository. We processed the program files bug fix change data and obtained a set of metrics, which are related to program file changes. To develop a reliable effort estimation model we used regression, neural network, support vector machine, classification rules and decision tree methods. Furthermore, we compared the outcome of the different methods using several evaluation criteria. The results show that the machine learning based models are better compared to the statistical regression model. In case of support vector machine the relative absolute error (MMRE) is lowest, while in case of classification rule the correlation between the actual\u00a0\u2026", "num_citations": "7\n", "authors": ["1033"]}
{"title": "Knowledge extraction from c-code\n", "abstract": " In this paper we present first ideas for extracting knowledge from C source code of control programs. The extracted knowledge is intended to be used in our smart control engine which takes a rule set and decides which rules to use based on the internal and environmental conditions. The extraction of rules is based on the control-flow graph of the supplied C program: Basically, our method extracts rules that correspond to paths to given high-level function calls. The advantage of this method is to get a first knowledge-base from available source code which makes using a smart control engine more applicable for industry. We use an industrial control program as example within the paper in order to justify the usefulness of our approach.", "num_citations": "7\n", "authors": ["1033"]}
{"title": "Runtime fault detection and localization in component-oriented software systems\n", "abstract": " In this paper we introduce a novel technique for run-time fault detection and localization in component-oriented software systems. Our novel approach allows to define arbitrary properties via rules at the component level. By monitoring the software system at run-time we can detect violations of these properties and, most notably, also localize possible causes for specific property violation (s). Relying on the model-based diagnosis paradigm, our fault localization technique is able to deal with intermittent fault symptoms and it allows for measurement selection. Finally, we discuss results obtained from our most recent case studies and relate our work to those of others.", "num_citations": "7\n", "authors": ["1033"]}
{"title": "DiKe-a model-based diagnosis kernel and its application\n", "abstract": " This paper describes the DiKe model-based diagnosis framework, which incorporates multiple diagnosis engines, multiple user-level system description languages, a theorem prover, and a graphical user interface to provide an integrated toolset for the development of model-based diagnosis applications. The framework has been used for representing a number of application domains. We present the AD2L language, the main user language for the system geared towards use by non-specialists, and discuss use of DiKe in various domains.", "num_citations": "7\n", "authors": ["1033"]}
{"title": "Model-based diagnosis of hardware description languages\n", "abstract": " This paper discusses the use of fault models for the diagnosis of hardware designs written in the VHDL hardware description language. VHDL designs are concurrent programs consisting of hundreds of thousands of lines of source code, whose testing and debugging is a very time-consuming process. Building on an abstract representation that allows the search for errors in even the largest VHDL programs, but with strictly limited accuracy, this paper presents a more detailed approach which is currently under study for local use in situations where focusing on a small part of the program may be possible. The approach is based on assigning fault modes to VHDL statements, with the main di erence to the standard hardware diagnosis approach being that fault modes are directly expressed in terms of repair operations that will presumably improve the correctness of the program. We provide a running example and discuss the implications of the representation.", "num_citations": "7\n", "authors": ["1033"]}
{"title": "Planning-based security testing of web applications with attack grammars\n", "abstract": " Web applications are deployed on machines around the globe and offer almost universal accessibility. These applications assure functional interconnectivity between different components on a 24/7 basis. One of the most important requirements is data confidentiality and secure authentication. However, implementation flaws and unfulfilled requirements often result in security leaks that malicious users eventually exploited. In this context, the application of different testing methods is of utmost importance in order to detect software defects during development and to prevent unauthorized access in advance. In this paper, we contribute to test automation for web applications. In particular, we focus on using planning for testing where we introduce underlying models covering attacks and their use in testing of web applications. The planning model offers a high degree of extendibility and configurability and as well\u00a0\u2026", "num_citations": "6\n", "authors": ["1033"]}
{"title": "Investigating the effectiveness of mutation testing tools in the context of deep neural networks\n", "abstract": " Verifying the correctness of the implementation of machine learning algorithms like neural networks has become a major topic because \u2013 for example \u2013 its increasing use in the context of safety critical systems like automated or autonomous vehicles. In contrast to evaluating the learning capabilities of such machine learning algorithms, in verification, and particularly in testing we are interested in finding critical scenarios and in giving some sort of guarantees with respect to the underlying used tests. In this paper, we contribute to the area of testing machine learning algorithms and investigate the effectiveness of traditional mutation tools in the context of Deep Neural Networks testing. In particular, we try to answer the question whether mutated neural networks can be identified considering their learning capabilities when compared to the original network. To answer this question, we performed an empirical\u00a0\u2026", "num_citations": "6\n", "authors": ["1033"]}
{"title": "Adapting unit tests by generating combinatorial test data\n", "abstract": " Conventional unit tests are still mainly handcrafted. Generalizing conventional unit tests to parameterized unit tests supports automatic test data generation. Methods that were introduced to instantiate parameterized unit tests with concrete values as test data are based on search based approaches, dynamic symbolic execution, or property based testing. In this work, we introduce an approach that retrofits existing conventional unit tests into parameterized unit tests by generalization, and generate test data by combinatorial valuation to adapt existing conventional unit test suites. We conduct an empirical study to investigate whether our test suite adaption approach is beneficial in terms of additional fault detection capabilities and code coverage. Our results show that mutation score and condition coverage increase with feasible effort compared to existing conventional unit tests.", "num_citations": "6\n", "authors": ["1033"]}
{"title": "Mutation score, coverage, model inference: Quality assessment for t-way combinatorial test-suites\n", "abstract": " In this paper we assess and evaluate the quality of t-way combinatorial test-suites using three different test-suite quality assessment methods. As t-way combinatorial test-suites reduce the input space of a program under test, we investigate how an increasing t affects the quality of the test-suite. There are some limitations of existing test-suite quality assessment methods e.g. the number of mutants is limited by execution time and code coverage measurement might be intrusive due to changes of the behavior of the program under test when instrumenting the code. Here we generate t-way combinatorial test-suites for Java programs of different size. We compute mutation score and code coverage for the generated test-suites, and apply additionally a new model inference based approach, that does not require to execute the program under test, to compare the generated test-suites with each other and assign a quality\u00a0\u2026", "num_citations": "6\n", "authors": ["1033"]}
{"title": "A goal-question-metrics model for configuration knowledge bases.\n", "abstract": " Configuration knowledge bases are a wellestablished technology for describing configurable products like cars, computers, and financial services. Such knowledge bases are characterized by sets of constraints, variables, and domains. Lot of research has been done for testing knowledge bases, finding conflicts, and recommending repair actions. In contrast, less work has been done in the area of measuring the quality of configuration knowledge bases. Such quality measurements can help knowledge engineers to improve the maintainability, understandability, and functionality of knowledge bases. Based on a literature review we first give an overview of the state-of-the-art in knowledge base metrics. We will extend the current research by using the goal-questionmetrics (GQM) approach of the software engineering discipline to find gaps for the characterization of knowledge bases. We will also identify further metrics to complete the model. The results of this paper help knowledge engineers to reduce the effort to develop and maintain configuration knowledge bases.", "num_citations": "6\n", "authors": ["1033"]}
{"title": "Testing diagnostics components supervising functional safety requirements\n", "abstract": " For safety-critical applications, safety diagnostics components are an attractive safeguard for meeting some specified safety requirements under operation. Like a monitor, such a software artifact shall supervise a system under operation, and furthermore, if needed, it overrides the system\u2019s control software in order to maintain safety. In this paper we contribute to testing such a component, suggesting an approach that draws on fault injection and, in order to enhance deployability, accommodates also needs in respect of business issues like intellectual property disclosure and resource efficiency. The required testing oracle we directly obtain from the defined and formalized functional safety requirements, for the purpose of assessing that the safety diagnostic component in-deed maintains safety also under faulty conditions.", "num_citations": "6\n", "authors": ["1033"]}
{"title": "Detecting equivalent mutants by means of constraint systems\n", "abstract": " Mutation testing has been used along the research community as an efficient method to evaluate the process of software testing, ie, the quality of the test suite. One major drawback is represented by the equivalent mutant problem. Through this current research we aim to come with a reliable solution to this problem and improve the available test suite pool. We do this by combining the mutation testing procedure together with a constraint satisfaction paradigm and the concept of distinguishing test cases. Mutation testing has been seen, in most of the cases, as a measure for evaluating the quality of a user\u2019s test suite. But, also mutation testing can be of great help in the test case generation process. By means of a constraint system we generate test scenarios able to distinguish between two different versions of a program. We start from the hypothesis that when our constraint system is not able to find any solution it might be the case that two equivalent mutants were encountered. The first empirical results, ie an increased mutation score, encourage us to further apply the strategy on medium size applications.", "num_citations": "6\n", "authors": ["1033"]}
{"title": "Program debugging using constraints--Is it feasible?\n", "abstract": " Automated debugging, i.e., automated fault localization in programs, is an important and challenging problem. In literature the use of AI techniques like model-based diagnosis have been reported in order to solve the debugging problem at least partially. Most recently stating the debugging problem as a constraint satisfaction problem has been suggested including the integration of pre- and post-conditions. In this paper we follow this approach and report on most recent results obtained when using a today's constraint solver. Moreover, we show that there is a very good correspondence between the running time required for finding bugs and the structure of the program's constraint representation. We are able to prove this relationship with a linear correlation coefficient of 0.9. The empirical results indicate that the constraint satisfaction approach is very promising when focusing on debugging methods and functions\u00a0\u2026", "num_citations": "6\n", "authors": ["1033"]}
{"title": "Debugging and test case generation using constraints and mutations\n", "abstract": " The automation of debugging, i.e., fault localization, is an old but still open challenge in computer science. There are a number of at least partial solutions reported in literature. Some of them rely on basic concepts of AI like model-based debugging or debugging based on constraints. In this paper we focus on constraint-based debugging, provide a detailed formal introduction of the basic ideas and concepts, and finally state the automated debugging challenge as a constraint satisfaction problem. Although the proposed solution is general, the approach is more applicable to restricted programs like the one used in control. Furthermore, we introduce an extension of previous work that is based on program mutations and distinguishing test cases and discuss empirical results indicating the applicability of the approach. With the introduced extensions we obtain reductions in the number of diagnosis candidates of more\u00a0\u2026", "num_citations": "6\n", "authors": ["1033"]}
{"title": "On the way to automated belief repair for autonomous robots\n", "abstract": " If an autonomous mobile robot acts in a real nondeterministic environment it might faces situations where its internal belief of the world is in contradiction with the world itself. Such situations are caused by inaccurate acting and sensing or exogenous events. A reliable and dependable robot has to have the capabilities to actively cope with such situation.In this paper we motivate the importance of methods for autonomous diagnosis and repair of beliefs of robots. Moreover, we discuss problems that arise from the application of diagnosis to an autonomous system which acts in the real world. Finally, we highlight interesting research questions stimulated by this particular application.", "num_citations": "6\n", "authors": ["1033"]}
{"title": "Enhancing plan execution in dynamic domains using model-based reasoning\n", "abstract": " If an autonomous mobile robot has to perform a really complex task like setting the table for dinner, it has to have capabilities for planning and reasoning in order to be able to successfully finish the task. For the calculation of a plan for a given goal there exist a number of suitable algorithms. But if such a plan is executed on an autonomous mobile robot in a dynamic environment, a number of problems are likely to occur. Beside the problems caused by the assumption used in the planning phase problems arise trough inaccurate sensing, acting and events which are not under control of the robot. All these problems have in common that they cause an inconsistency between the intentions of the plan and the observed world. In this paper we propose model-based diagnosis as a method for the detection and the categorization of such inconsistencies. The obtained knowledge about failures in plan execution\u00a0\u2026", "num_citations": "6\n", "authors": ["1033"]}
{"title": "Model-based reasoning with multiple test cases and its application to debugging\n", "abstract": " Today\u2019s simulation-centric hardware development process requires to leverage quality test suites for fault localization rather than employing them solely for detecting malfunctioning. In this article we (1) propose an extension of the model-based debugging theory to address the treatment of test suites in a well-founded way and (2) relate this novel approach to an algorithmic technique known as filtering. For multiple test cases revealing a certain fault (3) we propose an iterative computation of diagnoses as an extension to Reiter\u2019s diagnosis algorithm, and (4) notably report on empirical evaluations of this algorithm taking into account even dual-fault diagnosis.", "num_citations": "6\n", "authors": ["1033"]}
{"title": "A Constraint Model for Automated Deployment of Automotive Control Software.\n", "abstract": " In this paper we address automated software deployment for embedded automotive systems in terms of a constraint satisfaction problem (CSP). Our purely model-based approach allows for fully automatic deployment of software functions in a resource-constrained system (exemplified in terms of memory and bus load). Besides of its applicability in an early stage of development, most notably, our model incorporates optimization criteria from algorithmic approaches proposed recently. Capturing the problemrelevant aspects in terms of a CSP is straightforward and thus easily extendable to complex scenarios like, for example, temporal requirements or the diverse bus protocols in the automotive domain.", "num_citations": "6\n", "authors": ["1033"]}
{"title": "A comparison of fault explanation and localization\n", "abstract": " Explaining and localizing a fault in a software system after observing that one exists is nontrivial. Therefore, an automatic approach to this task is highly desirable. Several methodologies have been proposed so far, but none of them solves this problem satisfactory. In this paper we compare two such approaches. One approach is based on heuristics using counterexamples from a model checker and the other is based on a logically sound diagnosis framework. Both approaches have specific strengths and weaknesses with respect to the type of software that is to be debugged. The goal of this work is to improve approaches based on logic with heuristics and vice versa.", "num_citations": "6\n", "authors": ["1033"]}
{"title": "Debugging with an enriched dependency-based model or how to distinguish between aliasing and value assignment\n", "abstract": " This paper introduces a new model for debugging of Java programs. This model is based on previous functional dependency models that have been developed for the same purpose. In contrast the model makes not only use of dependency information but also of aliasing information. Therefore, the results are better for a large class of examples. The model is basically a qualitative model where values of variables are ignored. Hence, the approach can be seen as an application of qualitative reasoning for debugging software. In the paper we further discuss the compilation of Java programs to a constrained value-flow graph, and the mapping from the graph to its logical representation.", "num_citations": "6\n", "authors": ["1033"]}
{"title": "An adaptive system for autonomous driving\n", "abstract": " Having systems that can adapt themselves in case of faults or changing environmental conditions is of growing interest for industry and especially for the automotive industry considering autonomous driving. In autonomous driving, it is vital to have a system that is able to cope with faults in order to enable the system to reach a safe state. In this paper, we present an adaptive control method that can be used for this purpose. The method selects alternative actions so that given goal states can be reached, providing the availability of a certain degree of redundancy. The action selection is based on weight models that are adapted over time, capturing the success rate of certain actions. Besides the method, we present a Java implementation and its validation based on two case studies motivated by the requirements of the autonomous driving domain. We show that the presented approach is applicable both in\u00a0\u2026", "num_citations": "5\n", "authors": ["1033"]}
{"title": "Comparing two systematic approaches for testing automated driving functions\n", "abstract": " Thoroughly validating and verifying automated or autonomous driving functions is inevitable for assuring to meet quality criteria for safety-critical systems. In this paper, we discuss two system testing techniques that have been already used for detecting critical situations for the automated emergency braking function based on vehicle simulations. In particular, we introduce combinatorial testing and search-based testing techniques and compare them. Whereas the first is for identifying interactions of parameters that lead to harmful situations considering predefined value domains, the latter is for finding parameter values that cause such critical situations. We discuss the underlying foundations behind the methods as well as their potential application areas. In addition, we summarize the results obtained when using these methods for testing automated emergency braking.", "num_citations": "5\n", "authors": ["1033"]}
{"title": "Testing chatbots using metamorphic relations\n", "abstract": " Modern-day demands for services often require an availability on a 24/7 basis as well as online accessibility around the globe. For this sake, personalized software systems, called chatbots, are applied. Chatbots offer services, goods or information in natural language. These programs respond to the user in real-time and offer an intuitive and simple interface to interact with. Advantages like these makes them increasingly popular. Chatbots can even act as substitutes for humans for specific purposes. Since the chatbot market is growing, chatbots might outperform and replace classical web applications in the future. For this reason, ensuring correct functionality of chatbots is of high and increasing importance. However, since different implementations and user behavior result in unpredictable results, the chatbot\u2019s output is difficult to predict and classify as well. In fact, testing of chatbots represents a\u00a0\u2026", "num_citations": "5\n", "authors": ["1033"]}
{"title": "Empirical study of correlation between mutation score and model inference based test suite adequacy assessment\n", "abstract": " In this paper we investigate a method for test suite evaluation that is based on an inferred model from the test suite. The idea is to use the similarity between the inferred model and the system under test as a measure of test suite adequacy, which is the ability of a test suite to expose errors in the system under test. We define similarity using the root mean squared error computed from the differences of the system under test output and the model output for certain inputs not used for model inference. In the paper we introduce the approach and provide results of an experimental evaluation where we compare the similarity with the mutation score. We used the Pearson Correlation coefficient to calculate whether a linear correlation between mutation score and root mean squared error exists. As a result we obtain that in certain cases the computed similarity strongly correlates with the mutation score.", "num_citations": "5\n", "authors": ["1033"]}
{"title": "Abductive diagnosis based on modelica models\n", "abstract": " When employing model-based diagnosis, coming up with the required model is a knowledge and resource-intensive task. In this article, we show how to automatically derive an abductive diagnosis model from system models written in the popular Modelica modeling language. Using Modelica\u2019s simulation features we inject potentially faulty component behavior into the system model and automatically derive cause and effect rules. We afterwards use these rules for performing abductive diagnosis of the malfunctioning system. Our first case studies demonstrate the applicability and viability of the approach.", "num_citations": "5\n", "authors": ["1033"]}
{"title": "Intelligent supporting techniques for the maintenance of constraint-based configuration systems.\n", "abstract": " Constraint-based systems like knowledge-based recommendation and configuration are well established technologies in many different product areas like cars, computers, notebooks, and financial services. Such systems reduce the number of valid products and configurations regarding the customers\u2019 preferences. The relationship between product variables and customer questions is represented by constraints. Nowadays, constraint-based configuration systems represent volatile product assortments: Variables must be adapted, new product features lead to new questions for the customer, and/or the constraints must be updated. We call such scenarios maintenance tasks.In complex constraint-based configuration systems the maintenance task is time consuming and error prone. Previous research focused on the detection of conflicts, repair actions for the conflicts, and redundant constraints. In this paper we give an overview about these techniques and present new approaches like recommendation, well-formedness violation, simulation, and knowledge base verification for the support of knowledge engineers.", "num_citations": "5\n", "authors": ["1033"]}
{"title": "From theory to practice: Model-based diagnosis in industrial applications\n", "abstract": " Due to the increasing complexity of technical systems, accurate fault identification is crucial in order to reduce maintenance costs and system downtime. Model-based diagnosis has been proposed as an approach to improve fault localization. By utilizing a system model, possible causes, ie defects, for observable anomalies can be computed. Even though model-based diagnosis rests on solid theoretical background, it has not been widely adopted in practice. The reasons are twofold: on the one hand it requires an initial modeling effort and on the other hand a high computational complexity is associated with the diagnosis task in general. In this paper we address these issues by proposing a process for abductive model-based diagnosis in an industrial setting. Suitable models are created automatically from failure assessments available. Further, the compiled system descriptions reside within a tractable space of abductive diagnosis. In or-der to convey the feasibility of the approach we present results of an empirical evaluation based on several failure assessments.", "num_citations": "5\n", "authors": ["1033"]}
{"title": "The SiMoL modeling language for simulation and (re-) configuration\n", "abstract": " From automotive and up to telecommunication industry, configuration and simulation are used for solving complex problems connected to the ever growing number of components, which have to work together. To assist these needs, many tools are nowadays available. Modeling languages like Matlab/Simulink or Modelica are often used to model the dependencies between the components of physical systems. However these are less suitable for the area of knowledge-based systems. In this paper, we present a modeling language, which combines the two different directions. SiMoL is an object-oriented language that allows representing systems comprising basic and hierarchical components. We state the syntax and the semantics of the language, referring also to the implementation of SiMoL, which is based on the MINION constraint solver. Furthermore, we discuss how the obtained model can be used\u00a0\u2026", "num_citations": "5\n", "authors": ["1033"]}
{"title": "Are there language specific bug patterns? Results obtained from a case study using Mozilla\n", "abstract": " A lot of information can be obtained from configuration management systems and post-release bug databases like Bugzilla. In this paper we focus on the question whether there are language specific bug patterns in large programs. For this purpose we implemented a system for extracting the necessary information from the Mozilla project files. A comparison of the extracted information with respect to the programming language showed that there are bug patterns specific to programming languages. In particular we found that Java files of the Mozilla project are less error prone than C and C++ files. Moreover, we found out that the bug lifetime when using Java was almost double the lifetime of bugs in C or C++ file.", "num_citations": "5\n", "authors": ["1033"]}
{"title": "Improving coverage based test purposes\n", "abstract": " Test purposes have been presented as a solution to avoid the state space explosion when selecting test cases from formal models. We previously presented a technique that assists a test engineer with test purpose design: It allows automatic generation of coverage based test suites and can be used to automatically exercise those aspects of the system that manually designed test purposes missed. Although the generated test purposes allow for coverage based testing, they did not comprise refuse states. Refuse states in test purposes restrict the state space that needs to be considered during test case generation. In this paper, we present an approach that leads to test purposes with refuse states, thus speeding up the test case generation. Furthermore, our new approach allows one to generate test cases for coverage items where our previous approach failed. We consider coverage of LOTOS specifications, and\u00a0\u2026", "num_citations": "5\n", "authors": ["1033"]}
{"title": "A database for the analysis of program change patterns\n", "abstract": " Software repositories contain an enormous amount of information regarding the evolution of any large software system. In our experiments we choose the dataset of the freely available Mozilla CVS repository. We downloaded 9552 program files (C++), extracted the CVS log data, and extracted the Mozilla bugs information from the Bugzilla database. From these sources we extracted the program file change data and used a database for storing the extracted data. We further used this database for the analysis of program file changes in order to find change patterns. We apply an approach on the database that allows us to identify the different types of change transactions like bug fixing, clean, bug introducing and bug fix-introducing transactions. We further use the database to find the program file change distribution. Furthermore we use the probability of bug introducing and bug fix-introducing changes to identify the\u00a0\u2026", "num_citations": "5\n", "authors": ["1033"]}
{"title": "Using AI techniques for fault localization in component-oriented software systems\n", "abstract": " In this paper we introduce a technique for runtime fault detection and localization in component-oriented software systems. Our approach allows for the definition of arbitrary properties at the component level. By monitoring the software system at runtime we can detect violations of these properties and, most notably, also locate possible causes for specific property violation(s). Relying on the model-based diagnosis paradigm, our fault localization technique is able to deal with intermittent fault symptoms and it allows for measurement selection. Finally, we discuss results obtained from our most recent case studies.", "num_citations": "5\n", "authors": ["1033"]}
{"title": "A Causal Analysis Method for Concurrent Hybrid Automata.\n", "abstract": " Modern artifacts are typically composed of many system components and exhibit a complex pattern of continuous/discrete behaviors. A concurrent hybrid automaton is a powerful modeling concept to capture such a system\u2019s behavior in terms a concurrent composition of hybrid automata for the individual system components. Because of the potentially large number of modes of the concurrent automaton model it is non-trivial to validate the composition such that every possible operational mode leads to a causally valid dynamic model for the overall system. This paper presents a novel model analysis method that validates the automata composition without the necessity to analyze a prohibitively large number of modes. We achieve this by formulating the exhaustive causal analysis of hybrid automata as a diagnosis problem. This provides causal specifications of the component automata and enables us to efficiently calculate the causal relationships for their concurrent composition and thus validate a concurrent automaton model.", "num_citations": "5\n", "authors": ["1033"]}
{"title": "Fault localization based on abstract dependencies\n", "abstract": " Debugging, i.e., removing faults from programs, comprises three parts. Fault detection is used to find a misbehavior. Within fault localization the root-cause for the detected misbehavior is searched for. And finally, during repair the responsible parts of the program are replaced by others in order to get rid of the detected misbehavior. In this paper we focus on fault localization which is based on abstract dependencies that are used by the Aspect system [1] for detecting faults. Abstract dependencies are relations between variables of a program. We say that a variable x depends on a variable y iff a new value for y may causes a new value for x. For example, the assignment statement x = y + 1; implies such a dependency relation. Every time we change the value of y the value of x is changed after executing the statement. Another example which leads to the same dependency is the following program fragment\u00a0\u2026", "num_citations": "5\n", "authors": ["1033"]}
{"title": "A diagnosis-based causal analysis method for concurrent hybrid automata\n", "abstract": " Modern artifacts are typically composed of many system components and exhibit a complex pattern of continuous/discrete behaviors. A concurrent hybrid automaton is a powerful modeling concept to capture such a system\u2019s behavior in terms of hybrid automata for the individual system components and the concurrent composition of thereof. Because of the potentially large number of modes of the concurrent automaton model it is non-trivial to validate the composition such that every possible operational mode leads to a causally valid dynamic model for the overall system. This paper presents a novel model analysis method that validates the automata composition without the necessity to analyze a prohibitively large number of modes. We achieve this by formulating the exhaustive causal analysis of hybrid automata as a diagnosis problem. This provides causal specifications of the component automata and enables us to efficiently calculate the causal relationships for their concurrent composition and thus validate a concurrent automaton model. 1", "num_citations": "5\n", "authors": ["1033"]}
{"title": "Using abstract dependencies in debugging\n", "abstract": " Fault localization is the next step after detecting faults in programs. Testing and formal verification techniques like model-checking are usually used for detecting faults but fail to locate the root-cause for the detected faulty behavior. This article makes use of abstract dependencies between program variables for localizing faults in programs. It explains the basic ideas, the underlying theory and the limitations. The fault localization model is based on a previous work that uses abstract dependencies for fault detection. Moreover, the paper discusses the relationship between the abstract model and qualitative reasoning.", "num_citations": "5\n", "authors": ["1033"]}
{"title": "Debugging VHDL designs using temporal process instances\n", "abstract": " In this paper we outline the usage of model-based diagnosis for fault localization in VHDL-RTL designs. In contrast to previous research, our approach makes use of temporal aspects of a VHDL program. The facts that the conversion of the VHDL program to a logical representation can be done automatically, and that a standard model-based diagnosis engine can be used, make the approach easy to implement and use. In the first part of the paper, we show how a model can be used to compute diagnosis for a VHDL program. In the second part, we introduce a new logical model that allows the diagnosis engine to deal with temporal information directly by unfolding the circuit with respect to time, thereby employing temporal instances of VHDL processes.", "num_citations": "5\n", "authors": ["1033"]}
{"title": "Analysing models for software debugging \u0403\n", "abstract": " This paper extends our previous work on the representation and analysis of Java programs for diagnosis in a new direction by providing a description and analysis of the issues arising from handling object references in dependency-based models of Java programs. We empirically compare dependencybased models with a value-based model using a set of example programs in terms of required user interaction (questions put to the user) and examine and incorporate specific interesting error categories. Apart from being based on experience with an actual implementation of the various models, the model extensions and analysis deal with aliasing, an issue that the programming language community has been examining for a long time, and that is also crucial to object-orientedness.", "num_citations": "5\n", "authors": ["1033"]}
{"title": "Model-based debugging of functional programs\n", "abstract": " Model-based debugging of functional programs \u2014 Graz University of Technology Skip to main navigation Skip to search Skip to main content Graz University of Technology Logo English Deutsch Home Persons Research Units Research Outputs Projects Activities Prizes Press / Media Search by expertise, name or affiliation Model-based debugging of functional programs Franz Wotawa, Markus Stumptner Institute of Software Technology (7160) Research output: Chapter in Book/Report/Conference proceeding \u203a Conference contribution Overview Original language English Title of host publication International Workshop on Principles of Diagnosis Publisher . Pages ?-? Publication status Published - 1998 Cite this APA Standard Harvard Vancouver Author BIBTEX RIS Wotawa, F., & Stumptner, M. (1998). Model-based debugging of functional programs. In International Workshop on Principles of Diagnosis (pp. ?-?). .. \u2026", "num_citations": "5\n", "authors": ["1033"]}
{"title": "Towards swarm level optimisation: the role of different movement patterns in swarm systems\n", "abstract": " In a swarm system, for example in a beehive, group decision is based on interactions and interferences of all individuals without a central unit that decides for everybody. When making experiments with young honeybees (Apis mellifera), a swarm algorithm, called BEECLUST, was derived. The algorithm enables swarms to locate the \u2018Global-Goal\u2019 out of several local optima. There were also four different behavioural types discovered during the experiments: Random-Walker, Goal-Finder, Wall-Follower and the Immobile Bee. In this paper, we introduce the four behavioural types to the BEECLUST algorithm and analyse how the decision making process of the swarm can be influenced. We show how the different types can be used to optimise the decision making for a certain setup of the arena and discuss about Swarm Level Optimisation.", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Evolutionary propositionalization of multi-relational data\n", "abstract": " Propositionalization has been proven to be a very effective solution for multi-relational data mining problems. The approaches usually follow a two-step principle: transforming the relational data into a single, flat table and applying a propositional learning algorithm. During the transformation, the target table gets expanded by adding many new features summarizing the information of the non-target tables. Based on the used feature construction strategy, this leads to a table of very high dimensionality with a lot of irrelevant and/or redundant features that can negatively affect the predictive performance. In this paper, we propose a modification of the traditional two-step framework to overcome such problems. The proposed approach evaluates the features during the construction phase and reports only a subset of highly predictive features to the propositional learner. We present an implementation of this approach\u00a0\u2026", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Applying algorithm selection to abductive diagnostic reasoning\n", "abstract": " The complexity of technical systems requires increasingly advanced fault diagnosis methods to ensure safety and reliability during operation. Particularly in domains where maintenance constitutes an extensive portion of the entire operation cost, efficient and effective failure identification holds the potential to provide large economic value. Abduction offers an intuitive concept for diagnostic reasoning relying on the notion of logical entailment. Nevertheless, abductive reasoning is an intractable problem and computing solutions for instances of reasonable size and complexity persists to pose a challenge. In this paper, we investigate algorithm selection as a mechanism to predict the \u201cbest\u201d performing technique for a specific abduction scenario within the framework of model-based diagnosis. Based on a set of structural attributes extracted from the system models, our meta-approach trains a machine learning\u00a0\u2026", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Spectrum-based fault localization for logic-based reasoning\n", "abstract": " When obtaining a full-fledged model for diagnostic and debugging purposes is out of reach, abstract logic models might allow us to fall back to abductive reasoning for isolating faults. Such models often only aggregate knowledge about which inputs and faults would have this or that effect on the system. Like in property-based system design or formal verification, we have that the quality of the resulting reasoning process depends heavily on this logic model. Since logic descriptions are not entirely intuitive to formulate and automated processes to derive them are prone to be incomplete, we'd certainly be interested in assessing a model's quality and isolate issues. In this paper, we're proposing to use test cases and spectrum-based fault localization for this task, drawing on the flexibility and ease-of-use of such a spectrum-based concept. Focusing on logic models formulated in propositional Horn-clauses, we provide\u00a0\u2026", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Adaptive system for autonomous driving\n", "abstract": " Avoiding faults in systems is of uttermost importance during system development. In case of autonomous systems this requirement becomes more important because of the fact that there is no human in the loop that can take over control after a fault. In this paper, we discuss a methodology allowing to implement a system that reacts on faults in a smart way using rules specifying possible sequences of actions a system can take for reaching a goal. In the methodology the selection of actions is done automatically aiming at reaching the goal state. The methodology allows a system to adapt in cases where action execution fails. Besides the underlying foundations, we show the applicability of the methodology using an example from the autonomous driving domain considering different sensors for obstacle detection. For this case study the methodology leads to a substantial improvement of availability compared to a\u00a0\u2026", "num_citations": "4\n", "authors": ["1033"]}
{"title": "A model for bio-inspired underwater swarm robotic exploration\n", "abstract": " Swarm intelligence has interested researchers in various areas of research for several decades because of its stability, resilience and simplicity. Several researchers have used swarm intelligence behaviours to design systems which can accomplish single tasks. In this paper, we will make a step forward by designing a swarm intelligent system that draws from two different natural swarms, bees and slime mould, to form an integrated underwater swarm robotic exploration system. An agent based simulation of such a system is presented in this paper along with some basic performance evaluation measures of the presented system. The main question the authors are attempting to answer through this model is how feasible the such an exploration system would be with regards to time, the number of robots allocated by the decentralized system for exploring interesting locations and the resilience of such a system to\u00a0\u2026", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Testing tls using combinatorial methods and execution framework\n", "abstract": " The TLS protocol is the standard for secure Internet communication between two parties. Unfortunately, there have been recently successful attacks like DROWN or BREACH that indicate the necessity for thoroughly testing TLS implementations. In our research work, we focus on automated test case generation and execution for the TLS security protocol, where the aim is to make use of combinatorial methods for providing test cases that ideally also reveal previously unknown attacks. This is made feasible by creating appropriate input parameter models for different messages that can appear in a TLS message sequence. In this paper, we present the resulting test case generation and execution framework together with the corresponding testing oracle. Furthermore, we discuss first empirical results obtained using different TLS implementations and their releases.", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Model-based diagnosis in practice: interaction design of an integrated diagnosis application for industrial wind turbines\n", "abstract": " Model-based diagnosis derives explanations for discrepancies between the expected and observed system behavior by relying on a formal representation of the artifact under consideration. Although its theoretical background has been established decades ago and various research prototypes have been implemented, industrial applications are sparse. This paper emphasizes the role of essential technology acceptance factors, i.e., usefulness and usability, within the context of model-based diagnosis. In particular, we develop a concept and interface design for an abductive model-based diagnosis application integrated into existing condition monitoring software for industrial wind turbines. This fault identification tool should enhance the performance of the maintenance personnel while respecting their current work processes, taking into account their particular needs, and being easy to use under the\u00a0\u2026", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Using Modelica programs for deriving propositional horn clause abduction problems\n", "abstract": " Despite ample advantages of model-based diagnosis, in practice its use has been somehow limited to proof-of-concept prototypes. Some reasons behind this observation are that the required modeling step is resource consuming, and also that this step requires additional training. In order to overcome these problems, we suggest to use modeling languages like Modelica that are already established in academia and industry for describing cyber-physical systems as basis for deriving logic based models. Together with observations about the modeled system, those models can then be used by an abductive diagnosis engine for deriving the root causes for detected defects. The idea behind our approach is to introduce fault models for the components written in Modelica, and to use the available simulation environment to determine behavioral deviations to the expected outcome of a fault free model. The\u00a0\u2026", "num_citations": "4\n", "authors": ["1033"]}
{"title": "On the use of qualitative deviation models for diagnosis\n", "abstract": " Detecting and even locating faults in systems is an important but also very much resource consuming task, which is especially true for finding and fixing bugs in programs. In literature someone finds different approaches for supporting the fault localization task for programs including statistical methods like spectrumbased fault localization, methods based on control and data dependences like slicing, and even model-based diagnosis relying on a logical or constraint representation of a program for computing diagnosis candidates. One issue that hampers the use of model-based diagnosis for debugging is its computational requirements especially when relying on a more or less one-to-one representation of the underlying source code. In order to decrease computational requirements abstract models have to be used. In this paper, we discuss the use of deviation models and provide a framework for comparing such models making use of an abstraction function. First experimental results indicate that some abstract models behave similar to concrete models for diagnosis but come with a much lower computational footprint enabling their use in practice even for larger programs.", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Maintaining constraint-based configuration systems: Challenges ahead\n", "abstract": " Constraint-based configuration systems like knowledge-based recommendation and configuration are used in many different product areas such as cars, bikes, mobile phones, and computers. The development and maintenance of such systems is a time-consuming and error prone task because the content of such systems and the responsible knowledge engineers are changing over time. Much research has been done to support knowledge engineers in their maintenance task. In this paper we give a short overview of previous research in the context of intelligent techniques to support the maintenance task and give an overview of future research aspects in this area. This paper focuses on intelligent simulation techniques for generating metrics, predicting boundary values for automated test case generation, assignment-based (instead of constraint-based) anomaly management, and processes for the development of constraintbased configuration systems.", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Bpel integration testing\n", "abstract": " Service-oriented architectures, and evolvements such as clouds, provide a promising infrastructure for future computing. They encapsulate an IP core\u2019s functionality for easy access via well-defined business and web interfaces, and in turn allow us to flexibly realize complex software drawing on available expertise. In this paper, we take a look at some challenges we have to face during the task of testing such systems for verification purposes. In particular, we delve into the task of test suite generation, and compare the performance of two corresponding algorithms. In addition, we report on experiments for a collection of BPEL processes taken from the literature, in order to identify performance trends with respect to fault coverage metrics. Our results suggest that a structural reasoning might outperform a completely random approach.", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Testing Configuration Knowledge-Bases.\n", "abstract": " Writing tests for configuration knowledge-bases is a difficult task. One not minor reason is the huge search space. For exhaustive testing, all possible combinations of configuration parameters must be considered. In practice, exhaustive testing is thus often impossible, due to the sheer, exponential, number of combinations. Consequently it becomes necessary to focus on the most important configurations first. This abstract challenge is well-known in the testing community, and can be addressed by exploiting combinatorial testing. Combinatorial testing deals with reducing the number of test inputs by aiming at exhaustive combinations of parameter subsets. That is, ensuring that a test-suite contains tests covering all value combinations for all parameter subsets for (or up to) a given size. In this paper, we formulate the configuration-testing problem and show how combinatorial testing can be used in a corresponding test case generation process, in order to achieve a huge reduction in the number of required test cases.", "num_citations": "4\n", "authors": ["1033"]}
{"title": "On the evaluation and certification of the robustness of autonomous intelligent systems\n", "abstract": " On the Evaluation and Certification of the Robustness of Autonomous Intelligent Systems \u2014 Technische Universit\u00e4t Graz Zur Hauptnavigation wechseln Zur Suche wechseln Zum Hauptinhalt wechseln Technische Universit\u00e4t Graz Logo English Deutsch Home Personen Forschungsgruppen Ver\u00f6ffentlichungen Projekte Verwandte T\u00e4tigkeiten Pr\u00e4mien Presseberichte Nach Expertise, Namen oder Zugeh\u00f6rigkeit suchen On the Evaluation and Certification of the Robustness of Autonomous Intelligent Systems Gerald Steinbauer, Franz Wotawa Institut f\u00fcr Softwaretechnologie (7160) Publikation: Beitrag in Buch/Bericht/Konferenzband \u203a Beitrag in einem Konferenzband \u00dcbersicht (Administrator/-in) Projekte (2) Originalsprache englisch Titel International Workshop on Principles of Diagnosis Herausgeber (Verlag) . Seiten 167-170 Publikationsstatus Ver\u00f6ffentlicht - 2011 Veranstaltung 22nd International Workshop on \u2026", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Challenges of distributed model-based diagnosis\n", "abstract": " The importance of distributed systems is increasing. More and more systems are built using multi-agent or service-oriented architectures. The size of the resulting systems also increases, which makes the diagnosis task more difficult because of the underlying complexity. As a consequence distributed diagnosis has become more and more important but usually it is tied to specific modeling concepts or based on particular algorithms whose correctness and completeness is not proven. Therefore, we focus in this paper on a general theory for distributed diagnosis, which provides a framework for checking the correctness and completeness of distributed diagnosis algorithms. Moreover, we present a simple algorithm and show that correctness and completeness can only be guaranteed under certain assumptions. The theory is of importance for industry to ensure the correctness of diagnosis systems in the\u00a0\u2026", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Using qualitative and model-based reasoning for sensor validation of autonomous robots\n", "abstract": " Reference: A. Kleiner, G. Steinbauer, and F. Wotawa. Using qualitative and model-based reasoning for sensor validation of autonomous robots. In Twentieth International Workshop on Principles of Diagnosis (DX 2009), Stockholm, Sweden, 2009.", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Intelligent, fault adaptive control of autonomous systems\n", "abstract": " We present a methodology for intelligent control of an autonomous and resource constrained embedded system. Geared towards mastering permanent and transient faults by dynamic reconfiguration, our approach uses rules for describing device functionality, valid environmental interactions, and goals the system has to reach. Besides rules, we use functions that characterize a goal\u2019s activity. These functions control the frequency our system uses to reach the goal. In this chapter we present the system model, discuss properties of the rule selection mechanism, and show results gained from running the approach on an embedded device.", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Test case generation from qr models\n", "abstract": " In this paper we present the application of AI to automated test case generation. In particular we introduce a technique for deriving abstract test cases from qualitative models. In the case of reactive systems, the behavior of the device depends on its internal state and the perception of the environment via its sensors. Such systems are well suited for modeling with using Qualitative Reasoning methods. Qualitative Reasoning enables one to specify system behavior that also acquires changing environmental conditions and hence provides a good foundation to derive more realistic test cases. In the first part of this paper we give a short introduction to Qualitative Reasoning and Garp3, the tool we use for model creation and simulation. We also present a method for modeling differential equations within Garp3. In the second part we deal with abstract test case generation from QR models and present first results\u00a0\u2026", "num_citations": "4\n", "authors": ["1033"]}
{"title": "From constraint representations of sequential code and program annotations to their use in debugging\n", "abstract": " Debugging, ie, the detection, localization, and correction of bugs, has been considered an important task in software engineering. A lot of research has been devoted to debugging but mainly to fault detection. In this paper we focus on fault localization, which is based on the constraint representation of programs. For this purpose, programs are converted into their equivalent constraint satisfaction problem (CSP). A solution of the corresponding CSP is a diagnosis candidate. Besides the source code, a failure revealing test case has to be given. For more information regarding CSP we refer to [2]. The work described in this paper is most closely to the work of Ceballos et al. authors [9], where constraint programming is used for fault localization. There approach requires that the programmer provides contracts, ie, pre-and post-conditions, for every function. However, the authors do not investigate the complexity of\u00a0\u2026", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Gradient-based diagnosis\n", "abstract": " Repairing a fault in a highly dynamic environment under uncertain conditions not always requires a distinct fault detection and localization pre-processing step. In this paper we present an approach based on the behavior of a device combined with gradients which indicate the appropriateness of a certain behavior in a given situation. The gradients in our approach work like a memory storing past experiences and thus allow for adapting the system\u2019s behavior smoothly over time. We show that the approach is feasible for small devices having strong resources constraints regarding computational power and available memory. Moreover, we introduce a case study where a device using the gradient approach is capable to handle permanent and transient faults which occur over time.", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Model-based fault diagnosis and reconfiguration of robot drives\n", "abstract": " Reference: MBM Hofbaur, G. Steinbauer, and F. Wotawa. Model-based fault diagnosis and reconfiguration of robot drives. In Proceedings of the 2007 IEEE International Conference on Intelligent Robots and Systems, San Diego, CA, USA, 2007.", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Diagnosing program errors with light-weighted specifications\n", "abstract": " During the last decade many computer-aided debugging tools have been developed to assist users to detect program errors in a software system. A good example are model checking tools that provide counterexamples in case a given program violates the specified properties. However, even with a detailed erroneous run, it remains difficult for users to understand the error well and to isolate its root cause quickly and cheaply. This paper presents object store models for diagnosing program errors with light-weighted specifications. The models we use can keep track on object relations arising during program execution, detect counterexamples that violate user-provided properties, and highlight statements responsible for the violation. We have used the approach to help students to locate and correct the program errors in their course works.", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Mobile robots in exhibitions, games and education. Do they really help?\n", "abstract": " Mobile robots have gained great popularity in domains like exhibitions, games, education and others. They have shown the capability to attract people. The aims and benefits of the deployment of mobile robots in these events are manifold. They promote a product, guide people through exhibitions or give students the opportunity to learn more about mobile robots. But all these applications have one attribute together: They have all the aura of toy applications and there is almost no commercial market for them except some rare examples like the AIBO entertainment robot. But all the deployments of mobile robots in exhibitions, contest, games and education are of course valuable as they introduce mobile robots to a bigger non-academic audience, forms test-beds for pushing forward robotics research and finally show the current borders of technology. In this paper we discuss the question if and how mobile robots can be applied to these domains to gain optimal benefit for the community, students and researchers.", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Exploiting Static Abstractions of Data Structures for Debugging\n", "abstract": " There is a variety of inferred program behavior models. They might miss some features because they are approximating not the program specification but the implementation. In this paper, we present a discrete model to avoid this problem by generating data for approximating object relations arising from the program execution. The data is a collection of object relations which can be used for debugging structural properties provided by the user.", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Model-based Reasoning in Mathematical Tutoring Systems-Preliminary Thoughts and Problems to be solved\n", "abstract": " This paper deals with the application of model-based reasoning to tutoring systems for teaching high-school-level mathematics. It presents the current state of such a tutoring system ISAC that has been developed for this purpose. The shortcomings of the current system and the question of how model-based reasoning can be used to overcome this drawbacks is discussed. In particular we introduce a framework for handling the knowledge that has to be dealt with for this purpose.", "num_citations": "4\n", "authors": ["1033"]}
{"title": "Using Multiple Models for Debugging VHDL Designs*\n", "abstract": " Debugging is a time-consuming task especially for larger programs written by a group of people. In this paper we describe the use of multiple models for debuggingVHDL designs, and presents some practical results. The models are derived from a general value-based model representing different fault situations that should be handled by a debugger.We propose the use of a probability-based selection strategy for selecting the most appropriate model in a given situation. For example large programs should be debugged using a model only distinguishing concurrent VHDL statements and not sequential statements. As a result of multi- model reasoning in this domain we expect performance gains allowing to debug larger designs in a reasonable time, and more expressive diagnosis results.", "num_citations": "4\n", "authors": ["1033"]}
{"title": "JADE\u2013A Step towards an Intelligent Debugger \u0403\n", "abstract": " The idea behind Model-based debugging is the notion of using the techniques of model-based diagnosis for locating errors in software. This requires the presence of a model of the software being debugged, which is generated automatically from the source code, and combined with test results and user input to identify statements or expressions that may be the cause of incorrect results. We describe the actual use of model-based debugging support for Java programs, based on an extended version of a previously presented model for representing these programs. Even with an extremely simple model, the system uses the diagnosis outcomes to guide user interaction with the debugger and lead the user (programmer) towards the source of the error. We compare the behavior of the integrated debugger with the outcomes produced by support methods from the programming community.", "num_citations": "4\n", "authors": ["1033"]}
{"title": "On Using k-means Clustering for Test Suite Reduction\n", "abstract": " Testing large software or other systems where test execution is time consuming or requires high computational resources is difficult and requires the selection of appropriate test cases. In the context of testing, appropriate means to have tests that most likely reveal faults or at least indicate when passing that the important functionality of the system works. In practice it is often the case that we have to reduce available test suites in order to finalize testing in a given time not exceeding other resources. In this paper, we introduce a machine learning based algorithm for test suite reduction that combines k-means clustering with binary search. The idea behind the algorithm is to cluster test cases that are close together and to select a representative test case from each of the clusters to be used in the new reduced test suite. We use binary search for looking for the proper number of clusters that allows to reduce the test suite\u00a0\u2026", "num_citations": "3\n", "authors": ["1033"]}
{"title": "A swarm design paradigm unifying swarm behaviors using minimalistic communication\n", "abstract": " Numerous nature inspired algorithms have been suggested to enable robotic swarms, mobile sensor networks and other multi-agent systems to exhibit various self-organized behaviors. Swarm intelligence and swarm robotics research have been underway for a few decades and have produced many such algorithms based on natural self-organizing systems. While a large body of research exists for variations and modifications in swarm intelligence algorithms, there have been few attempts to unify the underlying agent level design of these widely varying behaviors. In this work, a design paradigm for a swarm of agents is presented which can exhibit a wide range of collective behaviors at swarm level while using minimalistic single-bit communication at the agent level. The communication in the proposed paradigm is based on waves of'ping'-signals inspired by strategies for communication and self organization of\u00a0\u2026", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Software testing: According to plan!\n", "abstract": " Automated planning and scheduling represents a branch of classical artificial intelligence (AI) research. Although initially used in robotics and intelligent agents, the use of planning for testing purposes has increased over the years. There sequences of actions representing interactions with the system under test guide the test execution towards reaching a test purpose. A planning problem is formally defined as a model that resembles the interaction with a real system under test (SUT). The obtained solutions are generated, i.e., the plans, directly correspond to test cases. The planning model offers the possibility to generate test cases with a great variety of interactions without the need for an extensive model definition. Until now, planning has proven to be efficient in detecting both functional and non-functional issues. The second play a major role in uncovering vulnerabilities in software. In fact, testing of any domain\u00a0\u2026", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Weighted combinatorial sequence testing for the TLS protocol\n", "abstract": " In this paper, we apply the notion of weighted t-way sequences to derive sequence test cases for testing implementations of the TLS protocol version 1.2. The used weights have been derived from an analysis of a security bug database of GnuTLS and we tested four implementations of the TLS protocol against them comparing their behavior. Our results indicate discrepancies in the behavior of different TLS implementations.", "num_citations": "3\n", "authors": ["1033"]}
{"title": "On the Importance of System Testing for Assuring Safety of AI Systems.\n", "abstract": " Rigorous testing of automated and autonomous systems is inevitable especially in case of safetycritical systems like cars or airplanes. There exist several functional safety standards that have to be fulfilled like IEC 61508 explicitly stating that AI methodologies are not recommended to be used in case of systems with higher safety requirements. Hence, there is a necessity to adopt these standards in a direction where AI methodology is allowed to be used providing to fulfill certain standardized quality assurance method to be taken care of during development. In this paper, we contribute to this endeavor and discuss the urgent need for system testing in the context of safety-critical systems comprising AI methodologies. In particular, we argue based on one example from the automotive industry that it is strongly recommended to consider not only subsystems but instead the whole system interacting with its environment when carrying out tests. The discussed example is an advanced driver-assistance systems used to break in case of an emergency that does not rely on machine learning but comprises a decision part that invokes breaking once the sensors identify an obstacle that might be hit otherwise. Results obtained from an already reported testing methodology, revealed that when using tests considering the environment of an automated emergency breaking systems, we obtain critical scenarios that might otherwise have not been detected. From this observation, we conclude that rigorous system testing becomes even more important for systems with AI methodology based on machine learning or allowing to adapt the system\u2019s behavior during\u00a0\u2026", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Fault detection and localization using Modelica and abductive reasoning\n", "abstract": " Modelica is an object-oriented and domain-independent programming language that is excellently suited for modeling and simulating a wide range of systems. In this chapter, after briefly discussing the use of Modelica for representing hybrid systems, we show how to use corresponding simulation results for detecting and isolating faults. To this end, we present three approaches to comparing simulated signals with actually observed behavior. This includes the use of average values and pre-defined tolerances, temporal band sequences, and the Pearson correlation coefficient. Once we identify significant deviations from expected behavior, we are, of course, interested in identifying their cause. For this task, we show how to add fault models to the Modelica system model, so that we can simulate the corresponding faulty behavior. From the described faults and their simulations, we then derive an intuitive cause\u00a0\u2026", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Classifying test suite effectiveness via model inference and ROBBDs\n", "abstract": " Deciding whether a given test suite is effective enough is certainly a challenging task. Focusing on a software program\u2019s functionality, we propose in this paper a new method that leverages Boolean functions as abstract reasoning format. That is, we use machine learning in order to infer a special binary decision diagram from the considered test suite and extract a total variable order, if possible. Intuitively, if an ROBDD derived from the Boolean functions representing the program under test\u2019s specification actually coincides with that of the test suite (using the same variable order), we conclude that the test suite is effective enough. That is, any program that passes such a test suite should clearly show the desired input-output behavior. In our paper, we provide the corresponding algorithms of our approach and their respective proofs. Our first experimental results illustrate our approach\u2019s practicality and viability.", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Integration of failure assessments into the diagnostic process\n", "abstract": " The complexity of technical systems requires increasingly advanced fault diagnosis methods to improve safety and reliability. Particularly in domains where maintenance poses an extensive part of the entire operation cost, accurate identification of failure sources has a large economic impact. Modelbased diagnosis, as a subfield of Artificial Intelligence, allows to determine root causes based on observed anomalies and has already been applied to a variety of domains. Abductive model-based diagnosis considers information on failures and how they affect detectable system measurements. Thus, this type of fault localization procedure depends on systematic and analytic knowledge on components, their possible", "num_citations": "3\n", "authors": ["1033"]}
{"title": "On structural properties to improve FMEA-based abductive diagnosis\n", "abstract": " Abductive Model-Based Diagnosis (MBD) provides an intuitive approach to fault identification by reasoning on a description of the system to be diagnosed. Nevertheless, its computational complexity hinders a vast adoption and thus motivates further evaluation of efficient methods. In this paper, we investigate the structural metrics inherent to models and diagnosis problems generated on the basis of Failure Mode Effect Analysis (FMEA). Proceeding on the metrics developed, we investigate their potential as classification features to identify the most suitable diagnosis algorithm for a particular diagnosis problem. Evaluated on artificial and practical samples, our approach shows that the classifier trained on the described metrics is able to indicate the most efficient method in case of a specific diagnosis scenario.", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Analysis Methods in the Development Process of Mechatronic Drivetrain Systems with Special Focus on Automotive Software\n", "abstract": " The steadily increasing complexity in automotive technology due to the application of mechatronic systems requires efficient quality management and enhanced development processes. An additional challenge in the automotive industry is the development of interacting mechatronic components composed of electronics/electrics, automotive software, and mechanics. High reliability and fault prevention are enabled by introducing new analysis methods based on objective quality evaluations and specific metrics. In case of automotive software, the aim is to apply effective analysis methods in early development phases to support an objective quality evaluation and risk-analysis for the release process. The present publication introduces and discusses different analysis methods, which allow an objective evaluation of the development process and support reliability by the use of stochastic approaches.", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Intelligent engineering techniques for knowledge bases.\n", "abstract": " Knowledge bases are encountered in different AI areas such as configuration, planning, diagnosis, semantic web, game playing, and others. Very often the amount and arrangement of the elements in the knowledge base outstrips the capability of a knowledge engineer to survey them and to efficiently perform maintenance operations\u2013a situation that triggers an enormous demand of extending and improving existing development and maintenance practices. The goal of this AI Communications Special Issue on \u201cIntelligent Engineering Techniques for Knowledge Bases\u201d is to show novel and innovative research related to different knowledge engineering tasks. The major topics of the special issue include aspects of knowledge evolution, automated knowledge base repair, consistency maintenance, knowledge acquisition, and knowledge representation.The paper on \u201cChallenges of Knowledge Evolution in Practice\u201d by Andreas Falkner and Alois Haselb\u00f6ck provides an overview of major challenges in industry related to knowledge evolution which are, for example, knowledge base redesign, schema evolution, upgrade of configuration instances, adaptation of the solver, and the maintenance of test suites. On the basis of the PartnerUnits problem, the authors discuss advantages and disadvantages of different configuration knowledge representations such as Generative Constraint Satisfaction and UML/OCL.", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Model-based simulation and configuration of mobile phone networks-the SIMOA approach\n", "abstract": " Machine to machine communication via mobile phone networks is of increasing importance for mobile phone network suppliers as well as for companies offering applications in the domain. For example the question whether a distributed application that communicates within such a network can meet certain quality of services has to be answered before deployment. In this paper we present a tool that uses a model of the network and the intended network use in order to answer such questions. Beside simulation of the network the proposed approach is also capable of providing configurations, ie, changes in certain parameters in order to meet given specifications. The underlying tool makes use of a modeling language that allows to specify the behavior of components over time and their interconnections. In the paper we discuss the approach, the currently deployed tool, the used modeling language, and some empirical results obtained that indicate feasibility of the approach for the indicated application domain.", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Combining Runtime Diagnosis and AI-planning in a Mobile Autonomous Robot to Achieve a Graceful Degradation after Software Failures.\n", "abstract": " Our past work deals with model-based runtime diagnosis in the software system of a mobile autonomous robot. Unfortunately, as an automated repair of failed software components at runtime is hardly possible, it may happen that failed components must be removed from the control system. In this case, those capabilities of the control system which depend on the removed components are lost. This paper focuses on the necessary adaptions of the high-level decision making in order to achieve a graceful degradation. Assuming that those decisions are made by an AI-planning system, we propose extensions which enable such a system to generate only plans which can be executed and monitored despite the lost capabilities. Among others, we propose an abstract model of software capabilities, and we show how to dynamically determine those capabilities which are required for monitoring a plan.", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Employing test suites for verilog fault localization\n", "abstract": " This article briefly states the idea behind model-based diagnosis and its application to localizing faults in Verilog programs. Specifically this article outlines how to employ a test suite to further reduce the number of fault candidates. For this purpose, we propose the filtering approach and relate it to the concept of Ackermann constraints. Notably, our empirical results demonstrate that our novel technique considerably increases the diagnosis resolution even under presence of only a couple of test cases.", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Concept evaluation of a reflex inspired ball handling device for autonomous soccer robots\n", "abstract": " This paper presents a concept evaluation for a passive ball handling device for autonomous robots that enables the robot to \u201dfeel\u201d the ball. A combination of a capacitive and a pressure sensor delivers accurate information of the ball position and movement within the ball handling device - even without touching it. Inspired by the human reflex the sensor values are evaluated to implement a low-level based control loop. This should enable the robot to make minor movement corrections to the overall path calculated by the high-level control system.", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Detect and localize faults in alias-free programs using specification knowledge\n", "abstract": " Locating faults is one of the most time consuming tasks in today\u2019s fast paced economy. Testing and formal verification techniques like model-checking are usually used for detecting faults but do not attempt to locate the root-cause for the detected faulty behavior. This article makes use of an abstract dependences between program variables for detecting and locating faults in alias-free programs in cases where an abstract specification is available. The idea of using dependences for fault detection and localization is not new. But the relationship between the abstract model and the concrete evaluation of programs have not been considered so far. In particular we show that the dependence model is correct. Whenever the dependence model reveals a fault there is a test case, which also reveals a fault.", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Using qualitative and model-based reasoning for sensor validation of autonomous mobile robots\n", "abstract": " Mobile robots performing tasks in dynamic environments have to rely on both reliable sensor data and data processing. Since actions performed by robots in the real world are based on this information, uncertain or even wrong data can be fatal. For instance, a compass may be significantly disturbed by metal structures in the environment. Truly autonomous robots must be able to cope with such situations.In order to enhance robotic systems with this capability we propose a sensor validation approach. The key idea is to qualitatively compare trends of sensors which are related by some physical constrain. These observations together with an abstract model of these relations are utilized by a model-based reasoning approach for finding the root cause of data unreliability. The result of the reasoning process can be used online on the robot platform to adapt its sensor data processing in order to mitigate the effect.", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Random vs. scenario-based vs. fault-based testing: An industrial evaluation of formal black-box testing methods\n", "abstract": " Random vs. Scenario-Based vs. Fault-Based Testing: An Industrial Evaluation of Formal Black-Box Testing Methods \u2014 Technische Universit\u00e4t Graz Zur Hauptnavigation wechseln Zur Suche wechseln Zum Hauptinhalt wechseln Technische Universit\u00e4t Graz Logo English Deutsch Home Personen Forschungsgruppen Ver\u00f6ffentlichungen Projekte Verwandte T\u00e4tigkeiten Pr\u00e4mien Presseberichte Random vs. Scenario-Based vs. Fault-Based Testing: An Industrial Evaluation of Formal Black-Box Testing Methods Martin Weiglhofer, Franz Wotawa Institut f\u00fcr Softwaretechnologie (7160) Publikation: Beitrag in Buch/Bericht/Konferenzband \u203a Beitrag in einem Konferenzband \u00dcbersicht (Administrator/-in) Originalsprache englisch Titel Proceedings of the 3rd International Conference on Evaluation of Novel Approaches to Software Engineering Herausgeber (Verlag) . Seiten 115-122 Publikationsstatus Ver\u00f6ffentlicht - 2008 \u2026", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Automated Classification of Faults in Programs using Machine Learning Techniques\n", "abstract": " Automated Classification of Faults in Programs using Machine Learning Techniques \u2014 Technische Universit\u00e4t Graz Zur Hauptnavigation wechseln Zur Suche wechseln Zum Hauptinhalt wechseln Technische Universit\u00e4t Graz Logo English Deutsch Home Personen Forschungsgruppen Ver\u00f6ffentlichungen Projekte Verwandte T\u00e4tigkeiten Pr\u00e4mien Presseberichte Automated Classification of Faults in Programs using Machine Learning Techniques Syed Nadeem Ahsan, Javed Ferzund, Franz Wotawa Institut f\u00fcr Softwaretechnologie (7160) Publikation: Beitrag in Buch/Bericht/Konferenzband \u203a Beitrag in einem Konferenzband \u203a Forschung \u203a Begutachtung \u00dcbersicht (Administrator/-in) Originalsprache englisch Titel Proceedings of the Artificial Intelligence Techniques in Software Engineering Workshop Herausgeber (Verlag) . Seiten 31-35 Publikationsstatus Ver\u00f6ffentlicht - 2008 Veranstaltung ECAI 2008: Workshop on \u2026", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Advances in automated source-level debugging of verilog designs\n", "abstract": " Developing models for fault localization in HDL designs has been an active research area in recent years. Whereas research on circuit verification is typically conducted on Verilog programs, research on fault localization has recently focused on the VHDL domain. The research presented herein focuses on fault localization models for Verilog designs and thus promotes the investigation of the relationships between models for property verification and fault localization. Primarily we focus on two novel contributions. First, this article points out notable semantic differences between VHDL and Verilog models and discusses its implications for fault localizations. Secondly, we advance existing work by incorporating multiple testcases and provide first empirical results obtained from the the ISCAS 89 benchmarks indicating our novel technique\u2019s applicability for real world designs.", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Diagnosing Dependent Failures\u2013an Extension of Consistency-based Diagnosis\n", "abstract": " Most applications of model-based diagnosis rely on the assumption that components fail independently. However, dependent failures are quite common in some domains. In such domains, the failure of one component may cause the failure of other components. Hence, multiple faults are much more likely, and the minimal diagnoses may not contain all components which have failed. In this work we propose the concept of diagnosis environments (DEs). DEs distinguish between independent and dependent failures, and they may consider components as failed which are not part of the minimal diagnoses. We provide a formalization of our approach and present an algorithm which computes all minimal DEs.", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Executing abstract test cases\n", "abstract": " Generally, test cases derived from a formal model can not be directly fed into implementations under test (IUT), because model based test generation techniques produce abstract test cases. In order to run an abstract test case against an IUT the abstract test case either has to be transformed to a concrete test case or an execution of the abstract test case is needed. In this paper we propose a rule based test execution framework, which allows the execution of abstract test cases. Furthermore, we present first results from testing a so called SIP Registrar by executing abstract test cases derived with the TGV tool from a formal specification.", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Configuring collaboration of software modules at runtime\n", "abstract": " We present an approach for (re-) configuring the collaboration of software modules on board an autonomous device. The proposed methodology largely is based on principles of logics: Different configurations are evaluated on the fly before one configuration is chosen and applied to the system. Each configuration has its own semantical meaning that is also included in the decision process. The set of all possible configurations is stored in a knowledge base that is queried before choosing a configuration. The presented approach allows to specify preferred configurations. We present first results obtained by running a prototype implementation of the presented methodology at the end of the paper.", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Generating test-cases from qualitative knowledge\u2013preliminary report\n", "abstract": " In this paper we introduce a methodology for extracting testcases from qualitative knowledge which represents the expected behavior of the environment of a system under test. Usually in software engineering test-cases are only derived from the requirements documentation and do hardly consider environmental constraints. This is especially problematic if a system like a mobile device has interactions with the environ-ment which cannot be foreseen in advance in all details. An approach that is based on the behavior of the world which is external to the system would help to generate test cases which are realistic and capture the whole range of interactions. The usc of qualitativc rcasoning for rcpresenting for cxample thc physical world is an advantage because the underlying models capture all possible behaviors and thus guarantee completeness of the generated test-case set to some extent.", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Lightweight fault localization with abstract dependences\n", "abstract": " Locating faults is one of the most time consuming tasks in today's fast paced economy. Testing and formal verification techniques like model-checking are usually used for detecting faults but do not attempt to locate the root-cause for the detected faulty behavior. This article makes use of abstract dependences between program variables for locating faults in programs. We discuss the basic ideas, the underlying theory, and first experimental results, as well our model's limitations. Our fault localization model is based on a previous work that uses the abstract dependences for fault detection. First case studies indicate our model's practical applicability", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Plan Description and Execution with Invariants, The Planning System of the RoboCup Team Mostly Harmless\n", "abstract": " Plan Description and Execution with Invariants, The Planning System of the RoboCup Team Mostly Harmless \u2014 Technische Universit\u00e4t Graz Zur Hauptnavigation wechseln Zur Suche wechseln Zum Hauptinhalt wechseln Technische Universit\u00e4t Graz Logo English Deutsch Home Personen Forschungsgruppen Ver\u00f6ffentlichungen Projekte Verwandte T\u00e4tigkeiten Pr\u00e4mien Presseberichte Plan Description and Execution with Invariants, The Planning System of the RoboCup Team Mostly Harmless Gordon Fraser, Franz Wotawa Institut f\u00fcr Softwaretechnologie (7160) Publikation: Beitrag in einer Fachzeitschrift \u203a Artikel \u203a Forschung \u00dcbersicht (Administrator/-in) Projekte (1) Originalsprache englisch Seiten (von - bis) 2-7 Fachzeitschrift \u00d6GAI-Journal Jahrgang 22 Ausgabenummer 4 Publikationsstatus Ver\u00f6ffentlicht - 2003 Projekte 2002 2002 1 Laufend RoboCup Wotawa, F., Kandlhofer, M., Weiglhofer, M., Reip, M., Gspandl, \u2026", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Model-based Reasoning in Mathematical Tutoring Systems\u2013Preliminary Report\n", "abstract": " This paper deals with the application of model-based reasoning to tutoring systems for teaching high-school-level mathematics. It presents the current state of such a tutoring system ISAC that has been developed for this purpose. The shortcomings of the current system and the question of how model-based reasoning can be used to overcome this drawbacks is discussed. In particular we introduce a framework for handling the knowledge that has to be dealt with for this purpose.", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Ad2l-a programming language for model-based systems (preliminary report)\n", "abstract": " Model-based reasoning in general and model-based diagnosis (MBD) in particular has become a very important technique for providing solutions to real-world problems. However, modeling has become a problem making the use of MBD in companies difficult or even preventing it from being considered. Reasons are the lack of modeling principles and a general accepted language for modeling. In this paper we propose a programming language AD2L specially tailored for describing systems to be diagnosed. In addition, we discuss guidelines a modeling language should or even must fulfill, give some properties of the language, and an overview about further extensions increasing the applicability of AD2L.", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Guest-editorial special issue on industrial applications of model-based reasoning\n", "abstract": " Guest - Editorial Special Issue on Industrial Applications of Model-based Reasoning \u2014 Graz University of Technology Skip to main navigation Skip to search Skip to main content Graz University of Technology Logo English Deutsch Home Persons Research Units Research Outputs Projects Activities Prizes Press / Media Search by expertise, name or affiliation Guest - Editorial Special Issue on Industrial Applications of Model-based Reasoning Franz Wotawa, Markus Stumptner Institute of Software Technology (7160) Research output: Contribution to journal \u203a Article Overview Original language English Pages (from-to) ?-? Journal AI Communications Issue number 13(2) Publication status Published - 2000 Treatment code (N\u00e4here Zuordnung) Basic - Fundamental (Grundlagenforschung) Cite this APA Standard Harvard Vancouver Author BIBTEX RIS Wotawa, F., & Stumptner, M. (2000). Guest - Editorial Special Issue \u2026", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Detecting and locating faults in hardware designs\n", "abstract": " The state of the art in integrated circuit design is the use of special hardware description languages such as VHDL. Designs are programmed in VHDL and refined up to the point where the physical realization of the new circuit or board can be created automatically. Before that stage is reached, the designs are tested by simulating them and comparing their output to that prescribed by the specification. The task of circuit design therefore becomes primarily one of software development. A significant part of the design effort is taken up by detection of unacceptable deviations from this specification and the correction of such faults. This paper deals with the development of VHDLDIAG, a knowledge-based design aid for VHDL programs, with the goal of reducing time spent in fault detection and localization in very large designs (hundreds of thousands of lines of code). Size and variability of these programs makes it infeasible in practice to use techniques based on a detailed representation of program semantics. Instead, the functional topology of the program is derived from the source code. Model-based Diagnosis is then applied to find or at least focus in on the component (s) in the program that caused the behavioral divergence. The support given to the developer is sufficiently detailed to yield substantial reductions in the debugging costs when compared to the current manpower-intensive approach. A prototype is currently being tested as an integral part of the standard computer-aided VHDL development environment. Discrimination between diagnoses can be improved by use of multiple test cases (as well as interactive input by the developer).", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Computing Multi-Scenario Diagnoses\n", "abstract": " Deriving global diagnoses for observations from multiple scenarios is computationally challenging. In this paper, we propose with MSRC-Tree a diagnosis algorithm that considers all scenarios in a single search and compare it to the naive strategy of collecting conflicts for all individual scenarios first and deriving global diagnoses from them in a second step. For ISCAS85 circuits with up to 3 faults and up to twenty failed test cases, we could achieve a speed-up of up to two orders of magnitude, where MSRC-Tree offered better performance also on average and for most scenarios.", "num_citations": "3\n", "authors": ["1033"]}
{"title": "Intelligent Agents Diagnostics\u2014Enhancing Cyber\u2010Physical Systems with Self\u2010Diagnostic Capabilities\n", "abstract": " Allowing intelligent agents to deal with unforeseen situations that have not been considered during development in a smart way is a first step for increasing their autonomy. This requires diagnostic capabilities to detect the unforeseen situation and to identify a root cause that can be used afterward for carrying out repair and other compensating actions. Herein, foundations for diagnostic reasoning based on models of the system are provided. In particular, a diagnostic solution is presented that utilizes answer set solvers, which allow implementing non\u2010monotonic reasoning. The underlying ideas are introduced, an algorithm is discussed, and experimental results are obtained to clarify the question whether the approach can be used in practical applications. The obtained results indicate that answer set solving provides similar and sometimes even better results than specialized diagnosis algorithms, and can be used\u00a0\u2026", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Automatic Generation of Challenging Road Networks for ALKS Testing based on Bezier Curves and Search\n", "abstract": " In this paper, we outline an approach for automatic generation of challenging road networks for virtual testing of an automated lane keep system. Based on a set of control points, we construct a parametric curve that represents a road network, which defines the dynamic driving task an automated lane keep system equipped vehicle has to perform. Changing control points has global influence on the resulting road geometry. Our approach uses search to find a set of control points that results in a challenging road geometry, eventually forcing the vehicle to leave the intended path. We evaluated our approach in three different search-configurations regarding test efficiency and practical applicability for automatic virtual testing of an automated lane keep system.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "CatIO-A Framework for Model-Based Diagnosis of Cyber-Physical Systems\n", "abstract": " Diagnosing cyber-physical systems is often a challenge due to the complex interactions between its individual cyber and physical components. With CatIO (From \u2018Causarum Cognitio\u2019, Latin for \u201c(seek) knowledge of causes\u201d), we propose a framework that supports a designer in developing corresponding diagnostic solutions that utilize either abductive or consistency-based diagnosis for detecting and localizing faults at runtime. Employing an interface to tools of the modeling language Modelica, a designer is able to simulate a cyber-physical system\u2019s detailed behavior, and based on the observed data she can then assesses the diagnostic solution(s) under development and explore the trade-offs of individual solutions. For the abductive reasoning variant, CatIO supports also in coming up with the required abductive diagnosis model via an automated concept based on fault injection and the simulation of\u00a0\u2026", "num_citations": "2\n", "authors": ["1033"]}
{"title": "On the use of answer set programming for model-based diagnosis\n", "abstract": " Model-based diagnosis has been an active area of AI for several decades leading to many applications ranging from automotive to space. The underlying idea is to utilize a model of a system to localize faults in the system directly. Model-based diagnosis usually is implemented using theorem provers or constraint solvers combined with specialized diagnosis algorithms. In this paper, we contribute to research in model-based diagnosis and present a way of using answer set programming for computing diagnoses. In particular, we discuss a specific coding of diagnosis problems as answer set programs, and answer the research question whether answer set programming can be used for diagnosis in practice. For this purpose, we come up with an experimental study based on Boolean circuits comparing diagnosis using answer set programming with diagnosis based on a specialized diagnosis algorithm\u00a0\u2026", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Ontology-driven Security Testing of Web Applications\n", "abstract": " Vulnerabilities in existing software systems represent a great challenge for security assurance, where well known attacks like cross-site scripting (XSS) or SQL injections (SQLI) still represent a common threat for today's web applications. Failure to cover these issues in verification might result in unforeseen consequences for users of such software systems. For this reason, we have to come up with a rigorous testing approach should that should combine knowledge about common attacks and the system under test. Ontologies, which is a concept originating from philosophy and also considered in AI research, provide means for formalizing such knowledge from which we want to obtain test cases in an automated fashion. In this paper, we follow this idea and present a security testing approach that relies on ontologies of attacks and the system under test. In particular, the used ontology depicts information from the\u00a0\u2026", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Efficient Model-Based Diagnosis of Sequential Circuits\n", "abstract": " In Model-Based Diagnosis (MBD), we concern ourselves with the health and safety of physical and software systems. Although we often use different knowledge representations and algorithms, some tools like satisfiability (SAT) solvers and temporal logics, are used in both domains. In this paper we introduce Finite Trace Next Logic (FTNL) models of sequential circuits and propose an enhanced algorithm for computing minimal-cardinality diagnoses.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Crucial tool features for successful combinatorial input parameter testing in an industrial application\n", "abstract": " In this paper, we report on the use of available combinatorial testing tools on a large industrial object-oriented .N E T application to find out whether combinatorial testing methods are readily usable to perform combinatorial input parameter testing in an industrial setup. In particular, we applied CAmetrics and CCM to compute the combinatorial coverage of existing tests, and CAgen and ACTS to generate test suites from scratch. We identified shortcomings in some of the tools that may prevent them from being used in practice.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Planning-based Security Testing for Chatbots\n", "abstract": " Chatbots are of increasing importance in modern day communication between users and industrial applications. For example, providers of financial and medical institutions make use of intelligent agents in order to provide accessibility on a 24/7 basis. The human-like communication, often realized in an entertaining way, represents one of these advantages that chatbots offer. Eventually, chatbots make use of artificial intelligence methods in order to learn from past communication interactions, to provide better and more personalized responses. Often chatbots are deployed as part of web applications. As a consequence, this makes them vulnerable to typical security attacks on websites. Planning-based techniques can help to identify security leaks for common attack scenarios in a smart way. In this paper, we present such an approach that relies on artificial intelligence planning for security testing of chatbots that are accessible using web applications.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Software Configuration Diagnosis-A Survey of Existing Methods and Open Challenges.\n", "abstract": " As software systems become more complex and featurerich, configuration mechanisms are needed to adapt them to different execution environments and usage profiles. As a consequence, failures due to erroneous configuration settings are becoming more common, calling for effective mechanisms for diagnosis, repair, and prevention of such issues. In this paper, we survey approaches for diagnosing software configuration errors, methods for debugging these errors, and techniques for testing against such issues. In addition, we outline current challenges of isolating and fixing faults in configuration settings, including improving fault localization, handling the case of multi-stack systems, and configuration verification at runtime.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Improving Abductive Diagnosis Through Structural Features: A Meta-Approach.\n", "abstract": " While abductive reasoning provides an intuitive approach to diagnosis, its computational complexity remains an obstacle. Even though certain model representations are tractable, computing solutions for instances of reasonable size and complexity persists to pose a challenge. Hence, the discovery of efficient methods to derive abductive explanations presents itself as appealing research area. In this paper, we investigate the structural properties inherent to formalizations suitable for abductive failure localization. Based on the features extracted we construct a meta-approach exploiting a machine learning classifier to predict the abductive reasoning technique yielding the \u201cbest\u201d performance on a specific diagnosis scenario. To assess whether the proposed attributes are in fact sufficient for forecasting the appropriate abduction procedure and to evaluate the efficiency of our algorithm selection in comparison to traditional abductive reasoning approaches, we conducted an empirical experiment. The results obtained indicate that the trained model is capable of predicting the most efficient algorithm and further, we can show that the meta-approach is capable of outperforming each single abductive reasoning method investigated.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "KI 2016: Advances in Artificial Intelligence\n", "abstract": " This volume contains the conference proceedings of the 39th German Conference on Artificial Intelligence, KI 2016, which was held on September 26\u201330, 2016. Having started as German Workshop on AI (GWAI) in 1975, this annual event traditionally brings together academic and industrial researchers from all areas of AI, providing a highly regarded international forum for research on the foundations and applications of artificial intelligence systems and algorithms. This year, the conference took place in Klagenfurt, Austria, in conjunction with the Austrian Society for Artificial Intelligence (\u00d6GAI). Five workshops on specialized topics within Artificial Intelligence as well as the workshop on Current AI Research in Austria (CAIRA) were held on the first two days of the conference, followed by three days featuring the main technical program of the conference. The conference received 44 submissions from 18 countries\u00a0\u2026", "num_citations": "2\n", "authors": ["1033"]}
{"title": "On the practical performance of minimal hitting set algorithms from a diagnostic perspective\n", "abstract": " Minimal hitting sets (MHSs) meliorate our reasoning in many applications, including AI planning, CNF/DNF conversion, and program debugging. When following Reiter\u2019s\u201d theory of diagnosis from first principles\u201d, minimal hitting sets are also essential to the diagnosis problem, since diagnoses can be characterized as the minimal hitting sets of conflicts in the", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Testing Software and Systems\n", "abstract": " This volume contains the conference proceedings of the IFIP 28th International Conference on Testing Software and Systems, which was held October 17\u201319, 2016. The International Conference on Testing Software and Systems (ICTSS) addresses the conceptual, theoretic, and practical problems of testing software systems, including communication protocols, services, distributed platforms, middleware, embedded-and cyber-physical systems, and security infrastructures. ICTSS is the successor of previous (joint) conferences TESTCOM and FATES and aims to be a forum for researchers, developers, testers, and users to review, discuss, and learn about new approaches, concepts, theories, methodologies, tools, and experience in the field of testing communicating systems and software.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Parse tree structure in LTL requirements diagnosis\n", "abstract": " Automated assistance in ensuring a product's reliability and functional correctness is certainly a powerful asset, but also requires us to express our expectations in a formal way as accessible to our algorithms and tools. In recent work, we showed for specifications in Pnueli's \"Temporal Logic of Programs\" LTL how to diagnose such a specification if we find that it does not catch our intent, i.e., when some behavior expected to satisfy it actually violates it (and vice versa). In this paper, we show how to improve this process in that we exploit structural data in the form of a specification's parse tree for our diagnostic reasoning. We discuss the achieved effects for the example of the well-known model-based diagnosis algorithm HS-DAG and report on corresponding experimental results that show our reasoning's attractiveness.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Conflict management for constraint-based recommendation\n", "abstract": " Constraint-based recommendation systems are well-established in several domains like cars, computers, and financial services. Such recommendation tasks are based on sets of product constraints and customer preferences. Customer preferences reduce the number of products which are relevant for the customer. In scenarios like that it may happen that the set of customer preferences is inconsistent with the set of constraints in the recommendation system. In order to repair an inconsistency, the customer is informed about possible ways to adapt his/her preferences. There are different possibilities to present this information to the customer: a) via preferred diagnoses, b) via preferred conflicts, and c) via similar products. On the basis of the results of an empirical study we show that diagnoses, conflicts, and similar products are evaluated differently by users in terms of understandability, user satisfaction, and conflict resolution effort.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Retaining Consistency for Knowledge-based Security Testing\n", "abstract": " Testing of software and systems requires a set of inputs to the system under test as well as test oracles for checking the correctness of the obtained output. In this paper we focus on test oracles within the domain of security testing, which require consistent knowledge of security policies. Unfortunately, consistency of knowledge cannot always be ensured. Therefore, we strongly require a process of retaining consistencies in order to provide a test oracle. In this paper we focus on an automated approach for consistency handling that is based on the basic concepts and ideas of model-based diagnosis. Using a brief example, we discuss the underlying method and its application in the domain of security testing. The proposed algorithm guarantees to find one root cause of an inconsistency and is based on theorem proving.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Test case generation in practice for communicating embedded systems\n", "abstract": " The vastly growing complexity of software enabled functionality \u2013 especially in the automotive industry where it is usually distributed over a network \u2013 requires also a steadily increasing number of test cases to ensure a high product quality. The automatic generation of test cases can ease this situation, but suffers from the well-known state space explosion problem, which is caused by the often infinite number of possible execution paths. The state space can be minimized by rules applied to test case generation leading to an enhanced scalability. A flexible rule adjustment according to the model structure allows a tailored test case generation capable of being fast as well as complete according to a given goal. In this work the implications of such rules on the searching capabilities are studied. The analysis is performed on a symbolic test generation engine based on a network of timed, deterministic UML state\u00a0\u2026", "num_citations": "2\n", "authors": ["1033"]}
{"title": "On the use of constraints in dynamic slicing for program debugging\n", "abstract": " During the past decades research in automated debugging has led to several approaches. Some of them are based on structural and some of them on behavioral characteristics of the source code. The quality of the obtained results in terms of computed fault candidates compared to the overall number of statement usually is better when considering the program's behavior or even more sophisticated models representing the structure and the semantics of the program. However, for larger programs such approaches are not feasible and more light-weighted techniques have to be used in order to keep running time as small as possible. In this paper, we introduce an approach that combines dynamic slicing with constraint computation in order to increase the debugging quality while retaining small computational footprint. Using the presented approach it was possible to remove all fault candidates except the correct\u00a0\u2026", "num_citations": "2\n", "authors": ["1033"]}
{"title": "An abstract operational framework for dependence models in software debugging\n", "abstract": " In this article we introduce an abstract operational framework employing Aspect's notion of abstract dependences. We exemplify that this framework allows one for motivating certain desirable model properties in an intuitive and straightforward way. Moreover, we propose an algorithm that allows for obtaining a static program slice from an abstract execution trace. This computation resembles computing a dynamic slice for a certain test case, but unlike to a dynamic slice, does not suffer from error masking since it covers all possible executions. We show how to employ abstract dependences to determine those variables upon which computation of the slice is most beneficial. Moreover, we show how to best use the obtained static slices to compute diagnoses, that is - fault candidates, in terms of hitting sets.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Diagnosis-based reconfiguration using the MINION constraint solver\n", "abstract": " In this paper we tackle the challenge of reconfiguration, ie, finding system changes in order to get a new system that fulfills new requirements. We define the reconfiguration problem similar to the diagnosis problem and present a diagnosis algorithm that can be used to compute all minimal cardinality diagnoses, which are equivalent in our framework to solutions of the corresponding reconfiguration problem. The algorithm computes diagnoses directly from the model. Thus there is no need to compute conflicts and hitting sets. Moreover, we present a modeling language that allows for stating reconfiguration problems. Furthermore, the paper comprises a brief discussion on first empirical results obtained. The results indicate that the proposed approach is even feasible for diagnosing larger systems.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "From sketch to plan\n", "abstract": " One of the most important tasks in the RoboCup soccer leagues is to build up soccer domain knowledge for decision-making. Therefore, most RoboCup teams adapt tactics graphs to develop their agents\u2019 behavior manually. This is a very laborious and time-consuming job.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "A practical approach for the online diagnosis of industrial transportation systems\n", "abstract": " Model-based diagnosis enables the identification of minimal faulty component sets that explain encountered inconsistencies between a system's observed behavior and that of a \u201cgolden\u201d system model. In this paper, we present a compositional model for the (online-)diagnosis of transient faults (like malfunctioning transportation segments, sensor errors, misrouting, \u2026) in industrial transportation systems. Instead of analyzing flow parameters or modeling temporal behavior via finite state machines, we consider the temporal and logic constraints about a distributed item's progress separately, and at different abstraction levels. Initial results from an industrial facility show the applicability of our consistency-based diagnosis approach.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Challenging automatic test case generation tools with real world applications\n", "abstract": " This work presents results on applying recent advances in automatic test generation for Java programs based on Design-by-ContractTM specifications on two real world applications. It therefore extends an existing tool with both, already well-known approaches and the first time ever with a SMT solver. The results show that those fancy techniques do not matter since the most important challenge in this area is still generating test data that conform to their specification-at least as soon as it comes to real world applications.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Converting programs into constraint satisfaction problems\n", "abstract": " In this paper we introduce the basic methodology for analyzing and debugging programs. We first convert programs into their loop-free equivalents and from this into the static single assignment form. From the static single assignment form we derive a corresponding constraint satisfaction problem. The constraint representation can be directly used for debugging. From the corresponding hyper-tree representation of the constraint satisfaction problem we compute the hyper-tree width which characterizes the complexity of finding a solution for the constraint satisfaction problem. Since constraint satisfaction can be effectively used for diagnosis the conversion can be used for debugging and the obtained hyper-tree width is an indicator of the debugging complexity.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Collaboration of intelligent, autonomous systems: Situation aware behavior change\n", "abstract": " Random encounters of autonomous devices capable of inter-device communication open up the possibility for collaboration. Often times, however, a change of each device\u2019s behavior is needed in order to leverage synergies arising from co-location. We present an approach based on a knowledge base that is able to control a device in an isolated situation as well as during co-location with other devices. In both instances, control is done in a fault tolerant way. The algorithm is capable of smooth behavior transitions as well as behavior shifts where the behavior of the device changes abruptly, which can be seen as a change in strategy. The underlying knowledge base stores all possible behaviors of the device. We present an experiment that illustrates shifts in behavior as well as behavior changes in the context of internal faults.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Dependent failures in consistency-based diagnosis\n", "abstract": " Model-based diagnosis (MBD) approaches which follow the consistency-based diagnosis paradigm [3, 2] usually assume that components fail independently; ie, that any abnormal behavior of a component is the consequence of an internal fault. Although some researchers have acknowledged that components may fail dependently, there are very few works which have addressed this issue. In [5] we presented an approach for diagnosing dependent failures in the hardware-software hybrid system of a mobile autonomous robot, and in [4] we described a formalization of this approach. This paper proposes an improved technique for modeling failure dependencies. We formalize the semantics of our model, and we propose a troubleshooting strategy for systems with dependent failures. With the term dependent failure we denote cascades of failures which happen when a component, the cause of the cascade (CoC\u00a0\u2026", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Intelligent, fault tolerant control for autonomous systems\n", "abstract": " We present a methodology for intelligent control of an autonomous and resource constrained embedded system. Geared towards mastering permanent and transient faults by dynamic reconfiguration, our approach uses rules for describing device functionality, valid environmental interactions, and goals the system has to reach. Besides rules, we use functions that characterize a goal's target activity profile. The target activity profile controls the frequency our system uses to reach the corresponding goal. In the paper we discuss a first implementation of the given methodology, and introduce useful extensions. In order to underline the feasibility and effectiveness of the presented control system, we present a case study that has been carried out on a prototype system.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "AI-planning in a mobile autonomous robot with degraded software capabilities\n", "abstract": " Experience has shown that a major obstacle towards real autonomy of mobile robots is the occurrence of unexpected faults at runtime. While past research has mainly focused on the hardware, we have developed methods for the localization and repair of faulty software components at runtime. However, as it is often not possible to autonomously repair failed components, the deliberative layer of the control system should be aware of the lost capabilities of the system and adapt its decision-making. In this paper we present an AI-planning system for an autonomous soccer robot. We model the abstract capabilities of the control system, and we show how the planning system infers the available capabilities from the results obtained by the runtime diagnosis. We augment action preconditions with capability requirements, and we propose a method which allows to dynamically determine the sensing capabilities required for monitoring of plans.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Towards lightweight fault localization in procedural programs\n", "abstract": " In this paper we present a novel extension of a lightweight model for fault localization that allows for modeling procedural programs. The procedural programming paradigm is often used in (safety-critical) control software where a program\u2019s verification and subsequent fault localization is of utmost importance. In this article we present results from our recent case study relying on this kind of programs. Notably, our lightweight model is always able to localize the misbehavior\u2019s real cause.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Retaining consistency in temporal knowledge bases\n", "abstract": " Retaining consistency for large knowledge bases is a difficult task. This holds especially in the case where the knowledge base comprise temporal knowledge and where the knowledge comes from independent and unreliable sources. In this paper we propose the use of temporal logics, i.e., CTL, to describe the background theory and the corresponding Kripke Structure to store the temporal knowledge. Moreover, we introduce a declarative formalization of belief revision which is necessary to keep the knowledge base in a consistent state. Finally, we discuss how the structure of CTL formulas can be used to implement belief revision. The research described in the paper is motivated by a project that deals with automating the analysis of meetings, e.g., to provide meeting summaries, where cameras, microphones, and other sources of knowledge has to be integrated.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Binding environmental sciences and artificial intelligence\n", "abstract": " This special issue on Binding Environmental Sciences and Artificial Intelligence contains a number of seven papers selected from the Fourth ECAI-2004 Workshop on Binding Environmental Sciences and Artificial Intelligence (BESAI\u20192004) which was held on August 22, and 23, 2004, in Val\u00e8ncia, Spain. Previous workshops were held at Brighton (BESAI\u201998), Berlin (BESAI\u20192000), and Lyon (BESAI\u20192002), within the general ECAI conference. The purpose of the BESAI workshop series is to bring together researchers from environmental sciences and artificial intelligence to discuss open issues in the use of AI techniques for solving problems in the environmental domain, and to show the applicability of AI techniques in domains where a huge amount of data are available, and most information is vague and uncertain.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Towards a model for automated fault localization in VHDL designs: Exploring counterexample-Traces using a model-Based diagnosis approach\n", "abstract": " In this paper we discuss the exploration of a model checker\u2019s counterexample trace using model-based debugging techniques. We show that a diagnosis model obtained from a single counterexample run in an event-driven simulation is not appropriate for localizing a failures real cause in general. Notably, modeling VHDL\u2019s event and process semantics as originally defined hampers the integration of today\u2019s model checkers with our event-centered diagnosis approach considerably. Therefore, we propose a static but still event-centered and a data-driven approach for debugging hardware description languages. Both models do not exhibit the restrictions of the event-driven simulation approach with respect to integration of model checking tools.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Exploiting alias information to fault localization for Java programs\n", "abstract": " In software system it is still a challenging task to automatically extract program model by capturing properties to release the full potential of model-based software debugging. This paper introduces a new model which can be used by a model-based diagnosis engine to localize faults of Java programs. The proposed model is a qualitative model where values of variables are ignored, and it can reason at a higher level of abstraction by using dependency information and aliasing information. To show how it works, we discuss the compilation of Java programs to a constrained value-flow graph, and the mapping from the graph to its logical representation, which can be used by a model-based diagnosis engine. Indeed our experimental results suggest that our approach can achieve better diagnosis results.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Towards a framework for automated debugging: Abstracting the temporal behavior of VHDL-RTL programs\n", "abstract": " In this article we propose a formal framework that allows for a precise description of automated debugging of hardware designs. Unlike to previous work, that deals with localizing faults by considering the state of the system at a single point in time, we outline an approach that exploits the temporal behavior of hardware designs employing a standard diagnosis engine by unfolding the program with respect to time.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Modellbasierte Diagnose\u2014\u00dcberblick und technische Anwendung\n", "abstract": " Unter dem Begriff der modellbasierten Diagnose versteht man eine Familie von Methoden zur automatischen Fehlersuche in (meist) technischen Systemen. Im Unterschied zu den klassischen so genannten \u201cExpertensystem\u201d-Ans\u00e4tzen geht die modellbasierte Diagnose nicht von einer detaillierten und aufwendigen Auflistung aller m\u00f6glichen Fehlerf\u00e4lle aus, sondern beschreibt stattdessen das korrekte Verhalten des Systems. Diese Beschreibung erfolgt baukastenartig, so dass z. B. verschiedene Modelle konkreter Schaltkreise aus einer Menge von Komponentenbeschreibungen einfach zusammengesetzt werden k\u00f6nne. Wird ein Fehlverhalten beobachtet, so kann mit Hilfe problemunabh\u00e4ngiger L\u00f6sungsverfahren nach einer Menge von Komponenten gesucht werden, deren Schadhaftigkeit das Problem erkl\u00e4ren w\u00fcrde.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "MBD research activities at Vienna University of Technology\n", "abstract": " Over the past 10 years the Database and Expert-system Group of the Institut f\u00fcr Informationssysteme located at the TU Wien has done research in many subfields of AI, including Model-based Reasoning (MBR). Within MBR algorithms for consistency-based diagnosis [7, 3], abductive diagnosis [4], and the integration of repair into the diagnosis process [5, 6, 8] has been explored. In the last years research has focused on applying model-based diagnosis to software debugging [1]. This line of research was initiated by the DDV project funded by Siemens Austria. Section 2 gives an overview of the project and future research activities. Another direction of research includes the object-oriented design of diagnosis kernels, providing a language for defining new diagnosis components and complete diagnosis systems (see section 3). Motivated by this work, our group has spent effort on building new more efficient diagnosis algorithms which can be used also for very large systems (up to 10.000 components and more). See [17] for an algorithm for tree-structured diagnosis systems. Currently we are involved in a project with the aim of building scale-able diagnosis agents running on workstations, PCs, and personal digital assistants (PDAs), and are able to communicate diagnosis informations to each other. Section 4 gives an overview of this project.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Jade\u2013Java Diagnosis Experiments Status and Outlook\n", "abstract": " Model-based diagnosis is a successful AI technique for diagnosing physical systems but faces new challenges when applied to finding faults in software, ie, debugging. Previous work has mostly dealt with modeling the behavior of programming languages with exploitable special properties: logic, concurrent, or functional. In this paper we describe the objectives, the current state, and the addressed research issues of the Jade project. The aim of the project is to develope the theory and practice of applying model-based diagnosis to software debugging of object-oriented programs. The Java language has been chosen as a vehicle for the project due to its relatively simple semantics, its ubiquity (if not now, then in the near future), and its imperative and object-oriented characteristics.", "num_citations": "2\n", "authors": ["1033"]}
{"title": "Finding Critical Scenarios for Automated Driving Systems: A Systematic Literature Review\n", "abstract": " Scenario-based approaches have been receiving a huge amount of attention in research and engineering of automated driving systems. Due to the complexity and uncertainty of the driving environment, and the complexity of the driving task itself, the number of possible driving scenarios that an ADS or ADAS may encounter is virtually infinite. Therefore it is essential to be able to reason about the identification of scenarios and in particular critical ones that may impose unacceptable risk if not considered. Critical scenarios are particularly important to support design, verification and validation efforts, and as a basis for a safety case. In this paper, we present the results of a systematic literature review in the context of autonomous driving. The main contributions are: (i) introducing a comprehensive taxonomy for critical scenario identification methods; (ii) giving an overview of the state-of-the-art research based on the taxonomy encompassing 86 papers between 2017 and 2020; and (iii) identifying open issues and directions for further research. The provided taxonomy comprises three main perspectives encompassing the problem definition (the why), the solution (the methods to derive scenarios), and the assessment of the established scenarios. In addition, we discuss open research issues considering the perspectives of coverage, practicability, and scenario space explosion.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "CIMAX: collective information maximization in robotic swarms using local communication\n", "abstract": " Robotic swarms and mobile sensor networks are used for environmental monitoring in various domains and areas of operation. Especially in otherwise inaccessible environments, decentralized robotic swarms can be advantageous due to their high spatial resolution of measurements and resilience to failure of individuals in the swarm. However, such robotic swarms might need to be able to compensate misplacement during deployment or adapt to dynamical changes in the environment. Reaching a collective decision in a swarm with limited communication abilities without a central entity serving as decision-maker can be a challenging task. Here, we present the CIMAX algorithm for collective decision-making for maximizing the information gathered by the swarm as a whole. Agents negotiate based on their individual sensor readings and ultimately make a decision for collectively moving in a particular direction so\u00a0\u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Finding Critical Scenarios for Automated Driving Systems: The Data Extraction Form\n", "abstract": " Method: makes use of ontologies for describing the environment of autonomous vehicles and convert them to input models for combinatorial testing. The input model includes all the parameters and their representative values including their relations and constraints. The combinatorial test suite comprises abstract test cases that", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Mutation Testing for Artificial Neural Networks: An Empirical Evaluation\n", "abstract": " Testing AI-based systems and especially when they rely on machine learning is considered a challenging task. In this paper, we contribute to this challenge considering testing neural networks utilizing mutation testing. A former paper focused on applying mutation testing to the configuration of neural networks leading to the conclusion that mutation testing can be effectively used. In this paper, we discuss a substantially extended empirical evaluation where we considered different test data and the source code of neural network implementations. In particular, we discuss whether a mutated neural network can be distinguished from the original one after learning, only considering a test evaluation. Unfortunately, this is rarely the case leading to a low mutation score. As a consequence, we see that the testing method, which works well at the configuration level of a neural network, is not sufficient to test neural network\u00a0\u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Ontology-based Testing: An Emerging Paradigm for Modeling and Testing Systems and Software\n", "abstract": " Model-based testing has been successfully applied for test case generation in practice. Its underlying idea is to utilize models of the system for obtaining system inputs and their corresponding expected outputs. In this paper, we report on experiences gained when using a different methodology relying on models, i.e., ontology-based testing, for generating test suites in practice. Instead of modeling the system's behavior, ontology-based testing relies on models of the system's environment, i.e., an environmental ontology. Test cases are generated from ontologies converting them into an input model for combinatorial testing, and using a combinatorial testing algorithm for finally computing the test cases. We show how ontology-based testing can be applied in three different application domains, i.e., testing autonomous driving functionality, security testing, and compiler testing, discuss issues arising and indicate future\u00a0\u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "On Using Ontologies for Testing Compilers\n", "abstract": " Testing compilers requires coming up with textual input that can be parsed. Depending on the input the compiler may indicate an error, e.g., a lexical or a syntactical error, or may proceed converting the input to the output format. In this paper, we focus on the parsing functionality of a compiler and discuss an approach that is based on combinatorial testing for generating textual inputs. In particular, we make use of ontology-based testing, where we come up with an ontology describing potential inputs. Originally, ontology-based testing has been developed for testing safety-critical systems where the underlying idea was to use ontologies to describe the concepts of an environment of the system under test, and to use combinatorial testing for extracting critical scenarios based on these concepts. Making use of ontology-based testing for compilers extends the applicability of this testing method to the domain of compiler\u00a0\u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Machine learning for water supply supervision\n", "abstract": " In an industrial setting water supply systems can be complex. Constructing physical models for fault diagnosis or prediction requires extensive knowledge about the system\u2019s components and characteristics. Through advances in embedded computing, consumption meter data is often readily available. This data can be used to construct black box models that describe system behavior and highlight irregularities such as leakages. In this paper we discuss the application of artificial intelligence to the task of identifying irregular consumption patterns. We describe and evaluate data models based on neural networks and decision trees that were used for consumption prediction in buildings at the Graz University of Technology.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Extending Automated FLTL Test Oracles With Diagnostic Support\n", "abstract": " Testing is a versatile and in practice also dominant technique when it comes to verifying whether a system meets our expectations. After executing a test case, we use test oracles to judge whether the execution should be considered to have failed or passed. Fully automated oracles considering properties in temporal logics like FLTL allow us to derive such a verdict in a fully automated process. In this manuscript, we will show how to extend such an oracle with diagnostic support. In particular, drawing on model-based diagnosis (MBD), we will isolate exactly which parts of the property were violated for a failed test case. Such data are orthogonal to MBD focusing on the system itself and where we isolate faulty system components. With our diagnoses, we thus provide valuable information for the subsequent debugging and repair process in respect of how the test execution violated the property. We show that a\u00a0\u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "A rule-based smart control for fail-operational systems\n", "abstract": " When systems become smarter they have to cope with faults occurring during operation in an intelligent way. For example, an autonomous vehicle has to react appropriately in case of a fault occurring during driving on a highway in order to assure safety for passengers and other humans in its surrounding. Hence, there is a need for fail-operational systems that extend the concept of fail-safety. In this paper, we introduce a method that relies on rules for controlling a system. The rules specify the behavior of the system including behavioral redundancies. In addition, the method provides a runtime execution engine that selects the rules accordingly to reach a certain goal. In addition, we present a language and an implementation of the method and discuss its capabilities using a case study from the mobile robotics domain. In particular, we show how the rule-based fail-operational system can adapt to a fault\u00a0\u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Collective event detection using bio-inspired minimalistic communication in a swarm of underwater robots\n", "abstract": " Mobile sensor networks and robotic swarms are being used for monitoring and exploring environments or environmental events due to the advantages offered by their distributed nature. However, coordination and self-organization of a large number of individuals is often costly in terms of energy and computation power, thus limiting the longevity of the distributed system. In this paper we present a bio-inspired algorithm enabling a robotic swarm to collectively detect anomalies in environmental parameters in a self-organized, reliable and energy efficient manner. Individuals in the swarm communicate via 1-bit signals to collectively confirm the detection of an anomaly while minimizing energy spent for communication and taking measurements. This algorithm is specifically designed for a swarm of underwater robots called \u201caMussels\u201d to examine a phenomenon referred to as \u201canoxia\u201d which results in oxygen depletion\u00a0\u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "swarmfstaxis: Borrowing a swarm communication mechanism from fireflies and slime mold\n", "abstract": " One main motivation for studying swarm intelligence comes from observing the resilience of living systems in nature. Swarm intelligence has provided important inspirations for the engineering of technical systems. The swarmtaxis algorithm and the FSTaxis algorithm are swarm intelligent algorithms that aim to move a group of agents from a starting point to a predefined goal. The swarmtaxis algorithm bases its state transition on a voting like mechanism in which the agents count the number of \u201cpings\u201d they get from their surroundings. In contrast, the FSTaxis algorithm uses a scroll wave based communication mechanism inspired by slime mold and fireflies. The scroll wave based communication is expected to be more resilient than the voting like mechanism of the swarmtaxis algorithm. In this paper, we borrow the communication mechanism used in FSTaxis algorithm to improve the swarmtaxis algorithm. We\u00a0\u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "An Approach to Automatically Extract Predictive Properties from Nominal Attributes in Relational Databases\n", "abstract": " Feature engineering is a fundamental step in data mining and yet it is both difficult and expensive. Hand-crafting features is not only a time-consuming task that requires specific domain knowledge, it also may prevent new information to emerge. The extraction of meaningful features from relational data is particularly difficult due to complex relationships between tables. In the last decade there is an emerging trend towards automating the process of constructing propositional features from relational data and such approaches have been successfully used for solving numerous real-world problems. Despite their success, most of them lack an adequate support of nominal attributes. We present a new approach helping propositionalization methods to extract meaningful features from nominal attributes and improve their predictive performance. In an experimental evaluation on three datasets we demonstrate that the\u00a0\u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Quality assurance methodologies for automated driving\n", "abstract": " Fu\u0308r sicherheitskritische Systeme wie Autos, Zu\u0308ge oder Flugzeuge sind Methoden und Techniken zur Qualita\u0308tssicherung entscheidend, um den Schutz von Leib und Leben zu garantieren. Automatisiertes Fahren stellt eine neue Herausforderung fu\u0308r die Entwicklung und den Test von sicherheitskritischen Systemen dar. Dazu geho\u0308rt die Frage, wie sichergestellt werden kann, dass Systeme, die auf ku\u0308nstliche Intelligenz und maschinellen Lernen aufbauen, alle sicherheitskritischen Anforderungen, die wa\u0308hrend des Betriebs auftreten ko\u0308nnen, erfu\u0308llen. In diesem Beitrag stellen die Autoren zuna\u0308chst simulationsbasierte Verifikations-und Validierungsmethoden fu\u0308r sol-che Systeme vor und diskutieren anschlie\u00dfend zuku\u0308nftige Herausforderungen, die gelo\u0308st werden mu\u0308ssen, um automatisiertes Fahren in die Praxis umzusetzen, ohne die Sicherheitsanforderungen zu verletzten.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "On the automation of testing a logic-based diagnosis system\n", "abstract": " In this paper, we report on the introduction of test suites partially generated automatically for the reasoning core of a logic-based diagnosis system implemented in Java. We discuss why certain testing techniques like model-based testing can hardly be used for the application. We introduce the testing requirements comprising functional testing but also performance testing for identifying memory leaks. Furthermore, we discuss open challenges and needs for automating not only test suite execution but test suite generation.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Introduction to WOSPP: wave oriented swarm programming paradigm\n", "abstract": " In this work, we present a programming paradigm allowing the control of swarms with a minimum communication bandwidth in a simple manner, yet allowing the emergence of diverse complex behaviors and autonomy of the swarm. Communication in the proposed paradigm is based on single bit \u201cping\u201d-signals propagating as information-waves throughout the swarm. We show that even this minimum bandwidth communication between agents suffices for the design of a substantial set of behaviors in the domain of essential behaviors of a collective, including locomotion and self awareness of the swarm.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "On the Superiority of Conflict-Driven Search in MUS Enumeration.\n", "abstract": " The extraction of minimal unsatisfiable cores from an unsatisfiable set of constraints is a computationally hard problem that finds application in a variety of tasks such as model checking, configuration, or diagnosis. Domain-agnostic algorithms for online minimal unsatisfiable subset enumeration allow the computation of all conflicts and can be applied to any type of constraint system. We aim at extending this research by combining two well-known approaches from different research communities; on the one hand, we exploit the traversal of the power set as suggested by the MARCO algorithm in the domain of infeasibility analysis and on the other hand, we take advantage of the implicit exploration of the search space as proposed by HS-DAG in modelbased diagnosis. In particular, we show that the conflict-driven search utilized by HS-DAG renders MARCO\u2019s SAT calls unnecessary and given a certain problem structure a combination of both is advantageous in domains where consistency checks are expensive.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Wind Turbine Fault Localization: A Practical Application of Model-Based Diagnosis\n", "abstract": " Diagnosis of complex engineered systems such as wind turbines poses a challenging task involving fault detection, localization, and repair activities. Wind turbines are equipped with a large number of sensors tracking their operation and condition. Data is continuously transmitted to a central monitoring system, where it can be used to automatically detect deviations between the observed and expected behavior. Based on the revealed anomalies, appropriate actions may be taken to restore an operational state. Whereas fault detection has been automated to some extent, localization is still performed mostly manually based on the experience of the service staff. This is inefficient due to limitations in available human resources, lack of long-term learning, and a high potential for false positives. In this chapter, we introduce an application that supports the process of efficient fault identification. Besides exploring\u00a0\u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "A \u201cstrength of decision tree equivalence\u201d-taxonomy and its impact on test suite reduction\n", "abstract": " Being able to reduce test suites without having to execute them for assessing the effects on their fault detection capabilities is quite appealing. In this direction, we proposed recently to characterize test suites via inferred decision trees and use these for comparisons in a reduction process. The equivalence relation underlying the comparisons plays obviously a significant role for the effectiveness achieved and efficiency experienced. In this paper, we explore five such relations that take different aspects into account and investigate their impact on test suite reduction, their effectiveness in fault detection, and computation time. We report corresponding results, and show as well as prove that the equivalence relations build a taxonomy.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Results of a comparative study of code coverage tools in computer vision\n", "abstract": " The high quality of computer vision (CV) software has a great impact on the usability of the overall CV systems in real world scenarios. As the usage of standardized quality assurance methods, metrics and tools can ease the work of any CV developer and quickly improve the overall process, we report here on the introduction of code coverage analysis in the field. Our initial motivations were both to understand the available test coverage tools and to compare them in order to answer the questions of which test coverage tool to prefer in the area of CV software and whether we can introduce some specific evaluation criteria for identifying the right tool to be used within a CV project. The readers may use this study to help choose the right coverage testing tools for their needs and environment. This article is also valuable to those who are new to the practice and the art of software coverage testing, as it is generally the\u00a0\u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "An Automated (F) LTL Test Oracle for Testing with Requirements\n", "abstract": " Especially for safety-critical systems, we might want to express desired system properties in precise formal requirements. Verifying that a system then adheres to these requirements is obviously quite crucial. Complementing related methods like model checking or runtime monitors, for testing and most importantly debugging recognized problems, we would certainly be interested in automated test oracles for deriving program spectra. Such program spectra containing the details of the executions and the oracle's verdicts have been shown to be an effective reasoning basis for debugging purposes. In this paper, we show how to automatically derive such a test oracle via a special satisfiability encoding. In particular, we instantiate a dedicated SAT problem in conjunctive normal form directly from the requirements and a test case's execution data. As our experiments illustrate, our approach shows attractive performance\u00a0\u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Fireslime algorithm: Bio-inspired emergent gradient taxis\n", "abstract": " FireSlime Algorithm: Bio-Inspired Emergent Gradient Taxis \u2014 Graz University of Technology Skip to main navigation Skip to search Skip to main content Graz University of Technology Logo English Deutsch Home Persons Research Units Research Outputs Projects Activities Prizes Press / Media Search by expertise, name or affiliation FireSlime Algorithm: Bio-Inspired Emergent Gradient Taxis Joshua Cherian Varughese, Ronald Thenius, Franz Wotawa, Thomas Schmickl Institute of Software Technology (7160) Research output: Contribution to conference \u203a Paper Overview Fingerprint Abstract This article presents a novel bio-inspired emergent gradient taxis principle for robot swarms. The underlying communica- tion method was inspired by slime mold and fireflies. Nature showcases a number of simple organisms which can display complex behavior in various aspects of their lives such as sig- naling, foraging, \u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Exploiting Structural Metrics in FMEA-Based Abductive Diagnosis.\n", "abstract": " Exploiting Structural Metrics in FMEA-Based Abductive Diagnosis. \u2014 Technische Universit\u00e4t Graz Zur Hauptnavigation wechseln Zur Suche wechseln Zum Hauptinhalt wechseln Technische Universit\u00e4t Graz Logo English Deutsch Home Personen Forschungsgruppen Ver\u00f6ffentlichungen Projekte Verwandte T\u00e4tigkeiten Pr\u00e4mien Presseberichte Nach Expertise, Namen oder Zugeh\u00f6rigkeit suchen Exploiting Structural Metrics in FMEA-Based Abductive Diagnosis. Roxane Koitz, Franz Wotawa Institut f\u00fcr Softwaretechnologie (7160) Publikation: Beitrag in Buch/Bericht/Konferenzband \u203a Beitrag in einem Konferenzband \u00dcbersicht (Administrator/-in) Originalsprache englisch Titel Proceedings of the 27th International Workshop on Principles of Diagnosis (DX) Seiten 1-7 Seitenumfang 7 Publikationsstatus In Vorbereitung - 2016 Dieses zitieren APA Standard Harvard Vancouver Author BIBTEX RIS Koitz, R., & Wotawa, F. (\u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Analyzing the reduction of test suite redundancy\n", "abstract": " When testing complex products, one would certainly tend towards implementing an extensive test set in order to stimulate and evaluate the device under scrutiny to the best of one's knowledge. Test suite size is however also directly related to the time needed for its execution, and the related costs drawing on a project's budget. The motivation to keep test suites as small as possible but also achieve maximum effectiveness at identifying faults is thus certainly an obvious one. We focus on algorithms that for a given test suite remove those test eases redundant in terms of fault identification capabilities, with the aim of assuring that the resulting test suite still fulfills certain properties in respect of coverage or mutation scores.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Test suite coverage measurement and reporting for testing an operating system without instrumentation\n", "abstract": " Measuring the coverage of a test suite provides common metrics to assess the quality of a test suite. In safety-critical applications, as in the domains of avionics and automotive, complete coverage is required for certification. Usual approaches to measure the coverage require instrumentation of the source code or the object code of the system under test to obtain processable execution traces. However, instrumentation might change the behavior of the system under test. In this paper we show an approach to measure the coverage of a test suite and to generate human-readable reports without instrumentation of the system under test. As a system under test we use an operating system. Our approach is based on the execution traces obtained from an instrumented QEMU CPU emulator. We use this emulator to execute the operating system and the test cases. From the execution of the test cases we obtain execution traces. We provide a framework to map these execution traces back to the source code and to generate a detailed report exposing execution and branching (taken/not taken) information at the assembly language level and source code level.To evaluate our approach we generate coverage reports for the RTEMS real time operating system. We provide detailed coverage results for RTEMS running on different CPUs in this paper. Coverage of a test suite can be used by operating system developers to assess test suite quality and guide test case creation. Our approach is due to the lack of instrumentation of source code and object code broadly applicable for development of embedded systems applications.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Diagnosis of technical systems\n", "abstract": " Increasing complexity of technical systems requires a precise fault localization in order to reduce maintenance costs and system downtimes. Model-based diagnosis has been presented as a method to derive root causes for observed symptoms, utilizing a description of the system to be diagnosed. Practical applications of model-based diagnosis, however, are often prevented by the initial modeling task and computational complexity associated with diagnosis. In the proposed thesis, we investigate techniques addressing these issues. In particular, we utilize a mapping function which converts fault information available in practice into propositional horn logic sentences to be used in abductive model-based diagnosis. Further, we plan on devising algorithms which allow an efficient computation of explanations given the obtained models.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Maintaining constraint-based con-guration systems: Challenges ahead\n", "abstract": " Constraint-based configuration systems like knowledge-based recommendation and configuration are used in many difierent product areas such as cars, bikes, mobile phones, and computers. The development and maintenance of such systems is a time-consuming and error prone task be-cause the content of such systems and the responsible knowl-edge engineers are changing over time. Much research has been done to support knowledge engi-neers in their maintenance task. In this paper we give a short overview of previous research in the context of intelligent tech-niques to support the maintenance task and give an overview of future research aspects in this area. This paper focuses on intelligent simulation techniques for generating metrics, predicting boundary values for automated test case genera-tion, assignment-based (instead of constraint-based) anomaly management, and processes for the development of constraint-based configuration systems.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "iCone: intelligent environment for the Development and Maintenance of Configuration Knowledge bases\n", "abstract": " Constraint-based recommendation systems are used in many different domains like notebooks, cars, and mobile phones. Such systems describe product domains in sets of product and customer variables, their domains, and constraints which define the relationship between the variables. Maintenance is a crucial task in constraint-based recommendation systems, because it is time-consuming and error-prone. We implemented a new application called'iCone'(intelligent environment for the development and maintenance of configuration knowledge bases) to support knowledge engineers and their maintenance tasks. We present intelligent techniques like recommendation, anomaly management, dependency detection, and metrics to support knowledge engineers when maintaining constraint-based systems.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Using filtering to improve value-level debugging of verilog designs\n", "abstract": " In this article, we report on novel insights in model-based software debugging of hardware description languages (HDLs). Our debugging model allows one for exploiting failing and passing test cases by incorporating Ackermann constraints. This article reports on an empirical evaluation of the introduced models. The evaluation of our approach on the well-known ISCAS 89 benchmarks concerning single and dual-fault diagnoses clearly indicates that incorporating passing test cases into fault localization improves considerably the accuracy of the obtained diagnosis candidates.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Trust, But Verify\n", "abstract": " \"Trust, But Verify\" \u2014 Graz University of Technology Skip to main navigation Skip to search Skip to main content Graz University of Technology Logo English Deutsch Home Persons Research Units Research Outputs Projects Activities Prizes Press / Media Search by expertise, name or affiliation \"Trust, But Verify\" Franz Wotawa Institute of Software Technology (7160) Research output: Chapter in Book/Report/Conference proceeding \u203a Conference contribution Overview Original language English Title of host publication Ausgew\u00e4hlte Beitr\u00e4ge zur Anwenderkonferenz f\u00fcr Softwarequalit\u00e4t Test und Innovation Place of Publication Wien Publisher \u00d6sterreichische Computer Gesellschaft Pages 38-47 ISBN (Print) 978-3-85403-295-3 Publication status Published - 2013 Fields of Expertise Information, Communication & Computing Treatment code (N\u00e4here Zuordnung) Review Basic - Fundamental (Grundlagenforschung) Cite \u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Selective Belief Management for High-\u2010Level Robot Programs\n", "abstract": " Selective Belief Management for High-\u2010Level Robot Programs \u2014 Technische Universit\u00e4t Graz Zur Hauptnavigation wechseln Zur Suche wechseln Zum Hauptinhalt wechseln Technische Universit\u00e4t Graz Logo English Deutsch Home Personen Forschungsgruppen Ver\u00f6ffentlichungen Projekte Verwandte T\u00e4tigkeiten Pr\u00e4mien Presseberichte Nach Expertise, Namen oder Zugeh\u00f6rigkeit suchen Selective Belief Management for High-\u2010Level Robot Programs Siegfried Podesser, Gerald Steinbauer, Franz Wotawa Institut f\u00fcr Softwaretechnologie (7160) Publikation: Beitrag in Buch/Bericht/Konferenzband \u203a Beitrag in einem Konferenzband \u00dcbersicht (Administrator/-in) Projekte (1) Originalsprache englisch Titel International Workshop on Principles of Diagnosis Herausgeber (Verlag) . Publikationsstatus Angenommen/In Druck - 2012 Veranstaltung International Workshop on Principles of Diagnosis - Great Malvern, \u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "The IntiSa approach: Test Input Data Generation for Non-Primitive Data Types by means of SMT solver based Bounded Model Checking\n", "abstract": " In this paper we present an approach for automatically deriving test input data from Design by Contract specifications. Preconditions of a method under test (MUT) require specific object states of the input parameters. In this paper we present IntiSa, a novel approach, which calculates test input values to be used with mock objects. The calculated values do not only satisfy the precondition of the method under test, but are guaranteed to be states that could be reached through method calls on the object as well. This property is not supported by previous work, such as random or pure SMT based approaches, and genetic algorithm. But it is important since it reduces false positive test cases. Based on the idea of bounded-model checking, IntiSa encodes possible state space changes of method calls for all parameters of the MUT. This model is then verified against an adopted precondition of the MUT. Besides a detailed\u00a0\u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Evaluating the robustness of the perception-decision-execution cycle of autonomous robots\n", "abstract": " Reference: G. Steinbauer and F. Wotawa. Evaluating the Robustness of the Perception-Decision-Execution Cycle of Autonomous Robots. In ICAR Workshop on Performance Measures for Quantifying Safe and Reliable Operation of Professional Service Robots in Unstructured, Dynamic Environments, Tallinn, Estonia, 2011.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Constraint-based configuration of embedded automotive software\n", "abstract": " Adopting mass customisation approaches allows companies to build a variety of systems with a certain technical diversity. In the automotive industry thousands of variation points and configuration parameters need to be managed for engineering as well as production. Today we are aware of successful applications of configuration techniques in mass-volume production. However, the potential of variability management in engineering embedded automotive systems is recognised rather vaguely. In this paper, we apply configuration techniques for software deployment in the automotive domain. We discuss a simplified problem scenario, outline the used constraint-based model for software deployment, present a prototype implementation, and give first empirical results obtained from the prototype implementation of the constraint model.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Representing program debugging as constraint satisfaction problem\n", "abstract": " The SSA-form int power SSA (int a, int exp)1. int e 0= exp; 2. int res 0= 1; 3. bool cond 0=(e 0> 0); 4. int res 1= res 0* a; 5. int e 1= e 0-1; 6. bool cond 1= cond 0\u2227(e 1> 0); 7. int res 2= res 1* a; 8. int e 2= e 1-1; 9. int res 3= \u03a6 (res 2, res 1, cond 1); 10. int e 3= \u03a6 (e 2, e 1, cond 1); 11. int res 4= \u03a6 (res 3, res 0, cond 0); 12. int e 4= \u03a6 (e 3, e 0, cond 0);", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Test patterns for verilog design error localization\n", "abstract": " In this article we briefly state the idea behind model-based diagnosis and its application to debugging RTL (Register Transfer Level) Verilog designs. In providing a debugging model for the Verilog HDL (Hardware Description Language) we rely on a specific abstraction (trace semantics) that captures solely quiescent states of the design. In this vein we manage to overcome the inherent complexity issues of event-based Verilog without relying on specific fault models. To leverage test patterns for design error localization we propose the filtering approach and relate it to the concept of Ackermann constraints. Notably, our empirical results demonstrate that our novel technique considerably increases the diagnosis resolution even under presence of only a couple of test cases. The article outlines a case study comprising several circuits, where the proposed technique allowed one for excluding 95 per cent of the Verilog\u00a0\u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Rule-Set Extraction from C-Code\n", "abstract": " We present an approach for extracting knowledge from C source code ofcontrol programs. The extracted knowledge is intended to be used in our smartcontrol engine which takes a rule set and decides which rules to use based onthe internal and environmental conditions. The extraction of rules is based onthe control-flow graph of the supplied C program: Basically, our methodextracts rules that correspond to paths to given high-level function calls. Theadvantage of this method is to get a first knowledge-base from availablesource code which makes using a smart control engine more applicable forindustry. We use an industrial control program as example within the paper inorder to justify the usefulness of our approach.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Adding Fault Adaptive Control To Embedded Systems\n", "abstract": " Fault adaptive control is an indispensable element in the design of robust devices. Often, however, the question arises, whether it is possible to add fault adaptive control to existing devices with minimal additional costs. We report our experiences learned when integrating self reasoning capabilities with an industry supplied prototype embedded system. The self reasoning capabilities added to the device rely on a rule set that stores all possible behavior and includes information about unexpected faults, the number of times a certain rule was activated, and preferred behavior. At runtime the reasoning engine tries to find sequences of rules that transform the current system state to a goal state as specified in the rule set. We show how the rules that form the system model can be extracted from existing C code and discuss the immediate gain in robustness on the basis of a real hardware fault.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Automated Learning of Diagnosis Models for Component-Oriented Robot Control Software\n", "abstract": " Control software of autonomous mobile robots comprises a number of software modules which show very rich behaviors and interact in a very complex manner. These facts among others have a strong influence on the robustness of robot control software in the field. In this paper we present an approach which is able to automatically derive a model of the structure and the behavior of the communication within component-orientated control software. Such a model can be used for on-line model-based diagnosis in order to increase the robustness of the software by allowing the robot to autonomously cope with faults occurred during runtime. Due to the fact that the model is learned form recorded data and the use of the popular publisher-subscriber paradigm the approach can be applied to a wide range of complex and even partially unknown systems.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Diagnosing dependent failures in the context of consistency-based diagnosis\n", "abstract": " Consistency-based diagnosis approaches usually assume that components fail independently, ie, that any abnormal behavior of a component is the consequence of an internal fault. Dependent failures occur when the behavior of a faulty component causes the failure of other components as well. We provide a general discussion on dependent failures and the shortcomings of common model-based diagnosis approaches in systems with dependent failures. We propose a model which makes the dependencies between components explicit, and we provide algorithms for computing hypotheses which indicate the causal order of the failures.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Combining quantitative and qualitative models with active observations for better diagnoses of autonomous mobile robots\n", "abstract": " Quantitative and qualitative models and reasoning methods for diagnosis are able to cover a wide range of divers properties of a system. Both groups of methods have advantages and drawbacks in respect to fault diagnosis. In this paper we propose a framework which combines methods of both group to a combined diagnosis engine in order to improve the overall quality of diagnosis. Moreover, we present the different methods based on a running example of an autonomous mobile robots. Furthermore, we discuss the problems and research topics which arise from such a fusion of diverse methods. Finally, we explain how actively gathered observation are able to further improve the quality of diagnosis of complex systems.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Runtime race detection for multi-threaded C++ server applications\n", "abstract": " Multi-threaded programming is becoming more important, because physical limits prevent further speedup by increasing clock speed. Therefore, it is required to make use of multiple processors. Unfortunately, multi-threading is error-prone and hard to find defects arise with current popular programming languages, mainly data races and deadlocks. Therefore, tools that help finding these faults are important, but currently available tools are either difficult to use or do not scale well. This paper describes improvements to the Eraser algorithm for C++ applications resulting in a drastic reduction of false warnings. We present empirical results from our experiments with a server application comprising more than 500.000 lines of code.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Model-Based Reasoning For Fault-Tolerant Robot Hardware And Software\n", "abstract": " An autonomous mobile robot comprises a number of complex software and hardware modules and interactions between them. Because of this complexity there is always the possibility of faults at runtime even in the case of well-defined and rigorously executed design processes. If an autonomous robot is unable to automatically detect and repair such faults it tends to fail to finish its task. In this paper we present model-based reasoning techniques which enable a robot to perform such supervision tasks. We explain in detail the methods for software and hardware supervision. Finally, we present examples for the application of the methods to a real robot system.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "An introduction to model-based systems\n", "abstract": " In this paper, we first discuss how to define lines of demarcation between model-based systems and other disciplines that also use models. A brief overview of the main techniques and model types used in model-based reasoning then provide background information to introduce the articles selected for this special issue.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Model-Based Reasoning for Self-Repair of Autonomous Mobile Robots\n", "abstract": " Retaining functionality of a mobile robot in the presence of faults is of particular interest in autonomous robotics. From our experiences in robotics we know that hardware is one of the weak points in mobile robots. In this paper we present the foundations of a system that automatically monitors the driving device of a mobile robot. In case of a detected fault, e.g., a broken motor, the system automatically re-configures the robot in order to allow to reach a certain position. The described system is based on a generalized model of the motion hardware. The path-planner has only to change its behavior in case of a serious damage. The high-level control system remains the same. In the paper we present the model and the foundations of the diagnosis and re-configuration system.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "An object store model for diagnosing Java programs\n", "abstract": " During the last decade many intelligent debugging tools have been developed to assist users to detect program errors in a software system. The tools based on formal verification reveal counterexamples in case a given program violates the specified properties. However, these counterexamples do not allow to locate the root cause sufficiently. In order to bridge the gap between counterexamples and root causes of failure we introduce a new model for localizing program errors. The model we use keeps track on object relations arising during program execution on the given counterexample. We have used the approach to isolate the errors in several small Java programs.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Exploring object relations for automated fault localization\n", "abstract": " During the last decade formal verification has become very important not only in academia but also in industry, eg, for verifying hardware designs and device drivers. Program verification tools reveal counterexamples in case a given program violates the specified properties. However, these counterexamples do not allow to locate the root cause sufficiently. In order to bridge the gap between counterexamples and root causes of failure we introduce an automated approach to error localization. Our approach is based on a logical model of a program that keeps track on object relations arising during program execution on the given counterexample. We have used the approach to isolate the errors in several small Java programs to prove its principal applicability.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Challenges in runtime detecting and locating faults in autonomous mobile robots\n", "abstract": " In this paper we introduce the problems and challenges that are related to the model-based systems application area mobile and autonomous robotics. We describe the application area using one realworld example. Furthermore, we discuss a simple model for the problem domain which supports the localization process. We identify open problems, eg, the problem of self-repair and the required modeling, and challenges. One of the challenges is to provide models that allow to reason about other models in order to find appropriate actions for recovering from undesired behaviors.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Are Error Traces Enough for Automated Fault Localization in VHDL Designs?\n", "abstract": " Are Error Traces Enough for Automated Fault Localization in VHDL Designs? \u2014 Graz University of Technology Skip to main navigation Skip to search Skip to main content Graz University of Technology Logo English Deutsch Home Persons Research Units Research Outputs Projects Activities Prizes Press / Media Are Error Traces Enough for Automated Fault Localization in VHDL Designs? Franz Wotawa, Bernhard Peischl Institute of Software Technology (7160) Research output: Chapter in Book/Report/Conference proceeding \u203a Conference contribution \u203a Research \u203a peer-review Overview Original language English Title of host publication Workshop on Intelligent Solutions in Embedded Systems Publisher . Pages 49-60 Publication status Published - 2004 Event Workshop on Intelligent Solutions in Embedded Systems - Graz, Austria Duration: 25 Jun 2004 \u2192 25 Jun 2004 Conference Conference Workshop on \u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "DiKe\u2013a model\u2010based diagnosis kernel and its application\n", "abstract": " This paper describes the DiKe model\u2010based diagnosis framework, which incorporates multiple diagnosis engines, multiple user\u2010level system description languages, a theorem prover, and a graphical user interface to provide an integrated toolset for the development of model\u2010based diagnosis applications. The framework has been used for representing a number of application domains. We present the AD2L language, the main user language for the system geared towards use by non\u2010specialists, and discuss the use of DiKe in various domains.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Analysing models for software debugging\n", "abstract": " Analysing Models for Software Debugging \u2014 Technische Universit\u00e4t Graz Zur Hauptnavigation wechseln Zur Suche wechseln Zum Hauptinhalt wechseln Technische Universit\u00e4t Graz Logo English Deutsch Home Personen Forschungsgruppen Ver\u00f6ffentlichungen Projekte Verwandte T\u00e4tigkeiten Pr\u00e4mien Presseberichte Nach Expertise, Namen oder Zugeh\u00f6rigkeit suchen Analysing Models for Software Debugging Franz Wotawa, Markus Stumptner, Dominik Wieland Institut f\u00fcr Softwaretechnologie (7160) Publikation: Beitrag in Buch/Bericht/Konferenzband \u203a Beitrag in einem Konferenzband \u00dcbersicht (Administrator/-in) Originalsprache englisch Titel International Workshop on Principles of Diagnosis Herausgeber (Verlag) . Seiten ?-? Publikationsstatus Ver\u00f6ffentlicht - 2001 Treatment code (N\u00e4here Zuordnung) Basic - Fundamental (Grundlagenforschung) Dieses zitieren APA Standard Harvard Vancouver Author \u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Coupling CSP Decomposition and Diagnosis for Tree-Structured Systems\n", "abstract": " Decomposition methods are used to convert general constraint satisfaction problems into an equivalent tree-structured problem that can be solved more effectively. Recently, diagnosis algorithms for tree-structured systems have been introduced, but the prerequisites of coupling these algorithms to the outcome of decomposition methods have not been analyzed in detail, thus limiting their diagnostic applicability. In this paper we generalize the TREE* algorithm and show how to use hypertree decomposition outcomes as input to the algorithm to compute the diagnoses of a general diagnosis problem.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "A Value-Based Diagnosis Model for Java Programs\n", "abstract": " A key advantage of model-based diagnosis is the ability to use a generic model for the production of system descriptions that can be used to derive diagnoses for differently structured individual systems from a domain. This advantage is nowhere more apparent than in the software error diagnosis (or debugging) area, where given a model, system descriptions can be automatically derived from source code. However, effective models for diagnosing programs have so far been limited to special-purpose languages. We describe a value-based model for Java programs that enables us to explicitly deal with imperative program execution (including loop execution), and compare the outcome of our approach to the results obtained by using program slicing, a traditional technique from the software debugging community, and a simple dependencybased model for Java.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "An environment and language for industrial use of model-based diagnosis\n", "abstract": " Model-based diagnosis provides a well founded theory and a set of algorithms for finding and fixing a misbehavior caused by components. Actually applying model-based diagnosis effectively requires a flexible implementation which is capable of handling the differing requirements of multiple application domains. The diagnosis framework described in this paper has been developed for the purpose of being used in an industrial setting. It derives a significant part of its effectiveness from being integrated with a component oriented language for describing diagnosis models. The framework itself contains a class library comprising several different diagnosis engines having a standardized interface and allows rapid prototyping of diagnosis applications. The paper describes the framework, shows application domains, where the framework was applied, and gives an overview of the capability of the system description language AD2L.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "A communication language and the design of a diagnosis agent\u2013Towards a framework for mobile diagnosis agents\n", "abstract": " In this article we present a communication language and a design concept for a diagnosis agent. The communication language is divided in two Parts. One part contains primitives necessary to control and query the agent. The other provides constructs for formulating the structure and behavior of Systems to be diagnosed, and for observations determining the current state of the System. Additionally we give an overview of a WWW-based architecture for accessing an (diagnosis) agent\u2019s functionality. This approach is intended to make diagnosis tools accessible from todays WWW browsers.", "num_citations": "1\n", "authors": ["1033"]}
{"title": "DSA 2020\n", "abstract": " Steering Committee - IEEE Conference Publication Steering Committee Abstract: Provides a listing of current committee members and society officers. Published in: 2020 7th International Conference on Dependable Systems and Their Applications (DSA) Article #: Date of Conference: 28-29 Nov. 2020 Date Added to IEEE Xplore: 26 January 2021 ISBN Information: Electronic ISBN: 978-0-7381-2422-3 Print on Demand(PoD) ISBN: 978-0-7381-2423-0 INSPEC Accession Number: Persistent Link: https://xplorestaging.ieee.org/servlet/opac?punumber=9329443 More \u00bb Publisher: IEEE IEEE Account Change Username/Password Update Address Purchase Details Payment Options Order History View Purchased Documents Profile Information Communications Preferences Profession and Education Technical Interests Need Help? US & Canada: +1 800 678 4333 Worldwide: +1 732 981 0060 Contact & Support About \u2026", "num_citations": "1\n", "authors": ["1033"]}
{"title": "Foundations of Data and Knowledge-based Systems\n", "abstract": " Foundations of Data and Knowledge-based Systems Page 1 Foundations of Data and Knowledge-based Systems VO 181.031 (2h) Franz Wotawa Institut fur Informationssysteme, Database and Artificial Intelligence Group, Technische Universitat Wien Email: wotawa@dbai.tuwien.ac.at 1 Page 2 Goals ATMS/TMS \u2013 Theoretical foundations and al- gorithms Planning \u2013 Foundations (STRIPS planning) and Graphplan algorithm Diagnosis \u2013 Model-based diagnosis Solving practical problems using AI techniques Data and Knowledge-based Systems/99/00 2 Page 3 Motivation Concurrent statements Status information Source code Current design Design information VMBD Project NASA Deep Space One Software debuggging Automotive industrie (on-board, off-board diagnosis) NASA (Deep Space One) Monitoring of plants, technical devices, . . . Data and Knowledge-based Systems/99/00 3 Page 4 Contents/NMR From \u00a1\u2026", "num_citations": "1\n", "authors": ["1033"]}