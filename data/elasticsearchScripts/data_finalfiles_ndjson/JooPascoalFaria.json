{"title": "Reverse engineering of GUI models for testing\n", "abstract": " The incorrect behaviour of Graphical User Interfaces (GUIs) can compromise the effective use of the overall software application. One way to discover defects and increase the quality of GUIs is through testing. Test cases can be created manually or produced automatically from a model of the GUI. The size and complexity of GUIs makes it unpractical to do extensive manual testing. However, creating a model of the GUI in order to generate automatically test cases is also a laborious task. This paper presents a reverse engineering approach for diminishing the effort required for constructing the model of an existing GUI. The GUI is exercised by a combination of manual and automatic exploration, and information about its structure and some of its behaviour is automatically extracted, resulting in an incomplete GUI model. This model is subsequently completed manually, validated and used as input for automatic test\u00a0\u2026", "num_citations": "62\n", "authors": ["1364"]}
{"title": "Towards the Integration of Visual and Formal Models for GUI Testing\n", "abstract": " This paper presents an approach to diminish the effort required in GUI modelling and test coverage analysis within a model-based GUI testing process. A familiar visual notation a subset of UML with minor extensions is used to model the structure, behaviour and usage of GUIs at a high level of abstraction and to describe test adequacy criteria. The GUI visual model is translated automatically to a model-based formal specification language (e.g., Spec\u266f), hiding formal details from the testers. Then, additional behaviour may be added to the formal model to be used as a test oracle. The adequacy of the test cases generated automatically from the formal model is accessed based on the structural coverage of the UML behavioural diagrams.", "num_citations": "44\n", "authors": ["1364"]}
{"title": "Reverse engineered formal models for GUI testing\n", "abstract": " This paper describes a process to reverse engineer structural and behavioural formal models of a GUI application by a dynamic technique, mixing manual with automatic exploration. The goal is to diminish the effort required to construct the model and mapping information needed in a model-based GUI testing process. A skeleton of a state machine model of the GUI, represented in a formal pre/post specification language, is generated automatically by the exploration process. Mapping information between the model and the implementation is also generated along the way. The model extracted automatically is then completed manually in order to get an executable model which can be used as a test oracle. Abstract test cases, including expected outputs, can be generated automatically from the final model and executed over the GUI application, using the mapping information generated during the\u00a0\u2026", "num_citations": "42\n", "authors": ["1364"]}
{"title": "Automatic generation of user interface models and prototypes from domain and use case models\n", "abstract": " The model-driven automatic generation of interactive applications has been addressed by some research projects, but only few propose the model-to-model generation of a graphical user interface (UI). Existing solutions generate only part of the interactive application and most of them require as input the full specification of a UI model. This paper proposes an iterative and incremental approach that enables the modeler to generate a form-based executable prototype from the constructed models, favouring an evolutionary construction of models starting with a domain model, proceeding with an extended domain model and finally complementing it with a use case model. The approach derives a UI model from the previously referred models and allows its execution by generating an executable description of the UI in a XML-based UI description language, together with code for the specified logic and for persisting the data entities. The generated UI description may be further refined and supplemented with style definitions in order to obtain a final UI.", "num_citations": "40\n", "authors": ["1364"]}
{"title": "Dynamic reverse engineering of graphical user interfaces\n", "abstract": " This paper presents a dynamic reverse engineering approach and a tool, ReGUI, developed to reduce the effort of obtaining models of the structure and behaviour of a software applications Graphical User Interface (GUI). It describes, in more detail, the architecture of the REGUI tool, the process followed to extract information and the different types of models produced to represent such information. Each model describes different characteristics of the GUI. Besides graphical representations, which allow checking visually properties of the GUI, the tool also generates a textual model in Spec# to be used in the context of model based GUI testing and a Symbolic Model Verification model, which enables the verification of several properties expressed in computation tree logic. The models produced must be completed and validated in order to ensure that they faithfully describe the intended behaviour. This validation process may be performed by manually analysing the graphical models produced or automatically by proving properties, such as reachability, through model checking. A feasibility study is described to illustrate the overall approach, the tool and the results obtained.", "num_citations": "36\n", "authors": ["1364"]}
{"title": "A metamodel-based approach for automatic user interface generation\n", "abstract": " One of the advantages of following a MDA-based approach in the development of interactive applications is the possibility of generating multiple platform-specific user interfaces (UI) from the same platform independent UI model. However, the effort required to create the UI model may be significant. In the case of data-intensive applications, a large part of the UI structure and functionality is closely related with the structure and functionality of the domain entities described in the domain model, and the access rules specified in the use case model. This paper presents an approach to reduce the effort required to create platform independent UI models for data intensive applications, by automatically generating an initial UI model from domain and use case models. For that purpose, UML-aligned metamodels for domain and use case models are defined, together with a MOF-based metamodel for user interface\u00a0\u2026", "num_citations": "36\n", "authors": ["1364"]}
{"title": "Automated pattern-based testing of mobile applications\n", "abstract": " This paper presents an approach for testing mobile applications using reverse engineering and behavioural patterns. The goal of this research work is to ease the testing of mobile applications by automatically identifying and testing behaviour that is common in this type of applications, i.e., behaviour patterns. The approach includes a tool to automatically explore an Android application. This tool also identifies patterns in the behaviour of the application and apply tests previously associated with those patterns. The final results of this research work will be a catalogue of behavioural patterns and the tool which will output a report on the matched patterns and another one on the testing of those patterns.", "num_citations": "33\n", "authors": ["1364"]}
{"title": "Wiki based requirements documentation of generic software products\n", "abstract": " Organizations that develop generic software products, such as ERP or CRM products, and implement them in customers with varying needs, are faced with the problem of relating each customer requirements to the generic product requirements and characteristics, in a way that accelerates product implementation and supports product evolution decisions. To help attain these goals, we present a requirements documentation approach, comprising a documentation model and a XML and Wiki-based documentation infrastructure. The relationship above mentioned is established mainly via configuration parameters and associated configuration questions. Variability in the requirements and characteristics of the generic product is described based on the configuration parameters. The requirements of each implementation are described by answering the configuration questions and, when needed, by documenting variations to the base requirements and characteristics. Linking and viewing facilities support traceability analysis, instantiation of base requirements and characteristics for actual parameter values, and variability analysis among actual implementations.", "num_citations": "28\n", "authors": ["1364"]}
{"title": "Reverse engineering of graphical user interfaces\n", "abstract": " This paper describes a dynamic reverse engineering approach and the correspondent tool, ReGUI, developed to reduce the effort of obtaining visual and formal models of both the structure and the behaviour of a software application\u2019s graphical user interface.This paper describes the tool\u2019s architecture, the exploration process it follows, the outputs it generates and the rules used to generate a Spec# model, which can be used in the context of Model-Based Graphical User Interface Testing. The case study presents the results obtained by applying the tool to the Microsoft Notepad application.", "num_citations": "27\n", "authors": ["1364"]}
{"title": "Test coverage analysis of UML state machines\n", "abstract": " Software testing is a very important activity of the software development process. To expedite the testing process and improve the quality of the tests, models are increasingly used as a basis to derive test cases automatically - a technique known as model-based testing (MBT). Given a system model and a test suite derived automatically from the model or created by other process, the coverage of the model achieved by the test suite is important to assess the quality and completeness of the test suite early in the software development process. This paper presents a novel tool that shows visually the coverage achieved by a test suite on a UML state machine model. The tool receives as input a UML state machine model represented in XMI and a test suite represented in a XML format, and produces a colored UML state machine model that shows the coverage result. Model test coverage is determined by simulating the\u00a0\u2026", "num_citations": "24\n", "authors": ["1364"]}
{"title": "Specification-based testing of user interfaces\n", "abstract": " It is proposed an approach to integrate formal methods in the software development process, with an emphasis on the user interface development. The approach covers the specification by means of formal models, early model animation and validation, construction and conformity testing of the user interface implementation with respect to the specification. These conformity tests are described in detail through a state transition model with an abstraction function mapping concrete (implementation) to abstract (specification) states and operations. In order to illustrate the approach, it is presented a simple login/password dialog specification in VDM++, using a reusable control specification library, with a straightforward translation to Java or C#.", "num_citations": "23\n", "authors": ["1364"]}
{"title": "A reactive and model-based approach for developing internet-of-things systems\n", "abstract": " Software has a longstanding association with a state of crisis considering its success rate. The explosion of Internet-connected devices - Internet-of-Things - adds to the complexity of software systems. The particular characteristics of these systems, such as its large-scale and heterogeneity, pose increasingly new challenges. Model-based approaches have been widely used as a mechanism to abstract low-level programming details and processes. By using such approaches, and leveraging concepts as reactive design, visual notations, and live programming, we believe to be able to reduce the complexity of creating, operate/monitor and evolve such systems. The main objective of this Ph.D. is to delve into the software engineering practices for developing IoT systems and systems of systems, exploiting models as a suitable abstraction, expecting to reduce the complexity of managing most of the software\u00a0\u2026", "num_citations": "20\n", "authors": ["1364"]}
{"title": "A gap analysis methodology for the team software process\n", "abstract": " Over the years software quality is becoming more and more important in software engineering. Like in other engineering disciplines where quality is already a commodity, software engineering is moving into these stages. The Team Software Process (TSP) was created by the Software Engineering Institute (SEI) with the main objective of helping software engineers and teams to ensure high-quality software products and improve process management in the organization. This paper presents a methodology for assessing an organization against the TSP practices so that it is possible to assess the future gains and needs an organization will have during and after the implementation of TSP. The gap analysis methodology has two pillars in terms of data collection: interviews and documentation analysis. Questionnaires have been developed to guide the assessment team on the task of conducting interviews and further\u00a0\u2026", "num_citations": "20\n", "authors": ["1364"]}
{"title": "Visual self-healing modelling for reliable internet-of-things systems\n", "abstract": " Internet-of-Things systems are comprised of highly heterogeneous architectures, where different protocols, application stacks, integration services, and orchestration engines co-exist. As they permeate our everyday lives, more of them become safety-critical, increasing the need for making them testable and fault-tolerant, with minimal human intervention. In this paper, we present a set of self-healing extensions for Node-RED, a popular visual programming solution for IoT systems. These extensions add runtime verification mechanisms and self-healing capabilities via new reusable nodes, some of them leveraging meta-programming techniques. With them, we were able to implement self-modification of flows, empowering the system with self-monitoring and self-testing capabilities, that search for malfunctions, and take subsequent actions towards the maintenance of health and recovery. We tested these\u00a0\u2026", "num_citations": "19\n", "authors": ["1364"]}
{"title": "Test patterns for IoT\n", "abstract": " The Internet of Things (IoT) is expected to bring forward new promising solutions in various domains. Consequently, it can impact many aspects of everyday life, and errors can have serious consequences. Despite this, there is a lack of standard testing processes and methods, which poses a major challenge for IoT testing. Nonetheless, closer examination makes it possible to identify a set of recurring behaviors of IoT applications and a set of corresponding test strategies. This paper formalizes the notion of a Pattern-Based IoT Testing method for systematizing and automating the testing of IoT ecosystems. It consists in a set of test strategies for recurring behaviors of the IoT system, which can be defined as IoT Test Patterns.", "num_citations": "18\n", "authors": ["1364"]}
{"title": "GUI reverse engineering with machine learning\n", "abstract": " This paper proposes a new approach to reduce the effort of building formal models representative of the structure and behaviour of Graphical User Interfaces (GUI). The main goal is to automatically extract the GUI model with a dynamic reverse engineering process, consisting in an exploration phase, that extracts information by interacting with the GUI, and in a model generation phase that, making use of machine learning techniques, uses the extracted information of the first step to generate a state-machine model of the GUI, including guard conditions to remove ambiguity in transitions.", "num_citations": "18\n", "authors": ["1364"]}
{"title": "Izinto a pattern-based IoT testing framework\n", "abstract": " The emergence of Internet of Things (IoT) technology is expected to offer new promising solutions in various domains and, consequently, impact many aspects of everyday life. However, the development and testing of software applications and services for IoT systems encompasses several challenges that existing solutions have not yet properly addressed. Particularly, the difficulty to test IoT systems-due to their heterogeneous and distributed nature-, and the importance of testing in the development process give rise to the need for an efficient way to implement automated testing in IoT. Although there are already several tools that can be used in the testing of IoT systems, a number of issues can be pointed out, such as focusing on a specific platform, language, or standard, limiting the possibility of improvement or extension, and not providing out-of-the-box functionalities. This paper describes Izinto, a pattern-based\u00a0\u2026", "num_citations": "15\n", "authors": ["1364"]}
{"title": "A toolset for conformance testing against UML sequence diagrams based on event-driven colored Petri nets\n", "abstract": " Novel techniques and a toolset are presented for automatically testing the conformance of software implementations against partial behavioral models constituted by a set of parameterized UML sequence diagrams, describing both external interactions with users or client applications and internal interactions between objects in the system. Test code is automatically generated from the sequence diagrams and executed on the implementation under test, and test results and coverage information are presented back visually in the model. A runtime test library handles internal interaction checking, test stubs, and user interaction testing, taking advantage of aspect-oriented programming techniques. Incremental conformance checking is achieved by first translating sequence diagrams to Extended Petri Nets that combine the characteristics of Colored Petri Nets and Event-Driven Petri Nets.", "num_citations": "15\n", "authors": ["1364"]}
{"title": "Specification-driven unit test generation for java generic classes\n", "abstract": " Several approaches exist to automatically derive test cases that check the conformance of the implementation of abstract data types (ADTs) with respect to their specification. However, they lack support for the testing of implementations of ADTs defined by generic classes. In this paper, we present a novel technique to automatically derive, from specifications, unit test cases for Java generic classes that, in addition to the usual testing data, encompass implementations for the type parameters. The proposed technique relies on the use of Alloy Analyzer to find model instances for each test goal. JUnit test cases and Java implementations of the parameters are extracted from these model instances.", "num_citations": "15\n", "authors": ["1364"]}
{"title": "Adaptive object-modelling: Patterns, tools and applications\n", "abstract": " Adaptive object models, though a well-known architectural pattern, is seldomly used in software projects where, due to their nature, would highly benefit from it. Characteristics such as complexity, reduced literature and case-studies, lack of reusable framework components, and fundamental issues as those regarding runtime evolution, drive developers away. By overcoming these barriers with a set of patterns, tools and applications, and addressing pending research problems, adaptive object models can dramatically alter the way developers design their software. This paper presents a survey in the field, describes the preliminary contributions and outlines the ongoing doctoral work.", "num_citations": "15\n", "authors": ["1364"]}
{"title": "PSP PAIR: automated personal software process performance analysis and improvement recommendation\n", "abstract": " High-maturity software development processes, making intensive use of metrics and quantitative methods, such as the Personal Software Process (PSP) and the Team Software Process (TSP), can generate a significant amount of data that can be periodically analyzed to identify performance problems, determine their root causes and devise improvement actions. Currently, there are several tools that automate data collection and produce performance charts for manual analysis in the context of the PSP/TSP, but practically no tool support exists for automating the data analysis and the recommendation of improvement actions. Manual analysis of this performance data is problematic because of the large amount of data to analyze and the time and expertise required. Hence, we propose in this paper a performance model and a tool (named PSP PAIR) to automate the analysis of performance data produced in the\u00a0\u2026", "num_citations": "14\n", "authors": ["1364"]}
{"title": "Automatic model transformation from uml sequence diagrams to coloured petri nets\n", "abstract": " The dependence of our society on ever more complex software systems makes the task of testing and validating this software increasingly important and challenging. In many cases, multiple independent and heterogeneous systems form a system of systems responsible for providing services to users, and the current testing automation tools and techniques provide little support for the performance of this task.This dissertation is part of a larger scale project that aims to produce a Model-based Testing tool that will automate the process of testing distributed systems, from UML sequence diagrams. These diagrams graphically define the interaction between the different modules of a system and its actors in a sequential way, facilitating the understanding of the system's operation and allowing the definition of critical sections of distributed systems such as situations of concurrency and parallelism.This dissertation intends to develop one of the components of this project that will be in charge of the conversion of the descriptive diagrams of the system in Petri Nets. Petri Nets are a modeling formalism that is indicated for describing distributed systems by their ability to define communication and synchronization tasks, and by the possibility of executing them in runtime using tools such as CPN Tools.The objective will be to define Model-to-Model translation rules that will allow the conversion of models, in order to allow integration with the target system, taking advantage of existing model transformation frameworks (e.g. EMF - Eclipse Modeling Framework). With this, we have been able to hide the complexity of the system analysis to the user (Software Tester\u00a0\u2026", "num_citations": "13\n", "authors": ["1364"]}
{"title": "A survey on testing distributed and heterogeneous systems: The state of the practice\n", "abstract": " Distributed and heterogeneous systems (DHS), running over interconnected mobile and cloud-based platforms, are used in a growing number of domains for provisioning end-to-end services to users. Testing DHS is particularly important and challenging, with little support being provided by current tools. In order to assess the current state of the practice regarding the testing of DHS and identify opportunities and priorities for research and innovation initiatives, we conducted an exploratory survey that was responded by 147 software testing professionals that attended industry-oriented software testing conferences. The survey allowed us to assess the relevance of DHS in software testing practice, the most important features to be tested in DHS, the current status of test automation and tool sourcing for testing DHS, and the most desired features in test automation solutions for DHS. Some follow up interviews\u00a0\u2026", "num_citations": "13\n", "authors": ["1364"]}
{"title": "End-to-end automatic business process validation\n", "abstract": " Business Process Testing is the act of validating that end-to-end transactions through enterprise systems continue to work correctly as the underlying packaged applications evolve. End-to-end automatic business process validation can be a challenging task, but an important way to check that business rules continue to work properly and that problems are detected and corrected as soon as possible. This paper presents the design of a test automation platform, ETAP-Pro, to test end-to-end business processes that aims to overcome some challenges in validating business processes.", "num_citations": "12\n", "authors": ["1364"]}
{"title": "Test generation from UML sequence diagrams\n", "abstract": " Model-driven engineering approaches aim at avoiding productivity, model quality and model maintenance problems that arise when models are used for documentation only, by generating executable applications from models. However, in many cases, the level of detail of the models needed to generate complete applications is too much or only effective for specific domains. For those cases where it is not practical to build complete models and generate complete applications from them, we propose a lightweight approach, applicable at different levels (unit, integration and system testing), that combines partial application generation from structural models with test generation from partial behavioral models. To demonstrate the approach, we developed a plug-in that adds to the code generation capabilities of an existing UML modeling tool, the capability of generating executable tests from sequence diagrams acting\u00a0\u2026", "num_citations": "12\n", "authors": ["1364"]}
{"title": "ProcessPAIR: A tool for automated performance analysis and improvement recommendation in software development\n", "abstract": " High-maturity software development processes can generate significant amounts of data that can be periodically analyzed to identify performance problems, determine their root causes and devise improvement actions. However, conducting that analysis manually is challenging because of the potentially large amount of data to analyze and the effort and expertise required. In this paper, we present ProcessPAIR, a novel tool designed to help developers analyze their performance data with less effort, by automatically identifying and ranking performance problems and potential root causes, so that subsequent manual analysis for the identification of deeper causes and improvement actions can be properly focused. The analysis is based on performance models defined manually by process experts and calibrated automatically from the performance data of many developers. We also show how ProcessPAIR was\u00a0\u2026", "num_citations": "11\n", "authors": ["1364"]}
{"title": "A model for analyzing performance problems and root causes in the personal software process\n", "abstract": " High\u2010maturity software development processes, such as the Team Software Process and the accompanying Personal Software Process (PSP), can generate significant amounts of data that can be periodically analyzed to identify performance problems, determine their root causes, and devise improvement actions. However, there is a lack of tool support for automating that type of analysis, and hence diminish the manual effort and expert knowledge required. So, we propose in this paper a comprehensive performance model, addressing time estimation accuracy, quality, and productivity, to enable the automated (tool based) analysis of performance data produced by PSP developers, namely, identify and rank performance problems and their root causes. A PSP data set referring to more than 30\u2009000 projects was used to validate and calibrate the model. Copyright \u00a9 2015 John Wiley & Sons, Ltd.", "num_citations": "11\n", "authors": ["1364"]}
{"title": "Inferring user interface patterns from execution traces of web applications\n", "abstract": " This paper presents a dynamic reverse engineering approach to extract User Interface (UI) Patterns from existent Web Applications. Firstly, information related to user interaction is saved, in particular: user actions and parameters; the HTML source pages; and the URLs. Secondly, the collected information is analysed in order to calculate several metrics (e.g., the differences between subsequent HTML pages). Thirdly, the existent UI Patterns are inferred from the overall information calculated based on a set of heuristic rules. The overall reverse engineering approach is evaluated with some experiments over several public Web Applications.", "num_citations": "11\n", "authors": ["1364"]}
{"title": "Test Generation from Bounded Algebraic Specifications using Alloy.\n", "abstract": " Algebraic specification languages have been successfully used for the formal specification of abstract data types (ADTs) and software components, and there are several approaches to automatically derive test cases that check the conformity between the implementation and the algebraic specification of a software component. However, existing approaches do not assure the coverage of conditional axioms and conditions embedded in complex axioms. In this paper, we present a novel approach and a tool to automatically derive test cases from bounded algebraic specifications of ADTs, assuring axiom coverage and of all minterms in its full disjunctive normal form (FDNF). The algebraic specification is first translated into the Alloy modelling language, and the Alloy Analyzer tool is used to find model instances for each test goal (axiom and minterm to cover), from which test cases in JUnit are extracted.", "num_citations": "11\n", "authors": ["1364"]}
{"title": "A testing and certification methodology for an open ambient-assisted living ecosystem\n", "abstract": " To cope with the needs raised by the demographic changes in our society, several Ambient-Assisted Living (AAL) technologies have emerged in recent years, but those \u2018first offers' are often monolithic, incompatible and thus expensive and potentially not sustainable. The AAL4ALL project aims at improving that situation through the development of an open ecosystem of interoperable AAL components (products and services), tied together by an integration infrastructure, comprising a message-queue based service bus and gateways bridging the communication with devices. To that end, the project encompasses the specification of interfaces and requirements for interoperable components, against which candidates can be tested and certified before entering the ecosystem. This paper proposes a testing and certification methodology for such an ecosystem. Besides fulfilling specified pre-requisites, candidate\u00a0\u2026", "num_citations": "10\n", "authors": ["1364"]}
{"title": "Towards real-time patient prioritization in hospital emergency services\n", "abstract": " Industrial cyber-physical systems are becoming increasingly popular and starting to emerge as a response to society's problems using the Internet of Things to create real-time solutions capable of analyzing large amounts of data. In this article, taking advantage of this type of technology, we present a patient prioritization system for hospital emergency services. Our system responds to the problems that occur in hospitals when there is a peak in the number of people using the emergency service, increasing the waiting times. In such a situation, the clinical condition of waiting patients may change after the initial triage, requiring immediate care or at least their re-prioritization. The proposed system consists of a combination of a Smart Priority Recommendation and Patient Control System and an Hospital Emergency Smart Band placed in each patient, allowing to detect changes in the vital signs of waiting patients that\u00a0\u2026", "num_citations": "9\n", "authors": ["1364"]}
{"title": "Towards decentralized conformance checking in model-based testing of distributed systems\n", "abstract": " In a growing number of domains, the provisioning of end-to-end services to the users depends on the proper interoperation of multiple products, forming a new distributed system. To ensure interoperability and the integrity of this new distributed system, it is important to conduct integration tests that verify not only the interactions with the environment but also the interactions between the system components. Integration test scenarios for that purpose may be conveniently specified by means of UML sequence diagrams, possibly allowing multiple execution paths. The automation of such integration tests requires that test components are also distributed, with a local tester deployed close to each system component, and a central tester coordinating the local testers. In such a test architecture, it is important to minimize the communication overhead during test execution. Hence, in this paper we investigate conditions upon\u00a0\u2026", "num_citations": "9\n", "authors": ["1364"]}
{"title": "A model for analyzing estimation, productivity, and quality performance in the personal software process\n", "abstract": " High-maturity software development processes, making intensive use of metrics and quantitative methods, such as the Team Software Process (TSP) and the accompanying Personal Software Process (PSP), can generate a significant amount of data that can be periodically analyzed to identify performance problems, determine their root causes and devise improvement actions. However, there is a lack of tool support for automating the data analysis and the recommendation of improvement actions, and hence diminish the manual effort and expert knowledge required. So, we propose in this paper a comprehensive performance model, addressing time estimation accuracy, quality and productivity, to enable the automated (tool based) analysis of performance data produced in the context of the PSP, namely, identify performance problems and their root causes, and subsequently recommend improvement actions\u00a0\u2026", "num_citations": "9\n", "authors": ["1364"]}
{"title": "Adaptive Object-Models: a Research Roadmap\n", "abstract": " The Adaptive Object-Model (AOM) is a metaarchitectural pattern of systems that expose an high-degree of runtime adaptability of their domain. Despite there being a class of software projects that would directly benefit by being built as AOMs, their usage is still very scarce. To address this topic, a wide scope of concepts surrounding to Adaptive Object-Models need to be understood, such as the role of incompleteness in software, and its effects on system variability and adaptability, as well as existing metamodeling and metaprogramming techniques and how do they relate to software construction. The inherent complexity, reduced literature and case-studies, lack of reusable framework components, and fundamental issues as those regarding evolution, frequently drive developers (and researchers) away from this topic. In this work, we provide an extensive review of the state-of-the-art in AOM, as well as a roadmap for empirical validation of research in this area, which underlying principles have the potential to alter the way software systems are perceived and designed.", "num_citations": "9\n", "authors": ["1364"]}
{"title": "Automatic Generation of Interactive Prototypes for Domain Model Validation.\n", "abstract": " This paper presents an approach to domain models validation with customers, end users and other stakeholders. From an early system model that represents the main domain (or business) entities in a UML class diagram, with classes, relationships, attributes and constraints, it is automatically generated an interactive form-based application prototype supporting the basic CRUD operations (create, retrieve, update and delete). The generated form-based user interface provides some features that are derived from the model\u2019s constraints and increase the prototype usability. This prototype allows the early validation of core system models, and can also be used as a basis for subsequent developments. The prototype generation process follows a model-driven development approach: the domain model, conforming to a defined domain meta-model, is first transformed to an application model, conforming to a defined application meta-model, based on a set of transformation rules; then a generator for a specific platform produces the executable files (currently, XUL and RDF files).", "num_citations": "9\n", "authors": ["1364"]}
{"title": "Inferring ui patterns with inductive logic programming\n", "abstract": " This paper presents an approach to infer UI patterns existent in a web application. This reverse engineering process is performed in two steps. First, execution traces are collected from user interactions using the Selenium software. Second, the existing UI patterns within those traces are identified using Machine Learning inference with the Aleph ILP system. The paper describes and illustrates the proposed methodology on a case study over the Amazon web site.", "num_citations": "8\n", "authors": ["1364"]}
{"title": "Propostas de melhoria da seguran\u00e7a dos sistemas de informa\u00e7\u00e3o cl\u00ednica em Portugal\n", "abstract": " Com vista \u00e0 melhoria dos cuidados de sa\u00fade prestados ao cidad\u00e3o, assiste-se ao crescente registo e circula\u00e7\u00e3o de informa\u00e7\u00e3o cl\u00ednica em formato electr\u00f3nico. Este facto traz consigo preocupa\u00e7\u00f5es acrescidas com a seguran\u00e7a e privacidade dessa informa\u00e7\u00e3o. Da an\u00e1lise da situa\u00e7\u00e3o actual nos sistemas de informa\u00e7\u00e3o cl\u00ednica do Servi\u00e7o Nacional de Sa\u00fade (SNS) em Portugal, ressaltam um conjunto de fragilidades, que podem ser minoradas se as propostas de melhoria da seguran\u00e7a, aqui apresentadas, for acolhido. Defende-se, nomeadamente, a implementa\u00e7\u00e3o de uma infra-estrutura de chaves p\u00fablicas (PKI) e a defini\u00e7\u00e3o de uma pol\u00edtica de seguran\u00e7a concertada ao n\u00edvel das institui\u00e7\u00f5es ligadas ao SNS, em conformidade com as normais internacionais existentes.", "num_citations": "8\n", "authors": ["1364"]}
{"title": "An approach for automated scenario-based testing of distributed and heterogeneous systems\n", "abstract": " The growing dependence of our society on increasingly complex software systems, makes software testing ever more important and challenging. In many domains, such as healthcare and transportation, several independent systems, forming a heterogeneous and distributed system of systems, are involved in the provisioning of end-to-end services to users. However, existing testing techniques, namely in the model-based testing field, provide little tool support for properly testing such systems. Hence, in this paper, we propose an approach and a toolset architecture for automating the testing of end-to-end services in distributed and heterogeneous systems. The tester interacts with a visual modeling frontend to describe key behavioral scenarios, invoke test generation and execution, and visualize test results and coverage information back in the model. The visual modeling notation is converted to a formal notation\u00a0\u2026", "num_citations": "7\n", "authors": ["1364"]}
{"title": "Automated Specification-based Testing of Interactive Components with AsmL.\n", "abstract": " It is presented a promising approach to test interactive components, supporting the automatic generation of test cases from a specification. The relevance and difficulties (issues and challenges) associated with the testing of interactive components are first presented. It is shown that a formal specification with certain characteristics allows the automatic generation of test cases while solving some of the issues presented. The approach is illustrated with an example of automatic testing of the conformity between the implementation of a button, in the. Net framework, and a specification, written in the AsmL language, using the AsmL Tester tool.", "num_citations": "7\n", "authors": ["1364"]}
{"title": "Helping software engineering students analyzing their performance data: tool support in an educational environment\n", "abstract": " Process PAIR is a novel tool for automating the performance analysis of software developers. Based on a performance model calibrated from the performance data of many developers, it automatically identifies and ranks potential performance problems and root causes of individual developers. We present the results of a controlled experiment involving 61 software engineering master students, half of whom used ProcessPAIR in a performance analysis assignment. The results show significant benefits in terms of students' satisfaction (average score of 4.78 out of 5 for ProcessPAIR users, against 3.81 for other users), quality of the analysis outcomes (average grades achieved of 88.1 out of 100 for ProcessPAIR users, against 82.5 for other users), and time required to do the analysis (average of 252 min for ProcessPAIR users, against 262 min for other users, but with much room for improvement).", "num_citations": "6\n", "authors": ["1364"]}
{"title": "A testing and certification methodology for an Ambient-Assisted Living ecosystem\n", "abstract": " To cope with the needs raised by the demographic changes in our society, several Ambient-Assisted Living (AAL) technologies have emerged in recent years, but those `first offers' are often monolithic, incompatible and thus expensive and potentially not sustainable. The AAL4ALL project aims at improving that situation through the development of an open ecosystem of interoperable products and services for AAL, tied together via an integration infrastructure. To that end, the project encompasses the specification of a set of reference models and requirements for interoperable products and services, against which candidate products and services can be tested and certified, and subsequently integrated as components of the ecosystem. This paper proposes a testing and certification methodology for such an ecosystem.", "num_citations": "6\n", "authors": ["1364"]}
{"title": "Auditing e-voting pilot processes and systems at the elections for the European Parliament and for the Portuguese Parliament\n", "abstract": " Auditing e-Voting pilot processes and systems at the elections for the European Parliament and for the Portuguese Parliament - Dialnet Ayuda \u00bfEn qu\u00e9 podemos ayudarle? \u00d7 Buscar en la ayuda Buscar Consultar la ayuda \u00bfEn qu\u00e9 podemos ayudarle? \u00d7 Buscar en la ayuda Buscar Consultar la ayuda Ir al contenido Dialnet Buscar Revistas Tesis Congresos Ayuda Auditing e-Voting pilot processes and systems at the elections for the European Parliament and for the Portuguese Parliament Jo\u00e3o Falc\u00e3o [1] ; Jo\u00e3o Pascoal Faria [1] ; M\u00e1rio Jorge Leit\u00e3o [1] ; Ant\u00f3nio Pimenta [1] ; Maria Ant\u00f3nia Carravilla [1] 1.[1] Universidade do Porto Localizaci\u00f3n: E-voting: the last electoral revolution / coord. por Josep Mar\u00eda Reniu, Jordi Barrat i Esteve, 2008, ISBN 978-84-608-0728-5, p\u00e1gs. 93-114 Idioma: ingl\u00e9s Texto completo no disponible (Saber m\u00e1s ...) Fundaci\u00f3n Dialnet Acceso de usuarios registrados Imagen de identificaci\u00f3n \u2026", "num_citations": "6\n", "authors": ["1364"]}
{"title": "Assisting software engineering students in analyzing their performance in software development\n", "abstract": " Collecting product and process measures in software development projects, particularly in education and training environments, is important as a basis for assessing current performance and opportunities for improvement. However, analyzing the collected data manually is challenging because of the expertise required, the lack of benchmarks for comparison, the amount of data to analyze, and the time required to do the analysis. ProcessPAIR is a novel tool for automated performance analysis and improvement recommendation; based on a performance model calibrated from the performance data of many developers, it automatically identifies and ranks potential performance problems and root causes of individual developers. In education and training environments, it increases students\u2019 autonomy and reduces instructors\u2019 effort in grading and feedback. In this article, we present the results of a controlled\u00a0\u2026", "num_citations": "5\n", "authors": ["1364"]}
{"title": "Automated testing of distributed and heterogeneous systems based on UML sequence diagrams\n", "abstract": " The growing dependence of our society on increasingly complex software systems makes software testing ever more important and challenging. In many domains, several independent systems, forming a distributed and heterogeneous system of systems, are involved in the provisioning of end-to-end services to users. However, existing test automation techniques provide little tool support for properly testing such systems. Hence, we propose an approach and toolset architecture for automating the testing of end-to-end services in distributed and heterogeneous systems, comprising a visual modeling environment, a test execution engine, and a distributed test monitoring and control infrastructure. The only manual activity required is the description of the participants and behavior of the services under test with UML sequence diagrams, which are translated to extended Petri nets for efficient test input\u00a0\u2026", "num_citations": "4\n", "authors": ["1364"]}
{"title": "Techniques and toolset for conformance testing against UML sequence diagrams\n", "abstract": " Novel techniques and a toolset are presented for automatically testing the conformance of software implementations against partial behavioral models constituted by a set of parameterized UML sequence diagrams (SDs), describing both external and internal interactions. Test code is automatically generated from the SDs and executed on the Java implementation under test, and test results and coverage information are presented back visually in the model. A runtime test library handles internal interaction checking, test stubs, and user interaction testing. Incremental conformance checking is achieved by first translating SDs to non-deterministic acceptance automata with parallelism.", "num_citations": "4\n", "authors": ["1364"]}
{"title": "Test coverage analysis of uml activity diagrams for interactive systems\n", "abstract": " User interface testing is a very important but time consuming activity. To automate and systematize the testing process, models can be used to derive test cases automatically-a technique known as model-based testing. Given a model representing the intended system behavior and a test suite derived from the model or produced manually, the coverage of the test suite over the model is an important early indicator of the quality and completeness of the test suite. This paper presents a novel tool that shows visually the coverage achieved by a test suite over an UML model of an interactive system. This model is based on activity and class diagrams, with special user interface modeling features (stereotypes and keywords) inspired in Concur Task Trees and Canonical Abstract Prototypes. The tool receives a UML model file and a test suite, determines the model coverage by simulating the execution of the test suite over\u00a0\u2026", "num_citations": "4\n", "authors": ["1364"]}
{"title": "A Methodology for Auditing e-Voting Processes and Systems used at the Elections for the Portuguese Parliament.\n", "abstract": " In the 2005 Portuguese Parliament General Elections there were non-valid experiments of e-voting at five voting places and also through the", "num_citations": "4\n", "authors": ["1364"]}
{"title": "A survey of blockchain frameworks and applications\n", "abstract": " The applications of the blockchain technology are still being discovered. When a new potential disruptive technology emerges, there is a tendency to try to solve every problem with that technology. However, it is still necessary to determine what approach is the best for each type of application. To find how distributed ledgers solve existing problems, this study looks for blockchain frameworks in the academic world. Identifying the existing frameworks can demonstrate where the interest in the technology exists and where it can be missing. This study encountered several blockchain frameworks in development. However, there are few references to operational needs, testing, and deploy of the technology. With the widespread use of the technology, either integrating with pre-existing solutions, replacing legacy systems, or new implementations, the need for testing, deploying, exploration, and maintenance is\u00a0\u2026", "num_citations": "3\n", "authors": ["1364"]}
{"title": "A model-based approach for product testing and certification in digital ecosystems\n", "abstract": " In a growing number of domains, such as ambient-assisted living (AAL) and e-health, the provisioning of end-to-end services to the users depends on the proper interoperation of multiple products from different vendors, forming a digital ecosystem. To ensure interoperability and the integrity of the ecosystem, it is important that candidate products are independently tested and certified against applicable interoperability requirements. Based on the experience acquired in the AAL4ALL project, we propose in this paper a model-based approach to systematize, automate and increase the assurance of such testing and certification activities. The approach encompasses the construction of several models: a feature model, an interface model, a product model, and unit and integration test models. The abstract syntax and consistency rules of these models are specified by means of metamodels written in UML and Alloy and\u00a0\u2026", "num_citations": "3\n", "authors": ["1364"]}
{"title": "Empirical evaluation of the ProcessPAIR tool for automated performance analysis\n", "abstract": " Software development processes can generate significant amounts of data that can be periodically analyzed to identify performance problems, determine their root causes and devise improvement actions. However, conducting that analysis manually is challenging because of the potentially large amount of data to analyze and the effort and expertise required. ProcessPAIR is a novel tool designed to help developers analyze their performance data with less effort, by automatically identifying and ranking performance problems and potential root causes. The analysis is based on performance models derived from the performance data of a large community of developers. In this paper, we present the results of an experiment conducted in the context of Personal Software Process (PSP) training, to show that ProcessPAIR is able to accurately identify and rank performance problems and potential root causes of individual developers so that subsequent manual analysis for the identification of deeper causes and improvement actions can be properly focused.", "num_citations": "3\n", "authors": ["1364"]}
{"title": "Factors affecting personal software development productivity: a case study with PSP data\n", "abstract": " Understanding the factors that affect the productivity of software developers and may cause productivity variations among individuals and projects is important for anyone interested in improving software engineering performance and estimates, and in particular for users of high-maturity processes, such as the Personal Software Process (PSP) and the Team Software Process (TSP). In order to contribute to the understanding of the personal and non-personal factors that affect productivity, we analyzed the data from more than 3000 developers that concluded successfully the 10 projects of the PSP for Engineers I/II training course. Regarding non-personal factors, by conducting a detailed per-phase analysis, we found significant variations of productivity among projects that can be partially explained by process changes. Regarding personal factors, we found significant variations among individuals that can be partially\u00a0\u2026", "num_citations": "3\n", "authors": ["1364"]}
{"title": "Reverse Engineering of GUI Models\n", "abstract": " Today's software systems usually feature Graphical User Interfaces (GUIs). GUIs are an important part of today\u2019s software and their correct execution is a very important requirement in order to ensure the legitimacy of the overall application. They are an important factor in the user\u2019s decisions to use or not the system.To ensure their correct execution, it is necessary to perform GUI tests. However, this is a difficult, extremely time-consuming, and costly activity, with a very few tools and techniques to aid in the testing process. One way to find defects in GUIs is to test them by executing test cases and verifying the execution outputs.", "num_citations": "3\n", "authors": ["1364"]}
{"title": "A review of Management Tools for OpenSimulator\n", "abstract": " To host OpenSimulator virtual world servers at educational institutions, system administrators find at their disposal a diversity of web-based management systems with different sets of features. To support the selection among current management tools and provide a baseline from which to identify subsequent development needs, we installed and evaluated 4 of these systems (WiFi pages, OSMW, MWI and jOpenSim), analysing and comparing their features. WiFi pages only provides account-management features. MWI has mostly the same features, but also provides systems administrators with the option of creating their own management website. OSMW has account-management and maintenance features, such as log management and editing of configuration files. jOpenSim provides features for account and event management and feature for generating some actions within virtual world, such as broadcasting a message to all regions. From matching the identified features with the literature-reported requirements for virtual world deployment at educational organizations, we conclude that there is no management tool that fulfils all the functional requirements reported in the literature and, therefore, that the adoption of current tools by system administrators will always requires manually performing some of the administrative tasks. We therefore call for development of novel, more encompassing administrative tools for OpenSimulator virtual worlds.", "num_citations": "2\n", "authors": ["1364"]}
{"title": "Mt4a: a no-programming test automation framework for android applications\n", "abstract": " The growing dependency of our society on increasingly complex software systems, combining mobile and cloud-based applications and services, makes the test activities even more important and challenging. However, sometimes software tests are not properly performed due to tight deadlines, due to the time and skills required to develop and execute the tests or because the developers are too optimistic about possible faults in their own code. Although there are several frameworks for mobile test automation, they usually require programming skills or complex configuration steps. Hence, in this paper, we propose a framework that allows creating and executing tests for Android applications without requiring programming skills. It is possible to create automated tests based on a set of pre-defined actions and it is also possible to inject data into device sensors. An experiment with programmers and non\u00a0\u2026", "num_citations": "2\n", "authors": ["1364"]}
{"title": "Towards the Online Testing of Distributed and Heterogeneous Systems with Extended Petri Nets\n", "abstract": " The growing dependence of our society on increasingly complex software systems makes software testing ever more important and challenging. In many domains, such as healthcare and transportation, several independent systems, forming a heterogeneous and distributed system of systems, are involved in the provisioning of end-to-end services to users. However, existing testing techniques, namely in the model-based testing field, provide little support for properly testing such systems. To bridge the gaps identified in the state of the art we intend to develop a research work where the main goal is to significantly reduce the cost of testing distributed and heterogeneous systems, from the standpoint of time, resources and expertise required, as compared to existing approaches. For that, we propose a preliminary approach and a toolset architecture for automating the testing of end-to-end services in distributed and\u00a0\u2026", "num_citations": "2\n", "authors": ["1364"]}
{"title": "Testing distributed and heterogeneous systems: State of the practice\n", "abstract": " In a growing number of domains, such as health-care and transportation, several independent systems, forming a heterogeneous and distributed system of systems, are involved in the provisioning of end-to-end services to users. Testing such systems, running over interconnected mobile and cloud-based platforms, is particularly important and challenging, with little support being provided by current tools. In order to assess the current state of the practice regarding the testing of distributed and heterogeneous systems (DHS) and identify opportunities and priorities for research and innovation initiatives, we conducted an exploratory survey that was responded by 147 software testing professionals that attended industry-oriented software testing conferences, and present the main results in this paper. The survey allowed us to assess the relevance of DHS in software testing practice, the most important features to be tested in DHS, the current status of test automation and tool sourcing for testing DHS, and the most desired features in test automation solutions for DHS. We expect that the results presented in the paper are of interest to researchers, tool vendors and service providers in this field.", "num_citations": "2\n", "authors": ["1364"]}
{"title": "An analysis of Monte Carlo simulations for forecasting software projects\n", "abstract": " Forecasts of the effort or delivery date can play an important role in managing software projects, but the estimates provided by development teams are often inaccurate and time-consuming to produce. This is not surprising given the uncertainty that underlies this activity. This work studies the use of Monte Carlo simulations for generating forecasts based on project historical data. We have designed and run experiments comparing these forecasts against what happened in practice and to estimates provided by developers, when available. Comparisons were made based on the mean magnitude of relative error (MMRE). We did also analyze how the forecasting accuracy varies with the amount of work to be forecasted and the amount of historical data used. To minimize the requirements on input data, delivery date forecasts for a set of user stories were computed based on takt time of past stories (time elapsed\u00a0\u2026", "num_citations": "1\n", "authors": ["1364"]}
{"title": "An Analysis of the State of the Art of Machine Learning for Risk Assessment in Software Projects\n", "abstract": " Risk management is one of the ten knowledge areas discussed in the Project Management Body of Knowledge (PMBOK), which serves as a guide that should be followed to increase the chances of project success. The popularity of research regarding the application of risk management in software projects has been consistently growing in recent years, particularly with the application of machine learning techniques to help identify risk levels or risk factors of a project before the project development begins, with the intent of improving the likelihood of success of software projects. This paper provides an overview of various concepts related to risk and risk management in software projects, including traditional techniques used to identify and control risks in software projects, as well as machine learning techniques and methods which have been applied to provide better estimates and classification of the risk levels\u00a0\u2026", "num_citations": "1\n", "authors": ["1364"]}
{"title": "DCO Analyzer: Local controllability and observability analysis and enforcement of distributed test scenarios\n", "abstract": " To ensure interoperability and the correct behavior of heterogeneous distributed systems in key scenarios, it is important to conduct automated integration tests, based on distributed test components (called local testers) that are deployed close to the system components to simulate inputs from the environment and monitor the interactions with the environment and other system components. We say that a distributed test scenario is locally controllable and locally observable if test inputs can be decided locally and conformance errors can be detected locally by the local testers, without the need for exchanging coordination messages between the test components during test execution (which may reduce the responsiveness and fault detection capability of the test harness). DCO Analyzer is the first tool that checks if distributed test scenarios specified by means of UML sequence diagrams exhibit those properties, and\u00a0\u2026", "num_citations": "1\n", "authors": ["1364"]}
{"title": "WebProcessPAIR: recommendation system for software process improvement\n", "abstract": " ProcessPAIR is a novel tool for helping software developers analyzing their personal performance. Based on a performance model calibrated from the anonymized performance data of many developers and the performance data submitted by an individual developer, it automatically identifies and ranks potential performance problems and their root causes for that developer. In this work we present WebProcessPAIR, which extends ProcessPAIR with the ability to recommend improvement actions to address the root causes identified, based on a crowdsourcing approach. A case study illustrates WebProcessPAIR usage.", "num_citations": "1\n", "authors": ["1364"]}
{"title": "M\u00e9todos Formais na Especifica\u00e7\u00e3o de Interfaces com o Utilizador: a Linguagem VDM++ e o Tratamento de Eventos\n", "abstract": " M\u00e9todos Formais na Especifica\u00e7\u00e3o de Interfaces com o Utilizador: a Linguagem VDM++ e o Tratamento de Eventos", "num_citations": "1\n", "authors": ["1364"]}
{"title": "UML Checker: Formal Specification of the Conformance Relation\n", "abstract": " This technical report presents the formal specification of the conformance relation underlying the UML Checker toolset. The toolset supports the automatic testing of an implementation with respect to a behavior specification constituted by a set of so-called test-ready sequence diagrams. An informal characterization of test-ready sequence diagrams and their meaning for conformance testing purposes was already presented in [1].The goal of the conformance relation is to define which execution traces obey a behavior specification defined by means of a test-ready sequence diagram. In other words, the conformance relation defines, in set-theoretic terms, the semantics of a test-ready sequence diagram, in terms of allowed execution traces.", "num_citations": "1\n", "authors": ["1364"]}
{"title": "UML Checker: Formal Specification in VDM++ of the Petri Net-based Conformance Checking Engine\n", "abstract": " This document contains a formal specification of the conformance checking engine of the UML Checker toolset based on Extended Petri Nets presented in our paper\u200e[4]. The specification is written in VDM++\u200e[2]. This documented (RTF version) can be executed with the VDM++ Toolbox.", "num_citations": "1\n", "authors": ["1364"]}
{"title": "Data-driven Active Rules for the Maintenance of Derived Data and Integrity Constraints in User Interfaces to Databases\n", "abstract": " It is presented an approach based on data-driven active rules for the maintenance of derived data (calculated data) and integrity constraints (data restrictions) in screen forms and other user interfaces to databases. The approach aims to improve the capabilities of current application development tools, by combining the power of active rules, as proposed in the context of active databases, with the simplicity and datadriven nature of spreadsheets. The proposed data-driven active rules define derived data items as functions of other data items, by explicitly reading and writing their values, conditionally or unconditionally. They are defined essentially as unordered action-only rules with implicit triggering events, and are executed essentially as ordered (prioritized) event-action (EA) rules, possibly in combination with other event-action (EA) or eventcondition-action (ECA) rules originated from different sources. The specialized nature of the actions performed by these rules allows the automatic determination of the triggering events and priorities among rules, as well as the establishment of improved conditions on rule sets that guarantee termination and confluence (determinism) of rule execution. The maintenance of integrity constraints is essentially reduced to the maintenance of derived data. The approach presented is not tied to a particular rule definition language or data model.", "num_citations": "1\n", "authors": ["1364"]}
{"title": "Faculdade de Engenharia da Universidade do Porto\n", "abstract": " Requirements defects are one of the common causes of failures and requirements defects are amongst the most common types of defects. The classification of the defects of the requirements specifications allows the analysis of their root causes; supports the creation of checklists to improve requirements reviews; and reduces risks associated with requirements. Other researchers used different taxonomies to classify requirements\u2019 defects but, to the best of our knowledge, none of them tested the quality properties of the defect classifiers list. We performed a literature review to assemble a list of classifiers applicable to requirements defects, following the recommendations of other authors. To demonstrate that the list had all the properties of a good classification scheme, we tested it in a couple of experiments involving students with knowledge of requirements engineering. The assembled list of classifiers is not orthogonal and we suspect that no defects classifiers list is. In the light of our observations we give recommendations to industry and other researchers on the design of experiments and treatment of classification results.", "num_citations": "1\n", "authors": ["1364"]}