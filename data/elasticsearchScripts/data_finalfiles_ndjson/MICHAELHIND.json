{"title": "Pointer analysis: Haven't we solved this problem yet?\n", "abstract": " During the past twenty-one years, over seventy-five papers and nine Ph. D. theses have been published on pointer analysis. Given the tomes of work on this topic one may wonder,\u201cHaven'trdquo; we solved this problem yet?''With input from many researchers in the field, this paper describes issues related to pointer analysis and remaining open problems.", "num_citations": "777\n", "authors": ["282"]}
{"title": "AI Fairness 360: An extensible toolkit for detecting, understanding, and mitigating unwanted algorithmic bias\n", "abstract": " Fairness is an increasingly important concern as machine learning models are used to support decision making in high-stakes applications such as mortgage lending, hiring, and prison sentencing. This paper introduces a new open source Python toolkit for algorithmic fairness, AI Fairness 360 (AIF360), released under an Apache v2.0 license {https://github.com/ibm/aif360). The main objectives of this toolkit are to help facilitate the transition of fairness research algorithms to use in an industrial setting and to provide a common framework for fairness researchers to share and evaluate algorithms. The package includes a comprehensive set of fairness metrics for datasets and models, explanations for these metrics, and algorithms to mitigate bias in datasets and models. It also includes an interactive Web experience (https://aif360.mybluemix.net) that provides a gentle introduction to the concepts and capabilities for line-of-business users, as well as extensive documentation, usage guidance, and industry-specific tutorials to enable data scientists and practitioners to incorporate the most appropriate tool for their problem into their work products. The architecture of the package has been engineered to conform to a standard paradigm used in data science, thereby further improving usability for practitioners. Such architectural design and abstractions enable researchers and developers to extend the toolkit with their new algorithms and improvements, and to use it for performance benchmarking. A built-in testing infrastructure maintains code quality.", "num_citations": "420\n", "authors": ["282"]}
{"title": "Which pointer analysis should I use?\n", "abstract": " During the past two decades many different pointer analysis algorithms have been published. Although some descriptions include measurements of the effectiveness of the algorithm, qualitative comparisons among algorithms are difficult because of varying infrastructure, benchmarks, and performance metrics. Without such comparisons it is not only difficult for an implementor to determine which pointer analysis is appropriate for their application, but also for a researcher to know which algorithms should be used as a basis for future advances.", "num_citations": "262\n", "authors": ["282"]}
{"title": "Vertical profiling: understanding the behavior of object-priented applications\n", "abstract": " Object-oriented programming languages provide a rich set of features that provide significant software engineering benefits. The increased productivity provided by these features comes at a justifiable cost in a more sophisticated runtime system whose responsibility is to implement these features efficiently. However, the virtualization introduced by this sophistication provides a significant challenge to understanding complete system performance, not found in traditionally compiled languages, such as C or C++. Thus, understanding system performance of such a system requires profiling that spans all levels of the execution stack, such as the hardware, operating system, virtual machine, and application.", "num_citations": "168\n", "authors": ["282"]}
{"title": "One explanation does not fit all: A toolkit and taxonomy of ai explainability techniques\n", "abstract": " As artificial intelligence and machine learning algorithms make further inroads into society, calls are increasing from multiple stakeholders for these algorithms to explain their outputs. At the same time, these stakeholders, whether they be affected citizens, government regulators, domain experts, or system developers, present different requirements for explanations. Toward addressing these needs, we introduce AI Explainability 360 (http://aix360.mybluemix.net/), an open-source software toolkit featuring eight diverse and state-of-the-art explainability methods and two evaluation metrics. Equally important, we provide a taxonomy to help entities requiring explanations to navigate the space of explanation methods, not only those in the toolkit but also in the broader literature on explainability. For data scientists and other users of the toolkit, we have implemented an extensible software architecture that organizes methods according to their place in the AI modeling pipeline. We also discuss enhancements to bring research innovations closer to consumers of explanations, ranging from simplified, more accessible versions of algorithms, to tutorials and an interactive web demo to introduce AI explainability to different audiences and application domains. Together, our toolkit and taxonomy can help identify gaps where more explainability methods are needed and provide a platform to incorporate them as they are developed.", "num_citations": "130\n", "authors": ["282"]}
{"title": "Using Hardware Performance Monitors to Understand the Behavior of Java Applications.\n", "abstract": " Modern Java programs, such as middleware and application servers, include many complex software components. Improving the performance of these Java applications requires a better understanding of the interactions between the application, virtual machine, operating system, and architecture. Hardware performance monitors, which are available on most modern processors, provide facilities to obtain detailed performance measurements of long-running applications in real time. However, interpreting the data collected using hardware performance monitors is difficult because of the low-level nature of the data.", "num_citations": "121\n", "authors": ["282"]}
{"title": "Assessing the effects of flow-sensitivity on pointer alias analyses\n", "abstract": " This paper describes an empirical comparison of four contextinsensitive pointer alias analysis algorithms that use varying degrees of flow-sensitivity: a flow-insensitive algorithm that tracks variables whose addresses were taken and stored; a flow-insensitive algorithm that computes a solution for each function; a variant of this algorithm that uses precomputed kill information; and a flow-sensitive algorithm. In addition to contrasting the precision and efficiency of these analyses, we describe implementation techniques and quantify their analysis-time speed-up.", "num_citations": "112\n", "authors": ["282"]}
{"title": "Automatic generation of DAG parallelism\n", "abstract": " We present an algorithm for automatically generating a nested, fork-join parallel program from a sequential program represented in terms of control and data dependences. This algorithm embodies two techniques for dealing with data dependences: the first implicitly satisfies such dependences by reducing parallelism, and the second eliminates some dependences by introducing private variables. This algorithm has been implemented in the PTRAN system [ABC* 87]. Previous work on automatic generation of parallelism focused on vectorization, relying on a datadependence-based and loop-based representation as input [Kuc78][Wo182][AK87]. This work is welldeveloped and includes automatic generation of synchronization for loop iterations [Mid86]. Previous work has applied privatization in the form of scalar expansion for vectorization [Wo178]. Other work has fully renamed a program so as to obviate\u00a0\u2026", "num_citations": "79\n", "authors": ["282"]}
{"title": "Understanding the connectivity of heap objects\n", "abstract": " Modern garbage collectors partition the set of heap objects to achieve the best performance. For example, generational garbage collectors partition objects by age and focus their efforts on the youngest objects. Partitioning by age works well for many programs because younger objects usually have short lifetimes and thus garbage collection of young objects is often able to free up many objects. However, generational garbage collectors are typically much less efficient for longer-lived objects, and thus prior work has proposed many enhancements to generational collection. Our work explores whether the connectivity of objects can yield useful partitions or improve existing partitioning schemes. We look at both direct (eg, object A points to object B) and transitive (eg, object A is reachable from object B) connectivity. Our results indicate that connectivity correlates strongly with object lifetimes and deathtimes and is\u00a0\u2026", "num_citations": "78\n", "authors": ["282"]}
{"title": "Fast online pointer analysis\n", "abstract": " Pointer analysis benefits many useful clients, such as compiler optimizations and bug finding tools. Unfortunately, common programming language features such as dynamic loading, reflection, and foreign language interfaces, make pointer analysis difficult. This article describes how to deal with these features by performing pointer analysis online during program execution. For example, dynamic loading may load code that is not available for analysis before the program starts. Only an online analysis can analyze such code, and thus support clients that optimize or find bugs in it. This article identifies all problems in performing Andersen's pointer analysis for the full Java language, presents solutions to these problems, and uses a full implementation of the solutions in a Java virtual machine for validation and performance evaluation. Our analysis is fast: On average over our benchmark suite, if the analysis\u00a0\u2026", "num_citations": "73\n", "authors": ["282"]}
{"title": "Evaluating the effectiveness of pointer alias analyses\n", "abstract": " This paper describes an empirical comparison of the effectiveness of six context-insensitive pointer analysis algorithms that use varying degrees of flow-sensitivity. Four of the algorithms are flow-insensitive, one is flow-sensitive, and another is flow-insensitive, but uses precomputed flow-sensitive information. The effectiveness of each analysis is quantified in terms of compile-time efficiency and precision. Efficiency is reported by measuring CPU time and memory consumption of each analysis. Precision is reported by measuring the computed solutions at the program points where a pointer is dereferenced. The results of this paper will help implementors determine which pointer analysis is appropriate for their application.", "num_citations": "70\n", "authors": ["282"]}
{"title": "Pointer analysis in the presence of dynamic class loading\n", "abstract": " Many optimizations need precise pointer analyses to be effective. Unfortunately, some Java features, such as dynamic class loading, reflection, and native methods, make pointer analyses difficult to develop. Hence, prior pointer analyses for Java either ignore these features or are overly conservative. This paper presents the first non-trivial pointer analysis that deals with all Java language features. This paper identifies all problems in performing Andersen\u2019s pointer analysis for the full Java language, presents solutions to those problems, and uses a full implementation of the solutions in Jikes\u00a0RVM for validation and performance evaluation. The results from this work should be transferable to other analyses and to other languages.", "num_citations": "68\n", "authors": ["282"]}
{"title": "TED: Teaching AI to explain its decisions\n", "abstract": " Artificial intelligence systems are being increasingly deployed due to their potential to increase the efficiency, scale, consistency, fairness, and accuracy of decisions. However, as many of these systems are opaque in their operation, there is a growing demand for such systems to provide explanations for their decisions. Conventional approaches to this problem attempt to expose or discover the inner workings of a machine learning model with the hope that the resulting explanations will be meaningful to the consumer. In contrast, this paper suggests a new approach to this problem. It introduces a simple, practical framework, called Teaching Explanations for Decisions (TED), that provides meaningful explanations that match the mental model of the consumer. We illustrate the generality and effectiveness of this approach with two different examples, resulting in highly accurate explanations with no loss of prediction\u00a0\u2026", "num_citations": "55\n", "authors": ["282"]}
{"title": "Increasing trust in AI services through supplier\u2019s declarations of conformity\n", "abstract": " The accuracy and reliability of machine learning algorithms are an important concern for suppliers of artificial intelligence (AI) services, but considerations beyond accuracy, such as safety, security, and provenance, are also critical elements to engender consumers' trust in a service. In this paper, we propose a supplier's declaration of conformity (SDoC) for AI services to help increase trust in AI services. An SDoC is a transparent, standardized, but often not legally required, document used in many industries and sectors to describe the lineage of a product along with the safety and performance testing it has undergone. We envision an SDoC for AI services to contain purpose, performance, safety, security, and provenance information to be completed and voluntarily released by AI service providers for examination by consumers. Importantly, it conveys product-level rather than component-level functional testing. We suggest a set of declaration items tailored to AI and provide examples for two fictitious AI services.", "num_citations": "49\n", "authors": ["282"]}
{"title": "Flow-sensitive type analysis for C++\n", "abstract": " Static determination of run-time types is a key analysis step for compile-time optimizations of objectoriented languages with dynamic dispatch of functions. Type information is fundamental for determining the virtual functions that can be invoked and enables a number of interprocedural analyses and transformations. For example, knowledge of the types of objects at virtual function call sites opens opportunities for inlining, which in turn facilitates a number of intraprocedural compiler optimizations. The results of type analysis may also aid function cloning based on the types of function parameters. In this paper, we show how an existing ow-sensitive pointer alias analysis that uses a compact representation can be adapted to provide a type analysis algorithm which computes type information in a lazy fashion, thereby incurring minimal additional overhead. We show that use of the type information as soon as it becomes available can, in turn, improve the precision of the pointer alias analysis. We demonstrate that incorporating knowledge of the class hierarchy into our algorithm improves its precision, and show that our ow-sensitive method is more precise than ow-insensitive methods.", "num_citations": "47\n", "authors": ["282"]}
{"title": "Phase shift detection: A problem classification\n", "abstract": " ABSTRACT B\u00a4 CEDGFIHQPSR8 FTD\u00a2 FIUVCXWYPSW!Tab Fd cEefIgIehFIH iWq psrXp# R# tXufPSvDw PSW! FIDw PSDGRxefp FIW y PSDEgvUVC cvcGtEU FTe\u00a4 FIcEcEef5FTRx ufRh\u00a2 F ehFIRsufpsefPS# PSDEg uf Gp WYpsHqFID ufPSR# W'Ia F cXefvgTehFIH DEp P HQcTeYuhFID u FIWYc p# RsuIa% XCXD\u00a2 FTHQP R FTD\u00a2 FTUSCXWYPSW PSW\u00a4 uf Ep Xpsufp# RsufPSID4IaA cE\u00a2 FIWYpsW# v GPSRh 4 R FTD4 Gp# USc4 PSHQcXefTdvp% cEefIgIehFTHe tED\u00a2 XpseYy W uhFTD\u00a2 XP DEgETfApse WYc p# R# P FIUSPS F ufPID!IcGcTeYuftGDGPVufPSp# W PSDQ F gCEDGFIHQPSRhIcEy ufPSHQPS F ufPIDq W CEW ufpsH v efp XtGR# p WYPSH tEUiF ufPSvDQ ufPSHQpv g FIDG Q XCXD\u00a2 FTHQPSR FIUSUVC FI GFTcEu HjtGUVufPVykR#vDXl\u00a2 gvtXehFTufPSvDm GFTeh g'FTefpn ufo cEefvgTehFIHq pp#\u00a2 F dgPSIe rUVuf GvtEgv pIufvDEU PSDEp FIDGTsQPSDGp cE\u00a2 FTWYp WY GPVatu'Epsufp# RxufPID FTU gIIy efPVuf EHQW psrXP W u HQvW uhTefuv GFIW awR# tEWYp dvDv uf GpQ psxQR# FIRsCvIa'uf Ep RsU PSp# D u PVuf GItEuh Fb XpsuhFIPSUSp q W uft\u00a2 gCTa uf Ep2 dIFTefPSItGWh XPSHQp# DGWYPSvDEW%Ta uf Ep tGDG EpsefUVCXPSDGg cE\u00a2 FTWYp WY GPVatu Epxufp# RsufPSvD! cEefvpEUSp# H yh Ep gvvFIU0Ia uf EP W cGFIc pse PSW'ufp psuYufpxe tGD\u00a2 XpsefW uhFIDG uf Ep\u00a4 awtED\u00a2 EFTy HQpsDguhFTU cXefvpEU psHzIa cG GFIWYp WY EPSaiu Xpsufp# RsufPSID h {Xc p# R# PVlGR FIUSUVC G% pq|} Xp# HQvDEW uYehFTufp uf GFTu\u00a4 FID PD uftEPSufPSd5p DGIufPSIDIa Fj cG\u00a2 FTWYp PSW\u00a4 DEIu'hpsU UVy Xpsl\u00a2 DEp 0 GI} h EpslGDGp FTD FTpGW uYehFIRxu cEefvpEUSp# H PVuf~ u\u00a0\u2026", "num_citations": "46\n", "authors": ["282"]}
{"title": "Flow-sensitive interprocedural constant propagation\n", "abstract": " We present a flow-sensitive interprocedural constant propagation algorithm, which supports recursion while only performing one flow-sensitive analysis of each procedure. We present experimental results which show that this method finds substantially more constants than previous methods and is efficient in practice. We introduce new metrics for evaluating interprocedural constant propagation algorithms which measure the number of interprocedural constant values that are propagated. We use these metrics to provide further experimental results for our algorithm.", "num_citations": "38\n", "authors": ["282"]}
{"title": "Explaining explainable AI\n", "abstract": " How good are you at explaining your decisions? Are you better than a machine? Today, AI systems are being asked to explain their decisions. This article explores the challenges in solving this problem and approaches researchers are pursuing.", "num_citations": "30\n", "authors": ["282"]}
{"title": "Combining interprocedural pointer analysis and conditional constant propagation\n", "abstract": " The information computed by a pointer alias analysis can be used to improve the precision of subsequent analyses, such as conditional constant propagation. Conditional constant propagation can, in turn, discover unexecutable code, which can improve the precision of pointer analysis. This improved alias precision, in turn, may increase the e ectiveness of the conditional constant propagation, and so on. One way to resolved this mutual dependence between conditional constant propagation and pointer alias analysis is to iterate over the two analyses until a xed point is reached. In addition to raising e ciency concerns, the resulting precision may also not be optimal, ie, a more tightly coupled analysis can have better precision for both alias analysis and conditional constant propagation than iterating over the two analyses.In this work we explore three combinations of pointer alias analysis and conditional constant propagation: a one-pass-over-analyses approach, an iterate-over-analyses approach, and a new algorithm that synthesizes pointer alias analysis and conditional constant propagation. We empirically demonstrate the e ciency and precision of these three approaches on a benchmark suite of 21 C programs ranging in size from 200 {4,600 LOC.", "num_citations": "28\n", "authors": ["282"]}
{"title": "Method and system for profile normalization in an autonomic software system\n", "abstract": " There is provided an autonomic software system and method for normalizing a profile collected for an executing application to account for one or more actions applied to the executing application after the profile was collected, comprising: predicting an impact on the profile of applying the one or more actions to the executing application; and adjusting the profile to form a normalized profile according to the predicted impact. A plurality of different a profile consumers, such as, a phase shift detector, an action evaluator as well as a normalizing controller, may utilize the normalized profile to improve the behavior of the executing application. In addition, online visualization tools may be implemented to graphically depict the normalized profiles, as well as differences between the collected profiles and the normalized profiles.", "num_citations": "24\n", "authors": ["282"]}
{"title": "An empirical comparison of interprocedural pointer alias analyses\n", "abstract": " This paper describes an empirical comparison of three pointer alias analysis algorithms: flow-sensitive, flow-insensitive, and flow-insensitive with precomputed kill information. In addition to contrasting the precision and efficiency of these analyses, it describes implementation techniques and quantifies their analysis-time speed-up. Lastly, it illustrates the object-oriented approach used in the design of the system, which provides a natural example of multiple inheritance.", "num_citations": "20\n", "authors": ["282"]}
{"title": "AI Explainability 360: An Extensible Toolkit for Understanding Data and Machine Learning Models.\n", "abstract": " As artificial intelligence algorithms make further inroads in high-stakes societal applications, there are increasing calls from multiple stakeholders for these algorithms to explain their outputs. To make matters more challenging, different personas of consumers of explanations have different requirements for explanations. Toward addressing these needs, we introduce AI Explainability 360, an open-source Python toolkit featuring ten diverse and state-of-the-art explainability methods and two evaluation metrics (http://aix360. mybluemix. net). Equally important, we provide a taxonomy to help entities requiring explanations to navigate the space of interpretation and explanation methods, not only those in the toolkit but also in the broader literature on explainability. For data scientists and other users of the toolkit, we have implemented an extensible software architecture that organizes methods according to their place in the AI modeling pipeline. The toolkit is not only the software, but also guidance material, tutorials, and an interactive web demo to introduce AI explainability to different audiences. Together, our toolkit and taxonomy can help identify gaps where more explainability methods are needed and provide a platform to incorporate them as they are developed.", "num_citations": "19\n", "authors": ["282"]}
{"title": "Collaborative Human-AI (CHAI): Evidence-based interpretable melanoma classification in dermoscopic images\n", "abstract": " Automated dermoscopic image analysis has witnessed rapid growth in diagnostic performance. Yet adoption faces resistance, in part, because no evidence is provided to support decisions. In this work, an approach for evidence-based classification is presented. A feature embedding is learned with CNNs, triplet-loss, and global average pooling, and used to classify via kNN search. Evidence is provided as both the discovered neighbors, as well as localized image regions most relevant to measuring distance between query and neighbors. To ensure that results are relevant in terms of both label accuracy and human visual similarity for any skill level, a novel hierarchical triplet logic is implemented to jointly learn an embedding according to disease labels and non-expert similarity. Results are improved over baselines trained on disease labels alone, as well as standard multiclass loss. Quantitative\u00a0\u2026", "num_citations": "19\n", "authors": ["282"]}
{"title": "Think your artificial intelligence software is fair? Think again\n", "abstract": " Today, machine-learning software is used to help make decisions that affect people's lives. Some people believe that the application of such software results in fairer decisions because, unlike humans, machine-learning software generates models that are not biased. Think again. Machine-learning software is also biased, sometimes in similar ways to humans, often in different ways. While fair model- assisted decision making involves more than the application of unbiased models-consideration of application context, specifics of the decisions being made, resolution of conflicting stakeholder viewpoints, and so forth-mitigating bias from machine-learning software is important and possible but difficult and too often ignored.", "num_citations": "18\n", "authors": ["282"]}
{"title": "Trusted multi-party computation and verifiable simulations: A scalable blockchain approach\n", "abstract": " Large-scale computational experiments, often running over weeks and over large datasets, are used extensively in fields such as epidemiology, meteorology, computational biology, and healthcare to understand phenomena, and design high-stakes policies affecting everyday health and economy. For instance, the OpenMalaria framework is a computationally-intensive simulation used by various non-governmental and governmental agencies to understand malarial disease spread and effectiveness of intervention strategies, and subsequently design healthcare policies. Given that such shared results form the basis of inferences drawn, technological solutions designed, and day-to-day policies drafted, it is essential that the computations are validated and trusted. In particular, in a multi-agent environment involving several independent computing agents, a notion of trust in results generated by peers is critical in facilitating transparency, accountability, and collaboration. Using a novel combination of distributed validation of atomic computation blocks and a blockchain-based immutable audits mechanism, this work proposes a universal framework for distributed trust in computations. In particular we address the scalaibility problem by reducing the storage and communication costs using a lossy compression scheme. This framework guarantees not only verifiability of final results, but also the validity of local computations, and its cost-benefit tradeoffs are studied using a synthetic example of training a neural network.", "num_citations": "15\n", "authors": ["282"]}
{"title": "Loop distribution with multiple exits\n", "abstract": " We present a loop distribution algorithm that accommodates loops with multiple exits. Our algorithm utilizes and appropriately transforms abstract representations of the program rendering these structures suitable for further program transformations. We present results from implementing this algorithm in the PTRAN system at IBM Research.", "num_citations": "13\n", "authors": ["282"]}
{"title": "Experiences with improving the transparency of ai models and services\n", "abstract": " AI models and services are used in a growing number of high-stakes areas, resulting in a need for increased transparency. Consistent with this, several proposals for higher quality and more consistent documentation of AI data, models, and systems have emerged. Little is known, however, about the needs of those who would produce or consume these new forms of documentation. Through semi-structured developer interviews, and two document-creation exercises, we have assembled a clearer picture of these needs and the various challenges faced in creating accurate and useful AI documentation. Based on the observations from this work, supplemented by feedback received during multiple design explorations and stakeholder conversations, we make recommendations for easing the collection and flexible presentation of AI facts to promote transparency.", "num_citations": "12\n", "authors": ["282"]}
{"title": "Efficient loop-level parallelism in Ada\n", "abstract": " Parallelism in scientific applications can most often be found at the loop level. Although Ada supports parallelism via the task construct, its coarseness renders it unsuitable for this ligM-rueight parallelism. In this work we propose Ada constructs to achieve efficient looplevel parallelism in ANSI-Ada. This is accomplished in two steps. First, we present an idiom that allows the specification of light-weight tasks. Second, we give an efficient implementation of thk idiom that performs better than a standard Ada task. In addition, we present an idiom that makes the fetch~ nd. add synchronization primitive available at the Ada level. Our implementation of this idiom is more efficient in both time and space than previous results. In addition to providing universal synchronization, using fetch-and-add simplifies program analysis(eg proving the absence of race conditions in the implementation of a parallel algorithm). Since all of\u00a0\u2026", "num_citations": "9\n", "authors": ["282"]}
{"title": "Teaching meaningful explanations\n", "abstract": " The adoption of machine learning in high-stakes applications such as healthcare and law has lagged in part because predictions are not accompanied by explanations comprehensible to the domain user, who often holds the ultimate responsibility for decisions and outcomes. In this paper, we propose an approach to generate such explanations in which training data is augmented to include, in addition to features and labels, explanations elicited from domain users. A joint model is then learned to produce both labels and explanations from the input features. This simple idea ensures that explanations are tailored to the complexity expectations and domain knowledge of the consumer. Evaluation spans multiple modeling techniques on a game dataset, a (visual) aesthetics dataset, a chemical odor dataset and a Melanoma dataset showing that our approach is generalizable across domains and algorithms. Results demonstrate that meaningful explanations can be reliably taught to machine learning algorithms, and in some cases, also improve modeling accuracy.", "num_citations": "7\n", "authors": ["282"]}
{"title": "Trust and transparency in contact tracing applications\n", "abstract": " The global outbreak of COVID-19 has led to focus on efforts to manage and mitigate the continued spread of the disease. One of these efforts include the use of contact tracing to identify people who are at-risk of developing the disease through exposure to an infected person. Historically, contact tracing has been primarily manual but given the exponential spread of the virus that causes COVID-19, there has been significant interest in the development and use of digital contact tracing solutions to supplement the work of human contact tracers. The collection and use of sensitive personal details by these applications has led to a number of concerns by the stakeholder groups with a vested interest in these solutions. We explore digital contact tracing solutions in detail and propose the use of a transparent reporting mechanism, FactSheets, to provide transparency of and support trust in these applications. We also provide an example FactSheet template with questions that are specific to the contact tracing application domain.", "num_citations": "6\n", "authors": ["282"]}
{"title": "Distributed platform for computation and trusted validation\n", "abstract": " An example operation may include one or more of generating a data frame storing content of a simulation, compressing the simulation content within the data frame based on previous simulation content stored in another data frame to generate a compressed data frame, and transmitting the compressed data frame via a blockchain request to one or more endorsing peer nodes of a blockchain network for inclusion of the compressed data frame within a hash-linked chain of blocks of the blockchain network.", "num_citations": "6\n", "authors": ["282"]}
{"title": "Promoting distributed trust in machine learning and computational simulation\n", "abstract": " Policy decisions are increasingly dependent on the outcomes of simulations and/or machine learning models. The ability to share and interact with these outcomes is relevant across multiple fields and is especially critical in the disease modeling community where models are often only accessible and workable to the researchers that generate them. This work presents a blockchain-enabled system that establishes a decentralized trust between parties involved in a modeling process. Utilizing the OpenMalaria framework, we demonstrate the ability to store, share and maintain auditable logs and records of each step in the simulation process, showing how to validate results generated by computational workers. We also show how the system monitors worker outputs to rank and identify faulty workers via comparison to nearest neighbors or historical reward spaces as a means of ensuring model quality.", "num_citations": "6\n", "authors": ["282"]}
{"title": "Profile normalization in an autonomic software system\n", "abstract": " There is provided an autonomic software system and method for normalizing a profile collected for an executing application to account for one or more actions applied to the executing application after the profile was collected, comprising: predicting an impact of applying the one or more actions to the executing application by utilizing the profile and the one or more actions; and adjusting the profile to form a normalized profile according to the predicted impact. A plurality of different a profile consumers, such as, a phase shift detector, an action evaluator as well as a normalizing controller, may utilize the normalized profile to improve the behavior of the executing application. In addition, online visualization tools may be implemented to graphically depict the normalized profiles, as well as differences between the collected profiles and the normalized profiles.", "num_citations": "6\n", "authors": ["282"]}
{"title": "Traveling through Dakota: Experiences with an object-oriented program analysis system\n", "abstract": " The paper describes experiences with the design and implementation of the NPIC program analysis system. We describe how the object oriented design of the intermediate representation (Dakota) provides front end and analysis independence using the abstract factory pattern, and illustrate how using multiple inheritance allows it to be extended to support program analysis. We also describe how the intermediate representation can be serialized to and from a file. The techniques described in the article provide useful insight into the construction of an object oriented program analysis system.", "num_citations": "6\n", "authors": ["282"]}
{"title": "A Methodology for Creating AI FactSheets\n", "abstract": " As AI models and services are used in a growing number of highstakes areas, a consensus is forming around the need for a clearer record of how these models and services are developed to increase trust. Several proposals for higher quality and more consistent AI documentation have emerged to address ethical and legal concerns and general social impacts of such systems. However, there is little published work on how to create this documentation. This is the first work to describe a methodology for creating the form of AI documentation we call FactSheets. We have used this methodology to create useful FactSheets for nearly two dozen models. This paper describes this methodology and shares the insights we have gathered. Within each step of the methodology, we describe the issues to consider and the questions to explore with the relevant people in an organization who will be creating and consuming the AI facts in a FactSheet. This methodology will accelerate the broader adoption of transparent AI documentation.", "num_citations": "5\n", "authors": ["282"]}
{"title": "A scalable blockchain approach for trusted computation and verifiable simulation in multi-party collaborations\n", "abstract": " In high-stakes multi-party policy making based on machine learning and simulation models involving independent computing agents, a notion of trust in results is critical in facilitating transparency, accountability, and collaboration. Using a novel combination of distributed validation of atomic computation blocks and a blockchain-based immutable audit mechanism, this work proposes a framework for distributed trust in computations. In particular we address the scalability problem by reducing the storage and communication costs using a lossy compression scheme. This framework guarantees not only verifiability of final results, but also the validity of local computations, and its cost-benefit tradeoffs are studied using a synthetic example of training a neural network.", "num_citations": "4\n", "authors": ["282"]}
{"title": "Constructing and compressing frames in blockchain-based verifiable multi-party computation\n", "abstract": " In previous work, we proposed a scalable multi-party verification scheme for expensive iterative computations on a Blockchain substrate by appropriate storage and endorsement of frames of iterates. In this work, we extend the framework to verify sets of complete computations with different unordered hyperparameters and develop frame ordering and compression algorithms to enable scalability in the system. We illustrate the efficacy of the proposed approach by verifying the OpenMalaria epidemiological simulation.", "num_citations": "4\n", "authors": ["282"]}
{"title": "Promoting distributed trust in machine learning and computational simulation via a blockchain network\n", "abstract": " Policy decisions are increasingly dependent on the outcomes of simulations and/or machine learning models. The ability to share and interact with these outcomes is relevant across multiple fields and is especially critical in the disease modeling community where models are often only accessible and workable to the researchers that generate them. This work presents a blockchain-enabled system that establishes a decentralized trust between parties involved in a modeling process. Utilizing the OpenMalaria framework, we demonstrate the ability to store, share and maintain auditable logs and records of each step in the simulation process, showing how to validate results generated by computing workers. We also show how the system monitors worker outputs to rank and identify faulty workers via comparison to nearest neighbors or historical reward spaces as a means of ensuring model quality.", "num_citations": "4\n", "authors": ["282"]}
{"title": "The phase shift detection problem is non-monotonic\n", "abstract": " Object-oriented languages have enabled the creation of large commercial applications, where high performance is critical. To achieve high performance, dynamic optimization, which is performed at execution time, must be continuously tailored to the application\u2019s changing runtime behavior. One important technology to enable this continuous optimization is phase shift detection, which allows a dynamic optimization system to react appropriately to improve the system\u2019s performance.However, there has been limited success in exploiting phase shift detection in virtual machines. To help evaluate phase detection algorithms, we attempted to find the canonical phase structure of a program\u2019s profile. Starting with a simple phase shift detection algorithm specified by three fundamental parameters, we demonstrate with examples and profile data that two of the three parameters are non-monotonic with respect to the phase shift detection algorithm\u2019s decisions. This result implies that to determine the \u201cbest\u201d value for a non-monotonic parameters may require an exhaustive search of all possible values. Furthermore, once the \u201cbest\u201d value for a parameter is found for a particular profile, tuning the parameter\u2019s value for another profile is no easier than attempting to find the value from scratch. This fundamental result is important for dynamic optimization systems because it implies that the choice of values for a phase shift detection algorithm\u2019s parameters can have a dramatic impact on the quality of the information that is produced, and thus the choices should be carefully studied.", "num_citations": "4\n", "authors": ["282"]}
{"title": "Assessing the Effects of Flow-sensitivity on Pointer Alias Analyses: Extended Version\n", "abstract": " This paper describes an empirical comparison of four contextinsensitive pointer alias analysis algorithms that use varying degrees of flow-sensitivity: a flow-insensitive algorithm that tracks variables whose addresses were taken and stored; a flowinsensitive algorithm that computes a solution for each function; a variant of this algorithm that uses precomputed kill information; and a flow-sensitive algorithm. In addition to contrasting the precision and efficiency of these analyses, we describe implementation techniques and quantify their analysistime speed-up. Lastly, it illustrates the object-oriented approach used in the design of the system, which provides a natural example of multiple inheritance.", "num_citations": "4\n", "authors": ["282"]}
{"title": "AI explainability 360: hands-on tutorial\n", "abstract": " This tutorial will teach participants to use and contribute to a new open-source Python package named AI Explainability 360 (AIX360)(https://aix360. mybluemix. net), a comprehensive and extensible toolkit that supports interpretability and explainability of data and machine learning models.", "num_citations": "3\n", "authors": ["282"]}
{"title": "Explanations for artificial intelligence based recommendations\n", "abstract": " Techniques regarding explanations for artificial intelligence recommendations are provided. For example, one or more embodiments described herein can comprise a system, which can comprise a memory that can store computer executable components. The system can also comprise a processor, operably coupled to the memory, and that can execute the computer executable components stored in the memory. The computer executable components can include: a combination component that receives a first training dataset comprising first feature vectors, first classes and first explanations, and combines the first classes and the first explanations to produce first augmented labels and a second training dataset that comprises the first feature vectors and the first augmented labels; a classifier, trained on the second training dataset, that analyses second feature vectors and generates second augmented labels; and a\u00a0\u2026", "num_citations": "3\n", "authors": ["282"]}
{"title": "Teaching AI to Explain its Decisions Using Embeddings and Multi-Task Learning\n", "abstract": " Using machine learning in high-stakes applications often requires predictions to be accompanied by explanations comprehensible to the domain user, who has ultimate responsibility for decisions and outcomes. Recently, a new framework for providing explanations, called TED, has been proposed to provide meaningful explanations for predictions. This framework augments training data to include explanations elicited from domain users, in addition to features and labels. This approach ensures that explanations for predictions are tailored to the complexity expectations and domain knowledge of the consumer. In this paper, we build on this foundational work, by exploring more sophisticated instantiations of the TED framework and empirically evaluate their effectiveness in two diverse domains, chemical odor and skin cancer prediction. Results demonstrate that meaningful explanations can be reliably taught to machine learning algorithms, and in some cases, improving modeling accuracy.", "num_citations": "2\n", "authors": ["282"]}
{"title": "TED: Teaching AI to Explain its Decisions\n", "abstract": " Artificial intelligence systems are being increasingly deployed due to their potential to increase the efficiency, scale, consistency, fairness, and accuracy of decisions. However, as many of these systems are opaque in their operation, there is a growing demand for such systems to provide explanations for their decisions. Conventional approaches to this problem attempt to expose or discover the inner workings of a machine learning model with the hope that the resulting explanations will be meaningful to the consumer. In contrast, this paper suggests a new approach to this problem. It introduces a simple, practical framework, called Teaching Explanations for Decisions (TED), that provides meaningful explanations that match the mental model of the consumer. We illustrate the generality and effectiveness of this approach with two different examples, resulting in highly accurate explanations with no loss of prediction accuracy for these two examples.", "num_citations": "2\n", "authors": ["282"]}
{"title": "Disparate Impact Diminishes Consumer Trust Even for Advantaged Users\n", "abstract": " Systems aiming to aid consumers in their decision-making (eg, by implementing persuasive techniques) are more likely to be effective when consumers trust them. However, recent research has demonstrated that the machine learning algorithms that often underlie such technology can act unfairly towards specific groups (eg, by making more favorable predictions for men than for women). An undesired disparate impact resulting from this kind of algorithmic unfairness could diminish consumer trust and thereby undermine the purpose of the system. We studied this effect by conducting a between-subjects user study investigating how (gender-related) disparate impact affected consumer trust in an app designed to improve consumers\u2019 financial decision-making. Our results show that disparate impact decreased consumers\u2019 trust in the system and made them less likely to use it. Moreover, we find that trust was affected\u00a0\u2026", "num_citations": "1\n", "authors": ["282"]}
{"title": "Addressing the disconnect between the good and the popular\n", "abstract": " For several decades universities have taught programming languages as a fundamental part of their un-dergraduate curriculum. These courses cover the core topics used in the design of good programming languages. However, widely used commercial languages quite often seem to go against the conventional wisdom of good language design that is taught in these courses. This disconnect between what is taught as good language design and what languages are used in industry has put the programming language course in a bind. Specifically, as computer science departments feel the increased pressure to add new emerging topics, many departments are choosing to remove the programming language course from the core curriculum. In this position paper, we argue that the disconnect between good language design and industry practice is exactly why a programming language course should be a crucial\u00a0\u2026", "num_citations": "1\n", "authors": ["282"]}
{"title": "The Need for a Whole-System View of Performance.\n", "abstract": " Middleware usually runs on top of a powerful execution platform. Often that platform includes extensive runtime libraries, a virtual machine, an operating system, and modern complex hardware.The understanding of middleware performance is complicated by intricate interactions between the application, the middleware, and the components of the underlying platform. The functional interfaces of the components of such a platform are clearly defined. They range from the API specification, over the virtual machine specification, the system call interface, to the processor\u2019s instruction set architecture. The functionality of a system component can be understood by just looking at that component\u2019s functional specification. The performance of a system component, on the other hand, can often not be understood in isolation. This is because performance interactions between components can be very intricate, non-linear, and involve unpredictable delays. We propose temporal vertical profiling [1] as an approach for whole system performance understanding. Temporal vertical profiling captures the temporal system behavior on all layers, and of all components, of the system. A trace of values for performance metrics from system components is captured and analyzed to identify correlations between such metrics. Correlation is the first step in the identification of causal releationships between metrics and components. And these causal relationships are the fundamental building blocks for performance understanding.", "num_citations": "1\n", "authors": ["282"]}
{"title": "NPIC\u2014New Paltz interprocedural compiler\n", "abstract": " Irregular design While software architectures can be highly individualistic, well-designed software does have structure, both modular and hierarchical. Since that structure differs from system to system, it is difficult to discover any state-space regularities once a design has been flattened.", "num_citations": "1\n", "authors": ["282"]}