{"title": "Specification patterns for probabilistic quality properties\n", "abstract": " Probabilistic verification techniques are a powerful means to ensure that a software-intensive system fulfills its quality requirements. To apply these techniques an accurate specification of the required properties in a probabilistic temporal logic is necessary. To help practitioners formulate these properties correctly, this paper presents a specification pattern system of common probabilistic properties called ProProST. This pattern system has been a developed based on a survey of 152 properties from academic examples and 48 properties of real-word quality requirements from avionic, defence and automotive systems. Furthermore, a structured English grammar that can guide in the specification of probabilistic properties is given. Similar to previous specification patterns for traditional and real-time properties, the presented specification pattern system and the structured English grammar captures expert knowledge\u00a0\u2026", "num_citations": "210\n", "authors": ["1906"]}
{"title": "ArcheOpterix: An extendable tool for architecture optimization of AADL models\n", "abstract": " For embedded systems quality requirements are equally if not even more important than functional requirements. The foundation for the fulfillment of these quality requirements has to be set in the architecture design phase. However, finding a suitable architecture design is a difficult task for software and system architects. Some of the reasons for this are an ever-increasing complexity of today's systems, strict design constraints and conflicting quality requirements. To simplify the task, this paper presents an extendable Eclipse-based tool, called ArcheOpterix, which provides a framework to implement evaluation techniques and optimization heuristics for AADL specifications. Currently, evolutionary strategies have been implemented to identify optimized deployment architectures with respect to multiple quality objectives and design constraints. Experiments with a set of initial deployment architectures provide evidence\u00a0\u2026", "num_citations": "209\n", "authors": ["1906"]}
{"title": "An approach to forecasting QoS attributes of web services based on ARIMA and GARCH models\n", "abstract": " Availability of several web services having a similar functionality has led to using quality of service (QoS) attributes to support services selection and management. To improve these operations and be performed proactively, time series ARIMA models have been used to forecast the future QoS values. However, the problem is that in this extremely dynamic context the observed QoS measures are characterized by a high volatility and time-varying variation to the extent that existing ARIMA models cannot guarantee accurate QoS forecasting where these models are based on a homogeneity (constant variation over time) assumption, which can introduce critical problems such as proactively selecting a wrong service and triggering unrequired adaptations and thus leading to follow-up failures and increased costs. To address this limitation, we propose a forecasting approach that integrates ARIMA and GARCH models to\u00a0\u2026", "num_citations": "130\n", "authors": ["1906"]}
{"title": "Aligning qualitative, real-time, and probabilistic property specification patterns using a structured english grammar\n", "abstract": " Formal methods offer an effective means to assert the correctness of software systems through mathematical reasoning. However, the need to formulate system properties in a purely mathematical fashion can create pragmatic barriers to the application of these techniques. For this reason, Dwyer et al. invented property specification patterns which is a system of recurring solutions to deal with the temporal intricacies that would make the construction of reactive systems very hard otherwise. Today, property specification patterns provide general rules that help practitioners to qualify order and occurrence, to quantify time bounds, and to express probabilities of events. Nevertheless, a comprehensive framework combining qualitative, real-time, and probabilistic property specification patterns has remained elusive. The benefits of such a framework are twofold. First, it would remove the distinction between qualitative and\u00a0\u2026", "num_citations": "122\n", "authors": ["1906"]}
{"title": "An approach to software reliability prediction based on time series modeling\n", "abstract": " Reliability is the key factor for software system quality. Several models have been introduced to estimate and predict reliability based on results of software testing activities. Software Reliability Growth Models (SRGMs) are considered the most commonly used to achieve this goal. Over the past decades, many researchers have discussed SRGMs\u2019 assumptions, applicability, and predictability. They have concluded that SRGMs have many shortcomings related to their unrealistic assumptions, environment-dependent applicability, and questionable predictability. Several approaches based on non-parametric statistics, Bayesian networks, and machine learning methods have been proposed in the literature. Based on their theoretical nature, however, they cannot completely address the SRGMs\u2019 limitations. Consequently, addressing these shortcomings is still a very crucial task in order to provide reliable software\u00a0\u2026", "num_citations": "106\n", "authors": ["1906"]}
{"title": "Identifying good architectural design alternatives with multi-objective optimization strategies\n", "abstract": " Architecture trade-off analysis methods are appropriate techniques to evaluate design decisions and design alternatives with respect to conflicting quality requirements. However, the identification of good design alternatives is a time consuming task, which is currently performed manually. To automate this task, this paper proposes to use evolutionary algorithms and multi-objective optimization strategies based on architecture refactorings to identify a sufficient set of design alternatives. This approach will reduce development costs and improve the quality of the final system, because an automated and systematic search will identify more and better design alternatives.", "num_citations": "89\n", "authors": ["1906"]}
{"title": "Model-driven safety evaluation with state-event-based component failure annotations\n", "abstract": " Over the past years, the paradigm of component-based software engineering has been established in the construction of complex mission-critical systems. Due to this trend, there is a practical need for techniques that evaluate critical properties (such as safety, reliability, availability or performance) of these systems. In this paper, we review several high-level techniques for the evaluation of safety properties for component-based systems and we propose a new evaluation model (State Event Fault Trees) that extends safety analysis towards a lower abstraction level. This model possesses a state-event semantics and strong encapsulation, which is especially useful for the evaluation of component-based software systems. Finally, we compare the techniques and give suggestions for their combined usage.", "num_citations": "89\n", "authors": ["1906"]}
{"title": "Probabilistic model-checking support for FMEA\n", "abstract": " Failure Mode and Effect Analysis (FMEA) is a method for assessing cause-consequence relations between component faults and hazards that may occur during the lifetime of a system. The analysis is typically time intensive and informal, and for this reason FMEA has been extended with traditional model checking support. Such support does not take into account the probabilities associated with a component fault occurring, yet such information is crucial to developing hazard reduction strategies for a system. In this paper we propose a method for FMEA which makes use of probabilistic fault injection and probabilistic model checking. Based on this approach safety engineers are able to formally identify if a failure mode occurs with a probability higher than its tolerable hazard rate.", "num_citations": "87\n", "authors": ["1906"]}
{"title": "Using graph transformation for practical model driven software engineering\n", "abstract": " Model transformations are one of the core technologies needed to apply OMG\u2019s model-driven engineering concept for the construction of real-world systems. Several formalisms are currently proposed for the specification of these model transformations. A suitable formalism is based on graph transformation systems and graph transformation rules. The chapter provides an overview about the needed concepts to apply graph transformations in the context of model driven engineering and we show the technical feasibility based on several tools and applications.", "num_citations": "85\n", "authors": ["1906"]}
{"title": "Safety analysis of an airbag system using probabilistic FMEA and probabilistic counterexamples\n", "abstract": " Failure mode and effects analysis (FMEA) is a technique to reason about possible system hazards that result from system or system component failures. Traditionally, FMEA does not take the probabilities with which these failures may occur into account. Recently, this shortcoming was addressed by integrating stochastic model checking techniques into the FMEA process. A further improvement is the integration of techniques for the generation of counterexamples for stochastic models, which we propose in this paper. Counterexamples facilitate the redesign of a potentially unsafe system by providing information which components contribute most to the failure of the entire system. The usefulness of this novel approach to the FMEA process is illustrated by applying it to the case study of an airbag system provided by our industrial partner, the TRW Automotive GmbH.", "num_citations": "82\n", "authors": ["1906"]}
{"title": "Early quality prediction of component-based systems\u2013a generic framework\n", "abstract": " Component-based software engineering is currently an emerging technology used to develop complex embedded systems. These embedded systems need to fulfil requirements regarding quality attributes such as safety, reliability, availability, maintainability, performance, security and temporal correctness. Since quality problems should be identified and tackled early in the development process, there is a rising need to predict and evaluate these properties in the architecture design phase. This paper describes a generic framework for predicting quality properties based on component-based architectures, which is derived from a comprehensive study of recent architecture evaluation methods. This generic framework defines common aspects between the different evaluation methods and enables the improvement of evaluation methods for specific quality properties, by transferring knowledge from one quality\u00a0\u2026", "num_citations": "75\n", "authors": ["1906"]}
{"title": "An automated approach to forecasting QoS attributes based on linear and non-linear time series modeling\n", "abstract": " Predicting future values of Quality of Service (QoS) attributes can assist in the control of software intensive systems by preventing QoS violations before they happen. Currently, many approaches prefer Autoregressive Integrated Moving Average (ARIMA) models for this task, and assume the QoS attributes' behavior can be linearly modeled. However, the analysis of real QoS datasets shows that they are characterized by a highly dynamic and mostly nonlinear behavior to the extent that existing ARIMA models cannot guarantee accurate QoS forecasting, which can introduce crucial problems such as proactively triggering unrequired adaptations and thus leading to follow-up failures and increased costs. To address this limitation, we propose an automated forecasting approach that integrates linear and nonlinear time series models and automatically, without human intervention, selects and constructs the best suitable\u00a0\u2026", "num_citations": "72\n", "authors": ["1906"]}
{"title": "Quantitative risk-based security prediction for component-based systems with explicitly modeled attack profiles\n", "abstract": " Systems and software architects require quantitative dependability evaluations, which allow them to compare the effect of their design decisions on dependability properties. For security, however, quantitative evaluations have proven difficult, especially for component-based systems. In this paper, we present a risk-based approach that creates modular attack trees for each component in the system. These modular attack trees are specified as parametric constraints, which allow quantifying the probability of security breaches that occur due to internal component vulnerabilities as well as vulnerabilities in the component\u2019s deployment environment. In the second case, attack probabilities are passed between system components as appropriate to model attacks that exploit vulnerabilities in multiple system components. The probability of a successful attack is determined with respect to a set of attack profiles that are\u00a0\u2026", "num_citations": "72\n", "authors": ["1906"]}
{"title": "Architecture-based reliability evaluation under uncertainty\n", "abstract": " The accuracy of architecture-based reliability evaluations depends on a number of parameters that need to be estimated, such as environmental factors or system usage. Researchers have tackled this problem by including uncertainties in architecture evaluation models and solving them analytically and with simulations. The usual assumption is that the input parameter distributions are normal, and that it is sufficient to report the attributes that describe the system in terms of the mean and variance of the attribute. In this work, we introduce a simulation-based approach that can accommodate a diverse set of parameter range distributions, self-regulate the number of architecture evaluations to the desired significance level and reports the desired percentiles of the values which ultimately characterise a specific quality attribute of the system. We include a case study which illustrates the flexibility of this approach using\u00a0\u2026", "num_citations": "66\n", "authors": ["1906"]}
{"title": "An automated failure mode and effect analysis based on high-level design specification with behavior trees\n", "abstract": " Formal methods have significant benefits for developing safety critical systems, in that they allow for correctness proofs, model checking safety and liveness properties, deadlock checking, etc. However, formal methods do not scale very well and demand specialist skills, when developing real-world systems. For these reasons, development and analysis of large-scale safety critical systems will require effective integration of formal and informal methods. In this paper, we use such an integrative approach to automate Failure Modes and Effects Analysis (FMEA), a widely used system safety analysis technique, using a high-level graphical modelling notation (Behavior Trees) and model checking. We inject component failure modes into the Behavior Trees and translate the resulting Behavior Trees to SAL code. This enables us to model check if the system in the presence of these faults satisfies its safety\u00a0\u2026", "num_citations": "63\n", "authors": ["1906"]}
{"title": "Reliability-driven deployment optimization for embedded systems\n", "abstract": " One of the crucial aspects that influence reliability of embedded systems is the deployment of software components to hardware nodes. If the hardware architecture is designed prior to the customized software architecture, which is often the case in product-line manufacturing (e.g. in the automotive domain), the system architect needs to resolve a nontrivial task of finding a (near-)optimal deployment balancing the reliabilities of individual services implemented on the software level.In this paper, we introduce an approach to automate this task. As distinct to related approaches, which typically stay with quantification of reliability for a specific deployment, we target multi-criteria optimization and provide the architect with near-optimal (non-dominated) deployment alternatives with respect to service reliabilities. Toward this goal, we annotate the software and hardware architecture with necessary reliability-relevant\u00a0\u2026", "num_citations": "60\n", "authors": ["1906"]}
{"title": "Automatic generation of analyzable failure propagation models from component-level failure annotations\n", "abstract": " Model-driven and component-based software engineering methodologies are currently key factors for the successful construction of complex software systems. To effectively apply these methodologies to mission- and safety-critical systems, component-based models should also support hazard analysis techniques and enable the automatic construction of safety cases. This paper outlines a technique, which annotates components with modular failure mode assumptions, described in the failure propagation transformation notation (FPTN) and generates an analyzable failure propagation model for the complete system. Based on this technique, a model-based safety evaluation is possible, which enables the automatic generation of safety cases based on system models. Consequently, a consistency between the safety case and the system model can be ensured, even if the system's architecture is changed.", "num_citations": "59\n", "authors": ["1906"]}
{"title": "A graphical specification of model transformations with triple graph grammars\n", "abstract": " Models and model transformations are the core concepts of OMG\u2019s MDA                   TM                  approach. Within this approach, most models are derived from the MOF and have a graph-based nature. In contrast, most of the current model transformations are specified textually. To enable a graphical specification of model transformation rules, this paper proposes to use triple graph grammars as declarative specification formalism. These triple graph grammars can be specified within the FUJABA tool and we argue that these rules can be more easily specified and they become more understandable and maintainable. To show the practicability of our approach, we present how to generate Tefkat rules from triple graph grammar rules, which helps to integrate triple graph grammars with a state of a art model transformation tool and shows the expressiveness of the concept.", "num_citations": "54\n", "authors": ["1906"]}
{"title": "Architecture-driven reliability and energy optimization for complex embedded systems\n", "abstract": " The use of redundant computational nodes is a widely used design tactic to improve the reliability of complex embedded systems. However, this redundancy allocation has also an effect on other quality attributes, including energy consumption, as each of the redundant computational nodes requires additional energy. As a result, the two quality objectives are conflicting. The approach presented in this paper applies a multi-objective optimization strategy to find optimal redundancy levels for different architectural elements. It is implemented in the ArcheOpterix tool and illustrated on a realistic case study from the automotive domain.", "num_citations": "53\n", "authors": ["1906"]}
{"title": "Lightweight adaptive filtering for efficient learning and updating of probabilistic models\n", "abstract": " Adaptive software systems are designed to cope with unpredictable and evolving usage behaviors and environmental conditions. For these systems reasoning mechanisms are needed to drive evolution, which are usually based on models capturing relevant aspects of the running software. The continuous update of these models in evolving environments requires efficient learning procedures, having low overhead and being robust to changes. Most of the available approaches achieve one of these goals at the price of the other. In this paper we propose a lightweight adaptive filter to accurately learn time-varying transition probabilities of discrete time Markov models, which provides robustness to noise and fast adaptation to changes with a very low overhead. A formal stability, unbiasedness and consistency assessment of the learning approach is provided, as well as an experimental comparison with state-of-the\u00a0\u2026", "num_citations": "49\n", "authors": ["1906"]}
{"title": "An outline of an architecture-based method for optimizing dependability attributes of software-intensive systems\n", "abstract": " Dependability requirements such as safety and availability often conflict with one another making the development of dependable systems challenging. It is not always possible to design a system that fulfils all of its dependability requirements and consequently, it is necessary to identify conflicts early in the development process and to optimize the architectural design with regard to dependability and cost. This paper first provides an overview of fifteen different approaches to optimizing system designs at an architectural level. Then an abstract method is proposed that synthesises the main points of the different approaches to yield a generic approach that could be applied across a wide variety of different system attributes.", "num_citations": "49\n", "authors": ["1906"]}
{"title": "Architecture-driven reliability optimization with uncertain model parameters\n", "abstract": " It is currently considered good software engineering practice to decide between design alternatives based on quantitative architecture evaluations for different quality attributes, such as reliability and performance. However, the results of these quantitative architecture evaluations are dependent on design-time estimates for a series of model-parameters, which may not be accurate and have to be estimated subject heterogeneous uncertain factors. As a result, sub-optimal design decisions may be taken. To overcome this problem, we present a novel robust optimization approach that deals with parameter uncertainties at the design phase of software-intensive systems. This work specifically focuses on architecture-based reliability evaluation models. The proposed approach is able to find good solutions that restrict the impact of parameter uncertainties, and thus provides better decision support. The accuracy and\u00a0\u2026", "num_citations": "46\n", "authors": ["1906"]}
{"title": "Experience with fault injection experiments for FMEA\n", "abstract": " Failure Modes and Effects Analysis (FMEA) is a widely used system and software safety analysis technique that systematically identifies failure modes of system components and explores whether these failure modes might lead to potential hazards. In practice, FMEA is typically a labor\u2010intensive team\u2010based exercise, with little tool support. This article presents our experience with automating parts of the FMEA process, using a model checker to automate the search for system\u2010level consequences of component failures. The idea is to inject runtime faults into a model based on the system specification and check if the resulting model violates safety requirements, specified as temporal logical formulas. This enables the safety engineer to identify if a component failure, or combination of multiple failures, can lead to a specified hazard condition. If so, the model checker produces an example of the events leading up to\u00a0\u2026", "num_citations": "46\n", "authors": ["1906"]}
{"title": "Let the ants deploy your software-an ACO based deployment optimisation strategy\n", "abstract": " Decisions regarding the mapping of software components to hardware nodes affect the quality of the resulting system. Making these decisions is hard when considering the ever-growing complexity of the search space, as well as conflicting objectives and constraints. An automation of the solution space exploration would help not only to make better decisions but also to reduce the time of this process. In this paper, we propose to employ Ant Colony Optmisation (ACO) as a multi-objective optimisation strategy. The constructive approach is compared to an iterative optimisation procedure - a Genetic Algorithm (GA) adaptation - and was observed to perform suprisingly similar, although not quite on a par with the GA, when validated based on a series of experiments.", "num_citations": "44\n", "authors": ["1906"]}
{"title": "Formalizing architectural refactorings as graph transformation systems\n", "abstract": " Architectural refactorings are an appropriate technique for the development and improvement of architectural specifications. However, these refactorings are often applied manually. This paper presents a mapping of an architectural specification language to a hypergraph-based data structure. Thus, architectural refactorings can be formalized as hypergraph transformation rules and can be applied automatically.", "num_citations": "44\n", "authors": ["1906"]}
{"title": "Test data generation with a Kalman filter-based adaptive genetic algorithm\n", "abstract": " Software testing is a crucial part of software development. It enables quality assurance, such as correctness, completeness and high reliability of the software systems. Current state-of-the-art software testing techniques employ search-based optimisation methods, such as genetic algorithms to handle the difficult and laborious task of test data generation. Despite their general applicability, genetic algorithms have to be parameterised in order to produce results of high quality. Different parameter values may be optimal for different problems and even different problem instances. In this work, we introduce a new approach for generating test data, based on adaptive optimisation. The adaptive optimisation framework uses feedback from the optimisation process to adjust parameter values of a genetic algorithm during the search. Our approach is compared to a state of the art test data optimisation algorithm that does not\u00a0\u2026", "num_citations": "41\n", "authors": ["1906"]}
{"title": "Towards an integration of standard component-based safety evaluation techniques with saveccm\n", "abstract": " To deliver complex functionalities in a cost effective manner, embedded software should ideally be developed with standardized interoperable components. At the same time, most of these embedded systems must be demonstrably safe and reliable. This paper aims to extend SaveCCM, a modelling language for component-based embedded systems, with standard safety evaluation models. Based on this extension, failure and hazard probabilities can be estimated early in the development process and can be used to check if a system can fulfil its safety requirements. The procedure of the safety evaluation is demonstrated with the case study of a computer assisted braking system.", "num_citations": "40\n", "authors": ["1906"]}
{"title": "Analysing the fitness landscape of search-based software testing problems.\n", "abstract": " Search-based software testing automatically derives test inputs for a software system with the goal of improving various criteria, such as branch coverage. In many cases, evolutionary algorithms are implemented to find near-optimal test suites for software systems. The result of the search is usually received without any indication of how successful the search has been. Fitness landscape characterisation can help understand the search process and its probability of success. In this study, we recorded the information content, negative slope coefficient and the number of improvements during the progress of a genetic algorithm within the EvoSuite framework. Correlating the metrics with the branch and method coverages and the fitness function values reveals that the problem formulation used in EvoSuite could be improved by revising the objective function. It also demonstrates that given the current formulation, the use of crossover has no benefits for the search as the most problematic landscape features are not the number of local optima but the presence of many plateaus.", "num_citations": "39\n", "authors": ["1906"]}
{"title": "Timed behavior trees for failure mode and effects analysis of time-critical systems\n", "abstract": " Behavior Trees are a graphical notation used for formalising functional requirements, and have been successfully applied to several industrial case studies. However, the standard notation does not support the concept of time, and consequently its application is limited to non-real-time systems. To overcome this limitation we extend the notation to timed Behavior Trees. We provide an operational semantics which is based on timed automata, and thus serves as a formal basis for the translation of timed Behavior Trees into the input notation of the timed model checker UPPAAL. System-level timing properties of a Behavior Tree model can then be automatically verified using UPPAAL. Based on the notational extensions with model checking support, we introduce timed Failure Mode and Effects Analysis, a process for identifying cause-consequence relationships between component failures and system hazards in real\u00a0\u2026", "num_citations": "34\n", "authors": ["1906"]}
{"title": "Probabilistic timed behavior trees\n", "abstract": " The Behavior Tree notation has been developed as a method for systematically and traceably capturing user requirements. In this paper we extend the notation with probabilistic behaviour, so that reliability, performance, and other dependability properties can be expressed. The semantics of probabilistic timed Behavior Trees is given by mapping them to probabilistic timed automata. We gain advantages for requirements capture using Behavior Trees by incorporating into the notation an existing elegant specification formalism (probabilistic timed automata) which has tool support for formal analysis of probabilistic user requirements.", "num_citations": "30\n", "authors": ["1906"]}
{"title": "Defining the abstract syntax of visual languages with advanced graph grammars--a case study based on behavior trees\n", "abstract": " Diagrammatic visual languages can increase the ability of engineers to model and understand complex systems. However, to effectively use visual models, the syntax and semantics of these languages should be defined precisely. Since most diagrammatic visual models that are currently used to specify systems can be described as (directed) typed graphs, graph grammars have been identified as a suitable formalism to describe the abstract syntax of visual modeling languages. In this article, we investigate how advanced graph-transformation techniques, such as conditional, structure-generic and type-generic graph-transformation rules, can help to improve and simplify the specification of the abstract syntax of a visual modeling language. To demonstrate the practicability of an approach that unifies these advanced graph-transformation techniques, we define the abstract syntax of behavior trees (BTs), a graphical\u00a0\u2026", "num_citations": "29\n", "authors": ["1906"]}
{"title": "How much event data is enough? A statistical framework for process discovery\n", "abstract": " With the increasing availability of business process related event logs, the scalability of techniques that discover a process model from such logs becomes a performance bottleneck. In particular, exploratory analysis that investigates manifold parameter settings of discovery algorithms, potentially using a software-as-a-service tool, relies on fast response times. However, common approaches for process model discovery always parse and analyse all available event data, whereas a small fraction of a log could have already led to a high-quality model. In this paper, we therefore present a framework for process discovery that relies on statistical pre-processing of an event log and significantly reduce its size by means of sampling. It thereby reduces the runtime and memory footprint of process discovery algorithms, while providing guarantees on the introduced sampling error. Experiments with two public real\u00a0\u2026", "num_citations": "28\n", "authors": ["1906"]}
{"title": "Transformational patterns for the improvement of safety properties in architectural specification\n", "abstract": " Over the past years, the functionality of technical systems been increasingly implemented in software components. These software components have to fulfill requirements regarding non-functional properties (NFPs), such as safety, availability, reliability and temporal correctness. Along with the rising need for increased functionality, this led to an increased complexity of these systems. As a result, the architectural specification and its quality have become important for the success of the development process. For the non-functional requirements, the quality of the architecture can be determined by an architecture evaluation. If the system does not fulfill these requirements, the architecture must be modified to improve the non-functional properties. To support this process we present a set of transformational patterns, that help to restructure architectures to especially improve the safety properties of the systems under development.", "num_citations": "28\n", "authors": ["1906"]}
{"title": "An efficient method for architecture-based reliability evaluation for evolving systems with changing parameters\n", "abstract": " Probabilistic models are widely used in Architecture-based reliability prediction in software intensive systems. However, for most of the cases, it is computationally expensive to compute the reliability metrics and re-compute them once the system has evolved or is used in a different environment. In this paper, we introduce an efficient computation method for Discrete Time Markov Chain based abstractions, which computes reliability metrics once, and we provide an incremental technique to recompute these metrics in case of a single change in the reliability evaluation model. As a result, fast an efficient reliability computation can be provided for scenarios like design-time architecture optimization and run time adaptation. An experimental validation of the new method shows a significant improvement in terms of computation time required to re-evaluate an evolved architecture.", "num_citations": "26\n", "authors": ["1906"]}
{"title": "An effective sequential statistical test for probabilistic monitoring\n", "abstract": " ContextA monitor checks if a system behaves according to a specified property at runtime. This is required for quality assurance purposes. Currently several approaches exist to monitor standard and real-time properties. However, a current challenge is to provide a comprehensive approach for monitoring probabilistic properties, as they are used to formulate quality of service requirements like performance, reliability, safety, and availability. The main problem of these probabilistic properties is that there is no binary acceptance condition.ObjectiveTo overcome this problem, this article presents an improved and generic statistical decision procedure based on acceptance sampling and sequential hypothesis testing.MethodThe developed decision procedure is validated using several experiments that determine the operating characteristic, runtime overhead as well as the expected sample sizes\u00a0\u2026", "num_citations": "24\n", "authors": ["1906"]}
{"title": "An automated dependability analysis method for COTS-based systems\n", "abstract": " The increasing application of COTS-components and component-based software engineering has entailed the development of appropriate component specifications. In the embedded systems domain it would be desirable to benefit from these component specifications to integrate and automate safety and reliability analysis. For this reason, we propose in this paper a component-based dependability analysis technique that annotates components with failure mode assumptions. The probabilities and dependencies of these failure modes are specified by Component Fault Trees (CFT\u2019s). Based on these CFT\u2019s and the architectural model the propagation of failures throughout the system can be automatically determined and a quantitative analysis is possible.", "num_citations": "24\n", "authors": ["1906"]}
{"title": "Evaluating probabilistic models with uncertain model parameters\n", "abstract": " Probabilistic models are commonly used to evaluate quality attributes, such as reliability, availability, safety and performance of software-intensive systems. The accuracy of the evaluation results depends on a number of system properties which have to be estimated, such as environmental factors or system usage. Researchers have tackled this problem by including uncertainties in the probabilistic models and solving them analytically or with simulations. The input parameters are commonly assumed to be normally distributed. Accordingly, reporting the mean and variances of the resulting attributes is usually considered sufficient. However, many of the uncertain factors do not follow normal distributions, and analytical methods to derive objective uncertainties become impractical with increasing complexity of the probabilistic models. In this work, we introduce a simulation-based approach which uses\u00a0\u2026", "num_citations": "21\n", "authors": ["1906"]}
{"title": "Mapping the effectiveness of automated test suite generation techniques\n", "abstract": " Automated test suite generation (ATSG) is an important topic in software engineering, with a wide range of techniques and tools being used in academia and industry. While their usefulness is widely recognized, due to the labor-intensive nature of the task, the effectiveness of the different techniques in automatically generating test cases for different software systems is not thoroughly understood. Despite many studies introducing various ATSG techniques, much remains to be learned, however, about what makes a particular technique work well (or not) for a specific software system. In this paper, we seek an answer to the question: \u201cWhat features of a software system impact the effectiveness of ATSG techniques?\u201d Once these features are identified, can they be used to select the most effective ATSG technique for a particular software system? To this end, we have implemented the mapping the effectiveness of test\u00a0\u2026", "num_citations": "20\n", "authors": ["1906"]}
{"title": "Timed behavior trees and their application to verifying real-time systems\n", "abstract": " Behavior trees (BTs) are a graphical notation used for formalising functional requirements and have been successfully applied to several case studies. However, the notation currently does not support the concept of time and consequently its application is limited to non-real-time systems. To overcome this limitation we extend the notation to timed behavior trees, which can be semantically defined by timed automata. Based on this extension we are able to include local timing assumptions in a BT model and can verify system-level timing properties with temporal proof methodologies. We validate the use of the new notation by means of a case study. To verify system-level timing properties we translate the model into timed automata and use the tool UPPAAL for timed model checking.", "num_citations": "20\n", "authors": ["1906"]}
{"title": "Co-Evolution of Software Architecture and Fault Tree models: An Explorative Case Study on a Pick and Place Factory Automation System.\n", "abstract": " Safety-critical systems are subject to rigorous safety analyses, eg, hazard analyses. Fault trees are a deductive technique to derive the combination of faults which cause a hazard. There is a tight relationship between fault trees and system architecture as the components contain the faults and the component structure influences the fault combinations. In this paper, we describe an explorative case study on multiple evolution scenarios of a factory automation system. We report on the evolution steps on the system architecture models and fault trees and how the evolution steps in the different models relate to each other.", "num_citations": "15\n", "authors": ["1906"]}
{"title": "Automated software architecture evolution with hypergraph transformation\n", "abstract": " AUTOMATED SOFTWARE ARCHITECTURE EVOLUTION WITH HYPERGRAPH TRANSFORMATION Lars Grunske Department of Software Engineering and Quality Management Hasso-Plattner-Institute for Software Systems Engineering, University of Potsdam Prof.-Dr.-Helmert-Stra\u00dfe 2-3, D-14482 Potsdam (Germany) +49(0)3315509152 grunske@hpi.uni-potsdam.de Abstract Architectural transformations are an appropriate technique for the development and improvement of architectural specifications. But these transformations are often applied manually. This paper presents a mapping of an architectural specification language to a hypergraph- based data structure. Thus, architectural transformations can be specified by hypergraph transformation rules and applied automatically. Key Words Architecture Specification and Evolution, Hypergraph Transformation, Non-Functional Properties 1. Introduction Over the \u2026", "num_citations": "14\n", "authors": ["1906"]}
{"title": "Increasing dependability of component-based software systems by online failure prediction (short paper)\n", "abstract": " Online failure prediction for large-scale software systems is a challenging task. One reason is the complex structure of many-partially inter-dependent-hardware and software components. State-of-the-art approaches use separate prediction models for parameters of interest or a monolithic prediction model which includes different parameters of all components. However, they have problems when dealing with evolving systems. In this paper, we propose our preliminary research work on online failure prediction targeting large-scale component-based software systems. For the prediction, three complementary types of models are used: (i) an architectural model captures relevant properties of hardware and software components as well as dependencies among them, (ii) for each component, a prediction model captures the current state of a component and predicts independent component failures in the future, (iii) a\u00a0\u2026", "num_citations": "13\n", "authors": ["1906"]}
{"title": "Using automated control charts for the runtime evaluation of qos attributes\n", "abstract": " As modern software systems operate in a highly dynamic context, they have to adapt their behaviour in response to changes in their operational environment or/and requirements. Triggering adaptation depends on detecting quality of service (QoS) violations by comparing observed QoS values to predefined thresholds. These threshold-based adaptation approaches result in late adaptations as they wait until violations have occurred. This may lead to undesired consequences such as late response to critical events. In this paper we introduce a statistical approach CREQA - Control Charts for the Runtime Evaluation of QoS Attributes. This approach estimates at runtime capability of a system, and then it monitors and provides early detection of any changes in QoS values allowing timely intervention in order to prevent undesired consequences. We validated our approach using a series of experiments and response\u00a0\u2026", "num_citations": "13\n", "authors": ["1906"]}
{"title": "Choosing the appropriate forecasting model for predictive parameter control\n", "abstract": " All commonly used stochastic optimisation algorithms have to be parameterised to perform effectively. Adaptive parameter control (APC) is an effective method used for this purpose. APC repeatedly adjusts parameter values during the optimisation process for optimal algorithm performance. The assignment of parameter values for a given iteration is based on previously measured performance. In recent research, time series prediction has been proposed as a method of projecting the probabilities to use for parameter value selection. In this work, we examine the suitability of a variety of prediction methods for the projection of future parameter performance based on previous data. All considered prediction methods have assumptions the time series data has to conform to for the prediction method to provide accurate projections. Looking specifically at parameters of evolutionary algorithms (EAs), we find that all\u00a0\u2026", "num_citations": "12\n", "authors": ["1906"]}
{"title": "Statistical detection of qos violations based on cusum control charts\n", "abstract": " Currently software systems operate in highly dynamic contexts, and consequently they have to adapt their behavior in response to changes in their contexts or/and requirements. Existing approaches trigger adaptations after detecting violations in quality of service (QoS) requirements by just comparing observed QoS values to predefined thresholds without any statistical confidence or certainty. These threshold-based adaptation approaches may perform unnecessary adaptations, which can lead to severe shortcomings such as follow-up failures or increased costs. In this paper we introduce a statistical approach based on CUSUM control charts called AuDeQAV-Automated Detection of QoS Attributes Violations. This approach estimates at runtime a current status of the running system, and monitors its QoS attributes and provides early detection of violations in its requirements with a defined level of confidence. This\u00a0\u2026", "num_citations": "12\n", "authors": ["1906"]}
{"title": "Generalizable safety annotations for specification of failure patterns\n", "abstract": " Components in programmable systems often exhibit patterns of failure that are independent of function or system context. In this paper, we show that it is possible to capture, and reuse where appropriate, such patterns for the purposes of system safety analysis. We describe a language that enables abstract specification of failure behaviour and define the syntax and semantics of this language. The language extends concepts originally defined in HiP\u2010HOPS, a technique that enables a largely automated form of compositional system safety analysis. The paper describes how this language can be used to describe component failure patterns and demonstrates how it can be applied using a simple fuel system example. The approach is evaluated on a set of retrospective industrial case studies, where data\u2010mining and reverse engineering techniques are applied in order to identify hidden patterns in legacy safety\u00a0\u2026", "num_citations": "12\n", "authors": ["1906"]}
{"title": "Online workload forecasting\n", "abstract": " This chapter gives a summary of the state-of-the-art approaches from different research fields that can be applied to continuously forecast future developments of time series data streams. More specifically, the input time series data contains continuously monitored metrics that quantify the amount of incoming workload units to a self-aware system. It is the goal of this chapter to identify and present approaches for online workload forecasting that are required for a self-aware system to act proactively\u2014in terms of problem prevention and optimization\u2014inferred from likely changes in their usage. The research fields covered are machine learning and time series analysis. We describe explicit limitations and advantages for each forecasting method.", "num_citations": "11\n", "authors": ["1906"]}
{"title": "Capture and reuse of composable failure patterns\n", "abstract": " Emerging safety analysis techniques use composition of failure models or fault simulation in formal models of a system to determine relationships between the causes and effects of failure. Most recent work has focused on developing system modelling and algorithms for automatic safety analysis. However, little work has focused on developing principles to improve reuse of safety analyses in the context of these techniques. In this paper, we describe a generalised failure logic (GFL) that can capture abstract reusable characteristics of failure behaviour and show how the GFL can be used with templates for the specification of reusable and inheritable component failure patterns. Finally, we illustrate how such patterns can be used with HiP-HOPS, an automated fault tree and FMEA synthesis tool, in order to simplify safety analysis while formalising and improving reuse. Benefits of this approach are discussed in the\u00a0\u2026", "num_citations": "10\n", "authors": ["1906"]}
{"title": "Timed simulation of extended AADL-based architecture specifications with timed abstract state machines\n", "abstract": " The Architecture Analysis and Design Language (AADL) is a popular language for architectural modeling and analysis of software intensive systems in application domains such as automotive, avionics, railway and medical systems. These systems often have stringent real-time requirements. This paper presents an extension to AADL\u2019s behavior model using time annotations in order to improve the evaluation of timing properties in AADL. The translational semantics of this extension is based on mappings to the Timed Abstract State Machines (TASM) language. As a result, timing analysis with timed simulation or timed model checking is possible. The translation is supported by an Eclipse-based plug-in and the approach is validated with a case study of an industrial production cell system.", "num_citations": "10\n", "authors": ["1906"]}
{"title": "CoWolf\u2013A generic framework for multi-view co-evolution and evaluation of models\n", "abstract": " Agile and iterative development with changing requirements lead to continuously changing models. In particular, the researchers are faced with the problem of consistently co-evolving different views of a model-based system. Whenever one model undergoes changes, corresponding models should co-evolve with respect to this change. On the other hand, domain engineers are faced with the huge challenge to find proper co-evolution rules which can be finally used to assist developers in the co-evolution process. In this paper, we introduce the CoWolf framework that enables co-evolution actions between related models and provides a tooling environment. Furthermore, we demonstrate the results of a case study on the developed tool.", "num_citations": "9\n", "authors": ["1906"]}
{"title": "PSPWizard: machine-assisted definition of temporal logical properties with specification patterns\n", "abstract": " Model checking provides a powerful means to assert and verify desired system properties. But, for the verification process to become feasible, a correct formulation of these properties in a temporal logic is necessary-a potential barrier to application in practice. Research on property specification has supplied us with rich pattern catalogs that capture commonly occurring system properties in different temporal logics. Furthermore, these property specification pattern catalogs usually offer both a structured English grammar to facilitate the pattern selection and an associated template solutions to express the properties formally. Yet, the actual use of property specification patterns remains cumbersome, due to limited tool support. For this reason, we have developed the Property Specification Pattern Wizard (PSPWizard), a framework that defines an interface for the currently accepted property specification pattern libraries\u00a0\u2026", "num_citations": "9\n", "authors": ["1906"]}
{"title": "State space reduction techniques for component interfaces\n", "abstract": " Automata-based interface and protocol specifications provide an elegant framework to capture and automatically verify the interactive behavior of component-based software systems. Unfortunately, the underlying formalisms suffer from combinatorial state explosion when constructing new specifications for composite components or systems and may therefore render the application of these techniques impractical for real-world applications. In this paper, we explore the bisimulation technique as a means for a mechanical state space reduction of component-based systems. In particular, we apply both strong and weak bisimulation to Component Interaction Automata in order to obtain a minimal automata that can serve as a behavioral equivalent abstraction for a given component specification and illustrate that the proposed approach can significantly reduce the complexity of an interface specification after\u00a0\u2026", "num_citations": "8\n", "authors": ["1906"]}
{"title": "MetaFMEA-A framework for reusable FMEAs\n", "abstract": " Failure mode and effects analysis (FMEA), is a widely used deductive failure analysis for safety critical systems. Since modern safety critical systems tend to increased complexity, automation and tool support have a long history in research and industry. Whereas compact embedded systems can be analyzed using FMEA in a manually maintained table using for example a spreadsheet application, complex systems easily result in an unmanageable long table especially when larger development teams are involved. During the application of the methodology in industry, two central problems were observed. First, textually described effects are interpreted differently and lead to inconsistencies. Second, one component often is used multiple times in a system, e.g. in electronic circuits where huge circuits are build using a small number of electronic devices. Each implementation of a component results in the\u00a0\u2026", "num_citations": "7\n", "authors": ["1906"]}
{"title": "Adaptive cruise controllers\u2013a literature review\n", "abstract": " An Adaptive Cruise Control (ACC) is an automobile system which purpose is control the velocity of the vehicle with regards to the surrounding environment. This report gives description of ACC models, a detailed description of the architecture of the ACC, and a survey of the ACCs on the market of today.", "num_citations": "6\n", "authors": ["1906"]}
{"title": "Architecture Description Languages for Automotive Systems\u2013A Literature Review\n", "abstract": " An Architecture Description Language (ADL) can be described as a language designed to model a system at an architectural level with respect to its software, hardware, and communication links. Due to the increasing complexity of software systems in areas like embedded control and web-based information systems, modelling with ADLs have gained attention in the research community and in practical software development projects. The specific aim of this technical report is to provide a literature review on ADLs for automotive software systems. This literature review consequently focuses on aspects that are relevant for automotive systems like safety, reliability and modelling of Electronic Control Units (ECU).", "num_citations": "6\n", "authors": ["1906"]}
{"title": "Application of behavior-preserving transformations to improve non-functional properties of an architecture specification\n", "abstract": " In particular for safety critical systems it is necessary to make sure that the non-functional properties imposed by a system architecture meet the corresponding requirements as early as possible. Therefore, appropriate architectural transformations have to be applied in the design phase in case the non-functional properties do not fulfill their requirements. As the selection and application of appropriate architectural transformations is a time consuming task and demands for personal effort, there is the idea to automate the architecture evolution process. In this paper, we outline our hypergraph-based approach towards automating the architecture evolution process and propose an algorithm that proves the behavioral equivalence of the architecture before and after a transformation.", "num_citations": "6\n", "authors": ["1906"]}
{"title": "Quality optimisation of software architectures and design specifications\n", "abstract": " This special issue of the Journal of Systems and Software presents novel software architecture optimisation frameworks. The majority of the approaches consider the problem of optimising conflicting quality attributes simultaneously. Other approaches focus on effectively searching for better software architectures by either using smart problem-dependent heuristics or by combining the expression power of ADLs with architecture optimisation.", "num_citations": "5\n", "authors": ["1906"]}
{"title": "Behavioral types for embedded software\u2013A survey\n", "abstract": " At present, there is a variety of formalisms for modeling and analyzing the communication behavior of components. Due to a tremendous increase in size and complexity of embedded systems accompanied by shorter time to market cycles and cost reduction, so called behavioral type systems become more and more important. This chapter presents an overview and a taxonomy of behavioral types. The intentions of this taxonomy are to provide a guidance for software engineers and to form the basis for future research.", "num_citations": "5\n", "authors": ["1906"]}
{"title": "Continuous assessment of designs and re-use in model-based safety analysis\n", "abstract": " To deliver complex functionalities in a cost effective manner, distributed manufacturing systems should ideally be based on standard interoperable components and be flexible and easily extensible. At the same time, systems must be demonstrably safe and reliable. In this paper, we argue that to balance these conflicting demands effective safety analysis techniques are required that partly automate and simplify off-line safety assessment. We outline a technique that automates the construction of fault trees and FMEAs and explain how this technique can be repeatedly applied in the course of the design life-cycle on functional and architectural models to enable continuous assessment of evolving designs. Finally, we discuss the issue of re-use of safety analyses and give examples of how such reuse simplifies the assessment.", "num_citations": "5\n", "authors": ["1906"]}
{"title": "Formal Semantics for Probabilistic Verification of Stochastic Regular Expressions.\n", "abstract": " Modelling and verification of software systems is an effective phase of system development, as it can uncover failures in design early in the development process. There is an increasing need for languages and processes that allow for the specification of uncertainty that allow, for example, the modelling of the unknown behaviour of a user, or the stochastic failure rate of hardware components. In this paper we introduce a formal semantics on Stochastic Regular Expressions (SREs) over probabilistic action logics for quantitative verification. We provide the recursive calculation of the language generated by an SRE, enhanced to reuse local results for global verification of system specifications. Furthermore, we demonstrate how to model systems with SREs and how to perform reachability analysis with Probabilistic Action-based Computational Tree Logic (PACTL*).", "num_citations": "3\n", "authors": ["1906"]}
{"title": "Process Components for Quality Evaluation and Quality Improvement\n", "abstract": " Processes and methods used for software construction have a high influence on the quality of the resulting software product. Therefore, the research in the field of method engineering should be more focused on quality aspects. Due to this reason, we propose in this paper, process components for quality evaluation and quality improvement. These process components can be stored in a repository and the instances of these process components can be used in process frameworks (eg OPEN Process Framework).", "num_citations": "3\n", "authors": ["1906"]}
{"title": "History-based model repair recommendations\n", "abstract": " Models in Model-driven Engineering are primary development artifacts that are heavily edited in all stages of software development and that can become temporarily inconsistent during editing. In general, there are many alternatives to resolve an inconsistency, and which one is the most suitable depends on a variety of factors. As also proposed by recent approaches to model repair, it is reasonable to leave the actual choice and approval of a repair alternative to the discretion of the developer. Model repair tools can support developers by proposing a list of the most promising repairs. Such repair recommendations will be only accepted in practice if the generated proposals are plausible and understandable, and if the set as a whole is manageable. Current approaches, which mostly focus on exhaustive search strategies, exploring all possible model repairs without considering the intention of historic changes, fail\u00a0\u2026", "num_citations": "2\n", "authors": ["1906"]}
{"title": "Evolutionary algorithms for safety-cost trade-offs in control system design\n", "abstract": " In the design of safety critical systems, engineers have to find trade-offs between different safety attributes, as well as between safety and costs, because in most cases the improvement of one safety attribute can't be achieved without causing extra costs or decreasing another safety attribute. This paper proposes the usage of evolutionary algorithms as multi-objective optimisation strategies to automatically find Pareto-optimal solutions that could be used as an input for the decision making process. The benefit of using evolutionary algorithms is in the ability to deal with complex solution spaces.", "num_citations": "2\n", "authors": ["1906"]}
{"title": "Mofuzz: A fuzzer suite for testing model-driven software engineering tools\n", "abstract": " Fuzzing or fuzz testing is an established technique that aims to discover unexpected program behavior (e.g., bugs, security vulnerabilities, or crashes) by feeding automatically generated data into a program under test. However, the application of fuzzing to test Model-Driven Software Engineering (MDSE) tools is still limited because of the difficulty of existing fuzzers to provide structured, well-typed inputs, namely models that conform to typing and consistency constraints induced by a given meta-model and underlying modeling framework. By drawing from recent advances on both fuzz testing and automated model generation, we present three different approaches for fuzzing MDSE tools: A graph grammar-based fuzzer and two variants of a coverage-guided mutation-based fuzzer working with different sets of model mutation operators. Our evaluation on a set of real-world MDSE tools shows that our approaches\u00a0\u2026", "num_citations": "1\n", "authors": ["1906"]}
{"title": "Learning from Evolution for Evolution\n", "abstract": " Missing knowledge about the system is often one of the root causes of failed software evolution in practice. For example, the well-known failed maiden launch of the Ariane 5 rocket [Dow97] can be attributed partly to missing knowledge about the behaviour of a software system reused from the Ariane 4 rocket. The old software was integrated into the Ariane 5 rocket, which, however, had a different flight trajectory compared to the Ariane 4 rocket. That integration problem led to a value conversion error eventually causing the self-destruction of the rocket. This very costly error serves as an illustrative example of the effects of missing knowledge during the evolution of systems. One of the focus areas of the priority program aims at providing \u201cKnowledge Carrying Software\u201d, that is avoiding missing knowledge in the first place. The other focus areas,\u201cMethods and Processes\u201d and \u201cPlatforms and Environments for Evolution\u201d, enable knowledge-carrying software. For successful evolution, knowledge not only about a piece of software but also about its environment, hardware, network, other software, libraries, and ecosystem is needed. Furthermore, users are an important part of the environment, and thus knowledge about the number of users, their different roles as stakeholders in the software, and their behaviour is equally important. For the software itself, knowledge about its structure, that is architecture and design, and its behaviour, is required.Based on the joint automation case study, the Pick and Place Unit (PPU)(see Chap. 4), several projects in the priority program address the process of acquiring such missing knowledge, that is they support the\u00a0\u2026", "num_citations": "1\n", "authors": ["1906"]}
{"title": "Informatik 2014\n", "abstract": " Informatik 2014 - Digitale Bibliothek - Gesellschaft f\u00fcr Informatik eV GI Logo GI Logo Anmelden Digitale Bibliothek Gesamter Bestand Bereiche & Sammlungen Titel Autor Erscheinungsdatum Schlagwort Diese Sammlung Titel Autor Erscheinungsdatum Schlagwort Toggle navigation Digital Bibliothek der Gesellschaft f\u00fcr Informatik eV GI-DL English Deutsch Deutsch English Deutsch Dokumentanzeige Startseite Lecture Notes in Informatics Proceedings INFORMATIK - Jahrestagung der Gesellschaft f\u00fcr Informatik eV P232 - INFORMATIK 2014 Dokumentanzeige Startseite Lecture Notes in Informatics Proceedings INFORMATIK - Jahrestagung der Gesellschaft f\u00fcr Informatik eV P232 - INFORMATIK 2014 Dokumentanzeige Informatik 2014 Autor(en): Pl\u00f6dereder, E. [DBLP] Grunske, L. [DBLP] Schneider, E. [DBLP] Ull, D. [DBLP] Vollst\u00e4ndige Referenz BibTeX Unbekannter Autor (2014). Informatik 2014. In: Pl\u00f6dereder, E., \u2026", "num_citations": "1\n", "authors": ["1906"]}
{"title": "Modeling an Adaptive Cruise Con-troller in the Architecture Analy-sis and Design Language: A Case Study\n", "abstract": " An Adaptive Cruise Control (ACC) is a part of an automobile system which purpose is to control the vehicle speed with regards to the surrounding environment. The objective of this report is to evaluate whether the Architecture and Analysis Description Language (AADL) is suitable to model an ACC. This report describes an ACC modeled in AADL with its Behavior and Error Annex.", "num_citations": "1\n", "authors": ["1906"]}