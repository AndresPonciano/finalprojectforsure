{"title": "XSB as an Efficient Deductive Database Engine\n", "abstract": " This paper describes the XSB system, and its use as an in-memory deductive database engine. XSB began from a Prolog foundation, and traditional Prolog systems are known to have serious deficiencies when used as database systems. Accordingly, XSB has a fundamental bottom-up extension, introduced through tabling (or memoing)[4], which makes it appropriate as an underlying query engine for deductive database systems. Because it eliminates redundant computation, the tabling extension makes XSB able to compute all modularly stratified datalog programs finitely and with polynomial data complexity. For non-stratified programs, a meta-interpreter with the same properties is provided. In addition XSB significantly extends and improves the indexing capabilities over those of standard Prolog.  Finally, its syntactic basis in HiLog [2], lends it flexibility for data modelling.The implementation of XSB derives from\u00a0\u2026", "num_citations": "555\n", "authors": ["351"]}
{"title": "XSB: A system for efficiently computing well-founded semantics\n", "abstract": " The well-founded model provides a natural and robust semantics for logic programs with negative literals in rule bodies. We implemented the well-founded semantics in the SLG-WAM of XSB [19]. Performance results indicate that the overhead of delay and simplification to Prolog \u2014 or tabled \u2014 evaluations is minimal. To compute the well-founded semantics, the SLG-WAM adds to an efficient tabling engine for definite programs three operations \u2014 negative loop detection, delay and simplification \u2014 which serve to detect, to break and to resolve cycles through negation that might arise in evaluating normal programs. XSB is a full Prolog system that closely approximates the ISO standard; additionally, it supports a tight integration of tabled predicates with nontabled predicates.", "num_citations": "200\n", "authors": ["351"]}
{"title": "Optimal dynamic partial order reduction\n", "abstract": " Stateless model checking is a powerful technique for program verification, which however suffers from an exponential growth in the number of explored executions. A successful technique for reducing this number, while still maintaining complete coverage, is Dynamic Partial Order Reduction (DPOR). We present a new DPOR algorithm, which is the first to be provably optimal in that it always explores the minimal number of executions. It is based on a novel class of sets, called source sets, which replace the role of persistent sets in previous algorithms. First, we show how to modify an existing DPOR algorithm to work with source sets, resulting in an efficient and simple to implement algorithm. Second, we extend this algorithm with a novel mechanism, called wakeup trees, that allows to achieve optimality. We have implemented both algorithms in a stateless model checking tool for Erlang programs. Experiments show\u00a0\u2026", "num_citations": "178\n", "authors": ["351"]}
{"title": "An abstract machine for tabled execution of fixed-order stratified logic programs\n", "abstract": " SLG resolution uses tabling to evaluate nonfloundering normal logic pr ograms according to the well-founded semantics.  The SLG-WAM, which forms the engine of the XSB system, can compute in-memory recursive queries an order of magnitute faster than current deductive databases.  At the same time, the SLG-WAM tightly intergrates Prolog code with tabled SLG code, and executes Prolog code with minimal overhead compared to the WAM.  As a result, the SLG-WAM brings to logic programming important termination and complexity properties of deductive databases.  This article describes the architecture of the SLG-WAM for a powerful class of programs, the class of fixed-order dynamically stratified programs.  We offer a detailed description of the algorithms,  data structures, and instructions that the SLG-WAM adds to the WAM, and a performance analysis of engine overhead due to the extensions.", "num_citations": "160\n", "authors": ["351"]}
{"title": "Stateless Model Checking for TSO and PSO\n", "abstract": " We present a technique for efficient stateless model checking of programs that execute under the relaxed memory models TSO and PSO. The basis for our technique is a novel representation of executions under TSO and PSO, called chronological traces. Chronological traces induce a partial order relation on relaxed memory executions, capturing dependencies that are needed to represent the interaction via shared variables. They are optimal in the sense that they only distinguish computations that are inequivalent under the widely-used representation by Shasha and Snir. This allows an optimal dynamic partial order reduction algorithm to explore a minimal number of executions while still guaranteeing full coverage. We apply our techniques to check, under the TSO and PSO memory models, LLVM assembly produced for C/pthreads programs. Our experiments show that our technique reduces the\u00a0\u2026", "num_citations": "137\n", "authors": ["351"]}
{"title": "Efficient access mechanisms for tabled logic programs\n", "abstract": " The use of tabling in logic programming allows bottom-up evaluation to be incorporated in a top-down framework, combining advantages of both. At the engine level, tabling also introduces issues not present in pure top-down evaluation, due to the need for subgoals and answers to access tables during resolution. This article describes the design, implementation, and experimental evaluation of data structures and algorithms for high-performance table access. Our approach uses tries as the basis for tables. Tries, a variant of discrimination nets, provide complete discrimination for terms, and permit a lookup and possible insertion to be performed in a single pass through a term. In addition, a novel technique of substitution factoring is proposed. When substitution factoring is used, the access cost for answers is proportional to the size of the answer substitution, rather than to the size of the answer itself. Answer tries\u00a0\u2026", "num_citations": "117\n", "authors": ["351"]}
{"title": "Practical type inference based on success typings\n", "abstract": " In languages where the compiler performs no static type checks, many programs never go wrong, but the intended use of functions and component interfaces is often undocumented or appears only in the form of comments which cannot always be trusted. This often makes program maintenance problematic. We show that it is possible to reconstruct a significant portion of the type information which is implicit in a program, automatically annotate function interfaces, and detect definite type clashes without fundamental changes to the philosophy of the language or imposing a type system which unnecessarily rejects perfectly reasonable programs. To do so, we introduce the notion of success typings of functions. Unlike most static type systems, success typings incorporate subtyping and never disallow a use of a function that will not result in a type clash during runtime. Unlike most soft typing systems that have\u00a0\u2026", "num_citations": "111\n", "authors": ["351"]}
{"title": "A PropEr integration of types and function specifications with property-based testing\n", "abstract": " We present a tight integration of the language of types and function specifications of Erlang with property-based testing. To achieve this integration we have developed from scratch PropEr, an open-source QuickCheck-inspired property-based testing tool. We present technical details of this integration, most notably how the conversion of recursive types into appropriate generators takes place and how function specifications can be turned automatically into simple properties in order to exercise the code of these functions. Finally, we present experiences and advice for the proper use of PropEr.", "num_citations": "100\n", "authors": ["351"]}
{"title": "Detecting software defects in telecom applications through lightweight static analysis: A war story\n", "abstract": " In safety-critical and high-reliability systems, software development and maintenance are costly endeavors. The cost can be reduced if software errors can be identified through automatic tools such as program analyzers and compile-time software checkers. To this effect, this paper describes the architecture and implementation of a software tool that uses lightweight static analysis to detect discrepancies (i.e., software defects such as exception-raising code or hidden failures) in large commercial telecom applications written in Erlang. Our tool, starting from virtual machine bytecode, discovers, tracks, and propagates type information which is often implicit in Erlang programs, and reports warnings when a variety of type errors and other software discrepancies are identified. Since the analysis currently starts from bytecode, it is completely automatic and does not rely on any user annotations. Moreover, it is\u00a0\u2026", "num_citations": "69\n", "authors": ["351"]}
{"title": "A high performance Erlang system\n", "abstract": " Erlang is a concurrent functional programming language designed to ease the development of large-scale distributed soft real-time control applications. It has so far been quite successful in this application domain, despite the fact that its currently available implementations are emulators of virtual machines. In this paper, we improve on the performance aspects of Erlang implementations by presenting HiPE, an open-source native code compiler for Erlang. HiPE is a complete implementation of Erlang, offers flexible integration between emulated and native code, and efficiently supports features crucial for Erlang's application domain such as concurrency. As our performance evaluations show, HiPE is currently the fastest among all Erlang implementations.", "num_citations": "61\n", "authors": ["351"]}
{"title": "CAT: The copying approach to tabling\n", "abstract": " The SLG-WAM implements tabling by freezing the WAM stacks: this technique has a reasonably small execution overhead, but is not easy to implement on top of an existing Prolog system. We propose a new technique for the implementation of tabling: the Copying Approach to Tabling. CAT does not interfere with normal Prolog execution and can be introduced in an existing Prolog system orthogonally. We have implemented CAT starting from XSB by taking out SLG-WAM and adding CAT. We describe the additions needed for adopting CAT in a WAM implementation. We show a case in which CAT performs arbitrarily worse than SLG-WAM, but on the other hand we present empirical evidence that CAT is competitive and often faster than SLG-WAM. We discuss issues related to memory management and the impact of the scheduling.", "num_citations": "60\n", "authors": ["351"]}
{"title": "CHAT: The copy-hybrid approach to tabling\n", "abstract": " The Copying Approach to Tabling, abbrv. CAT, is an alternative to SLG-WAM and based on total copying of the areas that the SLG-WAM freezes to preserve execution states of suspended computations. The disadvantage of CAT as pointed out in a previous paper is that in the worst case, CAT must copy so much that it becomes arbitrarily worse than the SLG-WAM. Remedies to this problem have been studied, but a completely satisfactory solution has not emerged. Here, a hybrid approach is presented: CHAT. Its design was guided by the requirement that for non-tabled (i.e. Prolog) execution no changes to the underlying WAM engine need to be made. CHAT combines certain features of the SLG-WAM with features of CAT, but also introduces a technique for freezing WAM stacks without the use of the SLG-WAM\u2019s freeze registers that is of independent interest. Empirical results indicate that CHAT is a better\u00a0\u2026", "num_citations": "58\n", "authors": ["351"]}
{"title": "Systematic testing for detecting concurrency errors in Erlang programs\n", "abstract": " We present the techniques used in Concuerror, a systematic testing tool able to find and reproduce a wide class of concurrency errors in Erlang programs. We describe how we take advantage of the characteristics of Erlang's actor model of concurrency to selectively instrument the program under test and how we subsequently employ a stateless search strategy to systematically explore the state space of process interleaving sequences triggered by unit tests. To ameliorate the problem of combinatorial explosion, we propose a novel technique for avoiding process blocks and describe how we can effectively combine it with preemption bounding, a heuristic algorithm for reducing the number of explored interleaving sequences. We also briefly discuss issues related to soundness, completeness and effectiveness of techniques used by Concuerror.", "num_citations": "55\n", "authors": ["351"]}
{"title": "Demand-driven indexing of Prolog clauses\n", "abstract": " As logic programming applications grow in size, Prolog systems need to efficiently access larger and larger data sets and the need for any- and multi-argument indexing becomes more and more profound. Static generation of multi-argument indexing is one alternative, but applications often rely on features that are inherently dynamic which makes static techniques inapplicable or inaccurate. Another alternative is to employ dynamic schemes for flexible demand-driven indexing of Prolog clauses. We propose such schemes and discuss issues that need to be addressed for their efficient implementation in the context of WAM-based Prolog systems. We have implemented demand-driven indexing in two different Prolog systems and have been able to obtain non-negligible performance speedups: from a few percent up to orders of magnitude. Given these results, we see very little reason for Prolog systems not\u00a0\u2026", "num_citations": "49\n", "authors": ["351"]}
{"title": "Semantica: Version 1.0 (for NEXTSTEP)\n", "abstract": " Semanticais the manual for a new software application that allows the user to explore the semantic structure of language in an engaging, interactive way. The program, which was produced as part of a National Science Foundation initiative for improving linguistics instruction, is designed to be used with Syntactica, a tool for studying natural language syntax. Semanticaprovides a simple graphical interface for creating semantic theories, viewing the truth conditions that those theories assign to phrase-markers created in Syntactica, and for testing those truth conditions in a pictorially represented world. Although designed for use in introductory semantics courses, Semanticahas features that will appeal to professionals. For example, it can be used as a\" derivation calculator\" in following out complex semantic derivations involving many steps and operations. Manual plus NeXTStep software for PCs and NeXTStations running NeXTStep version 3.2 or higher.", "num_citations": "47\n", "authors": ["351"]}
{"title": "TypEr: A type annotator of Erlang code\n", "abstract": " We describe and document the techniques used in TOOL, a fully automatic type annotator for Erlang programs based on constraint-based type inference of success typings (a notion closely related to principal typings). The inferred typings are fine-grained and the type system currently includes subtyping and subtype polymorphism but not parametric polymorphism. In particular, we describe and illustrate through examples a type inference algorithm tailored to Erlang's characteristics which is modular, reasonably fast, and appears to scale well in practice.", "num_citations": "45\n", "authors": ["351"]}
{"title": "XSB: An overview of its use and implementation\n", "abstract": " Several features of the XSB Logic Programming System make it suitable as a database engine including: its foundation on SLG resolution, its e ciency for memory-resident queries, and its exibility for for data modelling. SLG resolution is a goal-directed resolution strategy that uses memoing and delay to compute the well-founded semantics for general programs. In doing so, XSB eliminates problems with literal ordering and with redundant computations so common when languages like Prolog are used for data-oriented applications. XSB extends the WAM (Warren Abstract Machine) 31] to implement SLG resolution. The implementation has been completed for (modularly) strati ed programs, and comparisons indicate that XSB is signi cantly faster than other deductive database systems for a wide range of queries.XSB o ers advanced facilities for data modelling as well. All interfaces of XSB syntax supports HiLog 2] syntax. HiLog predicates are compiled, and execute at speeds only slightly less than compiled Prolog. Furthermore, XSB o ers exible indexing and data storage facilities that make it suitable for a wide range of data-oriented problems. It is available through anonymous ftp.", "num_citations": "45\n", "authors": ["351"]}
{"title": "The XSB Programmer's Manual: Version 1.4.1\n", "abstract": " The XSB Programmer's Manual Version 1.7.1 \u0391\u03c1\u03c7\u03b9\u03ba\u03ae \u03a3\u03b5\u03bb\u03af\u03b4\u03b1 \u2192 \u039a\u03b5\u03bd\u03c4\u03c1\u03b9\u03ba\u03ae \u0392\u03b9\u03b2\u03bb\u03b9\u03bf\u03b8\u03ae\u03ba\u03b7 \u0395\u039c\u03a0\u2192 \u0399\u03b4\u03c1\u03c5\u03bc\u03b1\u03c4\u03b9\u03ba\u03cc \u0391\u03c0\u03bf\u03b8\u03b5\u03c4\u03ae\u03c1\u03b9\u03bf \u2192 \u0394\u03b7\u03bc\u03bf\u03c3\u03b9\u03b5\u03cd\u03c3\u03b5\u03b9\u03c2 \u03bc\u03b5\u03bb\u03ce\u03bd \u0394\u0395\u03a0\u03c3\u03b5 \u03c0\u03b5\u03c1\u03b9\u03bf\u03b4\u03b9\u03ba\u03ac \u2192 \u0395\u03bc\u03c6\u03ac\u03bd\u03b9\u03c3\u03b7 \u03a4\u03b5\u03ba\u03bc\u03b7\u03c1\u03af\u03bf\u03c5 HEAL DSpace The XSB Programmer's Manual Version 1.7.1 \u0391\u03c0\u03bf\u03b8\u03b5\u03c4\u03ae\u03c1\u03b9\u03bf DSpace/Manakin The XSB Programmer's Manual Version 1.7.1 Sagonas, K; Swift, T; Warren, D; Freire, J; Rao, P URI: http://hdl.handle.net/123456789/23854 \u0397\u03bc\u03b5\u03c1\u03bf\u03bc\u03b7\u03bd\u03af\u03b1: 1994 \u0395\u03bc\u03c6\u03ac\u03bd\u03b9\u03c3\u03b7 \u03c0\u03bb\u03ae\u03c1\u03bf\u03c5\u03c2 \u03b5\u03b3\u03b3\u03c1\u03b1\u03c6\u03ae\u03c2 \u0391\u03c1\u03c7\u03b5\u03af\u03b1 \u03c3\u03b5 \u03b1\u03c5\u03c4\u03cc \u03c4\u03bf \u03c4\u03b5\u03ba\u03bc\u03ae\u03c1\u03b9\u03bf \u0391\u03c1\u03c7\u03b5\u03af\u03b1 \u039c\u03ad\u03b3\u03b5\u03b8\u03bf\u03c2 \u039c\u03bf\u03c1\u03c6\u03cc\u03c4\u03c5\u03c0\u03bf \u03a0\u03c1\u03bf\u03b2\u03bf\u03bb\u03ae \u0394\u03b5\u03bd \u03c5\u03c0\u03ac\u03c1\u03c7\u03bf\u03c5\u03bd \u03b1\u03c1\u03c7\u03b5\u03af\u03b1 \u03c0\u03bf\u03c5 \u03c3\u03c7\u03b5\u03c4\u03af\u03b6\u03bf\u03bd\u03c4\u03b1\u03b9 \u03bc\u03b5 \u03b1\u03c5\u03c4\u03cc \u03c4\u03bf \u03c4\u03b5\u03ba\u03bc\u03ae\u03c1\u03b9\u03bf. \u0391\u03c5\u03c4\u03cc \u03c4\u03bf \u03c4\u03b5\u03ba\u03bc\u03ae\u03c1\u03b9\u03bf \u03b5\u03bc\u03c6\u03b1\u03bd\u03af\u03b6\u03b5\u03c4\u03b1\u03b9 \u03c3\u03c4\u03b7\u03bd \u03b1\u03ba\u03cc\u03bb\u03bf\u03c5\u03b8\u03b7 \u03c3\u03c5\u03bb\u03bb\u03bf\u03b3\u03ae(\u03ad\u03c2) \u0394\u03b7\u03bc\u03bf\u03c3\u03b9\u03b5\u03cd\u03c3\u03b5\u03b9\u03c2 \u03bc\u03b5\u03bb\u03ce\u03bd \u0394\u0395\u03a0\u03c3\u03b5 \u03c0\u03b5\u03c1\u03b9\u03bf\u03b4\u03b9\u03ba\u03ac \u03a0\u03b5\u03c1\u03b9\u03ae\u03b3\u03b7\u03c3\u03b7 \u03a3\u03b5 \u03cc\u03bb\u03bf \u03c4\u03bf DSpace \u039a\u03bf\u03b9\u03bd\u03cc\u03c4\u03b7\u03c4\u03b5\u03c2 & \u03a3\u03c5\u03bb\u03bb\u03bf\u03b3\u03ad\u03c2 \u0391\u03bd\u03ac \u0397\u03bc\u03b5\u03c1\u03bf\u03bc\u03b7\u03bd\u03af\u03b1 \u0395\u03ba\u03b4\u03bf\u03c3\u03b7\u03c2 \u03a3\u03c5\u03b3\u03b3\u03c1\u03b1\u03c6\u03b5\u03af\u03c2 \u03a4\u03af\u03c4\u03bb\u03bf\u03b9 \u0398\u03ad\u03bc\u03b1\u03c4\u03b1 \u0391\u03c5\u03c4\u03ae \u03b7 \u03a3\u03c5\u03bb\u03bb\u03bf\u03b3\u03ae \u0391\u03bd\u03ac \u0397\u03bc\u03b5\u03c1\u03bf\u03bc\u03b7\u03bd\u03af\u03b1 \u0395\u03ba\u03b4\u03bf\u03c3\u03b7\u03c2 \u03a3\u03c5\u03b3\u03b3\u03c1\u03b1\u03c6\u03b5\u03af\u03c2 \u03a4\u03af\u03c4\u03bb\u03bf\u03b9 \u0398\u03ad\u03bc\u03b1\u03c4\u03b1 \u039f \u039b\u03bf\u03b3\u03b1\u03c1\u03b9\u03b1\u03c3\u03bc\u03cc\u03c2 \u03bc\u03bf\u03c5 \u03a3\u03cd\u03bd\u03b4\u03b5\u03c3\u03b7 \u0395\u03b3\u03b3\u03c1\u03b1\u03c6\u03ae \u039f\u03b4\u03b7\u03b3\u03af\u03b5\u03c2 / \u0392\u03bf\u03ae\u03b8\u03b5\u03b9\u03b1 \u039f\u03b4\u03b7\u03b3\u03af\u03b5\u03c2 - \u2026", "num_citations": "44\n", "authors": ["351"]}
{"title": "A scalability benchmark suite for Erlang/OTP\n", "abstract": " Programming language implementers rely heavily on benchmarking for measuring and understanding performance of algorithms, architectural designs, and trade-offs between alternative implementations of compilers, runtime systems, and virtual machine components. Given this fact, it seems a bit ironic that it is often more difficult to come up with a good benchmark suite than a good implementation of a programming language.", "num_citations": "42\n", "authors": ["351"]}
{"title": "Static detection of race conditions in Erlang\n", "abstract": " We address the problem of detecting some commonly occurring kinds of race conditions in Erlang programs using static analysis. Our analysis is completely automatic, fast and scalable, and avoids false alarms by taking language characteristics into account. We have integrated our analysis in dialyzer, a commonly used tool for detecting software defects in Erlang programs which is part of Erlang/OTP, and evaluate its effectiveness and performance on a suite of widely used industrial and open source programs of considerable size. The analysis has detected a significant number of previously unknown race conditions.", "num_citations": "42\n", "authors": ["351"]}
{"title": "An Abstract Machine for Computing the Well-Founded Semantics\n", "abstract": " The well-founded semantics has gained wide acceptance partly because it is a skeptical semantics. That is, the well-founded model posits as unknown atoms which are deemed true or false in other formalisms such as stable models. This skepticism makes the well-founded model not only useful in itself, but also suitable as a basis for other forms of non-monotonic reasoning. For instance, since algorithms to compute stable models are intractable, the atoms relevant to such algorithms can be limited to those undefined in the well-founded model. This paper presents an implementation of the well-founded semantics in the SLG-WAM of XSB. To compute the well-founded semantics, the SLG-WAM adds three operations to its tabling engine| negative loop detection, delay and simplification| which serve to detect, to break and to resolve cycles through negation that may arise in evaluating normal programs. We describe fully the addition of these operations to our tabling engine, and demonstrate the efficiency of our implementation in two ways. First, we present a theorem that bounds the need for delay to those literals which are not dynamically stratified for a fixed-order computation. Secondly, we present performance results that indicate that the overhead of delay and simplification to Prolog| or tabled| evaluations is minimal.", "num_citations": "42\n", "authors": ["351"]}
{"title": "The Limits of Fixed-Order Computation\n", "abstract": " Fixed-order computation rules, used by Prolog and most deductive database systems, do not suffice to compute the well-founded semantics (Van Gelder et al., J. ACM 38 (3)(1991) 620\u2013650) because they cannot properly resolve loops through negation. This inadequacy is reflected both in formulations of SLS-resolution (Przymusinski, in: Proc. 8th ACM SIGACT-SIGMOD-SIGART Symp. on Principles of Database Systems, ACM Press, Philadelphia, Pennsylvania, March 1989, pp. 11\u201321; Ross, J. Logic Programming 13 (1)(1992) 1\u201322) which is an ideal search strategy, and in more practical strategies like SLG (Chen and Warren, J. ACM 43 (1)(1996) 20\u201374), or Well-Founded Ordered Search (Stucky and Sudarshan, J. Logic Programming 32 (3)(1997) 171\u2013206). Typically, these practical strategies combine an inexpensive fixed-order search with a relatively expensive dynamic search, such as an alternating fixed\u00a0\u2026", "num_citations": "41\n", "authors": ["351"]}
{"title": "The XSB programmer's manual\n", "abstract": " The XSB Programmer's Manual Version 1.7.1 \u0391\u03c1\u03c7\u03b9\u03ba\u03ae \u03a3\u03b5\u03bb\u03af\u03b4\u03b1 \u2192 \u039a\u03b5\u03bd\u03c4\u03c1\u03b9\u03ba\u03ae \u0392\u03b9\u03b2\u03bb\u03b9\u03bf\u03b8\u03ae\u03ba\u03b7 \u0395\u039c\u03a0\u2192 \u0399\u03b4\u03c1\u03c5\u03bc\u03b1\u03c4\u03b9\u03ba\u03cc \u0391\u03c0\u03bf\u03b8\u03b5\u03c4\u03ae\u03c1\u03b9\u03bf \u2192 \u0394\u03b7\u03bc\u03bf\u03c3\u03b9\u03b5\u03cd\u03c3\u03b5\u03b9\u03c2 \u03bc\u03b5\u03bb\u03ce\u03bd \u0394\u0395\u03a0\u03c3\u03b5 \u03c0\u03b5\u03c1\u03b9\u03bf\u03b4\u03b9\u03ba\u03ac \u2192 \u0395\u03bc\u03c6\u03ac\u03bd\u03b9\u03c3\u03b7 \u03a4\u03b5\u03ba\u03bc\u03b7\u03c1\u03af\u03bf\u03c5 HEAL DSpace The XSB Programmer's Manual Version 1.7.1 \u0391\u03c0\u03bf\u03b8\u03b5\u03c4\u03ae\u03c1\u03b9\u03bf DSpace/Manakin The XSB Programmer's Manual Version 1.7.1 Sagonas, K; Swift, T; Warren, D; Freire, J; Rao, P URI: http://hdl.handle.net/123456789/23854 \u0397\u03bc\u03b5\u03c1\u03bf\u03bc\u03b7\u03bd\u03af\u03b1: 1994 \u0395\u03bc\u03c6\u03ac\u03bd\u03b9\u03c3\u03b7 \u03c0\u03bb\u03ae\u03c1\u03bf\u03c5\u03c2 \u03b5\u03b3\u03b3\u03c1\u03b1\u03c6\u03ae\u03c2 \u0391\u03c1\u03c7\u03b5\u03af\u03b1 \u03c3\u03b5 \u03b1\u03c5\u03c4\u03cc \u03c4\u03bf \u03c4\u03b5\u03ba\u03bc\u03ae\u03c1\u03b9\u03bf \u0391\u03c1\u03c7\u03b5\u03af\u03b1 \u039c\u03ad\u03b3\u03b5\u03b8\u03bf\u03c2 \u039c\u03bf\u03c1\u03c6\u03cc\u03c4\u03c5\u03c0\u03bf \u03a0\u03c1\u03bf\u03b2\u03bf\u03bb\u03ae \u0394\u03b5\u03bd \u03c5\u03c0\u03ac\u03c1\u03c7\u03bf\u03c5\u03bd \u03b1\u03c1\u03c7\u03b5\u03af\u03b1 \u03c0\u03bf\u03c5 \u03c3\u03c7\u03b5\u03c4\u03af\u03b6\u03bf\u03bd\u03c4\u03b1\u03b9 \u03bc\u03b5 \u03b1\u03c5\u03c4\u03cc \u03c4\u03bf \u03c4\u03b5\u03ba\u03bc\u03ae\u03c1\u03b9\u03bf. \u0391\u03c5\u03c4\u03cc \u03c4\u03bf \u03c4\u03b5\u03ba\u03bc\u03ae\u03c1\u03b9\u03bf \u03b5\u03bc\u03c6\u03b1\u03bd\u03af\u03b6\u03b5\u03c4\u03b1\u03b9 \u03c3\u03c4\u03b7\u03bd \u03b1\u03ba\u03cc\u03bb\u03bf\u03c5\u03b8\u03b7 \u03c3\u03c5\u03bb\u03bb\u03bf\u03b3\u03ae(\u03ad\u03c2) \u0394\u03b7\u03bc\u03bf\u03c3\u03b9\u03b5\u03cd\u03c3\u03b5\u03b9\u03c2 \u03bc\u03b5\u03bb\u03ce\u03bd \u0394\u0395\u03a0\u03c3\u03b5 \u03c0\u03b5\u03c1\u03b9\u03bf\u03b4\u03b9\u03ba\u03ac \u03a0\u03b5\u03c1\u03b9\u03ae\u03b3\u03b7\u03c3\u03b7 \u03a3\u03b5 \u03cc\u03bb\u03bf \u03c4\u03bf DSpace \u039a\u03bf\u03b9\u03bd\u03cc\u03c4\u03b7\u03c4\u03b5\u03c2 & \u03a3\u03c5\u03bb\u03bb\u03bf\u03b3\u03ad\u03c2 \u0391\u03bd\u03ac \u0397\u03bc\u03b5\u03c1\u03bf\u03bc\u03b7\u03bd\u03af\u03b1 \u0395\u03ba\u03b4\u03bf\u03c3\u03b7\u03c2 \u03a3\u03c5\u03b3\u03b3\u03c1\u03b1\u03c6\u03b5\u03af\u03c2 \u03a4\u03af\u03c4\u03bb\u03bf\u03b9 \u0398\u03ad\u03bc\u03b1\u03c4\u03b1 \u0391\u03c5\u03c4\u03ae \u03b7 \u03a3\u03c5\u03bb\u03bb\u03bf\u03b3\u03ae \u0391\u03bd\u03ac \u0397\u03bc\u03b5\u03c1\u03bf\u03bc\u03b7\u03bd\u03af\u03b1 \u0395\u03ba\u03b4\u03bf\u03c3\u03b7\u03c2 \u03a3\u03c5\u03b3\u03b3\u03c1\u03b1\u03c6\u03b5\u03af\u03c2 \u03a4\u03af\u03c4\u03bb\u03bf\u03b9 \u0398\u03ad\u03bc\u03b1\u03c4\u03b1 \u039f \u039b\u03bf\u03b3\u03b1\u03c1\u03b9\u03b1\u03c3\u03bc\u03cc\u03c2 \u03bc\u03bf\u03c5 \u03a3\u03cd\u03bd\u03b4\u03b5\u03c3\u03b7 \u0395\u03b3\u03b3\u03c1\u03b1\u03c6\u03ae \u039f\u03b4\u03b7\u03b3\u03af\u03b5\u03c2 / \u0392\u03bf\u03ae\u03b8\u03b5\u03b9\u03b1 \u039f\u03b4\u03b7\u03b3\u03af\u03b5\u03c2 - \u2026", "num_citations": "41\n", "authors": ["351"]}
{"title": "Detection of asynchronous message passing errors using static analysis\n", "abstract": " Concurrent programming is hard and prone to subtle errors. In this paper we present a static analysis that is able to detect some commonly occurring kinds of message passing errors in languages with dynamic process creation and communication based on asynchronous message passing. Our analysis is completely automatic, fast, and strikes a proper balance between soundness and completeness: it is effective in detecting errors and avoids false alarms by computing a close approximation of the interprocess communication topology of programs. We have integrated our analysis in dialyzer, a widely used tool for detecting software defects in Erlang programs, and demonstrate its effectiveness on libraries and applications of considerable size. Despite the fact that these applications have been developed over a long period of time and are reasonably well-tested, our analysis has managed to detect a\u00a0\u2026", "num_citations": "40\n", "authors": ["351"]}
{"title": "Termination proofs for logic programs with tabling\n", "abstract": " Tabled evaluation is receiving increasing attention in the logic programming community. It avoids many of the shortcomings of SLD execution and provides a more flexible and often considerably more efficient execution mechanism for logic programs. In particular, tabled execution terminates more often than execution based on SLD-resolution. In this article, we introduce two notions of universal termination of logic programming with tabling: quasi-termination and (the stronger notion of) LG-termination. We present sufficient conditions for these two notions of termination, namely quasi-acceptability and LG-acceptability, and we show that these conditions are also necessary in case the selection of tabled predicates meets certain natural criteria. Starting from these conditions, we  develop modular termination proofs, i.e., proofs capable of combining termination proofs of separate programs to obtain termination proofs\u00a0\u2026", "num_citations": "39\n", "authors": ["351"]}
{"title": "Unification factoring for efficient execution of logic programs\n", "abstract": " The efficiency of resolution-based logic programming languages, such as Prolog, depends critically on selecting and executing sets of applicable clause heads to resolve against subgoals. Traditional approaches to this problem have focused on using indexing to determine the smallest possible applicable set. Despite their usefulness, these approaches ignore the non-determinism inherent in many programming languages to the extent that they do not attempt to optimize execution after the applicable set theory has been determined.", "num_citations": "39\n", "authors": ["351"]}
{"title": "Semantic-based program analysis for logic-based languages using XSB\n", "abstract": " This article describes a simple and efficient way of using a logic programming language with builtin tabulation for general purpose semantics-based program analysis. The simplicity of the method is based on a clear separation of abstraction and control: conceptually, a concrete program is executed over an abstract domain and the tabulation mechanism avoids recomputation, ensures termination and collects the results of the analysis. The efficiency derives from the fact that an abstract interpreter induces an abstract compiler which maps input programs to corresponding abstract programs which are (compiled and) run in XSB [43]. The design of new analyses is an easy and fast process, because XSB is a general purpose logic programming system which supports efficient fix-point computations through tabling implemented at the abstract machine level and comes off the shelf: in fact, due to its optimized control and superior tabling performance, our approach using XSB competitively compares with most of the existing special purpose abstract interpretation tools for logic programs. We demonstrate that our approach to using XSB for abstract interpretation supports the usual techniques and optimizations of other frameworks in a straightforward and flexible way.\u00a9 1998 Springer-Verlag.", "num_citations": "37\n", "authors": ["351"]}
{"title": "Turning centralized coherence and distributed critical-section execution on their head: A new approach for scalable distributed shared memory\n", "abstract": " A coherent global address space in a distributed system enables shared memory programming in a much larger scale than a single multicore or a single SMP. Without dedicated hardware support at this scale, the solution is a software distributed shared memory (DSM) system. However, traditional approaches to coherence (centralized via\" active\" home-node directories) and critical-section execution (distributed across nodes and cores) are inherently unfit for such a scenario. Instead, it is crucial to make decisions locally and avoid the long latencies imposed by both network and software message handlers. Likewise, synchronization is fast if it rarely involves communication with distant nodes (or even other sockets). To minimize the amount of long-latency communication required in both coherence and critical section execution, we propose a DSM system with a novel coherence protocol, and a novel hierarchical\u00a0\u2026", "num_citations": "36\n", "authors": ["351"]}
{"title": "Concolic testing for functional languages\n", "abstract": " Concolic testing is a software testing technique that simultaneously combines concrete execution of a program (given specific input, along specific paths) with symbolic execution (generating new test inputs that explore other paths, which gives better path coverage than random test case generation). So far, concolic testing has been applied, mainly at the level of bytecode or assembly code, to programs written in imperative languages that manipulate primitive data types such as integers and arrays. In this article, we demonstrate its application to a functional programming language core, the functional subset of Core Erlang, that supports pattern matching, structured recursive data types such as lists, recursion and higher-order functions. We present CutEr, a tool implementing this testing technique, and describe its architecture, the challenges that it needs to address, its current limitations, and report some experiences\u00a0\u2026", "num_citations": "35\n", "authors": ["351"]}
{"title": "Source sets: a foundation for optimal dynamic partial order reduction\n", "abstract": " Stateless model checking is a powerful method for program verification that, however, suffers from an exponential growth in the number of explored executions. A successful technique for reducing this number, while still maintaining complete coverage, is Dynamic Partial Order Reduction (DPOR), an algorithm originally introduced by Flanagan and Godefroid in 2005 and since then not only used as a point of reference but also extended by various researchers. In this article, we present a new DPOR algorithm, which is the first to be provably optimal in that it always explores the minimal number of executions. It is based on a novel class of sets, called source sets, that replace the role of persistent sets in previous algorithms. We begin by showing how to modify the original DPOR algorithm to work with source sets, resulting in an efficient and simple-to-implement algorithm, called source-DPOR. Subsequently, we\u00a0\u2026", "num_citations": "34\n", "authors": ["351"]}
{"title": "Queue delegation locking\n", "abstract": " The scalability of parallel programs is often bounded by the performance of synchronization mechanisms used to protect critical sections. The performance of these mechanisms is in turn determined by their sequential execution time, efficient use of hardware, and ability to avoid waiting. In this article, we describe queue delegation (QD) locking, a family of locks that both delegate critical sections and enable detaching execution. Threads delegate work to the thread currently holding the lock and are able to detach, i.e., immediately continue their execution until they need a result from a previously delegated critical section. We show how to use queue delegation to build synchronization algorithms with lower overhead and higher throughput than existing algorithms, even when critical sections need to communicate results back immediately. Experiments when using up to 64 threads to access a shared priority queue\u00a0\u2026", "num_citations": "33\n", "authors": ["351"]}
{"title": "Tabling in Mercury: Design and implementation\n", "abstract": " For any LP system, tabling can be quite handy in a variety of tasks, especially if it is efficiently implemented and fully integrated in the language. Implementing tabling in Mercury poses special challenges for several reasons. First, Mercury is both semantically and culturally quite different from Prolog. While decreeing that tabled predicates must not include cuts is acceptable in a Prolog system, it is not acceptable in Mercury, since if-then-elses and existential quantification have sound semantics for stratified programs and are used very frequently both by programmers and by the compiler. The Mercury implementation thus has no option but to handle interactions of tabling with Mercury\u2019s language features safely. Second, the Mercury implementation is vastly different from the WAM, and many of the differences (e.g. the absence of a trail) have significant impact on the implementation of tabling. In this paper, we\u00a0\u2026", "num_citations": "33\n", "authors": ["351"]}
{"title": "A type and effect system for deadlock avoidance in low-level languages\n", "abstract": " The possibility to run into a deadlock is an annoying and commonly occurring hazard associated with the concurrent execution of programs. In this paper we present a polymorphic type and effect system that can be used to dynamically avoid deadlocks, guided by information about the order of lock and unlock operations which is computed statically. In contrast to most other type-based approaches to deadlock freedom, our system does not insist that programs adhere to a strict lock acquisition order or use locking primitives in a block-structured way. Lifting these restrictions is primarily motivated by our desire to target low-level languages, such as C with pthreads, but it also allows our system to be directly applicable in optimizing compilers for high-level languages, such as Java.", "num_citations": "32\n", "authors": ["351"]}
{"title": "The HiPE/x86 Erlang compiler: System description and performance evaluation\n", "abstract": " Erlang is a concurrent functional language, tailored for large-scale distributed and fault-tolerant control software. Its primary implementation is Ericsson\u2019s Erlang/OTP system, which is based on a virtual machine interpreter. HiPE (High-Performance Erlang) adds a native code execution mode to the Erlang/OTP system. This paper describes the x86 version of HiPE, including a detailed account of decisions and principles that guide the design of its compiler and runtime system. We also present a brief performance evaluation which indicates that HiPE/x86 delivers performance improvements on par with the more mature HiPE/SPARC system.", "num_citations": "30\n", "authors": ["351"]}
{"title": "A polyvariant binding-time analysis for off-line partial deduction\n", "abstract": " We study the notion of binding-time analysis for logic programs. We formalise the unfolding aspect of an on-line partial deduction system as a Prolog program. Using abstract interpretation, we collect information about the run-time behaviour of the program. We use this information to make the control decisions about the unfolding at analysis time and to turn the on-line system into an off-line system. We report on some initial experiments.", "num_citations": "30\n", "authors": ["351"]}
{"title": "Optimal dynamic partial order reduction with observers\n", "abstract": " Dynamic partial order reduction (DPOR) algorithms are used in stateless model checking (SMC) to combat the combinatorial explosion in the number of schedulings that need to be explored to guarantee soundness. The most effective of them, the Optimal DPOR algorithm, is optimal in the sense that it explores only one scheduling per Mazurkiewicz trace. In this paper, we enhance DPOR with the notion of observability, which makes dependencies between operations conditional on the existence of future operations, called observers. Observers naturally lead to a lazy construction of dependencies. This requires significant changes in the core of POR algorithms (and Optimal DPOR in particular), but also makes the resulting algorithm, Optimal DPOR with Observers, super-optimal in the sense that it explores exponentially less schedulings than Mazurkiewicz traces in some cases. We argue that observers\u00a0\u2026", "num_citations": "28\n", "authors": ["351"]}
{"title": "Test-driven development of concurrent programs using Concuerror\n", "abstract": " This paper advocates the test-driven development of concurrent Erlang programs in order to detect early and eliminate the vast majority of concurrency-related errors that may occur in their execution. To facilitate this task we have developed a tool, called Concuerror, that exhaustively explores process interleaving (possibly up to some preemption bound) and presents detailed interleaving information of any errors that occur. We describe in detail the use of Concuerror on a non-trivial concurrent Erlang program that we develop step by step in a test-driven fashion.", "num_citations": "28\n", "authors": ["351"]}
{"title": "Instruction merging and specialization in the SICStus Prolog virtual machine\n", "abstract": " Wanting to improve execution speed and reduce code size of SICStus Prolog programs, we embarked on a project whose aim was to systematically investigate combination and specialization of WAM instructions. Various variants of the SICStus Prolog virtual machine instruction set were designed, implemented, and their performance was evaluated against standard benchmarks and on big Prolog programs. In this paper, we describe our methodology in finding appropriate candicates for instruction merging and specialization, discuss related trade-offs, present detailed statistics and performance measurements that we gathered, and report on our experiences from our involvement in this feat. In short, our experience is positiv e: the speedup of performing instruction merging and specialization in the context of the SICStus emulator is approximately 10%, while the bytecode size reduction is about 15%.", "num_citations": "27\n", "authors": ["351"]}
{"title": "Automatic WSDL-guided test case generation for PropEr testing of web services\n", "abstract": " With web services already being key ingredients of modern web systems, automatic and easy-to-use but at the same time powerful and expressive testing frameworks for web services are increasingly important. Our work aims at fully automatic testing of web services: ideally the user only specifies properties that the web service is expected to satisfy, in the form of input-output relations, and the system handles all the rest. In this paper we present in detail the component which lies at the heart of this system: how the WSDL specification of a web service is used to automatically create test case generators that can be fed to PropEr, a property-based testing tool, to create structurally valid random test cases for its operations and check its responses. Although the process is fully automatic, our tool optionally allows the user to easily modify its output to either add semantic information to the generators or write properties that test for more involved functionality of the web services.", "num_citations": "26\n", "authors": ["351"]}
{"title": "Termination analysis for tabled logic programming\n", "abstract": " We provide a theoretical basis for studying the termination of tabled logic programs executed under SLG-resolution using a left-to-right computation rule. To this end, we study the classes of quasi-terminating and LG-terminating programs (for a set of atomic goals S). These are tabled logic programs where execution of each call from S leads to only a finite number of different (i.e., non-variant) calls, and a finite number of different calls and computed answer substitutions for them, respectively. We then relate these two classes through a program transformation, and present a characterisation of quasi-termination by means of the notion of quasi-acceptability of tabled programs. The latter provides us with a practical method of proving termination and the method is illustrated on non-trivial examples of tabled logic programs.", "num_citations": "26\n", "authors": ["351"]}
{"title": "Analysis of {DTLS} Implementations Using Protocol State Fuzzing\n", "abstract": " Recent years have witnessed an increasing number of protocols relying on UDP. Compared to TCP, UDP offers performance advantages such as simplicity and lower latency. This has motivated its adoption in Voice over IP, tunneling technologies, IoT, and novel Web protocols. To protect sensitive data exchange in these scenarios, the DTLS protocol has been developed as a cryptographic variation of TLS. DTLS\u2019s main challenge is to support the stateless and unreliable transport of UDP. This has forced protocol designers to make choices that affect the complexity of DTLS, and to incorporate features that need not be addressed in the numerous TLS analyses.", "num_citations": "24\n", "authors": ["351"]}
{"title": "Heap architectures for concurrent languages using message passing\n", "abstract": " We discuss alternative heap architectures for languages that rely on automatic memory management and implement concurrency through asynchronous message passing. We describe how interprocess communication and garbage collection happens in each architecture, and extensively discuss the tradeoffs that are involved. In an implementation setting (the Erlang/OTP system) where the rest of the runtime system is unchanged, we present a detailed experimental comparison between these architectures using both synthetic programs and large commercial products as benchmarks.", "num_citations": "24\n", "authors": ["351"]}
{"title": "Targeted Property-Based Testing\n", "abstract": " We introduce targeted property-based testing, an enhanced form of property-based testing that aims to make the input generation component of a property-based testing tool guided by a search strategy rather than being completely random. Thus, this testing technique combines the advantages of both search-based and property-based testing. We demonstrate the technique with the framework we have built, called Target, and show its effectiveness on three case studies. The first of them demonstrates how Target can employ simulated annealing to generate sensor network topologies that form configurations with high energy consumption. The second case study shows how the generation of routing trees for a wireless network equipped with directional antennas can be guided to fulfill different energy metrics. The third case study employs Target to test the noninterference property of information-flow control abstract\u00a0\u2026", "num_citations": "23\n", "authors": ["351"]}
{"title": "Experimental evaluation and improvements to linear scan register allocation\n", "abstract": " We report our experience from implementing and experimentally evaluating the performance of various register allocation schemes, focusing on the recently proposed linear scan register allocator. In particular, we describe in detail our implementation of linear scan and report on its behavior both on register\u2010rich and on register\u2010poor computer architectures. We also extensively investigate how different options to the basic algorithm and to the compilation process as a whole affect compilation times and quality of the produced code. In a nutshell, our experience is that a well\u2010tuned linear scan register allocator is a good choice on register\u2010rich architectures. It performs competitively with graph coloring based allocation schemes and results in significantly lower compilation times. When compilation time is a concern, such as in just\u2010in\u2010time compilers, it can also be a viable option on register\u2010poor architectures\u00a0\u2026", "num_citations": "23\n", "authors": ["351"]}
{"title": "ErLLVM: an LLVM backend for Erlang\n", "abstract": " This paper describes ErLLVM, a new backend for the HiPE compiler, the native code compiler of Erlang/OTP, that targets the LLVM compiler infrastructure. Besides presenting the overall architecture of ErLLVM and its integration in Erlang/OTP, we describe the changes to LLVM that ErLLVM required and discuss technical challenges and decisions we took. Finally, we provide a detailed performance evaluation of ErLLVM compared to BEAM, the existing backends of the HiPE compiler, and Erjang.", "num_citations": "22\n", "authors": ["351"]}
{"title": "A language for specifying type contracts in Erlang and its interaction with success typings\n", "abstract": " We propose a small extension of the Erlang language that allows programmers to specify contracts with type information at the level of individual functions. Such contracts are optional and they document the intended uses of functions. Contracts allow automatic documentation tools such as Edoc to generate better documentation and defect detection tools such as Dialyzer to detect more type clashes. Since the Erlang/OTP system already contains components which perform automatic type inference of success typings, we also describe how contracts interact with success typings and can often provide some key information to the inference process.", "num_citations": "22\n", "authors": ["351"]}
{"title": "Optimal stateless model checking for reads-from equivalence under sequential consistency\n", "abstract": " We present a new approach for stateless model checking (SMC) of multithreaded programs under Sequential Consistency (SC) semantics. To combat state-space explosion, SMC is often equipped with a partial-order reduction technique, which defines an equivalence on executions, and only needs to explore one execution in each equivalence class. Recently, it has been observed that the commonly used equivalence of Mazurkiewicz traces can be coarsened but still cover all program crashes and assertion violations. However, for this coarser equivalence, which preserves only the reads-from relation from writes to reads, there is no SMC algorithm which is (i) optimal in the sense that it explores precisely one execution in each reads-from equivalence class, and (ii) efficient in the sense that it spends polynomial effort per class. We present the first SMC algorithm for SC that is both optimal and efficient in practice\u00a0\u2026", "num_citations": "21\n", "authors": ["351"]}
{"title": "Message analysis for concurrent programs using message passing\n", "abstract": " We describe an analysis-driven storage allocation scheme for concurrent systems that use message passing with copying semantics. The basic principle is that in such a system, data which is not part of any message does not need to be allocated in a shared data area. This allows for the deallocation of thread-specific data without requiring global synchronization and often without even triggering garbage collection. On the other hand, data that is part of a message should preferably be allocated on a shared area since this allows for fast (O(1)) interprocess communication that does not require actual copying. In the context of a dynamically typed, higher-order concurrent functional language, we present a static message analysis which guides the allocation. As shown by our performance evaluation, conducted using a production-quality language implementation, the analysis is effective enough to discover most data\u00a0\u2026", "num_citations": "21\n", "authors": ["351"]}
{"title": "Memory management for Prolog with tabling\n", "abstract": " Tabling can be implemented in a (WAM-based) Prolog system by means of SLG-WAM: consumers suspend and their state is preserved by freezing the execution stacks. XSB is a system that currently implements tabling based on the SLG-WAM. The memory model is quite complex and attempts to understand the notion of usefulness of data in XSB well enough to build a precise garbage collector have failed in the past. CAT is a recent alternative to SLG-WAM: it suspends consumers by copying parts of the execution stacks. The memory model is simpler and the design of a more precise garbage collector became feasible. CAT also provided the necessary insights in the usefulness of data in the context of the SLG-WAM. This paper describes the memory management of tabled logic programming systems, whether based on the SLG-WAM or on CAT. Since CAT can perform arbitrarily worse than SLG-WAM space\u00a0\u2026", "num_citations": "21\n", "authors": ["351"]}
{"title": "Preserving termination of tabled logic programs while unfolding\n", "abstract": " We provide a first investigation of the specialisation and transformation of tabled logic programs through unfolding. We show that \u2014 surprisingly \u2014 unfolding, even determinate, can worsen the termination behaviour in the context of tabling. We therefore establish two criteria which ensure that such mishaps are avoided. We also briefly discuss the influence of some other transformation techniques on the termination and efficiency of tabled logic programs.", "num_citations": "21\n", "authors": ["351"]}
{"title": "The SLG-WAM: A Search-Efficient Engine for Well-Founded Evaluation of Normal Logic Programs\n", "abstract": " We investigate ways of bringing systems based on ideas from logic programming closer to the ideals of the paradigm. We conservatively extend Prolog implementations to overcome their susceptibility to infinite loops, and their unacceptable performance caused by repeated subcomputations. Moreover, we improve the expressive power of systems whose query language is based on logical rules with negation by supporting evaluation of queries according to the well-founded semantics. We focus on how to achieve these ambitious goals without sacrificing the search-efficiency of the evaluation strategy, or the performance of the underlying abstract machine.", "num_citations": "21\n", "authors": ["351"]}
{"title": "Stateless model checking of the Linux kernel's hierarchical read-copy-update (tree RCU)\n", "abstract": " Read-Copy-Update (RCU) is a synchronization mechanism used heavily in key components of the Linux kernel, such as the virtual filesystem (VFS), to achieve scalability by exploiting RCU's ability to allow concurrent reads and updates. RCU's design is non-trivial, requires significant effort to fully understand it, let alone become convinced that its implementation is faithful to its specification and provides its claimed properties. The fact that as time goes by Linux kernels are becoming increasingly more complex and are employed in machines with more and more cores and weak memory does not make the situation any easier.", "num_citations": "20\n", "authors": ["351"]}
{"title": "Dynamic deadlock avoidance in systems code using statically inferred effects\n", "abstract": " Deadlocks can have devastating effects in systems code. We have developed a type and effect system that provably avoids them and in this paper we present a tool that uses a sound static analysis to instrument multithreaded C programs and then links these programs with a run-time system that avoids possible deadlocks. In contrast to most other purely static tools for deadlock freedom, our tool does not insist that programs adhere to a strict lock acquisition order or use lock primitives in a block-structured way, thus it is appropriate for systems code and OS applications. We also report some very promising benchmark results which show that all possible deadlocks can automatically be avoided with only a small run-time overhead. More importantly, this is done without having to modify the original source program by altering the order of resource acquisition operations or by adding annotations.", "num_citations": "20\n", "authors": ["351"]}
{"title": "Experience from developing the Dialyzer: A static analysis tool detecting defects in Erlang applications\n", "abstract": " We describe some of our experiences from developing the Dialyzer defect detection tool and overseeing its use in large-scale commercial applications of the telecommunications industry written in Erlang. In particular, we mention design choices that in our opinion have contributed to Dialyzer\u2019s acceptance in its user community, things that have so far worked quite well in its setting, the occasional few that have not, and the lessons we learned from interacting with a wide, and often quite diverse, variety of users.", "num_citations": "20\n", "authors": ["351"]}
{"title": "CHAT is \u0398(SLG-WAM)\n", "abstract": " CHAT offers an alternative to SLG-WAM for implementing the suspension and resumption of consumers that tabling needs: unlike SLG-WAM, it does not use freeze registers nor a complicated trail to preserve their execution environments. CHAT also limits the amount of copying of CAT, which was previously put forward as another alternative to SLG-WAM. Although experimental results show that in practice CHAT is competitive with \u2014 if not better than \u2014 SLG-WAM, there remains the annoying fact that on contrived programs the original CHAT can be made arbitrarily worse than SLG-WAM, i.e. the original CHAT has an intrinsically higher complexity. In this paper we show how to overcome this problem, in particular, we deal with the two sources of higher complexity of CHAT: the repeated traversal of the choice point stack, and the lack of sufficient sharing of the trail. This is achieved without fundamentally\u00a0\u2026", "num_citations": "20\n", "authors": ["351"]}
{"title": "Syntactica\n", "abstract": " In Syntactica, a grammar consists of a set of context-free phrase structure rules and (typically) a lexicon. Phrase structure rules are created in a rule window. Lexicons are created in a lexicon window. Rules and lexicons are loaded into TreeViewer window where they are used to generate phrase-markers (or tree diagrams). The user enters a sentence (or other expression) and Syntactica tries to generate a phrase-marker for it using the grammar that has been loaded. When more than one structure is available, Syntactica displays the range.Multiple rule and lexicon windows can be open at any one time, making it easy to load alternate grammars, and to test and compare their results. Phrase-markers can be saved for later viewing, printing or inclusion in homework assignments emailed to a central location. Sentence and Tree windows allow you to conveniently collect sentences and trees generated by a grammar, or\u00a0\u2026", "num_citations": "20\n", "authors": ["351"]}
{"title": "The development of the HiPE system: Design and experience report\n", "abstract": " The concurrent functional programming language Erlang has been designed to ease the development of large-scale distributed soft real-time control applications. So far, it has been used quite successfully in industry, both within Ericsson Telecom, where it was designed and developed, and by other companies. This \u201cdeclarative language success-story\u201d has taken place despite the fact that Erlang implementations are slow compared with implementations of other functional languages. Wanting to improve the performance aspects of publicly available Erlang implementations, which are based on emulators, we embarked on a project called HiPE (High-Performance Erlang) whose aim has been to develop an efficient just-in-time native code compiler for Erlang (called the HiPE system). Since its start in 1996, the system has gone through various (re-)design phases, partly due to implementation choices that\u00a0\u2026", "num_citations": "19\n", "authors": ["351"]}
{"title": "An abstract machine for efficiently computing queries to well-founded models\n", "abstract": " The well-founded semantics has gained wide acceptance partly because it is a skeptical semantics. That is, the well-founded model posits as unknown atoms which are deemed true or false in other formalisms such as stable models. This skepticism makes the well-founded model not only useful in itself, but also suitable as a basis for other forms of non-monotonic reasoning. For instance, since algorithms to compute stable models are intractable, the atoms relevant to such algorithms can be limited to those undefined in the well-founded model. Thus, an engine that efficiently evaluates programs according to the well-founded semantics can be seen as a prerequisite to practical systems for non-monotonic reasoning. This paper describes the architecture of the Warren Abstract Machine (WAM)-based abstract machine underlying the XSB system. This abstract machine, called the SLG-WAM, uses tabling to efficiently\u00a0\u2026", "num_citations": "19\n", "authors": ["351"]}
{"title": "Efficient execution of HiLog in WAM-based Prolog implementations\n", "abstract": " In this paper we address the problem of e ciently implementing HiLog, a logic programming language with higher-order syntax and rst-order semantics. In contrast to approaches proposed in the literature that modify, or abandon the WAM framework in order to implement HiLog, our approach to the problem stems from a belief that the WAM should be an adequate abstract machine for the execution of any logic language with rst-order semantics. To show how to implement HiLog by staying within the WAM framework, we identify the reasons for poor performance characteristics of HiLog programs, present requirements for e cient HiLog execution, and propose a complete solution to the problem. Our proposal, which can be viewed either as a compile-time program specialisation preprocessing step, or as an enhancement to the HiLog encoding in predicate calculus presented by Chen, Kifer, and Warren in 1], allows HiLog to be e ciently implemented on any Prolog system by simply modifying Prolog's input/output predicates to handle terms that are expressed using the exible higher-order syntax of HiLog.We formally prove that our proposal allows all HiLog programs that do not use any higherorder features to execute at the same speed as Prolog programs. Furthermore, we present performance results showing that generic HiLog predicates when compiled using the compilation scheme execute at least an order of magnitude faster than generic Prolog predicates, and with only minimal overhead compared to non-generic Prolog ones.", "num_citations": "19\n", "authors": ["351"]}
{"title": "Delegation locking libraries for improved performance of multithreaded programs\n", "abstract": " While standard locking libraries are common and easy to use, delegation algorithms that offload work to a single thread can achieve better performance in multithreaded applications, but are hard to use without adequate library support. This paper presents an interface for delegation locks together with libraries for C and C++ that make it easy to use queue delegation locking, a versatile high-performance delegation algorithm. We show examples of using these libraries, discuss the porting effort needed to take full advantage of delegation locking in applications designed with standard locking in mind, and the improved performance that this achieves.", "num_citations": "18\n", "authors": ["351"]}
{"title": "Linear scan register allocation in a high-performance Erlang compiler\n", "abstract": " In the context of an optimizing native code compiler for the concurrent functional programming language Erlang, we experiment with various register allocation schemes focusing on the recently proposed linear scan register allocator. We describe its implementation and extensively report on its behaviour both on register-rich and on register-poor architectures. We also investigate how different options to the basic algorithm and to the compilation process as a whole affect compilation time and quality of the produced code. Overall, the linear scan register allocator is a good choice on register-rich architectures; when compilation time is a concern, it can also be a viable option on register-poor architectures.", "num_citations": "18\n", "authors": ["351"]}
{"title": "On enabling the WAM with region support\n", "abstract": " Region-based memory management is an attractive alternative to garbage collection. It relies on a compile-time analysis to annotate the program with explicit allocation and deallocation instructions, where lifetimes of memory objects are grouped together in regions. This paper investigates how to adapt the runtime part of region-based memory management to the WAM setting. We present additions to the memory architecture and instruction set of the WAM that are necessary to implement regions. We extend an optimized WAM-based Prolog implementation with a region-based memory manager which supports backtracking with instant reclamation, and cuts. The performance of region-based execution is compared with that of the baseline garbage-collected implementation on several benchmark programs. A region-enabled WAM performs competitively and often results in time and/or space improvements.", "num_citations": "18\n", "authors": ["351"]}
{"title": "Gradual typing of Erlang programs: a wrangler experience\n", "abstract": " Currently most Erlang programs contain no or very little type information. This sometimes makes them unreliable, hard to use, and difficult to understand and maintain. In this paper we describe our experiences from using static analysis tools to gradually add type information to a medium sized Erlang application that we did not write ourselves: the code base of Wrangler. We carefully document the approach we followed, the exact steps we took, and discuss possible difficulties that one is expected to deal with and the effort which is required in the process. We also show the type of software defects that are typically brought forward, the opportunities for code refactoring and improvement, and the expected benefits from embarking in such a project. We have chosen Wrangler for our experiment because the process is better explained on a code base which is small enough so that the interested reader can retrace its\u00a0\u2026", "num_citations": "17\n", "authors": ["351"]}
{"title": "Efficient support for range queries and range updates using contention adapting search trees\n", "abstract": " We extend contention adapting trees (CA trees), a family of concurrent data structures for ordered sets, to support linearizable range queries, range updates, and operations that atomically operate on multiple keys such as bulk insertions and deletions. CA trees differ from related concurrent data structures by adapting themselves according to the contention level and the access patterns to scale well in a multitude of scenarios. Variants of CA trees with different performance characteristics can be derived by changing their sequential component. We experimentally compare CA trees to state-of-the-art concurrent data structures and show that CA trees beat the best data structures we compare against with up\u00a0to 57\u00a0% in scenarios that contain basic set operations and range queries, and outperform them by more than 1200\u00a0% in scenarios that also contain range updates.", "num_citations": "16\n", "authors": ["351"]}
{"title": "On Using Erlang for Parallelization\n", "abstract": " Erlang is a functional language that allows programmers to employ shared nothing processes and asynchronous message passing for parts of applications which can naturally execute concurrently. This paper reports on a non-trivial effort to use these concurrency features to parallelize a widely used application written in Erlang. More specifically, we present how Dialyzer, consisting of about 30,000 lines of quite complex and sequential Erlang code, has been parallelized using the language primitives and report on the challenges that were involved and lessons learned from engaging in this feat. In addition, we evaluate the performance improvements that were achieved on a variety of modern hardware. On a 32-core AMD \u201cBulldozer\u201d machine, the parallel version of Dialyzer can now complete the analysis of Erlang/OTP\u2019s code base, consisting of about two million lines of Erlang code, in about six minutes\u00a0\u2026", "num_citations": "16\n", "authors": ["351"]}
{"title": "Mark and split\n", "abstract": " The mark-sweep garbage collection algorithm constructs a list of memory areas to allocate into (the free list) during its sweep phase. This phase needs time proportional to the size of the heap which is collected. We introduce mark-split, a non-moving garbage collection algorithm that constructs the free list during the mark phase by maintaining and splitting free intervals. With mark-split, the sweep phase of mark-sweep becomes unnecessary and the cost of collection is proportional to the size of the live data set. Our performance evaluation, using a high performance Java implementation running standard benchmarks, shows that mark-split can significantly reduce collection times compared with mark-sweep and requires little extra space to do so. The overhead to the cost of marking is moderate and often pays off for itself by avoiding the sweep phase. Since there is no guarantee that this is always the case, we also\u00a0\u2026", "num_citations": "16\n", "authors": ["351"]}
{"title": "On the use of tabling for abstract interpretation: An experiment with abstract equation systems\n", "abstract": " Abstract interpretation is a widely used method for the static analysis of programs. This extended abstract reports on our recent experiments with an alternative approach to implementing program analyses based on abstract interpretation. Instead of using a special-purpose system for abstract interpretation (such as PLAI, GAIA, or AMAI), we follow the approach advocated in 5] and use a logic programming system which supports tabling (namely XSB). To obtain the results of the analysis, we directly compile the program to be analysed into a tabled logic program such that its execution by XSB coincides with the abstract interpretation of the original program. We show how this approach is adapted to abstractions which satisfy the requirements of the framework of Bruynooghe 1] and that the approach is practical and competitive with stateof-the-art generic abstract interpretation systems implemented in Prolog. Our experiments are based on the non-trivial domain of abstract equation systems which is a parameterized domain which captures structure information together with modes, linearity and sharing.", "num_citations": "16\n", "authors": ["351"]}
{"title": "Just enough tabling\n", "abstract": " We introduce just enough tabling (JET), a mechanism to suspend and resume the tabled execution of logic programs at an arbitrary point. In particular, JET allows pruning of tabled logic programs to be performed without resorting to any recomputation. We discuss issues that are involved in supporting pruning in tabled resolution, how re-execution of tabled computations which were previously pruned can be avoided, and we describe the implementation of such a scheme based on an abstract machine like CHAT, which implements the suspension/resumption support that tabling requires through a combination of freezing and copying of execution states of suspended computations. Properties of just enough tabling and possible uses of the JET mechanism in a tabling system are also briefly discussed.", "num_citations": "15\n", "authors": ["351"]}
{"title": "All you wanted to know about the HiPE compiler:(but might have been afraid to ask)\n", "abstract": " We present a user-oriented description of features and characteristics of the High Performance ERLANG (HiPE) native code compiler, which nowadays is part of Erlang/OTP. In particular, we describe components and recent additions to the compiler that improve its performance and extend its functionality. In addition, we attempt to give some recommendations on how users can get the best out of HiPE's performance.", "num_citations": "15\n", "authors": ["351"]}
{"title": "Using Static Analysis to Detect Type Errors and Concurrency Defects in Erlang Programs\n", "abstract": " This invited talk will present the key ideas in the design and implementation of Dialyzer, a static analysis tool for Erlang programs. Dialyzer started as a defect detection tool using a rather ad hoc dataflow analysis to detect type errors in Erlang programs, but relatively early in its development it adopted a more disciplined approach to detecting definite type clashes in dynamically typed languages. Namely, an approach based on using a constraint-based analysis to infer success typings which are also enhanced with optional contracts supplied by the programmer.               In the first part of the talk, we will describe this constraint-based approach to type inference and explain how it differs with past and recent attempts to type check programs written in dynamic languages. In the second part of the talk, we will present important recent additions to Dialyzer, namely analyses that detect concurrency defects (such as\u00a0\u2026", "num_citations": "13\n", "authors": ["351"]}
{"title": "Efficient memory management for concurrent programs that use message passing\n", "abstract": " We present an efficient memory management scheme for concurrent programming languages where communication occurs by using message passing with copying semantics. The runtime system is built around process-local heaps, which frees the memory manager from redundant synchronization in a multi-threaded implementation and allows the memory reclamation of process-local heaps to be a private business and to often take place without ever triggering garbage collection. The allocator is guided by a static analysis which speculatively allocates data possibly used as messages in a shared memory area. To respect the (soft) real-time requirements of the language, we develop and present in detail a generational, incremental garbage collection scheme tailored to the characteristics of this runtime system. The incremental collector imposes no overhead on the mutator, requires no costly barrier mechanisms\u00a0\u2026", "num_citations": "13\n", "authors": ["351"]}
{"title": "ProFuN TG: A tool for programming and managing performance-aware sensor network applications\n", "abstract": " Sensor network macroprogramming methodologies such as the Abstract Task Graph hold the promise of enabling high-level sensor network application development. However, progress in this area is hampered by the scarcity of tools, and also because of insufficient focus on developing tool support for programming applications aware of performance requirements. We present ProFuN TG (Task Graph), a tool for designing sensor network applications using task graphs. ProFuN TG provides automated task mapping, sensor node firmware macrocompilation, application simulation, deployment, and runtime maintenance capabilities. It allows users to incorporate performance requirements in the applications, expressed through constraints on task-to-task dataflows. The tool includes middleware that uses an efficient flooding-based protocol to set up tasks in the network, and also enables runtime assurance by keeping\u00a0\u2026", "num_citations": "12\n", "authors": ["351"]}
{"title": "Static safety guarantees for a low-level multithreaded language with regions\n", "abstract": " We present the design of a formal low-level multithreaded language with advanced region-based memory management and thread synchronization primitives, where well-typed programs are memory safe and race free. In our language, regions and locks are combined in a single hierarchy and are subject to uniform ownership constraints imposed by this hierarchical structure: deallocating a region causes its sub-regions to be deallocated. Similarly, when a region is read/write-protected, then its sub-regions inherit the same access rights. We discuss aspects of the integration and implementation of the formal language within Cyclone and evaluate the performance of code produced by the modified Cyclone compiler against highly optimized C programs using pthreads. Our results show that the performance overhead for guaranteed race freedom and memory safety is in most cases acceptable.", "num_citations": "12\n", "authors": ["351"]}
{"title": "Race-free and memory-safe multithreading: design and implementation in Cyclone\n", "abstract": " We present the design of a formal low-level multi-threaded language with advanced region-based memory management and synchronization primitives, where well-typed programs are memory safe and race free. In our language, regions and locks are combined in a single hierarchy and are subject to uniform ownership constraints imposed by a hierarchical structure: deallocating a region causes its sub-regions to be deallocated. Similarly, when a region is protected, then its sub-regions are also protected. We discuss aspects of the integration and implementation of the formal language within Cyclone and evaluate the performance of code produced by the modified Cyclone compiler against highly optimized C programs using atomic operations, pthreads, and OpenMP. Although our implementation is still in a preliminary stage, our results show that the performance overhead for guaranteed race freedom and\u00a0\u2026", "num_citations": "12\n", "authors": ["351"]}
{"title": "Efficient manipulation of binary data using pattern matching\n", "abstract": " Pattern matching is an important operation in functional programs. So far, pattern matching has been investigated in the context of structured terms. This article presents an approach to extend pattern matching to terms without (much of a) structure such as binaries which is the kind of data format that network applications typically manipulate. After introducing the binary datatype and a notation for matching binary data against patterns, we present an algorithm that constructs a decision tree automaton from a set of binary patterns. We then show how the pattern matching using this tree automaton can be made adaptive, how redundant tests can be avoided, and how we can further reduce the size of the resulting automaton by taking interferences between patterns into account. Since the size of the tree automaton is exponential in the worst case, we also present an alternative new approach to compiling binary pattern\u00a0\u2026", "num_citations": "12\n", "authors": ["351"]}
{"title": "The Contention Avoiding Concurrent Priority Queue\n", "abstract": " Efficient and scalable concurrent priority queues are crucial for the performance of many multicore applications, e.g. for task scheduling and the parallelization of various algorithms. Linearizable concurrent priority queues with traditional semantics suffer from an inherent sequential bottleneck in the head of the queue. This bottleneck is the motivation for some recently proposed priority queues with more relaxed semantics. We present the contention avoiding concurrent priority queue (CA-PQ), a data structure that functions as a linearizable concurrent priority with traditional semantics under low contention, but activates contention avoiding techniques that give it more relaxed semantics when high contention is detected. CA-PQ avoids contention in the head of the queue by removing items in bulk from the global data structure, which also allows it to often serve DelMin operations without accessing memory\u00a0\u2026", "num_citations": "11\n", "authors": ["351"]}
{"title": "On reducing interprocess communication overhead in concurrent programs\n", "abstract": " We present several different ideas for increasing the performance of highly concurrent programs in general and Erlang programs in particular. These ideas range from simple implementation tricks that reduce communication latency to more thorough code rewrites guided by inlining across process boundaries. We also briefly discuss the impact of different heap architectures on interprocess communication in general and on our proposed optimizations in particular.", "num_citations": "11\n", "authors": ["351"]}
{"title": "Automating Targeted Property-Based Testing\n", "abstract": " Targeted property-based testing is an enhanced form of property-based testing (PBT) where the input generation is guided by a search strategy instead of being random, thereby combining the strengths of QuickCheck-like and search-based testing techniques. To use it, however, the user currently needs to specify a search strategy and also supply all ingredients that the search strategy requires. This is often a laborious process and makes targeted PBT less attractive than its random counterpart. In this paper, we focus on simulated annealing, the default search strategy of our tool, and present a technique that automatically creates all the ingredients that targeted PBT requires starting from only a random generator. Our experiments, comparing the automatically generated ingredients to fine-tuned manually written ones, show that the performance that one obtains is sufficient and quite competitive in practice.", "num_citations": "10\n", "authors": ["351"]}
{"title": "A Contention Adapting Approach to Concurrent Ordered Sets\n", "abstract": " With multicores being ubiquitous, concurrent data structures are increasingly important. This article proposes a novel approach to concurrent data structure design where the data structure dynamically adapts its synchronization granularity based on the detected contention and the amount of data that operations are accessing. This approach not only has the potential to reduce overheads associated with synchronization in uncontended scenarios, but can also be beneficial when the amount of data that operations are accessing atomically is unknown.Using this adaptive approach we create a contention adapting search tree (CA tree) that can be used to implement concurrent ordered sets and maps with support for range queries and bulk operations. We provide detailed proof sketches for the linearizability as well as deadlock and livelock freedom of CA tree operations. We experimentally compare CA trees to state\u00a0\u2026", "num_citations": "10\n", "authors": ["351"]}
{"title": "Contention adapting search trees\n", "abstract": " With multicourse being ubiquitous, concurrent data structures are becoming increasingly important. This paper proposes a novel approach to concurrent data structure design where the data structure collects statistics about contention and adapts dynamically according to this statistics. We use this approach to create a contention adapting binary search tree (CA tree) that can be used to implement concurrent ordered sets and maps. Our experimental evaluation shows that CA trees scale similar to recently proposed algorithms on a big multicore machine on various scenarios with a larger set size, and outperform the same data structures in more contended scenarios and in sequential performance. We also show that CA trees are well suited for optimization with hardware lock elision. In short, we propose a practically useful and easy to implement and show correct concurrent search tree that naturally adapts to the\u00a0\u2026", "num_citations": "10\n", "authors": ["351"]}
{"title": "More scalable ordered set for ETS using adaptation\n", "abstract": " The Erlang Term Storage (ETS) is a key component of the runtime system and standard library of Erlang/OTP. In particular, on big multicores, the performance of many applications that use ETS as a shared key-value store heavily depends on the scalability of ETS. In this work, we investigate an alternative implementation for the ETS table type ordered_set based on a contention adapting search tree. The new implementation performs many times better than the current one in contended scenarios and scales better than the ETS table types implemented using hashing and fine-grained locking when several processor chips are used. We evaluate the new implementation with a set of experiments that show its scalability in relation to the current ETS implementation as well as its low sequential overhead.", "num_citations": "10\n", "authors": ["351"]}
{"title": "Bit-level binaries and generalized comprehensions in Erlang\n", "abstract": " Binary (ie, bit stream) data are omnipresent in computer and network applications but most functional programming languages currently do not provide sufficient support for them. Erlang is an exception since it does support direct manipulation of binary data, albeit currently restricted to byte streams, not bit streams. To ameliorate the situation, we extend Erlang's built-in binary datatype so that it becomes flexible enough to handle bit streams properly. To further simplify programming on bit streams we then show how binary comprehensions can be introduced in the language and how binary and list comprehensions can be extended to allow both binary and list generators.", "num_citations": "10\n", "authors": ["351"]}
{"title": "Native code compilation of Erlang's bit syntax\n", "abstract": " Erlang's bit syntax caters for flexible pattern matching on bit streams (objects known as binaries). Binaries are nowadays heavily used in typical Erlang applications such as protocol programming, which in turn has created a need for efficient support of the basic operations on binaries. To this effect, we describe a scheme for efficient native code compilation of Erlang's bit syntax. The scheme relies on partial translation for avoiding code explosion, and improves the performance of programs manipulating binaries by translating frequently occurring instances of BEAM instructions into native code via an intermediate translation to instructions of a register transfer language. Our performance evaluation shows that in a HiPE-enabled Erlang/OTP system, the obtained speedups are often significant.", "num_citations": "10\n", "authors": ["351"]}
{"title": "HiPE: High Performance Erlang\n", "abstract": " Erlang is a concurrent functional programming language designed to ease the development of large-scale distributed soft real-time control applications. It has so far been quite successful in this application domain, despite the fact that its currently available implementations are emulators of virtual machines. In this paper, we improve on the performance aspects of Erlang implementations by presenting HiPE, a native-code compiler for Erlang. HiPE is a complete implementation of Erlang, offers flexible integration between emulated and native code, and efficiently supports features crucial for Erlang's application domain such as concurrency. As our performance evaluations show, HiPE is currently the fastest among all Erlang implementations.", "num_citations": "10\n", "authors": ["351"]}
{"title": "Modular termination proofs for Prolog with tabling\n", "abstract": " Tabling avoids many of the shortcomings of SLD(NF) execution and provides a more flexible and efficient execution mechanism for logic programs. In particular, tabled execution of logic programs terminates more often than execution based on SLD-resolution. One of the few works studying termination under a tabled execution mechanism is that of Decorte et al. They introduce and characterise two notions of universal termination of logic programs w.r.t. sets of queries executed under SLG-resolution, using the left-to-right selection rule; namely the notion of quasi-termination and the (stronger) notion of LG-termination. This paper extends the results of Decorte et al in two ways: (1) we consider a mix of tabled and Prolog execution, and (2) besides a characterisation of the two notions of universal termination under such a mixed execution, we also give modular termination conditions. From both practical and\u00a0\u2026", "num_citations": "10\n", "authors": ["351"]}
{"title": "The XSB Programmer\u2019s Manual (Version 1.8)\n", "abstract": " XSB is a research-oriented Logic Programming system for Unix and Windows/DOS-based systems. In addition to providing all the functionality of Prolog, XSB contains several features not usually found in Logic Programming systems, including", "num_citations": "10\n", "authors": ["351"]}
{"title": "On the scalability of the Erlang term storage\n", "abstract": " The Erlang Term Storage (ETS) is an important component of the Erlang runtime system, especially when parallelism enters the picture, as it provides an area where processes can share data. It is therefore important that ETS's implementation is efficient, flexible, but also as scalable as possible. In this paper we document and describe the current implementation of ETS in detail, discuss the main data structures that support it, and present the main points of its evolution across Erlang/OTP releases. More importantly, we measure the scalability of its implementations, the effects of its tuning options, identify bottlenecks, and suggest changes and alternative designs that can improve both its performance and its scalability.", "num_citations": "9\n", "authors": ["351"]}
{"title": "On preserving term sharing in the Erlang virtual machine\n", "abstract": " In programming language implementations, one of the most important design decisions concerns the underlying representation of terms. In functional languages with immutable terms, the runtime system can choose to preserve sharing of subterms or destroy sharing and expand terms to their flattened representation during certain key operations. Both options have pros and cons. The implementation of Erlang in the Erlang/OTP system from Ericsson has so far opted for an implementation where sharing of subterms is not preserved when terms are copied (eg, when sent from one process to another or when used as arguments in spawns).", "num_citations": "9\n", "authors": ["351"]}
{"title": "Segment order preserving and generational garbage collection for Prolog\n", "abstract": " We treat two important issues in heap garbage collection for WAM-based Prolog systems. First we describe a new method for preserving the order of heap segments in a copying garbage collector. Second, we deal with methods for (multi-)generational garbage collection; in particular we show the importance of precise maintenance of generation lines and propose different and novel ways for its implementation. All the methods are experimentally evaluated.", "num_citations": "9\n", "authors": ["351"]}
{"title": "Lock-free Contention Adapting Search Trees\n", "abstract": " Concurrent key-value stores with range query support are crucial for the scalability and performance of many applications. Existing lock-free data structures of this kind use a fixed synchronization granularity. Using a fixed synchronization granularity in a concurrent key-value store with range query support is problematic as the best performing synchronization granularity depends on a number of factors that are difficult to predict, such as the level of contention and the number of items that are accessed by range queries. We present the first linearizable lock-free key-value store with range query support that dynamically adapts its synchronization granularity. This data structure is called the lock-free contention adapting search tree (LFCA tree). An LFCA tree automatically performs local adaptations of its synchronization granularity based on heuristics that take contention and the performance of range queries into\u00a0\u2026", "num_citations": "8\n", "authors": ["351"]}
{"title": "Stateless model checking of the Linux kernel\u2019s read\u2013copy update (RCU)\n", "abstract": " Read\u2013copy update (RCU) is a synchronization mechanism used heavily in key components of the Linux kernel, such as the virtual filesystem (VFS), to achieve scalability by exploiting RCU\u2019s ability to allow concurrent reads and updates. RCU\u2019s design is non-trivial, requires a significant effort to fully understand it, let alone become convinced that its implementation is faithful to its specification and provides its claimed properties. The fact that as time goes by Linux kernels are becoming increasingly more complex and are employed in machines with more and more cores and weak memory does not make the situation any easier. This article presents an approach to systematically test the code of the main implementation of RCU used in the Linux kernel (Tree RCU) for concurrency errors, both under sequentially consistent and weak memory. Our modeling allows Nidhugg, a stateless model checking tool, to\u00a0\u2026", "num_citations": "8\n", "authors": ["351"]}
{"title": "Efficiently compiling a functional language on AMD64: the HiPE experience\n", "abstract": " We describe and document our experience from developing an AMD64 backend for the HiPE (High Performance Erlang) native code compiler. We consider implementation alternatives and critically examine design choices for obtaining an efficient AMD64 backend. In particular, we consider in detail how other functional language implementors can migrate their existing x86 backends to the AMD64 architecture, a platform which is becoming increasingly important these days. We mention backend components that can be shared between x86 and AMD64, and those that better be different for achieving high performance on AMD64. Finally, we measure the performance of several different alternatives in the hope that this information can save development effort for others who intend to engage in a similar feat.", "num_citations": "8\n", "authors": ["351"]}
{"title": "Unboxed compilation of floating point arithmetic in a dynamically typed language environment\n", "abstract": " In the context of the dynamically typed concurrent functional programming language Erlang, we describe a simple static analysis for identifying variables containing floating point numbers, how this information is used by the BEAM compiler, and a scheme for efficient (just-in-time) compilation of floating point bytecode instructions to native code. The attractiveness of the scheme lies in its implementation simplicity. It has been fully incorporated in Erlang/OTP R9, and improves the performance of Erlang programs manipulating floats considerably. We also show that by using this scheme, Erlang/OTP, despite being an implementation of a dynamically typed language, achieves performance which is competitive with that of state-of-the-art implementations of strongly typed strict functional languages on floating point intensive programs.", "num_citations": "8\n", "authors": ["351"]}
{"title": "Heap garbage collection in XSB: Practice and experience\n", "abstract": " Starting from a theoretical understanding of the usefulness logic of a logic programming system with built-in tabling, and from a collector that did not take the characteristics of a tabled abstract machine into account we have build two heap garbage collectors (one mark&slide, one mark\u00a9) for XSB on top of the CHAT implementation model for the suspension/resumption of consumers. Based on this experience we discuss implementation issues that are general to heap garbage collection for the WAM and also issues that are specific to an implementation with tabling: as such, this paper documents our own implementation and can serve as guidance for anyone attempting a similar feat. We report on the behaviour of the garbage collectors on different kinds of programs. We also present figures on the extent of internal fragmentation and the effectiveness of early reset in Prolog systems with and without tabling.", "num_citations": "8\n", "authors": ["351"]}
{"title": "Property-based testing of sensor networks\n", "abstract": " We advocate the use of property-based testing in the area of sensor networks and present a framework to apply this testing methodology. Our framework provides an expressive high-level language to specify a wide range of properties, starting from properties of individual functions to network-global properties, and infrastructure to automatically test these properties in Cooja, the network simulator of the Contiki operating system. We demonstrate the ease of use and effectiveness of our framework by two case studies. In the first, we test whether the energy consumption of the radio duty-cycle protocol X-MAC is within some specific bound. Property-based testing finds minimal network configurations where a small number of nodes violate the property. Property-based testing also reveals that the same property is not violated when ContikiMAC is used instead, but finds cases where ContikiMAC has higher energy\u00a0\u2026", "num_citations": "7\n", "authors": ["351"]}
{"title": "Detecting defects in Erlang programs using static analysis\n", "abstract": " This talk will review the main techniques used in the Dialyzer (Discrepancy AnaLYZer of ERlang programs) defect detection tool. Dialyzer employs various forms of static program analysis to automatically identify software errors in large applications written in Erlang, a concurrent functional language developed by Ericsson and commonly used for developing telecommunications software. Dialyzer is completely automatic, relatively fast, requires no annotations from its user to detect defects, and is exceptional in that it does not report any false positives. The heart of Dialyzer's analysis is inter-modular inference of success typings for Erlang functions and the talk will explain what success typings are and how they differ from type inference in statically typed language.", "num_citations": "7\n", "authors": ["351"]}
{"title": "The Nifty way to call hell from heaven\n", "abstract": " Often Erlang programmers want or need to use existing C libraries. Also, occasionally they have good reasons to implement parts of their applications directly in C. To cater for such situations, the Erlang/OTP system comes with various mechanisms to call C from Erlang. The most modern of them allows to call C functions from Erlang as natively implemented functions (NIFs). Unfortunately, the use of a NIF library currently requires writing by hand a fair amount of code that to a large extent is boilerplate. To ease the lives of Erlang programmers and simplify the task of using existing C code bases from Erlang, we have created Nifty, a tool that automates the process of creating NIF libraries from C header files containing declarations of types and functions that the library supplies. This paper describes the functionality and implementation of Nifty, its current limitations and our experiences with it so far.", "num_citations": "6\n", "authors": ["351"]}
{"title": "ProFuN TG: A tool using abstract task graphs to facilitate the development, deployment and maintenance of wireless sensor network applications\n", "abstract": " In this demo abstract we present ProFuN TG (Task Graph), a tool for sensor network application development using the data-flow programming paradigm. The tool has support for the whole lifecycle of WSN application: from the initial design of its task graph, task placement on network nodes, execution in a simulated environment, deployment on real hardware, to its automated maintenance through task remapping. ProFuN TG allows to program applications that incorporate quality-of-service requirements, expressed through constraints on task-to-task data flows.", "num_citations": "6\n", "authors": ["351"]}
{"title": "Message analysis-guided allocation and low-pause incremental garbage collection in a concurrent language\n", "abstract": " We present a memory management scheme for a concurrent programming language where communication occurs using message-passing with copying semantics. The runtime system is built around process-local heaps, which frees the memory manager from redundant synchronization in a multithreaded implementation and allows the memory reclamation of process-local heaps to be a private business and to often take place without garbage collection. The allocator is guided by a static analysis which speculatively allocates data possibly used as messages in a shared memory area. To respect the (soft) real-time requirements of the language, we develop a generational, incremental garbage collection scheme tailored to the characteristics of this runtime system. The collector imposes no overhead on the mutator, requires no costly barrier mechanisms, and has a relatively small space overhead. We have\u00a0\u2026", "num_citations": "6\n", "authors": ["351"]}
{"title": "Adaptive pattern matching on binary data\n", "abstract": " Pattern matching is an important operation in functional programs. So far, pattern matching has been investigated in the context of structured terms. This paper presents an approach to extend pattern matching to terms without (much of a) structure such as binaries which is the kind of data format that network applications typically manipulate. After introducing a notation for matching binary data against patterns, we present an algorithm that constructs a tree automaton from a set of binary patterns. We then show how the pattern matching can be made adaptive, how redundant tests can be avoided, and how we can further reduce the size of the resulting automaton by taking interferences between patterns into account. The effectiveness of our techniques is evaluated using implementations of network protocols taken from actual telecom applications.", "num_citations": "6\n", "authors": ["351"]}
{"title": "Testing and Verifying Chain Repair Methods for Corfu Using Stateless Model Checking\n", "abstract": " Corfu is a distributed shared log that is designed to be scalable and reliable in the presence of failures and asynchrony. Internally, Corfu is fully replicated for fault tolerance, without sharding data or sacrificing strong consistency. In this case study, we present the modeling approaches we followed to test and verify, using Concuerror, the correctness of repair methods for the Chain Replication protocol suitable for Corfu. In the first two methods we tried, Concuerror located bugs quite fast. In contrast, the tool did not manage to find bugs in the third method, but the time this took also motivated an improvement in the tool that reduces the number of traces explored. Besides more details about all the above, we present experiences and lessons learned from applying stateless model checking for verifying complex protocols suitable for distributed programming.", "num_citations": "5\n", "authors": ["351"]}
{"title": "Comparing source sets and persistent sets for partial order reduction\n", "abstract": " Partial order reduction has traditionally been based on persistent sets, ample sets, stubborn sets, or variants thereof. Recently, we have presented a strengthening of this foundation, using source sets instead of persistent/ample/stubborn sets. Source sets subsume persistent sets and are often smaller than persistent sets. We introduced source sets as a basis for Dynamic Partial Order Reduction (DPOR), in a framework which assumes that processes are deterministic and that all program executions are finite. In this paper, show how to use source sets for partial order reduction in a framework which does not impose these restrictions. We also compare source sets with persistent sets, providing some insights into conditions under which source sets and persistent sets do or do not differ.", "num_citations": "5\n", "authors": ["351"]}
{"title": "A type system for unstructured locking that guarantees deadlock freedom without imposing a lock ordering\n", "abstract": " Deadlocks occur in concurrent programs as a consequence of cyclic resource acquisition between threads. In this paper we present a novel type system that guarantees deadlock freedom for a language with references, unstructured locking primitives, and locks which are implicitly associated with references. The proposed type system does not impose a strict lock acquisition order and thus increases programming language expressiveness.", "num_citations": "5\n", "authors": ["351"]}
{"title": "HiPE on AMD64\n", "abstract": " Erlang is a concurrent functional language designed for developing large-scale, distributed, fault-tolerant systems. The primary implementation of the language is the Erlang/OTP system from Ericsson. Even though Erlang/OTP is by default based on a virtual machine interpreter, it nowadays also includes the HiPE (High Performance Erlang) native code compiler as a fully integrated component. This paper describes the recently developed port of HiPE to the AMD64 architecture. We discuss technical issues that had to be addressed when developing the port, decisions we took and why, and report on the speedups (compared with BEAM) which HiPE/AMD64 achieves across a range of Erlang programs and how these compare with speedups for the more mature SPARC and x86 back-ends.", "num_citations": "5\n", "authors": ["351"]}
{"title": "Parallel Graph-Based Stateless Model Checking\n", "abstract": " Stateless model checking (SMC) is an automatic technique with low memory requirements for finding errors in concurrent programs or for checking for their absence. To be effective, SMC tools require algorithms that combat the combinatorial explosion in the number of process/thread interactions that need to be explored. In recent years, a plethora of such algorithms have emerged, which can be classified broadly in those that explore interleavings (i.e., complete serializations of events) and those that explore traces (i.e., graphs of events). In either case, an SMC algorithm is optimal if it explores exactly one representative from each class of equivalent executions. In this paper, we examine the parallelization of a state-of-the-art graph-based algorithm for SMC under sequential consistency, based on the reads-from relation. The algorithm is provably optimal, and in practice spends only polynomial time per equivalence\u00a0\u2026", "num_citations": "4\n", "authors": ["351"]}
{"title": "Heap memory management in prolog with tabling: Principles and practice\n", "abstract": " We address memory management aspects of WAM-based logic programming systems that support tabled evaluation through the use of a suspension/resumption mechanism. We describe the memory organization and usefulness logic of such systems, and issues that have to be resolved for e ective and e cient garbage collection. Special attention is given to early reset in the context of suspended computations and to what is involved in the implementation of a segment order preserving copying collector for a tabled Prolog system. We also report our experience from building two working heap garbage collectors (one mark&slide and one mark\u00a9) for the XSB system on top of a CHAT-based tabled abstract machine: we discuss general implementation choices for heap garbage collection inplain'WAM and issues that are speci c to WAM with tabling. Finally, we compare the performance of our collectors with those of other Prolog systems and extensively analyze their characteristics. Thus, this article documents our own implementation and serves as guidance to anyone interested in proper memory management of tabled systems or systems that are similar in certain aspects.", "num_citations": "4\n", "authors": ["351"]}
{"title": "Extending partial deduction to tabled execution: Some results and open issues\n", "abstract": " Resolution methods based on tabling [Tamaki and Sato 1986; Warren 1992; Chen and Warren 1996] evaluate programs by recording subgoals (referred to as calls) and their provable instances (referred to as answers) in a global store called a table. Predicates are designated a priori as either tabled or nontabled, and execution proceeds as follows. For nontabled predicates the call is resolved against program clauses. For tabled predicates, if the call is new to the evaluation, it is entered in the table and Prolog-style program clause resolution is used to compute its set of answers which are also recorded in the table. If, on the other hand, the call is already present in the table, then it is resolved against its recorded answers. By using answer tables for resolving subsequent invocations of the same call, tabled execution prevents many cases of infinite looping which normally occur in Prologstyle SLD evaluation and\u00a0\u2026", "num_citations": "4\n", "authors": ["351"]}
{"title": "A better CAT made-in-Belgium: CHAT (or KAT)\n", "abstract": " The Copying Approach to Tabling, abbrv. CAT, is an alternative to SLG-WAM and based on total copying of the areas that SLG-WAM freezes to preserve execution states of suspended computations. The disadvantage of CAT as pointed out in a previous paper is that in the worst case, CAT must copy so much that it becomes arbitrarily worse than SLG-WAM. Remedies to this problem have been studied, but a completely satisfactory solution has not emerged. Here, a hybrid approach is presented: CHAT. Its design was guided by the requirement that for non-tabled (ie Prolog) execution no changes to the underlying WAM engine need to be made. CHAT combines certain features of the SLG-WAM with features of CAT, but also introduces a technique for freezing WAM stacks without the use of the SLG-WAM's freeze registers that is of independent interest. Empirical results indicate that CHAT is a better choice for implementing the control of tabling than SLG-WAM or CAT. However, programs with arbitrarily worse behaviour exist.", "num_citations": "4\n", "authors": ["351"]}
{"title": "The shared-memory interferences of Erlang/OTP built-ins\n", "abstract": " Erlang is a concurrent functional language based on the actor model of concurrency. In the purest form of this model, actors are realized by processes that do not share memory and communicate with each other exclusively via message passing. Erlang comes quite close to this model, as message passing is the primary form of interprocess communication and each process has its own memory area that is managed by the process itself. For this reason, Erlang is often referred to as implementing``shared nothing''concurrency. Although this is a convenient abstraction, in reality Erlang's main implementation, the Erlang/OTP system, comes with a large number of built-in operations that access memory which is shared by processes. In this paper, we categorize these built-ins, and characterize the interferences between them that can result in observable differences of program behaviour when these built-ins are used in\u00a0\u2026", "num_citations": "3\n", "authors": ["351"]}
{"title": "Minimal model tabling in Mercury\n", "abstract": " Prolog systems such as XSB have proven that tabling can be quite helpful in a variety of tasks, especially if it is efficiently implemented and fully integrated in the language. Implementing tabling in Mercury poses special challenges for several reasons. First, Mercury is both semantically and culturally quite different from Prolog. While decreeing that tabled predicates must not include cuts (or Prolog-style negations) is acceptable in a Prolog system, it is not acceptable in Mercury, since if-then-elses and existential quantification have sound semantics and are used very frequently both by programmers and by the compiler. The Mercury implementation thus has no option but to handle interactions of tabling with Mercury\u2019s language features safely. Second, the Mercury implementation is vastly different from the WAM, and many of the differences (eg storing values directly in stack slots without indirection, the absence of a trail) have significant impact on the implementation of tabling. In this paper, we describe how we adapted the copying approach to tabling to implement minimal model tabling in Mercury.", "num_citations": "2\n", "authors": ["351"]}
{"title": "From (multi-) generational to segment order preserving copying garbage collection for the WAM\n", "abstract": " We develop an algorithm for generational copying garbage collection in the WAM based on three generations. We then generalize this 3-generational algorithm to any number of generations. A new segment order preserving copying garbage collection algorithm then follows in a natural way. In contrast to previous segment preserving algorithms, the new algorithm does not require traversing the stacks in the opposite order, at the cost of a O (log (n)) pointer lookup where n is the number of collected heap segments. A trade-o between precision in the preservation of heap segment order and O (1) pointer lookup is presented. The algorithm gives an overall simple and practical way of implementing multi-generational copying garbage collection. Issues related to preserving generations on backtracking and cut are also discussed, as well as the impact of generations on early reset.", "num_citations": "2\n", "authors": ["351"]}
{"title": "Practical Aspects of Declarative Languages\n", "abstract": " Declarative languages build on sound theoretical bases to provide attractive frameworks for application development. These languages have been successfully applied to many different real-world situations, ranging from data base management to active networks to software engineering to decision support systems. New developments in theory and implementation have opened up new application areas. At the same time, applications of declarative languages to novel problems raise numerous interesting research issues. Well-known questions include designing for scalability, language extensions for application deployment, and programming environments. Thus, applications drive the progress in the theory and implementation of declarative systems, and benefit from this progress as well. PADL is a forum for researchers and practitioners to present original work emphasizing novel applications and\u00a0\u2026", "num_citations": "2\n", "authors": ["351"]}
{"title": "A portable compiler for integrating HiLog into Prolog systems\n", "abstract": " A portable compiler for integrating HiLog into Prolog systems | Proceedings of the 1994 International Symposium on Logic programming ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleProceedingsILPS '94A portable compiler for integrating HiLog into Prolog systems Article A portable compiler for integrating HiLog into Prolog systems Share on Authors: Konstantinos F. Sagonas View Profile , David S. Warren View Profile Authors Info & Affiliations Publication: ILPS '94: Proceedings of the 1994 International Symposium on Logic programmingNovember 1994 0citation 0 Downloads Metrics Total Citations0 Total Downloads0 Last 12 0 6 0 \u2026", "num_citations": "2\n", "authors": ["351"]}
{"title": "TSOPER: Efficient coherence-based strict persistency\n", "abstract": " We propose a novel approach for hardware-based strict TSO persistency, called TSOPER. We allow a TSO persistency model to freely coalesce values in the caches, by forming atomic groups of cachelines to be persisted. A group persist is initiated for an atomic group if any of its newly written values are exposed to the outside world. A key difference with prior work is that our architecture is based on the concept of a TSO persist buffer, that sits in parallel to the shared LLC, and persists atomic groups directly from private caches to NVM, bypassing the coherence serialization of the LLC.To impose dependencies among atomic groups that are persisted from the private caches to the TSO persist buffer, we introduce a sharing-list coherence protocol that naturally captures the order of coherence operations in its sharing lists, and thus can reconstruct the dependencies among different atomic groups entirely at the private\u00a0\u2026", "num_citations": "1\n", "authors": ["351"]}
{"title": "Enabling design of performance-controlled sensor network applications through task allocation and reallocation\n", "abstract": " Task Graph (ATaG) is a sensor network application development paradigm where the application is visually described by a graph where the nodes correspond to application-level tasks and edges correspond to data flows. We extend ATaG with the option to add non-functional requirements: constraints on end-to-end delay and packet delivery rate. Setting up these constraints at the design phase naturally leads to enabling run-time assurance at the deployment phase, when the conditions of the constraints are used as network's performance goals. We provide both run-time middleware that checks the conditions of these constraints and a central management unit that dynamically adapts the system by doing task reallocation and putting task copies on redundant nodes. Through extensive simulations we show that the system is efficient enough to enable adaptations within tens of seconds even in large networks.", "num_citations": "1\n", "authors": ["351"]}
{"title": "Typed callbacks for more robust behaviours\n", "abstract": " Behaviours are one of the most widely used features of Erlang/OTP. They offer a convenient and well-tested abstraction layer for frequently employed design patterns in concurrent Erlang programming. In effect, they allow programmers to focus on the functional characteristics of their applications without having to resort to Erlang's concurrency-supporting primitives. However, when it comes to ensuring that behaviours are properly used and callbacks are as expected, the current Erlang/OTP compiler performs only minimal checks. This is no fault of the compiler though, because most/all of the callbacks' API exists only in the documentation or the comments accompanying the code; as such, it cannot always be trusted and it is almost impossible to have it mechanically processed. In this paper, we propose a small extension to the language of function specifications of Erlang to allow the formal definition of the\u00a0\u2026", "num_citations": "1\n", "authors": ["351"]}
{"title": "Applications, implementation and performance evaluation of bit stream programming in Erlang\n", "abstract": " Writing code that manipulates bit streams is a painful and error-prone programming task, often performed via bit twiddling techniques such as explicit bit shifts and bit masks in programmer-allocated buffers. Still, this kind of programming is necessary in many application areas ranging from decoding streaming media files to implementing network protocols. In this paper we employ high-level constructs from declarative programming, such as pattern matching at the bit level and bit stream comprehensions, and show how a variety of bit stream programming applications can be written in a succinct, less error-prone, and totally memory-safe manner. We also describe how these constructs can be implemented efficiently. The resulting performance is superior to that of other (purely) functional languages and competitive to that of low-level languages such as C.", "num_citations": "1\n", "authors": ["351"]}