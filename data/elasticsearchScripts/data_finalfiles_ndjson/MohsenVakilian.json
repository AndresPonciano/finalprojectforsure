{"title": "A type and effect system for deterministic parallel java\n", "abstract": " Today\u2019s shared-memory parallel programming models are complex and error-prone. While many parallel programs are intended to be deterministic, unanticipated thread interleavings can lead to subtle bugs and nondeterministic semantics. In this paper, we demonstrate that a practical type and effect system can simplify parallel programming by guaranteeing deterministic semantics with modular, compile-time type checking even in a rich, concurrent object-oriented language such as Java. We describe an object-oriented type and effect system that provides several new capabilities over previous systems for expressing deterministic parallel algorithms. We also describe a language called Deterministic Parallel Java (DPJ) that incorporates the new type system features, and we show that a core subset of DPJ is sound. We describe an experimental validation showing that DPJ can express a wide range of realistic parallel programs; that the new type system features are useful for such programs; and that the parallel programs exhibit good performance gains (coming close to or beating equivalent, nondeterministic multithreaded programs where those are available).", "num_citations": "446\n", "authors": ["799"]}
{"title": "Use, disuse, and misuse of automated refactorings\n", "abstract": " Though refactoring tools have been available for more than a decade, research has shown that programmers underutilize such tools. However, little is known about why programmers do not take advantage of these tools. We have conducted a field study on programmers in their natural settings working on their code. As a result, we collected a set of interaction data from about 1268 hours of programming using our minimally intrusive data collectors. Our quantitative data show that programmers prefer lightweight methods of invoking refactorings, usually perform small changes using the refactoring tool, proceed with an automated refactoring even when it may change the behavior of the program, and rarely preview the automated refactorings. We also interviewed nine of our participants to provide deeper insight about the patterns that we observed in the behavioral data. We found that programmers use predictable\u00a0\u2026", "num_citations": "177\n", "authors": ["799"]}
{"title": "Automated decomposition of build targets\n", "abstract": " A (build) target specifies the information that is needed to automatically build a software artifact. This paper focuses on underutilized targets - an important dependency problem that we identified at Google. An underutilized target is one with files not needed by some of its dependents. Underutilized targets result in less modular code, overly large artifacts, slow builds, and unnecessary build and test triggers. To mitigate these problems, programmers decompose underutilized targets into smaller targets. However, manually decomposing a target is tedious and error-prone. Although we prove that finding the best target decomposition is NP-hard, we introduce a greedy algorithm that proposes a decomposition through iterative unification of the strongly connected components of the target. Our tool found that 19,994 of 40,000 Java library targets at Google can be decomposed to at least two targets. The results show that\u00a0\u2026", "num_citations": "37\n", "authors": ["799"]}
{"title": "A compositional paradigm of automating refactorings\n", "abstract": " Recent studies suggest that programmers greatly underuse refactoring tools, especially for complex refactorings. Complex refactorings tend to be tedious and error-prone to perform by hand. To promote the use of refactoring tools for complex changes, we propose a new paradigm for automating refactorings called compositional refactoring. The key idea is to perform small, predictable changes using a tool and manually compose them into complex changes. This paradigm trades off some level of automation by higher predictability and control. We show that this paradigm is natural, because our analysis of programmers\u2019 use of the Eclipse refactoring tool in the wild shows that they frequently batch and compose automated refactorings. We then show that programmers are receptive to this new paradigm through a survey of 100 respondents. Finally, we show that the compositional paradigm is effective\u00a0\u2026", "num_citations": "36\n", "authors": ["799"]}
{"title": "The need for richer refactoring usage data\n", "abstract": " Even though modern Integrated Development Environments (IDEs) support many refactorings, studies suggest that automated refactorings are used infrequently, and few developers use anything beyond Rename and Extract refactorings. Little is known about why automated refactorings are seldom used. We present a list of challenging questions whose answers are crucial for understanding the usability issues of refactoring tools. This paper argues that the existing data sources-Eclipse UDC, Eclipse refactoring histories, version control histories, etc.-are inadequate for answering these questions. Finally, we introduce our tools to collect richer usage data that will enable us to answer some of the open research questions about the usability of refactoring tools. Findings from our data will foster the design of the next generation of refactoring tools.", "num_citations": "32\n", "authors": ["799"]}
{"title": "Alternate refactoring paths reveal usability problems\n", "abstract": " Modern Integrated Development Environments (IDEs) support many refactorings. Yet, programmers greatly underuse automated refactorings. Recent studies have applied traditional usability testing methodologies such as surveys, lab studies, and interviews to find the usability problems of refactoring tools. However, these methodologies can identify only certain kinds of usability problems. The critical incident technique (CIT) is a general methodology that uncovers usability problems by analyzing troubling user interactions. We adapt CIT to refactoring tools and show that alternate refactoring paths are indicators of the usability problems of refactoring tools. We define an alternate refactoring path as a sequence of user interactions that contains cancellations, reported messages, or repeated invocations of the refactoring tool. We evaluated our method on a large corpus of refactoring usage data, which we collected\u00a0\u2026", "num_citations": "30\n", "authors": ["799"]}
{"title": "Modeling web service interactions using the coordination language reo\n", "abstract": " In this paper we propose an approach to derive the formal semantics of WS-BPEL processes compositionally using Reo and constraint automata. We map each WS-BPEL process into a Reo circuit and then construct the corresponding constraint automaton which shows the behavior of the process. The constraint automaton can be used for analyzing the process behavior. Our work covers the core part of the WS-BPEL language including basic and structured activities, correlation sets, variables, and links.", "num_citations": "26\n", "authors": ["799"]}
{"title": "Cascade: A universal programmer-assisted type qualifier inference tool\n", "abstract": " Type qualifier inference tools usually operate in batch mode and assume that the program must not be changed except to add the type qualifiers. In practice, programs must be changed to make them type-correct, and programmers must understand them. Cascade is an interactive type qualifier inference tool that is easy to implement and universal (i.e., it can work for any type qualifier system for which a checker is implemented). It shows that qualifier inference can achieve better results by involving programmers rather than relying solely on automation.", "num_citations": "17\n", "authors": ["799"]}
{"title": "A practical guide to analyzing ide usage data\n", "abstract": " Integrated development environments such as Eclipse and Visual Studio provide tools and capabilities to perform tasks such as navigating among classes and methods, continuous compilation, code refactoring, automated testing, and integrated debugging, all designed to increase productivity. Instrumenting the integrated development environment to collect usage data provides a more fine-grained understanding of developers\u2019 work than was previously possible. Usage data supports analysis of how developers spend their time, what activities might benefit from greater tool support, where developers have difficulty comprehending code, and whether they are following specific practices such as test-driven development. With usage data, we expect to uncover more nuggets of how developers create mental models, how they investigate code, how they perform mini trial-and-error experiments, and what might drive\u00a0\u2026", "num_citations": "17\n", "authors": ["799"]}
{"title": "Keshmesh: A tool for detecting and fixing Java concurrency bug patterns\n", "abstract": " Developing concurrent software is error prone. Others have cataloged common bug patterns in concurrent Java programs. But, there are no tools for detecting complex concurrency bug patterns accurately, and concurrent programs are full of similar bugs. We have been developing a tool called Keshmesh for detecting complex concurrency bug patterns in Java programs statically. Keshmesh is the first tool that accurately detects a few of the top concurrency bug patterns of the SEI CERT catalog [3] and suggests automated fixers for some of them. Keshmesh is fast enough to be used interactively, produces few false alarms and helps Java programmers to quickly find and fix common concurrency bug patterns in their programs.", "num_citations": "9\n", "authors": ["799"]}
{"title": "Less is sometimes more in the automation of software evolution tasks\n", "abstract": " Software rapidly evolves. A refactoring is a code change that preserves the behavior of the program. There has been much interest in automation to make refactoring more efficient and reliable. Although modern Integrated Development Environments (IDEs) provide many automated refactorings, studies suggest that programmers underuse automated refactorings. Based on our studies of programmers\u2019 refactoring practices, we argue that usability problems are the common reasons of underusing automated refactorings. We introduce compositional refactoring, a new paradigm of automating refactorings. In this paradigm, the tool designer decomposes the large refactorings into a set of smaller, primitive changes and automates the primitive changes. Then, programmers compose the primitive changes to make larger changes. We have used the compositional paradigm to automate two classes of refactorings: the\u00a0\u2026", "num_citations": "5\n", "authors": ["799"]}
{"title": "Composite refactorings: the next refactoring rubicons\n", "abstract": " The industry crossed the first refactoring rubicon, namely Extract Method, more than a decade ago. Today, all mainstream Integrated Development Environments (IDEs) support this refactoring, and empirical studies have shown that Extract Method is one of the most frequently used automated refactorings. Although complex refactorings are more tedious and error-prone, studies have shown that programmers use the automated refactorings mostly for performing simple changes. We argue that new interaction models are needed to support high-level composite refactorings. Because of the challenges involved in automating such complex refactorings, we consider composite refactorings as the next refactoring rubicons.", "num_citations": "3\n", "authors": ["799"]}
{"title": "Keshmesh: Bringing Advanced Static Analysis to Concurrency Bug Pattern Detectors\n", "abstract": " Bug patterns are coding idioms that may make the code less maintainable or turn into bugs in future. The state-of-the-art tools for detecting concurrency bug patterns (CBPs) perform simple, intraprocedural analyses. While this simplicity makes the analysis fast, it does not provide protection against CBPs that involve aliasing or multiple methods. This paper introduces a practical and extensible framework, Keshmesh, which employs advanced static analysis for detecting CBPs. Keshmesh builds upon the points-to analysis of WALA, a static analysis framework, and the user interface of FindBugs, a popular bug pattern detection tool. Keshmesh detects five CBPs using interprocedural analyses and fixes two of them. The challenges in automatic detection of these CBPs include reducing the rate of false positives, scaling to large projects, and accurate propagation of unsafe accesses along the call graph up to synchronization constructs. Keshmesh found 40 previously unknown CBP instances and only 12 false positives in six open-source projects. Programmers fixed 11 of the 20 issues we reported. These results show that Keshmesh is applicable to large projects, finds CBPs that programmers want to fix, and reports few false positives.", "num_citations": "2\n", "authors": ["799"]}
{"title": "Automated Decomposition of Build Targets (Extended Version)\n", "abstract": " A (build) target specifies the information that is needed to automatically build a software artifact. This paper focuses on underutilized targets\u2014an important dependency problem that we identified at Google. An underutilized target is one with files not needed by some of its dependents. Underutilized targets result in less modular code, overly large artifacts, slow builds, and unnecessary build and test triggers. To mitigate these problems, programmers decompose underutilized targets into smaller targets. However, manually decomposing a target is tedious and error-prone. Although we prove that finding the best target decomposition is NP-hard, we introduce a greedy algorithm that proposes a decomposition through iterative unification of the strongly connected components of the target. Our tool found that 19,994 of 40,000 Java library targets at Google can be decomposed to at least two targets. The results show that our tool is (1) efficient because it analyzes a target in two minutes on average and (2) effective because for each of 1,010 targets, it would save at least 50% of the total execution time of the tests triggered by the target.", "num_citations": "1\n", "authors": ["799"]}
{"title": "Joint review of how to solve it: a new aspect of mathematical method by George Polya and Street-fighting mathematics by Sanjoy Mahajan\n", "abstract": " Both books teach you some techniques to solve mathematical problems. The book by Polya is a classic and more general book whose techniques can be applied when solving any mathematical problem. But, the book by Mahajan presents some specific tricks to get you to the answer quickly.", "num_citations": "1\n", "authors": ["799"]}