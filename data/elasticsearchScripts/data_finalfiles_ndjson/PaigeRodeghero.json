{"title": "Improving automated source code summarization via an eye-tracking study of programmers\n", "abstract": " Source Code Summarization is an emerging technology for automatically generating brief descriptions of code. Current summarization techniques work by selecting a subset of the statements and keywords from the code, and then including information from those statements and keywords in the summary. The quality of the summary depends heavily on the process of selecting the subset: a high-quality selection would contain the same statements and keywords that a programmer would choose. Unfortunately, little evidence exists about the statements and keywords that programmers view as important when they summarize source code. In this paper, we present an eye-tracking study of 10 professional Java programmers in which the programmers read Java methods and wrote English summaries of those methods. We apply the findings to build a novel summarization tool. Then, we evaluate this tool and provide\u00a0\u2026", "num_citations": "168\n", "authors": ["2161"]}
{"title": "An Eye-Tracking Study of Java Programmers and Application to Source Code Summarization\n", "abstract": " Source Code Summarization is an emerging technology for automatically generating brief descriptions of code. Current summarization techniques work by selecting a subset of the statements and keywords from the code, and then including information from those statements and keywords in the summary. The quality of the summary depends heavily on the process of selecting the subset: a high-quality selection would contain the same statements and keywords that a programmer would choose. Unfortunately, little evidence exists about the statements and keywords that programmers view as important when they summarize source code. In this paper, we present an eye-tracking study of 10 professional Java programmers in which the programmers read Java methods and wrote English summaries of those methods. We apply the findings to build a novel summarization tool. Then, we evaluate this tool. Finally, we\u00a0\u2026", "num_citations": "53\n", "authors": ["2161"]}
{"title": "Detecting speech act types in developer question/answer conversations during bug repair\n", "abstract": " This paper targets the problem of speech act detection in conversations about bug repair. We conduct a``Wizard of Oz''experiment with 30 professional programmers, in which the programmers fix bugs for two hours, and use a simulated virtual assistant for help. Then, we use an open coding manual annotation procedure to identify the speech act types in the conversations. Finally, we train and evaluate a supervised learning algorithm to automatically detect the speech act types in the conversations. In 30 two-hour conversations, we made 2459 annotations and uncovered 26 speech act types. Our automated detection achieved 69% precision and 50% recall. The key application of this work is to advance the state of the art for virtual assistants in software engineering. Virtual assistant technology is growing rapidly, though applications in software engineering are behind those in other areas, largely due to a lack of\u00a0\u2026", "num_citations": "26\n", "authors": ["2161"]}
{"title": "An Empirical Study on the Patterns of Eye Movement during Summarization Tasks\n", "abstract": " Eye movement patterns are the order in which keywords or sections of keywords are read. These patterns are an important component of how programmers read source code. One strategy for determining how programmers perform summarization tasks is through eye tracking studies. These studies examine where people focus their attention while viewing text or images. In this study, we expand on eye tracking analysis to determine the eye movement patterns of programmers. We begin the study with a qualitative exploration of the eye movement patterns used by 10 professional programmers from an earlier study. We then use what we learned qualitatively to perform a quantitative analysis of those patterns. We found that all ten of the programmers followed nearly identical eye movement patterns. These patterns were analogous to eye movement patterns of reading natural language.", "num_citations": "25\n", "authors": ["2161"]}
{"title": "AudioHighlight: Code skimming for blind programmers\n", "abstract": " Blind programmers use a screen reader to read code aloud. Screen readers force blind programmers to read code sequentially one line at a time. In contrast, sighted programmers are able to skim visually to the most important code areas, assisted by syntax highlighting. However, there is a place where there is a widely adopted approach to skimming a structured document: the web. Modern screen readers employ what is known as a virtual cursor to navigate structural information on webpages such as HTML heading tags. These tags can indicate different sections and subsections in the structure of a page. We harness the existing familiarity of blind computer users with this interface in our approach which we call AudioHighlight. AudioHighlight renders the code inside a web view, either as part of the Eclipse IDE or as a web service. It places HTML heading tags on the structural elements of a source file such as\u00a0\u2026", "num_citations": "8\n", "authors": ["2161"]}
{"title": "An Empirical Study on How Expert Knowledge Affects Bug Reports\n", "abstract": " Bug reports are crucial software artifacts for both software maintenance researchers and practitioners. A typical use of bug reports by researchers is to evaluate automated software maintenance tools: a large repository of reports is used as input for a tool, and metrics are calculated from the tool's output. But this process is quite different from practitioners, who distinguish between reports written by experts, such as programmers, and reports written by non\u2010experts, such as users. Practitioners recognize that the content of a bug report depends on its author's expert knowledge. In this paper, we present an empirical study of the textual difference between bug reports written by experts and non\u2010experts. We find that a significant difference exists and that this difference has a significant impact on the results from a state\u2010of\u2010the\u2010art feature location tool. Through an additional study, we also found no evidence that these\u00a0\u2026", "num_citations": "7\n", "authors": ["2161"]}
{"title": "Making quantum computing open: Lessons from open source projects\n", "abstract": " Quantum computing (QC) is an emerging computing paradigm with the potential to revolutionize the field of computing. QC is a field that is quickly developing globally and has high barriers of entry. In this paper, we explore both successful contributors to the field as well as the wider QC community with the goal of understanding the backgrounds and training that helped them succeed. We gather data on 148 contributors to open source quantum computing projects hosted on GitHub and survey 46 members of QC community. Our findings show that QC practitioners and enthusiasts have diverse backgrounds, with most of them having a PhD and training in physics or computer science. We observe a lack of educational resources on quantum computing. Our goal is to use these results to start a conversation on making quantum computing more open.", "num_citations": "4\n", "authors": ["2161"]}
{"title": "Examining the Work Experience of Programmers with Visual Impairments\n", "abstract": " The rapid rise and ubiquity of computing has led to tremendous growth in the field of software development; growth that has outpaced society\u2019s ability to fill available positions. The gap between this large number of openings and the decidedly smaller pool of qualified candidates available to fill them has created opportunities for individuals from non-traditional backgrounds to pursue careers in software development. Due to the nature of their disability, blind and low vision persons have not to date been heavily pursued as candidates for software development positions given the arguably visually demanding nature of the practice. As such, we argue, there are significant knowledge gaps as it pertains to how visual impairment may impact a developer\u2019s contribution to a software development team. To explore this issue we interviewed 11 visually impaired software developers about their experiences. Our findings\u00a0\u2026", "num_citations": "4\n", "authors": ["2161"]}
{"title": "API Usage in Descriptions of Source Code Functionality\n", "abstract": " In this paper, we present a study exploring the use of API keywords within method summaries. We conducted a web-based study where we asked participants to rank Java method summaries based on five levels of detail, from low level to high level. We found that programmers widely use API in both high and low level summaries. Specifically, we found that 76.78% of higher level summaries contain Java API keywords. Additionally, we found that 93.75% of lower level summaries also contain them. This also shows that, in general, as the detail level decreases, the number of API keywords within the summary increases. It is our hope that this line of research will spark a discussion about API usage outside of source code. It is possible that method summaries are not the only form of documentation that API usage plays an important role. We believe these may be important results that could lead to an improvement for\u00a0\u2026", "num_citations": "4\n", "authors": ["2161"]}
{"title": "Discovering important source code terms\n", "abstract": " Terms in source code have become extremely important in Software Engineering research. These\" important\" terms are typically used as input to research tools. Therefore, the quality of the output of these tools will depend on the quality of the term extraction technique. Currently, there is no definitive best technique for predicting the importance of terms during program comprehension. In my work, I perform a literature review of several techniques. I then propose a unified importance prediction model based on a machine learning algorithm. I evaluate my model in a field study involving professional programmers, as well as a standard 10-fold synthetic study. I found that my model predicts the top quartile of most-important source code terms with approximately 50% precision and recall, outperforming tf/idf and other popular techniques. Furthermore, I found that, during actual program comprehension tasks, the\u00a0\u2026", "num_citations": "4\n", "authors": ["2161"]}
{"title": "Onboarding Bot for Newcomers to Software Engineering\n", "abstract": " Software development teams dedicate considerable resources to training newcomers. Newcomers are new developers to a software project. The software onboarding process is more complicated than onboarding into other organizations. It is much more challenging and time-consuming. The role of a mentor in onboarding newcomers in software engineering is well understood. However, the disruptions to the work of an experienced developer can reduce the quality of their work and job satisfaction. We propose a conversational bot that can help onboard newcomers to a software project instead of an experienced programmer. The bot will act as a mentor for the newcomer, thus putting less stress on experienced programmers. The bot will also be able to scan outside sources, such as stack overflow, for solutions to issues a newcomer may face. The newcomer will be able to interact with the bot using natural\u00a0\u2026", "num_citations": "3\n", "authors": ["2161"]}
{"title": "Program Comprehension in Virtual Reality\n", "abstract": " Virtual reality is an emerging technology for various domains such as medicine, psychotherapy, architecture, and gaming. Recently, software engineering researchers have started to explore virtual reality as a tool for programmers. However, few studies examine source code comprehension in a virtual reality (VR) environment. In this paper, we explore the human experience of comprehending source code in VR. We conducted a study with 26 graduate students. We found that the programmers experienced more challenges when reading and comprehending code in VR. We found no statistically significant difference in the programmers' perceived productivity between our VR and traditional comprehension studies.", "num_citations": "3\n", "authors": ["2161"]}
{"title": "Remote Pair Programming in Virtual Reality\n", "abstract": " There are many benefits to pair programming, including increased knowledge transfer, higher quality code, increased code comprehension, and team bonding. Unfortunately, when programmers work remotely, it becomes more challenging to collaborate. Virtual Reality (VR) technology has become increasingly popular in domains outside of software engineering. It allows humans to experience increased social presence, a key for collaboration, while still working remotely. In the last few years, and even more so recently, remote work has become very common for software engineers. In this paper, we explore remote pair programming and code comprehension in virtual reality. We conducted remote pair programming experiments with a total of 40 professional programmers. Half of the participants pair programmed using VR as a tool and the other half used a screen sharing system to collaborate. We found that\u00a0\u2026", "num_citations": "3\n", "authors": ["2161"]}
{"title": "Behavior-informed algorithms for automatic documentation generation\n", "abstract": " Programmers rely on source code documentation to quickly understand what the source code does and how they would use it. Unfortunately, many programmers do not have the time to write and maintain source code documentation. A solution to this problem is to document and summarize source code automatically. Unfortunately, research efforts to automatically generate documentation have stalled recently because the research community does not know exactly what a summary of source code should include. To solve this problem, my overall strategy is to study programmer behavior in order to write algorithms that mimic that behavior. I have four key areas of work in which I execute that strategy: First, I determine what areas of code programmers read when they create documentation. Second, I find patterns in programmers' eye movements when they reading code. Third, I use recordings of developer-client\u00a0\u2026", "num_citations": "3\n", "authors": ["2161"]}
{"title": "Exploring the Perspectives of Teachers of the Visually Impaired Regarding Accessible K12 Computing Education\n", "abstract": " As the computing job market continues to expand, the demand for eligible professionals to fill open positions has increased. In response, diversity efforts seek to broaden the participation of underrepresented populations in computing. This movement towards broadening participation includes blind or visually impaired (BVI) people who, historically, have faced barriers in succeeding in a primarily visually-oriented field. The present literature has examined modifying current tools for greater accessibility for BVI people and developing new, more inclusive learning environments. We argue, however, for additional investigation into the accessibility of computing education from the lens of instructors who teach computing to BVI students. Our paper reports on findings from interviews investigating the learning experience of BVI students in computer science courses from the perspective of teachers of the visually impaired\u00a0\u2026", "num_citations": "2\n", "authors": ["2161"]}
{"title": "How a Remote Video Game Coding Camp Improved Autistic College Students' Self-Efficacy in Communication\n", "abstract": " Communication and teamwork are essential skills for software developers. However, these skills are often difficult to learn for students with autism spectrum disorder (ASD). We designed, developed, and ran a 13-day, remote video game coding camp for incoming college first-year students with ASD. We developed instructional materials to teach computer programming, video game design, and communication and teaming skills. Students used the MakeCode Arcade development environment to build their games and Zoom to remotely collaborate with their teammates. In summative interviews, students reported improved programming skills, increased confidence in communication, and better experiences working with others. We also found that students valued the opportunity to practice teaming, such as being more vocal in expressing ideas to their peers and working out differences of opinion with their teammates\u00a0\u2026", "num_citations": "2\n", "authors": ["2161"]}
{"title": "Human-AI Partnerships for Chaos Engineering\n", "abstract": " Chaos Engineering refers to the practice of introducing faults in a system and observe the extent to which the system remains fault tolerant. However, is randomization the best approach to expose faults within a system? We aim to answer this question by introducing Chaos into different software architecture patterns and demonstrate how a back-end system can be made fault tolerant through artificial intelligence (AT). This paper discusses what aspects of AI would be used to make a system more resilient to perturbations and the results of these findings against existing chaos engineering approaches.", "num_citations": "2\n", "authors": ["2161"]}
{"title": "Invoking Principles of Groupware to Develop and Evaluate Present and Future Human-Agent Teams\n", "abstract": " Advances in artificial intelligence are constantly increasing its validity as a team member enabling it to effectively work alongside humans and other artificial teammates. Unfortunately, the digital nature of artificial teammates and their restrictive communication and coordination requirements complicate the interaction patterns that exist. In light of this challenge, we create a theoretical framework that details the possible interactions in human-agent teams, emphasizing interactions through groupware, which is based on literature regarding groupware and human-agent teamwork. As artificial intelligence changes and advances, the interaction in human-agent teams will also advance, meaning interaction frameworks and groupware must adapt to these changes. We provide examples and a discussion of the frameworks ability to adapt based on advancements in relevant research areas like natural language processing\u00a0\u2026", "num_citations": "2\n", "authors": ["2161"]}
{"title": "Exploring the Challenges of Cloud Migrations During a Global Pandemic\n", "abstract": " There are many benefits of migrating applications to the cloud, including highly available and elastic compute power, unlimited backup and storage, fully managed services, and overall cost savings. However, there are many challenges that software engineers face when migrating applications to the cloud. Even more challenges during the recent COVID-19 pandemic. The focus of this paper is to shed light on the challenges software engineers face performing cloud migrations during a global pandemic. A proposed set of research questions will be used to determine the challenges remote software engineers face, as well as the tools and methodologies used during the cloud migration process. Future work will consist of building a process model by examining the current state of cloud migration approaches as well as new approaches due to a global pandemic.", "num_citations": "2\n", "authors": ["2161"]}
{"title": "Position Paper: Towards Usability as a First-Class Quality of HPC Scientific Software\n", "abstract": " The modern HPC scientific software ecosystem is instrumental to the practice of science. However, software can only fulfill that role if it is readily usable. In this position paper, we discuss usability in the context of scientific software development, how usability engineering can be incorporated into current practice, and how software engineering research can help satisfy that objective.", "num_citations": "1\n", "authors": ["2161"]}