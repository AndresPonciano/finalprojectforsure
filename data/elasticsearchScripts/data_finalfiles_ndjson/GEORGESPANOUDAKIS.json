{"title": "Inconsistency management in software engineering: Survey and open research issues\n", "abstract": " The development of complex software systems is a complex and lengthy activity that involves the participation and collaboration of many stakeholders (e.g. customers, users, analysts, designers, and developers). This results in many partial models of the developing system. These models can be inconsistent with each other since they describe the system from different perspectives and reflect the views of the stakeholders involved in their construction. Inconsistent software models can have negative and positive effects in the software development life-cycle. On the negative side, inconsistencies can delay and increase the cost of system development; do not guarantee some properties of the system, such as safety and reliability; and generate difficulties on system maintenance. On the positive side, inconsistencies can facilitate identification of some aspects of the system that need further analysis, assist with the\u00a0\u2026", "num_citations": "340\n", "authors": ["347"]}
{"title": "Rule-based generation of requirements traceability relations\n", "abstract": " The support for traceability between requirement specifications has been recognised as an important task in the development life cycle of software systems. In this paper, we present a rule-based approach to support the automatic generation of traceability relations between documents which specify requirement statements and use cases (expressed in structured forms of natural language), and analysis object models for software systems. The generation of such relations is based on traceability rules of two different types. More specifically, we use requirement-to-object-model rules to trace the requirements and use case specification documents to an analysis object model, and inter-requirements traceability rules to trace requirement and use case specification documents to each other. By deploying such rules, our approach can generate four different types of traceability relations. To implement and demonstrate our\u00a0\u2026", "num_citations": "290\n", "authors": ["347"]}
{"title": "Software traceability: a roadmap\n", "abstract": " Traceability of software artefacts has been recognized as an important factor for supporting various activities in the software system development process. In general, the objective of traceability is to improve the quality of software systems. More specifically, traceability information can be used to support the analysis of implications and integration of changes that occur in software systems; the maintenance and evolution of software systems; the reuse of software system components by identifying and comparing requirements of new and existing systems; the testing of software system components; and system inspection, by indicating alternatives and compromises made during development. Traceability enables system acceptance by allowing users to better understand the system and contributes to a clear and consistent system documentation. Over the last few years, the software and system engineering\u00a0\u2026", "num_citations": "286\n", "authors": ["347"]}
{"title": "A framework for requirents monitoring of service based systems\n", "abstract": " This paper proposes a framework for monitoring the compliance of systems composed of web-services with requirements set for th. This framework assumes systems composed of web-services that are co-ordinated by a service composition process expressed in BPEL4WS and uses event calculus to specify the properties to be monitored. The monitorable properties may include behavioural properties of a syst which are automatically extracted from the specification of its composition process in BPEL4WS and/or assumptions that syst providers can specify in terms of events extracted from this specification.", "num_citations": "208\n", "authors": ["347"]}
{"title": "Establishing and monitoring SLAs in complex service based systems\n", "abstract": " In modern service economies, service provisioning needs to be regulated by complex SLA hierarchies among providers of heterogeneous services, defined at the business, software, and infrastructure layers. Starting from the SLA Management framework defined in the SLA@SOI EU FP7 Integrated Project, we focus on the relationship between establishment and monitoring of such SLAs, showing how the two processes become tightly interleaved in order to provide meaningful mechanisms for SLA management. We first describe the process for SLA establishment adopted within the framework; then,we propose an architecture for monitoring SLAs, which satisfies the two main requirements introduced by SLA establishment: the availability of historical data for evaluating SLA offers and the assessment of the capability to monitor the terms in a SLA offer.", "num_citations": "149\n", "authors": ["347"]}
{"title": "Run-time monitoring of requirements for systems composed of web-services: Initial implementation and evaluation experience\n", "abstract": " This paper describes a framework supporting the runtime monitoring of requirements for systems implemented as compositions of Web-services specified in BPEL. The requirements that can be monitored are specified in event calculus. The paper presents an overview of the framework and describes the architecture and implementation of a tool that we have developed to operationalise it. It also presents the results of a preliminary experimental evaluation of the framework.", "num_citations": "140\n", "authors": ["347"]}
{"title": "Non-intrusive monitoring of service-based systems\n", "abstract": " This paper presents a framework for monitoring the compliance of systems composed of Web-services with requirements set for them at runtime. This framework assumes systems composed of Web-services which are co-coordinated by a service composition process expressed in BPEL and uses event calculus to specify the requirements to be monitored. These requirements may include behavioral properties of a system which are automatically extracted from the specification of its composition process in BPEL and/or assumptions that system providers can specify in terms of events extracted from this specification.", "num_citations": "129\n", "authors": ["347"]}
{"title": "Monitoring WS-Agreements: An Event Calculus\u2013Based Approach\n", "abstract": " In this chapter, we present a framework that we have developed to support the monitoring of service level agreements (SLAs). The agreements that can be monitored by this framework are expressed in an extension of WS-Agreement that we propose. The main characteristic of the proposed extension is that it uses an event calculus\u2013based language, called EC-Assertion, for the specification of the service guarantee terms in a service level agreement that need to be monitored at runtime. The use of EC-Assertion for specifying service guarantee terms provides a well-defined semantics to the specification of such terms and a formal reasoning framework for assessing their satisfiability. The chapter describes also an implementation of the framework and the results of a set of experiments that we have conducted to evaluate it.", "num_citations": "101\n", "authors": ["347"]}
{"title": "A service discovery framework for service centric systems\n", "abstract": " An important aspect of service-centric systems (i.e. systems composed of services) is the ability to support service discovery at run-time in order to cope with unavailable or malfunctioning services. In this paper we present a framework that supports run-time service discovery. The central characteristic of this framework is the combination of components for monitoring the compliance of service-centric systems with requirements at run-time and components for discovering services at run-time. The framework uses the former components to detect violations of requirements at run-time and uses the specifications of the violated requirements to generate queries for discovering services that could substitute for malfunctioning services. It also uses queries derived from the process specification for service discovery. These queries incorporate both structural and behavioural aspects of the required services.", "num_citations": "90\n", "authors": ["347"]}
{"title": "Plausible and adaptive requirement traceability structures\n", "abstract": " This paper presents an extension of a traceability system which automates the generation of traceability relations between textual requirement artefacts and object models using heuristic traceability rules. These rules match syntactically related terms in the textual parts of the requirements artefacts with related elements in an object model (eg classes, attributes, operations) and create traceability relations of different types when a match is found. The extension described in this paper measures beliefs in:(1) the ability of specific traceability rules to generate correct traceability relations,(2) the satisfiability of traceability rules by particular types of artefacts, and (3) the correctness of individual traceability relations. It also provides a mechanism with well-founded semantics for revising these beliefs on the basis of partial (and even conflicting) assessments of the relations that these rules generate provided by different users.", "num_citations": "83\n", "authors": ["347"]}
{"title": "Overlaps in requirements engineering\n", "abstract": " Although overlap between specifications\u2014that is the incorporation of elements which designate common aspects of the system of concern\u2014is a precondition for specification inconsistency, it has only been a side concern in requirements engineering research. This paper is concerned with overlaps. It defines overlap relations in terms of specification interpretations, identifies properties of these relations which are derived from the proposed definition, shows how overlaps may affect the detection of inconsistency; shows how specifications could be rewritten to reflect overlap relations and still be amenable to consistency checking using theorem proving; analyses various methods that have been proposed for identifying overlaps with respect to the proposed definition; and outlines directions for future research.", "num_citations": "81\n", "authors": ["347"]}
{"title": "Tracing Software Requirements Artifacts.\n", "abstract": " The support for traceability between requirement specifications has been recognised as an important task in the development life-cycle of software systems. In this paper we present an approach for automatic generation and maintenance of bi-directional traceability relations between commercial and functional requirements expressed in natural language, and requirement object models. The generation of traceability relations is based on two types of traceability rules: requirements-to-object-model rules and inter-requirements rules. Our approach support three different types of traceability relations namely overlaps, realises, and requires. The requirement artefacts and traceability rules are described in XML. A prototype tool has been developed to demonstrate our approach, and has been used in a series of experiments that we have conducted to evaluate it. The results of these experiments are also presented.", "num_citations": "78\n", "authors": ["347"]}
{"title": "Comprehensive monitoring of BPEL processes\n", "abstract": " Service-oriented systems' distributed ownership has led to an increasing focus on runtime management solutions. Service-oriented systems can change greatly after deployment, hampering their quality and reliability. Their service bindings can change, and providers can modify the internals of their services. Monitoring is critical for these systems to keep track of behavior and discover whether anomalies have occurred. The Service-Centric Monitoring Language (SECMOL), a general monitoring specification language, clearly separates concerns between data collection, data computation, and data analysis, allowing for high flexibility and scalability. SECMOL also presents a concrete projection of the model onto three monitoring frameworks.", "num_citations": "77\n", "authors": ["347"]}
{"title": "Reconciling requirements: a method for managing interference, inconsistency and conflict\n", "abstract": " This paper outlines a method, called reconciliation, for managing interference between partial specifications or viewpoints. The method supports the detection, verification and tracking of ontological overlaps. The paper describes the heuristics on which the method is based and illustrates the application of the method using a scenario.", "num_citations": "66\n", "authors": ["347"]}
{"title": "Towards security monitoring patterns\n", "abstract": " Runtime monitoring is performed during system execution to detect whether the system's behaviour deviates from that described by requirements. To support this activity we have developed a monitoring framework that expresses the requirements to be monitored in event calculus-a formal temporal first order language. Following an investigation of how this framework could be used to monitor security requirements, in this paper we propose patterns for expressing three basic types of such requirements, namely confidentiality, integrity and availability. These patterns aim to ease the task of specifying confidentiality, integrity and availability requirements in monitorable forms by non-expert users. The paper illustrates the use of these patterns using examples of an industrial case study.", "num_citations": "64\n", "authors": ["347"]}
{"title": "Handbook of software engineering and knowledge engineering\n", "abstract": " This is the first handbook to cover comprehensively both software engineering and knowledge engineering OCo two important fields that have become interwoven in recent years. Over 60 international experts have contributed to the book. Each chapter has been written in such a way that a practitioner of software engineering and knowledge engineering can easily understand and obtain useful information. Each chapter covers one topic and can be read independently of other chapters, providing both a general survey of the topic and an in-depth exposition of the state of the art. Practitioners will find this handbook useful when looking for solutions to practical problems. Researchers can use it for quick access to the background, current trends and most important references regarding a certain topic. The handbook consists of two volumes. Volume One covers the basic principles and applications of software engineering and knowledge engineering. Volume Two will cover the basic principles and applications of visual and multimedia software engineering, knowledge engineering, data mining for software knowledge, and emerging topics in software engineering and knowledge engineering. Sample Chapter (s). Chapter 1.1: Introduction (97k). Chapter 1.2: Theoretical Language Research (97k). Chapter 1.3: Experimental Science (96k). Chapter 1.4: Evolutionary Versus Revolutionary (108k). Chapter 1.5: Concurrency and Parallelisms (232k). Chapter 1.6: Summary (123k). Contents: Computer Language Advances (DE Cooke et al.); Software Maintenance (G Canfora & A Cimitile); Requirements Engineering (AT Berztiss); Software Engineering\u00a0\u2026", "num_citations": "61\n", "authors": ["347"]}
{"title": "Managing interference\n", "abstract": " The construction of a complex software system involves many agents with different perspectives or views of the system they are trying to describe or model. This gives rise to many partial specifications-viewpoints. These viewpoints may \u201cinterfere\u201d with each other that is the goals of the agents may be mutually interdependent. This interference is inevitable and acceptable in system development. In this paper we examine how interference can be \u201cmanaged\u201d and the tasks that this entails. We summarise ongoing research and suggest new research directions.", "num_citations": "61\n", "authors": ["347"]}
{"title": "A framework for dynamic service discovery\n", "abstract": " Service discovery has been recognised as an important activity for service-based systems. In this paper we describe a framework for dynamic service discovery that supports the identification of service during the execution time of service-based systems. In the framework, services are identified based on structural, behavioural, quality, and contextual characteristics of a system represented in query languages. The framework supports both pull and push modes of query execution. In the approach, a service is identified based on the computation of distances between a query and a candidate service. A prototype tool has been implemented in order to illustrate and evaluate the framework. The paper also describes the results of a set of experiments that we have conducted to evaluate the work.", "num_citations": "59\n", "authors": ["347"]}
{"title": "Similarity for analogical software reuse: A computational model\n", "abstract": " This paper describes a computational model of similarity developed to support analogical software reuse. Similarity is computed from conceptual descriptions of software artifacts of any substance (ie code, design or specification artifacts). This computation is restricted by an axiomatic framework realizing properties of similarity assessments by humans and analogical reasoning and exploits the semantics of three common conceptual modeling abstractions, namely the classification, the generalization and the attribution. An operationalization of the model is presented together with a prototype implementing it. The consistency of the estimates of the operational model with respect to similarity assessments of software engineers and its recall performance are evaluated, in a preliminary experiment.", "num_citations": "55\n", "authors": ["347"]}
{"title": "A platform for context aware runtime web service discovery\n", "abstract": " In this paper we describe a platform that supports context aware runtime service discovery. The platform supports service discovery based on structural and behavioural service models as well as complex context related service discovery conditions which are specified in a newly introduced query language. During discovery, context information is obtained through a uniform scheme of calling \"context operations\" and is subsequently used in the evaluation of service discovery queries.", "num_citations": "53\n", "authors": ["347"]}
{"title": "Discovering services during service-based system design using UML\n", "abstract": " Recently, there has been a proliferation of service-based systems, i.e., software systems that are composed of autonomous services but can also use software code. In order to support the development of these systems, it is necessary to have new methods, processes, and tools. In this paper, we describe a UML-based framework to assist with the development of service-based systems. The framework adopts an iterative process in which software services that can provide functional and nonfunctional characteristics of a system being developed are discovered, and the identified services are used to reformulate the design models of the system. The framework uses a query language to represent structural, behavioral, and quality characteristics of services to be identified, and a query processor to match the queries against service registries. The matching process is based on distance measurements between the\u00a0\u2026", "num_citations": "51\n", "authors": ["347"]}
{"title": "Similarity for analogical software reuse: A conceptual modelling approach\n", "abstract": " We present our approach to defining similarity between software artifacts and discuss its potential exploitation in software reuse by analogy. We first establish properties of similarity which support its role in retrieving and mapping software descriptions. Then we develop a systematic basis for comparison within a fairly general conceptual modelling framework, whereby comparable elements of the descriptions of software objects and corresponding similarity criteria are identified. Finally, a general form of distance metrics for the computation of similarity measures is defined.", "num_citations": "47\n", "authors": ["347"]}
{"title": "Elaborating analogies from conceptual models\n", "abstract": " This article defines and analyzes a computational model of similarity which detects analogies between objects based on conceptual descriptions of them, constructed from classification, generalization relations, and attributes. Analogies are detected (elaborated) by functions which measure conceptual distances between objects with respect to these semantic modeling abstractions. The model is domain independent and operational upon objects described in nonuniform ways. It does not require any special forms of knowledge for identifying analogies and distinguishes the importance of distinct object elements. Also, it has a polynomial complexity. Due to these characteristics, it may be used in complex tasks involving intra\u2010 or interdomain analogical reasoning. So far the similarity model has been applied in the domain of software engineering. First, to support the specification of software requirements by\u00a0\u2026", "num_citations": "46\n", "authors": ["347"]}
{"title": "The serenity runtime monitoring framework\n", "abstract": " This chapter describes SERENITY\u2019s approach to runtime monitoring and the framework that has been developed to support it. Runtime monitoring is required in SERENITY in order to check for violations of security and dependability properties which are necessary for the correct operation of the security and dependability solutions that are available from the SERENITY framework. This chapter discusses how such properties are specified and monitored. The chapter focuses on the activation and execution of monitoring activities using S&D Patterns and the actions that may be undertaken following the detection of property violations. The approach is demonstrated in reference to one of the industrial case studies of the SERENITY project.", "num_citations": "45\n", "authors": ["347"]}
{"title": "Incremental certification of cloud services\n", "abstract": " Cloud is becoming fast a critical infrastructure. However, several recent incidents regarding the security of cloud services clearly demonstrate that security rightly remains one of the major concerns of enterprises and the general public regarding the use of the cloud. Despite advancements of research related to cloud security, we are still not in a position to provide a systematic assessment of cloud security based on real operational evidence. As a step towards addressing this problem, in this paper, we propose a novel approach for certifying the security of cloud services. Our approach is based on the incremental certification of security properties for different types of cloud services, including IaaS, PaaS and SaaS services, based on operational evidence from the provision of such services gathered through continuous monitoring. An initial implementation of this approach is presented.", "num_citations": "43\n", "authors": ["347"]}
{"title": "Proactive and reactive runtime service discovery: A framework and its evaluation\n", "abstract": " The identification of services during the execution of service-based applications to replace services in them that are no longer available and/or fail to satisfy certain requirements is an important issue. In this paper, we present a framework to support runtime service discovery. This framework can execute service discovery queries in pull and push mode. In pull mode, it executes queries when a need for finding a replacement service arises. In push mode, queries are subscribed to the framework to be executed proactively and, in parallel with the operation of the application, to identify adequate services that could be used if the need for replacing a service arises. Hence, the proactive (push) mode of query execution makes it more likely to avoid interruptions in the operation of service-based applications when a service in them needs to be replaced at runtime. In both modes of query execution, the identification of\u00a0\u2026", "num_citations": "43\n", "authors": ["347"]}
{"title": "Requirements monitoring for service-based systems: Towards a framework based on event calculus\n", "abstract": " This work proposes a framework for run-time monitoring of the compliance of systems composed of Web-services with requirements set for them. The framework assumes systems composed of Web-services which are coordinated by a service composition process expressed in BPEL4WS and uses event calculus to specify the requirements to be monitored. These requirements include behavioural properties of the system which are automatically extracted from the specification of its composition process in BPEL4WS and/or assumptions that system providers can specify in terms of events extracted from this specification. Requirements are checked using a variant of techniques for checking integrity constraints against temporal deductive databases.", "num_citations": "40\n", "authors": ["347"]}
{"title": "Measuring similarity between software artifacts.\n", "abstract": " This paper presents a model of estimating the similarity of software artifacts so as to promote their analogical reuse. The model permits comparisons between artifacts developed at the various stages of the software development (ie specifications, designs and code) from conceptual descriptions of these artifacts. This is achieved by using metrics measuring the distance between such descriptions with respect to general conceptual modeling abstractions (ie the classification, the generalization and the attribution) underlying them [21]. Similarity estimates are influenced by measures of salience of the involved attributes. Salience is measured as belief on three domain independent properties of attributes (ie the charactericity, the abstractness and the causality), suggested as predictive of their significance [22]. A prototype of the model is presented together with an example of using similarity to support the specification of requirements by reuse.", "num_citations": "37\n", "authors": ["347"]}
{"title": "Towards a traceability approach for product families requirements\n", "abstract": " The development of families of complex software-intensive products has become a reality. In such systems the documentation generated during the development life-cycle is of significant size and complexity, and are specified at different levels of abstraction and granularity.An example of the above situation is found in requirements documentation, in which there may be parts of the documents that specify common features of an entire product-family in broad market-terms, and parts that specify the exact functionality of the individual members of the family. Furthermore, depending on their purpose and contents, different parts of the documentation may be produced and owned by different stakeholders (eg marketing experts, developers). They may also evolve autonomously (eg certain functional requirements for an individual product in a family may change independently of the functional requirements for other members of the family). In such settings, support for inter-requirements traceability becomes very significant.", "num_citations": "36\n", "authors": ["347"]}
{"title": "Security and Dependability for Ambient Intelligence\n", "abstract": " Security and Dependability for Ambient Intelligence is the primary publication for the SERENITY approach which provides security and dependability (S&D) solutions for dynamic, highly distributed and heterogeneous systems. The term Ambient Intelligence identifies an ambitious vision for pushing technological developments, that will enable heterogeneous networked systems and devices with computing capabilities (cars, house applications, mobile phones etc.). The objective of SERENITY is to enhance the security and dependability of ambient intelligence systems by providing a framework supporting the automated integration, configuration, monitoring and adaptation of security and dependability mechanisms. Security and Dependability for Ambient Intelligence, an edited volume contributed by world leaders in this field, covers the foundations of ambient systems, the problems that their highly dynamic and heterogeneous nature poses to security and dependability and solutions. These solutions include the language that has developed for specifying S&D patterns. This volume is designed for researchers and practitioners focusing on the dynamic integration, deployment and verification of security solutions in highly distributed systems incorporating ambient intelligence features. This book is also suitable as a reference or secondary text book for advanced-level students in computer science or electrical engineering.", "num_citations": "35\n", "authors": ["347"]}
{"title": "Advanced service monitoring configurations with SLA decomposition and selection\n", "abstract": " Service Level Agreements (SLAs) for Software Services aim to clearly identify the service level commitments established between service requesters and providers. The commitments that are agreed however can be expressed in complex notations through a combination of expressions that need to evaluated and monitored efficiently. The dynamic allocation of the responsibility for monitoring SLAs (and often different parts within them) to different monitoring components is necessary as both SLAs and the components available for monitoring them may change dynamically during the operation of a service based system. In this paper we discuss an approach to supporting this dynamic configuration, and in particular, how SLAs expressed in higher-level notations can be efficiently decomposed and appropriate monitoring components dynamically allocated for each part of the agreements. The approach is illustrated\u00a0\u2026", "num_citations": "34\n", "authors": ["347"]}
{"title": "Architecture-driven service discovery for service centric systems\n", "abstract": " Service discovery has been recognized as an important aspect in the development of service-centric systems, ie, software systems which deploy Web services. To develop such systems, it is necessary to identify services that can be combined in order to fulfill the functionality and achieve quality criteria of the system being developed. In this paper, we present a framework supporting architecture-driven service discovery (ASD)\u2014that is the discovery of services that can provide functionalities and satisfy properties and constraints of systems as specified during the design phase of the development lifecycle based on detailed system design models. Our framework assumes an iterative design process and allows for the (re-) formulation of design models of service-centric systems based on the discovered services. The framework is composed of a query extractor, which derives queries from behavioral and structural UML\u00a0\u2026", "num_citations": "34\n", "authors": ["347"]}
{"title": "Revising Rules to Capture Requirements Traceability Relations: A Machine Learning Approach.\n", "abstract": " In this paper we present a machine learning approach for generating requirements traceability relations. This approach is based on a new learning algorithm that produces traceability rules which are able to capture traceability relations between requirement statements specified in natural language and object models. The creation of these traceability rules is informed by examples of traceability relations which are provided by the user and is based on a generalisation of other existing traceability rules.", "num_citations": "34\n", "authors": ["347"]}
{"title": "The Interoperability of Things: Interoperable solutions as an enabler for IoT and Web 3.0\n", "abstract": " This paper presents an overview of the interoperability concepts along with the challenges for the IoT domain and the upcoming Web 3.0. We identify four levels of interoperability and the relevant solutions for accomplishing vertical and horizontal compatibility between the various layers of a modern IoT ecosystem, referred to as: technological, syntactic, semantic, and organizational interoperability. The goal is to achieve cross-domain interaction and facilitate the proper usage and management of the provided IoT services and applications. An interoperability framework is also proposed where the involved system components can cooperate and offer the seamless operation from the device to the backend framework. This by-design end-to-end interoperation enables the interplay of several complex service composition settings and the management of the system via patterns. The overall proposal is adopted by the\u00a0\u2026", "num_citations": "31\n", "authors": ["347"]}
{"title": "A lightweight framework for secure life-logging in smart environments\n", "abstract": " As the world becomes an interconnected network where objects and humans interact with each other, new challenges and threats appear in the ecosystem. In this interconnected world, smart objects have an important role in giving users the chance for life-logging in smart environments. However, smart devices have several limitations with regards to memory, resources and computation power, hindering the opportunity to apply well-established security algorithms and techniques for secure life-logging on the Internet of Things (IoT) domain. The need for secure and trustworthy life-logging in smart environments is vital, thus, a lightweight approach has to be considered to overcome the constraints of Smart Objects. The purpose of this paper is to present in details the current topics of life-logging in smart environments, while describing interconnection issues, security threats and suggesting a lightweight framework for\u00a0\u2026", "num_citations": "31\n", "authors": ["347"]}
{"title": "Certifying services in cloud: The case for a hybrid, incremental and multi-layer approach\n", "abstract": " The use of clouds raises significant security concerns for the services they provide. Addressing these concerns requires novel models of cloud service certification based on multiple forms of evidence including testing and monitoring data, and trusted computing proofs. CUMULUS is a novel infrastructure for realising such certification models.", "num_citations": "31\n", "authors": ["347"]}
{"title": "Web service trust: Towards a dynamic assessment framework\n", "abstract": " Trust in software services is a key prerequisite for the success and wide adoption of services-oriented computing (SOC) in an open Internet world. However, trust is poorly assessed by existing methods and technologies, especially in dynamically composed and deployed SOC systems. In this paper, we discuss current methods for assessing trust in service-oriented computing and identify gaps of current platforms, in particular with regards to runtime trust assessment. To address these gaps, we propose a model of runtime trust assessment of software services and introduce a framework for realizing the model. A key characteristic of our approach is the support that it offers for customizable assessment of trust based on evidence collected during the operation of software services and its ability to combine this evidence with subjective assessments coming from service clients.", "num_citations": "30\n", "authors": ["347"]}
{"title": "Proactive runtime service discovery\n", "abstract": " In this paper we describe a framework that supports runtime service discovery in both pull and push modes. Our framework supports service discovery based on structural and behavioural models of services and applications, as well as quality and contextual constraints. In the approach, we use a proactive push mechanism in which services are identified in parallel to the execution of the system based on subscriptions of services and queries. A prototype tool has been implemented in order to illustrate and evaluate the framework.", "num_citations": "30\n", "authors": ["347"]}
{"title": "Property specification and static verification of UML models\n", "abstract": " We present a static verification tool (SVT), a system that performs static verification on UML models composed of UML class and state machine diagrams. Additionally, the SVT allows the user to add extra behavior specification in the form of guards and effects by defining a small action language. UML models are checked against properties written in a special-purpose property language that allows the user to specify linear temporal logic formulas that explicitly reason about UML components. Thus, the SVT provides a strong foundation for the design of reliable systems and a step towards model-driven security.", "num_citations": "29\n", "authors": ["347"]}
{"title": "Integrating specifications: A similarity reasoning approach\n", "abstract": " Requirements analysis usually results in a set of different specifications for the same system, which must be integrated. Integration involves the detection and elimination of discrepancies between them. Discrepancies may be due to differences in representation models, modeling perspectives or practices. As instances of the semantic heterogeneity problem (Gangopadhyay and Barsalou, 1991), discrepancies are broader than logical inconsistencies, and therefore not always detectable using theorem proving. This paper proposes an approach to their detection using meta-modeling and similarity analysis. Specification components are classified under a meta-model of domain independent semantic modeling abstractions and thereby compared according to a newly developed model of similarity. Similarity analysis results in an isomorphic mapping between them, which can be used as a basis for reconciling\u00a0\u2026", "num_citations": "28\n", "authors": ["347"]}
{"title": "Proactive sla negotiation for service based systems\n", "abstract": " In this paper we propose a framework for proactive SLA negotiation that integrates this process with dynamic service discovery and, hence, can provide integrated runtime support for both these key activities which are necessary in order to achieve the runtime operation of service based systems with minimised interruptions. More specifically, our framework discovers candidate constituent services for a composite service, establishes an agreed but not enforced SLA and a period during which this pre-agreement can be activated should this become necessary.", "num_citations": "26\n", "authors": ["347"]}
{"title": "Dynamic set-up of monitoring infrastructures for service based systems\n", "abstract": " Service based systems are intrinsically dynamic as the services deployed by them can be replaced at runtime. When this happens, the Service Level Agreements (SLAs) that regulate the provision of services may also need to change. Following such changes, the monitoring infrastructure that is used to monitor SLAs may also need to be modified to ensure the continuous provision of the necessary runtime checks. This paper presents a framework that supports the dynamic assessment of the monitorability of SLAs terms and the dynamic setup of an appropriate infrastructure for monitoring them following such changes. The monitorability checks are based on comparisons between the SLA terms for specific services and descriptions of the monitoring capabilities of these services which are expressed in languages introduced in the paper. The paper presents a prototype implementation of the framework and the\u00a0\u2026", "num_citations": "26\n", "authors": ["347"]}
{"title": "A UML-based static verification framework for security\n", "abstract": " Secure software engineering is a new research area that has been proposed to address security issues during the development of software systems. This new area of research advocates that security characteristics should be considered from the early stages of the software development life cycle and should not be added as another layer in the system on an ad-hoc basis after the system is built. In this paper, we describe a UML-based Static Verification Framework (USVF) to support the design and verification of secure software systems in early stages of the software development life-cycle taking into consideration security and general requirements of the software system. USVF performs static verification on UML models consisting of UML class and state machine diagrams extended by an action language. We present an operational semantics of UML models, define a property specification language\u00a0\u2026", "num_citations": "26\n", "authors": ["347"]}
{"title": "Usefulness of (1, 3) \u00df-D-glucan detection in bronchoalveolar lavage samples in Pneumocystis pneumonia and Pneumocystis pulmonary colonization\n", "abstract": " Objective of the study Recent data demonstrate the usefulness of (1, 3) \u00df-d-glucan (BG) detection in serum samples to distinguish patients developing Pneumocystis pneumonia and patients who are colonized by the fungus. In contrast, data of BG detection in bronchoalveolar lavage (BAL) samples from these patient populations are still rare. Patients In this context, we determined BG levels in BAL samples from 11 Pneumocystis pneumonia (PCP) patients, 10 colonized patients, and 24 Pneumocystis-uninfected patients. Materials and methods BG levels were determined on each BAL sample using the Fungitell\u00ae kit (Associates of Cape Cod, Inc., Cape Cod, MA, USA) according to the manufacturer's instructions applied to serum sample examination. Results The BG levels in BAL samples from the PCP patient group (mean value 20 588 pg/mL) were significantly higher than those in the colonized patient group\u00a0\u2026", "num_citations": "23\n", "authors": ["347"]}
{"title": "Towards hybrid cloud service certification models\n", "abstract": " In this paper, we introduce a hybrid approach for certifying security properties of cloud services that combines monitoring and testing data. The paper argues about the need for hybrid certification and examines some basic characteristics of hybrid certification models.", "num_citations": "23\n", "authors": ["347"]}
{"title": "Proactive sla negotiation for service based systems: Initial implementation and evaluation experience\n", "abstract": " This paper describes a framework that we have developed to integrate proactive SLA negotiation with dynamic service discovery to provide cohesive runtime support for both these activities. The proactive negotiation of SLAs as part of service discovery is necessary for reducing the extent of interruptions during the operation of a service based system when the need for replacing services in it arises. The developed framework discovers alternative candidate constituent services for a service client application, and negotiates/agrees but does not activate SLAs with these services until the need for using a service becomes necessary. A prototype tool has been implemented to realize the framework. This prototype is discussed in the paper along with the results of the initial evaluation of the framework.", "num_citations": "23\n", "authors": ["347"]}
{"title": "Guest editors' introduction: Special section on intelligent data preparation\n", "abstract": " DATA preparation (or data preprocessing) is the first step of data processing applications, including machine learning, data mining, data warehousing, information retrieval, and pattern recognition. Industrial practice indicates that more than 80 percent of the data mining work concentrates on data preparation. Indeed, once the data is well prepared, the mined results are more accurate and reliable. This means that data preparation is also a critical step for other data processing applications. Among others, data preparation mainly involves data cleaning, data transformation, and data selection [1]. The principal aim of data preparation is to provide quality data for other steps of data processing applications, which are often accomplished in tandem with data mining and knowledge discovery. Indeed, the boundary can sometimes be blurry, but the general principle of data preparation can still be singled out from other data processing techniques. However, there has been relatively little focused work done for data preparation.Recognizing the unique importance of data preparation, we have organized a series of workshops and special issues in top-quality journals to facilitate the development of data preparation techniques. Our first activity was the organization of the First International Workshop on Data Cleaning and Preprocessing, in conjunction with the IEEE International Conference on Data Mining (ICDM) in 2002, which was known as the DCAP workshop (ie, data cleaning and preparation). High-quality papers from the workshop was also selected and published in a special issue on data preparation for data mining in the Applied Artificial\u00a0\u2026", "num_citations": "23\n", "authors": ["347"]}
{"title": "EVEREST+ run-time SLA violations prediction\n", "abstract": " Monitoring the preservation of QoS properties during the operation of service-based systems at run-time is an important verification measure for checking if the current service usage is compliant with agreed SLAs. Monitoring, however, does not always provide sufficient scope for taking control actions against violations as it only detects violations after they occur.", "num_citations": "22\n", "authors": ["347"]}
{"title": "UML: An evaluation of the visual syntax of the language\n", "abstract": " Examination of the UML indicates weaknesses in its graphic syntax which undermine its structure as a visual language. Although the UML Notation claims to provide a \"canonical notation\", there are insufficient rules governing the graphic constructs used to produce the essential 'signifiers' of this visual language and to define their permissible combinations. The nature and composition of the graphical elements actually shown is a fundamental consideration, separate from the underlying constructs that they may signify. A much earlier formulation for notational systems, that provided by Nelson Goodman, clarifies the issues involved and makes it possible to set basic tests for a notational scheme, such as the UML, which require syntactic disjointness and differentiability. Application of these tests (plus others) to graphical primitives, simple characters and diagrams shows a variety of failures that lead to a fundamental\u00a0\u2026", "num_citations": "22\n", "authors": ["347"]}
{"title": "Analogical reuse of requirements specifications: A computational model\n", "abstract": " Specifications of requirements for new software systems can be revised, refined, or completed in reference to specifications of requirements for existing similar systems. Although realized as a form of analogical problem solving, specification by reuse is not adequately supported by available computational models for detecting analogies. This is chiefly due to the following reasons: (1) It is assumed that specifications are expressed according to the same specification model and in a uniform representation scheme. (2) Additional information is needed for the detection of analogies, which is not contained in the specifications. (3) Performance scales poorly with the complexity of specifications. This article presents a computational model for detecting analogies, which addresses these issues to a certain extent. The application of the model in the specification of requirements by analogical reuse is demonstrated through\u00a0\u2026", "num_citations": "22\n", "authors": ["347"]}
{"title": "UML-based service discovery framework\n", "abstract": " The development of service centric systems, i.e software systems constructed as compositions of autonomous services, has been recognised as an important approach for software system development. Recently, there has been a proliferation of systems which are developed, deployed, and consumed in this way. An important aspect of service centric systems is the identification of web services that can be combined to fulfill the functionality and quality criteria of the system being developed. In this paper we present the results of the evaluation of a UML-based framework for service discovery. This framework supports the identification of services that can provide the functionality and satisfy properties and constraints of service centric systems as specified during their design. Our approach adopts an iterative design process allowing for the (re-) formulation of the design models of service centric systems based\u00a0\u2026", "num_citations": "21\n", "authors": ["347"]}
{"title": "Extensions to pattern formats for cyber physical systems\n", "abstract": " Cyber Physical Systems (CPSs) are becoming not only increasingly complex but also increasingly important. Traditionally, CPSs were self-contained monolithic systems operating in a well-defined environment. CPSs today have evolved to large-scale systems including multiple interacting components. Due to the inherent complexity of the physical environments where CPSs operate and the ever changing operational and context conditions of these environments, CPSs need to be able to adapt in a semi-or fully autonomic manner. At the same time, in the course of adapting themselves, they need to satisfy key quality, security and privacy (QSP) requirements and be resilient to threats even if those were unknown at the time the CPS was designed. Engineering CPSs with such capabilities is a challenging problem that requires expert knowledge. Our approach to addressing this problem is based on the use of QSP-preserving patterns, ie, patterns that encode proven design and engineering solutions providing particular QSP properties. We argue that existing pattern formats miss some essential features of CPSs. As a step towards the realization of approach, in this paper we present a new pattern format that enables the representation of most important characteristics of QSP preserving patterns for CPS. Our format provides an initial basis for defining a full pattern language for engineering QSP preserving CPS.", "num_citations": "20\n", "authors": ["347"]}
{"title": "D2. 1: Security-aware SLA specification language and cloud security dependency model\n", "abstract": " In terms of cloud security, service level agreements and certificates share some strong similarities at their core: they both represent a form of assurance given to a customer about the security level provided by a service. Service level agreements represent the contractual commitments made by cloud providers to their customers, while certificates represent an assertion that has been verified to be true by a trusted authority. In this deliverable we mainly examine this core similarity between SLAs and certificates, in order to set the foundation for some of the work that will be done in the CUMULUS project, notably with the specification of a security property vocabulary.The implementation a certification process is a more complex process than creation of SLAs. Nevertheless, gaps in current SLAs specifications approaches and languages can inform us on issues that are likely to exist in the type of automated certification tools CUMULUS aims to provide. In section 1, we therefore start by highlight a key issue in current SLAs: the lack of standardized definition and measurement of security properties. For example, we show how competing cloud offerings can claim to offer similar \u201cuptime\u201d claims, which represent diverging performances in practice, simply by using a different definition for \u201cuptime\u201d. Our conclusion is that security properties in SLAs or certificates cannot simply be described by a", "num_citations": "20\n", "authors": ["347"]}
{"title": "Mining balance disorders' data for the development of diagnostic decision support systems\n", "abstract": " In this work we present the methodology for the development of the EMBalance diagnostic Decision Support System (DSS) for balance disorders. Medical data from patients with balance disorders have been analysed using data mining techniques for the development of the diagnostic DSS. The proposed methodology uses various data, ranging from demographic characteristics to clinical examination, auditory and vestibular tests, in order to provide an accurate diagnosis. The system aims to provide decision support for general practitioners (GPs) and experts in the diagnosis of balance disorders as well as to provide recommendations for the appropriate information and data to be requested at each step of the diagnostic process. Detailed results are provided for the diagnosis of 12 balance disorders, both for GPs and experts. Overall, the reported accuracy ranges from 59.3 to 89.8% for GPs and from 74.3 to 92.1\u00a0\u2026", "num_citations": "19\n", "authors": ["347"]}
{"title": "A framework for architecture-driven service discovery\n", "abstract": " Service discovery has been recognised as an important aspect in the development of service centric systems, ie software systems that are constructed based on the composition of web services. In order to develop service centric systems it is necessary to identify web services that can be combined to fulfil the functionality and quality criteria of the system being developed. In this paper we present a framework to support architecture-driven service discovery-that is the discovery of services that can provide the functionalities and satisfy properties and constraints of systems as specified during the design phase of the development lifecycle. Our framework assumes an iterative design process and allows for the (re-) formulation of the design models of service-centric systems based on the discovered services. A prototype tool has been developed and includes two main components: a UML 2.0 integration module, which\u00a0\u2026", "num_citations": "19\n", "authors": ["347"]}
{"title": "Continuous certification of non-repudiation in cloud storage services\n", "abstract": " This paper presents a certification model for Non-repudiation (NR) of cloud storage services. NR, i.e., The possession of proofs that certain exchanges have taken place amongst interacting parties, is a significant security property for cloud data storage services. Our model for certifying NR is based on continuous monitoring and has been defined and realised according to the CUMULUS approach. It also corresponds to certification of level 3 maturity in the reference certification framework of Cloud Security Alliance.", "num_citations": "18\n", "authors": ["347"]}
{"title": "A semi-automatic process of identifying overlaps and inconsistencies between requirements specifications\n", "abstract": " Reconciliation is a method which supports the detection and verification of overlaps and the resolution of certain forms of inconsistencies between requirements specifications expressed in an object-oriented framework. The method identifies a set of candidate overlaps between two specifications by analysing their similarity. These overlaps are assessed by the authors of the specifications. If the authors disagree with the overlaps identified by analysis, the method guides them through an exploration activity aimed at (1) identifying inconsistencies in the modelling of the specifications with respect to the overlaps indicated by them, and (2) resolving these inconsistencies in a way which ensures that the results of further analysis will converge with overlaps indicated by the authors. This paper provides an overview of the method focusing on the process of identifying and resolving inconsistencies between\u00a0\u2026", "num_citations": "18\n", "authors": ["347"]}
{"title": "Patterns for the design of secure and dependable software defined networks\n", "abstract": " In an interconnected world, cyber and physical networks face a number of challenges that need to be resolved. These challenges are mainly due to the nature and complexity of interconnected systems and networks and their ability to support heterogeneous physical and cyber components simultaneously. The construction of complex networks preserving Security and Dependability (S&D) properties is necessary to avoid system vulnerabilities, which may occur in all the different layers of Software Defined Networking (SDN) architectures. In this paper, we present a model based approach to support the design of secure and dependable SDN. This approach is based on executable patterns for designing networks able to guarantee S&D properties and can be used in SDN networks. The design patterns express conditions that can guarantee specific S&D properties and can be used to design networks that have these\u00a0\u2026", "num_citations": "17\n", "authors": ["347"]}
{"title": "Discovering secure service compositions\n", "abstract": " Security is an important concern for service based systems, i.e., systems that are composed of autonomous and distributed software services. This is because the overall security of such systems depends on the security of the individual services they deploy and, hence, it is difficult to assess especially in cases where the latter services must be discovered and composed dynamically. This paper presents a novel approach for discovering secure compositions of software services. This approach is based on secure service orchestration patterns, which have been proven to provide certain security properties and can, therefore, be used to generate service compositions that are guaranteed to satisfy these properties by construction. The paper lays the foundations of the secure service orchestration patterns, and presents an algorithm that uses the patterns to generate secure service compositions and a tool realising our entire approach.", "num_citations": "17\n", "authors": ["347"]}
{"title": "Towards a model-driven platform for evidence based public health policy making\n", "abstract": " The effective management of various health conditions depends on and requires appropriate public health policies (PHP). Such policies are important for several aspects of healthcare provision, including:(a) screening for prevention of disease;(b) early diagnosis and treatment;(c) long-term management of chronic diseases and disabilities; and (d) setting-up standards. Although it is widely recognised that the PHP life cycle (ie, the analysis, action plan design, execution, monitoring and evaluation of public health policies) should be evidenced based, current support for it is mainly in the form of guidelines, and is not supported by data analytics and decision making tools tailored to it. In this paper, we present a novel model driven approach to PHP life cycle management and an integrated platform for realising this life cycle. Our approach is based on PHP decision making models. Such models steer the PHP decision making process by defining the data that need to be collected and the ways in which these data should be analysed in order to produce the evidence required for PHP making. Our work is part of a new research programme on public health policy making for the management of hearing loss, called EVOTION, that is funded by the European Union.", "num_citations": "16\n", "authors": ["347"]}
{"title": "Translation of SLAs into monitoring specifications\n", "abstract": " The general architecture of the SLA@SOI framework supports the integration of different types of generic or special-purpose monitoring engines. While internally these engines may realise different monitoring approaches (or reasoning mechanisms), externally they support the same common interface. This interface enables the reasoning engines to receive the SLA guarantee terms that need to be monitored and to report monitoring results to the SLA@SOI framework. However, due to differences in the languages that the monitoring engines use to express operational monitoring specifications, the monitoring of SLAs expressed in the SLA specification language of SLA@SOI requires the translation of these SLAs into operational monitoring specifications. This chapter describes the translation scheme developed for the monitoring engine EVEREST, which has been used in the SLA@SOI framework for\u00a0\u2026", "num_citations": "16\n", "authors": ["347"]}
{"title": "ASSERT4SOA: Toward security certification of service-oriented applications\n", "abstract": " ASSERT4SOA project proposes machine readable certificates to be used to allow Web service requesters to automatically assess the security properties of Web services (and their providers) as certified by a trusted third party. This vision promises to open up an entire new market for certification services.", "num_citations": "16\n", "authors": ["347"]}
{"title": "Dynamic trust assessment of software services\n", "abstract": " Trust assessment is a key prerequisite for the adoption of software services but poorly supported by existing methods and technology especially when it comes to trust in dynamically composed and deployed software services. In this position paper, we discuss why this is the case and outline a programme of research focusing on the development of platform for dynamic trust assessment of software services.", "num_citations": "16\n", "authors": ["347"]}
{"title": "Reactive security for SDN/NFV\u2010enabled industrial networks leveraging service function chaining\n", "abstract": " The innovative application of fifth\u2010generation core technologies, ie, software\u2010defined networking (SDN) and network function virtualization, can help reduce capital and operational expenditures in industrial networks. Nevertheless, SDN expands the attack surface of the communication infrastructure, thus necessitating the introduction of additional security mechanisms. These major changes could not leave the industrial environment unaffected, with smart industrial deployments gradually becoming a reality, a trend that is often referred to as the Fourth Industrial Revolution or Industry 4.0. A wind park is a good example of an industrial application relying on a network with strict performance, security, and reliability requirements and was chosen as a representative example of industrial systems. This work highlights the benefit of leveraging the flexibility of SDN/network function virtualization\u2013enabled networks to\u00a0\u2026", "num_citations": "15\n", "authors": ["347"]}
{"title": "Public health policy for management of hearing impairments based on big data analytics: EVOTION at Genesis\n", "abstract": " The holistic management of hearing loss (HL) requires appropriate public health policies for HL prevention, early diagnosis, long-term treatment and rehabilitation; detection and prevention of cognitive decline; protection from noise; and socioeconomic inclusion of HL patients. However, currently the evidential basis for forming such policies is limited. Holistic HL management policies require the analysis of heterogeneous data, including Hearing Aid (HA) usage, noise episodes, audiological, physiological, cognitive, clinical and medication, personal, behavioural, life style, occupational and environmental data. To utilise these data in forming holistic HL management policies, EVOTION, a new European research and innovation project, aims to develop an integrated platform supporting: (a) the analysis of related datasets to enable the identification of causal and other effects amongst them using various forms of big\u00a0\u2026", "num_citations": "15\n", "authors": ["347"]}
{"title": "Constructing secure service compositions with patterns\n", "abstract": " In service based applications, it is often necessary to construct compositions of services in order to provide required functionality in cases where this is not possible through the use of a single service. Whilst creating service compositions, it is necessary to ensure not only that the functionality required of the composition is achieved but also that certain security properties are preserved. In this paper, we describe an approach to constructing secure service compositions. Our approach is based on the use of composition patterns and rules that determine the security properties that should be preserved by the individual services that constitute a composition in order to ensure that security properties of the overall composition are also satisfied. Our approach extends a framework developed to support the runtime service discovery.", "num_citations": "15\n", "authors": ["347"]}
{"title": "A monitoring approach for runtime service discovery\n", "abstract": " Effective runtime service discovery requires identification of services based on different service characteristics such as structural, behavioural, quality, and contextual characteristics. However, current service registries guarantee services described in terms of structural and sometimes quality characteristics and, therefore, it is not always possible to assume that services in them will have all the characteristics required for effective service discovery. In this paper, we describe a monitor-based runtime service discovery framework called MoRSeD. The framework supports service discovery in both push and pull modes of query execution. The push mode of query execution is performed in parallel to the execution of a service-based system, in a proactive way. Both types of queries are specified in a query language called SerDiQueL that allows the representation of structural, behavioral, quality, and contextual\u00a0\u2026", "num_citations": "14\n", "authors": ["347"]}
{"title": "Biosensors and Internet of Things in smart healthcare applications: challenges and opportunities\n", "abstract": " The use of health and well-being monitoring technologies has been steadily increasing and such systems can now be found in smart homes, age-friendly workplaces, public spaces, and elsewhere. These monitoring technologies employ a wide variety of off-the-shelf smart sensors and medical devices to support functional, physiological, and behavioral monitoring and to address social interaction aspects of daily life. These systems focus either on specific health-related conditions or on supporting the more general aims of comfort, well-being, and quality of life. However, there remain several technological (interoperability, expandability, etc.) and societal (cost, privacy, etc.) challenges to be addressed before smart biosensor systems are widely adopted.Motivated by the above, this chapter highlights the challenges and opportunities surrounding the application of smart biosensors in healthcare and presents three\u00a0\u2026", "num_citations": "13\n", "authors": ["347"]}
{"title": "Model-driven cyber range training: a cyber security assurance perspective\n", "abstract": " Security demands are increasing for all types of organisations, due to the ever-closer integration of computing infrastructures and smart devices into all aspects of the organisational operations. Consequently, the need for security-aware employees in every role of an organisation increases in accordance. Cyber Range training emerges as a promising solution, allowing employees to train in both realistic environments and scenarios and gaining hands-on experience in security aspects of varied complexity, depending on their role and level of expertise. To that end, this work introduces a model-driven approach for Cyber Range training that facilitates the generation of tailor-made training scenarios based on a comprehensive model-based description of the organisation and its security posture. Additionally, our approach facilitates the automated deployment of such training environments, tailored to each defined\u00a0\u2026", "num_citations": "13\n", "authors": ["347"]}
{"title": "Pattern-Based Design and Verification of Secure Service Compositions\n", "abstract": " Ensuring the preservation of security is a key requirement and challenge for Service-Based Systems (SBS) due to the use of third party software services not operating under different security perimeters. In this paper, we present an approach for verifying the security properties of SBS workflows and adapting them if such properties are not preserved. Our approach uses secure service composition patterns. These patterns encode proven dependencies between service level and workflow level security properties. These dependencies are used in reasoning processes supporting the verification of SBS workflows with respect to workflow security properties and their adaptation in ways that guarantee the properties if necessary. Our approach has been implemented by extending the Eclipse BPEL Designer and validated experimentally. The experimental evaluation has produced positive results, indicating that even for\u00a0\u2026", "num_citations": "13\n", "authors": ["347"]}
{"title": "Threat landscape and good practice guide for software defined networks/5g\n", "abstract": " 5G represents the next major phase of mobile telecommunication systems and network architectures beyond the current 4G standards, aiming at extreme broadband and ultra-robust, low latency connectivity, to enable the programmable connectivity for the Internet of Everything2. Despite the significant debate on the technical specifications and the technological maturity of 5G, which are under discussion in various fora3, 5G is expected to affect positively and significantly several industry sectors ranging from ICT to industry sectors such as car and other manufacturing, health and agriculture in the period up to and beyond 2020. 5G will be driven by the influence of software on network functions, known as Software Defined Networking (SDN) and Network Function Virtualization (NFV). The key concept that underpins SDN is the logical centralization of network control functions by decoupling the control and packet forwarding functionality of the network. NFV complements this vision through the virtualization of these functionalities based on recent advances in general server and enterprise IT virtualization. Considering the technological maturity of the technologies that 5G can leverage on, SDN is the one that is moving faster from development to production. To realize the business potential of SDN/5G, a number of technical issues related to the design and operation of Software Defined Networks need to be addressed. Amongst them, SDN/5G security is one of the key issues, that needs to be addressed comprehensively in order to avoid missing the business opportunities arising from SDN/5G. In this report, we review threats and potential\u00a0\u2026", "num_citations": "13\n", "authors": ["347"]}
{"title": "Diagnosing Runtime Violations of Security & Dependability Properties.\n", "abstract": " Monitoring the preservation of security and dependability (S&D) properties of complex software systems is widely accepted as a necessity. Basic monitoring can detect violations but does not always provide sufficient information for deciding what the appropriate response to a violation is. Such decisions often require additional diagnostic information that explains why a violation has occurred and can, therefore, indicate what would be an appropriate response action to it. In this paper, we describe a diagnostic procedure for generating explanations of violations of S&D properties developed as part of a runtime monitoring toolkit, called EVEREST. The procedure is based on a combination of abductive and evidential reasoning about violations of S&D properties which are expressed in Event Calculus.", "num_citations": "13\n", "authors": ["347"]}
{"title": "Supporting the reconciliation of models of object behaviour\n", "abstract": " This paper presents Reconciliation+, a method which identifies overlaps between models of software systems behaviour expressed as UML object interaction diagrams (i.e., sequence and/or collaboration diagrams), checks whether the overlapping elements of these models satisfy specific consistency rules and, in cases where they violate these rules, guides software designers in handling the detected inconsistencies. The method detects overlaps between object interaction diagrams by using a probabilistic message matching algorithm that has been developed for this purpose. The guidance to software designers on when to check for inconsistencies and how to deal with them is delivered by enacting a built-in process model that specifies the consistency rules that can be checked against overlapping models and different ways of handling violations of these rules. Reconciliation+ is supported by a toolkit\u00a0\u2026", "num_citations": "13\n", "authors": ["347"]}
{"title": "Architectural patterns for secure IoT orchestrations\n", "abstract": " The vast amount of connected devices on the Internet of Things (IoT) creates an enormous potential for new applications, by leveraging synergies arising through the convergence of consumer, business and industrial Internet, and creating open, global networks connecting people, data, and \u201cthings\u201d. In this context, the SEMIoTICS project aims to develop a pattern-driven framework, built upon existing IoT platforms, to enable and guarantee secure and dependable actuation and semi-autonomic behaviour in IoT/Industrial IoT applications. To achieve this, patterns are used to encode proven dependencies between the security, privacy, dependability and interoperability (SPDI) properties of individual smart objects and corresponding properties of orchestrations (composition) involving them. This paper sketches this approach followed by SEMIoTICS, whereby the SPDI patterns are used to generate IoT orchestrations\u00a0\u2026", "num_citations": "12\n", "authors": ["347"]}
{"title": "Fault tolerance using an sdn pattern framework\n", "abstract": " Software Defined Networking (SDN) and Network Function Virtualization (NFV) are a promising combination for programmable connectivity, rapid service provisioning and service chaining, as they offer the necessary end-to-end optimizations. However, with the actual exponential growth of connected devices, future networks such as SDN/NFV require an \"open-solutions\" architecture, facilitated by standards and a strong ecosystem. Such networks need to support communication services that offer guarantees about fault tolerance, redundancy, resilience and security. The construction of complex networks preserving Security and Dependability (S&D) properties is necessary to avoid system vulnerabilities, which may occur in the various layers of SDN architectures. In this work, we propose a pattern framework built in an SDN controller able to import design patterns in a rule-based language and provide fault\u00a0\u2026", "num_citations": "12\n", "authors": ["347"]}
{"title": "Monitoring-based certification of cloud service security\n", "abstract": " In this paper, we present a novel approach to cloud service security certification. This approach could be used to: (a) define and execute automatically certification models, which can continuously and incrementally acquire and analyse evidence regarding the provision of services on cloud infrastructures through continuous monitoring; (b) use this evidence to assess whether the provision is compliant with required security properties; and (c) generate and manage digital certificates confirming the compliance of services if the acquired evidence supports this. We also present the results of an initial experimental evaluation of our approach based on the MySQL server and RUBiS benchmark.", "num_citations": "12\n", "authors": ["347"]}
{"title": "Designing secure service workflows in BPEL\n", "abstract": " This paper presents an approach that we have developed to support the design of secure service based applications in BPEL. The approach is based on the use of secure service composition patterns, which are proven to preserve composition level security properties if the services that are composed according to the pattern satisfy other properties individually. The secure service composition patterns are used for two purposes: (a) to analyse whether a given workflow fragment satisfies a given security property, and (b) to generate compositions of services that could substitute for individual services within the workflow that cause the violation of the security properties. Our approach has been implemented in a tool that is based on Eclipse BPEL Designer.", "num_citations": "12\n", "authors": ["347"]}
{"title": "A privacy-level model of user-centric cyber-physical systems\n", "abstract": " In an interconnected cyber-world, Cyber-Physical Systems (CPSs) appear to play an increasingly important role in smart ecosystems. A variety of resource-constrained thin clients, such as sensors, RFIDs, actuators and smart devices, are included in the list of CPS. These devices can be used in a number of medical, vehicular, aviation, military and smart cities applications. A plethora of sensitive data is transmitted in insecure wireless or wired environments whilst adversaries are eager to eavesdrop, modify or destroy sensed data invading the privacy of user-centric CPSs. This work presents an overview and analysis of the most effective attacks, privacy challenges and mitigation techniques for preserving the privacy of users and their interconnected devices. In order to preserve privacy, a privacy-level model is proposed in which users have the capability of assigning different privacy levels based on the\u00a0\u2026", "num_citations": "12\n", "authors": ["347"]}
{"title": "Formal certification and compliance for run-time service environments\n", "abstract": " With the increased awareness of security and safety of services in on-demand distributed service provisioning (such as the recent adoption of Cloud infrastructures), certification and compliance checking of services is becoming a key element for service engineering. Existing certification techniques tend to support mainly design-time checking of service properties and tend not to support the run-time monitoring and progressive certification in the service execution environment. In this paper we discuss an approach which provides both design-time and runtime behavioural compliance checking for a services architecture, through enabling a progressive event-driven model-checking technique. Providing an integrated approach to certification and compliance is a challenge however using analysis and monitoring techniques we present such an approach for on-going compliance checking.", "num_citations": "12\n", "authors": ["347"]}
{"title": "An architecture for certification-aware service discovery\n", "abstract": " Service-orientation is an emerging paradigm for building complex systems based on loosely coupled components, deployed and consumed over the network. Despite the original intent of the paradigm, its current instantiations are limited to a single trust domain (e.g., a single organization) One of the main reasons for this is the trust gap that normally arises when software services, offered by previously unknown providers, are to be selected at run-time, without any human intervention. The idea of machine-readable security certificates (called asserts) paves the way to automated reasoning about security properties of services. Similarly to current security certification schemes, the assessment of the security properties of a service is delegated to an independent third party (certification authority), who issues a corresponding assert, bound to the service. Building on the assert concept, this paper describes our proposal\u00a0\u2026", "num_citations": "12\n", "authors": ["347"]}
{"title": "SMaRT: a workbench for reporting the monitorability of services from SLAs\n", "abstract": " Service Level Agreements (SLAs) for Software Services aim to clearly identify the service level commitments established between service requesters and providers. A dynamic configuration for the monitoring of these SLAs provides the opportunity for service monitor providers to offer and release monitoring infrastructures for different types of services. Whilst there has been work on automating this monitor matching and configuration, additional support may be needed in the negotiation and provision of monitors for which the current monitoring infrastructure does not provide suitable SLA term monitors. In this paper we describe an approach to effectively report and assist service monitoring support groups in managing this provision. The approach described is illustrated with mechanical support in the form of a SMaRT Workbench Eclipse IDE plug-in for reporting on the monitorability of SLAs for service monitoring\u00a0\u2026", "num_citations": "12\n", "authors": ["347"]}
{"title": "Advanced security service certificate for soa: Certified services go digital\n", "abstract": " Service-oriented architectures (SOA) constitute a major architectural style for large-scale infrastructures and applications built from loosely-coupled services and subject to dynamic configuration, operation and evolution. They are the structuring principle of a multitude of applications and the enabling technology for recent software paradigms like Mashup or SaaS.             Assessing the trustworthiness of such complex and continuously evolving systems is a challenging task since a) methodologies \u2013 mainly based on certification processes \u2013 developed for assessing conventional static systems can hardly handle the dynamicity and variety of SOA based systems, b) few artifacts can be used to support and automate the assessment of the trustworthiness of a stand-alone service, and no means exist to assess the trustworthiness of composite applications, c) there is no mechanism to express and confront claimed\u00a0\u2026", "num_citations": "12\n", "authors": ["347"]}
{"title": "From monitoring templates to security monitoring and threat detection\n", "abstract": " This paper presents our pattern-based approach to run-time requirements monitoring and threat detection being developed as part of an approach to build frameworks supporting the construction of secure and dependable systems for ambient intelligence. Our patterns infra-structure is based on templates. From templates we generate event-calculus formulas expressing security requirements to monitor at run-time. From these theories we generate attack signatures, describing threats or possible attacks to the system. At run-time, we evaluate the likelihood of threats from run-time observations using a probabilistic model based on Bayesian networks.", "num_citations": "12\n", "authors": ["347"]}
{"title": "A service discovery framework based on linear composition\n", "abstract": " Service discovery has been recognised as an important aspect of service oriented computing. This is even more the case when developing service centric systems in which software systems are constructed based on the identification and composition of Web services that together can fulfil the functionality of the system being developed. In this paper we present a framework that supports the discovery of services that can provide the functionality and satisfy the properties and constraints of service-based systems during their design phase. Our framework makes use of linear composition of service operations in which more than one Web service operations can be combined to fulfil a functionality of the system when no single operation can be identified. The discovery process is based on a graph-matching algorithm. A prototype tool has been developed to demonstrate and evaluate the framework.", "num_citations": "12\n", "authors": ["347"]}
{"title": "Viewpoints 96: international workshop on multiple perspectives in software development (sigsoft 96) workshop report\n", "abstract": " This report has been compiled by the workshop organisers. We have attempted to be fair and unbiased but probably failed! A short report cannot do justice to the discussion. You are best off reading the papers or talking to an attendee. What follows is definitely second best.The construction of a complex description or model in software development involves many agents (aka participants or actors). These agents have different perspectives or views of the artefact or system they are trying to describe or model (ie, the domain of discourse), and the process of constructing it. Examples of such perspectives might be performance, security, architecture, and so on. These perspectives or views are partial and incomplete descriptions that arise because of different responsibilities or roles assigned to the agents. These responsibilities or roles may be organisationally defined, or follow some defined structuring of the\u00a0\u2026", "num_citations": "12\n", "authors": ["347"]}
{"title": "A reactive security framework for operational wind parks using service function chaining\n", "abstract": " The innovative application of 5G core technologies, namely Software Defined Networking (SDN) and Network Function Virtualization (NFV), can help reduce capital and operational expenditures in industrial networks. Nevertheless, SDN expands the attack surface of the communication infrastructure, thus necessitating the introduction of additional security mechanisms. A wind park is a good example of an industrial application relying on a network with strict performance, security, and reliability requirements, and was chosen as a representative example of industrial systems. This work highlights the benefit of leveraging the flexibility of SDN/NFV-enabled networks to deploy enhanced, reactive security mechanisms for the protection of the industrial network, via the use of Service Function Chaining. Moreover, a proof of concept implementation of the reactive security framework for an industrial-grade wind park\u00a0\u2026", "num_citations": "11\n", "authors": ["347"]}
{"title": "A pattern-based approach for designing reliable cyber-physical systems\n", "abstract": " Cyber-Physical Systems (CPS) appear to be of paramount importance due to their increasing use on critical infrastructure. New challenges have occurred because of the nature and the complexity of such systems in supporting heterogeneous physical and cyber components simultaneously. Failures or attacks on system components decrease system reliability creating severe consequences to CPS and the attached applications. The construction of complex CPS with respect to security and dependability (S&D) properties is necessary to avoid system vulnerabilities at design level. Design patterns are solutions for reusable designs and interactions of objects. In this work we present a pattern-based language for designing CPS able to guarantee S&D properties. The first set of S&D patterns includes the Reliability Component Composition (RCC) Patterns for designing reliable CPS. RCC patterns are encoded in\u00a0\u2026", "num_citations": "11\n", "authors": ["347"]}
{"title": "Finding secure compositions of software services: Towards a pattern based approach\n", "abstract": " In service based systems, there is often a need to replace services at runtime as they become either unavailable or they no longer meet required quality or security properties. In such cases, it is often necessary to build compositions of services that can replace a problematic service because no single service with a sufficient match to it can be located. In this paper, we present an approach for building compositions of services that can preserve required security properties. Our approach is based on the use of secure composition patterns which are applied in connection with basic discovery mechanisms to build secure service compositions.", "num_citations": "11\n", "authors": ["347"]}
{"title": "Diagnosis of the significance of inconsistencies in object-oriented designs: a framework and its experimental evaluation\n", "abstract": " This paper presents: (a) a framework for assessing the significance of inconsistencies which arise in object-oriented design models that describe software systems from multiple perspectives, and (b) the findings of a series of experiments conducted to evaluate it. The framework allows the definition of significance criteria and measures the significance of inconsistencies as beliefs for the satisfiability of these criteria. The experiments conducted to evaluate it indicate that criteria definable in the framework have the power to create elaborate rankings of inconsistencies in models.", "num_citations": "11\n", "authors": ["347"]}
{"title": "Application of big data to support evidence-based public health policy decision-making for hearing\n", "abstract": " Ideally, public health policies are formulated from scientific data; however, policy-specific data are often unavailable. Big data can generate ecologically-valid, high-quality scientific evidence, and therefore has the potential to change how public health policies are formulated. Here, we discuss the use of big data for developing evidence-based hearing health policies, using data collected and analyzed with a research prototype of a data repository known as EVOTION (EVidence-based management of hearing impairments: public health pOlicy-making based on fusing big data analytics and simulaTION), to illustrate our points. Data in the repository consist of audiometric clinical data, prospective real-world data collected from hearing aids and an app, and responses to questionnaires collected for research purposes. To date, we have used the platform and a synthetic dataset to model the estimated risk of noise\u00a0\u2026", "num_citations": "10\n", "authors": ["347"]}
{"title": "MobileTrust: Secure knowledge integration in VANETs\n", "abstract": " Vehicular Ad hoc NETworks (VANET) are becoming popular due to the emergence of the Internet of Things and ambient intelligence applications. In such networks, secure resource sharing functionality is accomplished by incorporating trust schemes. Current solutions adopt peer-to-peer technologies that can cover the large operational area. However, these systems fail to capture some inherent properties of VANETs, such as fast and ephemeral interaction, making robust trust evaluation of crowdsourcing challenging. In this article, we propose MobileTrust\u2014a hybrid trust-based system for secure resource sharing in VANETs. The proposal is a breakthrough in centralized trust computing that utilizes cloud and upcoming 5G technologies to provide robust trust establishment with global scalability. The ad hoc communication is energy-efficient and protects the system against threats that are not countered by the\u00a0\u2026", "num_citations": "10\n", "authors": ["347"]}
{"title": "MBotCS: A mobile botnet detection system based on machine learning\n", "abstract": " As the use of mobile devices spreads dramatically, hackers have started making use of mobile botnets to steal user information or perform other malicious attacks. To address this problem, in this paper we propose a mobile botnet detection system, called MBotCS. MBotCS can detect mobile device traffic indicative of the presence of a mobile botnet based on prior training using machine learning techniques. Our approach has been evaluated using real mobile device traffic captured from Android mobile devices, running normal apps and mobile botnets. In the evaluation, we investigated the use of 5 machine learning classifier algorithms and a group of machine learning box algorithms with different validation schemes. We have also evaluated the effect of our approach with respect to its effect on the overall performance and battery consumption of mobile devices.", "num_citations": "10\n", "authors": ["347"]}
{"title": "A multi-layer and multitenant cloud assurance evaluation methodology\n", "abstract": " Data with high security requirements is being processed and stored with increasing frequency in the Cloud. To guarantee that the data is being dealt in a secure manner we investigate the applicability of Assurance methodologies. In a typical Cloud environment the setup of multiple layers and different stakeholders determines security properties of individual components that are used to compose Cloud applications. We present a methodology adapted from Common Criteria for aggregating information reflecting the security properties of individual constituent components of Cloud applications. This aggregated information is used to categorise overall application security in terms of Assurance Levels and to provide a continuous assurance level evaluation. It gives the service owner an overview of the security of his service, without requiring detailed manual analyses of log files.", "num_citations": "10\n", "authors": ["347"]}
{"title": "Analysing security requirements in cloud-based service level agreements\n", "abstract": " In cloud computing, measurable services such as packet loss and memory are quantized into different levels to provide different level of services to users. Initially, there will be a service level agreement (SLA) between users and service providers (SPs) and/or SPs and infrastructure providers (IPs). However, the most crucial service required by the users and SPs in cloud computing is security and privacy. Security parameters can be used to prevent attacks and to protect data and systems. In literature, there is no comprehensive solution which quantify all the security parameters associated with the cloud computing paradigm. In this paper, for the first time, we attempt to generalize and quantify the security parameters.", "num_citations": "10\n", "authors": ["347"]}
{"title": "A certification framework for cloud security properties: the monitoring path\n", "abstract": " In this paper we describe the structure and functionality of a certification integrated framework aimed to support the certification of security properties of a Cloud infrastructure (IaaS), a platform (PaaS), or the software layer (SaaS). Such framework will bring service users, service providers and cloud suppliers to work together with certification authorities in order to ensure security properties and certificates validity in the continuously evolving cloud environment. For this purpose, the framework relies on multiple types of evidence gathering with respect to security, e.g., testing services, monitoring agents or trusted computing proofs. In this paper we will focus only on the monitoring case and will illustrate its use. Yet, this framework is designed to be able to follow models for hybrid, incremental and multi-layer security certification since cloud security has to build upon the entire cloud stack.", "num_citations": "10\n", "authors": ["347"]}
{"title": "A framework for hierarchical and recursive monitoring of service based systems\n", "abstract": " Runtime monitoring of Service Based Systems (SBSs) usually relies on information derived from I/O messages exchanged within business processes implementing services. When service provisioning is regulated by complex Service Level Agreements (SLAs) between service requesters, (composed) services, and infrastructure providers, monitoring may require additional features, such as (i) coordination among events captured at different sources involved in service provisioning and (ii) delegation of properties monitoring to local sites. This paper discusses an architecture and engagement protocol supporting the two aforementioned requirements for monitoring complex SLA-driven service provisioning.", "num_citations": "10\n", "authors": ["347"]}
{"title": "Estimating event lifetimes for distributed runtime verification\n", "abstract": " Runtime system verification has been proposed as a form of dynamic verification of software systems which can be applied in settings where complete static verification or exhaustive system testing is not practical. Runtime verification checks properties against runtime events generated during the operation of a system. Current approaches to runtime verification assume that runtime events are time-stamped by a single clock and, thus, can be totally ordered. They also assume that events are received by the reasoning engine in the same order as they have been produced. These assumptions are apparently true only in systems with a single clock. In this paper, we present the extension of a framework for runtime verification which can monitor distributed systems, in which events are produced by different components, each having its own clock.", "num_citations": "10\n", "authors": ["347"]}
{"title": "A pattern-driven framework for monitoring security and dependability\n", "abstract": " In this paper we describe a framework that supports the dynamic configuration, adaptation and monitoring of systems that need to guarantee specific security and dependability (S&D) properties whilst operating in distributed settings. The framework is based on patterns providing abstract specifications of implementation solutions that can be used by systems in order to achieve specific S&D properties. The focus herein will be on the monitoring aspects of the framework which allow it to adapt to violations of the S&D requirements and changes to the current context.", "num_citations": "10\n", "authors": ["347"]}
{"title": "Overlaps among requirements specifications\n", "abstract": " Although overlap between specifications\u2013that is the incorporation of elements which designate common features of the domain of discourse\u2013is a prerequisite for specification inconsistency, it has only been a side concern in requirements engineering research. This paper discusses overlap, points out the complicating factors in its identification an outlines the key components of a programme of research in this area.", "num_citations": "10\n", "authors": ["347"]}
{"title": "Reconciliation: managing interference in software development\n", "abstract": " This paper outlines a method, called reconciliation, for managing interference between partial specifications or viewpoints. The method supports the detection, verification and tracking of ontological overlaps. The paper describes the heuristics on which the method is based and illustrates the application of the method to a scenario.", "num_citations": "10\n", "authors": ["347"]}
{"title": "Modern aspects of cyber-security training and continuous adaptation of Programmes to trainees\n", "abstract": " Nowadays, more-and-more cyber-security training is emerging as an essential process for the lifelong personnel education in organizations, especially for those which operate critical infrastructures. This is due to security breaches on popular services that become publicly known and raise people\u2019s security awareness. Except from large organizations, small-to-medium enterprises and individuals need to keep their knowledge on the related topics up-to-date as a means to protect their business operation or to obtain professional skills. Therefore, the potential target-group may range from simple users, who require basic knowledge on the current threat landscape and how to operate the related defense mechanisms, to security experts, who require hands-on experience in responding to security incidents. This high diversity makes training and certification quite a challenging task. This study combines pedagogical practices and cyber-security modelling in an attempt to support dynamically adaptive training procedures. The training programme is initially tailored to the trainee\u2019s needs, promoting the continuous adaptation to his/her performance afterwards. As the trainee accomplishes the basic evaluation tasks, the assessment starts involving more advanced features that demand a higher level of understanding. The overall method is integrated in a modern cyber-ranges platform, and a pilot training programme for smart shipping employees is presented. View Full-Text", "num_citations": "9\n", "authors": ["347"]}
{"title": "Behavior-aware, unified service discovery\n", "abstract": " Composite services commonly expose the choreography of message exchanges realized by their constituent services through appropriate descriptions and interfaces. Such information is very useful in deciding whether a composite service fully meets the behavioral requirements of a specific application or not. However, expressing behavioral requirements towards a service is currently a challenging task, often requiring the use of complex semantic annotations and the employment of related supporting technologies. Moreover, choreography descriptions and interfaces may be expressed in various formats and they are published in various types of registries, repositories, or networks. These issues hinder the applicability and effectiveness of behavior-aware service discovery. To overcome the aforementioned obstacles and to promote interoperability at the service discovery level, we propose in this paper a novel, unified solution towards expressing and evaluating behavioral requirements towards services. In our approach, queries are conveniently created in a visual manner with the use of UML; they are translated into a generic XML-based query language, namely USQL; they are uniformly executed in a wide variety of target registries, repositories, and networks, by means of a powerful service search engine; and they can be matched against different types of service choreography descriptions.", "num_citations": "9\n", "authors": ["347"]}
{"title": "Fully synthetic longitudinal real-world data from hearing aid wearers for public health policy modeling\n", "abstract": " Approximately one-third of people over 65 years of age, and 5% of the world\u2019s population, is affected by hearing loss (HL)(World Health Organization, 2017). Disabling HL is associated with early cognitive decline in adults (Olusanya et al., 2014), and when unaddressed, HL restricts social integration and reduces employment and educational opportunities, hampers emotional well-being and, thus, poses an economic challenge at both the individual and national level (Wilson et al., 2017). Moreover, more and more individuals suffer from HL, which is primarily due to increases in everyday noise exposure and an increase of the aging population (World Health Organization, 2017). Despite the fact that age-related HL is the third leading cause of years lived with disability (Vos et al., 2017), the population of individuals with hearing loss is underserved because few public health policies focus on prevention, intervention, and rehabilitation for age-related HL (Reavis et al., 2016). This inadequate focus has been attributed to a lack of evidence supporting policies that actively promote hearing healthcare (Moyer, 2012; Barker et al., 2016). However, this specific issue is targeted in the EU-funded H2020 project EVOTION (www. h2020evotion. eu), which collects a large volume of heterogenous data from almost 1,000 hearing aid (HA) users with varying degrees of hearing loss to support the development of evidence-based policy making within the hearing healthcare field (Spanoudakis et al., 2017; Gutenberg et al., 2018). Data are being collected from five sources:(i) hearing aids,(ii) a smartphone app,(iii) a biosensor,(iv) audiology clinics, and (v) electronic\u00a0\u2026", "num_citations": "8\n", "authors": ["347"]}
{"title": "Representation of security and dependability solutions\n", "abstract": " AmI considerations lead us to argue that it is essential for Security and Dependability (S&D) mechanisms to be able to adapt themselves to renewable context conditions in order to be applied to the ever-changing AmI scenarios. The key for this dynamic adaptation relies on the ability to capture the expertise of S&D engineers in such a way that it can be selected, adapted, used and monitored at runtime by automated means. S&D Artefacts proposed in this chapter represent the core of author\u2019s approach to precisely model such expertise in form of semantic descriptions. They adopt an integral methodology covering the complete system life cycle going from S&D Classes, mostly used at development time, to S&D Patterns and S&D Implementations, perfectly suited for deployment and runtime use. This chapter traces the foundations and internals of S&D Artefacts, describing how they are defined and\u00a0\u2026", "num_citations": "8\n", "authors": ["347"]}
{"title": "Diagnosis and Threat Detection Capabilities of the SERENITY Monitoring Framework\n", "abstract": " The SERENITY monitoring framework offers mechanisms for diagnosing the causes of violations of security and dependability (S&D) properties and detecting potential violations of such properties, called \u0201Cthreats\u201d. Diagnostic information and threat detection are often necessary for deciding what an appropriate reaction to a violation is and taking pre-emptive actions against predicted violations, respectively. In this chapter, we describe the mechanisms of the SERENITY monitoring framework which generate diagnostic information for violations of S&D properties and detecting threats.", "num_citations": "8\n", "authors": ["347"]}
{"title": "Significance of Inconsistencies in UML Models\n", "abstract": " This paper presents a diagnostic framework for assessing the significance of inconsistencies in design models of software systems expressed in the Unified Modelling Language (UML). This assessment is based on significance criteria which software designers have to specify and associate with specific consistency rules. These criteria are defined in terms of characteristics of the model elements involved in the breach of a consistency rule. The framework establishes belief functions which measure the extent to which it may be believed from the model that an element has a characteristic, and uses them to derive beliefs for the significance criteria. Results of a set of preliminary experiments conducted to evaluate the framework are also presented.", "num_citations": "8\n", "authors": ["347"]}
{"title": "Towards IoT orchestrations with security, privacy, dependability and interoperability guarantees\n", "abstract": " The advent of the Internet of Things opens a plethora of possibilities, provided the research and industry communities are able to overcome a number of challenges such as the dynamicity, scalability, heterogeneity and end-to-end security and privacy requirements of such environments. Motivated by these challenges, this paper proposes leveraging architectural patterns to provide, in an integrated manner, security, dependability, privacy, and interoperability guarantees, across horizontal and vertical compositional structures of IoT applications. The pattern language design process and definition is presented, along with an implementation enabling the automated, pattern- driven property verification and adaptation of IoT orchestrations.", "num_citations": "7\n", "authors": ["347"]}
{"title": "Pattern-driven security, privacy, dependability and interoperability management of IoT environments\n", "abstract": " Achieving Security, Privacy, Dependability and Interoperability (SPDI) is of paramount importance for the ubiquitous deployment and impact maximization of Internet of Things (IoT) applications. Nevertheless, said requirements are not only difficult to achieve at system initialization, but also hard to prove and maintain at run-time. This paper highlights an approach to tackling the above challenges, through the definition of pattern language and a framework that can guarantee SPDI in IoT orchestrations. By integrating pattern reasoning engines at the various layers of the IoT infrastructure, and a machine-processable representation of said pattern through Drools rules, the proposed framework can provide ways to fulfill SPDI requirements at design time, and also provide the means to guarantee those SPDI properties and manage the orchestrations accordingly. Moreover, an application example of the framework is\u00a0\u2026", "num_citations": "7\n", "authors": ["347"]}
{"title": "A big data repository and architecture for managing hearing loss related data\n", "abstract": " The vast amount of data, which arise in healthcare applications makes traditional data processing technology inadequate and requires the use of fast emerging big data technologies to cope with key challenges, including data heterogeneity, pace of acquisition, size, privacy and security. Addressing these challenges requires a shift from traditional data analysis systems and techniques to big data management and processing platforms as well as big data analytics centric architectures. In this paper, we introduce such an architecture. The architecture has been developed to support the acquisition and analysis of big data sets regarding hearing loss and the provision of related healthcare services for the purpose of informing public health policy making. The paper provides an overview of the system and presents the outcomes of an initial evaluation of its performance.", "num_citations": "7\n", "authors": ["347"]}
{"title": "Describing and Verifying Monitoring Capabilities for SLA-Driven Service Based Systems.\n", "abstract": " Monitoring the operation of Service Based Systems (SBS) to ensure compliance with a set of service level agreements (SLAs) for example cannot always rely on a pre-specified monitoring infrastructure, where all the information and components required for monitoring are a priori known and available. This because new services with unknown monitoring infrastructures and capabilities may be dynamically assembled to an SBS. To address the need for dynamic configuration of SBS monitoring infrastructures, this paper proposes a model for describing the monitoring capabilities of different services of an SBS and discusses the process for verifying the monitorability of required properties based on these capabilities.", "num_citations": "7\n", "authors": ["347"]}
{"title": "A Query Language for Service Discovery.\n", "abstract": " To support the discovery of services during development and execution time of service-based systems, it is necessary to have ways of expressing the characteristics of the services to be discovered and the applications that will use them. In this paper, we present SerDiQueL, an XML-based query language that allows for the description of service discovery queries expressing structural, behavioural, quality, and contextual characteristics of services to be discovered. The language supports the identification of services during both development and execution of service-based systems and is supported by prototyped query processors performing similarity analysis between services and queries.", "num_citations": "7\n", "authors": ["347"]}
{"title": "On evidential feature salience\n", "abstract": " This paper describes a method for estimating the salience of features comprising conceptual descriptions of software artifacts. Salience estimates are used in a model analyzing the similarity between such descriptions so as to promote the analogical reuse of the artifacts described by them. Salience is conceived as belief on the dominance of a feature, which is defined on the basis of three general properties that a feature may have in a conceptual model, namely the abstractness, the characteristicity and the causality. This belief is measured according to evidence inherent in conceptual schemas organizing software repositories.", "num_citations": "7\n", "authors": ["347"]}
{"title": "WARDOG: Awareness detection watchbog for Botnet infection on the host device\n", "abstract": " Botnets constitute nowadays one of the most dangerous security threats worldwide. High volumes of infected machines are controlled by a malicious entity and perform coordinated cyber-attacks. The problem will become even worse in the era of the Internet of Things (IoT) as the number of insecure devices is going to be exponentially increased. This paper presents WARDOG - an awareness and digital forensic system that informs the end-user of the botnet's infection, exposes the botnet infrastructure, and captures verifiable data that can be utilized in a court of law. The responsible authority gathers all information and automatically generates a unitary documentation for the case. The document contains undisputed forensic information, tracking all involved parties and their role in the attack. The deployed security mechanisms and the overall administration setting ensures non-repudiation of performed actions and\u00a0\u2026", "num_citations": "6\n", "authors": ["347"]}
{"title": "Detection of security and dependability threats: A belief based reasoning approach\n", "abstract": " Monitoring the preservation of security and dependability (S&D) properties during the operation of systems at runtime is an important verification measure that can increase system resilience. However it does not always provide sufficient scope for taking control actions against violations as it only detects problems after they occur. In this paper, we describe a proactive monitoring approach that detects potential violations of S&D properties, called ldquothreatsrdquo, and discuss the results of an initial evaluation of it.", "num_citations": "6\n", "authors": ["347"]}
{"title": "The runtime monitoring framework of SERENITY\n", "abstract": " This chapter describes SERENITY\u2019s approach to runtime monitoring and the framework that has been developed to support it. Runtime monitoring is required in SERENITY in order to check for violations of security and dependability properties which are necessary for the correct operation of the security and dependability solutions that are available from the SERENITY framework. This chapter discusses how such properties are specified and monitored. The chapter focuses on the activation and execution of monitoring activities using S&D Patterns and the actions that may be undertaken following the detection of property violations. The approach is demonstrated in reference to one of the industrial case studies of the SERENITY project.", "num_citations": "6\n", "authors": ["347"]}
{"title": "A scheme for requirements monitoring of web service based systems\n", "abstract": " This technical report proposes a framework for monitoring the compliance of systems composed of web-services with requirements set for them. This framework assumes systems composed of web-services which are co-ordinated by a service composition process expressed in BPEL4WS and uses event calculus to specify the properties to be monitored. The monitorable properties may include behavioural properties of a system which are automatically extracted from the specification of its composition process in BPEL4WS and/or assumptions that system providers can specify in terms of events extracted from this specification.", "num_citations": "6\n", "authors": ["347"]}
{"title": "G. Traceability Approach for I* and UML Models\n", "abstract": " In this paper we propose an approach that can be used to generate traceability relations between organisational models specified in i* and software systems models represented in UML (in particular use case and class diagrams). Our approach proposes different types of traceability relationships between i* and UML models and uses traceability rules to generate the different types of traceability relations between them. The traceability rules and traceable models are represented in XML. This makes possible the use of our approach in settings where the models are created and managed autonomously. The approach is supported by a prototype tool that interprets the rules and generates traceability relations.", "num_citations": "6\n", "authors": ["347"]}
{"title": "Multi-perspective requirements engineering within NATURE\n", "abstract": " This paper argues that existing definitions of viewpoints in software engineering are inadequate for requirements engineering (RE). The ESPRIT 6353 \u2018NATURE\u2019 basic research action proposes an alternative definition which recognises that viewpoints are social artefacts within the RE process. It also proposes novel computational mechanisms for analysing different viewpoints as a basis for more informed negotiation between viewpoint owners. This paper reports important aspects of this research and outlines an agenda for future research in multiperspective RE.", "num_citations": "6\n", "authors": ["347"]}
{"title": "Next-generation viewpoint-based environments\n", "abstract": " This paper discusses the notion of, and outlines requirements for Viewpoint-based Environments. These are next-generation CASE environments, which support the specification of requirements from multiple perspectives or so-called viewpoints. Requirements for such environments are mainly concerned with the detection and management of interference between viewpoints. Viewpoint-based Environments should also support the cooperation of multiple developers and maintain development histories in terms of multiple viewpoint versions. We briefly sketch an architecture for such environments and outline a research agenda for developing them.", "num_citations": "6\n", "authors": ["347"]}
{"title": "A high performance scheduler for an automated chemistry workstation\n", "abstract": " A high performance scheduler for an automated chemistry workstation | Proceedings of the 11th European Conference on Artificial Intelligence ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleProceedingsECAI'94A high performance scheduler for an automated chemistry workstation Article A high performance scheduler for an automated chemistry workstation Share on Authors: Robert J. Aarts View Profile , Stephen F. Smith View Profile Authors Info & Affiliations Publication: ECAI'94: Proceedings of the 11th European Conference on Artificial IntelligenceAugust 1994 Pages 3\u20137 0citation 0 Downloads Metrics Total Citations0 Total 0 Last \u2026", "num_citations": "6\n", "authors": ["347"]}
{"title": "Towards a Collection of Security and Privacy Patterns\n", "abstract": " Security and privacy (SP)-related challenges constitute a significant barrier to the wider adoption of Internet of Things (IoT)/Industrial IoT (IIoT) devices and the associated novel applications and services. In this context, patterns, which are constructs encoding re-usable solutions to common problems and building blocks to architectures, can be an asset in alleviating said barrier. More specifically, patterns can be used to encode dependencies between SP properties of individual smart objects and corresponding properties of orchestrations (compositions) involving them, facilitating the design of IoT solutions that are secure and privacy-aware by design. Motivated by the above, this work presents a survey and taxonomy of SP patterns towards the creation of a usable pattern collection. The aim is to enable decomposition of higher-level properties to more specific ones, matching them to relevant patterns, while also creating a comprehensive overview of security-and privacy-related properties and sub-properties that are of interest in IoT/IIoT environments. To this end, the identified patterns are organized using a hierarchical taxonomy that allows their classification based on provided property, context, and generality, while also showing the relationships between them. The two high-level properties, Security and Privacy, are decomposed to a first layer of lower-level sub-properties such as confidentiality and anonymity. The lower layers of the taxonomy, then, include implementation-level enablers. The coverage that these patterns offer in terms of the considered properties, data states (data in transit, at rest, and in process), and platform connectivity\u00a0\u2026", "num_citations": "5\n", "authors": ["347"]}
{"title": "Predicting software service availability: Towards a runtime monitoring approach\n", "abstract": " This paper presents a prediction model for software services availability measured by the mean-time-to-repair (MTTR) and mean-time-to-failure (MTTF) of a service. The prediction model is based on the experimental identification of probabilistic prediction for variables that affect MTTR/MTTF, based on monitoring service data collected at runtime.", "num_citations": "5\n", "authors": ["347"]}
{"title": "Designing and Adapting Service-based Systems: A Service Discovery Framework\n", "abstract": " This chapter describes a service discovery framework that has been developed within the EU 6th Framework projects SeCSE and Gredia. The framework supports design of service-based systems based on existing services and adaptation of service based systems during their execution due to different situations. It assumes services described from different perspectives and uses complex service discovery queries specified in an XML-based language that we have developed. The work is illustrated with the Cell Phone Operator case study.", "num_citations": "5\n", "authors": ["347"]}
{"title": "Runtime prediction of software service availability\n", "abstract": " This paper presents a prediction model for software service availability measured by the mean-time-to-repair (MTTR) and mean-time-to-failure (MTTF) of a service. The prediction model is based on the experimental identification of probability distribution functions for variables that affect MTTR/MTTF and has been implemented using a framework that we have developed to support monitoring and prediction of quality-of-service properties, called EVEREST+. An initial experimental evaluation of the model is presented in the paper.", "num_citations": "5\n", "authors": ["347"]}
{"title": "Monitoring security and dependability in mobile p2p systems\n", "abstract": " Ensuring the dependability and security of mobile P2P systems is an intricate task due to the autonomous and decentralised nature of such systems. In this paper, we present a framework that provides increased support for security and dependability properties by monitoring the compliance of the operation of mobile P2P applications with them at runtime. The framework performs monitoring driven by policies specified for the individual peers in a P2P application and decouples the monitoring process from the operation of the application, to increase its resilience and avoid adverse effects on its performance.", "num_citations": "5\n", "authors": ["347"]}
{"title": "A temporal abductive diagnostic process for runtime properties violations\n", "abstract": " The monitoring of properties of complex software systems can provide the core functionality for detecting violations of such properties. However, the violations detection cannot be always sufficient for the preservation of the properties. Except for the detection, the explanations of the occurrence of a violation could play significant role for the preservation task. In particular, diagnosis can indicate the cause (s) of a violation. Thus, diagnostic information is necessary for preserving the properties due to the support that can provide for deciding on the appropriate countermeasure against a violation. In this paper, we describe a process for diagnosing runtime violations of properties that we have developed as part of a runtime monitoring framework. The process is based on a combination of abductive, temporal and evidential reasoning over violations of process properties expressed in Event Calculus.", "num_citations": "5\n", "authors": ["347"]}
{"title": "Towards a framework for dynamic verification of peer-to-peer systems\n", "abstract": " Ensuring dependability and security of peer-to-peer (P2P) systems is an intricate task due to the autonomous and volatile nature of peers and the decentralization that characterizes such systems. Dynamic verification provides the means of monitoring aspects of peer behaviour at runtime and the capacity to react to identified violations with the aim of preserving the system in the desired state. Thus, it can provide an extra layer of checking properties like security and dependability and lead to enhanced system resilience in this respect. In this paper, we introduce a framework that supports the dynamic verification of P2P systems.", "num_citations": "5\n", "authors": ["347"]}
{"title": "Review of the state of the art (in Security and Dependability Monitoring and Recovery)\n", "abstract": " CiteSeerX \u2014 Review of the state of the art (in Security and Dependability Monitoring and Recovery) Documents Authors Tables Log in Sign up MetaCart DMCA Donate CiteSeerX logo Documents: Advanced Search Include Citations Authors: Advanced Search Include Citations Tables: DMCA Review of the state of the art (in Security and Dependability Monitoring and Recovery) (2006) Cached Download as a PDF Download Links [www.soi.city.ac.uk] Save to List Add to Collection Correct Errors Monitor Changes by G. Spanoudakis , C. Kloukinas , T. Tsigritis , K. Androutsopoulos , C. Ballas , Domenico Presenza Citations: 1 - 0 self Summary Citations Active Bibliography Co-citation Clustered Documents Version History Share Facebook Twitter Reddit Bibsonomy OpenURL Abstract Keyphrases dependability monitoring Powered by: Apache Solr About CiteSeerX Submit and Index Documents Privacy Policy Help Data -\u2026", "num_citations": "5\n", "authors": ["347"]}
{"title": "Reconciliation of object interaction models\n", "abstract": " This paper presents Reconciliation+, a tool-supported method which identifies overlaps between models of different object interactions expressed as UML sequence and/or collaboration diagrams, checks whether the overlapping messages of these models satisfy specific consistency rules, and guides developers in handling any inconsistencies detected.", "num_citations": "5\n", "authors": ["347"]}
{"title": "SPD-safe: Secure administration of railway intelligent transportation systems\n", "abstract": " The railway transport system is critical infrastructure that is exposed to numerous man-made and natural threats, thus protecting this physical asset is imperative. Cyber security, privacy, and dependability (SPD) are also important, as the railway operation relies on cyber-physical systems (CPS) systems. This work presents SPD-Safe\u2014an administration framework for railway CPS, leveraging artificial intelligence for monitoring and managing the system in real-time. The network layer protections integrated provide the core security properties of confidentiality, integrity, and authentication, along with energy-aware secure routing and authorization. The effectiveness in mitigating attacks and the efficiency under normal operation are assessed through simulations with the average delay in real equipment being 0.2\u20130.6 s. SPD metrics are incorporated together with safety semantics for the application environment. Considering an intelligent transportation scenario, SPD-Safe is deployed on railway critical infrastructure, safeguarding one outdoor setting on the railway\u2019s tracks and one in-carriage setting on a freight train that contains dangerous cargo. As demonstrated, SPD-Safe provides higher security and scalability, while enhancing safety response procedures. Nonetheless, emergence response operations require a seamless interoperation of the railway system with emergency authorities\u2019 equipment (eg, drones). Therefore, a secure integration with external systems is considered as future work. View Full-Text", "num_citations": "4\n", "authors": ["347"]}
{"title": "Cyber Range Training Programme Specification Through Cyber Threat and Training Preparation Models\n", "abstract": " In light of the ever-increasing complexity and criticality of applications supported by ICT infrastructures, Cyber Ranges emerge as a promising solution to effectively train people within organisations on cyber-security aspects, thus providing an efficient mechanism to manage the associated risks. Motivated by this, the work presented herein introduces the model-driven approach of the THREAT-ARREST project for Cyber Range training, presenting in detail the Cyber Threat Training and Preparation (CTTP) models. These models, comprising sub-models catering for different aspects of the training, are used for specifying and generating the Training Programmes. As such, the paper also provides details on implementation aspects regarding the use of these models in the context of a usable cyber range training platform and two specific training scenarios.", "num_citations": "4\n", "authors": ["347"]}
{"title": "Validation of service level agreements using probabilistic model checking\n", "abstract": " With the fast growth of Information Technology (IT), organisations rely mostly on web services, cloud services and recently on Big Data Analytics services (BDA services), in order to support their business services. To securely use these services, service clients sign a Service Level Agreement (SLA) with service providers, regarding a particular service provision. Typically, SLAs define the properties that need to be preserved during the provision of a service (e.g., quality of service properties) and actions that will be applied if the service provision violates the defined properties (e.g., penalties or re-negotiation). Whilst significant research has focused on monitoring SLAs during the provision of services, the exploration and validation of the potential consequences of SLAs for the involved parties prior to putting them in operation is not addressed by existing research. In this paper, we present an approach to SLA\u00a0\u2026", "num_citations": "4\n", "authors": ["347"]}
{"title": "Associations Between Hearing Performance and Physiological Measures-An Overview and Outlook.\n", "abstract": " The current paper summarises the research investigating associations between physiological data and hearing performance. An overview of state-of-theart research and literature is given as well as promising directions for associations between physiological data and data regarding hearing loss and hearing performance. The physiological parameters included in this paper are: electrodermal activity, heart rate variability, blood pressure, blood oxygenation and respiratory rate. Furthermore, the environmental and behavioural measurements of physical activity and body mass index, alcohol consumption and smoking have been included. So far, only electrodermal activity and heart rate variability are physiological signals simultaneously associated with hearing loss or hearing performance. Initial findings suggest blood pressure and respiratory rate to be the most promising physiological measures that relate to hearing loss and hearing performance.", "num_citations": "4\n", "authors": ["347"]}
{"title": "Dynamic creation of monitoring infrastructures\n", "abstract": " As a key part of monitoring and management, systems developed with a Service-Oriented Architecture (SOA) design pattern should utilise negotiated agreements between service providers and requesters. Typically, the results of these negotiations are specified in Service Level Agreements (SLAs), which are then used to monitor key levels of service provided, and to optionally specify preconditions and actions in case these levels are violated.", "num_citations": "4\n", "authors": ["347"]}
{"title": "Runtime Service Discovery for Grid Applications\n", "abstract": " A Virtual Organisation in large-scale distributed systems is a set of individuals and/or institutions with some common purposes or interests that need to share their resources to further their objectives, which is similar to a human community in social networks that consists of people have common interests or goals. Due to the similarity between social networks and Grids, the concepts in social science (eg small world phenomenon) can be adopted for the design of new generation Grid systems. This chapter presents a Small World Architecture for Effective Virtual Organisations (SWEVO) for Grid resource discovery in Virtual Organisations, which enables Virtual Organisations working in a more collaborative manner to support decision makers. In SWEVO, Virtual Organisations are connected by a small number of interorganisational links. Not every local network node needs to be connected to remote Virtual\u00a0\u2026", "num_citations": "4\n", "authors": ["347"]}
{"title": "UML-based service discovery tool\n", "abstract": " The development of service centric systems has been recognised as an important approach for software system development. In this paper, we present a UML-based tool to identify services that can provide the functionality and satisfy properties and constraints of service centric systems specified during the design phase of the development of these systems and allows for the (re-) formulation of the design models based on the discovered services", "num_citations": "4\n", "authors": ["347"]}
{"title": "Evidential diagnosis of inconsistencies in object-oriented designs\n", "abstract": " This paper presents a diagnostic framework for assessing the significance of inconsistencies (i.e., violations of consistency rules) in software design models expressed in the Unified Modeling Language (UML). The assessment is based on significance criteria that software designers can specify and associate with specific consistency rules. These criteria define characteristics that the model elements involved in the violation of a rule should have for the inconsistency to be significant, and they are specified in a formal language derived from the Object Constraint Language (OCL). The satisfiability of the criteria by individual model elements is measured by belief functions defined by the framework. The measures generated by these functions are used to rank the inconsistencies caused by different model elements. The presented framework has been evaluated through a set of experiments. The results of these\u00a0\u2026", "num_citations": "4\n", "authors": ["347"]}
{"title": "A Data-informed Public Health Policy-Makers Platform\n", "abstract": " Hearing loss is a disease exhibiting a growing trend due to a number of factors, including but not limited to the mundane exposure to the noise and ever-increasing size of the older population. In the framework of a public health policymaking process, modeling of the hearing loss disease based on data is a key factor in alleviating the issues related to the disease and in issuing effective public health policies. First, the paper describes the steps of the data-driven policymaking process. Afterward, a scenario along with the part of the proposed platform responsible for supporting policymaking are presented. With the aim of demonstrating the capabilities and usability of the platform for the policy-makers, some initial results of preliminary analytics are presented in the framework of a policy-making process. Ultimately, the utility of the approach is validated throughout the results of the survey which was presented to the health system policy-makers involved in the policy development process in Croatia. View Full-Text", "num_citations": "3\n", "authors": ["347"]}
{"title": "The THREAT-ARREST cyber-security training platform\n", "abstract": " Cyber security is always a main concern for critical infrastructures and nation-wide safety and sustainability. Thus, advanced cyber ranges and security training is becoming imperative for the involved organizations. This paper presets a cyber security training platform, called THREAT-ARREST. The various platform modules can analyze an organization\u2019s system, identify the most critical threats, and tailor a training program to its personnel needs. Then, different training programmes are created based on the trainee types (ie administrator, simple operator, etc.), providing several teaching procedures and accomplishing diverse learning goals. One of the main novelties of THREAT-ARREST is the modelling of these programmes along with the runtime monitoring, management, and evaluation operations. The platform is generic. Nevertheless, its applicability in a smart energy case study is detailed.", "num_citations": "3\n", "authors": ["347"]}
{"title": "Towards a security, privacy, dependability, interoperability framework for the Internet of Things\n", "abstract": " A popular application of ambient intelligence systems constitutes of assisting living services on smart buildings. As intelligence is imported in embedded equipment, the system becomes able to provide smart services (e.g. control lights, airconditioning, provide energy management services etc.). IoT is the main enabler of such environments. However, the interconnection of these cyber-physical systems and the processing of personal data raise serious security and privacy issues. In this paper we present a framework that can guarantee Security, Privacy, Dependability and Interoperability (SPDI) in IoT. Taking advantage of the underlying IoT deployment, the proposed framework not only implements the requested smart functionality but also provide modelling and administration that can guarantee those SPDI properties. Moreover, we provide an application example of the framework in a smart building scenario.", "num_citations": "3\n", "authors": ["347"]}
{"title": "IoT European security and privacy projects: Integration, architectures and interoperability\n", "abstract": " The chapter presents an overview of the eight that are part of the European IoT Security and Privacy Projects initiative (IoT-ESP) addressing advanced concepts for end-to-end security in highly distributed, heterogeneous and dynamic IoT environments. The approaches presented are holistic and include identification and authentication, data protection and prevention against cyber-attacks at the device and system levels. The projects present architectures, concepts, methods and tools for open IoT platforms integrating evolving sensing, actuating, energy harvesting, networking and Interface technologies. Platforms should provide connectivity and intelligence, actuation and control features, linkage to modular and ad-hoc cloud services, The IoT platforms used are compatible with existing international Developments addressing object identity management, discovery services, virtualisation of objects, devices and infrastructures and trusted IoT approaches.", "num_citations": "3\n", "authors": ["347"]}
{"title": "Cloud certification process validation using formal methods\n", "abstract": " The importance of cloud-based systems is increasing constantly as they become crucial for completing tasks in an effective and affordable manner. Yet, their use is affected by concerns about the security of the data and applications provisioned through them. Security certification provides a means of increasing confidence in such systems, by establishing that they fulfil certain security properties of interest. Certification processes involve security property assessments against specific threat models. These processes may be based on self-assessment, testing, inspection or runtime monitoring of security properties, and/or combinations of such methods (hybrid certification). One important question for all such processes is whether they actually deliver what they promise. This question is open at the moment and is the focus of our work. To address it, we have developed an approach that formalises certification\u00a0\u2026", "num_citations": "3\n", "authors": ["347"]}
{"title": "Towards transparent and trustworthy cloud\n", "abstract": " Despite its immense benefits in terms of flexibility, resource consumption, and simplified management, cloud computing raises several concerns due to lack of trust and transparency. Like all computing paradigms based on outsourcing, the use of cloud computing is largely a matter of trust. There is an increasing pressure by cloud customers for solutions that would increase their confidence that a cloud service/application is behaving in a secure and correct manner. Cloud assurance techniques, developed to assess the trustworthiness of cloud services, can play a major role in building trust. In this paper, we start from the assumption that an opaque cloud does not fit security, and present a reliable evidence collection process and infrastructure extending existing assurance techniques towards the definition of a trustworthy cloud. The proposed process and infrastructure are applied to a case study on cloud\u00a0\u2026", "num_citations": "3\n", "authors": ["347"]}
{"title": "Runtime prediction\n", "abstract": " Monitoring the preservation of quality of service (QoS) properties during the operation of service-based systems at runtime is an important verification measure for determining whether current service usage is compliant with agreed SLAs. Monitoring, however, does not always provide sufficient scope for taking control actions against violations, as it only detects violations after they occur. This chapter describes a model-based prediction framework for detecting potential violations of QoS properties before they occur to enable the undertaking of control actions that could prevent the violations. EVEREST+ receives prediction specifications expressed in Event Calculus and automatically identifies relevant monitoring data that should be collected at runtime to infer QoS property prediction models. It then analyses runtime monitoring data to infer statistical prediction models for the relevant properties, and uses the\u00a0\u2026", "num_citations": "3\n", "authors": ["347"]}
{"title": "A Framework for Proactive SLA Negotiation.\n", "abstract": " In this position paper we propose a framework for proactive SLA negotiation that integrates this process with dynamic service discovery and, hence, can provide integrated runtime support for both these key activities which are necessary in order to achieve the runtime operation of service based systems with minimised interruptions. More specifically, our framework discovers candidate constituent services for a composite service, establishes an agreed but not enforced SLA and a period during which this preagreement can be activated should this become necessary", "num_citations": "3\n", "authors": ["347"]}
{"title": "IT-outsourcing and IT-offshoring: Trends and impacts on SE/KE curricula\n", "abstract": " As a result of IT outsourcing and offshoring, IT professionals and educators are faced with the following question: What SE & KE skill sets will make a software engineer or a knowledge engineer immune to the impact of outsourcing and offshoring? This article summarizes the position papers from a panel held during the 2006 International Conference on Software Engineering and Knowledge Engineering from July 5 to 7 at the Hotel Sofitel, Redwood City in California, USA. Bringing software and knowledge engineers closer to the needs of their prospective customers and providing more value than simply pure software development and maintenance, is an open challenge at least for traditional computer science and software engineering curricula.", "num_citations": "3\n", "authors": ["347"]}
{"title": "Pattern-Based System Evolution: A Case-Study.\n", "abstract": " Design patterns help system designers apply proven solutions to commonly occurring problems in particular contexts. While their impact on software practice has been significant, the application of patterns has been limited to the early stages of the software lifecycle. In this paper, we show how the benefits of a pattern-centric approach can be leveraged across the lifecycle, specifically as the system evolves to meet changing requirements. The approach is based on a notation we have previously proposed for providing precise specifications of patterns and of how patterns are specialized for use in particular systems. In this paper, we summarize the main elements of the specification approach, show how such specifications allow us to capture essential pattern-centric information about a system, and demonstrate, via a simple but illustrative case-study, how this information allows us to preserve the design integrity of the system as it evolves.", "num_citations": "3\n", "authors": ["347"]}
{"title": "Software package requirements and procurement\n", "abstract": " This paper outlines the problems of specifying requirements and deploying these requirements in the procurement of software packages. Despite the fact that software construction de novo is the exception rather than the rule, little or no support for the task of formulating requirements to support assessment and selection among existing software packages has been developed. We analyse the problems arising in this process and review related work. We outline the key components of a programme of research in this area.", "num_citations": "3\n", "authors": ["347"]}
{"title": "Generating secure service compositions\n", "abstract": " Ensuring that the compositions of services that constitute service-based systems satisfy given security properties is a key prerequisite for the adoption of the service oriented computing paradigm. In this paper, we address this issue using a novel approach that guarantees service composition security by virtue of the generation of compositions. Our approach generates service compositions that are guaranteed to satisfy security properties based on secure service orchestration (SESO) patterns. These patterns express primitive (e.g., sequential, parallel) service orchestrations, which are proven to have certain global security properties if the individual services participating in them have themselves other security properties. The paper shows how SESO patterns can be constructed and gives examples of proofs for such patterns. It also presents the process of using SESO patterns to generate secure service\u00a0\u2026", "num_citations": "2\n", "authors": ["347"]}
{"title": "Biologically inspired near extinct system reconstruction\n", "abstract": " Recovery software system operations from a state of extensive damage without human intervention is a challenging problem as it may need to be based on a different infrastructure from the one that the system was originally designed for and deployed on (i.e., computational and communication devices) and significant reorganization of system functionalities. In this paper, we introduce a bio-inspired approach for reconstructing nearly extinct complex software systems. Our approach is based on encoding a computational DNA (co-DNA) of a system and computational analogues of biological processes to enable the transmission of co-DNA over computational devices and, through it, the transformation of these devices into system cells that can realise chunks of the system functionality, and spread further its reconstruction process.", "num_citations": "2\n", "authors": ["347"]}
{"title": "Taming the cloud: safety, certification and compliance for software services\n", "abstract": " The maturity of IT processes, such as software development, can be and is often certified. Current trends in the IT industry suggest that software systems in the future will be very different from their counterparts today, with an increasing adoption of the Service-Oriented Architecture (SOA) design pattern and the deployment of Software-as-a-Service (SaaS) on Cloud infrastructures. In this talk we discuss some issues surrounding engineering Software Services for Cloud infrastructures and highlight the need for enhanced control, service-level agreement and compliance mechanisms for Software Services. Cloud Infrastructures and Service Mash-ups.", "num_citations": "2\n", "authors": ["347"]}
{"title": "Dynamic verification and control of mobile peer-to-peer systems\n", "abstract": " The development of dependable mobile P2P systems is an inherently challenging task since such systems may operate in largely uncontrolled environments and may engage new peers or lose existing ones without any form of centralised control. In these circumstances, dependability and security can be enhanced through the runtime monitoring (a.k.a. dynamic verification) of the compliance of the system behaviour against specific dependability and security properties and the execution of control in cases where properties are violated. In this paper we present a framework for the dynamic verification and control of mobile P2P systems, which uses peer-specific monitoring policies to specify application-level properties. The deployment of this framework for monitoring system behaviour adds an extra layer of security and dependability checking, which is independent from checks performed directly by the P2P system\u00a0\u2026", "num_citations": "2\n", "authors": ["347"]}
{"title": "Supporting the Construction of Decision Models for Software Selection: Towards a Probabilistic Traceability Approach\n", "abstract": " This paper describes an approach to the problem of constructing software package selection models. This approach is based on an analysis of the contents of package description documents using rules which can:(i) extract selection criteria from descriptions of package features,(ii) structure the extracted criteria in a package selection model, and (iii) trace these criteria onto descriptions of other package features which have the potential of satisfying them.", "num_citations": "2\n", "authors": ["347"]}
{"title": "CYRA: A Model-Driven CYber Range Assurance Platform\n", "abstract": " Digital technologies are facilitating our daily activities, and thus leading to the social transformation with the upcoming 5G communications and the Internet of Things. However, mainstream and sophisticated attacks are remaining a threat, both for individuals and organisations. Cyber Range emerges as a promising solution to effectively train people in cybersecurity aspects. A Training Programme is considered adequate only if it can adapt to the scope of the attacks they cover and if the trainees apply the learning material to the operational system. Therefore, this study introduces the model-driven CYber Range Assurance platform (CYRA). The solution allows a trainee to be trained for known and new cyber-attacks by adapting to the continuously evolving threat landscape and examines if the trainees transfer the acquired knowledge to the working environment. Furthermore, this paper presents a use case on an operational backend ICT system, showing how the CYRA platform was utilised to increase the security posture of the organisation. View Full-Text", "num_citations": "1\n", "authors": ["347"]}
{"title": "Teaching Users New IoT Tricks: A Model-driven Cyber Range for IoT Security Training\n", "abstract": " As IoT ecosystems become mainstream, malicious actors routinely launch impactful attacks that affect both organizations and individuals-eg, see the Mirai IoT botnet and its variants, and the intensification of these attacks in the COVID-19 era-ultimately corroding our trust in IoT applications and services.While a barrier in tackling these issues is the existence of heterogeneous IoT applications and devices with inherent security flaws [1][2], the situation is further exacerbated by the lack of cybersecurity awareness and training. Users are typically not informed of the relevant risks and how to minimize them, nor are they trained to promptly identify and react to cyber-attacks (eg, IoT botnets [3], and COVID-19-focused ones [4])). Instead, users act as enablers for the various threat actors to deploy attacks successfully, and this is true both for enterprise [5](eg, Industrial IoT) as well as consumer [6](eg, smart home) environments.", "num_citations": "1\n", "authors": ["347"]}
{"title": "Pairing a Circular Economy and the 5G-Enabled Internet of Things: Creating a Class of? Looping Smart Assets?\n", "abstract": " The increase in the world's population has led to a massive rise in human consumption of the planet's natural resources, well beyond their replacement rate. Traditional recycling concepts and methods are not enough to counter such effects. In this context, a circular economy (CE), that is, a restorative and regenerative by-design economy, can reform today's \"take-make-dispose\" economic model. On the other hand, the Internet of Things (IoT) continues to gradually transform our everyday lives, allowing for the introduction of novel types of services while enhancing legacy ones. Taking this as our motivation, in this article we analyze the CE/IoT interplay, indicating innovative ways in which this interaction can drastically affect products and services, their underlying business models, and the associated ecosystems. Moreover, we present an IoT architecture that enables smart object integration into the IoT ecosystem\u00a0\u2026", "num_citations": "1\n", "authors": ["347"]}
{"title": "Secure Semantic Interoperability for IoT Applications with Linked Data\n", "abstract": " Interoperability stands for the capacity of a system to interact with the units of another entity. Although it is quite easy to accomplish this within the products of the same brand, it is not facile to provide compatibility for the whole spectrum of the Internet-of-Things (IoT) and the Linked Data (LD) world. Currently, the different applications and devices operate in their own cloud/platform, without supporting sufficient interaction with different vendor-products. As it concerns the meaning of data, which is the main focus of this paper, semantics can settle commonly agreed information models and ontologies for the used terms. However, as there are several ontologies for describing each distinct 'Thing', we need Semantic Mediators (SMs) in order to perform common data mapping across the various utilized formats (i.e. XML or JSON) and ontology alignment (e.g. resolve conflicts). Our goal is to enable end-to-end vertical\u00a0\u2026", "num_citations": "1\n", "authors": ["347"]}
{"title": "Towards the insurance of healthcare systems\n", "abstract": " Insurance of digital assets is becoming an important aspect nowadays, in order to reduce the investment risks in modern businesses. GDPR and other legal initiatives makes this necessity even more demanding as an organization is now accountable for the usage of its client data. In this paper, we present a cyber insurance framework, called CyberSure. The main contribution is the runtime integration of certification, risk management, and cyber insurance of cyber systems. Thus, the framework determines the current level of compliance with the acquired policies and provide early notifications for potential violations of them. CyberSure develops CUMULUS certification models for this purpose and, based on automated (or semi-automated) certification carried out using them, it develops ways of dynamically adjusting risk estimates, insurance policies and premiums. In particular, it considers the case of dynamic\u00a0\u2026", "num_citations": "1\n", "authors": ["347"]}
{"title": "Multiparametric data analysis for diagnostic decision support in balance disorders\n", "abstract": " In this work we present a framework for the analysis and mining of multiparametric data related to balance disorders. The overall concept is to define the schema of the analysis that provides optimal results for diagnostic decision support in balance disorders. The work is part of the integrated EMBalance platform which targets the management of patients with balance disorders, from the diagnosis to treatment and evolution of the disease. The obtained results in four different balance disorders range from 76.4% to 92.1%.", "num_citations": "1\n", "authors": ["347"]}
{"title": "Diagnosis of balance disorders using decision support systems based on data mining techniques\n", "abstract": " In this work we present the decision support of the EMBalance platform. EMBalance is a platform for the management of balance disorders in terms of diagnosis, treatment and evolution. The EMBalance platform aims to extend existing but generic and currently uncoupled balance modelling activities leading to a multi-scale and patient-specific balance model, which will be incorporated in a Decision Support System (DSS), towards the early diagnosis, prediction and the efficient treatment planning of balance disorders. The diagnosis part of the decision support system uses various data ranging from demographic characteristics to clinical examinations, auditory and vestibular tests. Currently we present some initial technical choices and indicative results of the decision support system for diagnosing balance disorders, based on data mining techniques and clinical guidelines.", "num_citations": "1\n", "authors": ["347"]}
{"title": "Assessing the genuineness of events in runtime monitoring of cyber systems\n", "abstract": " Monitoring security properties of cyber systems at runtime is necessary if the preservation of such properties cannot be guaranteed by formal analysis of their specification. It is also necessary if the runtime interactions between their components that are distributed over different types of local and wide area networks cannot be fully analyzed before putting the systems in operation. The effectiveness of runtime monitoring depends on the trustworthiness of the runtime system events, which are analyzed by the monitor. In this paper, we describe an approach for assessing the trustworthiness of such events. Our approach is based on the generation of possible explanations of runtime events based on a diagnostic model of the system under surveillance using abductive reasoning, and the confirmation of the validity of such explanations and the runtime events using belief based reasoning. The assessment process that\u00a0\u2026", "num_citations": "1\n", "authors": ["347"]}
{"title": "D2. 2 Certification models\n", "abstract": " The freedom of choice given by dynamic software provisioning on the cloud needs to be reconciled with the apparently conflicting requirement of making sure that software systems have the appropriate assurance levels for the intended purpose. In the case of security, influential guidelines like the US-\u2010NIST Special Publication (SP) 800-\u201037s mandate users to check at the time of use that software systems hold the desired set of security properties. This requirement is very difficult to satisfy in a cloud-\u2010based service marketplace, and in general with any dynamic model of software provisioning.", "num_citations": "1\n", "authors": ["347"]}
{"title": "On the Move to Meaningful Internet Systems: OTM 2010: International Workshops: AVYTAT, ADI, DATAVIEW, EI2N, ISDE, MONET, OnToContent, ORM, P2P-CDVE, SeDeS, SWWS and OTMA\n", "abstract": " and ontologies, and CoopIS (CooperativeInformationSystems, since 1993), c-ering the application of these technologies in an enterprise context through, for example, work? ow systems and knowledge management. In 2007 the IS wo-shop (Information Security) was added to try covering also the speci? c issues of security in complex Internet-based information systems. Each of the main c-ferences speci? cally seeks high-quality contributions and encourages researchers to treat their respective topics within a framework that incorporates jointly (a) theory,(b) conceptual design and development, and (c) applications, in part-ular case studies and industrial solutions. Following and expanding the model created in 2003, we again solicited and selected quality workshop proposals to complement the more \u201carchival\u201d nature of the main conferences with research results in a number of selected and more \u201cavant-garde\u201d areas related to the general topic of Web-based distributed c-puting. For instance, the so-called Semantic Web has given rise to several novel research areas combining linguistics, information systems technology and ar-? cial intelligence, such as the modeling of (legal) regulatory systems and the ubiquitous nature of their usage. We were glad to see that seven of our s-cessful earlier workshops (ADI, EI2N, SWWS, ORM, OnToContent, MONET, ISDE) re-appearedin 2010 with, in some cases, a fourth or even? fth edition,-ten in alliance with other older or newly emerging workshops, and that no fewer than four brand-new independent workshops could be selected from proposals and hosted: AVYTAT, DATAVIEW, P2PCDVE, SeDeS.", "num_citations": "1\n", "authors": ["347"]}
{"title": "Formal methods in model-driven development for service-oriented and cloud computing\n", "abstract": " Configuration of monitoring systems aligned with agreement and guarantees expressed in Service-Level Agreements (SLAs) can be a complex and time-consuming activity. For monitoring functional and non-functional aspects of services, the EU project SLA@ SOI has developed a model and language set to describe such SLAs aligning with a service monitoring system architecture for run-time monitoring. In this work we show how these models are formally and mechanically decomposed into terms and primitive events, whilst monitoring component selection for these terms and events is used to generate a complete monitoring system configuration for run-time.", "num_citations": "1\n", "authors": ["347"]}
{"title": "Service Discovery for Service Centric Systems\n", "abstract": " A service discovery process for engineering service-centric systems (SCS) is proposed. Current software engineering practice is extended by explicitly including the discovery of existing services in a way that the services are composed into the SCS being developed. A number of different stakeholder roles are assisted by the process, which is divided in three main activities: Early Service Discovery (ESD), Architecture-driven Service Discovery (ASD), and Run-time Discovery (RTD). ESD and ASD are iterative activities that help the revision of system requirements, and architecture and design models, respectively. RTD ensures the resilience and re-configurability of SCS when services fail or start malfunctioning. The specific techniques used for discovery include information retrieval, similarity matching, and goal-based reasoning. Tools and prototypes to support ESD, ASD, and RTD are being developed and evaluated by our industrial partners.", "num_citations": "1\n", "authors": ["347"]}
{"title": "Information Monitors: An Architecture Based on XML\n", "abstract": " In this paper we present an approach to allow monitoring of XML documents on the World Wide Web. We describe a distributed information monitoring architecture based on monitor rules. The architecture preserves the autonomy of the participating documents and allows evolution of the system by adding, removing and modifying XML documents. In order to illustrate the approach we present an example in the financial domain.", "num_citations": "1\n", "authors": ["347"]}
{"title": "Evidential Management of Inconsistencies in Object Interaction Models\n", "abstract": " This paper presents Reconciliation+, a tool-supported method which identifies overlaps between models of different object interactions expressed as UML sequence and/or collaboration diagrams, checks whether the overlapping elements of these models satisfy specific consistency rules, and guides developers in handling these inconsistencies. The method also keeps track of the decisions made and the actions taken in the process of managing inconsistencies. Thus, it covers the entire spectrum of the activities of what is known in the literature as\" inconsistency management\".", "num_citations": "1\n", "authors": ["347"]}
{"title": "Quantitative assessment of the significance of inconsistencies in object-oriented designs\n", "abstract": " This paper presents a framework for assessing the significance of inconsistencies which arise in object-oriented design models that describe systems from multiple perspectives. The framework allows the definition of significance criteria and measures the significance of inconsistencies as beliefs for the satisfiability of these criteria.", "num_citations": "1\n", "authors": ["347"]}
{"title": "Integrating Specifications\n", "abstract": " Requirements analysis usually results into a set of different specifications for the same system, which must be integrated. Integration involves elimination of discrepancies completion and validation and proceeds in stages of analysis and synthesis. Realizing that discrepancies between specifications may be due to differences in representation models and/or modeling perspectives and practices, we propose an approach to the analysis stage using meta-modeling and similarity analysis, whereby comparison of components is achieved through their classification under domain-and model-independent abstractions, and a newly developed model of similarity. Similarity analysis results into an isomorphic mapping between specification elements that can be used as a basis for negotiating their merging.", "num_citations": "1\n", "authors": ["347"]}