{"title": "Automatic test case generation using unified modeling language (UML) state diagrams\n", "abstract": " UML is widely accepted and used by industry for modelling and design of software systems. A novel method to automatically generate test cases based on UML state models is presented. In the present approach, the control and data flow logic available in the UML state diagram to generate test data are exploited. The state machine graph is traversed and the conditional predicates on every transition are selected. Then these conditional predicates are transformed and function minimisation technique is applied to generate test cases. The present test data generation scheme is fully automatic and the generated test cases satisfy transition path coverage criteria. The generated test cases can be used to test class as well as cluster-level state-dependent behaviours.", "num_citations": "119\n", "authors": ["1911"]}
{"title": "Enhanced bee colony algorithm for efficient load balancing and scheduling in cloud\n", "abstract": " Cloud computing is a promising paradigm which provides resources to customers on their request with minimum cost. Cost effective scheduling and load balancing are major challenges in adopting cloud computation. Efficient load balancing methods avoids under loaded and heavy loaded conditions in datacenters. When some VMs are overloaded with several number of tasks, these tasks are migrated to the under loaded VMs of the same datacenter in order to maintain Quality of Service (QoS). This paper proposes a modification in the bee colony algorithm for efficient and effective load balancing in cloud environment. The honey bees foraging behaviour is used to balance load across virtual machines. The tasks removed from over loaded VMs are treated as honeybees and under loaded VMs are the food sources. The method also tries to minimize makespan as well as number of VM migrations. The\u00a0\u2026", "num_citations": "96\n", "authors": ["1911"]}
{"title": "Automatic test case generation from UML communication diagrams\n", "abstract": " We present a method to generate cluster level test cases based on UML communication diagrams. In our approach, we first construct a tree representation of communication diagrams. We then carry out a post-order traversal of the constructed tree for selecting conditional predicates from the communication diagram. We transform the conditional predicates on the communication diagram and apply function minimization technique to generate the test data. The generated test cases achieve message paths coverage as well as boundary coverage. We have implemented our technique and tested it on several example problems.", "num_citations": "82\n", "authors": ["1911"]}
{"title": "Test sequence generation from UML sequence diagrams\n", "abstract": " In this paper, we present an approach to generate test sequences from UML 2.0 sequence diagrams. Sequence diagrams are one of the most widely used UML models in the software industry. Although sequence diagrams are used for modeling the dynamic aspects of the system, they can also be used for model based testing. Existing work does not encompass certain important features of UML 2.0 sequence diagrams. Our work considers many of the novel features of UML 2.0 sequence diagrams like alt, loop, opt and break to generate test sequences. These areimportant features as far as testing is concerned. Our work begins with defining the important types of relationship that can exist between the messages. Based on the relationship between the messages, the message sequences are generated. Our work considers an important feature of UML 2.0 sequence diagrams called the dasiaExecution\u00a0\u2026", "num_citations": "56\n", "authors": ["1911"]}
{"title": "Slicing-based test case generation from UML activity diagrams\n", "abstract": " UML diagrams are important design and modeling artifacts. These diagrams can also be used to generate test cases. We present a novel test case generation method that is based on dynamic slicing of UML activity diagrams. We use flow dependence graph (FDG) of an activity diagram to generate dynamic slices. Dynamic slices are created using an edge marking method. Slices are constructed corresponding to each conditional predicate on activity edges and test cases are automatically generated with respect to each slice. Our generated test cases satisfy path coverage criterion. Our test data generation scheme is automatic and the test data is generated considering the slice condition. We have implemented our approach to realize a prototype tool.", "num_citations": "52\n", "authors": ["1911"]}
{"title": "A novel test case design technique using dynamic slicing of UML sequence diagrams\n", "abstract": " We present a novel methodology for test case generation based on UML sequence diagrams. We create message dependence graphs (MDG) from UML sequence diagrams. Edge marking dynamic slicing method is applied on MDG to create slices. Based on the slice created with respect to each predicate on the sequence diagram, we generate test data. We formulate a test adequacy criterion named slice coverage criterion. Test cases that we generate achieves slice coverage criterion. Our approach achieves slice test coverage with few test cases. We generate effective test cases for cluster level testing.", "num_citations": "36\n", "authors": ["1911"]}
{"title": "Uml sequence diagram based testing using slicing\n", "abstract": " We present a novel testing methodology to test object oriented software based on UML sequence diagrams. In our approach we use dynamic slicing and generate test cases automatically from UML sequence diagrams. We identify the message guards on sequence diagrams and create dynamic slices with respect to each conditional predicates. We generate the test data with respect to the slice. We have formulated a test adequacy criterion named slice coverage criterion. Test cases that we generate satisfy slice test coverage. Our approach achieves adequate test coverage without unduly increasing the number of test cases. This paper also describes how dynamic slicing is used in testing.", "num_citations": "34\n", "authors": ["1911"]}
{"title": "Load balancing of tasks in cloud computing environment based on bee colony algorithm\n", "abstract": " Cloud computing is an emerging computing paradigm in which shared resources are provided according to the customer request at specific time. Load balancing is the process of distributing workload among various nodes of the computing system. The load can be CPU load, memory capacity, or network load. An efficient load balancing avoids a situation where some of the nodes are heavily loaded while other nodes are idle or doing very little work. When Virtual Machine (VM) is overloaded with multiple tasks, these tasks are removed and migrated to the under loaded VMs of the same or different datacenter. This paper proposes a bee colony based algorithm for efficient load balancing, which is based on the foraging behavior of honey bees to balance load across VMs. In the proposed method, tasks removed from over loaded VMs are treated as honey bees and under loaded VMs are the food sources. The\u00a0\u2026", "num_citations": "30\n", "authors": ["1911"]}
{"title": "Virtual machine placement for improved quality in IaaS cloud\n", "abstract": " Cloud computing, with its immense potentials in low cost and on-demand services, is a promising computing platform for both commercial and non-commercial computation applications. It focuses on the sharing of information and computation in a large network that are quite likely to be owned by geographically disbursed different vendors. The proposed Bin packing based algorithm tries to maximize the resource utilization in a cloud datacenter and thereby increasing the profit of that cloud provider. In the proposed system, Best-fit -- Worst-fit strategy efficiently places the virtual machines to the less number of active physical servers. The jobs are scheduled using best-fit approach. The cloud broker employs worst-fit method for VM placement. The simulation result shows the significant improvements in the performance of the cloud system.", "num_citations": "28\n", "authors": ["1911"]}
{"title": "Web services regression test case prioritization\n", "abstract": " Web services and their underlying system grow over time and need to be retested whenever there is a change. This is essential for ensuring uncompromised quality. If we have modified only a small part of the system, it should be possible to reuse the existing test suite. Anyhow, for large modifications or for large systems, retesting the entire test suite will consume large amounts of time and computing resources. In this paper we propose a new method to prioritize test cases in web applications. Our test prioritization technique orders test cases in such a way that the most beneficial is executed first. Most of the existing test prioritization methods are based on the code of the system, but we propose a model-based test prioritization using activity diagram. Our technique identifies difference between original model and modified model. Using this information we plot activity paths for each test case and identify the most\u00a0\u2026", "num_citations": "27\n", "authors": ["1911"]}
{"title": "Self-organized key management with trusted certificate exchange in MANET\n", "abstract": " In MANET, security is more challenging due to problems related to key exchange. It is necessary to secure the exchanges in MANETs for assuring the development of services in the network. The self-organized MANET is visualized as a key communication technology enabler for application such as network centric warfare, disaster relief operations, emergency situations, and intelligent transportation systems. In this paper, we propose a self-organized key management technique coupled with trusted certificate exchange for mobile ad hoc networks. The proposed architecture consists of one coordinator node, servers and normal mobile nodes. The coordinator acts as a mediator for transmitting the message among the servers and mobile nodes. Each node generates its own public/private key pairs using server-signed public keying technique. Then multi-path certificate exchange technique is employed where public\u00a0\u2026", "num_citations": "25\n", "authors": ["1911"]}
{"title": "Automatic code generation using unified modeling language activity and sequence models\n", "abstract": " A fully automatic translation of unified modeling language (UML) models to complete source code is not reported so far because some implementation details will not be there in the model, or a single UML model is not enough for complete code generation, or some model elements may not be directly convertible to source code. These issues are addressed in this study. The authors take workflow modelling and automation as the focus of their research. Hence, UML activity diagram is considered. Activity diagram alone cannot give the implementation details like object interactions. A formal association is found between activity and sequence diagrams to add object interaction details to the work flow. Moreover, the authors formulate an algorithm,  Am_To_Prototype , which is composed of two subroutines named  Method_Body & Excecution_Logic , to generate code from the combined model of activity and sequence\u00a0\u2026", "num_citations": "24\n", "authors": ["1911"]}
{"title": "Automatic code generation from UML state chart diagrams\n", "abstract": " The fact that event driven systems can be modeled and implemented using unified modeling language (UML) state chart diagrams has led to the development of code generation tools. These are tremendously helpful in making software system designs and can even generate skeletal source code from these designs. The implementation of such automatic code generation from state diagrams is not fully supported by the existing programming languages. The major down side is that there is no one-to-one correspondence between the elements in the state chart diagram and the programming constructs. The existing programming elements cannot effectively implement two main components of the state diagram namely, state hierarchy and concurrency. In this paper, we present a novel design pattern for the implementation of the state diagram which includes hierarchical, concurrent, and history states. The state\u00a0\u2026", "num_citations": "20\n", "authors": ["1911"]}
{"title": "Boundary value testing based on uml models\n", "abstract": " We present a novel method to automatically generate test cases based on UML state chart specifications. In our approach, we transform the conditional predicates on state transitions and apply function minimization technique to generate the test data. We use boundary value testing methods to generate effective test cases that satisfy test coverage criteria like full predicate coverage criteria and transition path coverage criteria. Our approach achieves adequate test coverage without unduly increasing the number of test cases. The test cases are generated for class as well as cluster level testing.", "num_citations": "20\n", "authors": ["1911"]}
{"title": "Relative Extraction Methodology for class diagram generation using dependency graph\n", "abstract": " Requirement analysis is the preliminary step in software development process. The requirements stated by the clients are analyzed and an abstraction of it is created which is termed as requirements model. Unified Modeling Language (UML) models are helpful for understanding the problems, communicating with application experts and preparing documentation. The static design view of the system can be modeled using a UML class diagram. System requirements stated by the user are usually in natural language form despite a wide variety of formal languages and UML. This is an imprecise and inconsistent form which is difficult to be used by the developer for design. We present a new methodology for generating UML class diagrams or models from natural language problem statement or requirement specification. We have named our methodology as Relative Extraction Methodology which uses an\u00a0\u2026", "num_citations": "18\n", "authors": ["1911"]}
{"title": "Synthesize of high speed floating-point multipliers based on Vedic mathematics\n", "abstract": " This work proposes designing of high speed floating point multipliers. The multipliers are designed using Vedic Mathematics. The Vedic Multiplier (VM) has a regular structure therefore can be easily layout in a Silicon chip. Two different VMs are designed with different adder structures viz. Ripple Carry Adder (RCA) and Carry Look-ahead Adder (CLA). A single precision floating point multiplier is designed with these two VM structures. The multipliers are structurally modeled in Verilog HDL. The simulation and synthesis are done in Xilinx\u00ae ISE 14.2. A comparison on the basis of area, power and delay is performed on Virtex-5 (xc5vlx110tff1136-1).", "num_citations": "17\n", "authors": ["1911"]}
{"title": "Evolution or revolution: the critical need in genetic algorithm based testing\n", "abstract": " Software testing is one of the most inevitable processes in software development. The field of software testing has seen an extensive use of search based techniques in the last decade. Among the search based techniques, it is the metaheuristic techniques such as genetic algorithm that has garnered the major share of attention from researchers. Looking at the large body of work that has happened and is happening in this field, we feel that it is high time someone studied how well genetic algorithm based techniques fare in practical testing process. Method: In this work, we present a roadmap to the future of genetic algorithm based software testing, based on a review of literature. We have mainly reviewed the works which use genetic algorithm for software test data generation. This independent review is designed to direct the attention of future researchers to the deficiencies of genetic algorithm based\u00a0\u2026", "num_citations": "16\n", "authors": ["1911"]}
{"title": "Role of gateways in MANET integration scenarios\n", "abstract": " Background/Objectives: Mobile Ad Hoc Network, an auto configured wireless network using mobile devices without a predefined infrastructure can be integrated with infrastructure based network to overcome the problems in following networks. Methods/Statistical analysis: Integrating two entirely different communication technologies have enormous challenges. The integration process requires an intermediate entity named Gateway for connecting entirely different networks. This paper analyze the role played by gateway in solving issues related with integration using Mobile Ad Hoc Network in various heterogeneous networks and the various phases in communication between two networks using gateways. Findings: Recent researches in Green Communication, Machine to Machine Networks, Internet of Things, Device to Device Communication explores the use of Mobile Ad hoc Networks in deploying future wireless networks with less cost and overhead. This paper reviews various categories of networks so far integrated with Mobile Ad-hoc networks, issues discovered in such integration scenarios and importance of different gateways used in integration architectures. Paper also compared different gateway discovery and selection schemes so far adopted in integration scenarios. Applications/", "num_citations": "16\n", "authors": ["1911"]}
{"title": "A content-based image retrieval system based on polar raster edge sampling signature\n", "abstract": " Content Based Image Retrieval (CBIR) is used to effectively retrieve required images from fairly large databases. CBIR extracts images that are relevant to the given query image, based on the features extracted from the contents of the image. Most of the CBIR systems available in the literature are not rotation and scale invariant. Retrieval efficiency is also poor. In this paper, shape features are extracted from the database images and the same are polar raster scanned into specified intervals in both radius and angle, using the proposed Polar Raster Edge Sampling Signature (PRESS) algorithm. Counts of edge points lying in these bins are stored in the feature library. When a query image passed on to the system, the features are extracted in the similar fashion. Subsequently, similarity measure is performed between the query image features and the database image features based on Euclidian Distance similarity measure and the database images that are relevant to the given query image are retrieved. PRESS algorithm has been successfully implemented and tested in a CBIR System developed by us. This technique preserves rotation and scale invariance. It is evaluated by querying different images. The retrieval efficiency is also evaluated by determining precision-recall values for the retrieval results.", "num_citations": "16\n", "authors": ["1911"]}
{"title": "Concept networks for personalized web search using genetic algorithm\n", "abstract": " Web search engines gives users an initial point for their information hunt. The problem with the traditional search engine is that it retrieves the same set of web pages for all users even though each user has their own preference for a particular search. For retrieving web pages based on user's preference personalized search is needed. The main drawback of this method is that it cannot provide accurate result when user's preference changes or have to search something new. In the proposed method, a concept network is created to identify users search preferences. This concept network consists of list of related concepts based on the history of users\u2019 previous search. This policy helps to retrieve web pages related to the context in which the user needs information. Genetic Algorithm (GA) is used when user searches for something new. GA is used to compare the user's concept network with other user's concept\u00a0\u2026", "num_citations": "15\n", "authors": ["1911"]}
{"title": "Service\u2010level agreement\u2013aware scheduling and load balancing of tasks in cloud\n", "abstract": " Cloud computing is an innovative computing paradigm designed to provide a flexible and low\u2010cost way to deliver information technology services on demand over the Internet. Proper scheduling and load balancing of the resources are required for the efficient operations in the distributed cloud environment. Since cloud computing is growing rapidly and customers are demanding better performance and more services, scheduling and load balancing of the cloud resources have become very interesting and important area of research. As more and more consumers assign their tasks to cloud, service\u2010level agreements (SLAs) between consumers and providers are emerging as an important aspect. The proposed prediction model is based on the past usage pattern and aims to provide optimal resource management without the violations of the agreed service\u2010level conditions in cloud data centers. It considers SLA in\u00a0\u2026", "num_citations": "14\n", "authors": ["1911"]}
{"title": "Software requirement elicitation using natural language processing\n", "abstract": " Software requirements are usually written in natural language or speech language which is asymmetric and irregular. This paper presents a suitable method for transforming user software requirement specifications (SRS) and business designs written in natural language into useful object oriented models. For sentence detection, tokenization, parts of speech tagging and parsing of requirement specifications we incorporate an open natural language processing (OpenNLP)tool. It provides very relevant parts of speech (POS) tags. This parts of speech tagging of the SRS is quite useful for further identification of object oriented elements like classes, objects, attributes, relationships etc. After obtaining the required and relative information, Semantic Business Vocabulary and Rules (SBVR) are applied to identify and to extract the object oriented elements from the requirement specification.", "num_citations": "13\n", "authors": ["1911"]}
{"title": "Interference aware prediction mechanism for auto scaling in cloud\n", "abstract": " Advancements in cloud computing has transformed it into the most promising computing paradigm for business organizations. In a dynamic cloud environment, Virtual Machine (VM) migration is a critical step in resource management, especially in large scale datacenters. Most of the VM migration and load balancing policies are based on power consumption and response time, with little attention on the interferences caused due to VM migrations. Such interferences degrade the overall performance of the system, and consequently violates the service level agreement (SLA) between the customer and the provider. This paper introduces an interference aware prediction mechanism for VM migration, with auto scaling. The automatic scaling policies help to handle sudden load changes with precise prediction and minimum VM migration. The experimental results and comparative analysis show that the proposed model\u00a0\u2026", "num_citations": "11\n", "authors": ["1911"]}
{"title": "A distributed hierarchical key management scheme for mobile Ad hoc networks\n", "abstract": " In MANET, when a node is compromised it tends to reveal the other node's key information and corrupts the whole network. The scalable method of cryptographic key management (SMOCK) proposes a method to deal with such node compromise attacks. But it has certain main drawbacks such as over dependent on centralized server and increase in key-pair when node increases. To deal with these drawbacks, we present an enhanced hierarchical key management scheme using a stable and power efficient cluster management technique. Each cluster head retains the public key of its member nodes only and act as a router when dealing with nodes of other cluster members. Using this technique, the overhead on centralized server is reduced. Moreover, the need of each node storing all public keys are diminished thus minimizing the storage overhead on each node. By Simulation results, we show that our\u00a0\u2026", "num_citations": "10\n", "authors": ["1911"]}
{"title": "Enhancing UML activity diagrams using OCL\n", "abstract": " Business process automation is very much important for the customer satisfaction and for good productivity. UML Activity diagram is a behavioral diagram which is suitable to model business process. The activity diagram can be enhanced using Object Constraint Language (OCL). This elaboration will help us to include more implementation specific details in the activity diagram. In this paper we present different possibilities to include OCL in the activity diagram and their metamodels. The paper proposes an algorithm to convert the OCL statements to a target code. The OCL enhanced activity diagram can be converted to any target language like Java, C++ etc. In this paper we are converting the system design, represented in activity diagram, to Java code. We also present a prototype of the code generator named ActivityOCLKode and we evaluate the prototype with parameters like complexity, percentage of code\u00a0\u2026", "num_citations": "9\n", "authors": ["1911"]}
{"title": "An evolutionary multi population approach for test data generation\n", "abstract": " In this paper we propose an approach for test data generation using genetic algorithm. Our objective is to design a multi-population genetic algorithm using uniform crossover. In this paper we analyze the performance of proposed uniform crossover multi population genetic algorithm method with different combinations of factors that influence the test data generation strategy. For implementing multi-population genetic algorithm, random migration is used and individuals are added to the existing subpopulation. Here we have also compared the single population approach and multi-population approach to determine which of these are effective towards generation of test data. By combining the individuals in the subpopulation using uniform cross over the test data generated will have better chance of existence.", "num_citations": "9\n", "authors": ["1911"]}
{"title": "Improving the productivity in global software development\n", "abstract": " Globalization has led to the expansion of information technology and distributed software development. Most of the software development companies face various challenges in distributing the project. As a consequence of the dispersed nature of global software development projects, communication, coordination, and control become more difficult which adversely influence effort estimation of the software development. The major ingredients that impact software development productivity of globally distributed projects are project delivery rate, team size and communication complexity. The paper analyses the factors affecting the productivity of the globally distributed projects. The project distribution can be effectively done depending on the estimated productivity for the different sites. The project distribution to the multiple sites can be done in the order of decreasing productivity factor.", "num_citations": "8\n", "authors": ["1911"]}
{"title": "Impact of node density on node connectivity in manet routing protocols\n", "abstract": " The functioning of routing protocols in Mobile Ad-hoc Networks depends on factors like node mobility, node failure, broken paths, node connectivity and node density. These factors make the network dynamic. Due to the change in node connectivity, availability of link for data transfer data may vary. This paper discusses about Mobile Ad-Hoc environment with varying node density and its effect on node connectivity among MANET routing protocols. The performance of two routing protocols like DSDV from proactive routing protocols, AODV from reactive routing protocols are analyzed and compared. Quantitative metrics like normalized overhead, packet delivery ratio, number of control packets are evaluated using the Network Simulator NS-2. This paper helps in identifying the impact of varying node densities on the node connectivity in Mobile Ad-Hoc networks. The result of performance comparison can also\u00a0\u2026", "num_citations": "8\n", "authors": ["1911"]}
{"title": "Forward slicing algorithm based test data generation\n", "abstract": " In this paper we have suggested a new method for test data generation using dynamic forward slicing algorithm. Separating the suspicious parts of code from the original program will make the process of test data generation easier. In forward dynamic slicing, the slices produced are much smaller than the original program and the search space for testing is considerably reduced. In this paper, we discuss the forward algorithm and the advantages of using forward dynamic algorithm for test data generation. The test cases are generated by analyzing the constraints present in the slices constructed from forward dynamic slicing algorithm. In the proposed method, the program for which the test data to be generated is analyzed. Forward slicing of the program is done with respect to all the variables whose value is changed during program execution. Slices obtained are then verified for statements which define certain\u00a0\u2026", "num_citations": "8\n", "authors": ["1911"]}
{"title": "Fixing class design inconsistencies using self regulating particle swarm optimization\n", "abstract": " ContextThe practice of using Unified Modeling Language models during software development and the chances of occurrence of model inconsistencies during software design are increasing. Hence detection of intra-model design inconsistencies is significant in the development of quality software.ObjectiveThe existing approaches of detecting class attribute inconsistencies rely on human decision making. Manual detection of inconsistencies is exhaustive, time consuming and sometimes incomplete. Therefore, we propose an automated and novel approach to perform consistency check of class attributes using artificial intelligence.MethodInconsistency in attribute definition and specification is detected and fixed with self regulating particle swarm optimization (SRPSO) algorithm that uses a fitness function to optimize the consistency of attributes in class diagram and activity diagrams. SRPSO is preferred since the\u00a0\u2026", "num_citations": "7\n", "authors": ["1911"]}
{"title": "Query translation from SQL to XPath\n", "abstract": " Today XML is the de facto standard of data exchange format for the information on the Web. At the same time, database systems are well known for consistent storage, retrieval and manipulation of data. XML querying language (XPath) is used to access XML documents whereas Structured Query Language (SQL) for retrieving and manipulating data in relational database. It may not be possible for users and developers to be familiar with both the query languages easily and quickly. Here, we examine how XML data can be queried using SQL. In this paper, we propose a new concept and framework where SQL statements can be easily transformed to XPath expressions. We use SQL, as it has long been the standard language. Users can access XML database and relational database through the query language SQL using our framework. We present algorithms for translating queries expressed in SQL (SELECT\u00a0\u2026", "num_citations": "7\n", "authors": ["1911"]}
{"title": "Object constraint language for code generation from activity models\n", "abstract": " ContextAchieving hundred percent automation in code generation process from Unified Modeling Language (UML) models will make a drastic advancement in software industry. UML does not use a fully formalized semantics. So it leads to ambiguity during automatic implementation of UML models. These ambiguities can be avoided to a large extent using Object Constraint Language (OCL). OCL is formal and user friendly which is also familiar to industry people.ObjectiveThis paper examines how to improve the code generation from UML models, with the help of Object Constraint Language. It also explores the possibilities to incorporate OCL in UML activity models and generate code from the OCL enhanced activity diagrams.MethodMeta models for the association of OCL expressions with the UML activity diagram is proposed in the paper. OCL expressions are added as part of the UML activity models to improve\u00a0\u2026", "num_citations": "6\n", "authors": ["1911"]}
{"title": "Object oriented method to implement the hierarchical and concurrent states in UML state chart diagrams\n", "abstract": " The event driven systems can be modeled and implemented using UML state chart diagrams. Code generation tools are used in the software development for making software system designs and for automatically generating skeletal source code from the system designs. Many research works concentrate on the automatic code generation from the state diagrams. Unfortunately the existing Object oriented languages do not support the direct implementation of state diagrams. We cannot find a one to one mapping between elements in the state chart diagram and the Object oriented programming constructs. The two main components of state diagram that cannot be effectively implemented in object oriented way is state hierarchy and concurrency. In this paper, we present an implementation pattern for the state diagram which includes both hierarchical and concurrent states. The state transitions of parallel\u00a0\u2026", "num_citations": "6\n", "authors": ["1911"]}
{"title": "Performance analysis of big data gathering in wireless sensor network using an EM based clustering scheme\n", "abstract": " Big-data is a popular term in the field of information and communication technology. Wireless Sensor Networks (WSN) is one of the eminent contributors of big data. WSN contains numerous sensor nodes that cooperatively monitor an environment. Each network consists of sensor node, memory, and communication device. Data generated by single sensor node is small but data generated by distributed sensor network is significantly large and it is termed as big-data. The critical issue in WSN is energy consumption and data gathering. This paper mainly focus on Expectation Maximization (EM) based clustering scheme implementation and the performance analysis of WSN using single mobile sink to eight mobile sink. From the analysis we also derived a relationship between the number of mobile sinks required for a particular network with a given number of sensor nodes. Experimental results show that the number\u00a0\u2026", "num_citations": "6\n", "authors": ["1911"]}
{"title": "Lossless segment based DNA compression\n", "abstract": " This paper introduces a new Lossless Segment Based DNA Compression (LSBD) method for compressing the DNA sequences. It stores the individual gene position in a compressed file. Since LSBD method performs a gene wise compression, further processing of compressed data reduces memory usage. The biggest advantage of this algorithm is that it enables part by part decompression and can work on any sized data. Here the method identifies individual gene location and then constructs triplets that are mapped to an eight bit number. The individual gene information is stored in a pointer table and a pointer is provided to corresponding location in the compressed file. The LSBD technique appropriately compresses the non-base characters and performs well on repeating sequences.", "num_citations": "6\n", "authors": ["1911"]}
{"title": "A predictive clustering technique for effective key management in mobile ad hoc networks\n", "abstract": " In cluster-based key management techniques, the details of the mobile nodes are gathered always before joining or starting the clustering process,which produces congestion and additional overhead. In this paper, to reduce overhead and congestion of a cluster head, we propose a predictive clustering technique for effective key management. The predictive technique predicts the node movement and proactively sends information in cases of cluster movement. The combined metric for prediction is estimated based on route expiration time and node velocity. In key management technique, each cluster head retains the public key of its member nodes only and act as a router when dealing with nodes of other cluster members. Using this technique, the overhead on centralized key management schemes is reduced. Moreover, the need of each node storing all public keys is diminished, thus minimizing the storage\u00a0\u2026", "num_citations": "6\n", "authors": ["1911"]}
{"title": "Open NLP based refinement of software requirements\n", "abstract": " Software requirements are usually written in natural language (NL) or speech language which is asymmetric and irregular. This paper presents a suitable method for transforming user software requirement specifications (SRS) and business designs written in natural language into useful object oriented models. Here a neoteric approach is proposed to generate object oriented items from SRS. For NL processes like sentence detection, tokenization, parts of speech tagging and parsing of requirement specifications we incorporate an open natural language processing (OpenNLP) tool. It provides very relevant parts of speech (POS) tags. This parts of speech tagging of the SRS is quite useful for further identification of object oriented elements like classes, objects, attributes, relationships etc. After obtaining the required and relative information, Semantic Business Vocabulary and Rules (SBVR) are applied to identify and to extract the object oriented elements from the NL processed requirement specifications.", "num_citations": "5\n", "authors": ["1911"]}
{"title": "Translation of behavioral models to source code\n", "abstract": " It is a wonderful idea to directly execute the system designs. In this paper we are introducing a method to convert the behavioral models to the implementation code. UML is used for modeling and Java is used as the target language. This paper describes how a system design depicted using activity, sequence and state machine diagrams can be converted to its implementation code. Activity diagram helps to make the outline of the source program, and the sequence and state machine diagrams contribute to the expansion of the source code. We are using an MDA approach where the system design is done in Platform Independent Model (PIM), then converted to Platform Specific Model (PSM) and finally to implementation code. One tool is implemented based on our method and it is evaluated against some other existing tools.", "num_citations": "5\n", "authors": ["1911"]}
{"title": "Domain ontology based class diagram generation from functional requirements\n", "abstract": " Domain ontology formally represents knowledge as a set of concepts within a domain, and the relationships among those concepts. This paper proposes a method to generate class diagram from functional requirement specification which is written in natural language by using Domain ontology and Natural language processing techniques. Major steps in this method are identification of nouns and verbs from requirement specification statements and linking them with the ontology. From the ontology we get information about core concepts and relationships among those concepts. Thus domain ontology helps in the identification of classes, attributes and relationships for the particular domain for which the system is to be developed.", "num_citations": "5\n", "authors": ["1911"]}
{"title": "Improving design quality by automatic verification of activity diagram syntax\n", "abstract": " The quality of the product is an important issue in software development and quality assurance is an important aspect of any software design. One of the factors that affect the software quality is the correctness of its design. Any defect in the design can lead to high cost for defect correction. Activity diagrams are used to model the dynamic or behavioral aspects of the system. In this paper, an algorithm that analyzes activity diagrams and automatically verifies the syntax of each of its components is presented. Incomplete workflow can lead to incorrect results and a missing edge can lead to incomplete workflow. Mismatch in fork, join pair can lead to concurrency issues and synchronization problems. Detection of such errors in the design phase ensures product quality. The activity diagram is transformed to its components and analysis is performed on the components based on the syntactic specifications to detect errors\u00a0\u2026", "num_citations": "5\n", "authors": ["1911"]}
{"title": "Code clones in program test sequence identification\n", "abstract": " In this work, we have emphasized the need for software clones in test sequence identification. We have provided some relevant features of code clones which make them apt in assisting test sequence identification. In this paper, we have pointed out the relevance of automated test sequence generation in software development life cycle and we have also presented a classification of clones. We have used program slicing technique to obtain slices of the source program and from these slices software code clones are identified. The main contribution of this work is to highlight the relevance of code clones in test sequence identification and the importance of using program slicing in code clone detection. Applying both static and forward dynamic slicing techniques will make code clone detection more factual. We have also mentioned the need for mapping of values in test sequence identification.", "num_citations": "5\n", "authors": ["1911"]}
{"title": "Document Type Definition for the XMI Representation of UML2. 0 Activity Diagram\n", "abstract": " Definition (DTD) to represent UML activity diagram in XMI (XML Metadata Interchange) format. DTDs are important as far as automatic code generation is concerned. Our proposed DTD considers the activity diagram as a graph. The elements in the activity diagram are nodes and edges. The old versions (1. x) of the UML DTDs describe the activity diagram as a special type of state machine. The proposed DTD is based on UML 2.0, where the activity diagram semantics is rooted in Petri Nets rather than state machines. The proposed DTD defines the tags for different types (action, decision, initial, final etc.) of nodes in the activity diagram and the attributes required for the edges. Each node and edge in the activity diagram can be mapped to the respective XMI tags using this DTD. This can be done in sequential manner. The paper also describes how this DTD is used in the conversion of activity diagram to XMI format, and an algorithm for the conversion process.", "num_citations": "5\n", "authors": ["1911"]}
{"title": "Analysis and modeling of resource management overhead in Hadoop YARN Clusters\n", "abstract": " Hadoop clusters are widely used distributed computing framework for big data processing. Yet Another Resource Negotiator (YARN) was introduced in Hadoop 2.0 and it provides container based resource partitioning and allocation to subdivided units of computation. Hadoop YARN in combination with Hadoop Distributed File System (HDFS) possess almost all the characteristics of a distributed operating system. A container consists of Java virtual machines initiated with dedicated allocation of memory and CPU shares. When jobs are split into small tasks and scheduled to run on containers created dynamically on the nodes of a cluster, the resource management overhead will have significant impact on the execution time of applications. This overhead depends on number of component tasks into which the job gets split. The work presented in this paper evaluates the resource management overhead in Hadoop\u00a0\u2026", "num_citations": "4\n", "authors": ["1911"]}
{"title": "Study of execution parallelism by resource partitioning in Hadoop YARN\n", "abstract": " Hadoop YARN is a widely used distributed computing framework mainly used for big data processing. Yet Another Resource Negotiator (YARN) was introduced in Hadoop 2.0 to solve the scalability issues of the earlier realization. Hadoop YARN in combination with Hadoop Distributed File System (HDFS) can be considered as a distributed operating system with capabilities similar to that of the proprietary Tandem Nonstop kernel. Now it is possible to use YARN as a general purpose framework for distributed computing. When a job is divided into tasks and distributed among the nodes of a cluster and further distributed on different CPU cores of the nodes, parallelism in the execution of tasks plays a major role in the completion time of jobs. In distributed computing frameworks, a global scheduler distributes the tasks of the workloads among the nodes and the local schedulers manages the tasks submitted to the\u00a0\u2026", "num_citations": "4\n", "authors": ["1911"]}
{"title": "Optimal sensor selection from sensor pool in IoT environment\n", "abstract": " Internet of Things (IoT) is the technique to connect each and everything to Internet, and it provides anything at anytime regardless of where the thing is located. If we connect devices in this way, by 2020, billions of devices will get connected to the Internet. The current trends shows that the deployment of sensors and IoT paradigm growing in a rapid pace. This shows that the next information revolution will be Internet of Everything (IoE). In IoT environment everything will get a unique ID to identify themself in the world of connected devices. This technology will be a huge revolution and will become a big milestone in the history of Information Technology (IT) along with cloud datacenters. If we want to identify the correct sensor for data collection among these sensor embedded smart objects, it will be cumbersome task. Sensors attached with these smart objects will sense the data from its surroundings. Sometimes an\u00a0\u2026", "num_citations": "4\n", "authors": ["1911"]}
{"title": "Fault recovery algorithm using king spare allocation and shortest path shifting for reconfigurable systems\n", "abstract": " Field Programmable Gate Arrays (FPGAs) have the capability of reconfiguring in-field and at runtime that helps in fault recovery. FPGAs are used to implement complex functions in applications such as nuclear systems, space missions, communication systems etc where system reliability is very critical. Such systems must be designed with the capability of fault tolerance. A wide range of fault tolerance techniques have been proposed for FPGAs ranging from architectural redundancies to fully online adaptive implementations. This paper presents an algorithm for efficient fault recovery using king spare allocation technique and Dijkstra\u2019s shortest path shifting. This algorithm can be applied to any modern FPGA that has partial reconfiguration (PR) capability. PR allows to modify parts of the design of the operating FPGA without affecting the other parts. The normal system operation can be ensured in noisy environment using this algorithm. This fault recovery algorithm is demonstrated using Matlab.", "num_citations": "4\n", "authors": ["1911"]}
{"title": "A Novel Image Retrieval System using an Effective Region-based Shape Representation Technique\n", "abstract": " With recent improvements in methods for the acquisition and rendering of shapes, the need for retrieval of shapes from large repositories of shapes has gained prominence. A variety of methods have been proposed that enable the efficient querying of shape repositories for a desired shape or image. Many of these methods use a sample shape as a query and attempt to retrieve shapes from the database that have a similar shape. This paper introduces a novel and efficient shape matching approach for the automatic identification of real world objects. The identification process is applied on isolated objects and requires the segmentation of the image into separate objects, followed by the extraction of representative shape signatures and the similarity estimation of pairs of objects considering the information extracted from the segmentation process and shape signature. We compute a 1D shape signature function from a region shape and use it for region shape representation and retrieval through similarity estimation. The proposed region shape feature is much more efficient to compute than other region shape techniques invariant to image transformation.", "num_citations": "4\n", "authors": ["1911"]}
{"title": "Energy aware clustered load balancing in cloud computing environment\n", "abstract": " Cloud is a collection of datacentres with heterogeneous resources, which gives services to the users based on pay-as-you-use model. Even though it has several advantages such as availability, scalability, and reliability, some performance parameters like energy consumption, load balancing, response time, resource allocation time, etc., are not properly fine tuned. This paper proposes an energy aware clustered load balancing system in which, heterogeneous resources are clustered into different groups by using a partitioning-based clustering algorithm. The clustering reduces number of resources needs to be searched and hence minimizes the time required for resource discovery. An energy aware best-fit virtual machine (VM) allocation is used for reducing the power consumption. The process allocations to VMs are done based on best-fit allocation strategy for optimal space utilisation. The results show that\u00a0\u2026", "num_citations": "3\n", "authors": ["1911"]}
{"title": "Particle swarm optimization method based consistency checking in UML class and activity diagrams\n", "abstract": " Unified Modeling Language models are the de facto industry standard for object-oriented modeling of the static and dynamic aspects of software systems. To ensure software quality, it is essential to maintain consistency between the models. Inconsistencies among the diagrams of a model may result in serious faults which are hard to detect and may lead to project failure. Complex systems require large number of diagrams and hence detection of inconsistencies among the diagrams has a significant role during the design phase of software development. In this paper we describe a method for detection of inconsistencies among the class and activity diagrams using particle swarm optimization technique. Particle Swarm Optimization (PSO) is a soft computing technique that provides solutions to optimization problems by maximizing certain objectives in a complex search space. The PSO algorithm is applied\u00a0\u2026", "num_citations": "3\n", "authors": ["1911"]}
{"title": "Partial slices in program testing\n", "abstract": " Program slicing is widely used as an aid in program analysis. In several cases, it is observed that the static slices contain a large number of program statements. Due to this increased size of the static slice, they are of little use in many practical applications. Moreover, the static slices may be less precise compared to dynamic slices. Partial slicing is suggested as a method for program testing in order to eliminate the disadvantages of static slicing. In partial slices, in addition to the static slicing criterion, the user has to provide the program point. Program point specifies the program statement up to which the static slicing is to be performed. The partial slices produced in this manner combines both static and program point information. This in turn is analyzed to verify the constraints and conditions in the slices to remove any obscurity in the program testing process. In this work we propose a partial slicing approach, which\u00a0\u2026", "num_citations": "3\n", "authors": ["1911"]}
{"title": "Insert queries in XML database\n", "abstract": " The need for interoperation and data exchange through the Internet has made Extensible Markup Language (XML) a dominant standard for data representation, while relational databases are widely used in enterprises to support critical business operations. XML querying language (XUpdate) is used to modify XML documents where as structured query language (SQL) for retrieving and manipulating data in relational databases. It may not be possible for users and developers to be familiar with both the query languages easily and quickly. Here, we examine how XML data can be modified using INSERT and UPDATE. In this paper, we propose a new concept and framework where SQL (INSERT, UPDATE) can be easily transformed to XUpdate expressions. We use SQL, as it has long been the standard language. Users can manipulate XML database through the query language SQL using our framework. We\u00a0\u2026", "num_citations": "3\n", "authors": ["1911"]}
{"title": "An on-demand byzantine-resilient secure routing protocol for wireless adhoc networks\n", "abstract": " Security has become a primary concern in order to provide protected communication between mobile nodes in a hostile environment. We refer to any arbitrary action by authenticated nodes resulting in disruption of the routing service such as drop packets, modify packets and miss-route packets as Byzantine behavior, and to such an adversary as a Byzantine adversary. Nodes may exhibit Byzantine behavior, either alone or colluding with other nodes. Several routing protocols were proposed to cope with insider attacks, outsider attacks and selective data forwarding attacks. To mitigate these vulnerabilities of routing protocols in wireless adhoc networks, we propose a new Byzantine-Resilient Secure Routing Protocol (BRSR) that provides resilience against Byzantine attacks. The proposed protocol provides security for inside attacks, outside attacks and selective data forwarding attacks in mobile adhoc networks. Simulation results demonstrate that BRSR effectively mitigates the identified attacks while providing better delivery ratio, and also more resistant against node capture attacks.", "num_citations": "3\n", "authors": ["1911"]}
{"title": "Improving prediction with enhanced Distributed Memory-based Resilient Dataset Filter\n", "abstract": " Launching new products in the consumer electronics market is challenging. Developing and marketing the same in limited time affect the sustainability of such companies. This research work introduces a model that can predict the success of a product. A Feature Information Gain (FIG) measure is used for significant feature identification and Distributed Memory-based Resilient Dataset Filter (DMRDF) is used to eliminate duplicate reviews, which in turn improves the reliability of the product reviews. The pre-processed dataset is used for prediction of product pre-launch in the market using classifiers such as Logistic regression and Support vector machine. DMRDF method is fault-tolerant because of its resilience property and also reduces the dataset redundancy; hence, it increases the prediction accuracy of the model. The proposed model works in a distributed environment to handle a massive volume of the\u00a0\u2026", "num_citations": "2\n", "authors": ["1911"]}
{"title": "Agent-based asynchronous training in distributed software development\n", "abstract": " In the changing software development, training on tools and techniques are necessary for the developers for better quality. Global software development faces great challenge for employee training as project members are scattered geographically. Developers should aware of the custom and culture of co-developers to improve their social and interpersonal competencies such as negotiation, teamwork, conflict resolution, time management, leadership, and communication using common language. The paper discussed a framework for agent based training model that can simulate global software development from different cultures; allows learners to train asynchronously as the agents are always available, and permits to play different roles in the various stages of project development. The framework also provides effective client training on product and effective for the discussion between the client and the\u00a0\u2026", "num_citations": "2\n", "authors": ["1911"]}
{"title": "Petri net model for resource scheduling with auto scaling in elastic cloud\n", "abstract": " Cloud service vendors offer wide range of services in a pay per use paradigm to the customers. The aim of cloud resource management is to speed up the execution of tasks and efficient usage of computing resources. The main benefit of optimal scheduling policy is reduced makespan, energy as well as cost with minimum number of service level agreement (SLA) violations. In market oriented cloud the service vendors offer vivid variety of purchasing options and also dynamic prices to the customers. In order to incorporate these purchase-promotional offers and dynamic prices, this paper proposes a Petri net model for scheduling the workload across physical servers. Here, SLA requirements considered are CPU speed, memory, makespan and bandwidth with fewer virtual machine migrations. The experimental results indicate that the proposed system efficiently performs dynamic provisioning and elasticity in\u00a0\u2026", "num_citations": "2\n", "authors": ["1911"]}
{"title": "Optimum parallelism in Spark framework on Hadoop YARN for maximum cluster resource\n", "abstract": " Spark is widely used as a distributed computing frameworkforin-memory parallel processing. It implements distributed computing by splitting the jobs into tasks and deploying them on executors on the nodes of a cluster. Executors are JVMs with dedicated allocation of CPU cores and memory. The number of tasks depends on the partitions of input data. Depending on the number of CPU cores allocated to executors, one or more cores get allocated to one task. Tasks run as independent threads on executors hosted on JVMs dedicated exclusively to the executor. One or more executors are deployed on the nodes of the cluster depending on the resource availability. The performance advantage provided by distributed computing on Spark framework depends on the level of parallelism configured at 3 levels, namely node level, executor level, and task level. The parallelism at each of these levels should be configured to fully utilize the available computing resources. This paper recommends optimum parallelism configuration for Apache Spark framework deployed on Hadoop YARN cluster. The recommendations are based on the results of the experiments conducted to evaluate the dependency of parallelism at each of these levels on the performance of Spark applications. For the purpose of the evaluation, a CPU-intensive job and an I/O-intensive job are used. The performance is measured by varying the parallelism at each of the 3 levels. The results presented in this paper help Spark users in selecting optimum parallelism at each of these levels for achieving maximum performance for Spark jobs by maximum resource utilization.", "num_citations": "2\n", "authors": ["1911"]}
{"title": "Maintaining connectivity of mobile nodes using MANET gateway nodes.\n", "abstract": " Mobile users in today's world are in search of wireless communication techniques that provide services anytime, anywhere with less cost and better connectivity. Recent research areas like green cellular networks, device to device communication (D2D) are now focusing on mobile ad hoc networks (MANET), an infrastructure less wireless network that can be deployed with less time and cost, in solving the issues in wireless world. This paper introduces an effective way of integrating MANET with cellular networks using MANET gateway nodes. The proposed architecture helps in maintaining connection between mobile nodes not under the cellular range or experiencing denied services from nearby base stations in densely populated areas. A modified routing protocol which incorporates the gateway discovery and selection is also designed. The new model experience a better packet delivery ratio compared to other\u00a0\u2026", "num_citations": "2\n", "authors": ["1911"]}
{"title": "MULTIOBJECTIVE BUILT IN SELF REPAIR ALGORITHM WITH MULTIPLE FAULT DETECTION FOR RECONFIGURABLE SYSTEMS.\n", "abstract": " Abstract Field Programmable Gate Arrays (FPGAs) are widely used in reliability-critical applications due to their reconfiguration ability. The emergence of partial reconfiguration in FPGAs has made it possible to incorporate fault tolerance into systems more easily. Fault tolerance includes fault detection and fault recovery. This paper presents the investigation of a fault detection and repair algorithm. Currently available self-repair algorithm makes use of large number of spare cells to achieve good fault coverage. This limitation is overcomed by the proposed algorithm, MORe which satisfies multiple objectives such as less area, minimum routing overhead and multiple fault detection capability. The MORe algorithm is demonstrated and compared with the other two existing algorithms using Matlab.", "num_citations": "2\n", "authors": ["1911"]}
{"title": "Fault localization using forward slicing spectrum\n", "abstract": " An increase in the cost incurred during manual software testing, debugging process and the requirement for reliable test data have forced the researchers to develop an automated system for software fault localization. We have proposed a forward slicing spectrum for fault localization. The proposed approach alleviates some of the core issues of standalone fault localization techniques such as program slicing and program spectrum based methods.", "num_citations": "2\n", "authors": ["1911"]}
{"title": "Coverage based route maintenance in MANET routing protocol\n", "abstract": " Mobile Ad-hoc Network (MANET) is an infrastructure less, wireless network consisting of a set of mobile nodes. Due to frequent movement of nodes, the network topology of MANET always changes, which affects the network connectivity as a whole. Dynamic topology can be chosen as one of the main factors which affect the performance of MANET routing protocols. Many protocols have been proposed, with the goal of achieving efficient routing. These protocols differ in the approach used for searching a new route or modifying an existing route to make off with the dynamic topology. Route discovery and route maintenance are two areas were an efficient routing protocol becomes helpful. In this paper, we propose a coverage based hybrid routing method. In this method, we first create a Cover-set for each node, which is calculated using the coverage area of the corresponding node. Both proactive and reactive\u00a0\u2026", "num_citations": "2\n", "authors": ["1911"]}
{"title": "Fixing state change inconsistency with self regulating particle swarm optimization\n", "abstract": " Software has made a profound influence in all walks of life. Developing quality software is a major challenge, and the consistency and completeness of the design has a prime role in the development of quality software. Many a times, the process of consistency checking in industries is manual. Artificial intelligence techniques can replace many of these manual efforts to make the development of software easier and cost-effective. Software developers use state diagrams to represent the dynamic behavior in the design stage. We propose a novel application of self regulating particle swarm optimization (SRPSO) algorithm to ensure consistency of state diagrams during the design phase of software development. Inconsistency management is modeled as an optimization problem. In this work, we detect two types of state change inconsistency, incompatible behavior inconsistency and disconnected model inconsistency\u00a0\u2026", "num_citations": "1\n", "authors": ["1911"]}
{"title": "Randomized Agent-Based Model for Mobile Customer Retention Behaviour Prediction\n", "abstract": " Due to the development of technology, mobile phones have a crucial role in human life. Multiple sim card phones and a single person using multiple mobile phones are common nowadays. Telecommunication is a major area where big data technologies are needed. Competition among the telecommunication companies is high due to customer churn. Customer retention in telecom companies is one of the major problems. In this paper, we propose a Randomized Method (RM) using Map and Reduce big data functions to avoid data duplication in the customer call data of telecommunication application. We use agent-based model (ABM) to predict the complex customer behaviour for the retention of customers with a particular telecommunication service. Agent-based model increases the prediction accuracy due to its dynamic nature of agents. ABM suggests rules based on mobile user variable features\u00a0\u2026", "num_citations": "1\n", "authors": ["1911"]}
{"title": "Feature intersection for agent-based customer churn prediction\n", "abstract": " PurposeTelecommunication has a decisive role in the development of technology in the current era. The number of mobile users with multiple SIM cards is increasing every second. Hence, telecommunication is a significant area in which big data technologies are needed. Competition among the telecommunication companies is high due to customer churn. Customer retention in telecom companies is one of the major problems. The paper aims to discuss this issue.Design/methodology/approachThe authors recommend an Intersection-Randomized Algorithm (IRA) using MapReduce functions to avoid data duplication in the mobile user call data of telecommunication service providers. The authors use the agent-based model (ABM) to predict the complex mobile user behaviour to prevent customer churn with a particular telecommunication service provider.FindingsThe agent-based model increases the prediction\u00a0\u2026", "num_citations": "1\n", "authors": ["1911"]}
{"title": "Context aware reliable sensor selection in IoT\n", "abstract": " Internet of things (IoT) is a computing concept where physical objects with embedded sensors connect to the internet and can identify themselves to other devices. Today, the number of devices connected to the internet is increasing rapidly and they want to communicate each other for different purposes. The future internet will comprise of billions of intelligent communicating objects having capabilities for sensing, actuating and data processing. Each object in this cyber physical systems (CPS) will have one or more embedded sensors that will capture huge amount of data. Managing these data in cloud and obtaining the relevant data from appropriate sensors are important concerns. For information retrieval context awareness is important. Usually users need information from these sensors depending upon several factors such as location, accuracy level, etc. The proposed method senses reliable data from a sensor\u00a0\u2026", "num_citations": "1\n", "authors": ["1911"]}
{"title": "Preventing Pollution Attacks in Cloud Storages\n", "abstract": " Cloud storage is a cloud-computing model in which data is stored on remote servers accessed from the internet. It has significantly changed the way users and administrators manage and access their data. Using remote storages to store data has many advantages in terms of availability and operational costs, but the security of such data is still one of the major concerns for the users. Pollution attack, where an adversary modifies some of the stored data is one of the many potent risks that affect the cloud data. In this paper, we show how disastrous pollution attack can be in coding based block level cloud storages, and how our algorithm using LRC, a version of Raptor codes, can identify an attack even before decoding all of the received packets.", "num_citations": "1\n", "authors": ["1911"]}
{"title": "Trust prediction model for certificate exchange and revocation in MANET\n", "abstract": " In mobile ad hoc networks (MANETs), security is more challenging due to problems related to key exchange. It is necessary to secure the exchanges in MANETs for assuring the development of services in the network. The self-organised MANET is visualised as a key communication technology enabler for application such as network centric warfare, disaster relief operations, emergency situations, intelligent transportation systems and so on. In this paper, we propose a trust prediction model for certificate exchange and revocation in MANET. The proposed architecture consists of one coordinator node, servers and normal mobile nodes. Then, multi-path certificate exchange technique is employed where public key of the nodes are certified by different nodes. Those nodes that issued the certificates are validated using the trust prediction model. The source node discards the malicious nodes in the data sending path\u00a0\u2026", "num_citations": "1\n", "authors": ["1911"]}
{"title": "Secure Cloud Multi-tenant Applications with Cache in PaaS\n", "abstract": " Multi-tenant applications come into existence in clouds, which aims \u201cbetter resource utilization\u201d for application provider. Today most of the present application optimizations are based on Service Level Agreements which focuses on virtual machine (VM) based computing service, while other services such as storage and cache are often neglected. This paper mainly focuses on cache based approach for multi-tenant application on PaaS. Currently in multi-tenant cloud applications data are often evicted mistakenly by cache service, which is managed by existing algorithms such as LRU. It keeps the query information to reload the evicted data from storage which might be sensitive. Hence there is a possibility of data breach when these data are accessed improperly by other tenants. For faster access caching of the data is common in cloud based applications while the security is an important area that should not\u00a0\u2026", "num_citations": "1\n", "authors": ["1911"]}
{"title": "Synchronous training in distributed software development team\n", "abstract": " In the changing development industry, training for the project team members is necessary to maintain with the most up-to-date tools and techniques. The software development organizations that provide appropriate training to their employees can expect e a higher quality from their development. In global software development as project members are scattered geographically, the training for the employees is a great challenge for the companies. The paper discusses methods for globally distributed technical person training in order to produce an effective and economical product. The paper analysed the use of synchronous and asynchronous training in the distributed software development context. The major facts that affect the online learning, particularly in a distributed environment are discussed. The paper identifies synchronous training as the method to minimize the issues due to time, distance and cost, which\u00a0\u2026", "num_citations": "1\n", "authors": ["1911"]}
{"title": "Foundational UML Behavioral Specification with Java\n", "abstract": " An executable UML model has a detailed behavioural specification that enables it to run as a program. The detailed specification enables to test and validate the model independent of any implementation platform. The foundational UML (fUML) specification adopted in 2008 provided the first operational base semantics of activity modelling. Since the fUML specification did not provide any new concrete syntax, in order to execute the model one had to draw a very detailed activity diagram. This led to the development of a textual representation to specify the computations which led to the development of action language for foundational UML known as Alf. The UML behaviour specified using textual notation in Alf can be attached to a UML model at any place. Syntactically, Alf looks like C, C++ or Java and semantically it maps to the fUML subset. Alf provides an additional layer of abstraction. In this paper we\u00a0\u2026", "num_citations": "1\n", "authors": ["1911"]}
{"title": "An Overview of Recent Trends in Software Testing\n", "abstract": " In the field of search based software testing, genetic algorithm based testing has received a major share of attention among researchers during the last few years. Though there are advantages for this type of testing, there also exist some practical difficulties which can make this technique less attractive for software testing industry. The potential of program slicing in testing has not been fully exploited till now and the works that have explicitly demonstrated the application of slicing in testing field are rare. Our paper aims to analyze existing techniques for software testing and to introduce an approach for software testing using program slicing technique. A systematic review of genetic algorithm based works reveals that, fitness function design, population initialization and parameter settings impact the quality of solution obtained in software testing using genetic algorithm. Based on the conclusions from the existing literature, we have probed deeper about the issues in these areas. Making an unbiased review like this may help to solve these unresolved issues in genetic algorithm based software testing. In this work, we have emphasized and has given clear directions on how slicing can be used as a potential tool for practical software testing. In addition, a set of research questions have been framed, which may be answered by reviewing the study made in this work. This may help future research in this area, leading to major breakthrough in software testing field.", "num_citations": "1\n", "authors": ["1911"]}
{"title": "Translation of Behavioral Models to Java Code and Enhance With State Charts\n", "abstract": " It is a wonderful idea to directly execute the system designs. In this paper we are introducing a method to convert the behavioral models to the implementation code. UML is used for modeling and Java is used as the target language. This paper describes how a system design depicted using activity, sequence and statemachine diagrams can be converted to its implementation code. Activity diagram helps to make the outline of the source program, and the sequence and statemachine diagrams contribute to the expansion of the source code. We are using an MDA approach where the system design is done in Platform Independent Model (PIM), then converted to Platform Specific Model (PSM) and finally to implementation code. One tool is implemented based on our method and it is evaluated against some other existing tools.", "num_citations": "1\n", "authors": ["1911"]}
{"title": "Traceability Matrix for Regression Testing in Distributed Software Development\n", "abstract": " Distributed software development is a process that is done across many business worksites or locations. Geographically distributed teams and cross-platform functionalities complicated the process of quality management. Software quality is essential to business success. One of the main issues distributed teams face is change management. For large changes, retesting the entire system is complex. So an automated regression testing technique is a must in distributed system. Thus identifying proper test cases is essential in regression testing. In this paper we propose a new method to find out essential test cases using traceability matrix. Traceability matrix correlates both user requirements and functional requirements with test cases of the system. By analyzing the traceability matrix we can ensure that we have covered all the required functionalities of the system. It also ensures that all the modification done\u00a0\u2026", "num_citations": "1\n", "authors": ["1911"]}
{"title": "Biochemical genetics of selected commercially important penaeid prawns\n", "abstract": " The Shodhganga@ INFLIBNET Centre provides a platform for research students to deposit their Ph. D. theses and make it available to the entire scholarly community in open access. Shodhganga Mirror Site", "num_citations": "1\n", "authors": ["1911"]}