{"title": "Teaching analytics: towards automatic extraction of orchestration graphs using wearable sensors\n", "abstract": " 'Teaching analytics' is the application of learning analytics techniques to understand teaching and learning processes, and eventually enable supportive interventions. However, in the case of (often, half-improvised) teaching in face-to-face classrooms, such interventions would require first an understanding of what the teacher actually did, as the starting point for teacher reflection and inquiry. Currently, such teacher enactment characterization requires costly manual coding by researchers. This paper presents a case study exploring the potential of machine learning techniques to automatically extract teaching actions during classroom enactment, from five data sources collected using wearable sensors (eye-tracking, EEG, accelerometer, audio and video). Our results highlight the feasibility of this approach, with high levels of accuracy in determining the social plane of interaction (90%, \u03ba= 0.8). The reliable detection\u00a0\u2026", "num_citations": "111\n", "authors": ["2149"]}
{"title": "Multimodal data as a means to understand the learning experience\n", "abstract": " Most work in the design of learning technology uses click-streams as their primary data source for modelling & predicting learning behaviour. In this paper we set out to quantify what, if any, advantages do physiological sensing techniques provide for the design of learning technologies. We conducted a lab study with 251 game sessions and 17 users focusing on skill development (i.e., user's ability to master complex tasks). We collected click-stream data, as well as eye-tracking, electroencephalography (EEG), video, and wristband data during the experiment. Our analysis shows that traditional click-stream models achieve 39% error rate in predicting learning performance (and 18% when we perform feature selection), while for fused multimodal the error drops up to 6%. Our work highlights the limitations of standalone click-stream models, and quantifies the expected benefits of using a variety of multimodal data\u00a0\u2026", "num_citations": "72\n", "authors": ["2149"]}
{"title": "Multimodal teaching analytics: Automated extraction of orchestration graphs from wearable sensor data\n", "abstract": " The pedagogical modelling of everyday classroom practice is an interesting kind of evidence, both for educational research and teachers' own professional development. This paper explores the usage of wearable sensors and machine learning techniques to automatically extract orchestration graphs (teaching activities and their social plane over time) on a dataset of 12 classroom sessions enacted by two different teachers in different classroom settings. The dataset included mobile eye\u2010tracking as well as audiovisual and accelerometry data from sensors worn by the teacher. We evaluated both time\u2010independent and time\u2010aware models, achieving median F1 scores of about 0.7\u20130.8 on leave\u2010one\u2010session\u2010out k\u2010fold cross\u2010validation. Although these results show the feasibility of this approach, they also highlight the need for larger datasets, recorded in a wider variety of classroom settings, to provide automated\u00a0\u2026", "num_citations": "65\n", "authors": ["2149"]}
{"title": "Understanding collaborative program comprehension: Interlacing gaze and dialogues\n", "abstract": " We study the interaction of participants in a pair program comprehension task across different time scales in a dual eye-tracking setup. We identify four layers of interaction episodes at different time scales. Each layer spans across the whole interaction. The present study concerns the relationship between different layers at different time scales. The first and third layers are based on the utterances of the participants while the second and fourth layers are based on participants' gaze.", "num_citations": "52\n", "authors": ["2149"]}
{"title": "Using mobile eye-trackers to unpack the perceptual benefits of a tangible user interface for collaborative learning\n", "abstract": " In this study, we investigated the way users memorize, analyze, collaborate, and learn new concepts on a Tangible User Interface (TUI). Twenty-seven pairs of apprentices in logistics (N = 54) interacted with an interactive simulation of a warehouse. Their task was to discover efficient design principles for building storehouses. In a between-subjects experimental design, half of the participants used 3D physical shelves, whereas the other half used 2D paper shelves. This manipulation allowed us to control for the \u201crepresentational effect\u201d of 3D tangibles: the first group saw the warehouse as a small-scale model with realistic shelves, whereas the second group had access to a more abstract layout with rectangular pieces of paper. Both groups interacted with the system in the same way. We found that participants in the first group (i.e., who used 3D realistic shelves) better memorized a warehouse layout, built a more\u00a0\u2026", "num_citations": "47\n", "authors": ["2149"]}
{"title": "Leveraging mobile eye-trackers to capture joint visual attention in co-located collaborative learning groups\n", "abstract": " This paper describes a promising methodology for studying co-located groups: mobile eye-trackers. We provide a comprehensive description of our data collection and analysis processes so that other researchers can take advantage of this cutting-edge technology. Data were collected in a controlled experiment where 27 student dyads (N\u2009=\u200954) interacted with a Tangible User Interface. They first had to define some design principles for optimizing a warehouse layout by analyzing a set of Contrasting Cases, and build a small-scale layout based on those principles. The contributions of this paper are that: 1) we replicated prior research showing that levels of Joint Visual Attention (JVA) are correlated with collaboration quality across all groups; 2) we then qualitatively analyzed two dyads with high levels of JVA and show that it can hide a free-rider effect (Salomon and Globerson 1989); 3) in conducting this\u00a0\u2026", "num_citations": "45\n", "authors": ["2149"]}
{"title": "How do you feel about learning to code? Investigating the effect of children\u2019s attitudes towards coding using eye-tracking\n", "abstract": " Computational thinking and coding for children are attracting increasing attention. There are several efforts around the globe to implement coding frameworks for children, and there is a need to develop an empirical knowledge base of methods and tools. One major problem for integrating study results into a common body of knowledge is the relatively limited measurements applied, and the relation of the widely used self-reporting methods with more objective measurements, such as biophysical ones. In this study, eye-tracking activity was used to measure children\u2019s learning and activity indicators. The goal of the study is to utilize eye-tracking to understand children\u2019s activity while they learn how to code and to investigate any potential association between children\u2019s attitudes and their gaze. In this contribution, we designed an experiment with 44 children (between 8 and 17 years old) who participated in a full-day\u00a0\u2026", "num_citations": "45\n", "authors": ["2149"]}
{"title": "Using eye-tracking to unveil differences between kids and teens in coding activities\n", "abstract": " Computational thinking and coding is gradually becoming an important part of K-12 education. Most parents, policy makers, teachers, and industrial stakeholders want their children to attain computational thinking and coding competences, since learning how to code is emerging as an important skill for the 21st century. Currently, educators are leveraging a variety of technological tools and programming environments, which can provide challenging and dynamic coding experiences. Despite the growing research on the design of coding experiences for children, it is still difficult to say how children of different ages learn to code, and to cite differences in their task-based behaviour. This study uses eye-tracking data from 44 children (here divided into\" kids\"[age 8-12] and\" teens\"[age 13-17]) to understand the learning process of coding in a deeper way, and the role of gaze in the learning gain and the different age\u00a0\u2026", "num_citations": "41\n", "authors": ["2149"]}
{"title": "Studying teacher orchestration load in technology-enhanced classrooms\n", "abstract": " Teacher orchestration of technology-enhanced learning (TEL) processes plays a major role in students\u2019 outcomes, especially in face-to-face classrooms. However, few studies look into the fine-grained details of how such orchestration unfolds, the challenges and cognitive overload that using technologies at a classroom level pose for teachers. This paper proposes a mixed-method approach to the study of orchestration cognitive load, combining physio-behavioural (eye-tracking) and subjective measurements (questionnaires, stimulated recall interviews). We illustrate the approach by applying it to study the orchestration of two technology-enhanced geometry lessons, by a secondary school teacher. The results of our mixed-method analyses highlight the difficulty of classroom-level (as opposed to individual- or group-level) interactions, especially in modelling students\u2019 progress and understanding. Such\u00a0\u2026", "num_citations": "41\n", "authors": ["2149"]}
{"title": "\u201cWith-me-ness\u201d: A gaze-measure for students\u2019 attention in MOOCs\n", "abstract": " We propose a gaze-based indicator of students\u2019 attention in a MOOC video lecture. We report the results from an eye-tracking study during a MOOC lecture. We define the gazebased indicator of students\u2019 attention as \u201cwith-me-ness\u201d. This answers a question from teachers\u2019 perspective \u201chow much are the students with me?\u201d With-me-ness is defined at two levels: perceptual, following teacher\u2019s deictic acts-and conceptual\u2013following teacher discourse. We conducted an experiment with 40 participants and observed a significant and positive correlation between the two levels of with-me-ness and the posttest scores.", "num_citations": "41\n", "authors": ["2149"]}
{"title": "Building pipelines for educational data using AI and multimodal analytics: A \u201cgrey\u2010box\u201d approach\n", "abstract": " Students' on\u2010task engagement during adaptive learning activities has a significant effect on their performance, and at the same time, how these activities influence students' behavior is reflected in their effort exertion. Capturing and explaining effortful (or effortless) behavior and aligning it with learning performance within contemporary adaptive learning environments, holds the promise to timely provide proactive and actionable feedback to students. Using sophisticated machine learning (ML) algorithms and rich learner data, facilitates inference\u2010making about several behavioral aspects (including effortful behavior) and about predicting learning performance, in any learning context. Researchers have been using ML methods in a \u201cblack\u2010box\u201d approach, ie, as a tool where the input data is the learner data and the output is a given class from the chosen construct. This work proposes a methodological shift from the\u00a0\u2026", "num_citations": "38\n", "authors": ["2149"]}
{"title": "A gaze-based learning analytics model: in-video visual feedback to improve learner's attention in MOOCs\n", "abstract": " In the context of MOOCs,\" With-me-ness\" refers to the extent to which the learner succeeds in following the teacher, specifically in terms of looking at the area in the video that the teacher is explaining. In our previous works, we employed eye-tracking methods to quantify learners' With-me-ness and showed that it is positively correlated with their learning gains. In this contribution, we describe a tool that is designed to improve With-me-ness by providing a visual-aid superimposed on the video. The position of the visual-aid is suggested by the teachers' dialogue and deixis, and it is displayed when the learner's With-me-ness is under the average value, which is computed from the other students' gaze behavior. We report on a user-study that examines the effectiveness of the proposed tool. The results show that it significantly improves the learning gain and it significantly increases the extent to which the students follow\u00a0\u2026", "num_citations": "37\n", "authors": ["2149"]}
{"title": "Identifying Styles and Paths toward Success in MOOCs.\n", "abstract": " Current schemes to categorise MOOC students result from a single view on the population which either contains the engagement of the students or demographics or self reported motivation. We propose a new hierarchical student categorisation, which uses common online activities capturing both engagement and achievement of MOOC students. A first level is based on the online engagement with the course structure, ie, whether they take part in graded activities or not. Based on this criterion, we divide students into two major categories: active students and viewers. The second levels are based on the different activities typically performed by the students in these two categories. For the \u201cactive students\u201d we categorise them based on their final result. For the \u201cviewers\u201d, we further divide the category based on their engagement quotient, ie, how much of the course content they follow and whether they involve with the non-mandatory exercises in the course or not. Further, in this contribution we analyse the behaviour of the students in different categories to highlight the basic differences among them.", "num_citations": "37\n", "authors": ["2149"]}
{"title": "Gaze Evidence for different activities in program understanding\n", "abstract": " We present an empirical study that illustrates the potential of dual eye-tracking to detect successful understanding and social processes during pair-programming. The gaze of forty pairs of programmers was recorded during a program understanding task. An analysis of the gaze transitions between structural elements of the code, declarations of identifiers and expressions shows that pairs with better understanding do less systematic execution of the code and more \u201ctracing\u201d of the data flow by alternating between identifiers and expressions. Interaction consists of moments where partners\u2019 attention converges on the same same part of the code and moments where it diverges. Moments of convergence are accompanied by more systematic execution of the code and less transitions among identifiers and expressions.", "num_citations": "37\n", "authors": ["2149"]}
{"title": "Orchestration load indicators and patterns: In-the-wild studies using mobile eye-tracking\n", "abstract": " Orchestration load is the effort a teacher spends in coordinating multiple activities and learning processes. It has been proposed as a construct to evaluate the usability of learning technologies at the classroom level, in the same way that cognitive load is used as a measure of usability at the individual level. However, so far this notion has remained abstract. In order to ground orchestration load in empirical evidence and study it in a more systematic and detailed manner, we propose a method to quantify it, based on physiological data (concretely, mobile eye-tracking measures), along with human-coded behavioral data. This paper presents the results of applying this method to four exploratory case studies, where four teachers orchestrated technology-enhanced face-to-face lessons with primary, secondary school, and university students. The data from these studies provide a first validation of this method in different\u00a0\u2026", "num_citations": "36\n", "authors": ["2149"]}
{"title": "Looking AT versus looking THROUGH: A dual eye-tracking study in MOOC context\n", "abstract": " We present an eye-tracking study to show the different gaze patterns across the MOOC learners. We hypothesize that the pretests can be used to shape the attention of the students. Moreover we also proposed a collaborative add on activity to the learning material for the students to help them reflect on the material they learnt in the MOOC video. What comes out of the present study is two different interaction styles that differentiate the good students from the poor students. The good students engage with the teacher/collaborating partner through the interface/display. While the poor students engage with the material only. We name these two interaction styles as \u201clooking through\u201d and \u201clooking at\u201d respectively.", "num_citations": "35\n", "authors": ["2149"]}
{"title": "3D tangibles facilitate joint visual attention in dyads\n", "abstract": " We report results from a dual eye-tracking study around a Tangible User Interface (TUI). Participants (N=54) worked in groups of two and solved optimization problems on the TinkerTable, a TUI designed for students in logistics. The TinkerTable features tangible shelves that students can manipulate to build and optimize the layout of a warehouse while the system provides feedback with a projector above the table. Using mobile eye-trackers, we examined participants\u2019 visual coordination when solving those problems. We describe two contributions to the CSCL community: first, we propose a methodology for synchronizing two eye-tracking goggles and computing measures of joint visual attention (JVA) in a co-located setting. Second, we report preliminary findings suggesting that participants were more likely to have moments of joint attention when looking at 3D, realistic objects compared to 2D, abstract ones. JVA was also found to be a significant predictor of students\u2019 learning gains and performance during the optimization tasks. We discuss implications of these findings for supporting interactions around a TUI.", "num_citations": "33\n", "authors": ["2149"]}
{"title": "Iterative design of an upper limb rehabilitation game with tangible robots\n", "abstract": " Rehabilitation aims to ameliorate deficits in motor control via intensive practice with the affected limb. Current strategies, such as one-on-one therapy done in rehabilitation centers, have limitations such as treatment frequency and intensity, cost and requirement of mobility. Thus, a promising strategy is home-based therapy that includes task specific exercises. However, traditional rehabilitation tasks may frustrate the patient due to their repetitive nature and may result in lack of motivation and poor rehabilitation. In this article, we propose the design and verification of an effective upper extremity rehabilitation game with a tangible robotic platform named Cellulo as a novel solution to these issues. We first describe the process of determining the design rationales to tune speed, accuracy and challenge. Then we detail our iterative participatory design process and test sessions conducted with the help of stroke, brachial\u00a0\u2026", "num_citations": "30\n", "authors": ["2149"]}
{"title": "How to quantify student\u2019s regularity?\n", "abstract": " Studies carried out in classroom-based learning context, have consistently shown a positive relation between students\u2019 conscientiousness and their academic success. We hypothesize that time management and regularity are main constructing blocks of students\u2019 conscientiousness in the context of online education. In online education, despite intuitive arguments supporting on-demand courses as more flexible delivery of knowledge, completion rate is higher in the courses with rigid temporal constraints and structure. In this study, we further investigate how students\u2019 regularity affects their learning outcome in MOOCs. We propose several measures to quantify students regularity. We validate accuracy of these measures as predictors of students\u2019 performance in the course.", "num_citations": "30\n", "authors": ["2149"]}
{"title": "How students learn using MOOCs: An eye-tracking insight\n", "abstract": " We present the results of an eye-tracking study on a Massive Open Online Course (MOOC) lecture showing the relation between gaze variables and students\u2019 performance and learning strategy. 40 students watched a MOOC lecture while their eye-movements were being recorded. We present a method to define stimuli-based gaze variables that can be defined for any kind of stimulus. The advantage of using stimuli-based gaze variables is that the relation of the gaze indicators with performance measures and behavioral measures can be interpreted differently for different kinds of stimulus. MOOCs are very diverse in nature; having such a variable description enables the researchers to have a common measure for the different kind of stimulus present in different MOOCs. The long-term goal is to create student profiles based on their performance and learning strategy using stimuli-based gaze variables and to provide the students with gaze-aware feedback to improve the overall learning process.", "num_citations": "29\n", "authors": ["2149"]}
{"title": "The burden of facilitating collaboration: towards estimation of teacher orchestration load using eye-tracking measures\n", "abstract": " Teacher facilitation of CSCL activities is widely recognized as one of the main factors affecting student learning outcomes in formal face-to-face settings. However, the orchestration load that such facilitation represents for the teacher, within the constraints of an authentic classroom, remains under-researched. This paper presents a novel method to estimate the cognitive load of teachers during facilitation of CSCL sessions, using mobile eye-tracking techniques. Throughout three studies of increasing authenticity, we demonstrate the feasibility of this approach, and extract insights about classroom usability challenges in CSCL practice: the increased load of class-level facilitation, or the real-time monitoring of students\u2019 progress. This new instrument in the CSCL researcher\u2019s toolkit can help focus our attention in critical, fine-grained classroom usability episodes, to make more informed design decisions.", "num_citations": "28\n", "authors": ["2149"]}
{"title": "Coding games and robots to enhance computational thinking: How collaboration and engagement moderate children\u2019s attitudes?\n", "abstract": " Collaboration and engagement while coding are vital elements for children, yet very little is known about how children\u2019s engagement and collaboration impact their attitudes toward coding activities. The goal of the study is to investigate how collaboration and engagement moderate children\u2019s attitudes about coding activities. To do so, we designed an study with 44 children (between 8 and 17 years old) who participated in a full-day coding activity. We measured their engagement and collaboration during the activity by recording their gaze, and their attitudes in relation to their learning, enjoyment, team-work and intention by post-activity survey instruments. Our analysis shows that there is a significant moderating effect of collaboration and engagement on children\u2019s attitudes. In other words, highly engaging and collaborative coding activities significantly moderate children\u2019s attitudes. Our findings highlight the\u00a0\u2026", "num_citations": "25\n", "authors": ["2149"]}
{"title": "Eye-tracking and artificial intelligence to enhance motivation and learning\n", "abstract": " The interaction with the various learners in a Massive Open Online Course (MOOC) is often complex. Contemporary MOOC learning analytics relate with click-streams, keystrokes and other user-input variables. Such variables however, do not always capture users\u2019 learning and behavior (e.g., passive video watching). In this paper, we present a study with 40 students who watched a MOOC lecture while their eye-movements were being recorded. We then proposed a method to define stimuli-based gaze variables that can be used for any kind of stimulus. The proposed stimuli-based gaze variables indicate students\u2019 content-coverage (in space and time) and reading processes (area of interest based variables) and attention (i.e., with-me-ness), at the perceptual (following teacher\u2019s deictic acts) and conceptual levels (following teacher discourse). In our experiment, we identified a significant mediation effect of the\u00a0\u2026", "num_citations": "23\n", "authors": ["2149"]}
{"title": "Fitbit for learning: Towards capturing the learning experience using wearable sensing\n", "abstract": " The assessment of learning during class activities mostly relies on standardized questionnaires to evaluate the efficacy of the learning design elements. However, standardized questionnaires pose additional strain on students, do not provide \u201ctemporal\u201d information during the learning experience, require considerable effort and language competence, and sometimes are not appropriate. To overcome these challenges, we propose using wearable devices, which allow for continuous and unobtrusive monitoring of physiological parameters during learning. In this paper we set out to quantify how well we can infer students\u2019 learning experience from wrist-worn devices capturing physiological data. We collected data from 31 students in 93 class sessions (3 class sessions per student), and our analysis shows that wrist data can predict the learning experience with 11% error. We also show that 6.25\u00a0min (SD\u00a0=\u00a03.1\u00a0min) of\u00a0\u2026", "num_citations": "23\n", "authors": ["2149"]}
{"title": "Coding activities for children: Coupling eye-tracking with qualitative data to investigate gender differences\n", "abstract": " Computational thinking and coding are becoming an integral part of K-12 education, with female students being underrepresented in such subjects. The proliferation of technological tools and programming environments offers the opportunity for creative coding activities for children and increases the need for appropriate instructional practices. In this study, we design and evaluate a coding workshop for children. Our goal is to examine differences between boys and girls using eye-tracking as an objective measure and triangulating the findings with qualitative data coming from children's interviews. The results show no statistically significant difference between female and male gaze and learning gain during the coding activity; interestingly, the qualitative data show differences in the strategies and implemented practices during coding, and in perceptions about those coding activities. Our results highlight that further\u00a0\u2026", "num_citations": "23\n", "authors": ["2149"]}
{"title": "Multimodal data capabilities for learning: What can multimodal data tell us about learning?\n", "abstract": " Most research on learning technology uses clickstreams and questionnaires as their primary source of quantitative data. This study presents the outcomes of a systematic literature review of empirical evidence on the capabilities of multimodal data (MMD) for human learning. This paper provides an overview of what and how MMD have been used to inform learning and in what contexts. A search resulted in 42 papers that were included in the analysis. The results of the review depict the capabilities of MMD for learning and the ongoing advances and implications that emerge from the employment of MMD to capture and improve learning. In particular, we identified the six main objectives (ie, behavioral trajectories, learning outcome, learning\u2010task performance, teacher support, engagement and student feedback) that the MMLA research has been focusing on. We also summarize the implications derived from the\u00a0\u2026", "num_citations": "22\n", "authors": ["2149"]}
{"title": "Predicting learners' effortful behaviour in adaptive assessment using multimodal data\n", "abstract": " Many factors influence learners' performance on an activity beyond the knowledge required. Learners' on-task effort has been acknowledged for strongly relating to their educational outcomes, reflecting how actively they are engaged in that activity. However, effort is not directly observable. Multimodal data can provide additional insights into the learning processes and may allow for effort estimation. This paper presents an approach for the classification of effort in an adaptive assessment context. Specifically, the behaviour of 32 students was captured during an adaptive self-assessment activity, using logs and physiological data (ie, eye-tracking, EEG, wristband and facial expressions). We applied k-means to the multimodal data to cluster students' behavioural patterns. Next, we predicted students' effort to complete the upcoming task, based on the discovered behavioural patterns using a combination of Hidden\u00a0\u2026", "num_citations": "22\n", "authors": ["2149"]}
{"title": "Detecting collaborative dynamics using mobile eye-trackers\n", "abstract": " Prior work has successfully described how low and high-performing dyads of students differ in terms of their visual synchronization (e.g., Barron, 2000; Jermann, Mullins, Nuessli & Dillenbourg, 2011). But there is far less work analyzing the diversity of ways that successful groups of students use to achieve visual coordination. The goal of this paper is to illustrate how well-coordinated groups establish and sustain joint visual attention by unpacking their different strategies and behaviors. Our data was collected in a dual eye-tracking setup where dyads of students (N=54) had to interact with a Tangible User Interface (TUI). We selected two groups of students displaying high levels of joint visual attention and compared them using cross-recurrence graphs displaying moments of joint attention from the eye-tracking data, speech data, and by qualitatively analyzing videos generated for that purpose. We found that greater insights can be found by augmenting cross-recurrence graphs with spatial and verbal data, and that high levels of joint visual attention can hide a free-rider effect (Salomon & Globerson, 1989). We conclude by discussing implications for automatically analyzing students\u2019 interactions using dual eye-trackers.", "num_citations": "22\n", "authors": ["2149"]}
{"title": "Displaying teacher\u2019s gaze in a MOOC: Effects on students\u2019 video navigation patterns\n", "abstract": " We present an eye-tracking study where we augment a Massive Open Online Course (MOOC) video with the gaze information of the teacher. We tracked the gaze of a teacher while he was recording the content for a MOOC lecture. Our working hypothesis is that displaying the gaze of the teacher will act as cues in crucial moments of dyadic conversation, the teacher-student dyad, such as reference disambiguation. We collected data about students\u2019 video interaction behaviour within a MOOC. The results show that the showing the teacher\u2019s gaze made the content easier to follow for the students even when complex visual stimulus present in the video lecture.", "num_citations": "20\n", "authors": ["2149"]}
{"title": "Using sequential pattern mining to explore learners\u2019 behaviors and evaluate their correlation with performance in inquiry-based learning\n", "abstract": " This study analyzes students\u2019 behaviors in a remote laboratory environment in order to identify new factors of prediction of academic success. It investigates relations between learners\u2019 activities during practical sessions, and their performance at the final assessment test. Based on learning analytics applied to data collected from an experimentation conducted with our remote lab dedicated to computer education, we discover recurrent sequential patterns of actions that lead us to the definition of learning strategies as indicators of higher level of abstraction. Results show that some of the strategies are correlated to learners\u2019 performance. For instance, the construction of a complex action step by step, or the reflection before submitting an action, are two strategies applied more often by learners of a higher level of performance than by other students. While our proposals are domain-independent and can thus\u00a0\u2026", "num_citations": "17\n", "authors": ["2149"]}
{"title": "Temporal analysis of multimodal data to predict collaborative learning outcomes\n", "abstract": " The analysis of multiple data streams is a long\u2010standing practice within educational research. Both multimodal data analysis and temporal analysis have been applied successfully, but in the area of collaborative learning, very few studies have investigated specific advantages of multiple modalities versus a single modality, especially combined with temporal analysis. In this paper, we investigate how both the use of multimodal data and moving from averages and counts to temporal aspects in a collaborative setting provides a better prediction of learning gains. To address these questions, we analyze multimodal data collected from 25 9\u201311\u2010year\u2010old dyads using a fractions intelligent tutoring system. Assessing the relation of dual gaze, tutor log, audio and dialog data to students' learning gains, we find that a combination of modalities, especially those at a smaller time scale, such as gaze and audio, provides a\u00a0\u2026", "num_citations": "15\n", "authors": ["2149"]}
{"title": "Gaze insights into debugging behavior using learner-centred analysis\n", "abstract": " The presented study tries to tackle an intriguing question of how user-generated data from current technologies can be used to reinforce learners' reflections, improve teaching practices, and close the learning analytics loop. In particular, the aim of the study is to utilize users' gaze to examine the role of a mirroring tool (ie Exercise View in Eclipse) in orchestrating basic behavioral regulation of participants engaged in a debugging task. The results demonstrated that students who processed the information presented in the Exercise View and acted upon it, improved their performance and achieved higher level of success than those who failed to do it. The findings shed a light how to capture what constitute relevant data within a particular context using gaze patterns, that could guide collection of essential learner-centred analytics for the purpose of designing usable and modular learning environments based on data\u00a0\u2026", "num_citations": "15\n", "authors": ["2149"]}
{"title": "Visual aesthetics of E-commerce websites: An eye-tracking approach\n", "abstract": " This study adopts four facets of visual aesthetics (ie, simplicity, diversity, colorfulness, craftsmanship) to explain how they relate with users\u2019 gaze patterns, based on how much they fixate on certain points, as well as how fast and how much distance their eyes cover. On a sample of 23 experienced users in online shopping, we collect eye-tracking data while looking at high, neutral, and low appealing websites, and then register their perceptions on visual aesthetics towards those websites. Findings show different patterns of gaze behavior related with users\u2019 perceptions on visual aesthetics. Short fixations with high saccade show high simplicity, while high fixation variance and high backtrack shows high diversity. Short fixations with high backtrack show high colorfulness. Low saccade velocity with high skewness shows high craftsmanship. We contribute towards the need of automatizing the process of understanding users\u2019 perceptions of visual aesthetics, as we might be able to predict the user behavior in real time in the future.", "num_citations": "15\n", "authors": ["2149"]}
{"title": "Visual Augmentation of Deictic Gestures in MOOC videos\n", "abstract": " We present an eye-tracking study to compare different modalities for visual augmentations of the teacher\u2019s explicit deictic gestures on a video lecture. We compared three visualizations: 1) hand gestures with a pointer, 2) gaze overlay, and 3) no-augmentation baseline. We investigate the teacher-student pair in a video-based learning context as an abstraction of an expert-novice pair where the goal is to attain a high level of shared understanding. The key phase of having a shared understanding is to have a common ground between the pair. Previous studies showed that explicit deixis plays a major role in initiating and maintaining common ground. This led us to hypothesize that augmenting videos with teacher\u2019s deictic gestures might help students perform better. We found that augmenting the video with teacher\u2019s gaze results in higher learning gain than no visualization. Moreover, gaze visualization also helped students in maintaining longer attention spans than hand gestures.", "num_citations": "15\n", "authors": ["2149"]}
{"title": "Studying teacher cognitive load in multi-tabletop classrooms using mobile eye-tracking\n", "abstract": " Increasing affordability is making multi-tabletop spaces (eg, in school classrooms) a real possibility, and first design guidelines for such environments are starting to appear. However, there are still very few studies into the usability of such multi-tabletop classrooms as a whole, considering well-established constructs such as cognitive load. In this poster we present an exploratory study of the usage of mobile eye-tracking techniques to follow cognitive load of a teacher during a lesson in such a multi-tabletop space. By analyzing several eye-tracking measures over three sessions of a collaborative learning lesson on fractions, we obtained insights on the user experience of the facilitator in these concrete sessions. We also show the potential of eye-tracking to identify critical episodes in the usage of a multi-tabletop space under realistic usage conditions, in a less intrusive and more objective manner.", "num_citations": "15\n", "authors": ["2149"]}
{"title": "Online reviews or marketer information? An eye-tracking study on social commerce consumers\n", "abstract": " Driven by the increasing popularity of social commerce sites, this study seeks to examine the information sources and formats that influence consumer intentions to purchase. Specifically, we build on uses and gratifications theory and dual-process theory to determine how user-generated content and marketer-generated content are consumed by users when making a purchase decision. Using an eye-tracking approach on a popular social commerce site with a sample of 23 consumers, we find significant differences in the types of information used for product purchase compared to those omitted. Our study demonstrates that the format and source of information that consumers utilize, as well as the gaze transitions they make between different types of content when browsing, follow different patterns depending on if a product is bought or rejected. We conclude the paper summarizing the findings and drawing\u00a0\u2026", "num_citations": "14\n", "authors": ["2149"]}
{"title": "Assessing cognitive performance using physiological and facial features: Generalizing across contexts\n", "abstract": " Sensing and machine learning advances have enabled the unobtrusive measurement of physiological responses and facial expressions so as to estimate one's cognitive performance. This often boils down to mapping the states of the cognitive processes underpinning human cognition: physiological responses (e.g., heart rate) and facial expressions (e.g., frowning) often reflect the states of our cognitive processes. However, it remains unclear whether physiological responses and facial expressions used in one particular task (e.g., gaming) can reliably assess cognitive performance in another task (e.g., coding), because complex and diverse tasks often require varying levels and combinations of cognitive processes. In this paper, we measure the cross-task reliability of physiological and facial responses. Specifically, we assess cognitive performance based on physiological responses and facial expressions for\u00a0\u2026", "num_citations": "13\n", "authors": ["2149"]}
{"title": "On Generalizability of MOOC Models.\n", "abstract": " The big data imposes the key problem of generalizability of the results. In the present contribution, we discuss statistical tools which can help to select variables adequate for target level of abstraction. We show that a model considered as over-fitted in one context can be accurate in another. We illustrate this notion with an example analysis experiment on the data from 13 university Massive Online Open Courses (MOOCs). We discuss statistical tools which can be helpful in the analysis of generalizability of MOOC models.", "num_citations": "13\n", "authors": ["2149"]}
{"title": "Shaping learners\u2019 attention in Massive Open Online Courses\n", "abstract": " We present an eye-tracking study in the context of Massive Open Online Course (MOOC) videos. We propose to use a pre-test as a way of priming students about the video content before they watch the video. In this study, we used two versions of the same pre-test: textual and schema based. The results show that priming has an effect on the learning gain as well as the gaze patterns of students as they watch the videos; the type of priming has an effect on whether students spend more time looking at textual or schema video elements.", "num_citations": "13\n", "authors": ["2149"]}
{"title": "Joint emotional state of children and perceived collaborative experience in coding activities\n", "abstract": " This paper employs facial features to recognize emotions during a coding activity with 50 children. Extracting group-level emotional states via facial features, allows us to understand how emotions of a group affect collaboration. To do so, we captured joint emotional state using videos and collaborative experience using questionnaires, from collaborative coding sessions. We define groups' emotional state using a method inspired from dynamic systems, utilizing a measure called cross-recurrence. We also define a collaborative emotional profile using the different measurements from facial features of children. The results show that the emotional cross recurrence (coming from the videos) is positively related with the collaborative experience (coming from the surveys). We also show that the groups with better experience than the others showcase more positive and a consistent set of emotions during the coding activity\u00a0\u2026", "num_citations": "12\n", "authors": ["2149"]}
{"title": "Evidence for programming strategies in university coding exercises\n", "abstract": " Success in coding exercises is deeply related to the strategy employed by the students to solve coding tasks. In this contribution, we analyze the programming assignments of 600 students from an introductory university course in object-oriented programming. The students were provided unit tests for the assessment of their code, and their editing and testing actions were recorded using an Eclipse plug-in. The primary motivation for this study is to discover the programming strategies used by students for coding exercises with different difficulty levels, and find out if any relation exists between these strategies and the success in solving the coding tasks. More insights into this process will enable educators to provide future students timely, appropriate and constructive feedback on their coding process. Thus, to predict success in the coding exercises, we used indicators from students\u2019 testing behaviour\u00a0\u2026", "num_citations": "12\n", "authors": ["2149"]}
{"title": "Utilizing Interactive Surfaces to Enhance Learning, Collaboration and Engagement: Insights from Learners\u2019 Gaze and Speech\n", "abstract": " Interactive displays are becoming increasingly popular in informal learning environments as an educational technology for improving students\u2019 learning and enhancing their engagement. Interactive displays have the potential to reinforce and maintain collaboration and rich-interaction with the content in a natural and engaging manner. Despite the increased prevalence of interactive displays for learning, there is limited knowledge about how students collaborate in informal settings and how their collaboration around the interactive surfaces influences their learning and engagement. We present a dual eye-tracking study, involving 36 participants, a two-staged within-group experiment was conducted following single-group time series design, involving repeated measurement of participants\u2019 gaze, voice, game-logs and learning gain tests. Various correlation, regression and covariance analyses employed to investigate students\u2019 collaboration, engagement and learning gains during the activity. The results show that collaboratively, pairs who have high gaze similarity have high learning outcomes. Individually, participants spending high proportions of time in acquiring the complementary information from images and textual parts of the learning material attain high learning outcomes. Moreover, the results show that the speech could be an interesting covariate while analyzing the relation between the gaze variables and the learning gains (and task-based performance). We also show that the gaze is an effective proxy to cognitive mechanisms underlying collaboration not only in formal settings but also in informal learning scenarios. View Full-Text", "num_citations": "11\n", "authors": ["2149"]}
{"title": "Combining Gaze, Dialogue, and Action from a Collaborative Intelligent Tutoring System to Inform Student Learning Processes\n", "abstract": " In a computer supported collaborative learning environment, students have both interactions with each other as well as the technology that is guiding their learning, which can influence how the students construct their knowledge. Often in technology enhanced learning situations, information from the system provides discrete data points that can be used to infer learning without providing much information on the knowledge construction. On the other hand, analysis of student dialogues can be time consuming and subjective. In this paper, we propose combining log data, student dialogue, and gaze analysis to provide a clearer picture of how students construct knowledge collaboratively while working with an intelligent tutoring system. We found that students\u2019 gaze similarity is negatively correlated with levels of abstraction in speech and that students have higher gaze similarity surrounding feedback provided by the tutor. These results show that the gaze data can be used as a proxy for dialogue in a collaborative learning context.", "num_citations": "11\n", "authors": ["2149"]}
{"title": "Monitoring Children's Learning Through Wearable Eye-Tracking: The Case of a Making-Based Coding Activity\n", "abstract": " Learning activities for/with children include rich interactions with peers, tutors, and learning materials (in digital or physical form). During such activities, children gain new knowledge and master their skills. Automatized and continuous monitoring of children's learning is a complex task, but, if efficient, can greatly enrich teaching and learning. Wearable devices, such as eye-tracking glasses, have the capacity to continuously and unobtrusively monitor children's interactions, and such interactions might be capable of predicting children's learning. In this article, we set out to quantify the extent to which children's gaze, captured with eye-tracking glasses, can predict their learning. To do so, we collected data from a case study with 44 children (8-17 years old) during a making-based coding activity. Our analysis shows that children's gaze can predict their learning with 15.79% error. Our results also identify the most\u00a0\u2026", "num_citations": "10\n", "authors": ["2149"]}
{"title": "Analyzing learners\u2019 behavior beyond the MOOC: An exploratory study\n", "abstract": " Most of literature on massive open online courses (MOOCs) have focused on describing and predicting learner\u2019s behavior with course trace data. However, little is known on the external resources beyond the MOOC they use to shape their learning experience, and how these interactions relate with their success in the course. This paper presents the results of an exploratory study that analyzes data from 572 learners in 4 MOOCs to understand (1) what the learners\u2019 activities beyond the MOOC are, and (2) how they relate with their course performance. We analyzed frequencies of the students\u2019 individual activities in and beyond the MOOC, and the transitions between these activities. Then, we analyzed the time spent on outside the MOOC content as well as the nature of this content. Finally, we predict which transitions better predict final learners\u2019 grades. The results show that we can predict accurately\u00a0\u2026", "num_citations": "10\n", "authors": ["2149"]}
{"title": "Gaze-Driven Design Insights to Amplify Debugging Skills: A Learner-Centered Analysis Approach\n", "abstract": " This study investigates how multimodal user-generated data can be used to reinforce learner reflection, improve teaching practices, and close the learning analytics loop. In particular, the aim of the study is to utilize user gaze and action-based data to examine the role of a mirroring tool (ie, Exercise View in Eclipse) in orchestrating basic behavioural regulation during debugging. The results demonstrated that students who processed the information presented in the Exercise View and acted upon it, improved their performance and achieved a higher level of success than those who failed to do so. The findings shed light on what constitutes relevant data within a particular learning context in programming using gaze patterns. Moreover, these findings could guide the collection of essential learner-centred analytics for designing usable, modular learning environments based on data-driven approaches.", "num_citations": "10\n", "authors": ["2149"]}
{"title": "Utilizing multimodal data through fsQCA to explain engagement in adaptive learning\n", "abstract": " Investigating and explaining the patterns of learners' engagement in adaptive learning conditions is a core issue towards improving the quality of personalized learning services. This article collects learner data from multiple sources during an adaptive learning activity, and employs a fuzzy set qualitative comparative analysis (fsQCA) approach to shed light to learners' engagement patterns, with respect to their learning performance. Specifically, this article measures and codes learners' engagement by fusing and compiling clickstreams (e.g., response time), physiological data (e.g., eye-tracking, electroencephalography, electrodermal activity), and survey data (e.g., goal-orientation) to determine what configurations of those data explain when learners can attain high or medium/low learning performance. For the evaluation of the approach, an empirical study with 32 undergraduates was conducted. The analysis\u00a0\u2026", "num_citations": "9\n", "authors": ["2149"]}
{"title": "Exploring causality within collaborative problem solving using eye-tracking\n", "abstract": " When students are working collaboratively and communicating verbally in a technology enhanced environment, the system is not aware of what collaboration is happening outside of the technology, making it difficult to adapt the system to better support the collaboration of the students. In this paper, we analyze the causal relationships between collaborative and individual gaze measures and the influence that the students dialogue, prior knowledge, or success has on these relationships to find indicators that can be used within an adaptive system. We found that when students are discussing concrete aspects of the problem, the causal relationship between their eye gaze measures changes compared to other types of dialogue patterns. The results also show a clear difference in causal relations when the pairs with high prior knowledge or success are compared with the pairs with low prior knowledge or\u00a0\u2026", "num_citations": "9\n", "authors": ["2149"]}
{"title": "The General Data Protection Regulation: An Opportunity for the HCI Community?\n", "abstract": " With HCI, researchers conduct studies in interdisciplinary projects involving massive volume of data, artificial intelligence and machine learning capabilities. Awareness of the responsibility is emerging as a key concern for the HCI community.", "num_citations": "9\n", "authors": ["2149"]}
{"title": "Using sensing technologies to explain children's self-representation in motion-based educational games\n", "abstract": " Motion-Based Touchless Games (MBTG) are being investigated as a promising interaction paradigm in children's learning experiences. Within these games, children's digital persona (ie, avatar), enables them to efficiently communicate their motion-based interactivity. However, the role of children's Avatar Self-Representation (ASR) in educational MBTG is rather under-explored. We present an in-situ within subjects study where 46 children, aged 8--12, played three MBTG with different ASRs. Each avatar had varying visual similarity and movement congruity (synchronisation of movement in digital and physical spaces) to the child. We automatically and continuously monitored children's experiences using sensing technology (eye-trackers, facial video, wristband data, and Kinect skeleton data). This allowed us to understand how children experience the different ASRs, by providing insights into their affective and\u00a0\u2026", "num_citations": "8\n", "authors": ["2149"]}
{"title": "Learner-computer interaction\n", "abstract": " Learner-Computer Interaction (LCI) research addresses the design, development and use of interactive technologies to support and amplify human learning. LCI is based on the rationale that learning while interacting with technology is a complex, multi-layered phenomenon, thus, designing the conditions for engaging in meaningful learning is vital in the 21st century, yet, it remains a challenging process. LCI developments are expected to contribute towards a coherent new, high-impact way of understanding and building learner-centered interaction concepts to support the design of future learning environments. LCI provides an interdisciplinary playground for researchers and professionals across all areas of learning technologies, psychology, learning science and human-computer interaction (HCI), with an ultimate objective of providing a forum at the intersection of these topical areas. LCI aims to develop a\u00a0\u2026", "num_citations": "8\n", "authors": ["2149"]}
{"title": "Nonstationary modelling of tail dependence of two subjects\u2019 concentration\n", "abstract": " We analyse eye-tracking data to understand how people collaborate. Our dataset consists of time series of measurements for eye movements, such as spatial entropy, calculated for each subject during an experiment when several pairs of participants collaborate to accomplish a task. We observe that pairs with high collaboration quality obtain their highest values of concentration (or equivalently lowest values of spatial entropy) occurring simultaneously. In this paper, we propose a flexible model that describes the tail dependence structure between two subjects\u2019 entropy when the pair is collaborating. More generally, we develop a generalized additive model (GAM) framework for tail dependence coefficients in the presence of covariates. As for any GAM-type model, the methodology can be used to predict collaboration quality or to explore how joint concentration depends on other cognitive operations and varies\u00a0\u2026", "num_citations": "8\n", "authors": ["2149"]}
{"title": "Measuring causality between collaborative and individual gaze metrics for collaborative problem\u2010solving with intelligent tutoring systems\n", "abstract": " When students are working collaboratively and communicating verbally in a technology\u2010enhanced environment, the system cannot track what collaboration is happening outside of the technology, making it difficult to fully assess the collaboration of the students and adapt accordingly. In this article, we propose using gaze measures as a proxy for cognitive processes to achieve collaboration awareness. Specifically, we use Granger causality to analyse the causal relationships between collaborative and individual gaze measures from students working on a fractions intelligent tutoring system and the influence that the students' dialogue, prior knowledge, or success has on these relationships. We found that collaborative gaze patterns drive the individual focus in the pairs with high posttest scores and when they are engaged in problem\u2010solving dialogues but the opposite with low performing students. Our work adds\u00a0\u2026", "num_citations": "7\n", "authors": ["2149"]}
{"title": "Improving girls\u2019 perception of computer science as a viable career option through game playing and design: Lessons from a systematic literature review\n", "abstract": " The objective of exposing girls to Computer Science as a career option has led to research directed towards gaming activities for girls. These activities include both game play and game design. Research about gaming activities for increasing girls\u2019 interest in computer science has gained much attention over the past few years and has resulted in a number of contributions. We follow up with an overview of the status of research through a Systematic Literature Review. We investigate the relation between the various game playing or designing activities and their impact on girls\u2019 perception of Computer Science as a career choice. We further present the design consideration for the games and related activities to potentially improve the perception of girls towards a Computer Science career. The applied method is a Systematic Literature Review through which we investigate which contributions were made, which\u00a0\u2026", "num_citations": "7\n", "authors": ["2149"]}
{"title": "Motion-Based Educational Games: Using Multi-Modal Data to Predict Player\u2019s Performance\n", "abstract": " Multi-Modal Data (MMD) can help educational games researchers understand the synergistic relationship between player\u2019s movement and their learning experiences, and consequently uncover insights that may lead to improved design of movement-based game technologies for learning. Predicting player performance fosters opportunities to cultivate heightened educational experiences and outcomes. However, predicting player\u2019s performance utilising player-generated MMD during their interactions with educational Motion-Based Touchless Games (MBTG) is challenging. To bridge this gap, we implemented an in-situ study where 26 users, age 11, played 2 maths MBTGs in a single 20-30 minute session. We collected player\u2019s MMD (i.e., gaze data from eye-tracking glasses, physiological data from wristbands, and skeleton data from Kinect) produced during game-play. To investigate the potential of MMD for\u00a0\u2026", "num_citations": "7\n", "authors": ["2149"]}
{"title": "Seeking information on social commerce: An examination of the impact of user-and marketer-generated content through an eye-tracking study\n", "abstract": " Following the growing popularity of social commerce sites, there is an increased interest in understanding how consumers decide what products to purchase based on the available information. Consumers nowadays are confronted with the task of assessing marketer-generated (MGC) as well as user-generated information (UGC) in a range of different forms to make informed purchase-related decisions. This study examines the information types and forms that influence consumers in their decision-making process on social commerce. Building on uses and gratifications and dual-process theories, we distinguish between marketer and user generated content, and differentiate formats into informational and normative. Using a mixed methods approach that builds on an eye-tracking study, followed by semi-structured interviews with 23 participants, our results indicate significant differences in the types and format of\u00a0\u2026", "num_citations": "7\n", "authors": ["2149"]}
{"title": "Modelling Learners\u2019 Behaviour: A Novel Approach Using GARCH with Multimodal Data\n", "abstract": " Most of the contemporary approaches in learner behaviour modelling either quantize continuous data into discrete states/events (e.g., HMM), or assume that the patterns in the data are distributed homogeneously in time (e.g., auto-regression). This paper proposes a novel approach that overcomes the above mentioned issues and models learner behaviour using Generalized Auto-Regressive Conditional Heteroskedasticity (GARCH). GARCH uses continuous time-series data, without the need for information quantization, and it considers the heterogeneity of event distribution in the time-series. A study was conducted to demonstrate how GARCH can be configured in an adaptive assessment setting. Specifically, GARCH was applied on six different constructs from eye-tracking and electroencephalogram (EEG) data, and compared with existing methods of modelling time-series data, such as Markov\u00a0\u2026", "num_citations": "7\n", "authors": ["2149"]}
{"title": "Towards automatic and pervasive physiological sensing of collaborative learning\n", "abstract": " We present a collaborative learning study contextualized within Project based Learning. The main aim of our contribution is to use the physiological data such as heart rate, skin temperature, electrodermal activity and blood volume pressure to quantify the learning experiences of the collaborating teams. We propose an automatic method to extract collaborative measures and study their relationship with the perceived performance, usefulness and satisfaction from the collaborative sessions from various student groups in a university degree course. We aim to contribute towards automatized, pervasive and more generalizable sensing of collaborative learning. Our results show that the synchrony in automatically extracted physiological states correlates positively with perceived performance and satisfaction of teams.", "num_citations": "7\n", "authors": ["2149"]}
{"title": "Digital storytelling for good with Tappetina game\n", "abstract": " ContextStorytelling is an important asset in today\u2019s society. Digital platforms for storytelling can facilitate collaborative development of stories. The storytelling process, if properly facilitated, can lead to the creation of stories that improve the relations between the players. Moreover, stories convey important information about the players and their interaction. Extended knowledge and better tools are needed about how to facilitate storytelling for good and analysis to exploit the power of the generated data.Research questionHow to facilitate Digital Storytelling for good?MethodThe investigation is based on a case study approach in which participants have been engaged in the creation of stories. The study is based on empirical data collection and analysis: from the stories recorded, we extract the storytelling features and performance. We have provided qualitative (Domain Expert) and quantitative (Machine Learning\u00a0\u2026", "num_citations": "6\n", "authors": ["2149"]}
{"title": "An application of extreme value theory to learning analytics: predicting collaboration outcome from eye-tracking data\n", "abstract": " The statistics used in education research are based on central trends such as the mean or standard deviation, discarding outliers. This paper adopts another viewpoint that has emerged in Statistics, called the Extreme Value Theory (EVT). EVT claims that the bulk of the normal distribution is mostly comprised of uninteresting variations while the most extreme values convey more information. We applied EVT to eye-tracking data collected during online collaborative problem solving with the aim of predicting the quality of collaboration. We compare our previous approach, based on central trends, with an EVT approach focused on extreme episodes of collaboration. The latter occurred to provide a better prediction of the quality of collaboration.", "num_citations": "6\n", "authors": ["2149"]}
{"title": "Towards predicting success in MOOCs: Programming assignments\n", "abstract": " Students of programming languages in massive on-line open courses (MOOCs) solve programming assignments in order to internalize the concepts. Programming assignments also constitute the assessment procedure for such courses. Depending on their motivation and learning styles, students pursue different strategies. We identify which approach to attempt these assignments results in better performance. We predict students\u2019 success from their online behaviour; and identify different paths students chose in order to complete the MOOC. We also discuss how students resign from the course after having difficulties with assignments. Moreover, we also predict, when would a student give-up (or succeed) submitting solutions to a given assignment.", "num_citations": "6\n", "authors": ["2149"]}
{"title": "Gaze analysis methods for learning analytics\n", "abstract": " Eye-tracking had been shown to be predictive of expertise, task-based success, task-difficulty, and the strategies involved in problem solving, both in the individual and collaborative settings. In learning analytics, eye-tracking could be used as a powerful tool, not only to differentiate between the levels of expertise and task-outcome, but also to give constructive feedback to the users. In this dissertation, we show how eye-tracking could prove to be useful to understand the cognitive processes underlying dyadic interaction; in two contexts: pair program comprehension and learning with a Massive Open Online Course (MOOC). The first context is a typical collaborative work scenario, while the second is a special case of dyadic interaction namely the teacher-student pair.We also demonstrate, using one example experiment, how the findings about the relation between the learning outcome in MOOCs and the students\u2019 gaze patterns can be leveraged to design a feedback tool to improve the students\u2019 learning outcome and their attention levels while learning through a MOOC video. We also show that the gaze can also be used as a cue to resolve the teachers\u2019 verbal references in a MOOC video; and this way we can improve the learning experiences of the MOOC students.", "num_citations": "6\n", "authors": ["2149"]}
{"title": "Children\u2019s play and problem-solving in motion-based learning technologies using a multi-modal mixed methods approach\n", "abstract": " Motion-Based Learning Technologies (MBLT) offer a promising approach for integrating play and problem-solving behaviour within children\u2019s learning. The proliferation of sensor technology has driven the field of learning technology towards the development of tools and methods that may benefit from the produced Multi-Modal Data (MMD). Such data can be used to uncover cognitive, affective and physiological processes during learning activities. Combining MMD with more traditionally exercised assessment tools, such as video content analysis, provides a more holistic understanding of children\u2019s learning experiences and has the potential to enable the design of educational technologies capable of harmonising children\u2019s cognitive, affective and physiological processes, while promoting appropriately balanced play and problem-solving efforts. However, the use of an MMD mixed methods approach that\u00a0\u2026", "num_citations": "5\n", "authors": ["2149"]}
{"title": "Sensing technologies and child-computer interaction: Opportunities, challenges and ethical considerations\n", "abstract": " This study presents the outcomes of a systematic literature review of empirical evidence on the capabilities of sensing technologies for child\u2013computer interaction (CCI). This paper provides an overview of what and how sensing technologies have been used to explain, understand, and predict children\u2019s experiences with interactive devices and technologies and in what contexts. A search resulted in 44 papers that were included in the analysis. The results of the review depict the capabilities of sensing technologies for gauging children\u2019s performance, engagement, and experiences (while interacting with technology) and the ongoing advances and implications that emerge from the employment of sensors to capture and improve child behavior. In particular, we identified the four main objectives (i.e., engagement of children, recognition/prediction of special needs/behavior, explaining/understanding the behavior\u00a0\u2026", "num_citations": "5\n", "authors": ["2149"]}
{"title": "Information flow and cognition affect each other: Evidence from digital learning\n", "abstract": " In the context of learning systems, identifying causal relationships among information presented to the user, their behavior and cognitive effort required/exerted to understand and perform a task is key to building effective learning experiences, and to maintain engagement in learning processes. An unexplored question is whether our interaction with presented information affects our cognitive effort (and behaviour), or vice-versa. We investigate causal relationship between information presented and cognitive effort (and behaviour) in the context of two separate studies (N = 40, N = 98), and study the effect of instruction (active/passive task). We utilize screen-recordings and eye-tracking data to investigate the relationship among these variables. To investigate the causal relationships among the different measurements, we use Granger\u2019s causality. Further, we propose a new method to combine two time-series from\u00a0\u2026", "num_citations": "5\n", "authors": ["2149"]}
{"title": "Systems, methods and programmed products for dynamically tracking delivery and performance of digital advertisements in electronic digital displays\n", "abstract": " Systems and methods for dynamically tracking delivery and performance of digital advertising placed on non-personal devices in physical locations and integrating, displaying, and reporting impressions and events in digital advertising systems.", "num_citations": "4\n", "authors": ["2149"]}
{"title": "Gaze as a Proxy for Cognition and Communication\n", "abstract": " We investigate the potential of gaze as a predictor for the quality of dialogue and the level of understanding in collaborative problem-solving. We unveil a triangular relation among collaborators' dialogue, their gaze pattern, and their performance in the context of a pair programming task. Pairs of participants were asked to understand a JAVA program while their gaze was synchronously recorded. The performance was measured as the level of understanding attained by the pair at the end of the program comprehension task. Gaze patterns were analyzed based on probabilistic hit based areas of interest called gaze tokens. A novel dialogue coding scheme was developed to capture the program description as well as collaboration management aspect of pair program understanding. Both the areas of interest and the dialogue codes reflect top-down and bottom-up program comprehension strategies. Results show\u00a0\u2026", "num_citations": "4\n", "authors": ["2149"]}
{"title": "Interlacing Gaze and Actions to Explain the Debugging Process\n", "abstract": " Debugging is an indispensable skill of successful programmers. As such, teacher\u2019s should not overlook it when teaching programming. The main aim of the study is to use gaze data combined with measures at different temporal granularities to show how these measures are related to the outcomes (in particular debugging success as a learning by doing outcome) students have at the end of the debugging task. The results delineate that combining gaze data with actions (reading, writing, scrolling) and unit tasks (main method and JUnit test) gives new insights to further understand the cognitive actions in debagging a program. Moreover, this study also focuses on discovering debugging patterns of successful students in order to improve the design of learning activities to teach students how to debug. Finally, with the analysis, the authors have shown an automatic way of detecting successful action-gaze patterns.", "num_citations": "4\n", "authors": ["2149"]}
{"title": "Cscl and eye-tracking: Experiences, opportunities and challenges\n", "abstract": " The idea of using gaze as a medium to look into the collaborative processes had been around in CSCL for past few years. However, it had not been widely used in the community. Most of the works done in the direction of understanding collaborative cognition are majorly based on the qualitative methods. Research has shown that the collaborative gaze data can be used as an alternate source of information to assess collaboration. Once, we understand the how the gaze data reflects the collaboration quality and success, we could design gaze-aware systems to support remote/collocated collaboration. In this symposium, we bring together five papers that use eye-tracking data as a proxy for communication and cognition during remote/collocated collaborative learning and propose design of gaze-aware systems.", "num_citations": "4\n", "authors": ["2149"]}
{"title": "Consumer shopping decision making styles at Departmental Stores: An exploratory study of gender differences\n", "abstract": " Retailing has brought about an immense change in the economy today. It entails direct access to a customer\u2019s needs. The present study focuses on the Organized Retailing Sector. It has been argued that gender is of immense importance when it comes to a retail activity. Since gender has been identified in much literature on consumer shopping behavior as a significant factor in understanding consumer behavior and as a fundamental market segmentation index for companies to meet their customers\u2019 needs and wants, marketers should strive to understand the gender differences in decision-making styles. Research addressing the issue of gender differences in decision-making styles could help marketers to find better ways of communicating with both sexes and to guide marketing mix decisions (Mitchell & Walsh, 2004). This research will contribute to the body of consumer behavior literature by investigating the decision-making styles of male and female consumers in Mumbai using the Sproles and Kendall\u2019s (1986) 40-item Consumer Style Inventory (CSI). Specifically, this research examined the interrelationships among observed variables and subsequently, a model of interrelationships was created by means of exploratory factor analysis. The sample for the study was 100 respondents from Mumbai. One of the key findings of this study is the confirmation of gender differences in decision-making styles among young-adult consumers.", "num_citations": "4\n", "authors": ["2149"]}
{"title": "Children\u2019s play and problem solving in motion-based educational games: synergies between human annotations and multi-modal data\n", "abstract": " Identifying and supporting children\u2019s play and problem solving behaviour is important for designing educational technologies. This can inform feedback mechanisms to scaffold learning (provide hints or progress information), and assist facilitators (teachers, parents) in supporting children. Traditionally, researchers manually code video to dissect children\u2019s nuanced play and problem solving behaviour. Advancements in sensing technologies and their respective Multi-Modal Data (MMD), afford observation of invisible states (cognitive, affective, physiological), and provide opportunities to inspect internal processes experienced during learning and play. However, limited research combines traditional video annotations and MMD to understand children\u2019s behaviour as they interact with educational technology. To address this concern, we collected data from webcam, wristband, eye-trackers, and Kinect, as 26 children\u00a0\u2026", "num_citations": "3\n", "authors": ["2149"]}
{"title": "Characterizing Learners\u2019 Engagement in MOOCs: An Observational Case Study Using the NoteMyProgress Tool for Supporting Self-Regulation\n", "abstract": " Recent research shows that learners who are able to self-regulate their learning show greater levels of engagement with massive open online course (MOOC) content. To improve support for learners in their self-regulatory processes, researchers have proposed technological solutions to transform recorded MOOC data into actionable knowledge. However, studies providing empirical evidence on how these solutions impact learners\u2019 engagement with the course and their self-regulatory behavior remain scarce. In this article, we present the results of an observational case study in which NoteMyProgress (NMP), a web-based tool designed to support learners\u2019 self-regulation in MOOCs, is applied as an intervention in two MOOCs. The main aim of this article is to provide insights into how the support of learners\u2019 self-regulated learning (SRL) strategies correlates with course engagement. We performed the evaluation\u00a0\u2026", "num_citations": "3\n", "authors": ["2149"]}
{"title": "Multimodal Learning Analytics to Inform Learning Design: Lessons Learned from Computing Education.\n", "abstract": " Programming is a complex learning activity that involves coordination of cognitive processes and affective states. These aspects are often considered individually in computing education research, demonstrating limited understanding of how and when students learn best. This issue confines researchers to contextualize evidencedriven outcomes when learning behaviour deviates from pedagogical intentions. Multimodal learning analytics (MMLA) captures data essential for measuring constructs (eg, cognitive load, confusion) that are posited in the learning sciences as important for learning, and cannot effectively be measured solely with the use of programming process data (IDE-log data). Thus, we augmented IDE-log data with physiological data (eg, gaze data) and participants\u2019 facial expressions, collected during a debugging learning activity. The findings emphasize the need for learning analytics that are consequential for learning, rather than easy and convenient to collect. In that regard, our paper aims to provoke productive reflections and conversations about the potential of MMLA to expand and advance the synergy of learning analytics and learning design among the community of educators from a post-evaluation design-aware process to a permanent monitoring process of adaptation.", "num_citations": "3\n", "authors": ["2149"]}
{"title": "Stimuli-based gaze analytics to enhance motivation and learning in MOOCs\n", "abstract": " The interaction with the various learners in a Massive Open Online Course (MOOC) is often complex. Contemporary MOOC learning analytics relate with click-streams, keystrokes and other user-input variables. Such variables however, do not always capture learners' learning and behavior (e.g., passive video watching). In this paper, we present a study with 40 students who watched a MOOC lecture while their eye-movements were being recorded. We then proposed a method to define stimuli-based gaze variables that can be used for any kind of stimulus. The proposed stimuli-based gaze variables indicate students' attention (i.e., with-me-ness), at the perceptual (following teacher's deictic acts) and conceptual levels (following teacher discourse). In our experiment, we identified a significant mediation effect of the two levels of with-me-ness on the relation between students' motivation and their learning\u00a0\u2026", "num_citations": "3\n", "authors": ["2149"]}
{"title": "GPU based computational simulation of aircraft evacuation: temporal and spatial analysis\n", "abstract": " The effectiveness of Aircraft Emergency Evacuation plays a vital role in the safety of the passengers on board an Aircraft, in case of Emergency landing. In this paper, the implementation and development of a Cellular Automata (CA) based simulator which can be used to simulate the Aircraft Evacuation process is presented. Given the seat-map of the Aircraft, number of passengers, passenger feature distribution and number of functional exits, the simulator can calculate the approximate time of Evacuation. For computational implementation, a bi-dimensional as well as uni-dimensional grid which represents the 2D Aircraft seat-map and an agent which control the passenger movement during Evacuation of the Aircraft is used. Each agent represents a passenger and is characterized by the properties of a human being. An agent has properties like age, sex, walking speed, response time, position and status. The\u00a0\u2026", "num_citations": "3\n", "authors": ["2149"]}
{"title": "Determining consumer engagement in word-of-mouth: trust and network ties in a social commerce setting\n", "abstract": " Prompted by the popularity of social commerce in the past few years, this study seeks to examine how online reviews influence consumer\u2019s tendency to engage in word-of-mouth (WOM). We investigate how different aspects pertinent to online reviews affect consumers trust, and how that in turn induces WOM passing and WOM giving. The moderating influence of network ties is studied in the trust to WOM relationship. Building on survey-based study design with a sample of 385 social commerce consumers, we that specific aspects induce a sense of trust towards vendors. In turn, our study demonstrates that trust positively influences WOM passing and WOM giving and this relationship is amplified in conditions of strong network ties. We conclude the paper summarizing the findings and drawing theoretical and practical implications that arise.", "num_citations": "3\n", "authors": ["2149"]}
{"title": "Looking THROUGH versus looking AT: A strong concept in technology enhanced learning\n", "abstract": " When watching an educational video, our eyes look for relevant information related to the topic that is being explained at that particular moment. Studying the learners\u2019 gaze behavior and particularly how it correlates with their performance, we have found a series of results, which converge to an understanding about learner behavior that is more abstracted than the use situation or the studied learning contexts. In this contribution we present \u201cLooking Through vs. Looking At\u201d as a generative intermediate-level body of knowledge, and show how it can construct a Strong Concept (as developed by H\u00f6\u00f6k\u00a0[10]) in technology enhanced learning (TEL). \u201cLooking At\u201d, simply put, refers to missing the relevant information because of either looking at the incorrect place or lagging behind the teacher in time. \u201cLooking Through\u201d, on the other hand, is the success in finding the relevant displayed information at the right\u00a0\u2026", "num_citations": "3\n", "authors": ["2149"]}
{"title": "Contextualizing the co-creation of artefacts within the nested social structure of a collaborative MOOC\n", "abstract": " MOOCs have traditionally been seen as providing an individual learning experience, however there is an increasing trend towards enabling social learning in MOOCs. To make online learning at scale more social and collaborative, some MOOCs have introduced cohorts. The interaction between a smaller number of learners, within a cohort, facilitates a richer exchange of experiences and ideas as compared to the effect of \u201cdrinking from the fire hose\u201d felt in MOOCs without cohorts. Traditionally, these cohorts have been formed randomly. In this paper, we examine the MOOC \u201cInquiry and Technology for Teachers\u201d, where we formed cohorts based on student demographics relevant to our course design. Furthermore, these cohorts (which we called Special Interest Groups, SIGs) contained a nested social structure of small teams that worked together on co-creating a final artifact. The different social planes\u00a0\u2026", "num_citations": "3\n", "authors": ["2149"]}
{"title": "Task based teaching: Using modals for ESL learners\n", "abstract": " Ms. Krati Sharma works as a lecturer with the Department of English, Jaipur National University.", "num_citations": "3\n", "authors": ["2149"]}
{"title": "How quickly can we predict users\u2019 ratings on aesthetic evaluations of websites? Employing machine learning on eye-tracking data\n", "abstract": " This study examines how quickly we can predict users\u2019 ratings on visual aesthetics in terms of simplicity, diversity, colorfulness, craftsmanship. To predict users\u2019 ratings, first we capture gaze behavior while looking at high, neutral, and low visually appealing websites, followed by a survey regarding user perceptions on visual aesthetics towards the same websites. We conduct an experiment with 23 experienced users in online shopping, capture gaze behavior and through employing machine learning we examine how fast we can accurately predict their ratings. The findings show that after 25 s we can predict ratings with an error rate ranging from 9% to 11% depending on which facet of visual aesthetic is examined. Furthermore, within the first 15 s we can have a good and sufficient prediction for simplicity and colorfulness, with error rates 11% and 12% respectively. For diversity and craftsmanship, 20 s are needed\u00a0\u2026", "num_citations": "2\n", "authors": ["2149"]}
{"title": "CrossMMLA in practice: Collecting, annotating and analyzing multimodal data across spaces\n", "abstract": " Learning is a complex processthat is associated with many aspects of interaction and cognition (e.g., hard mental operations, cognitive friction etc.) and that can take across diverse contexts (online, classrooms, labs, maker spaces, etc.). The complexity of this process and its environments means that it is likely that no single data modality can paint a complete picture of the learning experience, requiring multiple data streams from different sources and times to complement each other. The need to understand and improve learning that occurs in ever increasingly open, distributed, subject-specific and ubiquitous scenarios, require the development of multimodal and multisystem learning analytics. Following the tradition of CrossMMLA workshop series, the proposed workshop aims to serve as a place to learn about the latest advances in the design, implementation and adoption of systems that take into account the different modalities of human learning and the diverse settings in which it takes place. Apart from the necessary interchange of ideas, it is also the objective of this workshop to develop critical discussion, debate and co-development of ideas for advancing the state-of-the-art in CrossMMLA.", "num_citations": "2\n", "authors": ["2149"]}
{"title": "Exploring EEG signals during the different phases of game-player interaction\n", "abstract": " Games are nowadays used to enhance different learning and teaching practices in institutions, companies and other venues. Factors that increase the adoption and integration of learning games have been widely studied in the past. However, the effect of different backgrounds and designs on learners'/players' electroencephalographic (EEG) signals during game-play remains under-explored. These insights may enable us to design and utilize games in a way that adapts to users' cognitive abilities and facilitates learning. In this paper, we describe a controlled study consisted of 251 game sessions and 17 players that focused on skill development (i.e., user's ability to master complex tasks), while collecting EEG and game-play data. Our results unveiled factors that relate to the game-phases and learners'/players' expertise and affect their mental effort when playing a learning game. In particular, our analysis showed\u00a0\u2026", "num_citations": "2\n", "authors": ["2149"]}
{"title": "Social commerce and consumer search behavior: An eye-tracking study\n", "abstract": " Following the increasing popularity of social commerce sites, this study investigates the information sources and forms that affect consumers in their decision-making process. Building on the theoretical underpinnings of uses and gratifications and dual-process theories, we distinguish between marketer and user generated content, and differentiate formats into informational and normative. Using an eyetracking approach on a popular social commerce site with a sample of 23 participants, we find significant differences in the types and format of information consumed for selected versus eliminated products. Specifically, we looked at engagement, cognitive processing, and observation of consumers, since they reveal information about the mental and processing mechanisms during decision making. We find that consumers present a number of differences in terms of these measures among the different types of content, and with respect to selected versus eliminated products. We conclude the paper summarizing the findings and drawing theoretical and practical implications.", "num_citations": "2\n", "authors": ["2149"]}
{"title": "A Comparison of Gaze Behavior of Experts and Novices to Explain Website Visual Appeal.\n", "abstract": " The present study examines how gaze behavior relates with users\u2019 expertise in evaluating the visual appeal of a website. We adopt four facets of visual aesthetics (ie, simplicity, diversity, colorfulness, craftsmanship) and explain how ones\u2019 expertise may change the way he or she looks at a high or low appealing website. We employ eye-tracking techniques to capture users\u2019 gaze behavior while looking at high and low appealing e-commerce websites, on a sample of 23 users with previous experience in e-commerce. The findings show that expert users\u2019 make more careful observations, have a deeper cognitive processing, demonstrate less anticipation, along with more local processing and engagement with the task than novices. Also, gaze behavior remains the same for both low and high appealing websites. The study contributes by providing evidence on how to capture and use gaze data from experts to train new and inexperienced users to have more accurate judgements about the aesthetics of websites, and thus improving both user experience and website design.", "num_citations": "2\n", "authors": ["2149"]}
{"title": "On generalizability of MOOC models\n", "abstract": " The big data imposes the key problem of generalizability of the results. In the present contribution, we discuss statistical tools which can help to select variables adequate for target level of abstraction. We show that a model considered as over-fitted in one context can be accurate in another. We illustrate this notion with an example analysis experiment on the data from 13 university Massive Online Open Courses (MOOCs). We discuss statistical tools which can be helpful in the analysis of generalizability of MOOC models.", "num_citations": "2\n", "authors": ["2149"]}
{"title": "Eye tracking with educational robots: A cautionary tale\n", "abstract": " We present an eye-tracking study on an educational robot Thymio II with 52 participants. The participants observed the robot detecting obstacles in the first phase of the experiment and they interacted with the robot in the second phase of the experiment. Finally, they were asked to explain the functionality of the robot. The gaze of the participants was recorded during both the phases. The values from the robot\u2019s sensors were visualized on the robot\u2019s body using LEDs in two different ways in the two experimental conditions and there was no sensor data visualization in the control condition. We found that the sensor data visualization has an impact on the gaze patterns and the performance of the participants. The main goal of the experiment was to investigate that eye tracking could bring insights to the effectiveness of the interaction between the human user and the robot.", "num_citations": "2\n", "authors": ["2149"]}
{"title": "Exploring students' cognitive and affective states during problem solving through multimodal data: Lessons learned from a programming activity\n", "abstract": " Background Problem\u2010solving is a multidimensional and dynamic process that requires and interlinks cognitive, metacognitive, and affective dimensions of learning. However, current approaches practiced in computing education research (CER) are not sufficient to capture information beyond the basic programming process data (i.e., IDE\u2010log data). Therefore, how cognition and affect intertwine and unfold over time in programming problem\u2010solving activities are rarely investigated.   Objectives In this study, we examined how the theory\u2010informed measures from multimodal data that we have selected as proxies for cognitive and affective dimensions of learning, are associated with student performance, and in comparison, to prior\u2010knowledge.   Methods A high\u2010frequency temporal data was collected with a camera, an electroencephalogram, and an eye\u2010tracker from 40 computer science students (bachelor and master\u00a0\u2026", "num_citations": "1\n", "authors": ["2149"]}
{"title": "Challenging Joint Visual Attention as a Proxy for Collaborative Performance\n", "abstract": " Researchers have used joint visual attention (JVA) as a proxy for collaborative quality and/or performance during the last decade due to its association with both measures. However, the notion of looking at the same object does not necessarily indicate that students are solving the problem together (or learning together). We propose a complementary approach to joint visual attention by augmenting it with joint mental effort (JME). JME is computed as a cross-recurrence of the cognitive load of the peers in a dyad. We use data from 41 dyads to show the synergy between JVA and JME and the insights that they can shed in the collaborative process. The results show that in certain episodes of collaboration (characterized by the dialogue and division of labor strategy of the dyad) combining these two dual-eye tracking measures provide deeper insights about the collaborative processes and performance than JVA alone.", "num_citations": "1\n", "authors": ["2149"]}
{"title": "Children's Interaction with Motion-Based Touchless Games: Kinecting Effectiveness and Efficiency\n", "abstract": " Leveraging movement data to support children's learning is appealing and technically challenging. However, there is limited knowledge about exploiting the complete design potential of bodily interplay in learning games. We conducted an in-the-wild study with 8 children, with special educational needs, playing a language based educational motion-based touchless game. We collected children's interaction data (correctness and reaction time), and data regarding the different design elements (game settings) implemented in 90 game sessions. Our analysis shows that number of items on-screen, selection gestures, and time to select items, impact the effectiveness (correctness) and efficiency (reaction time) of the children. We highlight the value of interaction analytics and quantify the relationship between different game design elements and children? s efficiency and effectiveness. Our findings help shape the future\u00a0\u2026", "num_citations": "1\n", "authors": ["2149"]}
{"title": "On the Dependence Structure Between Learners' Response-time and Knowledge Mastery: If Not Linear, Then What?\n", "abstract": " Popular approaches in learner modeling explore response-time as observational data supplemental to response correctness, to enrich the predictive models of learner knowledge. It has been argued that the relationship between response-time and knowledge mastery is non-linear. Determining the degree of association (dependence structure) between those two observations is an open question. To address this objective, we propose an approach based on copulas, ie, a statistical tool suitable for capturing dependence structure between two variables. All of the information about the dependence structures can be estimated by copula models separately, allowing for the construction of more flexible joint distributions than existing multivariate distributions. This paper puts into practice a two-step pipeline for building the analytical models. Specifically, we propose a flexible copula-based approach that describes the\u00a0\u2026", "num_citations": "1\n", "authors": ["2149"]}
{"title": "Using Multimodal Learning Analytics to Explore how Children Experience Educational Motion-Based Touchless Games\n", "abstract": " Leveraging motion-based touchless games (MBTG) to support children\u2019s learning is appealing and technically challenging. The application of multimodal learning analytics (MMLA) can help researchers to better understand how children experience learning through movement by providing insights into children\u2019s cognitive, behavioural, interaction, and learning processes. However, there is limited knowledge about exploiting the integration of MMLA into the use of educational MBTG in children\u2019s learning. We present an in-progress study in which we conducted an experiment with 55 children, playing three different educational MBTG centred on the development of math and English competencies. We collected multimodal data from 6 different sources: eye-tracking glasses, video, wristband, game analytics, Kinect point cloud, and questionnaires. Future analysis will explore relationships between the various multimodal data, in pursuit of establishing a more holistic understanding of children\u2019s cognitive, behavioural, interaction, and learning processes experienced while engaged with MBTG for learning.", "num_citations": "1\n", "authors": ["2149"]}
{"title": "An Alternate Statistical Lens to Look at Collaboration Data: Extreme Value Theory\n", "abstract": " To provide beneficial feedback to students during their collaboration, it is important to identify behaviors that are indicative of good collaboration. However, in a collaborative learning session, students engage in a range of behaviors and it can be difficult to indicate which of those behaviors correlate with higher outcomes. In this paper, we propose using Extreme Value Theory (EVT), a method that considers the data points in the tail (upper or lower) of the distribution, to analyse the relationship between collaborative process variables and outcome measures through insights derived from high impact, low-frequency events. Specifically, in this paper, we analyse the relationship between dual gaze patterns and outcome measures across two different datasets. In both datasets we found that students with lower outcomes had lower focus during the collaborative session. This paper provides a contribution by both introducing EVT as a viable method for analysing CSCL data as well as demonstrating the effectiveness of eye- tracking as a collaborative indicator to use to adapt to in real-time.", "num_citations": "1\n", "authors": ["2149"]}
{"title": "Semantically Meaningful Cohorts Enable Specialized Knowledge Sharing in a Collaborative MOOC\n", "abstract": " This study presents an analysis of a MOOC on inquiry and technology for in-service teachers, which was designed to scaffold multiple disciplinary knowledge communities through common weekly themes, and course-long collaboration scripts happening at different social planes. Using our course design to inform the design of the analysis, we examine how the discourse in each semantically meaningful cohort (Special Interest Groups, SIGs) is indexed to the weekly themes, and develops these themes in areas informed by the discipline, and by the group dynamics. We show that SIG membership influences individual contributions, and that more cohesive disciplinary SIGs are correlated with higher quality student work.", "num_citations": "1\n", "authors": ["2149"]}
{"title": "Kid Coding Games and Artistic Robots: Attitudes and Gaze Behavior\n", "abstract": " We present a study in the context of coding activities for children. Our main focus is towards understanding the relation between children's attitudes towards coding and their behaviour while coding. Forty-four school children participated in this study solving different coding problems. We used mixed methods to capture attitude and behaviour of the children participating in the study. The attitudes towards learning to program were recorded using the self-reporting questionnaires and the behaviour was captured using the eye-trackers. The results show that the gaze-behaviour of the children moderates the relationship among the different attitudes towards coding.", "num_citations": "1\n", "authors": ["2149"]}
{"title": "\u00c9tude du comportement des apprenants dans les travaux pratiques et de sa corr\u00e9lation avec la performance acad\u00e9mique\n", "abstract": " sem-link sem-link R\u00e9mi Venant sem-link sem-link Kshitij Sharma sem-link sem-link Philippe Vidal sem-link sem-link Pierre Dillenbourg sem-link sem-link Julien Broisin", "num_citations": "1\n", "authors": ["2149"]}
{"title": "Utilizing Real-Time Descriptive Learning Analytics to Enhance Learning Programming\n", "abstract": " The focus of this case study is the usage of visualized learning analytics coupled with the provision of feedback and support provided to the students and their impact in provoking change at student programming habits. To this end, this", "num_citations": "1\n", "authors": ["2149"]}
{"title": "Firewall and Load Balancer Implementation in Software Defined Networking\n", "abstract": " It has become increasingly clear that the there existsa need, to restructure the networks of today into something whichis much more dynamic, scalable and manageable. The networksof the present day are largely inflexible and are failing to copewith the ever changing demands of the changing IT atmosphere. Software Defined Networking (SDN) is an emerging paradigm that aims to transform todays networking infrastructure andintroduce flexible programmability by separating the data planeand the control plane, ie, it facilitates the building of applicationson the top of the data and control plane resulting in increasedflexibility. This paper focuses on the basic operations in OpenFlowprotocol based SDN controller, namely the floodlight controller. The study includes packet forwarding through the firewall andload balancing applications of the floodlight controller. Theimplementation details as well as the results achieved during the study are tabulated.", "num_citations": "1\n", "authors": ["2149"]}
{"title": "Dual Gaze as a Proxy for Collaboration in Informal Learning\n", "abstract": " Interactive displays are increasingly employed in informal learning environments as a technology for enhancing students\u2019 learning and engagement. Interactive displays allow students to collaborate and interact with the content in a natural and engaging manner. Despite the increased prevalence of interactive displays for learning, we know very little about how students collaborate in such settings and how this collaboration influences their performance. In this dual eye-tracking study, with 36 participants, a two-staged within-group experiment was conducted to investigate students\u2019 collaboration and learning gains in an interactive display. The results show that collaboratively, pairs who have high gaze similarity have high learning outcomes. Individually, participants spending high proportions of time in acquiring the complementary information from images and textual parts of the learning material attain high learning outcomes. We show that the gaze is an effective proxy to cognitive mechanisms underlying collaboration not only in formal settings but also in informal learning scenarios.", "num_citations": "1\n", "authors": ["2149"]}
{"title": "Dual Eye Tracking for Pair Programming\n", "abstract": " Pair programming practices often yield better results than the solo programming. Eye-tracking research in pair programming aims at understanding the relation between gaze based indicators and various socio-cognitive descriptors such as task based task-performance and collaboration quality. Understanding such relations is a prerequisite in designing softwares that support collaboration and collaborative learning, both in terms of functionalities and interface design. Thus, we propose studying dual eye-tracking setup in pair programming scenario for understanding the relation between gaze patterns and underlying cognitive and collaborative processes.", "num_citations": "1\n", "authors": ["2149"]}