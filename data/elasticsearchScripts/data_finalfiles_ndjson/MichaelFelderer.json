{"title": "Security testing: A survey\n", "abstract": " Identifying vulnerabilities and ensuring security functionality by security testing is a widely applied measure to evaluate and improve the security of software. Due to the openness of modern software-based systems, applying appropriate security testing techniques is of growing importance and essential to perform effective and efficient security testing. Therefore, an overview of actual security testing techniques is of high value both for researchers to evaluate and refine the techniques and for practitioners to apply and disseminate them. This chapter fulfills this need and provides an overview of recent security testing techniques. For this purpose, it first summarize the required background of testing and security engineering. Then, basics and recent developments of security testing techniques applied during the secure software development life cycle, ie, model-based security testing, code-based testing and static\u00a0\u2026", "num_citations": "147\n", "authors": ["1137"]}
{"title": "Research challenges of industry 4.0 for quality management\n", "abstract": " By promising huge benefits for industries and new opportunities for a multitude of applications, Industry 4.0 is currently one of the major and most discussed topics in academia and practice. Beside this trend, today\u2019s manufacturing companies have to produce products of highest quality in order to retain competitive and satisfy the steadily increasing customer requirements. Thus, an essential prerequisite and key to sustainable economical success for any company is to focus on quality management. Through its concepts (Smart Factory, Cyber-Physical System, Internet of Things and Services), Industry 4.0 provides promising opportunities for quality management. Therefore, this paper presents research challenges of Industry 4.0 for quality management motivated by a practical insight of an Austrian electronic manufacturing services company. The presented research challenges are structured by the three key\u00a0\u2026", "num_citations": "133\n", "authors": ["1137"]}
{"title": "A taxonomy of risk-based testing\n", "abstract": " Software testing has often to be done under severe pressure due to limited resources and a challenging time schedule facing the demand to assure the fulfillment of the software requirements. In addition, testing should unveil those software defects that harm the mission-critical functions of the software. Risk-based testing uses risk (re-)assessments to steer all phases of the test process to optimize testing efforts and limit risks of the software-based system. Due to its importance and high practical relevance, several risk-based testing approaches were proposed in academia and industry. This paper presents a taxonomy of risk-based testing providing a framework to understand, categorize, assess, and compare risk-based testing approaches to support their selection and tailoring for specific purposes. The taxonomy is aligned with the consideration of risks in all phases of the test process and consists of the\u00a0\u2026", "num_citations": "107\n", "authors": ["1137"]}
{"title": "Model\u2010based security testing: a taxonomy and systematic classification\n", "abstract": " Model\u2010based security testing relies on models to test whether a software system meets its security requirements. It is an active research field of high relevance for industrial applications, with many approaches and notable results published in recent years. This article provides a taxonomy for model\u2010based security testing approaches. It comprises filter criteria (i.e.\u00a0model of system security, security model of the environment and explicit test selection criteria) as well as evidence criteria (i.e.\u00a0maturity of evaluated system, evidence measures and evidence level). The taxonomy is based on a comprehensive analysis of existing classification schemes for model\u2010based testing and security testing. To demonstrate its adequacy, 119 publications on model\u2010based security testing are systematically extracted from the five most relevant digital libraries by three researchers and classified according to the defined filter and\u00a0\u2026", "num_citations": "100\n", "authors": ["1137"]}
{"title": "Ten principles for living models-a manifesto of change-driven software engineering\n", "abstract": " The new generation of open networked IT systems poses particular challenges to software engineering due to their evolving nature and their high quality requirements. In particular, the management of service oriented systems requires the integration of perspectives from IT management, software engineering and systems operation and a systematic way to handle changes. In this paper we will present the core ideas of Living Models - a novel paradigm of model-based development, management and operation of evolving service oriented systems. A core concern of Living Models is to support the cooperation of stakeholders from IT management, software engineering and systems operation by providing appropriate model-based abstractions and the fostering of interdependencies. Based on this idea the running services together with their modelling environments constitute the basic unit of quality management and\u00a0\u2026", "num_citations": "84\n", "authors": ["1137"]}
{"title": "A classification for model-based security testing\n", "abstract": " Security testing defines tests for security requirements of software. Security requirements are non-functional, and thus require a different way of testing compared to functional requirements. Model-based testing applies model-based design for modeling test artifacts or the automation of test activities. Although model-based testing techniques improve security testing, these two testing activities have rarely been combined systematically. Like functional system models improve functional testing, risk models can improve security testing. This paper first gives an overview of existing security testing approaches, and based on that, develops a novel classification for modelbased security tests along the two dimensions risk and automated test generation. The classification allows for understanding which areas of model-based security testing are already well-covered by research and practice, and furthermore, can serve as a guideline for deciding which testing approach fits specific circumstances. Based on the classification, we identify tasks for interesting future research.", "num_citations": "51\n", "authors": ["1137"]}
{"title": "Comparison of the FMEA and STPA safety analysis methods\u2013a case study\n", "abstract": " As our society becomes more and more dependent on IT systems, failures of these systems can harm more and more people and organizations. Diligently performing risk and hazard analysis helps to minimize the potential harm of IT system failures on the society and increases the probability of their undisturbed operation. Risk and hazard analysis is an important activity for the development and operation of critical software intensive systems, but the increased complexity and size puts additional requirements on the effectiveness of risk and hazard analysis methods. This paper presents a qualitative comparison of two hazard analysis methods, failure mode and effect analysis (FMEA) and system theoretic process analysis (STPA), using case study research methodology. Both methods have been applied on the same forward collision avoidance system to compare the effectiveness of the methods and to\u00a0\u2026", "num_citations": "50\n", "authors": ["1137"]}
{"title": "What industry wants from academia in software testing? Hearing practitioners' opinions\n", "abstract": " The level of industry-academia collaboration (IAC) in software engineering in general and in software testing in particular is quite low. Many researchers and practitioners are not collaborating with the\" other side\" to solve industrial problems. To shed light on the above issue and to characterize precisely what industry wants from academia in software testing, we solicited practitioners' opinions on their challenges in different testing activities and also the particularly relevant topics that they want the research community to work on. This short paper aims to draw the community's attention to the important issue of strengthening IAC with the hope of more IAC in software testing in the areas of most importance to the industry.", "num_citations": "48\n", "authors": ["1137"]}
{"title": "Anomaly detection in the cloud: Detecting security incidents via machine learning\n", "abstract": " Cloud computing is now on the verge of being embraced as a serious usage-model. However, while outsourcing services and workflows into the cloud provides indisputable benefits in terms of flexibility of costs and scalability, there is little advance in security (which can influence reliability), transparency and incident handling. The problem of applying the existing security tools in the cloud is twofold. First, these tools do not consider the specific attacks and challenges of cloud environments, e.g., cross-VM side-channel attacks. Second, these tools focus on attacks and threats at only one layer of abstraction, e.g., the network, the service, or the workflow layers. Thus, the semantic gap between events and alerts at different layers is still an open issue. The aim of this paper is to present ongoing work towards a Monitoring-as-a-Service anomaly detection framework in a hybrid or public cloud. The goal of our\u00a0\u2026", "num_citations": "45\n", "authors": ["1137"]}
{"title": "Developing, verifying, and maintaining high-quality automated test scripts\n", "abstract": " With the increasing importance, size, and complexity of automated test suites, the need exists for suitable methods and tools to develop, assess the quality of, and maintain test code (scripts) in parallel with regular production (application) code. A recent review paper called this subarea of software testing software test code engineering (STCE). This article summarizes STCE tools, techniques, and guidelines. It also presents specific quantitative examples in this area based on experience in projects and raises important issues practitioners and researchers must address to further advance this field.", "num_citations": "43\n", "authors": ["1137"]}
{"title": "Integrating manual and automatic risk assessment for risk-based testing\n", "abstract": " In this paper we define a model-based risk assessment procedure that integrates automatic risk assessment by static analysis, semi-automatic risk assessment and guided manual risk assessment. In this process probability and impact criteria are determined by metrics which are combined to estimate the risk of specific system development artifacts. The risk values are propagated to the assigned test cases providing a prioritization of test cases. This supports to optimize the allocation of limited testing time and budget in a risk-based testing methodology. Therefore, we embed our risk assessment process into a generic risk-based testing methodology. The calculation of probability and impact metrics is based on system and requirements artifacts which are formalized as model elements. Additional time metrics consider the temporal development of the system under test and take for instance the bug and\u00a0\u2026", "num_citations": "43\n", "authors": ["1137"]}
{"title": "Querying UML models using OCL and Prolog: A performance study\n", "abstract": " The size of unified modeling language (UML) models used in practice is very large and ranges up to hundreds and thousands of classes. Querying of these models is used to support their quality assessment by information filtering and aggregating. For both, human cognition and automated analysis, there is a need for fast querying. In this context performance of model queries becomes an important issue. We investigated performance characteristics of two different querying engines: one using the object constraint language (OCL) and the other using prolog. Our comparison is based on equivalent queries in both languages. We applied the queries to 118 models of a size up to 10000 classes to analyze model load and evaluation time. Our preliminary results show that if execution time of queries is linear then prolog is faster. For one of the presented cases, the execution time in prolog was nonlinear and thus higher\u00a0\u2026", "num_citations": "41\n", "authors": ["1137"]}
{"title": "A systematic classification of security regression testing approaches\n", "abstract": " The openness of modern IT systems and their permanent change make it challenging to keep these systems secure. A combination of regression and security testing called security regression testing, which ensures that changes made to a system do not harm its security, are therefore of high significance and the interest in such approaches has steadily increased. In this article we present a systematic classification of available security regression testing approaches based on a solid study of background and related work to sketch which parts of the research area seem to be well understood and evaluated, and which ones require further research. For this purpose we extract approaches relevant to security regression testing from computer science digital libraries based on a rigorous search and selection strategy. Then, we provide a classification of these according to security regression approach criteria\u00a0\u2026", "num_citations": "40\n", "authors": ["1137"]}
{"title": "How is security testing done in agile teams? a cross-case analysis of four software teams\n", "abstract": " Security testing can broadly be described as (1) the testing of security requirements that concerns confidentiality, integrity, availability, authentication, authorization, nonrepudiation and (2) the testing of the software to validate how much it can withstand an attack. Agile testing involves immediately integrating changes into the main system, continuously testing all changes and updating test cases to be able to run a regression test at any time to verify that changes have not broken existing functionality. Software companies have a challenge to systematically apply security testing in their processes nowadays. There is a lack of guidelines in practice as well as empirical studies in real-world projects on agile security testing; industry in general needs a more systematic approach to security. The findings of this research are not surprising, but at the same time are alarming. The lack of knowledge on security by agile teams in general, the large dependency on incidental pen-testers, and the ignorance in static testing for security are indicators that security testing is highly under addressed and that more efforts should be addressed to security testing in agile teams.", "num_citations": "39\n", "authors": ["1137"]}
{"title": "Current state of research on continuous experimentation: a systematic mapping study\n", "abstract": " The systematic evaluation of ideas by experiments are the foundation of continuous experimentation. It allows to assess the value of an idea, remove guessing and subjective opinions from the discussion. The enormous interest of it by practitioners and researchers let the body of knowledge consistently grow. New framework, methods and techniques are developed and its application is constantly expanded to new fields like cyber-physical systems or social networks. In this paper we present a systematic mapping study to characterize the current state of research on continuous experimentation. Our study analyzes the following aspects: intensity of research activity and industry-academia collaboration, influential authors and publications, frequent research types and topics, kind of contributions and terms used for continuous experimentation. Our findings show amongst others that the intensity of research activities\u00a0\u2026", "num_citations": "34\n", "authors": ["1137"]}
{"title": "Towards a model based security testing approach of cloud computing environments\n", "abstract": " In recent years Cloud computing became one of the most aggressively emerging computer paradigms resulting in a growing rate of application in the area of IT outsourcing. However, as recent studies have shown, security most of the time is the one requirement, neglected at all. Yet, especially because of the nature of usage of Cloud computing, security is inevitable. Unfortunately, assuring the security of a Cloud computing environment is not a one time task, it is a task to be performed during the complete lifespan of the Cloud. This is motivated by the fact that Clouds undergo daily changes in terms of newly deployed applications and offered services. Based on this assumption, in this paper, we propose a novel model -- based, change -- driven approach, employing risk analysis, to test the security of a Cloud computing environment among all layers. As a main intrusion point, our approach exploits the public service\u00a0\u2026", "num_citations": "34\n", "authors": ["1137"]}
{"title": "New Perspectives on Software Quality [Guest editors' introduction]\n", "abstract": " This special issue, owing to its fundamental software quality focus, comprises a collection of diverse articles that address the challenges and directions for software quality research. The Web extra at http://youtu.be/T7V4RSr1KEE is an audio interview in which Davide Falessi speaks with guest editors Annie Kuntzmann-Combelles, Michael Felderer, and Ruth Breu about methods for improving software quality management, testing, and security on intelligent and interconnected devices.", "num_citations": "32\n", "authors": ["1137"]}
{"title": "A generic platform for model-based regression testing\n", "abstract": " Model-based testing has gained widespread acceptance in the last few years. Models enable the platform independent analysis and design of tests in an early phase of software development resulting in effort reduction in terms of time and money. Furthermore, test models are easier to maintain than test code when software systems evolve due to their platform independence and traceability support. Nevertheless, most regression testing approaches, which ensure that system evolution does not introduce unintended effects, are solely code-based. Additionally, many model-based testing approaches do not consider regression testing when applied in practice, mainly due to the lack of appropriate tool support. Therefore, in this paper we present a generic tool platform for model-based regression testing based on the model versioning and evolution framework MoVE. Our approach enhances existing model\u00a0\u2026", "num_citations": "31\n", "authors": ["1137"]}
{"title": "Using defect taxonomies to improve the maturity of the system test process: results from an industrial case study\n", "abstract": " Defect taxonomies collect and organize the domain knowledge and project experience of experts and are a valuable instrument of system testing for several reasons. They provide systematic backup for the design of tests, support decisions for the allocation of testing resources and are a suitable basis for measuring the product and test quality. In this paper, we propose a method of system testing based on defect taxonomies and investigate how these can systematically improve the efficiency and effectiveness, i.e. the maturity of requirements-based testing. The method is evaluated via an industrial case study based on two projects from a public health insurance institution by comparing one project with defect taxonomy-supported testing and one without. Empirical data confirm that system testing supported by defect taxonomies (1) reduces the number of test cases, and (2) increases of the number of\u00a0\u2026", "num_citations": "30\n", "authors": ["1137"]}
{"title": "An analysis and classification of public information security data sources used in research and practice\n", "abstract": " In order to counteract today\u2019s sophisticated and increasing number of cyber threats the timely acquisition of information regarding vulnerabilities, attacks, threats, countermeasures and risks is crucial. Therefore, employees tasked with information security risk management processes rely on a variety of information security data sources, ranging from inter-organizational threat intelligence sharing platforms to public information security data sources, such as mailing lists or expert blogs. However, research and practice lack a comprehensive overview about these public information security data sources, their characteristics and dependencies. Moreover, comprehensive knowledge about these sources would be beneficial to systematically use and integrate them to information security processes. In this paper, a triangulation study is conducted to identify and analyze public information security data sources. Furthermore\u00a0\u2026", "num_citations": "28\n", "authors": ["1137"]}
{"title": "Software paradigms, assessment types and non-functional requirements in model-based integration testing: a systematic literature review\n", "abstract": " Context: In modern systems, like cyber-physical systems, where software and physical services are interacting, safety, security or performance play an important role. In order to guarantee the correct interoperability of such systems, with respect to functional and non-functional requirements, integration testing is an effective measure to achieve this. Model-based testing moreover not only enables early definition and validation, but also test automation. This makes it a good choice to overcome urgent challenges of integration testing. Objective: Many publications on model-based integration testing (MBIT) approaches can be found. Nevertheless, a study giving a systematic overview on the underlying software paradigms, measures for guiding the integration testing process as well as non-functional requirements they are suitable for, is missing. The aim of this paper is to find and synthesize the relevant primary studies\u00a0\u2026", "num_citations": "28\n", "authors": ["1137"]}
{"title": "Towards adaptive test code generation for service oriented systems\n", "abstract": " With the increasing number of service oriented system implementations, new challenges concerning their development and testing are emerging.This paper presents an approach for model-driven system testing of service oriented systems. The approach offers a systematic testing methodology and it is based on tightly integrated system and test models with a formal metamodel. The test code generation itself is supported by automatic consistency and coverage checks and has a flexible adapter concept that allows different target technologies to be integrated.", "num_citations": "27\n", "authors": ["1137"]}
{"title": "Concepts for model-based requirements testing of service oriented systems\n", "abstract": " In this paper we present the core concepts of Telling Test-Stories, a model\u2013driven framework for test\u2013driven requirements testing of service oriented systems. Telling TestStories provides a new way of eliciting and validating requirements through intertwined specification of requirements and executable test stories. We define a Domain Specific Language (DSL) to formalize the system requirements and the test model. The DSL allows test cases to be specified based on the concepts of the requirements specification (actors, objects, services) and test cases to be separated from test data. To ensure the quality of the designed artifacts we introduce consistency and coverage checks expressed in OCL. We provide a prototypic implementation of the concepts and started an industrial validation of its usability.", "num_citations": "27\n", "authors": ["1137"]}
{"title": "Manual test case derivation from UML activity diagrams and state machines: A controlled experiment\n", "abstract": " ContextIt is a difficult and challenging task to fully automatize model-based testing because this demands complete and unambiguous system models as input. Therefore, in practice, test cases, especially on the system level, are still derived manually from behavioral models like UML activity diagrams or state machines. But this kind of manual test case derivation is error-prone and knowing these errors makes it possible to provide guidelines to reduce them.ObjectiveThe objective of the study presented in this paper therefore is to examine which errors are possible and actually made when manually deriving test cases from UML activity diagrams or state machines and whether there are differences between these diagram types.MethodWe investigate the errors made when deriving test cases manually in a controlled student experiment. The experiment was performed and internally replicated with overall 84\u00a0\u2026", "num_citations": "26\n", "authors": ["1137"]}
{"title": "Is business domain language support beneficial for creating test case specifications: A controlled experiment\n", "abstract": " Context: Behavior Driven Development (BDD), widely used in modern software development, enables easy creation of acceptance test case specifications and serves as a communication basis between business- and technical-oriented stakeholders. BDD is largely facilitated through simple domain specific languages (DSL) and usually restricted to technical test domain concepts. Integrating business domain concepts to implement a ubiquitous language for all members of the development team is an appealing test language improvement issue. But the integration of business domain concepts into BDD toolkits has so far not been investigated.Objective: The objective of the study presented in this paper is to examine whether supporting the ubiquitous language features inside a DSL, by extending a DSL with business domain concepts, is beneficial over using a DSL without those concepts. In the context of the study\u00a0\u2026", "num_citations": "25\n", "authors": ["1137"]}
{"title": "A risk assessment framework for software testing\n", "abstract": " In industry, testing has to be performed under severe pressure due to limited resources. Risk-based testing which uses risks to guide the test process is applied to allocate resources and to reduce product risks. Risk assessment, i.e., risk identification, analysis and evaluation, determines the significance of the risk values assigned to tests and therefore the quality of the overall risk-based test process. In this paper we provide a risk assessment model and its integration into an established test process. This framework is derived on the basis of best practices extracted from published risk-based testing approaches and applied to an industrial test process.", "num_citations": "25\n", "authors": ["1137"]}
{"title": "A tool-based methodology for system testing of service-oriented systems\n", "abstract": " We present a tool environment and its underlying principles for Telling TestStories, an approach to model-driven system testing of service-oriented systems. Telling TestStories is based on tightly integrated platform-independent system and test models. The approach is capable of test-driven development on the model level, and guarantees high quality system and test models by checking consistency and coverage. Additionally, Telling TestStories provides full traceability between the requirements, the system and test models, and the executable services of the system. The tool environment supports these features in an integrated and clear way.", "num_citations": "25\n", "authors": ["1137"]}
{"title": "Requirements engineering practice and problems in agile projects: results from an international survey\n", "abstract": " Requirements engineering (RE) is considerably different in agile development than in more traditional development processes. Yet, there is little empirical knowledge on the state of the practice and contemporary problems in agile RE. As part of a bigger survey initiative (Naming the Pain in Requirements Engineering), we build an empirical basis on such aspects of agile RE. Based on the responses of representatives from 92 different organisations, we found that agile RE concentrates on free-text documentation of requirements elicited with a variety of techniques. Often, traces between requirements and code are explicitly managed and also software testing and RE are aligned. Furthermore, continuous improvement of RE is performed due to intrinsic motivation. Important experienced problems include unclear requirements and communication flaws. Overall, we found that most organisations conduct RE in a way we would expect and that agile RE is in several aspects not so different from RE in other development processes.", "num_citations": "23\n", "authors": ["1137"]}
{"title": "Security testing by telling teststories\n", "abstract": " Security testing is very important to assure a certain level of reliability in a system. On the system level, security testing has to guarantee that security requirements such as confidentiality, integrity, authentication, authorization, availability and non-repudiation hold. In this paper, we present an approach to system level security testing of service oriented systems that evaluates security requirements. Our approach is based on the Telling TestStories methodology for model-driven system testing. After the elicitation of security requirements, we define a system and a test model. The test model is then transformed to executable test code. We show how traceability between all artifacts can be established and how the tests can be executed focusing on security relevant aspects. All steps are explained based on an industrial case study.", "num_citations": "23\n", "authors": ["1137"]}
{"title": "Improvement methods for software requirement specifications: a mapping study\n", "abstract": " Software Requirement Specifications (SRS) are a key result of the Requirement Engineering (RE) process and an important basis for every large industrial software development project. Nevertheless, accurate, complete and consistent SRS are still a challenge in practice. Many publications related to SRS address problems and provide solutions for solving these. The most frequently researched SRS problems and improvement methods are listed and referenced in this mapping study. As final result of the search process, publication are analyzed and mapped to each other. This mapping is important for a further evaluations of SRS improvement methods that helps practitioners and researchers to compare those approaches.", "num_citations": "22\n", "authors": ["1137"]}
{"title": "NLP-assisted software testing: A systematic mapping of the literature\n", "abstract": " ContextTo reduce manual effort of extracting test cases from natural-language requirements, many approaches based on Natural Language Processing (NLP) have been proposed in the literature. Given the large amount of approaches in this area, and since many practitioners are eager to utilize such techniques, it is important to synthesize and provide an overview of the state-of-the-art in this area.ObjectiveOur objective is to summarize the state-of-the-art in NLP-assisted software testing which could benefit practitioners to potentially utilize those NLP-based techniques. Moreover, this can benefit researchers in providing an overview of the research landscape.MethodTo address the above need, we conducted a survey in the form of a systematic literature mapping (classification). After compiling an initial pool of 95 papers, we conducted a systematic voting, and our final pool included 67 technical papers\u00a0\u2026", "num_citations": "21\n", "authors": ["1137"]}
{"title": "Estimating the cost and benefit of model-based testing: a decision support procedure for the application of model-based testing in industry\n", "abstract": " Model-based testing is of high practical relevance and many model-based testing approaches have been developed during the last years. But the key question under which conditions model-based testing pays off and a related decision support procedure for its application has not been sufficiently addressed. In this paper we develop a generic decision support procedure whether to apply model-based testing in a project or not. The decision support procedure compares estimated costs and benefits of model-based testing throughout all phases of the test process and is derived on the basis of a case study performed at the European Space Agency.", "num_citations": "21\n", "authors": ["1137"]}
{"title": "Using defect taxonomies for requirements validation in industrial projects\n", "abstract": " Quality of requirements is of great importance for the software development lifecycle as it influences all steps of software development. To ensure various quality attributes, suitable requirements validation techniques such as reviews or testing are essential. In this paper, we show how defect taxonomies can improve requirements reviews and testing. We point out how defect taxonomies can be seamlessly integrated into the requirements engineering process and discuss requirements validation with defect taxonomies as well as its benefits and the lessons learned with reference to industrial projects of a public health insurance institution where this approach has been successfully applied.", "num_citations": "21\n", "authors": ["1137"]}
{"title": "Integrating software quality models into risk-based testing\n", "abstract": " Risk-based testing is a frequently used testing approach which utilizes identified risks of a software system to provide decision support in all phases of the testing process. Risk assessment, which is a core activity of every risk-based testing process, is often done in an ad hoc manual way. Software quality assessments, based on quality models, already describe the product-related risks of a whole software product and provide objective and automation-supported assessments. But so far, quality models have not been applied for risk assessment and risk-based testing in a systematic way. This article tries to fill this gap and investigates how the information and data of a quality assessment based on the open quality model QuaMoCo can be integrated into risk-based testing. We first present two generic approaches showing how quality assessments based on quality models can be integrated into risk-based\u00a0\u2026", "num_citations": "19\n", "authors": ["1137"]}
{"title": "Industry-academia collaborations in software engineering\n", "abstract": " Research collaboration between industry and academia supports improvement and innovation in industry and helps to ensure industrial relevance in academic research. However, many researchers and practitioners believe that the level of joint industry-academia collaboration (IAC) in so ware engineering (SE) research is still relatively low, compared to the amount of activity in each of the two communities. e goal of the empirical study reported in this paper is to exploratory characterize the state of IAC with respect to a set of challenges, pa erns and anti-pa erns identi ed by a recent Systematic Literature Review study. To address the above goal, we gathered the opinions of researchers and practitioners wrt their experiences in IAC projects. Our dataset includes 47 opinion data points related to a large set of projects conducted in 10 di erent countries. We aim to contribute to the body of evidence in the area of IAC, for the bene t of researchers and practitioners in conducting future successful IAC projects in SE. As an output, the study presents a set of empirical ndings and evidence-based recommendations to increase the success of IAC projects.", "num_citations": "18\n", "authors": ["1137"]}
{"title": "Evolution of security requirements tests for service\u2013centric systems\n", "abstract": " Security is an important quality aspect of open service\u2013centric systems. However, it is challenging to keep such systems secure because of steady evolution. Thus, security requirements testing, considering system changes is crucial to provide a certain level of reliability in a service\u2013centric system. In this paper, we present a model\u2013driven method to system level security testing of service\u2013centric systems focusing on the aspect of requirements, system and test evolution. As requirements and the system may change over time, regular adaptations to the tests of security requirements are essential to retain, or even improve, system quality. We attach state machines to all model elements of our system- and test model to obtain consistent and traceable evolution of the system and its tests. We highlight the specifics for the evolution of security requirements, and show by a case study how changes of the attached\u00a0\u2026", "num_citations": "18\n", "authors": ["1137"]}
{"title": "Knowledge-based security testing of web applications by logic programming\n", "abstract": " This article introduces a new method for knowledge-based security testing by logic programming and the related tool implementation for model-based non-functional security testing of web applications. Our method helps to overcome the current prevalent focus on functional instead of non-functional (or negative) requirements as well as the required high level of security knowledge when performing non-functional security testing. It addresses issues like considering non-functional requirements for testing, managing the virtually infinite amount of negative security test cases, advancing non-functional security testing away from its prevalent penetration testing-like style, and making non-functional security testing feasible for testers that are not experts in security via a security knowledge base. The method and its model-based tool implementation are evaluated in two studies, which show the method\u2019s\u00a0\u2026", "num_citations": "17\n", "authors": ["1137"]}
{"title": "Enhancing model driven security through pattern refinement techniques\n", "abstract": " Security requirements are typically defined at a business abstract level by non-technical security officers. However, in order to fulfill the security requirements, technical security controls or mechanisms have to be considered and deployed on the target system. Based on these security controls security patterns have to be selected. The MDS (Model Driven Security) approach uses security requirement models at a high level of abstraction to automatically generate security artefacts that configure security services. The main drawback of the current MDS solutions is that they consider just one security pattern for each security requirement. Current SOA and cloud services are scattered across multiple heterogeneous security domains. Partners and clients with different security infrastructures are changing continuously, which requires the support of multiple patterns for the same security service. The challenge is to\u00a0\u2026", "num_citations": "17\n", "authors": ["1137"]}
{"title": "Risk-based data validation in machine learning-based software systems\n", "abstract": " Data validation is an essential requirement to ensure the reliability and quality of Machine Learning-based Software Systems. However, an exhaustive validation of all data fed to these systems (ie up to several thousand features) is practically unfeasible. In addition, there has been little discussion about methods that support software engineers of such systems in determining how thorough to validate each feature (ie data validation rigor). Therefore, this paper presents a conceptual data validation approach that prioritizes features based on their estimated risk of poor data quality. The risk of poor data quality is determined by the probability that a feature is of low data quality and the impact of this low (data) quality feature on the result of the machine learning model. Three criteria are presented to estimate the probability of low data quality (Data Source Quality, Data Smells, Data Pipeline Quality). To determine the\u00a0\u2026", "num_citations": "14\n", "authors": ["1137"]}
{"title": "A systematic literature review of crowdsourcing-based research in information security\n", "abstract": " Crowdsourcing is a well-established concept in several application areas of computer science and information systems. While crowdsourcing is favored in areas such as information sharing, quality management or data acquisition, only little attention has been drawn to crowdsourcing capabilities for information security in the past. Since a few years an increase of crowdsourcing-based research in information security can be identified. To which extend remains unclear since a comprehensive overview of applied crowdsourcing techniques and related challenges is missing. In this paper we try to shed some light on this by conducting a systematic literature review based on the snowballing methodology. It delivered 23 relevant papers which we analyzed with respect to the following perspectives: (a) Bibliographic information, (b) applied research methodology, (c) addressed information security application context, (d\u00a0\u2026", "num_citations": "14\n", "authors": ["1137"]}
{"title": "On the role of defect taxonomy types for testing requirements: Results of a controlled experiment\n", "abstract": " Context: The use of defect taxonomies and their assignment to requirements can improve system-level testing of requirements. Experiences from industrial applications indicate that the type of the underlying top-level defect categories constitutes the main influence factor for defining defect taxonomies. Objective: The objective addressed in this paper is to investigate the influence of the type of top-level defect categories on the quality of the created defect taxonomy, on the quality of the assignment of requirements to defect categories as well as the quality of designed test cases. Method: We conducted a controlled student experiment to determine the influence of two different types of top-level defect categories, i.e., Generic and web application specific, on the quality of the created defect taxonomy, their assignment to requirements and the derived test cases. Results: The results indicate an influence of the type of the\u00a0\u2026", "num_citations": "14\n", "authors": ["1137"]}
{"title": "Comprehensibility of system models during test design: a controlled experiment comparing UML activity diagrams and state machines\n", "abstract": " UML activity diagrams and state machines are both used for modeling system behavior from the user perspective and are frequently the basis for deriving system test cases. In practice, system test cases are often derived manually from UML activity diagrams or state machines. For this task, comprehensibility of respective models is essential and a relevant question for practice to support model selection and design, as well as subsequent test derivation. Therefore, the objective of this paper is to compare the comprehensibility of UML activity diagrams and state machines during manual test case derivation. We investigate the comprehensibility of UML activity diagrams and state machines in a controlled student experiment. Three measures for comprehensibility have been investigated: (1) the self-assessed comprehensibility, (2) the actual comprehensibility measured by the correctness of answers to\u00a0\u2026", "num_citations": "13\n", "authors": ["1137"]}
{"title": "An exploratory study on risk estimation in risk-based testing approaches\n", "abstract": " Risk estimation is a core activity in every risk-based testing process because it determines the significance of the risk values assigned to tests and therefore the quality of the overall risk-based testing process. In this paper we explore how risk estimation is performed in risk-based testing approaches. For this purpose, we classify 17 collected risk-based testing approaches according to predefined dimensions risk item type, factors, criteria, estimation technique, risk scale, estimation date, automation of measurement as well as tool support, and analyze the classification. Results from this classification reveal that a broad range of estimation variants is used but most approaches estimate risk for functional artifacts, consider probability and impact explicitly, use a quantitative scale and are based on manual measurement.", "num_citations": "13\n", "authors": ["1137"]}
{"title": "Laying the foundation for smart contract development: an integrated engineering process model\n", "abstract": " Smart contracts are seen as the major building blocks for future autonomous blockchain- and Distributed Ledger Technology (DLT)-based applications. Engineering such contracts for trustless, append-only, and decentralized digital ledgers allows mutually distrustful parties to transform legal requirements into immutable and formalized rules. Previous experience shows this to be a challenging task due to demanding socio-technical ecosystems and the specificities of decentralized ledger technology. In this paper, we therefore develop an integrated process model for engineering DLT-based smart contracts that accounts for the specificities of DLT. This model was iteratively refined with the support of industry experts. The model explicitly accounts for the immutability of the trustless, append-only, and decentralized DLT ecosystem, and thereby overcomes certain limitations of traditional software engineering process\u00a0\u2026", "num_citations": "12\n", "authors": ["1137"]}
{"title": "Using defect taxonomies for testing requirements\n", "abstract": " Systematic defect management based on bug-tracking systems such as Bugzilla is well established and has been successfully used in many software organizations. Defect management weights the failures observed during test execution according to their severity and forms the basis for effective defect taxonomies. In practice, most defect taxonomies are used only for the a posteriori allocation of testing resources to prioritize failures for debugging. Thus, these taxonomies' full potential to control and improve all the steps of testing has remained unexploited. This is especially the case for testing a system's user requirements. System-level defect taxonomies can improve the design of requirements-based tests, the tracing of defects to requirements, the quality assessment of requirements, and the control of the relevant defect management. So, we developed requirements-based testing with defect taxonomies (RTDT\u00a0\u2026", "num_citations": "12\n", "authors": ["1137"]}
{"title": "RisCal--A Risk Estimation Tool for Software Engineering Purposes\n", "abstract": " Decision making in software engineering requires the consideration of risk information. The reliability of risk information is strongly influenced by the underlying risk estimation process which consists of the steps risk identification, risk analysis and risk prioritization. In this paper we present a novel risk estimation tool for software engineering pruposes called RisCal. RisCal is based on a generic risk model and supports the integration of manually and automatically determined metrics into the risk estimation. This makes the tool applicable for arbitrary software engineering activities like risk-based testing or release planning. We show how RisCal supports risk identification, analysis and prioritizations, provide an estimation example, and discuss its application to risk-based testing and release planning.", "num_citations": "12\n", "authors": ["1137"]}
{"title": "An integrated tool environment for experimentation in domain specific language engineering\n", "abstract": " Domain specific languages (DSLs) are widely used in practice and investigated in software engineering research. But so far, language workbenches do not provide sufficient built-in decision support for language design and improvement. Controlled experiments have the potential to provide appropriate, data-driven decision support for language engineers and researchers to compare different language features with evidence-based feedback. This paper provides an integrated end-to-end tool environment to perform controlled experiments in DSL engineering. The experiment environment is built on the basis and integrated into the language workbench Meta Programming System (MPS). The environment not only supports language design but also all steps of experimentation, ie, planning, operation, analysis & interpretation, as well as presentation & package. The tool environment is presented by means of a\u00a0\u2026", "num_citations": "11\n", "authors": ["1137"]}
{"title": "Weaving social software features into enterprise resource planning systems\n", "abstract": " In this paper we present the Social Weaver platform that enables end users to weave snippets of social software features into the workflows of existing enterprise applications. We discuss the underlying vision from a technological viewpoint, i.e., an end-user development viewpoint, and an organizational viewpoint which is about a certain ubiquitous understanding of enterprise application integration. We present the system\u2019s requirements, architecture and realization. The concrete platform is based on the standard web technology stack, which makes sense because the web is the current natural host for enterprise applications, at least for new ones. However, the approach presented in this article is technological-independent with the concrete platform as a concrete instance proving the approach as doable. Conceptually, the realized platform is a key to analyze the current situation and possible future of\u00a0\u2026", "num_citations": "11\n", "authors": ["1137"]}
{"title": "Towards Risk--Driven Security Testing of Service Centric Systems\n", "abstract": " The increased deployment of service centric systems in security critical application contexts poses new challenges to properly test such a system's security. If taking a closer look at the inherent complexity of such applications, sophisticated approaches to testing security are indispensable. In our paper we propose a novel model - based methodology for the risk - driven security testing of service centric systems.", "num_citations": "11\n", "authors": ["1137"]}
{"title": "Risk management practices in information security: Exploring the status quo in the DACH region\n", "abstract": " Information security management aims at ensuring proper protection of information values and information processing systems (i.e. assets). Information security risk management techniques are incorporated to deal with threats and vulnerabilities that impose risks to information security properties of these assets. This paper investigates the current state of risk management practices being used in information security management in the DACH region (Germany, Austria, Switzerland). We used an anonymous online survey targeting strategic and operative information security and risk managers and collected data from 26 organizations. We analyzed general practices, documentation artifacts, patterns of stakeholder collaboration as well as tool types and data sources used by enterprises to conduct information security management activities. Our findings show that the state of practice of information security risk\u00a0\u2026", "num_citations": "10\n", "authors": ["1137"]}
{"title": "Model-based regression testing by OCL\n", "abstract": " Model-based testing has gained widespread acceptance over the last decade, not only in academia but also in industry. Despite its powerful features of abstraction and automation, most existing approaches and tools provide only limited support for regression testing. Yet regression testing, the repeated execution of selected test cases after system modification, is vital, because changes may introduce new bugs or unwanted side effects that must be avoided at all costs. Model-based testing\u2019s potential for supporting regression testing has yet to be explored, even though syntactic and semantic abstractions within software models already allow identifying changes in software systems. This change information can easily be used for test case selection. In this article, we present a model-based regression testing method based on OCL. By means of a running example using the UML Testing Profile we show how\u00a0\u2026", "num_citations": "10\n", "authors": ["1137"]}
{"title": "Mining user reviews of COVID contact-tracing apps: An exploratory analysis of nine European apps\n", "abstract": " Context:More than 78 countries have developed COVID contact-tracing apps to limit the spread of coronavirus. However, many experts and scientists cast doubt on the effectiveness of those apps. For each app, a large number of reviews have been entered by end-users in app stores.Objective:Our goal is to gain insights into the user reviews of those apps, and to find out the main problems that users have reported. Our focus is to assess the \u201csoftware in society\u201d aspects of the apps, based on user reviews.Method:We selected nine European national apps for our analysis and used a commercial app-review analytics tool to extract and mine the user reviews. For all the apps combined, our dataset includes 39,425 user reviews.Results:Results show that users are generally dissatisfied with the nine apps under study, except the Scottish (\u201cProtect Scotland\u201d) app. Some of the major issues that users have complained\u00a0\u2026", "num_citations": "9\n", "authors": ["1137"]}
{"title": "Relating verification and validation methods to software product quality characteristics: results of an expert survey\n", "abstract": " [Context] Employing appropriate verification and validation (V&V) methods is essential to improve software product quality. However, while several V&V methods have been documented, little is known about how these methods relate to specific product quality characteristics. [Goal] The goal of this paper is to provide an initial configuration on the suitability of selected V&V methods to address ISO 25010 software product quality characteristics. [Method] Therefore, we compiled a list of V&V methods and conducted a survey with V&V experts, asking them to evaluate how well each V&V method allows for addressing the ISO 25010 characteristics. [Results] We received 19 answers from experts of 7 different countries. Our results express the aggregated expert opinion. It is noteworthy that the experts mostly agreed in their opinions, indicating consistency in the results. [Conclusions] This work provides the first\u00a0\u2026", "num_citations": "9\n", "authors": ["1137"]}
{"title": "Risk-based testing\n", "abstract": " In many development projects, testing has to be done under severe pressure due to limited resources, a challenging time schedule, and the demand to guarantee security and safety of the released software system. Risk-based testing, which utilizes identified risks of a software system for testing purposes, has a high potential to improve testing in this context. It optimizes the allocation of resources and time, is a means for mitigating risks, helps to early identify critical areas, and provides decision support for the management [1, 2].", "num_citations": "9\n", "authors": ["1137"]}
{"title": "Information management for holistic, collaborative information security management\n", "abstract": " The importance of information, asset and technology as key differentiator for modern organizations is increasingly recognized. More than 6,600 organizations worldwide are implementing an information security management system (ISMS) in accordance to ISO/IEC 27001. An optimal information management is a critical success factor for the effectiveness, performance and sustainability of ISMS. Information security (IS) has been considered as technical job for a long time. In the last years IS research has developed further an IS governance and people oriented direction. Additionally, different best practices such as control objectives for information and related technology (COBIT) and the information technology infrastructure library (ITIL) have been published. In accordance to the IS approaches the information management for ISMS was studied either only from a technical perspective or a measurement\u00a0\u2026", "num_citations": "9\n", "authors": ["1137"]}
{"title": "Estimating the return on investment of defect taxonomy supported system testing in industrial projects\n", "abstract": " Defect taxonomies collect and organize the domain knowledge and project experience of experts and are a valuable instrument of system testing for several reasons. They provide systematic backup for the design of tests, support decisions for the allocation of testing resources and provide a suitable basis for measuring the product and test quality. In this paper, we present a method of system testing based on defect taxonomies and an appropriate estimation procedure for its return on investment depending on several parameters like the average test design time or the number of test cycles and experience values of a test organization. The estimated return on investment provides decision support whether to apply defect taxonomy supported system testing for a specific product or not. We develop the estimation procedure in the context of an industrial project from a public health insurance institution where the return\u00a0\u2026", "num_citations": "9\n", "authors": ["1137"]}
{"title": "Indicators for cooperative, online-based learning and their role in quality management of online learning\n", "abstract": " Learning is a constructive and social process that works best in interaction with others. From this perspective, interaction and cooperation are seen as essential for learning especially in online-based learning environments. The objective of this chapter is to propose and test indicators for cooperative online-based learning. The indicators focus on three areas: presence of participants (indicators: access index, access pattern index), participation of participants (reading index, contribution index, completion index), and interaction of participants (answer contribution index, connectivity index, reciprocity index). The indicators can be applied both to students and instructors. The indicators were applied to three online-based courses in higher education. Log data from the learning management system was used. Also, success rates, student evaluations, and workload analysis were conducted. Results show that the\u00a0\u2026", "num_citations": "8\n", "authors": ["1137"]}
{"title": "Technical debt in data-intensive software systems\n", "abstract": " The ever-increasing amount, variety as well as generation and processing speed of today's data pose a variety of new challenges for developing Data-Intensive Software Systems (DISS). As with developing other kinds of software systems, developing DISS is often done under severe pressure and strict schedules. Thus, developers of DISS often have to make technical compromises to meet business concerns. This position paper proposes a conceptual model that outlines where Technical Debt (TD) can emerge and proliferate within such data-centric systems by separating a DISS into three parts (Software Systems, Data Storage Systems and Data). Further, the paper illustrates the proliferation of Database Schema Smells as TD items within a relational database-centric software system based on two examples.", "num_citations": "8\n", "authors": ["1137"]}
{"title": "Shifting quality assurance of machine learning algorithms to live systems\n", "abstract": " A fundamental weakness of existing solutions to assess the quality of machine learning algorithms is the assumption that test environments sufficiently mimic the later application. Given the data dependent behavior of these algorithms, only limited reasoning about their later performance is possible. Thus, meaningful quality assurance is not possible with test environments. A shift from the traditional testing environment to the live system is needed. Thus, costly test environments are replaced with available live systems that constantly execute the algorithm.", "num_citations": "8\n", "authors": ["1137"]}
{"title": "Data science challenges to improve quality assurance of internet of things applications\n", "abstract": " With the increasing importance and complexity of Internet of Things (IoT) applications, also the development of adequate quality assurance techniques becomes essential. Due to the massive amount of data generated in workflows of IoT applications, data science plays a key role in their quality assurance. In this paper, we present respective data science challenges to improve quality assurance of Internet of Things applications. Based on an informal literature review, we first outline quality assurance requirements evolving with the IoT grouped into six categories (Environment, User, Compliance/Service Level Agreement, Organizational, Security and Data Management). Finally, we present data science challenges to improve the quality assurance of Internet of Things applications sub-divided into four categories (Defect prevention, Defect analysis, User incorporation and Organizational) derived from the six\u00a0\u2026", "num_citations": "8\n", "authors": ["1137"]}
{"title": "Cloud risk analysis by textual models\n", "abstract": " The development of secure software systems strongly relies on the availability of a known risk profile. In cloud computing, such a known risk profile does not exist yet, resulting in highly insecure cloud deployments. In our paper we propose a textual modeling language for cloud deployments making it possible to derive a risk profile using a risk analysis, based on stable model semantics.", "num_citations": "8\n", "authors": ["1137"]}
{"title": "Applying security testing techniques to automotive engineering\n", "abstract": " Over the past few decades, the automotive industry was mostly focused on testing the safety aspects of a vehicle. However, this was not the case with security testing as it only began to be addressed recently. As a result, multiple approaches applying various security testing techniques on different software-based vehicle IT components emerged. With that said, the research and practice lack an overview about these techniques. In this paper, we conduct a systematic mapping study. This involved the investigation on the following five dimensions:(1) security testing techniques,(2) AUTOSAR layers,(3) functional interfaces of AUTOSAR,(4) vehicle lifecycle phases and (5) attacks. In total, 39 papers presenting approaches for security testing in automotive engineering were systematically selected and classified. The results identify multiple security testing techniques focusing on early phases of vehicle life cycle through\u00a0\u2026", "num_citations": "7\n", "authors": ["1137"]}
{"title": "A process for mastering security evolution in the development lifecycle\n", "abstract": " Continuous system evolution makes it challenging to keep software systems permanently secure as changes either in the system itself or its environment may cause new threats and vulnerabilities. Therefore, suitable activities aligned with the software development process are required to master security evolution. This introduction to the special section on eternal security evolution presents a process for handling security evolution throughout the software development lifecycle and uses this process to position the individual contributions. We first present the underlying security development process comprising the phases initialization, security analysis, security design, security implementation, security testing, and security deployment. On this basis, we define the security evolution process comprising the activities security requirements review, adaptation of design models, code fixing and patch development\u00a0\u2026", "num_citations": "7\n", "authors": ["1137"]}
{"title": "Model Validation in a Tool\u2013based Methodology for System Testing of Service\u2013oriented Systems\n", "abstract": " In this article we present a novel model\u2013driven system testing methodology for service\u2013centric systems called Telling TestStories, its tool implementation and the underlying model validation mechanism. Telling TestStories is based on tightly integrated but separated platform\u2013independent requirements, system and test models. The test models integrate test data tables and encourage domain experts to design tests. This process is supported by consistency, completeness, and coverage checks in and between the requirements, system and test models which guarantees a high quality of the models. Telling TestStories is capable of test\u2013driven development on the model level and provides full traceability between all system and testing artifacts. The testing process of the Telling TestStories methodology comprises model development, model validation and system validation. The model development and the system validation are managed by the Telling TestStories tool and the model validation is managed by the SQUAM tool. All process steps, the underlying artifacts and the tools for implementing the process steps are presented by an industrial case study.", "num_citations": "7\n", "authors": ["1137"]}
{"title": "Technical debt and waste in non-functional requirements documentation: An exploratory study\n", "abstract": " Background: To adequately attend to non-functional requirements (NFRs), they must be documented; otherwise, developers would not know about their existence. However, the documentation of NFRs may be subject to Technical Debt and Waste, as any other software artefact. Aims: The goal is to explore indicators of potential Technical Debt and Waste in NFRs documentation. Method: Based on a subset of data acquired from the most recent NaPiRE (Naming the Pain in Requirements Engineering) survey, we calculate, for a standard set of NFR types, how often respondents state they document a specific type of NFR when they also state that it is important. This allows us to quantify the occurrence of potential Technical Debt and Waste. Results: Based on 398 survey responses, four NFR types (Maintainability, Reliability, Usability, and Performance) are labelled as important but they are not documented\u00a0\u2026", "num_citations": "6\n", "authors": ["1137"]}
{"title": "Systematic support for full knowledge management lifecycle by advanced semantic annotation across information system boundaries\n", "abstract": " In today\u2019s organizations, there exist a variety of information-system paradigms to support the diverse organizational needs that reside on different levels of operations, tactics and strategies on the one hand, and are subject to different work styles on the other hand. This makes it challenging to design knowledge management systems that can be integrated into heterogeneous information-system applications. In this paper, we present Tippanee that allows users to create and manage semantic annotations over dynamically generated contents across the boundaries of arbitrary information-system applications. We further show, how these advanced semantic annotation capabilities can be systematically exploited in the full knowledge-management lifecycle. We explain, how the essentially important transformation of tacit-explicit-tacit knowledge corresponds to the reorganization of semantic schemata by a\u00a0\u2026", "num_citations": "6\n", "authors": ["1137"]}
{"title": "Measuring and improving testability of system requirements in an industrial context by applying the goal question metric approach\n", "abstract": " Testing is subject to two basic constraints, namely cost and quality. The cost depends on the efficiency of the testing activities as well as their quality and testability. The author's practical experience in large-scale systems shows that if the requirements are adapted iteratively or the architecture is altered, testability decreases. However, what is often lacking is a root cause analysis of the testability degradations and the introduction of improvement measures during software development. In order to introduce agile practices in the rigid strategy of the V-model, good testability of software artifacts is vital. So testability is also the bridgehead towards agility. In this paper, we report on a case study in which we measure and improve testability on the basis of the Goal Question Metric Approach.", "num_citations": "6\n", "authors": ["1137"]}
{"title": "On evidence-based risk management in requirements engineering\n", "abstract": " Background: The sensitivity of Requirements Engineering (RE) to the context makes it difficult to efficiently control problems therein, thus, hampering an effective risk management devoted to allow for early corrective or even preventive measures.                        Problem: There is still little empirical knowledge about context-specific RE phenomena which would be necessary for an effective context-sensitive risk management in RE.                        Goal: We propose and validate an evidence-based approach to assess risks in RE using cross-company data about problems, causes and effects.                        Research Method: We use survey data from 228 companies and build a probabilistic network that supports the forecast of context-specific RE phenomena. We implement this approach using spreadsheets to support a light-weight risk assessment.                        Results: Our results from an initial validation in 6\u00a0\u2026", "num_citations": "6\n", "authors": ["1137"]}
{"title": "Software quality assurance during implementation: results of a survey in software houses from Germany, Austria and Switzerland\n", "abstract": " Context: Quality assurance performed during the implementation phase, e.g., by coding guidelines, static analysis or unit testing, is of high importance to ensure quality of software, but there is a lack of common knowledge and best practices on it. Objective: The goal of this paper is to investigate the state-of-practice of quality assurance during the implementation phase in software houses. Method: For this purpose, we conducted a survey in Germany, Austria, and Switzerland where 57 software houses participated. The questionnaire comprised questions regarding techniques, tools, and effort for software quality assurance during implementation as well as the perceived quality after implementation. The results were complemented by interviews and results from other surveys on software quality in general. Results: Results from the survey show that the most common software quality assurance\u00a0\u2026", "num_citations": "6\n", "authors": ["1137"]}
{"title": "A Bayesian prediction model for risk-based test selection\n", "abstract": " In industry, testing is commonly performed under severe pressure due to limited resources. Therefore, risk-based testing, which uses predicted risks to guide the test process, is employed to select test cases. To this end, risks have so far mainly been estimated ad hoc, but not systematically predicted on the basis of the defect history and defect costs. In this paper, we present a novel approach to risk-based test selection, which employs a comprehensive and versatile Bayes risk model taking defect probabilities and costs into account. It enables the prediction of a risk decrement that could potentially be used for test selection. We first define a generic Bayes risk decision criterion for test selection, and then implement and evaluate it in an industrial software development project, where it is intended to support decisions steering the quality assurance process.", "num_citations": "6\n", "authors": ["1137"]}
{"title": "Innovations in enterprise information systems management and engineering\n", "abstract": " This book contains revised papers from the 2015 ERP Future\u2014Research Conference, held in Munich, Germany, in November 2015. The 12 papers presented in this volume were carefully peer-reviewed and selected from a total of 23 submissions. The ERP Future\u2014Research Conference is a platform for research in ERP systems and closely related topics such as business processes, business intelligence, and enterprise information systems. Submitted contributions cover the given topics from a business and a technological point of view with high theoretical as well as practical impact.", "num_citations": "6\n", "authors": ["1137"]}
{"title": "Mutual knowledge transfer between industry and academia to improve testing withdefect taxonomies\n", "abstract": " Software engineering is an applied research area preferably conducted jointly by academia and industry to enable transfer of knowledge in both directions and at the end improvement software engineering in industry. In this paper we present how the required mutual knowledge transfer via empirical evaluation was performed to improve testing with defect taxonomies in industry.", "num_citations": "6\n", "authors": ["1137"]}
{"title": "Architecture for an Ontology and Web Service Modelling Studio.\n", "abstract": " This paper outlines the architecture of a WSMO Studio, that aims at developing formal specification according to the WSMO Meta Model. Developing formal specification according to a specific formalism is not an easy task. As soon as the descriptions get numerous, large and different authors are involved manual editing without tool support does not scale anymore. In the field of ontology editors are already various tools available, however derivations in the underlying formalism and the special extension needs for a WSMO Studio require a custom development. In this paper we outline the concrete functional requirements and propose an open architecture for a studio based on the analyzes of existing work.", "num_citations": "6\n", "authors": ["1137"]}
{"title": "A taxonomy to assess and tailor risk-based testing in recent testing standards\n", "abstract": " This article provides a taxonomy for risk-based testing that serves as a tool to define, tailor, or assess such approaches. In this setting, the taxonomy is used to systematically identify deviations between the requirements from public standards and the individual testing approaches.", "num_citations": "5\n", "authors": ["1137"]}
{"title": "Building a Community of Inquiry Within an Online-Based Health Informatics Program: Instructional Design and Lessons Learned.\n", "abstract": " The rapid medical and technological progress and the resulting need for life-long learning lead to the proliferation of online-based programs in health informatics for health care and health informatics professionals. Effective learning in these online-based programs demands close interaction and cooperation between students and instructors. In such cooperative online-based programs, special emphasis is thus put on fostering a community of inquiry between all participants. The online-based master program on Health Information Management at the University UMIT is firmly based on the constructivist theory of situated learning in such a community of inquiry. Online activities in this master program are designed to promote social presence, cognitive presence and teacher presence as preconditions for successful learning. To verify whether these three forms of presences are visible and whether learning was successful, the first four six-week online-based modules with overall 60 participants were analyzed in depth, combining data from community of inquiry surveys, student evaluations, workload assessments and final assessment results. Results indicate that it was possible to build a community of inquiry (with scores of 4.2 and higher) and to foster effective learning. We conclude with recommendations on how to build a community of inquiry in online-based cooperative learning and also discuss some constraints.", "num_citations": "5\n", "authors": ["1137"]}
{"title": "Hybrid software and system development in practice: initial results from Austria\n", "abstract": " The application of software process models in industry includes traditional processes, agile processes, and process variants that aim at balancing traditional and agile with focus on specific industry needs. To investigate the characteristics of such hybrid software and system development approaches that combine agile and traditional approaches the HELENA project was initiated. HELENA is based on a large international survey. Based on the first HELENA survey, conducted in 2016, in 2017 a second round of surveys has been launched. This paper focuses on initial results and discussions of the data from Austria where 22 persons participated. Results showed a good balance of small and medium enterprises and large organizations. Iterative development processes and Scrum are widely spread in these organizations where traditional approaches are often combined with some agile practices.", "num_citations": "5\n", "authors": ["1137"]}
{"title": "Initial investigations on the influence of requirement smells on test-case design\n", "abstract": " Requirements-based testing has become a critical quality assurance technique designed to ensure a sufficiently high degree of product quality. However, the quality of the test cases depends on the quality of the requirements specification. In a preliminary experiment, we analyze potential links between the quality of the requirements and of the test cases.", "num_citations": "5\n", "authors": ["1137"]}
{"title": "Developing and Evaluating Collaborative Online-Based Instructional Designs in Health Information Management.\n", "abstract": " The number of students enrolled in online courses is increasing steadily. Distance education offers many advantages, but also has inherent challenges. Successful distance education needs a thoughtfully designed instructional strategy where students are supported to actively create knowledge. We present the design and evaluation of three online-based courses in health informatics. The courses were based on a collaborative instructional strategy. The evaluation comprised workload analysis, student evaluation, student interviews and student reflections. Students expressed high satisfaction with online learning, despite a high workload, and high perceived learning outcomes. Using the Community of Inquiry framework as reference, we found very high levels of teaching presence, social presence and cognitive presence. Summarizing, we found that the chosen instructional strategy supported student-centered, collaborative learning. We conclude by presenting lesson learned for online-based instructional design.", "num_citations": "5\n", "authors": ["1137"]}
{"title": "Research Challenges in Empowering Agile Teams with Security Knowledge Based on Public and Private Information Sources.\n", "abstract": " The application of agile methods has become increasingly popular that now it is also used in critical system development. Because of this, it is essential to consider the security aspects during agile development. Despite security being knowledge-intensive, developers and product owners in agile projects still have low security knowledge. To overcome this problem, people require more access to easily processable and up-to-date security information, which should be provided on-time and without excessive effort. In this paper, we propose a framework for security data extraction, processing and application. The framework consists of two main components: a security data collection and analysis component as well as a security knowledge generation component. However, the development and process integration of such a framework poses many challenges that are discussed in this paper.", "num_citations": "5\n", "authors": ["1137"]}
{"title": "On the role of software quality management in software process improvement\n", "abstract": " Software Process Improvement (SPI) programs have been implemented, inter alia, to improve quality and speed of software development. SPI addresses many aspects ranging from individual developer skills to entire organizations. It comprises, for instance, the optimization of specific activities in the software lifecycle as well as the creation of organizational awareness and project culture. In the course of conducting a systematic mapping study on the state-of-the-art in SPI from a general perspective, we observed Software Quality Management (SQM) being of certain relevance in SPI programs. In this paper, we provide a detailed investigation of those papers from the overall systematic mapping study that were classified as addressing SPI in the context of SQM (including testing). From the main study\u2019s result set, 92 papers were selected for an in-depth systematic review to study the contributions and to\u00a0\u2026", "num_citations": "5\n", "authors": ["1137"]}
{"title": "Testing security requirements with non-experts: approaches and empirical investigations\n", "abstract": " Security testing has become a critical quality assurance technique to provide a sufficient degree of security. However, it is regarded to be too complex to be performed by system testers, who are non-experts in security. This paper provides two approaches to testing security requirements, one based on a Failure Modes, Vulnerabilities and Effect Analysis (FMVEA) and the other based on misuse cases, both suitable for testers who have domain knowledge but are not security experts. We perform a controlled experiment to empirically compare the two testing approaches based on the quality of the derived test cases. The results of the experiment show that the use of attack patterns in the misuse-case-based approach delivers test cases with a better alignment between requirements and security test cases as well as a higher amount of correct test cases.", "num_citations": "5\n", "authors": ["1137"]}
{"title": "Security test generation by answer set programming\n", "abstract": " Security testing still is a hard task, especially if focusing on non-functional security testing. The two main reasons behind this are, first, at the most a lack of the necessary knowledge required for security testing, second, managing the almost infinite amount of negative test cases, which result from potential security risks. To the best of our knowledge, the issue of the automatic incorporation of security expert knowledge, e.g., known vulnerabilities, exploits and attacks, in the process of security testing is not well considered in the literature. Furthermore, well-known \"de facto\" security testing approaches, like fuzzing or penetration testing, lack systematic procedures regarding the order of execution of test cases, which renders security testing a cumbersome task. Hence, in this paper we propose a new method for generating negative security tests by logic programming, which applies a risk analysis to establish a set of\u00a0\u2026", "num_citations": "5\n", "authors": ["1137"]}
{"title": "Innovation and future of enterprise information systems\n", "abstract": " \u00a9 Springer-Verlag Berlin Heidelberg 2013", "num_citations": "5\n", "authors": ["1137"]}
{"title": "Generic arbitrations for test reporting\n", "abstract": " Generic arbitrations over multiple test runs are important from an industrial point of view as a mean to provide a better understanding of the testing process, to enable monitoring of implementation progress and to estimate an overall software system reliability and to reduce the development cost. We propose to combine behavioural and performance aspects into uniform validation of a system under test which is especially important in the domain of telecommunication, real\u2013time databases and concurrent systems. We introduce expressive and extensible definitions of verdict functions and show how they should be integrated into arbitrations and test reports. The work presented in this paper is a part of the Telling TestStories framework dedicated to model\u2013driven testing in early development stages.", "num_citations": "5\n", "authors": ["1137"]}
{"title": "Continuous experiment definition characteristics\n", "abstract": " The definition of an experiment is a fundamental artifact of continuous experiments. It is used to formalize ideas as a plan of action and to document attained knowledge. Although there is a large body of research on continuous experimentation, the definition of experiments is not researched sufficiently. In this paper, we present a taxonomy of characteristics of continuous experiment definitions. The taxonomy is synthesized from a systematic literature review and a tool review of experimentation platforms. Our findings show amongst others that there are 17 characteristics of experiment definitions. Moreover, that platforms primarily focus on the execution of experiments and that experimentation is more than the execution of an experiment.", "num_citations": "4\n", "authors": ["1137"]}
{"title": "Evaluating the Usefulness and Ease of Use of an Experimentation Definition Language.\n", "abstract": " Before any online controlled experiment, a hypothesis has to be formulated. Moreover, the design, execution, and analysis have to be planned. Given that the definition of an experiment varies considerably amongst experimentation platforms, no common experiment definition exists. Furthermore, there is to the best of the authors\u2019 knowledge no platform-independent experiment definition model proposed in the literature. Thus, we aim to propose an experimentation definition language and evaluate its usefulness and ease of use. Therefore, we developed a domain-specific language based on the results of a previous study and conducted a technology acceptance model study with 30 participants. It revealed that the proposed experiment definition language is considered useful amongst the majority of participants. Moreover, most of the participants rated the language easy to use. Participants without prior knowledge of the domain-specific language\u2019s host language (JSON\u2013JavaScript Object Notation) rated the language considerably less easy to use. To conclude, the proposed experimentation definition language supports practitioners in their experimentation process by providing them a structure and pointing them out to experiment characteristics that could be considered. Furthermore, the machine-readable definition of experiments represents a first step for many research directions, like the automated verification of experiments, or the development of an experiment knowledge base.", "num_citations": "4\n", "authors": ["1137"]}
{"title": "Addressing data quality problems with metamorphic data relations\n", "abstract": " In the era of big data, cloud computing and the Internet of Things, the quality of data has tremendous impact on our everyday life. Moreover, the increasing velocity, volume and variety of data requires new approaches for quality assessment. In this paper, a new approach for quality assessment is presented that applies metamorphic testing to data quality. The exemplary application of the approach on a big data application shows promising results for the suitability of the approach.", "num_citations": "4\n", "authors": ["1137"]}
{"title": "Exploring Security in Software Architecture and Design\n", "abstract": " Cyber-attacks continue to rise as more individuals rely on storing personal information on networks. Even though these networks are continuously checked and secured, cybercriminals find new strategies to break through these protections. Thus, advanced security systems, rather than simple security patches, need to be designed and developed. Exploring Security in Software Architecture and Design is an essential reference source that discusses the development of security-aware software systems that are built into every phase of the software architecture. Featuring research on topics such as migration techniques, service-based software, and building security, this book is ideally designed for computer and software engineers, ICT specialists, researchers, academicians, and field experts.", "num_citations": "4\n", "authors": ["1137"]}
{"title": "What we know about software testability: a survey\n", "abstract": " Context: Software testability is the degree to which a software system or a unit under test supports its own testing. To predict and improve software testability, a large number of techniques and metrics have been proposed by both practitioners and researchers in the last several decades. Reviewing and getting an overview of the entire state-of-the-art and\u2013practice in this area is often challenging for a practitioner or a new researcher.Objective: Our objective is to summarize the state-of-the-art and\u2013practice in this area and to benefit the readers (both practitioners and researchers) in preparing, measuring and improving software testability.Method: To address the above need, we conducted a survey in the form of a systematic literature mapping (classification) in this area. After compiling an initial pool of 303 papers, a systematic voting was conducted among the authors, and our final pool included 208 papers.Results: The area of software testability has been comprehensively studied by researchers and practitioners. Approaches for measurement of testability and improvement of testability are the most-frequently addressed in the papers. The two most often mentioned factors affecting testability are observability and controllability. Common ways to improve testability are testability transformation, improving observability, adding assertions, and improving controllability.Conclusion: We believe that this paper would benefit both practitioners and researchers by serving as an \u201cindex\u201d to the vast body of knowledge in this area. The results could help practitioners measure and improve software testability in their projects. To assess potential benefits of this\u00a0\u2026", "num_citations": "4\n", "authors": ["1137"]}
{"title": "Traceability types for mastering change in collaborative software quality management\n", "abstract": " Software is constantly evolving and to successfully comprehend and manage this evolutionary change is a challenging task which requires traceability support. In this paper we propose a novel approach to traceability as a cornerstone for successful impact analysis and change management, in the context of collaborative software quality management. We first motivate the crucial role of traceability within lifecycle management of the new generation of distributed fragmented software services. Based on the model-based collaborative software quality management framework of Living Models, we then categorize software quality management services and identify novel types of traceability. This is followed by an overview and classification of sample software quality management services from literature, enabled by the interrelation with the identified types of traceability. From this classification we derive the\u00a0\u2026", "num_citations": "4\n", "authors": ["1137"]}
{"title": "Test process improvement with documentation driven integration testing\n", "abstract": " Improving the maturity of the test process in an organization, especially but not limited to integration testing, involves obstacles and risks, such as the additional work overhead of the new process. In addition, integration testing descriptions are often too technical not addressing the language needs of the domain. In research cooperations with companies from the insurance and banking domain it turned out that test descriptions and reports are one of the most useful testing artifacts, while doing adhoc testing. This paper presents a bottom up testing approach, which first helps the integration tester in producing a semi-formal test description and report, up to be an enabler for automatic model-based testing in the very end. The presented approach is based on a textual domain specific language that is able to evolve over time. This is done by analyzing the test descriptions and reports automatically with machine learning\u00a0\u2026", "num_citations": "4\n", "authors": ["1137"]}
{"title": "Design of a Questionnaire on Testing in ERP Projects\n", "abstract": " In this paper we present the design of a questionnaire on testing in ERP projects in the German-speaking area. The questionnaire is designed on the basis of a literature search on testing in ERP projects and a comparable survey on software testing in general. We describe the design process and the structure of the resulting questionnaire which is the basis for future work presented as well.", "num_citations": "4\n", "authors": ["1137"]}
{"title": "Security risk analysis by logic programming\n", "abstract": " In recent years, the complexity of software systems has increased drastically. But methods for assuring their security by testing failed to keep up with this increased complexity. As a result, currently security testing at the most is done by penetration testing, which lacks an underlying structured method. Thus, in this paper we propose an automated risk analysis by logic programming, whose results are valuable in doing structured security testing by additionally focusing on non-functional requirements, a main source for security bugs.", "num_citations": "4\n", "authors": ["1137"]}
{"title": "ERP future 2012\n", "abstract": " This is the introduction of the ERP Future 2012 Research Conference proceedings. It provides a short motivation and an overview of the topics covered by the conference.", "num_citations": "4\n", "authors": ["1137"]}
{"title": "A quality analysis procedure for request data of ERP systems\n", "abstract": " Request data is a valuable source for the release planning and request management of Enterprise Resource Planning systems. As a prerequisite the request data has to be analyzed to check its quality and to identify correlations. In this paper we propose a quality analysis approach for ERP request data and apply it in an industrial case study.", "num_citations": "4\n", "authors": ["1137"]}
{"title": "Managing evolution of service centric systems by test models\n", "abstract": " For various reasons, service centric systems are subject to continuous evolution. Therefore, regular adaptations to their tests are essential to keep, or even improve, their quality of service. In this paper, we present a model\u2013based approach to manage tests for evolving service centric systems. We do so by attaching state machines to all model elements of our system model and test model to manage the consistent evolution of the system and its tests. In our approach, a modification to an arbitrary model element is propagated to related model elements. As a consequence, also these model elements may change their state. Based on test requirements, our approach enables the selective generation and automatic execution of a minimal regression test suite. We demonstrate our approach by a real\u2013world industrial example.", "num_citations": "4\n", "authors": ["1137"]}
{"title": "Analysing the performance of mobile cross-platform development approaches using UI interaction scenarios\n", "abstract": " For developing mobile apps, developers can choose between a native development approach, in which a unique code base needs to be maintained for each supported mobile platform, and mobile cross-platform development (MCPD) approaches. MCPD approaches allow building and deploying mobile apps for several mobile platforms from one single code base. As MCPD approaches build on top of different technologies, in this paper, we analyze the performance of MCPD approaches based on UI interactions. We developed one app natively, and two using MCPD approaches. Using automated tests, we measured CPU usage, memory consumption and rendered frames of these apps when executing UI interaction scenarios consisting of three selected UI interactions (i.e., opening/closing a navigation drawer, screen transition, and virtual scrolling). The study confirms results of previous studies showing that\u00a0\u2026", "num_citations": "3\n", "authors": ["1137"]}
{"title": "Von Autofahrern und Autobauern\u2013Zur Rolle der Informatik in der (Medien) bildung\n", "abstract": " Mit der zunehmenden Digitalisierung aller Lebensbereiche nimmt auch die Bedeutung von Informatik und Medien in der modernen Informationsgesellschaft immer weiter zu. Informatische Bildung hat die M\u00fcndigkeit in der Informationsgesellschaft zum Ziel und vermittelt das entsprechende R\u00fcstzeug, um die Herausforderungen der Digitalisierung auf allen Ebenen bew\u00e4ltigen zu k\u00f6nnen. Basierend auf der Informatik als Schl\u00fcsseldisziplin der Digitalisierung beschreiben wir in diesem Artikel die drei S\u00e4ulen informatischer Bildung. Neben der Informatik sind dies die IKT-Anwendungskompetenz sowie die Medienbildung. Darauf aufbauend stellen wir zwei am Institut f\u00fcr Informatik der Universit\u00e4t Innsbruck entwickelte Unterrichtskonzepte im Bereich Softwarequalit\u00e4t bzw. Datenschutz und Datensicherheit vor, welche die Umsetzung der beiden wissenschaftlichen S\u00e4ulen der informatischen Bildung\u2013die ingenieurwissenschaftlich ausgerichtete Informatik und die sozialwissenschaftlich ausgerichtete Medienbildung\u2013im Unterricht der Sekundarstufe II fundiert umsetzen.", "num_citations": "3\n", "authors": ["1137"]}
{"title": "Integrating a lightweight risk assessment approach into an industrial development process\n", "abstract": " Risk assessment is dependent on its application domain. Risk values consist of probability and impact factors, but there is no fixed, unique guideline for the determination of these two factors. For a precise risk-value calculation, an adequate collection of factors is crucial. In this paper, we show the evolution from the first phase until the application of a risk assessment approach in the area of an international insurance company. In such a risk-aware field we have to systematically determine relevant factors and their severity. The final results are melted into a calculation tool that is embedded in the companies development process and used for decision support system. This paper shows the results and observations for the whole implementation process achieved via action research.", "num_citations": "3\n", "authors": ["1137"]}
{"title": "A case study on the efficiency of model-based testing at the european space agency\n", "abstract": " In this paper we present the results of an empirical case study performed at the European Space Agency (ESA). In this major project, the various challenges for testing were tackled using a model-based approach for test design and the generation of executable test automation scripts. An evaluation of this approach''s efficiency identified significant cost savings and quality improvements.", "num_citations": "3\n", "authors": ["1137"]}
{"title": "Eine industriell erprobte Methode f\u00fcr den Review und Test von Anforderungen mit Hilfe von Fehlertaxonomien\n", "abstract": " Eine industriell erprobte Methode f\u00fcr den Review und Test von Anforderungen mit Hilfe von Fehlertaxonomien Page 1 Eine industriell erprobte Methode f\u00fcr den Review und Test von Anforderungen mit Hilfe von Fehlertaxonomien Michael Felderer1, Armin Beer2 1Universit\u00e4t Innsbruck & QE LaB Business Services Innsbruck, \u00d6sterreich michael.felderer@uibk.ac.at 2Beer Test Consulting Baden, \u00d6sterreich info@arminbeer.at GI Fachgruppentreffen RE 28.11.2013 28.11.2013 Review und Test von Anforderungen mit Hilfe von Fehlertaxonomien Folie 1 Page 2 \u2022 \u00d6ffentliche Sozialversicherungsanstalt in \u00d6sterreich \u2022 Inkrementeller und iterativer Entwicklungs- und Testprozess \u2022 Anforderungs- und Testmanagement wird durch externe Berater unterst\u00fctzt \u2022 Fehlertaxonomien als Ma\u00dfnahme zur Verbesserung der Anforderungsqualit\u00e4t und der Testeffektivit\u00e4t identifiziert und eingesetzt \u2022 Motivation zur systematischen \u2026", "num_citations": "3\n", "authors": ["1137"]}
{"title": "Towards a model-and learning-based framework for security anomaly detection\n", "abstract": " For critical areas, such as the health-care domain, it is common to formalize workflow, traffic-flow and access control via models. Typically security monitoring is used to firstly determine if the system corresponds to the specifications in these models and secondly to deal with threats, e.g. by detecting intrusions, via monitoring rules. The challenge of security monitoring stems mainly from two aspects. First, information in form of models needs to be integrated in the analysis part, e.g. rule creation, visualization, such that the plethora of monitored events are analyzed and represented in a meaningful manner. Second, new intrusion types are basically invisible to established monitoring techniques such as signature-based methods and supervised learning algorithms.               In this paper, we present a pluggable monitoring framework that focuses on the above two issues by linking event information and modelling\u00a0\u2026", "num_citations": "3\n", "authors": ["1137"]}
{"title": "A taxonomy of attack mechanisms in the automotive domain\n", "abstract": " In the last decade, the automotive industry incorporated multiple electronic components into vehicles introducing various capabilities for adversaries to generate diverse types of attacks. In comparison to older types of vehicles, where the biggest concern was physical security, modern vehicles might be targeted remotely. As a result, multiple attack vectors aiming to disrupt different vehicle components emerged. Research and practice lack a comprehensive attack taxonomy for the automotive domain. In this regard, we conduct a systematic literature study, wherein 48 different attacks were identified and classified according to the proposed taxonomy of attack mechanisms. The taxonomy can be utilized by penetration testers in the automotive domain as well as to develop more sophisticated attacks by chaining multiple attack vectors together. In addition, we classify the identified attack vectors based on the following\u00a0\u2026", "num_citations": "2\n", "authors": ["1137"]}
{"title": "An Infrastructure for Platform-Independent Experimentation of Software Changes\n", "abstract": " Current experimentation platforms for online controlled experimentation focus on the technical execution of an experiment. This makes them specific to the application domain, the expected infrastructure, and the used technology. Moreover, the experiment definitions include numerous implicit assumptions about the platform\u2019s implementation. As a result, experiments are difficult to replicate or compare across platforms or even platform versions.", "num_citations": "2\n", "authors": ["1137"]}
{"title": "Towards a Learning Environment for Internet of Things Testing with LEGO\u00ae MINDSTORMS\u00ae\n", "abstract": " Internet of Things (IoT) is one of the most fast-growing topics in computer science. Nearly all devices can be connected to the Internet nowadays. This is related with big opportunities on the one hand, but also with significant risks on the other hand. The challenge is to define a strategy how to test single IoT devices and complete IoT environments consisting of a suite of multiple connected devices. The range of application fields is very extensive and consequently there is no unique testing strategy existing which is suitable for all possible application areas. Testing experts need to be qualified in IoT Testing because this requires more than common software testing technical knowledge of the functions of several devices and its integration in embedded environments. In this paper a concept for further training of testing experts in IoT Testing with LEGO\u00ae MINDSTORMS\u00ae will be demonstrated. Thereby the proven course\u00a0\u2026", "num_citations": "2\n", "authors": ["1137"]}
{"title": "Characteristics of an online controlled experiment: preliminary results of a literature review\n", "abstract": " In this paper the preliminary results of a literature review on characteristics used to define continuous experiments are presented. In total 14 papers were selected. The results were synthesized into a model that gives an overview of all characteristics.", "num_citations": "2\n", "authors": ["1137"]}
{"title": "Using Mini-Projects to Teach Empirical Software Engineering.\n", "abstract": " Empirical studies have become a central element of software engineering research and practice. Yet, teaching the instruments of empirical software engineering is challenging, since students need to understand the theory of the scientific method and also have to develop an understanding of the application of those instruments and their benefits. In this paper, we present and evaluate an approach to teach empirical software engineering with course-integrated mini-projects. In mini-projects, students conduct small empirical studies, eg, surveys, literature reviews, controlled experiments, and data mining studies in collaborating teams. We present the approach through two implementations at two universities as a self-contained course on empirical software engineering and as part of an advanced software engineering course; with 101 graduate students in total. Our evaluation shows a positive learning experience and an improved understanding of the concepts taught. More than a half of the students consider empirical studies helpful for their later careers. Finally, a qualitative coding and a statistical analysis showed the proposed approach beneficial, but also revealed challenges of the scientific work process, eg, data collection activities that were underestimated by the students.", "num_citations": "2\n", "authors": ["1137"]}
{"title": "A process for evidence-based engineering of domain-specific languages\n", "abstract": " Domain-specific languages (DSLs) are mainly designed ad-hoc and gut feeling resulting in languages that are often not well suited for their users and engineers. In this paper we develop a process for evidence-based language engineering to design domain-specific languages based on empirical evidence to support decision in language engineering. The developed process comprises an iterative execution of the phases DSL engineering, issue identification, data collection and evidence appraisal. We exemplify the concept by designing a DSL for Gherkin, a language test-driven acceptance testing in Xtext. The required evidence is derived by mining and analyzing all GitHub projects until July 1, 2017 that apply Gherkin.", "num_citations": "2\n", "authors": ["1137"]}
{"title": "Recent results on classifying risk-based testing approaches\n", "abstract": " In order to optimize the usage of testing efforts and to assess risks of software-based systems, risk-based testing uses risk (re-)assessments to steer all phases in a test process. Several risk-based testing approaches have been proposed in academia and/or applied in industry, so that the determination of principal concepts and methods in risk-based testing is needed to enable a comparison of the weaknesses and strengths of different risk-based testing approaches. In this chapter we provide an (updated) taxonomy of risk-based testing aligned with risk considerations in all phases of a test process. It consists of three top-level classes, i.e., contextual setup, risk assessment, and risk-based test strategy. This taxonomy provides a framework to understand, categorize, assess and compare risk-based testing approaches to support their selection and tailoring for specific purposes. Furthermore, we position four recent risk-based testing approaches into the taxonomy in order to demonstrate its application and alignment with available risk-based testing approaches.", "num_citations": "2\n", "authors": ["1137"]}
{"title": "Evaluation of an Integrated Tool Environment for Experimentation in DSL Engineering\n", "abstract": " Domain specific languages (DSL) are a popular means for providing customized solutions to a certain problem domain. So far, however, language workbenches lack sufficient built-in features in providing decision support when it comes to language design and improvement. Controlled experiments can provide data-driven decision support for both, researchers and language engineers, for comparing different languages or language features. This paper provides an evaluation of an integrated end-to-end tool environment for performing controlled experiments in DSL engineering. The experimentation environment is presented by a running example from engineering domain specific languages for acceptance testing. The tool is built on and integrated into the Meta Programming System (MPS) language workbench. For each step of an experiment the language engineer is supported by suitable DSLs and\u00a0\u2026", "num_citations": "2\n", "authors": ["1137"]}
{"title": "Wie gelingt gemeinsames Lernen in asynchronen Lernumgebungen?\n", "abstract": " Im Pflegebereich ist eine kontinuierliche Fort- und Weiterbildung wichtig, wobei zunehmend auch online-gest\u00fctzte Angebote entstehen. Studieren in online-gest\u00fctzten Lernsettings bietet eine Reihe von Vorteilen wie die Zeit- und Ortsunabh\u00e4ngigkeit des Lernens. Dem gegen\u00fcber steht die Herausforderung, auch in virtuellen Lernumgebungen und damit verbundenen asynchronen Lernsettings soziale Interaktionen und gemeinsames Lernen zu f\u00f6rdern. Entsprechende Angebote m\u00fcssen daher sorgf\u00e4ltig entworfen werden.               Die Community of Inquiry ist ein etabliertes Rahmenwerk f\u00fcr die Gestaltung und Bewertung online-gest\u00fctzter Lernprozesse. Es beschreibt drei Erfolgs-faktoren f\u00fcr online-basiertes Lernen: Social Presence, Teaching Presence, und Cognitive Presence. Wir haben einen rein online-gest\u00fctzten Kurs zum Thema \u201eeHealth\u201c f\u00fcr Personen aus dem Gesundheitswesen durchgef\u00fchrt und an\u00a0\u2026", "num_citations": "2\n", "authors": ["1137"]}
{"title": "Risk Management During Software Development: Results of a Survey in Software Houses from Germany, Austria and Switzerland\n", "abstract": " Resource constraints during development require an elaborated decision-making process supported by risk information. The goal of this paper is to investigate the state-of-practice of risk management during development in software houses. For this purpose, we conducted a survey in Germany, Austria, and Switzerland where 57 software houses participated. The survey results are triangulated by results from literature and interviews with a subset of the survey participants. Results from the survey show that less than a third of the companies performs risk management during development. Main reasons for not performing risk management are lack of resources, need and knowledge. An important application area of risk assessment results is the prioritization of test cases. Finally, technical product risks as well as project risks are commonly applied risk assessment criteria.", "num_citations": "2\n", "authors": ["1137"]}
{"title": "An Agile and Tool-Supported Methodology for Model-Driven System Testing of Service-Centric Systems\n", "abstract": " In this chapter, the authors present an agile and model-driven system testing methodology for service-centric systems called Telling TestStories. The methodology has a tool implementation and is based on separated system, requirements, and test models that can be validated in an integrated way. Test models contain test stories describing test behavior and test data in an integrated way. The underlying testing process is iterative, incremental, and supports a test-driven design on the model level. After a general overview of the artifacts and the testing process, the authors employ the methodology and the tool implementation on a case study from the healthcare domain.", "num_citations": "2\n", "authors": ["1137"]}
{"title": "Monitoring anomalies in it-landscapes using clustering techniques and complex event processing\n", "abstract": " Monitoring the behavior of IT-landscapes is the basis for the detection of breaches of non-functional requirements like security. Established methods, such as signature-based monitoring extract features from data instances and compare them to features of the signature database. However, signature-based monitoring techniques have an intrinsic limitation concerning unseen instances of aberrations (or attacks) because new instances have features which are not yet recognized in the signature database. Therefore, anomaly detection has been introduced to automatically detect non-conforming patterns in data. Unfortunately, it is often prohibitively hard to attain labeled training data to employ supervised-learning based approaches. Hence, the application of nonsupervised techniques such as clustering became popular. In this paper, we apply complex event processing rules and clustering techniques\u00a0\u2026", "num_citations": "2\n", "authors": ["1137"]}
{"title": "D9v0. 1 WSMO Editor\n", "abstract": " Limitations: The meta model for the ontology is simplified (according to the OKBC compliant meta model of Protege, ie we support at the moment concepts (classes) and attributes (facets)). It is currently not possible to modularize ontologies. All information (WSMO, domain ontology and instance data are exported to Flora).Usage: After starting Protege load the WSMO ontology that came with the zip file (\" C:\\WSMOTab\\examples\"). In the classes and instances Tab you can maintain your domain ontology. Within the Web Service Tab you can create the annotation for your service. Note, that all instances will be exported into a separate file (when invoking flora), so you can browse through the relevant F-logic [Kifer et al., 1995] syntax.", "num_citations": "2\n", "authors": ["1137"]}
{"title": "An Architecture to Integrate Experimentation into the Software Development Infrastructure\n", "abstract": " Available platforms for online controlled experimentation primarily focus on the technical execution of experiments and are isolated from the remaining software development infrastructure. The platform-independent experimentation infrastructure separates the experiment definition from its execution and focuses on the experimentation process. However, it is still not integrated into the remaining infrastructure. In this paper, we extend the platform-independent experimentation infrastructure about interfaces to ease its integration into the software development infrastructure. The proposed solution is evaluated using a mixed-method research design to assess its usefulness, ease of use, strengths, and weaknesses. The results indicate that the proposed solution represents an adaptable, platform-independent, and cross-domain experimentation infrastructure that is perceived to be easy to use and useful.", "num_citations": "1\n", "authors": ["1137"]}
{"title": "PWA vs the Others: A Comparative Study on the UI Energy-Efficiency of Progressive Web Apps\n", "abstract": " Developing the same mobile app for multiple platforms is a prominent challenge for practitioners in mobile software development. When starting an app project, practitioners are faced with a plethora of development approaches to choose from. Progressive Web Apps (PWAs) are a novel and promising approach for mobile cross-platform development (MCPD). As mobile devices are limited regarding battery capacity, the energy footprint of a mobile app should be kept as low as possible. Thus, the aim of this study is to analyze the difference in energy consumption of PWAs and other mobile development approaches with a focus on UI rendering and interaction scenarios. For this, we implemented five versions of the same app with different development approaches and examined their energy footprint on two Android devices with four execution scenarios. The results show that the used development approach\u00a0\u2026", "num_citations": "1\n", "authors": ["1137"]}
{"title": "AI-Based Enhancement of Test Models in an Industrial Model-Based Testing Tool\n", "abstract": " This paper presents an envisioned approach to AI-based enhancements of test models in the industrial model-based testing tool TEMPPO Designer. Based on an overview of the tool, we present the required data collector, the AI-based data analyzer and ways to integrate the results into TEMPPO Designer.", "num_citations": "1\n", "authors": ["1137"]}
{"title": "An Approach for Platform-Independent Online Controlled Experimentation\n", "abstract": " Online controlled experimentation is an established technique to assess ideas for software features. Current approaches to conduct experimentation are based on experimentation platforms. However, each experimentation platform has its own explicit properties and implicit assumptions about an experiment. As a result, experiments are incomplete, difficult to repeat, and not comparable across experimentation platforms or platform versions. Our approach separates the experiment definition from the experimentation platform. This makes the experimentation infrastructure-less dependent on the experimentation platform. Requirements on the independent experiment definition are researched and an architecture to implement the approach is proposed. A proof-of-concept demonstrates the feasibility and achieved level of independence from the platform.", "num_citations": "1\n", "authors": ["1137"]}
{"title": "A taxonomy of risk-based testing\n", "abstract": " Software testing has often to be done under severe pressure due to limited resources and a challenging time schedule facing the demand to assure the fulfillment of the software requirements. In addition, testing should unveil those software defects that harm the mission-critical functions of the software. Risk-based testing uses risk (re-)assessments to steer all phases of the test process in order to optimize testing efforts and limit risks of the software-based system. Due to its importance and high practical relevance several risk-based testing approaches were proposed in academia and industry. This paper presents a taxonomy of risk-based testing providing a framework to understand, categorize, assess, and compare risk-based testing approaches to support their selection and tailoring for specific purposes. The taxonomy is aligned with the consideration of risks in all phases of the test process and consists of the top-level classes risk drivers, risk assessment, and risk-based test process. The taxonomy of risk-based testing has been developed by analyzing the work presented in available publications on risk-based testing. Afterwards, it has been applied to the work on risk-based testing presented in this special section of the International Journal on Software Tools for Technology Transfer.", "num_citations": "1\n", "authors": ["1137"]}
{"title": "Impact of Students' Presence and Course Participation on Learning Outcome in Co-Operative Online-based Courses.\n", "abstract": " Socio-constructive instructional designs for online-based learning focus on interaction and communication of students to allow in-depth learning. The objective of this study is to analyze whether increased interaction of students in online-based learning settings may contribute to better outcome. We developed indicators for presence, participation, and interactivity of students. We extracted log data from the learning management system for 31 students in 10 online courses (n= 123 course attendances). We correlated indicators to final grades and also applied a decision tree based machine learning approach. We found only weak to moderate correlations between the indicators and final grades, but acceptable results concerning prediction of students\u2019 success based on the indicators. Our results support the theory that student presence and participation in online-based courses is related to learning outcome.", "num_citations": "1\n", "authors": ["1137"]}
{"title": "Formal methods in industrial practice-Bridging the gap (track summary)\n", "abstract": " Already for many decades, formal methods are considered to be the way forward to help the software industry to make more reliable and trustworthy software. However, despite this strong belief, and many individual success stories, no real change in industrial software development seems to happen. In fact, the software industry is moving fast forward itself, and the gap between what formal methods can achieve, and the daily software development practice does not seem to get smaller (and might even be growing).", "num_citations": "1\n", "authors": ["1137"]}
{"title": "Toward an integrated process model for smart contract engineering\n", "abstract": " Engineering smart contracts for trustless, append-only, and decentralized digital ledgers allows mutually distrustful parties to transform legal requirements into immutable and formalized rules. We present an integrated process model for engineering blockchain-based smart contracts, which explicitly accounts for the immutability of the trustless, append-only, and decentralized digital ledger ecosystem and overcomes several limitations of traditional software engineering process models. Applying such a model when engineering smart contracts will help software engineers and developers to streamline and better understand the overall engineering process of decentralized digital ledgers in general and the blockchain in particular.", "num_citations": "1\n", "authors": ["1137"]}
{"title": "Organizational Patterns between Developers and Testers-Investigating Testers' Autonomy and Role Identity.\n", "abstract": " 1Department of Information Technologies, University of Economics, Prague, Czech Republic 2Institute of Computer Science, University of Innsbruck, Innsbruck, Austria 3Department of Software Engineering, Blekinge Institute of Technology, Karlskrona, Sweden michal. dolezel@ vse. cz, michael. felderer@ uibk. ac. at", "num_citations": "1\n", "authors": ["1137"]}
{"title": "Indikatoren f\u00fcr kooperative, online-basierte Lernprozesse: Entwicklung und Erprobung\n", "abstract": " Lernen als konstruktiver und sozialer Prozess funktioniert am besten in Interaktion mit anderen Personen. Insbesondere in online-basierten Lernsettings sind Interaktion und Kooperation der Studierenden ein wichtiger Faktor f\u00fcr erfolgreiches Lernen.", "num_citations": "1\n", "authors": ["1137"]}
{"title": "Engineering of Software Test-Code: Developing, verifying and maintaining high-quality automated test scripts\n", "abstract": " Automated software testing and development of test code (scripts) are now mainstream in the software industry. For instance, in a recent book, Microsoft test engineers reported that \u201cthere were more than a million [automated] test cases written for Microsoft Office 2007\u201d[1].With emergence of large and complex automated test suites for any major commercial or open-source software, there is a major need for holistic end-to-end management of test code across its entire lifecycle (\u2018holistic\u2019), from test-code development, to its quality assessment and quality improvement, and co-maintenance of test code with production code (\u2018end-to-end\u2019). In a recent review paper [2], we referred to all those activities that should be conducted during the entire lifecycle of test code as Software Test-Code Engineering (STCE) and provided a summary of tools and techniques in this area.", "num_citations": "1\n", "authors": ["1137"]}
{"title": "Issues on software quality models for mastering change\n", "abstract": " A promising cornerstone to master change and to continuously control software quality in the context of todays dynamically evolving complex software systems are software quality models. These models provide an abstract and analyzable view of software artifacts with the objective to describe, assess and/or predict quality. Although software quality models have a high potential to improve effectiveness and efficiency of quality assurance to cope with software change, their acceptance and spread in the software industry is still rather low, as there are several unresolved issues that have to be addressed by upcoming research. This article discusses and exemplifies unresolved key issues on descriptive, generating and predictive software quality models with regard to the (1) creation and maintenance of models, (2) support for extra-functional aspects, (3) traceability between quality models and unstructured\u00a0\u2026", "num_citations": "1\n", "authors": ["1137"]}
{"title": "Towards a concept for enterprise systems landscape testing\n", "abstract": " In this paper, a concept towards productive enterprise systems testing is presented. Identified challenges, including research gaps derived from literature, are discussed. These challenges and research gaps can initially be confirmed based on results of the herein presented survey analysis. Hence, a concept of an enterprise systems landscape is proposed and combined to the ERP testing stage model.", "num_citations": "1\n", "authors": ["1137"]}
{"title": "Threatening the Cloud: Securing Services and Data by Continuous, Model-Driven Negative Security Testing\n", "abstract": " Today's increasing trend towards outsourcing IT landscapes and business processes into the Cloud is a double-edged sword. On the one side, companies can save time and money; however, on the other side, moving possible sensitive data and business processes into the Cloud demands for a high degree of information security. In the course of this chapter, the authors give an overview of a Cloud's various vulnerabilities, how to address them properly, and last but not least, a model-driven approach to evaluate the state of security of a Cloud environment by means of negative testing. Besides, the authors incorporate the idea of living models to allow tracking and incorporating of changes in the Cloud environment and react properly and, more important, in time on evolving security requirements throughout the complete Cloud Life Cycle.", "num_citations": "1\n", "authors": ["1137"]}
{"title": "Novel Methods and Technologies for Enterprise Information Systems\n", "abstract": " \u00a9 Springer International Publishing Switzerland 2014", "num_citations": "1\n", "authors": ["1137"]}
{"title": "Towards Collaborative Requirements Engineering Tool for ERP Product Customization\n", "abstract": " Requirements Engineering (RE) is the foundation for efficient software quality management. It is a cumbersome and complex task, particularly in the context of complex software products such as ERP systems, since it has to deal with numerous and specific challenges and large number of requirements to develop successful product, and therefore requires a systematic and collaborative approach. Tools which support RE in general are numerous nowadays; however, the task of providing a tool that specializes in RE for dynamic, customizable service-centric systems has been addressed seldom. In this sense, the result of our effort to provide such a tool\u2014a support tool for collaborative requirements engineering and software artifacts linking (traceability), with focus on ERP product development and customization\u2014is presented in this short paper. This tool was developed based on results of an analysis of\u00a0\u2026", "num_citations": "1\n", "authors": ["1137"]}
{"title": "MDHPCL 2012 workshop summary\n", "abstract": " This paper provides a summary of the First International Workshop on Model-Driven Engineering for High Performance and CLoud computing (MDHPCL) held as a satellite event of the ACM/IEEE 15th International Conference on Model Driven Engineering Languages and Systems (MODELS) that took place in Innsbruck, Austria on October 2, 2012.", "num_citations": "1\n", "authors": ["1137"]}
{"title": "Telling TestStories\u2013Modellbasiertes Akzeptanz\u2013Testen Serviceorientierter Systeme\n", "abstract": " In diesem Artikel geben wir einen \u00dcberblick \u00fcber Telling TestStories, ein modellbasiertes Testverfahren und Testframework, welches speziell f\u00fcr Akzeptanztests von Serviceorientierten Systemen geeignet ist und derzeit im Rahmen einer Forschungskooperation zwischen der Universit\u00e4t Innsbruck und der Firma softmethod1 entwickelt wird.", "num_citations": "1\n", "authors": ["1137"]}
{"title": "TestStories\u2013Ausf\u00fc\u0308hrbare Requirements f\u00fcr Serviceorientierte Architekturen\n", "abstract": " In diesem Artikel beschreiben wir einen neuen Ansatz f\u00fcr das anforderungsbasierte Testen Serviceorientierter Systeme. Unser Ansatz beinhaltet sowohl eine Testmethode, welche Teile der Anforderungsspezifikation zur Modellierung von Testabl\u00e4ufen n\u00fctzt, als auch ein Testframework, mit welchem es m\u00f6glich ist, aus den Testabl\u00e4ufen konkrete Testf\u00e4lle zu generieren, diese auszuf\u00fchren und zu verwalten. Dadurch wird es m\u00f6glich, Teile der Anforderungsspezifikation \u201d\u2018ausf\u00fchrbar\u201d\u2019 zu machen, was deren Qualit\u00e4t und damit auch jene des Systems als ganzes entscheidend verbessert.", "num_citations": "1\n", "authors": ["1137"]}