{"title": "Handbook of process algebra\n", "abstract": " Process Algebra is a formal description technique for complex computer systems, especially those involving communicating, concurrently executing components. It is a subject that concurrently touches many topic areas of computer science and discrete math, including system design notations, logic, concurrency theory, specification and verification, operational semantics, algorithms, complexity theory, and, of course, algebra. This Handbook documents the fate of process algebra since its inception in the late 1970's to the present. It is intended to serve as a reference source for researchers, students, and system designers and engineers interested in either the theory of process algebra or in learning what process algebra brings to the table as a formal system description and verification technique. The Handbook is divided into six parts spanning a total of 19 self-contained Chapters. The organization is as follows. Part 1, consisting of four chapters, covers a broad swath of the basic theory of process algebra. Part 2 contains two chapters devoted to the sub-specialization of process algebra known as finite-state processes, while the three chapters of Part 3 look at infinite-state processes, value-passing processes and mobile processes in particular. Part 4, also three chapters in length, explores several extensions to process algebra including real-time, probability and priority. The four chapters of Part 5 examine non-interleaving process algebras, while Part 6's three chapters address process-algebra tools and applications.", "num_citations": "867\n", "authors": ["1622"]}
{"title": "CCS expressions, finite state processes, and three problems of equivalence\n", "abstract": " We examine the computational complexity of testing finite state processes for equivalence in Milner's Calculus of Communicating Systems (CCS). The equivalence problems in CCS are presented as refinements of the familiar problem of testing whether two nondeterministic finite automata (NFA) are equivalent, i.e., accept the same language. Three notions of equivalence proposed for CCS are investigated, namely, observational equivalence, strong observational equivalence, and failure equivalence. We show that observational equivalence can be tested in polynomial time. As defined in CCS, observational equivalence is the limit of a sequence of successively finer equivalence relations, \u2248k, where \u22481 is nondeterministic finite automaton equivalence. We prove that, for each fixed k, deciding \u2248k is PSPACE-complete. We show that strong observational equivalence can be decided in polynomial time by reducing\u00a0\u2026", "num_citations": "865\n", "authors": ["1622"]}
{"title": "Algebraic reasoning for probabilistic concurrent systems\n", "abstract": " We extend Milner's SCCS to obtain a calculus, PCCS, for reasoning about communicating probabilistic processes. In particular, the nondeterministic process summation operator of SCCS is replaced with a probabilistic one, in which the probability of behaving like a particular summand is given explicitly. The operational semantics for PCCS is based on the notion of probabilistic derivation, and is given structurally as a set of inference rules. We then present an equational theory for PCCS based on probabilistic bisimulation, an extension of Milner's bisimulation proposed by Larsen and Skou. We provide the first axiomatization of probabilistic bisimulation, a subset of which is relatively complete for finite-state probabilistic processes. In the probabilistic case, a notion of processes with almost identical behavior (ie, with probability 1\\Gamma ffl, for ffl sufficiently small) appears to be more useful in practice than a notion of equivalence, since the latter is often too restricti...", "num_citations": "317\n", "authors": ["1622"]}
{"title": "Efficient model checking using tabled resolution\n", "abstract": " We demonstrate the feasibility of using the XSB tabled logic programming system as a programmable fixed-point engine for implementing efficient local model checkers. In particular, we present XMC, an XSB-based local model checker for a CCS-like value-passing language and the alternation-free fragment of the modal mu-calculus. XMC is written in under 200 lines of XSB code, which constitute a declarative specification of CCS and the modal mu-calculus at the level of semantic equations.             In order to gauge the performance of XMC as an algorithmic model checker, we conducted a series of benchmarking experiments designed to compare the performance of XMC with the local model checkers implemented in C/C++ in the Concurrency Factory and SPIN specification and verification environments. After applying certain newly developed logic-programming-based optimizations (along with some\u00a0\u2026", "num_citations": "286\n", "authors": ["1622"]}
{"title": "Interactive computation: The new paradigm\n", "abstract": " The interaction paradigm is a new conceptualization of computational phenomena that emphasizes interaction over algorithms, reflecting the shift in technology from main-frame number-crunching to distributed intelligent networks with graphical user interfaces. The book is arranged in four sections:\" Introduction\", comprising three chapters that explore and summarize the fundamentals of interactive computation;\" Theory\" with six chapters, each discussing a specific aspect of interaction;\" Applications,\" five chapters showing how this principle is applied in subdisciplines of computer science; and\" New Directions,\" presenting four multidisciplinary applications. The book challenges traditional Turing machine-based answers to fundamental questions of problem solving and the scope of computation.", "num_citations": "256\n", "authors": ["1622"]}
{"title": "Equivalences, congruences, and complete axiomatizations for probabilistic processes\n", "abstract": " We study several notions of process equivalence\u2014viz. trace, failure, ready, and bisimulation equivalence\u2014in the context of probabilistic labeled transition systems. We show that, unlike nondeterministic transition systems, \u201cmaximality\u201d of traces and failures does not increase the distinguishing power of trace and failure equivalence, respectively. Thus, in the probabilistic case, trace and maximal trace equivalence coincide, and failure and ready equivalence coincide.             We then propose a language PCCS for communicating probabilistic processes, and present its operational semantics. We show that in PCCS, trace equivalence and failure equivalence are not congruences, whereas Larsen-Skou probabilistic bisimulation is. Furthermore, we prove that trace congruence, the largest congruence contained in trace equivalence, lies between failure equivalence and bisimulation equivalence in terms of its\u00a0\u2026", "num_citations": "255\n", "authors": ["1622"]}
{"title": "Monte carlo model checking\n", "abstract": " We present MC                 2, what we believe to be the first randomized, Monte Carlo algorithm for temporal-logic model checking. Given a specification S of a finite-state system, an LTL formula \u03d5, and parameters \u03b5 and \u03b4, MC                 2 takes M = ln (\u03b4) / ln (1 \u2013 \u03b5) random samples (random walks ending in a cycle, i.e lassos) from the B\u00fcchi automaton B\u2009=\u2009B                                    S                  \u00d7B                 \u00ac\u03d5                 . to decide if L(B) = \u2205. Let p                                    Z                  be the expectation of an accepting lasso in B. Should a sample reveal an accepting lasso l, MC                 2 returns false with l as a witness. Otherwise, it returns true and reports that the probability of finding an accepting lasso through further sampling, under the assumption that p                                    Z                  \u2265 \u03b5, is less than \u03b4. It does so in time O(MD) and space O(D), where D is B\u2019s recurrence diameter, using an optimal number of samples\u00a0\u2026", "num_citations": "230\n", "authors": ["1622"]}
{"title": "Composition and behaviors of probabilistic I/O automata\n", "abstract": " We augment the I/O automaton model of Lynch and Tuttle with probability, as a step toward the ultimate goal of obtaining a useful tool for specifying and reasoning about asynchronous probabilistic systems. Our new model, called probabilistic I/O automata, preserves the fundamental properties of the I/O automaton model, such as the asymmetric treatment of input and output and the pleasant notion of asynchronous composition. For certain classes of probabilistic I/O automata, we show that probabilistic behavior maps, which are an abstract representation of I/O automaton behavior in terms of a certain expectation operator, are compositional and fully abstract with respect to a natural notion of probabilistic testing.", "num_citations": "168\n", "authors": ["1622"]}
{"title": "Axiomatizing probabilistic processes: ACP with generative probabilities\n", "abstract": " This paper is concerned with finding complete axiomatizations of probabilistic processes. We examine this problem within the context of the process algebra ACP and obtain as our endresult the axiom system pr ACP\u2212l, a version of ACP whose main innovation is a probabilistic asynchronous interleaving operator. Our goal was to introduce probability into ACP in as simple a fashion as possible, Optimally, ACP should be the homomorphic image of the probabilistic version in which the probabilities are forgotten, We begin by weakening slightly ACP to obtain the axiom system ACP\u2212l. The main difference between ACP and ACP\u2212l is that the axiom x + \u03b4 = x, which does not yield a plausible interpretation in the generative model of probabilistic computation, is rejected in ACP\u2212l. We argue that this does not affect the usefulness of ACP\u2212l in practice, and show how ACP can be reconstructed from ACP\u2212l with a minimal\u00a0\u2026", "num_citations": "161\n", "authors": ["1622"]}
{"title": "Turing machines, transition systems, and interaction\n", "abstract": " This paper presents persistent Turing machines (PTMs), a new way of interpreting Turing-machine computation, based on dynamic stream semantics. A PTM is a Turing machine that performs an infinite sequence of \u201cnormal\u201d Turing machine computations, where each such computation starts when the PTM reads an input from its input tape and ends when the PTM produces an output on its output tape. The PTM has an additional worktape, which retains its content from one computation to the next; this is what we mean by persistence.A number of results are presented for this model, including a proof that the class of PTMs is isomorphic to a general class of effective transition systems called interactive transition systems; and a proof that PTMs without persistence (amnesic PTMs) are less expressive than PTMs. As an analogue of the Church-Turing hypothesis which relates Turing machines to algorithmic computation\u00a0\u2026", "num_citations": "140\n", "authors": ["1622"]}
{"title": "A process calculus for mobile ad hoc networks\n", "abstract": " We present the \u03c9-calculus, a process calculus for formally modeling and reasoning about Mobile Ad Hoc Wireless Networks (MANETs) and their protocols. The \u03c9-calculus naturally captures essential characteristics of MANETs, including the ability of a MANET node to broadcast a message to any other node within its physical transmission range (and no others), and to move in and out of the transmission range of other nodes in the network. A key feature of the \u03c9-calculus is the separation of a node\u2019s communication and computational behavior, described by an \u03c9-process, from the description of its physical transmission range, referred to as an \u03c9-process interface. Our main technical results are as follows. We give a formal operational semantics of the \u03c9-calculus in terms of labeled transition systems and show that the state reachability problem is decidable for finite-control \u03c9-processes. We also prove that the \u03c9\u00a0\u2026", "num_citations": "119\n", "authors": ["1622"]}
{"title": "On randomization in sequential and distributed algorithms\n", "abstract": " Probabilistic, or randomized, algorithms are fast becoming as commonplace as conventional deterministic algorithms. This survey presents five techniques that have been widely used in the design of randomized algorithms. These techniques are illustrated using 12 randomized algorithms\u2014both sequential and distributed\u2014 that span a wide range of applications, including:primality testing (a classical problem in number theory), interactive probabilistic proof systems (a new method of program testing), dining philosophers (a classical problem in distributed computing), and Byzantine agreement (reaching agreement in the presence of malicious processors). Included with each algorithm is a discussion of its correctness and its computational complexity. Several related topics of interest are also addressed, including the theory of probabilistic automata, probabilistic analysis of conventional algorithms, deterministic\u00a0\u2026", "num_citations": "119\n", "authors": ["1622"]}
{"title": "From cardiac cells to genetic regulatory networks\n", "abstract": " A fundamental question in the treatment of cardiac disorders, such as tachycardia and fibrillation, is under what circumstances does such a disorder arise? To answer to this question, we develop a multiaffine hybrid automaton (MHA) cardiac-cell model, and restate the original question as one of identification of the parameter ranges under which the MHA model accurately reproduces the disorder. The MHA model is obtained from the minimal cardiac model of one of the authors (Fenton) by first bringing it into the form of a canonical, genetic regulatory network, and then linearizing its sigmoidal switches, in an optimal way. By leveraging the Rovergene tool for genetic regulatory networks, we are then able to successfully identify the parameter ranges of interest.", "num_citations": "115\n", "authors": ["1622"]}
{"title": "A compositional semantics for Statecharts using labeled transition systems\n", "abstract": " We characterize the statecharts step semantics of Pnueli and Shalev as a mapping \u03a8 from an inductively defined algebra of statecharts terms to a domain of labeled transition systems (LTSs). Statecharts equivalence= sc, ie LTS isomorphism, is shown not to be a congruence and hence the step semantics is not compositional. We define a new semantic mapping \u03a8> to a domain of LTSs with a richer label structure, and show that LTS isomorphism in this domain is the largest congruence contained in= sc.", "num_citations": "115\n", "authors": ["1622"]}
{"title": "Simple linear-time algorithms for minimal fixed points\n", "abstract": " We present global and local algorithms for evaluating minimal fixed points of dependency graphs, a general problem in fixed-point computation and model checking. Our algorithms run in linear-time, matching the complexity of the best existing algorithms for similar problems, and are simple to understand. The main novelty of our global algorithm is that it does not use the counter and \u201creverse list\u201d data structures commonly found in existing linear-time global algorithms. This distinction plays an essential role in allowing us to easily derive our local algorithm from our global one. Our local algorithm is distinguished from existing linear-time local algorithms by a combination of its simplicity and suitability for direct implementation.             We also provide linear-time reductions from the problems of computing minimal and maximal fixed points in Boolean graphs to the problem of minimal fixed-point evaluation in\u00a0\u2026", "num_citations": "113\n", "authors": ["1622"]}
{"title": "Fundamental Results for the Verification of Observational Equivalence: A Survey.\n", "abstract": " Various algebraic specification languages for concurrent systems, such as CCS and LOTOS, are based semantically on the notion of observational equivalence between labeled transition systems. We survey a collection of results and algorithms, some of which have appeared very recently, that address the construction of automated tools for verifying observational equivalence of finite transition systems. We then illustrate some basic results and problems concerning how and when CCS expressions may be mapped onto finite transition systems, a necessary step to be able to apply the efficient algorithms above.", "num_citations": "103\n", "authors": ["1622"]}
{"title": "Model checking the secure electronic transaction (SET) protocol\n", "abstract": " We use model checking to establish five essential correctness properties of the secure electronic transaction (SET) protocol. SET has been developed jointly by Visa and MasterCard as a method to secure payment card transactions over open networks, and industrial interest in the protocol is high. Our main contributions are to firstly create a formal model of the protocol capturing the purchase request, payment authorization, and payment capture transactions. Together these transactions constitute the kernel of the protocol. We then encoded our model and the aforementioned correctness properties in the input language of the FDR model checker. Running FDR on this input established that our model of the SET protocol satisfies all five properties even though the cardholder and merchant, two of the participants in the protocol, may try to behave dishonestly in certain ways. To our knowledge, this is the first attempt to\u00a0\u2026", "num_citations": "96\n", "authors": ["1622"]}
{"title": "A comprehensive study of the complexity of multiparty interaction\n", "abstract": " A multipaq interaction is a set of I/0 actions executed jointly by a number of processes, each of which must be ready to execute its own action for any of the actions in the set to occur, An attempt to participate in an interaction delays a process until all other participants are available. Although a relatively new concept, the multiparty interaction has found its way into a number of distributed programming languages and algebraic models of concurrency. In this paper, we present a taxonomy of languages for multiparty interaction that covers all proposals of which we are aware. Based on this taxonomy, we then present a comprehensive analysis of the computational complexity of the multipa~ interaction scheddirrg prob [em, the problem of scheduling multiparty interactions in a given execution environment.", "num_citations": "86\n", "authors": ["1622"]}
{"title": "Model-carrying code (MCC): a new paradigm for mobile-code security\n", "abstract": " A new approach for ensuring the security of mobile code is proposed. Our approach enables a mobile-code consumer to understand and formally reason about what a piece of mobile code can do; check if the actions of the code are compatible with his/her security policies; and, if so, execute the code. The compatibility-checking process is automated, but if there are conflicts, consumers have the opportunity to refine their policies, taking into account the functionality provided by the mobile code. Finally, when the code is executed, our framework uses runtime-monitoring techniques to ensure that the code does not violate the consumer's (refined) policies. At the heart of our method, which we call model-carrying code (MCC), is the idea that a piece of mobile code comes equipped with an expressive yet concise model of the code's (security-relevant) behavior. The generation of such models can be automated. MCC\u00a0\u2026", "num_citations": "85\n", "authors": ["1622"]}
{"title": "Safety-liveness semantics for UML 2.0 sequence diagrams\n", "abstract": " We provide an automata-theoretic solution to one of the main open questions about the UML standard, namely how to assign a formal semantics to a set of sequence diagrams without compromising refinement? Our solution relies on a rather obvious idea, but to our knowledge has not been used before in this context: that bad and good sequence diagrams in the UML standard should be regarded as safety and liveness properties, respectively. Proceeding in this manner, we obtain a semantics that essentially complements the set of behaviors associated with the set of sequence diagrams, thereby allowing us to use the standard notion of refinement as language inclusion. We show that refinement in this setting is compositional with respect to sequential composition, alternative composition, parallel composition, and star+ composition.", "num_citations": "78\n", "authors": ["1622"]}
{"title": "Fully local and efficient evaluation of alternating fixed points\n", "abstract": " We introduce Partitioned Dependency Graphs (PDGs), an abstract framework for the specification and evaluation of arbitrarily nested alternating fixed points. The generality of PDGs subsumes that of similarly proposed models of nested fixed-point computation such as Boolean graphs, Boolean equation systems, and the propositional modal mu-calculus. Our main result is an efficient local algorithm for evaluating PDG fixed points. Our algorithm, which we call LAFP, combines the simplicity of previously proposed induction-based algorithms (such as Winskel's tableau method for v-calculus model checking) with the efficiency of semantics-based algorithms (such as the bit-vector method of Cleaveland, Klein, and Steffen for the equational \u039c-calculus). In particular, LAFP is simply specified, we provide a completely rigorous proof of its correctness, and the number of fixed-point iterations required by the algorithm\u00a0\u2026", "num_citations": "77\n", "authors": ["1622"]}
{"title": "Processes, tasks, and monitors: a comparative study of concurrent programming primitives\n", "abstract": " Three notations for concurrent programming are compared, namely CSP, Ada, and monitors. CSP is an experimental language for exploring structuring concepts in concurrent programming. Ada is a general-purpose language with concurrent programming facilities. Monitors are a construct for managing access by concurrent processes to shared resources. We start by comparing \"lower-level\" communication, synchronization, and nondeterminism in CSP and Ada and then examine \"higher-level\" module interface properties of Ada tasks and monitors.", "num_citations": "74\n", "authors": ["1622"]}
{"title": "Data flow analysis of distributed communicating processes\n", "abstract": " Data flow analysis is a technique essential to the compile-time optimization of computer programs, wherein facts relevant to program optimizations are discovered by the global propagation of facts obvious locally. This paper extends several known techniques for data flow analysis of sequential programs to the static analysis of distributed communicating processes. In particular, we present iterative algorithms for detecting unreachable program statements, and for determining the values of program expressions. The latter information can be used to place bounds on the size of variables and messages. Our main innovation is theevent spanning graph, which serves as a heuristic for ordering the nodes through which data flow information is propagated. We consider bothstatic communication, where all channel arguments are constants, and the more difficultdynamic communication, where channel arguments\u00a0\u2026", "num_citations": "68\n", "authors": ["1622"]}
{"title": "A process calculus for mobile ad hoc networks\n", "abstract": " We present the \u03c9-calculus, a process calculus for formally modeling and reasoning about Mobile Ad Hoc Wireless Networks (MANETs) and their protocols. The \u03c9-calculus naturally captures essential characteristics of MANETs, including the ability of a MANET node to broadcast a message to any other node within its physical transmission range (and no others), and to move in and out of the transmission range of other nodes in the network. A key feature of the \u03c9-calculus is the separation of a node\u2019s communication and computational behavior, described by an \u03c9-process, from the description of its physical transmission range, referred to as an \u03c9-process interface.             Our main technical results are as follows. We give a formal operational semantics of the \u03c9-calculus in terms of labeled transition systems and show that the state reachability problem is decidable for finite-control \u03c9-processes. We also prove\u00a0\u2026", "num_citations": "67\n", "authors": ["1622"]}
{"title": "Priority as extremal probability\n", "abstract": " We extend the stratified model of probabilistic processes to obtain a very general notion ofprocess priority. The main idea is to allow probability guards of value 0 to be associated with alternatives of a probabilistic summation expression. Such alternatives can be chosen only if the non-zero alternatives are precluded by contextual constraints. We refer to this model as one of \u201cextremal probability\u201d and to its signature asPCCS                 \u03b6. We providePCCS                 \u03b6 with a structural operational semantics and a notionof probabilistic bisimulation, which is shown to be a congruence. Of particular interest is the abstractionPCCS                 \u03c0 ofPCCS                 \u03b6 in which all non-zero probability guards are identified.PCCS                 \u03c0 represents a customized framework for reasoning about priority, and covers all features of process algebras proposed for reasoning about priority that we know of.", "num_citations": "65\n", "authors": ["1622"]}
{"title": "Composition and behaviors of probabilistic I/O automata\n", "abstract": " We augment the I/O automaton model of Lynch and Tuttle with probability, as a step toward the ultimate goal of obtaining a useful tool for specifying and reasoning about asynchronous probabilistic systems. Our new model, called probabilistic I/O automata, preserves the fundamental properties of the I/O automaton model, such as the asymmetric treatment of input and output and the pleasant notion of asynchronous composition. For the class of probabilistic I/O automata without internal actions, we show that probabilistic behavior maps, which are an abstract representation of I/O automaton behavior in terms of a certain expectation operator, are compositional and fully abstract with respect to a natural notion of probabilistic testing.", "num_citations": "61\n", "authors": ["1622"]}
{"title": "Efficient modeling of excitable cells using hybrid automata\n", "abstract": " We present an approach based on hybrid automata (HA), which combine discrete transition graphs with continuous dynamical systems, to modeling complex biological systems. Our goal is to efficiently capture the behavior of excitable cells previously modeled by systems of nonlinear differential equations. In particular, we derive HA models from the Hodgkin-Huxley model of the giant squid axon, the Luo-Rudy dynamic model of a guinea pig ventricular cell, and a model of a neonatal rat ventricular myocyte. Our much simpler HA models are able to successfully capture the action-potential morphology of the different cells, as well as reproduce typical excitable cell characteristics, such as refractoriness (period of non-responsiveness to external stimulation) and restitution (adaptation to pacing rates). To model electrical wave propagation in a cell network, the single-cell HA models are linked to a classical 2D spatial model. The resulting simulation framework exhibits significantly improved computational efficiency in modeling complex wave patterns, such as the spiral waves underlying pathological conditions in the heart.", "num_citations": "52\n", "authors": ["1622"]}
{"title": "Winston: A tool for hierarchical design and simulation of concurrent systems\n", "abstract": " Winston is an interactive environment that offers hierarchical editing, analysis, and simulation of concurrent systems. Winston is built using the design/OA\u2122 Development System and hence inherits all the graphics capabilities of design. Winston supports the development of hierarchically structured networks of processes, in which networks of communicating processes may be decomposed recursively into subnetworks. A system specification created using Winston can be studied through multi-level simulation, and by analysis tools which include efficient procedures for deciding Milner\u2019s strong and weak observational equivalence between Finite State Processes.", "num_citations": "51\n", "authors": ["1622"]}
{"title": "Partial-order reduction in the weak modal mu-calculus\n", "abstract": " We present a partial-order reduction technique for local model checking of hierarchical networks of labeled transition systems in the weak modal mu-calculus. We have implemented our technique in the Concurrency Factory specification and verification environment; experimental results show that partial-order reduction can be highly effective in combating state explosion in modal mu-calculus model checking.", "num_citations": "49\n", "authors": ["1622"]}
{"title": "Abstract model repair\n", "abstract": " Given a Kripke structure M and CTL formula \u03d5, where , the problem of Model Repair is to obtain a new model M\u2032 such that M\u2032\u2009\u22a7\u2009\u03d5. Moreover, the changes made to M to derive M\u2032 should be minimal with respect to all such M\u2032. As in model checking, state explosion can make it virtually impossible to carry out model repair on models with infinite or even large state spaces. In this paper, we present a framework for model repair that uses abstraction refinement to tackle state explosion. Our model-repair framework is based on Kripke Structures, a 3-valued semantics for CTL, and Kripke Modal Transition Systems (KMTSs), and features an abstract-model-repair algorithm for KMTSs. Application to an Automatic Door Opener system is used to illustrate the practical utility of abstract model repair.", "num_citations": "47\n", "authors": ["1622"]}
{"title": "Modelling excitable cells using cycle-linear hybrid automata\n", "abstract": " Cycle-linear hybrid automata (CLHAs), a new model of excitable cells that efficiently and accurately captures action-potential morphology and other typical excitable-cell characteristics such as refractoriness and restitution, is introduced. Hybrid automata combine discrete transition graphs with continuous dynamics and emerge in a natural way during the (piecewise) approximation process of any nonlinear system. CLHAs are a new form of hybrid automata that exhibit linear behaviour on a per-cycle basis but whose overall behaviour is appropriately nonlinear. To motivate the need for this modelling formalism, first it is shown how to recast two recently proposed models of excitable cells as hybrid automata: the piecewise-linear model of Biktashev and the nonlinear model of Fenton-Karma. Both of these models were designed to efficiently approximate excitable-cell behaviour. We then show that the CLHA closely\u00a0\u2026", "num_citations": "46\n", "authors": ["1622"]}
{"title": "Finite-state analysis of the CAN bus protocol\n", "abstract": " We formally specify the data link layer of the Controller Area Network (CAN), a high-speed serial bus system with real-time capabilities, widely used in embedded systems. CAN's primary application domain is automotive, and the physical and data link layers of the CAN architecture were the subject of the ISO 11898 international standard. We checked our specification against 12 important properties of CAN, eight of which are gleaned from the ISO standard; the other four are desirable properties not directly mentioned in the standard. Our results indicate that not all properties can be expected to hold of a CAN implementation and we discuss the implications of these findings. Moreover, we have conducted a number of experiments aimed at determining how the size of the protocol's state space is affected by the introduction of various features of the data link layer, the number of nodes in the network the number of\u00a0\u2026", "num_citations": "46\n", "authors": ["1622"]}
{"title": "Coordinating first-order multiparty interactions\n", "abstract": " A first-order multiparty interaction is an abstraction mechanism that defines communication among a set of formal process roles. Actual processes participate in a first-order interaction by enroling into roles, and execution of the interaction can proceed when all roles are filled by distinct processes. As in CSP, enrolement statements can serve as guards in alternative commands. The enrolement guard-scheduling problem then is to enable the execution of first-order interactions through the judicious scheduling of roles to processes that are currently ready to execute enrolement guards. We present a fully distributed and message-efficient algorithm for the enrolement guard-scheduling problem, the first such  solution of which we are aware. We also describe several extensions of the algorithm, including: generic roles; dynamically changing environments, where processes can be created and destroyed at run time; and\u00a0\u2026", "num_citations": "46\n", "authors": ["1622"]}
{"title": "Formal analysis of the kaminsky DNS cache-poisoning attack using probabilistic model checking\n", "abstract": " We use the probabilistic model checker PRISM to formally model and analyze the highly publicized Kaminsky DNS cache-poisoning attack. DNS (Domain Name System) is an internet-wide, hierarchical naming system used to translate domain names such as google.com into physical IP addresses such as 208.77.188.166. The Kaminsky DNS attack is a recently discovered vulnerability in DNS that allows an intruder to hijack a domain, i.e. corrupt a DNS server so that it replies with the IP address of a malicious web server when asked to resolve URLs within a non-malicious domain such as google.com. A proposed fix for the attack is based on the idea of randomizing the source port a DNS server uses when issuing a query to another server in the DNS hierarchy. We use PRISM to introduce a Continuous Time Markov Chain representation of the Kaminsky attack and the proposed fix, and to perform the required\u00a0\u2026", "num_citations": "45\n", "authors": ["1622"]}
{"title": "OSP: an environment for operating system projects\n", "abstract": " OSP\u2014an environment for operating system projects | IEEE Computer Society Technical Committee Newsletter on Operating Systems and Application Environments ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search IEEE Computer Society Technical Committee Newsletter on Operating Systems and Application Environments Periodical Home Latest Issue Archive Authors Affiliations Award Winners More HomeBrowse by TitlePeriodicalsIEEE Computer Society Technical Committee Newsletter on Operating Systems and Application EnvironmentsVol. , No. OSP\u2014an environment for operating system projects article OSP\u2014an environment for operating system projects Share on Authors: Michael Kifer profile \u2026", "num_citations": "45\n", "authors": ["1622"]}
{"title": "A complete axiom system for finite-state probabilistic processes\n", "abstract": " A complete equational axiomatization of probabilistic bisimulation for nitestate probabilistic processes is presented. It extends Milner's complete axiomatization of regular behaviors, which appeared in Volume 28 of the Journal of Computer and System Sciences (1984).", "num_citations": "43\n", "authors": ["1622"]}
{"title": "A logical encoding of the p-calculus: model checking mobile processes using tabled resolution\n", "abstract": " We present MMC, a model checker for mobile systems specified in the style of the \u03c0-calculus. MMC\u2019s development builds on that of XMC, a model checker for an expressive extension of Milner\u2019s value-passing calculus implemented using the XSB tabled logic-programming engine. MMC addresses the salient issues that arise in the \u03c0-calculus, including scope extrusion and intrusion and dynamic generation of new names to avoid name capture. We show that logic programming provides an efficient implementation platform for model checking \u03c0-calculus specifications and can be used to obtain an exact encoding of the \u03c0-calculus\u2019s transitional semantics. Moreover, MMC is easily extended to handle process expressions in the spi-calculus of Abadi and Gordon. Our experimental data show that MMC outperforms other known tools for model checking the \u03c0-calculus.", "num_citations": "41\n", "authors": ["1622"]}
{"title": "A process algebraic semantics for statecharts via state refinement\n", "abstract": " Statecharts 8] is a highly structured and economical description language for complex systems, such as communication protocols and digital control units. Statecharts extend conventional state transition diagrams with three elements dealing with the notions of hierarchy, concurrency and communication. Hierarchy is achieved by embedding one statechart in the state of another statechart. Concurrency is supported by a (mainly) synchronous operation of statechart composition permitting a broadcast-style of communication among the constituent statecharts.It is important to have a formal semantics for statecharts so that their behavior can be precisely and unambiguously understood, and safety-critical properties of systems can be formally veri ed. As pointed out in 12, 17] this is no easy task due to the richness of the language and the fact that it is a visual language. The rst formal semantics for statecharts was given by Harel et al. 10] in the form of an operational model de ned over a sequence of system con gurations and intervals. A system con guration at one interval evolves to another system con guration in the next interval by means of a step. A step is de ned as a maximal sequence of micro-steps, and", "num_citations": "41\n", "authors": ["1622"]}
{"title": "Tabled resolution+ constraints: A recipe for model checking real-time systems\n", "abstract": " Presents a computational framework based on tabled resolution and constraint processing for verifying real-time systems. We also discuss the implementation of this framework in the context of the XMC/RT (eXtended Model Checker/Real-Time) verification tool. For systems specified using timed automata, XMC/RT offers backward and forward reachability analysis, as well as timed modal mu-calculus model checking. It can also handle timed infinite-state systems, such as those with unbounded message buffers, provided the set of reachable states is finite. We illustrate this capability on a real-time version of the Leader Election protocol. Finally, XMC/RT can function as a model checker for untimed systems. Despite this versatility, preliminary benchmarking experiments indicate that XMC/RT's performance remains competitive with that of other real-time verification tools.", "num_citations": "40\n", "authors": ["1622"]}
{"title": "Query-based model checking of ad hoc network protocols\n", "abstract": " A prominent source of complexity in the verification of ad hoc network (AHN) protocols is the fact that the number of network topologies grows exponentially with the square of the number of nodes. To combat this instance explosion problem, we present a query-based verification framework for AHN protocols that utilizes symbolic reachability analysis. Specifically we consider AHN nodes of the form P:I, where P is a process and I is an interface: a set of groups, where each group represents a multicast port. Two processes can communicate if their interfaces share a common group. To achieve a symbolic representation of network topologies, we treat process interfaces as variables and introduce a constraint language for representing topologies. Terms of the language are simply conjunctions of connection and disconnection constraints of the form  and , where  and  are interface\u00a0\u2026", "num_citations": "39\n", "authors": ["1622"]}
{"title": "Compositional analysis of expected delays in networks of probabilistic I/O automata\n", "abstract": " Probabilistic I/O automata (PIOA) constitute a model for distributed or concurrent systems that incorporates a notion of probabilistic choice. The PIOA model provides a notion of composition, for constructing a PIOA for a composite system from a collection of PIOAs representing the components. We present a method for computing completion probability and expected completion time for PIOAs. Our method is compositional, in the sense that it can be applied to a system of PIOAs, one component at a time, without ever calculating the global state space of the system (i.e. the composite PIOA). The method is based on symbolic calculations with vectors and matrices of rational functions, and it draws upon a theory of observables, which are mappings from delayed traces to real numbers that generalize the classical \"formal power series\" from algebra and combinatorics. Central to the theory is a notion of representation for\u00a0\u2026", "num_citations": "38\n", "authors": ["1622"]}
{"title": "Model checking and evidence exploration\n", "abstract": " We present an algebraic framework for evidence exploration: the process of interpreting, manipulating, and navigating the proof structure or evidence produced by a model checker when attempting to verify a system specification for a temporal-logic property. Due to the sheer size of such evidence, single-step traversal is prohibitive and smarter exploration methods are required. Evidence exploration allows users to explore evidence through smaller, manageable views, which are definable in relational graph algebra, a natural extension of relational algebra to graph structures such as model-checking evidence. We illustrate the utility of our approach by applying the Evidence Explorer, our tool implementation of the evidence-exploration framework, to the Java meta-locking algorithm, a highly optimized technique deployed by the Java Virtual Machine to ensure mutually exclusive access to object monitor queues by\u00a0\u2026", "num_citations": "37\n", "authors": ["1622"]}
{"title": "Integrated environments for formally well-founded design and simulation of concurrent systems\n", "abstract": " An ongoing project concerned with the development of environments that support the specification and design of concurrent systems is reported. The project has two key aspects: an existing and working system, Clara, that supports Milner's CCS as a specification and design language; and the development of general techniques for computer-aided generation of Clara-like environments for other concurrent languages. The Clara environment is emphasized. It has two main components: support for the usage of formal techniques in the design process, and a rich and highly interactive simulation facility. A further distinguishing feature is the environment's graphical user interface which is based on a pictorial version of CCS. The semantics of CCS is defined nonprocedurally in two phases: an operational semantics given as a set of inference rules, and an algebraic semantics represented by a set of equational rules.< >", "num_citations": "34\n", "authors": ["1622"]}
{"title": "Formal Analysis of the DNS Bandwidth Amplification Attack and its Countermeasures Using Probabilistic Model Checking\n", "abstract": " The DNS Bandwidth Amplification Attack (BAA) is a distributed denial-of-service attack in which a network of computers floods a DNS server with responses to requests that have never been made. Amplification enters into the attack by virtue of the fact that a small 60-byte request can be answered by a substantially larger response of 4,000 bytes or more in size. We use the PRISM probabilistic model checker to introduce a Continuous Time Markov Chain model of the DNS BAA and three recently proposed countermeasures, and to perform an extensive cost-benefit analysis of the countermeasures. Our analysis, which is applicable to both DNS and DNSSec (a security extension of DNS), is based on objective metrics that weigh the benefits for a server in terms of the percentage increase in the processing of legitimate packets against the cost incurred by incorrectly dropping legitimate traffic. The results we obtain\u00a0\u2026", "num_citations": "32\n", "authors": ["1622"]}
{"title": "Strong interaction fairness via randomization\n", "abstract": " We present MULTI, a symmetric, distributed, randomized algorithm that, with probability one, schedules multiparty interactions in a strongly fair manner. To our knowledge, MULTI is the first algorithm for strong interaction fairness to appear in the literature. Moreover, the expected time taken by MULTI to establish an interaction is a constant not depending on the total number of processes in the system. In this sense, MULTI guarantees real-time response. MULTI makes no assumptions (other than boundedness) about the time it takes processes to communicate. It, thus, offers an appealing tonic to the impossibility results of Tsay and Bagrodia, and Joung concerning strong interaction fairness in an environment, shared-memory, or message-passing, in which processes are deterministic and the communication time is nonnegligible. Because strong interaction fairness is as strong a fairness condition that one might\u00a0\u2026", "num_citations": "30\n", "authors": ["1622"]}
{"title": "On the computational complexity of bisimulation\n", "abstract": " In his Turing Award lecture, Juris Hartmanis eloquently discusses, among other things, the fundamental role of computational complexity theory in computer science. He goes on, in the context of describing joint work with Phil Lewis and Richard Stearns, to highlight some of the results obtained on the computational complexity of problems in formal language theory; for example, all contextfree languages are contained in TIME [n3] and SPACE [log2 n].We argue here that the computational complexity of generative devices such as grammars or automata takes on a new and interesting light when such devices are interpreted as generating(concurrent) processes rather than formal languages and the traditional notion of language equivalence is replaced by bisimulation equivalence. Bisimulation is the cornerstone of a number of theories of concurrent and distributed computing, most notably Robin Milner\u2019s Calculus of\u00a0\u2026", "num_citations": "29\n", "authors": ["1622"]}
{"title": "Model checking the Java meta-locking algorithm\n", "abstract": " We apply the XMC model checker to the Java meta-locking algorithm, a highly optimized technique for ensuring mutually exclusive access by threads to object monitor queues. Our abstract specification of the meta-locking algorithm is fully parameterized, both on M, the number of threads, and N, the number of objects. Using XMC, we show that for a variety of values of M and N, the algorithm indeed provides mutual exclusion and freedom from lockout.", "num_citations": "28\n", "authors": ["1622"]}
{"title": "Runtime assurance framework development for highly adaptive flight control systems\n", "abstract": " This report was developed under a SBIR contract. This report describes the technical progress made by Barron Associates, Inc. and its partners in runtime assurance RTA systems, which hold the promise of protecting advanced systems that cannot be fully certified at design time due to their inherent complexity. A number of technical hurdles remain in the implementation of RTA systems for highly complex safety-critical systems, and the main objective of this effort was to further address these issues. One main focus of this project was to investigate the necessary structure of RTA frameworks for multi-level interacting feedback systems. As such, a challenge problem was constructed for a fleet of unmanned aircraft systems UASs performing a surveillance mission. The demonstration platform consisted of RTA systems for the inner-loop control, outer-loop guidance, ownship flight management, and fleet mission planning elements. The framework design and certification requirements for such a system were explored in this program. For the inner-loop, the concept of employing multiple transition controllers in the reversionary control system was studied. For all feedback levels, the required RTA checks were developed and the critical reversionary switching conditions defined. The interactions between the RTA protected systems and certified collision avoidance systems were also investigated. A safety case argument for design-time certification of the RTA protected systems was constructed using subsystem requirements contracts that were developed from a compositional reasoning approach explored over the course of the project.Descriptors:", "num_citations": "26\n", "authors": ["1622"]}
{"title": "A logical encoding of the \u03c0-calculus: Model checking mobile processes using tabled resolution\n", "abstract": " We present MMC, a model checker for mobile systems speci fied in the style of the \u03c0-calculus. MMC\u2019s development builds on our experience gained in developing XMC, a model checker for an extension of Milner\u2019s value-passing calculus implemented using the XSB tabled logic-programming system. MMC, however, is not simply an extension of XMC; rather it is virtually a complete re-implementation that addresses the salient issues that arise in the \u03c0-calculus, including scope extrusion and intrusion, and dynamic generation of new names to avoid name capture. We show that tabled logic programming is especially suitable as an efficient implementation platform for model checking \u03c0-calculus specications, and can be used to obtain an exact encoding of the \u03c0-calculus\u2019s transitional semantics. Moreover, MMC is easily extended to handle process expressions in the spi-calculus. Our experimental data shows\u00a0\u2026", "num_citations": "26\n", "authors": ["1622"]}
{"title": "Learning cycle-linear hybrid automata for excitable cells\n", "abstract": " We show how to automatically learn the class of Hybrid Automata called Cycle-Linear Hybrid Automata (CLHA) in order to model the behavior of excitable cells. Such cells, whose main purpose is to amplify and propagate an electrical signal known as the action potential (AP), serve as the \u201cbiologic transistors\u201d of living organisms. The learning algorithm we propose comprises the following three phases: (1)\u00a0Geometric analysis of the APs in the training set is used to identify, for each AP, the modes and switching logic of the corresponding Linear Hybrid Automata. (2)\u00a0For each mode, the modified Prony\u2019s method is used to learn the coefficients of the associated linear flows. (3)\u00a0The modified Prony\u2019s method is used again to learn the functions that adjust, on a per-cycle basis, the mode dynamics and switching logic of the Linear Hybrid Automata obtained in the first two phases. Our results show that the learned\u00a0\u2026", "num_citations": "25\n", "authors": ["1622"]}
{"title": "On the analysis of cooperation and antagonism in networks of communicating processes\n", "abstract": " We propose a new method for the analysis of cooperative and antagonistic properties of communicating finite state processes (FSPs). This algebraic technique is based on a composition operator and on the notion of possibility equivalence among FSPs. We demonstrate its utility by showing that potential blocking, termination, and lockout can be decided in polynomial time for loosely connected networks of tree FSPs. Potential blocking and termination are examples of cooperative properties, while lockout is an antagonistic one. For loosely connected networks of (the more general) acyclic FSPs, the cooperative properties become NP-complete and the antagonistic ones PSPACE-complete. For tightly coupled networks of tree FSPs, we also have NP-completeness for the cooperative properties. For the harder case of FSPs with cycles, we provide a natural extension of the method.", "num_citations": "24\n", "authors": ["1622"]}
{"title": "The complexity of reachability in distributed communicating processes\n", "abstract": " A crucial problem in the analysis of communicating processes is the detection of program statements that are unreachable due to communication deadlocks. In this paper, we consider the computational complexity of the reachability problem for various models of communicating processes. We obtain these models by making simplifying assumptions about the behavior of message queues and program control, with the hope that reachability may become easier to decide. Depending on the assumptions made, we show that reachability is undecidable, requires nearly exponential space infinitely often, or is NP-complete. In obtaining these results, we demonstrate a very close relationship between the decidable models and Petri nets and Habermann's path expressions, respectively.", "num_citations": "24\n", "authors": ["1622"]}
{"title": "ANALYSIS OF COMMUNICATING FINITE-STATE PROCESSES.\n", "abstract": " Degree: Ph. D.DegreeYear: 1984Institute: Brown UniversityIn this thesis we analyze a subclass of message-passing programs that can be modeled algebraically as networks of Finite-State Processes (FSPs). These networks form a subset of the systems describable in Milners CCS, and are used as a semantics for a regular subset of Hoare''s CSP.", "num_citations": "24\n", "authors": ["1622"]}
{"title": "Using statistical model checking for measuring systems\n", "abstract": " State spaces represent the way a system evolves through its different possible executions. Automatic verification techniques are used to check whether the system satisfies certain properties, expressed using automata or logic-based formalisms. This provides a Boolean indication of the system\u2019s fitness. It is sometimes desirable to obtain other indications, measuring e.g., duration, energy or probability. Certain measurements are inherently harder than others. This can be explained by appealing to the difference in complexity of checking CTL and LTL properties. While the former can be done in time linear in the size of the property, the latter is PSPACE in the size of the property; hence practical algorithms take exponential time. While the CTL-type of properties measure specifications that are based on adjacency of states (up to a fixpoint calculation), LTL properties have the flavor of expecting some multiple\u00a0\u2026", "num_citations": "22\n", "authors": ["1622"]}
{"title": "Quantitative model checking\n", "abstract": " We present QMC, a one-sided error Monte Carlo decision procedure for the LTL model-checking problem S|= \u03d5. Besides serving as a randomized algorithm for LTL model checking, QMC delivers quantitative information about the likelihood that S|= \u03d5. In particular, given a specification S of a finite-state system, an LTL formula \u03d5, and parameters \u03f5 and \u03b4, QMC performs random sampling to compute an estimate epZ of the expectation pZ that the language L (B) of the B\u00fcchi automaton B= BS\u00d7 B\u00ac \u03d5 is empty; B is such that L (B)=\u2205 iff S|= \u03d5. A random sample in our case is a lasso, ie an initialized random walk through B ending in a cycle. The estimate epZ output by QMC is an (\u03f5, \u03b4)-approximation of pZ\u2014one that is within a factor of 1\u00b1\u03f5 with probability at least 1\u2212 \u03b4\u2014and is computed using a number of samples N that is optimal to within a constant factor, in expected time O (N\u00b7 D) and expected space O (D), where D is B\u2019s recurrence diameter. Experimental results demonstrate that QMC is fast, memory-efficient, and scales extremely well.", "num_citations": "22\n", "authors": ["1622"]}
{"title": "Stochastic game-based analysis of the DNS bandwidth amplification attack using probabilistic model checking\n", "abstract": " The Domain Name System (DNS) is an Internet-wide, hierarchical naming system used to translate domain names into numeric IP addresses. Any disruption of DNS service can have serious consequences. We present a formal game-theoretic analysis of a notable threat to DNS, namely the bandwidth amplification attack (BAA), and the countermeasures designed to defend against it. We model the DNS BAA as a two-player, turn-based, zero-sum stochastic game between an attacker and a defender. The attacker attempts to flood a victim DNS server with malicious traffic by choosing an appropriate number of zombie machines with which to attack. In response, the defender chooses among five BAA countermeasures, each of which seeks to increase the amount of legitimate traffic the victim server processes. To simplify the model and optimize the analysis, our model does not explicitly track the handling of each\u00a0\u2026", "num_citations": "21\n", "authors": ["1622"]}
{"title": "State refinement in process algebra\n", "abstract": " We introduce a state re nement operator into BPA with recursive speci cations and present a comprehensive technical development of the resulting theory, BPA+ SR. Our main technical results are that bisimulation is a congruence in BPA+ SR and that guarded recursive speci cations have unique solutions. We also have that bisimulation remains a congruence if the merge operator of ACP is added to BPA+ SR. This is signi cant since action re nement, another approach to re nement in process algebra, does not in general preserve semantic equivalences based on interleavings of atomic actions.State re nement, to our knowledge, represents the rst attempt to capture the essence of Harel's statecharts| viz., hierarchically structured state transition behavior| within a purely process algebraic setting. A succinct, hierarchical speci cation of an alarm clock is given to illustrate the utility of state re nement in process algebra.", "num_citations": "21\n", "authors": ["1622"]}
{"title": "Model checking with probabilistic tabled logic programming\n", "abstract": " We present a formulation of the problem of probabilistic model checking as one of query evaluation over probabilistic logic programs. To the best of our knowledge, our formulation is the first of its kind, and it covers a rich class of probabilistic models and probabilistic temporal logics. The inference algorithms of existing probabilistic logic-programming systems are well defined only for queries with a finite number of explanations. This restriction prohibits the encoding of probabilistic model checkers, where explanations correspond to executions of the system being model checked. To overcome this restriction, we propose a more general inference algorithm that uses finite generative structures (similar to automata) to represent families of explanations. The inference algorithm computes the probability of a possibly infinite set of explanations directly from the finite generative structure. We have implemented our inference\u00a0\u2026", "num_citations": "20\n", "authors": ["1622"]}
{"title": "Data-driven robust control for type 1 diabetes under meal and exercise uncertainties\n", "abstract": " We present a fully closed-loop design for an artificial pancreas (AP) which regulates the delivery of insulin for the control of Type\u00a0I diabetes. Our AP controller operates in a fully automated fashion, without requiring any manual interaction (e.g.\u00a0in the form of meal announcements) with the patient. A major obstacle to achieving closed-loop insulin control is the uncertainty in those aspects of a patient\u2019s daily behavior that significantly affect blood glucose, especially in relation to meals and physical activity. To handle such uncertainties, we develop a data-driven robust model-predictive control framework, where we capture a wide range of individual meal and exercise patterns using uncertainty sets learned from historical data. These sets are then used in the controller and state estimator to achieve automated, precise, and personalized insulin therapy. We provide an extensive in silico evaluation of our robust\u00a0\u2026", "num_citations": "19\n", "authors": ["1622"]}
{"title": "Compositionality results for cardiac cell dynamics\n", "abstract": " By appealing to the small-gain theorem of one of the authors (Girard), we show that the 13-variable sodium-channel component of the 67-variable IMW cardiac-cell model (Iyer-Mazhari-Winslow) can be replaced by an approximately bi-similar, 2-variable HH-type (Hodgkin-Huxley) abstraction. We show that this substitution of (approximately) equals for equals is safe in the sense that the approximation error between sodium-channel models is not amplified by the feedback-loop context in which it is placed. To prove this feedback-compositionality result, we exhibit quadratic-polynomial, exponentially decaying bisimulation functions between the IMW and HH-type sodium channels, and also for the IMW-based context in which these sodium-channel models are placed. These functions allow us to quantify the overall error introduced by the sodium-channel abstraction and subsequent substitution in the IMW model. To\u00a0\u2026", "num_citations": "19\n", "authors": ["1622"]}
{"title": "On the energy consumption and performance of systems software\n", "abstract": " Models of energy consumption and performance are necessary to understand and identify system behavior, prior to designing advanced controls that can balance out performance and energy use. This paper considers the energy consumption and performance of servers running a relatively simple file-compression workload. We found that standard techniques for system identification do not produce acceptable models of energy consumption and performance, due to the intricate interplay between the discrete nature of software and the continuous nature of energy and performance. This motivated us to perform a detailed empirical study of the energy consumption and performance of this system with varying compression algorithms and compression levels, file types, persistent storage media, CPU DVFS levels, and disk I/O schedulers. Our results identify and illustrate factors that complicate the system's energy\u00a0\u2026", "num_citations": "19\n", "authors": ["1622"]}
{"title": "A theory of testing for soft real-time processes\n", "abstract": " We present a semantic framework for soft real-time processes, ie, processes that meet their deadlines most of the time. The key components of our framework are:(1) a speci cation language PDP (for Probabilistic and Discrete-time Processes) that incorporates both probabilistic and timing aspects of process behavior;(2) a formal operational semantics for PDP given as a recursively de ned probability distribution function over process terms and atomic actions; and (3) a natural notion of a process passing a test with a certain probability, where a test is a process with the added capability of reporting success. By encoding deadlines as tests, the probability of a process passing a test may now be interpreted as the probability of the process meeting a deadline, thereby capturing the essence of soft real-time. A simple video frame transmission example illustrates our approach.", "num_citations": "19\n", "authors": ["1622"]}
{"title": "Towards efficient parallelization of equivalence checking algorithms\n", "abstract": " Towards efficient parallelization of equivalence checking algorithms | Proceedings of the IFIP TC6/WG6.1 Fifth International Conference on Formal Description Techniques for Distributed Systems and Communication Protocols: Formal Description Techniques, V ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleProceedingsFORTE '92Towards efficient parallelization of equivalence checking algorithms Article Towards efficient parallelization of equivalence checking algorithms Share on Authors: Shipei Zhang profile image Shipei Zhang View Profile , Scott Allen Smolka profile image Scott A. Smolka View Profile Authors Info & Affiliations \u2026", "num_citations": "18\n", "authors": ["1622"]}
{"title": "Generation of all counter-examples for push-down systems\n", "abstract": " We present a new, on-the-fly algorithm that given a push-down model representing a sequential program with (recursive) procedure calls and an extended finite-state automaton representing (the negation of) a safety property, produces a succinct, symbolic representation of all counter-examples; i.e., traces of system behaviors that violate the property. The class of what we call minimum-recursion loop-free counter-examples can then be generated from this representation on an as-needed basis and presented to the user. Our algorithm is also applicable, without modification, to finite-state system models. Simultaneous consideration of multiple counter-examples can minimize the number of model-checking runs needed to recognize common root causes of property violations. We illustrate the use of our techniques via application to a Java-Tar utility and an FTP-server program, and discuss a prototype tool\u00a0\u2026", "num_citations": "17\n", "authors": ["1622"]}
{"title": "Vacuity Checking in the Modal Mu-Calculus*\n", "abstract": " Vacuity arises when a logical formula is trivially true in a given model due, for example, to antecedent failure. Beer et al. have recently introduced a logic-independent notion of vacuity and shown that certain logics, i.e., those with polarity, admit an efficient decision procedure for vacuity detection. We show that the modal mu-calculus, a very expressive temporal logic, is a logic with polarity and hence the results of Beer et al. are applicable. We also extend the definition of vacuity to achieve a new notion of redundancy in logical formulas. Redundancy captures several forms of antecedent failure that escape traditional vacuity analysis, including vacuous actions in temporal modalities and unnecessarily strong temporal operators. Furthermore, we have implemented an efficient redundancy checker for the modal mu-calculus in the context of the XMC model checker. Our checker generates diagnostic information\u00a0\u2026", "num_citations": "16\n", "authors": ["1622"]}
{"title": "Software monitoring with bounded overhead\n", "abstract": " In this paper, we introduce the new technique of high-confidence software monitoring (HCSM), which allows one to perform software monitoring with bounded overhead and concomitantly achieve high confidence in the observed error rates. HCSM is formally grounded in the theory of supervisory control of finite-state automata: overhead is controlled, while maximizing confidence, by disabling interrupts generated by the events being monitored - and hence avoiding the overhead associated with processing these interrupts - for as short a time as possible under the constraint of a user-supplied target overhead Otarget. HCSM is a general technique for software monitoring in that HCSM-based instrumentation can be attached at any system interface or API. A generic controller implements the optimal control strategy described above. As a proof of concept, and as a practical framework for software monitoring, we have\u00a0\u2026", "num_citations": "15\n", "authors": ["1622"]}
{"title": "On the computational complexity of bisimulation, redux\n", "abstract": " Paris Kanellakis and the second author (Smolka) were among the first to investigate the computational complexity of bisimulation, and the first and third authors (Moller and Srba) have long-established track records in the field. Smolka and Moller have also written a brief survey about the computational complexity of bisimulation [ACM Comput. Surv. 27(2) (1995) 287]. The authors believe that the special issue of Information and Computation devoted to PCK50: Principles of Computing and Knowledge: Paris C. Kanellakis Memorial Workshop represents an ideal opportunity for an up-to-date look at the subject.", "num_citations": "13\n", "authors": ["1622"]}
{"title": "Localizing program errors for Cimple debugging\n", "abstract": " We present automated techniques for the explanation of counter-examples, where a\u00a0counter-example should be understood as a sequence of program statements. Our approach is based on variable dependency analysis and is applicable to programs written in Cimple, an expressive subset of the C programming language. Central to our approach is the derivation of a\u00a0focus-statement sequence (FSS) from a given counter-example: a\u00a0subsequence of the counter-example containing only those program statements that directly or indirectly affect the variable valuation leading to the program error behind the counter-example. We develop a\u00a0ranking procedure for FSSs where FSSs of higher rank are conceptually easier to understand and correct than those of lower rank. We also analyze constraints over uninitialized variables in order to localize program errors to specific program segments; this often allows the\u00a0\u2026", "num_citations": "13\n", "authors": ["1622"]}
{"title": "Evidence explorer: A tool for exploring model-checking proofs\n", "abstract": " We present the Evidence Explorer (http://www.cs.sunysb.edu/~lmc/ee/), a new tool for assisting users in navigating the proof structure, or evidence, produced by a model checker when attempting to verify a system specification for a temporal-logic property. Due to the sheer size of such evidence, single-step traversal is prohibitive and smarter exploration methods are required. The Evidence Explorer enables users to explore evidence through a collection of orthogonal but coordinated views. These views allow one to quickly ascertain the overall perception of evidence through consistent visual cues, and easily locate interesting regions by simple drill-down operations. As described in [3], views are definable in relational graph algebra, a natural extension of relational algebra to graph structures such as model-checking evidence.", "num_citations": "13\n", "authors": ["1622"]}
{"title": "Computing bisimulation functions using SOS optimization and \u03b4-decidability over the reals\n", "abstract": " We present BFComp, an automated framework based on Sum-Of-Squares (SOS) optimization and \u03b4-decidability over the reals, to compute Bisimulation Functions (BFs) that characterize Input-to-Output Stability (IOS) of dynamical systems. BFs are Lyapunov-like functions that decay along the trajectories of a given pair of systems, and can be used to establish the stability of the outputs with respect to bounded input deviations.", "num_citations": "12\n", "authors": ["1622"]}
{"title": "Using integer clocks to verify the timing-sync sensor network protocol\n", "abstract": " We use the UPPAAL model checker for Timed Automata to verify the Timing-Sync time-synchronization protocol for sensor networks (TPSN). The TPSN protocol seeks to provide network-wide synchronization of the distributed clocks in a sensor network. Clock-synchronization algorithms for sensor networks such as TPSN must be able to perform arithmetic on clock values to calculate clock drift and network propagation delays. They must be able to read the value of a local clock and assign it to another local clock. Such operations are not directly supported by the theory of Timed Automata. To overcome this formal-modeling obstacle, we augment the UPPAAL specification language with the integer clock derived type. Integer clocks, which are essentially integer variables that are periodically incremented by a global pulse generator, greatly facilitate the encoding of the operations required to synchronize clocks as in the TPSN protocol. With this integer-clock-based model of TPSN in hand, we use UPPAAL to verify that the protocol achieves network-wide time synchronization and is devoid of deadlock. We also use the UPPAAL Tracer tool to illustrate how integer clocks can be used to capture clock drift and resynchronization during protocol execution.", "num_citations": "12\n", "authors": ["1622"]}
{"title": "Neural predictive monitoring\n", "abstract": " Neural State Classification (NSC) is a recently proposed method for runtime predictive monitoring of Hybrid Automata (HA) using deep neural networks (DNNs). NSC trains a DNN as an approximate reachability predictor that labels a given HA state x as positive if an unsafe state is reachable from x within a given time bound, and labels x as negative otherwise. NSC predictors have very high accuracy, yet are prone to prediction errors that can negatively impact reliability. To overcome this limitation, we present Neural Predictive Monitoring (NPM), a technique based on NSC and conformal prediction that complements NSC predictions with statistically sound estimates of uncertainty. This yields principled criteria for the rejection of predictions likely to be incorrect, without knowing the true reachability values. We also present an active learning method that significantly reduces both the NSC predictor\u2019s error\u00a0\u2026", "num_citations": "11\n", "authors": ["1622"]}
{"title": "FocusCheck: A tool for model checking and debugging sequential C programs\n", "abstract": " We present the FocusCheck model-checking tool for the verification and easy debugging of assertion violations in sequential C programs. The main functionalities of the tool are the ability to: (a) identify all minimum-recursion, loop-free counter-examples in a C program using on-the-fly abstraction techniques; (b) extract focus-statement sequences (FSSs) from counter-examples, where a focus statement is one whose execution directly or indirectly causes the violation underlying a counter-example; (c) detect and discard infeasible counter-examples via feasibility analysis of the corresponding FSSs; and (d) isolate program segments that are most likely to harbor the erroneous statements causing the counter-examples. FocusCheck is equipped with a smart graphical user interface that provides various views of counter-examples in terms of their FSSs, thereby enhancing usability and readability of model\u00a0\u2026", "num_citations": "11\n", "authors": ["1622"]}
{"title": "Model discovery for energy-aware computing systems: An experimental evaluation\n", "abstract": " We present a model-discovery methodology for energy-aware computing systems that achieves high prediction accuracy. Model discovery, or system identification, is a critical first step in designing advanced controllers that can dynamically manage the energy-performance trade-off in an optimal manner. Our methodology favors Multiple-Inputs-Multiple-Outputs (MIMO) models over a collection of Single-Input-Single-Output (SISO) models, when the inputs and outputs of the system are coupled in a nontrivial way. In such cases, MIMO is generally more accurate than SISO over a wide range of inputs in predicting system behavior. Our experimental evaluation, carried out on a representative server workload, validates our approach. We obtained an average prediction accuracy of 77% and 76% for MIMO power and performance, respectively. We also show that MIMO models are consistently more accurate than SISO\u00a0\u2026", "num_citations": "10\n", "authors": ["1622"]}
{"title": "Software design, specification, and verification: Lessons learned from the Rether case study\n", "abstract": " Rether is a software-based real-time ethernet protocol developed at SUNY Stony Brook. The purpose of this protocol is to provide guaranteed bandwidth and deterministic, periodic network access to multimedia applications over commodity ethernet hardware. It has been implemented in the PreeBSD 2.1. 0 operating system, and is now being used to support the Stony Brook Video Server (SBVS), a low-cost, ethernet LAN-based server providing real-time delivery of video to end-users from the server's disk subsystem. Using local model checking, as provided by the Concurrency Factory specification and verification environment, we showed (for a particular network configuration) that Rether indeed makes good on its bandwidth guarantees to real-time nodes without exposing non-real-time nodes to the possibility of starvation. In the course of specifying and verifying Rether, we identified an alternative design of the\u00a0\u2026", "num_citations": "10\n", "authors": ["1622"]}
{"title": "Probabilistic reachability analysis of the tap withdrawal circuit in caenorhabditis elegans\n", "abstract": " We present a probabilistic reachability analysis of a (nonlinear ODE) model of a neural circuit in Caeorhabditis elegans (C. elegans), the common roundworm. In particular, we consider Tap Withdrawal (TW), a reflexive behavior exhibited by a C. elegans worm in response to vibrating the surface on which it is moving. The neural circuit underlying this response is the subject of this investigation. Specially, we perform bounded-time reachability analysis on the TW circuit model of Wicks et al. (1996) to estimate the probability of various TW responses. The Wicks et al. model has a number of parameters, and we demonstrate that the various TW responses and their probability of occurrence in a population of worms can be viewed as a problem of parameter uncertainty. Our approach to this problem rests on encoding each TW response as a hybrid automaton with parametric uncertainty. We then perform probabilistic\u00a0\u2026", "num_citations": "9\n", "authors": ["1622"]}
{"title": "Model checking the Java metalocking algorithm\n", "abstract": " We report on our efforts to use the XMC model checker to model and verify the Java metalocking algorithm. XMC [Ramakrishna et al. 1997] is a versatile and efficient model checker for systems specified in XL, a highly expressive value-passing language. Metalocking [Agesen et al. 1999] is a highly-optimized technique for ensuring mutually exclusive access by threads to object monitor queues and, therefore; plays an essential role in allowing Java to offer concurrent access to objects. Metalocking can be viewed as a two-tiered scheme. At the upper level, the metalock level, a thread waits until it can enqueue itself on an object's monitor queue in a mutually exclusive manner. At the lower level, the monitor-lock level, enqueued threads race to obtain exclusive access to the object. Our abstract XL specification of the metalocking algorithm is fully parameterized, both on the number of threads M, and the number of\u00a0\u2026", "num_citations": "9\n", "authors": ["1622"]}
{"title": "Lagrangian reachabililty\n", "abstract": " We introduce LRT, a new Lagrangian-based ReachTube computation algorithm that conservatively approximates the set of reachable states of a nonlinear dynamical system. LRT makes use of the Cauchy-Green stretching factor (SF), which is derived from an over-approximation of the gradient of the solution-flows. The SF measures the discrepancy between two states propagated by the system solution from two initial states lying in a well-defined region, thereby allowing LRT to compute a reachtube with a ball-overestimate in a metric where the computed enclosure is as tight as possible. To evaluate its performance, we implemented a prototype of LRT in C++/Matlab, and ran it on a set of well-established benchmarks. Our results show that LRT compares very favorably with respect to the CAPD and Flow* tools.", "num_citations": "8\n", "authors": ["1622"]}
{"title": "Model checking tap withdrawal in C. Elegans\n", "abstract": " We present what we believe to be the first formal verification of a biologically realistic (nonlinear ODE) model of a neural circuit in a multicellular organism: Tap Withdrawal (TW) in C. Elegans, the common roundworm. TW is a reflexive behavior exhibited by C. Elegans in response to vibrating the surface on which it is moving; the neural circuit underlying this response is the subject of this investigation. Specially, we perform reach-tube-based reachability analysis on the TW circuit model of Wicks et al. (1996) to estimate key model parameters. Underlying our approach is the use of Fan and Mitra\u2019s recently developed technique for automatically computing local discrepancy (convergence and divergence rates) of general nonlinear systems.                 The results we obtain are a significant extension of those of Wicks et al. (1996), who equip their model with fixed parameter values that reproduce the predominant\u00a0\u2026", "num_citations": "8\n", "authors": ["1622"]}
{"title": "Tools and Algorithms for the Construction and Analysis of Systems: 19th International Conference, TACAS 2013, Held as Part of the European Joint Conferences on Theory and\u00a0\u2026\n", "abstract": " This book constitutes the proceedings of the 19th International Conference on Tools and Algorithms for the Construction and Analysis of Systems, TACAS 2013, held in Rome, Italy, in March 2013. The 42 papers presented in this volume were carefully reviewed and selected from 172 submissions. They are organized in topical sections named: Markov chains; termination; SAT/SMT; games and synthesis; process algebra; pushdown; runtime verification and model checking; concurrency; learning and abduction; timed automata; security and access control; frontiers (graphics and quantum); functional programs and types; tool demonstrations; explicit-state model checking; B\u00fcchi automata; and competition on software verification.", "num_citations": "8\n", "authors": ["1622"]}
{"title": "Hybrid automata as a unifying framework for modeling excitable cells\n", "abstract": " We propose hybrid automata (HA) as a unifying framework for computational models of excitable cells. HA, which combine discrete transition graphs with continuous dynamics, can be naturally used to obtain a piecewise, possibly linear, approximation of a nonlinear excitable-cell model. We first show how HA can be used to efficiently capture the action-potential morphology-as well as reproduce typical excitable-cell characteristics such as refractoriness and restitution-of the dynamic Luo-Rudy model of a guinea-pig ventricular myocyte. We then recast two well-known computational models, Biktashev's and Fenton-Karma, as HA without any loss of expressiveness. Given that HA possess an intuitive graphical representation and are supported by a rich mathematical theory and numerous analysis tools, we argue that they are well positioned as a computational model for biological processes", "num_citations": "8\n", "authors": ["1622"]}
{"title": "Testing protocol robustness the CCS way\n", "abstract": " We present a procedure to decide if a finite-state communication protocol provides end-users with a robust communication medium. The underlying model is algebraic and is based on Milner's CCS and observation equivalence, the notion that two processes cannot be distinguished by an external observer. In particular, we test if the protocol's visible behavior is observationally equivalent to the behavior of an ideal communication medium. We develop asynchronous versions of the protocols to illustrate our technique.", "num_citations": "8\n", "authors": ["1622"]}
{"title": "Committed moving horizon estimation for meal detection and estimation in type 1 diabetes\n", "abstract": " We introduce a model-based meal detection and estimation method for the treatment of type 1 diabetes that automatically detects the occurrence and estimates the amount of carbohydrate (CHO) intake from continuous glucose monitor (CGM) data. Meal detection and estimation play a critical role in closed-loop insulin control by enabling automatic regulation of post-meal insulin dosing in artificial pancreas systems without manual meal announcements by the patient. Our approach to meal detection is based on a novel technique we call Committed Moving Horizon Estimation (CMHE), an extension of Moving Horizon Estimation (MHE). While MHE alone is not well-suited for disturbance estimation and meal detection, CMHE aggregates the meal disturbances estimated by multiple MHE instances to balance future and past information at decision time, thus providing timely detection and accurate estimation. We\u00a0\u2026", "num_citations": "7\n", "authors": ["1622"]}
{"title": "Alternating fixed points in Boolean equation systems as preferred stable models\n", "abstract": " We formally characterize alternating fixedp oints of boolean equation systems as models of (propositional) normal logic programs. To this end, we introduce the notion of a preferred stable model of a logic program, andd efine a mapping that associates a normal logic program with a boolean equation system such that the solution to the equation system can be \u201creado. \u201d the preferredstable model of the logic program. We also show that the preferredmo del cannot be calculateda-p osteriori (i.e. compute stable models andc hoose the preferredone) but rather must be computedin an intertwinedfashion with the stable model itself. The mapping reveals a natural relationship between the evaluation of alternating fixedp oints in boolean equation systems andthe Gelfond- Lifschitz transformation usedin stable-model computation.               For alternation-free boolean equation systems, we show that the logic\u00a0\u2026", "num_citations": "7\n", "authors": ["1622"]}
{"title": "Real-time verification techniques for untimed systems\n", "abstract": " We show that verification techniques for timed automata based on the Alur and Dill region-graph construction can be applied to much more general kinds of systems, including asynchronous untimed systems over unbounded integer variables. We follow this approach in proving that the model-checking problem for the n-process Bakery algorithm is decidable, for any fixed n. We believe this is the first decidability proof for this problem to appear in the literature.", "num_citations": "7\n", "authors": ["1622"]}
{"title": "A comprehensive study of the complexity of multiparty interaction\n", "abstract": " We present a taxonomy of languages for multiparty interaction, which covers all proposals of which we are aware. Based on this taxonomy, we present a comprehensive analysis of the computational complexity of the multiparty interaction implementation problem, the problem of scheduling multiparty interactions in a given execution environment.", "num_citations": "7\n", "authors": ["1622"]}
{"title": "Swarm model checking on the GPU\n", "abstract": " We present Grapple, a new and powerful framework for explicit-state model checking on GPUs. Grapple is based on swarm verification (SV), a model-checking technique wherein a collection or swarm of small, memory- and time-bounded verification tests (VTs) are run in parallel to perform state-space exploration. SV achieves high state-space coverage via diversification of the search strategies used by constituent VTs. Grapple represents a swarm implementation for the GPU. In particular, it runs a parallel swarm of internally parallel VTs, which are implemented in a manner that specifically targets the GPU architecture and the SIMD parallelism its computing cores offer. Grapple also makes effective use of the GPU shared memory, eliminating costly inter-block communication overhead. We conducted a comprehensive performance analysis of Grapple focused on various design parameters, including the size of the\u00a0\u2026", "num_citations": "6\n", "authors": ["1622"]}
{"title": "A cycle-linear approach to modeling action potentials\n", "abstract": " We introduce cycle-linear hybrid automata (CLHA) and show how they can be used to efficiently model dynamical systems that exhibit nonlinear, pseudo-periodic behavior. CLHA are based on the observation that such systems cycle through a fixed set of operating modes, although the dynamics and duration of each cycle may depend on certain computational aspects of past cycles. CLHA are constructed around these modes such that the per-cycle, per-mode dynamics are given by a time-invariant linear system of equations; the parameters of the system are dependent on a deformation coefficient computed at the beginning of each cycle as a function of memory units. Viewed over time, CLHA generate a very intuitive, linear approximation of the entire phase space of the original, nonlinear system. We show how CLHA can be used to efficiently model the action potential of various types of excitable cells and their\u00a0\u2026", "num_citations": "6\n", "authors": ["1622"]}
{"title": "A provably correct compiler for efficient model checking of mobile processes\n", "abstract": " We present an optimizing compiler for the \u03c0-calculus that significantly improves the time and space performance of the MMC model checker. MMC exploits the similarity between the manner in which resolution techniques handle variables in a logic program and the manner in which the operational semantics of the \u03c0-calculus handles names by representing \u03c0-calculus names in MMC as Prolog variables, with distinct names represented by distinct variables. Given a \u03c0-calculus process P, our compiler for MMC produces an extremely compact representation of P\u2019s symbolic state space as a set of transition rules. It also uses AC unification to recognize states that are equivalent due to symmetry.", "num_citations": "6\n", "authors": ["1622"]}
{"title": "Safe CPS from Unsafe Controllers\n", "abstract": " In this paper, we explore using runtime verification to design safe cyber-physical systems (CPS). We build upon the Simplex Architecture, where control authority may switch from an unverified and potentially unsafe advanced controller to a backup baseline controller in order to maintain system safety. New to our approach, we remove the requirement that the baseline controller is statically verified. This is important as there are many types of powerful control techniques -- model-predictive control, rapidly-exploring random trees and neural network controllers -- that often work well in practice, but are difficult to statically prove correct, and therefore could not be used before as baseline controllers. We prove that, through more extensive runtime checks, such an approach can still guarantee safety. We call this approach the Black-Box Simplex Architecture, as both high-level controllers are treated as black boxes. We present case studies where model-predictive control provides safety for multi-robot coordination, and neural networks provably prevent collisions for groups of F-16 aircraft, despite occasionally outputting unsafe actions.", "num_citations": "5\n", "authors": ["1622"]}
{"title": "Lagrangian Reachtubes: The Next Generation\n", "abstract": " We introduce LRT-NG, a set of techniques and an associated toolset that computes a reachtube (an over-approximation of the set of reachable states over a given time horizon) of a nonlinear dynamical system. LRT-NG significantly advances the state-of-the-art Langrangian Reachability and its associated tool LRT. From a theoretical perspective, LRT-NG is superior to LRT in three ways. First, it uses for the first time an analytically computed metric for the propagated ball which is proven to minimize the ball\u2019s volume. We emphasize that the metric computation is the centerpiece of all bloating-based techniques. Secondly, it computes the next reachset as the intersection of two balls: one based on the Cartesian metric and the other on the new metric. While the two metrics were previously considered opposing approaches, their joint use considerably tightens the reachtubes. Thirdly, it avoids the \"wrapping effect\"\u00a0\u2026", "num_citations": "5\n", "authors": ["1622"]}
{"title": "Data-driven robust control for a closed-loop artificial pancreas\n", "abstract": " We present a fully closed-loop design for an artificial pancreas (AP) that regulates the delivery of insulin for the control of Type I diabetes. Our AP controller operates in a fully automated fashion, without requiring any manual interaction with the patient (e.g., in the form of meal announcements). A major obstacle to achieving closed-loop insulin control are the \u201cunknown disturbances\u201d related to various aspects of a patient's daily behavior, especially meals and physical activity. Such disturbances can significantly affect the patient's blood glucose levels. To handle such uncertainties, we present a data-driven, robust, model-predictive control framework in which we capture a wide range of individual meal and exercise patterns using uncertainty sets learned from historical data. These uncertainty sets are then used in the insulin controller to achieve automated, precise, and personalized insulin therapy. We provide an\u00a0\u2026", "num_citations": "5\n", "authors": ["1622"]}
{"title": "Computing compositional proofs of input-to-output stability using SOS optimization and \u03b4-decidability\n", "abstract": " We present BFComp, an automated framework based on Sum-Of-Squares (SOS) optimization and \u03b4-decidability over the reals, to compute Bisimulation Functions (BFs) that characterize Input-to-Output Stability (IOS) of dynamical systems. BFs are Lyapunov-like functions that decay along the trajectories of a given pair of systems, and can be used to establish the stability of the outputs with respect to bounded input deviations. In addition to establishing IOS, BFComp is designed to provide tight bounds on the squared output errors between systems whenever possible. For this purpose, two SOS optimization formulations are employed: SOSP 1, which enforces the decay requirements on a discretized grid over the input space, and SOSP 2, which covers the input space exhaustively. SOSP 2 is attempted first, and if the resulting error bounds are not satisfactory, SOSP 1 is used to compute a Candidate BF (CBF). The\u00a0\u2026", "num_citations": "5\n", "authors": ["1622"]}
{"title": "MODELNG THE AODV ROUTING PROTOCOL IN THE \u03c9-CALCULUS\n", "abstract": " Mobile ad hoc wireless networks (MANETs) are autonomous collections of mobile nodes that communicate over wireless links. Formal verification of routing protocols for MANETs requires concise yet property-preserving modeling to correctly verify the model and at the same time also avoid running into the problem of state-space explosion. The characteristics of MANETs that pose challenge to the task of modeling are node mobility and broadcast. We have developed a new modeling formalism, called the \u03c9-calculus, to naturally and succinctly model MANET protocols. This paper describes the modeling of AODV, a reactive routing protocol for MANETs, in the \u03c9-calculus. We aim to subject the model to formal verification in order to prove properties of the AODV routing protocol.", "num_citations": "5\n", "authors": ["1622"]}
{"title": "Efficient event-driven simulation of excitable hybrid automata\n", "abstract": " We present an efficient, event-driven simulation framework for large-scale networks of excitable hybrid automata (EHA), a particular kind of hybrid automata that we use to model excitable cells. A key aspect of EHA is that they possess protected modes of operation in which they are non-responsive to external inputs. In such modes, our approach takes advantage of the analytical solution of the modes' linear differential equations to eliminate all integration steps, and therefore to dramatically reduce the amount of computation required. We first present a simple simulation framework for EHA based on a time-step integration method that follows naturally from our EHA models. We then present our event-driven simulation framework, where each cell has an associated event specifying both the type of processing next required for the cell and a time at which the processing must occur. A priority queue, specifically\u00a0\u2026", "num_citations": "5\n", "authors": ["1622"]}
{"title": "On the verification of neural odes with stochastic guarantees\n", "abstract": " We show that Neural ODEs, an emerging class of time-continuous neural networks, can be verified by solving a set of global-optimization problems. For this purpose, we introduce Stochastic Lagrangian Reachability (SLR), an abstraction-based technique for constructing a tight Reachtube (an over-approximation of the set of reachable states over a given time-horizon), and provide stochastic guarantees in the form of confidence intervals for the Reachtube bounds. SLR inherently avoids the infamous wrapping effect (accumulation of over-approximation errors) by performing local optimization steps to expand safe regions instead of repeatedly forward-propagating them as is done by deterministic reachability methods. To enable fast local optimizations, we introduce a novel forward-mode adjoint sensitivity method to compute gradients without the need for backpropagation. Finally, we establish asymptotic and non-asymptotic convergence rates for SLR.", "num_citations": "4\n", "authors": ["1622"]}
{"title": "Synthesizing stealthy reprogramming attacks on cardiac devices\n", "abstract": " An Implantable Cardioverter Defibrillator (ICD) is a medical device used for the detection of potentially fatal cardiac arrhythmias and their treatment through the delivery of electrical shocks intended to restore normal heart rhythm. An ICD reprogramming attack seeks to alter the device's parameters to induce unnecessary therapy or prevent required therapy. In this paper, we present a formal approach for the synthesis of ICD reprogramming attacks that are both effective, ie, lead to fundamental changes in the required therapy, and stealthy, ie, are hard to detect. We focus on the discrimination algorithm underlying Boston Scientific devices (one of the principal ICD manufacturers) and formulate the synthesis problem as one of multi-objective optimization. Our solution technique is based on an Optimization Modulo Theories encoding of the problem and allows us to derive device parameters that are optimal with respect\u00a0\u2026", "num_citations": "4\n", "authors": ["1622"]}
{"title": "Tight continuous-time reachtubes for lagrangian reachability\n", "abstract": " We introduce continuous Lagrangian reachability (CLRT), a new algorithm for the computation of a tight and continuous-time reachtube for the solution flows of a nonlinear, time-variant dynamical system. CLRT employs finite strain theory to determine the deformation of the solution set from time t i  to time t i+1 . We have developed simple explicit analytic formulas for the optimal metric for this deformation; this is superior to prior work, which used semi-definite programming. CLRT also uses infinitesimal strain theory to derive an optimal time increment h i  between t i  and t i+1 , nonlinear optimization to minimally bloat (i.e., using a minimal radius) the state set at time t i  such that it includes all the states of the solution flow in the interval [t i , t i+1 ]. We use \u03b4-satisfiability to ensure the correctness of the bloating. Our results on a series of benchmarks show that CLRT performs favorably compared to state-of-the-art tools\u00a0\u2026", "num_citations": "4\n", "authors": ["1622"]}
{"title": "Symbolic analysis of the neuron action potential\n", "abstract": " We present a novel approach to investigating key behavioral properties of complex biological systems by first using automated techniques to learn a simplified Linear Hybrid Automaton model of the system under investigation, and then carrying out automatic reachability analysis on the resulting model. The specific biological system we consider is the neuronal Action Potential and the specific question of interest is bifurcation: the graded response of the neuron to stimulation of varying amplitude and duration. Reachability analysis in this case is performed using the d/dt analysis tool for hybrid systems. The results we so obtain reveal the precise conditions under which bifurcation manifests, when taking into consideration an infinite class of input stimuli of arbitrary shape, amplitude, and duration within given respective intervals. To the best of our knowledge, this represents the first time that formal (reachability\u00a0\u2026", "num_citations": "4\n", "authors": ["1622"]}
{"title": "Formal analysis of abnormal excitation in cardiac tissue\n", "abstract": " We present the Piecewise Linear Approximation Model of Ion Channel contribution (PLAMIC) to cardiac excitation. We use the PLAMIC model to conduct formal analysis of cardiac arrhythmic events, namely Early Afterdepolarizations (EADs). The goal is to quantify (for the first time) the contribution of the overall sodium (Na\u2009+\u2009), potassium (K\u2009+\u2009) and calcium (Ca2\u2009+\u2009) currents to the occurrence of EADs during the plateau phase of the cardiac action potential (AP). Our analysis yields exact mathematical criteria for the separation of the parameter space for normal and EAD-producing APs, which is validated by simulations with classical AP models based on complex systems of nonlinear differential equations. Our approach offers a simple formal technique for the prediction of conditions leading to arrhythmias (EADs) from a limited set of experimental measurements, and can be invaluable for devising new\u00a0\u2026", "num_citations": "4\n", "authors": ["1622"]}
{"title": "Practical considerations in protocol verification: The e-2c case study\n", "abstract": " We report on our efforts to formally specify and verify a new protocol of the E-2C Hawkeye Early Warning Aircraft. The protocol, which is currently in test at Northrop Grumman, supports communication between a mission computer (MC) and three or more tactical workstations (TWSs), connected by a single-segment LAN. We modeled the protocol in the PROMELA specification language of the SPIN verification tool, and used SPIN to analyze a number of properties of the protocol. Our investigation revealed a race condition that can lead to a disconnect of an MC/TWS connection when there is one lost UDP datagram and significant timing delays. Such delays are virtually impossible under normal E-2C operating conditions, but could be due to noise on the MC/TWS LAN. A simple modification was proposed that avoids the disconnect in many situations. Practical considerations, however, mandated that the protocol be\u00a0\u2026", "num_citations": "4\n", "authors": ["1622"]}
{"title": "Steady, oscillatory, and unsteady subsonic Aerodynamics, production version 1. 1(SOUSSA-P 1. 1). Volume 2: User/programmer manual\n", "abstract": " This work was performed under NASA Contract NASl-14977. The authors of this volume would first like to extend their appreciation to the tecllnical monitor of the contract Dr. E. Carson Yates, Jr. of NASA Langley Research C~ nter, for his many extremely valuable comments and highly welcomed suggestions regarding the content of this manual. The authors are indebted as well to Mr. Robert N. Desmarais, the alternate monitor from NASA Langley Research Center, for his continued programming support and for providing the out-of-core solver. Also, the authors are grateful to Dr. Gary L. Giles and Mr. James C. Robinson, both of NASA Langley Research Center, for providing them with assistance in the use of the portions of the SPAR program that were incorporated into SOUSSA-Po Furthermore, the authors would like to thank Mr. William H. Hoffman for his fundamental role during the initial development of the program. Finally, the authors wish to acknowledge the significant contribution of Ms. Denise M. Dennett, Mr. Robert R. Carella, Ms. Felicita Saiez, Mr. Thomas M. Spura, and Mr. John P. Kantelis in generating and editing this report, as well as the publication services provided by Mrs. Barbara Monleon. i", "num_citations": "4\n", "authors": ["1622"]}
{"title": "Gotube: Scalable stochastic verification of continuous-depth models\n", "abstract": " We introduce a new stochastic verification algorithm that formally quantifies the behavioral robustness of any time-continuous process formulated as a continuous-depth model. The algorithm solves a set of global optimization (Go) problems over a given time horizon to construct a tight enclosure (Tube) of the set of all process executions starting from a ball of initial states. We call our algorithm GoTube. Through its construction, GoTube ensures that the bounding tube is conservative up to a desired probability. GoTube is implemented in JAX and optimized to scale to complex continuous-depth models. Compared to advanced reachability analysis tools for time-continuous neural networks, GoTube provably does not accumulate over-approximation errors between time steps and avoids the infamous wrapping effect inherent in symbolic techniques. We show that GoTube substantially outperforms state-of-the-art verification tools in terms of the size of the initial ball, speed, time-horizon, task completion, and scalability, on a large set of experiments. GoTube is stable and sets the state-of-the-art for its ability to scale up to time horizons well beyond what has been possible before.", "num_citations": "3\n", "authors": ["1622"]}
{"title": "Under the Hood of a Stand-Alone Lagrangian Reachability Tool.\n", "abstract": " Tool presentation: We present work in progress on a stand-alone implementation of Lagrangian reachability, a recently introduced over-approximation technique for nonlinear continuous systems. Unlike the previous prototype, the current implementation does not depend on the over-approximation tool CAPD, and invokes an improved Lohner\u2019s QR method to tame the infamous wrapping effect.", "num_citations": "3\n", "authors": ["1622"]}
{"title": "Automated software engineering using concurrent class machines\n", "abstract": " Concurrent Class Machines are a novel state-machine model that directly captures a variety of object-oriented concepts, including classes and inheritance, objects and object creation, methods, method invocation and exceptions, multithreading and abstract collection types. The model can be understood as a precise definition of UML activity diagrams which, at the same time, offers an executable, object-oriented alternative to event-based statecharts. It can also be understood as a visual, combined control and data flow model for multithreaded object-oriented programs. We first introduce a visual notation and tool for Concurrent Class Machines and discuss their benefits in enhancing system design. We then equip this notation with a precise semantics that allows us to define refinement and modular refinement rules. Finally, we summarize our work on generation of optimized code, implementation and experiments\u00a0\u2026", "num_citations": "3\n", "authors": ["1622"]}
{"title": "VERITAS: Visualization environment research in the applied sciences\n", "abstract": " VERITAS (Visualization Environment Research In The Applied Sciences) involves the design and development of tools for the creation of user environments for scientific computing systems. The initial goal has been to provide a tool-based environment in which a scientist can easily and rapidly construct, with no programming effort, a powerful customized graphical user interface to an existing scientific application. The ultimate goal is to support in a similar interactive, high-level way the development of the entire scientific application system by the scientist, to allow a tighter integration of the application model and the graphical interface. The project involves research and development in visualization and interactive data presentation techniques, knowledge representation and management systems, and high-level specification and programming languages.", "num_citations": "3\n", "authors": ["1622"]}
{"title": "Recent Results in the Static Analysis of Communicating Finite State Processes\n", "abstract": " The Finite State Process (FSP) is a modelling technique for concurrent programs and network protocols stemming from several recent algebraic treatments of concurrency (Mil, Br, BHR, Hol). We examine the FSP in the context of two problems of static analysis:(1) FSP equivalence, and (2) cooperation vs. antagonism in networks of FSPs.Regarding (1), we analyze two equivalence notions from Milner's CCS (Mil), observation equivalence and congruence. We also consider failure equivalence from the (BHR) failure model. We show that observation equivalence () and congruence can be tested in cubic time. Observation equivalence is the limit of a sequence of successively finer equivalence relations, mk, where, is NFA equivalence. We show that, for each fixed k,* is PSPACE-complete. We also provide an O (n log n) test for congruence of n-state processes of bounded fanout by extending Hopcroft's algorithm for minimizing the states of a DFA (Hop).", "num_citations": "3\n", "authors": ["1622"]}
{"title": "Neural predictive monitoring and a comparison of frequentist and Bayesian approaches\n", "abstract": " Neural state classification (NSC) is a recently proposed method for runtime predictive monitoring of hybrid automata (HA) using deep neural networks (DNNs). NSC trains a DNN as an approximate reachability predictor that labels an HA state x as positive if an unsafe state is reachable from x within a given time bound, and labels x as negative otherwise. NSC predictors have very high accuracy, yet are prone to prediction errors that can negatively impact reliability. To overcome this limitation, we present neural predictive monitoring (NPM), a technique that complements NSC predictions with estimates of the predictive uncertainty. These measures yield principled criteria for the rejection of predictions likely to be incorrect, without knowing the true reachability values. We also present an active learning method that significantly reduces the NSC predictor\u2019s error rate and the percentage of rejected predictions. We\u00a0\u2026", "num_citations": "2\n", "authors": ["1622"]}
{"title": "A Distributed Simplex Architecture for Multi-Agent Systems\n", "abstract": " We present Distributed Simplex Architecture (DSA), a new runtime assurance technique that provides safety guarantees for multi-agent systems (MASs). DSA is inspired by the Simplex control architecture of Sha et al., but with some significant differences. The traditional Simplex approach is limited to single-agent systems or a MAS with a centralized control scheme. DSA addresses this limitation by extending the scope of Simplex to include MASs under distributed control. In DSA, each agent has a local instance of traditional Simplex such that the preservation of safety in the local instances implies safety for the entire MAS. We provide a proof of safety for DSA, and present experimental results for several case studies, including flocking with collision avoidance, safe navigation of ground rovers through way-points, and the safe operation of a microgrid.", "num_citations": "2\n", "authors": ["1622"]}
{"title": "Compositional branching-time measurements\n", "abstract": " Formal methods are used to increase the reliability of software and hardware systems. Methods such as model checking, verification and testing are used to search for design and coding errors, integrated in the process of system design. Beyond checking whether a system satisfies a particular specification, we may want to measure some of its quantitative properties. Earlier works on system measurements suggest extending model checking techniques to measure quantitative artifacts, based on weights associated with the transitions of a transition system. Other works allow counting while performing model checking or runtime verification. This paper presents a simple and efficient compositional measuring framework based on quantitative state testers. The framework allows combining multiple measures, such as distance and power consumption, using a variety of functions, such as min, max, and average\u00a0\u2026", "num_citations": "2\n", "authors": ["1622"]}
{"title": "Monte carlo methods for process algebra\n", "abstract": " We review the recently developed technique of Monte Carlo model checking and show how it can be applied to the implementation problem for I/O Automata. We then consider some open problems in applying Monte Carlo techniques to other process-algebraic problems, such as simulation and bisimulation.", "num_citations": "2\n", "authors": ["1622"]}
{"title": "Specification and evaluation of logic-based model checking\n", "abstract": " Tabled resolution for logic programs [TS86, CW96] addresses the major shortcomings of Prolog-style resolution, namely, weak termination, repeated subcomputations, and weak semantics for negation. Techniques used for program analysis and verification, such as model checking and abstract interpretation, can be implemented using tabling by treating the semantic equations as logic rules. For instance, we implemented XMC [RRR+ 97], an efficient model checker for alternation-free modal mu-calculus, by encoding the semantic equations as a logic program, and evaluating the program using the XSB tabled logic programming system [XSB99].", "num_citations": "2\n", "authors": ["1622"]}
{"title": "Turing machines, transition systems\n", "abstract": " This paper presents Persistent Turing Machines (PTMs), a new way of interpreting Turing-machine computation, based on dynamic stream semantics. A PTM is a Turing machine that performs an infinite sequence of\" normal\" Turing machine computations, where each such computation starts when the PTM reads an input from its input tape and ends when the PTM produces an output on its output tape. The PTM has an additional worktape, which retains its content from one computation to the next; this is what we mean by persistence. A number of results are presented for this model, including a proof that the class of PTMs is isomorphic to a general class of effective transition systems called interactive transition systems; and a proof that PTMs without persistence (amnesic PTMs) are less expressive than PTMs. As an analogue of the Church-Turing hypothesis which relates Turing machines to algorithmic computation\u00a0\u2026", "num_citations": "2\n", "authors": ["1622"]}
{"title": "Digital signatures with encryption: Fact and fiction\n", "abstract": " We analyze a security protocol that combines digital signatures with data encryption. The analysis technique we utilize is temporal logic model checking as provided by the Concurrency Factory speci cation and veri cation toolset CLSS96]. We show that the protocol is secure, providing privacy and proof of authorship. We demonstrate, however, that a version of the protocol in which con rmation messages are used is susceptible to an attack. This is the case even if the encryption and signature operations are di erent, contrary to what is claimed in Sch94]. Finally, we show how the protocol with con rmation messages can be xed by including the identity of the sender in messages transmitted by the protocol.", "num_citations": "2\n", "authors": ["1622"]}
{"title": "Visualization tools for the applied sciences\n", "abstract": " Visualization tools for the applied sciences | Proceedings of the third international conference on human-computer interaction, Vol.1 on Work with computers: organizational, management, stress and health aspects ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleProceedingsProceedings of the third international conference on human-computer interaction, Vol.on Work with computers: organizational, management, stress and health aspectsVisualization tools for the applied sciences Article Visualization tools for the applied sciences Share on Authors: Alessandro Giacalone View Profile , Arie Kaufman View Profile , Scott A. Smolka View \u2026", "num_citations": "2\n", "authors": ["1622"]}
{"title": "Distributed algorithms for tree pattern matching\n", "abstract": " We present efficient distributed algorithms for the Tree Pattern Matching problem. To the best of our knowledge, these are the first distributed algorithms of this nature. Tree pattern matching is a fundamental operation in many programming task such as code optimization and automated theorem proving, and has a number of applications in distributed systems. We present both a top-down and bottom-up algorithm for linear tree pattern matching (where any variable occurs at most once in the pattern) for the case in which the subject tree is completely distributed as a node per processor. The pattern is assumed to reside within the local memory of each processor. Let the subject tree have n nodes and height h                  s               , and the pattern m nodes and height h                  p               . The top-down algorithm has bit complexity O(n log m h                  p               ) and time complexity O(h                  s\u00a0\u2026", "num_citations": "2\n", "authors": ["1622"]}
{"title": "Bayesian Neural Predictive Monitoring.\n", "abstract": " Neural State Classification (NSC) is a recently proposed method for runtime predictive monitoring of Hybrid Automata (HA) using deep neural networks (DNNs). NSC predictors have very high accuracy, yet are prone to prediction errors that can negatively impact reliability. To overcome this limitation, we present Neural Predictive Monitoring (NPM), a technique that complements NSC predictions with estimates of the predictive uncertainty. These measures yield principled criteria for the rejection of predictions likely to be incorrect, without knowing the true reachability values. We also present an active learning method that significantly reduces the NSC predictor\u2019s error rate and the percentage of rejected predictions. NPM is based on the use of Bayesian techniques, Bayesian Neural Networks and Gaussian Processes, to learn respectively the predictor and the rejection rule. Our approach is highly efficient, with computation times on the order of milliseconds, and effective, managing in our experimental evaluation to successfully reject almost all incorrect predictions.", "num_citations": "1\n", "authors": ["1622"]}
{"title": "Neural state classification for hybrid systems\n", "abstract": " Model checking of hybrid systems is usually expressed in terms of the following reachability problem for hybrid automata (HA)[6]: given an HA M, a set of initial states I, and a set of unsafe states U, determine whether there exists a trajectory of M starting in an initial state and ending in an unsafe state. The time-bounded version of this problem considers trajectories that are within a given time bound T.", "num_citations": "1\n", "authors": ["1622"]}
{"title": "A simplex architecture for hybrid systems using barrier certificates\n", "abstract": " This paper shows how to use Barrier Certificates (BaCs) to design Simplex Architectures for hybrid systems. The Simplex architecture entails switching control of a plant over to a provably safe Baseline Controller when a safety violation is imminent under the control of an unverified Advanced Controller. A key step of determining the switching condition is identifying a recoverable region, where the Baseline Controller guarantees recovery and keeps the plant invariably safe. BaCs, which are Lyapunov-like proofs of safety, are used to identify a recoverable region. At each time step, the switching logic samples the state of the plant and uses bounded-time reachability analysis to conservatively check whether any states outside the zero-level set of the BaCs, which therefore might be non-recoverable, are reachable in one decision period under control of the Advanced Controller. If so, failover is initiated\u00a0\u2026", "num_citations": "1\n", "authors": ["1622"]}
{"title": "Model predictive control for memory profiling\n", "abstract": " We make two contributions in the area of memory profiling. The first is a real-time, memory-profiling toolkit we call Memcov that provides both allocation/deallocation and access profiles of a running program. Memcov requires no recompilation or relinking and significantly reduces the barrier to entry for new applications of memory profiling by providing a clean, non-invasive way to perform two major functions: processing of the stream of memory-allocation events in real time and monitoring of regions in order to receive notification the next time they are hit. Our second contribution is an adaptive memory profiler and leak detector called Memcov MPC . Built on top of Memcov, Memcov MPC  uses model predictive control to derive an optimal control strategy for leak detection that maximizes the number of areas monitored for leaks, while minimizing the associated runtime overhead. When it observes that an area has not\u00a0\u2026", "num_citations": "1\n", "authors": ["1622"]}
{"title": "Getting to the root of the problem: Focus statements for the analysis of counter-examples\n", "abstract": " We present a methodology and corresponding implementation that, given a program and a correctness assertion violated by the program, identifies a set of focus statements that captures in the most succinct manner possible the cause of the violation. Our method, which is based on program dependency analysis, also automatically identifies feasible counter-examples and presents the user with sets of constraints over program variables necessary for their feasibility. We illustrate the practical utility of our approach via its successful application to the Resolution Advisory module of the Traffic Collision Avoidance system (TCAS).", "num_citations": "1\n", "authors": ["1622"]}
{"title": "Evidence exploration for model checking\n", "abstract": " It is widely believed that formal verification can play an essential role in the design and development of highconfidence computer-based systems. While a number of powerful formal verification techniques exist, their acceptance in the industrial sector has been limited in part by a perceived lack of usability. Research related to improving usability has targeted various stages of formal verification, including writing more understandable and less error-prone specifications, visualizing system dynamics via graphical languages such as statecharts and message sequence charts, shortening verification time (efficiency is a usability issue too), and generating meaningful error diagnostics.In this paper, we are interested in the latter stages of model checking: manipulating and interpreting the output of a model checker, in particular its proof structure. Model checking [4, 7] can be viewed as the problem of proving or disproving that a system M satisfies a property \u03c6 specified in some kind of temporal logic. For a decidable modelchecking problem, there exists a proof or disproof of the goal M|= \u03c6. A proof in this setting consists of a set of subgoals, including the main goal, and their interrelationships via inference rules. This notion of proof also covers disproofs since a disproof of M|= \u03c6 is a proof of M|=\u00ac \u03c6 if the logic is closed under negation. We refer to such a proof structure as the model checker\u2019s evidence [8, 9].", "num_citations": "1\n", "authors": ["1622"]}
{"title": "Polynomial-time analysis for a class of communicating processes\n", "abstract": " \"Can a process terminate prematurely?\" is a computationally difficult question to answer for finite-state communicating processes. We present an algorithm for this problem that runs in polynomial (quadratic) time for a significant class of communicating processes. The underlying model is algebraic and represents a restriction of Milner's CCS to finite-state systems with one-to-one communication.             In order to answer the question of premature termination for process P                  i               , we express the problem as a two-player game, P                  i                versus the rest of the network. We then show that this problem can be restated in terms of the network's [HBR] failure. This leads to an algorithm based on an efficient procedure for computing the failures of a network. An on-board comparator and a rebound sorter are used as illustrative examples.", "num_citations": "1\n", "authors": ["1622"]}
{"title": "Nonpotential Aerodynamics for Windmills in Shear-Winds\n", "abstract": " The important but complex problem of predicting the aero-dynamic loading on windmill rotors may be transformed, by the Bernoulli Theorem, to one of predicting the velocity flow field around the rotor. Prediction of the velocity flow field, how-ever is difficult due to the fact that presence of vorticity in the unperturbed flow (tower-shadow and/or shear-flow due to the atmospheric boundary-layer) and in the rotor boundary-layer cannot be disregarded. Both types of vorticity are considered here. It may be noted that the classical boundary-layer ap-proach is to divide the flow into an inner flow (boundary-layer) and an outer flow (inviscid potential flow) and\" matching\" the two solutions; on the other hand, for the wind-shear vorticity, only physical-variable formulations have been available thus far. A new general approach (which is based upon the classical results of dividing the velocity flow field into an irrotational part and a rotational solenoidal part, and capable of studying both types of vorticity flow problems) was introduced in Ref. 1 and is used here. For computational efficacy, however, this general approach is simplified by introducing the frozen-vorticity hypothesis for the case of the incoming (tower-shadow and/or wind-shear) vorticity, whereas for the rotor boundary layer, the spanwise variations are neglected, thereby reducing the formulation to its two-dimensional equivalent.", "num_citations": "1\n", "authors": ["1622"]}
{"title": "RECENT DEVELOPMENTS IN THE GREEN'S FUNCTION METHOD FOR AERODYNAMICS.\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "1\n", "authors": ["1622"]}
{"title": "Fully Local and E cient Evaluation of Alternating Fixed Points?\n", "abstract": " We introduce Partitioned Dependency Graphs (PDGs), an abstract framework for the speci cation and evaluation of arbitrarily nested alternating xed points. The generality of PDGs subsumes that of similarly proposed models of nested xed-point computation such as Boolean graphs, Boolean equation systems, and the propositional modal mu-calculus. Our main result is an e cient local algorithm for evaluating PDG xed points. Our algorithm, which we call LAFP, combines the simplicity of previously proposed induction-based algorithms (such as Winskel's tableau method for-calculus model checking) with the e ciency of semantics-based algorithms (such as the bit-vector method of Cleaveland, Klein, and Ste en for the equational-calculus). In particular, LAFP is simply speci ed, we provide a completely rigorous proof of its correctness, and the number of xed-point iterations required by the algorithm is asymptotically the same as that of the best existing global algorithms. Moreover, preliminary experimental results demonstrate that LAFP performs extremely well in practice. To our knowledge, this makes LAFP the rst e cient local algorithm for computing xed points of arbitrary alternation depth to appear in the literature.", "num_citations": "1\n", "authors": ["1622"]}