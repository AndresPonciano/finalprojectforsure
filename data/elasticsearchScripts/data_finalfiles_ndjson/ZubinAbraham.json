{"title": "Concept drift detection for streaming data\n", "abstract": " Common statistical prediction models often require and assume stationarity in the data. However, in many practical applications, changes in the relationship of the response and predictor variables are regularly observed over time, resulting in the deterioration of the predictive performance of these models. This paper presents Linear Four Rates (LFR), a framework for detecting these concept drifts and subsequently identifying the data points that belong to the new concept (for relearning the model). Unlike conventional concept drift detection approaches, LFR can be applied to both batch and stream data; is not limited by the distribution properties of the response variable (e.g., datasets with imbalanced labels); is independent of the underlying statistical-model; and uses user-specified parameters that are intuitively comprehensible. The performance of LFR is compared to benchmark approaches using both simulated\u00a0\u2026", "num_citations": "83\n", "authors": ["1089"]}
{"title": "Climate Scenario Development and Applications for Local/Regional Climate Change Impact Assessments: An Overview for the Non\u2010Climate Scientist: Part II: Considerations When\u00a0\u2026\n", "abstract": " Although downscaling methods for deriving local/regional climate change scenarios have been extensively studied, little guidance exists on how to use the downscaled scenarios in applications such as impact assessments. In this second part of a two\u2010part communication, we review for non\u2010climate scientists a number of practical considerations when utilizing climate change scenarios. The issues discussed are drawn from questions frequently asked by our colleagues on assessment teams and include sources of observational data for scenario evaluation, the advantages of scenario ensembles, adjusting for scenario biases, and the availability of archived downscaled scenarios. Together with Part I, which reviews various downscaling methods, Part II is intended to improve the communication between suppliers and users of local/regional climate change scenarios, with the overall goal of improving the utility of\u00a0\u2026", "num_citations": "63\n", "authors": ["1089"]}
{"title": "Securing sensor nodes against side channel attacks\n", "abstract": " Side channel attacks are non-invasive attacks in which adversaries gain confidential information by passively observing the target computing device. Sensor nodes are particularly vulnerable to side channel attacks due to the lack of protective physical shielding and their deployment in open environments. As sensor nodes are increasingly being deployed in safety critical applications such as power grid, volcano monitoring, and even military applications, protecting sensor nodes from side channel attacks is critical. However, side channel attacks on sensor nodes have not been investigated in previous work. In this paper, we present a taxonomy of side channel attacks on sensor nodes. For each type of the attacks, we provide guidelines and approaches to thwart the attack. We also propose a new technique, called process obfuscation, which can be used as a countermeasure for a variety of side channel attacks on\u00a0\u2026", "num_citations": "36\n", "authors": ["1089"]}
{"title": "Concept drift detection with hierarchical hypothesis testing\n", "abstract": " When using statistical models (such as a classifier) in a streaming environment, there is often a need to detect and adapt to concept drifts to mitigate any deterioration in the model's predictive performance over time. Unfortunately, the ability of popular concept drift approaches in detecting these drifts in the relationship of the response and predictor variable is often dependent on the distribution characteristics of the data streams, as well as its sensitivity on parameter tuning. This paper presents Hierarchical Linear Four Rates (HLFR), a framework that detects concept drifts for different data stream distributions (including imbalanced data) by leveraging a hierarchical set of hypothesis tests in an online setting. The performance of HLFR is compared to benchmark approaches using both simulated and real-world datasets spanning the breadth of concept drift types. HLFR significantly outperforms benchmark approaches\u00a0\u2026", "num_citations": "29\n", "authors": ["1089"]}
{"title": "An integrated framework for simultaneous classification and regression of time-series data\n", "abstract": " Zero-inflated time series data are commonly encountered in many applications, including climate and ecological modeling, disease monitoring, manufacturing defect detection, and traffic monitoring. Such data often leads to poor model fitting using standard regression methods because they tend to underestimate the frequency of zeros and the magnitude of non-zero values. This paper presents an integrated framework that simultaneously performs classification and regression to accurately predict future values of a zero-inflated time series. A regression model is initially applied to predict the value of the time series. The regression output is then fed into a classification model to determine whether the predicted value should be adjusted to zero. Our regression and classification models are trained to optimize a joint objective function that considers both classification errors on the time series and regression errors on\u00a0\u2026", "num_citations": "27\n", "authors": ["1089"]}
{"title": "Concept drift detection and adaptation with hierarchical hypothesis testing\n", "abstract": " A fundamental issue for statistical classification models in a streaming environment is that the joint distribution between predictor and response variables changes over time (a phenomenon also known as concept drifts), such that their classification performance deteriorates dramatically. In this paper, we first present a hierarchical hypothesis testing (HHT) framework that can detect and also adapt to various concept drift types (e.g., recurrent or irregular, gradual or abrupt), even in the presence of imbalanced data labels. A novel concept drift detector, namely Hierarchical Linear Four Rates (HLFR), is implemented under the HHT framework thereafter. By substituting a widely-acknowledged retraining scheme with an adaptive training strategy, we further demonstrate that the concept drift adaptation capability of HLFR can be significantly boosted. The theoretical analysis on the Type-I and Type-II errors of HLFR is also\u00a0\u2026", "num_citations": "23\n", "authors": ["1089"]}
{"title": "Request-and-reverify: Hierarchical hypothesis testing for concept drift detection with expensive labels\n", "abstract": " One important assumption underlying common classification models is the stationarity of the data. However, in real-world streaming applications, the data concept indicated by the joint distribution of feature and label is not stationary but drifting over time. Concept drift detection aims to detect such drifts and adapt the model so as to mitigate any deterioration in the model's predictive performance. Unfortunately, most existing concept drift detection methods rely on a strong and over-optimistic condition that the true labels are available immediately for all already classified instances. In this paper, a novel Hierarchical Hypothesis Testing framework with Request-and-Reverify strategy is developed to detect concept drifts by requesting labels only when necessary. Two methods, namely Hierarchical Hypothesis Testing with Classification Uncertainty (HHT-CU) and Hierarchical Hypothesis Testing with Attribute-wise \"Goodness-of-fit\" (HHT-AG), are proposed respectively under the novel framework. In experiments with benchmark datasets, our methods demonstrate overwhelming advantages over state-of-the-art unsupervised drift detectors. More importantly, our methods even outperform DDM (the widely used supervised drift detector) when we use significantly fewer labels.", "num_citations": "20\n", "authors": ["1089"]}
{"title": "Position preserving multi-output prediction\n", "abstract": " There is a growing demand for multiple output prediction methods capable of both minimizing residual errors and capturing the joint distribution of the response variables in a realistic and consistent fashion. Unfortunately, current methods are designed to optimize one of the two criteria, but not both. This paper presents a framework for multiple output regression that preserves the relationships among the response variables (including possible non-linear associations) while minimizing the residual errors of prediction by coupling regression methods with geometric quantile mapping. We demonstrate the effectiveness of the framework in modeling daily temperature and precipitation for climate stations in the Great Lakes region. We showed that, in all climate stations evaluated, the proposed framework achieves low residual errors comparable to standard regression methods while preserving the joint\u00a0\u2026", "num_citations": "16\n", "authors": ["1089"]}
{"title": "Distribution regularized regression framework for climate modeling\n", "abstract": " Regression-based approaches are widely used in climate modeling to capture the relationship between a climate variable of interest and a set of predictor variables. These approaches are often designed to minimize the overall prediction errors. However, some climate modeling applications emphasize more on fitting the distribution properties of the observed data. For example, histogram equalization techniques such as quantile mapping have been successfully used to debias outputs from computer-simulated climate models to obtain more realistic projections of future climate scenarios. In this paper, we show the limitations of current regression-based approaches in terms of preserving the distribution of observed climate data and present a multi-objective regression framework that simultaneously fits the distribution properties and minimizes the prediction error. The framework is highly flexible and can be applied\u00a0\u2026", "num_citations": "12\n", "authors": ["1089"]}
{"title": "Advances in Knowledge Discovery and Data Mining, Part II: 14th Pacific-Asia Conference, PAKDD 2010, Hyderabad, India, June 21-24, 2010, Proceedings\n", "abstract": " The14thPaci? c-AsiaConferenceonKnowledgeDiscoveryandData Mining was held in Hyderabad, India during June 21\u201324, 2010; this was the? rst time the conference was held in India. PAKDDisamajorinternationalconferenceintheareasofdatamining (DM) and knowledge discovery in databases (KDD). It provides an international-rum for researchers and industry practitioners to share their new ideas, original research results and practical development experiences from all KDD-related areas including data mining, data warehousing, machine learning, databases, statistics, knowledge acquisition and automatic scienti? c discovery, data visu-ization, causal induction and knowledge-based systems. PAKDD-2010 received 412 research papers from over 34 countries incl-ing: Australia, Austria, Belgium, Canada, China, Cuba, Egypt, Finland, France, Germany, Greece, Hong Kong, India, Iran, Italy, Japan, S. Korea, Malaysia, Mexico, TheNetherlands, NewCaledonia, NewZealand, SanMarino, Singapore, Slovenia, Spain, Switzerland, Taiwan, Thailand, Tunisia, Turkey, UK, USA, and Vietnam. This clearly re? ects the truly international stature of the PAKDD conference. AfteraninitialscreeningofthepapersbytheProgramCommitteeChairs, for papers that did not conform to the submission guidelines or that were deemed not worthy of further reviews, 60 papers were rejected with a brief expla-tion for the decision. The remaining 352 papers were rigorously reviewed by at least three reviewers. The initial results were discussed among the reviewers and? nally judged by the Program Committee Chairs. In some cases of c-? ict additional reviews were sought\u00a0\u2026", "num_citations": "10\n", "authors": ["1089"]}
{"title": "A semi-supervised framework for simultaneous classification and regression of zero-inflated time series data with application to precipitation prediction\n", "abstract": " Time series data with abundant number of zeros are common in many applications, including climate and ecological modeling, disease monitoring, manufacturing defect detection, and traffic accident monitoring. Classical regression models are inappropriate to handle data with such skewed distribution because they tend to underestimate the frequency of zeros and the magnitude of non-zero values in the data. This paper presents a hybrid framework that simultaneously perform classification and regression to accurately predict future values of a zero-inflated time series. A classifier is initially used to determine whether the value at a given time step is zero while a regression model is invoked to estimate its magnitude only if the predicted value has been classified as nonzero. The proposed framework is extended to a semi-supervised learning setting via graph regularization. The effectiveness of the framework is\u00a0\u2026", "num_citations": "9\n", "authors": ["1089"]}
{"title": "Smoothed quantile regression for statistical downscaling of extreme events in climate modeling\n", "abstract": " Statistical downscaling is commonly used in climate modeling to obtain high-resolution spatial projections of future climate scenarios from the coarse-resolution outputs projected by global climate models. Unfortunately, most of the statistical downscaling approaches using standard regression methods tend to emphasize projecting the conditional mean of the data while paying scant attention to the extreme values that are rare in occurrence yet critical for climate impact assessment and adaptation studies. This paper presents a statistical downscaling framework that focuses on the accurate projection of future extreme values by estimating directly the conditional quantiles of the response variable. We also extend the proposed framework to a semi-supervised learning setting and demonstrate its efficacy in terms of inferring the magnitude, frequency, and timing of climate extreme events. The proposed approach outperformed baseline statistical downscaling approaches in 85% of the 37 stations evaluated, in terms of the accuracy of the magnitude projected for extreme data points.", "num_citations": "6\n", "authors": ["1089"]}
{"title": "Distribution preserving multi-task regression for spatio-temporal data\n", "abstract": " For many spatio-temporal applications, building regression models that can reproduce the true data distribution is often as important as building models with high prediction accuracy. For example, knowing the future distribution of daily temperature and precipitation can help scientists determine their long-term trends and assess their potential impact on human and natural systems. As conventional methods are designed to minimize residual errors, the shape of their predicted distribution may not be consistent with their actual distribution. To overcome this challenge, this paper presents a novel, distribution-preserving multi-task learning framework for multi-location prediction of spatio-temporal data. The framework employs a non-parametric density estimation approach with L2-distance to measure the divergence between the predicted and true distribution of the data. Experimental results using climate data from\u00a0\u2026", "num_citations": "4\n", "authors": ["1089"]}
{"title": "Empirical comparison of active learning strategies for handling temporal drift\n", "abstract": " Active learning strategies often assume that the target concept will remain stationary over time. However, in many real world systems, it is not uncommon for the target concept and distribution properties of the generated data to change over time. This paper presents an empirical study that evaluates the effectiveness of using active learning strategies to train statistical models in the presence of various temporaldrift scenarios. The study also evaluates the benefit of incorporating popular approaches to address temporal drift on the various active learning strategies. The performance of the best performing active learning strategies, were found to be at least comparable, if not significantly better than random sampling strategy across the various types of temporal drifts in 99% of the scenarios tested. In approximately 50% of those instances, active learning strategies were significantly better than random sampling. However, the further away the temporal drift, less is the advantage of using active learning strategies over random sampling. It is shown that uncertainty-based sampling often had the best performance among the various active learning strategies.", "num_citations": "4\n", "authors": ["1089"]}
{"title": "Multi-task learning and its application to geospatio-temporal data\n", "abstract": " Multi-task learning (MTL) is a data mining and machine learning approach for modeling multiple prediction tasks simultaneously by exploiting the relatedness among the tasks. MTL has been successfully applied to various domains, including computer vision, healthcare, genomics, recommender systems, and natural language processing. The goals of this thesis are:(1) to investigate the feasibility of applying MTL to geospatio-temporal prediction problems, particularly those encountered in the climate and environmental science domains and (2) to develop novel MTL frameworks that address the challenges of building effective predictive models from geospatio-temporal data.", "num_citations": "3\n", "authors": ["1089"]}
{"title": "Contour regression: A distribution\u2010regularized regression framework for climate modeling\n", "abstract": " Regression methods are commonly used to learn the mapping from a set of predictor variables to a continuous\u2010valued target variable such that their prediction errors are minimized. However, minimizing the errors alone may not be sufficient for some applications, such as climate modeling, which require the overall predicted distribution to resemble the actual observed distribution. On the other hand, histogram equalization methods, such as quantile mapping, are often used in climate modeling to alter the distribution of input data to fit the distribution of observed data, but they provide no guarantee of accurate predictions. This paper presents a flexible regression framework known as contour regression that simultaneously minimizes the prediction error and removes biases in the predicted distribution. The framework is applicable to linear, nonlinear, and conditional quantile models and can utilize data from\u00a0\u2026", "num_citations": "1\n", "authors": ["1089"]}
{"title": "Multi-Objective Regression With Application To The Climate Domain\n", "abstract": " This chapter presents a multi-objective approach for predicting future values of a time series data that are inherently zero-inflated. The proposed framework decouples the prediction task into two objectives\u2014a classification step to predict whether the value of the time series is zero and a regression step to estimate the magnitude of the non-zero time series value.", "num_citations": "1\n", "authors": ["1089"]}
{"title": "Saturation distribution prediction method for the spilled hydrocarbon in soil\n", "abstract": " During the production, transport, storage and use of hydrocarbons, there is a possibility of harmful impacts on the environment and human health. Considering the magnitude of the pollution problem it is necessary to understand a saturation distribution of the pollutants (oil) in the soil subsurface, among the other pollution data. The model presented in this paper is solely related to the saturation distribution of the hydrocarbon pollutants. In order to carry out a timely assessment of the pollution parameters for the selection of the most appropriate remediation approach, there is a need for a simple prediction model. This paper gives an overview of a mathemacical model which is easy to use for environmental practice and requires small amounts of data for the calculation of the saturation d", "num_citations": "1\n", "authors": ["1089"]}