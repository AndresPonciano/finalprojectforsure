{"title": "Privacy practices of Internet users: Self-reports versus observed behavior\n", "abstract": " Several recent surveys conclude that people are concerned about privacy and consider it to be an important factor in their online decision making. This paper reports on a study in which (1) user concerns were analysed more deeply and (2) what users said was contrasted with what they did in an experimental e-commerce scenario. Eleven independent variables were shown to affect the online behavior of at least some groups of users. Most significant were trust marks present on web pages and the existence of a privacy policy, though users seldom consulted the policy when one existed. We also find that many users have inaccurate perceptions of their own knowledge about privacy technology and vulnerabilities, and that important user groups, like those similar to the Westin \u201cprivacy fundamentalists\u201d, do not appear to form a cohesive group for privacy-related decision making.In this study we adopt an experimental\u00a0\u2026", "num_citations": "507\n", "authors": ["852"]}
{"title": "Privacy policies as decision-making tools: an evaluation of online privacy notices\n", "abstract": " Studies have repeatedly shown that users are increasingly concerned about their privacy when they go online. In response to both public interest and regulatory pressures, privacy policies have become almost ubiquitous. An estimated 77% of websites now post a privacy policy. These policies differ greatly from site to site, and often address issues that are different from those that users care about. They are in most cases the users' only source of information. This paper evaluates the usability of online privacy policies, as well as the practice of posting them. We analyze 64 current privacy policies, their accessibility, writing, content and evolution over time. We examine how well these policies meet user needs and how they can be improved. We determine that significant changes need to be made to current practice to meet regulatory and usability requirements.", "num_citations": "487\n", "authors": ["852"]}
{"title": "Code coverage for suite evaluation by developers\n", "abstract": " One of the key challenges of developers testing code is determining a test suite's quality--its ability to find faults. The most common approach is to use code coverage as a measure for test suite quality, and diminishing returns in coverage or high absolute coverage as a stopping rule. In testing research, suite quality is often evaluated by a suite's ability to kill mutants (artificially seeded potential faults). Determining which criteria best predict mutation kills is critical to practical estimation of test suite quality. Previous work has only used small sets of programs, and usually compares multiple suites for a single program. Practitioners, however, seldom compare suites---they evaluate one suite. Using suites (both manual and automatically generated) from a large set of real-world open-source projects shows that evaluation results differ from those for suite-comparison: statement (not block, branch, or path) coverage predicts\u00a0\u2026", "num_citations": "153\n", "authors": ["852"]}
{"title": "Joining free/open source software communities: An analysis of newbies' first interactions on project mailing lists\n", "abstract": " Free/Open source software (FOSS) is an important part of the IT ecosystem. Due to the voluntary nature of participation, continual recruitment is key to the growth and sustainability of these communities. It is therefore important to understand how and why potential contributors fail in the process of transitioning from user to contributor. Most newcomers, or \"newbies\", have their first interaction with a community through a mailing list. To understand how this first contact influences future interactions, we studied eight mailing lists across four FOSS projects: MediaWiki, GIMP, PostgreSQL, and Subversion. We analyzed discussions initiated by newbies to determine the effect of gender, nationality, politeness, helpfulness and timeliness of response. We found that nearly 80% of newbie posts received replies, and that receiving timely responses, especially within 48 hours, was positively correlated with future participation. We\u00a0\u2026", "num_citations": "89\n", "authors": ["852"]}
{"title": "Mutations: How close are they to real faults?\n", "abstract": " Mutation analysis is often used to compare the effectiveness of different test suites or testing techniques. One of the main assumptions underlying this technique is the Competent Programmer Hypothesis, which proposes that programs are very close to a correct version, or that the difference between current and correct code for each fault is very small. Researchers have assumed on the basis of the Competent Programmer Hypothesis that the faults produced by mutation analysis are similar to real faults. While there exists some evidence that supports this assumption, these studies are based on analysis of a limited and potentially non-representative set of programs and are hence not conclusive. In this paper, we separately investigate the characteristics of bug-fixes and other changes in a very large set of randomly selected projects using four different programming languages. Our analysis suggests that a typical\u00a0\u2026", "num_citations": "83\n", "authors": ["852"]}
{"title": "The life and times of files and information: a study of desktop provenance\n", "abstract": " In the field of Human-Computer Interaction, provenance refers to the history and genealogy of a document or file. Provenance helps us to understand the evolution and relationships of files; how and when different versions of a document were created, or how different documents in a collection build on each other through copy-paste events. Though methods for tracking provenance and the subsequent use of this meta-data have been proposed and developed into tools, there have been no studies documenting the types and frequency of provenance events in typical computer use. This is knowledge essential for the design of efficient query methods and information displays. We conducted a longitudinal study of knowledge workers at Intel Corporation tracking provenance events in their computer use. We also interviewed knowledge workers to determine the effectiveness of provenance cues for document recall\u00a0\u2026", "num_citations": "79\n", "authors": ["852"]}
{"title": "Participatory design with older adults: an analysis of creativity in the design of mobile healthcare applications\n", "abstract": " Researchers often use participatory design--involving endusers in technology ideation--as this is found to lead to more useful and relevant products. Researchers have sought to involve older adults in the design of emerging technologies like smartphones, with which older adults often have little experience. Therefore, their effectiveness as co-designers could be questioned. We examine whether older adults can create novel design ideas, and whether critiquing existing applications prior to ideation helps or hinders creativity. Panelists from industry and academia evaluated design ideas generated by focus groups of older adults. Out of five groups, the most creative design idea came from one with no smartphone experience or critique exposure. We found that while only some designs scored high on the novelty dimension of creativity, participants were enthusiastic about participating and adapted quickly. We found\u00a0\u2026", "num_citations": "74\n", "authors": ["852"]}
{"title": "Beyond pretty pictures: Examining the benefits of code visualization for open source newcomers\n", "abstract": " Joining an Open Source project is not easy. Newcomers often experience a steep learning curve dealing with technical complexity, lack of domain knowledge, and the amount of project information available for starters. This paper looks at the information needs of newcomers and the potential benefits of information visualization in supporting newcomers through a controlled experiment. Our results show that current OSS environments and development tools are lacking in support for the information needs of newcomers, and that existing visualization tools and techniques can help. We also discuss the potential problems and pitfalls associated with the inappropriate use of code visualization tools.", "num_citations": "65\n", "authors": ["852"]}
{"title": "What health topics older adults want to track: a participatory design study\n", "abstract": " Older adults are increasingly savvy consumers of smartphone-based health solutions and information. These technologies may enable older adults to age-in-place more successfully. However, many app creators fail to do needs assessments of their end-users. To rectify this issue, we involved older adults (aged 65+) in the beginning stages of designing a mobile health and wellness application. We conducted a participatory design study, where 5 groups of older adults created 5 designs. Four groups identified at least 1 health metric not currently offered in either the iPhone app store or the Google Play store. At the end of the sessions we administered a questionnaire to determine what health topics participants would like to track via smartphone or tablet. The designs included 13 health topics that were not on the questionnaire. Seventeen of eighteen participants expressed interest in tracking health metrics using a\u00a0\u2026", "num_citations": "53\n", "authors": ["852"]}
{"title": "On the limits of mutation reduction strategies\n", "abstract": " Although mutation analysis is considered the best way to evaluate the effectiveness of a test suite, hefty computational cost often limits its use. To address this problem, various mutation reduction strategies have been proposed, all seeking to reduce the number of mutants while maintaining the representativeness of an exhaustive mutation analysis. While research has focused on the reduction achieved, the effectiveness of these strategies in selecting representative mutants, and the limits in doing so have not been investigated, either theoretically or empirically.", "num_citations": "45\n", "authors": ["852"]}
{"title": "Uneven achievement in a constructionist learning environment\n", "abstract": " Noting the heavy gender bias with previous programming experience, we examined whether programming achievement on MOOSE Crossing is directly related to gender (Table 2). While the boys had a higher mean programming score (1.63 boys, 1.04 girls) and a higher median score (1 boys, 0 girls), the curves for both boys and girls have the same approximate shape as the composite (Figure 4) The slightly higher performance of the boys may be explained by their prior programming experience and slightly higher time on task, but these differences are not significant. Our data indicates that gender does not affect the kids' level of achievement or involvement (p> 0.05 (Mann-Whitney Test for programming scores and non-pooled T-Test for involvement)).ABSTRACT", "num_citations": "41\n", "authors": ["852"]}
{"title": "Tracking website data-collection and privacy practices with the iWatch web crawler\n", "abstract": " In this paper we introduce the iWatch web crawler, a tool designed to catalogue and analyze online data practices and the use of privacy related indicators and technologies. Our goal in developing iWatch was to make possible a new type of analysis of trends, the impact of legislation on practices, and geographic and social differences online. In this paper we present preliminary findings from two sets of data collected 15 months apart and analyzed with this tool. Our combined samples included more than 240,000 pages from over 24,000 domains and 47 different countries. In addition to providing useful and needed data on the state of online data practices, we show that iWatch is a promising approach to the study of the web ecosystem.", "num_citations": "41\n", "authors": ["852"]}
{"title": "STRAP: a structured analysis framework for privacy\n", "abstract": " Privacy is an important concern for users, and a difficult design challenge. Different user populations have different requirements and expectations when it comes to privacy; thus finding universally acceptable solutions is far from trivial. Design guidelines have been available for a number of years, but often fail to address the dynamic and impromptu nature of privacy management. These methods also fail to provide a robust and replicable procedure for identifying potential problems, leaving the design process more in the realm of art than science. We identify general requirements for privacy-aware design and review how existing methods and guidelines meet these requirements. We then introduce a light-weight method adapted from the requirements engineering literature for the structured analysis of privacy vulnerabilities in design and the iterative adaptation of preferences. We present a study of this method on a predictive group calendar system.", "num_citations": "40\n", "authors": ["852"]}
{"title": "Can testedness be effectively measured?\n", "abstract": " Among the major questions that a practicing tester faces are deciding where to focus additional testing effort, and deciding when to stop testing. Test the least-tested code, and stop when all code is well-tested, is a reasonable answer. Many measures of\" testedness\" have been proposed; unfortunately, we do not know whether these are truly effective. In this paper we propose a novel evaluation of two of the most important and widely-used measures of test suite quality. The first measure is statement coverage, the simplest and best-known code coverage measure. The second measure is mutation score, a supposedly more powerful, though expensive, measure.", "num_citations": "38\n", "authors": ["852"]}
{"title": "Gender differences in early free and open source software joining process\n", "abstract": " With the growth of free and open source software (FOSS) and the adoption of FOSS solutions in business and everyday life, it is important that projects serve their growingly diverse user base. The sustainability of FOSS projects relies on a constant influx of new contributors. Several large demographic surveys found that FOSS communities are very homogenous, dominated by young men, similar to the bias existing in the rest of the IT workforce. Building on previous research, we examine mailing list subscriptions and posting statistics of female FOSS participants. New participants often experience their first interaction on a FOSS project\u2019s mailing list. We explored six FOSS projects \u2013 Buildroot, Busybox, Jaws, Parrot, uClibc, and Yum. We found a declining rate of female participation from the 8.27% of subscribers, to 6.63% of posters, and finally the often reported code contributor rate of 1.5%. We found a\u00a0\u2026", "num_citations": "36\n", "authors": ["852"]}
{"title": "Mutation reduction strategies considered harmful\n", "abstract": " Mutation analysis is a well known yet unfortunately costly method for measuring test suite quality. Researchers have proposed numerous mutation reduction strategies in order to reduce the high cost of mutation analysis, while preserving the representativeness of the original set of mutants. As mutation reduction is an area of active research, it is important to understand the limits of possible improvements. We theoretically and empirically investigate the limits of improvement in effectiveness from using mutation reduction strategies compared to random sampling. Using real-world open source programs as subjects, we find an absolute limit in improvement of effectiveness over random sampling- 13.078%. Given our findings with respect to absolute limits, one may ask: How effective are the extant mutation reduction strategies? We evaluate the effectiveness of multiple mutation reduction strategies in comparison to\u00a0\u2026", "num_citations": "35\n", "authors": ["852"]}
{"title": "Science education\n", "abstract": " The registration fee for members and non-members of NARST includes a ticket to the annual luncheon. The annual luncheon program will include the presentation of the annual JRST Award, the NARST Award, recognition of committees and board members, and the installation of the new president.", "num_citations": "34\n", "authors": ["852"]}
{"title": "An empirical examination of the relationship between code smells and merge conflicts\n", "abstract": " Background: Merge conflicts are a common occurrence in software development. Researchers have shown the negative impact of conflicts on the resulting code quality and the development workflow. Thus far, no one has investigated the effect of bad design (code smells) on merge conflicts. Aims: We posit that entities that exhibit certain types of code smells are more likely to be involved in a merge conflict. We also postulate that code elements that are both \"smelly\" and involved in a merge conflict are associated with other undesirable effects (more likely to be buggy). Method: We mined 143 repositories from GitHub and recreated 6,979 merge conflicts to obtain metrics about code changes and conflicts. We categorized conflicts into semantic or non-semantic, based on whether changes affected the Abstract Syntax Tree. For each conflicting change, we calculate the number of code smells and the number of future\u00a0\u2026", "num_citations": "33\n", "authors": ["852"]}
{"title": "How hard does mutation analysis have to be, anyway?\n", "abstract": " Mutation analysis is considered the best method for measuring the adequacy of test suites. However, the number of test runs required for a full mutation analysis grows faster than project size, which is not feasible for real-world software projects, which often have more than a million lines of code. It is for projects of this size, however, that developers most need a method for evaluating the efficacy of a test suite. Various strategies have been proposed to deal with the explosion of mutants. However, these strategies at best reduce the number of mutants required to a fraction of overall mutants, which still grows with program size. Running, e.g., 5% of all mutants of a 2MLOC program usually requires analyzing over 100,000 mutants. Similarly, while various approaches have been proposed to tackle equivalent mutants, none completely eliminate the problem, and the fraction of equivalent mutants remaining is hard to\u00a0\u2026", "num_citations": "32\n", "authors": ["852"]}
{"title": "Understanding how and why open source contributors use diagrams in the development of Ubuntu\n", "abstract": " Some of the most interesting differences between Open Source Software (OSS) development and commercial co-located software development lie in the communication and collaboration practices of these two groups of developers. One interesting practice is that of diagramming. Though well studied and important in many aspects of co-located software development (including communication and collaboration among developers), its role in OSS development has not been thoroughly studied. In this paper, we report our investigation on how and why Ubuntu contributors use diagrams in their work. Our study shows that diagrams are not actively used in many scenarios where they commonly would in co-located software development efforts. We describe differences in the use and practices of diagramming, their possible reasons, and present design considerations for potential systems aimed at better supporting\u00a0\u2026", "num_citations": "32\n", "authors": ["852"]}
{"title": "The NAVE Design and Implementation of a Non-Expensive Immersive Virtual Environment 249\n", "abstract": " As demonstrated by the popularity of the CAVE and products such as the Virtual Workbench, there is a great amount of interest in projected stereoscopic environments as alternatives to head-mounted displays. One of the primary obstacles to their widespread adoption has been their high cost.The goal of the NAVE project was to design a low-cost, PC-driven, multi-screen, multi-user, stereoscopic, virtual environment with many of the desirable elements of the CAVE at a fraction of its cost. The NAVE was built at a total price of less than $60,000.", "num_citations": "30\n", "authors": ["852"]}
{"title": "An empirical study of design degradation: How software projects get worse over time\n", "abstract": " Context: Software decay is a key concern for large, long-lived software projects. Systems degrade over time as design and implementation compromises and exceptions pile up. Goal: Quantify design decay and understand how software projects deal with this issue. Method: We conducted an empirical study on the presence and evolution of code smells, used as an indicator of design degradation in 220 open source projects. Results: The best approach to maintain the quality of a project is to spend time reducing both software defects (bugs) and design issues (refactoring). We found that design issues are frequently ignored in favor of fixing defects. We also found that design issues have a higher chance of being fixed in the early stages of a project, and that efforts to correct these stall as projects mature and the code base grows, leading to a build-up of problems. Conclusions: From studying a large set of open\u00a0\u2026", "num_citations": "28\n", "authors": ["852"]}
{"title": "Lessons learned from teaching open source software development\n", "abstract": " Free/Open Source Software allows students to learn valuable real world skills and experiences, as well as a create a portfolio to show future employers. However, the learning curve to joining FOSS can be daunting, often leading newcomers to walk away frustrated. Universities therefore need to find ways to provide a structured introduction to students, helping them overcome the barriers to entry. This paper describes two courses taught at two universities, built around a Communities of Practice model, and the lessons learned from these. Suggestions and insights are shared for how to structure and evaluate such courses for maximum effect.", "num_citations": "27\n", "authors": ["852"]}
{"title": "The theory of composite faults\n", "abstract": " Fault masking happens when the effect of one fault serves to mask that of another fault for particular test inputs. The coupling effect is relied upon by testing practitioners to ensure that fault masking is rare. It states that complex faults are coupled to simple faults in such a way that a test data set that detects all simple faults in a program will detect a high percentage of the complex faults. While this effect has been empirically evaluated, our theoretical understanding of the coupling effect is as yet incomplete. Wah proposed a theory of the coupling effect on finite bijective (or near bijective) functions with the same domain and co-domain and assuming a uniform distribution for candidate functions. This model, however, was criticized as being too simple to model real systems, as it did not account for differing domain and co-domain in real programs, or for the syntactic neighborhood. We propose a new theory of fault\u00a0\u2026", "num_citations": "25\n", "authors": ["852"]}
{"title": "Coping with duplicate bug reports in free/open source software projects\n", "abstract": " Free/Open Source Software (FOSS) communities often use open bug reporting to allow users to participate by reporting bugs. This practice can lead to more duplicate reports, as users can be less rigorous about researching existing bug reports. This paper examines how FOSS projects deal with duplicate bug reports. We examined 12 FOSS projects: 4 small, 4 medium and 4 large, where size was determined by number of code contributors. First, we found that contrary to what has been reported from studies of individual large projects like Mozilla and Eclipse, duplicate bug reports are a problem for FOSS projects, especially medium-sized, which struggle with a large number of submissions without the resources of large projects. Second, we found that the focus of a project does not affect the number of duplicate bug reports. Our findings indicate a need for additional scaffolding and training for bug reporters.", "num_citations": "24\n", "authors": ["852"]}
{"title": "Applying mutation analysis on kernel test suites: An experience report\n", "abstract": " Mutation analysis is an established technique for measuring the completeness and quality of a test suite. Despite four decades of research on this technique, its use in large systems is still rare, in part due to computational requirements and high numbers of false positives. We present our experiences using mutation analysis on the Linux kernel's RCU (Read Copy Update) module, where we adapt existing techniques to constrain the complexity and computation requirements. We show that mutation analysis can be a useful tool, uncovering gaps in even well-tested modules like RCU. This experiment has so far led to the identification of 3 gaps in the RCU test harness, and 2 bugs in the RCU module masked by those gaps. We argue that mutation testing can and should be more extensively used in practice.", "num_citations": "21\n", "authors": ["852"]}
{"title": "Measuring effectiveness of mutant sets\n", "abstract": " Redundancy in mutants, where multiple mutants end up producing the same semantic variant of a program, is a major problem in mutation analysis. Hence, a measure of effectiveness that accounts for redundancy is an essential tool for evaluating mutation tools, new operators, and reduction techniques. Previous research suggests using the size of the disjoint mutant set as an effectiveness measure. We start from a simple premise: test suites need to be judged on both the number of unique variations in specifications they detect (as a variation measure), and also on how good they are at detecting hard-to-find faults (as a measure of thoroughness). Hence, any set of mutants should be judged by how well it supports these measurements. We show that the disjoint mutant set has two major inadequacies - the single variant assumption and the large test suite assumption - when used as a measure of effectiveness in\u00a0\u2026", "num_citations": "20\n", "authors": ["852"]}
{"title": "How verified is my code? falsification-driven verification (t)\n", "abstract": " Formal verification has advanced to the point that developers can verify the correctness of small, critical modules. Unfortunately, despite considerable efforts, determining if a \"verification\" verifies what the author intends is still difficult. Previous approaches are difficult to understand and often limited in applicability. Developers need verification coverage in terms of the software they are verifying, not model checking diagnostics. We propose a methodology to allow developers to determine (and correct) what it is that they have verified, and tools to support that methodology. Our basic approach is based on a novel variation of mutation analysis and the idea of verification driven by falsification. We use the CBMC model checker to show that this approach is applicable not only to simple data structures and sorting routines, and verification of a routine in Mozilla's JavaScript engine, but to understanding an ongoing effort to\u00a0\u2026", "num_citations": "19\n", "authors": ["852"]}
{"title": "Older adults and free/open source software: A diary study of first-time contributors\n", "abstract": " The global population is aging rapidly, and older adults are becoming increasingly technically savvy. This paper explores ways to engage these individuals to contribute to free/open source software (FOSS) projects. We conducted a pilot diary study to explore motivations, barriers, and the contribution processes of first-time contributors in a real time, qualitative manner. In addition, we measured their self-efficacy before and after their participation. We found that what drove participants were intrinsic motivations, altruism, and internal values, which differed from previous work with older adults and with the general FOSS population. We also found that self-efficacy did not change significantly, even when participants encountered significant barriers or setbacks. The top 3 barriers were lack of communication, installation issues, and documentation issues. We found that asking for and receiving help, and avoiding difficult\u00a0\u2026", "num_citations": "18\n", "authors": ["852"]}
{"title": "Does choice of mutation tool matter?\n", "abstract": " Though mutation analysis is the primary means of evaluating the quality of test suites, it suffers from inadequate standardization. Mutation analysis tools vary based on language, when mutants are generated (phase of compilation), and target audience. Mutation tools rarely implement the complete set of operators proposed in the literature and mostly implement at least a few domain-specific mutation operators. Thus different tools may not always agree on the mutant kills of a test suite. Few criteria exist to guide a practitioner in choosing the right tool for either evaluating effectiveness of a test suite or for comparing different testing techniques. We investigate an ensemble of measures for evaluating efficacy of mutants produced by different tools. These include the traditional difficulty of detection, strength of minimal sets, and the diversity of mutants, as well as the information carried by the mutants produced\u00a0\u2026", "num_citations": "16\n", "authors": ["852"]}
{"title": "Private Policies Examined: Fair Warning or Fair Game?\n", "abstract": " Posting privacy policies has become a popular practice with businesses as they seek to shield themselves from potential liability or regulation, as well as inform users about their privacy and rights. These policies are in many ways modeled after software license statements, and are often more legalistic than user friendly. This paper examines the current practice of privacy policies as fair warning hold up from a usability perspective, and what steps can be taken to ensure that the average user can protect their privacy online.", "num_citations": "16\n", "authors": ["852"]}
{"title": "An evaluation of game controllers and tablets as controllers for interactive tv applications\n", "abstract": " There is a growing interest in bringing online and streaming content to the television. Gaming platforms such as the PS3, Xbox 360 and Wii are at the center of this digital convergence; platforms for accessing new media services. This presents a number of interface challenges, as controllers designed for gaming have to be adapted to accessing online content. This paper presents a user study examining the limitations and affordances of novel game controllers in an interactive TV (iTV) context and compares them to\" second display\" approaches using tablets. We look at task completion times, accuracy and user satisfaction across a number of tasks and find that the Wiimote is most liked and performed best in almost all tasks. Participants found the Kinect difficult to use, which led to slow performance and high error rates. We discuss challenges and opportunities for the future convergence of game consoles and iTV.", "num_citations": "15\n", "authors": ["852"]}
{"title": "Topsy-Turvy: a smarter and faster parallelization of mutation analysis\n", "abstract": " Mutation analysis is an effective, if computationally expensive, technique that allows practitioners to accurately evaluate the quality of their test suites. To reduce the time and cost of mutation analysis, researchers have looked at parallelizing mutation runs---running multiple mutated versions of the program in parallel, and running through the tests in sequence on each mutated program until a bug is found. While an improvement over sequential execution of mutants and tests, this technique carries a significant overhead cost due to its redundant execution of unchanged code paths. In this paper we propose a novel technique (and its implementation) which parallelizes the test runs rather than the mutants, forking mutants from a single program execution at the point of invocation, which reduces redundancy. We show that our technique can lead to significant efficiency improvements and cost reductions.", "num_citations": "14\n", "authors": ["852"]}
{"title": "The Impact of Automatic Crash Reports on Bug Triaging and Development in Mozilla\n", "abstract": " Free/Open Source Software projects often rely on users submitting bug reports. However, reports submitted by novice users may lack information critical to developers, and the process may be intimidating and difficult. To gather more and better data, projects deploy automatic crash reporting tools, which capture stack traces and memory dumps when a crash occurs. These systems potentially generate large volumes of data, which may overwhelm developers, and their presence may discourage users from submitting traditional bug reports. In this paper, we examine Mozilla's automatic crash reporting system and how it affects their bug triaging process. We find that fewer than 0.00009% of crash reports end up in a bug report, but as many as 2.33% of bug reports have data from crash reports added. Feedback from developers shows that despite some problems, these systems are valuable. We conclude with a\u00a0\u2026", "num_citations": "14\n", "authors": ["852"]}
{"title": "Exploring the role of outside organizations in Free/Open Source Software projects\n", "abstract": " Free/Open Source Software (FOSS) projects have a reputation for being grass-roots efforts driven by individual contributors volunteering their time and effort. While this may be true for a majority of smaller projects, it is not always the case for large projects. As projects grow in size, importance and complexity, many come to depend on corporations, universities, NGO\u2019s and governments, for support and contributions, either financially or through seconded staff. As outside organizations get involved in projects, how does this affect their governance, transparency and direction? To study this question we gathered bug reports and commit logs for GCC and the Linux Kernel. We found that outside organizations contribute a majority of code but rarely participate in bug triaging. Therefore their code does not necessarily address the needs of others and may distort governance and direction. We conclude that\u00a0\u2026", "num_citations": "14\n", "authors": ["852"]}
{"title": "Jimbo: a collaborative IDE with live preview\n", "abstract": " Team collaboration plays a key role in the success of any multi-user activity. Software engineering is a highly collaborative activity, where multiple developers and designers work together to solve a common problem. Meaningful and effective designer-developer collaboration improves the user experience, which can improve the chances of success for the project. Learning to program is another activity that can be implemented in a more collaborative way, students can learn in an active style by working with others. The growth of online classes, from small structured seminars to massive open online courses (MOOCs), and the isolation and impoverished learning experience some students report in these, points to an urgent need for tools that support remote pair programming in a distributed educational setting.", "num_citations": "13\n", "authors": ["852"]}
{"title": "Do mutation reduction strategies matter?\n", "abstract": " Mutation analysis is a well-known, but computationally intensive, method for measuring test suite quality. While multiple strategies have been proposed to reduce the number of mutants, there is inconclusive evidence for their utility due to the limited number and size of programs used for validation, and a lack of comprehensive comparative studies. Traditional evaluation criteria for mutation reduction also rely on mutation-adequate suites, which are rare in practice.We propose novel criteria for evaluating reduction strategies for non-mutation-adequate test suites, directly linked to the actual use of mutation analysis during development\u2014to ensure that tests check for many different possible faults. We evaluate using both these criteria and the traditional criteria with 201 realworld projects, and show that the popular strategies\u2014operator selection, and stratified sampling (on operators or program elements)\u2014are at best marginally better than random sampling, and are often worse.", "num_citations": "13\n", "authors": ["852"]}
{"title": "Sketching and drawing in the design of open source software\n", "abstract": " In co-located software development, diagramming practices, such as sketching ideas out with a pen and paper, support the creative process and allow designers to shape, analyze, and communicate their ideas. This study focuses on the diagramming practices used in the design of Open Source Software (OSS), where the norm is highly distributed group work. In OSS, text-based communication (e.g., mailing lists) dominates, and sketching and drawing diagrams collaboratively remains difficult due to the barriers imposed by distance and technology. Previous studies have examined these practices and barriers in the context of individual projects. To understand how contributors across OSS projects use diagrams in design-related activities, we conducted a survey of 230 contributors from 40 different OSS projects, and interviewed eight participants. Our results show that although contributors understand the\u00a0\u2026", "num_citations": "12\n", "authors": ["852"]}
{"title": "On older adults in free/open source software: reflections of contributors and community leaders\n", "abstract": " Researchers have investigated the lack of diversity in Free/Open Source Software (FOSS) communities, but there have been few studies on age diversity. We interviewed 11 older FOSS contributors and 6 FOSS community leaders (of any age). This formative study reports on 4 key findings from those interviews: 1) motivations of older contributors, 2) benefits and challenges to contribution, 3) older adults' views on discrimination in FOSS, and 4) ways in which older adults enrich FOSS communities. We found that older adults' contributions are driven by intrinsic motivation, altruism, and community identification. In older adults' most recent contributions, we found that there were more social than technical challenges to participation. Interestingly, the majority of older adults claimed to have witnessed discrimination towards others in FOSS, especially against non-native English speakers and women. This stands in\u00a0\u2026", "num_citations": "11\n", "authors": ["852"]}
{"title": "Integrating user feedback with heuristic security and privacy management systems\n", "abstract": " Tools aimed at helping users safely navigate the web and safeguard themselves against potential online predators have become reasonably common. Currently there are two families of tools; heuristics analysis tools that test websites directly using automated scripts and programs, and community based tools where users rate websites and write reviews for the benefit of others. In this paper we examine the relative strengths and weaknesses of each technique, whether these techniques are compatible, and how community feedback can be combined with heuristic-based evaluations. In order to do this we conduct a large-scale comparison of the ratings of heuristic and community based tools, and explore novel methods for abstracting key information from user comments, which could be used to add context and nuance to heuristic based ratings. We find that heuristic and community based ratings are highly\u00a0\u2026", "num_citations": "11\n", "authors": ["852"]}
{"title": "Cutting and pasting up:\" Documents\" and provenance in a complex work environment\n", "abstract": " This paper explores how historical models of documents as stable information artifacts should be replaced with a new model of information objects that exist around and between document boundaries. The new model is information-centered; files and documents are seen as snapshots in time, part of individual and group information flows. The flows are versioned across multiple documents and applications. This model is based on new fine-grained tracking and analysis capabilities derived from machine learning research. Using these capabilities, we outline a view of documents based on results from an experiment that tracked the activities of 17 information workers doing their regular work over 8 weeks. The research supports certain postmodern theories of work, specifically the notion of \"pasting up.\" The construct of provenance describes information flows and networks and is the core theoretical base of the\u00a0\u2026", "num_citations": "11\n", "authors": ["852"]}
{"title": "An empirical investigation into merge conflicts and their effect on software quality\n", "abstract": " Merge conflicts are known to cause extra effort for developers, but little is known about their effect on software. While some research has been done, many questions remain. To better understand merge conflicts and their impact we performed an empirical study about the types, frequency, and impact of merge conflicts, where impact is measured in terms of bug fixing commits associated with conflicts. We analyzed 143 open source projects and found that almost 1 in 5 merges cause conflicts. In 75.23% of these cases, a developer needed to reflect on the program logic to resolve it. We also found that the code associated with a merge conflict is twice as likely to have a bug. When the code associated with merge conflicts require manual intervention, the code is 26\u00d7 more likely to have a bug.", "num_citations": "9\n", "authors": ["852"]}
{"title": "Leyline: Provenance-based search using a graphical sketchpad\n", "abstract": " The most effective strategy for finding files is to carefully arrange them into folders. This strategy breaks down for teams, where organizational schemes often differ between team members. It also breaks down when information is copied and reused as it becomes harder to track versions. As storage continues to grow and costs decline, the incentives to carefully archive old versions of files diminish. It is therefore important to explore new and improved search tools. The most common approach is keyword search, though recalling effective keywords can be challenging, especially as repositories grow and information flows across projects. A less common alternative is to use provenance--information about the creation, use and sharing of documents and their context, including collaborators. This paper presents a limited user study showing that provenance data is useful and desirable in search, and that an interface\u00a0\u2026", "num_citations": "9\n", "authors": ["852"]}
{"title": "Experimental evaluation of a lightweight method for augmenting requirements analysis\n", "abstract": " We introduce the concept of augmentation methods, methods that complement other methods by addressing specific non-functional requirements (NFRs). Since most projects do not have dedicated expertise in all relevant NFRs most team members may be comparative novices for that class of NFR. STRAP is a lightweight goal-refinement method for analyzing privacy NFRs. We describe it briefly and then present three experiments to assess its effectiveness and that of several existing privacy frameworks. We analyze the results in terms of method efficiency: the number of analysts needed to find a given proportion of benchmark problems. The alternative methods are generally effective in identifying privacy vulnerabilities but they are inefficient, since the average analyst misses many potential problems. In three distinct application domains, STRAP led to equal or better identification of privacy vulnerabilities and was\u00a0\u2026", "num_citations": "9\n", "authors": ["852"]}
{"title": "Toward a method for privacy vulnerability analysis\n", "abstract": " Users are concerned about their privacy, and many of the problems they face in managing their privacy are fundamentally HCI problems. Palen and Dorish note that privacy is a fluid process [4]. Individual differences in preferences and thresholds are often significant, and constantly evolving over time. Given a moderately complex system, it is likely impossible to accommodate everyone.Designing for privacy must therefore focus on facilitating awareness of policies, information collection, information use, and control over exposure. The challenge is identifying the processes users care about. Many non-trivial problems are caused by high-level architectural problems affecting many aspects of a system. These are hard to identify before a system is built, or fix afterwards.", "num_citations": "9\n", "authors": ["852"]}
{"title": "How verified (or tested) is my code? Falsification-driven verification and testing\n", "abstract": " Formal verification has advanced to the point that developers can verify the correctness of small, critical modules. Unfortunately, despite considerable efforts, determining if a \u201cverification\u201d verifies what the author intends is still difficult. Previous approaches are difficult to understand and often limited in applicability. Developers need verification coverage in terms of the software they are verifying, not model checking diagnostics. We propose a methodology to allow developers to determine (and correct) what it is that they have verified, and tools to support that methodology. Our basic approach is based on a novel variation of mutation analysis and the idea of verification driven by falsification. We use the CBMC model checker to show that this approach is applicable not only to simple data structures and sorting routines, and verification of a routine in Mozilla\u2019s JavaScript engine, but to understanding an ongoing\u00a0\u2026", "num_citations": "8\n", "authors": ["852"]}
{"title": "An exploration of code quality in FOSS projects\n", "abstract": " It is a widely held belief that Free/Open Source Software (FOSS) development leads to the creation of software with the same, if not higher quality compared to that created using proprietary software development models. However there is little research on evaluating the quality of FOSS code, and the impact of project characteristics such as age, number of core developers, code-base size, etc. In this exploratory study, we examined 110 FOSS projects, measuring the quality of the code and architectural design using code smells. We found that, contrary to our expectations, the overall quality of the code is not affected by the size of the code base, but that it was negatively impacted by the growth of the number of code contributors. Our results also show that projects with more core developers don\u2019t necessarily have better code quality.", "num_citations": "8\n", "authors": ["852"]}
{"title": "Designing for privacy in interactive systems\n", "abstract": " Current models for privacy-aware design were examined and compared to priorities and needs of end-users as determined from a number of studies presented. Based on these studies, we predicted these frameworks to be sub-optimal because of either a lack of structure in the analysis task, or too high a cost. To examine this point a new design framework combining the advantages of previous frameworks with a lightweight goal-oriented analysis technique. This new framework, STRAP (Structured Analysis of Privacy), was predicted to out-perform existing frameworks in terms of effectiveness (overall detection of privacy issues) and efficiency (number of privacy issues discovered over time on task or number of independent analysts).", "num_citations": "8\n", "authors": ["852"]}
{"title": "Integrating collaborative and live coding for distance education\n", "abstract": " What does an online programming course need to engage students and improve their skills? To answer this question, the authors designed and tested a feature-rich collaborative environment for an online class and found that it enhanced learning through methods such as remote pair programming, live coding, and a tight code-to-artifact feedback loop.", "num_citations": "7\n", "authors": ["852"]}
{"title": "An empirical comparison of mutant selection approaches\n", "abstract": " Mutation analysis is a well-known method for measuring the quality of test suites. However, it is computationally intensive compared to other measures, which makes it hard to use in practice. Choosing a smaller subset of mutations to run is a simple approach that can alleviate this problem. Mutation operator selection has been heavily researched. Recently, researchers have found that sampling mutants can achieve accuracy and mutant reduction similar to operator selection. However, the empirical support for these conclusions has been limited, due to the small number of subject programs investigated. The best sampling technique is also an open problem. Our research compares a large number of sampling and operator selection criteria based on their ability to predict the full mutation score as well as the consistency of mutation reduction ratios achieved. Our results can be used to choose an appropriate mutation reduction technique by the reduction and level of fidelity to full mutation results required. We find that all sampling approaches perform better than operator selection methods, when considering ability to predict the full mutation score as well as the consistency of mutation reduction ratios achieved.", "num_citations": "6\n", "authors": ["852"]}
{"title": "Drawing the big picture: temporal visualization of dynamic collaboration graphs of OSS software forks\n", "abstract": " How can we understand FOSS collaboration better? Can social issues that emerge be identified and addressed as they happen? Can the community heal itself, become more transparent and inclusive, and promote diversity? We propose a technique to address these issues by quantitative analysis and temporal visualization of social dynamics in FOSS communities. We used social network analysis metrics to identify growth patterns and unhealthy dynamics; This gives the community a heads-up when they can still take action to ensure the sustainability of the project.", "num_citations": "6\n", "authors": ["852"]}
{"title": "On the relationship between design discussions and design quality: a case study of Apache projects\n", "abstract": " Open design discussion is a primary mechanism through which open source projects debate, make and document design decisions. However, there are open questions regarding how design discussions are conducted and what effect they have on the design quality of projects. Recent work has begun to investigate design discussions, but has thus far focused on a single communication channel, whereas many projects use multiple channels. In this study, we examine 37 Apache projects and their design discussions, the project\u2019s design quality evolution, and the relationship between design discussion and design quality. A mixed method empirical analysis (data mining and a survey of 130 developers) shows that: I) 89.51% of all design discussions occur in project mailing list, II) both core and non-core developers participate in design discussions, but core developers implement more design related changes (67\u00a0\u2026", "num_citations": "5\n", "authors": ["852"]}
{"title": "A case study of motivations for corporate contribution to FOSS\n", "abstract": " Free/Open Source Software developers come from a myriad of different backgrounds, and are driven to contribute to projects for a variety of different reasons, including compensation from corporations or foundations. Motivation can have a dramatic impact on how and what contribution an individual makes, as well as how tenacious they are. These contributions may align with the needs of the developer, the community, the organization funding the developer, or all of the above. Understanding how corporate sponsorship affects the social dynamics and evolution of Free/Open Source code and community is critical to fostering healthy communities. We present a case study of corporations contributing to the Linux Kernel. We find that corporate contributors contribute more code, but are less likely to participate in non-coding activities. This knowledge will help project leaders to better understand the dynamics of\u00a0\u2026", "num_citations": "5\n", "authors": ["852"]}
{"title": "Mutant census: An empirical examination of the competent programmer hypothesis\n", "abstract": " Mutation analysis is often used to compare the effectiveness of different test suites or testing techniques. One of the main assumptions underlying this technique is the Competent Programmer Hypothesis, which proposes that programs are very close to a correct version, or that the difference between current and correct code for each fault is very small. Testers have generally assumed, on the basis of the Competent Programmer Hypothesis, that mutation analysis with single token changes produces mutations that are similar to real faults. While there exists some evidence that supports this assumption, these studies are based on analysis of a limited and potentially non-representative set of programs and are hence not conclusive. In this paper, we investigate the Competent Programmer Hypothesis by analyzing changes (and bug-fixes in particular) in a very large set of randomly selected projects using four different programming languages. Our analysis suggests that a typical fault involves about three to four tokens, and is seldom equivalent to any traditional mutation operator. We also find the most frequently occurring syntactical patterns, and identify the factors that affect the real bug-fix change distribution. Our analysis suggests that different languages have different distributions, which in turn suggests that operators optimal in one language may not be optimal for others. Moreover, our results suggest that mutation analysis stands in need of better empirical support of the connection between mutant detection and detection of actual program faults in a larger body of real programs.", "num_citations": "5\n", "authors": ["852"]}
{"title": "Supporting learners in online courses through pair programming and live coding\n", "abstract": " Pair programming has been shown to be a beneficial and popular technique for engaging students and improving learning outcomes in programming and related classes. While using pair programming in a collocated classroom setting is relatively straightforward, there is a strong lack of good tools and options for distributed classroom settings. The growth of such classes, from small structured seminars to massive open online courses (MOOCs), and the isolation and impoverished learning experience some students report in these, points to an urgent need for tools that support remote pair programming in a distributed educational setting. This paper explores the requirements and needs of online learners in Computer Science through a literature survey. To validate these requirements, we implement a collaborative development environment aimed at improving the learning experience through pair programming and\u00a0\u2026", "num_citations": "4\n", "authors": ["852"]}
{"title": "Misconceptions and Barriers to Adoption of FOSS in the US Energy Industry\n", "abstract": " In this exploratory study, we map the use of free and open source software (FOSS) in the United States energy sector, especially as it relates to cyber security. Through two surveys and a set of semi-structured interviews\u2014targeting both developers and policy makers\u2014we identified key stakeholders, organizations, and FOSS projects, be they rooted in industry, academia, or public policy space that influence software and security practices in the energy sector. We explored FOSS tools, common attitudes and concerns, and challenges with regard to FOSS adoption. More than a dozen themes were identified from interviews and surveys. Of these, drivers for adoption and risks associated with FOSS were the most prevalent. More specifically, the misperceptions of FOSS, the new security challenges presented by the smart grid, and the extensive influence of vendors in this space play the largest roles in FOSS\u00a0\u2026", "num_citations": "4\n", "authors": ["852"]}
{"title": "The commentator information system: a usability evaluation of a real-time sport information service\n", "abstract": " Many of the most vivid recollections we have of major sporting events and accomplishments as TV viewers and sports fans are things like scores, statistics, or the TV images of specific events. What make many of these live in our memories, or grab our attention in the first place is often the commentator or sports-caster, their words of wisdom, or lack thereof, the excitement and emotion in their voices, echoing our own. The commentator is a vital part to the sportscast experience, part of what can make watching sports remotely more enjoyable than at the stadium. In order to provide accurate and timely data to TV viewers, radio, or online listeners, commentators sometimes rely on a system called the Commentator Information System (CIS). In this paper we present an in-depth usability study of a CIS, how commentators do their job, how the process may be improved, and how to make sportscasts and simulations more\u00a0\u2026", "num_citations": "4\n", "authors": ["852"]}
{"title": "Evaluation of a visual programming keyboard on touchscreen devices\n", "abstract": " Block-based programming languages are used by millions of people around the world. Blockly is a popular JavaScript library for creating visual block programming editors. To input a block, users employ a drag-and-drop input style. However, there are some limitations to this input style. We introduce a custom soft keyboard to input Blockly programs. This keyboard allows inputting, changing or editing blocks with a single touch. We evaluated the keyboard users' speed, number of touches, and errors while inputting a Blockly program and compared its performance with the drag-and-drop method. Our keyboard reduces the input errors by 68.37% and the keystrokes by 47.97 %. Moreover, it increases the input speed by 71.26% when compared to the drag-and-drop. The keyboard users perceived it to be physically less demanding with less effort than the drag-and-drop method. Moreover, participants rated the drag\u00a0\u2026", "num_citations": "3\n", "authors": ["852"]}
{"title": "Longitudinal Analysis of the Run-up to a Decision to Break-up (Fork) in a Community\n", "abstract": " In this paper, we use a developer-oriented statistical approach to understand what causes people in complex software development networks to decide to fork (break away), and what changes a community goes through in the run-up\u00a0to a decision to break-up. Developing complex software systems is complex. Software developers interact. They may have the same or different goals, communication styles, or values. Interactions can be healthy or troubled. Troubled interactions cause troubled communities, that face failure. Some of these failures manifest themselves as a community split (known as forking). These failures affects many people; developers and users. Can we save troubled projects? We statistically model the longitudinal socio-grams of software developers and present early indicators and warning signs that can be used to predict an imminent break-up decision.", "num_citations": "3\n", "authors": ["852"]}
{"title": "The nave: Design and implementation of a non-expensive automatic virtual environment\n", "abstract": " This paper describes the NAVE, an affordable, immersive stereoscopic virtual reality display. The goal of the NAVE is to make key features of the CAVE available to a larger audience and introduce new and powerful features of its own. This paper describes the NAVE in detail, and offers diagrams and component information to allow others to build similar systems.", "num_citations": "3\n", "authors": ["852"]}
{"title": "Syntax-directed keyboard extension: Evolution and evaluation\n", "abstract": " The syntax-directed keyboard extension presented by Almusaly et al. in 2015 allows programmers to input Java source code with fewer errors and keystrokes compared to the soft QWERTY keyboard and it supports a comparable typing speed. While these results were obtained after only 10 minutes of practice, it is unclear how long term use affects performance. In this paper, we present an updated design for the original syntax-directed keyboard extension, replicate the original results, and evaluate the evolved design with Java programmers over eight sessions in a period of two weeks. Our results indicate that a programmer using the new keyboard extension for two weeks can input Java programs 16.5% faster (words per minute) than an expert QWERTY keyboard typist. In addition, we demonstrate that the efficiency and accuracy for inputting Java source code improves with repeated use over time and that\u00a0\u2026", "num_citations": "2\n", "authors": ["852"]}
{"title": "Temporal visualization of dynamic collaboration graphs of OSS software forks\n", "abstract": " Oregon State University, School of Electrical Engineering & Computer Science 1148 Kelley Engineering Center, Corvallis OR 97331, USA {azarbaam, cjensen}@ eecs. oregonstate. edu http://eecs. oregonstate. edu/~ azarbaam http://eecs. oregonstate. edu/people/jensen", "num_citations": "2\n", "authors": ["852"]}
{"title": "The Leyline: A comparative approach to designing a graphical provenance-based search ui\n", "abstract": " In this paper we explore the design of Leyline, a provenance-based desktop search and file management system, both on a conceptual and user interface level. We start with a comparative analysis and classification of previous provenance based search systems, examining their underlying assumptions and focus, search coverage and flexibility, as well as features and limitations. We then describe a novel provenance-based search system based around a flexible visual sketchpad interface, and explore how this interface technique expands the flexibility of such systems within acceptable limits on complexity and search time. We conclude with a discussion of design implications and lessons learned in the development and evaluation of such a provenance-based search system.", "num_citations": "2\n", "authors": ["852"]}
{"title": "Analyzing FOSS Collaboration and Social Dynamics with Temporal Social Networks\n", "abstract": " How can we understand FOSS collaboration better? Can social issues that emerge be identified and addressed before it is too late? Can the commua nity heal itself, become more transparent and inclusive, and promote diversity? We propose a technique to address these issues by quantitative analysis of social dynamics in Foss communities. We propose using social network analysis meta rics to identify growth patterns and unhealthy dynamics; giving the community a headsaup when they can still take action to ensure the sustainability of the project.", "num_citations": "2\n", "authors": ["852"]}
{"title": "Lifting the Curtain on Merge Conflict Resolution: A Sensemaking Perspective\n", "abstract": " Merge conflicts are an inevitable, but painful part of collaborative software development. Merge conflict resolution is nontrivial because it requires gathering information from disparate sources (e.g., a codebase, diffs between versions, history of changes, documentation etc.) and then piecing together not only this information, but the rationale and context behind the conflicting changes. Current tools offer inadequate support to developers trying to understand the context and impact of the conflicting changes. They also offer little support in evaluating potential resolutions. To improve conflict resolution tools, we first need to understand the information needs of conflict resolution and its underlying sensemaking process. In this paper, through in-situ observations of 10 conflict resolutions, we qualitatively investigate how developers collect and sensemake different conflict-related information and how they reach a\u00a0\u2026", "num_citations": "1\n", "authors": ["852"]}
{"title": "Using goal-oriented analysis for structured analysis of privacy\n", "abstract": " Privacy is an important concern for users, and a difficult design challenge. Different user populations have different requirements and expectations when it comes to privacy; thus finding universally acceptable solutions is far from trivial. Design guidelines have been available for a number of years, but often fail to address the dynamic and impromptu nature of privacy management, and are prone to design fixation. These methods also fail to provide a robust and replicable procedure for identifying potential problems, leaving the design process more in the realm of art than science. In this paper, we apply a goaloriented requirements engineering method to create a rational model of privacy, addressing the limitations of previous approaches. As an example we analyze a hypothetical browser, its privacy vulnerabilities, and propose a set of design changes at the architectural level to address a set of these vulnerabilities.", "num_citations": "1\n", "authors": ["852"]}