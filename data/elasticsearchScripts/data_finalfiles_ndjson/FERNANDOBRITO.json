{"title": "Evaluating the impact of object-oriented design on software quality\n", "abstract": " Describes the results of a study where the impact of object-oriented (OO) design on software quality characteristics is experimentally evaluated. A suite of Metrics for OO Design (MOOD) was adopted to measure the use of OO design mechanisms. Data collected on the development of eight small-sized information management systems based on identical requirements were used to assess the referred impact. Data obtained in this experiment show how OO design mechanisms such as inheritance, polymorphism, information hiding and coupling, can influence quality characteristics like reliability or maintainability. Some predictive models based on OO design metrics are also presented.", "num_citations": "406\n", "authors": ["371"]}
{"title": "Candidate metrics for object-oriented software within a taxonomy framework\n", "abstract": " This article offers an overview of the state of the art in object-oriented (OO) metrics as well as some new contributions. The usefulness of metrics is reviewed. The inappropriateness of \u201ctraditional\u201d metrics to encompass development under the OO paradigm is discussed. A framework for classifying metrics is suggested. Metrics are classified along two vectors: category and granularity, the usefulness and rationale behind each category are presented. Candidate metrics are suggested within the proposed framework. Finally, some research directions that require further effort are identified.", "num_citations": "264\n", "authors": ["371"]}
{"title": "A coupling-guided cluster analysis approach to reengineer the modularity of object-oriented systems\n", "abstract": " Describes a validation experiment of a quantitative approach to the modularization of object-oriented systems. The approach used is based on cluster analysis, a statistical technique used in many fields of science to group items. In this case, the clusters are modules and the items are classes. A sample of some relatively large object-oriented systems was used in this experiment. The calculation of the dissimilarity between classes is based on their relative couplings combined through six different rating schemes. These couplings are classified according to a taxonomy framework where categories were assigned weights. The coupling data were obtained with the MOODKit G2 tool. The results obtained allow conclusions concerning the applicability of the proposed approach. This work was developed in the realm of the MOOD (Modularization of Object-Oriented Systems) project, which aims to deliver a quantitative\u00a0\u2026", "num_citations": "95\n", "authors": ["371"]}
{"title": "Using OCL to formalize object-oriented design metrics definitions\n", "abstract": " This paper describes the formalization effort of different sets of object-oriented metrics definitions using the Object Constraint Language (OCL), a part of the Unified Modeling Language (UML) standard. The formalization is based upon the UML meta-model. This approach allows unambiguous metrics definition, which in turn helps increasing tool support for Object-Oriented metrics. Also, it is possible to establish comparisons among the formalized sets of metrics.", "num_citations": "74\n", "authors": ["371"]}
{"title": "Using OCL to formalize object oriented metrics definitions\n", "abstract": " CiNii \u8ad6\u6587 - Using OCL to Formalize Object Oriented Metrics Definitions CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005 \u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 CiNii\u7a93\u53e3 \u696d\u52d9\u306e\u518d\u958b\u306b\u3064\u3044\u3066 Using OCL to Formalize Object Oriented Metrics Definitions ABREU FB \u88ab \u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 ABREU FB \u53ce\u9332\u520a\u884c\u7269 Tutorial in 5th International ECOOP Workshop on Quantitative Approaches in Object-Oriented Software Engineering (QAOOSE 2001) Tutorial in 5th International ECOOP Workshop on Quantitative Approaches in Object-Oriented Software Engineering (QAOOSE 2001), 2001 \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 \u30e2\u30c7\u30eb\u99c6\u52d5\u578b \u958b\u767a\u306b\u304a\u3051\u308b\u30e2\u30c7\u30eb\u30e1\u30c8\u30ea\u30c3\u30af\u30b9\u306e\u5b9a\u7fa9\u624b\u6cd5 \u4f50\u4f2f \u5143\u53f8 , \u6d77\u8c37 \u6cbb\u5f66 \u96fb\u5b50\u60c5\u5831\u901a\u4fe1\u5b66\u4f1a\u6280\u8853\u7814\u7a76. , \u2026", "num_citations": "60\n", "authors": ["371"]}
{"title": "Formal Definition of Object Oriented Design Metrics\n", "abstract": " Software measurement has become essential to good Software Engineering. However, most published works on software engineering concentrate on the coding activity. As quality indicators and predictors of structural problems, metrics should be available as early as possible in the software life cycle, and not dependant on source code availability. This thesis intends to assist object-oriented software measurement, improving its use among software designers. For achieving this goal, the FLAME-a Formal Library for Aiding Metrics Extraction-is built with The Object Constraint Language (OCL), a part of the Unified Modeling Language (UML) standard. Based upon OCL, object-oriented design metrics definitions are formalized on a compositional way.The definition of each metric is done upon the UML meta-model, at different levels of abstraction, including the meta-classes Package, Model Element, Generalizable Element, Classifier, Feature, Operation and Attribute. The combination of the UML meta-model and OCL allows unambiguous metrics definition, which in turn helps increasing tool support for objectoriented metrics extraction.", "num_citations": "58\n", "authors": ["371"]}
{"title": "An ontological approach to describe the SQL: 2003 object-relational features\n", "abstract": " The SQL (Structured Query Language) is currently available in most database management systems and is the focus of an intense standardization process resulting in the latest version of the SQL:2003 standard. Standards are fundamental, but often they are difficult to use, due to their lack of understandability and the occurrence of inconsistencies. An ontology is useful for clarifying the elements of a standard, along with their interrelationships, as well as for detecting inconsistencies. In this paper we propose an ontology for the object-relational features of the new SQL:2003 standard, formalized with UML 2.0 class diagrams and OCL well-formedness rules. The ontology is instantiated with an example in which most of the new object-relational features of the SQL:2003 standard are presented.", "num_citations": "53\n", "authors": ["371"]}
{"title": "A formal library for aiding metrics extraction\n", "abstract": " This paper presents a library of measures, named FLAME\u2013A Formal Library for Aiding Metrics Extraction, which is mainly used to formalize object-oriented design metrics definitions. The library itself is formalized with the Object Constraint Language upon the UML meta-model. The combination of FLAME functions together with the UML meta-model allow unambiguous metrics definitions, which in turn help increasing tool support for objectoriented metrics extraction. When applied to the object-oriented design, the metrics definitions performed with FLAME make available a set of comparisons among different models, leading to recommendations and conclusions for the developers. These assumptions can help improving the quality of object-oriented design, as well as they indirectly help in the enhancement of this methodology, contributing to the progress of the overall software life cycle.", "num_citations": "52\n", "authors": ["371"]}
{"title": "An OCL-based formalization of the MOOSE metric suite\n", "abstract": " Design metrics are useful for several means, including the improvement of software quality, the identification of fault-prone classes, the prediction of maintenance efforts, the estimation of rework efforts, etc. However, many of the existing metrics suffer from an ill definition, which leads to different interpretations and to a subsequent lack of their use, due to their informal definitions. So, in spite of research studies, design metrics have not been widely utilized in the software industry. One of the major problems that limitates their use is the nonattendance of available tools to measure the metrics, which in turn can be a consequence of the metrics imprecise specification. This paper presents an approach used to formalize metric suites in a precise way, solving the ambiguity problems that can reduce their use. The MOOSE metrics\u2013Metrics for Object-Oriented Software Engineering\u2013serve to exemplify the simplicity and limitations of our approach.", "num_citations": "43\n", "authors": ["371"]}
{"title": "Formalizing object-oriented design metrics upon the UML meta-model\n", "abstract": " This paper discusses the formalization effort of object-oriented design metrics definitions and presents some concrete examples, developed upon the UML meta-model. The Object Constraint Language (OCL), a part of the Unified Modeling Language (UML) standard, is used in the formalization. The combination of the UML meta-model and OCL allows unambiguous metrics definition, which in turn helps increasing tool support for object-oriented metrics extraction. This formalization renders possible the comparisons among different sets of metrics, as well as it may be used to establish a common vocabulary among different stakeholders. As consequence, the precision of the metrics collection increases, contributing to the overall quality of the Software Engineering process.", "num_citations": "40\n", "authors": ["371"]}
{"title": "Towards a Components Quality Model\n", "abstract": " Component Based Development (CBD) is becoming increasingly important for the software industry. According to studies performed by four major market researchers (Gartner Group, Gica, Ovum and PriceWaterhouseCoopers) the component market has been growing steadily over the recent years and forecasts for its growth are made [1][2]. CBD is supposed to reduce the cost and time to market of software applications while increasing their quality. Since components are reused in several occasions, they are likely to be more reliable than software developed from scratch, as they were tested under a larger variety of conditions. Cost and time savings result from the effort that would otherwise be necessary to develop and integrate the functionalities provided by the components in each new software application.Most of the research dedicated to software components is focused on their functional aspects. In our ongoing research, we are concerned with the evaluation of software components quality. This evaluation should be performed using a component quality model. There are several difficulties in the development of such a model, such as (1) which quality characteristics should be considered,(2) how we can evaluate them and (3) who should be responsible for such evaluation. The development and validation of a model that answers these questions would offer a very useful evaluation tool to clients looking for components to include in their software applications. Currently, little or no information on quality is provided by component vendors. For the sake of discussion, we will use here the following component definition: a software component\u00a0\u2026", "num_citations": "38\n", "authors": ["371"]}
{"title": "Reducing subjectivity in code smells detection: Experimenting with the long method\n", "abstract": " Guidelines for refactoring are meant to improve software systems internal quality and are widely acknowledged as among software's best practices. However, such guidelines remain mostly qualitative in nature. As a result, judgments on how to conduct refactoring processes remain mostly subjective and therefore non-automatable, prone to errors and unrepeatable. The detection of the Long Method code smell is an example. To address this problem, this paper proposes a technique to detect Long Method objectively and automatically, using a Binary Logistic Regression model calibrated by expert's knowledge. The results of an experiment illustrating the use of this technique are reported.", "num_citations": "34\n", "authors": ["371"]}
{"title": "Adding preciseness to BPMN models\n", "abstract": " BPMN is becoming the de facto standard for process description, analysis and simulation, in IT and many other business domains. BPMN supports different levels of abstraction, from high-level process models, to detailed models capable of being executed. Several tools now support, at least partly, OMG's BPMN metamodel specification. However, while several other OMG's metamodels include a formal specification of well-formedness rules, using OCL, the BPMN metamodel specification only includes those rules in natural language, scattered across several hundred pages of that document. Not surprisingly, we found that all mainstream BPMN tools do not enforce those well-formedness rules, while checking the correctness of process models. Model preciseness enforcement is important to mitigate ambiguity. The latter hampers the achievement of a shared meaning among process stakeholders, is detrimental to\u00a0\u2026", "num_citations": "29\n", "authors": ["371"]}
{"title": "A Formal Definition for Object-Relational Database Metrics\n", "abstract": " 1QUASAR Research Group. Faculty of Sciences and Technology. Universidade Nova de Lisboa. Portugal Email: alinebaroni@ di. fct. unl. pt, fba@ di. fct. unl. pt 2ALARCOS Research Group. Department of Compuer Science. Universirt of Castilla-La Mancha. Spain Email: coral. calero@ uclm. es, mario. piattini@ uclm. es", "num_citations": "28\n", "authors": ["371"]}
{"title": "Model-driven gui generation and navigation for android bis apps\n", "abstract": " This paper presents our approach for producing graphical user interfaces (GUIs) for functionally rich business information system (BIS) prototypes, upon a mobile platform. Those prototypes are specified with annotated UML class diagrams. Navigation in the generated GUIs is allowed through the semantic links that match the associations and cardinalities among the conceptual domain entities, as expressed in the model. We start by reviewing the Android scaffolding for producing flexible GUIs for mobile devices. The latter can present rather different displays, in terms of size, orientation and resolution. Then we show how our model-based generative technique allows producing prototypes that match both the Android GUIs requirements, while implementing our model-driven approach for user navigation.", "num_citations": "26\n", "authors": ["371"]}
{"title": "Websites Quality: Does It Depend on the Application Domain?\n", "abstract": " Websites quality models are important to rank presences in the web, to identify best practices or pinpoint poor implementations. This paper presents a preliminary step of a website quality evaluation approach based on fully automatic collection of quality metrics, grouped by ISO9126 quality characteristics. In this step, over sixty candidate metrics, mostly proposed by other Web Engineering researchers, were collected. Besides providing evidence on the feasibility of automatic collection, we present the results of an empirical study where we assess which metrics of website quality depend on the application domain. Using a modified web crawler and a database, we collected a sample of more than one hundred sites, organized in three balanced groups, each corresponding to a different application domain area (banks, newspapers and airlines). Then, we tested if the application domain had a statistically significant\u00a0\u2026", "num_citations": "26\n", "authors": ["371"]}
{"title": "Clustering relations into abstract er schemas for database reverse engineering\n", "abstract": " Database reverse engineering (DBRE) methods recover conceptual data models from physical databases. The bottom-up nature of these methods imposes two major limitations. First, they do not provide an initial high-level abstract schema suitable for use as a basis for reasoning about the application domain: a single detailed schema is only produced at the very end of the project. Second, they provide no support for a divide-and-conquer approach: the entire database schema must be analysed and processed as a unit. This paper presents a simple solution to overcome both limitations. In our proposal, relations are grouped based on their primary keys. Each group can be perceived in two ways: as a relational schema that can be reversed engineered as a standalone DBRE project; and as an element, either an entity or a relationship, of a high-level abstract schema that provides initial insight about the application\u00a0\u2026", "num_citations": "23\n", "authors": ["371"]}
{"title": "Integrating IT Service Management Within the Enterprise Architecture\n", "abstract": " Published work in the IT services area is generally centered on the description of management best practices or specific technological issues. There is a lack of empirical studies the relationship among service level agreements (the quality parameters of service agreed between customer and provider) and the required IT parts to deliver IT services. In the ITIL framework, the service level agreements process is fully described, albeit without a formal representation. Enterprise Architecture frameworks provide a mean for formal description of IT and business parts of organizations and their interrelationships, however without reference to service level agreements. In this research, we intend to derive a formal specification of service level agreements by integrating IT Services Management within an Enterprise Architecture framework. This integration will facilitate the provision of a business-aligned automatic checking of\u00a0\u2026", "num_citations": "21\n", "authors": ["371"]}
{"title": "An Ontology for IT Services\n", "abstract": " The survey of related work on ontological studies in the IT services domain, allowed us to identify some serious limitations on the current state-of-the-art across a set of six maturity dimensions. To mitigate that shortcoming this paper proposes a formal ontology for IT services. To grant preciseness to this ontology we have expressed well-formedness rules with the OCL constraint language. The proposed ontology is then instantiated to illustrate its validity in addressing realistic examples.", "num_citations": "21\n", "authors": ["371"]}
{"title": "Influential factors on incident management: Lessons learned from a large sample of products in operation\n", "abstract": " Understanding causal relationships on incident management can help software development organizations in finding the adequate level of resourcing, as well as improving the quality of services they provide to their end-users and/or cus tomers. This paper presents an empirical study conducted upon a sample of in cident reports recorded during the operation of several hundred commercial software products, over a period of three years, on six countries in Europe and Latin America. The underlying research questions refer to the validation of which are the influencing factors affecting the incidents management lifecycle. Non parametric analysis of variance procedures are used for testing hypotheses.", "num_citations": "20\n", "authors": ["371"]}
{"title": "Strengthening refactoring: Towards software evolution with quantitative and experimental grounds\n", "abstract": " Refactoring is a process meant to improve the internal quality of software systems. However, while on one hand, the guidelines for this delicate process are still empirical and qualitative, on the other hand, software product metrics often indicate that this process has the opposite results. Also, there is a lack of evidence regarding improvements on maintainability due to refactoring. This means that this process, although widely acknowledged as one of the best software practices, is difficult to deploy within large scale software systems, and can be better grounded. To address these challenges, we propose a method for refactoring with quantitative and experimental grounds. Upon the consolidation of this method, we will build the necessary blocks to implement and validate it.", "num_citations": "17\n", "authors": ["371"]}
{"title": "Modularity-oriented refactoring\n", "abstract": " Refactoring, in spite of widely acknowledged as one of the best practices of object-oriented design and programming, still lacks quantitative grounds and efficient tools for tasks such as detecting smells, choosing the most appropriate refactoring or validating the goodness of changes. This is a proposal for a method, supported by a tool, for cross-paradigm refactoring (e.g. from OOP to AOP), based on paradigm and formalism-independent modularity assessment.", "num_citations": "17\n", "authors": ["371"]}
{"title": "Software development process mining: Discovery, conformance checking and enhancement\n", "abstract": " Software development has become a fundamental process on any business or organization. As a consequence, together with other emergent technologies, new development platforms (IDEs) are being created, mainly in the cloud (e.g., Eclipse Orion, Cloud9, Codio), requiring different approaches on the way software development can be studied. Empirical studies on software development most often are based on data taken from software configuration management repositories, source code management systems and issue tracking tools, but not from the IDEs themselves, because they do not record data publically regarding developers' activities. We aim to bring forward new insights on the software development process by analyzing how developers use their IDE. Based upon process mining techniques such as process discovery and conformance checking, this missing perspective will hopefully allow the\u00a0\u2026", "num_citations": "15\n", "authors": ["371"]}
{"title": "Formalizing object-relational structural metrics\n", "abstract": " This paper describes a meta-modeling approach to formalize a set of metrics suited for object-relational databases. Those metrics are expected to help database designers in their activity, offering a mechanism for comparing and selecting, among possible schema designs, the one with more quality. Formalization of metrics is important for avoiding misinterpretation of definitions, while producing metrics collection tools. The metamodel used for formalization purposes is represented as a UML class diagram and is based on the newest version of the ISO SQL: 2003 standard. The formalizing technique uses OCL for expressing the metrics, which in turn allows automating metrics collection. An extract of an object-relational database schema is used to illustrate the metrics collection process using the proposed approach.", "num_citations": "15\n", "authors": ["371"]}
{"title": "An IT infrastructure patterns approach to improve IT service management quality\n", "abstract": " IT services are built on top and are delivered by (and therefore depend upon) IT infrastructures. The design of the latter is critical, since it will influence the overall quality of IT services. However, designing IT infrastructures for large organizations is a challenge task since it requires knowledge of existing organization processes, the views of different players, and the conjunction of technical expertise in different domains, that rarely reside in a single individual. To improve the design of IT infrastructures, namely by allowing to reuse proven solutions to recurrent problems we propose the use of IT infrastructure patterns. The use of patterns in the design of IT infrastructure will provide several benefits such as facilitate the communication among IT design stakeholders, simplify the whole design process and potentially decrease size and complexity, which all contribute to increase the quality of IT service management\u00a0\u2026", "num_citations": "13\n", "authors": ["371"]}
{"title": "Mining software development process variations\n", "abstract": " Process tailoring aims to customize a software process to better suit the specific needs of an organization when executing a software project or due to a social context in which the process is inserted. Tailoring happens, in general, through variations in the process elements, such as activities, artifacts, and control flows. This paper aims to introduce a technique that uses process mining to uncover elements from the software process that are candidates for tailoring. The proposed approach analyzes the execution logs from several process instances that share a common standard process. As a result, execution traces that differ from the standard process flow are identified and assessed to uncover their variable elements. The proposed technique was evaluated with data extracted from a real software development scenario when a large system was under development for a set of Brazilian Federal Institutes of Education\u00a0\u2026", "num_citations": "12\n", "authors": ["371"]}
{"title": "An Eclipse Plugin to Support Code Smells Detection\n", "abstract": " Eradication of code smells is often pointed out as a way to improve readability, extensibility and design in existing software. However, code smell detection in large systems remains time consuming and error-prone, partly due to the inherent subjectivity of the detection processes presently available. In view of mitigating the subjectivity problem, this paper presents a tool that automates a technique for the detection and assessment of code smells in Java source code, developed as an Eclipse plug-in. The technique is based upon a Binary Logistic Regression model and calibrated by expert's knowledge. A short overview of the technique is provided and the tool is described.", "num_citations": "12\n", "authors": ["371"]}
{"title": "SLALOM: a Language for SLA Specification and Monitoring\n", "abstract": " IT services provisioning is usually underpinned by service level agreements (SLAs), aimed at guaranteeing services quality. However, there is a gap between the customer perspective (business oriented) and that of the service provider (implementation oriented) that becomes more evident while defining and monitoring SLAs. This paper proposes a domain specific language (SLA Language for specificatiOn and Monitoring - SLALOM) to bridge the previous gap. The first step in SLALOM creation was factoring out common concepts, by composing the BPMN metamodel with that of the SLA life cycle, as described in ITIL. The derived metamodel expresses the SLALOM abstract syntax model. The second step was to write concrete syntaxes targeting different aims, such as SLA representation in process models. An example of SLALOM's concrete syntax model instantiation for an IT service sup-ported by self-service financial terminals is presented.", "num_citations": "12\n", "authors": ["371"]}
{"title": "Defining and observing the compliance of service level agreements: A model driven approach\n", "abstract": " IT Service Management (ITSM) is the set of processes that allow planning, organizing, directing and controlling the provisioning of IT services. Among the concerns of ITSM, namely within the service level management process, are the requirements for services availability, performance, accuracy, capacity and security, which are specified in terms of service-level agreements (SLA). SLA definition and monitoring are open issues within the ITSM domain. This paper overviews an ongoing research initiative concerned with three specific problems in this context: (1) SLAs in the context of ITSM are informally specified in natural language, (2) SLAs specifications are not grounded on models of ITSM processes, (3) SLAs compliance verification in IT services is not performed at the same level of abstraction as service design. To mitigate those problems, we propose a model-based approach to IT services SLA specification\u00a0\u2026", "num_citations": "11\n", "authors": ["371"]}
{"title": "Towards paradigm-independent software assessment\n", "abstract": " The milestones of the history of software development are paradigm shifts. Each paradigm brought its own features and new ways of composing them to assemble software systems. Understanding the impact of paradigm shifts encompasses making comparisons among systems built with different paradigms. Performing this kind of assessments is a very difficult exercise since the characterization of software assets is generally performed using paradigm-specific quantifications. In this paper we propose a metamodel for describing software products (either source code or design models) that is paradigm-independent. This metamodel, combined with a formal quantification approach, can help performing paradigm-independent software systems assessment. We illustrate the use of the proposed metamodel on a case study comparing functionally-equivalent systems produced with OOP andAOP.", "num_citations": "11\n", "authors": ["371"]}
{"title": "Object-relational database metrics formalization\n", "abstract": " In this paper the formalization of a set of metrics for assessing the complexity of ORBDs is presented. An ontology for the SQL:2003 standard was produced, as a framework for representing the SQL schema definitions. It was represented using UML. The metrics were defined with OCL, upon the SQL:2003 ontology", "num_citations": "10\n", "authors": ["371"]}
{"title": "An overview of metrics-based approaches to support software components reusability assessment\n", "abstract": " Objective: To present an overview on the current state of the art concerning metrics-based quality evaluation of software components and component assemblies. Method: Comparison of several approaches available in the literature, using a framework comprising several aspects, such as scope, intent, definition technique, and maturity. Results: The identification of common shortcomings of current approaches, such as ambiguity in definition, lack of adequacy of the specifying formalisms and insufficient validation of current quality models and metrics for software components. Conclusions: Quality evaluation of components and component-based infrastructures presents new challenges to the Experimental Software Engineering community.", "num_citations": "9\n", "authors": ["371"]}
{"title": "Definition and Validation of Complexity Metrics for ITSM Process Models\n", "abstract": " Process metrics can be used to establish baselines, to predict the effort required to go from an \u201cas-is\u201d to a \u201cto-be\u201d scenario or to pinpoint problematic ITSM process models. Several metrics proposed in the literature for business process models can be used for ITSM process models as well. This paper formalizes some of those metrics and proposes some new ones, using the Metamodel-Driven Measurement (M2DM) approach that provides precision, objectiveness and automatic collection. According to that approach, metrics were specified with the Object Constraint Language (OCL), upon a lightweight BPMN metamodel that is briefly described. That metamodel was instantiated with a case study consisting of two ITSM processes with two scenarios (\u201cas-is\u201d and \u201cto-be\u201d) each. Values collected automatically by executing the OCL metrics definitions, upon the instantiated metamodel, are presented. Using a larger sample\u00a0\u2026", "num_citations": "8\n", "authors": ["371"]}
{"title": "Assessing Software Development Teams' Efficiency using Process Mining\n", "abstract": " Context. Improving the efficiency and effectiveness of software development projects implies understanding their actual process. Given the same requirements specification, different software development teams may follow different strategies and that may lead to inappropriate use of tools or non-optimized allocation of effort on spurious activities, non-aligned with the desired goals. However, due to its intangibility, the actual process followed by each developer or team is often a black box. Objective. The overall goal of this study is to improve the knowledge on how to measure efficiency in development teams where a great deal of variability may exist due to the human-factor. The main focus is on the discovery of the underlying processes and compare them in terms of efficiency and effectiveness. By doing so, we expect to reveal potentially hidden costs and risks, so that corrective actions may take place on a timely\u00a0\u2026", "num_citations": "6\n", "authors": ["371"]}
{"title": "Model-driven service level management\n", "abstract": " Service-level agreements (SLA) definition and monitoring are open issues within the IT Service Management (ITSM) domain. Our main goals are to propose a model-based approach to IT services SLA specification and compliance verification. The specification will be accomplished by proposing a SLA language - a domain specific language for defining quality attributes as non functional requirements (NFRs) in the context of ITSM. This will allow that SLA monitoring and compliance validation at a level of abstraction that is understood by the stakeholders involved in the service specification.", "num_citations": "6\n", "authors": ["371"]}
{"title": "Modularity Improvements with Aspect-Oriented Programming\n", "abstract": " CITI - BibTeX Generator CITI has stopped operations in 2014, to co-launch NOVA LINCS THIS SITE IS NOT BEING UPDATED SINCE 2013 citi banner Home \\ BibTeX Generator Login CITI Welcome Research Areas Organization Executive Board Advisory Board Contacts Useful Information People CITI Members Visitors Activities Research Projects Publications Seminars @ CITI External Talks & Seminars Graduation Activities Organization of Events Editorial Committees Prototypes Visits & Missions Activity Reports Search & Query Search BibTeX Generator banner bottom [ BibTeX Generator ] Go to the bibtex generator form Dissertations In Proceedings S\u00e9rgio Bryton ( 8 publications ) Thursday 10th of June 2021 06:04:32 AM *** Dissertations ( 1 ) *** @mastersthesis{ bryton2008b, author = { S\u00e9rgio Bryton }, title = { Modularity Improvements with Aspect-Oriented Programming }, school = { Faculdade de Ci\u00eancias e , de }'\u2026", "num_citations": "6\n", "authors": ["371"]}
{"title": "Design quality metrics for object-oriented software systems\n", "abstract": " The adoption of the Object-Oriented paradigm is expected to help produce better and cheaper software. The main structural mechanisms of this paradigm, namely, inheritance, encapsulation, information hiding or polymorphism, are the keys to foster reuse and achieve easier maintainability. However, the use of language constructs that support those mechanisms can be more or less intensive, depending mostly on the designer ability. We can then expect rather different quality products to emerge, as well as different productivity gains. Advances in quality and productivity need to be correlated with the use of those constructs. We then need to evaluate this use quantitatively to guide OO design.", "num_citations": "6\n", "authors": ["371"]}
{"title": "Object-oriented software design metrics\n", "abstract": " Object-orientation is not a panacea for successful system development as noted in [Jacobson92]. The shift from craftsmanship to industrialism must come on a more fundamental level that also includes the organization of the complete development process. Object-Oriented Software Engineering (OOSE) has, accordingly, received an inflated attention. Its main objective is to make the OO software development process an engineering activity, either by adapting\" traditional\" software engineering techniques, or by proposing its own. OOSE deals with technical and managerial issues, the former having received much more attention in the past few years.Several problem areas in OOSE are, among others, the adoption of the OO technology itself (ie paradigm shift), the lack of adequate life-cycle models that support reusability, the ability to assess the quality of the development process and resulting products, and the capability of evaluating the productivity of development teams. These last two issues are fundamental in order for managers to control, steer and follow up software development efforts.", "num_citations": "6\n", "authors": ["371"]}
{"title": "Finding where to apply object-relational database schema refactorings: an ontology-guided approach\n", "abstract": " Less complex object-relational (OR) database schemas are more understandable, changeable, maintainable and reusable. This paper addresses the use of OR metrics to (i) detect complex fragments of OR database schemas, which are candidates to perform refactorings, and (ii) to assess if the application of the selected refactorings has indeed reduced the schema complexity. The schema metrics are formally defined with OCL, upon an ontology of the SQL: 2003 standard, expressed as a UML class diagram. This formalization allows automating metrics collection. Although our approach does not point out how to select the most adequate refactoring transformation, it helps designers and developers to pinpoint the spots in the database schema where a refactoring is likely to produce a quality improvement. An illustrating example is included.", "num_citations": "5\n", "authors": ["371"]}
{"title": "From Objects to Components: a Quantitative Approach\n", "abstract": " Component based software development (CBD) is increasingly becoming a de facto approach to software development. Most software professionals were originally trained to build software using another paradigm, such as the object orientation (OO) paradigm, or the structured programming one. To face the trend to CBD, software professionals are required to make a paradigm shift. Such a shift incurs in considerable costs. This paper describes an experiment where part of a legacy software application built with the OO paradigm was transformed into a software component, using three different technologies (Object Pascal, C++ and Java). In this experiment, we were concerned not only with the qualitative aspects of the problems dealt with by a software professional in this transformation, but mostly with some quantitative ones. In particular, we compared the effort required to make such transformations with each of the technologies. The subject performing the experiment was at ease with all the involved OO languages, but not with the component models supported by the used platforms.", "num_citations": "5\n", "authors": ["371"]}
{"title": "Code smells survival analysis in web apps\n", "abstract": " Web applications are heterogeneous, both in their target platform (split across client and server sides) and on the formalisms they are built with, usually a mixture of programming and formatting languages. This heterogeneity is perhaps an explanation why software evolution of web applications (apps) is a poorly addressed topic in the literature. In this paper we focus on web apps built with PHP, the most widely used server-side programming language.               We analyzed the evolution of 6 code smells in 4 web applications, using the survival analysis technique. Since code smells are symptoms of poor design, it is relevant to study their survival, that is, how long did it take from their introduction to their removal. It is obviously desirable to minimize their survival.               In our analysis we split code smells in two categories: scattered smells and localized smells, since we expect the former to be more harmful\u00a0\u2026", "num_citations": "4\n", "authors": ["371"]}
{"title": "Techniques, Tools, and Formalisms for Capturing and Assessing the Architectural Quality in Object-Oriented Software\n", "abstract": " The main objective of this workshop was to establish a working dialogue about the adequate use of techniques, formalisms and tools, as well as their combination in order to increase the architectural quality of object-oriented software systems. The workshop focussed on three major topics leading to split attendees in three groups. After a short report of the outcomes, the remaining of the chapter is devoted to the thirteen selected position papers. An extended version of this workshop report can be found on:                    http://www.emn.fr/borne/ECOOP98-W02.html                                    .", "num_citations": "4\n", "authors": ["371"]}
{"title": "Knowledge discovery metamodel-based unit test cases generation\n", "abstract": " Existing unit test cases generative approaches are language-dependent. In this document we propose a novel approach, dubbed KDM2xUnit that will allow the generation of test suites matching the xUnit framework, using several transformations and Knowledge Discovery Metamodel (KDM) compliant models as a common intermediate representation for existing software systems and their operating environments.", "num_citations": "3\n", "authors": ["371"]}
{"title": "Analyzing web applications quality evolution\n", "abstract": " Software evolution is a well-established research topic, but not in the web applications area. Web projects are normally more complex than other software development projects because they have both server and client code, encompass a variety of programming languages, and are multidisciplinary. We aim to produce a catalog of web smells to help mitigating quality problems in web apps implementation, thus saving time and reducing cost. By means of longitudinal studies, we plan to analyze the impact of these web smells in web apps maintainability and reliability. This paper describes several particularities of the proposed research work, as well as introduce procedures and techniques to be used.", "num_citations": "3\n", "authors": ["371"]}
{"title": "Web systems quality evolution\n", "abstract": " Software evolution is a well-established research area, but not in the area of web systems/applications. Web projects are normally more complex than other software development projects because they have both server and client code, encompass a variety of programming languages, and are multidisciplinary. We aim to produce a catalog of web smells to help avoiding the problems in web development code before they happen, thus saving time and reducing cost. By means of longitudinal studies we plan to analyze the impact of these web smells in web systems maintainability and reliability. This will require developing a tool to detect the proposed web smells. For validation sake, we will also use surveys among web systems developers and peer reviewing in academic fora.", "num_citations": "3\n", "authors": ["371"]}
{"title": "Verification and Validation of UML Diagrams using Checklists\n", "abstract": " There are several methods for the verification and validation of UML modeling. UML is becoming the most used modeling language in the Software Engineering world, so we consider that this is a subject of some importance. The diagrams considered are Use Case, Class, State chart, Sequence and Collaboration diagrams. For each type, we consider a typical defect and show how it can be solved using verification and validation techniques.", "num_citations": "3\n", "authors": ["371"]}
{"title": "Reengineering IT Infrastructures: A method for topology discovery\n", "abstract": " ICT systems are made of software, middleware and hardware components and are usually distributed over a network. Middleware and hardware components are combined on what is usually designated an \"IT Infrastructure (ITI)\". It is upon that ITI that application software is run. The topology of that ITI poses constraints on software algorithms, data structures and software configuration, due to concerns such as fault tolerance, latency or synchronization. In large ITIs that topology evolves constantly. Therefore, when faced to the challenge of maintaining a legacy ICT system, it is important to use reengineering techniques to discover the ITI topology. We propose a reengineering technique to discover the topology of a distributed IT infrastructure, based on a multinomial logistic regression model and a set of topology stereotypes. To demonstrate the feasibility of the approach we applied the model to several organizations\u00a0\u2026", "num_citations": "3\n", "authors": ["371"]}
{"title": "Information Technology Service Management: An Experimental Approach Towards IT Service Prediction\n", "abstract": " Software development and software quality improvement have been strong topics for discussion in the last decades. Software Engineering has always been concerned with theories and best practices to develop software for large-scale usage. However, most times those theories are not validated in real live environments. Therefore, the need for experiments is immense. The incidents database can be an important asset for software engineering teams. If they learn from past experience in service management, then they will be able to shift from a reactive approach to a more proactive one. The main goal of this dissertation is shedding some light on the influential factors that affect incidents lifecycle, from creation to its closure, and also to investigate to what accuracy the ARIMA models are a valid approach to model and predict not only the ITIL incident management process, but also other ITIL processes and services in general. The dissertation presented herein is on the crossroads of Empirical Software Engineering and of the emerging area of Services Science. It describes an experiment conducted upon a sample of incident reports, recorded during the operation of several hundred commercial software products, over a period of three years (2005-2007), on six countries in Europe and Latin America. The incidents were reported by customers of a large independent software vendor. The primary goal of an Incident Management process is to restore normal service operation as quickly as possible and minimize the adverse impact on business operations, thus ensuring that the best possible levels of service quality and availability are maintained. As\u00a0\u2026", "num_citations": "3\n", "authors": ["371"]}
{"title": "A Model-Driven Approach for Mobile Business Information Systems Applications\n", "abstract": " Context: Mobile BIS apps demand is increasing, with shorter time-to-market requirements, but their production faces problems, such as handling business rules concurrently, multiple platforms, localization and extensibility. Objective: Propose a generative approach for mobile BIS apps that will mitigate the identified problems.Method: We adopted the Design Science Research methodology, that helps gaining problem understanding, identifying systemically appropriate solutions, and in evaluating innovative solutions.Results: We identified the problem and its motivation, defined the objectives for a solution, designed and developed a prototype generative tool for BIS apps, demonstrated its usage and evaluated how well it mitigates a subset of the identified problems in an observational study. Limitations: Several issues are pending such as distributed business rules enforcement and the formalization of the required transformations from the PIM to several platform-specific models (PSMs). Conclusion: We intend to contribute for reducing BIS apps time-to-market, while improving the maintainability of those apps.", "num_citations": "2\n", "authors": ["371"]}
{"title": "A Semi-automatic Approach to Code Smells Detection\n", "abstract": " Eradication of code smells is often pointed out as a way to improve readability, extensibility and design in existing software. However, code smell detection remains time consuming and error-prone, partly due to the inherent subjectivity of the detection processes presently available. In view of mitigating the subjectivity problem, this dissertation presents a tool that automates a technique for the detection and assessment of code smells in Java source code, developed as an Eclipse plugin. The technique is based upon a Binary Logistic Regression model that uses complexity metrics as independent variables and is calibrated by expert\u201fs knowledge. An overview of the technique is provided, the tool is described and validated by an example case study.", "num_citations": "2\n", "authors": ["371"]}
{"title": "An Empirical Study on Refactoring Objects to Aspects\n", "abstract": " It has been proclaimed in the literature that AOP al-lows obtaining better modularized systems than those built with OOP, namely by reducing tangling and scattering. Very few quantitative studies sustaining that claim were published. None is known to contradict it.We briefly describe an assessment process that allows performing paradigm-independent modularity assessments, based on a metamodel driven approach, and a set of paradigm-independent metrics. We use this assessment process upon the 23 GoF design patterns that were refactored from Java to AspectJ. We then perform a set of statistical tests to answer some important research questions on the effect of refactoring on overall coupling, cohesion and modularity.", "num_citations": "2\n", "authors": ["371"]}
{"title": "Exploring and overcoming major challenges in IT infrastructures faced by IT executives\n", "abstract": " This paper aims at identifying top challenges faced by IT executives in IT infrastructures to help the formulation of meaningful research questions. The introduction of this paper describes the importance of IT infrastructures to organizations. The top challenges according to a recent survey are also introduced in the state-of-the-art section. Then, to improve our understanding and face challenges, we propose an approach based upon a research method and we describe several research techniques that we plan to use (e.g. laddering technique) and the use of empirical research in IT infrastructures. Finally, we present the expected contributions, work already performed and some preliminary results.", "num_citations": "2\n", "authors": ["371"]}
{"title": "Pedagogical patterns: picking the metaphor from the OO design community\n", "abstract": " Pedagogical Patterns are a recent proposal for formalizing and condensing the usually diffuse and scattered knowledge on proven solutions to teaching and training in software related matters. As with Design Patterns, every Pedagogical Pattern uses a common architecture including the following sections: intent, motivation, applicability, structure, consequences, implementation, related patterns, example instances and resources. Two complete pedagogical patterns, the PRCM (Peer Review and Corrective Maintenance) Pattern and the PIPR (Preparation, Industrial Presentation and Roundtable) Pattern are presented here.", "num_citations": "2\n", "authors": ["371"]}
{"title": "Metrics in the management of information systems development projects\n", "abstract": " CiNii \u8ad6\u6587 - Metrics in the management of information systems development projects CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74 \u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 CiNii\u7a93\u53e3\u696d\u52d9\u306e\u518d\u958b\u306b\u3064\u3044\u3066 Metrics in the management of information systems development projects ABREU FB \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 ABREU FB \u53ce\u9332\u520a\u884c\u7269 Proc. of the 6th Jornadas de Qualidade no Software, APQ, Lisbon, Portugal, 1992 Proc. of the 6th Jornadas de Qualidade no Software, APQ, Lisbon, Portugal, 1992, 1992 \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u6307\u5411\u5206\u6790\u30fb\u8a2d\u8a08\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u8a08\u6e2c\u30b7\u30b9\u30c6\u30e0\u306e\u4f5c\u6210 \u677e\u6751 \u5d07\u53f2 , \u5cf6 \u548c\u4e4b , \u677e\u672c \u5065\u4e00 , \u9ce5\u5c45 \u5b8f\u6b21 \u96fb\u5b50\u60c5\u5831\u901a\u4fe1\u5b66\u4f1a\u6280\u8853\u7814\u7a76\u5831\u544a. SS, \u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u30b5\u30a4\u30a8\u30f3\u30b9 96(172), 9-16, 1996-07-() \u2026", "num_citations": "2\n", "authors": ["371"]}
{"title": "PHP code smells in web apps: survival and anomalies\n", "abstract": " Context: Code smells are considered symptoms of poor design, leading to future problems, such as reduced maintainability. Except for anecdotal cases (e. g. code dropout), a code smell survives until it gets explicitly refactored or removed. This paper presents a longitudinal study on the survival of code smells for web apps built with PHP. Objectives: RQ: (i) code smells survival depends on their scope? (ii) practitioners attitudes towards code smells removal in web apps have changed throughout time? (iii) how long code smells survive in web applications? (iv) are there sudden variations (anomalies) in the density of code smells through the evolution of web apps? Method: We analyze the evolution of 6 code smells in 8 web applications written in PHP at the server side, across several years, using the survival analysis technique. We classify code smells according to scope in two categories: scattered and localized. Scattered code smells are expected to be more harmful since their influence is not circumscribed as in localized code smells. We split the observations for each web app into two equal and consecutive timeframes, to test the hypothesis that code smells awareness has increased throughout time. As for the anomalies, we standardize their detection criteria. Results: We present some evidence that code smells survival depends on their scope: the average survival rate decreases in some of them, while the opposite is observed for the remainder. The survival of localized code smells is around 4 years, while the scattered ones live around 5 years. Around 60% of the smells are removed, and some live through all the application life. We also\u00a0\u2026", "num_citations": "1\n", "authors": ["371"]}
{"title": "Unveiling process insights from refactoring practices\n", "abstract": " Context: Software comprehension and maintenance activities, such as refactoring, are said to be negatively impacted by software complexity. The methods used to measure software product and processes complexity have been thoroughly debated in the literature. However, the discernment about the possible links between these two dimensions, particularly on the benefits of using the process perspective, has a long journey ahead. Objective: To improve the understanding of the liaison of developers\u2019 activities and software complexity within a refactoring task, namely by evaluating if process metrics gathered from the IDE, using process mining methods and tools, are suitable to accurately classify different refactoring practices and the resulting software complexity. Method: We mined source code metrics from a software product after a quality improvement task was given in parallel to (117) software developers\u00a0\u2026", "num_citations": "1\n", "authors": ["371"]}
{"title": "SLAME: a Service Level Agreements Method Elicitation\n", "abstract": " IT service management (ITSM) is a set of processes aimed to support the design, operation and improvement of IT services. In ITSM context, service level management (SLM) is the process that specifically addresses the definition of IT services quality attributes (eg availability, performance, security), which are part of the service level agreements (SLAs) contracts signed between customers and providers. Nowadays, current approaches for SLAs specification, in ITSM context, are mostly based in best practices, supported by check-lists and templates. However, the utilisation of those artefacts is subjective in nature, and heavily dependent on practitioner\u2019s experience, which makes SLAs elicitation procedures, difficult of being generalized and replicated in other organizations. To tackle this issue, we propose SLAME (SLA Method Elicitation), a blend of semiformal and formal approaches for IT services quality attributes set up in SLA contracts. SLAME is underpinned by a process modeling notation (BPMN), a metamodeling language (OCL), and a goal-oriented requirements engineering approach (KAOS). SLAME is also intended to bridge the gap between business and IT communities, by ensuring the traceability among business metrics (eg number of issued documents or clients assisted), IT services metrics (eg service availability, end-to-end response time) and IT infrastructure metrics (eg servers\u2019 capacity, network performance).", "num_citations": "1\n", "authors": ["371"]}
{"title": "The Eclipse Java Metamodel: Scaffolding software engineering research on Java projects with MDE techniques\n", "abstract": " Java on the Eclipse IDE is a frequent choice for software development nowadays. Software Engineering researchers have built program analysis tools in that environment for several purposes. However, that requires a deep understanding of Eclipse internals, such as the Java AST. This paper discusses the feasibility of a metamodel-driven approach to scaffold the construction of such tools. Its core is the Eclipse Java Metamodel (EJMM), obtained through reverse engineering. The latter is instantiated with meta-objects representing the constructs of a given Java program. We then use OCL to traverse programs very easily. To validate the feasibility of our metamodel-driven approach to program analysis, we developed an Eclipse plug-in based on it, to support the metamodel-driven measurement (M2DM) approach.", "num_citations": "1\n", "authors": ["371"]}
{"title": "Contribui\u00e7\u00e3o da gest\u00e3o \u00e1gil para projectos de software: Um estudo emp\u00edrico em portais de not\u00edcias do Brasil\n", "abstract": " Muito se tem discutido, nos \u00faltimos anos, no \u00e2mbito das abordagens \u00e1geis de gest\u00e3o de projectos de desenvolvimento de software. Estas abordagens v\u00eam conquistando mais praticantes, mas escasseiam as evid\u00eancias sobre a contribui\u00e7\u00e3o real das mesmas para o sucesso dos projectos. Esta disserta\u00e7\u00e3o teve como intuito corroborar a exist\u00eancia de factores \u00e1geis contribuintes para o sucesso de projectos de software, por meio de um estudo de campo, de natureza descritiva e quantitativa, com teste de hip\u00f3teses. Foi aplicado um question\u00e1rio aos profissionais de TI dos portais de not\u00edcias do Brasil mais visitados. Optou-se por este dom\u00ednio devido ao facto de o mesmo ser caracterizado por uma grande muta\u00e7\u00e3o e agilidade nos projectos. Foram obtidas 63 respostas oriundas de 8 organiza\u00e7\u00f5es, localizadas nas cidades de S\u00e3o Paulo-SP, Rio de Janeiro-RJ e Porto Alegre-RS. Os resultados obtidos permitiram comprovar a exist\u00eancia de tr\u00eas factores \u00e1geis: i) Estrat\u00e9gias de Entregas; ii) Capacita\u00e7\u00e3o e Comprometimento da Equipa; e iii) Envolvimento do Cliente que foram contribuintes para o sucesso dos projectos de software. Esses factores foram determinados por an\u00e1lise de componentes principais, tendo como base um grande n\u00famero de pr\u00e1ticas \u00e1geis identificadas na literatura. Foi poss\u00edvel construir, por meio de regress\u00e3o log\u00edstica, um modelo de estima\u00e7\u00e3o do sucesso dos projectos baseado nos supracitados factores.", "num_citations": "1\n", "authors": ["371"]}
{"title": "Improving IT Infrastructures Representation: A UML Profile\n", "abstract": " IT infrastructures are most times informally modeled. The resulting models are ambiguous to stakeholders, cannot be checked for validity, and therefore are unable to play their important role in design, deployment and maintenance activities. The main reason for such a poor stateof-the-art lies mainly in the absence of a modeling language capable of representing IT infrastructures at the required level of abstraction. Indeed, existing candidate languages are too abstract, as shown in this paper by reviewing their metamodels. The present paper mitigates this problem by proposing a UML profile to describe the semantics of an IT infrastructure.", "num_citations": "1\n", "authors": ["371"]}
{"title": "Design Metrics for Object-Oriented Software Systems\n", "abstract": " This presentation introduces some advances towards the quantitative evaluation of design attributes of object-oriented software systems. We believe that these attributes can express the quality of internal structure, thus being strongly correlated with quality characteristics like analyzability, changeability, stability and testability, which are important to software developers and main tainers. An OO design metrics set is reviewed, along with its rationale. Several suppositions regarding the design are evaluated. Results described elsewhere show that some design heuristics can be derived and used to help guide the design process.", "num_citations": "1\n", "authors": ["371"]}