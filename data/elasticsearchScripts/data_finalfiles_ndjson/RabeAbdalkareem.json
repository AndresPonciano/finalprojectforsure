{"title": "Reasons and drawbacks of using trivial npm packages: the developers' perspective\n", "abstract": " Code reuse is traditionally seen as good practice. Recent trends have pushed the idea of code reuse to an extreme, by using packages that implement simple and trivial tasks, which we call \u2018trivial packages\u2019. A recent incident where a trivial package led to the breakdown of some of the most popular web applications such as Facebook and Netflix, put the spotlight on whether using trivial packages should be encouraged. Therefore, in this research, we mine more than 230,000 npm packages and 38,000 JavaScript projects in order to study the prevalence of trivial packages. We found that trivial packages are common, making up 16.8% of the studied npm packages. We performed a survey with 88 Node. js developers who use trivial packages to understand the reasons for and drawbacks of their use. We found that trivial packages are used because they are perceived to be well-implemented and tested pieces of code\u00a0\u2026", "num_citations": "8\n", "authors": ["785"]}
{"title": "Using Others\u2019 Tests to Identify Breaking Updates\n", "abstract": " The reuse of third-party packages has become a common practice in contemporary software development. Software dependencies are constantly evolving with newly added features and patches that fix bugs in older versions. However, updating dependencies could introduce new bugs or break backward compatibility. In this work, we propose a technique to detect breakage-inducing versions of third-party dependencies. The key insight behind our approach is to leverage the automated test suites of other projects that depend upon the same dependency to test newly released versions. We conjecture that this crowd-based approach will help to detect breakage-inducing versions because it broadens the set of realistic usage scenarios to which a package version has been exposed. To evaluate our conjecture, we perform an empirical study of 391,553 npm packages. We use the dependency network from these\u00a0\u2026", "num_citations": "5\n", "authors": ["785"]}
{"title": "Toward Software Measurement and Quality Analysis of MARF and GIPSY Case Studies, a Team 8 SOEN6611-S14 Project Report\n", "abstract": " Measurement is an important criterion to improve the performance of a product. This paper presents a comparative study involving measurements between two frameworks MARF and GIPSY. Initially it establishes a thorough understanding of these frameworks and their applications. MARF comprises of a number of algorithms for voice and speech processing etc. GIPSY on the contrary provides a multi lingual platform for developing compiler components. These frameworks are meant to provide an open source environment for the programmers or users and implement them in applications. Several metrics are used for object-oriented design quality assessment. We use these metrics to evaluate the code quality of both MARF and GIPSY. We describe how tools can be used to analyze these metric values and categorize the quality of the code as excellent or worse. Based on these values we interpret the results in terms of quality attributes achieved. Quantitative and qualitative analysis of metric values is made in this regard to elaborate the impact of design parameters on the quality of the code.", "num_citations": "4\n", "authors": ["785"]}