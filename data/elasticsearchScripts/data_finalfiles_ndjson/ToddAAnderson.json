{"title": "Forwarding and control element separation (ForCES) framework\n", "abstract": " hjp: doc: RFC 3746: Forwarding and Control Element Separation (ForCES) Framework hjp doc RFCs RFC 3746 Rfc 3746 Title Forwarding and Control Element Separation (ForCES) Framework Author L. Yang, R. Dantu, T. Anderson, R. Gopal Date April 2004 Format: TXT, HTML Status: INFORMATIONAL Network Working Group L. Yang Request for Comments: 3746 Intel Corp. Category: Informational R. Dantu Univ. of North Texas T. Anderson Intel Corp. R. Gopal Nokia April 2004 Forwarding and Control Element Separation (ForCES) Framework Status of this Memo This memo provides information for the Internet community. It does not specify an Internet standard of any kind. Distribution of this memo is unlimited. Copyright Notice Copyright (C) The Internet Society (2004). All Rights Reserved. Abstract This document defines the architectural framework for the ForCES (Forwarding and Control Element Separation) \u2026", "num_citations": "637\n", "authors": ["1708"]}
{"title": "Apparatus and method for secure, automated response to distributed denial of service attacks\n", "abstract": " An apparatus and method for secure, automated response to distributed denial of service (DDoS) attacks are described. The method includes notification of a DDoS attack received by an Internet host. Once received by an Internet host, the Internet host establishes security authentication from an upstream router from which the attack traffic, transmitted by one or more host computers, is received. The Internet host then transmits filter (s) to the upstream router generated based upon characteristics of the attack traffic. Once installed by the upstream router, the attack traffic is dropped to terminate a DDoS attack. In addition, the router may determine upstream router (s) coupled to ports from which attack traffic is received, and securely forward the filter (s) to the upstream routers as a routing protocol updated in order to drop the attack traffic at a point closer to a source of the DDoS attack.", "num_citations": "513\n", "authors": ["1708"]}
{"title": "Replication, consistency, and practicality: are these mutually exclusive?\n", "abstract": " Previous papers have postulated that traditional schemes for the management of replicated data are doomed to failure in practice due to a quartic (or worse) explosion in the probability of deadlocks. In this paper, we present results of a simulation study for three recently introduced protocols that guarantee global serializability and transaction atomicity without resorting to the two-phase commit protocol. The protocols analyzed in this paper include a global locking protocol [10], a \u201cpessimistic\u201d protocol based on a replication graph [5], and an \u201coptimistic\u201d protocol based on a replication graph [7]. The results of the study show a wide range of practical applicability for the lazy replica-update approach employed in these protocols. We show that under reasonable contention conditions and sufficiently high transaction rate, both replication-graph-based protocols outperform the global locking protocol. The distinctions among\u00a0\u2026", "num_citations": "197\n", "authors": ["1708"]}
{"title": "Requirements for separation of IP control and forwarding\n", "abstract": " hjp: doc: RFC 3654: Requirements for Separation of IP Control and Forwarding hjp doc RFCs RFC 3654 Rfc 3654 Title Requirements for Separation of IP Control and Forwarding Author H. Khosravi, Ed., T. Anderson, Ed. Date November 2003 Format: TXT, HTML Status: INFORMATIONAL Network Working Group H. Khosravi, Ed. Request for Comments: 3654 T. Anderson, Ed. Category: Informational Intel November 2003 Requirements for Separation of IP Control and Forwarding Status of this Memo This memo provides information for the Internet community. It does not specify an Internet standard of any kind. Distribution of this memo is unlimited. Copyright Notice Copyright (C) The Internet Society (2003). All Rights Reserved. Abstract This document introduces the Forwarding and Control Element Separation (ForCES) architecture and defines a set of associated terminology. This document also defines a set of \u2026", "num_citations": "193\n", "authors": ["1708"]}
{"title": "Reducing communication for reads and updates in distributed object systems\n", "abstract": " In a distributed system, a server may distribute a primary object copy having one or more chunks of data associated with a primary per-chunk metadata copy to a client over a network. The client may selectively fetch and update the one or more chunks of data of the primary object copy based on the primary per-chunk metadata copy. For example, by determining at a client whether a portion of the data in a cached data object, such as a file, is changed relative to a copy of a data object for the cached data object at a server, less than all of the data of the cached data object may be replaced with a corresponding data in the copy of the data object.", "num_citations": "146\n", "authors": ["1708"]}
{"title": "Toward internet distributed computing\n", "abstract": " Emerging Internet uses-including peer-to-peer and grid computing-provide both a glimpse of and the impetus for evolving the Internet into a distributed computing, platform of unprecedented scale. Taking a longer view, the authors consider what would be needed to make the Internet an application-hosting platform: a networked, distributed counterpart of the hosting environment traditional operating systems provide to applications within a single node. The foundation of their proposed approach is to disaggregate and virtualize individual system resources as services that can be described, discovered, and dynamically configured at runtime to execute an application.", "num_citations": "100\n", "authors": ["1708"]}
{"title": "Thread Scheduling for Multi-Core Platforms.\n", "abstract": " As multi-core processors with tens or hundreds of cores begin to proliferate, system optimization issues once faced only by the high-performance computing (HPC) community will become important to all programmers. However, unlike with HPC, the focus of the multi-core programmer will be on programming productivity and portability as much as performance. We introduce in this paper a novel scheduling framework for multi-core processors that strikes a balance between control over the system and the level of abstraction. Our framework uses high-level information supplied by the user to guide thread scheduling and also, where necessary, gives the programmer fine control over thread placement.", "num_citations": "65\n", "authors": ["1708"]}
{"title": "Optimizations in a private nursery-based garbage collector\n", "abstract": " This paper describes a garbage collector designed around the use of permanent, private, thread-local nurseries and is principally oriented towards functional languages. We try to maximize the cache hit rate by having threads continually reuse their individual private nurseries. These private nurseries operate in such a way that they can be garbage collected independently of other threads, which creates low collection pause times. Objects which survive thread-local collections are moved to a mature generation that can be collected either concurrently or in a stop-the-world fashion. We describe several optimizations (including two dynamic control parameter adaptation schemes) related to garbage collecting the private nurseries and to our concurrent collector, some of which are made possible when the language provides mutability information. We tested our collector against six benchmarks and saw single\u00a0\u2026", "num_citations": "47\n", "authors": ["1708"]}
{"title": "DERBY: A memory management system for distributed main memory databases\n", "abstract": " This paper describes a main memory data storage system for a distributed system of heterogeneous general purpose workstations. We show that distributed main memory storage managers are qualitatively different from distributed disk-based storage managers. Specifically, we show that load balancing, which is crucial to disk-based systems, has little effect on the performance of a memory-based system. On the other hand, we show that saturation prevention in cases where the server exceeds its memory capacity or becomes overloaded is crucial to smooth performance. Finally, we show that distributed memory-based storage results in performance more than one order of magnitude better than their disk-based counterparts.", "num_citations": "22\n", "authors": ["1708"]}
{"title": "HPAT: high performance analytics with scripting ease-of-use\n", "abstract": " Big data analytics requires high programmer productivity and high performance simultaneously on large-scale clusters. However, current big data analytics frameworks (eg Apache Spark) have prohibitive runtime overheads since they are library-based. We introduce a novel auto-parallelizing compiler approach that exploits the characteristics of the data analytics domain such as the map/reduce parallel pattern and is robust, unlike previous auto-parallelization methods. Using this approach, we build High Performance Analytics Toolkit (HPAT), which parallelizes high-level scripting (Julia) programs automatically, generates efficient MPI/C++ code, and provides resiliency. Furthermore, it provides automatic optimizations for scripting programs, such as fusion of array operations. Thus, HPAT is 369X to 2033X faster than Spark on the Cori supercomputer and 20X to 256X times on Amazon AWS.", "num_citations": "21\n", "authors": ["1708"]}
{"title": "Parallelizing Julia with a Non-invasive DSL\n", "abstract": " Computational scientists often prototype software using productivity languages that offer high-level programming abstractions. When higher performance is needed, they are obliged to rewrite their code in a lower-level efficiency language. Different solutions have been proposed to address this trade-off between productivity and efficiency. One promising approach is to create embedded domain-specific languages that sacrifice generality for productivity and performance, but practical experience with DSLs points to some road blocks preventing widespread adoption. This paper proposes a non-invasive domain-specific language that makes as few visible changes to the host programming model as possible. We present ParallelAccelerator, a library and compiler for high-level, high-performance scientific computing in Julia. ParallelAccelerator's programming model is aligned with existing Julia programming idioms. Our compiler exposes the implicit parallelism in high-level array-style programs and compiles them to fast, parallel native code. Programs can also run in\" library-only\" mode, letting users benefit from the full Julia environment and libraries. Our results show encouraging performance improvements with very few changes to source code required. In particular, few to no additional type annotations are necessary.", "num_citations": "21\n", "authors": ["1708"]}
{"title": "The Intel labs Haskell research compiler\n", "abstract": " The Glasgow Haskell Compiler (GHC) is a well supported optimizing compiler for the Haskell programming language, along with its own extensions to the language and libraries. Haskell's lazy semantics imposes a runtime model which is in general difficult to implement efficiently. GHC achieves good performance across a wide variety of programs via aggressive optimization taking advantage of the lack of side effects, and by targeting a carefully tuned virtual machine. The Intel Labs Haskell Research Compiler uses GHC as a frontend, but provides a new whole-program optimizing backend by compiling the GHC intermediate representation to a relatively generic functional language compilation platform. We found that GHC's external Core language was relatively easy to use, but reusing GHC's libraries and achieving full compatibility were harder. For certain classes of programs, our platform provides substantial\u00a0\u2026", "num_citations": "18\n", "authors": ["1708"]}
{"title": "Sparso: Context-driven optimizations of sparse linear algebra\n", "abstract": " The sparse matrix is a key data structure in various domains such as high-performance computing, machine learning, and graph analytics. To maximize performance of sparse matrix operations, it is especially important to optimize across the operations and not just within individual operations. While a straightforward per-operation mapping to library routines misses optimization opportunities, manually optimizing across the boundary of library routines is time-consuming and error-prone, sacrificing productivity.", "num_citations": "17\n", "authors": ["1708"]}
{"title": "Method, apparatus and system for processing message bundles on a network\n", "abstract": " Network bundles may be processed in a distributed network having a decentralized serving structure. The message bundles may be modified to include a client address. Additionally, each message bundle comprises a plurality of sub-messages, and each sub-message may contain either a link to the output of another sub-message, or a network address. A network device may be implemented to gather responses to the sub-messages from various servers and to organize the responses into a final response to send to the client.", "num_citations": "15\n", "authors": ["1708"]}
{"title": "Pillar: A parallel implementation language\n", "abstract": " As parallelism in microprocessors becomes mainstream, new prog- ramming languages and environments are emerging to meet the challenges of parallel programming. To support research on these languages, we are developing a low-level language infrastructure called Pillar (derived from Parallel Implementation Language). Although Pillar programs are intended to be automatically generated from source programs in each parallel language, Pillar programs can also be written by expert programmers. The language is defined as a small set of extensions to C. As a result, Pillar is familiar to C programmers, but more importantly, it is practical to reuse an existing optimizing compiler like gcc [1] or Open64 [2] to implement a Pillar compiler.               Pillar\u2019s concurrency features include constructs for threading, synchronization, and explicit data-parallel operations. The threading constructs focus on creating\u00a0\u2026", "num_citations": "13\n", "authors": ["1708"]}
{"title": "Measuring the Haskell gap\n", "abstract": " Papers on functional language implementations frequently set the goal of achieving performance\" comparable to C\", and sometimes report results comparing benchmark results to concrete C implementations of the same problem. A key pair of questions for such comparisons is: what C program to compare to, and what C compiler to compare with? In a 2012 paper, Satish et al [9] compare naive serial C implementations of a range of throughput-oriented benchmarks to best-optimized implementations parallelized on a six-core machine and demonstrate an average 23X (up to 53X) speedup. Even accounting for thread parallel speedup, these results demonstrate a substantial performance gap between naive and tuned C code. In this current paper, we choose a subset of the benchmarks studied by Satish et al to port to Haskell. We measure performance of these Haskell benchmarks compiled with the standard\u00a0\u2026", "num_citations": "11\n", "authors": ["1708"]}
{"title": "System and method of annotating network packets\n", "abstract": " A system and method of transmitting network packets between network processing elements through links are disclosed. One or more configuration entities may allocate one or more fixed length slots to be appended to network packets forwarded on a link between network processing elements in-band of the link.", "num_citations": "9\n", "authors": ["1708"]}
{"title": "RFC3654: Requirements for Separation of IP Control and Forwarding\n", "abstract": " This document introduces the Forwarding and Control Element   Separation (ForCES) architecture and defines a set of associated   terminology.  This document also defines a set of architectural,   modeling, and protocol requirements to logically separate the control   and data forwarding planes of an IP (IPv4, IPv6, etc.) networking   device.", "num_citations": "9\n", "authors": ["1708"]}
{"title": "An Application-Aware Data Storage Model.\n", "abstract": " We describe a new application-controlled le persistence model in which applications select the desired stability from a range of persistence guarantees. This new abstraction extends conventional abstractions by allowing applications to specify a le's volatility and methods for automatic reconstruction in case of loss. The model allows applications, particularly ones with weak persistence requirements, to leverage the memory space of other machines to improve their performance. An automated (lenamematching) interface permits legacy applications to take advantage of the variable persistence guarantees without being modi ed. Our prototype implementation shows signi cant speed-ups, in some cases more than an order of magnitude over conventional network le systems such as NFS version 3.", "num_citations": "9\n", "authors": ["1708"]}
{"title": "Requirements for the dynamic partitioning of switching elements\n", "abstract": " hjp: doc: RFC 3532: Requirements for the Dynamic Partitioning of Switching Elements hjp doc RFCs RFC 3532 Rfc 3532 Title Requirements for the Dynamic Partitioning of Switching Elements Author T. Anderson, J. Buerkle Date May 2003 Format: TXT, HTML Status: INFORMATIONAL Network Working Group T. Anderson Request for Comments: 3532 Intel Labs Category: Informational J. Buerkle Nortel Networks May 2003 Requirements for the Dynamic Partitioning of Switching Elements Status of this Memo This memo provides information for the Internet community. It does not specify an Internet standard of any kind. Distribution of this memo is unlimited. Copyright Notice Copyright (C) The Internet Society (2003). All Rights Reserved. Abstract This document identifies a set of requirements for the mechanisms used to dynamically reallocate the resources of a switching element (eg, an ATM switch) to its partitions. \u2026", "num_citations": "8\n", "authors": ["1708"]}
{"title": "Concurrent, moving, garbage collector\n", "abstract": " Electronic garbage collection moves objects within memory to consolidate the objects thereby reducing access time and improving memory performance. Transactions occurring in an atomic transactional memory appear to occur instantaneously\u2014such that the transaction completes in its entirety or is aborted. A garbage collection circuit attempts to move a memory object from a first memory location to a second memory location using a transactional fast-path move operation. If the transactional fast-path move operation is unsuccessful after a number of attempts, the garbage collection circuit attempts to move the object using a non-transactional slow-path move.", "num_citations": "7\n", "authors": ["1708"]}
{"title": "Chihuahua: A concurrent, moving, garbage collector using transactional memory\n", "abstract": " Hardware Transactional Memory (HTM) offers a powerful new parallel synchronization mechanism, but one whose performance properties are different from techniques that it competes with, such as locks and atomic instructions. Because of HTM\u2019s differing characteristics, when algorithms based on earlier synchronization mechanisms are adapted to use HTM instead, the performance may be disappointing, sometimes even appearing not to significantly outperform software transactional memory. In this paper, however, we show that HTM, and specifically its strong atomicity property, allows approaches to synchronization that would not otherwise be possible, allowing simpler synchronization algorithms than would otherwise be possible that nevertheless have promising performance.Specifically, we present a new garbage collector named Chihuahua that is designed specifically for HTM, in which garbage collector threads execute transactionally but the mutator does not. In contrast to other work which has adapted existing parallel collectors to make them transactional, Chihuahua is a transactional adaptation of a serial collector (taken from MMTk in the Jikes RVM). Although Chihuahua is a proof of concept rather than an industrial-strength, production garbage collector, we believe it highlights opportunities in the design space of garbage collectors and other parallel algorithms that are available in HTM but not available in competing techniques.", "num_citations": "7\n", "authors": ["1708"]}
{"title": "A dynamic migration algorithm for a distributed memory-based file management system\n", "abstract": " Conventional migration strategies attempt to evenly balance the load across all available server machines. The paper discusses why conventional migration approaches are not necessarily appropriate for distributed memory based file systems and presents an alternative approach that spreads data (possibly unevenly) across as few machines as possible and involves other available machines only as needed. The main advantage of our approach is that it keeps the system minimally distributed, thereby reducing the failure rate among servers, the communication overhead among servers, the time needed to compute data relocation, distributed addressing costs, and the probability of unanticipated migrations (e.g., caused by, and an inconvenience to, returning users).", "num_citations": "6\n", "authors": ["1708"]}
{"title": "Variable write back delay apparatus and methods\n", "abstract": " Variable write back delay apparatus, methods and articles of manufacture are disclosed. The disclosed variable write back delay apparatus, methods and articles of manufacture identify a probability associated with a loss of a file and determine the write back delay based on the probability associated with the loss of the file. The disclosed apparatus, methods and articles of manufacture associate a write back delay with each file that results in a minimal expected total time cost of recreating and storing that file.", "num_citations": "5\n", "authors": ["1708"]}
{"title": "Portable just-in-time compilation in managed runtime environments\n", "abstract": " The portability of a just-in-time compiler may be increased by enabling it to inquire as to the need, during the just-in-time compilation, for special byte code from a managed runtime environment in which it may be employed. This may be useful, for example, to permit a just-in-time compiler to be compatible with different managed runtime environments that implement various operations in various ways. Such operations may include garbage collection, storage of values for static fields, threading, or exception handling.", "num_citations": "5\n", "authors": ["1708"]}
{"title": "Intel Corp.\n", "abstract": " Forwarding and Control Element Separation (ForCES) Framework Status of this Memo This memo provides information for the Internet community. It does not specify an Internet standard of any kind. Distribution of this memo is unlimited. Copyright Notice Copyright (C) The Internet Society (2004). All Rights Reserved. This document defines the architectural framework for the ForCES (Forwarding and Control Element Separation) network elements, and identifies the associated entities and their interactions.", "num_citations": "4\n", "authors": ["1708"]}
{"title": "Learning Fitness Functions for Machine Programming\n", "abstract": " The problem of automatic software generation has been referred to as machine programming. In this work, we propose a framework based on genetic algorithms to help make progress in this domain. Although genetic algorithms (GAs) have been successfully used for many problems, one criticism is that hand-crafting GAs fitness function, the test that aims to effectively guide its evolution, can be notably challenging. Our framework presents a novel approach to learn the fitness function using neural networks to predict values of ideal fitness functions. We also augment the evolutionary process with a minimally intrusive search heuristic. This heuristic improves the framework\u2019s ability to discover correct programs from ones that are approximately correct and does so with negligible computational overhead. We compare our approach with several state-of-the-art program synthesis methods and demonstrate that it finds more correct programs with fewer candidate program generations.", "num_citations": "3\n", "authors": ["1708"]}
{"title": "HiFrames: High Performance Data Frames in a Scripting Language\n", "abstract": " Data frames in scripting languages are essential abstractions for processing structured data. However, existing data frame solutions are either not distributed (e.g., Pandas in Python) and therefore have limited scalability, or they are not tightly integrated with array computations (e.g., Spark SQL). This paper proposes a novel compiler-based approach where we integrate data frames into the High Performance Analytics Toolkit (HPAT) to build HiFrames. It provides expressive and flexible data frame APIs which are tightly integrated with array operations. HiFrames then automatically parallelizes and compiles relational operations along with other array computations in end-to-end data analytics programs, and generates efficient MPI/C++ code. We demonstrate that HiFrames is significantly faster than alternatives such as Spark SQL on clusters, without forcing the programmer to switch to embedded SQL for part of the program. HiFrames is 3.6x to 70x faster than Spark SQL for basic relational operations, and can be up to 20,000x faster for advanced analytics operations, such as weighted moving averages (WMA), that the map-reduce paradigm cannot handle effectively. HiFrames is also 5x faster than Spark SQL for TPCx-BB Q26 on 64 nodes of Cori supercomputer.", "num_citations": "3\n", "authors": ["1708"]}
{"title": "Methods and apparatus to preemptively compile an application\n", "abstract": " Methods and apparatus to preemptively compile an application are disclosed. In an example method, at least one preemptive compilation thread (PCT) is generated. Data associated with at least one method of the application is identified in a preemptive compilation priority queue (PCPQ). The at least one method identified in the PCPQ is converted into native code by executing the PCT.", "num_citations": "3\n", "authors": ["1708"]}
{"title": "Learning Fitness Functions for Genetic Algorithms\n", "abstract": " A genetic algorithm (GA) attempts to solve a problem using a pool of potential solutions that are iteratively refined using various selection techniques. Although GAs have been used successfully for many problems, one criticism is that hand-crafting a GA's fitness function, the test that aims to effectively guide its evolution, can be notably challenging. Moreover, the complexity of a GA's fitness function tends to grow proportionally with the complexity of the problem being solved. In this work, we present a novel approach to learn a GA's fitness function. For the purpose of simplicity, we limit the demonstration of this technique to automatic software program generation. However, our system has no specific restrictions that prevent it from being applied to other domains. We also augment the GA evolutionary process with a minimally intrusive search heuristic. This heuristic improves the GA's ability to discover correct programs from ones that are approximately correct and does so with negligible computational overhead. We compare our approach to two state-of-the-art program generation systems and demonstrate that it finds more correct programs with fewer candidate program generations.", "num_citations": "2\n", "authors": ["1708"]}
{"title": "Technologies for automatic reordering of sparse matrices\n", "abstract": " Technologies for automatic reordering of sparse matrices include a computing device to determine a distributivity of an expression defined in a code region of a program code. The expression is determined to be distributive if semantics of the expression are unaffected by a reordering of an input/output of the expression. The computing device performs inter-dependent array analysis on the expression to determine one or more clusters of inter-dependent arrays of the expression, wherein each array of a cluster of the one or more clusters is inter-dependent on each other array of the cluster, and performs bi-directional data flow analysis on the code region by iterative backward and forward propagation of reorderable arrays through expressions in the code region based on the one or more clusters of the inter-dependent arrays. The backward propagation is based on a backward transfer function and the forward\u00a0\u2026", "num_citations": "2\n", "authors": ["1708"]}
{"title": "Experience Integrating a New Compiler and a New Garbage Collector Into Rotor.\n", "abstract": " We found it easier to integrate our JIT than our GC because Rotor has a well-defined interface for the former but not the latter. However, our JIT integration still required significant changes to both Rotor and our JIT. For example, we modified Rotor to support multiple JITs. We also added support for a second JIT manager in Rotor, and implemented a new code manager compatible with our JIT. We had to change our JIT compiler to support Rotor\u2019s calling conventions, helper functions, and exception model. Our GC integration was complicated by the many places in Rotor where components make assumptions about how its garbage collector is implemented, as well as Rotor\u2019s lack of a well-defined GC interface. We also had to reconcile the different assumptions made by Rotor and our garbage collector about the layout of objects, virtual-method tables, and thread structures.", "num_citations": "2\n", "authors": ["1708"]}
{"title": "RFC3532: Requirements for the Dynamic Partitioning of Switching Elements\n", "abstract": " This document identifies a set of requirements for the mechanisms   used to dynamically reallocate the resources of a switching element   (e.g., an ATM switch) to its partitions.  These requirements are   particularly critical in the case of an operator creating a switch   partition and then leasing control of that partition to a third   party.", "num_citations": "2\n", "authors": ["1708"]}
{"title": "Apparatus and methods for program synthesis using genetic algorithms\n", "abstract": " Example apparatus and methods for program synthesis using genetic algorithms are disclosed herein. An example apparatus includes a program length predictor to predict a length of a first program by executing a first neural network model, a program generator to generate a candidate program having a length corresponding to the predicted length, a candidate program analyzer to generate a fitness score for the candidate program by executing a second neural network model and to identify the first candidate program for use in a breeding operation relative a second candidate program based on the fitness score, and a genetic program generator to perform the breeding operation with at least one of the first candidate program or the second candidate program to generate an evolved candidate program.", "num_citations": "1\n", "authors": ["1708"]}
{"title": "Mbfs: a memory-based file system\n", "abstract": " Although hardware is improving at a phenomenal rate, file systems have prevented applications from realizing similar performance improvements. Slow application performance is largely due to file systems' one-size-fits-all persistence model that guarantees disk persistence for all files. This dissertation describes a new application-controlled persistence model in which applications can select the desired file storage stability from a range of persistence guarantees and provides methods for automatic file reconstruction in case of unexpected loss. The model allows applications, particularly ones with weak persistence requirements, to avoid the performance penalties of conventional disk-persistence file-system designs by leveraging idle remote memory. The system combines the memory resources of idle machines into a large high-speed volatile storage space. As idle memory resources in the system move, a\u00a0\u2026", "num_citations": "1\n", "authors": ["1708"]}