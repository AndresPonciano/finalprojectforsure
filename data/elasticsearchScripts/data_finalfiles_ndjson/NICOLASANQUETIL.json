{"title": "Experiments with clustering as a software remodularization method\n", "abstract": " As valuable software systems get old, reverse engineering becomes more and more important to the companies that have to maintain the code. Clustering is a key activity in reverse engineering to discover a better design of the systems or to extract significant concepts from the code. Clustering is an old activity, highly sophisticated, offering many methods to answer different needs. Although these methods have been well documented in the past, these discussions may not apply entirely to the reverse engineering domain. We study some clustering algorithms and other parameters to establish whether and why they could be used for software remodularization. We study three aspects of the clustering activity: abstract descriptions chosen for the entities to cluster; metrics computing coupling between the entities; and clustering algorithms. The experiments were conducted on three public domain systems (gcc, Linux\u00a0\u2026", "num_citations": "433\n", "authors": ["67"]}
{"title": "An examination of software engineering work practices\n", "abstract": " This paper presents work practice data of the daily activities of software engineers. Four separate studies are presented; one looking longitudinally at an individual SE; two looking at a software engineering group; and one looking at company-wide tool usage statistics. We also discuss the advantages in considering work practices in designing tools for software engineers, and include some requirements for a tool we have developed as a result of our studies.", "num_citations": "403\n", "authors": ["67"]}
{"title": "Extracting concepts from file names: a new file clustering criterion\n", "abstract": " Decomposing complex software systems into conceptually independent subsystems is a significant software engineering activity which received considerable research attention. Most of the research in this domain considers the body of the source code; trying to cluster together files which are conceptually related. We discuss techniques for extracting concepts (abbreviations) from a more informal source of information: file names. The task is difficult because nothing indicates where to split the file names into substrings. In general, finding abbreviations would require domain knowledge to identify the concepts that are referred to in a name and intuition to recognize such concepts in abbreviated forms. We show by experiment that the techniques we propose allow about 90% of the abbreviations to be found automatically.", "num_citations": "154\n", "authors": ["67"]}
{"title": "Recovering software architecture from the names of source files\n", "abstract": " We discuss how to extract a useful set of subsystems from a set of existing source\u2010code file names. This problem is challenging because many legacy systems use thousands of files names, including some that are very short and cryptic. At the same time the problem is important because software maintainers often find it difficult to understand such systems.  We propose a general algorithm to cluster files based on their names, and a set of alternative methods for implementing the algorithm. One of the key tasks is picking candidate words to try to identify in file names. We do this by (a) iteratively decomposing file names, (b) finding common substrings, and (c) choosing words in routine names, in an English dictionary or in source\u2010code comments. In addition, we investigate generating abbreviations from the candidate words in order to find matches in file names, as well as how to split file names into components\u00a0\u2026", "num_citations": "149\n", "authors": ["67"]}
{"title": "Assessing the relevance of identifier names in a legacy software system\n", "abstract": " Reverse engineering is a di cult task even for humans. When trying to provide tools to assist in this task, one should try to take advantage of all possible sources of information. Informal sources, like naming conventions, are more abstract than the code, thus helping to bridge the gap between code and design. On the other hand, there is no certainty that they actually represent the current state of the system.", "num_citations": "139\n", "authors": ["67"]}
{"title": "Architecture of a source code exploration tool: A software engineering case study\n", "abstract": " We discuss the design of a software system that helps software engineers (SE\u2019s) to perform the task we call just in time comprehension (JITC) of large bodies of source code. We discuss the requirements for such a system and how they were gathered by studying SE\u2019s at work. We then analyze our requirements with respect to other tools available to SE\u2019s for the JITC task. Next, we walk through system design and the objectoriented analysis process for our system, discussing key design issues. Some issues, such as dealing with multi-part names and conditional compilation are unexpectedly complex.", "num_citations": "66\n", "authors": ["67"]}
{"title": "Comparative study of clustering algorithms and abstract representations for software remodularisation\n", "abstract": " As valuable software systems become older, reverse engineering becomes increasingly important to companies that have to maintain the code. Clustering is a key activity in reverse engineering that is used to discover improved designs of systems or to extract significant concepts from code. Clustering is an old, highly sophisticated, activity which offers many methods to meet different needs. The various methods have been well documented in the past; however, conclusions from general clustering literature may not apply entirely to the reverse engineering domain. In the paper, the authors study three decisions that need to be made when clustering: the choice of (i) abstract descriptions of the entities to be clustered, (ii) metrics to compute coupling between the entities, and (iii) clustering algorithms. For each decision, our objective is to understand which choices are best when performing software remodularisation\u00a0\u2026", "num_citations": "65\n", "authors": ["67"]}
{"title": "Legacy software restructuring: Analyzing a concrete case\n", "abstract": " Software re-modularization is an old preoccupation of reverse engineering research. The advantages of a well structured or modularized system are well known. Yet after so much time and efforts, the field seems unable to come up with solutions that make a clear difference in practice. Recently, some researchers started to question whether some basic assumptions of the field were not overrated. The main one consists in evaluating the high-cohesion/low-coupling dogma with metrics of unknown relevance. In this paper, we study a real structuring case (on the Eclipse platform) to try to better understand if (some) existing metrics would have helped the software engineers in the task. Results show that the cohesion and coupling metrics used in the experiment did not behave as expected and would probably not have helped the maintainers reach there goal. We also measured another possible restructuring which is\u00a0\u2026", "num_citations": "64\n", "authors": ["67"]}
{"title": "Traceability for model driven, software product line engineering\n", "abstract": " Traceability is an important challenge for software organizations. This is true for traditional software development and even more so in new approaches that introduce more variety of artefacts such as Model Driven development or Software Product Lines. In this paper we look at some aspect of the interaction of Traceability, Model Driven development and Software Product Line.", "num_citations": "64\n", "authors": ["67"]}
{"title": "File clustering using naming conventions for legacy systems\n", "abstract": " Decomposing complex software systems into conceptually independent subsystems represents a signicant software engineering activity that receives considerable research attention. Most of the research in this domain deals with the source code; trying to cluster together les which are conceptually related. In this paper we propose using a more informal source of information: le names. We present an experiment which shows that le naming convention is the best le clustering criteria for the software system we are studying. Based on the experiment results, we also sketch a method to build a conceptual browser on a software system.", "num_citations": "63\n", "authors": ["67"]}
{"title": "Predicting software defects with causality tests\n", "abstract": " In this paper, we propose a defect prediction approach centered on more robust evidences towards causality between source code metrics (as predictors) and the occurrence of defects. More specifically, we rely on the Granger causality test to evaluate whether past variations in source code metrics values can be used to forecast changes in time series of defects. Our approach triggers alarms when changes made to the source code of a target system have a high chance of producing defects. We evaluated our approach in several life stages of four Java-based systems. We reached an average precision greater than 50% in three out of the four systems we evaluated. Moreover, by comparing our approach with baselines that are not based on causality tests, it achieved a better precision.", "num_citations": "53\n", "authors": ["67"]}
{"title": "Aspect-oriented, model-driven software product lines: The AMPLE way\n", "abstract": " Software product lines provide a systematic means of managing variability in a suite of products. They have many benefits but there are three major barriers that can prevent them from reaching their full potential. First, there is the challenge of scale: a large number of variants may exist in a product line context and the number of interrelationships and dependencies can rise exponentially. Second, variations tend to be systemic by nature in that they affect the whole architecture of the software product line. Third, software product lines often serve different business contexts, each with its own intricacies and complexities. The AMPLE (http://www. ample-project. net/) approach tackles these three challenges by combining advances in aspect-oriented software development and model-driven engineering. The full suite of methods and tools that constitute this approach are discussed in detail in this edited volume and illustrated using three real-world industrial case studies.", "num_citations": "51\n", "authors": ["67"]}
{"title": "Uncovering causal relationships between software metrics and bugs\n", "abstract": " Bug prediction is an important challenge for software engineering research. It consist in looking for possible early indicators of the presence of bugs in a software. However, despite the relevance of the issue, most experiments designed to evaluate bug prediction only investigate whether there is a linear relation between the predictor and the presence of bugs. However, it is well known that standard regression models cannot filter out spurious relations. Therefore, in this paper we describe an experiment to discover more robust evidences towards causality between software metrics (as predictors) and the occurrence of bugs. For this purpose, we have relied on Granger Causality Test to evaluate whether past changes in a given time series are useful to forecast changes in another series. As its name suggests, Granger Test is a better indication of causality between two variables. We present and discuss the results of\u00a0\u2026", "num_citations": "45\n", "authors": ["67"]}
{"title": "A comparison of graphs of concept for reverse engineering\n", "abstract": " To group related things together (for example to form subsystems), researchers in reverse engineering are looking for algorithms that create meaningful groups. One such algorithm, concept analysis, received a lot of interest recently. It creates a lattice of concepts which have some advantages over the more traditional tree of clusters from clustering algorithms. We argue that the main interest of concept analysis lies in the concepts themselves and can be disconnected from the particular structure (the lattice of concepts) in which the concepts are usually arranged. We compare concept analysis to various other algorithms trying to select the most important concepts contained in a set of entities. Our main conclusion is that although it has advantages, the lattice of concepts suffers from a major drawback that other constructs do not have: it returns much more information (concepts) than it was given as input (a set of\u00a0\u2026", "num_citations": "42\n", "authors": ["67"]}
{"title": "Remodularization analysis using semantic clustering\n", "abstract": " In this paper, we report an experience on using and adapting Semantic Clustering to evaluate software remodularizations. Semantic Clustering is an approach that relies on information retrieval and clustering techniques to extract sets of similar classes in a system, according to their vocabularies. We adapted Semantic Clustering to support remodularization analysis. We evaluate our adaptation using six real-world remodularizations of four software systems. We report that Semantic Clustering and conceptual metrics can be used to express and explain the intention of the architects when performing common modularization operators, such as module decomposition.", "num_citations": "37\n", "authors": ["67"]}
{"title": "Knowledge for software maintenance\n", "abstract": " Knowledge management is emerging as a promising area to support software engineering activities. The general idea is to use knowledge gained in previous projects to help future ones. We believe this approach is even more relevant when considering software maintenance where maintainers often have to modify a system that they did not develop, that has no documentation, and that nobody knows intimately. Contrasting with this lack of information on the system, maintainers need a lot of knowledge: about the application domain, the organization software maintenance procedures, the system itself, the language used, past development methods, etc. Although one can readily agree with this fact, there is no clear, exhaustive definition of what knowledge would be useful to perform software maintenance. In this paper we describe our research to identify these needs. This research is part of a long term project that aims at building a knowledge management system for software maintenance.", "num_citations": "37\n", "authors": ["67"]}
{"title": "An empirical model for continuous and weighted metric aggregation\n", "abstract": " It is now understood that software metrics alone are not enough to characterize software quality. To cope with this problem, most of advanced and/or industrially validated quality models aggregate software metrics: for example, cyclomatic complexity is combined with test coverage to stress the fact that it is more important to cover complex methods than accessors. Yet, aggregating and weighting metrics to produce quality indexes is a difficult task. Indeed, certain weighting approaches may lead to abnormal situations where a developer increasing the quality of a software component seeing the overall quality degrade. Finally, mapping combinations of metric values to quality indexes may be a problem when using thresholds. In this paper, we present the problems we faced when designing the Squale quality model, then we present an empirical solution based on weighted aggregations and on continuous functions\u00a0\u2026", "num_citations": "29\n", "authors": ["67"]}
{"title": "A disturbing result on the knowledge used during software maintenance\n", "abstract": " As part of a long term project aiming at empowering software maintainers with knowledge based tools, we conducted an empirical study on the knowledge they use when doing maintenance. The study was intended as a preliminary work to get initial data on the type on knowledge used and the importance of each type of knowledge. For example, it is commonly assumed that application domain knowledge is important when doing maintenance. However nobody can tell exactly how much more important it is than Computer Science knowledge. We monitored six software engineers in two different organizations and analyzed the knowledge they used in their maintenance activity. In this paper we present and discuss some results and propose research directions from these. Our results include: the fact that software engineers rarely \"search for\" some new knowledge and rather work from what they already know; or the\u00a0\u2026", "num_citations": "25\n", "authors": ["67"]}
{"title": "Javacompext: Extracting architectural elements from java source code\n", "abstract": " Software architecture erosion is a general problem in legacy software. To fight this trend, component models and languages are designed to try to make explicit, and automatically enforceable, the architectural decisions in terms of components, interfaces, and allowed communication channels between component interfaces. To help maintainers work on existing object-oriented systems, we explore the possibility of extracting architectural elements (components, communications, services, ...) from the source code. We designed a tool based on some heuristics for extracting component information from Java source code.", "num_citations": "21\n", "authors": ["67"]}
{"title": "A mapping study on architecture-driven modernization\n", "abstract": " Background: Perhaps the most common of all software engineering activities is the modernization of software. Unfortunately, during such modernization often leaves behind artifacts that are difficult to understand for those other than its author. Thus, the Object Management Group (OMG) has defined standards in the modernization process, by creating the concept of Architecture-Driven Modernization (ADM). Nevertheless, to the best of our knowledge, there is no a systematic mapping study providing an overview of how researchers have been employing ADM. Thus, we assert that there is a need for a more systematic investigation of the topics encompassed by this research area. Objective: To describe a systematic mapping study on ADM, highlighting the main research thrusts in this field. Method: We undertook a systematic mapping study, emphasizing the most important electronic databases. Results: We identified\u00a0\u2026", "num_citations": "15\n", "authors": ["67"]}
{"title": "OZONE: Layer Identification in the presence of Cyclic Dependencies\n", "abstract": " A layered software architecture helps in understanding the role of software entities (e.g. packages or classes) in a system and, hence, the impact of changes on these entities. However, the computation of an optimal layered organization in the presence of cyclic dependencies is difficult. In this paper, we present an approach that (i) provides a strategy supporting the automated detection of cyclic dependencies, (ii) proposes heuristics to break cyclic dependencies, and (iii) computes an organization of software entities in multiple layers even in the presence of cyclic dependencies. Our approach performs better than the other existing approaches in terms of accuracy and interactivity, and it supports human inputs and constraints. In this paper, we present this approach and compare it to existing solutions. We applied our approach on two large software systems to identify package layers and the results are manually\u00a0\u2026", "num_citations": "14\n", "authors": ["67"]}
{"title": "Characterizing the informal knowledge contained in systems\n", "abstract": " Program comprehension of legacy systems is a highly knowledge-intensive task. One of the goals of reverse engineering is to propose automated help to relate application domain concepts to all their implementation instances. It is generally accepted that to do so would require analyzing such documentation as identifiers or comments. However, before attempting to perform this difficult analysis, it would be useful to know precisely what information the documentation contains and if it is worth trying. In this paper, we present the results of a study of the knowledge contained in two sources of documentation for the Mosaic system. This knowledge is categorized into various domains, and the relative proportions of these domains are discussed. Among other things, the results highlight the high frequency with which application domain concepts are used, which could provide the means to identify them.", "num_citations": "13\n", "authors": ["67"]}
{"title": "Extracting Hierarchical graphs of concepts from an object set: Comparison of two methods\n", "abstract": " Understanding something is to discover the important notions it implies, explaining it is mainly to regurgitate these important notions. Computers, with their abilities to rapidly treats large amount of information, has long been expected to do so. Wille's lattice of concepts 14 is a good mean of browsing through a set of objects and the concepts they embed, but for large corpus there are so many concepts that the user get overwhelmed by the amount of information. An other solution is to extract the concepts using a clustering technique 7, but there are other inconveniences (time complexity of the algorithms, no incremental algorithms).In this article, we present a method that takes advantage of both approaches, starting from a lattice of concepts, it selects the most relevant ones to ease the understanding of the whole data corpus. We will compare the extracted concept set of both method, to underline each one strength and weakness.", "num_citations": "13\n", "authors": ["67"]}
{"title": "Approaches to clustering for program comprehension and remodularization\n", "abstract": " When presented with a large legacy system which has little design information, an important approach to understanding and maintaining it is to automatically divide it into a more understandable set of modules or subsystems\u2014a process called remodularization.", "num_citations": "9\n", "authors": ["67"]}
{"title": "A systematic review on mining techniques for crosscutting concerns\n", "abstract": " ABSTRACT< u> Background:</u> The several maintenance tasks a system is submitted during its life usually cause its architecture deviates from the original conceivable design, ending up with scattered and tangled concerns across the software. The research area named concern mining attempts to identify such scattered and tangled concerns to support maintenance and reverse-engineering.< u> Objectives:</u> The aim of this paper is threefold:(i) identifying techniques employed in this research area,(ii) extending a taxonomy available on the literature and (iii) recommending an initial combination of some techniques.< u> Results:</u> We selected 62 papers by their mining technique. Among these papers, we identified 18 mining techniques for crosscutting concern. Based on these techniques, we have extended a taxonomy available in the literature, which can be used to position each new technique, and to compare it with the existing ones along relevant dimensions. As consequence, we present\u00a0\u2026", "num_citations": "8\n", "authors": ["67"]}
{"title": "Analysing microsoft access projects: building a model in a partially observable domain\n", "abstract": " Due to the technology evolution, every IT Company migrates their software systems at least once. Reengineering tools build system models which are used for running software analysis. These models are traditionally built from source code analysis and information accessible by data extractors (that we call such information observable). In this article we present the case of Microsoft Access projects and how this kind of project is partially observable due to proprietary storing formats. We propose a novel approach for building models that allows us to overcome this problem by reverse engineering the development environment runtime through the usage of Microsoft COM interface. We validate our approach and implementation by fully replicating 10 projects, 8 of them industrial, based only on our model information. We measure the replication performance by measuring the errors during the process and\u00a0\u2026", "num_citations": "5\n", "authors": ["67"]}
{"title": "Ten years later, experiments with clustering as a software remodularization method\n", "abstract": " In this talk we will first review our research program that led to the paper which has been designated the most influential paper from WCRE 1999. The paper discussed a wide variety of aspects to be considered when clustering software, including formal and nonformal descriptive features, the types of links, the similarity metrics, the clustering algorithms themselves, as well as criteria to evaluation experimental results. In addition to presenting our results published in WCRE ten years ago, we will also take a look at some of our other work on this topic and follow the literature since then to see how others have built on our work, including at least 20 papers that directly cite our research. We will conclude by discussing opportunities that remain for future research.", "num_citations": "5\n", "authors": ["67"]}
{"title": "Topicviewer: Evaluating remodularizations using semantic clustering\n", "abstract": " Software visualization techniques have been proposed to improve program comprehension, as large systems get difficult to understand and maintain. In this paper, we describe the design and main features of TopicViewer, a tool that uses Information Retrieval techniques and Hierarchical Clustering to show how domain concepts are disposed across one system\u2019s architecture as it evolves. Also, we describe an application of this tool during the remodularization of JHotDraw.", "num_citations": "3\n", "authors": ["67"]}
{"title": "Concepts+ Relations=\u201cAbstract Constructs\u201d\n", "abstract": " The goal of Reverse Engineering is to create an abstract representation of a system, identifying the concepts it implements and the relations between them. Both kind of information (concepts and relationships) have been the subject of various studies, but there are very few works that actually consider them jointly. In this article, we propose a method trying to remedy this deficiency. We will present some experiments we performed on the Mosaic system and discuss their results. They show that our method is successful and can actually extract significant conceptual information. Examples of discovery of subsystem wrapping or extraction of concepts inheritance hierarchy are presented.", "num_citations": "3\n", "authors": ["67"]}
{"title": "Meta-knowledge for the object model: Simple as NOT\n", "abstract": " Use of the object model as a modeling tool introduces new needs, like the quest for more expressiveness. Some look for meta-knowledge speci cation and re exivity, re-users need to specify object frameworks, developers want to use multiple views, other want to solve constraints, etc. However, negation, one of the most powerful tools of knowledge representation, seems to be neglected.", "num_citations": "3\n", "authors": ["67"]}
{"title": "Acquisition et classification de concepts pour la r eutilisation\n", "abstract": " Reutiliser un composant logiciel (procedure, classe, structure de donnee,) c'est avant tout le retrouver dans une base de composant logiciels reutilisables, c'est a dire pouvoir disposer d'un systeme ecace de classication et de depistage. Nous presentons ici une methode realisant ces operations. Elle procede par d'acquisition de concepts a partir d'une base de composants logiciels. Les concepts decouverts sont organises en un graphe hierarchique qui favorise la recherche et la navigation dans la base de composants. Notre methode fait appel a des algorithmes statistiques tels que le clustering, elle est independante du domaine considere et est completement automatique.", "num_citations": "3\n", "authors": ["67"]}