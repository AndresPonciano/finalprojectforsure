{"title": "RE: a good practice guide\n", "abstract": " 1. Define a standard structure 2. Make a document easy to change 3. Uniquely identify each requirements 4. Define policies for requirements management 5. Define standard template for requirements description 6. Use language simply, consistently and concisely 7. Organise formal requirements inspection 8. Define validation checklist 9. Use checklist for requirements analysis 10. Plan for conflicts and conflict resolution", "num_citations": "2380\n", "authors": ["1452"]}
{"title": "Ethnographically-informed systems design for air traffic control\n", "abstract": " This paper relates experiences of a project where an ethnographic study of air traffic controllers is being used to inform the design of the controllers\u2019 interface to the flight data base. We outline the current UK air traffic control system, dkcuss the ethnographic work we have undertaken studying air traffic control as a cooperative activity, describe some of the difficulties in collaboration between software developers and sociologists and show how the ethnographic studies have influenced the systems design process. Our conclusions are that ethnographic studies are helpful in informing the systems design process and may produce insights which contradict conventional thinking in systems design.", "num_citations": "632\n", "authors": ["1452"]}
{"title": "Viewpoints: principles, problems and a practical approach to requirements engineering\n", "abstract": " The paper includes a survey and discussion of viewpoint\u2010oriented approaches to requirements engineering and a presentation of new work in this area which has been designed with practical application in mind. We describe the benefits of viewpoint\u2010oriented requirements engineering and describe the strengths and weaknesses of a number of viewpoint\u2010oriented methods. We discuss the practical problems of introducing viewpoint\u2010oriented requirements engineering into industrial software engineering practice and why these have prevented the widespread use of existing approaches.               We then introduce a new model of viewpoints called Preview. Preview viewpoints are flexible, generic entities which can be used in different ways and in different application domains. We describe the novel characteristics of the Preview viewpoints model and the associated processes of requirements discovery\u00a0\u2026", "num_citations": "334\n", "authors": ["1452"]}
{"title": "Requirements elicitation: Towards the unknown unknowns\n", "abstract": " Requirements elicitation research is reviewed using a framework categorising the relative `knowness' of requirements specification and Common Ground discourse theory. The main contribution of this survey is to review requirements elicitation from the perspective of this framework and propose a road map of research to tackle outstanding elicitation problems involving tacit knowledge. Elicitation techniques (interviews, scenarios, prototypes, etc.) are investigated, followed by representations, models and support tools. The survey results suggest that elicitation techniques appear to be relatively mature, although new areas of creative requirements are emerging. Representations and models are also well established although there is potential for more sophisticated modelling of domain knowledge. While model-checking tools continue to become more elaborate, more growth is apparent in NL tools such as text\u00a0\u2026", "num_citations": "219\n", "authors": ["1452"]}
{"title": "Survey of aspect-oriented analysis and design approaches\n", "abstract": " A number of Aspect-Oriented (AO) Requirements, Architecture, and Design approaches have emerged recently. In this report we survey the most significant of these approaches, considering their origins, aims, and contributions. Alongside the AO approaches, we also analyse some of the contemporary non-AO work in order to bring out the differences between two sets of techniques, and to understand the potential contributions of aspect-oriented analysis and design. We also provide some initial insights into processes for AO requirements engineering, analysis and design which may serve as basis for integration of the work of the AOSD- EUROPE project partners. We also outline some issues relevant to such integration.", "num_citations": "131\n", "authors": ["1452"]}
{"title": "Architectural support for cooperative multiuser interfaces\n", "abstract": " Computer support for cooperative work requires the construction of applications that support interaction by multiple users. The highly dynamic and flexible nature of cooperative work makes the need for rapid user-interface prototyping a central concern. We have designed and developed a software architecture that provides mechanisms to support rapid multiuser-interface construction and distributed user-interface management. Rapid prototyping requires mechanisms that make the information determining interface configuration visible, accessible, and tailorable. We developed the architecture as part of a project investigating support for the cooperative work of air traffic controllers. Extensive use of prolonged ethnographic investigation helped to uncover the nature of cooperation in air traffic control. The aim of the architecture is to support an environment in which a multidisciplinary team can experiment with a wide\u00a0\u2026", "num_citations": "131\n", "authors": ["1452"]}
{"title": "Requirements process improvement through the phased introduction of good practice\n", "abstract": " Current process improvement and maturity models pay little attention to requirements engineering. Typically, requirements engineering is considered to be a single activity in the overall development process. Even where this is not strictly the case, the requirements activities are not elaborated in sufficient detail to permit the derivation of an improvement plan. This is unfortunate because requirements engineering is increasingly recognized as a problem. Despite the regular improvement of techniques for eliciting, analysing, validating and managing requirements, even otherwise mature organizations repeatedly experience requirements problems. This paper describes a good practice\u2010based approach to requirements engineering process improvement which aims to fill the gap left by existing process improvement methods. This distils practical information from over 60 requirements practices and provides a\u00a0\u2026", "num_citations": "121\n", "authors": ["1452"]}
{"title": "Shallow knowledge as an aid to deep understanding in early phase requirements engineering\n", "abstract": " Requirements engineering's continuing dependence on natural language description has made it the focus of several efforts to apply language engineering techniques. The raw textual material that forms an input to early phase requirements engineering and which informs the subsequent formulation of the requirements is inevitably uncontrolled and this makes its processing very hard. Nevertheless, sufficiently robust techniques do exist that can be used to aid the requirements engineer provided that the scope of what can be achieved is understood. In this paper, we show how combinations of lexical and shallow semantic analysis techniques developed from corpus linguistics can help human analysts acquire the deep understanding needed as the first step towards the synthesis of requirements.", "num_citations": "112\n", "authors": ["1452"]}
{"title": "Dynamically adaptive systems are product lines too: Using model-driven techniques to capture dynamic variability of adaptive systems\n", "abstract": " In this paper we propose an approach to support the design and operation of dynamically adaptive systems. We apply the concept of variability modeling from software product lines to define how systems adapt at runtime to changes in their environment. Our approach models two dynamic variability dimensions; environment variability, which defines the conditions under which a system must adapt, and structural variability which defines the resulting architectural configurations. The variability dimensions identified are modeled using domain-specific languages (DSMLs) tailored to adaptive middleware technologies that provide support for runtime variability according to reconfiguration policies. We describe our experience with applying this approach through a case study; the design of a flood warning system.", "num_citations": "108\n", "authors": ["1452"]}
{"title": "The case for dumb requirements engineering tools\n", "abstract": " [Context and Motivation] This paper notes the advanced state of the natural language (NL) processing art and considers four broad categories of tools for processing NL requirements documents. These tools are used in a variety of scenarios. The strength of a tool for a NL processing task is measured by its recall and precision. [Question/Problem] In some scenarios, for some tasks, any tool with less than 100% recall is not helpful and the user may be better off doing the task entirely manually. [Principal Ideas/Results] The paper suggests that perhaps a dumb tool doing an identifiable part of such a task may be better than an intelligent tool trying but failing in unidentifiable ways to do the entire task. [Contribution] Perhaps a new direction is needed in research for RE tools.", "num_citations": "96\n", "authors": ["1452"]}
{"title": "Towards requirements aware systems: Run-time resolution of design-time assumptions\n", "abstract": " In earlier work we proposed the idea of requirements-aware systems that could introspect about the extent to which their goals were being satisfied at runtime. When combined with requirements monitoring and self adaptive capabilities, requirements awareness should help optimize goal satisfaction even in the presence of changing run-time context. In this paper we describe initial progress towards the realization of requirements-aware systems with REAssuRE. REAssuRE focuses on explicit representation of assumptions made at design time. When such assumptions are shown not to hold, REAssuRE can trigger system adaptations to alternative goal realization strategies.", "num_citations": "84\n", "authors": ["1452"]}
{"title": "A flexible framework to experiment with ontology learning techniques\n", "abstract": " Ontology learning refers to extracting conceptual knowledge from several sources and building an ontology from scratch, enriching, or adapting an existing ontology. It uses methods from a diverse spectrum of fields such as Natural Language Processing, Artificial Intelligence and Machine learning. However, a crucial challenging issue is to quantitatively evaluate the usefulness and accuracy of both techniques and combinations of techniques, when applied to ontology learning. It is an interesting problem because there are no published comparative studies. We are developing a flexible framework for ontology learning from text which provides a cyclical process that involves the successive application of various NLP techniques and learning algorithms for concept extraction and ontology modelling. The framework provides support to evaluate the usefulness and accuracy of different techniques and possible\u00a0\u2026", "num_citations": "84\n", "authors": ["1452"]}
{"title": "Revisiting ontology-based requirements engineering in the age of the semantic web\n", "abstract": " There is a long history of research into utilising ontologies in the Requirements Engineering process. An ontology is generally based upon some logical formalism, and has the benefits for requirements of explicitly modelling domain knowledge in a machine interpretable way, eg allowing requirements to be traced and checked for consistency by an inference engine, and software specifications to be derived.With the emergence of the semantic web, the interest in ontologies for Requirements Engineering is on the increase. Whilst efforts have been concentrated upon re-interpreting software engineering techniques for the semantic web, it is interesting to consider what benefits there are to be passed from the semantic web to traditional Software Engineering techniques.", "num_citations": "83\n", "authors": ["1452"]}
{"title": "REVERE: support for requirements synthesis from documents\n", "abstract": " Documents are important sources of system requirements. This is particularly true of domains that are document-centric in terms of their operational and development processes. For system evolution in organisations that have been subject to organisational change and loss of organisational memory, documents may be the major source of key requirements. Hence, systems engineers often face a daunting task of synthesising crucial requirements from a range of documents that include standards, interview transcripts and legacy specifications. The goal of REVERE was to investigate support for this task which has been described as document archaeology (Robertson S. and Robertson J. Mastering the Requirements Process. Reading, MA, Addison-Wesley, 1999). This paper describes the resulting REVERE toolset, its utility for document archaeology and for other tasks that have emerged in the course of our\u00a0\u2026", "num_citations": "76\n", "authors": ["1452"]}
{"title": "The European Union and Recent Transformations\n", "abstract": " This chapter adopts a resolutely state-theoretical but not state-centred approach to the emerging Europolity and its role in economic and political restructuring. An adequate account must relate these topics to more general changes in the interrelated political economies of capitalism and the modern state-in part because the European Union is itself an integral aspect therein. This said, recent changes in the EU's economic and political organisation point to the emergence of a relatively novel form of political regime. Previously dominant but competing state-centred and governance-centred paradigms cannot grasp the distinctiveness of this emerging regime. I therefore introduce an alternative based on the strategic-relational approach to the state before summarizing recent changes in the capitalist type of state and describing some more general changes in the modern state. I then consider the EU as an emerging form of statehood.", "num_citations": "72\n", "authors": ["1452"]}
{"title": "Managing process inconsistency using viewpoints\n", "abstract": " Discusses the notion of software process inconsistency and suggests that inconsistencies in software processes are inevitable and sometimes desirable. We present an approach to process analysis that helps discover different perceptions of a software process and that supports the discovery of process inconsistencies and process improvements stimulated by these inconsistencies. By analogy with viewpoints for requirements engineering that allow multiple perspectives on a software system specification to be managed, we have developed the notion of process viewpoints that provide multi-perspective descriptions of software processes. A process viewpoint includes a statement of focus or \"world view\", a set of sources of process information, a process description and a set of organizational concerns that represent goals or constraints on the process analysis. We present a description and rationale of process\u00a0\u2026", "num_citations": "70\n", "authors": ["1452"]}
{"title": "Using constraint programming to manage configurations in self-adaptive systems\n", "abstract": " Combining goal-modeling techniques with constraint programming provides the means to identify the variants best suited to the environmental contexts that a self-adaptive software system might encounter at runtime.", "num_citations": "67\n", "authors": ["1452"]}
{"title": "Packaged software: challenges for RE\n", "abstract": " Packaged Software: Challenges for RE - Lancaster EPrints LOADING Skip to main content Lancaster University homepage Home Browse By Year By Subject By Department Search Help Packaged Software: Challenges for RE Sawyer, Peter (2000) Packaged Software: Challenges for RE. In: Sixth International Workshop on Requirements Engineering: Foundations of Software Quality (REFSQ 2000) Stockholm, 1900-01-01. (Unpublished) Full text not available from this repository. Item Type: Contribution to Conference (Other) Journal or Publication Title: Sixth International Workshop on Requirements Engineering: Foundations of Software Quality (REFSQ 2000) Stockholm Uncontrolled Keywords: /dk/atira/pure/researchoutput/libraryofcongress/qa75 Subjects: Departments: Faculty of Science and Technology > School of Computing & Communications ID Code: 11842 Deposited By: ep_importer_comp Deposited On: \u2026", "num_citations": "64\n", "authors": ["1452"]}
{"title": "Identifying tacit knowledge-based requirements\n", "abstract": " Requirements may be derived from a number of sources. Determining the source of a given requirement is known as pre-requirements tracing. Typically, some requirements appear that have no clear source, yet stakeholders will attest to the necessity of these requirements. However, such requirements are likely to be based on tacit or tacit-like knowledge embedded in the problem domain. A tool called Prospect that retrospectively identifies pre-requirement traces is presented. This tracing is achieved by working backwards from requirements to the documented records of the elicitation process, such as interview transcripts or ethnographic reports. A vector-space technique, latent semantic analysis, is shown to be useful to perform pre-requirements tracing. The identification of badly sourced requirements naturally leads to the inference that further investigation of these requirements is necessary, whether or not the\u00a0\u2026", "num_citations": "54\n", "authors": ["1452"]}
{"title": "Cooperative systems design\n", "abstract": " This paper discusses an innovative experiment where sociologists were actively involved in the requirements analysis for an interactive software system to support the work of air traffic controllers. Air traffic control is intrinsically cooperative and our work involved an analysis of that process from a social perspective and the development of a prototype user interface for air traffic controllers' interaction with a flight information system.         As part of the analysis process, sociologists were involved in ethnographic studies of work and discovered subtle and complex patterns of cooperation which, we suspect, would not have been discovered using structured methods for requirements analysis. From a software development perspective, we describe how the input from the sociologists was essential for understanding the real automation requirements, discuss the difficulties of inter-disciplinary cooperative working and\u00a0\u2026", "num_citations": "50\n", "authors": ["1452"]}
{"title": "Melting of the glacier base during a small-volume subglacial rhyolite eruption: evidence from Bl\u00e1hn\u00fakur, Iceland\n", "abstract": " Although observations of recent volcanic eruptions beneath Vatnaj\u00f6kull, Iceland have improved the understanding of ice deformation and meltwater drainage, little is known about the processes that occur at the glacier base. We present observations of the products of a small-volume, effusive subglacial rhyolite eruption at Bl\u00e1hn\u00fakur, Torfaj\u00f6kull, Iceland. Lava bodies, typically 7 m long, have unusual conical morphologies and columnar joint orientations that suggest emplacement within cavities melted into the base of a glacier. Cavities appear to have been steep-walled and randomly distributed. These features can be explained by a simple model of conductive heat loss during the ascent of a lava body to the glacier base. The released heat melts a cavity in the overlying ice. The development of vapour-escape pipes in the waterlogged, permeable breccias surrounding the lava allows rapid heat transfer between lava\u00a0\u2026", "num_citations": "49\n", "authors": ["1452"]}
{"title": "Ontology and model alignment as a means for requirements validation\n", "abstract": " This paper reports on work that is investigating the application of ontology engineering and natural language processing to software engineering. Our focus is the transition from requirements to design which remains one of the main challenges in software engineering. A key reason for why this is so challenging is that the vast majority of requirements documents are informal, written in natural language, whereas the final goal (code) is formal. System models, as an intermediate step between the requirements and code, help understand requirements. Even a seemingly precise requirements document typically contains a lot of inconsistencies and omissions, which become visible when we model the system. Our hypothesis is that these inconsistencies become apparent when we compare the project-specific model with a generic model of the application domain. To test our hypothesis, we need to transform natural\u00a0\u2026", "num_citations": "48\n", "authors": ["1452"]}
{"title": "On the effectiveness of abstraction identification in requirements engineering\n", "abstract": " The identification of abstractions, i.e. terms that have a particular significance in a given domain, and such that they can indirectly characterize the most salient features of the document in which they appear, has often been recognized as a useful tool in the analysis of domain descriptions and requirements documents in software development. In this paper we propose a new technique for the identification of single- and multi-word abstractions named Relevance driven abstraction identification (RAI) and a corresponding tool implementation, present an experiment comparing the effectiveness of our technique with human judgement and with a different technique proposed in the literature, and discuss a number of ways in which the abstractions so identified can be used to good profit in requirements engineering.", "num_citations": "47\n", "authors": ["1452"]}
{"title": "Understanding the scope of uncertainty in dynamically adaptive systems\n", "abstract": " [Context and motivation] Dynamically adaptive systems are increasingly conceived as a means to allow operation in changeable or poorly understood environments. [Question/problem] This can result in the selection of solution strategies based on assumptions that may not be well founded. [Principle ideas/results] This paper proposes the use of claims in goal models as a means to reason about likely sources of uncertainty in dynamically adaptive systems. Accepting that such claims can\u2019t be easily validated at design-time, we should instead evaluate how the system will behave if a claim is proven false by developing a validation scenario. [Contribution] Validation scenarios may be costly to evaluate so the approach we advocate is designed to carefully select only those claims that are less certain, or whose falsification would have serious consequences.", "num_citations": "46\n", "authors": ["1452"]}
{"title": "Reflective component-based technologies to support dynamic variability\n", "abstract": " In this paper we propose an approach to support dynamic or runtime variability in systems that must adapt dynamically to changing runtime context. The approach is founded on reflective component-based technologies to support the dynamic variability at the architectural level. Adaptive behaviour is encoded in reconfiguration policies that are consulted at run-time when changes in the underlying environment are detected. Specifically, the reconfiguration policies dictate the component-based architecture to be used in actively changing contexts. However, the increasing number of variants and their interdependency relationships add to the complexity of variability management. Therefore, the paper also proposes a notation and associated models to address the management of dynamic variability. We describe our experience with applying this approach through a case study; the support and management of dynamic variability for service discovery protocols. Keywords: dynamic variability, architectural reconfiguration, orthogonal variability models.", "num_citations": "42\n", "authors": ["1452"]}
{"title": "Improving the requirements process\n", "abstract": " The state-of-the practice in requirements engineering is currently such that organisations wishing to improve their requirements processes find it hard to discover, evaluate and apply good practice. Good practice certainly exist but dissemination of practical experience is poor. Standards coverage of the requirements process is also patchy. This paper describes the Requirements Engineering Good Practice Guide which attempts to fill this gap by disseminating good requirements practice within a process improvement framework. The work is motivated by the authors' judgement that it is timely to exploit industry's interest in software process improvement as a vehicle for raising the profile of good requirements practice.", "num_citations": "40\n", "authors": ["1452"]}
{"title": "Self-explanation in adaptive systems based on runtime goal-based models\n", "abstract": " The behaviour of self adaptive systems can be emergent, which means that the system\u2019s behaviour may be seen as unexpected by its customers and its developers. Therefore, a self-adaptive system needs to garner confidence in its customers and it also needs to resolve any surprise on the part of the developer during testing and maintenance. We believe that these two functions can only be achieved if a self-adaptive system is also capable of self-explanation. We argue a self-adaptive system\u2019s behaviour needs to be explained in terms of satisfaction of its requirements. Since self-adaptive system requirements may themselves be emergent, we propose the use of goal-based requirements models at runtime to offer self-explanation of how a system is meeting its requirements. We demonstrate the analysis of run-time requirements models to yield a self-explanation codified in a domain specific language\u00a0\u2026", "num_citations": "34\n", "authors": ["1452"]}
{"title": "Self-explanation in adaptive systems\n", "abstract": " The behaviour of self adaptive systems can be emergent. The difficulty in predicting the system's behaviour means that there is scope for the system to surprise its customers and its developers. Because its behaviour is emergent, a self-adaptive system needs to garner confidence in its customers and it needs to resolve any surprise on the part of the developer during testing and mainteinance. We believe that these two functions can only be achieved if a self-adaptive system is also capable of self-explanation. We argue a self-adaptive system's behaviour needs to be explained in terms of satisfaction of its requirements. Since self-adaptive system requirements may themselves be emergent, a means needs to be found to explain the current behaviour of the system and the reasons that brought that behaviour about. We propose the use of goal-based models during runtime to offer self-explanation of how a system is\u00a0\u2026", "num_citations": "34\n", "authors": ["1452"]}
{"title": "A faceted approach to service specification\n", "abstract": " Service-centric computing is developing and maturing rapidly as a paradigm for developing distributed systems. In recent years there has been a rapid growth in the number and types of processes being proposed to support aspects of SOC. Many of these processes require that services be modelled in a particular way and this puts great pressure on traditional notions of service specification, questioning the very nature of how services should be described for potential consumers. We present a technique for addressing this theoretical and practical bottleneck: faceted service specification. This allows different specifications to exist side-by-side if they are needed, yet places little obligation on the service provider to support specifications that are judged to be of little or no value. We show how faceted service specification is being used in the SeCSE project to support advanced service-centric system development\u00a0\u2026", "num_citations": "33\n", "authors": ["1452"]}
{"title": "A flexible approach for instance adaptation during class versioning\n", "abstract": " One of the consequences of evolution can be the inability to access objects created using the older schema definition under the new definition and vice versa. Instance adaptation is the conversion of objects to a compatible definition or making objects exhibit a compatible interface. Existing evolution approaches are committed to a particular instance adaptation strategy. This is because changes to the instance adaptation strategy or an attempt to adopt an entirely different strategy would be very costly. This paper proposes a flexible instance adaptation approach for systems employing class versioning to manage evolution. Flexibility is achieved by encapsulating the instance adaptation code in aspects - abstractions introduced by aspect-oriented programming to localise cross-cutting concerns. This makes it possible to make cost-effective changes to the instance adaptation strategy. The flexibility of the\u00a0\u2026", "num_citations": "33\n", "authors": ["1452"]}
{"title": "The REVERE project: experiments with the application of probabilistic NLP to systems engineering\n", "abstract": " Despite natural language\u2019s well-documented shortcomings as a medium for precise technical description, its use in software-intensive systems engineering remains inescapable. This poses many problems for engineers who must derive problem understanding and synthesise precise solution descriptions from free text. This is true both for the largely unstructured textual descriptions from which system requirements are derived, and for more formal documents, such as standards, which impose requirements on system development processes. This paper describes experiments that we have carried out in the REVERE1 project to investigate the use of probabilistic natural language processing techniques to provide systems engineering support.", "num_citations": "33\n", "authors": ["1452"]}
{"title": "Abnormalities of saccadic eye movements in dementia due to Alzheimer\u2019s disease and mild cognitive impairment\n", "abstract": " Background: There is increasing evidence that people in the early stages of Alzheimer\u2019s disease (AD) have subtle impairments in cognitive inhibition that can be detected by using relatively simple eye-tracking paradigms, but these subtle impairments are often missed by traditional cognitive assessments. People with mild cognitive impairment (MCI) are at an increased likelihood of dementia due to AD. No study has yet investigated and contrasted the MCI subtypes in relation to eye movement performance. Methods: In this work we explore whether eye-tracking impairments can distinguish between patients with the amnesic and the non-amnesic variants of MCI. Participants were 68 people with dementia due to AD, 42 had a diagnosis of aMCI, and 47 had a diagnosis of naMCI, and 92 age-matched cognitively healthy controls. Results: The findings revealed that eye-tracking can distinguish between the two forms of\u00a0\u2026", "num_citations": "32\n", "authors": ["1452"]}
{"title": "Relevance-based abstraction identification: technique and evaluation\n", "abstract": " When first approaching an unfamiliar domain or requirements document, it is often useful to get a quick grasp of what the essential concepts and entities in the domain are. This process is called abstraction identification, where the word abstraction refers to an entity or concept that has a particular significance in the domain. Abstraction identification has been proposed and evaluated as a useful technique in requirements engineering (RE). In this paper, we propose a new technique for automated abstraction identification called relevance-based abstraction identification (RAI), and evaluate its performance\u2014in multiple configurations and through two refinements\u2014compared to other tools and techniques proposed in the literature, where we find that RAI significantly outperforms previous techniques. We present an experiment measuring the effectiveness of RAI compared to human judgement, and discuss\u00a0\u2026", "num_citations": "31\n", "authors": ["1452"]}
{"title": "Aspect-orientation and database systems: an effective customisation approach\n", "abstract": " The problem of providing database systems customised to the specific needs of an organisation or application is addressed. The authors demonstrate that such customisations are expensive in existing database systems owing to the crosscutting nature of customisable features, and they propose a customisation approach based on `aspect-oriented programming' techniques which allow separation of crosscutting features using special constructs known as `aspects'. Changes to the features encapsulated by aspects are localised, making cost-effective customisation possible (at compile-time and run-time) at both the DBMS level and the database level.", "num_citations": "28\n", "authors": ["1452"]}
{"title": "Requirements tracing to support change in dynamically adaptive systems\n", "abstract": " [Context and motivation] All systems are susceptible to the need for change, with the desire to operate in changeable environments driving the need for software adaptation. A Dynamically Adaptive System (DAS) adjusts its behaviour autonomously at runtime in order to accommodate changes in its operating environment, which are anticipated in the system\u2019s requirements specification. [Question/Problem] In this paper, we argue that Dynamic Adaptive Systems\u2019 requirements specifications are more susceptible to change than those of traditional static systems. We propose an extension to i* strategic rationale models to aid in changing a DAS. [Principal Ideas/Results] By selecting some of the types of tracing proposed for the most complex systems and supporting them for DAS modelling, it becomes possible to handle change to a DAS\u2019 requirements efficiently, whilst still allowing artefacts to be\u00a0\u2026", "num_citations": "27\n", "authors": ["1452"]}
{"title": "Discovering affect-laden requirements to achieve system acceptance\n", "abstract": " Novel envisioned systems face the risk of rejection by their target user community and the requirements engineer must be sensitive to the factors that will determine acceptance or rejection. Conventionally, technology acceptance is determined by perceived usefulness and ease-of-use, but in some domains other factors play an important role. In healthcare systems, particularly, ethical and emotional factors can be crucial. In this paper we describe an approach to requirements discovery that we developed for such systems. We describe how we have applied our approach to a novel system to passively monitor users for signs of cognitive decline consistent with the onset of dementia. A key challenge was eliciting users' reactions to emotionally charged events never before experienced by them at first hand. Our goal was to understand the range of users' emotional responses and their values and motivations, and from\u00a0\u2026", "num_citations": "25\n", "authors": ["1452"]}
{"title": "Survey of aspect-oriented analysis and design\n", "abstract": " Survey of Aspect-Oriented Analysis and Design - Lancaster EPrints LOADING Skip to main content Lancaster University homepage Home Browse By Year By Subject By Department Search Help Survey of Aspect-Oriented Analysis and Design Chitchyan, R. and Rashid, A. and Sawyer, Pete and Garcia, A. and Bakker, J. and Pinto Alarcon, M. and Tekinerdogan, B. and Clarke, S. and Jackson, A. (2005) Survey of Aspect-Oriented Analysis and Design. UNSPECIFIED. (Unpublished) Full text not available from this repository. Item Type: Other Uncontrolled Keywords: /dk/atira/pure/researchoutput/libraryofcongress/qa75 Subjects: Departments: Faculty of Science and Technology > School of Computing & Communications Faculty of Science and Technology > Lancaster Environment Centre ID Code: 12600 Deposited By: ep_importer_comp Deposited On: 07 Jul 2011 14:52 Refereed?: No Published?: Unpublished Last \u2026", "num_citations": "24\n", "authors": ["1452"]}
{"title": "Assisting requirements engineering with semantic document analysis\n", "abstract": " Requirements engineering is the first stage in the software life-cycle and is concerned with discovering and managing a software system's services, constraints and goals. Requirements engineers frequently face the task of extracting domain knowledge and recovering requirements from large documents. This is needed to complement the often incomplete information elicited from the people who will use or otherwise have a stake in the system to be developed. The documents that have to be analysed may vary from structured documents, such as specifications of work processes, to unstructured, verbatim reports of interviews or workplace observations. This paper shows that tools exploiting natural language processing techniques, in particular semantic analysis, are able to assist in retrieval from these documents.", "num_citations": "24\n", "authors": ["1452"]}
{"title": "Concept mapping as a means of requirements tracing\n", "abstract": " Requirements documents often describe the system on different abstraction levels. This results in the fact that the same issues may be described in different documents and with different vocabulary. For analysts who are new to the application domain, this poses a major orientation problem, as they cannot link different concepts or documents with each other. In the presented paper, we propose an approach to map concepts extracted from different documents to each other. This, in turn, allows us to find related passages in different documents, even though the documents represent different levels of abstraction. Practical applicability of the approach was proven in a case study with real-world requirements documents.", "num_citations": "23\n", "authors": ["1452"]}
{"title": "Comparing requirements engineering approaches for handling crosscutting concerns\n", "abstract": " A number of requirements engineering (RE) approaches have focused on addressing broadly scoped (non-functional) properties such as security, availability, etc. More recently, several aspect-oriented requirements engineering (AORE) approaches have been proposed to tackle both functional and non-functional requirements of a crosscutting nature. In this paper, we analyse how some well-known RE approaches address crosscutting concerns. We compare these approaches with AORE approaches in order to identify the additional contributions the latter have to offer while at the same time investigating what AORE can learn from traditional RE techniques. We use our comparison to derive a set of challenges to be addressed by AORE techniques. This paper is our position statement, rather then an attempt to precisely evaluate the discussed approaches, for which several large case studies are necessary.", "num_citations": "23\n", "authors": ["1452"]}
{"title": "M marinum infections in a Chesapeake Bay community.\n", "abstract": " Their proximity to Eastern Virginia's abundant waterways has given the authors experience in managing the destructive tenosynovitis and deep tissue infections caused by M marinum. They present nine cases, discuss diagnosis and treatment, review the literature, and urge urban physicians to be on the alert for the disease in patients recently returned from fishing trips.", "num_citations": "23\n", "authors": ["1452"]}
{"title": "Object database evolution using separation of concerns\n", "abstract": " This paper proposes an object database evolution approach based on separation of concerns. The lack of customisability and extensibility in existing evolution frameworks is a consequence of using attributes at the meta-object level to implement links among meta-objects and the injection of instance adaptation code directly into the class versions. The proposed approach uses dynamic relationships to separate the connection code from meta-objects and aspects - abstractions used by Aspect-Oriented Programming to localise cross-cutting concerns - to separate the instance adaptation code from class versions. The result is a customisable and extensible evolution framework with low maintenance overhead.", "num_citations": "22\n", "authors": ["1452"]}
{"title": "Dynamic relationships in object oriented databases: A uniform approach\n", "abstract": " In this paper we present a uniform approach to dynamic relationships in object oriented databases. We present our relationship categorisation based on dividing the object database into three virtual spaces each hosting entities of a particular type and show how relationships from the modelling domain map onto relationships in our categorisation. We present a relationship model and the semantics of relationships. The relationship model is complemented with a metamodel for implementing dynamic relationships in an object oriented database. The applicability of the dynamic relationships approach is explored by employing it to implement the database model for a system in order to achieve dynamic schema modification capabilities.", "num_citations": "22\n", "authors": ["1452"]}
{"title": "Database systems: challenges and opportunities for graphical HCI\n", "abstract": " Databases and their applications form one of the most important classes of computer systems yet they have received relatively little attention from the HCI community. They have nevertheless spawned some notably innovative user interfaces and it is interesting to examine these in the light of contemporary HCI issues. The paper addresses the relationship between HCI and database systems, reviews some of the major themes running through existing database user interfaces and postulates some issues which are likely to be important to database usability in the future. The underlying argument is that databases are sufficiently different from other classes of application to necessitate a raft of user interface techniques specifically for the needs of database users which would reward increased attention by the HCI community.", "num_citations": "22\n", "authors": ["1452"]}
{"title": "Canary: Extracting requirements-related information from online discussions\n", "abstract": " Online discussions about software applications generate a large amount of requirements-related information. This information can potentially be usefully applied in requirements engineering; however currently, there are few systematic approaches for extracting such information. To address this gap, we propose Canary, an approach for extracting and querying requirements-related information in online discussions. The highlight of our approach is a high-level query language that combines aspects of both requirements and discussion in online forums. We give the semantics of the query language in terms of relational databases and SQL. We demonstrate the usefulness of the language using examples on real data extracted from online discussions. Our approach relies on human annotations of online discussions. We highlight the subtleties involved in interpreting the content in online discussions and the\u00a0\u2026", "num_citations": "21\n", "authors": ["1452"]}
{"title": "Ensemble methods for ontology learning-an empirical experiment to evaluate combinations of concept acquisition techniques\n", "abstract": " Most approaches to ontology learning combine techniques from different areas (hybrid approaches) to increase the efficiency of the ontology learning process. However, the results from the ontology learning process do not fully satisfy the users at present. An important problem is that there is a lack of quantitative and comparative data about the efficiency of techniques and technique combinations applied to ontology learning. In this paper we present a quantitative comparison of technique combinations for concept extraction and a software system (OntoLancs) to support the evaluation of techniques. By applying OntoLancs, users are able to assist the process of building ontologies by semi- automatically acquiring concepts from large-scale domain document collections and experiment with different combinations of knowledge acquisition techniques to refine and organize domain concepts into a taxonomy\u00a0\u2026", "num_citations": "21\n", "authors": ["1452"]}
{"title": "Can you detect early dementia from an email? A proof of principle study of daily computer use to detect cognitive and functional decline\n", "abstract": " Objective To determine whether multiple computer use behaviours can distinguish between cognitively healthy older adults and those in the early stages of cognitive decline, and to investigate whether these behaviours are associated with cognitive and functional ability.   Methods Older adults with cognitive impairment (n\u00a0=\u00a020) and healthy controls (n\u00a0=\u00a024) completed assessments of cognitive and functional abilities and a series of semi\u2010directed computer tasks. Computer use behaviours were captured passively using bespoke software.   Results The profile of computer use behaviours was significantly different in cognitively impaired compared with cognitively healthy control participants including more frequent pauses, slower typing, and a higher proportion of mouse clicks. These behaviours were significantly associated with performance on cognitive and functional assessments, in particular, those related to\u00a0\u2026", "num_citations": "19\n", "authors": ["1452"]}
{"title": "Revisiting goal-oriented models for self-aware systems-of-systems\n", "abstract": " Systems-of-systems (SoS) are systems resulted from the interaction among other independent constituent systems that collaborate to offer new functionalities towards accomplishing global missions. Each of these constituent systems accomplishes its individual missions and is able to contribute to the achievement of the global missions of the SoS, both being viewed as a set of associated goals. In the perspective of self-aware systems, SoS need to exhibit goal-awareness, i.e., They need to be aware of their own goals and of how their constituent systems contribute to their accomplishment. In this paper, we revisit goal-oriented concepts aiming at identifying and modeling goals at both SoS level and the constituent systems level. Moreover, we take advantage of such goal-oriented models to express the relationship among goals at these levels as well as to define how each constituent system can contribute to the\u00a0\u2026", "num_citations": "19\n", "authors": ["1452"]}
{"title": "Modeling personalized adaptive systems\n", "abstract": " A new theoretical framework for the conceptual modeling of personalized and context-aware systems is described which supports specification of customization for individual users and analyzing the interaction between the domain context and functionality. An initial taxonomy of models is proposed based on the concept of personalized requirements. Two layers of human-centric models are proposed: an individual user characteristics layer for adaptation in assistive technology, learning and learning support systems and an individual values and personal goals layer to tailor applications to personal requirements. Practical application of the modeling framework is illustrated in a healthcare case study of a personalized, self-adaptive context-aware system.", "num_citations": "16\n", "authors": ["1452"]}
{"title": "Maturing requirements engineering process maturity models\n", "abstract": " The interest in Software Process Improvement (SPI) in the early 1990s stimulated tentative work on parallel models for Requirements Engineering (RE) process improvement in the late 1990s. This chapter examines the role of SPI and the implications of the exclusion of explicit support for RE in the most widely used SPI models. The chapter describes the principal characteristics of three RE-specific improvement models that are in the public domain: the Requirements Engineering Good Practice Guide (REGPG), the Requirements Engineering Process Maturity Model (REPM), and the University of Hertfordshire model. The chapter examines the utility of these models and concludes by considering the lessons learned from industrial pilot studies.", "num_citations": "16\n", "authors": ["1452"]}
{"title": "Recovering legacy requirements\n", "abstract": " It is common for organisations to introduce substantial changes to their structure and operations in order to adapt to new business environments. This often confers legacy status on their software systems because they can\u2019t adequately support the new business processes. In this paper, we argue that it is necessary to recover the requirements of in-service legacy software to ensure that its evolution or replacement is properly informed by an understanding of what is redundant, what must be retained and what can be reused. Much of this information is often contained in documents. However, retrieval of the information is often difficult due to problems of completeness, quality and sheer volume. In the REVERE project we are integrating a number of techniques to provide a set of tools to help requirements engineers explore the documentation and reconstruct conceptual models of the software and business processes. At the core of this work is the exploitation of probabilistic NLP tools to provide a \u2018quick way in\u2019to large, complex and imperfectly structured documents, saving much painstaking and error-prone manual effort.", "num_citations": "16\n", "authors": ["1452"]}
{"title": "When to adapt? identification of problem domains for adaptive systems\n", "abstract": " Dynamically adaptive systems (DASs) change behaviour at run-time to operate in volatile environments. As we learn how best to design and build systems with greater autonomy, we must also consider when to do so. Thus far, DASs have tended to showcase the benefits of adaptation infrastructures with little understanding of what characterizes the problem domains that require run-time adaptation. This position paper posits that context-dependent variation in the acceptable trade-offs between non-functional requirements is a key indicator of problems that require dynamically adaptive solutions.", "num_citations": "15\n", "authors": ["1452"]}
{"title": "Evaluation for Evolution: How Well Commercial Systems Do\n", "abstract": " Like any other database application object database applications are subject to evolution. Evolution is, however, critical in object databases because it is the very characteristic of complex applications such as CAD, etc. for which they provide inherent support. This paper discusses the evolution facilities offered by some of the existing systems. We first provide an overview of the ODMG 2.0 standard from an evolution viewpoint. We then describe our extension to the database evolution features specified by the ODMG 2.0 standard. Using this extension as a basis we form evaluation criteria, which we employ to assess the various evolution facilities offered by four commercially available object database management systems: POET, Versant, O2 and Jasmine.", "num_citations": "15\n", "authors": ["1452"]}
{"title": "Monitoring dementia with automatic eye movements analysis\n", "abstract": " Eye movement patterns are found to reveal human cognitive and mental states that can not be easily measured by other biological signals. With the rapid development of eye tracking technologies, there are growing interests in analysing gaze data to infer information about people\u2019 cognitive states, tasks and activities performed in naturalistic environments. In this paper, we investigate the link between eye movements and cognitive function. We conducted experiments to record subject\u2019s eye movements during video watching. By using computational methods, we identified eye movement features that are correlated to people\u2019s cognitive health measures obtained through the standard cognitive tests. Our results show that it is possible to infer people\u2019s cognitive function by analysing natural gaze behaviour. This work contributes an initial understanding of monitoring cognitive deterioration and dementia with\u00a0\u2026", "num_citations": "14\n", "authors": ["1452"]}
{"title": "Supporting the active learning of collaborative database browsing techniques\n", "abstract": " We describe the implications of a study of database browsing behaviour for the development of a system to support more effective browsing. In particular we consider the importance of collaborative working, both in learning browsing skills and in co-operating on a shared information-retrieval task. From our study, we believe that an interface to support collaboration should promote the awareness of the activities of others, better visualization of the information data structures being browsed, and effective communication of the browsing process.", "num_citations": "14\n", "authors": ["1452"]}
{"title": "Combining mouse and keyboard events with higher level desktop actions to detect mild cognitive impairment\n", "abstract": " We present a desktop monitoring application that combines keyboard, mouse, desktop and application-level activities. It has been developed to discover differences in cognitive functioning amongst older computer users indicative of mild cognitive impairment (MCI). Following requirements capture from clinical domain experts, the tool collects all Microsoft Windows events deemed potentially useful for detecting early clinical indicators of dementia, with a view to further analysis to determine the most pertinent. Further requirements capture from potential end-users has resulted in a system that has little impact on users' daily activities and ensures data security from initial recording of events through to data analysis. We describe two experiments: firstly, volunteers were asked to perform a short set of known tasks, the second (ongoing) experiment is a longitudinal study, with the software currently successfully running on\u00a0\u2026", "num_citations": "13\n", "authors": ["1452"]}
{"title": "Ontology-aided translation in the comparison of candidate service quality\n", "abstract": " In engineering service-centric systems, it is possible to receive early feedback on candidate services that best match requirements. This includes the possibility of comparing the quality (not just functionality) of candidate services. This paper concentrates on the assessment of service quality at the requirements stage. In doing so, it is found that there is a problem in reaching a common understanding between the parties involved - i.e. different service providers and requirements engineers may use different metrics, units, etc. We present an approach in which our requirements-based service discovery tool exploits an ontology-based quality specification mechanism. This simplifies the problem of reaching a common understanding of quality and allows translation where providers choose to specify quality differently.", "num_citations": "13\n", "authors": ["1452"]}
{"title": "Run-time resolution of uncertainty\n", "abstract": " Requirements awareness should help optimize requirements satisfaction when factors that were uncertain at design time are resolved at runtime. We use the notion of claims to model assumptions that cannot be verified with confidence at design time. By monitoring claims at runtime, their veracity can be tested. If falsified, the effect of claim negation can be propagated to the system's goal model and an alternative means of goal realization selected automatically, allowing the dynamic adaptation of the system to the prevailing environmental context.", "num_citations": "12\n", "authors": ["1452"]}
{"title": "Managing testing complexity in dynamically adaptive systems: A model-driven approach\n", "abstract": " Autonomous systems are increasingly conceived as a means to allow operation in changeable or poorly understood environments. However, granting a system autonomy over its operation removes the ability of the developer to be completely sure of the system's behaviour under all operating contexts. This combination of environmental and behavioural uncertainty makes the achievement of assurance through testing very problematic. This paper focuses on a class of system, called an m-DAS, that uses run-time models to drive run-time adaptations in changing environmental conditions. We propose a testing approach which is itself model-driven, using model analysis to significantly reduce the set of test cases needed to test for emergent behaviour. Limited testing resources may therefore be prioritised for the most likely scenarios in which emergent behaviour may be observed.", "num_citations": "12\n", "authors": ["1452"]}
{"title": "A collaborative workflow for building ontologies: A case study in the biomedical field\n", "abstract": " Much medical knowledge is contained within available literature, such as clinical guidelines and protocols. Recently, an interest has been developed in automatic content extraction to construct ontologies of this knowledge to make it more widely available. With groups of domain experts distributed geographically, and the growing amount of medical literature, an important challenge is to develop collaborative workflows to support ways for domain experts to contribute in the ontology learning process. This paper presents a collaborative workflow for ontology learning based on coupling an Ontology Learning Tool (OntoLancs) with and Ontology engineer (Protege) to provide semi-automatic support for text mining and a collaborative tool to model formal ontologies. The work presented in this paper was evaluated with a case study on a Clinical Practice Guideline of Diabetic Retinopathy. The major benefits of coupling\u00a0\u2026", "num_citations": "12\n", "authors": ["1452"]}
{"title": "A database evolution taxonomy for object\u2010oriented databases\n", "abstract": " Like any other database application, object database applications are subject to evolution. Evolution, however, is a critical requirement in object\u2010oriented databases as it is a fundamental characteristic of complex applications such as computer\u2010aided design and manufacturing (CAD/CAM) and office information systems. Object\u2010oriented databases are inherently suited to supporting such applications. In this paper we present a database evolution taxonomy for object\u2010oriented databases. We describe a conceptual database model and use it to define the taxonomy. We also present the various invariants and rules governing the various evolution operations. The execution sequence of rules is described. An implementation of the database model and the evolution taxonomy in the Semi\u2010Autonomous Database Evolution System (SADES), is discussed. The implementation employs aspect\u2010oriented programming\u00a0\u2026", "num_citations": "12\n", "authors": ["1452"]}
{"title": "Satisfying requirements for pervasive service compositions\n", "abstract": " Pervasive environments are characterised by highly heterogeneous services and mobile devices with dynamic availability. Approaches such as that proposed by the Connect project provide means to enable such systems to be discovered and composed, through mediation where necessary. As services appear and disappear, the set of feasible compositions changes. In such a pervasive environment, a designer encounters two related challenges: what goals it is reasonable to pursue in the current context and how to use the services presently available to achieve his goals. This paper proposes an approach to design service compositions, facilitating an interactive process to find the trade-off between the possible and the desirable. Following our approach, the system finds at runtime, where possible, compositions related to the developer's requirements. This process can realise the intent the developer specifies at\u00a0\u2026", "num_citations": "11\n", "authors": ["1452"]}
{"title": "Supporting MEASUR-driven analysis using NLP tools\n", "abstract": " Supporting MEASUR-driven analysis using NLP tools - Lancaster EPrints LOADING Skip to main content Lancaster University homepage Home Browse By Year By Subject By Department Search Help Supporting MEASUR-driven analysis using NLP tools Sawyer, Peter and Cosh, K. (2004) Supporting MEASUR-driven analysis using NLP tools. In: 10th International Workshop on Requirements Engineering, 1900-01-01. (Unpublished) Full text not available from this repository. Item Type: Contribution to Conference (Other) Journal or Publication Title: 10th International Workshop on Requirements Engineering Uncontrolled Keywords: /dk/atira/pure/researchoutput/libraryofcongress/qa75 Subjects: Departments: Faculty of Science and Technology > School of Computing & Communications ID Code: 12460 Deposited By: ep_importer_comp Deposited On: 07 Jul 2011 16:22 Refereed?: No Published?: Unpublished Last \u2026", "num_citations": "11\n", "authors": ["1452"]}
{"title": "Assisting requirements recovery from legacy documents\n", "abstract": " Business change is often accompanied by loss of continuity of experience. This has serious implications for the adaptation of an organisation\u2019s software since people with detailed knowledge of either the software or business processes may be unavailable to inform its adaptation. In many cases organisational memory will persist principally in the form of documents such as requirements specifications, operating procedures and regulatory standards. These offer an important resource for informing what features of the software are redundant, need to be retained or can be reused. Exploiting this resource poses formidable problems, however, since it is often incomplete, poorly structured, poorly maintained and voluminous. This paper proposes that tools exploiting probabilistic natural language-processing techniques offer the potential to ease these problems. Such tools are available, mature and have been\u00a0\u2026", "num_citations": "11\n", "authors": ["1452"]}
{"title": "Facilitating virtual representation of CAD data through a learning based approach to conceptual database evolution employing direct instance sharing\n", "abstract": " This paper presents a framework for a learning based approach to dynamically evolve the conceptual structure of a database in order to facilitate virtual representation of data in a CAD environment. A generic object model is presented which spans applications from a wide range of engineering design domains. The object model is complemented with a schema model. The object model and the schema model are justified through several sample cases depicting the mapping from the object model to the schema model.", "num_citations": "11\n", "authors": ["1452"]}
{"title": "The Viking Legacy.\u201d\n", "abstract": " Our knowledge of Viking activity in western Europe largely depends on texts written by churchmen. Archaeological evidence, coins, and place-names provide a great deal of additional information, much of it unobtain-able in any other way, but that evidence is all the more instructive when set in the framework provided by the chronicles, charters, laws, and other texts produced in the churches and courts of the Christian West. The value of such conventional historical sources is underlined by comparison with eastern Europe where the only contemporary texts to help interpret the abundant archaeological and numismatic evidence were produced by Muslims and Byzantines, not by the peoples who were directly affected by the Scandinavian invaders. A few of these texts, notably those by Ibn Fadlan and Constantine Porphyrogenitos, include information gained at first hand, but our understanding of the role of Scandinavians in the east is inevitably much more conjectural than of their role in the west.", "num_citations": "11\n", "authors": ["1452"]}
{"title": "Effect of aging on post-saccadic oscillations\n", "abstract": " Recent research have shown that the eye movement data measured by an eye tracker does not necessarily reflect the exact rotations of the eyeball. For example, post-saccadic eye movements may be more reflecting the relative movements between the pupil and the iris rather than the eyeball oscillations. Since, accurate measurement of eye movements is important in many studies, it is crucial to identify different factors that influence the dynamics of the eye movements measured by an eye tracker. Previous studies have shown that deformation of the internal structure of the iris and size of the pupil directly affect the amplitude of the post-saccadic oscillations that are measured by video-based eye trackers that are pupil-based. In this paper, we look at the effect of aging on post-saccadic oscillations. We recorded eye movements from a group of 43 young and 22 older participants during an abstract and a more\u00a0\u2026", "num_citations": "10\n", "authors": ["1452"]}
{"title": "Combining data mining and text mining for detection of early stage dementia: the SAMS framework\n", "abstract": " In this paper, we describe the open-source SAMS framework whose novelty lies in bringing together both data collection (keystrokes, mouse movements, application pathways) and text collection (email, documents, diaries) and analysis methodologies. The aim of SAMS is to provide a non-invasive method for large scale collection, secure storage, retrieval and analysis of an individual\u2019s computer usage for the detection of cognitive decline, and to infer whether this decline is consistent with the early stages of dementia. The framework will allow evaluation and study by medical professionals in which data and textual features can be linked to deficits in cognitive domains that are characteristic of dementia. Having described requirements gathering and ethical concerns in previous papers, here we focus on the implementation of the data and text collection components.", "num_citations": "10\n", "authors": ["1452"]}
{"title": "Requirement process establishment and improvement from the viewpoint of cybernetics\n", "abstract": " As a branch of engineering cybernetics, automatic control theory has been extensively applied to improve products, increase productivity and rationalize management. This paper adapts the principles of automatic control theory to the field of software process improvement. In particular, the work described uses control theory to define a requirement engineering (RE) process control system, its dynamic and steady-state performance, and the steps in designing, analyzing and improving such a system. The work has highlighted the need for process activities relating to measuring elements, including those in feedback compensation and organizational support. The results of this research can be used to guide the establishment and improvement of RE processes, compare different requirement process solutions quantitatively, develop methods for evaluating benefits from process improvements, and structure the\u00a0\u2026", "num_citations": "10\n", "authors": ["1452"]}
{"title": "Speculative requirements: design fiction and RE\n", "abstract": " Many innovative software products are conceived, developed and deployed without any conventional attempt to elicit stakeholder requirements. Rather, they are the result of the vision and intuition of a small number of creative individuals, facilitated by the emergence of a new technology. In this paper we consider how the conditions that enable new products' emergence might be better anticipated, making innovations a little less reliant on individual vision and a little more informed by stakeholder need. This is particularly important where a new technology would have the potential for social impact, good or bad. Speculative design seeks to explore this landscape. We describe a case study using a variant called design fiction to explore how plausible new technologies might impact on dementia care.", "num_citations": "9\n", "authors": ["1452"]}
{"title": "Object-Oriented Database Systems: A Framework for User Interface Development\n", "abstract": " Object-oriented database management systems (OODBMSs) are emerging as commercial products. While they do not compete directly with relational databases, relational systems have established a level of usability which OODBMSs must strive to match. This is true particularly in the area of tools and user interfaces. OODBMSs pose particular problems for user interface designers but also provide some potentially exploitable characteristics. This paper identifies some of these and describes a framework for providing user interfaces for a class of OODBMS where the direct encapsulation of objects\u2019 user interfaces in methods or views is neither possible nor desirable.", "num_citations": "9\n", "authors": ["1452"]}
{"title": "Oculomotor and inhibitory control in dyslexia\n", "abstract": " Previous research has suggested that people with dyslexia may have an impairment of inhibitory control. The oculomotor system is vulnerable to interference at various levels of the system, from high level cognitive control to peripheral neural pathways. Therefore, in this work we examined two forms of oculomotor inhibition and two forms of oculomotor interference at high and low levels of the control system. This study employed a prosaccade, antisaccade, and a recent distractor eye movement task (akin to a spatial negative priming) in order to explore high level cognitive control and the inhibition of a competing distractor. To explore low-level control we examined the frequency of microsaccades and post-saccade oscillations. The findings demonstrated that dyslexics have an impairment of volitional inhibitory control, reflected in the antisaccade task. In contrast, inhibitory control at the location of a competing distractor was equivalent in the dyslexic and non-dyslexic groups. There was no difference in the frequency of microsaccades between the two groups. However, the dyslexic group generated larger microsaccades prior to the target onset in the prosaccade and the antisaccade tasks. The groups did not differ in the frequency or in the morphology of the post-saccade oscillations. These findings reveal that the word reading and attentional difficulties of dyslexic readers cannot be attributed to an impairment in the inhibition of a visual distractor or interference from low-level oculomotor instability. We propose that the inhibitory impairment in dyslexia occurs at a higher cognitive level, perhaps in relation to the process of attentional disengagement.", "num_citations": "8\n", "authors": ["1452"]}
{"title": "Canary: an interactive and query-based approach to extract requirements from online forums\n", "abstract": " Interactions among stakeholders and engineers is key to Requirements engineering (RE). Increasingly, such interactions take place online, producing large quantities of qualitative (natural language) and quantitative (e.g., votes) data. Although a rich source of requirements-related information, extracting such information from online forums can be nontrivial.We propose Canary, a tool-assisted approach, to facilitate systematic extraction of requirements-related information from online forums via high-level queries. Canary (1) adds structure to natural language content on online forums using an annotation schema combining requirements and argumentation ontologies, (2) stores the structured data in a relational database, and (3) compiles high-level queries in Canary syntax to SQL queries that can be run on the relational database.We demonstrate key steps in Canary workflow, including (1) extracting raw data from\u00a0\u2026", "num_citations": "8\n", "authors": ["1452"]}
{"title": "Dementia and social sustainability: challenges for software engineering\n", "abstract": " Dementia is a serious threat to social sustainability. As life expectancy increases, more people are developing dementia. At the same time, demographic change is reducing the economically active part of the population. Care of people with dementia imposes great emotional and financial strain on sufferers, their families and society at large. In response, significant research resources are being focused on dementia. One research thread is focused on using computer technology to monitor people in at-risk groups to improve rates of early diagnosis. In this paper we provide an overview of dementia monitoring research and identify a set of scientific challenges for the engineering of dementia-monitoring software, with implications for other mental health self-management systems.", "num_citations": "8\n", "authors": ["1452"]}
{"title": "Profiling and tracing stakeholder needs\n", "abstract": " The first stage in transitioning from stakeholders\u2019 needs to formal designs is the synthesis of user requirements from information elicited from the stakeholders. In this paper we show how shallow natural language techniques can be used to assist analysis of the elicited information and so inform the synthesis of the user requirements. We also show how related techniques can be used for the subsequent management of requirements and even help detect the absence of requirements\u2019 motivation by identifying unprovenanced requirements.", "num_citations": "8\n", "authors": ["1452"]}
{"title": "Ubiquitous computing: Adaptability requirements supported by middleware platforms\n", "abstract": " We are increasingly surrounded by computation-empowered devices that need to be aware of changes in their environment. They need to automatically adapt by taking actions based on environmental changes to ensure the continued satisfaction of user requirements. This complexity, of how to handle the requirements arising from different states of the environment, how to cope when the environment changes to ensure that ubiquitous systems [1] fulfill their intended purpose poses a major challenge for software engineering. One approach to handling this complexity at the architectural level is to augment middleware platforms with adaptive capabilities using reflection [2, 3, 4]. These augmented middleware platforms allow us to avoid building large monolithic systems that try to cover all the possible events, by providing components enabled with adaptation capabilities. These components can then be configured automatically and dynamically in response to changes in context.Our current research is concerned with how adaptive middleware can be exploited by analysts handling requirements for ubiquitous systems. The problem here is to identify the requirements for adaptability from the user requirements, and map them onto the adaptive capabilities of the middleware in a way that is traceable and verifiable.", "num_citations": "8\n", "authors": ["1452"]}
{"title": "Finding tacit knowledge by solving the pre-requirements tracing problem\n", "abstract": " Tacit knowledge prevents requirements engineers from completely identifying system constraints. Users may be unaware of the need to articulate this knowledge or even be aware they posses it. Therefore external methods of tacit knowledge identification are required. In this position paper we present a proposed method of tacit knowledge identification by solving pre-requirements specification tracing using statistical natural language processing techniques.", "num_citations": "8\n", "authors": ["1452"]}
{"title": "Understanding the impact of change in COTS-based systems\n", "abstract": " The use of commercial off-the-shelf software components (COTS) promises significant advances in terms of greater productivity, reduced time to market and reliability. However, the blackbox nature of these components poses equally significant challenges for managing maintenance, future change to componentbased systems and in particular the impact of proposed changes. Unless these challenges are adequately addressed, the use of COTS components may result in the deployment of systems that are almost impossible to maintain safely. We propose a combined approach for helping developers to understand the impact of change which relies on a COTS component-oriented development process and the use of architecture description language (ADL) for documenting component system architectures.", "num_citations": "8\n", "authors": ["1452"]}
{"title": "Known and unknown requirements in healthcare\n", "abstract": " We report experience in requirements elicitation of domain knowledge from experts in clinical and cognitive neurosciences. The elicitation target was a causal model for early signs of dementia indicated by changes in user behaviour and errors apparent in logs of computer activity. A Delphi-style process consisting of workshops with experts followed by a questionnaire was adopted. The paper describes how the elicitation process had to be adapted to deal with problems encountered in terminology and limited consensus among the experts. In spite of the difficulties encountered, a partial causal model of user behavioural pathologies and errors was elicited. This informed requirements for configuring data- and text-mining tools to search for the specific data patterns. Lessons learned for elicitation from experts are presented, and the implications for requirements are discussed as \u201cunknown unknowns\u201d, as\u00a0\u2026", "num_citations": "7\n", "authors": ["1452"]}
{"title": "The effects of previous error and success in Alzheimer\u2019s disease and mild cognitive impairment\n", "abstract": " This work investigated in Alzheimer\u2019s disease dementia (AD), whether the probability of making an error on a task (or a correct response) was influenced by the outcome of the previous trials. We used the antisaccade task (AST) as a model task given the emerging consensus that it provides a promising sensitive and early biological test of cognitive impairment in AD. It can be employed equally well in healthy young and old adults, and in clinical populations. This study examined eye-movements in a sample of 202 participants (42 with dementia due to AD; 65 with mild cognitive impairment (MCI); 95 control participants). The findings revealed an overall increase in the frequency of AST errors in AD and MCI compared to the control group, as predicted. The errors on the current trial increased in proportion to the number of consecutive errors on the previous trials. Interestingly, the probability of errors was reduced on\u00a0\u2026", "num_citations": "7\n", "authors": ["1452"]}
{"title": "How the web of things challenges requirements engineering\n", "abstract": " As a subset of the Internet of Things (IoT), the Web of Things (WoT) shares many characteristics with wireless sensor and actuator networks (WSANs) and ubiquitous computing systems (Ubicomp). Yet to a far greater degree than the IoT, WSANs or Ubicomp, the WoT will integrate physical and information objects, necessitating a means to model and reason about a range of context types that have hitherto received little or no attention from the RE community. RE practice is only now developing the means to support WSANs and Ubicomp system development, including faltering first steps in the representation of context. We argue that these techniques will need to be developed further, with a particular focus on rich context types, if RE is to support WoT application development.", "num_citations": "7\n", "authors": ["1452"]}
{"title": "Using pre-requirements tracing to investigate requirements based on tactic knowledge.\n", "abstract": " Pre-requirements specification tracing concerns the identification and maintenance of relationships between requirements and the knowledge and information used by analysts to inform the requirements\u2019 formulation. However, such tracing is often not performed as it is a time-consuming process. This paper presents a tool for retrospectively identifying pre-requirements traces by working backwards from requirements to the documented records of the elicitation process such as interview transcripts or ethnographic reports. We present a preliminary evaluation of our tools performance using a case study. One of the key goals of our work is to identify requirements that have weak relationships with the source material. There are many possible reasons for this, but one is that they embody tacit knowledge. Although we do not investigate the nature of tacit knowledge in RE we believe that even helping to identify the probable presence of tacit knowledge is useful. This is particularly true for circumstances when requirements\u2019 sources need to be understood during, for example, the handling of change requests.", "num_citations": "7\n", "authors": ["1452"]}
{"title": "Transparent Dynamic Database Evolution from Java\n", "abstract": " With the increasing provision by the ODMG standard and commercial OODBMS products for transparent access to the traditional database functionality of an OODBMS from Java, there is a need to provide Java programmers transparent access to advanced functionality such as dynamic evolution. This paper proposes a transparent API for the purpose. The API is based on a high-level object-oriented model. The application programmer interacts with the high-level model instead of interacting with the lower level model of the particular OODBMS. The various dynamic evolution features operate within the constraints of the Java type system.R\u00c9SUM\u00c9:", "num_citations": "7\n", "authors": ["1452"]}
{"title": "Language engineering for the recovery of requirements from legacy documents\n", "abstract": " Legacy documents, such as requirements documents or manuals of business procedures, can sometimes offer an important resource for informing what features of legacy software are redundant, need to be retained or can be reused. This situation is particularly acute where business change has resulted in the dissipation of human knowledge through staff turnover or redeployment. Exploiting legacy documents poses formidable problems, however, since they are often incomplete, poorly structured, poorly maintained and voluminous. This report proposes that language engineering using tools that exploit probabilistic natural language processing (NLP) techniques offer the potential to ease these problems. Such tools are available, mature and have been proven in other domains. The document provides a review of NLP and a discussion of the components of probabilistic NLP techniques and their potential for requirements recovery from legacy documents. The report concludes with a summary of the preliminary results of the adaptation and application of these techniques in the REVERE project.", "num_citations": "7\n", "authors": ["1452"]}
{"title": "Recovering Requirements from Legacy Documents\n", "abstract": " Business change is often accompanied by loss of continuity of experience. This has serious implications for the adaptation of an organisation\u2019s software since people with detailed knowledge of either the software or business processes may be unavailable to inform its adaptation. In many cases organisational memory will persist principally in the form of documents such as requirements specifications, operating procedures, regulatory standards, etc. These offer an important resource for informing what features of the software are redundant, need to be retained or can be reused. Exploiting this resource poses formidable problems, however, since it is often incomplete, poorly structured, poorly maintained and voluminous. This paper proposes that tools exploiting probabilistic natural language processing techniques offer the potential to ease these problems. Such tools are available, mature and have been proven in other domains.", "num_citations": "7\n", "authors": ["1452"]}
{"title": "Revisiting the relationship between software architecture and requirements: the case of dynamically adaptive systems\n", "abstract": " This paper revisits the relationship between software architecture and requirements focusing on the case of selfadaptive systems. The authors present their view of the state-of-the-art, including their own work, on both areas and their contribution towards the development of selfadaptive systems. The authors support the claim that there is no fundamental distinction between architectural decisions and architecturally significant requirements and discuss how these claims are specifically appropriate for the case of selfadaptive systems. A discussion of the approach described and challenges for the case of adaptive systems are also presented.", "num_citations": "6\n", "authors": ["1452"]}
{"title": "Desktop Objects: directly manipulating data and meta data\n", "abstract": " In this paper, we discuss the potential for the application of the popular and well-known desktop metaphor to object-oriented databases (OODBs). We describe an initial prototype, the Oggetto Desktop, which supports browsing of both the type and structural lattices of an OODB and direct manipulation for accomplishing schema evolution.", "num_citations": "6\n", "authors": ["1452"]}
{"title": "Specifying and constructing a fault-tolerant composite service\n", "abstract": " This paper proposes a means to specify the semantics of fault tolerant Web services at an abstract level using semantics adapted from queuing system theory. A framework that supports the implementation of specified fault-tolerance is also described. Based on our work, we show how the redundancy and diversity characteristics of a service-oriented system can be expressed and implemented in a Web-service application.", "num_citations": "5\n", "authors": ["1452"]}
{"title": "Service-Centric Systems and Requirements Engineering.\n", "abstract": " Service-Centric Systems and Requirements Engineering Why? \u2751 Different communities \u2022 Requirements engineering \u2022 Se Page 1 1 Service-Centric Systems and Requirements Engineering Luciano Baresi, Neil Maiden, Peter Sawyer Politecnico di Milano, City University London, Lancaster University Why? \u2751 Different communities \u2022 Requirements engineering \u2022 Service-centric computing \u2022 Little communication, let alone collaboration \u2751 Shared concepts \u2022 Requirements monitoring, quality-of-service, service discovery queries \u2751 But missed research and practice opportunities \u2751 The SeCSE project Page 2 2 Mini-Tutorial Agenda \u2751 Services and service-oriented systems \u2751 How each can influence the other \u2751 Some SeCSE solutions: processes and software \u2022 Publishing services based on provider specifications \u2022 Discovering services that meet consumer needs \u2022 Monitoring services for compliance \u2751 Future trends \u2751 \u2026", "num_citations": "5\n", "authors": ["1452"]}
{"title": "Requirement process establishment and improvement: from the viewpoint of cybernetics\n", "abstract": " As a branch of engineering cybernetics, automatic control theory has been extensively applied to improve product, increase productivity and rationalize management. As a first try, this paper intends to adapt the principles of conventional control theory to the field of software process, and use them to define a requirement process control system, its dynamic and steady-state performance, and steps in designing, analyzing and improving such a system. Preliminary studies show that more requirements engineering (RE) process activities relating to measuring elements, including those in feedback compensation and organization support, need to be introduced, recommended and selected. The results of this research can be used to guide the establishment and improvement of RE processes, compare different requirement process solutions quantitatively, develop methods for evaluating benefits from process\u00a0\u2026", "num_citations": "5\n", "authors": ["1452"]}
{"title": "Issues in collaborative database browsing\n", "abstract": " Interfaces to databases have traditionally been designed as single-user systems. The existence of other users has implicitly been assumed to be an attribute of the system that should be hidden from end-users. In recent years the emergence of the field of CSCW (Computer Supported Cooperative Work) has highlighted the importance of collaborative approaches in many diverse activities. This report examines the possibilities for extending the CSCW approach to searching and browsing in computerised databases. In particular we are concerned with supporting the learning of browsing techniques. In the Higher Education sector the most visible data resource is that of the university library; most of which have computerised their stocks with online public access catalogues (OPACs). This resource is supplemented by the provision of databases on CD-ROM of books and journal articles. Increasingly, both the student and the researcher are including remote libraries and databases amongst their data sources [Sack, 1986]. The relentless growth of the Internet and the success of browsers such as Mosaic only add to the enormous variety and number of resources available. The computerised library (or other similar database) is already an integral part of undergraduate courses and the skills to effectively access and utilise can be expected to become increasingly valued, both in academic and commercial environments [Jackson, 1989]. We can expect that in the near future, the ability to effectively browse databases will be one of the transferable skills expected by employers of all graduates regardless of their course of study.This report takes the OPAC as\u00a0\u2026", "num_citations": "5\n", "authors": ["1452"]}
{"title": "Deriving Adaptive Behaviour from i* models.\n", "abstract": " Dynamically Adaptive Systems (DASs) adjust their behaviour at runtime to tolerate changes in context. With potentially incomplete or inaccurate knowledge of an operating environment, tailoring specific behavioural adjustments to individual contextual changes is a time-consuming and errorprone process. i* models of a DAS'behavioural adjustments can aid understanding, and can form part of the specification of the DAS'adaptive behaviour; speeding the specification process. This paper presents an approach by which a DAS'adaptive behaviour may be derived directly from a set of i* models, and a tool capable of performing the derivation automatically.", "num_citations": "4\n", "authors": ["1452"]}
{"title": "Exposing Tacit Knowledge via Pre-Requirements Tracing\n", "abstract": " Pre-requirements specification tracing concerns the identification and maintenance of relationships between requirements and the knowledge and information used by analysts to inform the requirements' formulation. Some of the knowledge used is tacit and therefore hard to identify and associate with requirements. This paper presents a tool for retrospectively identifying pre-requirements traces from requirements to their respective source material. We posit that poorly sourced requirements may indicate a requirement based on tacit knowledge. We present a preliminary evaluation of our tools performance using a case study", "num_citations": "4\n", "authors": ["1452"]}
{"title": "SaccadeMachine: Software for analyzing saccade tests (anti-saccade and pro-saccade)\n", "abstract": " Various types of saccadic paradigms, in particular, Prosaccade and Antisaccade tests are widely used in Pathophysiology and Psychology. Despite been widely used, there has not been a standard tool for processing and analyzing the eye tracking data obtained from saccade tests. We describe an open-source software for extracting and analyzing the eye movement data of different types of saccade tests that can be used to extract and compare participants' performance and various task-related measures across participants. We further demonstrate the utility of the software by using it to analyze the data from an antisaccade, and a recent distractor experiment.", "num_citations": "3\n", "authors": ["1452"]}
{"title": "Psovis: an interactive tool for extracting post-saccadic oscillations from eye movement data\n", "abstract": " Post-microsaccadic eye movements recorded by high frame-rate pupil-based eye trackers reflect movements of different ocular structures such as deformation of the iris and pupil- eyeball relative movement as well as the dynamic overshoot of the eye globe at the end of each saccade. These Post-Saccadic Oscillations (PSO) exhibit a high degree of reproducibility across saccades and within participants. Therefore in order to study the characteristics of the post-saccadic eye movements, it is often desirable to extract the post-saccadic parts of the recorded saccades and to look at the ending part of all saccades. In order to ease the study- ing of PSO eye movements, a simple tool for extracting PSO signals from the eye movement recordings has been developed. The software application implements functions for extracting, aligning, visualising and finally exporting the PSO signals from eye movement recordings, to be used for post-processing. The code which is written in Python can be download from https://github.com/dmardanbeigi/PSOVIS.git", "num_citations": "3\n", "authors": ["1452"]}
{"title": "From click to cognition: detecting cognitive decline through daily computer use\n", "abstract": " This chapter explores cognitively based interventions that might be useful for supporting the well-being of people with dementia and their families, and familiarize the reader with the steps involved in developing interventions. The three approaches to cognitive intervention would seem to fit differently with different coping styles. The chapter considers autobiographical memory, prospective memory and meta-memory. It describes cognitive stimulation, cognitive training and cognitive rehabilitation in a little more detail, citing the guiding principles, the application and mode of delivery and the evidence base. A recent study showed that improvements in self rated quality of life were maintained over six months in people with dementia who had the benefit of maintenance cognitive stimulation therapy sessions on a weekly basis following an initial more intensive programme. The development of person-centred cognitive\u00a0\u2026", "num_citations": "3\n", "authors": ["1452"]}
{"title": "Foreword: First Workshop requirements@ run. time\n", "abstract": " The following topics are dealt with: goal oriented requirement modelling; running systems; continuous requirement engineering framework; self adaptive systems; runtime system performance monitoring; adaptive software requirement monitoring and requirements traceability.", "num_citations": "3\n", "authors": ["1452"]}
{"title": "Skeletons and Semantic Web Descriptions to Integrate Parallel Programming into Ontology Learning Frameworks\n", "abstract": " The current growth of biomedical knowledge is increasing the demand from the user community to automate the conversion of free text into a biomedical ontology. Thus ontology learning frameworks are gaining momentum as potential candidates to alleviate the current overload of biomedical information. Unfortunately the current problem at hand with these frameworks is scalability in terms of computing resources, processing power and the processing time required for biomedical experts and trained terminologists who use these frameworks. The current research study aims to tackle current difficulties in low-level parallel and distributed programming, e.g. the MPI standard, and probe the advantages for ontology learning frameworks in coupling high-level programming models together with formal semantic descriptions to enable a pay-back for the effort involved in skeleton-based parallel programming.", "num_citations": "3\n", "authors": ["1452"]}
{"title": "How to use Web services in your requirements process\n", "abstract": " An effective solution for exploiting Web services to improve requirements must support specifying both requirements and services, discover services that match user requirements, and guide service integrators to exploit Web services to improve their specifications. The Service-Centric Systems Engineering (SeCSE) project provides solutions to these challenges.", "num_citations": "3\n", "authors": ["1452"]}
{"title": "A user interface framework for object-oriented database systems\n", "abstract": " Increases in the power and pervasiveness of computers have been matched by corresponding increases in the variety and complexity of their system and application software. With the exception of a few classes of system, such as some embedded realtime software, most systems are interactive. There is a two-way communication between the information system and the user (s), and it is the user interface which is the component responsible for managing this communication. Such is the importance of providing a soundly designed user interface that Fischer [Fischer 89] observes that\" The success of new computer systems is judged less and less on processing speed and memory size and more and more on the quality of communication capabilities\"(meaning the quality of the user interface). The effort devoted to developing the user interface to a new software product which is to stand any chance of success in the market place reflects this.The increasing importance of systems' user interface components has driven the development of new paradigms of interaction. Of particular significance is the development of direct manipulation [Schneiderman 82] which permits users to interact directly with visual representations of program entities. This contrasts with traditional interaction mechanisms in which users may access entities\" indirectly\" via language abstractions such as command languages or menus. In general, direct manipulation interfaces succeed by providing representations of entities which embody tacit, visual\" clues\" to the nature of the operations which may be performed on entities. This has the effect of reducing the user's cognitive\u00a0\u2026", "num_citations": "3\n", "authors": ["1452"]}
{"title": "Towards priority-awareness in autonomous intelligent systems\n", "abstract": " In Autonomous and Intelligent systems (AIS), the decision-making process can be divided into two parts:(i) the priorities of the requirements are determined at design-time;(ii) design selection follows where alternatives are compared, and the preferred alternatives are chosen autonomously by the AIS. Runtime design selection is a trade-off analysis between non-functional requirements (NFRs) that uses optimisation methods, including decision-analysis and utility theory. The aim is to select the design option yielding the highest expected utility. A problem with these techniques is that they use a uni-scalar cumulative utility value to represent a combined priority for all the NFRs. However, this uni-scalar value doesn't give information about the varying impacts of actions under uncertain environmental contexts on the satisfaction priorities of individual NFRs. In this paper, we present a novel use of Multi-Reward Partially\u00a0\u2026", "num_citations": "2\n", "authors": ["1452"]}
{"title": "A comparison of post-saccadic oscillations in European-Born and China-Born British University Undergraduates\n", "abstract": " Previous research has revealed that people from different genetic, racial, biological, and/or cultural backgrounds may display fundamental differences in eye-tracking behavior. These differences may have a cognitive origin or they may be at a lower level within the neurophysiology of the oculomotor network, or they may be related to environment factors. In this paper we investigated one of the physiological aspects of eye movements known as post-saccadic oscillations and we show that this type of eye movement is very different between two different populations. We compared the post-saccadic oscillations recorded by a video-based eye tracker between two groups of participants: European-born and Chinese-born British students. We recorded eye movements from a group of 42 Caucasians defined as White British or White Europeans and 52 Chinese-born participants all with ages ranging from 18 to 36 during a prosaccade task. The post-saccadic oscillations were extracted from the gaze data which was compared between the two groups in terms of their first overshoot and undershoot. The results revealed that the shape of the post-saccadic oscillations varied significantly between the two groups which may indicate a difference in a multitude of genetic, cultural, physiologic, anatomical or environmental factors. We further show that the differences in the post-saccadic oscillations could influence the oculomotor characteristics such as saccade duration. We conclude that genetic, racial, biological, and/or cultural differences can affect the morphology of the eye movement data recorded and should be considered when studying eye movements\u00a0\u2026", "num_citations": "2\n", "authors": ["1452"]}
{"title": "CreativeTeams: Exploring the creative performance of co-located and virtual teams\n", "abstract": " This thesis compares the creative performance of traditional co-located and virtual teams. Motivation for this research is twofold. Firstly there is the reluctance shown by many organisations to adopt virtual working practises. Second, there is the gap in existing research exploring how virtual teams collaborate synchronously when addressing complex tasks. In particular there is a lack of empirical research com-paring co-located and virtual team performance. The CreativeTeams tool has been created to address this by providing an objective method of measuring team creative performance regardless of location. Creativity is assessed because it is an important socio-cognitive process, and is often key in addressing complex tasks requiring extensive team collaboration such as designing, problem solving and emergency planning. Such complex tasks have traditionally been the sole domain of co-located teams. This\u00a0\u2026", "num_citations": "2\n", "authors": ["1452"]}
{"title": "Beyond awareness requirements\n", "abstract": " We report the strategies and outcomes of requirements analysis in the SAMS project, which aims to detect early signs of dementia from records of user behaviour derived from monitoring home computer activity. Initial requirements elicitation specified a complex monitoring system in the genre of awareness requirements. As the complexity of the requirements for interpreting user activity became apparent, we revised our strategy towards an iterative refinement driven by analysis of recorded data. We propose that analysis of complex awareness requirements may necessitate a tool-driven approach where data mining software is configured to discover new requirements. Requirements for data mining and data analysis in SAMS are described. Application of the conceptual architecture for directing requirements analysis strategy in complex system with human in the loop for data analysis and adaptation is investigated\u00a0\u2026", "num_citations": "2\n", "authors": ["1452"]}
{"title": "From click to cognition: detecting cognitive decline through daily computer use\n", "abstract": " Detecting cognitive decline, particularly in the early stages of impairment, can often be challenging. Determining whether a memory lapse is due to age-related cognitive problems, stress, depression or early dementia may be difficult and require a multi-faceted assessment. Increasingly, older computer users are turning to the internet to find the answers. There are now several easily accessible on-line self-assessment memory tools and websites for \u2018brain training\u2019and detection of cognitive impairment. However, the ability of these on-line methods to accurately determine whether cognition is deteriorating over time and whether such deterioration is \u2018clinically significant\u2019has yet to be demonstrated. Furthermore, most of the existing methods can only determine performance at a discrete moment in time and cannot accurately assess cognitive performance on a continuous basis. Alternatively, in order to uncover subtle, early cognitive and functional changes that may indicate the onset of an impending dementia, new methods which harness the ongoing and continuously generated pool of online data generated by daily computer use may play a role. This chapter will introduce the concept of how computer software might be used to detect evolving cognitive impairment through the exploration and analysis of daily computer use outputs from elderly computer users. It will also describe the approach taken by a study at Lancaster University and the University of Manchester, UK,\u2018Software Architecture for Mental Health Self-Assessment\u2019(The \u2018SAMS\u2019study), which aims to develop a software \u2018marker\u2019of early cognitive and functional change.", "num_citations": "2\n", "authors": ["1452"]}
{"title": "Geographically distributed sensemaking: developing understanding in forum-based software development teams\n", "abstract": " Global software development is becoming increasingly popular. Working in geographically distributed teams affords advantages to both employer and employee alike. Despite this, distributed working remains a point of contention for many organisations, with some claiming it unsuitable for complex collaborative work. Many argue that the complex act of team sense making (the process by which a team develops an understanding of a situation or problem) can only effectively be performed in colocated environments. To investigate this assumption, we examine the communications of a geographically distributed game development team. This global team communicates entirely via forums, yet still manages complex sense making tasks asynchronously. We use thematic analysis to investigate how themes develop during online conversations, and use speech act sequences to explore how understanding is developed\u00a0\u2026", "num_citations": "2\n", "authors": ["1452"]}
{"title": "Satisfying requirements for pervasive service compositions\n", "abstract": " Pervasive environments are characterised by highly heterogeneous services and mobile devices with dynamic availability. Approaches such as that proposed by the Connect project provide means to enable such systems to be discovered and composed, through mediation where necessary. As services appear and disappear, the set of feasible compositions changes. In such a pervasive environment, a designer encounters two related challenges: what goals it is reasonable to pursue in the current context and how to use the services presently available to achieve his goals. This paper proposes an approach to design service compositions, facilitating an interactive process to find the trade-o between the possible and the desirable. Following our approach, the system finds at runtime, where possible, compositions related to the developer's requirements. This process can realise the intent the developer specifies at design time, taking into account the services available at runtime, without a prohibitive level of pre-specification, inappropriate for such dynamic environments.", "num_citations": "2\n", "authors": ["1452"]}
{"title": "Tracing requirements for adaptive systems using claims\n", "abstract": " The complexity of environments faced by dynamically adaptive systems (DAS) means that the RE process will often be iterative with analysts revisiting the system specifications based on new environmental understanding product of experiences with experimental deployments, or even after final deployments. An ability to trace backwards to an identified environmental assumption, and to trace forwards to find the areas of a DAS's specification that are affected by changes in environmental understanding aids in supporting this necessarily iterative RE process. This paper demonstrates how claims can be used as markers for areas of uncertainty in a DAS specification. The paper demonstrates backward tracing using claims to identify faulty environmental understanding, and forward tracing to allow generation of new behaviour in the form of policy adaptations and models for transitioning the running system.", "num_citations": "2\n", "authors": ["1452"]}
{"title": "Using QoS for relevance feedback in service discovery: A preliminary empirical investigation\n", "abstract": " Service-centric systems pose new challenges and opportunities for requirements processes and techniques. This paper describes our requirements-based service discovery tool that exploits an ontology-based quality specification mechanism to receive early feedback on candidate services that best match quality requirements. An empirical evaluation of the tool is presented that assesses the feasibility of the approach to filtering candidate services based upon quality using real-world scenarios from our industrial partners. The results reveal that commitment to a common ontology helps achieving the desired quality-based filtering.", "num_citations": "2\n", "authors": ["1452"]}
{"title": "Special section on natural language in software engineering\n", "abstract": " This special section on Natural Language in Software Engineering was conceived in response to what we observed to be the continuing ubiquity of natural language in software engineering. The short-comings of natural language as a means for precise description are well know, yet, despite the fundamental importance of precise description for the effective development of software, software engineering\u2019s reliance on natural language seems to be unshakable\u2013and, if anything, is increasing with the widespread adoption of inclusive development practices, where customer involvement in all phases of development is actively encouraged.Precise description and the development of formal and semi-formal notations have been major themes of software engineering research over the last thirty years or so. In some important contexts, however, the benefits to software engineers of such notations are undermined by their\u00a0\u2026", "num_citations": "2\n", "authors": ["1452"]}
{"title": "Handling multiple levels of requirements for middleware-supported adaptive systems\n", "abstract": " Adaptability is emerging as a crucial enabling capability for many applications, particularly those deployed in dynamically changing environments such as environment monitoring, disaster management, and military systems. One of the challenges that these pose to RE is that of complexity and how to handle the requirements arising from different states of the environment, and the requirements for coping when the environment changes. One approach to handling this complexity at the architectural level is to augment middleware systems with adaptive capabilities. This paper examines how adaptive middleware can be exploited by analysts handling requirements for adaptive systems. Here, requirements for adaptability, and the associated requirements for identifying when and how to adapt are allocated to the middleware. We describe how this is achieved in the Gridkit middleware that has been developed to support adaptive grid applications. Gridkit exploits a set of frameworks, each responsible for different types of middleware behaviour. This mechanism provides the basic capability for adaptation, while adaptability requirements are encoded as rules that are consulted at run-time when a change in the underlying environment is detected.", "num_citations": "2\n", "authors": ["1452"]}
{"title": "Ontology acquisition process: A framework for experimenting with different nlp techniques\n", "abstract": " Since the manual construction of ontologies is time-consuming and expensive, an increasing number of initiatives to ease the construction by automatic or semi-automatic means have been published. Most initiatives combine a certain level of NLP techniques with machine learning approaches to find concepts and relationships. However, a challenging issue is to quantitatively evaluate the usefulness or accuracy of the techniques and combinations of techniques when applied to ontology learning. We are developing a framework for acquiring an ontology from a large collection of domain texts. This framework provides support for evaluating different NLP and machine learning techniques when they are applied to ontology learning. Our initial experiment supports our assumptions on the usefulness of our approach.", "num_citations": "2\n", "authors": ["1452"]}
{"title": "Tracing the distribution concern: Bridging the gap\n", "abstract": " Distribution is often presented as an example of a crosscutting concern that is difficult to modularize. This paper presents an approach for modeling distribution using a combination of AOSD and use cases. One of the aims of the paper is to bridge the gap between the handling of crosscutting concerns during the early and later phases of the lifecycle when developing distributed applications. With our approach the distribution concern is modularized in control objects in Analysis, in design control classes in Design and in distributed components in Implementation and Deployment. Use cases are used to establish a clear traceability among the analysis, design, deployment and implementation stages. In this sense, control objects of the analysis have a direct correspondence with distributed components in the implementation and deployment models.", "num_citations": "2\n", "authors": ["1452"]}
{"title": "An interface to support collaborative database browsing\n", "abstract": " We describe work on a system to more effectively support the browsing of library databases. In particular we are interested in how to support the process of collaborative browsing. We have made a study of browsing techniques which included observing remote collaboration using existing simple tools including Unix talk in order to reveal the problems and requirements that a more sophisticated system should address.The use of library resources is stereotyped as a solitary activity, with hardly any mention in the substantial library science and information retrieval literature on the social aspects of information systems. However, our study indicates notable collaboration, with users consulting both library staff and each other. Informal computer-based collaboration already exists through sharing or leaning over terminals and pointing at screens. Traditionally as computer scientists we have designed databases to appear\u00a0\u2026", "num_citations": "2\n", "authors": ["1452"]}
{"title": "Investigating the potential impact of values on requirements and software engineering\n", "abstract": " This paper describes an investigation into value-based software engineering and proposes a comprehensive value taxonomy with interpretation of design feature implications. The value taxonomy is used to assess the design of Covid-19 symptom tracker applications, contrasting the UK\u2019s NHS phase 1 and 2 designs which adopted centralized, then decentralized, architectures. The value/feature analysis is also applied to the King\u2019s/Zoe Covid app which does not detect proximity, instead relying on user self-reporting. Value analysis illuminated design choices but was insufficient to account for download acceptance of the apps. We argue that motivational cost-benefit analysis needs to complement a values-based approach.", "num_citations": "1\n", "authors": ["1452"]}
{"title": "Interfaces to Database Systems (IDS94): Proceedings of the Second International Workshop on Interfaces to Database Systems, Lancaster University, 13\u201315 July 1994\n", "abstract": " A brief survey of the major DBMS and HeI conference proceedings over the past 10 years will reveal isolated pockets of research in database user interfaces but little sense of being swept along with the general advances in DBMS technology and Hel. New data models have evolved to meet the needs of different application domains; persistent programming languages are blurring the traditional distinction between data definition and application programming languages; distribution and inter-operability have become issues as have the storage of heterogeneous media types; yet it is still rare to read of the HeI issues raised by these technological innovations being expressly addressed and rarer still to find recognition of the usability problems with longer-established database technologies. There are at least two reasons why this should be surprising:\u2022 Database systems are not like other computer systems; existing both as back-ends to other applications and as stand-alone data stores, they are typically slow, deal with very large volumes of data and can involve all sorts of security, confidentiality and even cooperability issues.\u2022 Databases are everywhere. Perhaps only word processors and spread sheets are more widespread. In addition, as business cultures change and personal computing continues to mould expectations, end-users find themselves interacting increasingly closely with database systems.", "num_citations": "1\n", "authors": ["1452"]}
{"title": "Spring Wire Straightening\n", "abstract": " Equation 2 The membership functions of the input variable yield point Rp are laid down in Figure 2, page 53. The fuzziness is particularly evident in the overlapping of the variable sets. For example, an elongation limit Rp= 800 MPa at 33%(degree of membership \u03bc= 0.33) is assigned to the set very_small and at 67%(degree of membership \u03bc= 0.67) to the set small. Use of a suitable inference mechanism and a specific defuzzifying method results finally in a", "num_citations": "1\n", "authors": ["1452"]}
{"title": "Is a dominant service-centric sector good for diversity of provision?\n", "abstract": " An obvious assumption underpinning the immense interest in service-oriented computing is that it is an inherently Good Thing, by which we mean that robust processes and tools for developing service-based systems will bring benefits for service providers and service consumers. The arguments, in terms of consumer choice and flexibility, are certainly quite convincing. However, in this position paper, we question the nature of the underlying assumption, in a world where requirements are as many and varied as potential users and ask if safeguards are needed to ensure that diversity of provision is maintained.", "num_citations": "1\n", "authors": ["1452"]}
{"title": "Aiding semiotic analysis using natural language processing tools\n", "abstract": " Semiotics treats organisations as sign systems and concerns the study of organisations, human communication and information systems. It is used as an approach to requirements engineering that develops integrated structural and behavioural models. This paper focuses on the MEASUR approach, which has been successfully applied to well-understood, bounded problems. However it is difficult to apply MEASUR systematically to complex, poorly bounded problems. This paper investigates these problems and suggests how the approach could be improved by using Natural Language Processing tools to assist the process.", "num_citations": "1\n", "authors": ["1452"]}
{"title": "Using natural language processing tools to assist semiotic analysis of information systems\n", "abstract": " Semiotic Analysis has been used to aid understanding of information or communication systems, providing information that can be used during requirements engineering. The MEASUR approach begins by analysing short, natural language problem statements and manually extracting the key themes involved. As the process is scaled up and applied to longer problem statements, as found in many real life circumstances, the manual effort required increases. When the starting point for Semiotic Analysis is a large document describing the information system, such as an ethnographic report, assistance in the analytical process is necessary. This paper investigates how statistical Natural Language Processing Tools can aid this analysis. Natural Language Processing Tools can assist the analyst by directing them to the central themes in the document. Comparing a frequency list of the document with a frequency list from a large corpus of text such as the British National Corpus reveals the key words in the document. Collocation analysis of these keywords enables the creation of a lexical network and then closer investigation of the collocates in context allows the analyst to add semantic information to the model.", "num_citations": "1\n", "authors": ["1452"]}
{"title": "Guest editor's introduction to the special issue on the conference on european industrial requirements engineering\n", "abstract": " In contrast to many other conference, symposia and workshop series on RE, CEIRE was not primarily a research forum. Its focus was on exchanging experience and good practice rather than in flagging promising but yet untried research. Our aim was to provide every participant with requirements engineering practices of direct and immediate relevance to their work. We hoped that practitioners would be able to compare experiences with colleagues in different companies and domains, get nuggets of wisdom from the invited\" gurus\" and discover at first hand what the tool vendors could do for them and their business. Similarly we hoped that researchers would get an insight into the stateof-the-practice and a view of the issues emerging from technology transfer exercises.These conference aims impelled a diversity of threads concentrated into a highly parallel programme. A consequence of this was that rather than forming the core of the programme, the paper presentations were merely an equal partner to the tutorials, workshops, vendor demonstrations and informal events. To fit the conference theme, the papers chosen had to offer a clear take-home message for the expected audience.", "num_citations": "1\n", "authors": ["1452"]}
{"title": "Tackling the Concerns of Requirements Engineering\n", "abstract": " A common complaint from industrial development projects is that systems fail to address the real concerns of the major stakeholders. This results in much rework as missing requirements are identified, or incorrectly stressed requirements are changed at later stages in the life-cycle. A major cause of these problems is that the overriding needs become subsumed by other requirements information. These high-level, paramount needs, which are frequently vaguely expressed, represent the true concerns of the major stakeholders. As such they should be carefully elaborated and then used to drive the requirements process in such a way that conflicting requirements are identified early and negotiated away. This paper describes a method called PREview which integrates concerns into a viewpoint-oriented approach. PREview mandates the explicit identification and elaboration of concerns at the commencement of a\u00a0\u2026", "num_citations": "1\n", "authors": ["1452"]}
{"title": "Keynote talk\n", "abstract": " The importance of tacit knowledge in requirements elicitation and understanding is widely accepted but poorly understood. There is no clear definition of tacit knowledge, with definitions spanning knowledge that cannot be articulated to knowledge that is merely unarticulated. The situation is further confused by the fact that the most widely cited author on tacit knowledge (Michael Polanyi) actually wrote about tacit knowing. As a phenomenon, tacit knowledge is regarded both as a problem and an advantage. It\u2019sa problem because if knowledge remains tacit, then it cannot be effectively communicated and codified, making the explicit knowledge that we hold incomplete. It\u2019s an advantage because if it is valuable to our company, our competitors cannot easily gain access to it.In requirements engineering, we know that we cannot make everything explicit. Much must remain implicit; we need to assume that sufficient\u00a0\u2026", "num_citations": "1\n", "authors": ["1452"]}