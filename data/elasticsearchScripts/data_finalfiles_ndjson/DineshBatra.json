{"title": "Comparing representations with relational and EER models\n", "abstract": " The diffusion of technology to end users who can now develop their own information systems raises issues concerning the cost, quality, efficiency, and accuracy of such systems.", "num_citations": "339\n", "authors": ["2230"]}
{"title": "Conceptual data modelling in database design: similarities and differences between expert and novice designers\n", "abstract": " This paper explores the similarities and differences between experts and novices engaged in a conceptual data modelling task, a critical part of overall database design, using data gathered in the form of think-aloud protocols. It develops a three-level process model of the subjects' behavior and the differentiated application of this model by experts and novices. The study found that the experts focused on generating a holistic understanding of the problem before developing the conceptual model. They were able to categorize problem descriptions into standard abstractions. The novices tended to have more errors in their solutions largely due to their inability to integrate the various parts of the problem description and map them into appropriate knowledge structures. The study also found that the expert and novice behavior was similar in terms of modelling facets like entity, identifier, descriptor and binary relationship\u00a0\u2026", "num_citations": "213\n", "authors": ["2230"]}
{"title": "Object-oriented systems analysis and design\n", "abstract": " SYSTEMS ANALYSIS AND DESIGN Page 1 OBJECT-ORIENTED SYSTEMS ANALYSIS AND DESIGN hu-'\" . JOEY F. GEORGE DIN ES H \u0412 ATRA \u042e5\u0415\u0420\u041d S. VALACICH JEFFREY A HOFFER Page 2 Contents Preface \u0437\u0441\u0433\u0445 PART 1 FOUNDATIONS FOR OBJECT-ORIENTED SYSTEMS DEVELOPMENT 2 Chapter 1 The Object-Oriented Systems Development Environment ; What Is Information Systems Analysis and Design? 4 Systems Analysis and Design: Core Concepts 4 Systems 6 Definitions of a System and Its Parts 6 Important Systems Concepts 8 Information Systems Analysis and Design 10 Step One: Project Management and Planning 10 Step Two: Systems Analysis 11 Step Three: Systems Design 11 Step Four: Systems Implementation and Operation 12 Types of Information Systems and Systems Development 13 Transaction Processing Systems 14 Management Information Systems 14 Decision Support \u2026", "num_citations": "134\n", "authors": ["2230"]}
{"title": "Balancing agile and structured development approaches to successfully manage large distributed software projects: A case study from the cruise line industry\n", "abstract": " Agile methods and traditional structured approaches are often viewed as competing bi-polar choices. Agile methods such as Scrum and XP are recommended for small, co-located projects that involve changing requirements. The traditional structured plan-driven approaches, such as the Capability Maturity Model (CMM) and the waterfall lifecycle frameworks, are recommended for large projects with stable requirements. If a project is large, strategically important, distributed, and has dynamic user requirements and organizational changes, it presents unique challenges that neither the agile methods nor the traditional structured approaches can effectively deal with alone. Although there is an increasing call for a balanced approach, there is little empirical research that shows when and how the two approaches can complement each other. Based on a case study from the cruise line industry of a large distributed strategic project with unanticipated changes, we conclude that this balance is not only workable, but is essential to ensure that the project demonstrates both control and agility for achieving its challenging and dynamic goals. Agile without structure can cause chaos, particularly in large complex distributed projects where planning, control, and coordination are critical. Structure without agility can lead to rigidity, particularly when a project involves a great deal of learning, discovery, and changes.", "num_citations": "129\n", "authors": ["2230"]}
{"title": "Novice errors in conceptual database design\n", "abstract": " Conceptual and logical database modelling are difficult tasks for designers, and the potential for committing and correcting errors is significant. This paper reports on two laboratory experiments that investigated the underlying causes of errors committed by novice designers engaged in conceptual database modelling tasks. These causes can be traced to combinatorial complexity of the task, biases resulting from misapplication of heuristics, and incomplete knowledge about database design. The most common error was that subjects translated their initial understanding of the application into final database structures and did not consider alternative hypotheses and solutions. The paper includes recommendations to reduce the occurrence of errors.", "num_citations": "110\n", "authors": ["2230"]}
{"title": "Accessibility, security, and accuracy in statistical databases: The case for the multiplicative fixed data perturbation approach\n", "abstract": " Organizations store data regarding their operations, employees, consumers, and suppliers in their databases. Some of the data are considered confidential, and by law, the organization is required to provide appropriate security measures in order to preserve privacy. Yet a number of companies have little or no security measures. The reason for this lack of security may, at least in part, be attributed to a lack of awareness and empirical evidence about the relative effectiveness of security mechanisms. This study investigates the effectiveness of different security mechanisms for protecting numerical database attributes. The trade-off between security, accessibility, and accuracy are examined. A comparison of different security mechanisms reveals that fixed data perturbation is preferred because it maximizes both security and accessibility. An investigation of the different approaches to fixed data perturbation indicates\u00a0\u2026", "num_citations": "93\n", "authors": ["2230"]}
{"title": "Modified agile practices for outsourced software projects\n", "abstract": " Frustration with the bureaucratic nature of the disciplined approach has led to the call for agile development. The new approach is defined by the Agile Manifesto (http://agilemanifesto.org/), which values individuals and interactions over processes and tools, working software over comprehensive documentation, customer collaboration over contract negotiation, and agility in responding to change over following a prescribed plan. Agile development does not focus on process improvement; instead it focuses on customer satisfaction and employee empowerment. This is evident from reading the stated values and principles of the Agile Manifesto, which include fairly extreme positions such as \"welcome changing requirements, even late in development\" and \"the best architectures, requirements, and designs emerge from self-organizing teams.\" An interesting issue arising from the call for agile development is its role in\u00a0\u2026", "num_citations": "83\n", "authors": ["2230"]}
{"title": "Conceptual data modeling patterns: Representation and validation\n", "abstract": " The tremendous demand for software productivity has led to the idea of reuse of solutions that have worked successfully in the past. The notion of a design pattern is now well accepted in software design, and research in the area of data modeling has also begun. Although two books have explicitly attempted to cover this area, the representations provided in the books seem to be focused on specific applications and do not provide a generic and comprehensive set of templates. Another book attempts to address the problem but provides patterns at a level of granularity too small to be useful. This paper teases out underlying structures that tend to occur frequently in these books and provides patterns at an abstract and more useful level of granularity. It describes 11 data modeling patterns commonly found in business scenarios. The patterns are then validated by checking the frequency of occurrence of each pattern\u00a0\u2026", "num_citations": "68\n", "authors": ["2230"]}
{"title": "Conceptual data modelling in theory and practice\n", "abstract": " Conceptual data modelling (CDM) refers to the phase of the information systems development process that involves the abstraction and representation of the real world data pertinent to an organization. When CDM is properly and rigorously performed, the delivered system is expected to be functionally richer, less error-prone, more fully attuned to meet user needs, more able to adjust to changing user requirements and less expensive. However, there is little evidence that conceptual data modelling for the enterprise is actually conducted. There is the feeling that the \u2018corporate reality\u2019 is much different. In many organizations, CDM is never employed. In others, it is applied in a haphazard, project-to-project basis, thus leading to considerable redundancy. The academic community has mainly focused on proposing semantic data models but has not demonstrated a rigorous basis for conceptual data modelling\u00a0\u2026", "num_citations": "64\n", "authors": ["2230"]}
{"title": "CODASYS: a consulting tool for novice database designers\n", "abstract": " The paper describes the main features of a prototype tool CODASYS (COnceptual modeling tool for DAtabase SYStems), which purports to help novice designers engaged in conceptual data modeling. It is well known that conceptual data modeling is an error-prone process for novice database designers. The tool assists a designer in developing an entity-relationship diagram that can be translated to a normalized relational representation, free of derived dependencies. We first discuss a set of requirements for the tool that is based on achieving normal forms, on preventing data modeling errors, and on a theoretical foundation. We then discuss how the tool achieves the four normal forms and prevents common database errors such as incorrect degree, incorrect connectivity, and derived relationships. Further, we provide a cognitive framework for understanding novice error behavior and elaborate on how\u00a0\u2026", "num_citations": "56\n", "authors": ["2230"]}
{"title": "Improving conceptual database design through feedback\n", "abstract": " Design aids can improve the quality of systems developed by end-users and non-expert designers. This paper reports a study undertaken to establish the concept validation of a design aid that is based on feedback to improve the quality of conceptual and logical relational databases. We describe the design of SERFER (Simulated ER based FEedback system for R elational databases) and test its effectiveness in a laboratory experiment using the \"hidden operator\" method. The results show that feedback can help users detect and correct certain types of database design errors in modeling ternary relationships. However, no improvement seems possible in the case of unary relationships. The experiment could not determine whether errors can be corrected in modeling binary relationships, since the subjects were reasonably adept and rarely committed serious errors in this case.", "num_citations": "52\n", "authors": ["2230"]}
{"title": "Information Technology and Systems-I Systems Analysis and Design: Should We Be Researching What We Teach?\n", "abstract": " A guiding premise of academic scholarship is that knowledge gained from first-hand research experience is disseminated to students via the classroom. However, that valuable connection is lost when professors are not researching what they teach. In this paper, we explore issues of mismatch between teaching and research in the Information Systems (IS) discipline. Specifically, while systems analysis and design (SA&D) is an integral topic in IS curricula, this topic is the research specialty of few IS professors. This situation is reflected by the low number of research publications in this area; particularly in the leading mainstream IS journals. We characterize the gap between teaching and research in SA&D, offer possible explanations for this gap, suggest avenues to better understand and enhance SA&D research via the design science paradigm, list a number of areas in SA&D in which there is ample need and opportunity for high quality research, and show through an example how a research mindset can be incorporated in a graduate level SA&D course.", "num_citations": "47\n", "authors": ["2230"]}
{"title": "A conceptual database design approach based on rules and heuristics\n", "abstract": " Conceptual and logical database design are complex tasks for non-expert designers. Currently, the popular data models for conceptual and logical database design are the entity\u2013relationship (ER) and the relational model, respectively. Logical design methodologies for relational databases have relied on mathematically rigorous approaches which are impractical, or textbook approaches which do not provide the rich constructs to capture real applications. Consequently, designers have to use their intuition to develop their own rules and heuristics. There is a need, therefore, to develop practical rules and heuristics that can be used to handle the complexity of design in real applications. This paper proposes a realistic and detailed approach for conceptual design using the ER model for relational databases. The approach is based on four rules that specify the order in which various types of relationships\u00a0\u2026", "num_citations": "44\n", "authors": ["2230"]}
{"title": "Cognitive complexity in data modeling: causes and recommendations\n", "abstract": " Data modeling is a complex task for novice designers. This paper conducts a systematic study of cognitive complexity to reveal important factors pertaining to data modeling. Four major sources of complexity principles are identified: problem solving principles, design principles, information overload, and systems theory. The factors that lead to complexity are listed in each category. Each factor is then applied to the context of data modeling to evaluate if it affects data modeling complexity. Redundant factors from different sources are ignored, and closely linked factors are merged. The factors are then integrated to come up with a comprehensive list of factors. The factors that cannot largely be controlled are dropped from further analysis. The remaining factors are employed to develop a semantic differential scale for assessing cognitive complexity. The paper concludes with implications and recommendations\u00a0\u2026", "num_citations": "42\n", "authors": ["2230"]}
{"title": "A framework for studying human error behavior in conceptual database modeling\n", "abstract": " A framework is developed to explain human error behavior in modeling conceptual databases. The framework is based on the notion of directness distance or \u2018gulf\u2019 suggested in recent literature. It specifies four aspects of \u2018gulf\u2019 in the context of conceptual database design - syntax, mapping, rules, and consistency. Based on the model, six types of errors are suggested - syntactic, abstraction, simplification, overload, convergence, and divergence. These are then matched to errors found in four empirical studies on database representation. Four types of errors - convergence, abstraction, simplification and overload - were typically found in these studies. The paper provides design guidelines to prevent these errors.", "num_citations": "41\n", "authors": ["2230"]}
{"title": "A review and analysis of the usability of data management environments\n", "abstract": " Our objective in this paper is to provide a thorough understanding of the usability of data management environments with an end to conducting research in this area. We do this by synthesizing the existing literature that pertains to (i) data modelling as a representation medium and (ii) query interface evaluation in the context of data management. We were motivated by several trends that are prevalent in the current computing context. First, while there seems to be a proliferation of new modelling ideas that have been proposed in the literature, commensurate experimental evaluation of these ideas is lacking. Second, there appears to exist a significant user population that is quite adept at working in certain computing environments (e.g. spreadsheets) with a limited amount of computing skills. Finally, the choices in terms of technological platforms that are now available to implement new software designs allow us to\u00a0\u2026", "num_citations": "41\n", "authors": ["2230"]}
{"title": "Comparing a rule-based approach with a pattern-based approach at different levels of complexity of conceptual data modelling tasks\n", "abstract": " It is well known that conceptual database design is an unusually difficult and error-prone task for novice designers. To address the problem, at least two training approaches\u2014rule-based and pattern-based\u2014have been suggested. A rule-based approach prescribes a sequence in modelling the conceptual modelling constructs, and the action to be taken at each stage. A pattern-based approach presents data modelling structures that occur frequently in practice, and prescribes guidelines on how to recognize these structures. This paper describes the conceptual framework, experimental design, and results of a laboratory study that employed novice designers to compare the effectiveness of the two training approaches (between-subjects) at three levels of task complexity (within subjects). Results indicate an interaction effect between treatment and task complexity. The rule-based approach was significantly better in\u00a0\u2026", "num_citations": "38\n", "authors": ["2230"]}
{"title": "The use of a knowledge-based system in conceptual data modeling\n", "abstract": " Based on a study of the data modeling process of novice designers, and the errors they commit, a knowledge-based system (KBS) was designed and developed. It was found that the performance of novice designers was significantly better when they utilized the KBS instead of a system with no knowledge base. Two versions of the KBS\u2014one with a guidance interface that advised the designer on appropriate design choices and another with a restrictive interface that restricted the design choices available to the designer\u2014were developed. The restrictive interface was rated as being significantly easier to use than the guidance interface.", "num_citations": "33\n", "authors": ["2230"]}
{"title": "Consulting support during conceptual database design in the presence of redundancy in requirements specifications: an empirical study\n", "abstract": " This study examines the efficacy of a consulting system for designing conceptual databases in reducing data modelling errors. Seventy-two subjects participated in an experiment requiring modelling of two tasks using the consulting system. About half the subjects used the treatment version and the other half used the control version. The control version resembled the treatment version in the look and feel of the interface; however, it did not embed the rules and heuristics that were included in the treatment version.Research findings suggest that subjects using the treatment version significantly outscored their control version counterparts. There was an interaction effect between system and prior knowledge\u2014subjects who scored low in a pre-test benefited the most from the treatment version.This study has demonstrated that a consulting system can significantly reduce the incidence of errors committed by designers\u00a0\u2026", "num_citations": "32\n", "authors": ["2230"]}
{"title": "Extending agile principles to larger, dynamic software projects: A theoretical assessment\n", "abstract": " The article evaluates the feasibility of extending agile principles to larger, dynamic, and possibly distributed software development projects by uncovering the theoretical basis for agile values and principles for achieving agility. The extant literature focuses mainly on one theory\u2013complex adaptive systems\u2013to support agile methods, although recent research indicates that the control theory and the adaptive structuration theory are also applicable. This article proposes that at least three other theories exist that are highly relevant: transaction cost economics, social exchange theory, and expectancy theory. By employing these theories, a rigorous analysis of the Agile Manifesto is conducted. Certain agile values and principles find theoretical support and can be applied to enhance agility dynamic projects regardless of size; some agile principles find no theoretical support while others find limited support. Based on the\u00a0\u2026", "num_citations": "30\n", "authors": ["2230"]}
{"title": "Effects of data model and task characteristics on designer performance: a laboratory study\n", "abstract": " A laboratory experiment was conducted to compare designer performance in modelling user views using the relational and the entity relationship models. A user view is a form or a report used in an information system and is one of the sources of user requirements. Previous studies have not considered the effect of user view characteristics on designer performance. This study considered nine user views, which varied in two task characteristics: degree of nesting and derivation span. Degree of nesting is the number of nests in a user view, where a nest pertains to a group of attributes that is multivalued with respect to another group of attributes. Derivation span refers to the presence of attributes from different objects in the same view. Three levels each of degree of nesting and derivation span were considered. Subjects enrolled in a database class were trained in one of the two modelling approaches and were\u00a0\u2026", "num_citations": "26\n", "authors": ["2230"]}
{"title": "A study of conceptual data modeling in database design: similarities and differences between expert and novice designers\n", "abstract": " This paper explores the similarities and differences between experts and novices engaged in a conceptual data modeling task, a critical part of overall database design, using data gathered in the form of think-aloud protocols. It develops a three-level process model of the subjects' behavior and the differentiated application of this model by experts and novices. The study found that the experts focussed on generating a holistic understanding of the problem before developing the conceptual model. They were able to categorize problem descriptions into standard abstractions. The novices tended to have more errors in their solutions largely due to their inability to map parts of the problem description into appropriate knowledge structures. The study also found that the expert and novice behavior was similar in terms of modeling facets like entities, identifiers, descriptors, and binary and ternary relationships but was different in the modeling of unary relationships and categories. These findings are discussed in relation to the results of previous expert-novice studies in other domains.", "num_citations": "25\n", "authors": ["2230"]}
{"title": "Contemporary Approaches and Techniques for the Systems Analyst.\n", "abstract": " A recent survey of methodologies and techniques currently used in organizations for developing information systems indicates significant trends that call for a revision of the Information Systems (IS) Systems Analysis and Design (SA& D) course to define what methodologies, techniques, models, and tools need to be taught. As authors of analysis and design textbooks, we are particularly concerned about these trends, as are all who are involved in information systems educational programs. Each program needs to consider how to incorporate three fundamental changes on the SA& D curriculum-the growing popularity of object-oriented techniques, the emergence of the iterative approach, and the increasing adoption of the agile approach. This article discusses these three fundamental changes and references research describing the recent trends. Based on this research and on our experience teaching and writing\u00a0\u2026", "num_citations": "21\n", "authors": ["2230"]}
{"title": "The quality of data representations developed by nonexpert designers: An experimental study\n", "abstract": " A laboratory study was conducted to compare the quality of conceptual data representations in the relational form developed by non-experts using the data aggregation (DA) approach and the logical relational design methodology (LRDM). While significant differences were not found between the quality of the relational solutions developed using the two techniques, differences were noted with respect to the intermediate diagrams produced. Furthermore, subjects using the LRDM developed satisfactory Entity-Relationship (ER) solutions, but were not able to appropriately translate the ER solutions into the relational form. Subjects using the DA approach developed poor quality representations both in the data aggregation and the relational form. The findings from this study suggest that conceptual data modeling performance can be improved by using design aids which can perform the translation of ER diagrams into\u00a0\u2026", "num_citations": "20\n", "authors": ["2230"]}
{"title": "Unified modeling language (UML) topics: the past, the problems, and the prospects\n", "abstract": " Unified modeling language (UML) is a modeling language sponsored by a prominent consortium of companies, the object management group (OMG), for object-oriented (OO) systems development (Kobryn, 1999, 2004). It is widely acknowledged that UML has become the de facto standard for modeling object-oriented software development (Pender, 2003). It is used in specifying, visualizing, constructing, and documenting the artifacts of software-intensive systems (OMG, 2005). Although UML is popularly used in objectoriented software development, it is designed to be a general-purpose language with a rich set of diagrammatic notations that can model any type of software application. In a project lifecycle, it can be used for requirement determination, analysis, and design, and can serve as a basis for coding (Bell, 2004; George, Batra, Valacich, & Hoffer, 2007). It is supported by powerful tools such as the ones\u00a0\u2026", "num_citations": "19\n", "authors": ["2230"]}
{"title": "Adapting agile practices for data warehousing, business intelligence, and analytics\n", "abstract": " Business surveys indicate that fewer than 30% of data warehousing and business intelligence (DW/BI) projects meet the stated goals of the budget, schedule, and quality. Agile methods have been suggested as a possible solution, but because of the large size of the typical DW/BI project, it may be difficult to apply the agile values and principles. In this article, the following research questions are raised: Can agile practices be adapted for DW/BI development? What factors influence agile DW/BI development? Six semi-structured interviews were conducted using a questionnaire. The interview transcripts were coded using the grounded theory approach. Eight categories emerged from the analysis: business value, project management, agile development, shared understanding, technological capability, top management commitment, complexity, and organizational culture. Based on the categories, a research\u00a0\u2026", "num_citations": "17\n", "authors": ["2230"]}
{"title": "Collaboration in agile software development: Concept and dimensions\n", "abstract": " One of the four values listed in the Agile Manifesto emphasizes customer collaboration over contract negotiation, yet the literature has not explained what constitutes customer collaboration and how to assess it. Little research has examined the nature and dimensions of collaboration in the context of agile software development. Based on a grounded theory methodology and using interview data collected from five software development outsourcing vendors in China, we explore the nature and key underlying dimensions of collaboration in agile software development. Five major dimensions of collaboration emerged from our analysis: mutual benefits, engagement, coordination, communication, and knowledge sharing. In turn, each dimension comprises key subdimensions that provide a comprehensive view of collaboration. By revealing the underlying nature and key dimensions, we provide a conceptual basis for operationalizing collaboration that one can employ in future quantitative studies on agility and other project outcomes. Our study results suggest that collaboration in agile software development is multifaceted and mutually occurring in both directions between the customer and the vendor rather than single dimensional as the term \u201ccustomer collaboration\u201d in the Agile Manifesto indicates.", "num_citations": "17\n", "authors": ["2230"]}
{"title": "The READY model: Patterns of dynamic behavior in REA-based accounting applications\n", "abstract": " The Resource-Event-Agent (REA) model has gained considerable attention in accounting literature. While REA denotes a data model, which represents only the static aspect of a system, the dynamic aspect has now been introduced as the scenario concept in a recently proposed REA ontology. Using the Unified Modeling Language (UML) sequence diagram\u2014a popular method of showing interactions among objects\u2014and building on the REA framework and the scenario notion, the paper presents the READY model to illustrate patterns of dynamic behavior in accounting scenarios.", "num_citations": "17\n", "authors": ["2230"]}
{"title": "Agile values or plan-driven aspects: Which factor contributes more toward the success of data warehousing, business intelligence, and analytics project development?\n", "abstract": " Practically all organizations are developing data warehousing, business intelligence, and analytics (DW/BIA) projects for achieving customer value. A DW/BIA development project may be characterized by both agile and plan-driven aspects. The reported study investigated two research questions: (1) Which factor, agile values or plan-driven aspects, contributes more toward the success of DW/BIA? (2) What are the significant antecedents of agile values and plan-driven aspects? 124 respondents engaged in DW/BIA development filled a 30-item questionnaire on seven constructs. The partial least squares structural equation modeling (PLS-SEM) method was used to determine the strength of the relationships among the following factors: technological capability, shared understanding, top management commitment, and complexity as antecedents; agile values and plan-driven aspects as mediating; and project\u00a0\u2026", "num_citations": "16\n", "authors": ["2230"]}
{"title": "The impact of the COVID-19 on organizational and information systems agility\n", "abstract": " The unfortunate COVID-19 pandemic serendipitously might have evoked an era of agility. In information systems development (ISD), agility has been exemplified by agile software development. ISD researchers have proposed that the term agility be operationalized by the ability to create, embrace, and learn from change. The dynamic capabilities approach is similar and focuses on sensing, seizing, and reconfiguring opportunities. Risk and opportunity intelligence, aligned decision-making, IT flexibility, and employee capability are critical antecedents of agility.", "num_citations": "15\n", "authors": ["2230"]}
{"title": "Agility facilitators for contemporary software development\n", "abstract": " Agile software development generally refers to popular practices that are supposed to adhere to the Agile Manifesto with its values and principles. Empirical studies on agile software development have mainly focused on organizational adoption and impacts of agile practices. Furthermore, the literature on agile software development has mostly centered on small, co-located projects. However, agility is needed for software development projects of varied sizes in different organizations across industries. The general nature of agile values and principles and the procedure-driven nature of specific agile methods make it difficult for organizations to determine what they can do to effectively facilitate agility in their software development process. To bridge that literature gap and based on an evolved grounded-theory approach, this study identifies nine agility facilitators and their corresponding dimensions that extend\u00a0\u2026", "num_citations": "14\n", "authors": ["2230"]}
{"title": "Analysis and Design in the IS Curriculum: Taking it to the Next Level\n", "abstract": " Recent surveys of methodologies and techniques currently used in organizations for developing information systems indicate significant trends that call for a revision of the Information Systems (IS) Systems Analysis and Design (SA&D) course to define what methodologies, techniques, models, and tools need to be taught. Several course-related and environment governed trends seem to impact the coverage, including the growing popularity of object-oriented techniques, the shortening of the life cycle and the emergence of the iterative approach, the increasing adoption of the agile approach, the rising importance of UML, the outsourcing trend leading to global distribution of SA&D work, and the rate of change in the technical and business environments. The scope of the SA&D course has increased. Yet, most MIS degree programs have just one SA&D course. The typical SA&D instructor faces a number of difficult\u00a0\u2026", "num_citations": "14\n", "authors": ["2230"]}
{"title": "A comparison of user performance between the relational and the Extended Entity Relationship models in the discovery phase of database design\n", "abstract": " This paper reports on a laboratory study which compared conceptual data models developed by casual autonomous users using the relational and the extended entity relationship (EER) representation techniques. It was found that the EER model led to better user performance in modeling binary relationships, while the relational model was better in modeling unary relationships. Subjects found it difficult to model ternary relationships using either model, although the performance using the EER model was slightly better. In general, there was evidence that the EER model led to better user performance. Subjects using the EER model were more confident about their solutions and perceived the model as easier to use than their relational counterparts. The study's results raise questions concerning user performance using the relational model for a discovery (conceptual modeling) task.", "num_citations": "11\n", "authors": ["2230"]}
{"title": "Unified modeling language (UML) topics: cognitive issues in UML research\n", "abstract": " Journal of Database Management (Batra, 2008), and included four papers on the topic. The first issue covered UML application topics: the use of UML in practice (Dobing & Parsons, 2008), the organizational inadequacies of UML (Smolander & Rossi, 2008), the need to maintain seamless traceability of business rules in UML (Loucopoulos & Kadir, 2008), and assessment of the effectiveness of domain models as aids to application models developed using UML (Reinhartz-Berger & Sturm, 2008). In the current issue, the three papers address cognitive and ontological concerns related to UML. Assuming the novice perspective, VanderMeer and Dutta (2009) assert that UML is complex and difficult to learn. They evaluate the UML sequence diagram, which may be viewed as a bridge between a use case and its class diagram. By employing the cognitive complexity theory, they explore the difficulty in learning the\u00a0\u2026", "num_citations": "8\n", "authors": ["2230"]}
{"title": "A method for easing normalization of user views\n", "abstract": " Currently, most database management systems (DBMS) are based on the relational data model. Design methods that target relational models as the end product of logical design are generally based on the entity relationship model (ER) or semantic object model. Such methods entail developing an ER or semantic object representation followed by translation to the relational representation by the designer or by a CASE tool. However, there is no popular method that uses the relational concepts directly, that is, without an intermediate representation such as ER. Mathematically rigorous approaches using decomposition or synthesis do not seem to have been adopted by designers. When user views are complex, designers may encounter difficulty in the absence of an understandable method. This paper suggests a practical method for arriving at a normalized solution of user views.", "num_citations": "8\n", "authors": ["2230"]}
{"title": "Empirical validation of knowledge-based systems for conceptual database design\n", "abstract": " Conceptual database design is a complex and difficult task for non-expert designers. However, many of the commonly committed errors can be prevented with a knowledge-based (KB) design support system. The interface to such a system can be programmed using one of two strategies:(1) restrictive strategy in which the user is forced to follow a specific problem solving path or (2) the guidance strategy in which the user is advised on possible next steps in the problem solving process. This study involves the development of two versions of a KB system\u2013one with a restrictive interface and other with a guidance interface\u2013and a control system that offers no KB help. In a lab experiment non-expert designers solved a difficult data modeling task using one of the three systems. Analysis of their performance indicates that the KB systems improve the users\u2019 model accuracy. However, there was no significant difference in performance between the two KB system implementations. Subjects in the restrictive interface group rated their system as easier to use than the guidance interface group users.", "num_citations": "7\n", "authors": ["2230"]}
{"title": "Introduction to the special issue: the human-computer interface in information system design\n", "abstract": " Business professionals use various computerbased tools to improve their job productivity. The extent of improvement in end-user productivity is tightly linked to the characteristics of the humancomputer interface. These characteristics include, among others, its ease-of-use, its ease-of-learning, its on-line help facilities, and the extent to which it supports users' task completion. All the mechanisms used in the dialogue between the user and the computer constitute the interface (Card, Moran, and Newell, 1983). It includes the various input devices, the mode of dialog with the computer, the format of the menu, on-line help facilities, the presentation of information by the computer, etc.Despite many technological advances that have facilitated better interface design, the daily experience of using computers is still fraught with difficulty and barriers for most people (Kapor, 1991). Research institutions ate therefore devoting\u00a0\u2026", "num_citations": "6\n", "authors": ["2230"]}
{"title": "An event-oriented data modeling technique based on the cognitive semantics theory\n", "abstract": " The Resource-Event-Agent (REA) model has been proposed as a data modeling approach for representing accounting transactions. However, most business events are not transactions; thus, the REA formulation is incomplete. Based on the Conceptual Semantics theory, this paper discusses the entity-relationship event network (EREN) model, which extends the REA model and provides a comprehensive data template for a business event. Specifically, the notions of resource, event, and agent in the REA model are extended to include more discriminating entity types. The EREN technique can be used to identify events, sketch a network of events, and develop a data model of a business application by applying the EREN template to each event. Most extant techniques facilitate only the descriptive role whereas the EREN technique facilitates both the design and descriptive role of data modeling.", "num_citations": "5\n", "authors": ["2230"]}
{"title": "A deep knowledge planning decision support system for aiding nuclear waste transportation decisions\n", "abstract": " Planners and public policy makers in recent years have become increasingly concerned with issues related to nuclear waste transportation. Rational planning and policy for nuclear waste transportation depends upon systematically assimilating into a coherent and meaningful whole, diverse information at several levels of analysis. The authors describe and demonstrate the rudiments of a deep knowledge architecture for evaluating alternative nuclear waste transshipment possibilities.", "num_citations": "5\n", "authors": ["2230"]}
{"title": "Systems Analysis and Design\n", "abstract": " Journal of Information Systems Education | Vol 17 | Iss 3 Home Search Browse All Content My Account About DC Network Digital Commons Network\u2122 Skip to main content AIS Electronic Library (AISeL) Association for Information Systems Login Home Join AIS JAIS CAIS TRR THCI MISQE Home > Journals > Affiliated Journals > JISE > Vol. (2006) > Iss. Journal of Information Systems Education Systems Analysis and Design Article PDF Systems Analysis & Design: An Essential Part of IS Education Albert L. Harris, Michael Lang, Briony Oates, and Keng Siau PDF Interleaving Modeling and Writing Activities in Systems Analysis and Design James J. Pomykalski PDF Reflections on Teaching Information Systems Analysis and Design: From Then to Now! David Avison, Melissa Cole, and Guy Fitzgerald PDF Contemporary Approaches and Techniques for the Systems Analyst Dinesh Batra and John W. Satzinger PDF An \u2026", "num_citations": "4\n", "authors": ["2230"]}
{"title": "A comparison of the data aggregation approach with the logical relational design methodology\n", "abstract": " A laboratory study comparing relational representations developed using the Data Aggregation approach with the Logical Relational Design Methodology (LRDM) was conducted to investigate whether non-expert users could better comprehend and apply either methodology. While no significant differences between user performance were noted, the study did find that subjects following the LRDM produced quality Entity-Relationship (ER) representations, but there was a marked deterioration of the translation to the relational form. The Data Aggregation solutions were generally poor in quality. The study concludes that while non-expert designers can produce acceptable data abstractions using a conceptual modeling methodology (eg, ER diagrams), problems may arise during conversion to normalized relations (eg, relational representations).", "num_citations": "4\n", "authors": ["2230"]}
{"title": "What Constitutes Software Development Agility?\n", "abstract": " Software development agility is the capability to manage various kinds of changes during the development process. Agile methods purport to facilitate processes that can address agility. However, the underlying dimensions of agility are not well elucidated in the literature. Specifically, what constitutes software development agility and what are organizational antecedents and outcomes of the agility dimensions are research questions that remain to be adequately answered. To bridge this literature gap, this study presents agility dimensions with corresponding descriptions that can help develop measures of agility. This study will contribute to the theoretical literature by developing better understanding about the measurement and nature of agility. Furthermore, the study will provide guidance to practitioners regarding specific processes for achieving agility in the agile software development process.", "num_citations": "3\n", "authors": ["2230"]}
{"title": "Improving Sequence Diagram Modeling Performance: A Technique Based on Chunking, Ordering, and Patterning\n", "abstract": " The Unified Modeling Language (UML) has become the de facto standard for object-oriented software development. It has been widely adopted in both training and practice. However, UML has often been criticized for being overly complex and difficult to learn for novice analysts. Although some research studies have identified specific novice difficulties in learning UML, there is little research proposing viable techniques for addressing these difficulties. In particular, there is a lack of research evaluating the usability of the sequence diagram (SD), which models the interactions among objects of a software application. This paper reports a research study that proposes a technique called \u201cCHOP\u201d(CHunking, Ordering, Patterning), which is designed to improve novice analyst performance in modeling an SD. The CHOP technique is based on the Cognitive Load Theory (CLT) and was developed by addressing the three\u00a0\u2026", "num_citations": "3\n", "authors": ["2230"]}
{"title": "The effect of user view characteristics on database design performance of novices\n", "abstract": " Database design is a complex task for end users and novice designers. User views are an excellent input source for database design. This research investigates the effect of certain characteristics of user views on designer performance in the logical database design task. The study examines the extent to which performance of nonexpert designers engaged in normalizing user views and eliminating derived relationships can be predicted by examining the structure of user views. Two constructs that capture the complexity of a user view are defined-degree of nesting and derivation span. User views which varied on these parameters were included in a case. Subjects, who were enrolled in a database class and had learned the view decomposition approach, were asked to conduct logical database design of the case. Each view was graded using a predefined scheme. For each subject, there was a set of scores\u00a0\u2026", "num_citations": "3\n", "authors": ["2230"]}
{"title": "An investigation of the effectiveness of statistical distributions for additive fixed data perturbation\n", "abstract": " Statistical databases provide security of confidential data by preventing access to individual values. However, under certain situations, the security of individual data can be compromised by statistical functions alone. A number of approaches have been suggested to counter this problem. This paper addresses one such approach, namely, fixed data perturbation. The purpose of the research is to evaluate the effectiveness of different statistical distributions in perturbing different forms of database populations when employing an additive form of fixed data perturbation. Specifically, this paper evaluates the effectiveness of the Normal, Log-normal, Gamma and Uniform distributions in perturbing data sets with a defined distribution. The results of extensive Monte-Carlo experiments conducted on different database populations reveal that the Uniform distribution provides the best performance (high security and low bias\u00a0\u2026", "num_citations": "3\n", "authors": ["2230"]}
{"title": "Job-work fit as a determinant of the acceptance of large-scale agile methodology\n", "abstract": " The declaration of the Agile Manifesto in 2001 was hailed as a paradigmatic shift in the development of software systems. Initially, agile development was typically deployed in projects with a single team with fewer than ten members. Recently, a new kind of agile development has emerged for larger projects that may be referred to as large-scale agile methodology (LSAM). The taxonomy of LSAM is more enhanced and subsumes the Agile Manifesto. Based on the software development literature, the study investigates five important antecedents of methodology acceptance: perceived usefulness, compatibility, subjective norm, mandatoriness, and external support. As a result of the initial PLS analysis, the study introduces the notion of Job-Work Fit as a second-order construct composed of perceived usefulness and compatibility. Based on a survey of 123 respondents, the study finds that the construct job-work fit\u00a0\u2026", "num_citations": "2\n", "authors": ["2230"]}
{"title": "The relational model versus the extended entity relationship model: A comparison of representations developed by autonomous users\n", "abstract": " The inadequacies of the three classical data models in their ability to directly and naturally capture complex relationships between objects have led to suggestions of semantic data models. However, there is little empirical evidence that the semantic models lead to better user performance than the classical data models in conceptual data representation or any other database task.", "num_citations": "2\n", "authors": ["2230"]}
{"title": "Adapting Agile Practices for Analytics Projects\n", "abstract": " Business surveys indicate that fewer than 30% of business intelligence (BI) and data warehousing (DW) projects meet the stated goals on budget, schedule, and quality. Specifically, it has been noted that such projects are marred with delays from environment, and changes in user requirements during this period may render the project irrelevant. Usually projects are available to end users after they have been fully implemented, which can take several months or even years. Other times, end users do not see the business value of the information afforded by the projects. Agile practices can address the changes in end user requirements but because of the large size of the typical analytics project, it may difficult to apply the agile values and principles. In this study, the following research question is raised: how can agile practices be applied to analytics projects to achieve customer value and project success? Based on the agile, and analytics literature, an empirical study is proposed to examine the competing maxims for balancing agility with structured practices.", "num_citations": "1\n", "authors": ["2230"]}
{"title": "Tradeoffs between Delivery Capability and Agility in Software Development\n", "abstract": " The notion of delivery capability, which is the ability to deliver software solutions, is rooted in the traditional software development practices. In recent years, agile methods have become popular and the notion of agility, which is the ability to respond to changes, has become equally prevalent. A popular book has debated the balance between agility and discipline. Delivery capability can be considered as a surrogate of discipline. The effects of delivery capability and agility on software development success measures have not been evaluated in a quantitative study. Furthermore, the effects of antecedent process variables on delivery capability and agility have not been quantified. The process variables themselves may have antecedents. The structural model to determine these effects is, therefore, a lot more complex than has been reported in the literature. This research-inprogress study provides the basis for\u00a0\u2026", "num_citations": "1\n", "authors": ["2230"]}
{"title": "Cognitive Complexity Factors in Data Modeling\n", "abstract": " We live in the age of complexity. Yet, complexity is rarely studied in MIS. The paper studies cognitive complexity in an important IS domain\u2013data modeling. The focus is on novice data modelers. Four major sources of complexity principles are identified: problem solving principles, design principles, information overload, and systems theory. Based on prior literature, the factors that lead to complexity are listed in each category. Each factor is then applied to the context of data modeling to gauge the extent to which it affects data modeling complexity. Redundant factors from different sources are ignored, and closely linked factors are identified. The factors are then integrated to come up with a comprehensive list of factors, which are divided into two categories\u2013those that are intrinsic to data modeling and are difficult to control, and those than can be addressed to minimize data modeling complexity.", "num_citations": "1\n", "authors": ["2230"]}
{"title": "Experimental research in systems development methodologies: Opportunities and challenges\n", "abstract": " While GSS models identify individual member characteristics as an explanatory variable, little research has been dotie to examine the impact of these variables on the group process. One explanation for this dearth of research is simply that the number of possible dimensions of individual characteristics that could be explored is extremely large. The work of mental model researchers provides an excellent starting point for more closely examining the unique knowledge, understandings and perspectives that individuals bring to lhe group process.In this paper, we suggest an approach that addresses two significant barriers which confront GSS researchers interested in exploring this area: the extremely time consuming methodologies required to elicit and represent mental models and the lack of a means to form groups based on the similarity and dissimilarity of Lhe mental models of the group members. We detail a\u00a0\u2026", "num_citations": "1\n", "authors": ["2230"]}
{"title": "An ER Based Methodology for Modeling User Views and Detecting Derived Relationships\n", "abstract": " The entity relationship (ER) data model has become the most popular conceptual data modeling tool. Most CASE and expert tools that perform data modeling are based on the ER model. Further, many ER-based methodologies have been proposed. No ER-based methodology, however, has presented a systematic approach to model user views. This paper suggests an ER-based methodology for data modeling of user views even if they are complex and involve many layers of nested data. The methodology can not only handle binary relationships, but also ternary and higher degree relationships. In addition, it includes a methodical approach to detect derived relationships. It should be possible to implement the methodology in a CASE or expert tool.", "num_citations": "1\n", "authors": ["2230"]}