{"title": "Context-aware aspects\n", "abstract": " Context-aware applications behave differently depending on the context in which they are running. Since context-specific behavior tends to crosscut base programs, it can advantageously be implemented as aspects. This leads to the notion of context-aware aspects, i.e., aspects whose behavior depends on context. This paper analyzes the issue of appropriate support from the aspect language to both restrict the scope of aspects according to the context and allow aspect definitions to access information associated to the context. We propose an open framework for context-aware aspects that allows for the definition of first-class contexts and supports the definition of context awareness constructs for aspects, including the ability to refer to past contexts, and to provide domain- and application-specific constructs.", "num_citations": "105\n", "authors": ["131"]}
{"title": "Classboxes: A minimal module model supporting local rebinding\n", "abstract": " Classical module systems support well the modular development of applications but do not offer the ability to add or replace a method in a class that is not defined in that module. On the other hand, languages that support method addition and replacement do not provide a modular view of applications, and their changes have a global impact. The result is a gap between module systems for object-oriented languages on one hand, and the very desirable feature of method addition and replacement on the other hand. To solve these problems we present classboxes, a module system for object-oriented languages that provides method addition and replacement. Moreover, the changes made by a classbox are only visible to that classbox (or classboxes that import it), a feature we call local rebinding. To validate the model, we have implemented it in the Squeak Smalltalk environment, and performed\u00a0\u2026", "num_citations": "74\n", "authors": ["131"]}
{"title": "Identifying cycle causes with enriched dependency structural matrix\n", "abstract": " Dependency structure matrix (DSM) has been successfully applied to identify software dependencies among packages and subsystems. A number of algorithms were proposed to compute the matrix so that it highlights patterns and problematic dependencies between subsystems. However, existing DSM implementations often miss important information to fully support reengineering effort. For example, they do not clearly qualify and quantify problematic relationships, information which is crucial to support remediation tasks.In this paper we present enriched DSM (eDSM) where cells are enriched with contextual information about (i) the type of dependencies (inheritance, class reference...), (ii) the proportion of referencing entities, (iii) the proportion of referenced entities. We distinguish independent cycles and stress potentially simple fixes for cycles using coloring information. This work is language independent and\u00a0\u2026", "num_citations": "45\n", "authors": ["131"]}
{"title": "Learning from source code history to identify performance failures\n", "abstract": " Source code changes may inadvertently introduce performance regressions. Benchmarking each software version is traditionally employed to identify performance regressions. Although effective, this exhaustive approach is hard to carry out in practice. This paper contrasts source code changes against performance variations. By analyzing 1,288 software versions from 17 open source projects, we identified 10 source code changes leading to a performance variation (improvement or regression). We have produced a cost model to infer whether a software commit introduces a performance variation by analyzing the source code and sampling the execution of a few versions. By profiling the execution of only 17% of the versions, our model is able to identify 83% of the performance regressions greater than 5% and 100% of the regressions greater than 50%.", "num_citations": "40\n", "authors": ["131"]}
{"title": "Analyzing software process models with AVISPA\n", "abstract": " Software process models are sophisticated and large specifications aimed at organizing and managing software development. Their formal specification demands an enormous effort, but once specified there are few approaches and even fewer tools that aid the process engineer to analyze the quality of the process. For the last five years we have aided software companies in specifying their software processes and we have found a series of error patterns that indicate the potential presence of misconceptions or misspecifications. This paper presents these patterns, characterizes the kinds of errors they potentially reveal, and details how errors could be localized within a software process model. To assist process engineers to analyze the quality of their processes, we provide Avispa, a tool that graphically renders different aspects of a process model and highlights potential errors as intuitive and comprehensible\u00a0\u2026", "num_citations": "38\n", "authors": ["131"]}
{"title": "Avispa: a tool for analyzing software process models\n", "abstract": " Defining and formalizing the software development process is a common means for improving it. Software process modeling is often a challenging and expensive endeavor, because a well specified process may still include inefficiencies that are hardly detected before enacting it. Thus, assessing process quality is a relevant concern to improve several aspects such as conceptual integrity, correctness, usability, maintainability, and performance, among others. This paper describes Avispa, a graphical tool that allows analyzing the quality of SPEM 2.0 software processes models. Avispa identifies a series of error patterns and highlights them in different blueprints. A detailed description of the internals of Avispa is provided to show both its structure and its extensibility mechanisms. We also present an interactive mechanism to define new analysis scripts and to implement new patterns and blueprints. This paper\u00a0\u2026", "num_citations": "28\n", "authors": ["131"]}
{"title": "Software process model blueprints\n", "abstract": " Explicitly defining a software process model is widely recognized as a good software engineering practice. However, having a defined process does not necessarily mean that this process is good, sound and/or useful. There have been several approaches for software process evaluation including testing, simulation and metrics; the first one requires software process enactment, i.e., an expensive, risky and long process, and the others require high expertise for correctly interpreting their meaning. In this paper we propose a visual approach for software process model evaluation based on three architectural view types, each one focusing on basic process elements: Role Blueprint, Task Blueprint and Work Product Blueprint. They enable visual evaluation of different perspectives of a software process, each being relevant for a particular stakeholder. We illustrate the proposed approach by applying it to the\u00a0\u2026", "num_citations": "22\n", "authors": ["131"]}
{"title": "Squale\u2013software quality enhancement\n", "abstract": " The Squale project was born from industrial effort to control software quality. Its goals are to refine and enhance Qualixo model, a software-metric based quality model already used by large companies in France (Air France-KLM, PSA Peugeot-Citroen) and to support the estimation of return on investment produced by software quality. Qualixo model is a software quality model based on the aggregation of software metrics into higher level indicators called practices, criterias and factors. The coordination of Squale is carried out by Qualixo.", "num_citations": "22\n", "authors": ["131"]}
{"title": "Adding state and visibility control to traits using lexical nesting\n", "abstract": " Traits are reusable building blocks that can be composed to share methods across unrelated class hierarchies. Original traits are stateless and cannot express visibility control for methods. Two extensions, stateful traits and freezable traits, have been proposed to overcome these limitations. However, these extensions introduce complexity and have not yet been combined to simultaneously add both state and visibility control to traits.               This paper revisits the addition of state and visibility control to traits. Rather than extending the original traits model with additional operations, we allow traits to be lexically nested within other modules. Traits can then have (shared) state and visibility control by hiding variables or methods in their lexical scope. Although the Traits\u2019 \u201cflattening property\u201d has to be revisited, the combination of traits with lexical nesting results in a simple and expressive trait model. We discuss\u00a0\u2026", "num_citations": "21\n", "authors": ["131"]}
{"title": "Counting messages as a proxy for average execution time in pharo\n", "abstract": " Code profilers are used to identify execution bottlenecks and understand the cause of a slowdown. Execution sampling is a monitoring technique commonly employed by code profilers because of its low impact on execution. Regularly sampling the execution of an application estimates the amount of time the interpreter, hardware or software, spent in each method execution time. Nevertheless, this execution time estimation is highly sensitive to the execution environment, making it non reproductive, non-deterministic and not comparable across platforms.               On our platform, we have observed that the number of messages sent per second remains within tight (\u00b17%) bounds across a basket of 16 applications. Using principally the Pharo platform for experimentation, we show that such a proxy is stable, reproducible over multiple executions, profiles are comparable, even when obtained in different\u00a0\u2026", "num_citations": "20\n", "authors": ["131"]}
{"title": "Tracking down performance variation against source code evolution\n", "abstract": " Little is known about how software performance evolves across software revisions. The severity of this situation is high since (i) most performance variations seem to happen accidentally and (ii) addressing a performance regression is challenging, especially when functional code is stacked on it. This paper reports an empirical study on the performance evolution of 19 applications, totaling over 19 MLOC. It took 52 days to run our 49 benchmarks. By relating performance variation with source code revisions, we found out that: (i) 1 out of every 3 application revisions introduces a performance variation, (ii) performance variations may be classified into 9 patterns, (iii) the most prominent cause of performance regression involves loops and collections. We carefully describe the patterns we identified, and detail how we addressed the numerous challenges we faced to complete our experiment.", "num_citations": "19\n", "authors": ["131"]}
{"title": "Increasing test coverage with hapao\n", "abstract": " Test coverage is about assessing the relevance of unit tests against the tested application. It is widely acknowledged that software with a \u201cgood\u201d test coverage is more robust against unanticipated execution, thus lowering the maintenance cost. However, ensuring good quality coverage is challenging, especially since most of the available test coverage tools do not discriminate between software components that require \u201cstrong\u201d coverage from the components that require less attention from the unit tests. Hapao is an innovative test coverage tool, implemented in the Pharo Smalltalk programming language. It employs an effective and intuitive graphical representation to visually assess the quality of the coverage. A combination of appropriate metrics and relations visually shape methods and classes, which indicates to the programmer whether more effort on testing is required. This paper presents the important\u00a0\u2026", "num_citations": "19\n", "authors": ["131"]}
{"title": "CuboidMatrix: Exploring dynamic structural connections in software components using space-time cube\n", "abstract": " Static and dynamic evolution of software systems may be described in terms of connection additions and removals in a graph. Due to the inherent complexity of software, navigating through such a dynamic network is a non-trivial task and extracting relevant information typically involves sophisticated queries. We explore the notion of space-time cube, a well-known 3D representation of an evolving dynamic graph, to support a set of software engineering activities. CuboidMatrix is a visualization tool that offers simple and expressive navigation operations. We have evaluated our tool against two software comprehension activities, namely (i) assessing interaction of classes during a software execution and (ii) exploring the cause of breaking Lint-like quality rules over a large number of software revisions.", "num_citations": "15\n", "authors": ["131"]}
{"title": "Ic2d: Interactive control and debugging of distribution\n", "abstract": " Within the trend of object-based distributed programming, we present a non-intrusive graphical environment for remote monitoring and steering, IC2D: Interactive Control and Debugging of Distribution. Applications developped using the 100% Java ProActive PDC (Parallel, Distributed and Concurrent) computing library are monitored for \u2018free\u2019 by IC2D. As those targetted applications can run on any distributed runtime support ranging from multiprocessor workstations, clusters, to grid-based infrastructures (through the Globus toolkit), IC2D turns out to be a grid-enabled programming environment.", "num_citations": "15\n", "authors": ["131"]}
{"title": "Creating sophisticated development tools with OmniBrowser\n", "abstract": " Smalltalk is not only an object-oriented programming language; it is also known for its extensive integrated development environment supporting interactive and dynamic programming. While the default tools are adequate for browsing the code and developing applications, it is often cumbersome to extend the environment to support new language constructs or to build additional tools supporting new ways of navigating and presenting source code. In this paper, we present the OmniBrowser, a browser framework that supports the definition of browsers based on an explicit metamodel. With OmniBrowser a domain model is described in a graph and the navigation in this graph is specified in its associated metagraph. We present how new browsers are built from predefined parts and how new tools are easily described. The browser framework is implemented in the Squeak Smalltalk environment. This paper shows\u00a0\u2026", "num_citations": "13\n", "authors": ["131"]}
{"title": "Object equivalence: Revisiting object equality profiling (an experience report)\n", "abstract": " Modern object-oriented programming languages greatly alleviate the memory management for programmers. Despite the efficiency of garbage collection and Just-In-Time program analyzes, memory still remains prone to be wasted.   A bloated memory may have severe consequences, including frequent execution lags due to a high pressure on the garbage collector and suboptimal object dependencies.   We found that dynamically monitoring object production sites and the equivalence of the produced objects is key to identify wasted memory consumption caused by redundant objects. We implemented optimizations for reducing the memory consumption of six applications, achieving a reduction over 40% in half of the applications without having any prior knowledge of these applications.   Our results partially replicate the results obtained by Marinov and O'Callahan and explore new ways to identify redundant\u00a0\u2026", "num_citations": "10\n", "authors": ["131"]}
{"title": "Seaside\u2014Advanced Composition and Control Flow for Dynamic Web Applications\n", "abstract": " Page-centric Web application frameworks fail to offer adequate solutions to model composition and control flow. Seaside allows Web applications to be developed in the same way as desktop applications. Control flow is modelled as a continuous piece of code, and components may be composed, configured and nested as one would expect from traditional user interface frameworks.", "num_citations": "10\n", "authors": ["131"]}
{"title": "Aspectboxes: Controlling the Visibility of Aspects\n", "abstract": " Aspect composition is still a hot research topic where there is no consensus on how to express where and when aspects have to be composed into a base system. In this paper we present a modular construct for aspects, called aspectboxes, that enables aspects application to be limited to a well defined scope. An aspectbox encapsulates class and aspect definitions. Classes can be imported into an aspectbox defining a base system to which aspects may then be applied. Refinements and instrumentation defined by an aspect are visible only within this particular aspectbox leaving other parts of the system unaffected.", "num_citations": "10\n", "authors": ["131"]}
{"title": "Visualizing and assessing a compositional approach of business process design\n", "abstract": " In the context of Services Oriented Architecture (Soa), complex systems are realized through the design of business\u2013driven processes. Since the design of a complete process can be complex, composition tools such as aspects and features propose to define large systems by composing smaller artifacts, easier to understand. But these techniques shift the system complexity into the definition of composition directives able to build it. At composition time, process designers need support to assist them and assess their designed systems. We propose in this article a set of visualizations to represent compositions of business\u2013processes and then identify patterns and categorizations. We use the Adore framework as the underlying process composition platform. We validate this work by visualizing and assessing a Car Crash Crisis Management system (CCCMS, a comparison referential for Aspect Oriented\u00a0\u2026", "num_citations": "9\n", "authors": ["131"]}
{"title": "Prototyping Languages, Related Constructs and Tools with Squeak.\n", "abstract": " Prototyping new programming languages is often assimilated as a task requiring heavy expertise in parsing and compilation. This paper argues that choosing as a host platform a language having advanced reflective capabilities helps in reducing the effort and time spent on developing new language related constructs and tools. The Squeak Smalltalk implementation provides very expressive reflective facilities. In this paper we focus on having methods as first class entities, enabling methods manipulation as plain standard objects and reification of method execution. Powerful language related tools and efficient new programming constructs can be quickly implemented. ByteSurgeon, a bytecode manipulation library, and FacetS, an aspect mechanism, serve as illustrations.", "num_citations": "9\n", "authors": ["131"]}
{"title": "An architecture-tracking approach to evaluate a modular and extensible flight software for CubeSat nanosatellites\n", "abstract": " Delivering better flight software is an important concern to improve CubeSat missions success. It has been identified as a key element to enhance team collaboration, increase reusability, reduce the mission risk, and facilitate the development and operation of new mission concepts, such as satellite mega-constellations. An appropriated fight software architecture represents the functional and non-functional requirements and guides the development. Therefore, to achieve the expected software quality, the architecture should be closely monitored during the entire software life cycle. However, ensuring that a flight software for a spacecraft embedded system closely follows the proposed architecture and addresses the set of non-functional requirements is a difficult and nontrivial problem. Motivated by requirements commonly described in previous CubeSat missions, in this work, we present the design and\u00a0\u2026", "num_citations": "8\n", "authors": ["131"]}
{"title": "Live programming in practice: A controlled experiment on state machines for robotic behaviors\n", "abstract": " ContextLive programming environments are gaining momentum across multiple programming languages. A tenet of live programming is a development feedback cycle, resulting in faster development practices. Although practitioners of live programming consider it a positive inclusion in their workflow, no in-depth investigations have yet been conducted on its benefits in a realistic scenario, nor using complex API.ObjectiveThis paper carefully studies the advantage of using live programming in defining nested state machines for robot behaviors. We analyzed two important aspects of developing robotic behaviors using these machines: program comprehension and program writing. We analyzed both development practices in terms of speed and accuracy.MethodWe conducted two controlled experiments, one for program comprehension and another for program writing. We measured the speed and accuracy of\u00a0\u2026", "num_citations": "8\n", "authors": ["131"]}
{"title": "Analyzing the Scrum process model with AVISPA\n", "abstract": " Scrum is a widely known agile software process model specifically designed for guiding non-technical activities in software development. This process is formally defined in EPF and adopted by several software companies around the world. But having a process definition does not necessarily mean that it is well specified. We have developed AVISPA, a tool for localizing error patterns in software process models specified with EPF. In this paper, we analyze the public community specification of Scrum using AVISPA and we report our findings.", "num_citations": "8\n", "authors": ["131"]}
{"title": "FacetS: First class entities for an open dynamic AOP language\n", "abstract": " This paper describes a new aspect language construct for Squeak, named FACETS. Aspects are completely integrated within the Squeak programming language and its environment. The innovations of FACETS are:(i) traits can be part of the pointcut definition,(ii) two scoping policies are available to share state among aspects and (iii) aspects are prototype-based.", "num_citations": "8\n", "authors": ["131"]}
{"title": "Refactoring legacy JavaScript code to use classes: The good, the bad and the ugly\n", "abstract": " JavaScript systems are becoming increasingly complex and large. To tackle the challenges involved in implementing these systems, the language is evolving to include several constructions for programming-in-the-large. For example, although the language is prototype-based, the latest JavaScript standard, named ECMAScript 6 (ES6), provides native support for implementing classes. Even though most modern web browsers support ES6, only a very few applications use the class syntax. In this paper, we analyze the process of migrating structures that emulate classes in legacy JavaScript code to adopt the new syntax for classes introduced by ES6. We apply a set of migration rules on eight legacy JavaScript systems. In our study, we document: (a) cases that are straightforward to migrate (the good parts); (b) cases that require manual and ad-hoc migration (the bad parts); and (c) cases that cannot be\u00a0\u2026", "num_citations": "7\n", "authors": ["131"]}
{"title": "Toward lean development in formally specified software processes\n", "abstract": " Formally specifying the software development process has been the way followed by several companies for making development more predictable. However this formality has frequently introduced bureaucracy into the process. Lean software development is an agile practice that promotes developing only those work products that are required, ie, no waste should be included in the process. In this paper we present an automatic means of detecting and localizing the presence of certain type of waste in software processes that are formally specified using SPEM 2.0. We show our findings by analyzing the Scrum process model and the software development process model of a medium size software development company in Chile.", "num_citations": "7\n", "authors": ["131"]}
{"title": "The Debuggable Interpreter Design Pattern.\n", "abstract": " The use of Interpreter and Visitor design patterns has been widely adopted to implement programming language interpreters due to their expressive and simple design. However, no general approach to conceive a debugger is commonly adopted.This paper presents the debuggable interpreter design pattern as a general approach to extend a language interpreter with debugging facilities such as step-over and step-into. Moreover, it enables multiple debuggers coexisting and extends the Interpreter and Visitor design patterns with a few hooks and a debugging service. SmallJS, an interpreter for Javascript-like language, serves as an illustration.", "num_citations": "7\n", "authors": ["131"]}
{"title": "Reducing resource consumption of expandable collections: The pharo case\n", "abstract": " Expandable collections are collections whose size may vary as elements are added and removed. Hash maps and ordered collections are popular expandable collections. Expandable collection classes offer an easy-to-use API, however this apparent simplicity is accompanied by a significant amount of wasted resources.We describe some improvements of the collection library to reduce the amount of waste associated with collection expansions. We have designed two new collection libraries for the Pharo programming language that exhibit better resource management than the standard library. We improved the Pharo collection library using two complementary perspectives.First, across a basket of 5 applications, our optimized collection library significantly reduces the memory footprint of the collections: (i) the amount of intermediary internal array storage by 73%, (ii) the number of allocated bytes by 67% and (iii\u00a0\u2026", "num_citations": "6\n", "authors": ["131"]}
{"title": "Verifiable source code documentation in controlled natural language\n", "abstract": " Writing documentation about software internals is rarely considered a rewarding activity. It is highly time-consuming and the resulting documentation is fragile when the software is continuously evolving in a multi-developer setting. Unfortunately, traditional programming environments poorly support the writing and maintenance of documentation. Consequences are severe as the lack of documentation on software structure negatively impacts the overall quality of the software product. We show that using a controlled natural language with a reasoner and a query engine is a viable technique for verifying the consistency and accuracy of documentation and source code. Using ACE, a state-of-the-art controlled natural language, we present positive results on the comprehensibility and the general feasibility of creating and verifying documentation. As a case study, we used automatic documentation verification to identify\u00a0\u2026", "num_citations": "6\n", "authors": ["131"]}
{"title": "Reverse Generics: Parametrization after the Fact\n", "abstract": " By abstracting over types, generic programming enables one to write code that is independent from specific data type implementation. This style is supported by most mainstream languages, including C++ with templates and Java with generics. If some code is not designed in a generic way from the start, a major effort is required to convert this code to use generic types. This conversion is manually realized which is known to be tedious and error-prone.               We propose Reverse Generics, a general linguistic mechanism to define a generic class from a non-generic class. For a given set of types, a generic is formed by unbinding static dependencies contained in these types. This generalization and generic type instantiation may be done incrementally. This paper studies the possible application of this linguistic mechanism to C++ and Java and, in particular, it reviews limitations of Java generics against\u00a0\u2026", "num_citations": "6\n", "authors": ["131"]}
{"title": "Prioritizing versions for performance regression testing: the pharo case\n", "abstract": " ContextSoftware performance may suffer regressions caused by source code changes. Measuring performance at each new software version is useful for early detection of performance regressions. However, systematically running benchmarks is often impractical (e.g., long running execution, prioritizing functional correctness over non-functional).ObjectiveIn this article, we propose Horizontal Profiling, a sampling technique to predict when a new revision may cause a regression by analyzing the source code and using run-time information of a previous version. The goal of Horizontal Profiling is to reduce the performance testing overhead by benchmarking just software versions that contain costly source code changes.MethodWe present an evaluation in which we apply Horizontal Profiling to identify performance regressions of 17 software projects written in the Pharo programming language, totaling 1,288 software\u00a0\u2026", "num_citations": "5\n", "authors": ["131"]}
{"title": "Effective visualization of object allocation sites\n", "abstract": " Profiling the memory consumption of a software execution is usually carried out by characterizing calling-context trees. However, the plurality nature of this data-structure makes it difficult to adequately and efficiently exploit in practice. As a consequence, most of anomalies in memory footprints are addressed either manually or in an ad-hoc way. We propose an interactive visualization of the execution context related to object productions. Our visualization augments the traditional calling-context tree with visual cues to characterize object allocation sites. We performed a qualitative study involving eight software engineers conducting a software execution memory assessment. As a result, we found that participants find our visualization as beneficial to characterizing a memory consumption and to reducing the overall memory footprint.", "num_citations": "5\n", "authors": ["131"]}
{"title": "Design decisions in AspectMaps\n", "abstract": " AspectMaps is a visualization that shows the structure of aspectual source code. In its design and implementation we made a number of design decisions that we present and discuss in this text. This in the light of more than two years of using, extending and maintaining the AspectMaps visualization and tool. The purpose of this paper is to share our experience with other visualization designers and implementers, as an aid in the making of their design decisions.", "num_citations": "5\n", "authors": ["131"]}
{"title": "A tool for assessing quality of rescue plans by combining visualizations of different business process perspectives\n", "abstract": " Rescue plans for crisis situations such as natural or made disasters are mostly presented in a textual format to the relevant authority. Assessing the quality of a rescue plan requires analyzing different perspectives, such as plan complexity, resources costs, service time, allocation strategy and organization efficiency. Unfortunately, textual rescue plans lack a formal structure to ease the reading and navigation through the document. To address this problem we are composing tailored visualizations, each visualization representing a particular perspective. We provide a domain specific language to describe domain specific visualizations of processes. We validate our approach using static and dynamic analysis of the Ho Chi Minh city rescue plan in case of a tsunami. Our approach provides recommendations that are useful for the authority to improve the original rescue plan.", "num_citations": "4\n", "authors": ["131"]}
{"title": "Tracking performance failures with rizel\n", "abstract": " Understanding and minimizing the impact of software changes on performance are both challenging and essential when developing software. Unfortunately, current code execution profilers do not offer efficient abstractions and adequate representations to keep track of performance across multiple versions. Consequently, understanding the cause of a slow execution stemming from a software evolution is often realized in an ad hoc fashion.", "num_citations": "4\n", "authors": ["131"]}
{"title": "AVISPA: Localizing Improvement Opportunities in Software Process Models\n", "abstract": " Software process models are sophisticated and large specifications aimed at organizing and managing software development. Their formal specification demands an enormous effort, but once specified there are few approaches and even fewer tools that aid the process engineer to evaluate the quality of the process. According to the industrial experience we conducted over the last five years, we have found a series of software process model patterns that indicate the potential presence of misconceptions or misspecifications. This paper presents these patterns, characterizes the kind of error they potentially reveal, and details the graphical indicator we used to localize potential errors within a software process. To assist process engineers to assess the quality of their processes, we provide AVISPA, a tool that graphically renders different aspects of a process model. Potential errors are highlighted using intuitive and comprehensible indicators. The approach and the supporting tool are illustrated by applying them for evaluating the software process models of three industrial case studies.", "num_citations": "4\n", "authors": ["131"]}
{"title": "Matrice de d\u00e9pendances enrichie\n", "abstract": " Les matrices de d\u00e9pendance (DSM-Dependency Structure Matrix), d\u00e9velopp\u00e9es dans le cadre de l\u2019optimisation de processus, ont fait leurs preuves pour identifier les d\u00e9pendances logicielles entre des packages ou des sous-syst\u00e8mes. Il existe plusieurs algorithmes pour structurer une matrice de fa\u00e7on \u00e0 ce qu\u2019elle refl\u00e8te l\u2019architecture des \u00e9l\u00e9ments analys\u00e9s et mette en \u00e9vidence des cycles entre les sous-syst\u00e8mes. Cependant, les impl\u00e9mentations de matrices de d\u00e9pendance existantes manquent d\u2019informations importantes pour apporter une r\u00e9elle aide au travail de r\u00e9ing\u00e9nierie. Par exemple, le poids des relations qui posent probl\u00e8me ainsi que leur type ne sont pas clairement pr\u00e9sent\u00e9s. Ou encore, des cycles ind\u00e9pendants sont fusionn\u00e9s. Il est \u00e9galement difficile d\u2019obtenir une visualisation centr\u00e9e sur un package. Dans ce papier, nous am\u00e9liorons les matrices de d\u00e9pendance en ajoutant des informations sur (i) le type de r\u00e9f\u00e9rences,(ii) le nombre d\u2019entit\u00e9s r\u00e9f\u00e9ren\u00e7antes,(iii) le nombre d\u2019entit\u00e9s r\u00e9f\u00e9renc\u00e9es. Nous distinguons \u00e9galement les cycles ind\u00e9pendants. Ce travail a \u00e9t\u00e9 impl\u00e9ment\u00e9 dans l\u2019environnement de r\u00e9ing\u00e9nierie open-source Moose. Il a \u00e9t\u00e9 appliqu\u00e9 \u00e0 des \u00e9tudes de cas complexes comme le framework Morphic UI contenu dans les environnements Smalltalk open-source Squeak et Pharo. Les r\u00e9sultats obtenus ont \u00e9t\u00e9 appliqu\u00e9s dans l\u2019environnement de programmation Pharo et ont men\u00e9 \u00e0 des am\u00e9liorations.", "num_citations": "4\n", "authors": ["131"]}
{"title": "Mise en symbiose des traits et des classboxes. Application \u00e0 l expression des collaborations.\n", "abstract": " The trait model is complementary to class inheritance and allows collections of methods to be reused by several classes. The classbox model allows a collection of classes to be locally extended with variables and/or methods addition. This paper describes a symbiosis of these two models: classes can be locally extended by using a trait. It is illustrated by an efficient implementation of the collaboration model where a collaboration is represented by aa classbox and a role by a trait.R\u00c9SUM\u00c9. Le mod\u00e8le des traits propose un compl\u00e9ment \u00e0 l\u2019h\u00e9ritage des classes permettant la r\u00e9utilisation d\u2019une collection de m\u00e9thodes par diff\u00e9rentes classes. Le mod\u00e8le des classboxes permet l\u2019extension locale d\u2019une collection de classes par l\u2019ajout de variables et/ou de m\u00e9thodes d\u2019instance. Cet article pr\u00e9sente une symbiose de ces deux mod\u00e8les: permettre l\u2019extension locale d\u2019une classe par l\u2019utilisation d\u2019un trait et au del\u00e0, proposer une r\u00e9alisation du mod\u00e8le des collaborations pour lequel une collaboration est assimil\u00e9e \u00e0 un classbox et un r\u00f4le \u00e0 un trait.", "num_citations": "4\n", "authors": ["131"]}
{"title": "An interdisciplinary model for graphical representation\n", "abstract": " The paper questions whether data-driven and problem-driven models are sufficient for a software to automatically represent a meaningful graphical representation of scientific findings. The paper presents descriptive and prescriptive case studies to understand the benefits and the shortcomings of existing models that aim to provide graphical representations of data-sets. First, the paper considers data-sets coming from the field of software metrics and shows that existing models can provide the expected outcomes for descriptive scientific studies. Second, the paper presents data-sets coming from the field of human mobility and sustainable development, and shows that a more comprehensive model is needed in the case of prescriptive scientific fields requiring interdisciplinary research. Finally, an interdisciplinary problem-driven model is proposed to guide the software users, and specifically scientists, to\u00a0\u2026", "num_citations": "3\n", "authors": ["131"]}
{"title": "Fuzzing to estimate gas costs of ethereum contracts\n", "abstract": " This paper studies how a simple approach based on fuzzing testing can help authors of Solidity contracts to accurately estimate the gas cost of services specified in a contract. Our fuzzer creates a private blockchain and randomly generates transactions. Such an environment is meant to simulate large scale behavior that may be seen in a public blockchain. Our fuzzer handles Ethereum starting and target endpoints in a transaction to accommodate requirements expressed in financial contracts. By comparing the gas computation made by the Ethereum Solidity compiler and the actual consumption during our fuzzing, we are able to find discrepancies between predicted and real gas consumption. Our findings are beneficial to transaction authors to correctly predict the computing resources of Ethereum miners.", "num_citations": "3\n", "authors": ["131"]}
{"title": "VizRob: Effective visualizations to debug robotic behaviors\n", "abstract": " Building and debugging robotic programs is known to be difficult. The robotic community has produced numerous tools, APIs and middlewares to help debug and trace the construction and execution of robotic behaviors. However, most of available debugging tools are text and log-oriented, leading to a tedious and ad-hoc debugging activity. In this paper we fully describe VizRob, a tool to debug robotic behaviors using logs and execution time. VizRob produces interactive visualizations built from log traces within a state machine model, that is, the visual representation of the behavior. VizRob is founded on deficiencies we empirically found from semi-structured interviews and a revision of tutorial materials. A small case study received an initial feedback of VizRob in a robotic software engineering team. Our case study shows: (i) VizRob helps engineers solve intricate debugging scenarios and (ii) engineers perceive\u00a0\u2026", "num_citations": "3\n", "authors": ["131"]}
{"title": "A domain-specific language to visualize software evolution\n", "abstract": " ContextAccurately relating code authorship to commit frequency over multiple software revisions is a complex task. Most of the navigation tools found in common source code versioning clients are often too rigid to formulate specific queries and adequately present results of such queries. Questions related to evolution asked by software engineers are therefore challenging at answering using common Git clients.ObjectiveThis paper explores the use of stacked adjacency matrices and a domain specific language to produce tailored interactive visualizations for software evolution exploration. We are able to support some classical software evolution tasks using short and concise scripts using our language.MethodWe propose a domain-specific language to stack adjacency matrices and produce scalable and interactive visualizations. Our language and visualizations are evaluated using two independent controlled\u00a0\u2026", "num_citations": "3\n", "authors": ["131"]}
{"title": "Statically identifying class dependencies in legacy javascript systems: First results\n", "abstract": " Identifying dependencies between classes is an essential activity when maintaining and evolving software applications. It is also known that JavaScript developers often use classes to structure their projects. This happens even in legacy code, i.e., code implemented in JavaScript versions that do not provide syntactical support to classes. However, identifying associations and other dependencies between classes remain a challenge due to the lack of static type annotations. This paper investigates the use of type inference to identify relations between classes in legacy JavaScript code. To this purpose, we rely on Flow, a state-of-the-art type checker and inferencer tool for JavaScript. We perform a study using code with and without annotating the class import statements in two modular applications. The results show that precision is 100% in both systems, and that the annotated version improves the recall, ranging\u00a0\u2026", "num_citations": "3\n", "authors": ["131"]}
{"title": "Efficiently identifying object production sites\n", "abstract": " Most programming environments are shipped with accurate memory profilers. Although efficient in their analyses, memory profilers traditionally output textual listing reports, thus reducing the memory profile exploration as a set of textual pattern-matching operations. Memory blueprint visually reports the memory consumption of a program execution. A number of simple visual cues are provided to identify direct and indirect object production sites, key ingredients to efficiently address memory issues. Scalability is addressed by restricting the scope of interest both in the call graph and the considered classes. Memory blueprint has been implemented in the Pharo programming language, and is available under the MIT license.", "num_citations": "3\n", "authors": ["131"]}
{"title": "Inti: Tracking performance issue using a compact and effective visualization\n", "abstract": " Current tools to measure software performance commonly use a tree widget to indicate the CPU time distribution over the execution control flow. The tree representation is known to poorly scale in presence of large dataset and inadequately convey the time distribution across software components. We propose Inti, a sunburst-like visualization, to represent program executions. Inti uses color maps to indicate time distribution and comparison across set of software components. Visualizations produced by Inti are both compact and interactive. This paper describes the early development stage of Inti.", "num_citations": "3\n", "authors": ["131"]}
{"title": "Handling exceptions\n", "abstract": " Modern programming languages, including Smalltalk offer a dedicated exception-handling mechanism that greatly simplifies the way in which exceptional situations are signaled and handled. Before the development of the ANSI Smalltalk standard in 1996, several exception handling mechanisms existed, mostly incompatible with each other. Pharo\u2019s exception handling follows the ANSI standard, with some embellishments; we present it in this chapter from a user perspective.The basic idea behind exception handling is that client code does not clutter the main logic flow with checks for error codes, but specifies instead an exception handler to \u201ccatch\u201d exceptions. When something goes wrong, instead of returning an error code, the method that detects the exceptional situation interrupts the main flow of execution by signaling an exception. This does", "num_citations": "3\n", "authors": ["131"]}
{"title": "Generics and Reverse Generics for Pharo.\n", "abstract": " Generic programming is a mechanism for re-using code by abstracting specific types used in classes and programs. In this paper, we present a mechanism for adding generic programming in dynamically typed languages, showing how programmers can benefit from generic programming. Furthermore, we enhance the expressiveness of generic programming with reverse generics, a mechanism for automatically deriving new generic code starting from existing non-generic one. We implemented generics and reverse generics in Pharo Smalltalk, and we successfully used them to solve a problem of reusing unit test cases. This helped us to identify a number of bugs and anomalies in the stream class hierarchy.", "num_citations": "3\n", "authors": ["131"]}
{"title": "Is it Safe to Adopt the Scrum Process Model?\n", "abstract": " Scrum is a widely known agile software process model specifically designed for guiding non-technical activities in software development. This process has been formally defined in EPF and adopted by several software companies around the world. But having a process definition does not necessarily mean that it is well specified. We have developed AVISPA, a tool for localizing error patterns in software process models specified with EPF. In this paper, we analyze the public community specification of Scrum using AVISPA and we report our findings.ResumenScrum es un proceso \u00e1gil de desarrollo de software ampliamente conocido. Es un proceso especialmente apropiado para guiar las actividades no t\u00e9cnicas del desarrollo. Este proceso ha sido formalmente especificado en la plataforma EPF y adoptado por variadas empresas alrededor del mundo. Pero tener un proceso definido no implica necesariamente que est\u00e9 bien especificado. Hemos desarrollado AVISPA, una herramienta que permite localizar ciertos patrones de errores en especificaciones EPF de procesos. En este art\u00edculo analizamos usando AVISPA la especificaci\u00f3n formal de Scrum que est\u00e1 p\u00fablicamente disponible para la comunidad y reportamos nuestros hallazgos.", "num_citations": "3\n", "authors": ["131"]}
{"title": "FlowTalk: Language support for long-latency operations in embedded devices\n", "abstract": " Wireless sensor networks necessitate a programming model different from those used to develop desktop applications. Typically, resources in terms of power and memory are constrained. C is the most common programming language used to develop applications on very small embedded sensor devices. We claim that C does not provide efficient mechanisms to address the implicit asynchronous nature of sensor sampling. C applications for these devices suffer from a disruption in their control flow. In this paper, we present FlowTalk, a new object-oriented programming language aimed at making software development for wireless embedded sensor devices easier. FlowTalk is an object-oriented programming language in which dynamicity (e.g., object creation) has been traded for a reduction in memory consumption. The event model that traditionally comes from using sensors is adapted in FlowTalk with controlled\u00a0\u2026", "num_citations": "3\n", "authors": ["131"]}
{"title": "Improving the success rate of applying the extract method refactoring\n", "abstract": " Context: Most modern programming environments support refactorings. Although refactorings are relevant to improve the quality of software source code, they unfortunately suffer from severe usability issues. In particular, the extract method refactoring, one of the most prominent refactorings, has a failure rate of 49% when users attempt to use it.Objective: Our main objective is to improve the success rate of applying the extract method refactoring.Methods: First, to understand the cause of refactoring failure, we conducted a partial replication of Vakilian's ICSE '14 study about usability issues of refactoring using IntelliJ IDEA. Second, we designed and implemented TOAD, a tool that proposes alternative text selection for source code refactoring for the Pharo programming language. Third, we evaluated TOAD using a controlled experiment against the standard Pharo code refactoring tool. Seven professional software\u00a0\u2026", "num_citations": "2\n", "authors": ["131"]}
{"title": "Vision: alleviating Android developer burden on obfuscation\n", "abstract": " Mobile applications (apps) have gained an increasing importance in the field of software engineering as they are becoming one of the most widely used type of software. In the Android ecosystem, obfuscation tools are available to optimize, reduce the size and protect the intellectual properties of apps. However, despite the clear advantages provided by obfuscation most apps do not use it, often because of the difficulties induced by the usage of obfuscation which requires writing rules to keep a usable app. In this paper, we identify the concrete challenges encountered by app developers who wish to use obfuscation in their apps. In addition, we propose an approach using crowdsourcing to automatically generate rules, when static analysis is not sufficient. With the knowledge gained from hundreds of projects, we hope to lighten the burden on developers when writing rules.", "num_citations": "2\n", "authors": ["131"]}
{"title": "Roassal 3\n", "abstract": " Roassal 3 Page 1 Roassal 3 ObjectProfile Alexandre Bergel Milton Mamani Page 2 The ESUG19 Talk was a Demo Watch it on Youtube https://www.youtube.com/watch?v=e5rpcmV-igE The Following Slides are from another Presentation, adding more details Page 3 Roassal in a nutshell \u2022 Canvas and shapes \u2022 View and elements. \u2022 This is the version more than 2 less than 4. \u2022 Nothing in this presentation is final. Page 4 Canvas Page 5 The Canvas \u2022 Used to draw graphic objects. \u2022 The canvas is a TSCanvas. \u2022 It is the canvas where you can put shapes. \u2022 It is subclass of TSObject or Object. \u2022 Roassal use the notation TSShape, TSCanvas, TSBox, (Trachel Shape) for canvas components. Page 6 Canvas parts \u2022 Shapes \u2022 Events \u2022 Morph \u2022 Animations \u2022 And more Page 7 Canvas Shapes \u2022 The canvas has basic shapes \u2022 And fixed shapes Page 8 Shapes \u2022 All the shapes has these properties. \u2022 There is composition. \u2022 There , '\u2026", "num_citations": "2\n", "authors": ["131"]}
{"title": "Glyph-based software component identification\n", "abstract": " Glyphs are automatically generated visual icons, commonly employed as an object identification technique. Although popular in the Human Computer Interaction community, glyphs are rarely employed to address software engineering problems. We extended the VisualID glyph technique to cope with structural software elements and used it to address two issues in software maintenance: identify classes with the same dependencies and classes with a similar set of methods. We have compared VisualID against three visual representations: textual, graph (nodes and edges), and dependency structural matrix. Our experiments indicate that VisualID significantly helps identify classes with the same dependencies and classes with similar methods when compared with visual techniques commonly used in software maintenance.", "num_citations": "2\n", "authors": ["131"]}
{"title": "Identifying equivalent objects to reduce memory consumption\n", "abstract": " Executing an application may trigger the creation of a large amount of objects. For many applications, a large portion of these objects are unnecessary and their creation could simply be avoided.We describe a lightweight profiling technique to identity \u201cequivalent\u201d objects. Such equivalent objects are simply redundant and may be shared or reused to reduce the memory footprint. We propose object-centric execution blueprint, a visual representation to help practitioners identify cases where objects may be reused instead of being redundant.", "num_citations": "2\n", "authors": ["131"]}
{"title": "Generic programming in Pharo\n", "abstract": " Dynamically typed object-oriented languages have been left out of the scope of generic programming: in a dynamically typed setting, the need for generic programming has been less prominent since no restriction applies over the kind of elements a collection may contain. However, when creating an object, the class name is hardcoded in the program, and this makes the object instantiation process hard to abstract from.               In this paper, we describe our implementation of generic programming in Pharo, a Smalltalk dialect, showing how programmers can benefit from generic programming even in a dynamically typed language. Furthermore, we enhance the expressiveness of generic programming with reverse generics, a mechanism for automatically deriving new generic code starting from existing non-generic one.               As a case study, we show how we used generics and reverse generics in Pharo\u00a0\u2026", "num_citations": "2\n", "authors": ["131"]}
{"title": "Is it Safe to Adopt the Scrum Process Model?\n", "abstract": " Scrum is a widely known agile software process model specifically designed for guiding nontechnical activities in software development. This process has been formally defined in EPF and adopted by several software companies around the world. But having a process definition does not necessarily mean that it is well specified. We have developed AVISPA, a tool for localizing error patterns in software process models specified with EPF. In this paper, we analyze the public community specification of Scrum using AVISPA and we report our findings.", "num_citations": "2\n", "authors": ["131"]}
{"title": "Reconciling method overloading and dynamically typed scripting languages\n", "abstract": " The Java virtual machine (JVM) has been adopted as the executing platform by a large number of dynamically typed programming languages. For example, Scheme, Ruby, Javascript, Lisp, and Basic have been successfully implemented on the JVM and each is supported by a large community. Interoperability with Java is one important requirement shared by all these languages.We claim that the lack of type annotation in interpreted dynamic languages makes this interoperability either flawed or incomplete in the presence of method overloading. We studied 17 popular dynamically typed languages for JVM and .Net, none of them were able to properly handle the complexity of method overloading.We present dynamic type tag, an elegant solution for dynamic language interpreters to properly interact with Java objects in the presence of overloaded methods. The idea is to embody a type annotation in a Java object\u00a0\u2026", "num_citations": "2\n", "authors": ["131"]}
{"title": "Reproducing Bugs in Video Games using Genetic Algorithms\n", "abstract": " Video games are usually manually tested by a dedicated team. As such, testing is an expensive activity, both financial and emotional as most of the testing is mostly carried out before a release. This paper proposes a technique based on using Genetic Algorithm (GA) to reproduce bugs in video games. It consists in searching for a sequence of joystick and keyboard actions that lead to a faulty state of the game. We successfully applied our technique on two different video games, thus suggesting that using GA is a viable technique to reproduce bugs in video games.", "num_citations": "1\n", "authors": ["131"]}
{"title": "The Traveling Salesman Problem\n", "abstract": " The Traveling Salesman Problem (TSP) is a classical algorithm problem. It consists of identifying the shortest possible route between several connected cities. Not only is the problem relevant from an algorithmic point of view, but it also has many concrete applications, like microchip manufacturing, as you will shorty see.", "num_citations": "1\n", "authors": ["131"]}
{"title": "Agile Artificial Intelligence in Pharo\n", "abstract": " Artificial Intelligence (AI) is radically changing the way we use computers to solve problems. For example, by exploiting previous experience, which may be expressed in terms of examples, a machine can identify patterns in a given situation and try to identify the same patterns in a slightly different situation. This is essentially the way AI is used nowadays. The field of AI is moving quickly, and unfortunately, it is often difficult to understand.The objective of the Agile Artificial Intelligence in Pharo book is to provide a practical foundation for a set of expressive artificial intelligence algorithms using the Pharo programming language. The book makes two large contributions over existing related books. The first contribution is to bring agility in the way some techniques related to artificial intelligence are designed, implemented, and evaluated. The book provides material in an incremental fashion, beginning with a little\u00a0\u2026", "num_citations": "1\n", "authors": ["131"]}
{"title": "Continuation to the Rescue: Seamlessly Handling Battery Interruption in Drones\n", "abstract": " Adequately managing energy consumption is critical when defining a drone flight mission. A challenge when programming the drone is to make the drone behavior support battery replacements without disrupting its logic of execution. This paper explores the use of continuation, an ability of the programming language to capture a particular state of the application. Such a state can be reinstalled after a battery replacement to let the drone resume its execution. Our result indicates that a significant reduction of the engineering effort to handle energy consumption in a drone behavior may be achieved.", "num_citations": "1\n", "authors": ["131"]}
{"title": "Experience in Bridging Keras for Python with Pharo\n", "abstract": " Creating bridges or wrappers for libraries developed in different languages is a challenging task. We successfully created a bridge between Pharo and Python to use the neural network library Keras. The fact that Keras is implemented in Python is completely transparent to a Pharo programmer. We present and discuss the architectural decisions involved in the development of the bridge. Our decisions include the use of command messages for communication between languages and the use of first-class Pharo objects to generate and operate Python objects while providing liveprogramming capabilities.", "num_citations": "1\n", "authors": ["131"]}
{"title": "Dynamically composing collection operations through collection promises\n", "abstract": " Filtering, mapping, and iterating collections are frequent operations. It is known that composing a number of these operations may create intermediate collections causing an additional and unnecessary overhead. To reduce the number of intermediate collections it is often necessary to rewrite the source code and combine the operations. However, for some cases such reduction becomes aplicable only after a source code refactoring (ie, when the collection operations are in different methods) which could introduce code duplication.", "num_citations": "1\n", "authors": ["131"]}
{"title": "Does Live Programming Help Program Comprehension?\n", "abstract": " A tenet of Live Programming is that its tightening of the development feedback loop results in better program comprehension and hence higher developer productivity. There are however no extensive reports published on user studies that validate this claim when considering already existing code. In this paper we report on a controlled experiment that establishes whether our live programming language, LRP, helps in program understanding when compared to a non-live language and toolkit. We furthermore obtained qualitative feedback from the test subjects on their preferences between the two systems. Remarkably, while the users prefer the live system over a non-live system, the actual level and speed of program comprehension is the same for both systems.", "num_citations": "1\n", "authors": ["131"]}
{"title": "Reducing Waste in Expandable Collections: The Pharo Case\n", "abstract": " Expandable collections are collections whose size may vary as elements are added and removed. Hash maps and ordered collections are popular expandable collections. In the Pharo programming language, expandable collection classes offer an easy-to-use API, however this apparent simplicity is accompanied by a significant amount of wasted resource. We describe some improvements of the collection library to reduce the amount of waste associated with collection expansions. We have designed a new collection library for Pharo that exhibits better resource management than the standard library. Across a basket of 17 applications, our optimized collection library significantly reduces the memory footprint of the collections:(i) the amount of intermediary internal array storage by 73%,(ii) the number of allocated bytes by 67% and (iii) the number of unused bytes by 72%. This reduction of memory is accompanied with a speedup of about 3% for most of our benchmarks. We further discuss the applicability of our findings to other languages, including Java, C#, Scala, and Ruby.", "num_citations": "1\n", "authors": ["131"]}
{"title": "Desarrollo de herramienta colaborativa para el levantamiento de procesos BPMN en dispositivos m\u00f3viles\n", "abstract": " Hoy en d\u00eda se identifican numerosos problemas asociados al levantamiento de procesos, muchos de los cuales tienen su origen en que el conocimiento sobre los procesos no esta formalizado y/o esta repartido entre diversos actores. Para enfrentar esto se existen varias t\u00e9cnicas que involucran el trabajo en terreno y la colaboraci\u00f3n de varios participantes a la vez.", "num_citations": "1\n", "authors": ["131"]}
{"title": "Debugging performance failures\n", "abstract": " An application execution profile has meaning only when it is compared to another profile obtained from a slightly different executing context. Unfortunately, current profilers do not efficiently support performance comparison across multiple profiles. As a consequence, profiling multiple executions is often realized in an ad-hoc fashion, often resulting in missing opportunities for caching.", "num_citations": "1\n", "authors": ["131"]}
{"title": "Test coverage with hapao\n", "abstract": " Testing is an essential activity when developing software. It is widely acknowledged that a test coverage above 70% is associated with a decrease in reported failures. Coverage tools output after running the unit tests the list of classes and methods that are not executed. Simply tagging a software element as covered may convey an incorrect sense of necessity: executing a long and complex method just once is potentially enough to be 100% test-covered. As a result, a developer may have an incorrect judgement on where to focus testing effort.", "num_citations": "1\n", "authors": ["131"]}
{"title": "Agile Code Profiling Visualization\n", "abstract": " This demonstration presents two code profiler tools. The first one is a concrete nominal type extractor which operates on unit tests. The second tool is a time profiler that offers a number of synthetic and expressive source code visualizations to easily identify execution bottlenecks. These two tools have been successfully employed to identify bugs, anomalies and bottlenecks in the Mondrian visualization engine. These two tools are instantiations of Spy, a dedicated code profiling framework. Spy is briefly described and illustrated. All this work has been implemented in the Pharo Smalltalk programming language and is available under the MIT license.Even though computing resources are abundant, execution optimization and analysis through code profiling remains an important software development activity. Program profilers are crucial tools to identify execution bottlenecks and uncover interaction. Today, it is inconceivable to ship a programming environment without a code profiler included or provided by a third party. When we retrospectively look at the history of code profiler tools, we see that tool usability and profiling overhead reduction have steadily improved, but that the set of offered abstractions has remained constant. For instance, gprof, which appeared in 1982, offers a number of textual output focussed on \u201chow much time was spent executing directly in each function\u201d and call graphs1. JProfiler essentially proposes the same output, using a graphical rendering instead of a textual one2. Most of the research conducted in the field of code profiling focus on reducing the overhead triggered by the code instrumentation and observation. On\u00a0\u2026", "num_citations": "1\n", "authors": ["131"]}
{"title": "Contr\u00f4ler la visibilit\u00e9 des aspects avec Aspectboxes.\n", "abstract": " La composition et l\u2019int\u00e9raction des aspects est un domaine de recherche tr\u00e8s actif. Bien que plusieurs solutions existent, telles que l\u2019agencement des aspects et des advices, les approches propos\u00e9es par des langages \u00e0 aspects supposent qu\u2019une connaissance g\u00e9n\u00e9rale des aspects soit n\u00e9cessaire pour pouvoir les composer, et m\u00eame ceci ne permet pas d\u2019\u00e9viter les interactions implicites r\u00e9sultant d\u2019une composition.Cet article pr\u00e9sente les aspectboxes, un m\u00e9canisme de visibilit\u00e9 pour aspects. L\u2019unit\u00e9 \u00e9l\u00e9mentaire de visibilit\u00e9 est un aspectbox. Un aspectbox encapsule des d\u00e9finitions d\u2019aspects. Un aspectbox peut \u00eatre utilis\u00e9 par d\u2019autres aspectboxes pour aider la construction incr\u00e9mentale de logiciel \u00e0 base d\u2019aspects. Une classe peut utiliser un aspectbox dans le but de b\u00e9n\u00e9ficier des aspects d\u00e9finis.", "num_citations": "1\n", "authors": ["131"]}
{"title": "A Debugger for the Interpreter Design Pattern\n", "abstract": " Using Interpreter and Visitor design patterns is a widely adopted approach to implement programming language interpreters. The popularity of these patterns stems from their expressive and simple design. However, no general approach to conceive a debugger has been commonly adopted. This paper presents the debuggable interpreter design pattern, a general approach toextend alanguage interpreter with debugging facilities such as step-over and step-into. Moreover, it enables multiple debuggers to coexists. It extends the Interpreter and Visitor design patterns with few hooks and a debugging service. SmallJS, an interpreter for Javascript-like language, serves as illustration.", "num_citations": "1\n", "authors": ["131"]}
{"title": "Classboxes: supporting unanticipated variation points in the source code\n", "abstract": " Software product lines refer to engineering techniques for creating a portfolio of similar software systems from a shared set of software assets in a controlled way. Managing variability is the key issue of software product line practice. Modelling variation points is largely addressed by a selection of linguistic constructs and modelling techniques (e.g., design pattern, macro, configuration files). New constraints and industrial requirements often result in the emergence of new variation points. The success of the evolution of a product line depends on its capability to absorb unanticipated variation points. This paper presents the classboxes programming construct to support unanticipated variation point in the software source code. Classboxes offer a visibility mechanism that controls the scope of an evolution step and limits it only to the part of a program that needs to be affected by this evolution. Benefits of classboxes are illustrated on an arcade game maker product line.", "num_citations": "1\n", "authors": ["131"]}