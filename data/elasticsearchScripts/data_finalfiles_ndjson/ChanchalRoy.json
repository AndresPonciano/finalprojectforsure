{"title": "A survey on software clone detection research\n", "abstract": " Code duplication or copying a code fragment and then reuse by pasting with or without any modifications is a well known code smell in software maintenance. Several studies show that about 5% to 20% of a software systems can contain duplicated code, which is basically the results of copying existing code fragments and using then by pasting with or without minor modifications. One of the major shortcomings of such duplicated fragments is that if a bug is detected in a code fragment, all the other fragments similar to it should be investigated to check the possible existence of the same bug in the similar fragments. Refactoring of the duplicated code is another prime issue in software maintenance although several studies claim that refactoring of certain clones are not desirable and there is a risk of removing them. However, it is also widely agreed that clones should at least be detected. In this paper, we survey the state of the art in clone detection research. First, we describe the clone terms commonly used in the literature along with their corresponding mappings to the commonly used clone types. Second, we provide a review of the existing clone taxonomies, detection approaches and experimental evaluations of clone detection tools. Applications of clone detection research to other domains of software engineering and in the same time how other domain can assist clone detection research have also been pointed out. Finally, this paper concludes by pointing out several open problems related to clone detection research.", "num_citations": "883\n", "authors": ["979"]}
{"title": "NICAD: Accurate detection of near-miss intentional clones using flexible pretty-printing and code normalization\n", "abstract": " This paper examines the effectiveness of a new language- specific parser-based but lightweight clone detection approach. Exploiting a novel application of a source transformation system, the method accurately finds near-miss clones using an efficient text line comparison technique. The transformation system assists the method in three ways. First, using agile parsing it provides user-specified flexible pretty- printing to remove noise, standardize formatting and break program statements into parts such that potential changes can be detected as simple linewise text differences. Second, it provides efficient flexible extraction of potential clones to be compared using island grammars and agile parsing to select granularities and enumerate potential clones. Third, using transformation rules it provides flexible code normalization to allow for local editing differences between similar code segments and filtering out of\u00a0\u2026", "num_citations": "560\n", "authors": ["979"]}
{"title": "Sourcerercc: Scaling code clone detection to big-code\n", "abstract": " Despite a decade of active research, there has been a marked lack in clone detection techniques that scale to large repositories for detecting near-miss clones. In this paper, we present a token-based clone detector, SourcererCC, that can detect both exact and near-miss clones from large inter-project repositories using a standard workstation. It exploits an optimized inverted-index to quickly query the potential clones of a given code block. Filtering heuristics based on token ordering are used to significantly reduce the size of the index, the number of code-block comparisons needed to detect the clones, as well as the number of required token-comparisons needed to judge a potential clone. We evaluate the scalability, execution time, recall and precision of SourcererCC, and compare it to four publicly available and state-of-the-art tools. To measure recall, we use two recent benchmarks:(1) a big benchmark of real\u00a0\u2026", "num_citations": "354\n", "authors": ["979"]}
{"title": "The NiCad clone detector\n", "abstract": " The NiCad Clone Detector is a scalable, flexible clone detection tool designed to implement the NiCad (Automated Detection of Near-Miss Intentional Clones) hybrid clone detection method in a convenient, easy-to-use command-line tool that can easily be embedded in IDEs and other environments. It takes as input a source directory or directories to be checked for clones and a configuration file specifying the normalization and filtering to be done, and provides output results in both XML form for easy analysis and HTML form for convenient browsing. NiCad handles a range of languages and normalizations, and is designed to be easily extensible using a component-based plugin architecture. It is scalable to very large systems and has been used to analyze, for example, all 47 releases of FreeBSD (60 million lines) as a single system.", "num_citations": "247\n", "authors": ["979"]}
{"title": "A mutation/injection-based automatic framework for evaluating code clone detection tools\n", "abstract": " In recent years many methods and tools for software clone detection have been proposed. While some work has been done on assessing and comparing performance of these tools, very little empirical evaluation has been done. In particular, accuracy measures such as precision and recall have only been roughly estimated, due both to problems in creating a validated clone benchmark against which tools can be compared, and to the manual effort required to hand check large numbers of candidate clones. In this paper we propose an automated method for empirically evaluating clone detection tools that leverages mutation-based techniques to overcome these limitations by automatically synthesizing large numbers of known clones based on an editing theory of clone creation. Our framework is effective in measuring recall and precision of clone detection tools for various types of fine-grained clones in real\u00a0\u2026", "num_citations": "224\n", "authors": ["979"]}
{"title": "An empirical study of function clones in open source software\n", "abstract": " The new hybrid clone detection tool NICAD combines the strengths and overcomes the limitations of both text-based and AST-based clone detection techniques to yield highly accurate identification of cloned code in software systems. In this paper, we present a first empirical study of function clones in open source software using NICAD. We examine more than 15 open source C and Java systems, including the entire Linux Kernel and Apache httpd, and analyze their use of cloned code in several different dimensions, including language, clone size, clone location and clone density by proportion of cloned functions. We manually verify all detected clones and provide a complete catalogue of different clones in an online repository in a variety of formats. These validated results can be used as a cloning reference for these systems and as a benchmark for evaluating other clone detection tools.", "num_citations": "167\n", "authors": ["979"]}
{"title": "Evaluating clone detection tools with bigclonebench\n", "abstract": " Many clone detection tools have been proposed in the literature. However, our knowledge of their performance in real software systems is limited, particularly their recall. In this paper, we use our big data clone benchmark, BigCloneBench, to evaluate the recall of ten clone detection tools. BigCloneBench is a collection of eight million validated clones within IJaDataset-2.0, a big data software repository containing 25,000 open-source Java systems. BigCloneBench contains both intra-project and inter-project clones of the four primary clone types. We use this benchmark to evaluate the recall of the tools per clone type and across the entire range of clone syntactical similarity. We evaluate the tools for both single-system and cross-project detection scenarios. Using multiple clone-matching metrics, we evaluate the quality of the tools' reporting of the benchmark clones with respect to refactoring and automatic clone\u00a0\u2026", "num_citations": "125\n", "authors": ["979"]}
{"title": "Evaluating modern clone detection tools\n", "abstract": " Many clone detection tools and techniques have been introduced in the literature, and these tools have been used to manage clones and study their effects on software maintenance and evolution. However, the performance of these modern tools is not well known, especially recall. In this paper, we evaluate and compare the recall of eleven modern clone detection tools using four benchmark frameworks, including: (1) Bellon's Framework, (2) our modification to Bellon's Framework to improve the accuracy of its clone matching metrics, (3) Murakamki et al.'s extension of Bellon's Framework which adds type 3 gap awareness to the framework, and (4) our Mutation and Injection Framework. Bellon's Framework uses a curated corpus of manually validated clones detected by tools contemporary to 2002. In contrast, our Mutation and Injection Framework synthesizes a corpus of artificial clones using a cloning taxonomy\u00a0\u2026", "num_citations": "122\n", "authors": ["979"]}
{"title": "Near\u2010miss function clones in open source software: an empirical study\n", "abstract": " The new hybrid clone detection tool NICAD combines the strengths and overcomes the limitations of both text\u2010based and AST\u2010based clone detection techniques and exploits novel applications of a source transformation system to yield highly accurate identification of cloned code in software systems. In this paper, we present an in\u2010depth study of near\u2010miss function clones in open source software using NICAD. We examine more than 20 open source C, Java and C# systems, including the entire Linux Kernel, Apache httpd, J2SDK\u2010Swing and db4o and compare their use of cloned code in several different dimensions, including language, clone size, clone similarity, clone location and clone density both by proportion of cloned functions and lines of cloned code. We manually verify all detected clones and provide a complete catalogue of different clones in an online repository in a variety of formats. These validated\u00a0\u2026", "num_citations": "116\n", "authors": ["979"]}
{"title": "Detection and analysis of near-miss software clones\n", "abstract": " Software clones are considered harmful in software maintenance and evolution. However, despite a decade of active research, there is a marked lack of work in the detection and analysis of near-miss software clones, those where minor to extensive modifications have been made to the copied fragments. In this thesis, we advance the state-of-the-art in clone detection and analysis in several ways. First, we develop a hybrid clone detection method. Second, we address the decade of vagueness in clone definition by proposing a metamodel of clone types. Third, we conduct a scenario-based comparison and evaluation of all of the currently available clone detection techniques and tools. Fourth, in order to evaluate and compare the available tools in a realistic setting, we develop a mutation-based framework that automatically and efficiently measures (and compares) the recall and precision of clone detection tools\u00a0\u2026", "num_citations": "110\n", "authors": ["979"]}
{"title": "Scenario-based comparison of clone detection techniques\n", "abstract": " Over the last decade many techniques for software clone detection have been proposed. In this paper, we provide a comprehensive survey of the capabilities of currently available clone detection techniques. We begin with an overall survey based on criteria that capture the main features of detection techniques. We then propose a set of hypothetical editing scenarios for different clone types, and evaluate the techniques based on their estimated potential to accurately detect clones that may be created by those scenarios.", "num_citations": "106\n", "authors": ["979"]}
{"title": "Rack: Automatic api recommendation using crowdsourced knowledge\n", "abstract": " Traditional code search engines often do not perform well with natural language queries since they mostly apply keyword matching. These engines thus need carefully designed queries containing information about programming APIs for code search. Unfortunately, existing studies suggest that preparing an effective code search query is both challenging and time consuming for the developers. In this paper, we propose a novel API recommendation technique -- RACK that recommends a list of relevant APIs for a natural language query for code search by exploiting keyword-API associations from the crowdsourced knowledge of Stack Overflow. We first motivate our technique using an exploratory study with 11 core Java packages and 344K Java posts from Stack Overflow. Experiments using 150 code search queries randomly chosen from three Java tutorial sites show that our technique recommends correct API\u00a0\u2026", "num_citations": "96\n", "authors": ["979"]}
{"title": "An insight into the pull requests of github\n", "abstract": " Given the increasing number of unsuccessful pull requests in GitHub projects, insights into the success and failure of these requests are essential for the developers. In this paper, we provide a comparative study between successful and unsuccessful pull requests made to 78 GitHub base projects by 20,142 developers from 103,192 forked projects. In the study, we analyze pull request discussion texts, project specific information (eg, domain, maturity), and developer specific information (eg, experience) in order to report useful insights, and use them to contrast between successful and unsuccessful pull requests. We believe our study will help developers overcome the issues with pull requests in GitHub, and project administrators with informed decision making.", "num_citations": "87\n", "authors": ["979"]}
{"title": "Useful, but usable? factors affecting the usability of APIs\n", "abstract": " Software development today has been largely dependent on the use of API libraries, frameworks, and reusable components. However, the API usability issues often increase the development cost (e.g., time, effort) and lower code quality. In this regard, we study 1,513 bug-posts across five different bug repositories, using both qualitative and quantitative analysis. We identify the API usability issues that are reflected in the bug-posts from the API users, and distinguish relative significance of the usability factors. Moreover, from the lessons learned by manual investigation of the bug-posts, we provide further insight into the most frequent API usability issues.", "num_citations": "84\n", "authors": ["979"]}
{"title": "Correct: code reviewer recommendation in github based on cross-project and technology experience\n", "abstract": " Peer code review locates common coding rule violations and simple logical errors in the early phases of software development, and thus reduces overall cost. However, in GitHub, identifying an appropriate code reviewer for a pull request is a non-trivial task given that reliable information for reviewer identification is often not readily available. In this paper, we propose a code reviewer recommendation technique that considers not only the relevant cross-project work history (eg, external library experience) but also the experience of a developer in certain specialized technologies associated with a pull request for determining her expertise as a potential code reviewer. We first motivate our technique using an exploratory study with 10 commercial projects and 10 associated libraries external to those projects. Experiments using 17,115 pull requests from 10 commercial projects and six open source projects show that\u00a0\u2026", "num_citations": "81\n", "authors": ["979"]}
{"title": "Conflict-aware optimal scheduling of prioritised code clone refactoring\n", "abstract": " Duplicated or similar source code, also known as code clones, are possible malicious 'code smells' that may need to be removed through refactoring to enhance maintainability. Among many potential refactoring opportunities, the choice and order of a set of refactoring activities may have distinguishable effect on the design/code quality measured in terms of software metrics. Moreover, there may be dependencies and conflicts among those refactorings of different priorities. Addressing all the conflicts, priorities and dependencies, a manual formulation of an optimal refactoring schedule is very expensive, if not impossible. Therefore an automated refactoring scheduler is necessary to 'maximise benefit and minimise refactoring effort'. However, the estimation of the efforts required to perform code clone refactoring is a challenging task. This study makes two contributions. First, the authors propose an effort model for the\u00a0\u2026", "num_citations": "77\n", "authors": ["979"]}
{"title": "Towards a context-aware IDE-based meta search engine for recommendation about programming errors and exceptions\n", "abstract": " Study shows that software developers spend about 19% of their time looking for information in the web during software development and maintenance. Traditional web search forces them to leave the working environment (e.g., IDE) and look for information in the web browser. It also does not consider the context of the problems that the developers search solutions for. The frequent switching between web browser and the IDE is both time-consuming and distracting, and the keyword-based traditional web search often does not help much in problem solving. In this paper, we propose an Eclipse IDE-based web search solution that exploits the APIs provided by three popular web search engines-Google, Yahoo, Bing and a popular programming Q & A site, StackOverflow, and captures the content-relevance, context-relevance, popularity and search engine confidence of each candidate result against the encountered\u00a0\u2026", "num_citations": "75\n", "authors": ["979"]}
{"title": "An automatic framework for extracting and classifying near-miss clone genealogies\n", "abstract": " Extracting code clone genealogies across multiple versions of a program and classifying them according to their change patterns underlies the study of code clone evolution. While there are a few studies in the area, the approaches do not handle near-miss clones well and the associated tools are often computationally expensive. To address these limitations, we present a framework for automatically extracting both exact and near-miss clone genealogies across multiple versions of a program and for identifying their change patterns using a few key similarity factors. We have developed a prototype clone genealogy extractor, applied it to three open source projects including the Linux Kernel, and evaluated its accuracy in terms of precision and recall. Our experience shows that the prototype is scalable, adaptable to different clone detection tools, and can automatically identify evolution patterns of both exact and near\u00a0\u2026", "num_citations": "74\n", "authors": ["979"]}
{"title": "A constraint programming approach to conflict-aware optimal scheduling of prioritized code clone refactoring\n", "abstract": " Duplicated code, also known as code clones, are one of the malicious 'code smells' that often need to be removed through refactoring for enhancing maintainability. Among all the potential refactoring opportunities, the choice and order of a set of refactoring activities may have distinguishable effect on the design/code quality. Moreover, there may be dependencies and conflicts among those refactorings. The organization may also impose priorities on certain refactoring activities. Addressing all these conflicts, priorities, and dependencies, manual formulation of an optimal refactoring schedule is very expensive, if not impossible. Therefore, an automated refactoring scheduler is necessary, which will maximize benefit and minimize refactoring effort. In this paper, we present a refactoring effort model, and propose a constraint programming approach for conflict-aware optimal scheduling of code clone refactoring.", "num_citations": "65\n", "authors": ["979"]}
{"title": "Bigcloneeval: A clone detection tool evaluation framework with bigclonebench\n", "abstract": " Many clone detection tools have been proposed in the literature. However, our knowledge of their performance in real software systems is limited, particularly their recall. We previously introduced our BigCloneBench, a big clone benchmark of over 8 million clones within a large inter-project Java repository containing 25,000 open-source Java systems. In this paper we present BigCloneEval, a framework for evaluating clone detection tools with BigCloneBench. BigCloneEval makes it very easy for clone detection researchers to evaluate and compare clone detection tools. It automates the execution and evaluation of clone detection tools against the reference clones of BigCloneBench, and summarizes recall performance from a variety of perspectives, including per clone type, and per syntactical similarity regions.", "num_citations": "53\n", "authors": ["979"]}
{"title": "Towards flexible code clone detection, management, and refactoring in IDE\n", "abstract": " In this paper, we propose an IDE-based clone management system to flexibly detect, manage, and refactor both exact and near-miss code clones. Using a k-difference hybrid suffix tree algorithm we can efficiently detect both exact and near-miss clones. We have implemented the algorithm as a plugin to the Eclipse IDE, and have been extending this for real-time code clone management with semi-automated refactoring support during the actual development process.", "num_citations": "50\n", "authors": ["979"]}
{"title": "Improving ir-based bug localization with context-aware query reformulation\n", "abstract": " Recent findings suggest that Information Retrieval (IR)-based bug localization techniques do not perform well if the bug report lacks rich structured information (eg, relevant program entity names). Conversely, excessive structured information (eg, stack traces) in the bug report might not always help the automated localization either. In this paper, we propose a novel technique--BLIZZARD--that automatically localizes buggy entities from project source using appropriate query reformulation and effective information retrieval. In particular, our technique determines whether there are excessive program entities or not in a bug report (query), and then applies appropriate reformulations to the query for bug localization. Experiments using 5,139 bug reports show that our technique can localize the buggy source documents with 7%--56% higher [email protected], 6%--62% higher [email protected] and 6%--62% higher [email\u00a0\u2026", "num_citations": "48\n", "authors": ["979"]}
{"title": "The road to software clone management: A survey\n", "abstract": " 1 Yearly number of distinct authors contributing to clone research... 5 2 Categories of publications on software clone research in different years 5 3 Proportion of publications in each category over the period 1994\u20132011 6 4 A clone genealogy with two lineages over versions v k through v k+ 3[201] 18 5 Clone change patterns and types of genealogies [171]......... 20 6 Clone management workflow....................... 26 7 Kapser and Godfrey [107] Taxonomy: clone categorization based on location and functionality........................ 49 iii", "num_citations": "45\n", "authors": ["979"]}
{"title": "Simcad: An extensible and faster clone detection tool for large scale software systems\n", "abstract": " Code cloning is an inevitable phenomenon in evolution of software systems. To reduce the harmful effects of clones in software evolution, they need to be identified correctly as well in a time efficient way. There might be various types of clones in a software system. Earlier research shows detection of near-miss clones in large datasets appears to be costly in terms of time and memory. Among the clone detection tools available in practice, not very many of them are found effective in that regard. In this paper we present a standalone clone detection tool SimCad. It is based on a highly scalable and faster clone detection algorithm designed to detect both exact and near-miss clones in large-scale software systems. One of the potential aspects of SimCad is that its clone detection function is made more portable by packaging it into a library called SimLib. Thus, SimLib now can be used as an off-the-shelf clone detection\u00a0\u2026", "num_citations": "42\n", "authors": ["979"]}
{"title": "IDE-based real-time focused search for near-miss clones\n", "abstract": " Code clone is a well-known code smell that needs to be detected and managed during the software development process. However, the existing clone detectors have one or more of the three shortcomings:(a) limitation in detecting Type-3 clones,(b) they come as stand-alone tools separate from IDE and thus cannot support clone-aware development,(c) they overwhelm the developer with all clones from the entire code-base, instead of a focused search for clones of a selected code segment of the developer's interest.", "num_citations": "42\n", "authors": ["979"]}
{"title": "Fast and flexible large-scale clone detection with CloneWorks.\n", "abstract": " Clone detection in very-large inter-project repositories has numerous applications in software research and development. However, existing tools do not provide the flexibility researchers need to explore this emerging domain. We introduce CloneWorks, a fast and flexible clone detector for large-scale clone detection experiments. CloneWorks gives the user full control over the representation of the source code before clone detection, including easy plug-in of custom source transformation, normalization and filtering logic. The user can then perform targeted clone detection for any type or kind of clone of interest. CloneWorks uses our fast and scalable partitioned partial indexes approach, which can handle any input size on an average workstation using input partitioning. CloneWorks can detect Type-3 clones in an input as large as 250 million lines of code in just four hours on an average workstation, with good recall and precision as measured by our BigCloneBench.", "num_citations": "41\n", "authors": ["979"]}
{"title": "A mutation analysis based benchmarking framework for clone detectors\n", "abstract": " In recent years, an abundant number of clone detectors have been proposed in literature. However, most of the tool papers have lacked a solid performance evaluation of the subject tools. This is due both to the lack of an available and reliable benchmark, and the manual efforts required to hand check a large number of candidate clones. In this tool demonstration paper we show how a mutation analysis based benchmarking framework can be used by developers and researchers to evaluate clone detection tools at a fine granularity with minimal effort.", "num_citations": "41\n", "authors": ["979"]}
{"title": "Understanding the evolution of type-3 clones: an exploratory study\n", "abstract": " Understanding the evolution of clones is important both for understanding the maintenance implications of clones and building a robust clone management system. To this end, researchers have already conducted a number of studies to analyze the evolution of clones, mostly focusing on Type-1 and Type-2 clones. However, although there are a significant number of Type-3 clones in software systems, we know a little how they actually evolve. In this paper, we perform an exploratory study on the evolution of Type-1, Type-2, and Type-3 clones in six open source software systems written in two different programming languages and compare the result with a previous study to better understand the evolution of Type-3 clones. Our results show that although Type-3 clones are more likely to change inconsistently, the absolute number of consistently changed Type-3 clone classes is higher than that of Type-1 and Type-2\u00a0\u2026", "num_citations": "41\n", "authors": ["979"]}
{"title": "The impact of surface and geometry on coefficient of friction of artificial hip joints\n", "abstract": " Coefficient of friction (COF) tests were conducted on 28-mm and 36-mm-diameter hip joint prostheses for four different material combinations, with or without the presence of Ultra High Molecular Weight Polyethylene (UHMWPE) particles using a novel pendulum hip simulator. The effects of three micro dimpled arrays on femoral head against a polyethylene and a metallic cup were also investigated. Clearance played a vital role in the COF of ceramic on polyethylene and ceramic on ceramic artificial hip joints. Micro dimpled metallic femoral heads yielded higher COF against a polyethylene cup; however, with metal on metal prostheses the dimpled arrays significantly reduced the COF. In situ images revealed evidence that the dimple arrays enhanced film formation, which was the main mechanism that contributed to reduced friction.", "num_citations": "35\n", "authors": ["979"]}
{"title": "CloneWorks: a fast and flexible large-scale near-miss clone detection tool.\n", "abstract": " Clone detection within large inter-project sourcecode repositories has numerous rich applications. CloneWorks is a fast and flexible clone detector for large-scale near-miss clone detection experiments. CloneWorks gives the user full control over the processing of the source code before clone detection, enabling the user to target any clone type or perform custom clone detection experiments. Scalable clone detection is achieved, even on commodity hardware, using our partitioned partial indexes approach. CloneWorks scales to 250MLOC in just four on an average workstation with good recall and precision.", "num_citations": "34\n", "authors": ["979"]}
{"title": "On the use of context in recommending exception handling code examples\n", "abstract": " Studies show that software developers often either misuse exception handling features or use them inefficiently, and such a practice may lead an undergoing software project to a fragile, insecure and non-robust application system. In this paper, we propose a context-aware code recommendation approach that recommends exception handling code examples from a number of popular open source code repositories hosted at GitHub. It collects the code examples exploiting GitHub code search API, and then analyzes, filters and ranks them against the code under development in the IDE by leveraging not only the structural (i.e., graph-based) and lexical features but also the heuristic quality measures of exception handlers in the examples. Experiments with 4,400 code examples and 65 exception handling scenarios as well as comparisons with four existing approaches show that the proposed approach is highly\u00a0\u2026", "num_citations": "34\n", "authors": ["979"]}
{"title": "Effective reformulation of query for code search using crowdsourced knowledge and extra-large data analytics\n", "abstract": " Software developers frequently issue generic natural language queries for code search while using code search engines (e.g., GitHub native search, Krugle). Such queries often do not lead to any relevant results due to vocabulary mismatch problems. In this paper, we propose a novel technique that automatically identifies relevant and specific API classes from Stack Overflow Q & A site for a programming task written as a natural language query, and then reformulates the query for improved code search. We first collect candidate API classes from Stack Overflow using pseudo-relevance feedback and two term weighting algorithms, and then rank the candidates using Borda count and semantic proximity between query keywords and the API classes. The semantic proximity has been determined by an analysis of 1.3 million questions and answers of Stack Overflow. Experiments using 310 code search queries report\u00a0\u2026", "num_citations": "33\n", "authors": ["979"]}
{"title": "Towards a mutation-based automatic framework for evaluating code clone detection tools\n", "abstract": " In the last decade, a great many code clone detection tools have been proposed. Such a large number of tools calls for a quantitative comparison, and there have been several attempts to empirically evaluate and compare many of the state-of-the-art tools. However, a recent study shows that there are several factors that could influence the the validity of the results of such comparisons. In order to overcome the effects of such factors (at least in part), in this student poster paper we outline a mutation-based controlled frame-work for evaluating clone detection tools using edit-based mutation operators that model cloning actions. While the framework is not yet completely implemented and as yet we do not have experimental data, we anticipate that such a framework will provide a useful contribution to the community by providing a more solid objective foundation for tool evaluation.", "num_citations": "33\n", "authors": ["979"]}
{"title": "Are scripting languages really different?\n", "abstract": " Scripting languages such as Python, Perl, Ruby and PHP are increasingly important in new software systems as web technology becomes a dominant force. These languages are often spoken of as having different properties, in particular with respect to cloning, and the question arises whether the observations made based on traditional languages also apply to them. In this paper we present a first experiment in measuring the cloning properties of open source software systems written in the Python scripting language using the NiCad clone detector. We compare our results for Python with previous observations of C, C#, and Java, and discover that perhaps scripting languages are not so different after all.", "num_citations": "32\n", "authors": ["979"]}
{"title": "Conflict-aware optimal scheduling of code clone refactoring: A constraint programming approach\n", "abstract": " Duplicated code, also known as code clones, are one of the malicious `code smells' that often need to be removed through refactoring for enhancing maintainability. Among all the potential refactoring opportunities, the choice and order of a set of refactoring activities may have distinguishable effect on the design/code quality. Moreover, there may be dependencies and conflicts among those refactorings. The organization may also impose priorities on certain refactoring activities. Addressing all these conflicts, priorities, and dependencies, manual formulation of an optimal refactoring schedule is very expensive, if not impossible. Therefore, an automated refactoring scheduler is necessary, which will maximize benefit and minimize refactoring effort. In this paper, we present a refactoring effort model, and propose a constraint programming approach for conflict-aware optimal scheduling of code clone refactoring.", "num_citations": "29\n", "authors": ["979"]}
{"title": "STRICT: Information retrieval based search term identification for concept location\n", "abstract": " During maintenance, software developers deal with numerous change requests that are written in an unstructured fashion using natural language. Such natural language texts illustrate the change requirement involving various domain related concepts. Software developers need to find appropriate search terms from those concepts so that they could locate the possible locations in the source code using a search technique. Once such locations are identified, they can implement the requested changes there. Studies suggest that developers often perform poorly in coming up with good search terms for a change task. In this paper, we propose a novel technique-STRICT-that automatically identifies suitable search terms for a software change task by analyzing its task description using two information retrieval (IR) techniques-TextRank and POSRank. These IR techniques determine a term's importance based on not\u00a0\u2026", "num_citations": "26\n", "authors": ["979"]}
{"title": "A methodology to optimize query in wireless sensor networks using historical data\n", "abstract": " In wireless sensor networks (WSN), a query is commonly used for collecting periodical data from the objects under monitoring. Amount of sensory data drawn across WSNs by a query can significantly impact WSN\u2019s power consumption and its lifetime, since WSNs are battery operated. We present a novel methodology to construct an optimal query containing fewer sensory attributes as compared to a standard query, thereby reducing the sensory traffic in WSN. Our methodology employees a statistical technique, principal component analysis on historical traces of sensory data to automatically identify important attributes among the correlated ones. The optimal query containing reduced set of sensory attributes, guarantees at least 25% reduction in energy consumption of WSN with respect to a standard query. Furthermore, from reduced set of data reported by optimal query, the methodology synthesizes\u00a0\u2026", "num_citations": "25\n", "authors": ["979"]}
{"title": "Benchmarks for software clone detection: A ten-year retrospective\n", "abstract": " There have been a great many methods and tools proposed for software clone detection. While some work has been done on assessing and comparing performance of these tools, very little empirical evaluation has been done. In particular, accuracy measures such as precision and recall have only been roughly estimated, due both to problems in creating a validated clone benchmark against which tools can be compared, and to the manual effort required to hand check large numbers of candidate clones. In order to cope with this issue, over the last 10 years we have been working towards building cloning benchmarks for objectively evaluating clone detection tools. Beginning with our WCRE 2008 paper, where we conducted a modestly large empirical study with the NiCad clone detection tool, over the past ten years we have extended and grown our work to include several languages, much larger datasets, and\u00a0\u2026", "num_citations": "24\n", "authors": ["979"]}
{"title": "An insight into the unresolved questions at stack overflow\n", "abstract": " For a significant number of questions at Stack Overflow, none of the posted answers were accepted as solutions. Acceptance of an answer indicates that the answer actually solves the discussed problem in the question, and the question is answered sufficiently. In this paper, we investigate 3,956 such unresolved questions using an exploratory study where we analyze four important aspects of those questions, their answers and the corresponding users that partially explain the observed scenario. We then propose a prediction model by employing five metrics related to user behaviour, topics and popularity of question, which predicts if the best answer for a question at Stack Overflow might remain unaccepted or not. Experiments using 8,057 questions show that the model can predict unresolved questions with 78.70% precision and 76.10% recall.", "num_citations": "24\n", "authors": ["979"]}
{"title": "QUICKAR: Automatic query reformulation for concept location using crowdsourced knowledge\n", "abstract": " During maintenance, software developers deal with numerous change requests made by the users of a software system. Studies show that the developers find it challenging to select appropriate search terms from a change request during concept location. In this paper, we propose a novel technique-QUICKAR-that automatically suggests helpful reformulations for a given query by leveraging the crowdsourced knowledge from Stack Overflow. It determines semantic similarity or relevance between any two terms by analyzing their adjacent word lists from the programming questions of Stack Overflow, and then suggests semantically relevant queries for concept location. Experiments using 510 queries from two software systems suggest that our technique can improve or preserve the quality of 76% of the initial queries on average which is promising. Comparison with one baseline technique validates our preliminary\u00a0\u2026", "num_citations": "22\n", "authors": ["979"]}
{"title": "Improved wear resistance of functional diamond like carbon coated Ti\u20136Al\u20134V alloys in an edge loading conditions\n", "abstract": " This study investigates the durability of functional diamond-like carbon (DLC) coated titanium alloy (Ti\u20136Al\u20134V) under edge loading conditions for application in artificial hip joints. The multilayered (ML) functional DLC coatings consist of three key layers, each of these layers were designed for specific functions such as increasing fracture strength, adapting stress generation and enhancing wear resistance. A \u2018ball-on-disk\u2019 multi-directional wear tester was used in the durability test. Prior to the wear testing, surface hardness, modulus elasticity and Raman intensity were measured. The results revealed a significant wear reduction to the DLC coated Ti\u20136Al\u20134V disks compared to that of non-coated Ti\u20136Al\u20134V disks. Remarkably, the counterpart Silicon Nitride (Si3N4) balls also yielded lowered specific wear rate while rubbed against the coated disks. Hence, the pairing of a functional multilayered DLC and Si3N4 could\u00a0\u2026", "num_citations": "22\n", "authors": ["979"]}
{"title": "TextRank based search term identification for software change tasks\n", "abstract": " During maintenance, software developers deal with a number of software change requests. Each of those requests is generally written using natural language texts, and it involves one or more domain related concepts. A developer needs to map those concepts to exact source code locations within the project in order to implement the requested change. This mapping generally starts with a search within the project that requires one or more suitable search terms. Studies suggest that the developers often perform poorly in coming up with good search terms for a change task. In this paper, we propose and evaluate a novel TextRank-based technique that automatically identifies and suggests search terms for a software change task by analyzing its task description. Experiments with 349 change tasks from two subject systems and comparison with one of the latest and closely related state-of-the-art approaches show\u00a0\u2026", "num_citations": "21\n", "authors": ["979"]}
{"title": "Preparation of Hierarchical Porous Activated Carbon from Banana Leaves for High\u2010performance Supercapacitor: Effect of Type of Electrolytes on Performance\n", "abstract": " We demonstrate a facile efficient way to fabricate activated carbon nanosheets (ACNSs) consisting of hierarchical porous carbon materials. Simply heating banana leaves with K2CO3 produce ACNSs having a unique combination of macro\u2010, meso\u2010 and micropores with a high specific surface area of \u223c1459\u2005m2\u2009g\u22121. The effects of different electrolytes on the electrochemical supercapacitor performance and stability of the ACNSs are tested using a two\u2010electrode system. The specific capacitance (Csp) values are 55, 114, and 190\u2005F\u2009g\u22121 in aqueous 0.5\u2005M sodium sulfate, organic 1\u2005M tetraethylammonium tetrafluoroborate in acetonitrile, and pure ionic liquid 1\u2010butyl\u20103\u2010methylimidazolium hexafluorophosphate ([BMIM][PF6]) electrolytes, respectively. The ACNSs also shows the largest potential window of 3.0\u2005V, the highest specific energy (59\u2005Wh\u2009kg\u22121) and specific power (750\u2005W\u2009kg\u22121) in [BMIM][PF6]. A mini\u00a0\u2026", "num_citations": "20\n", "authors": ["979"]}
{"title": "gcad: A near-miss clone genealogy extractor to support clone evolution analysis\n", "abstract": " Understanding the evolution of code clones is important for both developers and researchers to understand the maintenance implications of clones and to design robust clone management systems. Generally, a study of clone evolution starts with extracting clone genealogies across multiple versions of a program and classifying them according to their change patterns. Although these tasks are straightforward for exact clones, extracting the history of near-miss clones and classifying their change patterns automatically is challenging due to the potential diverse variety of clone fragments even in the same clone class. In this tool demonstration paper we describe the design and implementation of a near-miss clone genealogy extractor, gCad, that can extract and classify both exact and near-miss clone genealogies. Developers and researchers can compute a wide range of popular metrics regarding clone evolution by\u00a0\u2026", "num_citations": "20\n", "authors": ["979"]}
{"title": "Visualizing the evolution of code clones\n", "abstract": " The knowledge of code clone evolution throughout the history of a software system is essential in comprehending and managing its clones properly and cost-effectively. However, investigating and observing facts in a huge set of text-based data provided by a clone genealogy extractor could be challenging without the support of a visualization tool. In this position paper, we present an idea of visualizing code clone evolution by exploiting the advantages of existing clone visualization techniques that would be both scalable and useful.", "num_citations": "20\n", "authors": ["979"]}
{"title": "Improved query reformulation for concept location using coderank and document structures\n", "abstract": " During software maintenance, developers usually deal with a significant number of software change requests. As a part of this, they often formulate an initial query from the request texts, and then attempt to map the concepts discussed in the request to relevant source code locations in the software system (a.k.a., concept location). Unfortunately, studies suggest that they often perform poorly in choosing the right search terms for a change task. In this paper, we propose a novel technique-ACER-that takes an initial query, identifies appropriate search terms from the source code using a novel term weight-CodeRank, and then suggests effective reformulation to the initial query by exploiting the source document structures, query quality analysis and machine learning. Experiments with 1,675 baseline queries from eight subject systems report that our technique can improve 71% of the baseline queries which is highly\u00a0\u2026", "num_citations": "19\n", "authors": ["979"]}
{"title": "Evaluating the conventional wisdom in clone removal: A genealogy-based empirical study\n", "abstract": " Clone management has drawn immense interest from the research community in recent years. It is recognized that a deep understanding of how code clones change and are refactored is necessary for devising effective clone management tools and techniques. This paper presents an empirical study based on the clone genealogies from a significant number of releases of six software systems, to characterize the patterns of clone change and removal in evolving software systems. With a blend of qualitative analysis, quantitative analysis and statistical tests of significance, we address a number of research questions. Our findings reveal insights into the removal of individual clone fragments and provide empirical evidence in support of conventional clone evolution wisdom. The results can be used to devise informed clone management tools and techniques.", "num_citations": "19\n", "authors": ["979"]}
{"title": "Automatic query reformulation for code search using crowdsourced knowledge\n", "abstract": " Traditional code search engines (e.g., Krugle) often do not perform well with natural language queries. They mostly apply keyword matching between query and source code. Hence, they need carefully designed queries containing references to relevant APIs for the code search. Unfortunately, preparing an effective search query is not only challenging but also time-consuming for the developers according to existing studies. In this article, we propose a novel query reformulation technique\u2013RACK\u2013that suggests a list of relevant API classes for a natural language query intended for code search. Our technique offers such suggestions by exploiting keyword-API associations from the questions and answers of Stack Overflow (i.e., crowdsourced knowledge). We first motivate our idea using an exploratory study with 19 standard Java API packages and 344K Java related posts from Stack Overflow. Experiments\u00a0\u2026", "num_citations": "18\n", "authors": ["979"]}
{"title": "Impact of continuous integration on code reviews\n", "abstract": " Peer code review and continuous integration often interleave with each other in the modern software quality management. Although several studies investigate how non-technical factors (e.g., reviewer workload), developer participation and even patch size affect the code review process, the impact of continuous integration on code reviews is not yet properly understood. In this paper, we report an exploratory study using 578K automated build entries where we investigate the impact of automated builds on the code reviews. Our investigation suggests that successfully passed builds are more likely to encourage new code review participation in a pull request. Frequently built projects are found to be maintaining a steady level of reviewing activities over the years, which was quite missing from the rarely built projects. Experiments with 26,516 automated build entries reported that our proposed model can identify 64\u00a0\u2026", "num_citations": "18\n", "authors": ["979"]}
{"title": "A change-type based empirical study on the stability of cloned code\n", "abstract": " Clones are the duplicate or similar code blocks in software systems. A large number of studies concerning the impacts of clones on software systems mainly focus on the frequency of changes to evaluate stability, consistency in evolution and introduction of bugs. Although it is obvious that not each type of changes has equal impact on software systems, none of the existing studies take the types of changes and their significance into account during comparative evaluation of stability of cloned and non-cloned code. This paper presents an empirical study on the comparative stability of cloned and non-cloned code from the perspective of different change types. Changes from successive revisions are extracted and classified using Change Distiller which employs Abstract Syntax Tree (AST) differencing of the successive revisions of source code and assigns the corresponding level of significance to each of the classified\u00a0\u2026", "num_citations": "18\n", "authors": ["979"]}
{"title": "Tuning research tools for scalability and performance: The NICAD experience\n", "abstract": " Clone detection is a research technique for analyzing software systems for similarities, with applications in software understanding, maintenance, evolution, license enforcement and many other issues. The NiCad near-miss clone detection method has been shown to yield highly accurate results in both precision and recall. However, its naive two-step method, involving a parsing first step to identify and normalize code fragments, followed by a text line-based second step using longest common subsequence (LCS) to compare fragments, has proven difficult to migrate to the efficiency and scalability required for large scale research applications. Rather than presenting the NiCad tool itself in detail, this paper focuses on our experience in migrating NiCad from an initial rapid prototype to a practical scalable research tool. The process has increased overall performance by a factor of up to 40 and clone detection speed\u00a0\u2026", "num_citations": "18\n", "authors": ["979"]}
{"title": "Debcheck: Efficient checking for open source code clones in software systems\n", "abstract": " The problem of finding code cloned from open source code in software systems is of interest both to the open source community (e.g., for GPL and other open source license enforcement) and the industrial community (e.g., to prevent GPL \"contamination\" of proprietary commercial software systems). The largest collection of open source software in general distribution is the collection of eight DVDs in the Debian source distribution, and checking for cross-cloning with the Debian source distribution goes a long way towards finding any possible copying from the set of all open source code in the world. The NiCad clone detector is an open source language- sensitive robust clone detector that has been shown to yield both high precision and high recall in detecting syntactically meaningful near-miss clones such as functions and blocks. Given a directory of new source code to check, DebCheck uses NiCad in its\u00a0\u2026", "num_citations": "18\n", "authors": ["979"]}
{"title": "Towards a reference architecture for cloud-based plant genotyping and phenotyping analysis frameworks\n", "abstract": " The domain of plant genotyping and phenotyping presents a number of challenges in the area of large data computation. Various tools and systems have been developed to automate the scientific workflows and support the computational needs of this domain. In this paper, we review a number of the popular systems (i.e., Galaxy, iPlant, GenAp and LemnaTec) in the domain of plant genotyping and phenotyping using the scenario-based architectural analysis method (SAAM). In particular, we focus on how different stakeholders are using these systems in a variety of scenarios and to what extent the systems support their needs. Our SAAM analysis shows that the existing systems have shortcomings. For example, they are limited in their support for high throughput processing of large amounts of heterogeneous types of data. Based on our findings we propose a reference architecture along with a preliminary\u00a0\u2026", "num_citations": "17\n", "authors": ["979"]}
{"title": "Near-miss clone patterns in web applications: An empirical study with industrial systems\n", "abstract": " Dynamic web pages composed of inter-woven (tangled) source code written in multiple programming languages (e.g., HTML, PHP, JavaScript, CSS) makes it difficult to analyze and manage clones in web applications. Despite more than a decade of research on software clones, there are not many studies towards the investigation of code clones in web applications. In this paper, we present an in-depth study on the patterns (i.e., forking and templating) of exact and near-miss code clones in two industrial dynamic web applications having distinct architecture. The findings of our study confirm the believed patterns for cloning and suggest that specialized techniques and tool support are necessary for effectively managing clones in the tangled source code of dynamic web applications.", "num_citations": "17\n", "authors": ["979"]}
{"title": "Rack: Code search in the IDE using crowdsourced knowledge\n", "abstract": " Traditional code search engines often do not perform well with natural language queries since they mostly apply keyword matching. These engines thus require carefully designed queries containing information about programming APIs for code search. Unfortunately, existing studies suggest that preparing an effective query for code search is both challenging and time consuming for the developers. In this paper, we propose a novel code search tool-RACK-that returns relevant source code for a given code search query written in natural language text. The tool first translates the query into a list of relevant API classes by mining keyword-API associations from the crowdsourced knowledge of Stack Overflow, and then applies the reformulated query to GitHub code search API for collecting relevant results. Once a query related to a programming task is submitted, the tool automatically mines relevant code snippets\u00a0\u2026", "num_citations": "16\n", "authors": ["979"]}
{"title": "Modeling erlang in the pi-calculus\n", "abstract": " This paper provides a contribution to the formal modeling and verification of programs written in the concurrent functional programming language Erlang, which is designed for telecommunication applications. It presents a mapping of Core Erlang programs into the \u03c0--calculus, a process algebra whose name--passing feature allows to represent the mobile aspects of Erlang software in a natural way.", "num_citations": "15\n", "authors": ["979"]}
{"title": "On the relationships between stability and bug-proneness of code clones: An empirical study\n", "abstract": " Exact or similar copies of code fragments in a code base are known as code clones. Code clones are considered as one of the serious code smells. Stability is a widely investigated perspective of assessing the impacts of clones on software systems. A number of existing studies show that clones are often less stable than non-cloned code. This suggests that clones change more frequently than non-cloned code and thus may require comparatively more maintenance efforts. Again, frequent changes to clones may increase the likelihood of missing change propagation to the co-change candidates leading to inconsistencies or bugs. However, none of the existing studies investigate whether stability of clones is related to the bug-proneness. In this paper, we present an empirical study that analyzes the relationships between stability and bug-proneness of clones. We identify bug-fix commits by analyzing the commit\u00a0\u2026", "num_citations": "14\n", "authors": ["979"]}
{"title": "Interactive visualization of bug reports using topic evolution and extractive summaries\n", "abstract": " Software bug reports are important project artifacts that evolve throughout the life of a software project. Software bugs are issues that are reported by users when these issues hinder their work. Software projects evolve over time as bugs are addressed and new features are added. Managing bugs can be a significant challenge as a project manager generally needs to be aware of all the bug reports for the current version, and this can be even more challenging when the number of bug reports becomes large. It is preferable that a developer new to a project improves her knowledge with the project along with the bug reports during working on it, which is likely to help her avoid or handle the reported issues. In this paper, we propose a prototype that assists developers review a project's bug reports by interactively visualizing insightful information regarding the bug reports using topic analysis. In addition, in order to\u00a0\u2026", "num_citations": "14\n", "authors": ["979"]}
{"title": "Surfclipse: Context-aware meta-search in the ide\n", "abstract": " Despite various debugging supports of the existing IDEs for programming errors and exceptions, software developers often look at web for working solutions or any up-to-date information. Traditional web search does not consider the context of the problems that they search solutions for, and thus it often does not help much in problem solving. In this paper, we propose a context-aware meta search tool, Surf Clipse, that analyzes an encountered exception and its context in the IDE, and recommends not only suitable search queries but also relevant web pages for the exception (and its context). The tool collects results from three popular search engines and a programming Q & A site against the exception in the IDE, refines the results for relevance against the context of the exception, and then ranks them before recommendation. It provides two working modes-interactive and proactive to meet the versatile needs of\u00a0\u2026", "num_citations": "14\n", "authors": ["979"]}
{"title": "Evaluating the evolution of small scale open source software systems\n", "abstract": " For real-world software to remain satisfactory to its stakeholders requires its continual enhancement and adaptation. Acceptance of this phenomenon, termed software evolution, as intrinsic to real world software has led to an increasing interest in disciplined and systematic planning, management and improvement of the evolution process. Almost all of the previous work on software evolution has been concerned with the evolution of large scale real-world software systems developed within a single company using traditional management techniques, or with the large scale open source software systems (LSOSSS). However, there is to our knowledge little or no work that has considered small scale open source software systems (SSOSSS). This paper presents an analysis of the evolution behavior of two small size open source software systems, the Barcode Library and Zlib. Surprisingly, unlike large scale open source software systems, the evolution behavior of these small size open source software systems appears to follow Lehman\u2019s laws for software evolution.", "num_citations": "14\n", "authors": ["979"]}
{"title": "Clcdsa: cross language code clone detection using syntactical features and api documentation\n", "abstract": " Software clones are detrimental to software maintenance and evolution and as a result many clone detectors have been proposed. These tools target clone detection in software applications written in a single programming language. However, a software application may be written in different languages for different platforms to improve the application's platform compatibility and adoption by users of different platforms. Cross language clones (CLCs) introduce additional challenges when maintaining multi-platform applications and would likely go undetected using existing tools. In this paper, we propose CLCDSA, a cross language clone detector which can detect CLCs without extensive processing of the source code and without the need to generate an intermediate representation. The proposed CLCDSA model analyzes different syntactic features of source code across different programming languages to detect\u00a0\u2026", "num_citations": "13\n", "authors": ["979"]}
{"title": "A machine learning based approach for evaluating clone detection tools for a generalized and accurate precision\n", "abstract": " An important measure of clone detection performance is precision. However, there has been a marked lack of research into methods for efficiently and accurately measuring the precision of a clone detection tool. Instead, tool authors simply validate a small random sample of the clones their tools detected in a subject software system. Since there could be many thousands of clones reported by the tool, such a small random sample cannot guarantee an accurate and generalized measure of the tool\u2019s precision for all the varieties of clones that can occur in any arbitrary software system. In this paper, we propose a machine-learning-based approach that can cluster similar clones together, and which can be used to maximize the variety of clones examined when measuring precision, while significantly reducing the biases a specific subject system has on the generality of the precision measured. Our technique reduces\u00a0\u2026", "num_citations": "13\n", "authors": ["979"]}
{"title": "Correct: Code reviewer recommendation at github for vendasta technologies\n", "abstract": " Peer code review locates common coding standard violations and simple logical errors in the early phases of software development, and thus, reduces overall cost. Unfortunately, at GitHub, identifying an appropriate code reviewer for a pull request is challenging given that reliable information for reviewer identification is often not readily available. In this paper, we propose a code reviewer recommendation tool-CORRECT-that considers not only the relevant cross-project work experience (eg, external library experience) of a developer but also her experience in certain specialized technologies (eg, Google App Engine) associated with a pull request for determining her expertise as a potential code reviewer. We design our tool using client-server architecture, and then package the solution as a Google Chrome plug-in. Once the developer initiates a new pull request at GitHub, our tool automatically analyzes the\u00a0\u2026", "num_citations": "13\n", "authors": ["979"]}
{"title": "An ide-based context-aware meta search engine\n", "abstract": " Traditional web search forces the developers to leave their working environments and look for solutions in the web browsers. It often does not consider the context of their programming problems. The context-switching between the web browser and the working environment is time-consuming and distracting, and the keyword-based traditional search often does not help much in problem solving. In this paper, we propose an Eclipse IDE-based web search solution that collects the data from three web search APIs-Google, Yahoo, Bing and a programming Q & A site-StackOverflow. It then provides search results within IDE taking not only the content of the selected error into account but also the problem context, popularity and search engine recommendation of the result links. Experiments with 25 runtime errors and exceptions show that the proposed approach outperforms the keyword-based search approaches with a\u00a0\u2026", "num_citations": "13\n", "authors": ["979"]}
{"title": "On the relationships between domain-based coupling and code clones: an exploratory study\n", "abstract": " Knowledge of similar code fragments, also known as code clones, is important to many software maintenance activities including bug fixing, refactoring, impact analysis and program comprehension. While a great deal of research has been conducted for finding techniques and implementing tools to identify code clones, little research has been done to analyze the relationships between code clones and other aspects of software. In this paper, we attempt to uncover the relationships between code clones and coupling among domain-level components. We report on a case study of a large-scale open source enterprise system, where we demonstrate that the probability of finding code clones among components with domain-based coupling is more than 90%. While such a probabilistic view does not replace a clone detection tool per se, it certainly has the potential to complement the existing tools by providing the\u00a0\u2026", "num_citations": "13\n", "authors": ["979"]}
{"title": "Poster: improving bug localization with report quality dynamics and query reformulation\n", "abstract": " Recent findings from a user study suggest that IR-based bug localization techniques do not perform well if the bug report lacks rich structured information such as relevant program entity names. On the contrary, excessive structured information such as stack traces in the bug report might always not be helpful for the automated bug localization. In this paper, we conduct a large empirical study using 5,500 bug reports from eight subject systems and replicating three existing studies from the literature. Our findings (1) empirically demonstrate how quality dynamics of bug reports affect the performances of IR-based bug localization, and (2) suggest potential ways (e.g., query reformulations) to overcome such limitations.", "num_citations": "12\n", "authors": ["979"]}
{"title": "Genealogical insights into the facts and fictions of clone removal\n", "abstract": " Clone management has drawn immense interest from the research community in recent years. It is recognized that a deep understanding of how code clones change and are refactored is necessary for devising effective clone management tools and techniques. This paper presents an empirical study based on the clone genealogies from a significant number of releases of nine software systems, to characterize the patterns of clone change and removal in evolving software systems. With a blend of qualitative analysis, quantitative analysis and statistical tests of significance, we address a number of research questions. Our findings reveal insights into the removal of individual clone fragments and provide empirical evidence in support of conventional clone evolution wisdom. The results can be used to devise informed clone management tools and techniques.", "num_citations": "12\n", "authors": ["979"]}
{"title": "Can issues reported at stack overflow questions be reproduced? an exploratory study\n", "abstract": " Software developers often look for solutions to their code level problems at Stack Overflow. Hence, they frequently submit their questions with sample code segments and issue descriptions. Unfortunately, it is not always possible to reproduce their reported issues from such code segments. This phenomenon might prevent their questions from getting prompt and appropriate solutions. In this paper, we report an exploratory study on the reproducibility of the issues discussed in 400 questions of Stack Overflow. In particular, we parse, compile, execute and even carefully examine the code segments from these questions, spent a total of 200 man hours, and then attempt to reproduce their programming issues. The outcomes of our study are two-fold. First, we find that 68% of the code segments require minor and major modifications in order to reproduce the issues reported by the developers. On the contrary, 22% code\u00a0\u2026", "num_citations": "11\n", "authors": ["979"]}
{"title": "On the comprehension of code clone visualizations: A controlled study using eye tracking\n", "abstract": " Code clone visualizations (CCVs) are graphical representations of clone detection results provided by various state-of-the-art command line and graphical analysis tools. In order to properly analyze and manipulate code clones within a target system, these visualizations must be easily and efficiently comprehensible. We conducted an eye-tracking study with 20 participants (expert, intermediate, and novice) to assess how well people can comprehend visualizations such as Scatter plots, Treemaps, and Hierarchical Dependency Graphs provided by VisCad, a recent clone visualization tool. The goals of the study were to find out what elements of the visualizations (e.g., colors, shapes, object positions) are most important for comprehension, and to identify common usage patterns for different groups. Our results help us understand how developers with different levels of expertise explore and navigate through the\u00a0\u2026", "num_citations": "11\n", "authors": ["979"]}
{"title": "The mutation and injection framework: Evaluating clone detection tools with mutation analysis\n", "abstract": " An abundant number of clone detection tools have been proposed in the literature due to the many applications and benefits of clone detection. However, there has been difficulty in the performance evaluation and comparison of these clone detectors. This is due to a lack of reliable benchmarks, and the manual efforts required to validate a large number of candidate clones. In particular, there has been a lack of a synthetic benchmark that can precisely and comprehensively measure clone-detection recall. In this paper, we present a mutation-analysis based benchmarking framework that can be used not only to evaluate the recall of clone detection tools for different types of clones but also for specific kinds of clone edits and without any manual efforts. The framework uses an editing taxonomy of clone synthesis for generating thousands of artificial clones, injects into code bases and automatically evaluates the\u00a0\u2026", "num_citations": "10\n", "authors": ["979"]}
{"title": "Crolsim: Cross language software similarity detector using api documentation\n", "abstract": " In today's open source era, developers look forsimilar software applications in source code repositories for anumber of reasons, including, exploring alternative implementations, reusing source code, or looking for a better application. However, while there are a great many studies for finding similarapplications written in the same programming language, there isa marked lack of studies for finding similar software applicationswritten in different languages. In this paper, we fill the gapby proposing a novel modelCroLSimwhich is able to detectsimilar software applications across different programming lan-guages. In our approach, we use the API documentation tofind relationships among the API calls used by the differentprogramming languages. We adopt a deep learning based word-vector learning method to identify semantic relationships amongthe API documentation which we then use to detect cross-language\u00a0\u2026", "num_citations": "10\n", "authors": ["979"]}
{"title": "Forksim: Generating software forks for evaluating cross-project similarity analysis tools\n", "abstract": " Software project forking, that is copying an existing project and developing a new independent project from the copy, occurs frequently in software development. Analysing the code similarities between such software projects is useful as developers can use similarity information to merge the forked systems or migrate them towards a reuse approach. Several techniques for detecting cross-project similarities have been proposed. However, no good benchmark to measure their performance is available. We developed ForkSim, a tool for generating datasets of synthetic software forks with known similarities and differences. This allows the performance of cross-project similarity tools to be measured in terms of recall and precision by comparing their output to the known properties of the generated dataset. These datasets can also be used in controlled experiments to evaluate further aspects of the tools, such as usability\u00a0\u2026", "num_citations": "10\n", "authors": ["979"]}
{"title": "A universal cross language software similarity detector for open source software categorization\n", "abstract": " While there are novel approaches for detecting and categorizing similar software applications, previous research focused on detecting similarity in applications written in the same programming language and not on detecting similarity in applications written in different programming languages. Cross-language software similarity detection is inherently more challenging due to variations in language, application structures, support libraries used, and naming conventions. In this paper we propose a novel model, CroLSim, to detect similar software applications across different programming languages. We define a semantic relationship among cross-language libraries and API methods (both local and third party) using functional descriptions and a word-vector learning model. Our experiments show that CroLSim can successfully detect cross-language similar software applications, which outperforms all existing\u00a0\u2026", "num_citations": "9\n", "authors": ["979"]}
{"title": "Clonecognition: machine learning based code clone validation tool\n", "abstract": " A code clone is a pair of similar code fragments, within or between software systems. To detect each possible clone pair from a software system while handling the complex code structures, the clone detection tools undergo a lot of generalization of the original source codes. The generalization often results in returning code fragments that are only coincidentally similar and not considered clones by users, and hence requires manual validation of the reported possible clones by users which is often both time-consuming and challenging. In this paper, we propose a machine learning based tool'CloneCognition'(Open Source Codes: https://github. com/pseudoPixels/CloneCognition; Video Demonstration: https://www. youtube. com/watch? v= KYQjmdr8rsw) to automate the laborious manual validation process. The tool runs on top of any code clone detection tools to facilitate the clone validation process. The tool shows\u00a0\u2026", "num_citations": "9\n", "authors": ["979"]}
{"title": "Nlp2api: Query reformulation for code search using crowdsourced knowledge and extra-large data analytics\n", "abstract": " Software developers frequently issue generic natural language (NL) queries for code search. Unfortunately, such queries often do not lead to any relevant results with contemporary code (or web) search engines due to vocabulary mismatch problems. In our technical research paper (accepted at ICSME 2018), we propose a technique-NLP2API-that reformulates such NL queries using crowdsourced knowledge and extra-large data analytics derived from Stack Overflow Q & A site. In this paper, we discuss all the artifacts produced by our work, and provide necessary details for downloading and verifying them.", "num_citations": "8\n", "authors": ["979"]}
{"title": "Recommending software experts using code similarity and social heuristics.\n", "abstract": " Successful collaboration among developers is crucial to the completion of software projects in a Distributed Software System Development (DSSD) environment. We have developed an Expert Recommender System Framework (ERSF) that assists a developer (called the\u201cActive Developer\u201d) to find other developers who can help them to fix code with which they are having difficulty. The ERSF first looks for other developers with similar technical expertise, as measured by their prior work on code fragments that are similar to (clones of) the code that the Active Developer is working on (the \u201ccode at hand\u201d). As well, it analyzes the other developers\u2019 social relationships with the Active Developer (available from the DSSD environment) and their social activities within the ERSF (information which helps to maintain developer profiles used in this analysis). This information is then combined to provide a ranked list of potential helpers based on both technical and social measures. A proof of concept experiment shows that the ERSF can recommend experts with good to excellent accuracy, when compared with human rankings of appropriate experts in the same scenarios", "num_citations": "8\n", "authors": ["979"]}
{"title": "Development of a Novel Bio\u2010based Redox Electrolyte using Pivalic Acid and Ascorbic Acid for the Activated Carbon\u2010based Supercapacitor Fabrication\n", "abstract": " Supercapacitor is considered a promising energy storage device due to its high\u2010power density and high specific capacitance. Electrode materials and electrolytes are major components of supercapacitors. The most used electrolytes are not biocompatible, which limits their practical applications. Bio\u2010electrolytes often cause low performances of supercapacitors. However, the inadequate performances of bio\u2010electrolytes for supercapacitor applications could be improved using redox molecules. Here, we are reporting the development of a novel redox bio\u2010electrolyte based on pivalic acid\u2005(PA) and ascorbic acid\u2005(AA). The salts of PA and AA\u2005served as the bio\u2010electrolyte and redox molecules, respectively. It is worth to note that PA which can be generated from bio\u2010sources and industrial wastes, is soluble in alkaline solutions. AA is found in most living organisms, including plants. The developed supercapacitor with\u00a0\u2026", "num_citations": "7\n", "authors": ["979"]}
{"title": "Improvement of the strength of poly (acrylic acid) hydrogels by the incorporation of functionally modified nanocrystalline Cellulose\n", "abstract": " Finding different strategies to incorporate functionalized nanocrystalline cellulose (NCC) into polymeric materials is a fascinating domain of current research. In this study, dialdehyde nanocrystalline cellulose (DANC) and dicarboxylated nanocrystalline cellulose (DCNC) were prepared by the functionalization of NCC at the C-2 and C-3 positions of the glucose moiety by a selective chemical oxidation process. The functionalized NCCs were successfully incorporated into poly(acrylic acid) (PAA) hydrogels to improve their mechanical properties. The PAA hydrogel incorporated with DCNC (PAA-DCNC) showed the most significant enhancement in mechanical properties compared to the neat PAA, PAA-NCC, and PAA-DANC hydrogels. The Young's modulus of the neat PAA hydrogel was only 90.2 kPa, which was increased by about six times (619.1 kPa) by the addition of a minimal amount (0.058 wt%) of DCNC with\u00a0\u2026", "num_citations": "7\n", "authors": ["979"]}
{"title": "Recommending relevant sections from a webpage about programming errors and exceptions\n", "abstract": " Programming errors or exceptions are inherent in software development and maintenance, and given today's Internet era, software developers often look at web for finding working solutions. They make use of a search engine for retrieving relevant pages, and then look for the appropriate solutions by manually going through the pages one by one. However, both the manual checking of a page's content against a given exception (and its context) and then working an appropriate solution out are non-trivial tasks. They are even more complex and time-consuming with the bulk of irrelevant (i.e., off-topic) and noisy (e.g., advertisements) content in the web page. In this paper, we propose an IDE-based and context-aware page content recommendation technique that locates and recommends relevant sections from a given web page by exploiting the technical details, in particular, the context of an encountered exception in the IDE. An evaluation with 250 web pages related to 80 programming exceptions, comparison with the only available closely related technique, and a case study involving comparison with VSM and LSA techniques show that the proposed technique is highly promising in terms of precision, recall and F1-measure.", "num_citations": "6\n", "authors": ["979"]}
{"title": "Embedded emotion-based classification of stack overflow questions towards the question quality prediction\n", "abstract": " Software developers often ask questions in Stack Overflow Q & A site, and their posted questions sometimes do not meet the standard guidelines. As a consequence, some of the questions are edited by expert users, some of them are down-voted, or some are even deleted permanently. Besides, the users (ie, developers) might not get the expected solutions for their problems. In this paper, we study up-voted and down-voted questions from Stack Overflow, and analyze the relationship of embedded emotions with question quality. We use Sentiment140 API for identifying embedded emotions in the question texts, and then apply Feed-Forward Multilayer Perceptron (MLP) and Support Vector Machine (SVM) on the emotion data for developing a quality prediction model. Experiments using 38,920 Stack Overflow questions suggest about 70% precision and about 74% recall for our model with 10-fold cross-validation, and these findings clearly reveal the impact of human emotions upon the quality of a question.", "num_citations": "6\n", "authors": ["979"]}
{"title": "Towards automatic verification of Erlang programs by \u03c0-calculus translation\n", "abstract": " ERLANG is a concurrent, dynamically typed, distributed, purely functional programming language with non-purely functional libraries that is mainly employed in telecommunication systems. This paper provides a contribution to the formal modeling and verificationn of programs written in Erlang. It presents a mapping of Erlang programs to the \u03c0-calculus, a process algebra whose name-passing feature allows representation of the mobile aspects of software written in Erlang in a natural way.", "num_citations": "6\n", "authors": ["979"]}
{"title": "Semanticclonebench: A semantic code clone benchmark using crowd-source knowledge\n", "abstract": " Not only do newly proposed code clone detection techniques, but existing techniques and tools also need to be evaluated and compared. This evaluation process could be done by assessing the reported clones manually or by using benchmarks. The main limitations of available benchmarks include: they are restricted to one programming language; they have a limited number of clone pairs that are confined within the selected system(s); they require manual validation; they do not support all types of code clones. To overcome these limitations, we proposed a methodology to generate a wide range of semantic clone benchmark(s) for different programming languages with minimal human validation. Our technique is based on the knowledge provided by developers who participate in the crowd-sourced information website, Stack Overflow. We applied automatic filtering, selection and validation to the source code in\u00a0\u2026", "num_citations": "5\n", "authors": ["979"]}
{"title": "Towards convenient management of software clone codes in practice: an integrated approach.\n", "abstract": " Software code cloning is inevitable during software development and unmanaged cloning practice can create substantial problems for software maintenance and evolution. Current research in the area software clones includes, but is not limited to: finding ways to manage clones; gaining more control over clone generation; and, studying clone evolution and its effects on the evolution of software. In this study, we investigate tools and techniques for detecting, managing, and understanding the evolution of clones, as well as design a convenient tool to make those techniques available to a developer\u2019s software development environment. Towards the goal of promoting the practical use of code clone research and to provide better support for managing clones in software systems, we first developed SimEclipse: a clone-aware software development platform, and then, using the tool, we performed a study to investigate the usefulness of using a number clone based technologies in an integrated platform rather than using those discretely. Finally, a small scale user study is performed to evaluate SimEclipse\u2019s effectiveness, usability and information management with respect to some pre-defined clone management activities. We believe that both researchers and developers would enjoy and utilize the benefits of using SimEclipse for different aspects of code clone research as well as for managing cloned code in software systems.", "num_citations": "5\n", "authors": ["979"]}
{"title": "A modification of huffman header\n", "abstract": " Huffman compression needs to store the header with the compressed file. The problem is how to store the header. The contents of header may be the actual character frequencies from which the Huffman tree can be built or may be the tree itself. But storing the frequencies may take unwanted large space. Here, the paper presents a modification of Huffman header. This modified header stores the bitmap representation of the Huffman tree instead of storing the frequencies of the symbols. The method first compresses the Huffman header itself and then adds it to the existing Huffman coding. The proposed technique increases the compression ratio and reduces expansion time of Huffman coding.", "num_citations": "5\n", "authors": ["979"]}
{"title": "Clone swarm: A cloud based code-clone analysis tool\n", "abstract": " A code clone is defined as a pair of similar code fragments within a software system. While code clones are not always harmful, they can have a detrimental effect on the overall quality of a software system due to the propagation of bugs and other maintenance implications. Because of this, software developers need to analyse the code clones that exist in a software system. However, despite the availability of several clone detection systems, the adoption of such tools outside of the clone community remains low. A possible reason for this is the difficulty and complexity involved in setting up and using these tools. In this paper, we present Clone Swarm, a code clone analytics tool that identifies clones in a project and presents the information in an easily accessible manner. Clone Swarm is publicly available and can mine any open-sourced GIT repository. Clone Swarm internally uses NiCad, a popular clone detection\u00a0\u2026", "num_citations": "4\n", "authors": ["979"]}
{"title": "On the Use of Machine Learning Techniques Towards the Design of Cloud Based Automatic Code Clone Validation Tools\n", "abstract": " A code clone is a pair of code fragments, within or between software systems that are similar. Since code clones often negatively impact the maintainability of a software system, a great many numbers of code clone detection techniques and tools have been proposed and studied over the last decade. To detect all possible similar source code patterns in general, the clone detection tools work on syntax level (such as texts, tokens, AST and so on) while lacking user-specific preferences. This often means the reported clones must be manually validated prior to any analysis in order to filter out the true positive clones from task or user-specific considerations. This manual clone validation effort is very time-consuming and often error-prone, in particular for large-scale clone detection. In this paper, we propose a machine learning based approach for automating the validation process. In an experiment with clones detected\u00a0\u2026", "num_citations": "4\n", "authors": ["979"]}
{"title": "Fast, scalable and user-guided clone detection\n", "abstract": " Despite the great number of clone detection approaches proposed in the literature, few have the scalability and speed to analyze large inter-project source datasets, where clone detection has many potential applications. Furthermore, because of the many uses of clone detection, an approach is needed that can adapt to the needs of the user to detect any kind of clone. We propose a clone detection approach designed for user-guided clone detection by exploiting the power of source transformation in a plugin based source processing pipeline. Clones are detected using a simple Jaccard-based clone similarity metric, and users customize the representation of their source code as sets of terms to target particular types or kinds of clones. Fast and scalable clone detection is achieved with indexing, sub-block filtering and input partitioning.", "num_citations": "4\n", "authors": ["979"]}
{"title": "Is code cloning in games really different?\n", "abstract": " Since there are a tremendous number of similar functionalities related to images, 3D graphics, sounds, and script in games software, there is a common wisdom that there might be more cloned code in games compared to traditional software. Also, there might be more cloned code across games since many of these games share similar strategies and libraries. In this study, we attempt to investigate whether such statements are true by conducting a large empirical study using 32 games and 9 non-games software, written in three different programming languages C, Java, and C#, for the case of both exact and near-miss clones. Using a hybrid clone detection tool NiCad and a visualization tool VisCad, we examine and compare the cloning status in them and compare it to the non-games, and examine the cloned methods across game engines. The results show that code reuse in open source games is much different\u00a0\u2026", "num_citations": "4\n", "authors": ["979"]}
{"title": "How should we read and analyze bug reports: an interactive visualization using extractive summaries and topic evolution\n", "abstract": " Software projects evolve over time as bugs are addressed and new functionalities are added. Managing bugs can be a significant challenge for a project manager especially when the number of reported bugs is large, and the manager needs to consult with them. It is also preferable that developers new to a project first familiarize themselves with the project and the reported bugs before actually working on them. In order to reduce developers\u2019 time and efforts for reading a bug report, in this paper, we propose a visualization technique that provides an extractive summary visualization for a given bug report. In addition, our proposed technique assists the developers or managers in reviewing a project\u2019s bug reports by interactively visualizing insightful information using topic analysis on the bug reports. In order to validate the effectiveness of our proposed visualization technique, we conducted a task-oriented user study involving six participants and a case study using 3914 bug reports. The findings from both studies show that our visualization technique is promising, and it can assist the comprehension and analysis of bug reports. The results from the user study indicate that visualized summary is relatively preferred to the non-visualized summary for quick comprehension of bug reports.", "num_citations": "4\n", "authors": ["979"]}
{"title": "Bigclonebench\n", "abstract": " Many clone detection tools and techniques have been created to tackle various use-cases, including syntactical clone detection, semantic clone detection, inter-project clone detection, large-scale clone detection and search, and so on. While a few clone benchmarks are available, none target this breadth of usage. BigCloneBench is a clone benchmark designed to evaluate clone detection tools across a variety of use-cases. It was built by mining a large inter-project source repository for functions implementing known functionalities. This produced a large benchmark of inter-project and intra-project semantic clones across the full spectrum of syntactical similarity. The benchmark is augmented with an evaluation framework named BigCloneEval which simplifies tool evaluation studies and allows the user to slice the benchmark based on the clone properties in order to evaluate for a particular use-case. We\u00a0\u2026", "num_citations": "3\n", "authors": ["979"]}
{"title": "Mussel\u2010Inspired Adhesive Nano\u2010Filler for Strengthening Polyacrylamide Hydrogel\n", "abstract": " Hydrogels are emerging as one of the most attractive watercontaining polymeric materials for many biomedical and industrial engineering applications. Cellulose nanocrystals (CNC) are often used as filler material to overcome the drawbacks of conventional hydrogels. However, weak frictional interaction of CNC with the polymeric backbone of hydrogels in the presence of water has limited its applications. Herein, we report a mussel-inspired preparation of a new bio-based nanofiller by grafting dopamine (DOPA) over the carboxylated cellulose nanocrystal (CCN), which has been obtained by oxidizing CNC extracted from sawdust. The swelling of polyacrylamide (PAM) hydrogels has been significantly suppressed by the incorporation of the modified filler. In contrast, the mechanical properties like Young\u2019s modulus, tensile strength, and toughness of PAM hydrogels increased remarkably indicating a strong interaction of CNC-DOPA with the PAM chains. For instance, the tensile strength increased from 19 kPa for the CNC-PAM to 39 kPa for the CCN-DOPA-PAM. Interestingly, insertion of only 1%(w/w) CCN-DOPA has led to the enhancement of the mechanical strength of PAM even more than that caused by the insertion of 4% pristine CNC. The spectroscopic data along with the morphological analysis of the composite hydrogels suggest strong hydrogen bonding of DOPA moiety and the PAM backbone is responsible for this incredible improvement of the mechanical strength.", "num_citations": "3\n", "authors": ["979"]}
{"title": "Efficiently Measuring an Accurate and Generalized Clone Detection Precision using Clone Clustering.\n", "abstract": " An important measure of clone detection performance is precision. However, there has been a marked lack of research into methods of efficiently and accurately measuring the precision of a clone detection tool. Instead, tool authors simply validate a small random sample of the clones their tools detected in a subject software system. Since there could be many thousands of clones reported by the tool, such a small random sample cannot guarantee an accurate and generalized measure of the tool\u2019s precision for all the varieties of clones that can occur in any arbitrary software system. In this paper, we propose a machine-learning based approach that can cluster similar clones together, and which can be used to maximize the variety of clones examined when measuring precision, while significantly reducing the biases a specific subject system has on the generality of the precision measured. Our technique reduces the efforts in measuring precision, while doubling the variety of clones validated and reducing biases that harm the generality of the measure by up to an order of magnitude. Our case study with the NiCad clone detector and the Java class library shows that our approach is effective in efficiently measuring an accurate and generalized precision of a subject clone detection tool.", "num_citations": "3\n", "authors": ["979"]}
{"title": "A case study on frequency reuse in OFDMA systems using hierarchical radio resource management\n", "abstract": " This paper presents a case study on the frequency reuse using hierarchical radio resource management (HRRM) in an OFDMA system. In this HRRM, an access point controller is developed to dynamically assign subchannels to the access points (APs) on the basis of interference measurements and traffic situation, and the APs allocate resource elements to the mobile terminals (MTs) using an OFDMA scheduler. Using this HRRM we focus on the effect of frequency reuse in the considered system. Three types of reuse constraints with different scaling of distances between the APs are used to analyze frequency reuse effect.", "num_citations": "3\n", "authors": ["979"]}
{"title": "Early Detection and Guidelines to Improve Unanswered Questions on Stack Overflow\n", "abstract": " Stack Overflow is one of the largest and most popular question-answering (Q&A) websites. It accumulates millions of programming related questions and answers to support the developers in software development. Unfortunately, a large number of questions are not answered at all, which might hurt the quality or purpose of this community-oriented knowledge base. Up to 29% of Stack Overflow questions do not have any answers. There have been existing attempts in detecting the unanswered questions. Unfortunately, they primarily rely on the question attributes (eg, score, view count) that are not available during the submission of a question. Detection of the potentially unanswered questions in advance during question submission could help one improve the question and thus receive the answers in time. In this paper, we compare unanswered and answered questions quantitatively and qualitatively by analyzing\u00a0\u2026", "num_citations": "2\n", "authors": ["979"]}
{"title": "A machine learning based framework for code clone validation\n", "abstract": " A code clone is a pair of code fragments, within or between software systems that are similar. Since code clones often negatively impact the maintainability of a software system, several code clone detection techniques and tools have been proposed and studied over the last decade. However, the clone detection tools are not always perfect and their clone detection reports often contain a number of false positives or irrelevant clones from specific project management or user perspective. To detect all possible similar source code patterns in general, the clone detection tools work on the syntax level while lacking user-specific preferences. This often means the clones must be manually inspected before analysis in order to remove those false positives from consideration. This manual clone validation effort is very time-consuming and often error-prone, in particular for large-scale clone detection. In this paper, we\u00a0\u2026", "num_citations": "2\n", "authors": ["979"]}
{"title": "Micro-level modularity of computaion-intensive programs in big data platforms: A case study with image data\n", "abstract": " With the rapid advancement of Big Data platforms such as Hadoop, Spark, and Dataflow, many tools are being developed that are intended to provide end users with an interactive environment for large-scale data analysis (e.g., IQmulus). However, there are challenges using these platforms. For example, developers find it difficult to use these platforms when developing interactive and reusable data analytic tools. One approach to better support interactivity and reusability is the use of microlevel modularisation for computation-intensive tasks, which splits data operations into independent, composable modules. However, modularizing data and computation-intensive tasks into independent components differs from traditional programming, e.g., when accessing large scale data, controlling data-flow among components, and structuring computation logic. In this paper, we present a case study on modularizing real world computationintensive tasks that investigates the impact of modularization on processing large scale image data. To that end, we synthesize image data-processing patterns and propose a unified modular model for the effective implementation of computation-intensive tasks on data-parallel frameworks considering reproducibility, reusability, and customization. We present various insights of using the modularity model based on our experimental results from running image processing tasks on Spark and Hadoop clusters.", "num_citations": "2\n", "authors": ["979"]}
{"title": "Adventures in NICAD: a ten-year retrospective\n", "abstract": " Based on the simple, naive idea of text-line differencing of pretty-printed code, at ICPC 2008 we introduced NICAD, the first code clone detector explicitly aimed at finding intentional \"near-miss\" (Type 3) clones. Using the TXL parser to identify and pretty-print all instances of a code unit of interest (functions, blocks, etc.), NICAD provides several ways to pre-process the code before comparison, including flexible formatting, renaming, normalization and abstraction, making it suitable for finding all kinds of clones in a wide range of different applications. In this talk we will outline the journey from that initial naive idea to an efficient, scalable, flexible clone detection tool that handles more than ten different languages with high accuracy in both precision and recall. Along the way we will highlight our experience in tuning our initial prototype to production speed and scalability, we will review its application in a range of large\u00a0\u2026", "num_citations": "2\n", "authors": ["979"]}
{"title": "Modelling programming languages for concurrent and distributed systems in specification languages\n", "abstract": " In this thesis work, a contribution to the field of Formal Verification is presented innovating a semantic-based approach for the verification of concurrent and distributed programs by applying model checking methods. Erlang is a declarative functional language for programming concurrent and distributed systems on which this thesis is aimed to employ the model checking methods. In contrast to the conventional approach of directly applying this verification technique to Erlang language, this thesis adopts the possibility of exploiting benefits from existing works by translating an Erlang program to a system model of the specification language \u03c0calculus for which analysis and verification techniques have already been well established and there are existing tools for model checking \u03c0-calculus systems.", "num_citations": "2\n", "authors": ["979"]}
{"title": "Self-Doped Activated Carbons from Car Exhaust as High-Performance Supercapacitor Electrode Materials for Sustainable Energy Storage System\n", "abstract": " Hydrocarbon based waste materials are emerging as an attractive source of generating activated carbons (ACs), having excellent potential for enormous in-field applications. In this study, it has been demonstrated that the carbon materials collected from the diesel engine exhaust could be a new source for preparing self-doped highly porous AC for high-performance supercapacitor applications. As the diesel engine exhaust carbon (DEEC) itself contains a large number of heteroatoms (O, N, S, and P), simple acid treatment (HCl) of DEEC resulted in a self-doped AC (SDAC_HCl) having contained a high level of heteroatoms as the dopant in it and consequently provided with a large specific surface area of 89 m 2 g\u2212 1. The pyrolytic treatment of DEEC with KOH further resulted in self-doped AC (SDAC_KOH) with an enhanced specific surface area of 549 m 2 g\u2212 1 due to the increase in porosity of AC. The\u00a0\u2026", "num_citations": "1\n", "authors": ["979"]}
{"title": "Graphene oxide crosslinker for the enhancement of mechanical properties of polylactic acid\n", "abstract": " Polylactic acid (PLA) biopolymer appears to provide environmental advantages over the petroleum\u2010derived polymers but often ends up with limited applications owing to their poor mechanical performance and brittleness. Herein, we present a PLA polymer compatible graphene oxide (GO) based crosslinker with the intention of improving the mechanical properties. Lactic acid (LA) functionalized GO (GO\u2010LA) crosslinker was prepared and had been crosslinked with the PLA chains through a one\u2010step polycondensation reaction. The mechanical properties of the as\u2010synthesized GO crosslinked PLA (GO\u2010C\u2010PLA) were investigated by compression tests and compared with neat PLA, and GO reinforced PLA (GO\u2010PLA) with no crosslinking. With 0.3% of GO\u2010LA crosslinker in GO\u2010C\u2010PLA, the compressive modulus increased by nine times compared to that of the neat PLA. The compressive strength also increased to 46\u00a0\u2026", "num_citations": "1\n", "authors": ["979"]}
{"title": "Development of functionalized nanocrystalline cellulose-based polyelectrolytes with high water uptake\n", "abstract": " Dicarboxylate nanocrystalline cellulose (DCNC) polyelectrolytes were prepared from nanocrystalline cellulose (NCC) by introducing carboxylate units at the C-2 and C-3 positions of a glucose moiety through a two-step selective oxidation process. The polyelectrolyte nature of the DCNC was investigated by measuring the water uptake capacity with a customized ion exchange system. The equilibrium water uptake capacity of DCNC was almost ten times greater than that of conventional C-6 functionalized monocarboxylated NCC. The conversion of NCC to DCNC ensured the presence of a large number of dissociable electrolytic ions and high degrees of conformational freedom in the material to generate high osmotic pressure. Conductivity and dynamic light-scattering measurements were performed to relate the water uptake capacity with the chemical and structural changes of the polyelectrolytes. Furthermore, it\u00a0\u2026", "num_citations": "1\n", "authors": ["979"]}
{"title": "Role of Ionic Moieties in Hydrogel Networks to Remove Heavy Metal Ions from Water\n", "abstract": " A variety of methods for removing heavy metal ions from wastewater have been developed but because of their low efficiency, further production of toxic sludge or other waste materials, high expense, and lengthy procedures, limited progress has been achieved to date. Polymeric hydrogel has been attracting particular attention for the effective removal of heavy metal ions from wastewater. Here, ionogenic polymeric hydrogels were prepared by free-radical copolymerization of a neutral acrylamide (AAm) monomer with an ionic comonomer in the presence of a suitable initiator and a cross-linker. Different types of ionic comonomers such as strongly acidic: 2-acrylamido-2-methylpropane sulfonic acid, weakly acidic: acrylic acid (AAc), and zwitterionic: 2-methacryloyloxy ethyl dimethyl-3-sulfopropyl ammonium hydroxide with varying amounts were incorporated into the poly(AAm) networks to fabricate the hydrogels\u00a0\u2026", "num_citations": "1\n", "authors": ["979"]}
{"title": "One-Step Gel Formation Method for the Synthesis of NiO-MnXOY Mixed Oxide Nanomaterials as a Prospective Supercapacitor Material\n", "abstract": " Composites of transition metal oxides are very well known for their excellent electrochemical performance. Herein, we have reported the preparation of a nano-architectured mixed metal oxide of NiO-Mn X O Y  by using simple gel formation method towards high-performance electrochemical supercapacitor. The surface morphology of the mixed oxides was investigated by scanning electron microscope (SEM) and was found to be in nano-dimension with capsule shape. The X-ray diffraction (XRD) pattern demonstrated the highly crystalline structure of the mixed oxides. The quasi-rectangular CV curves of NiO-Mn X O Y  in between (-0.4 to + 0.3 V) indicated almost ideal double-layer capacitive properties of the prepared material. However, the slightly distorted symmetrical triangular GCD confirmed the contribution of both electric double layer capacitance (EDLC), and pseudo capacitance over the total capacitance\u00a0\u2026", "num_citations": "1\n", "authors": ["979"]}
{"title": "Fine-grained attribute level locking scheme for collaborative scientific workflow development\n", "abstract": " Scientific Workflow Management Systems are being widely used in recent years for data-intensive analysis tasks or domain-specific discoveries. It often becomes challenging for an individual to effectively analyze the large scale scientific data of relatively higher complexity and dimensions, and requires a collaboration of multiple members of different disciplines. Hence, researchers have focused on designing collaborative workflow management systems. However, consistency management in the face of conflicting concurrent operations of the collaborators is a major challenge in such systems. In this paper, we propose a locking scheme (e.g., collaborator gets write access to non-conflicting components of the workflow at a given time) to facilitate consistency management in collaborative scientific workflow management systems. The proposed method allows locking workflow components at a granular level in\u00a0\u2026", "num_citations": "1\n", "authors": ["979"]}
{"title": "Interference aware dynamic subchannel allocation in a multi-cellular OFDMA system based on traffic situation\n", "abstract": " This paper presents the development and evaluation of a dynamic subchannel allocation scheme for downlink multi-cellular Orthogonal Frequency Division Multiple Access (OFDMA) systems. In the considered system each Access Point (AP) and the associated Mobile Terminals (MTs) are not operating on a frequency channel with a fixed bandwidth, rather the channel bandwidth for each AP is dynamically adapted according to the traffic load. The subchannels assignment procedure is based on quality estimations due to the interference measurements and the current traffic load. The developed dynamic subchannel allocation ensures Quality of Service (QoS), better traffic adaptability and higher spectrum efficiency with less computational complexity.", "num_citations": "1\n", "authors": ["979"]}