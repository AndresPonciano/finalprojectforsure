{"title": "A multi-objective technique to prioritize test cases\n", "abstract": " While performing regression testing, an appropriate choice for test case ordering allows the tester to early discover faults in source code. To this end, test case prioritization techniques can be used. Several existing test case prioritization techniques leave out the execution cost of test cases and exploit a single objective function (e.g., code or requirements coverage). In this paper, we present a multi-objective test case prioritization technique that determines the ordering of test cases that maximize the number of discovered faults that are both technical and business critical. In other words, our new technique aims at both early discovering faults and reducing the execution cost of test cases. To this end, we automatically recover links among software artifacts (i.e., requirements specifications, test cases, and source code) and apply a metric-based approach to automatically identify critical and fault-prone portions of\u00a0\u2026", "num_citations": "56\n", "authors": ["554"]}
{"title": "Managing risk in open source software adoption\n", "abstract": " By 2016 an estimated 95% of all commercial software packages will include Open Source Software (OSS). This extended adoption is yet not avoiding failure rates in OSS projects to be as high as 50%. Inadequate risk management has been identified among the top mistakes to avoid when implementing OSS-based solutions. Understanding, managing and mitigating OSS adoption risks is therefore crucial to avoid potentially significant adverse impact on the business. In this position paper we portray a short report of work in progress on risk management in OSS adoption processes. We present a risk-aware technical decision-making management platform integrated in a business-oriented decision-making framework, which together support placing technical OSS adoption decisions into organizational, business strategy as well as the broader OSS community context. The platform will be validated against a collection of use cases coming from different types of organizations: big companies, SMEs, public administration, consolidated OSS communities and emergent small OSS products.", "num_citations": "52\n", "authors": ["554"]}
{"title": "A constraint-based architecture for flexible support to activity scheduling\n", "abstract": " The O-OSCAR software architecture is a problem solving environment for complex scheduling problem that is based on a constraintbasedrep resentation. On top of this core representation a problem solver module and a schedule execution system guarantee a complete support to address a scheduling problem. Furthermore, a rather sophisticated interaction module allows users to maintain control on different phases of schedule management.", "num_citations": "46\n", "authors": ["554"]}
{"title": "A multi-objective technique to prioritize test cases based on latent semantic indexing\n", "abstract": " To early discover faults in source code, test case ordering has to be properly chosen. To this aim test prioritization techniques can be used. Several of these techniques leave out the execution cost of test cases and exploit a single objective function (e.g., code or requirements coverage). In this paper, we present a multi-objective test prioritization technique that determines sequences of test cases that maximize the number of discovered faults that are both technical and business critical. The technique uses the information related to the code and requirements coverage, as well as the execution cost of each test case. The approach also uses recovered trace ability links among source code and system requirements via the Latent Semantic Indexing technique. We evaluated our proposal against both a random prioritization technique and two single-objective prioritization techniques on two Java applications. The\u00a0\u2026", "num_citations": "44\n", "authors": ["554"]}
{"title": "Formalizing requirements with object models and temporal constraints\n", "abstract": " Flaws in requirements often have a negative impact on the subsequent development phases. In this paper, we present a novel approach for the formal representation and validation of requirements, which we used in an industrial project. The formalism allows us to represent and reason about object models and their temporal evolution. The key ingredients are class diagrams to represent classes of objects, their relationships and their attributes, fragments of first order logic to constrain the possible configurations of such objects, and temporal logic operators to deal with the dynamic evolution of the configurations. The approach to formal validation allows to check whether the requirements are consistent, if they are compatible with some scenarios, and if they guarantee some implicit properties. The validation procedure is based on satisfiability checking, which is carried out by means of finite instantiation and\u00a0\u2026", "num_citations": "29\n", "authors": ["554"]}
{"title": "Modelling risks in open source software component selection\n", "abstract": " Adopting Open Source Software (OSS) components is a decision that offers many potential advantages \u2013 such as cost effectiveness and reputation \u2013 but even introduces a potentially high number of risks, which span from the inability of the OSS community to continue the development over time, to a poor quality of code. Differently from commercial off-the-shelf components, to assess risk in OSS component adoption, we can rely on the public availability of measurable information about the component code and the developing communities. In the present paper, we present a risk evaluation technique that uses conceptual modelling to assess OSS component adoption risks. We root it in the existing literature on OSS risk assessment and validate it by means of our industrial partners.", "num_citations": "24\n", "authors": ["554"]}
{"title": "Case-based ranking for decision support systems\n", "abstract": " Very often a planning problem can be formulated as a ranking problem: i.e. to find an order relation over a set of alternatives. The ranking of a finite set of alternatives can be designed as a preference elicitation problem. While the casebased preference elicitation approach is more effective with respect to the first principle methods, still the scaling problem remains an open issue because the elicitation effort has a quadratic relation with the number of alternative cases. In this paper we propose a solution based on the machine learning techniques. We illustrate how a boosting algorithm can effectively estimate pairwise preferences and reduce the effort of the elicitation process. Experimental results, both on artificial data and a realworld problem in the domain of civil defence, showed that a good trade-off can be achieved between the accuracy of the estimated preferences, and the elicitation effort of the end user.", "num_citations": "24\n", "authors": ["554"]}
{"title": "O-Oscar: A flexible object-oriented architecture for schedule management in space applications\n", "abstract": " 6 ConclusionsThis Iaper ha~ described the main aspects of 0OSCAR a scheduling architecture for plan production and management. Two different systems relative to different space applicatiosn have been successfully developed with it. Interesting features of 0OSCAR are the complete approach to the scheduling", "num_citations": "18\n", "authors": ["554"]}
{"title": "Collaborative radio community\n", "abstract": " Recommender systems have been usually designed to support a single user in a one-to-one relation between a human and a service provider. This paper presents a collaborative radio community where the system delivers a personalization service on the fly, on the basis of the group recommending, promoting a shift from the one-to-one approach to a one-to-group scenario where the goal is assisting people in forming communities.", "num_citations": "17\n", "authors": ["554"]}
{"title": "Combining code and requirements coverage with execution cost for test suite reduction\n", "abstract": " Test suites tend to become large and complex after software evolution iterations, thus increasing effort and cost to execute regression testing. In this context, test suite reduction approaches could be applied to identify subsets of original test suites that preserve the capability of satisfying testing requirements and revealing faults. In this paper, we propose Multi-Objective test suites REduction (named MORE+): a three-dimension approach for test suite reduction. The first dimension is the structural one and concerns the information on how test cases in a suite exercise the under-test application. The second dimension is functional and concerns how test cases exercise business application requirements. The third dimension is the cost and concerns the time to execute test cases. We define MORE+ as a multi-objective approach that reduces test suites so maximizing their capability in revealing faults according to the\u00a0\u2026", "num_citations": "14\n", "authors": ["554"]}
{"title": "Adoption of free libre open source software (floss): A risk management perspective\n", "abstract": " Free Libre Open Source Software (FLOSS) has become a strategic asset in software development, and open source communities behind FLOSS are a key player in the field. The analysis of open source community dynamics is a key capability in risk management practices focused on the integration of FLOSS in all types of organizations. We are conducting research in developing methodologies for managing risks of FLOSS adoption and deployment in various application domains. This paper is about the ability to systematically capture, filter, analyze, reason about, and build theories upon, the behavior of an open source community in combination with the structured elicitation of expert opinions on potential organizational business risk. The novel methodology presented here blends together qualitative and quantitative information as part of a wider analytics platform. The approach combines big data analytics with\u00a0\u2026", "num_citations": "14\n", "authors": ["554"]}
{"title": "Design as intercultural dialogue: coupling human-centered design with requirement engineering methods\n", "abstract": " In the design of information technologies, the challenge of integrating a human-centered design approach with software engineering methods emerge in different forms. The main challenge is to set the ground for different disciplines and professional cultures communicate and work together. The orchestration of different contributions and the establishment of communication practices that facilitates the integration of the different languages and procedures are crucial steps to take full advantage of different research traditions. This paper presents a case study in which human-centered design and requirement engineering methodologies have been used within a large research projects aiming at developing innovative technologies and services to support professionals in nursing homes. The design process took the form of an intercultural dialogue that required human-centered and requirement-engineering\u00a0\u2026", "num_citations": "12\n", "authors": ["554"]}
{"title": "Risk awareness in open source component selection\n", "abstract": " Adopting Open Source Software (OSS) components offers many potential advantages \u2013 such as cost effectiveness and increased reputation \u2013 but also introduces a variety of new risks related to the intrinsic fluidity of the OSS development projects. In this paper, we present results of a systematic literature review on OSS adoption risks, which allows to relate them to available OSS measures. Relying on the results of the review, we also present a risk-aware selection process, which uses OSS measures to rank OSS project according to the adopter\u2019s criteria, improving the quality of the OSS component selection.", "num_citations": "11\n", "authors": ["554"]}
{"title": "MOTCP: A tool for the prioritization of test cases based on a sorting genetic algorithm and Latent Semantic Indexing\n", "abstract": " Test prioritization techniques can be used to determine test case ordering and early discover faults in source code. Several of these techniques exploit a single objective function, e.g., code or requirements coverage. In this tool demo paper, we present MOTCP, a software tool that implements a multi-objective test prioritization technique based on the information related to the code and requirements coverage, as well as the execution cost of each test case. To establish users' and system requirements coverage, the MOTCP uses Latent Semantic Indexing to recover traceability links among application source code and requirements specifications. The test case ordering is then obtained by applying a non-dominated sorting genetic algorithm.", "num_citations": "11\n", "authors": ["554"]}
{"title": "Aligning business goals and risks in oss adoption\n", "abstract": " Increasing adoption of Open Source Software (OSS) requires a change in the organizational culture and reshaping IT decision-makers mindset. Adopting OSS software components introduces some risks that can affect the adopter organization\u2019s business goals, therefore they need to be considered. To assess these risks, it is required to understand the socio-technical structures that interrelate the stakeholders in the OSS ecosystem, and how these structures may propagate the potential risks to them. In this paper, we study the connection between OSS adoption risks and OSS adopter organizations\u2019 business goals. We propose a model-based approach and analysis framework that combines two existing frameworks: the i* framework to model and reason about business goals, and the RiskML notation to represent and analyse OSS adoption risks. We illustrate our approach with data drawn from an\u00a0\u2026", "num_citations": "9\n", "authors": ["554"]}
{"title": "The RISCOSS platform for risk management in open source software adoption\n", "abstract": " Managing risks related to OSS adoption is a must for organizations that need to smoothly integrate OSS-related practices in their development processes. Adequate tool support may pave the road to effective risk management and ensure the sustainability of such activity. In this paper, we present the RISCOSS platform for managing risks in OSS adoption. RISCOSS builds upon a highly configurable data model that allows customization to several types of scopes. It implements two different working modes: exploration, where the impact of decisions may be assessed before making them; and continuous assessment, where risk variables (and their possible consequences on business goals) are continuously monitored and reported to decision-makers. The blackboard-oriented architecture of the platform defines several interfaces for the identified techniques, allowing new techniques to be plugged in.", "num_citations": "9\n", "authors": ["554"]}
{"title": "A multi-objective technique for test suite reduction\n", "abstract": " Entire test suites are often used to conduct regres-sion testing on subject applications even after limited and precise changes performed during maintenance operations. Often, this practice makes regression testing difficult and costly. To deal with these issues, techniques to reduce test suites have been proposed and adopted. In this paper, we present a multi-objective technique for test suite reduction. It uses information related to the code and requirements coverage, the past execution cost of each test case in the test suite, and traceability link among software artifacts. We evaluated our proposal by testing three Java applications and comparing the achieved results with those of some baseline techniques. The results indicate that our proposal outperforms the baselines and that improvements are still possible.", "num_citations": "9\n", "authors": ["554"]}
{"title": "Maintainability-based requirements prioritization by using artifacts traceability and code metrics\n", "abstract": " Requirements prioritization is a fundamental activity during software system maintenance. Prioritize requirements, in fact, means to determine the ordering in which requirements have to be considered in a given planning or maintenance activity. Most of the existing requirements prioritization techniques and tools focus on user and non/functional requirements, while only few attempt exists to consider how requirements are actually implemented, if they are implemented. In this demonstration paper, we present a tool that prioritizes (change) requirements by using artifacts traceability information, to locate the requirements implementation, and a set of code-based metrics, to measure several properties (e.g., coupling, size, scattering) of the requirements implementation. The tool, hence, determines the requirement ordering with respect to how these requirements are implemented in a subject software system.", "num_citations": "9\n", "authors": ["554"]}
{"title": "Gathering requirements for software configuration from the crowd\n", "abstract": " Today's complex software systems consist of several components that interact in complex ways to provide services to users. In doing so, these systems go through continuous assessment of their context and configure themselves accordingly to keep user satisfaction high. A popular approach to design adaptive software systems is to perform variability modelling, for instance adopting a feature-based approach. Features describe key components and characteristics of a system, which can take different values and be combined in different ways to obtain a system behavior that can best satisfy the needs of different users, who may use the software in different contexts. These design-time models should be complemented by rules that help in deciding when to switch from one valid system configuration to a different one to fit changing user needs or preferences. Eliciting information necessary to build suitable feature\u00a0\u2026", "num_citations": "8\n", "authors": ["554"]}
{"title": "Ahab\u2019s leg: Exploring the issues of communicating semi-formal requirements to the final users\n", "abstract": " In this paper, we present our experience in using narrative scenarios as a tool to communicate and validate semi-formal requirements with the stakeholders in a large software project. The process of translating the semi-formal language of Tropos into the narrative form of scenarios is introduced and some unintended implications of this process are discussed. In particular, we define the notion of Ahab\u2019s leg to describe the necessity to introduce new constraints or features in a description when moving to a different representational language. Starting from the lessons learned with this specific case study, we derive some general implications concerning the issue of requirement translation for validation tasks and we propose some methodological guidelines to address the Ahab\u2019s leg dilemma.", "num_citations": "8\n", "authors": ["554"]}
{"title": "Modeling and Analysis of Laws using BPR and Goal-oriented framework\n", "abstract": " Recently, two complementary approaches are proposed to represent, model, and analyze laws: the Nomos and VLPM approaches. Nomos is a goal-oriented approach to effectively capture high-level principles in terms of goal realization for requirements guided by satisfiability of normative propositions obtained from rules embedded in a law. The latter offers a tool supported (re-)engineering methodology to extract laws represented in XML and build models using a subset of UML diagrams. Both allow traceability between laws and their respective models. This paper proposes an integration of these two approaches. We believe that this provides a framework that allows to trace and reason either top-down, from principles to their implementation or, viceversa, bottom-up, from a change in the procedure to the principles. It is exactly this connection that adds value to the solution we propose and makes our approach\u00a0\u2026", "num_citations": "8\n", "authors": ["554"]}
{"title": "Ahab\u2019s legs in scenario-based requirements validation: An experiment to study communication mistakes\n", "abstract": " The correct identification of requirements is a crucial step for the implementation of a satisfactory software system. In the validation of requirements with scenarios, a straightforward communication is central to obtain a good participation from stakeholders. Technical specifications are translated into scenarios to make them concrete and easy to understand for non-technical users, and contextual details are added to encourage user engagement.However, additional contextual details (Ahab\u2019s legs) could generate a negative impact on the requirements\u2019 validation by leading to proliferating comments that are not pertinent to session objective. The objective of this study is to evaluate the impact of Ahab\u2019s leg to scenario-based requirement validation sessions. We conducted a controlled experiment with human participants and measured the pertinence of the comments formulated by participants when discussing the\u00a0\u2026", "num_citations": "7\n", "authors": ["554"]}
{"title": "Using genetic algorithms to search for key stakeholders in large-scale software projects\n", "abstract": " Large software projects have many stakeholders. In order for the resulting software system and architecture to be aligned with the enterprise and stakeholder needs, key stakeholders must be adequately consulted and involved in the project. This work proposes the use of genetic algorithms to identify key stakeholders and their actual influence in requirements elicitation, given the stakeholders\u2019 requirements and the actual set of requirements implemented in the project. The proposed method is applied to a large real-world software project. Results show that search is able to identify key stakeholders accurately. Results also indicate that many different good solutions exist. This implies that a stakeholder has the potential to play a key role in requirements elicitation, depending on which other stakeholders are already involved. This work demonstrates the true complexity of requirements elicitation\u2013all stakeholders\u00a0\u2026", "num_citations": "7\n", "authors": ["554"]}
{"title": "reBPMN: Recovering and reducing business processes\n", "abstract": " Specification models recovered from existing software applications can support developers in comprehending and checking the applications during maintenance and evolution operations. Often, in fact, a huge amount of business knowledge is embedded in the application implementation while documentation is not available or not aligned with the actual software implementation. In order to (re)acquire and preserve the business knowledge, specifications recovery techniques are adopted. In this paper we present reBPMN, a tool that recovers business process models from execution traces of target applications. It recovers the process exposed by means of Web interfaces and it applies a multi-objective process reduction technique, which minimizes at the same time process complexity, non-conformances, and loss of business content. This allows us to obtain processes having high readability by decreasing their\u00a0\u2026", "num_citations": "7\n", "authors": ["554"]}
{"title": "Establishing information system compliance: An argumentation-based framework\n", "abstract": " This paper introduces a mixed modeling and argumentation framework applied to assess the compliance of requirements with legal norms, and reports the results of its application in an industrial project in healthcare. Domain experts applied a goal-oriented modeling framework for the representation of requirements and norms, then used argumentation techniques to assess the compliance of requirements with norms, and revise requirements model to ensure compliance.", "num_citations": "7\n", "authors": ["554"]}
{"title": "TimeNetManager\u2014A software tool for generating random temporal networks\n", "abstract": " This paper describes a system, named TimeNetManager or TNM, that generates and manipulates random constraint networks corresponding to the so called Simple Temporal Problem (STP). The soft-ware tool satisfies both the requirements to build some common bench-marks useful to compare different research results, and to create a tool for supporting intensive test of new algorithms for temporal constraints management. The paper gives an overview of the functionalities of the software system and describes in detail the random generator able to fast generate sets of temporal networks controlled by a set of macro-parameters that characterize the topology and the temporal flexibility of the networks.", "num_citations": "7\n", "authors": ["554"]}
{"title": "Community data for OSS adoption risk management\n", "abstract": " Open source software (OSS) has increasingly played a leading role in current information technology practices. Its pervasive adoption is not without risks for an industry that has experienced significant failures in product quality, timelines and delivery costs. Inadequate risk management has been identified among the top deficiencies when implementing OSS-based solutions. A crucial aspect in managing and mitigating OSS adoption risks is that of deeply understanding the behavior and dynamics of the OSS communities that provide the software components. This can be achieved via the analysis of big amounts of data related, for example, to community activeness, reliability, or capacity of managing the OSS component maintenance and evolution. The objective of this chapter is to present a risk management method and platform for managing OSS risks. Our approach integrates different data sources that represent\u00a0\u2026", "num_citations": "6\n", "authors": ["554"]}
{"title": "Expert finding using markov networks in open source communities\n", "abstract": " Expert finding aims at identifying knowledgeable people to help in decision processes, such as eliciting or analysing requirements in Requirements Engineering. Complementary approaches exist to tackle specific contexts like in forum-based communities, exploiting personal contributions, or in structured organisations like companies, where the social relationships between employees help to identify experts. In this paper, we propose an approach to tackle a hybrid context like an Open Source Software (OSS) community, which involves forums open to contributors, as well as companies providing OSS-related services. By representing and relating stakeholders, their roles, the topics discussed and the terms used, and by applying inference algorithms based on Markov networks, we are able to rank stakeholders by their inferred level of expertise in one topic or more. Two preliminary experiments are\u00a0\u2026", "num_citations": "6\n", "authors": ["554"]}
{"title": "A goal-oriented approach for representing and using design patterns\n", "abstract": " Design patterns are known as proven solutions to recurring design problems. The role of pattern documentation format is to transfer experience thus making pattern employment a viable technique. This research line proposes a goal-oriented pattern documentation that highlights decision-relevant information. The contribution of this paper is twofold. First, it presents a semi-structural visual notation that visualizes context, forces, alternative solutions and consequences in a compact format. Second, it introduces a systematic reuse process, in which the use of goal-oriented patterns aids the practitioner in selecting and customizing design patterns. An empirical study has been conducted the results of which supports the hypothesis that the goal-oriented format provides benefits for the practitioner. The experiment revealed a trend in which solutions better address requirements when the subjects are equipped with the\u00a0\u2026", "num_citations": "5\n", "authors": ["554"]}
{"title": "Introducing motivations in design pattern representation\n", "abstract": " Design pattern formalization is aimed at encouraging the use of design patterns during the design phase. Many approaches focuses on providing solutions with a graphical notation and complementary text, typically composed by a static and a dynamic definitions. The weak point is the lack of flexibility when customizing the generic solution to the specific context of use. This paper proposes a criterion to motivate design pattern selection and reuse. Designer is supported with a technique for balancing pattern and context forces for selecting among alternative implementations. The provided representation summarizes and organizes relevant information in the classical informal pattern documentation.", "num_citations": "5\n", "authors": ["554"]}
{"title": "Collaborative case-based preference elicitation\n", "abstract": " Preference elicitation is a well known bottleneck that prevents the acquisition of the utility function and consequently the set up of effective decision-support systems. In this paper we present a new approach to preference elicitation based on pairwise comparison. The exploitation of learning techniques allows to overcome the usual restrictions that prevent to scale up. Furthermore, we show how our approach can easily support a distributed process of preference elicitation combining both autonomy and coordination among different stakeholders. We argue that a collaborative approach to preference elicitation can be effective in dealing with non homogeneous data representations.               The presentation of the model is followed by an empirical evaluation on a real world settings. We consider a case study on environmental risk assessment to test with real users the properties of our model.", "num_citations": "5\n", "authors": ["554"]}
{"title": "A Reconfigurable Constraint-Base Architecture as a Support for Automating Mission Planning\n", "abstract": " The O-OSCAR software architecture is a problem solving environment for complex planning/scheduling problems that is based on a constraint-based representation. On top of this core representation a problem solver module and a schedule execution system guarantee a complete support to address problems with complex time and resource features. In addition, a rather sophisticated interaction module allows to develop end-to-end applications in which users maintain control on different phases of plan/schedule management. This paper gives a sketchy view of O-OSCAR and then describes how it has been used to develop a complete solution to the problem of synthesizing the dumping operations of the Solid State Mass Memory on-board of MARS EXPRESS, an ESA spacecraft that will be launched during 2003.", "num_citations": "5\n", "authors": ["554"]}
{"title": "A model-based approach to the design, verification and deployment of railway interlocking system\n", "abstract": " This paper describes a model-based flow for the development of Interlocking Systems. The flow starts from a set of specifications in Controlled Natural Language (CNL), that are close to the jargon adopted in by domain experts, but fully formal. From the CNL, a complete SysML specification is extracted, leveraging various forms of diagrams, and enabling automated code generation. Several formal verification methods are supported. A complementary part of the flow supports the extraction of formal properties from legacy Interlocking Systems designed as Relay circuits. The flow is implemented in a comprehensive toolset, and is currently used by railway experts.", "num_citations": "4\n", "authors": ["554"]}
{"title": "A layered approach to managing risks in oss projects\n", "abstract": " In this paper, we propose a layered approach to managing risks in OSS projects. We define three layers: the first one for defining risk drivers by collecting and summarising available data from different data sources, including human-provided contextual information; the second layer, for converting these risk drivers into risk indicators; the third layer for assessing how these indicators impact the business of the adopting organisation. The contributions are: 1) the complexity of gathering data is isolated in one layer using appropriate techniques, 2) the context needed to interpret this data is provided by expert involvement evaluating risk scenarios and answering questionnaires in a second layer, 3) a pattern-based approach and risk reasoning techniques to link risks to business goals is proposed in the third layer.", "num_citations": "4\n", "authors": ["554"]}
{"title": "On the use of goal-oriented methodology for designing agriculture services in developing countries\n", "abstract": " Access to agricultural information services is vital to improve the livelihood of farmers in many directions specifically in the developing countries. There are several requirements for these services most of which stem from the nature and livelihood of involved stakeholders. Though various systems have been put to use so far, most failed to integrate these stakeholders in their requirement elicitation and design strategies. This paper uses a goal-oriented approach to provide an exhaustive view on the domain from specific design ideas to abstract requirements. The approach allows us to consider alternatives when developing novel services and to balance the impact that each design space can have on functional requirements of the system to-be. The analysis and design process took a bottom-up approach that starts from field study to the use of goal-oriented approach for the analysis and designing of requirements for\u00a0\u2026", "num_citations": "4\n", "authors": ["554"]}
{"title": "Using i* to represent oss ecosystems for risk assessment\n", "abstract": " Open Source Software (OSS) is a strategic asset for organisations thanks to its short time-to-market, the opportunity for a reduced development effort and total cost of ownership, and its customization capabilities. OSS-based solutions include projects that are developed and co-evolve within the same organisation, OSS communities, companies, and regulatory bodies, forming an articulated strategic business ecosystem. The adoption of OSS in commercial projects leads to numerous challenges in the wide spectrum of available OSS solutions and risks emerging from the intrinsic structure of an OSS project. In this position paper we devise the use of i* models for understanding the strategic perspective of OSS ecosystems, representing actors, intentional dependencies and responsibilities. We argue that these models can play a crucial role in the analysis of organisational risks inherent to OSS component adoption and in the definition of risk mitigation activities.", "num_citations": "3\n", "authors": ["554"]}
{"title": "Feeding data mining\n", "abstract": " Data mining is a complex process that aims to derive an accurate predictive model starting from a collection of data. Traditional approaches assume that data are given in advance and their quality, size and structure are independent parameters. In this paper we argue that an extended vision of data mining should include the step of data acquisition as part of the overall process. Moreover the static view should be replaced by an evolving perspective that conceives the data mining as an iterative process where data acquisition and data analysis repeatedly follow each other.A decision support tool based on data mining will have to be extended accordingly. Decision making will be concerned not only with a predictive purpose but also with a policy for a next data acquisition step. A successful data acquisition strategy will have to take into account both future model accuracy and the cost associated to the acquisition of each feature. To find a trade off between these two components is an open issue. A framework to focus this new challenging problem is proposed.", "num_citations": "3\n", "authors": ["554"]}
{"title": "Quantifying the Impact of OSS Adoption Risks with the help of i* Models.\n", "abstract": " Adopting Open Source Software (OSS) components in organisational settings requires evaluating the possible impact of adoption decisions on business goals. Measures available in OSS, capturing indicators such as the quality of open source code and the activeness of the developing community, can be used as a driver to assess various risks in component adoption. In this paper we illustrate how risk and impact models are used to relate measures obtained from the component under analysis to business goals in i*-based OSS business strategy models.", "num_citations": "2\n", "authors": ["554"]}
{"title": "Exploring the Boundaries: when Method Fragmentation is not Convenient.\n", "abstract": " This paper presents an approach to explore the coupling of User-Centred Design and Tropos methodologies. The two methodologies have been employed in a real project aiming at developing smart environment for nursing home to support medical and assistance staff. In particular Tropos has been used for modeling (and reason about) the domain and the system, whereas User-Centred Design has been useful for establishing an interface for communicating with stakeholders. The integration was challenging due to the epistemological differences between the two design approaches.", "num_citations": "2\n", "authors": ["554"]}
{"title": "Case\u2013Based Ranking for Environmental Risk Assessment\n", "abstract": " The assessment of environmental risk may be conceived as a process of ranking among alternative scenarios. First principle approach tends to define in advance the general criteria of risk assessment which not necessarily discriminate a meaningful priority relation afterwards. Moreover ex-ante methods relies on the tacit assumption of data homogeneity for describing risk scenarios. In this work we propose a method for risk assessment where the process of ranking is driven by cases. Steps of pairwise case analysis for rank elicitation are interleaved with steps of computational learning to estimate the ranks for unseen cases. The case-based approach is twofold: on one hand supporting the users to elicit their knowledge by examples, on the other hand enabling an approximation of target rank looking at case descriptions. A case study of environmental risk assessment in a northern region of Italy illustrates\u00a0\u2026", "num_citations": "2\n", "authors": ["554"]}
{"title": "Risk assessment in open source systems\n", "abstract": " Adopting Open Source Software (OSS) components offers many advantages to organizations but also introduces risks related to the intrinsic fluidity of the OSS development projects. Choosing the right components is a critical decision, as it could contribute to the success of any adoption process. Making the right decision requires to evaluate the technical capabilities of the components and also related strategic aspects, including possible impacts on high level objectives. This can be achieved through a portfolio of risk assessment and mitigation methods. In this briefing we introduce the basic concepts related to OSS ecosystems and to risk representation and reasoning. We illustrate how risk management activities in OSS can benefit from the large amount of data available from OSS repositories and how they can be connected to business goals for strategic decision-making. The concepts are illustrated with a\u00a0\u2026", "num_citations": "1\n", "authors": ["554"]}
{"title": "A context-specific definition of risk for enterprise-level decision making\n", "abstract": " Enterprise-level decision making implies risk. In software companies, the choice of adopting an open source software component to be embedded into a commercial product may expose a whole business to risks arising due to this component. While general-purpose definitions of risk abound in the literature, in our work we seek an ontological definition of risk that allows us to understand how risks can relate the characteristics of a software component to the adopter's business goals. In this paper we outline the challenges faced in building this ontological definition, and sketch some  issues that are still open.", "num_citations": "1\n", "authors": ["554"]}
{"title": "Ahab's Leg dilemma: On the design of a controlled experiment\n", "abstract": " To meet stakeholder non-technical background, requirements are often presented by analysts in terms of scenarios. While translating requirements into scenarios, details and over-specifications (called Ahab's Legs) need to be added to make requirements concrete and understandable to stakeholders. Despite the expected benefits that they should convey, Ahab's Legs could disturb the requirement validation session. They can, in fact, distract the attention of stakeholders. Valuable discussion time may be wasted when focusing on irrelevant details rather than on the actually relevant ones. In the present paper, we address the Ahab's Leg dilemma and its potential impact on requirement validation sessions. We discuss how to measure the distraction due to Ahab's Legs and what are the possible approaches an analyst can adopt to limit it. Moreover, we present the design of a controlled experiment devoted to\u00a0\u2026", "num_citations": "1\n", "authors": ["554"]}
{"title": "An advanced monitoring system for residential care facilities\n", "abstract": " Objective: The objective of the ACube (Ambient Aware Assistance) project is the development and testing of an advanced monitoring system to support professional caregivers in nursing home and residential care facilities. The goal of the system is the detection of events potentially dangerous for the guest of nursing homes, or interesting for the health care professionals, and the development of an appropriate response.Design: The prototype developed during the project relies on distributed sensor networks connected to an automatic reasoning system. Sensing technologies used for collecting environmental data include video cameras, RFID antennas, microphones, and wireless sensor networks. Wearable sensors for detecting biosignals (such as electrocardiogram, actigrafy and breath) are also used. The data acquired from the sensors are analyzed by the automatic reasoning system that identifies potentially\u00a0\u2026", "num_citations": "1\n", "authors": ["554"]}
{"title": "Enhancing law modeling and analysis: Using BPR-Based and goal-oriented frameworks\n", "abstract": " Legal documents contain regulations and principles at different levels of abstraction. They constitute rich sources of information for public administrations (PA) redesign and eventually for the software delivery that must comply with normative regulations that are specified in laws and procedures. In order to facilitate the alignment between these elements, systematic methods and tools automating regulations modeling and analysis must be developed. In this paper, we propose the integration of process modeling (named VLPM) and goal-oriented (named Nomos) tool-supported methodologies to systematically model and analyze laws and procedures in public administration. We show that such integrated view would provide a framework that allows tracing and reasoning either top-down, from the principles to the implementation or, vice versa, bottom-up, from a change in the procedure to the principles. Finally, we also believe that this would provide a facility for interchanging models among different tools and for sharing models among different actors.", "num_citations": "1\n", "authors": ["554"]}