{"title": "Defects4J: A database of existing faults to enable controlled testing studies for Java programs\n", "abstract": " Empirical studies in software testing research may not be comparable, reproducible, or characteristic of practice. One reason is that real bugs are too infrequently used in software testing research. Extracting and reproducing real bugs is challenging and as a result hand-seeded faults or mutants are commonly used as a substitute. This paper presents Defects4J, a database and extensible framework providing real bugs to enable reproducible studies in software testing research. The initial version of Defects4J contains 357 real bugs from 5 real-world open source pro-grams. Each real bug is accompanied by a comprehensive test suite that can expose (demonstrate) that bug. Defects4J is extensible and builds on top of each program\u2019s version con-trol system. Once a program is configured in Defects4J, new bugs can be added to the database with little or no effort. Defects4J features a framework to easily access\u00a0\u2026", "num_citations": "743\n", "authors": ["359"]}
{"title": "The Major mutation framework: Efficient and scalable mutation analysis for Java\n", "abstract": " Mutation analysis seeds artificial faults (mutants) into a pro-gram and evaluates testing techniques by measuring how well they detect those mutants. Mutation analysis is well-established in software engineering research but hardly used in practice due to inherent scalability problems and the lack of proper tool support. In response to those challenges, this paper presents Major, a framework for mutation analysis and fault seeding. Major provides a compiler-integrated mu-tator and a mutation analyzer for JUnit tests. Major implements a large set of optimizations to enable efficient and scalable mutation analysis of large software sys-tems. It has already been applied to programs with more than 200,000 lines of code and 150,000 mutants. Moreover, Major features its own domain specific language and is de-signed to be highly configurable to support fundamental re-search in software engineering. Due to its efficiency\u00a0\u2026", "num_citations": "195\n", "authors": ["359"]}
{"title": "Do Automatically Generated Unit Tests Find Real Faults? An Empirical Study of Effectiveness and Challenges\n", "abstract": " Rather than tediously writing unit tests manually, tools can be used to generate them automatically - sometimes even resulting in higher code coverage than manual testing. But how good are these tests at actually finding faults? To answer this question, we applied three state-of-the-art unit test generation tools for Java (Randoop, EvoSuite, and Agitar) to the 357 real faults in the Defects4J dataset and investigated how well the generated test suites perform at detecting these faults. Although the automatically generated test suites detected 55.7% of the faults overall, only 19.9% of all the individual test suites detected a fault. By studying the effectiveness and problems of the individual tools and the tests they generate, we derive insights to support the development of automated unit test generators that achieve a higher fault detection rate. These insights include 1) improving the obtained code coverage so that faulty\u00a0\u2026", "num_citations": "177\n", "authors": ["359"]}
{"title": "Static Analysis of Implicit Control Flow: Resolving Java Reflection and Android Intents\n", "abstract": " Implicit or indirect control flow is a transfer of control between procedures using some mechanism other than an explicit procedure call. Implicit control flow is a staple design pattern that adds flexibility to system design. However, it is challenging for a static analysis to compute or verify properties about a system that uses implicit control flow. This paper presents static analyses for two types of implicit control flow that frequently appear in Android apps: Java reflection and Android intents. Our analyses help to resolve where control flows and what data is passed. This information improves the precision of downstream analyses, which no longer need to make conservative assumptions about implicit control flow. We have implemented our techniques for Java. We enhanced an existing security analysis with a more precise treatment of reflection and intents. In a case study involving ten real-world Android apps that use\u00a0\u2026", "num_citations": "79\n", "authors": ["359"]}
{"title": "Higher accuracy and lower run time: efficient mutation analysis using non\u2010redundant mutation operators\n", "abstract": " Mutation analysis is a powerful but computationally expensive method to measure the effectiveness of a testing or debugging technique. The high cost is due, in part, to redundant mutants generated by commonly used mutation operators. A mutant is said to be redundant if its outcome can be predicted based on the outcome of other mutants. The execution of those redundant mutants is unnecessary and wastes CPU resources. Moreover, the inclusion of redundant mutants may lead to a skewed mutant detection rate and therefore misrepresent the effectiveness of the assessed testing or debugging technique. This paper extends previous work and makes the following contributions. First, it defines and provides non\u2010redundant versions of the conditional operator replacement, unary operator insertion, and relational operator replacement mutation operators. Second, it reports on a conducted empirical study using 10\u00a0\u2026", "num_citations": "54\n", "authors": ["359"]}
{"title": "Do automated program repair techniques repair hard and important bugs?\n", "abstract": " Existing evaluations of automated repair techniques focus on the fraction of the defects for which the technique can produce a patch, the time needed to produce patches, and how well patches generalize to the intended specification. However, these evaluations have not focused on the applicability of repair techniques and the characteristics of the defects that these techniques can repair. Questions such as \u201cCan automated repair techniques repair defects that are hard for developers to repair?\u201d and \u201cAre automated repair techniques less likely to repair defects that involve loops?\u201d have not, as of yet, been answered. To address such questions, we annotate two large benchmarks totaling 409 C and Java defects in real-world software, ranging from 22K to 2.8M lines of code, with measures of the defect\u2019s importance, the developer-written patch\u2019s complexity, and the quality of the test suite. We then analyze\u00a0\u2026", "num_citations": "45\n", "authors": ["359"]}
{"title": "Inferring mutant utility from program context\n", "abstract": " Existing mutation techniques produce vast numbers of equivalent, trivial, and redundant mutants. Selective mutation strategies aim to reduce the inherent redundancy of full mutation analysis to obtain most of its benefit for a fraction of the cost. Unfortunately, recent research has shown that there is no fixed selective mutation strategy that is effective across a broad range of programs; the utility (ie, usefulness) of a mutant produced by a given mutation operator varies greatly across programs.", "num_citations": "41\n", "authors": ["359"]}
{"title": "Unit testing tool competition\u2014round four\n", "abstract": " This paper describes the methodology and results of the 4th edition of the Java Unit Testing Tool Competition. This year's competition features a number of infrastructure improvements, new test effectiveness metrics, and the evaluation of the test generation tools for multiple time budgets. Overall, the competition evaluated four automated test generation tools. This paper details the methodology and contains the full results of the competition.", "num_citations": "25\n", "authors": ["359"]}
{"title": "Comparing developer-provided to user-provided tests for fault localization and automated program repair\n", "abstract": " To realistically evaluate a software testing or debugging technique, it must be run on defects and tests that are characteristic of those a developer would encounter in practice. For example, to determine the utility of a fault localization or automated program repair technique, it could be run on real defects from a bug tracking system, using real tests that are committed to the version control repository along with the fixes. Although such a methodology uses real tests, it may not use tests that are characteristic of the information a developer or tool would have in practice. The tests that a developer commits after fixing a defect may encode more information than was available to the developer when initially diagnosing the defect.", "num_citations": "23\n", "authors": ["359"]}
{"title": "Automating unit and integration testing with partial oracles\n", "abstract": " The oracle problem is an essential part in current research on automating software tests. Partial oracles seem to be a viable solution, but their suitability for different testing steps and general applicability for various systems remains still to be shown. This paper presents a study in which partial oracles are applied in order to automatically test a jpeg2000 encoder as an example for a modular software system with several integrated units and components. The effectiveness of the partial oracles is measured by means of mutation analysis to determine their adequacy for both unit and integration testing. Additionally, the paper presents possibilities of improving the effectiveness as well as the efficiency of the employed partial oracles. It shows how the knowledge of certain characteristics of the system to be tested, such as linearity or time-invariance, may lead to a better choice of partial oracles and thus to an\u00a0\u2026", "num_citations": "22\n", "authors": ["359"]}
{"title": "Benchmarking testing strategies with tools from mutation analysis\n", "abstract": " The assessment of a testing strategy and the comparison of different testing strategies is a crucial part in current research on software testing. Often, manual error seeding is used to generate faulty programs. As a consequence, the results obtained from the examination of these programs are often not reproducible and likely to be biased. In this paper, a flexible approach to the benchmarking of testing strategies is presented. The approach utilizes well- known results from mutation analysis to construct an objective effectiveness measure for test oracles. This measure allows to draw conclusions not only on the effectiveness of a single testing strategy but also to compare different testing strategies by their effectiveness measure.", "num_citations": "22\n", "authors": ["359"]}
{"title": "Tailored mutants fit bugs better\n", "abstract": " Mutation analysis measures test suite adequacy, the degree to which a test suite detects seeded faults: one test suite is better than another if it detects more mutants. Mutation analysis effectiveness rests on the assumption that mutants are coupled with real faults i.e. mutant detection is strongly correlated with real fault detection. The work that validated this also showed that a large portion of defects remain out of reach. We introduce tailored mutation operators to reach and capture these defects. Tailored mutation operators are built from and apply to an existing codebase and its history. They can, for instance, identify and replay errors specific to the project for which they are tailored. As our point of departure, we define tailored mutation operators for identifiers, which mutation analysis has largely ignored, because there are too many ways to mutate them. Evaluated on the Defects4J dataset, our new mutation operators creates mutants coupled to 14% more faults, compared to traditional mutation operators. These new mutation operators, however, quadruple the number of mutants. To combat this problem, we propose a new approach to mutant selection focusing on the location at which to apply mutation operators and the unnaturalness of the mutated code. The results demonstrate that the location selection heuristics produce mutants more closely coupled to real faults for a given budget of mutation operator applications. In summary, this paper defines and explores tailored mutation operators, advancing the state of the art in mutation testing in two ways: 1) it suggests mutation operators that mutate identifiers and literals, extending mutation\u00a0\u2026", "num_citations": "12\n", "authors": ["359"]}
{"title": "Tea: A High-level Language and Runtime System for Automating Statistical Analysis\n", "abstract": " Though statistical analyses are centered on research questions and hypotheses, current statistical analysis tools are not. Users must first translate their hypotheses into specific statistical tests and then perform API calls with functions and parameters. To do so accurately requires that users have statistical expertise. To lower this barrier to valid, replicable statistical analysis, we introduce Tea, a high-level declarative language and runtime system. In Tea, users express their study design, any parametric assumptions, and their hypotheses. Tea compiles these high-level specifications into a constraint satisfaction problem that determines the set of valid statistical tests and then executes them to test the hypothesis. We evaluate Tea using a suite of statistical analyses drawn from popular tutorials. We show that Tea generally matches the choices of experts while automatically switching to non-parametric tests when\u00a0\u2026", "num_citations": "11\n", "authors": ["359"]}
{"title": "Understanding open proxies in the wild\n", "abstract": " This paper conducts an extensive measurement study of open proxies to characterize how much these systems are used, what they are used for, and who uses them. We scanned the Internet to track proxy prevalence and monitored public statistics interfaces to gain insight into the machines hosting open proxies. We estimate that 220 TB of traffic flows through open proxies each day, making them one of the largest overlay networks in existence. We find that automatic traffic taking advantage of multiple vantage points to the Internet overwhelms the traffic of individual \u2018end users\u2019 on open proxies. We present a characterization of the workload experienced by these systems that can inform the design of future open access systems.", "num_citations": "9\n", "authors": ["359"]}
{"title": "Evaluating testing strategies for imaging software by means of mutation analysis\n", "abstract": " The oracle problem is a crucial part in current research on software testing. In many situations available solutions like partial oracles can be used, however the suitability of a specific oracle depends on the application to be tested. Moreover, the inputs have a considerable impact on the effectiveness of the testing strategy. Therefore selecting an appropriate oracle as well as adequate inputs is essential in order to yield satisfying results. In the present paper an approach is described that uses mutation analysis to assess testing strategies, which implies the determination of suitable inputs and the evaluation of partial oracles. The approach is illustrated using metamorphic relations as partial oracles for imaging software.", "num_citations": "9\n", "authors": ["359"]}
{"title": "Defects4J as a Challenge Case for the Search-Based Software Engineering Community\n", "abstract": " Defects4J is a collection of reproducible bugs, extracted from real-world Java software systems, together with a supporting infrastructure for using these bugs. Defects4J has been widely used to evaluate software engineering research, including research on automated test generation, program repair, and fault localization. Defects4J has recently grown substantially, both in number of software systems and number of bugs. This report proposes that Defects4J can serve as a benchmark for Search-Based Software Engineering (SBSE) research as well as a catalyst for new innovations. Specifically, it outlines the current Defects4J dataset and infrastructure, and details how it can serve as a challenge case to support SBSE research and to expand Defects4J itself.", "num_citations": "5\n", "authors": ["359"]}
{"title": "Medusa: Mutant equivalence detection using satisfiability analysis\n", "abstract": " This paper introduces Medusa, a framework for reasoning about the equivalence of first-order mutants in Java programs. Since the problem of detecting equivalent mutants is undecidable in general, even when restricted to first-order mutants, Medusa focuses on a subset of Java that can be modeled as SMT solver constraints. This paper describes the key insights behind Medusa and provides details about its concepts and components, in particular constraint forking-a novel approach that leverages structural similarities between mutants to improve its efficiency. This paper further reports on a preliminary evaluation and outlines several optimizations that leverage the first-order mutant property to further improve Medusa's applicability and efficiency.", "num_citations": "5\n", "authors": ["359"]}
{"title": "Special issue on mutation testing\n", "abstract": " Special issue on Mutation Testing | Information and Software Technology ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Information and Software Technology Periodical Home Latest Issue Archive Authors Affiliations Award Winners More HomeBrowse by TitlePeriodicalsInformation and Software TechnologyVol. , No. CSpecial issue on Mutation Testing research-article Special issue on Mutation Testing Share on Authors: Mike Papadakis profile image Mike Papadakis Interdisciplinary Centre for Security, Reliability and Trust, Luxembourg University, Luxembourg Interdisciplinary Centre for Security, Reliability and Trust, Luxembourg University, Luxembourg View Profile , Ren\u00e9 Just profile image Ren\u00e9 of , :\u2026", "num_citations": "5\n", "authors": ["359"]}
{"title": "On effective and efficient mutation analysis for unit and integration testing\n", "abstract": " Software testing is the most common technique to verify that a program meets certain quality standards. Sufficient manual testing is not only time consuming but also an error-prone task. Additionally, due to the rapidly growing size and complexity of software systems, automating the software testing process is desirable for more cost-effective testing. Besides automating the testing process, the quality of the applied testing strategy has to be assessed to achieve reliable results. This is of particular importance to ensure that the employed tests are also effective in terms of their fault-finding capabilities, and hence the results adequately reflect the quality of the software. By focusing on mutation analysis and testing with partial oracles, this thesis addresses the automation and assessment of unit and integrations tests. This thesis describes and evaluates approaches that improve the effectiveness and efficiency of mutation testing. While mutation testing is known to be computationally expensive and time consuming, it also lacks proper tool support for various purposes. Therefore, this thesis also presents a versatile and highly configurable mutation framework that implements the suggested approaches to enable further research as well as the application of mutation analysis for large software systems. The automation of software tests often results in the oracle problem, another crucial challenge in software testing. In an attempt to alleviate this problem, leveraging partial oracles seem to be viable solution but their adequacy for different testing purposes has not been examined sufficiently. Therefore, this thesis investigates whether partial oracles are in\u00a0\u2026", "num_citations": "2\n", "authors": ["359"]}
{"title": "Removing biased data to improve fairness and accuracy\n", "abstract": " Machine learning systems are often trained using data collected from historical decisions. If past decisions were biased, then automated systems that learn from historical data will also be biased. We propose a black-box approach to identify and remove biased training data. Machine learning models trained on such debiased data (a subset of the original training data) have low individual discrimination, often 0%. These models also have greater accuracy and lower statistical disparity than models trained on the full historical data. We evaluated our methodology in experiments using 6 real-world datasets. Our approach outperformed seven previous approaches in terms of individual discrimination and accuracy.", "num_citations": "1\n", "authors": ["359"]}
{"title": "Customized Program Mutation: Inferring Mutant Utility from Program Context\n", "abstract": " The purpose of selective mutation strategies is to reduce the inherent redundancy of full mutation analysis and hence obtain most of its bene t for a fraction of the cost. Unfortunately, recent research has shown that there is no xed selective mutation strategy that is e ective across a broad range of programs. In other words, for any given mutation operator, the utility (ie, usefulness) of a mutant produced by that operator varies greatly across programs. Hence, selective mutation, as currently de ned, is a dead end despite the fact that existing mutation systems are known to produce highly redundant mutants.This paper explores a novel path out of this conundrum. Specically, it hypothesizes that mutant utility, in terms of equivalency, triviality, and dominance, can be predicted by incorporating context information from the program in which the mutant is embedded. This paper rst explains the intuition behind this hypothesis with a motivational example and then tests the hypothesis by evaluating the predictive power of a series of program-context models and machine learning classi ers.", "num_citations": "1\n", "authors": ["359"]}
{"title": "Collaborative verification of information flow for a high-assurance app store\n", "abstract": " Current app stores distribute some malware to unsuspecting users, even though the app approval process may be costly and time-consuming. High-integrity app stores must provide stronger guarantees that their apps are not malicious. This talk presents a verification model for use in such app stores to guarantee that the apps are free of malicious information flows. In this model, the software vendor and the app store auditor collaborate-each does tasks that are easy for her/him, reducing overall verification cost. The software vendor provides a behavioral specification of information flow and source code annotated with information-flow type qualifiers. This talk also presents our flow-sensitive, context-sensitive information-flow type system that checks those information flow type qualifiers and proves that only information flows in the specification can occur at run time. We have implemented the information-flow type system for Android apps written in Java, and we evaluated both its effectiveness and usability in practice. In an adversarial Red Team evaluation, we analyzed 72 apps (576,000 lines of code) for malware. Our information-flow type system was effective: it detected 96\\% of malware whose malicious behavior was related to information flow.", "num_citations": "1\n", "authors": ["359"]}