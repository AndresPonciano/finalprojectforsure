{"title": "A graphical development and debugging environment for parallel programs\n", "abstract": " To provide high-level graphical support for PVM (Parallel Virtual Machine) based program development, a complex programming environment (GRADE) is being developed. GRADE currently provides tools to construct, execute, debug, monitor and visualize message-passing parallel programs. It offers a high-level graphical programming abstraction mechanism to construct parallel applications by introducing a new graphical language called GRAPNEL. GRADE also provides the programmer with the same graphical user interface during the program design and debugging stages. A distributed debugging engine (DDBG) assists the user in debugging GRAPNEL programs on distributed memory computer architectures. Tape/PVM and PROVE support the performance monitoring and visualization of parallel programs developed in the GRADE environment.", "num_citations": "116\n", "authors": ["1838"]}
{"title": "An integrated testing and debugging environment for parallel and distributed programs\n", "abstract": " To achieve a certain degree of confidence that a given program follows its specification, a testing phase must be included in the program development process, and also a complementary debugging phase to help locating the program's bugs. This paper presents an environment which results of the composition and integration of two basic tools: STEPS (Structural TEsting of Parallel Software), which is a testing tool, and DDBG (Distributed DeBuGger), which is a debugging tool. The two tools are presented individually as stand-alone tools, and we describe how they were combined through the use of another intermediate tool: DEIPA (Deterministic re-Execution and Interactive Program Analysis). We claim that the result achieved is a very effective testing and debugging environment.", "num_citations": "48\n", "authors": ["1838"]}
{"title": "A debugging engine for a parallel and distributed environment\n", "abstract": " This paper describes a debugging interface that has been developed for a parallel software engineering environment and that was developed on top of the PVM environment in the scope of the SEPP and HPCTI projects of the COPERNICUS Programme. The main goal of this interface is to provide the basic debugging functionalities that are required by some components of that environment. We give special attention to the requirements posed by high-level tools of the environment, and to the need of providing a flexible debugging support layer that can be suitably adapted and extended. We present the system logical architecture and the interface specification of the debugging engine. We discuss its interfacing with other components of the environment, namely a graphical editor for the GRAPNEL visual parallel programming language, and a testing tool. We finally describe current work on the improvement of the debugging engine. Keywords: Debugging, monitoring, parallel processing, software tools. 1", "num_citations": "45\n", "authors": ["1838"]}
{"title": "An experiment in tool integration: the DDBG parallel and distributed debugger\n", "abstract": " This paper discusses the development of a debugging tool for parallel programs showing how the requirements posed by high-level tools for parallel program development have influenced the design of the debugging system since its early stages of development. We concentrate our attention upon the interfacing of the debugger with other tools of a parallel software engineering environment, namely a graphical programming language and a testing and debugging tool. This is illustrated with the results of our experimentation with the design and implementation of DDBG, a debugger for the PVM environment.", "num_citations": "39\n", "authors": ["1838"]}
{"title": "Parallel Program development for cluster computing: methodology, tools and integrated environments\n", "abstract": " The book is divided into two parts, the first one covering the concepts and methodologies, and the second describing the tools and integrated environments that were developed in those projects. In this way, we hope that the reader will find the book useful not only concerning an identification of current trends in parallel program development, but also concerning their practical illustration through concrete tools and environments.", "num_citations": "36\n", "authors": ["1838"]}
{"title": "A framework to support parallel and distributed debugging\n", "abstract": " We discuss debugging prototypes that can easily support new functionalities, depending on the requirements of high-level computational models, and allowing a coherent integration with other tools in a software engineering environment. Concerning the first aspect, we propose a framework that identifies two distinct levels of functionalities that should be supported by a parallel and distributed debugger using: a process and thread-level, and a coordination level concerning sets of processes or threads. An incremental approach is used to effectively develop prototypes that support both functionalities. Concerning the second aspect, we discuss how the interfacing with other tools has influenced the design of a process-level debugging interface (PDBG) and a distributed monitoring and control layer called (DAMS).", "num_citations": "32\n", "authors": ["1838"]}
{"title": "Precise detection of atomicity violations\n", "abstract": " Concurrent programs that are free of unsynchronized accesses to shared data may still exhibit unpredictable concurrency errors, called atomicity violations, which include both high-level data races and stale-value errors. Atomicity violations occur when programmers make wrong assumptions about the atomicity scope of a code block, incorrectly splitting it in two or more atomic blocks and allowing them to be interleaved with other atomic blocks. In this paper we propose a novel static analysis algorithm that works on a dependency graph of program variables and detects both high-level data races and stale-value errors. The algorithm was implemented for a Java Bytecode analyzer and its effectiveness was evaluated with well known faulty programs. The results obtained show that our algorithm performs better than previous approaches, achieving higher precision for small and medium sized programs\u00a0\u2026", "num_citations": "26\n", "authors": ["1838"]}
{"title": "Efficient and correct transactional memory programs combining snapshot isolation and static analysis\n", "abstract": " The use of the Snapshot Isolation (SI) level in Transactional Memory (TM) eliminates the need of tracking memory read accesses, reducing the run-time overhead and fastening the commit phase. By detecting only write-write conflicts, SI allows many memory transactions to succeed that would otherwise abort if serialized. This higher commit rate comes at the expense of introducing anomalous behaviors by allowing some real conflicting transactions to commit. We aim at improving the performance of TM systems by running programs under SI, while guaranteeing a serializable semantics. This is achieved by static analysis of TM programs using Separation Logic to detect possible anomalies when running under SI. To guarantee correct behavior, the program code can be automatically modified to avoid these anomalies. Our approach can have an important impact on the performance of single multi-core node TM systems, and also of distributed TM systems by considerable reducing the required network traffic.", "num_citations": "23\n", "authors": ["1838"]}
{"title": "An integrated course on parallel and distributed processing\n", "abstract": " Most known teaching experiences focus on parallel computing courses only, but some teaching experiences on distributed computing courses have also been reported. In this paper we describe a course on Parallel and Distributed Processing that is taught at undergraduate level in the Computer Science degree of our University.This course presents an integrated approach concerning concurrency, parallelism, and distribution issues. It's a breadth-first course addressing a wide spectrum of abstractions: the theoretical component focus on the fundamental abstractions to model concurrent systems, including process cooperation schemes, concurrent programming models, data and control distribution, concurrency control and recovery in transactional systems, and parallel processing models; the practical component illustrates the design and implementation issues involved in selected topics such as a data and\u00a0\u2026", "num_citations": "22\n", "authors": ["1838"]}
{"title": "Understanding the behavior of transactional memory applications\n", "abstract": " Transactional memory is a new trend in concurrency control that was boosted by the advent of multi-core processors and the near to come many-core processors. It promises the performance of finer grain with the simplicity of coarse grain threading. However, there is a clear absence of software development tools oriented to the transactional memory programming model, which is confirmed by the very small number of related scientific works published until now.", "num_citations": "21\n", "authors": ["1838"]}
{"title": "Byzantium: Byzantine-Fault-Tolerant Database Replication Providing Snapshot Isolation.\n", "abstract": " Database systems are a key component behind many of today\u2019s computer systems. As a consequence, it is crucial that database systems provide correct and continuous service despite unpredictable circumstances, such as software bugs or attacks. This paper presents the design of Byzantium, a Byzantine fault-tolerant database replication middleware that provides snapshot isolation (SI) semantics. SI is very popular because it allows increased concurrency when compared to serializability, while providing similar behavior for typical workloads. Thus, Byzantium improves on existing proposals by allowing increased concurrency and not relying on any centralized component. Our middleware can be used with off-the-shelf database systems and it is built on top of an existing BFT library.", "num_citations": "20\n", "authors": ["1838"]}
{"title": "Testing patterns for software transactional memory engines\n", "abstract": " The emergence of multi-core processors is promoting the use of concurrency and multithreading. To raise the abstraction level of synchronization constructs is fundamental to ease the development of concurrent software, and Software Transactional Memory (STM) is a good approach towards such goal. However, execution environment issues such as the processor instruction set, caching policy, and memory model, may have strong influence upon the reliability of STM engines. This paper addresses the testing of STM engines aiming at improving their reliability and independence from execution environment. From our experience with porting and extending a specific STM engine, we report on some of the bugs found and synthesize some testing patterns that proved to be useful at testing STM engines.", "num_citations": "19\n", "authors": ["1838"]}
{"title": "Verifying concurrent programs using contracts\n", "abstract": " The central notion of this paper is that of contracts for concurrency, allowing one to capture the expected atomicity of sequences of method or service calls in a concurrent program. The contracts may be either extracted automatically from the source code, or provided by developers of libraries or software modules to reflect their expected usage in a concurrent setting. We start by extending the so-far considered notion of contracts for concurrency in several ways, improving their expressiveness and enhancing their applicability in practice. Then, we propose two complementary analyses - a static and a dynamic one - to verify programs against the extended contracts. We have implemented both approaches and present promising experimental results from their application on various programs, including real-world ones where our approach unveiled previously unknown errors.", "num_citations": "18\n", "authors": ["1838"]}
{"title": "Towards a persistent publish/subscribe system for networks of mobile devices\n", "abstract": " There is a clear trend and progressive interest in the quasi-real-time sharing of user-generated content, and mobile devices are among the main sources for such content. Although the portability and increasing capabilities of mobile devices allow their use in a wide range of activities, the common use of centralized services to support the sharing of data between users requires highly responsive services and places a huge burden on the network, fully occupying its bandwidth with the outgoing and incoming of data that (often) could be shared directly from device to device at the network edge. Thyme is a data persistent publish/subscribe system that provides for the dissemination and storage of data in networks of mobile devices, without requiring access to the Internet nor to centralized networking services. In this paper, we apply Thyme to real-world networks of Android devices, and use it in the development of a\u00a0\u2026", "num_citations": "15\n", "authors": ["1838"]}
{"title": "Group-to-group bidirectional wi-fi direct communication with two relay nodes\n", "abstract": " The current capabilities of mobile phones in terms of communication, processing and storage, enables its use to form autonomous networks of devices that can be used in case of collapse or inexistent support from a communication infrastructure. In this paper, we propose a network configuration of nodes that provides high-speed bidirectional device-to-device communication, with symmetrical data transfer rates, in Wi-Fi Direct multi-group scenarios, without using performance hindering broadcasts.", "num_citations": "14\n", "authors": ["1838"]}
{"title": "Towards the opportunistic combination of mobile ad-hoc networks with infrastructure access\n", "abstract": " One of the main characteristics of mobile ad-hoc networks (MANETs) is the lack of global, consistent, and up-to-date knowledge of the network topology. Thus, when routing messages, they must be forwarded from one node to the next based solely on each node's current local knowledge of the network. If, somehow, some nodes also have Internet access (even if intermittently), the mix of MANETs with that infrastructure access allows for a wider range of possibilities. In this exploratory work-in-progress paper, we argue for the opportunistic combination of ad-hoc networking with infrastructure access as a way of enabling possible optimizations. The routing protocol can leverage on the fact that some nodes might have infrastructure access and use them to make messages\" jump\" through the network whenever it pays off. Thus, we address the interaction between the ad-hoc routing and the infrastructure access by\u00a0\u2026", "num_citations": "13\n", "authors": ["1838"]}
{"title": "Ephemeral data storage for networks of hand-held devices\n", "abstract": " Presently, hand-held mobile devices, such as smartphones, generate and record large amounts of data (e.g., multimedia files like photos or videos). The off-the-shelf mechanisms for data sharing among these devices include: i) centralized cloud-based data storage services like Dropbox or Flickr, which rely on good quality Internet access for file uploading and downloading, and ii) application-based device-to-device file exchange over wireless technologies (e.g., Bluetooth). Thus, sharing multiple files among multiple devices is far from being a trivial task. In this paper, we propose EPHESUS, an ephemeral distributed data storage system for networks of hand-held mobile devices, where users can publish their own files and obtain files that have been shared by others. The system does not require Internet access and follows a best effort approach to data persistence and availability, also tolerating churn\u00a0\u2026", "num_citations": "13\n", "authors": ["1838"]}
{"title": "Detecting concurrency anomalies in transactional memory programs\n", "abstract": " Concurrent programs may suffer from concurrency anomalies that may lead to    erroneous and unpredictable program behaviors. To ensure program correctness,    these anomalies must be diagnosed and corrected. This paper addresses the    detection of both low- and high-level anomalies in the Transactional Memory    setting. We propose a static analysis procedure and a framework to address    Transactional Memory anomalies. We start by dealing with the classic case of    low-level dataraces, identifying concurrent accesses to shared memory cells    that are not protected within the scope of a memory transaction. Then, we    address the case of high-level dataraces, bringing the programmer\u2019s attention    to pairs of memory transactions that were misspecified and should have been    combined into a single transaction. Our framework was applied to a set of    programs, collected form different sources, containing well known low- and    high-level anomalies. The framework demonstrated to be accurate, confirming    the effectiveness of using static analysis techniques to precisely identify    concurrency anomalies in Transactional Memory programs.", "num_citations": "13\n", "authors": ["1838"]}
{"title": "Detection of transactional memory anomalies using static analysis\n", "abstract": " Transactional Memory allows programmers to reduce the number of synchronization errors introduced in concurrent programs, but does not ensures its complete elimination. This paper proposes a pattern matching based approach to the static detection of atomicity violation, based on a path-sensitive symbolic execution method to model four anomalies that may affect Transactional Memory programs. The proposed technique may be used to to bring to programmer's attention pairs of transactions that the programmer has mis-specified, and should have been combined into a single transaction. The algorithm first traverses the AST tree, removing all the non-transactional blocks and generating a trace tree in the path sensitive manner for each thread. The trace tree is a Trie like data structure, where each path from root to a leaf is a list of transactions. For each pair of threads, erroneous patterns involving two\u00a0\u2026", "num_citations": "13\n", "authors": ["1838"]}
{"title": "Fiddle: A flexible distributed debugger architecture\n", "abstract": " In the recent past, multiple techniques and tools have been proposed and contributed to improve the distributed debugging functionalities, in several distinct aspects, such as handling the non-determinism, allowing cyclic interactive debugging of parallel programs, and providing more user-friendly interfaces. However, most of these tools are tied to a specific programming language and provide rigid graphical user interfaces. So they cannot easily adapt to support distinct abstraction levels or user interfaces. They also don\u2019t provide adequate support for cooperation with other tools in a software engineering environment. In this paper we discuss several dimensions which may contribute to develop more flexible distributed debuggers. We describe Fiddle, a distributed debugging tool which aims at overcoming some of the above limitations.", "num_citations": "13\n", "authors": ["1838"]}
{"title": "GOCRGO and GOGO: two minimal communication topologies for WiFi-direct multi-group networking\n", "abstract": " Although mobile devices can collaborate and interact when connected by a communication infrastructure, such interactions may also be greatly desired or even highly necessary when such infrastructures are not available or cannot be used, like in crowded spaces, disaster situations, and remote areas, or when there is no trust in the existing infrastructures. A major requirement to support such autonomous collaborative systems on top of mobile devices is to build a communication network to interconnect them all. In this quest, Wi-Fi Direct (WFD) stands out as a promising technology to offer infrastructure-less WiFi networking to off-the-shelf devices. However, the WFD standard only addresses communications inside one group of devices, and current WFD inter-group communication solutions have several limitations, as they must contend with intermittent connections, slow communication (broadcasts and/or\u00a0\u2026", "num_citations": "10\n", "authors": ["1838"]}
{"title": "Efficient support for in-place metadata in transactional memory\n", "abstract": " Implementations of Software Transactional Memory (STM) algorithms associate metadata with the memory locations accessed during a transaction\u2019s lifetime. This metadata may be stored either in-place, by wrapping every memory cell in a container that includes the memory cell itself and the corresponding metadata; or out-place (also called external), by resorting to a mapping function that associates the memory cell address with an external table entry containing the corresponding metadata. The implementation techniques for these two approaches are very different and each STM framework is usually biased towards one of them, only allowing the efficient implementation of STM algorithms following that approach, hence inhibiting the fair comparison with STM algorithms falling into the other. In this paper we introduce a technique to implement in-place metadata that does not wrap memory cells, thus\u00a0\u2026", "num_citations": "10\n", "authors": ["1838"]}
{"title": "Using DDBG to support testing and high-level debugging interfaces\n", "abstract": " This paper describes our experience with the design and implementation of a distributed debugger for C/PVM programs within the scope of the SEPP and HPCTI Copernicus projects. These projects aimed at the development of an integrated parallel software engineering environment based on a high-level graphical parallel programming model (GRAPNEL) and a set of associated tools supporting graphical edition, compilation, simulated and real parallel execution, testing, debugging, performance monitoring, mapping, and load balancing. We discuss how the development of the debugging tool was strongly influenced by the requirements posed by other tools in the environment, namely support for high-level graphical debugging of GRAPNEL programs, and support for the integration of static and dynamic analysis tools. We describe the functionalities of the DDBG debugger and its internal architecture, and discuss its integration with two separate tools in the SEPP/HPCTI environment: the GRED graphical editor for GRAPNEL programs, and the STEPS testing tool for C/PVM programs.", "num_citations": "10\n", "authors": ["1838"]}
{"title": "Time-aware reactive storage in wireless edge environments\n", "abstract": " Nowadays, smart mobile devices generate huge amounts of data in all sorts of gatherings. Much of that data has localized and ephemeral interest, but can be of great use if shared among co-located devices. However, these devices often experience poor connectivity, leading to availability issues if applications' storage and logic are fully delegated to a remote cloud infrastructure. In turn, the edge computing paradigm pushes computations and storage beyond the data center, closer to end-user devices where data is generated and consumed. Thus, enabling the execution of certain components of edge-enabled systems directly and cooperatively on edge devices. In this paper, we address the challenge of supporting reliable and efficient data storage and dissemination among co-located wireless mobile devices without resorting to centralized services or network infrastructures. We propose Thyme, a novel time\u00a0\u2026", "num_citations": "9\n", "authors": ["1838"]}
{"title": "Debugging of parallel and distributed programs\n", "abstract": " This chapter surveys the main issues involved in correctness debugging of parallel and distributed programs. Distributed debugging is an instance of the more general problem of observation of a distributed computation. This chapter briefly summarizes the theoretical foundations of the distributed debugging activity. Then a survey is presented of the main methodologies used for parallel and distributed debugging, including state and event based debugging, deterministic re-execution, systematic state exploration, and correctness predicate evaluation. Such approaches are complementary to one another, and the chapter discusses how they can be supported using distinct techniques for observation and control.", "num_citations": "9\n", "authors": ["1838"]}
{"title": "Discovering concurrency errors\n", "abstract": " Lots of concurrent software is being developed for the now ubiquitous multicore processors. And concurrent programming is difficult because it is quite easy to introduce errors that are really hard to diagnose and fix. One of the main obstacles to concurrent programming is that threads are scheduled nondeterministically and their interactions may become hard to predict and to devise. This chapter addresses the nature of concurrent programming and some classes of concurrency errors. It discusses the application of dynamic program analysis techniques to detect, locate and diagnose some common concurrency errors like data races, atomicity violations and deadlocks. This chapter also mentions some techniques that can help with quality assurance of concurrent programs, regardless of any particular class of concurrency errors, like noise injection and systematic testing, and it is closed by some prospects\u00a0\u2026", "num_citations": "8\n", "authors": ["1838"]}
{"title": "Extracting static and dynamic structural information from java concurrent programs for coverage testing\n", "abstract": " This paper proposes novel techniques for the extraction of structural information from the source code of Java concurrent programs for their coverage testing. Such techniques differ from others because they consider synchronization flow among processes/threads, distinct paradigms of communication/synchronization, method calls and pointer manipulation. The structural information gathered from the source code is kept in a test model based on a Parallel Control Flow Graph (PCFG) and helps the generation of an instrumented source code, used for a future generation of trace files and to replay the concurrent execution. The results show the techniques can generate both an instrumented code and a PCFG for Java concurrent programs effectively, extracting static and runtime information required for structural testing.", "num_citations": "8\n", "authors": ["1838"]}
{"title": "Decentralized storage for networks of hand-held devices\n", "abstract": " In this paper we propose a fully distributed storage system for everyday hand-held mobile devices, eg, smartphones and tablets, that follows a best effort approach to ensure data persistence and availability even in the presence of churn (ie, the unpredictable arrival and departure of nodes).", "num_citations": "8\n", "authors": ["1838"]}
{"title": "Preventing atomicity violations with contracts\n", "abstract": " Software developers are expected to protect concurrent accesses to shared regions of memory with some mutual exclusion primitive that ensures atomicity properties to a sequence of program statements. This approach prevents data races but may fail to provide all necessary correctness properties.The composition of correlated atomic operations without further synchronization may cause atomicity violations. Atomic violations may be avoided by grouping the correlated atomic regions in a single larger atomic scope. Concurrent programs are particularly prone to atomicity violations when they use services provided by third party packages or modules, since the programmer may fail to identify which services are correlated. In this paper we propose to use contracts for concurrency, where the developer of a module writes a set of contract terms that specify which methods are correlated and must be executed in the same atomic scope. These contracts are then used to verify the correctness of the main program with respect to the usage of the module(s). If a contract is well defined and complete, and the main program respects it, then the program is safe from atomicity violations with respect to that module. We also propose a static analysis based methodology to verify contracts for concurrency that we applied to some real-world software packages. The bug we found in Tomcat 6.0 was immediately acknowledged and corrected by its development team.", "num_citations": "8\n", "authors": ["1838"]}
{"title": "Dynamic validation of contracts in concurrent code\n", "abstract": " Multi-threaded programs allow one to achieve better performance by doing a lot of work in parallel using multiple threads. Such parallel programs often contain code blocks that a thread must execute atomically, i.e., with no interference from the other threads of the program. Failing to execute these code blocks atomically leads to errors known as atomicity violations. However, frequently it not obvious to tell when a piece of code should be executed atomically, especially when that piece of code contains calls to some third-party library functions, about which the programmer has little or no knowledge at all. One solution to this problem is to associate a contract with such a library, telling the programmer how the library functions should be used, and then check whether the contract is indeed respected. For contract validation, static approaches have been proposed, with known limitations on precision and\u00a0\u2026", "num_citations": "8\n", "authors": ["1838"]}
{"title": "Practical verification of high-level dataraces in transactional memory programs\n", "abstract": " In this paper we present MoTh, a tool that uses static analysis to enable the automatic verification of concurrency anomalies in Transactional Memory Java programs. Currently MoTh detects high-level dataraces and stale-value errors, but it is extendable by plugging-in sensors, each sensor implementing an anomaly detecting algorithm. We validate and benchmark MoTh by applying it to a set of well known concurrent buggy programs and by close comparison of the results with other similar tools. The results achieved so far are very promising, yielding good accuracy while triggering only a very limited number of false warnings.", "num_citations": "8\n", "authors": ["1838"]}
{"title": "DDBG: A Distributed Debugger-User's Guide\n", "abstract": " This document describes a debugging tool called DDBG that has been developed for a parallel software engineering environment and that was developed on top of the PVM environment in the scope of the SEPP and HPCTI projects of the COPERNICUS Programme. The main goal of this tool is to provide the basic debugging functionalities that are required by other components of that environment but it can also be used on its own. We present the system logical architecture and the interface specification of the debugging engine in its main components: interface library and user consoles. 1", "num_citations": "8\n", "authors": ["1838"]}
{"title": "Mobile device-to-device distributed computing using data sets\n", "abstract": " The rapidly increasing computing power, available storage and communication capabilities of mobile devices makes it possible to start processing and storing data locally, rather than offloading it to remote servers; allowing scenarios of mobile clouds without infrastructure dependency. We can now aim at connecting neighboring mobile devices, creating a local mobile cloud that provides storage and computing services on local generated data.", "num_citations": "7\n", "authors": ["1838"]}
{"title": "Using program closures to make an application programming interface (API) implementation thread safe\n", "abstract": " Consider a set of methods implementing an Application Programming Interface (API) of a given library or program module that is to be used in a multithreaded setting. If those methods were not originally designed to be thread safe, races and deadlocks are expected to happen. This work introduces the novel concept of program closure and describes how it can be applied in a methodology used to make the library or module implementation thread safe, by identifying the high level data races introduced by interleaving the parallel execution of methods from the API. High-level data races result from the misspecification of the scope of an atomic block, by wrongly splitting it into two or more atomic blocks sharing a data dependency.", "num_citations": "7\n", "authors": ["1838"]}
{"title": "Efficient support for in\u2010place metadata in Java software transactional memory\n", "abstract": " Software transactional memory (STM) algorithms associate metadata with the memory locations accessed during a transaction's lifetime. This metadata may be stored in an external table by resorting to a mapping function that associates the address of a memory cell with the table entry containing the corresponding metadata (out\u2010place or external strategy). Alternatively, the metadata may be stored adjacent to the associated memory cell by wrapping the cell and metadata together (in\u2010place strategy). The implementation techniques to support these two approaches are very different and each STM framework is usually biased towards one of them, only allowing the efficient implementation of STM algorithms which suit one of the approaches and inhibiting a fair comparison with STM algorithms suiting the other. In this paper, we introduce a technique to implement in\u2010place metadata that does not wrap memory cells\u00a0\u2026", "num_citations": "6\n", "authors": ["1838"]}
{"title": "Snapshot isolation anomalies detection in software transactional memory\n", "abstract": " Some performance issues of transactional memory are caused by unnecessary abort situations where non serializable and yet non conflicting transactions are scheduled to execute concurrently. Smartly relaxing the isolation properties of transactions may overcome these issues and attain considerable performance improvements. However, it is known that relaxing isolation restrictions may lead to runtime anomalies. In some situations, like database management systems, developers may choose that compromise, hence avoiding anomalies explicitly. Memory transactions protect the state of the program, therefore execution anomalies may have more severe consequences in the semantics of programs. So, the compromise between a relaxed isolation strategy and enforcing the necessary program correctness is harder to setup. The solution we devise is to statically analyse programs to detect the kind of anomalies that emerge under snapshot isolation. Our approach allows a compiler to either warn the developer about the possible snapshot isolation anomalies in a given program, or possibly inform automatic correctness strategies to ensure Serializability.", "num_citations": "6\n", "authors": ["1838"]}
{"title": "Developing libraries using software transactional memory\n", "abstract": " Software transactional memory is a promising programming model that adapts many concepts borrowed from the databases world to control concurrent accesses to main memory (RAM). This paper discusses how to support revertible operations, such as memory allocation and release, within software libraries that will be used in software memory transactional contexts. The proposal is based in the extension of the transaction life cycle state diagram with new states associated to the execution of user-defined handlers. The proposed approach is evaluated in terms of functionality and performance by way of a use case study and performance tests. Results demonstrate that the proposal and its current implementation are flexible, generic and efficient. .", "num_citations": "6\n", "authors": ["1838"]}
{"title": "An experience in building a parallel and distributed problem-solving environment\n", "abstract": " We describe our experimentation with the design and implementation of specific environments, consisting of heterogeneous computational, visualization, and control components. We illustrate the approach with the design of a problem-solving environment supporting the execution of genetic algorithms. We describe a prototype steering parallel execution, visualization, and steering. A life cycle for the development of applications based an genetic algorithms is proposed.", "num_citations": "6\n", "authors": ["1838"]}
{"title": "Um sistema publicador/subscritor com persist\u00eancia de dados para redes de dispositivos m\u00f3veis\n", "abstract": " Os dispositivos m\u00f3veis s\u00e3o atualmente uma das principais fontes de gera\u00e7\u00e3o de conte\u00fados pessoais. A portabilidade e a crescente capacidade destes dispositivos permitem que os mesmos sejam utilizados nas mais variadas atividades, l\u00fadicas e n\u00e3o s\u00f3. Tal tend\u00eancia tem sido acompanhada pelo progressivo interesse em partilhar (em tempo real) os conte\u00fados gerados. No entanto, a comum utiliza\u00e7\u00e3o de servi\u00e7os centralizados para suportar a partilha de dados entre utilizadores requer sistemas de servidores com grande capacidade de resposta e coloca muita carga na rede, reduzindo a sua largura de banda com dados que (muitas vezes) podem ser partilhados na periferia. Nesta disserta\u00e7\u00e3o apresentamos uma implementa\u00e7\u00e3o em Android do Thyme, um sistema publicador/subscritor com persist\u00eancia de dados para redes de dispositivos m\u00f3veis, que fornece um mecanismo de dissemina\u00e7\u00e3o e armazenamento de dados adaptado para este tipo de redes, sem requerer acesso \u00e0 Internet. No Thyme, o tempo \u00e9 uma dimens\u00e3o de primeira ordem, associando um intervalo de tempo a cada subscri\u00e7\u00e3o, em que o in\u00edcio e fim do intervalo podem ser referentes ao futuro, presente ou passado. Como caso de uso apresentamos uma aplica\u00e7\u00e3o Android para partilha de fotografias. Os resultados obtidos mostram, que o trabalho desenvolvido apresenta o comportamento desejado num ambiente composto por um n\u00famero consider\u00e1vel de dispositivos, conseguindo inclusivamente lidar com mobilidade e churn. Foi poss\u00edvel ainda verificar que o Thyme apresenta tempos de resposta que garantem a interatividade com o utilizador, comprovando poder ser\u00a0\u2026", "num_citations": "5\n", "authors": ["1838"]}
{"title": "Pot: Deterministic transactional execution\n", "abstract": " This article presents Pot, a system that leverages the concept of preordered transactions to achieve deterministic multithreaded execution of programs that use Transactional Memory. Preordered transactions eliminate the root cause of nondeterminism in transactional execution: they provide the illusion of executing in a deterministic serial order, unlike traditional transactions that appear to execute in a nondeterministic order that can change from execution to execution. Pot uses a new concurrency control protocol that exploits the serialization order to distinguish between fast and speculative transaction execution modes in order to mitigate the overhead of imposing a deterministic order. We build two Pot prototypes: one using STM and another using off-the-shelf HTM. To the best of our knowledge, Pot enables deterministic execution of programs using off-the-shelf HTM for the first time. An experimental evaluation\u00a0\u2026", "num_citations": "5\n", "authors": ["1838"]}
{"title": "A suite of Java message-passing benchmarks to support the validation of testing models, criteria and tools\n", "abstract": " This paper proposes a novel suite of benchmarks for the evaluation of the structural testing of concurrent programs with message-passing paradigm. This suite is composed of thirteen bug-free programs and five faulty programs. The benchmarks are developed in Java and are available as free-software on the Internet. They were validated with experimental studies and also have been used in different research and for educational aims. The obtained results showed that the benchmarks can generate qualified workload for the testing of message-passing programs. The main contribution of this study is the development of a more robust and fair suite of benchmarks capable of improving the evaluation of the testing activity applied to concurrent programs.", "num_citations": "5\n", "authors": ["1838"]}
{"title": "Unifying memory and database transactions\n", "abstract": " Software Transactional Memory is a concurrency control technique gaining increasing popularity, as it provides high-level concurrency control constructs and eases the development of highly multi-threaded applications. But this easiness comes at the expense of restricting the operations that can be executed within a memory transaction, and operations such as terminal and file I/O are either not allowed or incur in serious performance penalties. Database I/O is another example of operations that usually are not allowed within a memory transaction. This paper proposes to combine memory and database transactions in a single unified model, benefiting from the ACID properties of the database transactions and from the speed of main memory data processing. The new unified model covers, without differentiating, both memory and database operations. Thus, the users are allowed to freely intertwine memory\u00a0\u2026", "num_citations": "5\n", "authors": ["1838"]}
{"title": "Time-Aware Publish/Subscribe for Networks of Mobile Devices\n", "abstract": " Smart mobile devices are increasingly ubiquitous and are the primary source of user-generated content, and current communication infrastructures are failing in keeping up with the rising demand for the avid sharing of such content. To alleviate this problem and fully harness the amount of resources currently available at the network edge, mobile edge paradigms started to emerge. Though, application developers still struggle to tap that potential at the edge due to the lack of adequate communication and interaction abstractions. Thus, we propose a high-level abstraction that can be easily exploited by developers to design mobile edge applications focused on data dissemination. In this paper, we propose Thyme, a novel extended topic-based, time-aware publish/subscribe system for networks of mobile devices. In Thyme, time is a rst order dimension. Each subscription has an associated time frame, starting and ending either in the future, present, or past. Making the past available requires both subscriptions and publications to be persistently stored. We present the design of Thyme and evaluate it using simulation, discussing and characterizing the scenarios best suited for its use.", "num_citations": "4\n", "authors": ["1838"]}
{"title": "A hardware approach for detecting, exposing and tolerating high level atomicity violations\n", "abstract": " Multicores are the main trend in computer architecture to gain performance without exponentially increasing the power consumption. However, to take advantage of these new architectures we need parallel programs. Parallel programming is challenging mainly because the programmer has to reason about many threads accessing data concurrently, and the data access interleavings are not deterministic, hence unpredictable.Locks are the most used mechanism to synchronize the accesses to shared memory. Using coarse-grain locks enforces the serialization of large code blocks and hinders performance, and using fine grain locks is a tedious and error prone process for the programmer that frequently ends up in deadlocks and other concurrency related errors. An alternative to locks is transactional memory, an abstraction for defining atomic blocks that may be executed speculatively, making good use of the available cores and solving some of the problems associated with locks. In this paper we address a solution for detecting and tolerating one of the most typical concurrency bugs: atomicity violations. More specifically, we address High Level Atomicity Violations (HLAV). High-level atomicity violations results from the misspecification of the scope of an atomic block, by splitting it in two or more atomic blocks which may be interleaved with other atomic blocks. Figure 1 shows an example of this type of atomicity violation. The intuitive idea behind HLAV is that if two shared data items (eg, memory locations) were both accessed inside an atomic block, they are interrelated and probably the programmer intention is that there shall be no\u00a0\u2026", "num_citations": "4\n", "authors": ["1838"]}
{"title": "Supporting multiple data replication models in distributed transactional memory\n", "abstract": " Distributed transactional memory (DTM) presents itself as a highly expressive and programmer friendly model for concurrency control in distributed programming. Current DTM systems make use of both data distribution and replication as a way of providing scalability and fault tolerance, but both techniques have advantages and drawbacks. As such, each one is suitable for different target applications, and deployment environments. In this paper we address the support of different data replication models in DTM. To that end we propose ReDstm, a modular and non-intrusive framework for DTM, that supports multiple data replication models in a general purpose programming language (Java). We show its application in the implementation of distributed software transactional memories with different replication models, and evaluate the framework via a set of well-known benchmarks, analysing the impact of the\u00a0\u2026", "num_citations": "4\n", "authors": ["1838"]}
{"title": "Crowd-sourcing mobile devices to provide storage in edge-clouds\n", "abstract": " Given the proliferation and enhanced capabilities of mobile devices, their computational and storage resources can now be combined in a wireless cloud of nearby mobile devices, a mobile edge-cloud. These clouds are of particular interest in low connectivity scenarios, eg, sporting events and disaster scenarios. In these dynamic clouds it is necessary to reliably disseminate and share data, and also to offload data processing computations to other devices in the edge-cloud. We are particularly interested in supporting storage services in these new type of edge-clouds, as a mean to enable data sharing, dissemination and querying, as well as to serve as a distributed file system for offloaded computations. In this Ph. D. thesis, we propose to address these questions by researching on the usage of ad-hoc clouds of mobile devices to develop an efficient storage service capable of providing high availability and reliability.", "num_citations": "4\n", "authors": ["1838"]}
{"title": "Macrodb: Scaling database engines on multicores\n", "abstract": " Multicore processors are available for over a decade, but general purpose database management systems (DBMS) still cannot fully explore the computational resources of these platforms. This paper explores a simple and easy to deploy approach for improving DBMS performance in multicore platforms, by maintaining multiple database engines running in parallel, rather than a single instance, thus circumventing the increase in contention due to load interactions. Unlike previous works, we focus on in-memory DBMS, exploring different design solutions that combine distributed systems and concurrent programming techniques. We show that we are able to improve performance over standalone solutions, without modifying either database or application code, by up to 3 times while minimizing response times.", "num_citations": "4\n", "authors": ["1838"]}
{"title": "Uma Infraestrutura para Suporte de Mem\u00f3ria Transacional Distribu\u00edda\n", "abstract": " As t\u00e9cnicas e algoritmos desenvolvidos sobre diferentes infraestruturas espec\u00edficas dificilmente podem ser comparados entre si. Este princ\u00edpio tamb\u00e9m se aplica \u00e0s infraestruturas para execu\u00e7\u00e3o de Mem\u00f3ria Transacional Distribu\u00edda (MTD), pois n\u00e3o s\u00f3 s\u00e3o muito escassas aquelas que permitem o desenvolvimento, teste e compara\u00e7\u00e3o de v\u00e1rios algoritmos e t\u00e9cnicas de implementa\u00e7\u00e3o, como fornecem uma interface intrusiva para o programador. Sem uma compara\u00e7\u00e3o justa, n\u00e3o \u00e9 poss\u00edvel aferir quais as t\u00e9cnicas e algoritmos mais apropriados em cada contexto de utiliza\u00e7\u00e3o (workload). Neste artigo propomos uma infraestrutura generalista, muito flex\u00edvel, que possibilita a experimenta\u00e7\u00e3o de v\u00e1rias estrat\u00e9gias de MTD, permitindo o desenvolvimento de uma grande variedade de algoritmos e de t\u00e9cnicas de implementa\u00e7\u00e3o eficientes e otimizadas. Atrav\u00e9s da sua utiliza\u00e7\u00e3o, \u00e9 agora poss\u00edvel a compara\u00e7\u00e3o de t\u00e9cnicas e algoritmos em diferentes contextos de utiliza\u00e7\u00e3o (workloads), recorrendo a uma \u00fanica infraestrutura e com implica\u00e7\u00f5es m\u00ednimas no c\u00f3digo da aplica\u00e7\u00e3o.", "num_citations": "4\n", "authors": ["1838"]}
{"title": "Open virtualization framework for testing ground systems\n", "abstract": " The recent developments in virtualization change completely the panorama of the Hardware/OS deployment. New bottlenecks arise in the deployment of application stacks, where IT industry will spend most of the time to assure automation. VIRTU tool aims at managing, configuring and testing distributed ground applications of space systems on a virtualized environment, based on open tools and cross virtualization support. This tool is a spin-off of previous activities performed by the European Space Operations Center (ESOC) and thus it covers the original needs from the ground data systems infrastructure division of the European Space Agency. VIRTU is a testing oriented solution. Its ability to group several virtual machines in an assembly provides the means to easily deploy a full testing infrastructure, including the client/server relationships.", "num_citations": "4\n", "authors": ["1838"]}
{"title": "A static approach for detecting concurrency anomalies in transactional memory\n", "abstract": " Programs containing concurrency anomalies will most probably exhibit harmful erroneous and unpredictable behaviors. To ensure program correctness, the sources of those anomalies must be located and corrected. Concurrency anomalies in Transactional Memory (TM) programs should also be diagnosed and fixed. In this paper we propose a framework to deal with two different categories of concurrency anomalies in TM. First, we will address low-level TM anomalies, also called dataraces, which arise from executing programs in weak isolation. Secondly, we will address high-level TM anomalies, also called high-level dataraces, bringing the programmer\u2019s attention to pairs of transactions that the programmer has misspecified, and should have been combined into a single transaction. Our framework was validated against a set of programs with well known anomalies and demonstrated high accuracy and effectiveness, thus contributing for improving the correctness of TM programs.", "num_citations": "4\n", "authors": ["1838"]}
{"title": "SmART: An Application Reconfiguration Framework\n", "abstract": " SmART (Smart Application Reconfiguration Tool) is a framework for the automatic configuration of systems and applications. The tool implements an application configuration workflow that resorts to the similarities between configuration files (i.e., patterns such as parameters, comments and blocks) to allow a syntax independent manipulation and transformation of system and application configuration files.Without compromising its generality, SmART targets virtualized IT infrastructures, configuring virtual appliances and its applications. SmART reduces the time required to (re)configure a set of applications by automating time-consuming steps of the process, independently of the nature of the application to be configured. Industrial experimentation and utilization of SmART show that the framework is able to correctly transform a large amount of configuration files into a generic syntax and back to their original\u00a0\u2026", "num_citations": "4\n", "authors": ["1838"]}
{"title": "Integration of formal verification and debugging methods in P-GRADE environment\n", "abstract": " In this paper we present a combined method, which enables the collaboration of parallel debugging techniques with simulation and verification of parallel program\u2019s coloured Petri-net model in the frame of an integrated development environment. For parallel applications, written in the hybrid graphical language of P-GRADE, the coloured Petri-net model can be automatically generated. The Occurrence Graph (a kind of state-space) is constructed straight away from the model by the GRSIM simulation engine, which allows examining and querying the Occurrence Graph for critical information, such as dead-locks, wrong termination, or the meeting the temporal logic specification. Based on the obtained information the macrostep-based execution can be steered towards the erroneous situations assisting to users to improve the quality of their software.", "num_citations": "4\n", "authors": ["1838"]}
{"title": "Control and debugging of distributed programs using Fiddle\n", "abstract": " The main goal of Fiddle, a distributed debugging engine, is to provide a flexible platform for developing debugging tools. Fiddle provides a layered set of interfaces with a minimal set of debugging functionalities, for the inspection and control of distributed and multi-threaded applications. This paper illustrates how Fiddle is used to support integrated testing and debugging. The approach described is based on a tool, called Deipa, that interprets sequences of commands read from an input file, generated by an independent testing tool. Deipa acts as a Fiddle client, in order to enforce specific execution paths in a distributed PVM program. Other Fiddle clients may be used along with Deipa for the fine debugging at process level. Fiddle and Deipa functionalities and architectures are described, and a working example shows a step-by-step application of these tools.", "num_citations": "4\n", "authors": ["1838"]}
{"title": "Supporting on-line distributed monitoring and debugging\n", "abstract": " Monitoring systems have traditionally been developed with rigid objectives and functionalities, and tied to specific languages, libraries and run-time environments. There is a need for more flexible monitoring systems which can be easily adapted to distinct requirements. On-line monitoring has been considered as increasingly important for observation and control of a distributed application. In this paper we discuss monitoring interfaces and architectures which support more extensible monitoring and control services. We describe our work on the development of a distributed monitoring infrastructure, and illustrate how it eases the implementation of a complex distributed debugging architecture. We also discuss several issues concerning support for tool interoperability and illustrate how the cooperation among multiple concurrent tools can ease the task of distributed debugging.", "num_citations": "4\n", "authors": ["1838"]}
{"title": "The PDBG process-level debugger for parallel and distributed programs\n", "abstract": " ConclusionsThe most distinctive aspects of the our approach are the provision of a framework to support the experimentation with the following aspects: l Incremental development of debugging functionalities; l Support for heterogeneity; l Tool interfacing and integration. Due to its flexibility, PDBG can be used to implement debugging specifications such as HPDF [I].", "num_citations": "4\n", "authors": ["1838"]}
{"title": "Replaying distributed applications with RPVM\n", "abstract": " Parallel debugging is complex and difficult. Complex because the programmer has to deal with multiple program flows and process interactions, and difficult due to the very limited choice on effective and easy-touse debugging tools for parallel programming. Simple and necessary features for parallel debugging are absent even from commercial debuggers, such as a record-replay feature, that allows to re-execute multiple times a parallel application assuring that during each re-execution the internal race conditions are solved in the same way they were in the first time. Some work has been done on record-replay techniques for parallel and distributed applications, but just a few have been applied to specific systems (such as PVM or MPI), and even less have produced working prototypes. In this paper we describe a method designed to work with the PVM system and how it was implemented to provide a working prototype.", "num_citations": "4\n", "authors": ["1838"]}
{"title": "Integrating a debugging engine to the GRAPNEL environment\n", "abstract": " Thisdocumentpresents asetof system calls tobe availableinadistributeddebuggingenvironment. It alsodescribeshowtheycanbeintegratedwithandcalledfromtheGRED (GRapnel EDitor environment). These system calls can be subdivided into two groups: basic and extended system calls. The rst group includes the minimum set of system calls necessary for the debugging and can be used directly, or as a basis to implement higher level ones. The second group includes complementary system calls, supported directly by the system or by the basic ones. In this document, no distinction is made between the basic and the extended functionalities.", "num_citations": "4\n", "authors": ["1838"]}
{"title": "The DDBG distributed debugger\n", "abstract": " This chapter presents the main issues involved in the design of the DDBG distributed debugger. DDBG provides basic support for state based debugging of distributed C/PVM processes. Due to its flexible architecture, DDBG enables the implementation of several debugging methodologies for deterministic re-execution and systematic state exploration. This is achieved through its integration with other tools in a parallel software development environment. The chapter describes how DDBG was integrated with two tools of the SEPP/HPCTI environment: the STEPS testing tool and the GRED graphical editor.", "num_citations": "3\n", "authors": ["1838"]}
{"title": "The DOTPAR project: Towards a framework supporting domain oriented tools for parallel and distributed processing\n", "abstract": " We discuss the problem of building domain oriented environments by a composition of heterogeneous application components and tools. We describe several individual tools that support such environments, namely a distributed monitoring and control tool (DAMS), a process-based distributed debugger (PDBG) and a heterogeneous interconnection model (PHIS). We discuss our experience with the development of a Problem Oriented Environment in the domain of genetic algorithms, obtained by a composition of heterogeneous tools and application components.", "num_citations": "3\n", "authors": ["1838"]}
{"title": "A thread-level distributed debugger\n", "abstract": " In order to address the diversity of existing parallel programming models, it is important to provide development environments that can be incrementally extended with new services. Concerning the debugging of processbased models, we have previously designed and implemented a basic interface that can be accessed by other tools as well as by debugging modules associated with high-level programming languages. In this paper we describe our work towards the support of further debugging functionalities for parallel and distributed programs, by discussing a model to support thread-based debugging services. We then show how those services are supported on top of a distributed monitoring and control software architecture.", "num_citations": "3\n", "authors": ["1838"]}
{"title": "A distributed debugging tool for a parallel software engineering environment\n", "abstract": " We discuss issues in the design and implementation of a flexible debugging tool and its integration into a parallel software engineering environment.", "num_citations": "3\n", "authors": ["1838"]}
{"title": "It\u2019s about Thyme: On the design and implementation of a time-aware reactive storage system for pervasive edge computing environments\n", "abstract": " Nowadays, smart mobile devices generate huge amounts of data in all sorts of gatherings. Much of that data has localized and ephemeral interest, but can be of great use if shared among co-located devices. However, mobile devices often experience poor connectivity, leading to availability issues if application storage and logic are fully delegated to a remote cloud infrastructure. In turn, the edge computing paradigm pushes computations and storage beyond the data center, closer to end-user devices where data is generated and consumed, enabling the execution of certain components of edge-enabled systems directly and cooperatively on edge devices. In this article, we address the challenge of supporting reliable and efficient data storage and dissemination among co-located wireless mobile devices without resorting to centralized services or network infrastructures. We propose Thyme, a novel time-aware\u00a0\u2026", "num_citations": "2\n", "authors": ["1838"]}
{"title": "RedMesh: A WiFi-Direct Network Formation Algorithm for Large-Scale Scenarios\n", "abstract": " Device-to-device communication enables collaboration between mobile devices, even when no communication infrastructure is available. In this setting, WiFi-Direct emerges as a technology able to provide device-to-device communication with WiFi coverage and speed. WiFi-Direct specification only addresses communication inside small groups (typically up to 8 devices), but some solutions for inter-group communication have been proposed and, atop such solutions, automatic network formation algorithms are now appearing. However, these proposals are neither efficient for large scale scenarios, due to the use of broadcasts, nor effective, as they offer limited connectivity.In this paper we propose RedMesh, the first algorithm that creates mesh networks of off-the-shelf WiFi-Direct enabled devices, establishing connections that exclusively use unicast communication. Our algorithm proved to be very effective, achieving full connectivity in 97.28% of the 1 250 tested scenarios with up to 250 nodes, in a total of 187 500 nodes.", "num_citations": "2\n", "authors": ["1838"]}
{"title": "On the relevance of total-order broadcast implementations in replicated software transactional memories\n", "abstract": " Transactional Memory (TM), an attractive solution to support concurrent accesses to main-memory storage, is already being deployed by some of the major CPU and compiler manufacturers. To address scalability and dependability challenges, researchers are now combining replication, TM and certification-based protocols. To maintain consistency and ensure common transaction serialisation order, these protocols rely in a total-order broadcast primitive, usually provided by some Group Communication System\u00a0(GCS). The total-order broadcast service can be implemented by different algorithms, which hold different properties. In this paper we present a detailed analysis of the impact of some algorithms implementing total-order broadcast in different TM workloads, opening up future work to improve performance of replicated TMs.", "num_citations": "2\n", "authors": ["1838"]}
{"title": "Software Component Replication for Improved Fault-Tolerance: Can Multicore Processors Make It Work?\n", "abstract": " Programs increasingly rely on the use of complex component libraries, such as in-memory databases. As any other software, these libraries have bugs that may lead to the application failure. In this work we revisit the idea of software component replication for masking software bugs in the context of multi-core systems. We propose a new abstraction: a Macro-Component. A Macro-Component is a software component that includes several internal replicas with diverse implementations to detect and mask bugs. By relying on modern multicores processing capacity it is possible to execute the same operation in multiple replicas concurrently, thus incurring in minimal overhead. Also, by exploring the multiple existent implementations of well-known interfaces, it is possible to use the idea without incurring in additional development cost.", "num_citations": "2\n", "authors": ["1838"]}
{"title": "Replica\u00e7ao parcial com mem\u00f3ria transacional distribu\u0131da\n", "abstract": " Os sistemas de mem\u00f3ria transacional distribu\u0131da atuais recorrem essencialmentea distribui\u00e7ao oua replica\u00e7ao total para distribuir os seus dados pelos m\u00faltiplos n\u00f3s do sistema. No entanto, estas estrat\u00e9gias de replica\u00e7ao de dados apresentam limita\u00e7oes. A distribui\u00e7ao nao oferece toler\u00e2ncia a falhas e a replica\u00e7ao total limita a capacidade de armazenamento do sistema. Nesse contexto, a replica\u00e7ao parcial de dados surge como uma solu\u00e7ao interm\u00e9dia, que combina o melhor das duas anteriores com o intuito de mitigar as suas desvantagens. Esta estrat\u00e9gia tem sido explorada no contexto das bases de dados distribu\u0131das, mas tem sido pouco abordada no contexto da mem\u00f3ria transacional e, tanto quanto sabemos, nunca antes tinha sido incorporada num sistema de mem\u00f3ria transacional distribu\u0131da para uma linguagem de prop\u00f3sito geral. Assim, neste artigo propomos e avaliamos uma infraestrutura para replica\u00e7ao parcial de dados para programas Java bytecode, que foi desenvolvida com base num sistema j\u00e1 existente de mem\u00f3ria transacional distribu\u0131da. A modularidade da infraestrutura que apresentamos permite a implementa\u00e7ao de m\u00faltiplos algoritmos e, por conseguinte, avaliar em que contextos de utiliza\u00e7ao (workloads, n\u00famero de n\u00f3s, etc.) a replica\u00e7ao parcial se apresenta como uma alternativa vi\u00e1vel a outras estrat\u00e9gias de replica\u00e7ao de dados.", "num_citations": "2\n", "authors": ["1838"]}
{"title": "Integration of STEPS and DDBG\n", "abstract": " This report describes the work done at UNL during the visit made by Marcin Neyman, from TUG, concerning the interfacing of the STEPS tool (TUG) and the DDBG tool (UNL). The improvements made to the previously defined (TeSS) interface are explained, as well as the details on the work done in the processing of TeSS files and in the deterministic (re) execution of distributed programs.", "num_citations": "2\n", "authors": ["1838"]}
{"title": "Teaching parallel processing: development of curriculum and software tools\n", "abstract": " This paper presents an approach to education in Parallel and Distributed Processing undertaken in the Technical University of Gdansk and Technical University of Wroclaw. The paper gives a detailed structure of the project entitled\u2018Teaching Parallel Processing: Development of Curriculum and Software Tools\u2019 which was started in 1994 and will be finish in 1997. Two universities from Poland: Technical University of Gdansk and Technical University of Wroclaw and two universities from EC countries: University Autonoma of Barcelona from Spain and University Nova of Lisbon from Portugal participate in the presented project. The main aim of the project is to develop existing curricula of Computer Science specialisation and to establish specialisation concerned with parallel and distributed processing at Polish universities.", "num_citations": "2\n", "authors": ["1838"]}
{"title": "Monitoring and Debugging Support\n", "abstract": " The development of any application includes its debugging and evaluation. These are particularly complex tasks for a parallel application. The programmer has difficulties in understanding the real execution of each process and the corresponding process interactions. So, there is a need to debug sequential pieces of code using traditional debuggers and also a need to obtain some performance evaluation. Some of the tools that can help on such tasks are being developed in SEPP and HPCTI projects. They rely upon the definition of a trace file format. They also should make the debugging of sequential code easier, even on a parallel and distributed environment. First we present the current proposal for the trace file records, based on Pablo's SDDF ASCII meta-format. Next we report on the work done towards the design and implementation of a debugging supporting library for PVM, and on the development of a single user interface to control a set of traditional sequential debuggers running over...", "num_citations": "2\n", "authors": ["1838"]}
{"title": "Verifying real-world software with contracts for concurrency\n", "abstract": " In this paper we present Contracts for Concurrency. A contract for concurrency specifies the protocol to access the services provided by a software module or library. A program that respects a (well-defined and complete) contract for a module is safe from high-level atomicity violations with respect to that module. On the other hand, violations of a contract may denote errors in the program, and the application of contracts for concurrency to some real-world open source software packages did uncover a few latent bugs.", "num_citations": "1\n", "authors": ["1838"]}
{"title": "Execu\u00e7\u00e3o concorrente e determinista de transa\u00e7\u00f5es\n", "abstract": " Neste artigo apresentamos um protocolo de controlo de concorr\u00eancia que garante que a execu\u00e7\u00e3o concorrente de transa\u00e7\u00f5es \u00e9 equivalente \u00e0 sua execu\u00e7\u00e3o sequencial por uma ordem predefinida. Isto permite executar programas que usam transa\u00e7\u00f5es de forma determinista. O protocolo (1) permite, pela primeira vez, a execu\u00e7\u00e3o determinista de programas que usam mem\u00f3ria transacional por hardware; e (2) garante a execu\u00e7\u00e3o determinista de programas que usam mem\u00f3ria transacional por software com um desempenho claramente superior ao estado da arte.", "num_citations": "1\n", "authors": ["1838"]}
{"title": "On Monitoring C/C++ Transactional Memory Programs\n", "abstract": " Transactional memory (TM) is an increasingly popular technique for synchronising threads in multi-threaded programs. To address both correctness and performance-related issues of TM programs, one needs to monitor and analyse their execution. However, monitoring concurrent programs (including TM programs) may have a non-negligible impact on their behaviour, which may hamper the objectives of the intended analysis. In this paper, we propose several approaches for monitoring TM programs and study their impact on the behaviour of the monitored programs. The considered approaches range from specialised lightweight monitoring to generic heavyweight monitoring. The implemented monitoring tools are publicly available to the scientific community, and the implementation techniques used for lightweight monitoring of TM programs may be used as an inspiration for developing other specialised\u00a0\u2026", "num_citations": "1\n", "authors": ["1838"]}
{"title": "Multicore Software Engineering, Performance, and Tools: International Conference, MUSEPAT 2013, Saint Petersburg, Russia, August 19-20, 2013, Proceedings\n", "abstract": " This book constitutes the refereed proceedings of the International Conference on Multiscore Software Engineering, Performance, and Tools, MUSEPAT 2013, held in Saint Petersburg, Russia, in August 2013. The 9 revised papers were carefully reviewed and selected from 25 submissions. The accepted papers are organized into three main sessions and cover topics such as software engineering for multicore systems; specification, modeling and design; programing models, languages, compiler techniques and development tools; verification, testing, analysis, debugging and performance tuning, security testing; software maintenance and evolution; multicore software issues in scientific computing, embedded and mobile systems; energy-efficient computing as well as experience reports.", "num_citations": "1\n", "authors": ["1838"]}
{"title": "Replica\u00e7\u00e3o Multi-n\u00edvel de Bases de Dados em Mem\u00f3ria\n", "abstract": " Os servi\u00e7os Web s\u00e3o frequentemente suportados por sistemas com uma arquitetura em camadas, sendo utilizadas bases de dados relacionais para armazenamento dos dados. A replica\u00e7\u00e3o dos diversos componentes tem sido uma das formas utilizadas para obter melhorarias de escalabilidade destes servi\u00e7os. Adicionalmente, a utiliza\u00e7\u00e3o de bases de dados em mem\u00f3ria permite alcan\u00e7ar um desempenho mais elevado. No entanto \u00e9 conhecida a fraca escalabilidade das bases de dados com o n\u00famero de n\u00facleos em m\u00e1quinas multi-n\u00facleo. Neste artigo propomos uma nova abordagem para lidar com este problema, intitulada MacroDDB. Utilizando uma solu\u00e7\u00e3o de replica\u00e7\u00e3o hier\u00e1rquica, a nossa proposta, replica a base da dados em v\u00e1rios n\u00f3s, sendo que cada n\u00f3, por sua vez, executa um conjunto de r\u00e9plicas da base de dados. Esta abordagem permite assim lidar com a falta de escalabilidade das bases de dados relacionais em m\u00e1quinas multi-n\u00facleo, o que por sua vez melhora a escalabilidade geral dos servi\u00e7os.", "num_citations": "1\n", "authors": ["1838"]}
{"title": "Preven\u00e7\u00e3o de Viola\u00e7\u00f5es de Atomicidade usando Contratos\n", "abstract": " A programa\u00e7\u00e3o concorrente obriga o programador a sincronizar os acessos concorrentes a regi\u00f5es de mem\u00f3ria partilhada, contudo esta abordagem n\u00e3o \u00e9 suficiente para evitar todas as anomalias que podem ocorrer num cen\u00e1rio concorrente. Executar uma sequ\u00eancia de opera\u00e7\u00f5es at\u00f3micas pode causar viola\u00e7\u00f5es de atomicidade se existir uma correla\u00e7\u00e3o entre essas opera\u00e7\u00f5es, devendo o programador garantir que toda a sequ\u00eancia de opera\u00e7\u00f5es \u00e9 executada atomicamente. Este problema \u00e9 especialmente comum quando se usam opera\u00e7\u00f5es de pacotes ou m\u00f3dulos de terceiros, pois o programador pode identificar incorretamente o \u00e2mbito das regi\u00f5es de c\u00f3digo que precisam de ser at\u00f3micas para garantir o correto comportamento do programa. Para evitar este problema o programador do m\u00f3dulo pode criar um contrato que especifica quais as sequ\u00eancias de opera\u00e7\u00f5es do m\u00f3dulo que devem ser sempre executadas de forma at\u00f3mica. Este trabalho apresenta uma an\u00e1lise est\u00e1tica para verifica\u00e7\u00e3o destes contratos.", "num_citations": "1\n", "authors": ["1838"]}
{"title": "Hardware and Software: Verification and Testing: 7th International Haifa Verification Conference, HVC 2011, Haifa, Israel, December 6-8, 2011, Revised Selected Papers\n", "abstract": " This book constitutes the thoroughly refereed post-conference proceedings of the 7th International Haifa Verification Conference, HVC 2011, held in Haifa, Israel in December 2011. The 15 revised full papers presented together with 3 tool papers and 4 posters were carefully reviewed and selected from 43 submissions. The papers are organized in topical sections on synthesis, formal verification, software quality, testing and coverage, experience and tools, and posters-student event.", "num_citations": "1\n", "authors": ["1838"]}
{"title": "Special session on debugging\n", "abstract": " In software, hardware, and embedded system domains, debugging is the process of locating and correcting faults in a system. Depending on the context, the various characteristics of debugging induce different challenges and solutions. Post-silicon hardware debugging, for example, needs to address issues such as limited visibility and controllability, while debugging software entails other issues, such as the handling of distributed or non-deterministic computation. The challenges that accompany such issues are the focus of many current research efforts. Solutions for debugging range from interactive tools to highly analytic techniques. We have seen great advances in debugging technologies in recent years, but bugs continue to occur, and debugging still encompasses significant portions of the lifecycles of many systems. The session covered state-of-the-art approaches as well as promising new research\u00a0\u2026", "num_citations": "1\n", "authors": ["1838"]}
{"title": "Comunica\u00e7\u00e3o M\u00f3vel Inter-Grupo Baseada em TCP sobre Wi-Fi Direct\u22c6\n", "abstract": " Neste artigo explora-se a utiliza\u00e7\u00e3o de dispositivos m\u00f3veis Android, non-rooted, em cen\u00e1rios de comunica\u00e7\u00e3o dispositivo-a-dispositivo utilizando WiFi-Direct. As atuais topologias de comunica\u00e7\u00e3o inter-grupo com WiFi-Direct t\u00eam a limita\u00e7\u00e3o de requererem: a utiliza\u00e7\u00e3o de broadcasts, multicasts; ou que os n\u00f3s tenham de desfazer as liga\u00e7\u00f5es e as refazer no sentido inverso; ou um no de n\u00f3s que pode n\u00e3o estar dispon\u00edvel. Neste artigo prop\u00f5e-se duas topologias de comunica\u00e7\u00e3o exclusivamente baseadas em liga\u00e7\u00f5es TCP: que tiram partido das caracter\u00edsticas deste tipo de liga\u00e7\u00f5es; que apresentam melhor velocidade de comunica\u00e7\u00e3o; e que requerem um menor no de n\u00f3s.", "num_citations": "1\n", "authors": ["1838"]}
{"title": "Armazenamento Distribu\u00eddo para Redes de Dispositivos M\u00f3veis\n", "abstract": " Os dispositivos m\u00f3veis em proximidade geogr\u00e1fica representam um conjunto de recursos inexplorados, tanto em termos de capacidade de processamento como de armazenamento, o que abre caminho para novas aplica\u00e7\u00f5es com oportunidades e desafios \u00fanicos. Os sistemas atuais de partilha de dados (eg, fotos, m\u00fasicas, v\u00eddeos) para dispositivos m\u00f3veis exigem que exista conectividade com a Internet para funcionarem. No entanto, em ambientes onde a conectividade com a Internet n\u00e3o \u00e9 constante ou de boa qualidade (eg, eventos desportivos e concertos), ou em locais remotos onde as infraestruturas de rede n\u00e3o existem, \u00e9 dif\u00edcil (ou mesmo imposs\u00edvel) partilhar dados entre v\u00e1rios dispositivos m\u00f3veis. Para resolver este problema, os dispositivos m\u00f3veis podem formar uma rede ad hoc para compartilhar os seus dados e recursos. Neste artigo propomos um sistema de armazenamento distribu\u00eddo para partilha de dados entre dispositivos m\u00f3veis de uso di\u00e1rio, eg, smartphones e tablets, usando um mecanismo de melhor esfor\u00e7o para garantir persist\u00eancia e disponibilidade de dados suportando churn (entrada e sa\u00edda inesperada de dispositivos).", "num_citations": "1\n", "authors": ["1838"]}