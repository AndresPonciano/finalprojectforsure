{"title": "An empirical study on software defect prediction with a simplified metric set\n", "abstract": " ContextSoftware defect prediction plays a crucial role in estimating the most defect-prone components of software, and a large number of studies have pursued improving prediction accuracy within a project or across projects. However, the rules for making an appropriate decision between within- and cross-project defect prediction when available historical data are insufficient remain unclear.ObjectiveThe objective of this work is to validate the feasibility of the predictor built with a simplified metric set for software defect prediction in different scenarios, and to investigate practical guidelines for the choice of training data, classifier and metric subset of a given project.MethodFirst, based on six typical classifiers, three types of predictors using the size of software metric set were constructed in three scenarios. Then, we validated the acceptable performance of the predictor based on Top-k metrics in terms of statistical\u00a0\u2026", "num_citations": "246\n", "authors": ["1976"]}
{"title": "Towards cross-project defect prediction with imbalanced feature sets\n", "abstract": " Cross-project defect prediction (CPDP) has been deemed as an emerging technology of software quality assurance, especially in new or inactive projects, and a few improved methods have been proposed to support better defect prediction. However, the regular CPDP always assumes that the features of training and test data are all identical. Hence, very little is known about whether the method for CPDP with imbalanced feature sets (CPDP-IFS) works well. Considering the diversity of defect data sets available on the Internet as well as the high cost of labeling data, to address the issue, in this paper we proposed a simple approach according to a distribution characteristic-based instance (object class) mapping, and demonstrated the validity of our method based on three public defect data sets (i.e., PROMISE, ReLink and AEEEM). Besides, the empirical results indicate that the hybrid model composed of CPDP and CPDP-IFS does improve the prediction performance of the regular CPDP to some extent.", "num_citations": "45\n", "authors": ["1976"]}
{"title": "Service classification and recommendation based on software networks\n", "abstract": " Service classification and recommendation are two important problems in service management and composition. This paper, utilizing service composition histories, investigates the method for service classification and recommendation from a topological perspective of service-oriented software(SOS). It proposes a software network model for SOS to abstract its topological structures; it uses a community detection algorithm to cluster software networks and realizes service classification; it uses software networks to describe compositional strength between services and proposes an algorithm for service recommendation. API services and mashup applications in ProgrammableWeb are used as subjects to demonstrate the feasibility of the proposed approach. Experimental results show a high cluster purity of 86. 8%. Finally we discuss the implications of our approach on service computing.", "num_citations": "25\n", "authors": ["1976"]}
{"title": "Simplification of training data for cross-project defect prediction\n", "abstract": " Cross-project defect prediction (CPDP) plays an important role in estimating the most likely defect-prone software components, especially for new or inactive projects. To the best of our knowledge, few prior studies provide explicit guidelines on how to select suitable training data of quality from a large number of public software repositories. In this paper, we have proposed a training data simplification method for practical CPDP in consideration of multiple levels of granularity and filtering strategies for data sets. In addition, we have also provided quantitative evidence on the selection of a suitable filter in terms of defect-proneness ratio. Based on an empirical study on 34 releases of 10 open-source projects, we have elaborately compared the prediction performance of different defect predictors built with five well-known classifiers using training data simplified at different levels of granularity and with two popular filters. The results indicate that when using the multi-granularity simplification method with an appropriate filter, the prediction models based on Naive Bayes can achieve fairly good performance and outperform the benchmark method.", "num_citations": "22\n", "authors": ["1976"]}
{"title": "Applying centrality measures to the behavior analysis of developers in open source software community\n", "abstract": " In this paper, we firstly create developer networks by affiliation between projects and developers, and then, with respect to social network analysis, take an approach to empirically study the new developers' behavior and the relationship with the centrality measures. We find that most of new developers choose to cooperate with each other initially, but more collaboration are established between new developers and existing developers, and more new collaboration are developed between existing developers who have never collaborated with each other than those have collaborated before. In addition we suggest that new developers prior to cooperate with high between ness centrality or degree centrality and then closeness centrality, discuss that centrality measures can use to guide the preferential collaboration of OSS community.", "num_citations": "17\n", "authors": ["1976"]}
{"title": "An improved approach to identifying key classes in weighted software network\n", "abstract": " To help the newcomers understand a software system better during its development, the key classes are in general given priority to be focused on as soon as possible. There are numerous measures that have been proposed to identify key nodes in a network. As a metric successfully applied to evaluate the productivity of a scholar, little is known about whether -index is suitable to identify the key classes in weighted software network. In this paper, we introduced four -index variants to identify key classes on three open-source software projects (i.e., Tomcat, Ant, and JUNG) and validated the feasibility of proposed measures by comparing them with existing centrality measures. The results show that the measures proposed not only are able to identify the key classes but also perform better than some commonly used centrality measures (the improvement is at least 0.215). In addition, the finding suggests that mE-Weight defined by the weight of a node\u2019s top  edges performs best as a whole.", "num_citations": "15\n", "authors": ["1976"]}
{"title": "An improved method for cross-project defect prediction by simplifying training data\n", "abstract": " Cross-project defect prediction (CPDP) on projects with limited historical data has attracted much attention. To the best of our knowledge, however, the performance of existing approaches is usually poor, because of low quality cross-project training data. The objective of this study is to propose an improved method for CPDP by simplifying training data, labeled as TDSelector, which considers both the similarity and the number of defects that each training instance has (denoted by defects), and to demonstrate the effectiveness of the proposed method. Our work consists of three main steps. First, we constructed TDSelector in terms of a linear weighted function of instances\u2019 similarity and defects. Second, the basic defect predictor used in our experiments was built by using the Logistic Regression classification algorithm. Third, we analyzed the impacts of different combinations of similarity and the normalization of defects on prediction performance and then compared with two existing methods. We evaluated our method on 14 projects collected from two public repositories. The results suggest that the proposed TDSelector method performs, on average, better than both baseline methods, and the AUC values are increased by up to 10.6% and 4.3%, respectively. That is, the inclusion of defects is indeed helpful to select high quality training instances for CPDP. On the other hand, the combination of Euclidean distance and linear normalization is the preferred way for TDSelector. An additional experiment also shows that selecting those instances with more bugs directly as training data can further improve the performance of the bug predictor trained by\u00a0\u2026", "num_citations": "9\n", "authors": ["1976"]}
{"title": "TDSelector: A training data selection method for cross-project defect prediction\n", "abstract": " In recent years, cross-project defect prediction (CPDP) attracted much attention and has been validated as a feasible way to address the problem of local data sparsity in newly created or inactive software projects. Unfortunately, the performance of CPDP is usually poor, and low quality training data selection has been regarded as a major obstacle to achieving better prediction results. To the best of our knowledge, most of existing approaches related to this topic are only based on instance similarity. Therefore, the objective of this work is to propose an improved training data selection method for CPDP that considers both similarity and the number of defects each training instance has (denoted by defects), which is referred to as TDSelector, and to demonstrate the effectiveness of the proposed method. Our experiments were conducted on 14 projects (including 15 data sets) collected from two public repositories. The results indicate that, in a specific CPDP scenario, the TDSelector-based bug predictor performs, on average, better than those based on the baseline methods, and the AUC (area under ROC curve) values are increased by up to 10.6 and 4.3%, respectively. Besides, an additional experiment shows that selecting those instances with more bugs directly as training data can further improve the performance of the bug predictor trained by our method.", "num_citations": "8\n", "authors": ["1976"]}
{"title": "Using software dependency to bug prediction\n", "abstract": " Software maintenance, especially bug prediction, plays an important role in evaluating software quality and balancing development costs. This study attempts to use several quantitative network metrics to explore their relationships with bug prediction in terms of software dependency. Our work consists of four main steps. First, we constructed software dependency networks regarding five dependency scenes at the class-level granularity. Second, we used a set of nine representative and commonly used metrics\u2014namely, centrality, degree, PageRank, and HITS, as well as modularity\u2014to quantify the importance of each class. Third, we identified how these metrics were related to the proneness and severity of fixed bugs in Tomcat and Ant and determined the extent to which they were related. Finally, the significant metrics were considered as predictors for bug proneness and severity. The result suggests that there is a statistically significant relationship between class\u2019s importance and bug prediction. Furthermore, betweenness centrality and out-degree metric yield an impressive accuracy for bug prediction and test prioritization. The best accuracy of our prediction for bug proneness and bug severity is up to 54.7% and 66.7% (top 50, Tomcat) and 63.8% and 48.7% (top 100, Ant), respectively, within these two cases.", "num_citations": "7\n", "authors": ["1976"]}
{"title": "A hybrid approach to service recommendation based on network representation learning\n", "abstract": " Network representation learning has attracted much attention as a new learning paradigm to embed network vertices into a low-dimensional vector space, by preserving network information. In this paper, in the light of user co-tag network and social network, we introduced network representation learning techniques into the learning of user preference, to encode user social relations into a continuous vector space. First, we proposed a hybrid network representation learning approach to effectively utilize users' tagging and social relationships, and then we took it for service recommendation. The experimental results show that, compared with four baselines on two public data sets, the improvement ratio over the baselines is up to 50% in terms of Recall@10 and Precision@10 and the improvement is even more than 90% in terms of NDGG@10 and MRR@10.", "num_citations": "5\n", "authors": ["1976"]}
{"title": "Ranking the importance of classes via software structural analysis\n", "abstract": " How to identify important classes in an object-oriented system is a significant task for resources allocation and decision making. However, the work on ranking the importance of classes is scarce. This paper introduces a weighted software network model to represent the structure of object-oriented software, and based on which an indicator, IC, is defined to measure the importance of classes. By ranking the ICs of all classes we can obtain the important classes we should focus on. Manually inspection of the source code verifies the meaningfulness of the classes obtained and also validates the feasibility of our approach.", "num_citations": "5\n", "authors": ["1976"]}
{"title": "An approach to semantic and structural features learning for software defect prediction\n", "abstract": " Research on software defect prediction has achieved great success at modeling predictors. To build more accurate predictors, a number of hand-crafted features are proposed, such as static code features, process features, and social network features. Few models, however, consider the semantic and structural features of programs. Understanding the context information of source code files could explain a lot about the cause of defects in software. In this paper, we leverage representation learning for semantic and structural features generation. Specifically, we first extract token vectors of code files based on the Abstract Syntax Trees (ASTs) and then feed the token vectors into Convolutional Neural Network (CNN) to automatically learn semantic features. Meanwhile, we also construct a complex network model based on the dependencies between code files, namely, software network (SN). After that, to learn the structural features, we apply the network embedding method to the resulting SN. Finally, we build a novel software defect prediction model based on the learned semantic and structural features (SDP-S2S). We evaluated our method on 6 projects collected from public PROMISE repositories. The results suggest that the contribution of structural features extracted from software network is prominent, and when combined with semantic features, the results seem to be better. In addition, compared with the traditional hand-crafted features, the F-measure values of SDP-S2S are generally increased, with a maximum growth rate of 99.5%. We also explore the parameter sensitivity in the learning process of semantic and structural features and\u00a0\u2026", "num_citations": "4\n", "authors": ["1976"]}
{"title": "An evolution analysis of software system based on multi-granularity software network\n", "abstract": " Software as a man-made system is a typical complex system, understanding its evolution contributes to better software engineering practice. In this paper, we construct software network model from a multi-granularity perspective, namely the level of package, class and feature respectively. Then we analyze the evolutions of three open-source software systems in terms of network scale, quality and structure control indicators, using complex network theory. Finally, taking Lehman's evolution laws as the benchmarks, we compare the evolution of software networks based on multi-granularity. The results show that:(1) the evolution characteristics are varied under different granularity levels, and software network built in the level of class supports the most Lehman laws;(2) the laws of continuing growth, increasing complexity, self-regulation and conservation of familiarity are independent of the levels of granularity;(3) the impact of software evolution in the level of package on software quality is trivial, but feedback system is only supported in the case of class level.", "num_citations": "4\n", "authors": ["1976"]}
{"title": "QoS Prediction of Web Services Based on Reputation-Aware Network Embedding\n", "abstract": " As the emergence of numerous services with similar functions, it is very helpful to recommend personalized services for users, and urgent to accurately predict the QoS(Quality-of-Service) values of Web services. Collaborative Filtering (CF) is a commonly-used method to handle above issues. However, it faces two common issues: data sparsity problem and trustworthiness issue, which greatly reduces its prediction accuracy. To address this problem properly and systematically, we introduce the network embedding learning into the QoS prediction process and propose an improved QoS prediction method based on the reputation-aware network embedding learning. Firstly, a two-phase K-means clustering is adopted to filter untrustworthy users. Next, the reputation of trustworthy users is calculated, and an attributed user-service bipartite network is constructed between trustworthy users and services while considering\u00a0\u2026", "num_citations": "3\n", "authors": ["1976"]}
{"title": "Centrality analysis of the manager collaboration network in open source community\n", "abstract": " With the rapid popularity of open source development pattern for software, the relationships between managers become more and more complex. Social network analysis as a useful tool for management can be combined with complex network researches to make a better understanding of the interactions between managers. In this paper, we construct the project-manager network of the SourceForge. net community, based on which the manager collaboration network(MCN) has been derived. The degree distribution analysis of MCN shows its apparent core/periphery structure. Thus, we further analyze the node centrality by the metrics of degree centrality, betweenness centrality and topology potential centrality respectively, to explore the central figures in MCN.", "num_citations": "2\n", "authors": ["1976"]}
{"title": "Towards Understanding Developers' Collaborative Behavior in Open Source Software Ecosystems.\n", "abstract": " Understanding developers\u2019 collaborative behavior is an essential step to facilitate the needs of collaborative development activities in open-source software (OSS) ecosystem. In this paper, we conducted an empirical study to gain insight into how existing developers collaborate together and what factors affect their collaborative behavior from the perspectives of collective interaction, and attempt to explore the typical interactive modes for the corresponding types of new collaborations. The results show that different existing developers tend to prefer different collaboration patterns, and short topological distance has very limited effect on their first collaboration. By contrast, development experience seems to be important factor that affect their potential collaboration. The results also indicate that different collaboration patterns support different interactive modes, and are related to the popularity of projects. The findings are of value for existing developers to maintain sufficient collaboration awareness, so as to improve the stability and sustainability of OSS ecosystem.", "num_citations": "1\n", "authors": ["1976"]}
{"title": "A Learning Approach to the Prediction of Reliability Ranking for Web Services\n", "abstract": " Service computing is a popular development paradigm in information technology. The functional properties of Web services assure correct functionality of cloud applications, while the nonfunctional properties such as reliability might significantly influence the user-perceived availability evaluation. Reliability rankings provide valuable information for making optimal cloud service selection from a set of functionally-equivalent candidate services. There existed several approaches that can conduct reliability ranking prediction for Web services. Those approaches acquire different rankings with different preference functions. It is arduous to determine whether there exists the best one in them, and what is the best one if not. This paper proposes a learning approach to reliability ranking prediction for Web services which utilizes past service invocation logs to train preference function. To validate the proposed approach\u00a0\u2026", "num_citations": "1\n", "authors": ["1976"]}
{"title": "Detection of Article Qualities in the Chinese Wikipedia Based on C4. 5 Decision Tree\n", "abstract": " The number of articles in Wikipedia is growing rapidly. It is important for Wikipedia to provide users with high quality and reliable articles. However, the quality assessment metric provided by Wikipedia are inefficient, and other mainstream quality detection methods only focus on the qualities of the English Wikipedia articles, and usually analyze the text contents of articles, which is also a time-consuming process. In this paper, we propose a method for detecting the article qualities of the Chinese Wikipedia based on C4.5 decision tree. The problem of quality detection is transformed to classification problem of high-quality and low-quality articles. By using the fields from the tables in the Chinese Wikipedia database, we built the decision trees to distinguish high-quality articles from low-quality ones.", "num_citations": "1\n", "authors": ["1976"]}
{"title": "A Kind of Innovative Model for Construction of SaaS Service\n", "abstract": " Service (SaaS) has been increasingly recognized as a new pattern, and it will become the dominated software operation pattern in the era of cloud computing. In order to satisfy personalized customization requirements of the SaaS tenants, the paper propose a innovative SaaS architecture based O-RGPS requirement meta model.", "num_citations": "1\n", "authors": ["1976"]}