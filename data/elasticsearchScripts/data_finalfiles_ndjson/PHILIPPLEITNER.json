{"title": "Optimized IoT service placement in the fog\n", "abstract": " The Internet of Things (IoT) leads to an ever-growing presence of ubiquitous networked computing devices in public, business, and private spaces. These devices do not simply act as sensors, but feature computational, storage, and networking resources. Being located at the edge of the network, these resources can be exploited to execute IoT applications in a distributed manner. This concept is known as fog computing. While the theoretical foundations of fog computing are already established, there is a lack of resource provisioning approaches to enable the exploitation of fog-based computational resources. To resolve this shortcoming, we present a conceptual fog computing framework. Then, we model the service placement problem for IoT applications over fog resources as an optimization problem, which explicitly considers the heterogeneity of applications and resources in terms of Quality of Service\u00a0\u2026", "num_citations": "241\n", "authors": ["193"]}
{"title": "Patterns in the chaos\u2014a study of performance variation and predictability in public iaas clouds\n", "abstract": " Benchmarking the performance of public cloud providers is a common research topic. Previous work has already extensively evaluated the performance of different cloud platforms for different use cases, and under different constraints and experiment setups. In this article, we present a principled, large-scale literature review to collect and codify existing research regarding the predictability of performance in public Infrastructure-as-a-Service (IaaS) clouds. We formulate 15 hypotheses relating to the nature of performance variations in IaaS systems, to the factors of influence of performance variations, and how to compare different instance types. In a second step, we conduct extensive real-life experimentation on four cloud providers to empirically validate those hypotheses. We show that there are substantial differences between providers. Hardware heterogeneity is today less prevalent than reported in earlier\u00a0\u2026", "num_citations": "187\n", "authors": ["193"]}
{"title": "Resource provisioning for IoT services in the fog\n", "abstract": " The advent of the Internet of Things (IoT) leads to the pervasion of business and private spaces with ubiquitous, networked computing devices. These devices do not simply act as sensors, but feature computational, storage, and networking resources. These resources are close to the edge of the network, and it is a promising approach to exploit them in order to execute IoT services. This concept is known as fog computing. Despite existing theoretical foundations, the adoption of fog computing is still at its very beginning. Especially, there is a lack of approaches for the leasing and releasing of resources. To resolve this shortcoming, we present a conceptual framework for fog resource provisioning. We formalize an optimization problem which is able to take into account existing resources in fog/IoT landscapes. The goal of this optimization problem is to provide delay-sensitive utilization of available fog-based\u00a0\u2026", "num_citations": "172\n", "authors": ["193"]}
{"title": "Cost-based optimization of service compositions\n", "abstract": " For providers of composite services, preventing cases of SLA violations is crucial. Previous work has established runtime adaptation of compositions as a promising tool to achieve SLA conformance. However, to get a realistic and complete view of the decision process of service providers, the costs of adaptation need to be taken into account. In this paper, we formalize the problem of finding the optimal set of adaptations, which minimizes the total costs arising from SLA violations and the adaptations to prevent them. We present possible algorithms to solve this complex optimization problem, and detail an end-to-end system based on our earlier work on the PREvent (prediction and prevention based on event monitoring) framework, which clearly indicates the usefulness of our model. We discuss experimental results that show how the application of our approach leads to reduced costs for the service provider, and\u00a0\u2026", "num_citations": "153\n", "authors": ["193"]}
{"title": "Extraction of microservices from monolithic software architectures\n", "abstract": " Driven by developments such as mobile computing, cloud computing infrastructure, DevOps and elastic computing, the microservice architectural style has emerged as a new alternative to the monolithic style for designing large software systems. Monolithic legacy applications in industry undergo a migration to microservice-oriented architectures. A key challenge in this context is the extraction of microservices from existing monolithic code bases. While informal migration patterns and techniques exist, there is a lack of formal models and automated support tools in that area. This paper tackles that challenge by presenting a formal microservice extraction model to allow algorithmic recommendation of microservice candidates in a refactoring and migration scenario. The formal model is implemented in a web-based prototype. A performance evaluation demonstrates that the presented approach provides adequate\u00a0\u2026", "num_citations": "138\n", "authors": ["193"]}
{"title": "Winds of change: From vendor lock-in to the meta cloud\n", "abstract": " The emergence of yet more cloud offerings from a multitude of service providers calls for a meta cloud to smoothen the edges of the jagged cloud landscape. This meta cloud could solve the vendor lock-in problems that current public and hybrid cloud users face.", "num_citations": "114\n", "authors": ["193"]}
{"title": "Esc: Towards an elastic stream computing platform for the cloud\n", "abstract": " Today, most tools for processing big data are batch-oriented. However, many scenarios require continuous, online processing of data streams and events. We present ESC, a new stream computing engine. It is designed for computations with real-time demands, such as online data mining. It offers a simple programming model in which programs are specified by directed acyclic graphs (DAGs). The DAG defines the data flow of a program, vertices represent operations applied to the data. The data which are streaming through the graph are expressed as key/value pairs. ESC allows programmers to focus on the problem at hand and deals with distribution and fault tolerance. Furthermore, it is able to adapt to changing computational demands. In the cloud, ESC can dynamically attach and release machines to adjust the computational capacities to the current needs. This is crucial for stream computing since the\u00a0\u2026", "num_citations": "97\n", "authors": ["193"]}
{"title": "Cost-efficient and application SLA-aware client side request scheduling in an infrastructure-as-a-service cloud\n", "abstract": " Providers of applications deployed in an Infrastructure-as-a-Service cloud permanently face the decision of whether it is more cost-efficient to scale up(i.e., rent more resources from the cloud) or to delay incoming requests, even though doing so may lead to dissatisfied customers and broken service level agreements. This decision is further complicated by the fact that not all customers have the same agreements, and not all requests require the same amount of resources devoted to them. In this paper, we present an approach for optimally scheduling incoming requests to virtual computing resources in the cloud, so that the sum of payments for resources and loss incurred by service level agreement violations is minimized. We discuss our approach based on an illustrative use case. Furthermore, we present a numerical evaluation based on real-life request data, which shows that our agreement-aware algorithm\u00a0\u2026", "num_citations": "84\n", "authors": ["193"]}
{"title": "VieSLAF Framework: Enabling Adaptive and Versatile SLA-Management\n", "abstract": " Novel computing paradigms like Grid and Cloud computing demand guarantees on non-functional requirements such as application execution time or price. Such requirements are usually negotiated following a specific Quality of Service (QoS) model and are expressed using Service Level Agreements (SLAs). Currently available QoS models assume either that service provider and consumer have matching SLA templates and common understanding of the negotiated terms or provide public templates, which can be downloaded and utilized by the end users. On the one hand, matching SLA templates represent an unrealistic assumption in systems where service consumer and provider meet dynamically and on demand. On the other hand, handling of public templates seems to be a rather challenging issue, especially if the templates do not reflect users\u2019 needs. In this paper we present VieSLAF, a novel\u00a0\u2026", "num_citations": "80\n", "authors": ["193"]}
{"title": "A mixed-method empirical study of Function-as-a-Service software development in industrial practice\n", "abstract": " Function-as-a-Service (FaaS) describes cloud computing services that make infrastructure components transparent to application developers, thus falling in the larger group of \u201cserverless\u201d computing models. When using FaaS offerings, such as AWS Lambda, developers provide atomic and short-running code for their functions, and FaaS providers execute and horizontally scale them on-demand. Currently, there is no systematic research on how developers use serverless, what types of applications lend themselves to this model, or what architectural styles and practices FaaS-based applications are based on. We present results from a mixed-method study, combining interviews with practitioners who develop applications and systems that use FaaS, a systematic analysis of grey literature, and a Web-based survey. We find that successfully adopting FaaS requires a different mental model, where systems are\u00a0\u2026", "num_citations": "71\n", "authors": ["193"]}
{"title": "Application-level performance monitoring of cloud services based on the complex event processing paradigm\n", "abstract": " Monitoring of applications deployed to Infrastructure-as-a-Service clouds is still an open problem. In this paper, we discuss an approach based on the complex event processing paradigm, which allows application developers to specify and monitor high-level application performance metrics. We use the case of a Web 2.0 sentiment analysis application to illustrate the limitations we currently experience with regard to cloud monitoring, and show how our approach allows for more expressive definitions of monitored metrics. Furthermore, we indicate how the higher-level metrics produced by our approach can be used to increase application elasticity in an existing cloud middleware.", "num_citations": "71\n", "authors": ["193"]}
{"title": "An empirical analysis of build failures in the continuous integration workflows of java-based open-source software\n", "abstract": " Continuous Integration (CI) has become a common practice in both industrial and open-source software development. While CI has evidently improved aspects of the software development process, errors during CI builds pose a threat to development efficiency. As an increasing amount of time goes into fixing such errors, failing builds can significantly impair the development process and become very costly. We perform an indepth analysis of build failures in CI environments. Our approach links repository commits to data of corresponding CI builds. Using data from 14 open-source Java projects, we first identify 14 common error categories. Besides test failures, which are by far the most common error category (up to >80% per project), we also identify noisy build data, e.g., induced by transient Git interaction errors, or general infrastructure flakiness. Second, we analyze which factors impact the build results, taking\u00a0\u2026", "num_citations": "69\n", "authors": ["193"]}
{"title": "Data-driven and automated prediction of service level agreement violations in service compositions\n", "abstract": " Service Level Agreements (SLAs), i.e., contractually binding agreements between service providers and clients, are gaining momentum as the main discriminating factor between service implementations. For providers, SLA compliance is of utmost importance, as violations typically lead to penalty payments or reduced customer satisfaction. In this paper, we discuss approaches to predict violations a priori. This allows operators to take timely remedial actions, and prevent SLA violations before they have occurred. We discuss data-driven, statistical approaches for both, instance-level prediction (SLA compliance prediction for an ongoing business process instance) and forecasting (compliance prediction for future instances). We present an integrated framework, and numerically evaluate our approach based on a case study from the manufacturing domain.", "num_citations": "65\n", "authors": ["193"]}
{"title": "Modelling and managing deployment costs of microservice-based cloud applications\n", "abstract": " We present an approach to model the deployment costs, including compute and IO costs, of Microservice-based applications deployed to a public cloud. Our model, which we dubbed CostHat, supports both, Microservices deployed on traditional IaaS or PaaS clouds, and services that make use of novel cloud programming paradigms, such as AWS Lambda. CostHat is based on a network model, and allows for what-if and cost sensitivity analysis. Further, we have used this model to implement tooling that warns cloud developers directly in the Integrated Development Environment (IDE) about certain classes of potentially costly code changes. We illustrate our work based on a case study, and evaluate the CostHat model using a standalone Python implementation. We show that, once instantiated, cost calculation in CostHat is computationally inexpensive on standard hardware (below 1 ms even for applications\u00a0\u2026", "num_citations": "50\n", "authors": ["193"]}
{"title": "Continuous experimentation: challenges, implementation techniques, and current research\n", "abstract": " Continuous experimentation is an up-and-coming technique for requirements engineering and testing, particularly for web-based systems. On the basis of a practitioner survey, this article gives an overview of challenges, implementation techniques, and current research in the field. This article is part of a theme issue on release engineering.", "num_citations": "43\n", "authors": ["193"]}
{"title": "All the services large and micro: Revisiting industrial practice in services computing\n", "abstract": " Services computing is both an academic field of study looking back at close to 15\u00a0years of fundamental research and a vibrant area of industrial software engineering. Industrial practice in this area is notorious for its ever-changing nature, with the state of the art changing almost on a yearly basis based on the ebb and flow of various hypes and trends (e.g., microservices). In this paper, we provide a look \u201cacross the wall\u201d into industrial services computing. We conducted an empirical study based on the service ecosystem of 42 companies, and report, among other aspects, how service-to-service communication is implemented, how service discovery works in practice, what Quality-of-Service metrics practitioners are most interested in, and how services are deployed and hosted. We argue that not all assumptions that are typical in academic papers in the field are justified based on industrial practice, and\u00a0\u2026", "num_citations": "43\n", "authors": ["193"]}
{"title": "Cloudscale: a novel middleware for building transparently scaling cloud applications\n", "abstract": " With the promise of seemingly unlimited IT resources, the trend of cloud computing is currently revolutionizing software engineering. However, at the moment, building applications for the cloud is a rather cumbersome and manual task. In this paper, we introduce the CloudScale middleware for building applications on top of Infrastructure-as-a-Service (IaaS) cloud offerings. CloudScale allows developers to build cloud applications like regular Java programs, without dealing with the intricacies of cloud hosts (virtual machine) management, remoting, and code distribution, without handing off control over the physical distribution of their application to commercial Platform-as-as-Service (PaaS) providers. We numerically evaluate the overhead introduced by CloudScale based on an example application, and discuss advantages and limitations of the system as compared to manually deploying the application on an IaaS\u00a0\u2026", "num_citations": "39\n", "authors": ["193"]}
{"title": "Preventing SLA violations in service compositions using aspect-based fragment substitution\n", "abstract": " In this paper we show how the application of the aspect-oriented programming paradigm to runtime adaptation of service compositions can be used to prevent SLA violations. Adaptations are triggered by predicted violations, and are implemented as substitutions of fragments in the service composition. Fragments are full-fledged standalone compositions, and are linked into the original composition via special activities, which we refer to as virtual activities. Before substitution we evaluate fragments with respect to their expected impact on the performance of the composition, and choose those fragments which are best suited to prevent a predicted violation. We show how our approach can be implemented using Windows Workflow Foundation technology, and discuss our work based on an illustrative case study.", "num_citations": "37\n", "authors": ["193"]}
{"title": "Generic event\u2010based monitoring and adaptation methodology for heterogeneous distributed systems\n", "abstract": " The Cloud computing paradigm provides the basis for a class of platforms and applications that face novel challenges related to multi\u2010tenancy, adaptivity, and elasticity. To account for service delivery guarantees in the face of ever increasing levels of heterogeneity, scale, and dynamism, service provisioning in the Cloud has raised the demand for systematic and flexible approaches to monitoring and adaptation of applications. In this paper, we tackle this issue and present a framework for efficient runtime management of Cloud environments and distributed heterogeneous systems in general. A novel domain\u2010specific language termed MONINA is introduced that allows to define integrated monitoring and adaptation functionality for controlling such systems. We propose a mechanism for optimal deployment of the defined control operators onto available computing resources. Deployment is based on solving a\u00a0\u2026", "num_citations": "33\n", "authors": ["193"]}
{"title": "Function-as-a-service performance evaluation: A multivocal literature review\n", "abstract": " Function-as-a-Service (FaaS) is one form of the serverless cloud computing paradigm and is defined through FaaS platforms (e.g., AWS Lambda) executing event-triggered code snippets (i.e., functions). Many studies that empirically evaluate the performance of such FaaS platforms have started to appear but we are currently lacking a comprehensive understanding of the overall domain. To address this gap, we conducted a multivocal literature review (MLR) covering 112 studies from academic (51) and grey (61) literature. We find that existing work mainly studies the AWS Lambda platform and focuses on micro-benchmarks using simple functions to measure CPU speed and FaaS platform overhead (i.e., container cold starts). Further, we discover a mismatch between academic and industrial sources on tested platform configurations, find that function triggers remain insufficiently studied, and identify HTTP API\u00a0\u2026", "num_citations": "30\n", "authors": ["193"]}
{"title": "Wpress: An application-driven performance benchmark for cloud-based virtual machines\n", "abstract": " Approaching a comprehensive performance benchmark for on-line transaction processing (OLTP) applications in a cloud environment is a challenging task. Fundamental features of clouds, such as the pay-as-you-go pricing model and unknown underlying configuration of the system, are contrary to the basic assumptions of available benchmarks such as TPC-W or RUBiS. In this paper, we introduce a systematic performance benchmark approach for OLTP applications on public clouds that use virtual machines(VMs). We propose WPress benchmark, which is based on the widespread blogging software, WordPress, as a representative OLTP application and implement an open source workload generator. Furthermore, we utilize a CPU micro-benchmark to investigate CPU performance of cloud-based VMs in greater detail. Average response time and total VM cost are the performance metrics measured by WPress\u00a0\u2026", "num_citations": "30\n", "authors": ["193"]}
{"title": "Deriving a unified fault taxonomy for event-based systems\n", "abstract": " Dependability and fault-tolerance, which are key requirements for business-or safety-critical applications, require explicit knowledge of potential faults that may occur within a system. In contrast to other major research directions, the emerging field of distributed event-based systems is yet lacking a common understanding of faults. In this paper we take a step forward and study potential origins and effects of faults in such systems. Our work on a unified fault taxonomy follows a rigorous methodology. We first identify five core sub-areas in the broader field of event-based systems, and discuss commonalities and differences among them. Then we derive from the existing literature a coherent domain model, which accurately captures the specifics of the different areas. The domain model provides a holistic view and covers both structural and procedural aspects of event-based systems. Based on this model, we elaborate\u00a0\u2026", "num_citations": "30\n", "authors": ["193"]}
{"title": "Connecting fog and cloud computing\n", "abstract": " Fog computing provides a conceptual approach for virtualizing and orchestrating computing, networking, and storage resources to process data. This issue helps toprogress the fog computing research field and offer solutions. It is clear that we are still in the formative phase of fog computing, and only the future will reveal which parts of the (sometimes competing) visions, solution proposals, and application areas will prove to be of most value to society and industry. However, as the four papers in this special issue show, the opportunities, as well as the challenges, are manifold. Some of these challenges can be addressed by adapting solutions that have proven their value before, such as the contributions on load balancing, scheduling, and NFV in this special issue.", "num_citations": "29\n", "authors": ["193"]}
{"title": "Bursting with Possibilities--An Empirical Study of Credit-Based Bursting Cloud Instance Types\n", "abstract": " We study the performance and cost efficiency as perceived by the end user of a specific class of Infrastructure-as-a-Service (IaaS) cloud instances, namely credit-based bursting instances. This class of instance types has been introduced by Amazon EC2 in summer 2014, and behaves on a fundamental level differently than any other existing instance type, either from EC2 or other vendors. We introduce a basic formal model for fostering the understanding and analysis of these types, and empirically study their performance in practice. Further, we compare the performance of credit-based bursting cloud instance types to existing general-purpose types, and derive potential use cases for practitioners. Our results indicate that bursting instance types are cost-efficient for CPU-bound applications with an average utilization of less than 40%, as well as for non-critical IO-bound applications. Finally, we also discuss a simple\u00a0\u2026", "num_citations": "28\n", "authors": ["193"]}
{"title": "JCloudScale: closing the gap between IaaS and PaaS\n", "abstract": " Building Infrastructure-as-a-Service (IaaS) applications today is a complex, repetitive, and error-prone endeavor, as IaaS does not provide abstractions on top of virtual machines. This article presents JCloudScale, a Java-based middleware for moving elastic applications to IaaS clouds, with minimal adjustments to the application code. We discuss the architecture and technical features, as well as evaluate our system with regard to user acceptance and performance overhead. Our user study reveals that JCloudScale allows many participants to build IaaS applications more efficiently, compared to industrial Platform-as-a-Service (PaaS) solutions. Additionally, unlike PaaS, JCloudScale does not lead to a control loss and vendor lock-in.", "num_citations": "27\n", "authors": ["193"]}
{"title": "Current and future bots in software development\n", "abstract": " Bots that support software development (\"DevBots\") are seen as a promising approach to deal with the ever-increasing complexity of modern software engineering and development. Existing DevBots are already able to relieve developers from routine tasks such as building project images or keeping dependencies up-to-date. However, advances in machine learning and artificial intelligence hold the promise of future, significantly more advanced, DevBots. In this paper, we introduce the terminology of contemporary and ideal DevBots. Contemporary DevBots represent the current state of practice, which we characterise using a facet-based taxonomy. We exemplify this taxonomy using 11 existing, industrial-strength bots. We further provide a vision and definition of future (ideal) DevBots, which are not only autonomous, but also adaptive, as well as technically and socially competent. These properties may allow ideal\u00a0\u2026", "num_citations": "24\n", "authors": ["193"]}
{"title": "Estimating cloud application performance based on micro-benchmark profiling\n", "abstract": " The continuing growth of the cloud computing market has led to an unprecedented diversity of cloud services. To support service selection, micro-benchmarks are commonly used to identify the best performing cloud service. However, it remains unclear how relevant these synthetic micro-benchmarks are for gaining insights into the performance of real-world applications. Therefore, this paper develops a cloud benchmarking methodology that uses micro-benchmarks to profile applications and subsequently predicts how an application performs on a wide range of cloud services. A study with a real cloud provider (Amazon EC2) has been conducted to quantitatively evaluate the estimation model with 38 metrics from 23 micro-benchmarks and 2 applications from different domains. The results reveal remarkably low variability in cloud service performance and show that selected micro-benchmarks can estimate the\u00a0\u2026", "num_citations": "24\n", "authors": ["193"]}
{"title": "Design by units: Abstractions for human and compute resources for elastic systems\n", "abstract": " Units make the usage and properties of diverse resources, including infrastructure and human resources, explicit early in system design, and allow for reasoning about complex system qualities, such as elasticity. They advance the measurability and management of systems whose quality depends largely on the resources that the system uses.", "num_citations": "22\n", "authors": ["193"]}
{"title": "Testing of data\u2010centric and event\u2010based dynamic service compositions\n", "abstract": " This paper addresses integration testing of data\u2010centric and event\u2010based dynamic service compositions. The compositions under test define abstract services that are replaced by concrete candidate services at runtime. Testing all possible instantiations of a composition leads to combinatorial explosion and is often infeasible. We consider data dependencies between services as potential points of failure and introduce the k\u2010node data flow test coverage metric, which helps to significantly reduce the number of test combinations. We formulate a combinatorial optimization problem for generating minimal sets of test cases. On the basis of this formalization, we present a mapping to the model of FoCuS, a coverage analysis tool. FoCuS efficiently computes near\u2010optimal solutions, which are used to automatically generate test instances. The proposed approach is applicable to various composition paradigms. We\u00a0\u2026", "num_citations": "21\n", "authors": ["193"]}
{"title": "Ws-aggregation: distributed aggregation of web services data\n", "abstract": " Recent trends of Web-based data processing (eg, service mashups, Data-as-a-Service) call for techniques to collect and process heterogeneous data from distributed sources in a uniform way. In this paper we present WS-Aggregation, a general purpose framework for aggregation of data exposed as Web services. WS-Aggregation provides clients with a single-site interface to execute multi-site queries. The framework autonomously collects and processes the requested data using a set of cooperative aggregator nodes. The query distribution is configurable using strategies, eg, QoS-based or location-based. We introduce WAQL as a specialized query language for Web service data aggregation that is based on XQuery. 3-way querying is a possibility to optimize requests by reducing the amount of data transferred between aggregator nodes. A Web-based graphical user interface facilitates composing aggregation\u00a0\u2026", "num_citations": "21\n", "authors": ["193"]}
{"title": "Test coverage of data-centric dynamic compositions in service-based systems\n", "abstract": " This paper addresses the problem of integration testing of data-centric dynamic compositions in service-based systems. These compositions define abstract services, which are replaced by invocations to concrete candidate services at runtime. Testing all possible runtime instances of a composition is often unfeasible. We regard data dependencies between services as potential points of failure, and introduce the k-node data flow test coverage metric. Limiting the level of desired coverage helps to significantly reduce the search space of service combinations. We formulate the problem of generating a minimum set of test cases as a combinatorial optimization problem. Based on the formalization we present a mapping of the problem to the data model of FoCuS, a coverage analysis tool developed at IBM. FoCuS can efficiently compute near-optimal solutions, which we then use to automatically generate and execute\u00a0\u2026", "num_citations": "20\n", "authors": ["193"]}
{"title": "A framework and middleware for application-level cloud bursting on top of infrastructure-as-a-service clouds\n", "abstract": " A core idea of cloud computing is elasticity, i.e., enabling applications to adapt to varying load by dynamically acquiring and releasing cloud resources. One concrete realization is cloud bursting, which is the migration of applications or parts of applications running in a private cloud to a public cloud to cover load spikes. Actually building a cloud bursting enabled application is not trivial. In this paper, we introduce a reference model and middleware realization for Cloud bursting, thus enabling elastic applications to run across the boundaries of different Cloud infrastructures. In particular, we extend our previous work on application-level elasticity in single clouds to multiple clouds, and apply it to implement an hybrid cloud model that combines good utilization of a private cloud with the unlimited scalability of a public cloud. By means of an experimental evaluation we show the feasibility of the approach and the benefits\u00a0\u2026", "num_citations": "19\n", "authors": ["193"]}
{"title": "Dynamic migration of processing elements for optimized query execution in event-based systems\n", "abstract": " This paper proposes a method for optimized placement of query processing elements in a distributed stream processing platform consisting of several computing nodes. We focus on the case that multiple users run different continuous Complex Event Processing (CEP) queries over various event streams. In times of increasing event frequency it may be required to migrate parts of the query processing elements to a new node. Our approach achieves a tradeoff between three dimensions: balancing the load among nodes, avoiding duplicate buffering of events, and minimizing the data transfer between nodes. Thereby, we also take one-time costs for migration of event buffers into account. We provide a detailed problem description, present a solution based on metaheuristic optimization, and evaluate different aspects of the problem in a Cloud Computing environment.", "num_citations": "19\n", "authors": ["193"]}
{"title": "What's wrong with my benchmark results? studying bad practices in JMH benchmarks\n", "abstract": " Microbenchmarking frameworks, such as Java's Microbenchmark Harness (JMH), allow developers to write fine-grained performance test suites at the method or statement level. However, due to the complexities of the Java Virtual Machine, developers often struggle with writing expressive JMH benchmarks which accurately represent the performance of such methods or statements. In this paper, we empirically study bad practices of JMH benchmarks. We present a tool that leverages static analysis to identify 5 bad JMH practices. Our empirical study of 123 open source Java-based systems shows that each of these 5 bad practices are prevalent in open source software. Further, we conduct several experiments to quantify the impact of each bad practice in multiple case studies, and find that bad practices often significantly impact the benchmark results. To validate our experimental results, we constructed patches\u00a0\u2026", "num_citations": "18\n", "authors": ["193"]}
{"title": "An approach and case study of cloud instance type selection for multi-tier web applications\n", "abstract": " A challenging problem for users of Infrastructure-as-a-Service (IaaS) clouds is selecting cloud providers, regions, and instance types cost-optimally for a given desired service level. Issues such as hardware heterogeneity, contention, and virtual machine (VM) placement can result in considerably differing performance across supposedly equivalent cloud resources. Existing research on cloud benchmarking helps, but often the focus is on providing low-level microbenchmarks (e.g., CPU or network speed), which are hard to map to concrete business metrics of enterprise cloud applications, such as request throughput of a multi-tier Web application. In this paper, we propose Okta, a general approach for fairly and comprehensively benchmarking the performance and cost of a multi-tier Web application hosted in an IaaS cloud. We exemplify our approach for a case study based on the two-tier AcmeAir application, which\u00a0\u2026", "num_citations": "16\n", "authors": ["193"]}
{"title": "Model-based Adaptation of Cloud Computing Applications.\n", "abstract": " In this paper we propose a provider-managed, model-based adaptation approach for cloud computing applications, allowing customers to easily specify application behavior goals or adaptation rules. Delegating control over corrective actions to the cloud provider will pose advantages for both, customers and providers. Customers are relieved of effort and expertise requirements necessary to build sophisticated adaptation solutions, while providers can incorporate and analyze data from a multitude of customers to improve adaptation decisions. The envisioned approach will enable increased application performance, as well as cost savings for customers, whereas providers can manage their infrastructure more efficiently.", "num_citations": "16\n", "authors": ["193"]}
{"title": "Identifying root causes of web performance degradation using changepoint analysis\n", "abstract": " The large scale of the Internet has offered unique economic opportunities, that in turn introduce overwhelming challenges for development and operations to provide reliable and fast services in order to meet the high demands on the performance of online services. In this paper, we investigate how performance engineers can identify three different classes of externally-visible performance problems (global delays, partial delays, periodic delays) from concrete traces. We develop a simulation model based on a taxonomy of root causes in server performance degradation. Within an experimental setup, we obtain results through synthetic monitoring of a target Web service, and observe changes in Web performance over time through exploratory visual analysis and changepoint detection. Finally, we interpret our findings and discuss various challenges and pitfalls.", "num_citations": "14\n", "authors": ["193"]}
{"title": "Fault management based on peer-to-peer paradigms; a case study report from the celtic project madeira\n", "abstract": " We present an approach to fault management based on an architecture for distributed and collaborative network management as developed in the CELTIC project Madeira. It uses peer-to-peer communication facilities and a logical overlay network facilitating decentralized and iterative alarm processing and correlation. We argue that such an approach might help to overcome key challenges that are posed by NGN scenarios to traditional centralized network management systems. Its feasibility is demonstrated by means of a case study from the area of wireless mesh networks, where an application prototype has been developed.", "num_citations": "14\n", "authors": ["193"]}
{"title": "Cloud futurology\n", "abstract": " The cloud has become integral to most Internet-based applications and user gadgets. This article provides a brief history of the cloud and presents a researcher's view of the prospects for innovating at the infrastructure, middleware, and applications and delivery levels of the already crowded cloud computing stack.", "num_citations": "13\n", "authors": ["193"]}
{"title": "A cloud benchmark suite combining micro and applications benchmarks\n", "abstract": " Micro and application performance benchmarks are commonly used to guide cloud service selection. However, they are often considered in isolation in a hardly reproducible setup with a flawed execution strategy. This paper presents a new execution methodology that combines micro and application benchmarks into a benchmark suite called RMIT Combined, integrates this suite into an automated cloud benchmarking environment, and implements a repeatable execution strategy. Additionally, a newly crafted Web serving benchmark called WPBench with three different load scenarios is contributed. A case study in the Amazon EC2 cloud demonstrates that choosing a cost-efficient instance type can deliver up to 40% better performance with 40% lower costs at the same time for the Web serving benchmark WPBench. Contrary to prior research, our findings reveal that network performance does not vary relevantly\u00a0\u2026", "num_citations": "11\n", "authors": ["193"]}
{"title": "SPEEDL-A declarative event-based language to define the scaling behavior of cloud applications\n", "abstract": " Contemporary cloud providers offer out-of-the-box auto-scaling solutions. However, defining a non-trivial scaling behavior that goes beyond the feature set provided by existing solutions is still challenging. In this paper we present SPEEDL, a declarative and extensible domain-specific language that simplifies the creation of elastic scaling behavior on top of IaaS clouds. SPEEDL simplifies the creation of event-driven policies for resource management (How many resources, and what resource types, are needed?), as well as task mapping (Which tasks should be handled by which resources?). Based on a dataset of real-life scaling policies, we demonstrate that SPEEDL can cover most scaling behaviors real-life developers want to express, and that the resulting SPEEDL policies are at the same time substantially more compact, easier to read, and less error-prone than the same behavior expressed via a general\u00a0\u2026", "num_citations": "11\n", "authors": ["193"]}
{"title": "Identifying web performance degradations through synthetic and real-user monitoring\n", "abstract": " The large scale of the Internet has offered unique economic opportunities, that in turn introduce overwhelming challenges for development and operations to provide reliable and fast services in order to meet the high demands on the performance of online services. In this paper, we investigate how performance engineers can identify three different classes of externally-visible performance problems (global delays, partial delays, periodic delays) from concrete traces. We develop a simulation model based on a taxonomy of root causes in server performance degradation. Within an experimental setup, we obtain results through synthetic monitoring of a targetWeb service, and observe changes inWeb performance over time through exploratory visual analysis and changepoint detection. We extend our analysis and apply our methods to real-user monitoring (RUM) data. In a use case study, we discuss how our underlying model can be applied to real performance data gathered from a multinational, high-traffic website in the financial sector. Finally, we interpret our findings and discuss various challenges and pitfalls.", "num_citations": "11\n", "authors": ["193"]}
{"title": "Ensuring cost-optimal sla conformance for composite service providers\n", "abstract": " For providers of composite services, service level agreements (SLAs) provide a means to guarantee a certain service quality to prospective customers. Usually, violating SLAs is associated with costs. However, the means necessary to ensure SLA conformance also generate costs. Oftentimes, it is therefore optimal from a business perspective to violate certain SLAs sometimes, instead of trying for the high (and expensive) road of always satisfying each one. In this paper we will sketch a framework for the prediction of SLA violations and for determining whether an adaptation of the process makes sense economically. If this is the case adaptation actions are triggered, which adapt the composition on either on instance, structural or environmental level. The ultimate goal is to implement a closed-loop system, which self-optimizes the costs resulting from SLA violations.", "num_citations": "11\n", "authors": ["193"]}
{"title": "Profiling-based task scheduling for factory-worker applications in infrastructure-as-a-service clouds\n", "abstract": " With the recent advances of cloud computing, effective resource usage (e.g., CPU, memory or network) becomes an important question as application developers have to continuously pay for rented resources, even if they are not used effectively. In order to maintain required performance levels, it is currently common to reserve resources for peak resource usage or possible resource usage overlaps, if more than one task is executed on a host. While this is a reasonable approach for long-running applications or web servers, for some applications with disperse resource usage over time, this strategy causes significant over-provisioning and thus resource wastage and financial loss. In this paper we present a profiling-based task scheduling approach for factory-worker applications that schedules tasks within the defined resource limitations (e.g., Existing machine memory size or network quota) and distributes the tasks\u00a0\u2026", "num_citations": "10\n", "authors": ["193"]}
{"title": "A note on software tools and techniques for monitoring and prediction of cloud services\n", "abstract": " Cloud computing is the latest computing paradigm that transparently delivers Information and Communication Technology resources as services, freeing the users of Cloud applications from dealing with low-level implementation and system administration details. Cloud provides the promise of on-demand access to affordable large-scale computing (eg, multi-core CPUs, GPUs, and clusters of GPUs), storage (such as disks), and software (eg, databases, application servers, and data processing frameworks) resources without substantial up-front investment. Cloud resources are hosted in large datacenters, often referred to as virtualized data farms, operated by companies such as Amazon, Apple, GoGrid, and Microsoft. While the growing ubiquity of Cloud computing is having a significant impact in many applications domains, there are still significant problems that exist with regard to efficient provisioning and\u00a0\u2026", "num_citations": "10\n", "authors": ["193"]}
{"title": "Non-intrusive policy optimization for dependable and adaptive service-oriented systems\n", "abstract": " The Service-Oriented Architecture paradigm facilitates the creation of distributed, composite applications. Services are usually simple to integrate, but often encapsulate complex and dynamic business logic with multiple variations and configurations. The fact that these services typically execute in a dynamic, unpredictable environment additionally complicates manageability and calls for adaptable management strategies. Current system control strategies mostly rely on static approaches, such as predefined policies. In this paper we propose a novel technique to improve management policies for complex service-based systems during runtime. This allows systems to adapt to changing environments, to circumvent unforeseen events and errors, and to resolve incompatibilities of composed services. Our approach requires no knowledge about the internals of services or service platforms, but analyzes log output to\u00a0\u2026", "num_citations": "10\n", "authors": ["193"]}
{"title": "State of the art and research challenges in the area of autonomous control for a reliable internet of services\n", "abstract": " The explosive growth of the Internet has fundamentally changed the global society. The emergence of concepts like service-oriented architecture (SOA), Software as a Service (SaaS), Platform as a Service (PaaS), Infrastructure as a Service (IaaS), Network as a Service (NaaS) and Cloud Computing in general has catalyzed the migration from the information-oriented Internet into an Internet of Services (IoS). This has opened up virtually unbounded possibilities for the creation of new and innovative services that facilitate business processes and improve the quality of life. However, this also calls for new approaches to ensuring quality and reliability of these services. The goal of this book chapter is to first analyze the state-of-the-art in the area of autonomous control for a reliable IoS and then to identify the main research challenges within it. A general background and high-level description of the current state of knowledge is presented. Then, for each of the three subareas, namely the autonomous management and real-time control, methods and tools for monitoring and service prediction, and smart pricing and competition in multi-domain systems, a brief general introduction and background are presented, and a list of key research challenges is formulated.", "num_citations": "8\n", "authors": ["193"]}
{"title": "Speedl-a declarative event-based language for cloud scaling definition\n", "abstract": " Contemporary cloud providers offer out-of-the-box auto-scaling solutions. However, defining a non-trivial scaling behavior that goes beyond the feature set provided by existing solutions is still challenging. In this paper we present SPEEDL, a declarative and extensible domain-specific language that simplifies the creation of elastic scaling behavior on top of IaaS clouds. SPEEDL simplifies the creation of event-driven policies for resource management (How many resources, and what resource types, are needed?), as well as task mapping (Which tasks should be handled by which resources?). Based on a dataset of real-life scaling policies, we demonstrate that SPEEDL can cover most scaling behaviors real-life developers want to express, and that the resulting SPEEDL policies are at the same time substantially more compact, easier to read, and less error-prone than the same behavior expressed via a general-purpose programming language.", "num_citations": "8\n", "authors": ["193"]}
{"title": "An empirical study of bots in software development: Characteristics and challenges from a practitioner\u2019s perspective\n", "abstract": " Software engineering bots\u2013automated tools that handle tedious tasks\u2013are increasingly used by industrial and open source projects to improve developer productivity. Current research in this area is held back by a lack of consensus of what software engineering bots (DevBots) actually are, what characteristics distinguish them from other tools, and what benefits and challenges are associated with DevBot usage. In this paper we report on a mixed-method empirical study of DevBot usage in industrial practice. We report on findings from interviewing 21 and surveying a total of 111 developers. We identify three different personas among DevBot users (focusing on autonomy, chat interfaces, and \u201csmartness\u201d), each with different definitions of what a DevBot is, why developers use them, and what they struggle with. We conclude that future DevBot research should situate their work within our framework, to clearly identify\u00a0\u2026", "num_citations": "7\n", "authors": ["193"]}
{"title": "Performance testing in the cloud. how bad is it really?\n", "abstract": " Rigorous performance engineering traditionally assumes measuring on bare-metal environments to control for as many confounding factors as possible. Unfortunately, some researchers and practitioners might not have access, knowledge, or funds to operate dedicated performance testing hardware, making public clouds an attractive alternative. However, cloud environments are inherently unpredictable and variable with respect to their performance. In this study, we explore the effects of cloud environments on the variability of performance testing outcomes, and to what extent regressions can still be reliably detected. We focus on software microbenchmarks as an example of performance tests, and execute extensive experiments on three different cloud services (AWS, GCE, and Azure) and for different types of instances. We also compare the results to a hosted bare-metal offering from IBM Bluemix. In total, we gathered more than 5 million unique microbenchmarking data points from benchmarks written in Java and Go. We find that the variability of results differs substantially between benchmarks and instance types (from 0.03% to > 100% relative standard deviation). We also observe that testing using Wilcoxon rank-sum generally leads to unsatisfying results for detecting regressions due to a very high number of false positives in all tested configurations. However, simply testing for a difference in medians can be employed with good success to detect even small differences. In some cases, a difference as low as a 1% shift in median execution time can be found with a low false positive rate given a large sample size of 20 instances.", "num_citations": "7\n", "authors": ["193"]}
{"title": "WPress: Benchmarking infrastructure-as-a-service cloud computing systems for on-line transaction processing applications\n", "abstract": " Approaching a comprehensive performance benchmark for on-line transaction processing (OLTP) applications in a cloud environment is a challenging task. Fundamental features of clouds, such as the pay-as-you-go pricing model and unknown underlying configuration of the system, are contrary to the basic assumptions of available benchmarks such as TPC-W or RUBiS. In this paper, we introduce a systematic performance benchmark approach for OLTP applications on public clouds that use virtual machines (VMs). We propose WPress benchmark, which is based on the widespread blogging software, WordPress, as a representative OLTP application and implement an open source workload generator. Furthermore, we utilize a CPU microbenchmark to investigate CPU performance of cloud-based VMs in greater detail. Average response time and total VM cost are the performance metrics measured by WPress. We evaluate small and large instance types of three real-life cloud providers, Amazon EC2, Microsoft Azure and Rackspace cloud. Results imply that Rackspace cloud has better average response times and total VM cost on small instances. However, Microsoft Azure is preferable for large instance type.", "num_citations": "7\n", "authors": ["193"]}
{"title": "Cost-based prevention of violations of service level agreements in composed services using self-adaptation\n", "abstract": " Providers of composite Web services face the challenge of having to comply to SLAs, which are agreements governing the minimum performance that customers can expect from a composite service. In this work, a framework for optimizing adaptations of service compositions with regards to SLA violations has been developed. The framework, dubbed PREvent (Prediction and Prevention of SLA Violations Based on Events), uses techniques from the areas of machine learning and heuristic optimization to construct models for prediction of SLA violations at runtime, and to decide which adaptation actions may be used to improve overall performance in a composition instance. An optimizer component decides, whether applying these changes makes sense economically (i.e., whether the costs of violating the SLAs are bigger than the adaptation costs). If this is the case, the respective actions are applied in an\u00a0\u2026", "num_citations": "7\n", "authors": ["193"]}
{"title": "Stepwise and asynchronous runtime optimization of web service compositions\n", "abstract": " Existing research work considers runtime adaptation of service compositions as a viable tool to prevent violations of service level agreements. In previous work we have formalized the optimization problem of identifying the most suitable adaptations to prevent a predicted set of violations, and presented suitable algorithms to solve this problem. Here, we introduce the idea of stepwise optimization as a solution to the problem of how to deal with situations when the optimization result is not available in time, i.e., when decisions need to be taken before the optimization problem can be fully solved.", "num_citations": "7\n", "authors": ["193"]}
{"title": "Distributed continuous queries over web service event streams\n", "abstract": " Complex Event Processing over Web service event streams poses huge challenges with regard to efficient, scalable execution as well as expressive models and languages that account for the dynamics in long-running queries. We present a distributed query platform that tackles these problems. Our novel query model permits to specify inputs that provide data for other inputs and need to be processed first. An XQuery language extension lets users easily express such dependencies, which are then continuously resolved with the required data at runtime. Query specifications are abstracted from physical deployment, allowing the platform to distribute the execution and to elastically scale up and down. We evaluate several aspects of our prototype in a Cloud computing environment.", "num_citations": "6\n", "authors": ["193"]}
{"title": "A step-by-step debugging technique to facilitate mashup development and maintenance\n", "abstract": " With Web mashups, data from different Web documents and services are\" mashed\" together to create a new functionality. The mashup developer usually has a clear vision of the desired output, ie, the resulting Web page to present to the end user. Complex mashups require multiple processing steps, and become hard to debug if the delivered result is not as expected. In this paper we propose an approach that supports step-by-step debugging for declarative development of data mashups. A dependency graph is constructed from the mashup definition, and developers are able to define breakpoints to inspect a snapshot of the running mashup execution. A Web 2.0 application visualizes the intermediate results in each processing step. On top of that, it is possible to specify expected and unexpected result elements. If the result does not comply with the specifications, the platform helps to identify the processing step\u00a0\u2026", "num_citations": "6\n", "authors": ["193"]}
{"title": "Performance Benchmarking of Infrastructure-as-a-Service (IaaS) Clouds with Cloud WorkBench\n", "abstract": " The continuing growth of the cloud computing market has led to an unprecedented diversity of cloud services with different performance characteristics. To support service selection, researchers and practitioners conduct cloud performance benchmarking by measuring and objectively comparing the performance of different providers and configurations (eg, instance types in different data center regions). In this tutorial, we demonstrate how to write performance tests for IaaS clouds using the Web-based benchmarking tool Cloud WorkBench (CWB). We will motivate and introduce benchmarking of IaaS cloud in general, demonstrate the execution of a simple benchmark in a public cloud environment, summarize the CWB tool architecture, and interactively develop and deploy a more advanced benchmark together with the participants.", "num_citations": "5\n", "authors": ["193"]}
{"title": "Dynamic program code distribution in infrastructure-as-a-service clouds\n", "abstract": " Elastically scaling cloud computing applications are becoming more and more prevalent in today's IT landscapes. One problem of building such applications in an Infrastructure-as-a-Service cloud is the runtime distribution of program code, configuration files and other resources. While it is possible to include all required program code in the used IaaS base images, this severely restricts the achievable dynamicity at runtime. In this paper, we present a framework for dynamic program code distribution. Our approach handles code distribution entirely transparently on middleware layer. We base our solution on an existing middleware, CloudScale. The paper discusses the design and implementation of our code distribution approach on top of CloudScale, and numerically evaluates the practicability and performance of the approach based on an illustrative case study.", "num_citations": "5\n", "authors": ["193"]}
{"title": "Identifying incompatible service implementations using pooled decision trees\n", "abstract": " We study fault localization techniques for identification of incompatible configurations and implementations in service-based applications (SBAs). Practice has shown that standardized interfaces alone do not guarantee compatibility of services originating from different partners. Hence, dynamic runtime instantiations of such SBAs pose a great challenge to reliability and dependability. The aim of this work is to monitor and analyze successful and faulty executions in SBAs, in order to detect incompatible configurations at runtime. We propose an approach using pooled decision trees for localization of faulty service parameter and binding configurations, explicitly addressing transient and changing fault conditions. The presented fault localization technique works on a per-request basis and is able to take individual service inputs into account. Considering not only the service configuration but also the service input data\u00a0\u2026", "num_citations": "5\n", "authors": ["193"]}
{"title": "Search-based scheduling of experiments in continuous deployment\n", "abstract": " Continuous experimentation involves practices for testing new functionality on a small fraction of the user base in production environments. Running multiple experiments in parallel requires handling user assignments (i.e., which users are part of which experiments) carefully as experiments might overlap and influence each other. Furthermore, experiments are prone to change, get canceled, or are adjusted and restarted, and new ones are added regularly. We formulate this as an optimization problem, fostering the parallel execution of experiments and making sure that enough data is collected for every experiment avoiding overlapping experiments. We propose a genetic algorithm that is capable of (re-)scheduling experiments and compare with other search-based approaches (random sampling, local search, and simulated annealing). Our evaluation shows that our genetic implementation outperforms the other\u00a0\u2026", "num_citations": "4\n", "authors": ["193"]}
{"title": "Towards identifying root causes of faults in service-based applications\n", "abstract": " In this paper we study fault localization techniques for identification of incompatible configurations and implementations in service-based applications. We propose an approach using pooled decision trees for localization of faulty service parameter and binding configurations, explicitly addressing temporary and changing fault conditions.", "num_citations": "4\n", "authors": ["193"]}
{"title": "SEPL\u2014a domain-specific language and execution environment for protocols of stateful Web services\n", "abstract": " In order to interact with stateful Web services, clients need to obtain information about the intra-service protocol, which contains valid operation sequences and the expected input-output transformation across invocations. While the community has widely agreed on WSDL as the standard for functional service description (the \u201cstatic\u201d service interface), there is still an evident lack of languages to describe the dynamic, behavioral interface of services. In this paper we introduce SEPL (SErvice Protocol Language), a domain-specific language (DSL) for defining executable intra-service protocols. Notable features of the DSL include support for WS-Addressing and simple creation of new Web service instances, synchronous and asynchronous service invocation facilities and easy access to WSRF-style service resource properties. Service providers use SEPL to define the procedure that clients must adhere to in\u00a0\u2026", "num_citations": "4\n", "authors": ["193"]}
{"title": "Securing the Madeira network management system\n", "abstract": " In the research project Madeira a meshed network management system based on P2P technologies was developed. Event though, up to date, security has always been neglected in this field of research despite the sensitivity of such systems and the high number of security threats that affect them, Madeira incorporates a security solution aimed at minimizing the identified highest-priority risks on all levels. This solution introduces a distributed certification authority based on threshold cryptography, certificate revocation list distribution points and a collaborative accusation protocol aimed at uncovering hosts that exhibit illegal or unwanted behaviour while avoiding false accusations from a malicious node.", "num_citations": "4\n", "authors": ["193"]}
{"title": "Fault Management based on peer-to-peer paradigms\n", "abstract": " We present an approach to fault management based on an architecture for distributed and collaborative network management as developed in the CELTIC project Madeira. It uses peer-to-peer communication facilities and a logical overlay network facilitating decentralized and iterative alarm processing and correlation. We argue that such an approach might help to overcome key challenges that are posed by NGN scenarios to traditional centralized network management systems. Its feasibility is demonstrated by means of a case study from the area of wireless mesh networks, where an application prototype has been developed.", "num_citations": "4\n", "authors": ["193"]}
{"title": "Modelling behaviour and distribution for the management of next generation networks\n", "abstract": " Current network management systems have been impeded by a scarcity of open standards for interoperable management solutions. Information models have made progress in promoting interoperability of traditional \u201ccentralised\u201d networks but have still to significantly address the proliferation of next generation networks such as autonomic networks. Such networks impose challenges which include distributed self-control and self-management. The goal of the Madeira project was to utilise novel technologies and methodologies, based on an underlying P2P paradigm, for a logically meshed, distributed Network Management System (NMS) that facilitates dynamic behaviour of transient network elements. In this paper, we describe a solution for a meta-model that attempts to capture the key concepts behind the task of network management of a mesh network. A case-study focusing on the fault management of\u00a0\u2026", "num_citations": "4\n", "authors": ["193"]}
{"title": "Advances in Service-Oriented and Cloud Computing: Workshops of ESOCC 2015, Taormina, Italy, September 15-17, 2015, Revised Selected Papers\n", "abstract": " This volume contains the technical papers presented in the seven high-quality workshops associated with the European Conference on Service-Oriented and Cloud Computing, ESOCC 2015, held in Taormina, Italy, in September 2015: Third International Workshop on Cloud for IoT (CLloT 2015), 5th International Workshop on Adaptive Services for the Future Internet (WAS4FI 2015), Second Workshop on Seamless Adaptive Multi-cloud Management of Service-Based Applications (SeaClouds 2015), First International Workshop on Cloud Adoption and Migration (CloudWay 2015), First International Workshop on Digital Enterprise Architecture and Engineering (IDEA 2015), First Workshop on Federated Cloud Networking (FedCloudNet 2015). Abstracts of the presentations held at the European Projects Forum (EU Projects 2015) are included in the back matter of this volume. The 25 full papers and 6 short papers were carefully reviewed and selected from 48 submissions. They focus on specific topics in service-oriented and cloud computing domains such as limits and/or advantages of existing cloud solutions, Future Internet technologies, efficient and adaptive deployment and management of service-based applications across multiple clouds, novel cloud service migration practices and solutions, digitization of enterprises in the cloud computing era, federated cloud networking services.", "num_citations": "3\n", "authors": ["193"]}
{"title": "On preventing violations of service level agreements in composed services using self-adaptation\n", "abstract": " Providers of composite Web services face the challenge of having to comply to Service Level Agreements (SLAs), which are agreements governing the minimum performance that customers can expect from a composite service. SLAs contain Service Level Objectives (SLOs), concrete numerical Quality of Service (QoS) objectives, which the service needs to fulfill. If objectives are violated, agreed upon consequences (usually taking the form of penalty payments) go into effect. However, fulfilling SLAs can also lead to costs for the service provider (eg, because the composite service provider needs to use more expensive services itself, or because of the costs inherent to optimizing the composition). Therefore, it is not trivial for the provider to decide to what extend the service's SLAs should be fulfilled, or which SLAs should (temporarily) be violated for economical reasons. Even more so, these decisions should ideally be automated, to allow for fast reactions to changes in the business environment. In this thesis, a framework for optimizing adaptations of service compositions with regards to SLA violations has been developed. The framework, dubbed PREvent (Prediction and Pre-vention of SLA Violations Based on Events), uses techniques from the areas of machine learning and heuristic optimization to construct models for prediction of SLA violations at runtime, and to decide which adaptation actions may be used to improve overall performance in a composi-tion instance. An optimizer component decides, whether applying these changes makes sense economically (ie, whether the costs of violating the SLAs are bigger than the adaptation costs). If\u00a0\u2026", "num_citations": "3\n", "authors": ["193"]}
{"title": "Facing the Giant: a Grounded Theory Study of Decision-Making in Microservices Migrations\n", "abstract": " Microservices migrations are challenging and expensive projects with many decisions that need to be made in a multitude of dimensions. Existing research tends to focus on technical issues and decisions (e.g., how to split services). Equally important organizational or business issues and their relations with technical aspects often remain out of scope or on a high level of abstraction. The objective of this study is to holistically chart the decision-making that happens on all dimensions of a migration project towards microservices. We investigate 16 migration cases, by conducting a grounded theory interview study with 19 participants that recently underwent a migration. We also provide an initial validation via a Web-based survey with 52 respondents. Our study approaches the topic with a strong focus on the human aspect of a migration, through stakeholders, their concerns and the decisions they need to make as part of the migration. We identify 3 decision-making processes consisting of 22 decision-points in total, and their typical alternatives or options. The decision-points are related to creating stakeholder engagement and assessing feasibility, technical implementation, and organizational restructuring. Our study provides an initial theory of decision-making in migrations to microservices, and outfits practitioners with a roadmap of which decisions they should be prepared to make and at which point in the migration.", "num_citations": "2\n", "authors": ["193"]}
{"title": "Cachematic-Automatic Invalidation in Application-Level Caching Systems\n", "abstract": " Caching is a common method for improving the performance of modern web applications. Due to the varying architecture of web applications, and the lack of a standardized approach to cache management, ad-hoc solutions are common. These solutions tend to be hard to maintain as a code base grows, and are a common source of bugs. We present Cachematic, a general purpose application-level caching system with an au-tomatic cache management strategy. Cachematic provides a simple programming model, allowing developers to explic-itly denote a function as cacheable. The result of a cacheable function will transparently be cached without the developer having to worry about cache management. We present algo-rithms that automatically handle cache management, han-dling the cache dependency tree, and cache invalidation. Our experiments showed that the deployment of Cachematic decreased\u00a0\u2026", "num_citations": "2\n", "authors": ["193"]}
{"title": "Temperf: Temporal correlation between performance metrics and source code\n", "abstract": " Today's rapidly evolving software systems continuously introduce new changes that can potentially degrade performance. Large-scale load testing prior to deployment is supposed to avoid performance regressions in production. However, due to the large input space in parameterized load testing, not all performance regressions can be prevented in practice. To support developers in identifying the change sets that had an impact on performance, we present TemPerf, a tool that correlates performance regressions with change sets by exploiting temporal constraints. It is implemented as an Eclipse IDE plugin that allows developers to visualize performance developments over time and display temporally correlated change sets retrieved from version control and continuous integration platforms.", "num_citations": "2\n", "authors": ["193"]}
{"title": "A monitoring data set for evaluating QoS-aware service-based systems\n", "abstract": " Research in service-oriented computing traditionally struggles with the absence of public cases and data sets for evaluating and comparing research results. This is particularly evident for QoS-aware service-based computing, where public and widely accepted QoS traces would help to strengthen the fair comparison of QoS-aware automated composition and QoS prediction approaches. In this paper, we present one public data set produced for the evaluation of a contribution to the IEEE Transactions on Services Computing journal. We briefly introduce the background story of the use case and describe our monitored data set. We hope that this data set can serve as a basis for evaluation of future research papers from other authors.", "num_citations": "2\n", "authors": ["193"]}
{"title": "An Exploratory Study of the Impact of Parameterization on JMH Measurement Results in Open-Source Projects\n", "abstract": " The Java Microbenchmarking Harness (JMH) is a widely used tool for testing performance-critical code on a low level. One of the key features of JMH is the support for user-defined parameters, which allows executing the same benchmark with different workloads. However, a benchmark configured with n parameters with m different values each requires JMH to execute the benchmark mn times (once for each combination of configured parameter values). Consequently, even fairly modest parameterization leads to a combinatorial explosion of benchmarks that have to be executed, hence dramatically increasing execution time. However, so far no research has investigated how this type of parameterization is used in practice, and how important different parameters are to benchmarking results. In this paper, we statistically study how strongly different user parameters impact benchmark measurements for 126 JMH\u00a0\u2026", "num_citations": "1\n", "authors": ["193"]}
{"title": "Studying the impact of CI on pull request delivery time in open source projects\u2014a conceptual replication\n", "abstract": " Nowadays, continuous integration (CI) is indispensable in the software development process. A central promise of adopting CI is that new features or bug fixes can be delivered more quickly. A recent repository mining study by Bernardo, da Costa & Kulesza (2018) found that only about half of the investigated open source projects actually deliver pull requests (PR) faster after adopting CI, with small effect sizes. However, there are some concerns regarding the methodology used by Bernardo et al., which may potentially limit the trustworthiness of this finding. Particularly, they do not explicitly control for normal changes in the pull request delivery time during a project\u2019s lifetime (independently of CI introduction). Hence, in our work, we conduct a conceptual replication of this study. In a first step, we replicate their study results using the same subjects and methodology. In a second step, we address the same core research question using an adapted methodology. We use a different statistical method (regression discontinuity design, RDD) that is more robust towards the confounding factor of projects potentially getting faster in delivering PRs over time naturally, and we introduce a control group of comparable projects that never applied CI. Finally, we also evaluate the generalizability of the original findings on a set of new open source projects sampled using the same methodology. We find that the results of the study by Bernardo et al. largely hold in our replication. Using RDD, we do not find robust evidence of projects getting faster at delivering PRs without CI, and we similarly do not see a speed-up in our control group that never introduced CI\u00a0\u2026", "num_citations": "1\n", "authors": ["193"]}
{"title": "Performance Benchmarking of Infrastructure-as-a-Service (IaaS) Clouds with Cloud WorkBench (Tutorial)\n", "abstract": " The continuing growth of the cloud computing market has led to an unprecedented diversity of cloud services with different performance characteristics. To support service selection, researchers and practitioners conduct cloud performance benchmarking by measuring and objectively comparing the performance of different providers and configurations (e.g., instance types in different data center regions). In this tutorial, we demonstrate how to write performance tests for IaaS clouds using the Web-based benchmarking tool Cloud WorkBench (CWB). We will motivate and introduce benchmarking of IaaS cloud in general, demonstrate the execution of a simple benchmark in a public cloud environment, summarize the CWB tool architecture, and interactively develop and deploy a more advanced benchmark together with the participants.", "num_citations": "1\n", "authors": ["193"]}
{"title": "Transpiling applications into optimized serverless orchestrations\n", "abstract": " The serverless computing paradigm promises increased development productivity by abstracting the underlying hardware infrastructure and software runtime when building distributed cloud applications. However, composing a serverless application consisting of many tiny functions is still a cumbersome and inflexible process due to the lack of a unified source code view and strong coupling to non-standardized function-level interfaces for code and configuration. In our vision, developers can focus on writing readable source code in a logical structure, which then gets transformed into an optimized multi-function serverless orchestration. Our idea involves transpilation (i.e., source-to-source transformation) based on an optimization model (e.g., cost optimization) by dynamically deciding which set of methods will be grouped into individual deployment units. A successful implementation of our vision would enable a\u00a0\u2026", "num_citations": "1\n", "authors": ["193"]}
{"title": "Identifying incompatible implementations of industry standard service interfaces for dependable service-based applications\n", "abstract": " In this paper we study fault localization techniques for identification of incompatible configurations and implementations in service-based applications (SBAs). We consider SBAs with abstract service interfaces that integrate multiple concrete service implementations from various providers. Practice has shown that standardized interfaces alone do not guarantee compatibility of services originating from different partners. Hence, dynamic runtime instantiations of such SBAs pose a great challenge to reliability and dependability. The aim of this work is to monitor and analyze successful and faulty executions in SBAs, in order to proactively detect incompatible configurations at runtime. Our approach is based on well-established machine learning techniques, and extends stateof-the-art fault localization by explicitly addressing temporary and changing fault conditions. Moreover, the presented fault localization technique works on a per-request basis and is able to take individual service inputs into account. Considering not only the service configuration but also the service input data as a parameter for the fault localization algorithm increases the computational complexity by an order of magnitude. Hence, our extensive performance evaluation is targeted at large-scale SBAs and illustrates the feasibility and decent scalability of the approach.", "num_citations": "1\n", "authors": ["193"]}
{"title": "Mining lifecycle event logs for enhancing service-based applications\n", "abstract": " Service-Oriented Architectures (SOAs), and traditional enterprise systems in general, record a variety of events (eg, messages being sent and received between service components) to proper log files, ie, event logs. These files constitute a huge and valuable source of knowledge that may be extracted through data mining techniques. To this end, process mining is increasingly gaining interest across the SOA community. The goal of process mining is to build models without a priori knowledge, ie, to discover structured process models derived from specific patterns that are present in actual traces of service executions recorded in event logs. However, in this work we focus on detecting frequent sequential patterns, thus considering process mining as a specific instance of the more general sequential pattern mining problem. Furthermore, we apply two sequential pattern mining algorithms to a real event log provided by the Vienna Runtime Environment for Serviceoriented Computing, ie, VRESCO. The obtained results show that we are able to find services that are frequently invoked together within the same sequence. Such knowledge could be useful at design-time, when service-based application developers could be provided with service recommendation tools that are able to predict and thus to suggest next services that should be included in the current service composition.", "num_citations": "1\n", "authors": ["193"]}
{"title": "Distributed continuous data aggregation over web service event streams\n", "abstract": " We present a distributed platform for continuous event-based aggregation of Web services and data. The platform both actively monitors Web services and receives XML events using WS-Eventing. An aggregation is composed of multiple inputs such as Web service invocations and event subscriptions, which are formulated and processed in a query language based on XQuery. Our query model allows to specify data dependencies among the inputs of an aggregation. We use an XQuery language extension that enables users to easily express which data are exchanged between the individual inputs. The dependencies are automatically resolved and continuously updated with the required data at execution time. The query specification is abstracted from its physical distribution, and the platform is able to distribute the execution among multiple computing nodes. We evaluate several aspects of the implemented prototype in a Cloud Computing setting.", "num_citations": "1\n", "authors": ["193"]}