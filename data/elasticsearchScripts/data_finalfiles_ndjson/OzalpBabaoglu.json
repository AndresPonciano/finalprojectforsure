{"title": "Gossip-based aggregation in large dynamic networks\n", "abstract": " As computer networks increase in size, become more heterogeneous and span greater geographic distances, applications must be designed to cope with the very large scale, poor reliability, and often, with the extreme dynamism of the underlying network. Aggregation is a key functional building block for such applications: it refers to a set of functions that provide components of a distributed system access to global information including network size, average load, average uptime, location and description of hotspots, and so on. Local access to global information is often very useful, if not indispensable for building applications that are robust and adaptive. For example, in an industrial control application, some aggregate value reaching a threshold may trigger the execution of certain actions; a distributed storage system will want to know the total available free space; load-balancing protocols may benefit from\u00a0\u2026", "num_citations": "962\n", "authors": ["511"]}
{"title": "Anthill: A framework for the development of agent-based peer-to-peer systems\n", "abstract": " Recent peer-to-peer (P2P) systems are characterized by decentralized control, large scale and extreme dynamism of their operating environment. As such, they can be seen as instances of complex adaptive systems (CAS) typically found in biological and social sciences. We describe Anthill, a framework to support the design, implementation and evaluation of P2P applications based on ideas such as multi-agent and evolutionary programming borrowed from CAS. An Anthill system consists of a dynamic network of peer nodes; societies of adaptive agents travel through this network, interacting with nodes and cooperating with other agents in order to solve complex problems. Anthill can be used to construct different classes of P2P services that exhibit resilience, adaptation and self-organization properties. We also describe preliminary experiences with Anthill in implementing a file sharing application.", "num_citations": "488\n", "authors": ["511"]}
{"title": "Consistent global states of distributed systems: Fundamental concepts and mechanisms\n", "abstract": " Many important problems in distributed computing admit solutions that contain a phase where some global property needs to be detected. This subproblem can be seen as an instance of the Global Predicate Evaluation (GPE) problem where the objective is to establish the truth of a Boolean expression whose variables may refer to the global system state. Given the uncertainties in asynchronous distributed systems that arise from communication delays and relative speeds of computations, the formulation and solution of GPE reveal most of the subtleties in global reasoning with imperfect information. In this paper, we use GPE as a canonical problem in order to survey concepts and mechanisms that are useful in understanding global states of distributed computations. We illustrate the utility of the developed techniques by examining distributed deadlock detection and distributed debugging as two instances of GPE.", "num_citations": "438\n", "authors": ["511"]}
{"title": "Design patterns from biology for distributed computing\n", "abstract": " Recent developments in information technology have brought about important changes in distributed computing. New environments such as massively large-scale, wide-area computer networks and mobile ad hoc networks have emerged. Common characteristics of these environments include extreme dynamicity, unreliability, and large scale. Traditional approaches to designing distributed applications in these environments based on central control, small scale, or strong reliability assumptions are not suitable for exploiting their enormous potential. Based on the observation that living organisms can effectively organize large numbers of unreliable and dynamically-changing components (cells, molecules, individuals, etc.) into robust and adaptive structures, it has long been a research challenge to characterize the key ideas and mechanisms that make biological systems work and to apply them to distributed\u00a0\u2026", "num_citations": "404\n", "authors": ["511"]}
{"title": "T-Man: Gossip-based overlay topology management\n", "abstract": " Overlay topology plays an important role in P2P systems. Topology serves as a basis for achieving functions such as routing, searching and information dissemination, and it has a major impact on their efficiency, cost and robustness. Furthermore, the solution to problems such as sorting and clustering of nodes can also be interpreted as a topology. In this paper we propose a generic protocol, T-MAN, for constructing and maintaining a large class of topologies. In the proposed framework, a topology is defined with the help of a ranking function. The nodes participating in the protocol can use this ranking function to order any set of other nodes according to preference for choosing them as a neighbor. This simple abstraction makes it possible to control the self-organization process of topologies in a straightforward, intuitive and flexible manner. At the same time, the T-MAN protocol involves only local\u00a0\u2026", "num_citations": "371\n", "authors": ["511"]}
{"title": "T-man: Gossip-based fast overlay topology construction\n", "abstract": " Large-scale overlay networks have become crucial ingredients of fully-decentralized applications and peer-to-peer systems. Depending on the task at hand, overlay networks are organized into different topologies, such as rings, trees, semantic and geographic proximity networks. We argue that the central role overlay networks play in decentralized application development requires a more systematic study and effort towards understanding the possibilities and limits of overlay network construction in its generality. Our contribution in this paper is a gossip protocol called T-Man that can build a wide range of overlay networks from scratch, relying only on minimal assumptions. The protocol is fast, robust, and very simple. It is also highly configurable as the desired topology itself is a parameter in the form of a ranking method that orders nodes according to preference for a base node to select them as neighbors. The\u00a0\u2026", "num_citations": "282\n", "authors": ["511"]}
{"title": "Messor: Load-balancing through a swarm of autonomous agents\n", "abstract": " Peer-to-peer (P2P) systems are characterized by decentralized control, large-scale and extreme dynamism of their environment. Developing applications that can cope with these characteristics requires a paradigm shift that puts adaptation, resilience and self-organization as primary concerns. Complex adaptive systems (CAS), commonly used to explain the behavior of many biological and social systems, could be an appropriate response to these requirements. In order to pursue these ideas, this paper presents Messor, a decentralized load-balancing algorithm based on techniques such as multi-agent systems drawn from CAS. A novel P2P grid computing system has been designed using the Messor algorithm, allowing arbitrary users to initiate computational tasks.", "num_citations": "246\n", "authors": ["511"]}
{"title": "Design and implementation of a p2p cloud system\n", "abstract": " Cloud Computing has gained popularity in both research and industrial communities. Cloud users can acquire computing resources on a need basis, achieving on demand scalability; Cloud providers can maximize resource utilizations of datacenters, increasing their return on investments. While Cloud systems are usually hosted in large datacenters and are centrally managed, other types of Cloud architectures can be imagined. In this paper we describe the design and prototype implementation of a fully decentralized, P2P Cloud. A P2P Cloud allows organizations or even individual to build a computing infrastructure out of existing resources, which can be easily allocated among different tasks. We focus on the problem of maintaining a coherent structure over a set of unreliable computing resources. We show that gossip-based protocols can be used to maintain an overlay network on top of the computing nodes\u00a0\u2026", "num_citations": "167\n", "authors": ["511"]}
{"title": "Server consolidation in clouds through gossiping\n", "abstract": " The success of Cloud computing, where computing power is treated as a utility, has resulted in the creation of many large data centers that are very expensive to build and operate. In particular, the energy bill accounts for a significant fraction of the total operation costs. For this reason a significant attention is being devoted to energy conservation techniques, for example by taking advantage of the built-in power saving features of modern hardware. Cloud computing offers novel opportunities for achieving energy savings: Cloud systems rely on virtualization techniques to allocate computing resources on demand, and modern Virtual Machine (VM) monitors allow live migration of running VMs. Thus, energy conservation can be achieved through server consolidation, moving VM instances away from lightly loaded computing nodes so that they become empty and can be switched to low-power mode. In this paper we\u00a0\u2026", "num_citations": "160\n", "authors": ["511"]}
{"title": "On the optimum checkpoint selection problem\n", "abstract": " We consider a model of computation consisting of a sequence of n tasks. In the absence of failures, each task i has a known completion time  . Checkpoints can be placed between any two consecutive tasks. At a checkpoint, the state of the computation is saved on a reliable storage medium. Establishing a checkpoint immediately before task i is known to cost . This is the time spent in saving the state of the computation. When a failure is detected, the computation is restarted at the most recent checkpoint. Restarting the computation at checkpoint i requires restoring the state to the previously saved value. The time necessary for this action is given by . We derive an  algorithm to select out of the  potential checkpoint locations those that result in the smallest expected time to complete all the tasks. An  algorithm is described for the reasonable case where  implies . These algorithms are applied to\u00a0\u2026", "num_citations": "159\n", "authors": ["511"]}
{"title": "Online reconfiguration in replicated databases based on group communication\n", "abstract": " Over the last years, many replica control protocols have been developed that take advantage of the ordering and reliability semantics of group communication primitives to simplify database system design and to improve performance. Although current solutions are able to mask site failures effectively, many of them are unable to cope with recovery of failed sites, merging of partitions, or joining of new sites. This paper addresses this important issue. It proposes efficient solutions for online system reconfiguration providing new sites with a current state of the database without interrupting transaction processing in the rest of the system. Furthermore, the paper analyzes the impact of cascading reconfigurations, and argues that they call be handled in an elegant way by extended forms of group communication.", "num_citations": "157\n", "authors": ["511"]}
{"title": "Streets of Byzantium: Network architectures for fast reliable broadcasts\n", "abstract": " A site broadcasting its local value to all other sites ina fault-prone environment is a fundamental paradigm in constructing reliable distributed systems. Time complexity lower bounds and network connectivity requirements for reliable broadcast protocols in point-to-point communication networks are well known. In this paper, we consider the reliable broadcast problem in distributed systems with broadcast networks (for example, Ethernets) as the basic communication architecture. We show how properties of such network architectures can be used to effectively restrict the externally visible behavior of faulty processors. We use these techniques to derive simple protocols that implement reliable broadcast in only two rounds, independent of the failure upper bounds.", "num_citations": "150\n", "authors": ["511"]}
{"title": "Group communication in partitionable systems: Specification and algorithms\n", "abstract": " Gives a formal specification and an implementation for a partitionable group communication service in asynchronous distributed systems. Our specification is motivated by the requirements for building \"partition-aware\" applications that can continue operating without blocking in multiple concurrent partitions and can reconfigure themselves dynamically when partitions merge. The specified service guarantees liveness and excludes trivial solutions, it constitutes a useful basis for building realistic partition-aware applications, and it is implementable in practical asynchronous distributed systems where certain stability conditions hold.", "num_citations": "136\n", "authors": ["511"]}
{"title": "Paralex: An environment for parallel programming in distributed systems\n", "abstract": " Modern distributed systems consisting of powerful workstations and high-speed interconnection networks are an economical alternative to special-purpose super computers. The technical issues that need to be addressed in exploiting the parallelism inherent in a distributed system include heterogeneity, high-latency communication, fault tolerance and dynamic load balancing. Current software systems for parallel programming provide little or no automatic support towards these issues and require users to be experts in fault-tolerant distributed computing. The Paralex system is aimed at exploring the extent to which the parallel application programmer can be liberated from the complexities of distributed systems. Paralex is a complete programming environment and makes extensive use of graphics to define, edit, execute and debug parallel scientific applications. All of the necessary code for distributing the\u00a0\u2026", "num_citations": "118\n", "authors": ["511"]}
{"title": "Robust aggregation protocols for large-scale overlay networks\n", "abstract": " Aggregation refers to a set of functions that provide global information about a distributed system. These junctions operate on numeric values distributed over the system and can be used to count network size, determine extremal values and compute averages, products or sums. Aggregation allows important basic functionality to be achieved in fully distributed and peer-to-peer networks. For example, in a monitoring application, some aggregate reaching a specific value may trigger the execution of certain operations; distributed storage systems may need to know the total free space available; load-balancing protocols may benefit from knowing the target average load so as to minimize the transfered load. Building on the simple but efficient idea of antientropy aggregation (a scheme based on the antientropy epidemic communication model), in this paper we introduce practically applicable robust and adaptive\u00a0\u2026", "num_citations": "111\n", "authors": ["511"]}
{"title": "A modular paradigm for building self-organizing peer-to-peer applications\n", "abstract": " Peer-to-peer (P2P) technology has undergone rapid growth, producing new protocols and applications, many of which enjoy considerable commercial success and academic interest. Yet, P2P applications are often based on complex protocols, whose behavior is not completely understood. We believe that in order to enable an even more widespread adoption of P2P systems in commercial and scientific applications, what is needed is a\u00a0modular paradigm in which well-understood, predictable components with clean interfaces can be combined to implement arbitrarily complex functions. The goal of this paper is to promote this idea by describing our initial experiences in this direction. Our recent work has resulted in a\u00a0collection of simple and robust components, which include aggregation and membership management. This paper shows how to combine them to obtain a\u00a0novel load-balancing algorithm that\u00a0\u2026", "num_citations": "110\n", "authors": ["511"]}
{"title": "Self-star Properties in Complex Information Systems, Conceptual and Practical Foundations\n", "abstract": " This book is a spin-off of a by-invitation-only workshop on self-* properties in complex systems held in summer 2004 in Bertinoro, Italy. The workshop aimed to identify the conceptual and practical foundations for modeling, analyzing, and achieving self-* properties in distributed and networked systems. Based on the discussions at the workshop, papers were solicited from workshop participants and invited from leading researchers in the field. Besides presenting sound research results, the papers also present visionary statements, thought-provoking ideas, and exploratory results. The 27 carefully reviewed revised full papers, presented together with a motivating introduction and overview, are organized in topical sections on self-organization, self-awareness, self-awareness versus self-organization, supporting self-properties, and peer-to-peer algorithms.", "num_citations": "106\n", "authors": ["511"]}
{"title": "Converting a swap-based system to do paging in an architecture lacking page-referenced bits\n", "abstract": " This paper discusses the modifications made to the UNIX operating system for the VAX-11/780 to convert it from a swap-based segmented system to a paging-based virtual memory system. Of particular interest is that the host machine architecture does not include page-referenced bits. We discuss considerations in the design of page-replacement and load-control policies for such an architecture, and outline current work in modeling the policies employed by the system. We describe our experience with the chosen algorithms based on benchmark-driven studies and production system use.", "num_citations": "100\n", "authors": ["511"]}
{"title": "Chord on demand\n", "abstract": " Structured peer-to-peer overlay networks are now an established paradigm for implementing a wide range of distributed services. While the problem of maintaining these networks in the presence of churn and other failures is the subject of intensive research, the problem of building them from scratch has not been addressed (apart from individual nodes joining an already functioning overlay). In this paper we address the problem of jump-starting a popular structured overlay, Chord, from scratch. This problem is of crucial importance in scenarios where one is assigned a limited time interval in a distributed environment such as Planet-Lab, or a grid, and the overlay infrastructure needs to be set up from the ground up as quickly and efficiently as possible, or when a temporary overlay has to be generated to solve a specific task on demand. We introduce T-Chord, that can build a Chord network efficiently starting from a\u00a0\u2026", "num_citations": "99\n", "authors": ["511"]}
{"title": "Non-blocking atomic commitment\n", "abstract": " In distributed database systems, an atomic commitment protocol ensures that transactions terminate consistently at all participating sites even in the presence of failures. An atomic commitment protocol is said to be non-blocking if it permits transaction termination to proceed at correct participants despite failures of others. Protocols that have this property are desirable since they limit the time intervals during which transactions may be holding valuable resources. In this paper, we show how non-blocking atomic commitment protocols can be obtained through slight modifications of the well-known Two-Phase Commit (2PC) protocol, which is known to be blocking. Our approach is modular in the sense that both the protocols and their proofs of correctness are obtained by plugging in the appropriate reliable broadcast algorithms as the basic communication primitives in the original 2PC protocol. The resulting protocols are not only conceptually simple, they are also efficient in terms of time and message complexity.", "num_citations": "98\n", "authors": ["511"]}
{"title": "Firefly-inspired heartbeat synchronization in overlay networks\n", "abstract": " Heartbeat synchronization strives to have nodes in a distributed system generate periodic, local \"heartbeat\" events approximately at the same time. Many useful distributed protocols rely on the existence of such heartbeats for driving their cycle-based execution. Yet, solving the problem in environments where nodes are unreliable and messages are subject to delays and failures is non-trivial. We present a heartbeat synchronization protocol for overlay networks inspired by mathematical models of flash synchronization in certain species of fireflies. In our protocol, nodes send flash messages to their neighbors when a local heartbeat triggers. They adjust the phase of their next heartbeat based on incoming flash messages using an algorithm inspired by mathematical models of firefly synchronization. We report simulation results of the protocol in various realistic failure scenarios typical in overlay networks and show\u00a0\u2026", "num_citations": "93\n", "authors": ["511"]}
{"title": "Towards adaptive, resilient and self-organizing peer-to-peer systems\n", "abstract": " Peer-to-peer (P2P) systems are characterized by decentralized control, large scale and extreme dynamism of their operating environment. Developing applications that can cope with these characteristics requires a paradigm shift, placing adaptation, resilience and self-organization as primary concerns. In this note, we argue that complex adaptive systems (CAS), which have been used to explain certain biological, social and economical phenomena, can be the basis of a programming paradigm for P2P applications. In order to pursue this idea, we are developing Anthill, a framework to support the design, implementation and evaluation of P2P applications based on ideas such as multi-agent and evolutionary programming borrowed from CAS.", "num_citations": "80\n", "authors": ["511"]}
{"title": "System support for partition-aware network applications\n", "abstract": " Network applications and services need to be environment-aware in order to meet quality-of-service requirements in an increasingly dynamic world. In this paper we consider partition awareness as an instance of environment awareness in network applications that need to be reliable and self-managing. Partition-aware applications dynamically reconfigure themselves and adjust the quality of their services in response to network partitions and merges. As such, they can automatically adapt to changes in the environment and remain available in multiple partitions with perhaps degraded or reduced services, but without blocking. We propose a system layer consisting of group membership and reliable multicast services that provides systematic support for partition-aware application development. We illustrate the effectiveness of the proposed interface by solving three problems that represent different classes of\u00a0\u2026", "num_citations": "68\n", "authors": ["511"]}
{"title": "Jgroup/ARM: a distributed object group platform with autonomous replication management\n", "abstract": " This paper presents the design and implementation of Jgroup/ARM, a distributed object group platform with autonomous replication management along with a novel measurement\u2010based assessment technique that is used to validate the fault\u2010handling capability of Jgroup/ARM. Jgroup extends Java RMI through the group communication paradigm and has been designed specifically for application support in partitionable systems. ARM aims at improving the dependability characteristics of systems through a fault\u2010treatment mechanism. Hence, ARM focuses on deployment and operational aspects, where the gain in terms of improved dependability is likely to be the greatest. The main objective of ARM is to localize failures and to reconfigure the system according to application\u2010specific dependability requirements. Combining Jgroup and ARM can significantly reduce the effort necessary for developing, deploying\u00a0\u2026", "num_citations": "66\n", "authors": ["511"]}
{"title": "On group communication in large-scale distributed systems\n", "abstract": " An increasing number of applications with reliability requirements are being deployed in distributed systems that span large geographic distances or manage large numbers of objects. We consider the process group mechanism as an appropriate application structuring paradigm in such large-scale distributed systems. We give a formal characterization for the attribute \"large scale\" as applied to distributed systems and examine the technical problems that need to be solved in making group technology scalable. Our design advocates multiple roles for group membership over a minimal set of abstractions and primitives. The design is currently being implemented on top of \"off-the-shelf\" technologies for both communication and computation.", "num_citations": "63\n", "authors": ["511"]}
{"title": "On the reliability of consensus-based fault-tolerant distributed computing systems\n", "abstract": " The designer of a fault-tolerant distributed system faces numerous alternatives. Using a stochastic model of processor failure times, we investigate design choices such as replication level, protocol running time, randomized versus deterministic protocols, fault detection, and authentication. We use the probability with which a system produces the correct output as our evaluation criterion. This contrasts with previous fault-tolerance results that guarantee correctness only if the percentage of faulty processors in the system can be bounded. Our results reveal some subtle and counterintuitive interactions between the design parameters and system reliability.", "num_citations": "62\n", "authors": ["511"]}
{"title": "Low-cost clock synchronization\n", "abstract": " We show how synchronized clocks can be realized in a distributed system as a byproduct of a common communication paradigm where processors periodically perform broadcasts. Our approach decouples theprecision concern of clock synchronization\u2014limiting how much correct clocks can differ from each other\u2014from theaccuracy concern\u2014limiting the rate at which any correct clock may drift from real time. Given a system that guarantees only precision, we develop a protocol whereby high accuracy can be achieved on demand. In this manner, the \u201clazy\u201d protocol we obtain incurs the cost of high accuracy only when needed while keeping the basic synchronization procedure extremely simple and cheap.", "num_citations": "61\n", "authors": ["511"]}
{"title": "Proximity-aware superpeer overlay topologies\n", "abstract": " The concept of superpeer has been introduced to improve the performance of popular P2P applications. A superpeer is a \u201cpowerful\u201d node that acts as a server for a set of clients, and as an equal with respect to other superpeers. By exploiting heterogeneity, the superpeer paradigm can lead to improved efficiency, without compromising the decentralized nature of P2P networks. The main issues in the construction of superpeer-based overlays are the selection of superpeers, and the association between superpeers and clients. Generally, superpeers are either run voluntarily (without an explicit selection process), or chosen among the \u201cbest\u201d nodes in the network, for example those with the most abondant resources, such as bandwidth or storage. In several contexts, however, shared resources are not the only factor; latency between clients and superpeers may play an important role, for example in online\u00a0\u2026", "num_citations": "57\n", "authors": ["511"]}
{"title": "Two-level replacement decisions in paging stores\n", "abstract": " One of the primary motivations for implementing virtual memory is its ability to automatically manage a hierarchy of storage systems with different characteristics. The composite system behaves as if it were a single-level system having the more desirable characteristics of each of its constituent levels. In this paper we extend the virtual memory concept to within the top level of a two-level hierarchy. Here, the top level is thought of as containing two additional levels within it. This hierarchy is not a physical one, but rather an artificial one arising from the employment of two different replacement algorithms. Given two replacement algorithms, one of which has good performance but high implementation cost and the other poor performance but low implementation cost, we propose and analyze schemes that result in an overall algorithm having the performance characteristics of the former and the cost characteristics of the\u00a0\u2026", "num_citations": "54\n", "authors": ["511"]}
{"title": "Detection and removal of malicious peers in gossip-based protocols\n", "abstract": " Method UPDATE builds a new local state based on the previous local state and the state received from the random peer. Semantics of the node state and the method UPDATE define the behavior and function of the protocol. For example, in membership management, a fixedsize set of peer addresses called the partial view constitutes the state. Method UPDATE can be implemented (as in lpbcast) by computing the new state through a random sampling of the union of the old view and the received view. In this case, selection of the random peer is done using the old view itself. In epidemic broadcasting, the state is a flag that records if the node is infected or not. Method UPDATE sets the state to infected if the received state is infected. To make our reasoning concrete, the discussion that follows is based on aggregation. Here, the state of a node is a numeric value. In a practical setting, this value can be any attribute of the environment, such as the current load or storage capacity. The task of the protocol is to calculate an aggregate value over the set of all numbers stored at nodes. Several aggregate functions are possible, including extremal values, average, sum, counting, etc. For example, if we are interested in the average, method UPDATE simply returns the arithmetic mean of the two states. The resulting protocol is know to result in exponential convergence to the correct global average at each node [8, 10].", "num_citations": "53\n", "authors": ["511"]}
{"title": "T-Man: Fast gossip-based construction of large-scale overlay topologies\n", "abstract": " Topology, as defined by the \u201cwho knows whom\u201d relation, has many applications that are of crucial importance in distributed systems. For example, characteristics of the communication topology play a key role in determining the performance of many functions including search, routing, monitoring, control and information dissemination. Other essential properties of functions such as scalability and robustness to failures are also heavily dependant on the communication topology. The \u201cwho knows whom\u201d relation can also be used to define solutions for problems such as sorting a set of numbers, clustering nodes based on similarity or pairing search requests with the locations of the information. In large-scale, dynamic, fully distributed systems constructing and maintaining a topology is a highly non-trivial problem. In this paper we identify topology management as an abstract service, independent of application or function, and propose a gossipbased scheme called TMan for the construction of a large class of different topologies. The topology is defined by a ranking function which can be based on any appropriate property of components, including geographical location, semantic proximity, bandwidth, or simply on an abstract, pre-defined topology over an ID space like a ring or a torus. In the present work, we examine three specific topologies: ring, torus and binary tree. We give theoretical arguments and experimental results to demonstrate that the proposed protocol is lightweight and fast in that it converges quickly, approximately in logarithmic time, and that this speed is largely independent of the actual topology being constructed. We also\u00a0\u2026", "num_citations": "52\n", "authors": ["511"]}
{"title": "Grassroots approach to self-management in large-scale distributed systems\n", "abstract": " Traditionally, autonomic computing is envisioned as replacing the human factor in the deployment, administration and maintenance of computer systems that are ever more complex. Partly to ensure a smooth transition, the design philosophy of autonomic computing systems remains essentially the same as traditional ones, only autonomic components are added to implement functions such as monitoring, error detection, repair, etc. In this position paper we outline an alternative approach which we call \u201cgrassroots self-management\u201d. While this approach is by no means a solution to all problems, we argue that recent results from fields such as agent-based computing, the theory of complex systems and complex networks can be efficiently applied to achieve important autonomic computing goals, especially in very large and dynamic environments. Unlike traditional compositional design, in the grassroots\u00a0\u2026", "num_citations": "51\n", "authors": ["511"]}
{"title": "Parallel computing in networks of workstations with Paralex\n", "abstract": " Modern distributed systems consisting of powerful workstations and high-speed interconnection networks are an economical alternative to special-purpose supercomputers. The technical issues that need to be addressed in exploiting the parallelism inherent in a distributed system include heterogeneity, high-latency communication, fault tolerance and dynamic load balancing. Current software systems for parallel programming provide little or no automatic support towards these issues and require users to be experts in fault-tolerant distributed computing. The Paralex system is aimed at exploring the extent to which the parallel application programmer can be liberated from the complexities of distributed systems. Paralex is a complete programming environment and makes extensive use of graphics to define, edit, execute, and debug parallel scientific applications. All of the necessary code for distributing the\u00a0\u2026", "num_citations": "51\n", "authors": ["511"]}
{"title": "A formalization of priority inversion\n", "abstract": " A priority inversion occurs when a low-priority task causes the execution of a higher-priority task to be delayed. The possibility of priority inversions complicates the analysis of systems that use priority-based schedulers because priority inversions invalidate the assumption that a task can be delayed by only higher-priority tasks. This paper formalizes priority inversion and gives sufficient conditions as well as some new protocols for preventing priority inversions.", "num_citations": "51\n", "authors": ["511"]}
{"title": "The bootstrapping service\n", "abstract": " We outline a lightweight architecture to support novel application scenarios for P2P systems. These scenarios include merging and splitting of large networks, or multiplexing relatively short-lived applications over a pool of shared resources. In such scenarios, the architecture needs to be quickly and efficiently (re)generated frequently, often from scratch. We propose the bootstrapping service abstraction as a solution to this problem. We present an instance of the service that can jumpstart any prefix-table based routing substrate quickly, cheaply and reliably from scratch. We experimentally analyze the proposed bootstrapping service, demonstrating its scalability and robustness.", "num_citations": "48\n", "authors": ["511"]}
{"title": "Fault-tolerant computing based on Mach\n", "abstract": " We consider the problem of providing automatic and transparent fault tolerance to arbitrary user computations based on the Mach operating system. Among the several alternatives for structuring such a system, we pursue the \"task-pair backup\" paradigm in detail and outline how it might be supported by Mach. Some of the new system calls and protocols that need to be incorporated into the Mach kernel and server tasks are sketched.", "num_citations": "48\n", "authors": ["511"]}
{"title": "Proximity-aware superpeer overlay topologies\n", "abstract": " The concept of superpeer has been introduced to improve the performance of popular P2P applications. A superpeer is a \"powerful\" node that acts as a server for a set of clients, and as an equal with respect to other superpeers. By exploiting heterogeneity, the superpeer paradigm can lead to improved efficiency, without compromising the decentralized nature of P2P networks. The main issues in constructing superpeer-based overlays are the selection of superpeers and the association between superpeers and clients. Generally, superpeers are either run voluntarily (without an explicit selection process), or chosen among the \"best\" nodes in the network, for example those with the most abundant resources, such as bandwidth or storage. In several contexts, however, shared resources are not the only factor; latency between clients and superpeers may play an important role, for example in online games and IP\u00a0\u2026", "num_citations": "47\n", "authors": ["511"]}
{"title": "Mapping parallel computations onto distributed systems in paralex\n", "abstract": " Paralex is a programming environment that allows parallel programs to be developed and executed on distributed systems as if the latter were uniform parallel multiprocessor computers. Architectural heterogeneity, remote communication and failures are rendered transparent to the programmer through automatic system support. Parallel programs are specified using a graphical language that is based on coarse-grain dataflow and may include existing sequential code as components. The Paralex loader selects hosts of a distributed system to execute a parallel program so as to satisfy the heterogeneity and fault tolerance requirements while trying to maximize performance. In this paper we address the problems of initial mapping and dynamic alteration of the association between parallel computation components and distributed system hosts. Our results include novel heuristics and mechanisms to resolve these problems despite the complexities introduced by architectural heterogeneity fault tolerance.", "num_citations": "38\n", "authors": ["511"]}
{"title": "The self-star vision\n", "abstract": " Achieving various self-\u22c6 properties has been a grand challenge of computer science and engineering since the building of the first computer. The latest reincarnation of this challenge is due to the fact that large, complex and dynamic information systems have suddenly become a key part of the infrastructure of modern societies. Accordingly, it has become very important to be able to build, manage, and exploit these systems in the most efficient way possible. In other words, these systems have to become self-\u22c6.", "num_citations": "37\n", "authors": ["511"]}
{"title": "Group Communication in Partitionable Distributed Systems\n", "abstract": " We give a formal specification and an implementation for a partitionable group communication service in asynchronous distributed systems. Our specification is motivated by the requirements for building \u201cpartition-aware\u201d applications that can continue operating without blocking in multiple concurrent partitions and reconfigure themselves dynamically when partitions merge. The specified service guarantees liveness and excludes trivial solutions; it constitutes a useful basis for building realistic partition-aware applications; and it is implementable in practical asynchronous distributed systems where certain stability conditions hold.", "num_citations": "36\n", "authors": ["511"]}
{"title": "Partitionable group membership: specification and algorithms\n", "abstract": " We give a formal specification for a partionable group membership service in asynchronous distributed systems. Our specification is motivated by the requirements for building \"partition-aware\" applications that can continue operating without blocking in multiple concurrent partitions and reconfigure themselves dynamically when partitions merge. The specified service is sound in the sense that it guarantees liveness, excludes trivial solutions and is implementable in practical asynchronous distributed systems where certain stability conditions hold.", "num_citations": "36\n", "authors": ["511"]}
{"title": "The inherent cost of strong-partial view-synchronous communication\n", "abstract": " We examine algorithmic issues associated with view-synchronous communication (VSC) group membership in large-scale distributed systems where network partitions may result in multiple views to be active concurrently. We first derive necessary conditions on the partial order of installed views such that VSC is meaningful and solvable in the presence of partitions. We then prove that strong-partial VSC, which guarantees concurrent views to be disjoint, is not easier than atomic commitment. As such, all know lower bound results for atomic commitment are also lower bounds for this problem, including the impossibility of non-blocking solutions in the presence of communication failures. We discuss the practical implications of our results in constructing group communication facilities for large-scale distributed systems.", "num_citations": "36\n", "authors": ["511"]}
{"title": "A framework for prototyping J2EE replication algorithms\n", "abstract": " In application server systems, such as J2EE, replication is an essential strategy for reliability and efficiency. Many J2EE implementations, both commercial and open-source, provide some replication support. However, the range of possible strategies is wide, and the choice of the best one, depending on the expected application profile, remains an open research question.               To support research in this area, we introduce a framework for prototyping J2EE replication algorithms. In effect, it divides replication code into two layers: the framework itself, which is common to all replication algorithms, and a specific replication algorithm, which is \u201cplugged in\u201d to the framework. The division is defined by an API.               The framework simplifies development in two ways. First, it keeps much of the complexity of modifying a J2EE implementation within the framework layer, which is implemented only once. Second\u00a0\u2026", "num_citations": "35\n", "authors": ["511"]}
{"title": "Managing clouds: a case for a fresh look at large unreliable dynamic networks\n", "abstract": " Peer-to-peer (P2P) protocols have proven efficient to provide scalable support to many large-scale distributed applications, successfully coping with unreliability and dynamics. However, to exploit them in a wider range of environments, such as very large-scale networks of smartphones or set-top boxes, it is imperative to make P2P protocols manageable: we need to be able to start, bootstrap and stop protocols, and assign resources dynamically. In this paper we present a general-purpose framework aimed to support several fully distributed applications running independently over a very large scale and dynamic pool of resources. We call this resource pool a cloud. The basic idea of the framework is a declarative application suit description, that describes what applications should be running on what resources, and a middleware that makes sure the currently available and dynamic cloud self-organizes into the\u00a0\u2026", "num_citations": "34\n", "authors": ["511"]}
{"title": "Replicated file management in large-scale distributed systems\n", "abstract": " Large-scale systems spanning geographically distant sites are potentially appropriate environments for distributed applications supporting collaboration. In this paper, we examine the possibility of using such systems as repositories for replicated files to facilitate lowlatency data sharing. Asynchrony in communication and computation, complex combinations of site and communication failures, and in particular, network partitions that characterize these systems make the design of algorithms to operate on them a difficult task. We show that viewsynchronous communication is not only an appropriate conceptual model for reasoning about large-scale distributed systems, it is also an effective programming model. We support these claims by developing algorithms for managing replicated files with one-copy serializability as the correctness criteria.", "num_citations": "31\n", "authors": ["511"]}
{"title": "Enhancing Jini with group communication\n", "abstract": " Reliable group communication has proven to be an important technology for building fault-tolerant applications, yet many frameworks for distributed application development (e.g. DCOM, Jini and Enterprise JavaBeans) do not support it. The only notable exception to this situation is CORBA, which has been recently extended to include a replication service. We claim that lack of group communication support in other development frameworks constitutes a major obstacle for their wider diffusion in the industry. In this paper, we discuss issues related to integrating reliable group communication and Jini technologies.", "num_citations": "29\n", "authors": ["511"]}
{"title": "Guest editors' introduction: Self-management through self-organization\n", "abstract": " Given the scale and complexity of today's information systems, it's increasingly important that they handle system management problems and tasks themselves--intelligently and autonomously. This special issue focuses on implementing self-management in a variety of distributed systems by observing the self-managing systems that surround us: multicellular organisms, social insects, market economies, human societies, ecosystems, and so on. These systems are made of components that obey local rules and act on the basis of local observations--often selfishly. Yet the system as a whole exhibits global properties such as self-healing, self-tuning, and self-organization. Distilling the key ideas from these systems and incorporating them into information systems often leads to inexpensive, straightforward, and highly robust solutions.This article is part of a special issue on Self-Managing Systems.", "num_citations": "28\n", "authors": ["511"]}
{"title": "Self-* properties through gossiping\n", "abstract": " As computer systems have become more complex, numerous competing approaches have been proposed for these systems to self-configure, self-manage, self-repair, etc. such that human intervention in their operation can be minimized. In ubiquitous systems, this has always been a central issue as well. In this paper, we overview techniques to implement self-* properties in large-scale, decentralized networks through bio-inspired techniques in general, and gossip-based algorithms in particular. We believe that gossip-based algorithms could be an important inspiration for solving problems in ubiquitous computing as well. As an example, we outline a novel approach to arrange large numbers of mobile agents (e.g. vehicles, rescue teams carrying mobile devices) into different formations in a totally decentralized manner. The approach is inspired by the biological mechanism of cell sorting via differential adhesion\u00a0\u2026", "num_citations": "27\n", "authors": ["511"]}
{"title": "The people's cloud\n", "abstract": " Peer-to-peer cloud computing could free us from the tyranny of data centers. With the right software, geographically distributed hardware can provide a unified cloud-computing resource. Some cloud-computing providers put all their hardware eggs in one datacenter basket [blue]. Others employ multiple data centers networked together [orange]. The logical extension is a peer-to-peer cloud made of individual computers [yellow].The computers in some P2P networks resemble gossiping office workers. Gossip-based protocols allow information to flow reliably, even if some computers leave the system and break previously established links [orange lines]. Gossip-based protocols are used to maintain an unstructured peer-to-peer network of individual computers, some of which do the work of one customer [orange] while other combinations serve different customers [blue and yellow].", "num_citations": "24\n", "authors": ["511"]}
{"title": "Power consumption modeling and prediction in a hybrid CPU-GPU-MIC supercomputer\n", "abstract": " Power consumption is a major obstacle for High Performance Computing (HPC) systems in their quest towards the holy grail of ExaFLOP performance. Significant advances in power efficiency have to be made before this goal can be attained and accurate modeling is an essential step towards power efficiency by optimizing system operating parameters to match dynamic energy needs. In this paper we present a study of power consumption by jobs in Eurora, a hybrid CPU-GPU-MIC system installed at the largest Italian data center. Using data from a dedicated monitoring framework, we build a data-driven model of power consumption for each user in the system and use it to predict the power requirements of future jobs. We are able to achieve good prediction results for over 80\u00a0% of the users in the system. For the remaining users, we identify possible reasons why prediction performance is not as good\u00a0\u2026", "num_citations": "23\n", "authors": ["511"]}
{"title": "Towards data-driven autonomics in data centers\n", "abstract": " Continued reliance on human operators for managing data centers is a major impediment for them from ever reaching extreme dimensions. Large computer systems in general, and data centers in particular, will ultimately be managed using predictive computational and executable models obtained through data-science tools, and at that point, the intervention of humans will be limited to setting high-level goals and policies rather than performing low-level operations. Data-driven autonomics, where management and control are based on holistic predictive models that are built and updated using generated data, opens one possible path towards limiting the role of operators in data centers. In this paper, we present a data-science study of a public Google dataset collected in a 12K-node cluster with the goal of building and evaluating a predictive model for node failures. We use BigQuery, the big data SQL platform\u00a0\u2026", "num_citations": "23\n", "authors": ["511"]}
{"title": "Distributed computing in the 21st century: Some aspects of cloud computing\n", "abstract": " The Cloud Computing paradigm has gained considerable attention owing to the notable commercial success of many Cloud service providers. Typically, a Cloud Computing service provides its customers with resources as a utility, using a pay-as-you-go model. Thus, Cloud Computing customers can reduce costs related to the acquisition and management of complex IT infrastructures, and Cloud service providers can make efficient use of large resource pools by consolidating multiple variable workloads. From the providers point of view a Cloud is a very large distributed system which poses many challenges, including monitoring, management, efficient resource sharing, fault-tolerance and so on. Knowledge and experience acquired in the development of distributed systems can be used to address some of these issues, while other problems pose new challenges that need new solutions. In this paper we\u00a0\u2026", "num_citations": "23\n", "authors": ["511"]}
{"title": "Tag-Based Cooperation in Peer-to-Peer Networks with Newscast\n", "abstract": " Recent work has proposed how socially inspired mechanisms, based on \u201ctags\u201d and developed within social science simulations, might be applied in peer-to-peer overlay networks to maintain high cooperation between peers even when they act selfishly. The proposed mechanism involves a dynamic re-wiring algorithm called \u201cSLAC\u201d. The algorithm assumes a random sampling service over the entire population of nodes but does not implement this itself. In this paper we re-implement SLAC on an open source peer-to-peer simulation testbed called \u201cPEERSIM\u201d. For the random sampling service we utilize an existing protocol called \u201cNEWSCAST\u201d. We present the results of some experiments we performed in which peers play the Prisoner\u2019s Dilemma game with their neighbours. Our results demonstrate that SLAC augmented with NEWSCAST produces high levels of cooperation. This increases our confidence that previous results from SLAC are generally applicable and valid and also that SLAC could have applications in real implemented systems. Finally we discuss the open issues that need to be addressed for SLAC to progress to a valuable deployable protocol.", "num_citations": "22\n", "authors": ["511"]}
{"title": "Data-driven job dispatching in HPC systems\n", "abstract": " As High Performance Computing (HPC) systems get closer to exascale performance, job dispatching strategies become critical for keeping system utilization high while keeping waiting times low for jobs competing for HPC system resources. In this paper, we take a data-driven approach and investigate whether better dispatching decisions can be made by transforming the log data produced by an HPC system into useful knowledge about its workload. In particular, we focus on job duration, develop a data-driven approach to job duration prediction, and analyze the effect of different prediction approaches in making dispatching decisions using a real workload dataset collected from Eurora, a hybrid HPC system. Experiments on various dispatching methods show promising results.", "num_citations": "21\n", "authors": ["511"]}
{"title": "A big data analyzer for large trace logs\n", "abstract": " Current generation of Internet-based services are typically hosted on large data centers that take the form of warehouse-size structures housing tens of thousands of servers. Continued availability of a modern data center is the result of a complex orchestration among many internal and external actors including computing hardware, multiple layers of intricate software, networking and storage devices, electrical power and cooling plants. During the course of their operation, many of these components produce large amounts of data in the form of event and error logs that are essential not only for identifying and resolving problems but also for improving data center efficiency and management. Most of these activities would benefit significantly from data analytics techniques to exploit hidden statistical patterns and correlations that may be present in the data. The sheer volume of data to be analyzed makes\u00a0\u2026", "num_citations": "20\n", "authors": ["511"]}
{"title": "Biology-inspired approaches to peer-to-peer computing in BISON\n", "abstract": " BISON is a research project funded by the European Commission that is developing new techniques and paradigms for the construction of robust, self-organizing and self-repairing information systems as ensembles of autonomous agents that mimic the behavior of some natural or biological process. In this paper we give a brief overview of BISON, discuss some preliminary results for peer-to-peer systems, describe the ongoing work and indicate future research directions that appear to be promising.", "num_citations": "20\n", "authors": ["511"]}
{"title": "Middleware for dependable network services in partitionable distributed systems\n", "abstract": " We describe the design and implementation of Jgroup: a middleware system that integrates group technology with distributed objects and is based on Java RMI. Jgroup supports a programming paradigm called object groups and enables development of dependable network services based on replication. Among the novel features of Jgroup is a uniform object-oriented interface for programming both services and their clients. The fact that Jgroup exposes network effects, including partitions, to applications makes it particularly suitable for developing highly-available services in partitionable distributed systems.", "num_citations": "20\n", "authors": ["511"]}
{"title": "Decentralized ranking in large-scale overlay networks\n", "abstract": " Modern distributed systems are often characterized by very large scale, poor reliability, and extreme dynamism of the participating nodes, with a continuous flow of nodes joining and leaving the system. In order to develop robust applications in such environments, middleware services aimed at dealing with the inherent unpredictability of the underlying networks are required. One such service is aggregation. In the aggregation problem, each node is assumed to have attributes. The task is to extract global information about these attributes and make it available to the nodes. Examples include the total free storage, the average load, or the size of the network. Efficient protocols for computing several aggregates such as average, count, and variance have already been proposed. In this paper, we consider calculating the rank of nodes, where the set of nodes has to be sorted according to a numeric attribute and each\u00a0\u2026", "num_citations": "17\n", "authors": ["511"]}
{"title": "Greedy cheating liars and the fools who believe them\n", "abstract": " Abstract                              Evolutionary algorithms based on \u201ctags\u201d can be adapted to induce cooperation in selfish environments such as peer-to-peer systems. In this approach, nodes periodically compare their utilities with random other peers and copy their behavior and links if they appear to have better utilities. Although such algorithms have been shown to posses many of the attractive emergent properties of previous tag models, they rely on the honest reporting of node utilities, behaviors and neighbors. But what if nodes do not follow the specified protocol and attempt to subvert it for their own selfish ends? We examine the robustness of a simple algorithm under two types of cheating behavior: a) when a node can lie and cheat in order to maximize its own utility and b) when a node acts nihilistically in an attempt to destroy cooperation in the network. For a test case representing an abstract cooperative\u00a0\u2026", "num_citations": "17\n", "authors": ["511"]}
{"title": "Reliable broadcasts and communication models: tradeoffs and lower bounds\n", "abstract": " Reliable Broadcast is a mechanism by which a processor in a distributed system disseminates a value to all other processors in the presence of both communication and processor failures. Protocols to achieve Reliable Broadcast are at the heart of most fault-tolerant applications. We characterize the execution time of Reliable Broadcast protocols as a function of the communication model. This model includes familiar communication structures such as fully-connected point-to-point graphs, linear chains, rings, broadcast networks (such as Ethernet) and buses. We derive a parameterized protocol that implements Reliable Broadcast for any member within this class. We obtain lower bound results that show the optimality of our protocols. The lower bound results identify a time complexity gap between systems where processors may only fail to send messages, and systems where processors may fail both to\u00a0\u2026", "num_citations": "17\n", "authors": ["511"]}
{"title": "Towards operator-less data centers through data-driven, predictive, proactive autonomics\n", "abstract": " Continued reliance on human operators for managing data centers is a major impediment for them from ever reaching extreme dimensions. Large computer systems in general, and data centers in particular, will ultimately be managed using predictive computational and executable models obtained through data-science tools, and at that point, the intervention of humans will be limited to setting high-level goals and policies rather than performing low-level operations. Data-driven autonomics, where management and control are based on holistic predictive models that are built and updated using live data, opens one possible path towards limiting the role of operators in data centers. In this paper, we present a data-science study of a public Google dataset collected in a 12K-node cluster with the goal of building and evaluating predictive models for node failures. Our results support the practicality of a data\u00a0\u2026", "num_citations": "16\n", "authors": ["511"]}
{"title": "A holistic approach to log data analysis in high-performance computing systems: The case of ibm blue gene/q\n", "abstract": " The complexity and cost of managing high-performance computing infrastructures are on the rise. Automating management and repair through predictive models to minimize human interventions is an attempt to increase system availability and contain these costs. Building predictive models that are accurate enough to be useful in automatic management cannot be based on restricted log data from subsystems but requires a holistic approach to data analysis from disparate sources. Here we provide a detailed multi-scale characterization study based on four datasets reporting power consumption, temperature, workload, and hardware/software events for an IBM Blue Gene/Q installation. We show that the system runs a rich parallel workload, with low correlation among its components in terms of temperature and power, but higher correlation in terms of events. As expected, power and temperature correlate\u00a0\u2026", "num_citations": "15\n", "authors": ["511"]}
{"title": "Selecting a \"primary partition\" in partitionable asynchronous distributed systems\n", "abstract": " We consider network applications that are based on the process group paradigm. When such applications are deployed over networks that are subject to failures, they may partition across several disconnected clusters resulting in multiple views of the group's current composition to exist concurrently. Application semantics determine which operations, if any, can be performed in different partitions without compromising consistency. For certain application classes, most (possibly all) operations need to be confined to a single primary partition while other partitions are allowed to service only a (possibly empty) subset of the operations. We propose a mechanism for deciding when a view constitutes the primary partition for the group. Our solution is highly flexible and has the following novel features: each group member can establish if it belongs to the primary partition or not, based solely on local information; the group\u00a0\u2026", "num_citations": "15\n", "authors": ["511"]}
{"title": "On programming with view synchrony\n", "abstract": " View synchrony has been proposed as a programming paradigm for developing reliable distributed applications. The paradigm is particularly attractive when the underlying computing system is asynchronous and prone to complex failure scenarios including partitions. View synchrony encourages a programming style where groups of processes cooperate closely in order to maintain some form of shared state among them. In this paper we examine the technical problems that arise in shared state management when programming applications using view synchrony. We identify three classes of problems corresponding to state transfer upon group joins, state recreation after total failures and state merging after partition unions. We argue that shared state problems are inherent to any implementation, and without explicit support, attempts to solve them may easily obscure much of the simplicity and elegance of view\u00a0\u2026", "num_citations": "14\n", "authors": ["511"]}
{"title": "FINJ: A fault injection tool for HPC systems\n", "abstract": " We present FINJ, a high-level fault injection tool for High-Performance Computing (HPC) systems, with a focus on the management of complex experiments. FINJ provides support for custom workloads and allows generation of anomalous conditions through the use of fault-triggering executable programs. FINJ can also be integrated seamlessly with most other lower-level fault injection tools, allowing users to create and monitor a variety of highly-complex and diverse fault conditions in HPC systems that would be difficult to recreate in practice. FINJ is suitable for experiments involving many, potentially interacting nodes, making it a very versatile design and evaluation tool.", "num_citations": "12\n", "authors": ["511"]}
{"title": "SLACER: randomness to cooperation in peer-to-peer networks.\n", "abstract": " Peer-to-peer applications can benefit from human friendship networks (e.g., e-mail contacts or instant message buddy lists). However these are not always available. We propose an algorithm, called SLACER that allows peer nodes to create their own friendship networks, through randomized interactions, producing an artificial social network (ASN) where nodes share high trust with their neighbors", "num_citations": "10\n", "authors": ["511"]}
{"title": "Application-based dynamic primary views in asynchronous distributed systems\n", "abstract": " We consider programming network applications that are based on the process group paradigm. When such applications are deployed in unreliable networks, they may partition into several disconnected clusters causing multiple views of the group's current composition to exist concurrently. In this paper we propose a mechanism for efficiently deciding when a view constitutes the \u201cprimary partition\u201d for the group. Our solution is highly flexible and has the following features: possibility to modify selection rules at run-time without having to halt and restart the application; support for dynamic groups whose membership may change not only due to failures/recoveries but also due to processes voluntarily joining and leaving; ability to re-establish a primary partition even after a \u201ctotal failure\u201d scenario where all group members crash. These features facilitate the development of partition-aware applications that are capable of\u00a0\u2026", "num_citations": "9\n", "authors": ["511"]}
{"title": "Heterogeneity-aware resource allocation in HPC systems\n", "abstract": " In their march towards exascale performance, HPC systems are becoming increasingly more heterogeneous in an effort to keep power consumption at bay. Exploiting accelerators such as GPUs and MICs together with traditional processors to their fullest requires heterogeneous HPC systems to employ intelligent job dispatchers that go beyond the capabilities of those that have been developed for homogeneous systems. In this paper, we propose three new heterogeneity-aware resource allocation algorithms suitable for building job dispatchers for any HPC system. We use real workload traces extracted from the Eurora HPC system to analyze the performance of our allocators when they are coupled with different schedulers. Our experimental results show that significant improvements can be obtained in job response times and system throughput over solutions developed for homogeneous systems. Our\u00a0\u2026", "num_citations": "8\n", "authors": ["511"]}
{"title": "Experimental Computer Performance and Evaluation D. Ferrari and M. Spadoni (eds.)\u00a9 SOGESTA, 1981 North-Holland Publishing Company\n", "abstract": " The concepts of synthetic programs and virtual memories (throughout this paper, we consider a paged implementation of virtual memory) have been with us for many years [Buch69][Denn 70]. As introduced by Buchholz, a synthetic program is a highly parametric program that is able to mimic a wide range of behaviours as measured by the amount of system resources consumed; namely, CPU cycles and 1/0 bandwidth.", "num_citations": "8\n", "authors": ["511"]}
{"title": "Predicting system-level power for a hybrid supercomputer\n", "abstract": " For current High Performance Computing systems to scale towards the holy grail of ExaFLOP performance, their power consumption has to be reduced by at least one order of magnitude. This goal can be achieved only through a combination of hardware and software advances. Being able to model and accurately predict the power consumption of large computational systems is necessary for software-level innovations such as proactive and power-aware scheduling, resource allocation and fault tolerance techniques. In this paper we present a 2-layer model of power consumption for a hybrid supercomputer (which held the top spot of the Green500 list on July 2013) that combines CPU, GPU and MIC technologies to achieve higher energy efficiency. Our model takes as input workload information - the number and location of resources that are used by each job at a certain time - and calculates the resulting system\u00a0\u2026", "num_citations": "7\n", "authors": ["511"]}
{"title": "Towards automatic social bootstrapping of peer-to-peer protocols\n", "abstract": " Current peer-to-peer systems rely on user intervention to install and update the software (protocols) that run on each node. We propose another direction where protocols are dynamically and automatically rolled-out over peers, with the peers themselves selecting those that are beneficial and rejecting those which are not. To achieve this, we argue that, new protocols should be \"injected\" live into a running P2P system, with peers themselves replicating them. This requires that peers select \"socially beneficial\" protocols even though they need to base this on their own individual performance evaluations. What we are proposing can be seen as a meta-protocol, which we call Automatic Social Bootstrapping, that intelligently selects and replicates those protocols that are for the social good --- that is, maximize the average utility of the entire population. We sketch an outline of the protocol and present some initial high\u00a0\u2026", "num_citations": "7\n", "authors": ["511"]}
{"title": "The BISON Project (Research Outlook).\n", "abstract": " Modern distributed information systems are gaining an increasing importance in our every day lives. As access to networked applications become omnipresent through PC\u2019s, hand-held and wireless devices, more and more economical, social and cultural transactions are becoming dependent on the reliability and availability of distributed applications. As a consequence of the increasing demands placed by users upon networked environments, the complexity of modern distributed systems has reached a level that puts them beyond our ability to deploy, manage and keep functioning correctly through traditional techniques. Part of the problem is due to the sheer size that these systems may reach, with millions of users and interconnected devices. The other aspect of the problem is due to the extremely complex interactions that may result among components even when their numbers are modest. Our current understanding of these systems is such that minor perturbations (eg, a software upgrade, a failure) in some remote corner of the system will often have unforeseen, and at times catastrophic, global repercussions. In addition to being fragile, many situations (eg, adding/removing components) arising from their highly dynamic environments require manual intervention to keep information systems functioning. In order to deal with the scale and dynamism that characterize modern distributed systems, we believe that a paradigm shift is required that includes self-organization, adaptation and resilience as intrinsic properties rather than as afterthought. For this reason, we have started BISON", "num_citations": "7\n", "authors": ["511"]}
{"title": "A machine learning approach to online fault classification in HPC systems\n", "abstract": " As High-Performance Computing (HPC) systems strive towards the exascale goal, failure rates both at the hardware and software levels will increase significantly. Thus, detecting and classifying faults in HPC systems as they occur and initiating corrective actions before they can transform into failures becomes essential for continued operation. Central to this objective is fault injection, which is the deliberate triggering of faults in a system so as to observe their behavior in a controlled environment. In this paper, we propose a fault classification method for HPC systems based on machine learning. The novelty of our approach rests with the fact that it can be operated on streamed data in an online manner, thus opening the possibility to devise and enact control actions on the target system in real-time. We introduce a high-level, easy-to-use fault injection tool called FINJ, with a focus on the management of complex\u00a0\u2026", "num_citations": "6\n", "authors": ["511"]}
{"title": "Stopping times of distributed consensus protocols: A probabilistic analysis\n", "abstract": " Given a model where each processor remains correct for an exponentially distributed random time and then fails independently of the others, we characterize system executions that permit the processors to reach consensus. We show that, with nonzero probability, a protocol can achieve consensus even during executions where the number of actual processors to fail exceeds its resiliency.", "num_citations": "6\n", "authors": ["511"]}
{"title": "The HOCA operating system specifications\n", "abstract": " This document describes the specification and some hints for design and construction of HOCAf, a simple operating system that has been designed as an educational tool to supplement formal operating system ideas through implementation. The system is level structured and incorporates most of the concepts found in modern operating systems. At Cornell, the HOCA implementation project accounts for the entire workload in a junior-level, two credit course called Practicum in Operating Systems which is a companion to the operating systems theory course.", "num_citations": "6\n", "authors": ["511"]}
{"title": "Design and implementation of the Berkeley virtual memory extensions to the UNIX operating system\n", "abstract": " This paper describes a modified version of the UNIX operating system that supports virtual memory through demand paging. The particular implementation being described here is specific to the VAX*-11/780 computer system although most of the design decisions have wider applicability.The modified system creates a large virtual address space for user programs while supporting the same user level interface as UNIX. The few new system calls that have been introduced are primarily aimed for performance enhancement. The paging system implements a variant of the global CLOCK replacement policy (an approximation of the global least recently used algorithm) with a working-set-like mechanism for the control of multiprogramming level.", "num_citations": "6\n", "authors": ["511"]}
{"title": "A data\u2010driven approach to modeling power consumption for a hybrid supercomputer\n", "abstract": " Power consumption of current High Performance Computing systems has to be reduced by at least one order of magnitude before they can be scaled up towards ExaFLOP performance. While we can expect novel hardware technologies and architectures to contribute towards this goal, significant advances have to come also from software technologies such as proactive and power\u2010aware scheduling, resource allocation, and fault\u2010tolerant computing. Development of these software technologies in turn relies heavily on our ability to model and accurately predict power consumption in large computing systems. In this paper, we present a data\u2010driven model of power consumption for a hybrid supercomputer (which held the top spot in the Green500 ranking in June 2013) that combines CPU, GPU, and MIC technologies to achieve high levels of energy efficiency. Our model takes as input workload characteristics\u2014the\u00a0\u2026", "num_citations": "5\n", "authors": ["511"]}
{"title": "Peer-to-peer document sharing using the ant paradigm\n", "abstract": " The peer-to-peer (P2P) paradigm for building distributed applications has recently gained renewed attention, partly due to the enormous success of systems like Napster and Gnutella. Subsequently, a multitude of projects focusing on anonymity, security, routing and reliability aspects of P2P have been initiated. A framework that supports the design, evaluation and implementation phases of P2P application development is currently missing. The Anthill project is an attempt to fill this void. In this paper we give a brief overview of Anthill and describe Gnutant, a document sharing application that combine the scalability property of Freenet with the free search capabilities of Gnutella. In addition, we present preliminary simulation results obtained by running the Gnutant application in the Anthill simulation environment. The simulation results indicate that after an initialization period, Gnutant is effective in finding documents.", "num_citations": "5\n", "authors": ["511"]}
{"title": "Communication Architectures for Fast Reliable Broadcasts.\n", "abstract": " Reliable Broadcast. A distinguished processor, called the transmitter, broadcasts a local value u such that the following two requirements are satisfied:", "num_citations": "5\n", "authors": ["511"]}
{"title": "Constraint Programming-Based Job Dispatching for Modern HPC Applications\n", "abstract": " HPC systems are increasingly being used for big data analytics and predictive model building that employ many short jobs. In these application scenarios, HPC job dispatchers need to process large numbers of short jobs quickly and make decisions on-line while ensuring high Quality-of-Service (QoS) levels and meet demanding timing requirements. Constraint Programming (CP) is an effective approach for tackling job dispatching problems. Yet, the state-of-the-art CP-based job dispatchers are unable to satisfy the challenges of on-line dispatching and take advantage of job duration predictions. These limitations jeopardize achieving high QoS levels, and consequently impede the adoption of CP-based dispatchers in HPC systems. We propose a class of CP-based dispatchers that are more suitable for HPC systems running modern applications. The new dispatchers are able to reduce the time required\u00a0\u2026", "num_citations": "4\n", "authors": ["511"]}
{"title": "Online fault classification in hpc systems through machine learning\n", "abstract": " As High-Performance Computing (HPC) systems strive towards the exascale goal, studies suggest that they will experience excessive failure rates. For this reason, detecting and classifying faults in HPC systems as they occur and initiating corrective actions before they can transform into failures will be essential for continued operation. In this paper, we propose a fault classification method for HPC systems based on machine learning that has been designed specifically to operate with live streamed data. We cast the problem and its solution within realistic operating constraints of online use. Our results show that almost perfect classification accuracy can be reached for different fault types with low computational overhead and minimal delay. We have based our study on a local dataset, which we make publicly available, that was acquired by injecting faults to an in-house experimental HPC system.", "num_citations": "4\n", "authors": ["511"]}
{"title": "Programming Partition-Aware Network Applications\n", "abstract": " We consider the problem of developing reliable applications to be deployed in partitionable asynchronous distributed systems. What makes this task difficult is guaranteeing the consistency of shared state despite asynchrony, failures and recoveries, including the formation and merging of partitions. While view synchrony within process groups is a powerful paradigm that can significantly simplify reasoning about asynchrony and failures, it is insufficient for coping with recoveries and merging of partitions after repairs. We first give an abstract characterization for shared state management in partitionable asynchronous distributed systems and then show how views can be enriched to convey structural and historical information relevant to the group's activity. The resulting paradigm, called enriched view synchrony, can be implemented efficiently and leads to a simple programming methodology for solving\u00a0\u2026", "num_citations": "4\n", "authors": ["511"]}
{"title": "Report on the fourth ACM SIGOPS European workshop fault tolerance support in distributed systems\n", "abstract": " Continuing the tradition of Ziirich (1984), Amsterdam (1986) and Cambridge (1988), the 1990 edition of the ACM SIGOPS European Workshop was held in Bologna, Italy from 3 to 5 September.As the theme of the workshop,\" fault-tolerance support in distributed systems\" was selected. The motivation for this choice was the observation that distribution and fault tolerance can be argued to be two faces of the same medallion--any system that can tolerate failures must be distributed, and any system that is distributed must be capable of surviving partial failures. To provoke further investigation of this duality, the Call for Participation included the following questions:", "num_citations": "4\n", "authors": ["511"]}
{"title": "Broadcasting at the critical threshold in peer-to-peer networks\n", "abstract": " Peer-to-peer (P2P) applications often require periodic broadcasting of messages from a single node to the entire network. For example, a node may wish to inform the network the availability of a new service or resource, or a node may want to query the network for a particular file or service. In unstructured P2P networks, a simple solution to this problem is to use a \u201cflood-fill\u201d algorithm. In flood-filling, each node passes the message to all of its neighbors in the network when it first receives it. Although this approach is robust to high node turnover and failure rates, it is highly inefficient since many more messages than necessary are sent. Furthermore, the approach is vulnerable to \u201cfree-riding\u201d nodes that may receive messages but do not want to invest their resources (bandwidth) for forwarding them to neighbors. In this paper we present a modified flood-fill algorithm that increases efficiency and reduces the incentive for freeriding while retaining the robustness and simplicity of the original scheme. Our algorithm makes use of an evolutionary approach in which nodes copy strategies of others. Interestingly, the technique self-organizes the network towards a critical threshold of the network. The approach is novel and may have applications beyond broadcasting.", "num_citations": "3\n", "authors": ["511"]}
{"title": "Distributed Algorithms: 10th International Workshop, WDAG'96, Bologna, Italy, October 9-11, 1996. Proceedings\n", "abstract": " The volume presents 21 revised full papers selected from 75 submissions together with invited contributions by Butler Lampson and Domenico Ferrari. The volume reflects the transition of the area from formerly being the domain of a small research community to becoming the dominant computing paradigm and an industrial technology. Among the topics covered are all current aspects of distributed algorithms ranging from theory to applications such as distributed intelligent agents.", "num_citations": "3\n", "authors": ["511"]}
{"title": "Tools and Techniques for Adding Fault Tolerance to Distributed and Parallel Programs\n", "abstract": " The scale of parallel computing systems is rapidly approaching dimensions where fault tolerance can no longer be ignored. No matter how reliable the individual components may be, the complexity of these systems results in a significant probability of failure during lengthy computations. in the case of distributed memory multiprocessors, fault tolerance techniques developed for distributed operating systems and applications can be applied also to parallel computations. In the paper we survey some of the principal paradigms for fault-tolerant distributed computing and discuss their relevance to parallel processing. One particular technique--passive replication--is explored in detail as it forms the basis for fault tolerance in the Paralex parallel programming environment.Descriptors:", "num_citations": "2\n", "authors": ["511"]}
{"title": "Autonomy or interdependence in distributed systems?: a position paper\n", "abstract": " By their very nature, distributed systems require harmonious cooperation among their components. Interdependence is a natural consequence of this cooperation. While some minimum amount of cooperation is inevitable in any distributed system to achieve effective communication, distributed applications that are built can have varying degrees of cooperation between their corresponding components. Consequently, distributed\" systems\" are by definition interdependent but distributed\" applications\" need not be. We argue that the principal consideration in selecting an appropriate~ evel for cooperation (and interdependence) in distributed applications has to be~ fault tolerance/functionality/cost multi-way tradeoff. In other words, the question to be addressed is: how much are we willing to pay (both materially and in terms of performance) for the application to deliver a certain level of service in the presence of failures\u00a0\u2026", "num_citations": "2\n", "authors": ["511"]}
{"title": "Cognified Distributed Computing\n", "abstract": " Cognification - the act of transforming ordinary objects or processes into their intelligent counterparts through Data Science and Artificial Intelligence - is a disruptive technology that has been revolutionizing disparate fields ranging from corporate law to medical diagnosis. Easy access to massive data sets, data analytics tools and High-Performance Computing (HPC) have been fueling this revolution. In many ways, cognification is similar to the electrification revolution that took place more than a century ago when electricity became a ubiquitous commodity that could be accessed with ease from anywhere in order to transform mechanical processes into their electrical counterparts. In this paper, we consider two particular forms of distributed computing - Data Centers and HPC systems - and argue that they are ripe for cognification of their entire ecosystem, ranging from top-level applications down to low-level\u00a0\u2026", "num_citations": "1\n", "authors": ["511"]}
{"title": "Gossip-based self-managing services for large scale dynamic networks.\n", "abstract": " Modern IP networks are dynamic, large-scale and heterogeneous. This implies that they are more unpredictable and difficult to maintain and build upon. Implementation and management of decentralized applications that exploit these networks can be enabled only through a set of special middleware services that shield the application from the scale, dynamism and heterogeneity of the environment. Among others, these services have to provide communication services (routing, multicasting, etc.) and global information like network size, load distribution, etc. The goal is not to provide abstractions that hide the distributedness of the system, but rather, to hide the unpleasant features of the system, such as dynamism, scale and heterogeneity. Most importantly, these services have to be self-managing: they have to be able to maintain certain properties in the face of extreme dynamism of the network. In this manner, such services can serve as the lowest layer that makes possible building more complex applications, or simply as a plugin to enhance existing systems, for example, GRID environments. Apart from self-management, we require that the services be simple and lightweight, to allow easy implementation and incur low cost. Our approach to achieving these goals is based on the gossip communication model. Gossip protocols are simple, robust and scalable, besides, they can be applied to implement not only information dissemination, but several other functions, as we will show. So far, we have designed gossip-based protocols for maintaining random overlays, which define group membership. Based on this random overlay, we have designed\u00a0\u2026", "num_citations": "1\n", "authors": ["511"]}