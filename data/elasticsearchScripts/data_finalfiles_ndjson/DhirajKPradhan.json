{"title": "Fault-tolerant computer system design\n", "abstract": " Today, when designing a functional system is a common matter, emphasis is placed on designing mission-critical systems with enhanced reliability and a high degree of safety. This textbook covers architecture and design of fault-tolerant and high-availability systems, from both the theoretical and the practical points of view. The book is divided into eight parts. The first part comprises four chapters, the first of which is an introduction. The second deals with redundancy techniques for hardware, software, and time. Chapter 3 treats evaluation techniques. Chapter 4 deals with design methodologies. Part 2, comprising seven chapters, discusses the architecture of fault-tolerant computers. The first chapter is an introduction to fault-tolerant architectures. The second chapter treats the categorization of applications and related systems. The third chapter is dedicated to several well-known computer architectures such as IBM\u00a0\u2026", "num_citations": "1206\n", "authors": ["497"]}
{"title": "A cluster-based approach for routing in dynamic networks\n", "abstract": " The design and analysis of routing protocols is an important issue in dynamic networks such as packet radio and ad-hoc wireless networks. Most conventional protocols exhibit their least desirable behavior for highly dynamic interconnection topologies. We propose a new methodology for routing and topology information maintenance in dynamic networks. The basic idea behind the protocol is to divide the graph into a number of overlapping clusters. A change in the network topology corresponds to a change in cluster membership. We present algorithms for creation of clusters, as well as algorithms to maintain them in the presence of various network events. Compared to existing and conventional routing protocols, the proposed cluster-based approach incurs lower overhead during topology updates and also has quicker reconvergence. The effectiveness of this approach also lies in the fact that existing routing\u00a0\u2026", "num_citations": "672\n", "authors": ["497"]}
{"title": "Fault-tolerant computing: Theory and technique, Volume I\n", "abstract": " This book presents papers discussing the aspects of making computer applications systems reliable-fault diagnosis and fault tolerance. It provides a current perspective of the testing and test generation area and an overview of the basic theoretical issues presented. The book includes test generation algorithms such as PODEM, functional testing and random testing. Techniques and issues involved in the design for testability area are addressed. The theory and application of error correcting codes at the subsystem level are covered.", "num_citations": "542\n", "authors": ["497"]}
{"title": "GABA sets the tempo for activity-dependent adult neurogenesis\n", "abstract": " GABA, a major inhibitory neurotransmitter in the adult brain, activates synaptic and extrasynaptic GABAA receptors, causing hyperpolarization of mature neurons. As in the embryonic nervous system, GABA depolarizes neural progenitors and immature neurons in the adult brain. Several recent studies have suggested that GABA has crucial roles in regulating different steps of adult neurogenesis, including proliferation of neural progenitors, migration and differentiation of neuroblasts, and synaptic integration of newborn neurons. Here, we review recent findings on how GABA regulates adult neurogenesis in the subventricular zone of the lateral ventricles and in the dentate gyrus of the hippocampus. We also discuss an emerging view that GABA serves as a key mediator of neuronal activity in setting the tempo of adult neurogenesis.", "num_citations": "418\n", "authors": ["497"]}
{"title": "The de Bruijn multiprocessor network: a versatile parallel processing and sorting network for VLSI\n", "abstract": " It is shown that the binary de Bruijn multiprocessor network (BDM) can solve a wide variety of classes of problems. The BDM admits an N-node linear array, an N-node ring, (N-1)-node complete binary trees, ((3N/4)-2)-node tree machines, and an N-node one-step shuffle-exchange network, where N (=2/sup k/, k an integer) is the total number of nodes. The de Bruijn multiprocessor networks are proved to be fault-tolerant as well as extensible. A tight lower bound of the VLSI layout area of the BDM is derived; a procedure for an area-optimal VLSI layout is also described. It is demonstrated that the BDM is more versatile than the shuffle-exchange and the cube-connected cycles. Recent work has classified sorting architectures into (1) sequential input/sequential output, (2) parallel input/sequential output, (3) parallel input/parallel output, (4) sequential input/parallel output, and (5) hybrid input/hybrid output. It is\u00a0\u2026", "num_citations": "387\n", "authors": ["497"]}
{"title": "Improving performance of TCP over wireless networks\n", "abstract": " Transmission Control Protocol (TCP) assumes a relatively reliable underlying network where most packet losses are due to congestion. In a wireless network, however, packet losses will occur more often due to unreliable wireless links than due to congestion. When using TCP over wireless links, each packet loss on the wireless link results in congestion control measures being invoked at the source. This causes severe performance degradation. In this paper, we study the effect of: burst errors on wireless links; packet size variation on the wired network; local error recovery by the base station; and explicit feedback by the base station, on the performance of TCP over wireless networks. It is shown that the performance of TCP is sensitive to the packet size, and that significant performance improvements are obtained if a good packet size is used. While local recovery by the base station using link-level retransmissions\u00a0\u2026", "num_citations": "385\n", "authors": ["497"]}
{"title": "Fault injection: A method for validating computer-system dependability\n", "abstract": " A fault tolerant computer system's dependability must be validated to ensure that its redundancy has been correctly implemented and the system will provide the desired level of reliable service. Fault injection-the deliberate insertion of faults into an operational system to determine its response offers an effective solution to this problem. We survey several fault injection studies and discuss tools such as React (Reliable Architecture Characterization Tool) that facilitate its application.< >", "num_citations": "333\n", "authors": ["497"]}
{"title": "Recursive learning: a new implication technique for efficient solutions to CAD problems-test, verification, and optimization\n", "abstract": " Motivated by the problem of test pattern generation in digital circuits, this paper presents a novel technique called recursive learning that is able to perform a logic analysis on digital circuits. By recursively calling certain learning functions, it is possible to extract all logic dependencies between signals in a circuit and to perform precise implications for a given set of value assignments. This is of fundamental importance because it represents a new solution to the Boolean satisfiability problem. Thus, what we present is a new and uniform conceptual framework for a wide range of CAD problems including, but not limited to, test pattern generation, design verification, as well as logic optimization problems. Previous test generators for combinational and sequential circuits use a decision tree to systematically explore the search space when trying to generate a test vector. Recursive learning represents an attractive\u00a0\u2026", "num_citations": "303\n", "authors": ["497"]}
{"title": "A fault-tolerant communication architecture for distributed systems\n", "abstract": " A communication architecture for distributed processors is presented here. This architecture is based on a new topolgy we have developed, one which interconnects n nodes by using rn links where the maximum internode distance is logrn, and where each node has, at most, 2r, I/O ports. It is also shown that this network is fault-tolerant, being able to tolerate up to (r \u2212 1) node failures.", "num_citations": "267\n", "authors": ["497"]}
{"title": "Consensus with dual failure modes\n", "abstract": " The problem of achieving consensus in a distributed system is discussed. Systems aretreated in which either or both of two types of faults may occur: dormant (essentiallyomission and timing faults) and arbitrary (exhibiting arbitrary behavior, commonly referred to as Byzantine). Previous results showed that are number of dormant faults may be tolerated when there are no arbitrary faults and that, at most,(n-1/3) arbitrary faults may be tolerated when there are no dormant faults (n is the number of processors). Acontinuum is established between the previous results: an algorithm exists if n (f/submax/+ 2m/sub max/) and c (f/sub max/+ m/sub max/)(where c is the system connectivity), when faults are constrained so that there are at most f/sub max/and at most m/submax/of these that are arbitrary. An algorithm is given and compared to known algorithms. A method is given to establish virtual links so that the\u00a0\u2026", "num_citations": "229\n", "authors": ["497"]}
{"title": "Recoverable mobile environment: Design and trade-off analysis\n", "abstract": " The mobile wireless environment poses challenging problems in designing fault-tolerant systems because of the dynamics of mobility, and limited bandwidth available on wireless links. Traditional fault-tolerance schemes, therefore, cannot be directly applied to these systems. Mobile systems are often subject to environmental conditions which can cause loss of communications or data. Because of the consumer orientation of most mobile systems, run-time faults must be corrected with minimal (if any) intervention from the user. The fault-tolerance capability must, therefore, be transparent to the user. The paper presents recovery schemes for the failure of a mobile host. It portrays the limitations of the mobile wireless environment, and their impact on recovery protocols. The adaptation of well-known recovery schemes are presented which suit the mobile environment. The performance of these schemes has been\u00a0\u2026", "num_citations": "211\n", "authors": ["497"]}
{"title": "Recursive Learning: An attractive alternative to the decision tree for test generation in digital ci\n", "abstract": " In this paper, a source-based optimal dynamic multicasting routing algorithm is proposed, which satisfies the network conditions of delay constraints, cost minimization and adapts to a dynamic network events. Also, some network requirements are considered, such as the high-quality data distribution and the adaptability to dynamically changing events for the efficient dynamic group support. We construct the dynamic delay-bounded optimal multicast tree using partial multicast routing and evaluate the performance of the proposed algorithm by running simulations, written in C++ with randomly generated test networks on a Sun Sparc 20 workstation. We can observe that our algorithm approach to an optimal solution, by choosing the appropriate values for both the maximum group size and the delay bound.", "num_citations": "210\n", "authors": ["497"]}
{"title": "Wavelet fuzzy combined approach for fault classification of a series-compensated transmission line\n", "abstract": " Series capacitor protected by metal-oxide varistor and air-gap arrangement imposes problems to line protection and other online decisions. Discrete wavelet transform integrated with a fuzzy logic system is designed for fault classification of a transmission line possessing a series capacitor at the midpoint. The approach uses information obtained from the wavelet decomposition of current signals for faulty phase selection and section identification. Two different FLSs are designed for the two classification objectives in this paper.", "num_citations": "175\n", "authors": ["497"]}
{"title": "Identification of cis Elements Directing Termination of Yeast Nonpolyadenylated snoRNA Transcripts\n", "abstract": " RNA polymerase II (Pol II) termination is triggered by sequences present in the nascent transcript. Termination of pre-mRNA transcription is coupled to recognition of cis-acting sequences that direct cleavage and polyadenylation of the pre-mRNA. Termination of nonpolyadenylated [non-poly(A)] Pol II transcripts in Saccharomyces cerevisiae requires the RNA-binding proteins Nrd1 and Nab3. We have used a mutational strategy to characterize non-poly(A) termination elements downstream of the SNR13 and SNR47 snoRNA genes. This approach detected two common RNA sequence motifs, GUA[AG] and UCUU. The first motif corresponds to the known Nrd1-binding site, which we have verified here by gel mobility shift assays. We also show that Nab3 protein binds specifically to RNA containing the UCUU motif. Taken together, our data suggest that Nrd1 and Nab3 binding sites play a significant role in defining non\u00a0\u2026", "num_citations": "172\n", "authors": ["497"]}
{"title": "Modeling non-syndromic autism and the impact of TRPC6 disruption in human neurons\n", "abstract": " An increasing number of genetic variants have been implicated in autism spectrum disorders (ASDs), and the functional study of such variants will be critical for the elucidation of autism pathophysiology. Here, we report a de novo balanced translocation disruption of TRPC6, a cation channel, in a non-syndromic autistic individual. Using multiple models, such as dental pulp cells, induced pluripotent stem cell (iPSC)-derived neuronal cells and mouse models, we demonstrate that TRPC6 reduction or haploinsufficiency leads to altered neuronal development, morphology and function. The observed neuronal phenotypes could then be rescued by TRPC6 complementation and by treatment with insulin-like growth factor-1 or hyperforin, a TRPC6-specific agonist, suggesting that ASD individuals with alterations in this pathway may benefit from these drugs. We also demonstrate that methyl CpG binding protein-2 (MeCP2\u00a0\u2026", "num_citations": "170\n", "authors": ["497"]}
{"title": "A cluster-based approach for routing in ad-hoc networks\n", "abstract": " This paper presents a\\cluster-based\" approach to routing in ad-hoc networks. A cluster is de ned by a subset of nodes which arereachable'to each other. Our approach is motivated by our study of existence of clusters (size greater than 2) in random graphs. The basic idea behind the protocol is to divide the graph into number of overlapping clusters. A change in the network topology corresponds to a change in the cluster membership. Performance of the proposed routing protocol (reconvergence time, and update overhead) will hence be determined by the average cluster size in the network graph. The e ectiveness of this approach lies in the fact that existing routing protocols can be directly applied to the network {replacing the nodes by clusters. When the average cluster size is less than 2, the proposed approach does not perform any worse than the existing routing protocols. Generalization of the proposed approach is a subject of ongoing research.", "num_citations": "170\n", "authors": ["497"]}
{"title": "NiVER: Non-increasing variable elimination resolution for preprocessing SAT instances\n", "abstract": " The original algorithm for the SAT problem, Variable Elimination Resolution (VER/DP) has exponential space complexity. To tackle that, the backtracking-based DPLL procedure [2] is used in SAT solvers. We present a combination of two techniques: we use NiVER, a special case of VER, to eliminate some variables in a preprocessing step, and then solve the simplified problem using a DPLL SAT solver. NiVER is a strictly formula size not increasing resolution based preprocessor. In the experiments, NiVER resulted in up to 74% decrease in N (Number of variables), 58% decrease in K (Number of clauses) and 46% decrease in L (Literal count). In many real-life instances, we observed that most of the resolvents for several variables are tautologies. Such variables are removed by NiVER. Hence, despite its simplicity, NiVER does result in easier instances. In case NiVER removable variables are not present\u00a0\u2026", "num_citations": "164\n", "authors": ["497"]}
{"title": "Roll-forward checkpointing scheme: A novel fault-tolerant architecture\n", "abstract": " We propose a novel architecture for a fault-tolerant multiprocessor environment. It is assumed that the multiprocessor organization consists of a pool of active processing modules and either a small number of spare modules or active modules with some spare processing capacity. A fault-tolerance scheme is developed for duplex systems using checkpoints. Our scheme, unlike traditional checkpointing schemes, requires no rollbacks for recovering from single faults. The objective is to achieve performance of a triple modular redundant system using duplex system redundancy.< >", "num_citations": "161\n", "authors": ["497"]}
{"title": "Error-correcting codes and self-checking circuits\n", "abstract": " Error-control coding techniques, implemented by means of self-checking circuits, will improve system reliability.", "num_citations": "151\n", "authors": ["497"]}
{"title": "A new framework for designing and analyzing BIST techniques and zero aliasing compression\n", "abstract": " A general framework for shift register-based signature analysis is presented, and a mathematical model for this framework-based on coding theory-is developed. There are two key features of this formulation, first, it allows for uniform treatment of LFSR, MISR, and multiple MISR-based signature analyzer. In addition, using this formulation, a new compression scheme for multiple output CUT is proposed. This scheme, referred to as multiinput LFSR, has the potential to achieve better aliasing than other schemes such as the multiple MISR scheme of comparable hardware complexity. Several results on aliasing are presented, and certain known results are shown to be direct consequences of the formulation. Also developed are error models that take into account the circuit topology and the effect of faults at the outputs. Using these models, exact closed-form expressions for aliasing probability are developed. A closed\u00a0\u2026", "num_citations": "138\n", "authors": ["497"]}
{"title": "A fast and efficient strategy for submesh allocation in mesh-connected parallel computers\n", "abstract": " A new approach for dynamic submesh allocation in mesh-connected multiprocessor system, which supports a multi-user environment, is proposed. The proposed strategy effectively prunes the search space by searching for free submeshes on the corners of allocated submeshes along with the corners of the mesh system. A submesh is selected with the potential of causing the least amount of fragmentation in the system. The proposed strategy possesses complete submesh recognition capability; it is a best-fit strategy, as well. Existing strategies do not provide this combination of capabilities. The deallocation time and memory overhead is shown to be constant in that it does not grow with the size of the mesh. Simulation results indicate that the proposed strategy outperforms the existing ones in terms of parameters such as average delay in honoring a request, standard deviation of the delays, average allocation\u00a0\u2026", "num_citations": "120\n", "authors": ["497"]}
{"title": "Fault-tolerant multiprocessor link and bus network architectures\n", "abstract": " This paper presents a general class of regular networks which provide optimal (near-optimal) fault tolerance.", "num_citations": "119\n", "authors": ["497"]}
{"title": "Matrix codes for reliable and cost efficient memory chips\n", "abstract": " This paper presents a method to protect memories against multiple bit upsets and to improve manufacturing yield. The proposed method, called a Matrix code, combines Hamming and Parity codes to assure the improvement of reliability and yield of the memory chips in the presence of high defects and multiple bit-upsets. The method is evaluated using fault injection experiments. The results are compared to well-known techniques such as Reed-Muller and Hamming codes. The proposed technique performs better than the Hamming codes and achieves comparable performance with Reed-Muller codes with very favorable implementation gains such as 25% reduction in area and power consumption. It also achieves reliability increase by more than 50% in some cases. Further, the yield benefits provided by the proposed method, measured by the yield improvements per cost metric, is up to 300% better than the\u00a0\u2026", "num_citations": "117\n", "authors": ["497"]}
{"title": "A new class of error-correcting/detecting codes for fault-tolerant computer applications\n", "abstract": " Separable error-correcting/detecting codes are developed that provide protection against combinations of both unidirectional and random errors. Specifically, codes are presented which can both: 1) correct (detect) some t random errors, and 2) detect any number of unidirectional errors which may also contain t or fewer random errors. Necessary and sufficient conditions for the existence of these codes are also developed. Decoding algorithms for these codes are presented, and implementations of the algorithms are also discussed.", "num_citations": "116\n", "authors": ["497"]}
{"title": "A novel Si-tunnel FET based SRAM design for ultra low-power 0.3 V VDD applications\n", "abstract": " Steep sub-threshold transistors are promising candidates to replace the traditional MOSFETs for sub-threshold leakage reduction. In this paper, we explore the use of Inter-Band Tunnel Field Effect Transistors (TFETs) in SRAMs at ultra low supply voltages. The uni-directional current conducting TFETs limit the viability of 6 T SRAM cells. To overcome this limitation, 7 T SRAM designs were proposed earlier at the cost of extra silicon area. In this paper, we propose a novel 6 T SRAM design using Si-TFETs for reliable operation with low leakage at ultra low voltages. We also demonstrate that a functional 6 T TFET SRAM design with comparable stability margins and faster performances at low voltages can be realized using proposed design when compared with the 7 T TFET SRAM cell. We achieve a leakage reduction improvement of 700 X and 1600 X over traditional CMOS SRAM designs at V DD  of 0.3 V and 0.5 V\u00a0\u2026", "num_citations": "114\n", "authors": ["497"]}
{"title": "Optimal unidirectional error detecting/correcting codes\n", "abstract": " In this correspondence a class of t-error correcting and multiple unidirectional error detecting systematic codes is presented. These codes are significantly more efficient than the earlier codes. The efficiency of these codes approaches the efficiency of the BCH codes, asymptotically. Furthermore, it is shown that these codes can be easily decoded. Also in this correspondence we have presented a generalization of Berger codes over Zq; these new codes are also shown to be optimal.", "num_citations": "112\n", "authors": ["497"]}
{"title": "A novel pattern generator for near-perfect fault-coverage\n", "abstract": " A new design methodology for a pattern generator is proposed, formulated in the context of on-chip BIST. The pattern generator consists of two components: a GLFSR, earlier proposed as a pseudo-random pattern generator, and combinational logic, to snap the outputs of the pseudo-random pattern generator. Using fewer test patterns with only a small area overhead, this combinatorial logic block, for a particular CUT, can be designed to achieve nearly 100% single stuck-at fault coverage. Specifically, where weighted pattern generators only enhance the probability of testing a specified set of hard-to-detect faults, the proposed combinational logic, using a comparable hardware overhead, can guarantee generating the test for those faults. Experimental results demonstrate that under identical conditions, the fault coverage of the proposed pattern generator is significantly higher, compared to the conventional\u00a0\u2026", "num_citations": "98\n", "authors": ["497"]}
{"title": "The hyper-debruijn networks: Scalable versatile architecture\n", "abstract": " Both Hypercube and deBruijn networks possess desirable properties. It should be understood, though, that some of the attractive features of one are not found in the other. The architecture proposed in this paper is a combination of these architectures, providing some of the desirable properties of both the networks such as admitting many computationally important networks, flexibility in terms of connections per node as well as level of fault-tolerance. Also the network allows a simple VLSI layout, scalability as well as decomposability. Thus, these networks can be a potential candidate for VLSI multiprocessor networks. The proposed network possesses logarithmic diameter, optimal connectivity, and simple routing algorithms amendable to networks with faults. Importantly, in addition to being pancyclic, these hyper-deBruijn networks admit most computationally important subnetworks including rings, multidimensional\u00a0\u2026", "num_citations": "98\n", "authors": ["497"]}
{"title": "Roll-forward and rollback recovery: Performance-reliability trade-off\n", "abstract": " Performance and reliability achieved by a modular redundant system depend on the recovery scheme used. Typically, gain in performance using comparable resources results in reduced reliability. Several high performance computers are noted for small mean time to failure. Performance is measured here in terms of mean and variance of the task completion time, reliability being a task-based measure defined as the probability that a task is completed correctly. Two roll-forward schemes are compared with two rollback schemes for achieving recovery in duplex systems. The roll-forward schemes discussed here are based on a roll-forward checkpointing concept. Roll-forward recovery schemes achieve significantly better performance than rollback schemes by avoiding rollback in most common fault scenarios. It is shown that the roll-forward schemes improve performance with only a small loss in reliability as\u00a0\u2026", "num_citations": "95\n", "authors": ["497"]}
{"title": "Interaction between FEZ1 and DISC1 in regulation of neuronal development and risk for schizophrenia\n", "abstract": " Disrupted-in Schizophrenia 1 (DISC1), a susceptibility gene for major mental disorders, encodes a scaffold protein that has a multifaceted impact on neuronal development. How DISC1 regulates different aspects of neuronal development is not well understood. Here, we show that Fasciculation and Elongation Protein Zeta-1 (FEZ1) interacts with DISC1 to synergistically regulate dendritic growth of newborn neurons in the adult mouse hippocampus, and that this pathway complements a parallel DISC1-NDEL1 interaction that regulates cell positioning and morphogenesis of newborn neurons. Furthermore, genetic association analysis of two independent cohorts of schizophrenia patients and healthy controls reveals an epistatic interaction between FEZ1 and DISC1, but not between FEZ1 and NDEL1, for risk of schizophrenia. Our findings support a model in which DISC1 regulates distinct aspects of neuronal\u00a0\u2026", "num_citations": "94\n", "authors": ["497"]}
{"title": "GLFSR-a new test pattern generator for built-in-self-test\n", "abstract": " A new and effective pseudorandom test pattern generator, termed GLFSR, is introduced. These are linear feedback shift registers (LFSR's) over a Galois field GF(2/sup /spl delta//), (/spl delta/>1). Unlike conventional LFSR's, which are over GF(2), these generators are not equivalent to cellular arrays and are shown to achieve significantly higher fault coverage. Experimental results are presented in this paper depicting that the proposed GLFSR can attain fault coverage equivalent to the LPSR, but with significantly fewer patterns. Specifically, results obtained demonstrate that in combinational circuits, for both stuck-at as well as transition faults, the proposed GLFSR outperforms all conventional pattern generators. Moreover, these experimental results are validated by certain randomness tests which demonstrate that the patterns generated by GLFSR achieve a higher degree of randomless.", "num_citations": "92\n", "authors": ["497"]}
{"title": "Novel verification framework combining structural and OBDD methods in a synthesis environment\n", "abstract": " This paper presents a new methodology for formal logic verification for combinational circuits. Specifically, a structural approach is used, based on indirect implications derived by using Recursive Learning. This is extended to formulate a hybrid approach where this structural method is used to reduce the complexity of a subsequent functional method based on OBDDs. It is demonstrated how OBDD-based verification can take great advantage of structural preprocessing in a synthesis environment. The experimental results show the effective compromise achieved between memory-efficient structural methods and functional methods. One more advantage of these methods lies in the fact that resources that go into logic synthesis can effectively be reused for verification purposes.", "num_citations": "92\n", "authors": ["497"]}
{"title": "Error-control coding in computers\n", "abstract": " In this article, intended for readers with basic knowledge in coding, the codes used in actual systems are surveyed. Error control in high-speed memories is examined, including bit-error-correcting/detecting codes, byte-error-correcting/detecting codes, and codes to detect single-byte errors as well as correct single-bit errors and detect double-bit errors. Tape and disk memory codes for error control in mass memories are discussed. Processor error control and unidirectional error-control codes are covered, including the application of the latter to masking asymmetric line faults.< >", "num_citations": "91\n", "authors": ["497"]}
{"title": "Modeling defect spatial distribution\n", "abstract": " The center-satellite model for describing the distribution of defects on wafers is discussed. This model assigns each defect to a cluster. The distribution of cluster centers on a wafer is one basic component of the model. The other basic component is the distribution of defects (satellites) about the cluster centers. Physical justification for the model is provided. Current yield models are quite accurate for VLSI designs without redundancy. A more flexible model is needed to evaluate the redundancy techniques that will be an integral part of WSI. An example is provided to demonstrate the type of analysis necessary to analyze fault-tolerant designs using the model. Empirical research needed to obtain parameters for the model is commented on, as is the need to reevaluate prior empirical research in which assumptions were made that are relaxed by the center-satellite model.< >", "num_citations": "91\n", "authors": ["497"]}
{"title": "Aliasing probability for multiple input signature analyzer\n", "abstract": " Single and multiple multiple-input-signature-register (MISR) aliasing probability expressions are presented for arbitrary test lengths. A framework, based on algebraic codes, is developed for the analysis and synthesis of MISR-based test response compressors for BIST. This framework is used to develop closed-form expressions for the aliasing probability of MISR for arbitrary test length. An error model, based on q-ary symmetric channel, is proposed using more realistic assumptions. Results are presented that provide the weight distributions for q-ary codes (q=2/sup m/, where the circuit under test has m outputs). These results are used to compute the aliasing probability for the MISR compression technique for arbitrary test lengths. This result is extended to compression using two different MISRs. It is shown that significant improvements can be obtained by using two signature analyzers instead of one. The weight\u00a0\u2026", "num_citations": "90\n", "authors": ["497"]}
{"title": "Yield and performance enhancement through redundancy in VLSI and WSI multiprocessor systems\n", "abstract": " New challenges have been brought to fault-tolerant computing and processor architecture research because of developments in IC technology. One emerging area is development of architectures, built by interconnecting a large number of processing elements on a single chip or wafer. Two important areas, related to such VLSI processor arrays, are the focus of this paper; they are fault-tolerance and yield improvement techniques. Fault tolerance in these VLSI processor arrays is of real practical significance; it provides for much-needed reliability improvement. Therefore, we first describe the underlying concepts of fault tolerance at work in these multiprocessor systems. These precepts are useful to then present certain techniques that will incorporate fault tolerance integrally into the design. In the second part of the paper we discuss models that evaluate how yield enhancement and reliability improvement may be\u00a0\u2026", "num_citations": "90\n", "authors": ["497"]}
{"title": "Modeling the effect of redundancy on yield and performance of VLSI systems\n", "abstract": " The incorporation of different forms of redundancy has been recently proposed for various VLSI and WSI designs. These include regular architectures, built by interconnecting a large number of a few types of system elements on a single chip or wafer. The motivation for introducing fault-tolerance (redundancy) into these architectures is two-fold: yield enhancement and performance (like computational availability) improvement.", "num_citations": "89\n", "authors": ["497"]}
{"title": "Job scheduling in mesh multicomputers\n", "abstract": " A new approach for dynamic job scheduling in mesh-connected multiprocessor system, which supports a multi-user environment, is proposed. The proposed job scheduler combines a priority-based scheduling policy with a submesh reservation policy to obtain high performance in terms of high throughput, high utilization and low turn-around times for jobs. The proposed scheduling strategy offers the flexibility of achieving high performance at the expense of short-term 'fairness' towards certain jobs. A fast and efficient implementation of the proposed scheduler has also been presented. Simulation results indicate that our scheduling strategy outperforms the FCFS policy significantly by reducing the average waiting delay significantly.", "num_citations": "81\n", "authors": ["497"]}
{"title": "Accelerated dynamic learning for test pattern generation in combinational circuits\n", "abstract": " An efficient technique for dynamic learning called oriented dynamic learning is proposed. Instead of learning being performed for almost all signals in the circuit, it is shown that it is possible to determine a subset of these signals to which all learning operations can be restricted. It is further shown that learning for this set of signals provides the same knowledge about the nonsolution areas in the decision trees as the dynamic learning of SOCRATES. High efficiency is achieved by limiting learning to certain learning lines that lie within a certain area of the circuit, called the active area. Experimental results are presented to show that oriented dynamic learning is far more efficient than dynamic learning in SOCRATES.< >", "num_citations": "81\n", "authors": ["497"]}
{"title": "Dynamically restructurable fault-tolerant processor network architectures\n", "abstract": " A class of novel fault-tolerant multiprocessor networks is proposed. These networks are restructurable in that they can assume different logical configurations to suit different problem environments. More importantly, this restructuriing capability is not altered even after the occurrence of faults. These networks are novel in that they uniquely combine certain desirable features, including self-routing of messages, dynamic reconfigurability, fault-tolerance, the ability to incorporate incremental extension, as well as the capacity to be partitioned with fault-tolerance. What is important about these fault-tolerant features is that they are built-in as an integral part of the design, and not as done traditionally, by means of redundancy.", "num_citations": "80\n", "authors": ["497"]}
{"title": "Robust SRAM designs and analysis\n", "abstract": " This book provides a guide to Static Random Access Memory (SRAM) bitcell design and analysis to meet the nano-regime challenges for CMOS devices and emerging devices, such as Tunnel FETs. Since process variability is an ongoing challenge in large memory arrays, this book highlights the most popular SRAM bitcell topologies (benchmark circuits) that mitigate variability, along with exhaustive analysis. Experimental simulation setups are also included, which cover nano-regime challenges such as process variation, leakage and NBTI for SRAM design and analysis. Emphasis is placed throughout the book on the various trade-offs for achieving a best SRAM bitcell design. Provides a complete and concise introduction to SRAM bitcell design and analysis; Offers techniques to face nano-regime challenges such as process variation, leakage and NBTI for SRAM design and analysis; Includes simulation set-ups for extracting different design metrics for CMOS technology and emerging devices; Emphasizes different trade-offs for achieving the best possible SRAM bitcell design.", "num_citations": "79\n", "authors": ["497"]}
{"title": "A single ended 6T SRAM cell design for ultra-low-voltage applications\n", "abstract": " In this paper, we present a novel six-transistor (6T) single-ended static random access memory (SE-SRAM) cell for ultralow-voltage applications. The proposed design has a strong 2. 65X worst case read static noise margin (SNM) compared to a standard 6T SRAM. A strong write-ability of logic \u2018one\u2019is achieved, which is problematic in an SE-SRAM cell with a 36% improvement compared to standard 6T SRAMs. A 16\u00d7 16\u00d7 32 bit SRAM with proposed and standard 6T bitcells is simulated and evaluated for read SNM, write-ability and power. The dynamic and leakage power dissipation in the proposed 6T SRAM are reduced by 28% and 21%, respectively, as compared to standard 6T SRAM.", "num_citations": "79\n", "authors": ["497"]}
{"title": "Location management in distributed mobile environments\n", "abstract": " Location management is an important problem in distributed mobile computing. Location management consists of location updates, searches and search-updates. An update occurs when a mobile host changes location. A search occurs when a mobile host needs to be located. A search-update occurs after a successful search. Various strategies can be designed for search, update and search-update. Static location management uses one combination of search, update and search-update strategies throughout the execution. Simulations were carried out to evaluate the performance of different static strategies for various communication and mobility patterns. Simulation results indicate that performing search-updates significantly reduces the message overhead of location management.< >", "num_citations": "78\n", "authors": ["497"]}
{"title": "A theory of Galois switching functions\n", "abstract": " Galois switching functions (GSF's) are generalizations of binary functions in that the input and output variables can assume values over any finite field. The concepts of minterms, k-cubes and minimal complexity realizations as related to GSF are introduced.", "num_citations": "78\n", "authors": ["497"]}
{"title": "Test scheduling for network-on-chip with BIST and precedence constraints\n", "abstract": " Network-on-a-chip (NoC) is becoming a promising paradigm of core-based system. We propose a new method for test scheduling in NoC. The method is based on the use of a dedicated routing path for the test of each core. We show that test scheduling under this approach is NP-complete and present an ILP model for solving small NoC instances. For NoCs with larger number of cores, we present an efficient heuristic. We then improve the heuristic by including BISTs and precedence constraints. Experimental results for the ITC'02 SoC benchmarks show that the new method leads to substantial reduction on test application time compared to previous work. The inclusion of BIST tests and precedence constraints provides a comprehensive solution for test scheduling in NoC.", "num_citations": "76\n", "authors": ["497"]}
{"title": "A design for testability scheme to reduce test application time in full scan\n", "abstract": " Full scan is a widely accepted design for testability technique for sequential circuits. However, the test application time required by full scan could be high because of the necessity to scan in and scan out test vectors. In this paper, a hybrid scheme is presented that aims to reduce test application time in circuits with full scan. The proposed scheme exploits the inherent sequential nature of the circuit in conjunction with the additional controllability and observability available through full scan. Also, it is shown that the hybrid scheme has an additional advantage of being suited for testing transition faults.< >", "num_citations": "74\n", "authors": ["497"]}
{"title": "A new algorithm for order statistic and sorting\n", "abstract": " An algorithm for rank filtering and stack filtering is presented. This algorithm is simple and results in fast and easy implementations. Various implementations of the algorithm are described, and the H-tree design is shown to be most area efficient. Also introduced is a modification of the filtering algorithm that results in better implement sorting.< >", "num_citations": "73\n", "authors": ["497"]}
{"title": "Modified tree structure for location management in mobile environments\n", "abstract": " In this paper we suggest a new data structure for location management in mobile networks. The data structure is based on the tree location database structure. We suggest replacing the root and some of the higher levels of the tree with another structure that balances the average load of search requests. For this modification we use a set-ary butterfly network, which is a generalization of the well-known k-ary butterfly. We also suggest modifying the lowest level of the tree to reflect neighbouring geographical regions more accurately, and to support simple location data management. The modification of the lowest level also supports simple handoffs. The update of the proposed location database ensures correct location data following any number of transient faults that corrupt the location database information, and thus is self-stabilizing.", "num_citations": "70\n", "authors": ["497"]}
{"title": "Static and adaptive location management in mobile wireless networks\n", "abstract": " Location management is one of the most important issues in mobile computing. Location management consists of location updates, searches and search-updates. An update occurs when a mobile host changes location. A search occurs when a host wants to communicate with a mobile host whose location is unknown to the requesting host. A search-update occurs after a successful search, when the location information corresponding to the searched host is updated at some hosts. Various strategies can be designed for search, update and search-update. Static location management uses one fixed combination of search, update and search-update strategies. Simulations were carried out to evaluate the performance of different static location management strategies for various call-mobility patterns. It was noticed that performing search-updates significantly reduced the search costs without significantly increasing\u00a0\u2026", "num_citations": "68\n", "authors": ["497"]}
{"title": "Two economical directory schemes for large-scale cache coherent multiprocessors\n", "abstract": " Cache coherence problem is a major issue in the design of shared-memory multiprocessors. As the number of processors grows, traditional bus-based snoopy schemes for cache coherence are no longer adequate. Instead, the directory-based scheme is a promising alternative for the large-scale cache coherence problem. However, the storage overhead of (full-map) directory scheme may become too prohibitive as the system size goes up. This paper presents two distributed directory schemes, the tree directory and the hierarchical full-map directory, to deal with the storage overhead problem. Preliminary trace-driven evaluations show that the performance of our schemes compares favorably to the full-map directory scheme, while reducing the storage overhead by over 90%. These two schemes should lend themselves to the design and implementation of large-scale cache coherent multiprocessors.", "num_citations": "68\n", "authors": ["497"]}
{"title": "A BIST pattern generator design for near-perfect fault coverage\n", "abstract": " A new design methodology for a pattern generator is proposed, formulated in the context of on-chip BIST. The design methodology is circuit-specific and uses synthesis techniques to design BIST generators. The pattern generator consists of two components: a pseudorandom pattern generator (like an LFSR or, preferably, a GLFSR) and a combinational logic to map the outputs of the pseudorandom pattern generator. This combinational logic is synthesized to produce a given set of target patterns by mapping the outputs of the pseudorandom pattern generator. It is shown that, for a particular CUT, an area-efficient combinational logic block can be designed/synthesized to achieve 100 (or almost 100) percent single stuck-at fault coverage using a small number of test the This method is significantly different from weighted pattern generation and can guarantee testing of all hard-to-detect faults without expensive test\u00a0\u2026", "num_citations": "63\n", "authors": ["497"]}
{"title": "Flip-trees: fault-tolerant graphs with wide containers\n", "abstract": " A family of graphs is introduced with (d(d-1)/sup l/-2)/(d-2) nodes, where d is the degree of every node and l is any positive integer. The graphs have diameter 2l-1. In the presence of at most d-1 faults, the diameter increases to at most 2l+1. Furthermore, there exists a container (set of node-disjoint paths) of width d and length at most 2l+1 between every pair of nodes. The graphs are compared to those that have been proposed previously with respect to diameter, fault-tolerant diameter, container width, ease of routing, ease of fault-tolerant routing, and extensibility.< >", "num_citations": "62\n", "authors": ["497"]}
{"title": "Universal test sets for multiple fault detection in AND-EXOR arrays\n", "abstract": " The fault-detection problem in AND-EXOR arrays is formulated in a new framework. The arrays considered are more general compared to those by the previous researchers. Designs of fault-detecting test sets to detect all multiple faults in these networks are presented. The designs are independent of the function realized and hence can be generated easily.", "num_citations": "62\n", "authors": ["497"]}
{"title": "Impact of Doppler weather radar data on numerical forecast of Indian monsoon depressions\n", "abstract": " This work is a first assessment of utilizing Doppler Weather Radar (DWR) radial velocity and reflectivity in a mesoscale model for prediction of Bay of Bengal monsoon depressions (MDs). The Weather Research Forecasting (WRF) modelling system\u2014Advanced Research version (ARW) is customized and evaluated for the Indian monsoon region by generating domain\u2010specific Background Error (BE) statistics and experiments involving two assimilation strategies (cold start and cycling). The monthly averaged 24 h forecast errors for wind, temperature and moisture profiles were analysed. From the statistical skill scores, it is concluded that the cycling mode assimilation enhanced the performance of the WRF three\u2010dimensional variational data assimilation (3DVAR) system over the Indian region using conventional and non\u2010conventional observations. DWR data from a coastal site were assimilated for simulation of two\u00a0\u2026", "num_citations": "61\n", "authors": ["497"]}
{"title": "LOT: Logic optimization with testability-new transformations using recursive learning\n", "abstract": " A new approach to optimize multi-level logic circuits is introduced. Given a multi-level circuit, the synthesis method optimizes its area, simultaneously enhancing its random pattern testability. The method is based on structural transformations at the gate level. New transformations involving EX-OR gates derived based on indirect implications by Recursive Learning have been introduced in the synthesis of multi-level circuits. This method is augmented with transformations that specifically enhance random-pattern testability while reducing the area. Testability enhancement is an integral part of our synthesis methodology. Experimental results show that the proposed methodology can not only realize lower area, but also achieves better testability compared to testability enhancement synthesis tools such as tstfx. Specifically for ISCAS-85 benchmark circuits, it was observed that EX-OR gate-based transformations can\u00a0\u2026", "num_citations": "59\n", "authors": ["497"]}
{"title": "Recovery in distributed mobile environments\n", "abstract": " Mobile computing is a rapidly emerging trend in distributed computing. The new mobile computing environment presents many challenges due to the mobile nature of the hosts. The authors present some fault-tolerant data management strategies for a distributed mobile environment. These strategies need to be different from the traditional fault-tolerance approaches because of the resource limitations of mobile computing environment.", "num_citations": "58\n", "authors": ["497"]}
{"title": "Interconnection topologies for fault-tolerant parallel and distributed architectures\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "57\n", "authors": ["497"]}
{"title": "Undetectability of bridging faults and validity of stuck-at fault test sets\n", "abstract": " The study of bridging faults (or short circuits that occur between conducting paths) has become increasingly important with the advent of LSI technology. To date, only a very few papers have been published on this topic. Specifically, little is known regarding undetectable bridging faults. More importantly, what has yet to be explored are the effects of undetectable bridging faults on the tests designed to detect stuck-at faults.", "num_citations": "57\n", "authors": ["497"]}
{"title": "Fault-tolerant design strategies for high reliability and safety\n", "abstract": " Several fundamental results related to reliability and safety are analyzed. Modular redundant systems consisting of multiple identical modules and an arbiter are considered. It is shown that for a given level of redundancy, a large number of implementation alternatives exist with varying degree of reliability and safety. Strategies are formulated that achieve a maximal combination of reliability and safety. The effect of increasing the number of modules on system reliability and safety is analyzed. It is shown that when one considers safety in addition to reliability, it does not necessarily help to simply add modules to the system. Specifically, increasing the number of modules by just one does not always improve both reliability and safety. To improve reliability and safety simultaneously, at least two additional modules are required when the outputs of the individual modules do not have any redundant information (e.g\u00a0\u2026", "num_citations": "54\n", "authors": ["497"]}
{"title": "A new framework for designing and analyzing BIST techniques: computation of exact aliasing probability\n", "abstract": " A coding theory framework is developed for analysis and synthesis of compression techniques in the built-in self test (BIST) environment. Using this framework, exact expressions are derived for the linear feedback shift register aliasing probability. These are shown to be more accurate than earlier ones. Also shown is that there exist compression techniques for which the aliasing probability can be reduced to zero asymptotically. An error model is presented that incorporates the effects of faults on output response. It is shown that the coding theory framework correlates well with this proposed error model. A signature analysis technique is presented, which achieves smaller aliasing probability than other recently proposed schemes.< >", "num_citations": "54\n", "authors": ["497"]}
{"title": "Thermal-aware testing of network-on-chip using multiple-frequency clocking\n", "abstract": " Chip overheating due to excessive and unbalanced power dissipation has become a critical problem during test of complex core-based systems. In this paper, we address the overheating problem in network-on-chip systems by using on-chip multiple-frequency clocking. We control the core temperatures during test scheduling by varying the test clock frequency assigned to each core, so that the power dissipation of each core during test can be adjusted individually and thermal balance is achieved. We present a heuristic where the optimization process can be integrated with test scheduling. Experimental results for NoC benchmarks show that the proposed method can guarantee thermal safety and yield better thermal balance", "num_citations": "52\n", "authors": ["497"]}
{"title": "Reuse-based test access and integrated test scheduling for network-on-chip\n", "abstract": " In this paper, we propose a new method for test access and test scheduling in NoC-based system. It relies on a progressive reuse of the network resources for transporting test data to routers. We present possible solutions to the implementation of this scheme. We also show how the router testing can be scheduled concurrently with core testing to reduce test application time. Experimental results for the ITC'02 SoC benchmarks show that the proposed method can lead to substantial reduction on test application time compared to previous work based on the use of serial boundary scan. The method can also help to reduce hardware overhead", "num_citations": "52\n", "authors": ["497"]}
{"title": "Matrix codes: Multiple bit upsets tolerant method for sram memories\n", "abstract": " This paper presents a high level method called Matrix code to protect SRAM-based memories against multiple bit upsets. The proposed method combines hamming code and parity code to assure the reliability of memory in presence of multiple bit-upsets with low area and performance overhead. The method is evaluated using one million multiple-fault injection experiments; next reliability and MTTF of the protected memories are estimated based on fault injection experiments and several equations. The fault detection/correction coverage are also calculated and compared with previous methods i.e., Reed-Muller and hamming code. The results reveal that the proposed method behaves better than these methods in terms of fault detection and correction of multiple faults regarding to the area overhead.", "num_citations": "51\n", "authors": ["497"]}
{"title": "Matrix-based codes for adjacent error correction\n", "abstract": " Memories are one of the most widely used elements in electronic systems, and their reliability when exposed to single events upsets (SEUs) has been studied extensively. As transistor sizes shrink, multiple cells upsets (MCUs) are becoming an increasingly important factor in the reliability of memories exposed to radiation effects. To address this issue, built-in current sensors (BICS) or Parity codes have recently been applied in conjunction with single error correction/double error detection (SEC-DED) codes to protect memories from MCUs. In this paper, this approach is taken one step further, proposing specific codes optimized to provide protection against errors in adjacent bits in memories. By exploiting the locality of errors within an MCU and the error detection and location capabilities of parity codes, the proposed codes result in both a better protection level and a reduced cost. This technique improves memory\u00a0\u2026", "num_citations": "50\n", "authors": ["497"]}
{"title": "Investigating the impact of NBTI on different power saving cache strategies\n", "abstract": " The occupancy of caches has tended to be dominated by the logic bit value `0' approximately 75% of the time. Periodic bit flipping can reduce this to 50%. Combining cache power saving strategies with bit flipping can lower the effective logic bit value `0' occupancy ratios even further. We investigate how Negative Bias Temperature Instability (NBTI) affects different power saving cache strategies employing symmetric and asymmetric 6- transistor (6T) and 8T Static Random Access Memory (SRAM) cells. We notice that greater than 38% to 66% of the recovery in stability parameters (SNM and WNM) under different power saving cache strategies have been achieved for different SRAM cells based caches. We also study the process variations effect along with NBTI for 32nm and 45nm technology node. It is observed that the rate of recovery in asymmetric SRAM cells based caches is slightly higher than the symmetric\u00a0\u2026", "num_citations": "50\n", "authors": ["497"]}
{"title": "Submesh allocation in mesh multicomputers using busy-list: a best-fit approach with complete recognition capability\n", "abstract": " A new approach is proposed for dynamic submesh allocation in mesh-connected multicomputer system, which supports a multiuser environment. The proposed strategy effectively prunes the search space by searching for free submeshes on the corners of allocated (busy) submeshes along with the four corners of the mesh system. A submesh is selected with the potential of causing the least amount of fragmentation in the system. The proposed strategy possesses complete submesh recognition capability; it is a best-fit strategy, as well. Existing strategies do not provide this combination of capabilities. The deallocation time and memory overhead are shown to be constant in that they do not grow with the size of the mesh. To demonstrate effectiveness, the performance of the proposed strategy is compared against all existing schemes. Simulation results indicate that the proposed strategy outperforms existing ones in\u00a0\u2026", "num_citations": "50\n", "authors": ["497"]}
{"title": "A novel framework for logic verification in a synthesis environment\n", "abstract": " A new methodology for formal logic verification of combinational circuits is presented. Specifically, a structural (logic network) approach is used, based on indirect implications derived by recursive learning. It is shown that implications can be used to capture similarity between designs. This is extended to formulate a hybrid approach, this structural (logic network) information is used to reduce the complexity of a subsequent functional method based on OBDDs. We demonstrate that OBDD-based verification can take great advantage of structural preprocessing in a synthesis environment where many small operations are performed that modify the circuit. The experimental results show that an effective combination can be achieved between memory efficient structural methods and powerful functional methods.", "num_citations": "50\n", "authors": ["497"]}
{"title": "A uniform representation of single-and multistage interconnection networks used in SIMD machines\n", "abstract": " A switching theoretic framework for the study of interconnection networks is developed. An equivalence relationship between networks is defined. Single-stage and multistage networks that are particularly useful for single-instruction multiple-data stream (SIMD) machines are studied. It is shown that the networks form two distinct equivalence classes under this definition of equivalence relationship. It is shown that any multistage network can be easily modified to realize the permutations that are admissible by any other network which is equivalent to it.", "num_citations": "50\n", "authors": ["497"]}
{"title": "Rollforward checkpointing scheme: Concurrent retry with nondedicated spares\n", "abstract": " CiNii \u8ad6\u6587 - Rollforward checkpointing scheme : Concurrent retry with nondedicated spares CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74 \u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 CiNii\u7a93\u53e3\u696d\u52d9\u306e\u518d\u958b\u306b\u3064\u3044\u3066 Rollforward checkpointing scheme : Concurrent retry with nondedicated spares PRADHAN DK \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 PRADHAN DK \u53ce\u9332\u520a\u884c\u7269 IEEE Workshop on Fault-Tolerant Parallel and Distributed Systems, 1992 IEEE Workshop on Fault-Tolerant Parallel and Distributed Systems, 1992, 166-174, 1992 \u88ab\u5f15\u7528\u6587\u732e : 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 Random Checkpoint Models with N Tandem Tasks NAKAGAWA Toshio , NARUSE Kenichiro , MAEJI Sayori IEICE transactions on fundamentals of electronics, and 92\u2026", "num_citations": "49\n", "authors": ["497"]}
{"title": "Reliable network-on-chip based on generalized de Bruijn graph\n", "abstract": " In this paper, we propose the generalized de Bruijn graph as a reliable and efficient network topology for a Network-on-Chip (NoC) design. We also propose a reliable routing algorithm to detour a problematic (i.e., faulty or congested) link. Our experimental results show that the latency and energy consumption of generalized de Bruijn graph are much less with compared to Mesh and Torus, the two common NoC architectures in the literature. The low energy consumption of de Bruijn graph-based NoC makes it suitable for portable devices which have to operate on limited batteries. Also, the gate level implementation of the proposed reliable routing shows a small area, power, and timing overheads due to the proposed reliable routing algorithm.", "num_citations": "46\n", "authors": ["497"]}
{"title": "A method to derive compact test sets for path delay faults in combinational circuits\n", "abstract": " In path delay fault testing, the number of faults to be tested in a circuit is inherently very large. Therefore, deriving compact test sets for path delay faults is an important issue. This paper presents a method to derive compact test sets for path delay faults by using the notion of compatible faults. A technique to derive maximal compatible path delay fault sets is described. The technique is based on identifying necessary conditions on lines in a circuit along with values a line cannot take in order to test a given path. Experimental results on ISCAS benchmarks are presented to demonstrate the effectiveness of using this technique in reducing test set size.< >", "num_citations": "45\n", "authors": ["497"]}
{"title": "Complementary resistive switch-based arithmetic logic implementations using material implication\n", "abstract": " Memristors are considered among the most promising future building blocks of next-generation digital systems. This paper focuses on specific ways to implement logic and arithmetic unit using memristors. In particular, we present a set of complementary resistive switching (CRS)-based stateful logic operations that use material implication to provide the basic logic functionalities needed to realize logic circuits. The proposed solution benefits from the exponential reduction in sneak path current in crossbar implemented logic. This paper also presents a closed-form expression for sneak current and analyzes the impact of device variation on the behavior of the proposed logic blocks. Our technique, as other similar techniques proposed in the literature, requires several sequential steps to perform the computation. However, in this paper, we show that only three steps are required for implementing N input nand gate\u00a0\u2026", "num_citations": "44\n", "authors": ["497"]}
{"title": "Integrated circuit manufacturability: the art of process and design integration\n", "abstract": " \" INTEGRATED CIRCUIT MANUFACTURABILITY provides comprehensive coverage of the process and design variables that determine the ease and feasibility of fabrication (or manufacturability) of contemporary VLSI systems and circuits. This book progresses from semiconductor processing to electrical design to system architecture. The material provides a theoretical background as well as case studies, examining the entire design for the manufacturing path from circuit to silicon. Each chapter includes tutorial and practical applications coverage. INTEGRATED CIRCUIT MANUFACTURABILITY illustrates the implications of manufacturability at every level of abstraction, including the effects of defects on the layout, their mapping to electrical faults, and the corresponding approaches to detect such faults. The reader will be introduced to key practical issues normally applied in industry and usually required by quality, product, and design engineering departments in today's design practices:* Yield management strategies* Effects of spot defects* Inductive fault analysis and testing* Fault-tolerant architectures and MCM testing strategies. This book will serve design and product engineers both from academia and industry. It can also be used as a reference or textbook for introductory graduate-level courses on manufacturing.\"", "num_citations": "44\n", "authors": ["497"]}
{"title": "On the design and optimization of a quantum polynomial-time attack on elliptic curve cryptography\n", "abstract": " We consider a quantum polynomial-time algorithm which solves the discrete logarithm problem for points on elliptic curves over GF(2                 m               ). We improve over earlier algorithms by constructing an efficient circuit for multiplying elements of binary finite fields and by representing elliptic curve points using a technique based on projective coordinates. The depth of our proposed implementation is O(m                      2), which is an improvement over the previous bound of O(m                      3).", "num_citations": "43\n", "authors": ["497"]}
{"title": "REACT: A synthesis and evaluation tool for fault-tolerant multiprocessor architectures\n", "abstract": " A software testbed that performs automated life testing of a variety of multiprocessor architectures through simulated fault injection is discussed. It is being developed to meet the need for a generalized simulation tool which can evaluate system reliability and availability metrics while avoiding several of the limitations associated with combinatorial and Markov modeling. Incorporating detailed system, workload, and fault/error models, REACT can be more accurate and easier to use than many dependability prediction tools based on analytical approaches. The authors motivate the development of REACT, describe its features, and explain its use. Example applications for the software are provided, and its limitations are discussed.< >", "num_citations": "41\n", "authors": ["497"]}
{"title": "Virtual checkpoints: Architecture and performance\n", "abstract": " Checkpoint and rollback recovery is a technique that allows a system to tolerate a failure by periodically saving the entire state and, if an error is detected, rolling back to the prior checkpoint. A technique that embeds the support for checkpoint and rollback recovery directly into the virtual memory translation hardware is presented. The scheme is general enough to be implemented on various scopes of data such as a portion of an address space, a single address space, or multiple address spaces. The technique can provide a high-performance scheme for implementing checkpoint and rollback recovery. The performance. of the scheme is analyzed using a trace-driven simulation. The overhead is a function of the interval between checkpoints and becomes very small for intervals greater than 10/sup 6/references. However, the scheme is shown to be feasible for intervals as small as 1000 references under certain\u00a0\u2026", "num_citations": "40\n", "authors": ["497"]}
{"title": "A defect tolerance scheme for nanotechnology circuits\n", "abstract": " Lithography-based integrated circuit fabrication is rapidly approaching its limit in terms of feature size. The current alternative is nanotechnology-based fabrication, which relies on self-assembly of nanotubes or nanowires. Such a process is subject to a high defect rate, which can be tolerated using carefully crafted defect tolerance techniques. This paper presents an algorithm for reconfiguration-based defect tolerance in nanotechnology switches. The algorithm offers an average switch density improvement of 50% to 100% to most recently published techniques. The algorithm is also consistent in improving the yield through minimizing false rejects as the results show over a large sample. The improvement percentage varies depending on the manufactured switch size and the desired defect-free size with the improvement in efficiency directly proportional to the size of the switch.", "num_citations": "38\n", "authors": ["497"]}
{"title": "Modeling live and dead lines in cache memory systems\n", "abstract": " An analytical model that predicts the fraction of live and dead lines present in a cache memory in a multitasking environment is presented. The model is two-fold. The first portion evaluates the number of live lines created in a fully associative cache during the execution of a process. The second portion models the interaction of two processes that share a cache and run in an interleaved fashion. The model admits direct-mapped, set-associative, and fully associative cache architectures. The complete model assumes a hyperbolic (or fractal) model of program behavior. It predicts the variations of the total number of lines (footprint) as well as the number of live lines held by a process in the various caches as a function of the number of cache accesses. The accuracy of the model is validated through trace driven simulations.< >", "num_citations": "38\n", "authors": ["497"]}
{"title": "BCH code based multiple bit error correction in finite field multiplier circuits\n", "abstract": " This paper presents a design methodology for multiple bit error detection and correction in Galois field arithmetic circuits such as the bit parallel polynomial basis (PB) multipliers over GF(2 m ). These multipliers are crucial in most of the cryptographic hardware designs and hence it is essential to ensure that they are not vulnerable to security threats. Security threats arising from injected soft (transient) faults into a cryptographic circuit can expose the secret information, e.g. the secret key, to an attacker. To prevent such soft or transient fault related attacks, we consider fault tolerance as a method of mitigation. Most of the current fault tolerant schemes are only multiple bit error detectable but not multiple bit error correctable. Keeping this in view, we present a multiple bit error correction scheme based on the BCH codes, with an efficient bit-parallel Chien search module. This paper details the design procedure as well as\u00a0\u2026", "num_citations": "37\n", "authors": ["497"]}
{"title": "Store address generator with on-line fault-detection capability\n", "abstract": " A novel technique for address generation is presented in this correspondence. This scheme has two useful features. Addresses are generated with check bits as an integral part of the address in order to provide multi-fault-detection capability. To date, there exists no such scheme with this feature. Secondly, the addresses generated through this scheme are pseudorandom; therefore, they can be used for storage hierarchies using hash coding techniques.", "num_citations": "36\n", "authors": ["497"]}
{"title": "Can concurrent checkers help BIST?\n", "abstract": " Concurrent checkers are commonly used in computer systems to detect computational errors on-line, which enhances reliability. Using the coding theory framework developed ear-lier by the authors, concurrent checkers already available within the circuit are shown to be significant help to off-line testing. Specifically, test time can be reduced while improving the fault escape probability. The proposed combined scheme can be implemented with simple modification of existing hardware. Specifically proposed is a novel, dual use of concurrent checkers and BIST hardware, yield-ing mutual advantage.", "num_citations": "35\n", "authors": ["497"]}
{"title": "Designing interconnection buses in VLSI and WSI for maximum yield and minimum delay\n", "abstract": " Exact expressions for the yield of an interconnection bus as a function of its physical dimensions and the parameters and distribution of the possible open-circuit and short-circuit defects are derived. The effect of introducing redundancy into the bus is examined and the optimal layout of a given bus (with and without redundancy) is obtained. Any change in the layout of a bus may affect the propagation delay of the bus and, as a consequence, the performance of the VLSI chip. Hence, the delay of the designed bus in addition to its yield must be taken into account when determining the final layout of the bus. Both yield and delay are discussed through several numerical examples.< >", "num_citations": "35\n", "authors": ["497"]}
{"title": "Fault-tolerant multiprocessor and VLSI-based system communication architectures\n", "abstract": " This chapter presents a collection of theoretical results relevant to fault-tolerant multiprocessors. Most of the chapter is devoted to presenting interconnection structures that have some redundancy, making it possible to recover from faults. An impressive collection of theoretical results has been gathered; on the other hand, practical examples of working fault-tolerant multiprocessors are not given. The chapter is divided into sections on \u201cReliable Shared Bus Design,\u201d\u201cFault-Tolerance in Shared Memory Interconnections,\u201d\u201cFault Tolerant Loop Architecture,\u201d\u201cFault-tolerant Tree Networks,\u201d\u201cDynamically Reconfigurable Fault-tolerant Networks,\u201d\u201cFault-tolerance in Binary Cube Interconnection,\u201d\u201cFault-tolerant Graph Networks,\u201d and \u201cFault-tolerant VLSI-based Systems.\u201d Most of the sections are devoted to presenting redundant interconnection schemes that can replace failing nodes and communication links. The emphasis in\u00a0\u2026", "num_citations": "35\n", "authors": ["497"]}
{"title": "Interpretation of the 21-ns Isomer in Hg 190 as (\u03bd i 13 2) 2 from a g-Factor Measurement\n", "abstract": " A previous assignment of the 21-ns isomer Hg 190 as (\u03c0 h 11 2) 10+\u2212 2 is investigated by means of a g-factor measurement. The experimental g factor,-0.21\u00b10.02, determines the configuration of the isomer as (\u03bd i 13 2) 2 and suggests a renewed study of the level scheme of Hg 190.", "num_citations": "35\n", "authors": ["497"]}
{"title": "Practical design verification\n", "abstract": " Improve design efficiency and reduce costs with this practical guide to formal and simulation-based functional verification. Giving you a theoretical and practical understanding of the key issues involved, expert authors including Wayne Wolf and Dan Gajski explain both formal techniques (model checking, equivalence checking) and simulation-based techniques (coverage metrics, test generation). You get insights into practical issues including hardware verification languages (HVLs) and system-level debugging. The foundations of formal and simulation-based techniques are covered too, as are more recent research advances including transaction-level modeling and assertion-based verification, plus the theoretical underpinnings of verification, including the use of decision diagrams and Boolean satisfiability (SAT).", "num_citations": "34\n", "authors": ["497"]}
{"title": "SEU-mitigation placement and routing algorithms and their impact in SRAM-based FPGAs\n", "abstract": " In this paper, the authors propose a new SEU-mitigative placement and routing of circuits in the FPGAs which is based on the popular VPR tool. The VPR tool is modified so that during placement and routing, decisions are taken with awareness of SEU-mitigation. Moreover, no redundancies during the placement and routing are used but the algorithms are based on the SEU avoidance. Using the modified tool, i.e., S-VPR, the role of placement and routing algorithms on the fault-tolerance of circuits implemented on FPGAs is achieved. The secondary propose of this paper is to find which of placement or routing is more suited for decreasing SEU sensibility of circuits and to find whether these SEU sensibility reductions are cumulative or not when they applied in sequence. We have investigated the effect of S-VPR on several MCNC benchmarks and the results of the placement and routing have been compared to the\u00a0\u2026", "num_citations": "34\n", "authors": ["497"]}
{"title": "Dynamic testing strategy for distributed systems\n", "abstract": " Fault diagnosis is treated as two distinct processes: fault discovery and dissemination of diagnostic information. Previous research determined what level of self-diagnosability a given set of test in a homogeneous system achieves, using a model in which only node failures occur and test coverage is complete. Adopting the same model, a new methodology is presented that minimizes the overhead associated with periodic testing, thus lowering testing overhead. The method diagnoses up to c-.1 faults (c is the connectivity of the system topology). The savings in testing is valid when processor failure rates are low. Environments are also examined with high processor failure rates. It is shown that adopting the proposed methodology for such systems results in greater reliability, while maintaining the same effective processing power.< >", "num_citations": "34\n", "authors": ["497"]}
{"title": "A subthreshold single ended I/O SRAM cell design for nanometer CMOS technologies\n", "abstract": " Lowering supply voltage is an effective technique for power reduction in memory design, however traditional memory cell design fails to operate, as shown in [3], [10], at ultra-low voltages. Therefore, to operate cells in the subthreshold regime, new cell structures needs to be explored. Towards this, we present a single-ended I/O (SEIO) bit-line latch style 7-transistor static random access memory (SRAM) cell (7T-LSRAM) as an alternative for nanometer CMOS technology which can function in ultra-low voltage regime. Compared to existing 6-transistor (6T) cell or 10-transistor cell design, the proposed cell has 2X improved read stability and 36% better write-ability at lower supply voltage. Furthermore, the 7T-LSRAM has improved process variation tolerance. The area analysis shows that there is 18% increase in area penalty compared to the standard 6T cell, however the improved performance and process variation\u00a0\u2026", "num_citations": "33\n", "authors": ["497"]}
{"title": "Fast SEU detection and correction in LUT configuration bits of SRAM-based FPGAs\n", "abstract": " FPGAs are an appealing solution for the space-based remote sensing applications. However, in a low-earth orbit, configuration bits of SRAM-based FPGAs are susceptible to single-event upsets (SEUs). In this paper, a new protected CLB and FPGA architecture are proposed which utilize error detection and correction codes to correct SEUs occurred in LUTs of the FPGA. The fault detection and correction is achieved using online or offline fast detection and correction cycles. In the latter, detection and correction is performed in predefined error-correction intervals. In both of them error detections and corrections of k-input LUTs are performed with a latency of 2 k  clock cycle without any required reconfiguration and significant area overhead. The power and area analysis of the proposed techniques show that these methods are more efficient than the traditional schemes such as duplication with comparison and TMR\u00a0\u2026", "num_citations": "32\n", "authors": ["497"]}
{"title": "EBIST: A novel test generator with Built-In fault detection capability\n", "abstract": " A novel design methodology for test pattern generation in built-in self-test (BIST) is proposed. Experimental results are presented to demonstrate how a fault in the test pattern generator (TPG) itself can have serious consequences, a problem that has not been investigated. A solution is presented here, where the faults and errors in the generator itself are detected during the test in the TPG itself. This provides several major advantages, including the ability to distinguish between TPG and circuit under test (CUT) faults. In addition, this will ensure that there is no loss of fault coverage for the CUT caused by a fault in the TPG. Two different design methodologies are presented: The first guarantees all single fault/error detection, the second capable of detecting multiple faults and errors. The proposed linear feedback shift registers (LFSRs) do not have additional hardware overhead. Importantly, the test patterns generated\u00a0\u2026", "num_citations": "32\n", "authors": ["497"]}
{"title": "Processor allocation in hypercube multicomputers: Fast and efficient strategies for cubic and noncubic allocation\n", "abstract": " A new approach for dynamic processor allocation in hypercube multicomputers which supports a multi-user environment is proposed. A dynamic binary tree is used for processor allocation along with an array of free lists. Two algorithms are proposed based on this approach, capable of efficiently handling cubic as well as noncubic allocation. Time complexities for both allocation and deallocation are shown to be polynomial, a significant improvement over the existing exponential and even super-exponential algorithms. Unlike existing schemes, the proposed strategies are best-fit strategies within their search space. Simulation results indicate that the proposed strategies outperform the existing ones in terms of parameters such as average delay in honoring a request, average allocation time, average deallocation time, and memory overhead.< >", "num_citations": "30\n", "authors": ["497"]}
{"title": "A novel memristor-based hardware security primitive\n", "abstract": " Memristor is an exciting new addition to the repertoire of fundamental circuit elements. Alternatives to many security protocols originally employing traditional mathematical cryptography involve novel hardware security primitives, such as Physically Unclonable Functions (PUFs). In this article, we propose a novel hybrid memristor-CMOS PUF circuit and demonstrate its suitability through extensive simulations of environmental and process variation effects. The proposed PUF circuit has substantially less hardware overhead than previously proposed memristor-based PUF circuits while being inherently resistant to machine learning-based modeling attacks because of challenge-dependent delays of the memristor stages. The proposed PUF can be conveniently used in many security applications and protocols based on hardware-intrinsic security.", "num_citations": "29\n", "authors": ["497"]}
{"title": "Error-control techniques for logic processors\n", "abstract": " A new error-control technique for logic processors is given. The proposed technique uses Reed-Muller codes (RMC's). The design scheme given has better efficiency than the schemes proposed earlier. The improved efficiency is obtained by relaxing a basic assumption originally made by Elias. Furthermore, it is shown that the efficiency of the proposed scheme asymptotically approaches the maximum efficiency achievable by a practical though restricted class of error-control schemes. Reliability of the proposed scheme is studied.", "num_citations": "29\n", "authors": ["497"]}
{"title": "Improved decoding algorithm for high reliable reed muller coding\n", "abstract": " A new decoding technique for triple error Reed-Muller codes is proposed. In the best of our knowledge this is the first time that Reed-Muller Codes (RMC) as on-chip triple error correcting scheme is reported. We\u2019ve compared the area, delay and power overhead for incorporating RMC and widely used Hamming Codes into a register file. The RMC on-chip results in 4.4X MTTF improvement with fault rate \u03bb=10 \u22124  and 5X reliability improvement in 512MB memory with \u03bb=10 \u22125  upsets/bit per day sacrificing area power and delay.", "num_citations": "28\n", "authors": ["497"]}
{"title": "VERILAT: Verification using logic augmentation and transformations\n", "abstract": " This paper presents a new framework for formal logic verification. What is depicted here is fundamentally different from previous approaches. In earlier approaches, the circuit is either not changed during the verification process, as in OBDD or implication-based methods, or the circuit is progressively reduced during verification. Whereas in our approach, we actually enlarge the circuits by adding gates during the verification process. Specifically introduced here is a new technique that transforms the reference circuit as well as the circuit to be verified, so that the similarity between the two is progressively enhanced. This requires addition of gates to the reference circuit and/or the circuit to be verified. In the process, we reduce the dissimilarity between the two circuits, which makes it easier to verify the circuits.", "num_citations": "28\n", "authors": ["497"]}
{"title": "Single ended 6T SRAM with isolated read-port for low-power embedded systems\n", "abstract": " This paper presents a six-transistor (6T) single-ended static random access memory (SE-SRAM) bitcell with an isolated read-port, suitable for low-V DD  and low-power embedded applications. The proposed bitcell has a better static noise margin (SNM) and write-ability compared to a standard 6T bitcell and equivalent to an 8T bitcell [1]. An 8Kbit SRAM module with the proposed and standard 6T bitcells is simulated, including full blown parasitics using BPTM, 65 nm CMOS technology node to evaluate and compare different performance parameters. The active power dissipation in the proposed 6T design is 28% and 25% less, compared to standard 6T and 8T SRAM modules respectively.", "num_citations": "27\n", "authors": ["497"]}
{"title": "Multiple upsets tolerance in SRAM memory\n", "abstract": " This paper presents a high level method called matrix code to protect SRAM-based memories against multiple bit upsets. The proposed method combines hamming code and parity code to assure the reliability of memory in presence of multiple bit-upsets with low area and performance overhead. The method is evaluated using one million multiple-fault injection experiments; next reliability and MTTF of the protected memories are estimated based on fault injection experiments and several equations. The fault detection/correction coverage are also calculated and compared with previous methods i.e., Reed-Muller and hamming code. The results reveal that the proposed method behaves better than these methods in terms of fault detection and correction of multiple faults regarding to the area overhead.", "num_citations": "27\n", "authors": ["497"]}
{"title": "Aliasing and diagnosis probability in MISR and STUMPS using a general error model\n", "abstract": " A number of methods have been proposed to study aliasing in MISR compression. However, most of the methods can compute aliasing probability only for specific test lengths and/or specific error models.Recently, a GLFSR structure [15] was introduced which admits coding theory formulation. The conventional signature analyzers such as LFSR and MISR form special cases of this GLFSR structure. Using this formulation, a general result is now presented which computes the exact aliasing probability for MISRs with primitive feedback polynomials, for", "num_citations": "27\n", "authors": ["497"]}
{"title": "Sequential network design using extra inputs for fault detection\n", "abstract": " IEEE, TRANSACTIONS, ON, COMPUTERS,, VOL., C-32,, NO., 3,, MARCH, 1983,[2], D., C., Bossen, and, S., J., Hong,,\" Cause-effect, analysis, for, multiple, fault, detection, in, combinational, networks,\", IEEE, Trans., Comput.,, vol., C-20,, pp., 1252-1257,, Nov., 1971.,[3], F., W., Clegg,,\" Use, of, SPOOF's, in, the, analysis, of, faulty, logic, networks,\", IEEE, Trans., Comput.,, vol., C-22,, pp., 229-234,, Mar., 1973.,[4], M., J., Flomenhoft,, S., C., Si, and, A., K., Susskind,,\" Algebraic, techniques, for, finding, tests, for, several, fault, types,\", in, Proc., 1973, Int., Symp., Fault-Tolerant, Computing,, pp., 85-90.,[5], J., P., Hayes,,\" A, NAND, model, for, fault, diagnosis, in, combinational, logic, networks,\", IEEE, Trans., Comput.,, vol., C-20,, pp., 1496-1506,, Dec., 1971.,[61, J., P., Hayes,,\" The, fanout, structure, of, switching, functions,\", J., Ass., Comput., Mach.,, vol., 22,, pp., 551-571,, Oct., 1976.,[71, J., P., Hayes,,\" Path, complexity, of, logic\u00a0\u2026", "num_citations": "27\n", "authors": ["497"]}
{"title": "Pseudomonas fluorescens PGPR bacteria as well as biocontrol agent: A review\n", "abstract": " Plant growth-promoting rhizobacteria (PGPR) are a diverse group of microorganisms that are increasingly appreciated for their contributions to primary productivity through promotion of growth and triggering of induced systemic resistance (ISR) in plants. By triggering plant defense, PGPR can make an important contribution to biocontrol of pests and pathogens of plants. Fluorescent Pseudomonas belong to plant Growth Promoting Rhizobacteria (PGPR) the important major group of bacteria that play a major role in the plant growth promotion, induced systemic resistance, biological control of pathogens. The ability of bacterial siderophores and antibiotics to suppress phytopathogens could be the significant agronomic importance. Both mechanisms have essential functions in microbial antagonism but also the mechanisms leads to elicit induced resistance. Resistance-inducing and antagonistic rhizobacteria might be useful in formulating new inoculants, offering an attractive alternate of environmentally friendly biological control of plant disease and improving the cropping systems into which it can be most profitably applied.", "num_citations": "26\n", "authors": ["497"]}
{"title": "Verilog-A based effective complementary resistive switch model for simulations and analysis\n", "abstract": " Resistive memory, also known as memristor, is recently emerging as a potential successor to traditional charge-based memories. However, the nanoscale features of these devices introduce challenges in modeling and simulation. In this paper, we propose a novel Verilog-A based complementary resistive switch memory model for effective simulation and analysis. Our proposed model captures desired nonlinear characteristics using voltage based state control as opposed to recently proposed current based state control. We demonstrate that such state control has advantages for our proposed CRS model based crossbar arrays in terms of symmetric ON/OFF voltages and significantly reduced sneak path currents with high noise margin compared to traditional memristor based architectures. Moreover, to validate the effectiveness of our Verilog-A based model we carry out extensive simulations and analyses for\u00a0\u2026", "num_citations": "26\n", "authors": ["497"]}
{"title": "An O(m2)-depth quantum algorithm for the elliptic curve discrete logarithm problem over GF(2m)a\n", "abstract": " We consider a quantum polynomial-time algorithm which solves the discrete logarithmproblem for points on elliptic curves over GF(2m). We improve over earlier algorithmsby constructing an efficient circuit for multiplying elements of binary finite fields andby representing elliptic curve points using a technique based on projective coordinates.The depth of our proposed implementation, executable in the Linear Nearest Neighbor(LNN) architecture, is O(m2), which is an improvement over the previous bound ofO(m3) derived assuming no architectural restrictions.", "num_citations": "26\n", "authors": ["497"]}
{"title": "LOT: Logic Optimization with Testability. New transformations for logic synthesis\n", "abstract": " A new approach to optimize multilevel logic circuits is introduced. Given a multilevel circuit, the synthesis method optimizes its area while simultaneously enhancing its random pattern testability. The method is based on structural transformations at the gate level. New transformations involving EX-OR gates as well as Reed-Muller expansions have been introduced in the synthesis of multilevel circuits. This method is augmented with transformations that specifically enhance random-pattern testability while reducing the area. Testability enhancement is an integral part of our synthesis methodology. Experimental results show that the proposed methodology not only can achieve lower area than other similar tools, but that it achieves better testability compared to available testability enhancement tools such as tstfx. Specifically for ISCAS-85 benchmark circuits, it was observed that EX-OR gate-based transformations\u00a0\u2026", "num_citations": "26\n", "authors": ["497"]}
{"title": "Zero aliasing compression\n", "abstract": " A compression technique, called periodic quotient compression, which eliminates the problem of aliasing is presented. The compression in signature analysis is based on polynomial division, where the remainder is the signature and the quotient is discarded. With this technique one looks at both the remainder and the quotient and assumes that the good circuit response is known a-priory during the design of the linear feedback shift register (LFSR). The concept of periodic polynomials is used to completely characterize the quotient, thus eliminating aliasing. The maximum number of bits required to compress an Nb response to achieve zero aliasing is determined. The authors provide an algorithm for constructing an LFSR to achieve this bound for any given circuit under test.<>", "num_citations": "26\n", "authors": ["497"]}
{"title": "Fault-diagnosis of parallel processor interconnection networks\n", "abstract": " CiNii \u8ad6\u6587 - Fault-diagnosis of parallel processor interconnection networks CiNii \u56fd\u7acb\u60c5\u5831\u5b66 \u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb \u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005 \u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 CiNii\u306e\u30b5\u30fc\u30d3\u30b9\u306b\u95a2\u3059\u308b\u30a2\u30f3\u30b1\u30fc\u30c8\u3092\u5b9f\u65bd\u4e2d\u3067\u3059\uff0811/11(\u6c34)-12/23(\u6c34)\uff09 Fault-diagnosis of parallel processor interconnection networks FALAVARJANI KM \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 FALAVARJANI KM \u53ce\u9332\u520a\u884c\u7269 Proc. FTCS Proc. FTCS, 209-212, 1981 \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 On the Multiple Bridge Fault Diagnosis of Baseline Multistage Interconnection Networks LOMBARDI Fabrizio , PARK Nohpill , HORIGUCHI Susumu IEICE transactions on information and systems 79(8), 1168-1179, 1996-08-25 \u53c2\u8003\u6587\u732e16\u4ef6 CiNii\u5229\u7528\u8005\u30a2\u30f3\u30b1\u30fc\u30c8 Tweet \u5404\u7a2eNII(\u2026", "num_citations": "26\n", "authors": ["497"]}
{"title": "Static and dynamic location management in distributed mobile environments\n", "abstract": " Location management is one of the most important issues in distributed mobile computing. Location management consists of location updates, searches and search-updates. An update occurs when a mobile host changes location. A search occurs when a host wants to communicate with a mobile host whose location is unknown to the requesting host. A search-update occurs after a successful search, when the requesting host updates the location information corresponding to the mobile host. Various strategies can be designed for search, update and search-update. Static location management uses one combination of search, update and search-update strategies throughout the execution. Simulations were carried out to evaluate the performance of di erent static location management strategies for various communication and mobility patterns. It was noticed that performing search-updates signi cantly reduced the search costs with very little cost to pay for updates (upon moves and searches). In order to obtain good performance using static location management, the system designer should a priori have a fair idea of the communication and the mobility pattern of the users. Having this information, the system designer can select the combination which performs best for the given values of communication and mobility. The host behavior (communication frequency, mobility) is not always available to the system designer. Thus, there is a need for dynamic location management. In this paper we present a scheme for dynamic location management. The basic philosophy behind dynamic management is that the past history of the system will re ect the\u00a0\u2026", "num_citations": "25\n", "authors": ["497"]}
{"title": "Design of programmable logic arrays for testability\n", "abstract": " CiNii \u8ad6\u6587 - Design of Programmable Logic Arrays for Testability CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853 \u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f \u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005 \u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 Design of Programmable Logic Arrays for Testability SON K. \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 SON K. \u53ce\u9332\u520a\u884c\u7269 IEEE Test Conference IEEE Test Conference, 163-166, 1980 \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 \u8ad6\u7406\u5f0f\u3092\u5206\u96e2\u52a0\u6cd5\u5f62\u5f0f\u3067\u8868\u73fe\u3059\u308b\u4e00\u624b\u6cd5 \u677e\u7530 \u79c0\u96c4 , \u5bae\u8170 \u9686 \u60c5\u5831\u51e6\u7406\u5b66\u4f1a\u8ad6\u6587\u8a8c 33(4), 560-569, 1992-04-15 \u53c2\u8003\u6587\u732e9\u4ef6 \u88ab\u5f15\u7528\u6587\u732e1\u4ef6 Tweet \u5404\u7a2e\u30b3\u30fc\u30c9 NII\u8ad6\u6587ID(NAID) 80000866355 \u8cc7\u6599\u7a2e\u5225 \u4f1a\u8b70\u8cc7\u6599 \u30c7\u30fc\u30bf\u63d0\u4f9b\u5143 CJP\u5f15\u7528 \u66f8\u304d\u51fa\u3057 RefWorks\u306b\u66f8\u304d\u51fa\u3057 EndNote\u306b\u66f8\u304d\u51fa\u3057 Mendeley\u306b\u66f8\u304d\u51fa\u3057 Refer/BiblX\u3067\u8868\u793a RIS\u3067\u8868\u793a BibTeX\u3067\u8868\u793a TSV\u3067\u8868\u793a \u554f\u984c\u306e\u6307\u6458 \u30c8\u30c3\u30d7(\u2026", "num_citations": "25\n", "authors": ["497"]}
{"title": "Directed graphs with minimal diameter and maximum node connectivity\n", "abstract": " de Bruijn \u30cd\u30c3\u30c8\u30ef\u30fc\u30af, \u5909\u5f62 de Bruijn \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u53ca\u3073 Kautz \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306b\u304a\u3051\u308b\u5206\u6563\u7684\u81ea\u5df1\u8a3a\u65ad\u53ef\u80fd\u30b7\u30b9\u30c6\u30e0", "num_citations": "25\n", "authors": ["497"]}
{"title": "Reliability analysis of H-tree random access memories implemented with built in current sensors and parity codes for multiple bit upset correction\n", "abstract": " This paper presents an efficient technique for designing high defect tolerance Static Random Access Memories (SRAMs) with significantly low power consumption. The new approach requires drastically lower area overhead, simpler encoding and decoding algorithms, and zero fault-detection latency time for multiple error detection when compared to conventional techniques. The approach is based on the use of Built-In-Current-Sensors (BICS) to detect the abnormal current dissipation in the memory power-bus to improve the reliability of H-Tree SRAM memories. This abnormal current is the result of a single-event upset (SEU) in the memory, and it is generated during the inversion of the state of the memory cell being upset (bit-flip). We demonstrate the assertions of the proposed approach with HSPICE simulations, and a reliability analysis that combines BICS with single-parity bit (or Hamming codes) per SRAM\u00a0\u2026", "num_citations": "24\n", "authors": ["497"]}
{"title": "Single element correction in sorting algorithms with minimum delay overhead\n", "abstract": " A low delay overhead technique for the correction of errors affecting sorting algorithms, based on the use of Hamming code, is presented. Given the number of values to be sorted the expected Hamming check bits (as SUMs) are calculated, and a checker technique performs single error correction with lower delay overhead than classic approaches based on algorithm redundancy. The proposed technique has been applied to the well known bubble sorting with different sets of values to be sorted and the comparison of the resulting overhead with that imposed by the classic duplication with comparison and triple modular redundancy techniques shows that it requires lower delay overhead while providing enhanced error correction capabilities.", "num_citations": "24\n", "authors": ["497"]}
{"title": "Meta-level control in multi-agent systems\n", "abstract": " Sophisticated agents operating in open environments must make complex real-time control decisions on scheduling and coordination of domain actions. These decisions are made in the context of limited resources and uncertainty about outcomes of actions. The question of how to sequence domain and control actions without consuming too many resources in the process, is the meta-level control problem for a resource-bounded rational agent. Our approach is to design and build a meta-level control framework with bounded computational overhead. This framework will support decisions on when to accept, delay or reject a new task, when it is appropriate to negotiate with another agent, whether to renegotiate when a negotiation task fails and how much effort to put into scheduling when reasoning about a new task.", "num_citations": "24\n", "authors": ["497"]}
{"title": "Utilization of on-line (concurrent) checkers during built-in self-test and vice versa\n", "abstract": " Concurrent checkers are commonly used in computer systems to detect computational errors on-line, which enhances reliability. Using the coding theory framework developed earlier by the authors, it is shown in the following that concurrent checkers, already available within the circuit, can be utilized very effectively during off-line testing. Specifically, test time as well as fault escape probability can both be reduced simultaneously. The proposed combined scheme can be implemented with simple modification of existing hardware. Also shown is a novel use of BIST hardware for concurrent checking. Specifically proposed is a novel, dual use of concurrent checkers and built-in self-test hardware, yielding mutual advantage.", "num_citations": "24\n", "authors": ["497"]}
{"title": "Fault-tolerant VLSI architectures based on de Bruijn graphs (Galileo in the mid nineties)\n", "abstract": " De Bruijn architectures have certain advantages over the architectures such as cube and shuffle-exchange. Important differences between de Bruijn interconnects and others are also described in this paper. The use of the de Bruijn interconnect for VLSI architectures was first proposed in [4] and developed later in [5-7; 9-12; 14, 16]. Table 1 describes the evolution of these results and proposals. It may be noted here that it is. indeed, a common misconception to treat de Bruijn graphs as analogous to well studied shuffle-exchange graphs [1, 15]. An 8-node binary shuffle-exchange is shown in Figure 1. Here, the links are defined by end-around shifting of the node address and complementing the least significant bit. Figure 2 illustrates an 8-node de Bruijn graph. First, it may be seen that both the degrees and diameters of these graphs are different. For example, in the binary case, the shuffle-exchange graph is of maximum degree 3, whereas the maximum degree is 4 for de Bruijn graph. The diameter for shuffle-exchange is 2 log, A\"-1. There are also some important but subtle differences. For example, the de Bruijn graph, unlike the shuffleexchange graph, can admit various logical configurations as shown in Figure 3. Imponantly, as well, the de Bruijn graph is naturally robust against faults [4-6, 10-14] whereas the shuffle-exchange graph is clearly prone to single", "num_citations": "24\n", "authors": ["497"]}
{"title": "A multiprocessor network suitable for single-chip VLSI implementation\n", "abstract": " This paper presents a multiprocessor network architecture suitable for VLSI implementation. The proposed class of architectures is based on De Bruijn graphs which are distinct from the well-studied shuffle-exchange graphs. Compared to these latter De Bruijn graphs possess a smaller diameter and a greater fault-tolerance. The proposed architectures are shown to be suitable for efficient execution of parallel algorithms such as the N-point fast Fourier transform (FFT). It is shown that any VLSI layout of the proposed networks requires an area of atleast \u03a9(N2/logN), thus, providing a lower bound which is greater than that for shuffle-exchange graphs. Two procedures for laying out these networks on a VLSI chip are presented. The first procedure produces an O(N2/logN)-area layout and has a time complexity of O(N). The second procedure also produces an O(N2/logN)-area layout with good aspect ratio close to unity\u00a0\u2026", "num_citations": "24\n", "authors": ["497"]}
{"title": "Simultaneous scheduling and binding for low gate leakage nano-complementary metal-oxide-semiconductor data path circuit behavioural synthesis\n", "abstract": " The authors present two polynomial time-complexity heuristic algorithms for optimisation of gate-oxide leakage (tunnelling current) during behavioural synthesis through simultaneous schedulling and binding. One algorithm considers the time-constraint explicitly and the other considers it implicitly, whereas both account for resource constraints. The algorithms selectively bind the off-critical operations to instances of the pre-characterised resources consisting of transistors of higher oxide thickness, and critical operations to the resources of lower oxide thickness for power and performance optimisation. We design and characterise functional and storage units of different gate-oxide thicknesses and built a data path library. Extensive experiments for several behavioural synthesis benchmarks for 45 nm complementary metal-oxide-semiconductor technology showed that reduction as high as 85% can be obtained.", "num_citations": "23\n", "authors": ["497"]}
{"title": "TRAM: a design methodology for high-performance, easily testable, multimegabit RAMs\n", "abstract": " An architecture is proposed for multimegabit dynamic RAMs (random-access memories) that achieves higher testability and performance than the conventional four-quadrant RAMs. Applying the principle of divide and conquer, the RAM is partitioned into modules, each appearing as the leaf node of a binary interconnect network. Such a network carries the address/data/control bus, permitting the nodes to communicate among themselves as well as with the outside world. This architecture is shown to be easily testable. Parallelism in testing and partial self-test result in a large savings of testing time; the savings is independent of the test algorithm used. Unlike other testability schemes, this approach promises improved performance with only a small increase in chip area. It is also shown that the architecture is easily partionable and restructurable, with potential for yield and reliability improvement.< >", "num_citations": "23\n", "authors": ["497"]}
{"title": "Low latency and energy efficient scalable architecture for massive NoCs using generalized de Bruijn graph\n", "abstract": " Employing thousands of cores in a single chip is the natural trend to handle the ever increasing performance requirements of complex applications such as those used in graphics and multimedia processing. System-on-chips (SoCs) platforms based on network-on-chips (NoCs) could be a viable option for the deployment of large multicore designs with thousands of cores. This paper proposes the generalized binary de Bruijn (GBDB) graph as a reliable and efficient network topology for a large NoC. We propose a reliable routing algorithm to detour a faulty channel between two adjacent switches. In addition, using integer linear programming, we propose an optimal tile-based implementation for a GBDB-based NoC in which the number of channels is less than that of Torus which has the same number of links. Our experimental results show that the latency and energy consumption of the generalized de Bruijn graph\u00a0\u2026", "num_citations": "22\n", "authors": ["497"]}
{"title": "A technique to identify and substitute faulty nodes in wireless sensor networks\n", "abstract": " In this paper, we propose a technique to identify and substitute faulty nodes to achieve fault tolerance in wireless sensor networks. The proposed technique divides the network into disjoint zones while having a master for each zone. The zone masters are used to identify faulty nodes by virtually dividing the zone into quadrants until a suspect node is found. Our fault model assumes both communication and sensing faults which are caused by a hardware failure in anode. To detect communication faults, the division process is based on calculating the throughput for each zone and comparing it to a predefined threshold. However, for sensing faults it is based on comparing the data a node senses to a predefined status and data ranges. In addition, we make use of a new technique, which was inspired by the roll forward checkpointing scheme, to activate sleeping nodes in order to validate the correctness of the\u00a0\u2026", "num_citations": "22\n", "authors": ["497"]}
{"title": "LPRAM: a novel low-power high-performance RAM design with testability and scalability\n", "abstract": " To date, all of the proposals for low-power designs of RAMs essentially focus on circuit-level solutions. What we propose here is a novel architecture (high) level solution. Our methodology provides a systematic tradeoff between power and area. Also, it allows tradeoff between test time and power consumed in test mode. Significantly, too, the proposed design has the potential to achieve performance improvements while simultaneously reducing power. In this respect, it stands apart from other approaches where power reduction results in speed reduction. The basic approach here divides the RAM into modules, interconnecting these modules in a binary tree where the tree can be reconfigured dynamically during normal operation and during test mode. Furthermore, during test mode, most of the RAM can be switched off, which provides major power reduction, while test-application time is reduced. The aspect ratio of\u00a0\u2026", "num_citations": "22\n", "authors": ["497"]}
{"title": "Wormhole routing in de Bruijn networks and hyper-de Bruijn networks\n", "abstract": " The order-(m, n) hyper-de Bruijn graph HD(m, n) is the direct product of an order-m hypercube and an order-n de Bruijn graph. The hyper-de Bruijn graph offers flexibility in terms of connections per node and the level of fault-tolerance. These networks as well possess logarithmic diameter, simple routing algorithms and support many computationally important subgraphs and admit efficient implementation. In this paper, we present results on wormhole routing in binary de Bruijn and hyper-de Bruijn networks. For an N-node binary de Bruijn network, four deadlock-free routing algorithms are presented. These algorithms use log N, /spl lceil/2/3 log N/spl rceil/, /spl lceil/1/2 log N/spl rceil/ and 4 virtual channels per physical channel. The number of hops needed to route a message using the above algorithms are /spl les/log N, /spl les/log N, /spl les/log N and /spl les/2 log N, respectively. We present a generalized\u00a0\u2026", "num_citations": "22\n", "authors": ["497"]}
{"title": "Soft error mitigation in switch modules of SRAM-based FPGAs\n", "abstract": " In this paper, we propose two techniques to mitigate soft error effects on the switch modules of SRAM-based FPGAs: 1) The first technique tolerates SEU-caused open errors based on a new programming method for SRAM-bits of switch modules, and 2) The second technique mitigates SEU-cause short errors in the switch modules based on a mixed programmable and hard-wired switch module structure in the FPGAs. The effects of these two techniques on the delay, area and power consumption for 20 MCNC benchmark circuits are achieved using a minor modification in VPR and T-VPack FPGA CAD tools. The experimental results show that the first technique increase reliability of connections of switch module up to 30% while the second technique decreases the susceptibility of switch modules to SEUs about 50% compared to the traditional ones", "num_citations": "21\n", "authors": ["497"]}
{"title": "Gate-level synthesis for low-power using new transformations\n", "abstract": " A new logic optimization method of multi-level combinational CMOS circuits is presented, which minimizes both power as well as power dissipation per unit area. The method described here uses Boolean transformations which exploit implications at the gate-level, based on both controllability and observability relationships. New transformations which form the basis of our synthesis method are presented. The emphasis is on power consumption rather than on area. Experimental results demonstrate that circuits synthesized by our method consume less power with a comparable area than those synthesized by state-of-the-art tools.", "num_citations": "21\n", "authors": ["497"]}
{"title": "Method for circuit verification and multi-level circuit optimization based on structural implications\n", "abstract": " A method for verifies that two integrated circuits are functionally equivalent by extracting equivalencies between internal nodes of the two circuits. Values are assigned to internal nodes in the first circuit and the effects of the assignments are determined in the rest of the first circuit and the second circuit. These effects, or implications, are analyzed to find internal equivalents between the first and second circuit. These steps are repeated with different values assigned to different nodes in the first circuit. The set of stored implications is used to determine if the two circuits are functionally equivalent.", "num_citations": "21\n", "authors": ["497"]}
{"title": "Functional Learning: A new approach to learning in digital circuits\n", "abstract": " Recently, learning-based techniques, which are extremely effective in finding test vectors for hard to detect faults and in detecting redundancies, have been proposed as an efficient alternative to the traditional branch-and-bound techniques for test generation. This paper presents functional learning, a new OBDD-based learning technique, that uses implication procedures. Functional learning is complete given enough time; it will determine all the uniquely implied values in the circuit from the current situation of value assignments. The most attractive feature of functional learning is its ability to extract, maintain and manipulate novel information regarding the circuit in compact OBDD representations for Boolean functions.< >", "num_citations": "21\n", "authors": ["497"]}
{"title": "Fault-tolerant asynchronous networks\n", "abstract": " The design of fault-tolerant asynchronous networks has been an unsolved problem. In this paper, necessary and sufficient conditions on state assignments for fault-tolerant asynchronous networks are given. Three design techniques, based on Liu's 2 so  - 1 assignment, Friedman et al.'s (2, 2) separating system, and (2s o  + 1) assignments, are given for fault-tolerant asynchronous networks. The earlier Liu's upper bound on state variables for USTI assignment for 2 so  rows is improved to 2 so  - 2 so -3 .", "num_citations": "21\n", "authors": ["497"]}
{"title": "Novel complementary resistive switch crossbar memory write and read schemes\n", "abstract": " Recent trends in emerging nonvolatile memory systems necessitate efficient read/write (R/W) schemes. Efficient solutions with zero sneak path current, nondestructive R/W operations, minimum area and low power are some of the key requirements. Toward this end, we propose a novel crossbar memory scheme using a configuration row of cells for assisting R/W operations. The proposed write scheme minimizes the overall power consumption compared to the previously proposed write schemes and reduces the state drift problem. We also propose two read schemes, namely, assisted-restoring and self-resetting read. In assisted-restoring scheme, we use the configuration cells which are used in the write scheme, whereas we implement additional circuitry for self-reset which addresses the problem of destructive read. Moreover, by formulating an analytical model of R/W operation, we compare the various schemes\u00a0\u2026", "num_citations": "20\n", "authors": ["497"]}
{"title": "E cient Location Management in Mobile Wireless Networks,\"\n", "abstract": " Location management schemes presented in the personal communication network standards (eg, EIA/TIA Interim Standard 41 (IS-41)) are not e cient. We propose forwarding techniques that augment the IS-41 scheme to provide e cient location management. We develop analytical models to compare the performance of the proposed approach with the IS-41 scheme. Analysis shows that forwarding signi cantly reduces the total network load due to location management. However for some network parameter values, the search cost of the forwarding scheme is very high. In order to reduce the search cost, we present a strategy to perform search-updates. A search-update occurs after a successful search, when the location information corresponding to the searched mobile host is updated at some hosts. Analysis shows that for some network parameter values, performing search-updates signi cantly reduces the search costs and total network load.", "num_citations": "20\n", "authors": ["497"]}
{"title": "Reliability analysis of unidirectional voting TMR systems through simulated fault-injection\n", "abstract": " Computer systems used in aircraft and reactor control often require critically high reliability for moderately short mission times. N-modular redundant (NMR) hardware has been employed in many of these ultrahigh reliability applications (1, 9, 15, 18]. Triple-modular redundancy (TMR) is perhaps its most common form, tolerating the failure of any one module. The three redundant processors of a TMR system concurrently execute identical tasks while the triplicated memories contain the same code and data. Majority voting is used to mask erroneous module outputs. As seen in Figure 1, the voter (V) is usually inserted into the redundant system buses between the processors (P) and memories (M). Bit-wise voting is typically performed on data, address and control lines during both read and write accesses to memory. Such a system will be referred to as bidirectional voting (BDV) TMR.", "num_citations": "20\n", "authors": ["497"]}
{"title": "A novel memristor based physically unclonable function\n", "abstract": " Memristor is an exciting new addition to the repertoire of fundamental circuit elements. Alternatives to many security protocols originally employing traditional mathematical cryptography involve novel hardware security primitives, such as Physically Unclonable Functions (PUFs). In this paper, we first introduce a novel hybrid memristor\u2013CMOS XOR/XNOR logic circuit that offers several advantages such as combinational circuit behavior, simpler operation and lower hardware overhead than existing solutions. Then, we use this XOR circuit as a component to design a hybrid memristor\u2013CMOS PUF circuit and demonstrate its effectiveness through extensive simulations of environmental and process variation effects. The proposed PUF circuit has substantially lesser hardware overhead than previously proposed memristor-based PUF circuits, while being resistant against machine learning based modelling attacks. The\u00a0\u2026", "num_citations": "19\n", "authors": ["497"]}
{"title": "Fault-tolerant parallel and distributed systems\n", "abstract": " The most important use of computing in the future will be in the context of the global\" digital convergence\" where everything becomes digital and every thing is inter-networked. The application will be dominated by storage, search, retrieval, analysis, exchange and updating of information in a wide variety of forms. Heavy demands will be placed on systems by many simultaneous re quests. And, fundamentally, all this shall be delivered at much higher levels of dependability, integrity and security. Increasingly, large parallel computing systems and networks are providing unique challenges to industry and academia in dependable computing, espe cially because of the higher failure rates intrinsic to these systems. The chal lenge in the last part of this decade is to build a systems that is both inexpensive and highly available. A machine cluster built of commodity hardware parts, with each node run ning an OS instance and a set of applications extended to be fault resilient can satisfy the new stringent high-availability requirements. The focus of this book is to present recent techniques and methods for im plementing fault-tolerant parallel and distributed computing systems. Section I, Fault-Tolerant Protocols, considers basic techniques for achieving fault-tolerance in communication protocols for distributed systems, including synchronous and asynchronous group communication, static total causal order ing protocols, and fail-aware datagram service that supports communications by time.", "num_citations": "19\n", "authors": ["497"]}
{"title": "Ambient air temperature effect on power plant performance\n", "abstract": " The performance of the power plant strongly depends on ambient air temperature (AAT). Mass flow rate (kg/s) of air decreases in summer with increasing AAT for the same volumetric flow rate (m3/s), which results in reduced power output of turbine and increased heat rate. This paper analyzes the effects of the AAT on various parameters of power plant viz., mass flow rate of air, fuel consumption, steam, power output of turbine, efficiency and heat rate of gas turbine, steam turbine and combined cycle plant.", "num_citations": "19\n", "authors": ["497"]}
{"title": "Fault tolerant single error correction encoders\n", "abstract": " Soft errors are an important issue for circuit reliability. To mitigate their effects on the system functionality, different techniques are used. In many cases Error Correcting Codes (ECC) are used to protect circuits. Single Error Correction (SEC) codes are commonly used in memories and can effectively remove errors as long as there is only one error per word. Soft errors however may also affect the circuits that implement the Error Correcting Codes: the encoder and the decoder. In this paper, the protection against soft errors in the ECC encoder is studied and an efficient fault tolerant implementation is proposed.", "num_citations": "19\n", "authors": ["497"]}
{"title": "Improving memory reliability against soft errors using block parity\n", "abstract": " Memory reliability is an important issue. The continuous scaling of transistor technology enables the use of larger memories making soft errors more likely to occur. To ensure that those errors do not cause data corruption, error correcting codes (ECC) are commonly used. Single error correction-double error detection codes (SEC-DED) are typically implemented in each memory word, so that a single error in a word can be corrected and two errors can be detected. In this paper, a technique to improve the reliability of memories that use SEC-DED is studied. The proposed technique shows that it is possible to substantially improve the mean time to failure (MTTF) of the memory at the cost of increasing the access time for writing operations.", "num_citations": "19\n", "authors": ["497"]}
{"title": "Shift registers designed for on-line fault detection\n", "abstract": " ABSTRACT A novel design of shift registers with builtin fault-detection capabilities is presented. The states of the shift register satisfy certain parity check equations, thus enabling detection of errors. This shift register design is over an extension field of Galois field of two elements GF (2). This particular design differs from the earlier designs which are over GF (2). One of the practical applications of our results is in the designing of selftesting storage address generators and linear counters.", "num_citations": "19\n", "authors": ["497"]}
{"title": "A new class of bit-and byte-error control codes\n", "abstract": " Error-control codes for byte-oriented systems are presented. The proposed codes are intended for systems wherein the erroneous bits tend to be confined to a small number of bytes. Mathematical techniques are developed for the construction of codes that can detect and correct such errors. Among the various codes presented, the codes for detection and correction of errors confined to a single byte are of particular interest. A decoding algorithm for these codes is also presented.< >", "num_citations": "19\n", "authors": ["497"]}
{"title": "VERILAT: Verification using logic augmentation and transformations\n", "abstract": " This paper presents a new framework for formal logic verification. What is depicted here is fundamentally different from previous approaches. In earlier approaches, the circuit is either not changed during the verification process, as in ordered binary decision diagram (OBDD) or implication-based methods, or the circuit is progressively reduced during verification. Whereas, in our approach, we actually enlarge the circuits by adding gates during the verification process. Specifically, introduced here is a new technique that transforms the reference circuit as well as the circuit to be verified, so that the similarity between the two is progressively enhanced. This requires addition of gates to the reference circuit and/or the circuit to be verified. In the process, we reduce the dissimilarity between the two circuits, which makes it easier to verify the circuits. In this paper, we first introduce a method to identify pacts of the two circuits\u00a0\u2026", "num_citations": "18\n", "authors": ["497"]}
{"title": "Sequential redundancy identification using recursive learning\n", "abstract": " A sequential redundancy identification procedure is presented. Based on uncontrollability analysis and recursive learning techniques, this procedure identifies c-cycle redundancies in large circuits, without simplifying assumptions or state transition information. The proposed procedure can identify redundant faults which require conflicting assignments on multiple lines. In this sense, it is a generalization of FIRES, a state-of-the-art redundancy identification algorithm. A modification of the proposed procedure is also presented for identifying untestable faults. Experimental results on ISCAS benchmarks demonstrate that these two procedures can efficiently identify a large portion of c-cycle redundant and untestable faults.", "num_citations": "18\n", "authors": ["497"]}
{"title": "The effect of program behavior on fault observability\n", "abstract": " Fault observability based on the behavior of memory references is studied. Traditional studies view memory as one monolithic entity that must completely work to be considered reliable. The usage patterns of a particular program's memory are emphasized here. This paper develops a new model for the successful execution of a program taking into account the usage of the data by extending a cache memory performance model. Three variations, based on well known allocation schemes, are presented (i.e., whether the program's storage is preallocated, dynamically allocated, or constrained in allocation). This is contrasted to traditional memory reliability calculations to show that the actual mean time to failure may be more optimistic when program behavior is considered. It also develops expressions for the probability of unobserved faults. With several studies reporting correlations between increased workloads and\u00a0\u2026", "num_citations": "18\n", "authors": ["497"]}
{"title": "The hyper-deBruijn multiprocessor networks\n", "abstract": " Hypercube and deBruijn networks each possess certain desirable properties. The architecture proposed is a combination of the hypercube and deBruijn architectures. Thus, it provides flexibility in terms of connections per node and the level of fault-tolerance. The graph structure allows a direct decomposition of the network into VLSI building blocks. These networks possess logarithmic diameter, optimal connectivity and simple routing algorithms amenable to networks with faults. These hyper-deBruijn networks admit many computationally important subnetworks such as rings, multidimensional meshes, complete binary trees and mesh of trees with perfect dilation, in addition to being pancyclic.<>", "num_citations": "18\n", "authors": ["497"]}
{"title": "Single error correctable bit parallel multipliers over GF(2m)\n", "abstract": " Motivated by the problems associated with soft errors in digital circuits and fault-related attacks in cryptographic hardware, a systematic method for designing single error correcting multiplier circuits is presented for finite fields or Galois fields over GF(2 m ). Multiple parity predictions to correct single errors based on the Hamming principles are used. The expressions for the parity prediction are derived from the input operands, and are based on the primitive polynomials of the fields. This technique, when compared with existing ones, gives better performance. It is shown that single error correction (SEC) multipliers over GF(2 m ) require slightly over 100% extra hardware, whereas with the traditional SEC techniques, this figure is more than 200%. Since single bit internal faults can cause multiple faults in the outputs, this has also been addressed here by using multiple Hamming codes with optimised hardware.", "num_citations": "17\n", "authors": ["497"]}
{"title": "Single event upset detection and correction\n", "abstract": " This paper proposes a low cost solution to detect and correct a transient faults in registers of a design. The proposed method realizes a single-event upset detection and correction (SEU-DC) technique. The detection and correction of SEU in registers of a design is difficult and requires some efficient approaches without significant area overhead and timing penalty. Furthermore, the proposed method is based on the traditional parity codes to detect and correct a single-bit error without significant increase in area overhead. We conducted experiments on the MCNC benchmark circuits which show that present approach has very low area overhead and timing penalty as compared to hardware redundancy approach.", "num_citations": "17\n", "authors": ["497"]}
{"title": "On-line Testing for VLSI\n", "abstract": " This paper presents an overview of a comprehensive collection of on-line testing techniques for VLSI. Such techniques are for instance: self-checking design, allowing high quality concurrent checking by means of hardware cost drastically lower than duplication; signature monitoring, allowing low cost concurrent error detection for FSMs; on-line monitoring of reliability relevant parameters such as current, temperature, abnormal delay, signal activity during steady state, radiation dose, clock waveforms, etc.; exploitation of standard BIST, or implementation of BIST techniques specific to on-line testing (Transparent BIST, Built-In Concurrent Self-Test,...); exploitation of scan paths to transfer internal states for performing various tasks for on-line testing or fault tolerance; fail-safe techniques for VLSI, avoiding complex fail-safe interfaces using discrete components; radiation hardened designs, avoiding expensive\u00a0\u2026", "num_citations": "17\n", "authors": ["497"]}
{"title": "Urethral anastomosis device and method\n", "abstract": " Provided herein is a two-part coupling assembly for re-connecting a first hollow body part to a second body part and an instrument and method for emplacement. The coupling assembly comprises coupling parts having securement elements that are actuated by separate deployment mechanisms of the instrument and attach to the first and second body parts. The first and second coupling parts having interconnecting elements that couple the two-part assembly together and re-connect the first and second body parts.", "num_citations": "16\n", "authors": ["497"]}
{"title": "Energy-efficient fault-tolerant systems\n", "abstract": " Energy efficiency is a widely acknowledged design objective in electronic systems research and development. With continued technology scaling reliability is an emerging concern in these systems due to increased device-level vulnerability in the presence of electromagnetic inductions and process variability. Achieving high reliability and energy efficiency objectives jointly can, however, be challenging as energy minimization techniques exacerbate the reliability further. Hence, energyefficient fault-tolerant (ie reliable) design is currently of high interest to both industry and academia to address these challenges effectively. The aim of this book is to introduce state-of-the-art and emerging issues in energy-efficient faulttolerant design techniques as applied or prototyped for current or future generations of system-on-chip (SoC). Although necessary brief background has been provided in each chapter, fundamental\u00a0\u2026", "num_citations": "16\n", "authors": ["497"]}
{"title": "A Fault-Tolerance Scheme for a System of Duplicated Communicating Processes\n", "abstract": " Process duplication is am echanism for detecting fail-ures. When processors executing the processes are not fail-stop, process duplication by itself is not adequate to identify the faulty processor. However, the existence of two replicas of each process can be exploited to achieve recovery efficiently. This paper presents a sender-based message logging scheme for a system of duplicated communicating processes. The senderbased message logging scheme proposed for fail-stop processors (4) requires that a receiver must inform the message sender the receive sequence number (RSN) of each received message, and then the sender must acknowledge the receipt of the RSN. This may re-quire additional messages to be sent over the net-work. The scheme presented here, by exploiting process duplication, eliminates the need for the receive sequence numbers to be sent over the network. The processes are checkpointed periodically. Different processes checkpoint independent of each other (no coor-dination is required), while replicas of a process must checkpoint at the same points in their execution. The scheme tolerates a single process failure. The proposed scheme is being presently implemented on a network of DECstations. the fault-free replica. When processors are not fail-stop, process duplication by itself is not adequate for identifying the faulty processor and achieving recov-ery. However, the existence of two replicas of each process can be exploited to achieve recovery. Here, fault detection is achieved by duplicating pro-cesses and executing replicas of a process on different processors. The processes are checkpointed periodi-cally\u00a0\u2026", "num_citations": "16\n", "authors": ["497"]}
{"title": "Dynamic testing strategy for distributed systems\n", "abstract": " Department of Electrical and Computer Engineering University of Massachusetts Amherst, Massachusetts 01003 Abstract: Testing and diagnosis is an important researchers proposing topologies (eg [Pr Re82]) consideration in the implementation of fault- have found it prudent to assume both the needs of a tolerant distributed systems. This paper treats distributed environment and the potential for fault diagnosis as two distinct processes: fault malicious faults (while research assuming dormant discovery and dissemination of diagnostic faulty components largely ceased). information. The corresponding testing overhead consists of periodic tests for fault discovery and Necessary and sufficient conditions on a further tests and/or message passing for static set of tests to achieve a level of dissemination of diagnostic information. Both diagnosability is established in [KuRe80). They homogeneous and nonhomogeneous systems in both subsequently enhanced their method to be able to synchronous and asynchronous environments are diagnose faulty communication links [KuRe 81). discussed. Hosseini pursued this research, investigating (nonhomogeneous) systems with a restricted set of Previous research derived precisely when a allowable tests (Hoss82); also that work sought to given set of tests in a homogeneous system can allow the incorporation into the system of achieve a specified level of self-diagnosability. rehabilitated components (Hoss82, HoKu84]. As did A new methodology is presented with the objective[Pr Me 67, KuRe80), we take testing to be singlyof minimizing the overhead associated with periodic invalidating, singly-complete\u00a0\u2026", "num_citations": "16\n", "authors": ["497"]}
{"title": "Memristor based arbiter PUF: cryptanalysis threat and its mitigation\n", "abstract": " Physically Unclonable Function (PUF) circuits are promising hardware security primitives. Recently a hybrid CMOS-memristor based lightweight PUF circuit was described by Mathew et al., and shown to be resistant against machine learning based model building attack. In this paper we demonstrate that such a PUF is vulnerable to cryptanalysis. We then propose a modification to the circuit to make it resistant against cryptanalysis, while retaining its robustness against machine learning attacks, and its low hardware footprint. We demonstrate the suitability of our proposed PUF through extensive simulation results and statistical characterization.", "num_citations": "15\n", "authors": ["497"]}
{"title": "A 2-port 6T SRAM bitcell design with multi-port capabilities at reduced area overhead\n", "abstract": " Low power, minimum transistor count and fast access static random access memory (SRAM) is essential for embedded multimedia and communication applications realized using system on a chip (SoC) technology. Hence, simultaneous or parallel read/write (R/W) access multi-port SRAM bitcells are widely employed in such embedded systems. In this paper, we present a 2-port 6T SRAM bitcell with multi-port capabilities and a reduced area overhead compared to existing 2-port 7-transistor (7T) and 8T SRAM bitcells. The proposed 2-port bitcell has six transistors (6T) and single-ended read and write bitlines (RBL/WBL). We compare the stability, simultaneous read/write disturbance, SNM sensitivity and misread current from the read bitline with the 7T and 8T bitcells. The static noise margin (SNM) of the 6T bitcells around the write disturbed bitcell is 53% to 61% higher than that of the 7T bitcell. The average active\u00a0\u2026", "num_citations": "15\n", "authors": ["497"]}
{"title": "Mathematical framework for representing discrete functions as word-level polynomials\n", "abstract": " This paper presents a mathematical framework for modeling arithmetic operators and other RTL design modules as discrete word-level functions and proposes a polynomial representation of those functions. The proposed representation attempts to bridge the gap between bit-level BDD representations and word-level representations, such as *BMDs and TEDs.", "num_citations": "15\n", "authors": ["497"]}
{"title": "Roll-forward checkpointing schemes\n", "abstract": " In modular redundant systems, tasks are replicated to achieve fault-tolerance. Checkpointing schemes that exploit replication can achieve better performance than the ones that ignore how the fault detection mechanism is implemented [24]. This Chapter presents two such schemes named Dynamic Roll-Forward Checkpointing Scheme and the Static Roll-Forward Checkpointing Scheme.             In the dynamic scheme for duplex systems, each task is assumed to be executing simultaneously on two processing modules. At each checkpoint, the state of the two modules executing the task is compared for detection of faults. If a fault is detected, instead of the usual roll-back, both the modules continue execution to the next checkpoint interval. The failed checkpoint interval is \u2018retried\u2019 on a spare module, which helps in identifying the failed processing module and making its state consistent.             It is demonstrated\u00a0\u2026", "num_citations": "15\n", "authors": ["497"]}
{"title": "A novel approach for subcube allocation in hypercube multiprocessors\n", "abstract": " A novel approach for dynamic subcube allocation in hypercube multiprocessors which supports a multiuser environment is proposed. A dynamic binary tree with nodes labeled by a binary reflected gray code is used for processor allocation along with two arrays of free lists. The time complexities for both allocation and deallocation are shown to be linear-orders of magnitude improvement over the existing exponential and even superexponential algorithms. A best-fit strategy, the proposed scheme does not excessively fragment the hypercube, unlike some existing strategies. In addition, static optimality is guaranteed. The performance of the proposed scheme is compared on such parameters as average delay in honouring a request, average allocation time, and average deallocation time against some existing schemes, demonstrating its effectiveness.< >", "num_citations": "15\n", "authors": ["497"]}
{"title": "Low cost memristor associative memory design for full and partial matching applications\n", "abstract": " Novel memory circuits based on variable-resistance devices (such as memristors) have been recently proposed to overcome the limitations of CMOS based memories. These novel memories although based on different technologies, all share the principle of storing information as the resistance value imposed to a variable-resistance devices. Another promising application of memristors is in content-addressable memory (CAM). The study of memristor based CAM design has become increasingly important with the advent of new hybrid CMOS molecular technologies. To this end, we present a two-transistor-memristor (2T2M) bitcell for CAM design, suitable for low-power applications. The proposed circuit consists of memristors to store data and transistors as access devices, and utilizes complementary logic values at the input. We present detailed simulation based characterization (for both full match and partial\u00a0\u2026", "num_citations": "14\n", "authors": ["497"]}
{"title": "A placement strategy for reducing the effects of multiple faults in digital circuits\n", "abstract": " This paper proposes a fault-aware placement strategy for digital circuits. Placement algorithms usually have a goal of reducing the overall chip area and routing wirelength while the solution proposed in this paper focuses on reducing the effects of multiple faults caused by transients. The target circuits are properly analysed in order to identify scenarios that promote reductions in the overall error rate. The occurrence of these scenarios is then maximised when the proposed placement strategy is executed. Results show that substantial error rate reductions can be achieved.", "num_citations": "14\n", "authors": ["497"]}
{"title": "Statistical DOE\u2013ILP based power\u2013performance\u2013process (P3) optimization of nano-CMOS SRAM\n", "abstract": " As technology continues to scale, maintaining important figures of merit of Static Random Access Memories (SRAMs), such as power dissipation and an acceptable Static Noise Margin (SNM), becomes increasingly challenging. In this paper, we address SRAM instability and power (leakage) dissipation in scaled-down technologies by presenting a novel design flow for simultaneous power minimization, performance maximization and process variation tolerance (P3) optimization of nano-CMOS circuits. The 45 and 32\u00a0nm technology node standard 6-Transistor (6T) and 8T SRAM cells are used as example circuits for demonstration of the effectiveness of the flow. Thereafter, the SRAM cell is subjected to a dual threshold voltage (dual-VTh) assignment based on a novel statistical Design of Experiments\u2013Integer Linear Programming (DOE\u2013ILP) approach. Experimental results show 61% leakage power reduction and\u00a0\u2026", "num_citations": "14\n", "authors": ["497"]}
{"title": "On the design of different concurrent EDC schemes for s-box and gf (p)\n", "abstract": " Recent studies have shown that an attacker can retrieve confidential information from cryptographic hardware (e.g. the secret key) by introducing internal faults. A secure and reliable implementation of cryptographic algorithms in hardware must be able to detect or correct such malicious attacks. Error detection/correction (EDC), through fault tolerance, could be an effective way to mitigate such fault attacks in cryptographic hardware. To this end, we analyze the area, delay, and power overhead for designing the S-Box, which is one of the main complex blocks in the Advanced Encryption Standard (AES), with error detection and correction capability. We use multiple Parity Predictions (PPs), based on various error correcting codes, to detect and correct errors. Various coding techniques are presented, which include simple parity prediction, split parity codes, Hamming, Hsiao, and LDPC codes. The S-Box, GF(p), and\u00a0\u2026", "num_citations": "14\n", "authors": ["497"]}
{"title": "A hamming distance based test pattern generator with improved fault coverage\n", "abstract": " This paper proposes a new test pattern generator (TPG) which is an enhancement of GLFSR (Galois LFSR). This design is based on certain non-binary error detecting codes, formulated over an extension field of GF(2/sup /spl delta//), /spl delta/ > 1. The resulting generator provides a guaranteed Hamming distance between successive test patterns, resulting in shorter test lengths. As an additional advantage, the proposed TPG has the intrinsic ability to detect 1-bit errors in the TPG itself. Detailed design methodology and experimental results are presented. The results presented here also have implications in algebraic coding theory in that they may lead to new coding techniques for test pattern generation.", "num_citations": "14\n", "authors": ["497"]}
{"title": "MODD: A new decision diagram and representation for multiple output binary functions\n", "abstract": " This paper presents a new decision diagram (DD), called MODD, for multiple output binary and multiple-valued functions. This DD is canonic and can be made minimal with respect to a given variable order. Unlike other reported DDs, our approach can represent arbitrary combination of bits at the word-level. The preliminary results show that our representation can result in considerable memory saving.", "num_citations": "14\n", "authors": ["497"]}
{"title": "Synthesis of initializable asynchronous circuits\n", "abstract": " We show that existing synthesis techniques may produce asynchronous circuits that are not initializable by gate level analysis tools even when the design is functionally initializable. Due to the absence of any initialization sequence, a fault simulator or test generator that assumes an unknown starting state will be completely ineffective for these circuits. In this paper, we show that proper consideration of initializability during the asynchronous circuit synthesis procedure can guarantee initializable implementations, The assignment of don't cares during the synthesis procedure is intimately related to the initializability of the final implementation. We present a novel implicit enumeration procedure that selectively assigns don't cares to obtain an initializable implementation. Initialization sequences are obtained as a by product of our synthesis procedure.< >", "num_citations": "14\n", "authors": ["497"]}
{"title": "Communication structures in fault\u2010tolerant distributed systems\n", "abstract": " The impact of communication structures on the robustness and performance of distributed computing systems is discussed. Communication structures are categorized as (1) point\u2010to\u2010point, (2) bus, and (3) multistage switching. The most significant networks that have been proposed are discussed. Networks are compared with respect to (1) connectivity, (2) diameter, (3) average distance, (4) diameter in the presence of faults, (5) extensibility (ease of adding or deleting processors), and (6) ease of routing in the presence of faults. Some attempts directed at achieving near optimality for each of these six factors are discussed. A strategy for designing good networks with respect to all of these factors is suggested. Attempts to predict the real\u2010time robustness of systems are reviewed and commented on and the power and consistency of metrics associated with such attempts are discussed. The impact of communication\u00a0\u2026", "num_citations": "14\n", "authors": ["497"]}
{"title": "A hierarchical directory scheme for large-scale cache-coherent multiprocessors\n", "abstract": " Cache coherence problem is a major design issue for shared-memory multiprocessors. As the system size scales, traditional bus-based snoopy cache coherence schemes are no longer adequate. Instead, the directory-based scheme is a promising approach to deal with the large-scale cache coherence problem. However, the storage overhead of directory schemes often becomes too prohibitive as the system size increases. The paper proposes the hierarchical full-map directory to reduce the storage requirement while still achieving satisfactory performance. The key point is to exploit the inherent geographical interprocessor locality among shared data in the parallel programs. Trace-driven evaluations show that the performance of the proposed scheme compares competitively to the full-map directory scheme, while reducing the storage overhead by over 90%. The proposed hierarchical full-map directory scheme\u00a0\u2026", "num_citations": "14\n", "authors": ["497"]}
{"title": "On a Class of Fault-Tolerant Multiprocessor Network Architectures.\n", "abstract": " This paper studies a class of fault tolerant multi processor networks recently proposed (1). It is shown that these networks can tolerate certain multiple node and link failures. As a result of this, these networks are partitionable into subnetworks of arbitrary sizes that failure of any subnetwork is easily tolerated. This observation is of practical interest in view of the fact that it is now feasible to implement multiple nodes on a single unit. Also formulated here are certain message routing algorithms that can be used in the event of these multiple node/link failures. These algorithms require only a small number of tag bits in the message for implementation, instead of the usual routing tables, directories, etc. Finally, certain self-diagnosis algo rithms are developed that can be used for diagnosis of the faulty nodes in a distributed mode. number of nodes, as well. Specifically, the maximum number of 1/0 ports that is required per node is limited to four or five. Also, the number of links is less than 2n. So, the interconnection complexity of these architectures is on a par with other structures such as double loop (11), binary tree [12], etc. Also, incremental changes can easily be incorporated into the system; and thus it is extensible (1). It should be remembered that in many implementations, it is required that the set of nodes be partitioned into subnetworks so that each subnetwork may be placed in a single unit. This poses certain additional problems of fault-tolerance and fault-diagnosability. These, however, are easily overcome in our system. Specifically, the proposed systems can be partitioned easily in to subnetworks such that faults effecting multiple nodes in any\u00a0\u2026", "num_citations": "14\n", "authors": ["497"]}
{"title": "Design of two-level fault-tolerant networks\n", "abstract": " Some new techniques for the synthesis of fault-tolerant two-level combinational networks are presented. Two classes of faults are defined, 1) critical faults and 2) subcritical faults. Critical fauls are the class of faults that cannot be tolerated by any two-level networks. Necessary conditions for synthesis of networks tolerating subcritical faults are developed. As a result it is established that the conditions required for tolerating faults in the logic elements and those required for tolerating faults in the primary inputs are significantly different. Several design techniques are presented and it is shown that if we restrict our class of faults, then certain normally assumed conditions on redundancy can be relaxed. A class of hazards is defined. It is shown that the synthesis of certain hazard-free realizations is equivalent to the fault-tolerant realization, and also an upper bound on the redundancy of the fault-tolerant realization is derived.", "num_citations": "14\n", "authors": ["497"]}
{"title": "An explicit/implicit Galerkin domain decomposition procedure for parabolic integro-differential equations\n", "abstract": " In this paper, a non-iterative domain decomposition procedure for parabolic integro-differential equation is discussed. While the flux is evaluated explicitly in time at the interface, that is, the inter-domain boundary, an implicit method is used to solve the problem in the sub-domains. A priori error estimates are derived and the result of a numerical experiment is presented.", "num_citations": "13\n", "authors": ["497"]}
{"title": "Fault tolerant reversible finite field arithmetic circuits\n", "abstract": " In this paper, we present a systematic method for the designing fault tolerant reversible arithmetic circuits for finite field or Galois fields of the form GF(2 m ). To tackle the problem of errors in computation, we propose error detection and correction using multiple parity prediction technique based on low density parity check (LDPC) code. For error detection and correction, we need additional garbage outputs. Our technique, when compared with traditional fault tolerant approach gives better implementation cost.", "num_citations": "13\n", "authors": ["497"]}
{"title": "A technique for representing multiple output binary functions with applications to verification and simulation\n", "abstract": " This paper presents a technique for representing multiple-output binary and word-level functions in GF(JV) (where N = p m , p is a prime number, and m is a nonzero positive integer) based on decision diagrams (DDs). The presented DD is canonical and can be made minimal with respect to a given variable order. The DD has been tested on benchmarks, including integer multiplier circuits, and the results show that it can produce better node compression (more than an order of magnitude in some cases) compared to shared binary DDs (BDDs). The benchmark results also reflect the effect of varying the input and output field sizes on the number of nodes. Methods of graph-based representation of characteristic and encoded characteristic functions in GF(iV) are also presented. Performance of the proposed representations has been studied in terms of average path lengths and the actual evaluation times with 50\u00a0\u2026", "num_citations": "13\n", "authors": ["497"]}
{"title": "Comparative study of CA with phase shifters and GLFSRs\n", "abstract": " In this paper, we investigate the use of Galois LFSRs (GLFSRs) as test pattern generators in BIST schemes that employ multiple scan chains. Current schemes use LFSRs or cellular automata (CA) with additional phase shifters to provide guaranteed minimum phase shifts between successive scan chains and also impose an upper bound on the number of taps for the XOR gate of each phase shifter. We compare CA with phase shifters (CAPSs) and GLFSRs without phase shifters in terms of the minimum inter-channel separation that they achieve and the overall XOR cost for each construction. Experimental results for different degrees show that GLFSRs are preferable in both hardware cost and fault coverage", "num_citations": "13\n", "authors": ["497"]}
{"title": "Providing seamless communication in mobile wireless networks\n", "abstract": " This paper presents a technique to provide seamless communication in mobile wireless networks. The motivation behind this study is to find a cost effective solution for minimizing the impact of active hand-offs (hand-offs during an active connection) on connection throughput. Existing solutions either provide total guarantee for seamless communication, incurring heavy network bandwidth usage (multicast based approach), or do not provide any guarantee for seamless communication (unicast based approach). Some other solutions are tuned to give good performance for specific protocols (e.g., fast-retransmit approach). This paper proposes a novel staggered multicast approach which provides a probablistic guarantee for seamless communication independent of the communication protocol used. We present experimental results of performance improvements achieved by our scheme, for data transfer using TCP\u00a0\u2026", "num_citations": "13\n", "authors": ["497"]}
{"title": "Fault-tolerant multiprocessor and distributed systems: principles\n", "abstract": " Fault-tolerant multiprocessor and distributed systems | Fault-tolerant computer system design ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksFault-tolerant computer system designFault-tolerant multiprocessor and distributed systems: principles chapter Fault-tolerant multiprocessor and distributed systems: principles Share on Authors: Dhiraj K. Pradhan View Profile , Prith Banerjee View Profile Authors Info & Affiliations Fault-tolerant computer system designFebruary 1996 Pages 135\u2013235 Published:01 February 1996 2citation 0 Downloads Metrics Total Citations2 Total Downloads0 Last 12 Months0 Last 6 weeks0 Get Citation ! to\u2026", "num_citations": "13\n", "authors": ["497"]}
{"title": "Degradable agreement in the presence of Byzantine faults\n", "abstract": " The authors consider a system consisting of a sender that wants to send a value to certain receivers. Byzantine agreement protocols have previously been proposed to achieve this in the presence of arbitrary failures. The imposed requirement typically is that the fault-free receivers must all agree on the same value. An agreement protocol is proposed that achieves Lamport's Byzantine agreement (L. Lamport et al., 1982) up to a certain number of faults and a degraded form of agreement with a higher number of faults. The degraded form of agreement allows the fault-free receivers to agree on at most two different values, one of which is necessarily the default value. The proposed approach is named degradable agreement. An algorithm for degradable agreement is presented along with bounds on the number of nodes and network connectivity necessary to achieve degradable agreement.< >", "num_citations": "13\n", "authors": ["497"]}
{"title": "System level diagnosis: Combining detection and location\n", "abstract": " The problem of system recovery from a large number of faults is addressed. Correlated transient upsets can corrupt the state of a large number of nodes (subsystems). In such a condition, locating faulty nodes can be difficult due to the large number of periodic tests that may have to be carried out. A new approach to system level diagnostics that combines fault detection and location and can detect the fault condition in the event of large number of faults is proposed. Detection allows alternate techniques of diagnosis or at the very least a safe shut-down. This approach is termed safe diagnosis as it provides a measure of safety for critical systems. It is demonstrated that safe diagnosis can be achieved with a small incremental cost. Results that characterize systems that admit a specified level of safe diagnosis are included. Diagnosis algorithms for such systems are presented. It is shown that the complexity of safe\u00a0\u2026", "num_citations": "13\n", "authors": ["497"]}
{"title": "Asynchronous state assignments with unateness properties and fault-secure design\n", "abstract": " Techniques to construct standard state assignments that yield unate next-state functions are presented. These proposed assignments use Berger codes. Further, it is also shown how to modify the so-called (2n + 1) type assignment for unateness. The modified assignments require 2[n + I + 1og 2  (n + 1)] variables Finally, a procedure to design fault-secure asynchronous networks is presented. The assignments proposed in this paper are shown to be useful for this design.", "num_citations": "13\n", "authors": ["497"]}
{"title": "IoT based fruit quality measurement system\n", "abstract": " In today's world, food processing industries are immense part of human livelihood be it directly or indirectly. Human population consume enormous amount of foods that are sold in packaged form manufactured in several food processing industries around the globe. Packaged fruit products such as juice, jam, jelly, tomato ketchup, fruit cakes etc. are the most popular examples of such intake. But, when quality of fruit comes into the scene, maximum fruit processing industries do still depend on direct human intervention. Especially, in the selection process of good quality fruits from a dynamic fruit chain. This method is obviously an error prone task in nature. Henceforth, influenced to abolish this practice, a study is conducted on how automated quality checking (i.e. ripening percentage) can be done. To counter this problem, a simple, easy to design and portable solution based on Internet of Things is presented in this\u00a0\u2026", "num_citations": "12\n", "authors": ["497"]}
{"title": "Introduction to energy-efficient fault-tolerant systems\n", "abstract": " Embedded systems are making their way into more and more devices, from hand-held gadgets to household appliances, and from mobile devices to cars. The current trend is that this growth will continue and the market is expected to experience a three-fold rise in the demand from 2013 to 2018 [20]. This growth has been possible due to continued technological advancements in terms of device miniaturization, feature richness, design cost control and performance improvement, originally described by the Moore\u2019s Law [32].", "num_citations": "12\n", "authors": ["497"]}
{"title": "Multiple bit error detection and correction in GF arithmetic circuits\n", "abstract": " This paper presents a design technique for multiple bit error correctable (fault tolerant) polynomial basis (PB) multipliers over GF(2 m ). These multipliers are the building blocks in certain types of cryptographic hardware, e.g. the Elliptic Curve Crypto systems (ECC). One of the drawbacks in the existing techniques is their inability to correct multiple bit errors at the outputs. Also, much attention has been given to error detection, as opposed to error correction. However, owing to possible security threats induced by soft or transient faults in cryptographic hardware, in certain cases multiple bit error correction, as a way of mitigating attacks, is more important than detection. To this end, we use multiple parity predictions to detect multiple errors based on popular error correcting codes. First, we present a multiple error detection scheme using Low Density Parity Check Codes (LDPC). The expressions for the parity prediction\u00a0\u2026", "num_citations": "12\n", "authors": ["497"]}
{"title": "Static random access memory\n", "abstract": " A static random access memory (\u201cSRAM\u201d) comprising: a pair of inverters each having an input and an output; a cross-coupling path coupling the input of a first inverter to the output of a second inverter; and a transmission gate, wherein the transmission gate comprises a p-channel transistor coupling the input of the second inverter to the output of the first inverter; and an n-channel transistor coupling the input of the second inverter to the output of the first inverter in parallel with the p-channel transistor. In another embodiment, the SRAM comprises a first inverter having a supply voltage node connected to a supply voltage, and a ground node connected to ground; a second inverter cross-coupled with the first inverter and having a supply voltage node connected to a supply voltage, and a ground node; and a switch selectively connecting and disconnecting the ground node of the second inverter to ground.", "num_citations": "12\n", "authors": ["497"]}
{"title": "A combined DOE-ILP based power and read stability optimization in nano-CMOS SRAM\n", "abstract": " A novel design approach for simultaneous power and stability (static noise margin, SNM) optimization of nano-CMOS static random access memory (SRAM) is presented. A 45 nm single-ended seven transistor SRAM is used as a case study. The SRAM is subjected to a dual-V Th  assignment using a novel combined Design of Experiments and Integer Linear Programming (DOE-ILP) algorithm, resulting in 50.6% power reduction (including leakage) and 43.9% increase in the read SNM. The process variation analysis of the optimal SRAM carried out considering twelve device parameters shows the robustness of the design.", "num_citations": "12\n", "authors": ["497"]}
{"title": "Feedback based real-time MAC (RT-MAC) protocol for wireless sensor networks\n", "abstract": " This paper presents a MAC layer protocol, called RTMAC, for real-time data streaming in wireless sensor networks. RT-MAC eliminates need to contend for a wireless medium by potential transmitting nodes in a range by introducing feedback control packet, called Clear Channel (CC). RT-MAC maximizes spatial channel reuse by avoiding false blocking problem of RTS/CTS exchange based wireless MAC protocols. RT-MAC reduces contention duration for control packets to facilitate faster traveling of data packets; thus, it reduces end-to-end delay of data packet transmission. RT-MAC facilitates periodic delivery of data packets as well as fast reporting of an alarming event. This paper provides the upper bounds of end-to-end delay of data packet transmission with periodic sleep/listen schedule for RT-MAC protocol. In this paper, extensive simulation results are presented. RT-MAC supports single stream\u00a0\u2026", "num_citations": "12\n", "authors": ["497"]}
{"title": "Design and analysis of a gracefully degrading interleaved memory system\n", "abstract": " The organization of interleaved memories in such a way that faults in the memory system degrade the performance in a graceful manner is studied. Attention is restricted to an interleaved memory system that starts out with 2/sup q/ memory banks and uses a low-order interleaving scheme. The motivation and design objectives of the memory system are described. A new reconfiguration scheme and the design of the hardware needed to implement it are presented. The reconfiguration scheme is evaluated using trace-driven simulation for a number of benchmarks. The ideas presented can easily be extended to other interleaved memory schemes.< >", "num_citations": "12\n", "authors": ["497"]}
{"title": "Reed-Muller like canonic forms for multivalued functions\n", "abstract": " In this correspondence we show the existence of a Reed-Muller like expansion for multivalued functions. We establish that any m-variable, N-valued function [mi]f(x m ,x m-1 ,...x 1 [/mi]) can be expressed as [mi]C o + C 1 x 1 + *--+ + C N m _ 1 x m N-1 x m-1 N-1 x 1 N-1 [/mi]. A matrix method for determining the coefficients of these expansions is presented. The problem of finding minimal expression for a given function is discussed. Finally, we present a new technique for realizing multiple output functions.", "num_citations": "12\n", "authors": ["497"]}
{"title": "Single-event transient analysis in high speed circuits\n", "abstract": " The effect of Single-Event Transients (SETs) (at a combinational node of a design) on the system reliability is becoming a big concern for ICs manufactured using advanced technologies. An SET at a node of a combinational part of a circuit may propagate as a transient pulse at the input of a flip-flop and consequently latches in the flip-flop, thus generating a soft-error. When an SET is combined with a transition at a node (i.e., dynamic behavior of that node) along a critical path of the combinational part of a design, a transient delay fault may occur at the input of a circuit flip-flop. Using the Probability Density Function (PDF) of an SET, this paper proposes a statistical method to compute the probability of soft-errors caused by SETs considering dynamic behavior of a circuit.", "num_citations": "11\n", "authors": ["497"]}
{"title": "Fault-tolerant de-Bruijn graph based multipurpose architecture and routing protocol for wireless sensor networks\n", "abstract": " As dense Wireless Sensor Networks (WSNs) are increasingly vulnerable to fault, network must continue processing data without affecting the faulty node. Fault aware routing is an effective way to mitigate such a scenario. To this end, we present a de-Bruijn graph based Multipurpose Architecture and Routing Protocol (MARP) which has all the properties of an efficient WSN. The MARP supports multicast routing, broadcasting, fault detection and efficient fault-tolerance. Its unique architecture makes it easily scalable and provides easy three-dimensional to two-dimensional mapping. Furthermore, we show that, depending on the fault-tolerance capability one wants, design requires higher redundancy. A small experiment of de-Bruijn graph based routing protocol is also presented with mica2 motes to check its feasibility in a real-life scenario.", "num_citations": "11\n", "authors": ["497"]}
{"title": "Fault diagnosis in multi layered de bruijn based architectures for sensor networks\n", "abstract": " Wireless sensor networks are expected to operate in an unattended manner for long periods of time. As a result, they should be able to tolerate faults and maintain a reasonable performance level. Therefore, we propose two fault-tolerant clustered De Bruijn based multi layered architectures, a fault-tolerant routing scheme and a distributed fault diagnosis algorithm. The performance of the proposed work was analyzed according to the end-to-end delay and the data success rate. Also, the performance was compared to that of mesh networks. Our simulation results show that De Bruijn based networks perform better in both fault free and faulty situations.", "num_citations": "11\n", "authors": ["497"]}
{"title": "Single ended static random access memory for low-vdd, high-speed embedded systems\n", "abstract": " Single-ended static random access memory (SE-SRAM) is well known for their tremendous potential of low active power and leakage dissipations. In this paper, we present a novel six-transistor (6T) SE-SRAM bitcell for low-V dd  and high speed embedded applications with significant improvement in their power, performance and stability under process variations. The proposed design has a strong 2.65times  worst   case  read static noise margin (SNM) compared to a standard 6T SRAM. A strong write-ability of logic 'one' is achieved, which is problematic in SE-SRAM cells even at lower voltage. The proposed bitcell design is mainly targeted for word-organized SRAMs. A 16 times 16 times 32 bit SRAM with proposed and standard 6T bitcells is simulated (including parasitics) for 65 nm CMOS technology to evaluate and compare the different performance parameters, such as, read SNM, write-ability, access delay\u00a0\u2026", "num_citations": "11\n", "authors": ["497"]}
{"title": "Embedding current monitoring in H-tree RAM architecture for multiple SEU tolerance and reliability improvement\n", "abstract": " In this paper, we present a new technique to improve the reliability of H-tree SRAM memories. This technique deals with the SRAM power-bus monitoring by using built-in current sensor (BICS) circuits that detect abnormal current dissipation in the memory power-bus. This abnormal current is the result of a single-event upset (SEU) in the memory and it is generated during the inversion of the state of the memory cell being upset. The current checking is performed on an H-tree SRAM in different ways. We demonstrate the assertions of the proposed technique by performing a reliability analysis while combining current monitoring with a single-parity bit or Hamming codes per RAM word to perform single or multiple error correction.", "num_citations": "11\n", "authors": ["497"]}
{"title": "Fault tolerant bit parallel finite field multipliers using LDPC codes\n", "abstract": " Motivated by the problems associated with soft errors in digital circuits and fault related attacks in cryptographic hardware, we presented a systematic method for designing single error correcting multiplier circuits for finite fields or Galois fields over GF(2 m ) in [7]. We used multiple parity predictions to correct single errors based on the Hamming principles. The problem with Hamming based error correction is the delay overhead. To mitigate the delay overhead, in this paper we present single error correction using Low Density Parity Check Codes (LDPC). The expressions for the parity prediction are derived from the input operands, and are based on the primitive polynomials of the fields. Our technique, when compared with existing techniques, gives better performance. We show that our Single Error Correction (SEC) multipliers over GF(2 m ) require slightly over 100 percent extra hardware, whereas with the\u00a0\u2026", "num_citations": "11\n", "authors": ["497"]}
{"title": "De Bruijn graph as a low latency scalable architecture for energy efficient massive NoCs\n", "abstract": " In this paper, we use the generalized binary de Bruijn (GBDB) graph as a scalable and efficient network topology for an on-chip communication network. Using just two-layer wiring, we propose an optimum tile-based implementation for a GBDB- based Network-on-Chip (NoC). Our experimental results show that the latency and energy consumption of generalized de Bruijn graph are much less with compared to Mesh and Torus, the two common NoC architectures in the literature.", "num_citations": "11\n", "authors": ["497"]}
{"title": "Single error correcting finite field multipliers over GF (2m)\n", "abstract": " This paper presents a new method for designing single error correcting Galois field multipliers over polynomial basis. The proposed method uses multiple parity prediction circuits to detect and correct logic errors and gives 100% fault coverage both in the functional unit and the parity prediction circuitry. Area, power and delay overhead for the proposed design technique is analyzed. It is found that compared to the traditional triple modular redundancy (TMR) techniques for single error correction the proposed technique is very cost efficient.", "num_citations": "11\n", "authors": ["497"]}
{"title": "A graph-based unified technique for computing and representing coefficients over finite fields\n", "abstract": " This paper presents the generalized theory and an efficient graph-based technique for the calculation and representation of coefficients of multivariate canonic polynomials over arbitrary finite fields in any polarity. The technique presented for computing coefficients is unlike polynomial interpolation or matrix-based techniques and takes into consideration efficient graph-based forms which can be available as an existing resource during synthesis, verification, or simulation of digital systems. Techniques for optimization of the graph-based forms for representing the coefficients are also presented. The efficiency of the algorithm increases for larger fields. As a test case, the proposed technique has been applied to benchmark circuits over GF(2 m ). The experimental results show that the proposed technique can significantly speed up execution time.", "num_citations": "11\n", "authors": ["497"]}
{"title": "Buffer assignment algorithms on data driven ASICs\n", "abstract": " Data driven architectures have significant potential in the design of high performance ASICs. By exploiting the inherent parallelism in the application, these architectures can maximize pipelining. The key consideration involved with the design of a data driven ASIC is ensuring that throughput is maximized while a relatively low area is maintained. Optimal throughput can be realized by ensuring that all operands arrive simultaneously at their corresponding operator node. If this condition is achieved, the underlying data flow graph is said to be balanced. If the initial data flow graph is unbalanced, buffers must be inserted to prevent the clogging of the pipeline along the shorter paths. A novel algorithm for the assignment of buffers in a data flow graph is proposed. The method can also be applied to achieve wave-pipelining in digital systems under certain restrictions. The algorithm uses a new application of the retiming\u00a0\u2026", "num_citations": "11\n", "authors": ["497"]}
{"title": "An efficient coordinated checkpointing scheme for multicomputers\n", "abstract": " A new approach for checkpointing multicomputer applications is presented. The checkpointing is initiated and controlled by a checkpoint coordinator, residing either on one of the nodes running the application or on the host processor attached to the multicomputer. A message count is used to determine if any messages are in transit. The proposed strategy is hardware-independent and can be implemented in any multicomputer system irrespective of the architecture, interconnection, and routing strategy. This scheme can be used for FIFO and non-FIFO channels as well as with channels where messages can be lost. Measurement results obtained from our simulations indicate that the proposed strategy outperforms an existing scheme proposed for fixed-path wormhole-routed multicomputer systems. Although the proposed strategy is targeted for high-performance, massively parallel multicomputers, it can also be\u00a0\u2026", "num_citations": "11\n", "authors": ["497"]}
{"title": "Yield optimization in large RAM's with hierarchical redundancy\n", "abstract": " The authors present and analyze large RAM architectures with hierarchical redundancy and determine the optimal redundancy organization for yield enhancement. A two-level redundancy scheme is used for defect tolerance, and the defect distribution is modeled using the compounded Poisson model. The tree random access memory (TRAM), which has been proposed as a design methodology for future multimegabit memories (N. Jarwala et al., 1988) is considered as an example for modeling and optimization. The results show that the two-level hierarchical redundancy approach, with spare bit and word lines within memory quadrants, and additional spare modules for global sparing, along with redundant interconnections can efficiently provide defect tolerance and viable yields for future generations of high-density dynamic random access memories.< >", "num_citations": "11\n", "authors": ["497"]}
{"title": "P3 (power-performance-process) optimization of nano-CMOS SRAMusing statistical DOE-ILP\n", "abstract": " In this paper, a novel design flow is presented for simultaneous P3 (power minimization, performance maximization and process variation tolerance) optimization of nano-CMOS circuits. For demonstration of the effectiveness of the flow, a 45nm single-ended 7-transistor SRAM is used as example circuit. The SRAM cell is subjected to a dual-V Th  assignment based on a novel statistical Design of Experiments-Integer Linear Programming (DOE-ILP) approach. Experimental results show 44.2% power reduction (including leakage) and 43.9% increase in the read static noise margin compared to the baseline design. The process variation analysis of the optimized cell is carried out considering the variability effect in 12 device parameters. A 8 \u00d7 8 array is constructed to show the feasibility of the proposed SRAM cell. To the best of the authors' knowledge, this is the first study which makes use of statistical Design of\u00a0\u2026", "num_citations": "10\n", "authors": ["497"]}
{"title": "ULS: A dual-Vth/high-\u03ba nano-CMOS universal level shifter for system-level power management\n", "abstract": " Power dissipation is a major bottleneck for emerging applications, such as implantable systems, digital cameras, and multimedia processors. Each of these applications is essentially designed as an Analog/Mixed-Signal System-on-a-Chip (AMS-SoC). These AMS-SoCs are typically operated from a single power-supply source which is a battery providing a constant supply voltage. In order to reduce power dissipation of the AMS-SoCs, multiple-supply voltage and/or variable-supply voltage is used as an attractive low-power design approach. In the multiple-/variable-supply voltage AMS-SoCs the use of a DC-to-DC voltage-level shifter is critical. The voltage-level shifter is an overhead when its own power dissipation is high. In this article a new DC-to-DC voltage-level shifter is introduced that performs level-up shifting, level-down shifting, and blocking of voltages and is called Universal Level Shifter (ULS). The ULS is\u00a0\u2026", "num_citations": "10\n", "authors": ["497"]}
{"title": "Algorithm level fault tolerance: a technique to cope with long duration transient faults in matrix multiplication algorithms\n", "abstract": " For technologies beyond the 45 nm node, radiation induced transients will last longer than one clock cycle. In this scenario, temporal redundancy techniques will no longer be able to cope with radiation induced soft errors, while spatial redundancy techniques still impose high power and area overheads. The solution to this impasse is the use of algorithm level techniques, able to detect and correct errors with low cost. In this paper, a new approach to deal with this problem is proposed, and applied to matrix multiplication algorithm. The proposed technique is compared to previously published fault tolerance techniques, and the costs of detection and recomputation for both approaches are compared and discussed.", "num_citations": "10\n", "authors": ["497"]}
{"title": "GfXpress: A Technique for Synthesis and Optimization ofPolynomials\n", "abstract": " This paper presents an efficient technique for synthesis and optimization of the polynomials over GF(2 m ), where to is a nonzero positive integer. The technique is based on a graph-based decomposition and factorization of the polynomials, followed by efficient network factorization and optimization. A technique for efficiently computing the coefficients of the polynomials over GF(p m ), where p is a prime number, is first presented. The coefficients are stored as polynomial graphs over GF(p m ). The synthesis and optimization is initiated from this graph-based representation. The technique has been applied to minimize multipliers over the fields GF(2 k ), where k = 2,...,8, generated with all the 51 primitive polynomials in the 0.18-mum CMOS technology with the help of the Synopsys design compiler. It has also been applied to minimize combinational exponentiation circuits, parallel integer adders and multipliers, and\u00a0\u2026", "num_citations": "10\n", "authors": ["497"]}
{"title": "C-testable bit parallel multipliers over GF(2m)\n", "abstract": " We present a C-testable design of polynomial basis (PB) bit-parallel (BP) multipliers over GF(2m) for 100% coverage of stuck-at faults. Our design method also includes the method for test vector generation, which is simple and efficient. C-testability is achieved with three control inputs and approximately 6% additional hardware. Only 8 constant vectors are required irrespective of the sizes of the fields and primitive polynomial. We also present a Built-In Self-Test (BIST) architecture for generating the test vectors efficiently, which eliminates the need for the extra control inputs. Since these circuits have critical applications as parts of cryptography (e.g., Elliptic Curve Crypto (ECC) systems) hardware, the BIST architecture may provide with added level of security, as the tests would be done internally and without the requirement of probing by external testing equipment. Finally we present experimental results comprising\u00a0\u2026", "num_citations": "10\n", "authors": ["497"]}
{"title": "Fast and efficient strategies for cubic and non-cubic allocation in hypercube multiprocessors\n", "abstract": " A new approach for dynamic processor allo cation in hypercube multiprocessors which sup ports a multi-user environment is proposed. A dynamic binary tree is used for processor allo cation along with an array of free lists. Two al gorithms are proposed based on this approach that are capable of handling cubic as well as non-cubic allocation efficiently. The time com plexities for both allocation and deallocation are shown to be polynomial; orders of mag nitude improvement over the existing expo nential and even super-exponential algorithms. Unlike the existing strategies, the proposed strategies are best-fit strategies and do not ex cessively fragment the hypercube. Simulation results indicate that the proposed strategies outperform the existing ones in terms of pa rameters such as average delay in honoring a request, average allocation time and average deallocation time.", "num_citations": "10\n", "authors": ["497"]}
{"title": "Correction to'The De Bruijn multiprocessor network: A versatile parallel processing and sorting network for VLSI'\n", "abstract": " Corrections to the galley proof of the above-titled paper by the authors (see ibid., vol.38, no.4, p.567-81 (1989)) that were inadvertently omitted from the published paper are given.< >", "num_citations": "10\n", "authors": ["497"]}
{"title": "Parallel algorithms and architectures report of a workshop\n", "abstract": " The primary goal in designing or building new computers is to achieve a massive speedup over current machines. In this section we discuss the role of computer architecture in achieving this speedup.", "num_citations": "10\n", "authors": ["497"]}
{"title": "Hyperspectral image processing for target detection using Spectral Angle Mapping\n", "abstract": " In this paper we concentrate on understanding the Hyperspectral Image subspace, spectral processing of the Hyperspectral Image using Spectral Angle Mapping to achieve target detection. A combined spatial-spectral integrated processing algorithm is proposed to be implemented in cases where spectral processing produces probable target pixels that are spatially spread. Atmospheric error correction is done using the method of Internal Average Relative Reflectance. To reduce processing time necessary dimensionality reduction has been implemented using Principal Component Analysis. EO-1 Hyperion datasets have been used for this project. The results of both the spectral classification and the proposed integrated spatial-spectral processing algorithm with and without atmospheric error correction as well as with and without dimensionality reduction has been analysed using ENVI Image processing toolbox\u00a0\u2026", "num_citations": "9\n", "authors": ["497"]}
{"title": "A closed-loop control strategy for glucose control in artificial pancreas systems\n", "abstract": " Maintaining good glycemic control is a continuous challenge for type-1 diabetic patients. The current means of insulin therapy are seen to subject patients to hyper- and hypoglycemic episodes. With the advancement of computer science and technology, an artificial pancreas, a computerized device that will automatically control patient's blood glucose level by providing the substitute for the insulin supply functionality of a healthy pancreas was proposed. The main challenge faced by the development of this device is a fully closed-loop control system. In this paper we proposed an artificial pancreas system with an adaptive closed-loop control strategy that computes the appropriate insulin infusion rate and thereby keeping the patient's blood glucose concentration within normoglycemic range. The adaptability is achieved through a rigorous pattern recognition technique with patient-specific glucose readings obtained\u00a0\u2026", "num_citations": "9\n", "authors": ["497"]}
{"title": "Synthesis of initializable asynchronous circuits\n", "abstract": " We show that existing synthesis techniques may produce asynchronous circuits that are not initializable by gate level analysis tools even when the design is functionally initializable. Due to the absence of any initialization sequence, a fault simulator or test generator that assumes an unknown starting state will be completely ineffective for these circuits. In this paper, we show that proper consideration of initializability during the asynchronous circuit synthesis procedure can guarantee initializable implementations. We show that the assignment of don't cares during the synthesis procedure affects the initializability of the final implementation. We present a novel implicit enumeration procedure that selectively assigns don't cares to obtain an initializable implementation. Initialization sequences are obtained as a by-product of our synthesis procedure.", "num_citations": "9\n", "authors": ["497"]}
{"title": "Optimal broadcasting in binary de Bruijn networks and hyper-deBruijn networks\n", "abstract": " The order-(m, n) hyper-deBruijn graph H D(m, n) is the direct product of an order-m hypercube and an order-n deBruijn graph. The hyper-deBruijn graph offers flexibility in terms of connections per node and the level of fault-tolerance. These networks as well possess logarithmic diameter, simple routing algorithms and support many computationally important subgraphs and admit efficient implementation. The authors present asymptotically optimal one-to-all (OTA) broadcasting scheme for these networks, assuming packet switched routing and concurrent communication on all ports. The product structure of the hyper-deBruijn graphs is exploited to construct an optimal number of edge-disjoint spanning trees to achieve this. Also, as an intermediate result they present a technique to construct an optimal number of spanning trees with heights bounded by the diameter in binary deBruijn graphs. This result is used to\u00a0\u2026", "num_citations": "9\n", "authors": ["497"]}
{"title": "Program fault tolerance based on memory access behavior\n", "abstract": " Fault observability based on the behavior of the memory references is studied. As opposed to traditional studies that view memory as one large entity that must completely work to be considered reliable, this study emphasizes the usage patterns of a particular program's memory. Expressions for the successful execution of a program that takes into account the usage of the data are developed. Three variations that depend on whether the program's storage is pre-allocated, dynamically allocated, or constrained in allocation are presented. A theory is proposed to explain the phenomenon that increased workloads lead to increased failure rates, which has been observed in several studies. The model is used to study several program traces, and is shown that increased workloads could cause an increase of the observed failure rates in the range of 27% to 53%.<>", "num_citations": "9\n", "authors": ["497"]}
{"title": "Easily testable high speed architecture for large RAMS\n", "abstract": " The RAM is partitioned into modules, each of which appear as the leaf node of a binary interconnect network. This network carries the address/data/control bus which permits the nodes to communicate between themselves and with the outside world. The address, data and control signals are applied to the root node. The most significant address bit is decoded, generating either a left subtree or a right subtree select. The other signals would be buffered and propogated down the tree. The solution process occurs at each level within the bus until finally a single leaf node would be selected. Within the node, then, the internal timing and control unit would access the data requested, sending it up the tree or writing the value on the data bus, into the addressed location.", "num_citations": "9\n", "authors": ["497"]}
{"title": "Organization and analysis of a gracefully-degrading interleaved memory system\n", "abstract": " A hardware mechanism has been proposed to reconfigure an interleaved memory system. The reconfiguration scheme is such that, at any instant all fault-free memory banks in the memory system are utilized in interleaved manner. A performance metric is defined which takes into account the bandwidth and the page-fault rate in an interleaved memory system. The reconfiguration scheme proposed in this paper is analyzed for a number of distinct programs using the performance metric defined in the paper. It is shown that the system performance degrades slowly, as the number of faulty banks increase, in a memory system using the proposed reconfiguration scheme.", "num_citations": "9\n", "authors": ["497"]}
{"title": "The de Bruijn multiprocessor network: A versatile sorting network\n", "abstract": " Recent work [I] has classified sorting architectures as:(A) Sequential input/Sequentlal output,(B) Parallel input/Sequentlal output,(C) Parallel Input/Parallel output,(D) Sequential input/Parallel output and (E) Hybrid input/Hybrld output. The classification is based, not only on the I/O method, but also on the interconnection network, the sorting algorithm and the type of keys used. This paper demonstrates that the architectures based on the undirected de BrulJn graphs (DGs) can sort data items in all of the above mentioned categories. To the best of our knowledge, no other single network which can sort data items in all the categories is known. Sorting algorithms and time complexities that correspond to each of these categories are given here. It is shown that these architectures can achieve the previously known best upper bound times, in all of the categories. Also, it is proven that they work as sorting networks, even in\u00a0\u2026", "num_citations": "9\n", "authors": ["497"]}
{"title": "Fault-tolerant asynchronous networks using read-only memories\n", "abstract": " In this paper, we present techniques for the construction of certain redundant state assignments suitable for fault-tolerant asynchronous network design. These assignments have certain characteristics that make them well-suited for error-control in asynchronous networks, using read-only memories, and are as follows: only a small number of additional state variables are required for incorporating fault-tolerance properties; the assignments form the codewords of an error-correcting code; and are systematic. An example is also provided to clarify some misconceptions that have arisen over the fault-tolerant design proposed earlier by the authors", "num_citations": "9\n", "authors": ["497"]}
{"title": "Techniques to construct (2, 1) separating systems from linear error-correcting codes\n", "abstract": " (2,1) separating systems have earlier been shown to be useful in designing asynchronous sequential circuits [6]. In this paper, techniques to derive (2,1) separating systems from linear error-correcting codes are given. It is shown that the proposed techniques yield better (2,1) separating systems than earlier klown techniques.", "num_citations": "9\n", "authors": ["497"]}
{"title": "Fault-tolerant carry-save adders\n", "abstract": " In this correspondence a design of fault-tolerant carry-save adders is presented. The design of fault-tolerant carry-save adders is of practical interest since in most of the modem day computers a carry-save adder is an essential circuit. We will also indicate how carry-save adders can be well used as a logic unit and thus some broader application of the design is illustrated.", "num_citations": "9\n", "authors": ["497"]}
{"title": "A design technique for synthesis of fault tolerant adders\n", "abstract": " A new technique for the design of fault toler veniently described in terms of a set of m+ 1, 2m-ant adders using Reed-Muller codes is presented. In dimensionaly, binary vectors w WOW2..., wmi Where w an earlier paper the author has shown that Reed-Muller is a vector having all 2\" components as l's and codes can be used for the design of fault tolerant when represented by rows of a mx2 matrix, logical processors. Reed-Muller codes are also applicable for correcting faults in memory of the the columns of this matrix will constitute all possible computers. With the proposed application of Reed- 200 binary m-tuples. Muller codes to the design of fault tolerant adders we have one class of codes applicable to all parts of For example when m= 3, computers which should prove useful in the design of fault tolerant computers.= 1 1 1 1 1 1 1 1 wo wi= 0 0 0 1 1 1 1 0 INTRODUCTION W2= 0 1 1 0 0 1 1 0In recent years much effort has been devoted W3= 1 0 1 0 1 0 1 0 to the development of reliable computers. The basic technique that has been proposed is redundancy. One[W.] and S,[WZ..... wml. The generator maof the important organs of a computer is the adder. trix of an ith order RMC can be constructed by taking Therefore the development of techniques for the design the union of 50, 92...., of failure tolerant adders has been one of the major concerns among the researchers.(1-15] At present S [w.", "num_citations": "9\n", "authors": ["497"]}
{"title": "Detection and restoration of multi-directional motion blurred objects\n", "abstract": " In this paper, an object blur detection and deblurring technique is proposed to restore multi-directional motion blurred objects in a single image. We have proposed local blur angle detection method based on Radon transform (RT) and Laplacian of Gaussian (LoG). While capturing the images, motion blur occurs mainly due to either movement of the objects or movement of the camera. Here, we have focused to restore the objects which has been blurred by motion of the objects. The estimation of likely blur direction is calculated in the blurred image using RT and gradient operators. To detect blur angle locally at each pixel, the new local blur angle estimator using RT and LoG has been developed. Numerical experiments have been carried out for the proposed method, and the results are compared with the state-of-the-art methods.", "num_citations": "8\n", "authors": ["497"]}
{"title": "Lifetime reliability-aware checkpointing mechanism: Modelling and analysis\n", "abstract": " Check pointing mechanism is used to tolerate the impact of transient faults through roll-back operation to a previously saved system state. In this paper, we propose a novel check pointing mechanism that considers fault tolerance in a duplex system in the presence of both transient and permanent faults. The main objective of our proposed mechanism is to extend the lifetime reliability of the duplex system by avoiding or even tolerating permanent faults in microprocessors. In addition, we also propose to migrate tasks from a 'near-to-die' processor to a spare processor under a condition where the current Mean-Time-To-Failure (MTTF) value is less or equal to a pre-determined threshold MTTF value. We validate our proposed mechanism and perform overhead analysis using various case studies. Later, we compare it with one of the most popular existing check pointing mechanism, namely the roll-forward check\u00a0\u2026", "num_citations": "8\n", "authors": ["497"]}
{"title": "Driver's face tracking based on improved CAMSHIFT\n", "abstract": " The statistic shows that the number of casualty increase in every year due to road accident related to driver drowsiness. After long journey or sleepless night, vehicle driver will perform some biofeatures with regard to drowsiness on them face. It is self-evident that getting location information of head in continuous monitoring and surveillance system rapidly and accurately can help prevent many accidents, and consequently save money and reduce personal suffering. In this paper, according the real situation in vehicle, an improved CAMShift approach is proposed to tracking motion of driver\u2019s head. Results from experiment show the significant performance of proposed approach in driver\u2019s head tracking.", "num_citations": "8\n", "authors": ["497"]}
{"title": "Neuroprotective effect of Bacopa monnieri leaf extract targeted at adenosine receptor in diabetic neuropathic pain.\n", "abstract": " see more details and subjected to thermal (cold and hot) and chemical (formalin) stimuli. Diabetic rats developed hyperalgesia by the end of six weeks in thermal and chemical stimuli test. Aqueous extract of Bacopa monnieri leaf (AEBM)(200 mg/kg, ip) produced significant reversal of responses to thermal and chemical stimuli in diabetic rats. The results indicate that AEBM is an effective analgesic in a model of diabetic neuropathy, and the protection produced by AEBM is via stimulation of adenosine A 1-receptors.", "num_citations": "8\n", "authors": ["497"]}
{"title": "Failure analysis for ultra low power nano-CMOS SRAM under process variations\n", "abstract": " Several design metrics have been used in the past to evaluate the SRAM cell stability. However, most of them fail to provide the exact stability figures as shown in this paper. Therefore, we investigate new stability metrics and report the stability analysis for typical a SRAM cell. In particular, a concept called power metric is introduced. From this metric we derive two new stability figures; static power noise margin (SPNM) and write trip power (WTP). It is shown that these new figures provide better cell stability analysis. Furthermore, we have exhaustively analyzed the impact of different parameters variations such as cell ratio, supply voltage V dd  and threshold voltage V th  on SPNM and WTP. Statistical models for estimating SPNM and WTP from intra-die V th  variations are presented. The estimated results match well with the Monte Carlo (MC) simulations.", "num_citations": "8\n", "authors": ["497"]}
{"title": "A nano-CMOS process variation induced read failure tolerant SRAM cell\n", "abstract": " In a nanoscale technology, memory bits are highly susceptible to process variation induced read/write failures. To address the above problem, in this paper a new memory cell is proposed which is highly stable against nanoscale process variations as well as power efficient. The effectiveness of the proposed cell is exhaustively evaluated through detailed Monte Carlo simulations. It is observed that the 16% variation in threshold voltage results in negligible effects on static noise margin (SNM) during read operation. Experiments under different loading conditions indicate that there is reduction 2X (approximately) in power dissipation and 2X (approximately) in leakage.", "num_citations": "8\n", "authors": ["497"]}
{"title": "Design of reversible finite field arithmetic circuits with error detection\n", "abstract": " Motivated by the potential of reversible computing, we present a systematic method for the designing reversible arithmetic circuits for finite field or Galois fields of form GF(2m). It is shown that an adder over GF(2m) can be designed with m garbage bits and that of a PB multiplier with 2m garbage bits. To tackle the problem of errors in computation, we also extend the circuit with error detection feature. Gate count and technology oriented cost metrics are used for evaluation. The expression for the upper bound for gate size is also derived for special primitive polynomials. Our technique, when compared with existing CAD tool gives the same gate size and quantum cost.", "num_citations": "8\n", "authors": ["497"]}
{"title": "Wideband low-distortion sigma-delta ADC for WLAN\n", "abstract": " This work presents a wideband low-distortion sigma- delta analog-to-digital converter (ADC) for wireless local area network (WLAN) standard. The proposed converter makes use of low-distortion swing suppression SDM architecture which is highly suitable for low oversampling ratios to attain high linearity over a wide bandwidth. The modulator employs a 2-2 cascaded sigma-delta modulator with feedforward path with a single-bit quantizer in the first stage and 4-bit in the second stage. The modulator is designed in TSMC 0.18 um CMOS technology and operates at 1.8 V supply voltage. Simulation results show that, a peak SNDR of 57 dB and a spurious free dynamic range (SFDR) of 66 dB is obtained for a 10 MHz signal bandwidth, and an oversampling ratio of 8.", "num_citations": "8\n", "authors": ["497"]}
{"title": "Easily Testable Implementation for Bit Parallel Multipliers in GF (2m)\n", "abstract": " A testable implementation of bit parallel multiplier over the finite field GF(2 m ) is proposed. A function independent test set of length (2m+4), which detects all the single stuck-at faults in an m bit GF(2 m ) multiplier circuit, is also presented. Test set can be determined readily from the corresponding algebraic forms without running an ATPG tool. The test complexity is lower than ATPG generated or algorithmic test set. The test set provides 100 percent single stuck-at fault coverage. The gate counts of the proposed testable multiplier as a function of degree m has been analyzed. The testable circuit realization requires only two extra inputs for controllability and some additional EX ns and need field testing, built-in self-test (BIST) circuit may be used to generate test pattern internally for detecting faults in the multiplier circuits", "num_citations": "8\n", "authors": ["497"]}
{"title": "Exploration of power optimal implementation technique of 128-pt fft/ifft for wpan using pseudo-parallel datapath structure\n", "abstract": " An optimal implementation of 128-Pt FFT/IFFT for low power IEEE 802.15.3a WPAN using pseudo-parallel datapath structure is presented, where the 128-Pt FFT is devolved into 8-Pt and 16-Pt FFTs and then once again by devolving the 16-Pt FFT into 4times4 and 2times8- We analyze 128-Pt FFT/IFFT architecture for various pseudo-parallel 8-Pt and 16-Pt FFTs and an optimum datapath architecture is explored. It is suggested that there exist an optimum degree of parallelism for the given algorithm. The analysis demonstrated that with modest increase in area one can achieve significant reduction in power. The proposed architectures complete one parallel-to-parallel (i.e., when all input data are available in parallel and all output data are generated in parallel) 128-point FFT computation in less than 312 ns and thereby meeting the standard specification. The relative merits and demerits of these architectures have\u00a0\u2026", "num_citations": "8\n", "authors": ["497"]}
{"title": "Software fault tolerance in parallel computing systems: new roll-forward checkpointing schemes for modular redundant systems\n", "abstract": " Software fault tolerance in parallel computing systems | Hardware and software fault tolerance in parallel computing systems ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksHardware and software fault tolerance in parallel computing systemsSoftware fault tolerance in parallel computing systems: new roll-forward checkpointing schemes for modular redundant systems chapter Software fault tolerance in parallel computing systems: new roll-forward checkpointing schemes for modular redundant systems Share on Authors: Dhiraj K. Pradhan View Profile , Nitin H. Vaidya View Profile Authors Info & Affiliations Publication: Hardware -\u2026", "num_citations": "8\n", "authors": ["497"]}
{"title": "Cord blood bilirubin level as a predictor of development of pathological hyperbilirubinemia in new-borns\n", "abstract": " Background: There may be a delay in recognition of pathological hyperbilirubinemia which may lead to serious consequences in the new born. The purpose of this study was to verify whether the cord bilirubin levels predicted the development of pathological hyperbilirubinemia.Methods: In this hospital based prospective cross-sectional study conducted at Central Referral Hospital, Gangtok from December 2014 to November 2015, 202 live new born meeting the inclusion criteria were enrolled. After birth, cord blood was collected for the estimation of cord blood bilirubin and the babies were followed up daily for the development of clinical jaundice. Peripheral venous blood was collected for the estimation of serum bilirubin levels in those who developed clinical jaundice.Results: The incidence of pathological hyperbilirubinemia in our study is 12.87%. The mean gestational age is 38.3 weeks. There is a significant association between cord blood total bilirubin levels and the development of pathological hyperbilirubinemia in newborns with a P-value of 0.000. A critical cord bilirubin level\u2265 2.50 mg/dl has sensitivity of 84.1%, specificity of 88.5%, positive predictive value of 98% and negative predictive value of 45.1% for predicting the risk of developing pathological jaundice. Conclusions: This study concludes that cord blood total bilirubin levels reliably predict the occurrence of pathological hyperbilirubinemia as defined by current operational guidelines.", "num_citations": "7\n", "authors": ["497"]}
{"title": "Improved multiple faults-aware placement strategy: Reducing the overheads and error rates in digital circuits\n", "abstract": " State-of-the-art commercial placement tools have as goals to optimize area, timing, and power. Over the years, several reliability oriented placement strategies have been proposed with distinct goals, such as to improve the error rate. However, we found that there are still improvements that can be made for this type of approach, to improve not only the error rates but also the performance of the placer itself. Thus, this paper proposes several improvements toward an efficient multiple faults-aware placement strategy. First, an analytical method to profile pair of gates is proposed. Second, we add another level of optimization to reduce the amount of wirelength observed after the placement is completed without jeopardizing the main objective (reliability). Third, we propose a way to manipulate white spaces between gates smartly, to separate the gates that are profiled as the most likely to reduce the error rate when\u00a0\u2026", "num_citations": "7\n", "authors": ["497"]}
{"title": "Fault detection and repair of dsc arrays through memristor sensing\n", "abstract": " Fault tolerant Photovoltaic array used for green energy systems is emerging as an important area of study because of growing emphasis on reliable design. Among various photovoltaic cells Dye Solar Cell (DSC) is a promising low-cost photovoltaic (PV) technology and high energy-conversion efficiency. Recently it has been shown that it has memristive behavior as well. To efficiently support this claim, in this paper we use experimental data to characterize DSC cell and show that it exhibits memristor state behavior and developed a SPICE model. We use memristive DSC cells as sensing devices. This enables us to identify faulty cells in regular DSC. First, we present the model from the experimental data. A search algorithm is defined to identify the faulty components of the DSC array that fulfill the first requirement of a fault tolerant design. The proposed diagnosis method utilizes recently proposed fault detection\u00a0\u2026", "num_citations": "7\n", "authors": ["497"]}
{"title": "Operator splitting technique with FORCE scheme employed to simulate pressure wave motion inside gun chamber\n", "abstract": " The work is focused to study the mathematical modeling and numerical simulation of solid propellant combustion during internal ballistics cycle. Here, we have used a reduced single phase model from Baer\u2013Nunziato two-phase flow model for gas and solid mixture of propellant. The model consists of balance equations of mass, momentum and energy with constitutive laws. First ORder CEntred (FORCE) scheme is employed to provide an insight of motion of pressure wave in gun chamber during burning of igniter and solid propellant. The study is performed with the constant emission rate of igniter gases. The burning rate of propellant is expressed as a non-linear function of pressure in terms of pressure exponent. Depending on the pressure exponent three cases are evolved: constant, linear and non-linear rate of burning of propellant. FORCE scheme captures the motion of pressure wave with time and space. The\u00a0\u2026", "num_citations": "7\n", "authors": ["497"]}
{"title": "Matching in memristor based auto-associative memory with application to pattern recognition\n", "abstract": " The study of memristor based associative memory design has become increasingly important with the advent of new hybrid CMOS Molecular (CMOL) technologies. To date, only a very few papers have been published on this topic. Specifically, little is know regarding partial or full match is possible in CMOL technologies which use CMOS and memristors. To this end, a new approach to implement partial of full matching in associative memory is introduced. The method is based on complementary transformations at the input. This method is augmented with transformations that specifically enhance partial or full matching of the input data while improving the performance. Experimental results show that the proposed methodology can achieve better performance than similar designs in the literature.", "num_citations": "7\n", "authors": ["497"]}
{"title": "Using memristor state change behavior to identify faults in photovoltaic arrays\n", "abstract": " Memristor is an emerging non-volatile memory device that features smaller size and hybrid memristor/CMOS integration, which maximizes the advantages of high density and versatility. In this paper we utilize the memristor as weights and its state change behavior to capture some of the potential faults in a system. Photovoltaic arrays are taken as an example for the study. We will demonstrate that the state variations can be mapped into a timing which can be used as useful information for behavior of the system under measurement. Empirical studies are carried out using Spice based simulations to investigate into the impact of biasing and threshold voltages on timing behavior. Underpinning these studies, a relationship between input voltage and memristor state transition is proposed and extensively validated through further simulations to identify specific faulty behavior.", "num_citations": "7\n", "authors": ["497"]}
{"title": "Complementary resistive switch based stateful logic operations using material implication\n", "abstract": " Memristor based logic and memories are increasingly becoming one of the fundamental building blocks for future system design. Hence, it is important to explore various methodologies for implementing these blocks. In this paper, we present a novel Complementary Resistive Switching (CRS) based stateful logic operations using material implication. The proposed solution benefits from exponential reduction in sneak path current in crossbar implemented logic. We validated the effectiveness of our solution through SPICE simulations on a number of logic circuits. It has been shown that only 4 steps are required for implementing N input NAND gate whereas memristor based stateful logic needs N+1 steps.", "num_citations": "7\n", "authors": ["497"]}
{"title": "A low power and robust carbon nanotube 6T SRAM design with metallic tolerance\n", "abstract": " Carbon nanotube field-effect transistor (CNTFET) is envisioned as a promising device to overcome the limitations of traditional CMOS based MOSFETs due to its favourable physical properties. This paper presents a novel six-transistor (6T) static random access memory (SRAM) bitcell design using CNTFETs. Extensive validations and comparative analyses are carried out with the proposed SRAM design using SPICE based simulations. We show that the proposed CNTFET based SRAM has a significantly better static noise margin (SNM) and write ability margin (WAM) compared to a CNTFET-based standard 6T bitcell, equivalent to isolated read-port 8T cell based on CNTFET, while consuming less dynamic power. We further demonstrate that it exhibits higher robustness under process, voltage and temperature (PVT) variations when compared with the traditional CMOS SRAM cell designs. Furthermore, metallic\u00a0\u2026", "num_citations": "7\n", "authors": ["497"]}
{"title": "A Robin-type non-overlapping domain decomposition procedure for second order elliptic problems\n", "abstract": " This article deals with the analysis of an iterative non-overlapping domain decomposition (DD) method for elliptic problems, using Robin-type boundary condition on the inter-subdomain boundaries, which can be solved in parallel with local communications. The proposed iterative method allows us to relax the continuity condition for Lagrange multipliers on the inter-subdomain boundaries. In order to derive the corresponding discrete problem, we apply a non-conforming Galerkin method using lowest order Crouzeix\u2013Raviart elements. The convergence of the iterative scheme is obtained by proving that the spectral radius of the matrix associated with the fixed point iterations is less than 1. Parallel computations have been carried out and the numerical experiments confirm the theoretical results established in this paper.", "num_citations": "7\n", "authors": ["497"]}
{"title": "On the synthesis of attack tolerant cryptographic hardware\n", "abstract": " Concurrent error detection and correction is an effective way to mitigate fault attacks in cryptographic hardware. Recent work on differential power analysis shows that even mathematically-secure cryptographic protocols may be vulnerable at the physical implementation level. By measuring energy consumed by a working digital circuit, it is possible to gain valuable information about the encryption algorithms used and even the specific encryption keys. Thwarting such attacks requires a new approach to logic and physical designs. This paper presents a systematic approach to fault tolerant cryptographic hardware designs. Firstly, the effectiveness of the Hamming code based error correction schemes as a fault tolerance method in stream ciphers is investigated. Coding is applied to Linear Feedback Shift Registers (LFSR) based stream cipher implementations. The method was implemented on industrial standard\u00a0\u2026", "num_citations": "7\n", "authors": ["497"]}
{"title": "A fast error correction technique for matrix multiplication algorithms\n", "abstract": " Temporal redundancy techniques will no longer be able to cope with radiation induced soft errors in technologies beyond the 45 nm node, because transients will last longer than the cycle time of circuits. The use of spatial redundancy techniques will also be precluded, due to their intrinsic high power and area overheads. The use of algorithm level techniques to detect and correct errors with low cost has been proposed in previous works, using a matrix multiplication algorithm as the case study. In this paper, a new approach to deal with this problem is proposed, in which the time required to recompute the erroneous element when an error is detected is minimized.", "num_citations": "7\n", "authors": ["497"]}
{"title": "A novel fault diagnosis technique in wireless sensor networks\n", "abstract": " In sensor networks, performance and reliability depend on the fault tolerance scheme used in the system. With increased network size traditional fault tolerant techniques have proven inadequate. Further, identifying and isolating the fault is one of the key steps towards reliable network design. Towards this, we propose two new algorithms to detect and substitute faulty nodes at different levels in the network. In the proposed approach, the network is divided into zones which are having a master for each zone. Moreover, the masters of the zones are connected in a De Bruijn graph based network. When a fault occurs, the masters are checked, tested. After that, the sensor nodes in the suspected zone are tested. Our fault model assumes communication, processing and sensing faults caused by hardware failures in a node. We analyzed the performance of the first algorithm according to the number of messages it needs to diagnose faulty nodes. In addition, the performance of a 4-node De Bruijn graph was also studied by measuring the end-to-end delay. Finally, the performance of the second algorithm was studied by measuring the fault detection accuracy.", "num_citations": "7\n", "authors": ["497"]}
{"title": "On the hardware reduction of z-datapath of vectoring CORDIC\n", "abstract": " In this article we present a novel design of a hardware optimal vectoring CORDIC processor. We present a mathematical theory to show that using bipolar binary notation it is possible to eliminate all the arithmetic computations required along the z-datapath. Using this technique it is possible to achieve three and 1.5 times reduction in the number of registers and adder respectively compared to classical CORDIC. Following this, a 16-bit vectoring CORDIC is designed for the application in Synchronizer for IEEE 802.11a standard. The total area and dynamic power consumption of the processor is 0.14 mm 2  and 700\u03bcW respectively when synthesized in 0.18\u03bcm CMOS library which shows its effectiveness as a low-area low-power processor.", "num_citations": "7\n", "authors": ["497"]}
{"title": "An efficient technique for synthesis and optimization of polynomials in GF(2m)\n", "abstract": " This paper presents an efficient technique for synthesis and optimization of polynomials over GF (2 m), where m is a non-zero positive integer. The technique is based on a graph-based decomposition and factorization of polynomials over GF (2 m), followed by efficient network factorization and optimization. A technique for efficiently computing coefficients over GF (p m), where p is a prime number, is first presented. The coefficients are stored as polynomial graphs over GF (p m). The synthesis and optimization is initiated from this graph based representation. The technique has been applied to minimize multipliers over all the 51 fields in GF (2 k), k= 2... 8 in 0.18 micron CMOS technology with the help of the Synopsys\u00ae design compiler. It has also been applied to minimize combinational exponentiation circuits, and other multivariate bit-as well as word-level polynomials. The experimental results suggest that the\u00a0\u2026", "num_citations": "7\n", "authors": ["497"]}
{"title": "MODD for CF: a representation for fast evaluation of multiple-output functions\n", "abstract": " Recently a mathematical framework was presented that bridges the gap between bit level BDD representation and word level representations such as BMD and TED. Here we present an approach that demonstrates that these diagrams admit fast evaluation of circuits for multiple outputs. The representation is based on characteristic function which provides faster evaluation time as well as compact representation. The average path length is used as a metric for evaluation time. The results obtained for benchmark circuits shows lesser number of nodes and faster evaluation time compared to binary representation.", "num_citations": "7\n", "authors": ["497"]}
{"title": "Recovery in multicomputers with finite error detection latency\n", "abstract": " In most research on checkpointing and recovery, it has been assumed that the processor halts immediately in response to any internal failure (fail-stop model). This paper presents a recovery scheme (independent checkpointing and message logging) for a multicomputer system consisting of processors having a non-zero error detection latency. Our scheme tolerates bounded error detection latencies, thus, achieving a higher fault coverage. The simulation results show that for typical detection latency values, the recovery overhead is almost independent of the detection latency.", "num_citations": "7\n", "authors": ["497"]}
{"title": "Signature analysis under a delay fault model\n", "abstract": " A framework for aliasing under a delay fault model is presented. First, error patterns under this fault model are characterized. Through this, specific error patterns that can occur are identified. Based on this, it is shown that using a model similar to the equiprobable model, the aliasing probability under certain conditions converges to 2/sup-m/for delay faults as well. A closed form expression for aliasing under an independent error model is also derived. This expression is shown to yield better theoretical estimates of the aliasing probability.<>", "num_citations": "7\n", "authors": ["497"]}
{"title": "A single cached copy data coherence scheme for multiprocessor systems\n", "abstract": " We present and evaluate a snoopy cache memory protocol, the Single Cache Copy Data Coherence (SCCDC), for multiprocessors that allows only a single cache to hold a given share-d data at any time. The simulations presented here indicate that despite its simplicity, the scheme has the potential for good performance comparable with more complex snoopy cache schemes. We have also shown in related work [8] that the existence of only a single copy of data in cache allows efficient access control to shared data by minimizing the overh-ead caused by critical sections. Thus, with low implementation cost, and the efficient support for important operating system functions, the SCCDC scheme appears attractive for multi-user, multi-thread environments where the actual shared rate is modest, and mostly caused by synchronization mechanisms.", "num_citations": "7\n", "authors": ["497"]}
{"title": "2T2M memristor based TCAM cell for low power applications\n", "abstract": " This paper presents a 2-transistors-memristors (2T2M) bitcell for content-addressable memory design suitable for low-power applications. It uses memristors to store data and MOS transistors as access devices. The low power proposed design splits the search lines to search logic 1 and logic 0 separately to reduce the search power consumption. Different word sizes of the proposed bitcells with and without low power structure are simulated, including full parasitics using BPTM, 45nm CMOS technology node to evaluate and compare different performance parameters. The proposed low power design reduces the active power dissipation of about 30% compared to the design with conventional search approach.", "num_citations": "6\n", "authors": ["497"]}
{"title": "High Payload Adaptive Audio Watermarking based on Cepstral Feature Modification.\n", "abstract": " In this paper, we propose two blind adaptive audio watermarking schemes based on complex cepstrum transform (CCT) domain features. In first scheme (Scheme-I), each audio segment is divided into two subsets having approximately same statistical mean value using down-sampling method. Since the human auditory system (HAS) is not much sensitive to the minute change of the wavelet high-frequency components, first level discrete wavelet transform (DWT) detail coefficients subbands of both subsets are used for embedding. Watermark is embedded by changing slightly the difference between the mean values (Mdiff) of insignificant CCT coefficients of these subsets in order to guarantee minimal perceptual distortion. The offset value by which mean is modified is made adaptive to the local energies of the audio frames in order to increase the audio quality further. In order to enhance the payload capacity, we propose an alternate audio watermarking scheme (Scheme-II) where watermark is embedded by deciding the transition of Mdiff value from one frame to another frame in two successive frames. In contrast to previous works, instead of embedding one bit per frame, Scheme-II can embed three bits per two frames. Thus 33.33% increase in embedding capacity is achieved. As amplitude scaling in time domain does not affect selected insignificant CCT coefficients, strong invariance towards amplitude scaling attacks is also proved theoretically. Experimental results reveal that the proposed watermarking schemes maintain high audio quality and are simultaneously robust to general attacks like MP3 compression, amplitude scaling, filtering, re\u00a0\u2026", "num_citations": "6\n", "authors": ["497"]}
{"title": "Statistical blockade method for fast robustness estimation and compensation of nano-cmos arithmetic circuits\n", "abstract": " The challenges for nano-CMOS based design engineers have been aggravated due to the introduction of variability into the design phase. One of the ways to understand the circuit behaviors under process variation is to analyze the rare events that may be originated due to such process variation. A method named Statistical Blockade (SB) has been proposed to estimate the rare events statistics especially for high-replication circuits. It has shown much faster speed than traditional exhaustive Monte Carlo simulation. The full Monte Carlo simulation may estimate the tolerant ability for the designs of different CMOS logic styles by estimating the statistics (e.g. mean, variance, and standard deviation) of the circuit specification. However, it is immensely computationally expensive, can be infeasible for large circuits, and may consume significant man hours in the ever shortening time-to-market. Therefore, the fast\u00a0\u2026", "num_citations": "6\n", "authors": ["497"]}
{"title": "Pharmacological interventions of some potential herbal extracts targeted at adenosine receptors in diabetic neuropathic pain.\n", "abstract": " see more details is generally considered to be one of the most troublesome complications affecting diabetic patients and current therapy provides inadequate pain relief. In the present study, the effect of aqueous extract of Butea monosperma butea monosperma Subject Category: Organism Names", "num_citations": "6\n", "authors": ["497"]}
{"title": "Design techniques for bit-parallel galois field multipliers with on-line single error correction and double error detection\n", "abstract": " Error correction is an effective way to mitigate fault attacks in cryptographic hardware. It is also an effective solution to soft errors in deep sub-micron technologies. To this end, we present a systematic method for designing single error correcting (SEC) and double error detecting (DED) finite field (Galoisfield) multipliers over GF(2 m ). The detection and correction are done on-line. We use multiple Parity Predictions (PPs) to correct single errors based on the Hamming principles. Specifically, a structural approach is first presented. The predicted parities are derived from the input operands. Further, a hybrid approach is presented where the multipliers and PP circuits are synthesized, and the decoding and correction circuits are structurally combined to form the complete error correcting designs. Our technique, when compared with existing techniques, gives better performance. We show that our SEC multipliers over GF\u00a0\u2026", "num_citations": "6\n", "authors": ["497"]}
{"title": "A triple-mode feed-forward sigma-delta modulator design for GSM/WCDMA/WLAN applications\n", "abstract": " This paper presents a cascaded 2-2-2 reconfigurable sigma-delta modulator that can handle GSM, WCDMA and WLAN standards. The modulator makes use of a low-distortion swing suppression topology which is highly suitable for wide band applications. In GSM mode, only the first stage (2 nd  order \u2211-\u0394 ADC) is turned on to achieve 88dB dynamic range with over-sampling ratio of 160 for a bandwidth of 200KHz; in WCDMA mode a 2-2 cascaded structure (4 th  order) is turned on with 1-bit in the first stage and 2-bit in the second stage to achieve 74 dB dynamic range with over-sampling ratio of 16 for a bandwidth of 2MHz and a 2-2-2 cascaded MASH architecture with a 4-bit in the last stage to achieve a dynamic range of 58dB for a bandwidth of 20MHz. The novelty lies in the fact that unused blocks of second and third stages can be switched off taking into considerations like power consumption. The modulator is\u00a0\u2026", "num_citations": "6\n", "authors": ["497"]}
{"title": "A soft error robust and power aware memory design\n", "abstract": " A new RAM design, which is soft error robust and power aware, is proposed. The basic advantage of the proposed architecture is that it does achieve a considerable power saving potential, combined with potential for performance and reliability enhancements, while imposing an acceptable area overhead. Analytical models of the proposed architecture are presented and discussed.", "num_citations": "6\n", "authors": ["497"]}
{"title": "Transition Fault Testability in Bit Parallel Multipliers over GF (2^{m})\n", "abstract": " This paper presents a C-testable technique for detecting transition faults with 100% fault coverage in the polynomial basis (PB) bit parallel (BP) multiplier circuits over GF(2 m ). The proposed technique requires only 10 vectors, which is independent of multiplier size, at the cost of 6% (avg.) extra hardware and three control pins. The proposed constant test vectors which are sufficient to detect both the transition and stuck-at faults in the multiplier circuits can be derived directly without any requirement of an ATPG tool. As the GF(2 m ) multipliers have found critical applications in public key cryptography and need secure internal testing, a built-in self-test (BIST) circuit is proposed for generating test patterns internally. This obviates the need of having three extra pins for the control inputs and also provides public-key security in cryptography. Area and delay of the testable circuit are analyzed using 0.18mum CMOS\u00a0\u2026", "num_citations": "6\n", "authors": ["497"]}
{"title": "Fault\u2010Tolerant Computing\n", "abstract": " This chapter provides an overview of fault\u2010tolerant computing. Fault\u2010tolerant computing can be defined as the process by which a computing system continues to perform its specified tasks correctly in the presence of faults with the goal of improving the dependability of the system. Principles of fault\u2010tolerant computing as well as various fault\u2010tolerant architectures are discussed. The article concludes by observing trends in the fault\u2010tolerant computing.", "num_citations": "6\n", "authors": ["497"]}
{"title": "A low power 128-Pt implementation of FFT/IFFT for high performance wireless personal area networks\n", "abstract": " An architecture for low power 128-pt FFT/IFFT processor for application in IEEE 802.15.3a standard design is proposed, where the 128-pt FFT is devolved into 8-pt and 16-pt FFTs and then once again by devolving the 16-pt FFT into 4times4 and 2times8. The analysis demonstrated that with modest increase in area one can achieve significant reduction in power. The proposed architectures complete one parallel-to-parallel (i.e., when all input data are available in parallel and all output data are generated in parallel) 128-pt FFT computation in 312ns. The relative merits and demerits of these architectures have been analyzed from the algorithm as well as implementation point of view. Detailed power analysis of architecture at block level is described. From power perspective the second architecture is better; however both the architectures give significant reduction of algorithmic complexity compared to the existing\u00a0\u2026", "num_citations": "6\n", "authors": ["497"]}
{"title": "Initialization issues in the synthesis of asynchronous circuits\n", "abstract": " We present a procedure for synthesizing initializable asynchronous circuits from functionally uninitializable Signal Transition Graphs (STG). After characterizing the necessary conditions for functional uninitializability, we propose a technique that transforms the original STG into an equivalent, functionally initializable STG. It is shown that initializability can be achieved by sacrificing minimal concurrency without violating the syntactic properties of the STG required for a hazard-free implementation. The synthesis of a trigger module illustrates this procedure.< >", "num_citations": "6\n", "authors": ["497"]}
{"title": "Design for testability of asynchronous sequential circuits\n", "abstract": " Asynchronous sequential circuits are becoming increasingly important with their potential for higher speed and as clock skew problems in synchronous circuits continue to persist. Modifications to asynchronous machines that will allow ease of testability are presented in this paper. The framework of checking experiments is used for evaluating the proposed design. Checking experiments, though complex, can provide a methodology for complete functional testing as well as design verification. The design techniques proposed here can be adapted for testing under the traditional stuck-at fault model as well.< >", "num_citations": "6\n", "authors": ["497"]}
{"title": "High level synthesis of data driven ASICs\n", "abstract": " A novel approach to high level synthesis of AsIcs based on a data driven execution model is presented. The synthesis procedure is directed at prodncing highly parallel Aslcs providing high throughput through pipe-lining. The major benefits of our approach are its poten-tial for higher speed, ease of design, ease of verification and testing.", "num_citations": "6\n", "authors": ["497"]}
{"title": "RTRAM: reconfigurable and testable multi-bit RAM design\n", "abstract": " An easily testable multibit RAM (random-access memory) design is proposed which provides dynamic reconfigurability for variable wordsize and multiword access. This design is a modification of a single-bit testable RAM design proposed earlier (1987). The basic idea in present design is to divide the RAM into modules and interconnect these modules using a binary tree structure. The design is then augmented by a built-in test structure which reduces the problem of testing the RAM to that of testing a single module. The proposed architecture has the potential to achieve faster access than the traditional architecture with a modest increase in area.< >", "num_citations": "6\n", "authors": ["497"]}
{"title": "A robust zero watermarking algorithm for stereo audio signals\n", "abstract": " Zero-watermarking techniques constructs zero watermarks without modifying the original host audio signal. This paper presents a robust zero-watermarking algorithm for stereo audio signals. The proposed algorithm exploits inter-channel redundancy of stereo audio signal in order to construct zero watermarks binary sequence. Here, the features are extracted from DWTDCT-SVD domain to construct zero watermarks; and are found to be robust against modified discrete cosine transform (MDCT)-based perceptual stereo audio coding schemes. Extensive experimental results assure that the proposed watermarking scheme is highly secure as well as robust to common attacks like, MP3 compression, cropping, filtering, re-sampling, amplitude scaling and re-quantisation, etc. To the best of our knowledge, zero-watermarking algorithm based on stereo audio properties is proposed first time.", "num_citations": "5\n", "authors": ["497"]}
{"title": "Lifetime reliability analysis of complementary resistive switches under threshold and doping interface speed variations\n", "abstract": " Complementary resistive switching (CRS) memristor is an emerging nonvolatile memory device that features low-sneak path current compared to traditional memristors. Despite its advantages, threshold voltage and doping interface drift speed variations over time are major concerns for CRS memory devices. In this paper, we will demonstrate that these variations can significantly reduce the CRS lifetime reliability in terms of number of memory operations that can be performed. Based on such demonstrations, comprehensive theoretical and empirical studies are carried out using H-Spice based simulations to investigate the impact of biasing and threshold voltages on CRS lifetime reliability. Underpinning these studies, a novel CRS lifetime relationship is proposed and extensively validated through further simulations.", "num_citations": "5\n", "authors": ["497"]}
{"title": "Software modification aided transient error tolerance for embedded systems\n", "abstract": " Commercial off-the-shelf (COTS) components are increasingly being employed in embedded systems due to their high performance at low cost. With emerging reliability requirements, design of these components using traditional hardware redundancy incur large overheads, time-demanding re-design and validation. To reduce the design time with shorter time-to-market requirements, software-only reliable design techniques can provide with an effective and low-cost alternative. This paper presents a novel, architecture-independent software modification tool, SMART (Software Modification Aided transient eRror Tolerance) for effective error detection and tolerance. To detect transient errors in processor data path, control flow and memory at reasonable system overheads, the tool incorporates selective and non-intrusive data duplication and dynamic signature comparison. Also, to mitigate the impact of the detected\u00a0\u2026", "num_citations": "5\n", "authors": ["497"]}
{"title": "A fast and effective DFT for test and diagnosis of power switches in SoCs\n", "abstract": " Power switches are increasingly becoming dominant leakage power reduction technique for sub-100nm CMOS technologies. Hence, fast and effective DFT solution for test and diagnosis of power switches is much needed to facilitate faster identification of potential faults and their locations. In this paper, we present a novel, coarse-grain DFT solution enabling divide and conquer based test and diagnosis solution of power switches. The proposed solution benefits from exponential time savings compared to previously reported solutions. Our DFT solution requires only (2\u2308log 2 m\u2308 + 3) clock cycles in the worst case for test and diagnosis for m-segment power switches. These time savings are further substantiated by effective discharge circuit design, which eliminates the possibility of false test and hence significantly reducing the charge and discharge times. We validated the effectiveness of our proposed solution\u00a0\u2026", "num_citations": "5\n", "authors": ["497"]}
{"title": "Robust multiple stereo audio watermarking for copyright protection and integrity checking\n", "abstract": " This paper presents a robust, stereo audio signal watermarking algorithm. The inter-channel redundancy of stereo audio signal is exploited by calculating average and difference signals from the LR channels of stereo audio. Discrete Wavelet Transform (DWT) followed by Discrete Cosine Transform (DCT) are applied to both average and difference signals. Few selected transform domain coefficients of average signal are used for embedding a robust watermark along with synchronization codes. A semi-fragile watermark is embedded for integrity check in a few of the transform domain coefficients of difference signal. Quantization technique is used for embedding. As both average and difference signals are used for embedding, the watermark will spread evenly in both LR channels without interfering each other. As more signal energy is concentrated in average signal compared to difference signal, larger\u00a0\u2026", "num_citations": "5\n", "authors": ["497"]}
{"title": "Introduction to SRAM\n", "abstract": " The trend of Static Random Access Memory (SRAM) along with CMOS technology scaling in different processors and system-on-chip (SoC) products has fuelled the need of innovation in the area of SRAM design. SRAM bitcells are made of minimum geometry devices for high density and to keep the pace with CMOS technology scaling, as a result, they are the first to suffer from technology scaling induced side-effects. At the same time, success of next generation technology depends on the successful realization of SRAM. Therefore, different SRAM bitcell topologies and array architectures have been proposed in the recent past to meet the nano-regime challenges. Some of the major challenges in SRAM design includes poor stability, process variation tolerance, device degradation due to ageing and soft errors. In this chapter, introduction and importance of SRAM in memory hierarchy of a modern computer\u00a0\u2026", "num_citations": "5\n", "authors": ["497"]}
{"title": "Pseudo-parallel datapath structure for power optimal implementation of 128-pt fft/ifft for wpan\n", "abstract": " An optimal implementation of 128-Pt FFT/IFFT for low power IEEE 802.15.3a WPAN using pseudo-parallel datapath structure is presented, where the 128-Pt FFT is devolved into 8-Pt and 16-Pt FFTs and then once again by devolving the 16-Pt FFT into 4\u00d74 and 2\u00d78. We analyze 128-Pt FFT/IFFT architecture for various pseudo-parallel 8-Pt and 16-Pt FFTs and an optimum datapath architecture is explored. It is suggested that there exists an optimum degree of parallelism for the given algorithm. The analysis demonstrated that with a modest increase in area one can achieve significant reduction in power. The proposed architectures complete one parallel-to-parallel (i.e., when all input data are available in parallel and all output data are generated in parallel) 128-point FFT computation in less than 312.5\u00a0ns and thereby meet the standard specification. The relative merits and demerits of these architectures have\u00a0\u2026", "num_citations": "5\n", "authors": ["497"]}
{"title": "Secure testable s-box architecture for cryptographic hardware implementation\n", "abstract": " It has been recently shown that observability of design for testability techniques compromises cryptographic hardware implementation security in a straightforward manner. During test, the chip can be configured so that it is possible to observe temporal data resulting from the encryption process of a plaintext that eventually exposes the secret key. To this end, we propose a C-testable S-box implementation which is one of the most complex blocks in advanced encryption standard hardware implementation. We divide the S-box structure into a positive polarity Reed\u2013Muller form and tested independently using a BIST circuit. The proposed structure does not use any scan chain for testability, hence avoiding the vulnerability of the chip during testing. Only 14 constant vectors are sufficient to achieve 100% fault coverage in the S-box. The C-testable feature comes with an extra hardware overhead of 15 per cent. By\u00a0\u2026", "num_citations": "5\n", "authors": ["497"]}
{"title": "Layout-aware Illinois Scan design for high fault coverage coverage\n", "abstract": " The Illinois Scan Architecture (ILS) consists of several scan path segments and is useful in reducing test application time and test data volume required to test today's high density VLSI circuits. However, to achieve high fault coverage with ILS architecture one requires judicious grouping and ordering of scan flip-flops for selecting these segments. This may also increase the wiring complexity and cost of the scan chain, as the physical locations of the flip-flops on silicon are determined at an early design stage before scan insertion. In this paper, we propose a scheme of layout-aware as well as coverage-driven ILS design. The partitioning of the flip-flops into ILS segments is determined by their geometric locations, whereas the set of the flip-flops to be placed in parallel is determined by the minimum incompatibility relations among the corresponding bits of a test set, to enhance fault coverage in broadcast mode. This\u00a0\u2026", "num_citations": "5\n", "authors": ["497"]}
{"title": "Pseudo parallel architecture for AES with error correction\n", "abstract": " Cryptographic hardware design is facing many challenges because of conflicting requirements such as fault attack tolerance and low power consumption. Therefore, it is important to explore different architectures that meet the above challenges. Towards this, in this paper we present different advanced encryption standard (AES) implementation with varying complexity. Specifically, we analyzed the architectural complexity with different data paths. Moreover, we incorporated error correction in sequential elements to mitigate the fault attacks and analyzed the area complexity.", "num_citations": "5\n", "authors": ["497"]}
{"title": "Logic transformation and coding theory-based frameworks for Boolean satisfiability\n", "abstract": " This paper proposes a new framework to the solution of Boolean Satisfiability. The first approach is based on certain structural analysis using circuit representation. Here, we convert the given CNF into multilevel circuits based on testability-driven transformation and optimization, and then apply a test technique developed by the authors to verify SAT. This test technique is based on the concepts developed by an earlier-proposed verification tool, VERILAT. Certain algebraic coding theory results are then derived that provide a lower bound on the number of solutions to SAT problems. These proposed frameworks have a real potential for providing new theoretical insights.", "num_citations": "5\n", "authors": ["497"]}
{"title": "Electronic distress call and position finding system for rescuing distressed people\n", "abstract": " Electronic distress call and position finding system for rescuing distressed people has a receiver with a screen and a distress call transmitter. For evaluating the distress call, it requires the positions of both the receiver and transmitter components. The positions (A) of the receiver (1) and (B) of the distress call transmitter (2) are established by their GPS modules from the data of specialized satellites (4), which orbit the earth on stationary orbits. The distress call transmitter radios its position (B) to the receiver. From the two positions, the distance and direction of the distress call transmitter are calculated. If the system is used for diving, the switched-on receiver remains on the ship, and the distress call transmitter is secured to the diver so that it cannot get lost. When a diver is drifting away, the distress call transmitter is switched on, the system begins to work, and his distance and direction with respect to the ship are\u00a0\u2026", "num_citations": "5\n", "authors": ["497"]}
{"title": "A novel scheme to reduce test application time in circuits with full scan\n", "abstract": " This paper proposes a hybrid method of combining sequential testing with scan testing in circuits with full scan capability. One shortcoming of full scan testing of sequential circuits is the high test application time. The goal of our scheme is to obtain shorter test application times while achieving detection of both the classical stuck-at faults as well as nonclassical faults such as delay faults. An algorithm for test generation in this hybrid scheme is described. Experimental results demonstrating the effectiveness of our approach on ISCAS '89 sequential benchmark circuits are presented. Results for the stuck-at fault model and the transition fault model (which represents a simplified model for delay faults) are presented. Significant reduction in test application time is shown possible.", "num_citations": "5\n", "authors": ["497"]}
{"title": "Degradable byzantine agreement\n", "abstract": " Traditional Byzantine agreement protocols require all fault-free receivers to agree on an identical value. The proposed degradable agreement approach achieves traditional agreement up to m faults and a degraded form of agreement up to u faults (u/spl ges/m), which allows fault-free receivers to agree on at most two different values (one of which is necessarily the default value). A degradable agreement algorithm and lower bounds are presented.< >", "num_citations": "5\n", "authors": ["497"]}
{"title": "Implication-Based Gate-level Synthesis for Low-Power\n", "abstract": " The paper presents a new logic optimization method of multi-level combinational CMOS circuits, which minimizes area and power. Present methods to reduce power on logic circuits apply functional methods like logic factorization on the Boolean networks. The method described here uses Boolean transformations that exploit implications at the gate-level based on both controllability and observability relationships. These transformations are novel and have not been explored for low power synthesis. It is observed", "num_citations": "5\n", "authors": ["497"]}
{"title": "Bit-serial generalized median filters\n", "abstract": " Generalized median filtering techniques that have appeared in literature suffer from some severe disadvantages. They are not only hardware intensive and time consuming but also tend to smear image edges. These shortcomings can be overcome by having bit-serial filtering techniques. The median selection of the sample values in the window is done for a few most significant bit stages. The sample values not in consensus with the majority are edited based on some criterion and averaged out with the rest of the data to yield the filter output. Depending on the criterion for editing the data, two filtering techniques-the B filter and the Tag-based Trimmed Mean (TTM) filter have been presented. The median-running mean filters are integrated in an area efficient manner to provide the basic building block for a signal processing chipset.< >", "num_citations": "5\n", "authors": ["497"]}
{"title": "Signal transition graph transformations for initializability\n", "abstract": " We present a method of transforming a functionally uninitializable signal transition graph (STG) into a functionally initializable STG. The design of a trigger module is described to illustrate the transformations.< >", "num_citations": "5\n", "authors": ["497"]}
{"title": "Buffer assignment for data driven architectures\n", "abstract": " Data driven architectures have the potential to exhibit higher performance and throughput when compared to their control driven counterparts. In order to ensure that these performance gains are realized, it is required that the underlying data flow graph (DFG) have no accumulation of data at its nodes. Hence, all operands should arrive simultaneously at a multi-input operation node. Buffers are therefore inserted to ensure these conditions. An algorithm for buffer distribution in a balanced DFG of order (V /spl times/ E) is proposed. The number of buffers in the proposed buffer distribution strategy is equal to the minimum number of buffers achieved by integer programming techniques. An extension of this algorithm, of order (V/sup 2/ /spl times/ log V) is proposed which can further reduce the number of buffers by altering the DFG while keeping the functionality and performance of the DFG intact. Performance results\u00a0\u2026", "num_citations": "5\n", "authors": ["497"]}
{"title": "A virtual memory translation mechanism to support checkpoint and rollback recovery\n", "abstract": " Checkpoint and Tollback Tecovery is a technique that allows a system to io~ eTate a faihwe by pe?\u2019iodically saving the eniipe siaie and if an emoT OCCUTS, Toliing back to the prioT checkpoint. This technique zs paTticulady suited to applications with long execution times such as those typically found m supercomputer environments. This paper presents a technique that embeds the support for checkpoint and Tollback recovery dmect~ y into the virtual memory translation hardware. The scheme is general enough to be implemented on various scopes oj data such as a portion of an address spacej a single address space OT multiple address spaces. A basic model is developed which measures the amount of work required by the scheme as a function of the checkpoint internal szze. Using this model the degree to which the overhead decTeases as the interval size increases is shown.", "num_citations": "5\n", "authors": ["497"]}
{"title": "Yield modeling and optimization of large redundant RAMs\n", "abstract": " Presents and analyzes redundant large area TRAM architectures (64 to 512 Mbit) for variations in redundancy level and determine the optimal redundancy organization for yield enhancement. A hierarchical redundancy scheme is used for defect tolerance and the yield of the redundant RAM is modelled using a compounded Poisson model. Results are presented that show the tradeoff in local versus global redundancy schemes for TRAM.< >", "num_citations": "5\n", "authors": ["497"]}
{"title": "Tissue isolator\n", "abstract": " A biocompatible tissue isolator is used to isolate and extract tissue during a surgical procedure. A method of using the tissue isolator for isolating and extracting morcellated tissue during the surgery.", "num_citations": "4\n", "authors": ["497"]}
{"title": "Exploring error-tolerant low-power multiple-output read scheme for memristor-based memory arrays\n", "abstract": " In an effort to reduce the overall read/write power consumption in emerging memory technologies, efficient read/write schemes have recently attracted increased attention. Among these emerging technologies is the memristor-based resistive random access memory (ReRAM) with simpler structures and capability of producing highly dense memory through the sneak-path prone crossbar architecture. In this paper, a multiple-cells read solution to reduce the overall energy consumption when reading from a memory array is considered. A closed form expression for the noise margin effect is derived and analysis shows that there is zero sneak-path when sensing certain patterns of stored data. The multiple-cells readout method was thus used to analyse an energy efficient Inverted-Hamming (I-H) architecture capable of detecting and correcting single-bit write error in memristor-based memory array.", "num_citations": "4\n", "authors": ["497"]}
{"title": "State transition based embedding in cepstrum domain for audio copyright protection\n", "abstract": " In this paper, we propose a new state transition based embedding (STBE) technique for audio watermarking with high fidelity. Furthermore, we propose a new correlation based encoding (CBE) scheme for binary logo image in order to enhance the payload capacity. The result of CBE is also compared with standard run-length encoding (RLE) compression and Huffman schemes. Most of the watermarking algorithms are based on modulating selected transform domain feature of an audio segment in order to embed given watermark bit. In the proposed STBE method instead of modulating feature of each and every segment to embed data, our aim is to retain the default value of this feature for most of the segments. Thus, a high quality of watermarked audio is maintained. Here, the difference between the mean values (Mdiff) of insignificant complex cepstrum transform (CCT) coefficients of down-sampled subsets is\u00a0\u2026", "num_citations": "4\n", "authors": ["497"]}
{"title": "Multinomial based memristor modelling methodology for simulations and analysis\n", "abstract": " In this article, we propose a novel memristor modelling methodology with multinomial window function obtained by extensive statistical fitting of the measured data of a practical memristor device. Due to such modelling, the desired electrical characteristics that a fabricated memristor device typically exhibits is accurately described. Moreover, the model features the non-linear state transition behaviour. To demonstrate the effectiveness of the proposed modelling methodology, a Verilog-A-based memristor model has been implemented, leading to further development of a memristor-based complementary resistive switch (CRS). We show that the proposed memristor modelling methodology facilitates accurate device-level characteristics and also advances effective circuits and system simulations using memristors.", "num_citations": "4\n", "authors": ["497"]}
{"title": "Multinomial memristor model for simulations and analysis\n", "abstract": " In this paper, we propose a novel memristor model with multinomial window function. The model describes the range of behaviours that a fabricated device can exhibit especially with respect to state transition behaviour with desired non-linear memristor characteristics. This multinomial window function can be obtained by fitting the measured data of a practical memristor device. Because the window function fits the measured data directly, the multinomial memristor model characterizes a real memristor.", "num_citations": "4\n", "authors": ["497"]}
{"title": "Design metrics of SRAM bitcell\n", "abstract": " This chapter presents the basics of standard 6T SRAM bitcell and simulation setups for measurement of bitcell read and write stability metrics. Different static and dynamic stability metrics are investigated. Static stability metrics includes conventional butterfly curves obtained from the voltage transfer characteristics, the N-curve based metrics and their simulation setup for read and write stability are also discussed. The static stability metrics for large scale dense cache SRAM measured from bitline, wordline and bitcell supply voltage are also presented in this chapter. Apart from static stability metrics commonly used in SRAM design and development, dynamic stability metrics are also presented along with their simulations setups. Detailed simulation results and illustrations for static and dynamic stability metrics are the main focus of this chapter.", "num_citations": "4\n", "authors": ["497"]}
{"title": "A dynamically error correctable bit parallel Montgomery multiplier over binary extension fields\n", "abstract": " Galois field arithmetic circuits find wide variety of application in cryptography. Thus they faces majority of the hardware based attacks for malicious gain. Though there are many approaches that have been proposed to mitigate such malicious attacks, most of them are inappropriate for practical applicability due to various design drawbacks. It is noted that Galois field multipliers are one among the many core arithmetic modules that are inevitable in the cryptography processors. Among them Montgomery multipliers are studied and implemented in applications like Elliptical Curve Cryptography arithmetic. However, a multiple bit error correctable Montgomery multiplier has not yet been implemented to this end. In this paper, we propose a novel multiple bit error correctable bit-parallel Montgomery multipliers with dynamic error detection and correction. First we present the BCH code based multiple bit error correctable\u00a0\u2026", "num_citations": "4\n", "authors": ["497"]}
{"title": "A DOE-ILP assisted conjugate-gradient based power and stability optimization in High-K Nano-CMOS SRAM\n", "abstract": " In this paper, a novel design flow is presented for power minimization of nano-CMOS SRAM (static random access memory) circuits, while maintaining their performance. A 32nm high-K/metalgate SRAM is used as an example circuit. The baseline SRAM circuit is subjected to power minimization using a dual-VTh assignment based on a novel Design of Experiments-Integer Linear Programming (DOE-ILP) approach. However, this leads to a 15% reduction in the Static Noise Margin (SNM) of the SRAM, which is an indicator of the stability degradation of the SRAM. This reduction in the SNM is then overcome using a conjugate gradient optimization, while maintaining the minimum power consumption. The final SRAM design shows 86% reduction in power (including leakage) consumption and 8% increase in the SNM compared to the baseline design. The variability analysis of the optimized cell is carried out\u00a0\u2026", "num_citations": "4\n", "authors": ["497"]}
{"title": "Increasing memory yield in future technologies through innovative design\n", "abstract": " Future technologies, with ever shrinking devices and higher densities, bring along higher defect rates and lower yield. Memory chips, which are among the densest circuits used in digital systems, are greatly impacted by the increasing defect rates, which make yield fall and production costs rise sharply. In this paper, a new approach for designing memory chips to be manufactured using future technologies is proposed, aiming to increase the overall yield. The proposed approach trades a small area overhead for dramatic production cost reduction, by allowing to use more defective memory chips as lower capacity ones, instead of discarding them.", "num_citations": "4\n", "authors": ["497"]}
{"title": "Derivation of Reduced Test Vectors for Bit-Parallel Multipliers over GF (2^ m)\n", "abstract": " This paper presents an algebraic testing method for detecting stuck-at faults in the polynomial-basis (PB) bit-parallel (BP) multiplier circuits over GF(2 m ). The proposed technique derives the test vectors from the expressions of the inner product (IP) variables without any requirement of the ATPG tool. This low- complexity testing method requires (2m + 1) test vectors for detecting single stuck-at faults in the AND part and multiple stuck-at faults in the EXOR part of the multiplier circuits. The test vectors are independent of the multiplier's structure, as proposed in (T. A. Gulliver et al., 1991), but are dependent on m. For the multiplier circuits, the test set is found to be smaller in size than the ATPG-generated test set. The test set provides 100 percent single stuck-at fault coverage.", "num_citations": "4\n", "authors": ["497"]}
{"title": "A galois field based logic synthesis approach with testability\n", "abstract": " In deep-submicron VLSI, efficient circuit testability is one of the most demanding requirements. Efficient testable logic synthesis is one way to tackle the problem. To this end, this paper introduces a new fast efficient graph-based decomposition technique for Boolean functions in finite fields, which utilizes the data structure of the multiple-output decision diagrams (MODD). In particular, the proposed technique is based on finite fields and can decompose any N valued arbitrary function F into N distinct sets conjunctively and N-l distinct sets disjunctively. The proposed technique is capable of generating testable circuits. The experimental results show that the proposed method is more economical in terms of literal count compared to existing approaches. Furthermore, we have shown that the basic block can be tested with eight test vectors.", "num_citations": "4\n", "authors": ["497"]}
{"title": "Improving Perceived Streaming-Video Quality in High Speed Downlink Packet Access\n", "abstract": " High Speed Downlink Packet Access (HSDPA) is an enhancement to UMTS networks that supports data rates of several Mbps, making it suitable for applications such as video streaming. Nevertheless, the shared downlink radio channel used in HSDPA is a challenging environment for such applications. In this paper, we focus on the issue of subjective video quality, and design a novel estimator of the user-perceived quality that operates in real time. We propose to integrate such estimator in User Equipments (UEs) so that it can provide regular feedback and help the UMTS resource management procedures. Then, we use it to study the impact of a recently proposed HSDPA scheduler directly on the perceived video quality. HSDPA scheduling is one of the salient points of HSDPA and is used to perform resource management (i.e., bandwidth allocation between terminals), taking into account the radio channel\u00a0\u2026", "num_citations": "4\n", "authors": ["497"]}
{"title": "Soft-error induced system-failure rate analysis in an SoC\n", "abstract": " This paper proposes an analytical method to assess the soft-error rate (SER) in the early stages of a System-on-Chip (SoC) platform-based design methodology. The proposed method gets an executable UML model of the SoC and the raw soft-error rate of different parts of the platform as its inputs. Soft-errors on the design are modelled by disturbances on the value of attributes in the classes of the UML model and disturbances on opcodes of software cores. This Architectural Vulnerability Factor (AVF) and the raw soft-error rate of the components in the platform are used to compute the SER of cores. Furthermore, the SER and the severity of error in each core in the SoC are used to compute the System-Failure Rate (SFR) of the SoC.", "num_citations": "4\n", "authors": ["497"]}
{"title": "Statistical analysis of steady state leakage currents in nano-CMOS devices\n", "abstract": " Motivated by the problem of process variation in nano-scale CMOS, in this paper, we propose a multivariate statistical technique that uses the well known approach of principal component analysis (PCA), a technique extensively used in statistical modeling, to analyse the process variations. We use this approach to extract significant statistical information from the simulated data. We also propose a statistical model to characterize nano-scale CMOS device characteristics such as dynamic current I dyn , gate leakage I gate , and subthreshold leakage I sub  considering the effects of random variations in the process and design parameters such as gate oxide thickness T ox , supply voltage V dd  and gate length L. These models can be used at higher level of circuit abstraction to study the design issues under process variation.", "num_citations": "4\n", "authors": ["497"]}
{"title": "Constant function independent test set for fault detection in bit parallel multipliers in GF (2^ m)\n", "abstract": " In this paper, a C-testable implementation of polynomial basis (PB) bit parallel (BP) multiplier over the Galois fields of form GF(2  m ) for detecting stuck-at faults in multiplier circuits has been proposed. The length of the constant test set is only 8. The fault detection can be incorporated in the multiplier circuit with only three extra inputs for controllability. The gate counts of the proposed testable multiplier as a function of degree m is also analyzed. The proposed constant test set is much smaller than ATPG generated or algorithmic test set, resulting in low power testability. As the GF(2  m ) multipliers have found some critical field applications and need for efficient online testing, built-in self-test (BIST) circuit is proposed to generate test pattern internally. This BIST also obviates the need of having three extra pins for the control inputs. Area and delay of testable circuits and BIST circuit is analyzed using 0.18mum CMOS\u00a0\u2026", "num_citations": "4\n", "authors": ["497"]}
{"title": "De bruijn graph based VLSI viterbi decoder\n", "abstract": " The disclosed system uses a binary tree which is embedded in a De Bruijn graph to sort the survivor paths based on their path metrics. The system includes a sorting algorithm which is implemented in a pipelined fashion. The same communication structure underlining the De Bruijn graph is used, so that no additional communication overhead is required for sorting. The system implementation is parallel resulting in a high throughput.", "num_citations": "4\n", "authors": ["497"]}
{"title": "Roll-forward and rollback recovery: Performance-reliability trade-o\n", "abstract": " Performance and reliability achieved by a modular redundant system depend on the recovery scheme used. Typically, gain in performance using comparable resources results in reduced reliability. Several highperformance computers are noted for small mean time to failure. Performance is measured here in terms of mean and variance of the task completion time, reliability being a task-based measure de ned as the probability that a task is completed correctly. Two roll-forward schemes are compared with two rollback schemes for achieving recovery in duplex systems. The roll-forward schemes discussed here are based on a roll-forward checkpointing concept proposed in 5-8]. Roll-forward recovery schemes achieve signi cantly better performance than rollback schemes by avoiding rollback in most common fault scenarios. It is shown that the roll-forward schemes improve performance with only a small loss in reliability as compared to rollback schemes.", "num_citations": "4\n", "authors": ["497"]}
{"title": "REACT: An Integrated Tool for the Design of Dependable Computing Systems\n", "abstract": " The REliable Architecture Characterization Tool (REACT) is a generalized software testbed for analyzing a variety of fault-tolerant multiprocessor systems. REACT abstracts a system at the architectural level and performs automated life testing through simulated fault-injection to accurately and efficiently measure dependability. It integrates detailed system, workload, and fault/error simulation models that have been derived, in part, from the published results of computer performance studies and low level fault-injection experiments.", "num_citations": "4\n", "authors": ["497"]}
{"title": "Yield optimization of modular and redundant multimegabit RAMs: a study of effectiveness of coding versus static redundancy using the center-satellite model\n", "abstract": " To determine the optimal redundancy organization for yield enhancement, redundant and modular memories are analyzed using the center-satellite model. The model suggests that the degree of redundancy for a memory module be determined according to its distance from the periphery of the wafer since the defect density increases as the periphery is neared. Analytical expressions are formulated for the yield of memory modules with extra rows and/or extra columns, coding, and coding with extra rows. Results from the analysis suggest that, for high levels of defect densities, coding can be more effective than simple extra rows and columns. For high levels of defect densities, coding with extra rows is shown to offer even better yield. For low levels of defect densities, though, just extra rows and columns may be sufficient for a high yield. An optimal amount of redundancy can be found to achieve the highest possible\u00a0\u2026", "num_citations": "4\n", "authors": ["497"]}
{"title": "Correction to\n", "abstract": " Correction to \"Fault-Tolerant Multiprocessor Link and Bus Architectures\" IEEE.org Help Cart Jobs Board Create Account Toggle navigation IEEE Computer Society Digital Library Jobs Tech News Resource Center Press Room Browse By Date Advertising About Us IEEE IEEE Computer Society IEEE Computer Society Digital Library My Subscriptions Magazines Journals Conference Proceedings Institutional Subscriptions IEEE IEEE Computer Society More Jobs Tech News Resource Center Press Room Browse By Date Advertising About Us Cart Advanced Search IEEE Transactions on Computers IEEE Transactions on Computers Home Current Issue Early Access About Editorial Board Staff Featured Paper of the Month Author Information Calls for Papers Special Issue/Section Proposals Peer Review Information Submit a Manuscript IEEE DataPort Overlength Submission Policy Multimedia IEEE Transactions on 1.2..'\u2026", "num_citations": "4\n", "authors": ["497"]}
{"title": "Computational analysis and comparison of reversible gates for design and test of logic circuits\n", "abstract": " Quantum computing is one of the most significant anticipation towards the accomplishment of interminable consumer demands of small, high speed, and low-power\u00a0operable electronics devices. As reversible logic circuits have direct applicability to quantum circuits, design and synthesis of these circuits are finding grounds for emerging nano-technologies\u00a0of quantum computing. Multiple Controlled Toffoli (MCT) and Multiple Controlled Fredkin (MCF) are the fundamental reversible gates that playing key role in this phase of development. A\u00a0number of special reversible gates have also been presented so far, which were claimed superior for providing certain purposes like logic development and testing. This paper critically analyses a\u00a0range of these gates to procure an optimal solution for design, synthesis and testing of reversible circuits. The experimentation is facilitated at three subsequent levels, i.e. gates\u00a0\u2026", "num_citations": "3\n", "authors": ["497"]}
{"title": "Selective segmentation of piecewise homogeneous regions\n", "abstract": " In this article, a novel method for the interactive segmentation of the object and background which has multiple piecewise homogeneous intensities has been introduced. We have proposed a new energy function based on intensity points selected from multiple homogeneous regions in the object and background. To minimize the derived energy function, we use the calculus of variation method and transformed it to PDE. The derived PDE has been solved using an additive operator splitting (AOS) method. Simulation results validate the correctness and accuracy of the proposed method. The performance is assessed by testing the algorithm on synthetic images and results are compared with state of the art methods using Jaccard\u2019s similarity index.", "num_citations": "3\n", "authors": ["497"]}
{"title": "Digital error correction\n", "abstract": " Error-correcting circuit includes: component generating a first output from first and second inputs; error detector generating an error flag indicative of whether or not an error is detected in the first output, based on the first output, and the first and second inputs; correction generator generating a correcting output after a first time period beginning with a timing event, based on the first output, and the first and second inputs; and output generator generating an output after a second time period beginning with the timing event. If the error flag indicates a detected error then the second time period may be longer than the first time period, otherwise it may be not longer, and the error-correcting circuit output may include a combination of the first output and the correcting output whereby the detected error is corrected, otherwise the error-correcting circuit output may correspond directly to the first output.", "num_citations": "3\n", "authors": ["497"]}
{"title": "A Low-Cost Unified Design Methodology for Secure Test and Intellectual Property Core Protection\n", "abstract": " On-chip security is an emerging challenge in the design of embedded systems with intellectual property (IP) cores. Traditionally this challenge is addressed using ad hoc design techniques with separate design objectives of secure design for testability (DfT), and IP core protection. However, in this paper, we will argue that such design approaches can incur high costs. Underpinning this argument, we propose a novel design methodology, called Secure TEst and IP core Protection (STEP), which aims to address the joint objective of IP core protection and secure testing. To ensure that this objective is achieved at a low cost, the STEP design methodology employs common key integrated hardware. This hardware is incorporated in the system through an automated design conversion technique, which can be easily merged into the electronic design automation (EDA) tool chain. We evaluate the effectiveness of our\u00a0\u2026", "num_citations": "3\n", "authors": ["497"]}
{"title": "Object detection and tracking based on silhouette based trained shape model with Kalman filter\n", "abstract": " Object detection and tracking plays an important role in the field of video surveillance and has been discussed since many years. There are several techniques available in literature. But to find out a robust method which can give the better result is a challenging job. In this paper, we proposed a method which can detect and track the motion of an object. The proposed method is a combination of adaptive background subtraction, a trained silhouette based model for detection and Kalman filter for tracking purpose.", "num_citations": "3\n", "authors": ["497"]}
{"title": "VLSI Architecture for Bit Parallel Systolic Multipliers for Special Class of GF(2m)Using Dual Bases\n", "abstract": " This paper presents the efficient VLSI architecture for bit parallel systolic multiplication over dual base for trinomial and pentanomial inGF(2                                    m                                  ) for effective use in RS decoders. This architecture supports pipelining. Here irreducible trinomial of form p(x)=x                                    m                                  +x                                    n                                  +1 and pentanomial of the form p(x) = x                                    m                                  +x                                    k\u2009+\u20092                 + x                                    k\u2009+\u20091                 +x                                    k                                  +1 generate the fields in GF(2                                    m                                  ). For ECC algorithms, NIST recommends the five reduction polynomials which are either trinomial or pentanomial. Since the systolic multiplier has the features of regularity, modularity and unidirectional data flow, this structure is well suited to VLSI implementations. For\u00a0\u2026", "num_citations": "3\n", "authors": ["497"]}
{"title": "An efficient de bruijn graph based fault tolerant sensor networks design\n", "abstract": " Wireless sensor network reliability is a growing concern as most of the sensors are expected to operate in an unattended manner for long periods of time. Therefore it is important that they should be able to tolerate faults and maintain a reasonable level of performance. To this end, in this paper we explore two De Bruijn and mesh based topologies and its fault tolerant routing scheme and a distributed fault detection algorithm. The performance of the proposed topologies and algorithms was analyzed considering end-to-end-delay, data success rate and energy consumption. Our simulation results show that the proposed topologies and algorithms give a good performance under different conditions and scenarios.", "num_citations": "3\n", "authors": ["497"]}
{"title": "ULS: A Dual-Vth/High-K Nano-CMOS Universal Level Shifter for System-Level Power Management\n", "abstract": " ULS: A Dual-Vth/High-K Nano-CMOS Universal Level Shifter for System-Level Power Management \u2014 University of Bristol Skip to main navigation Skip to search Skip to main content University of Bristol Logo Help & Terms of Use Home Profiles Research Units Research Outputs Projects Student theses Datasets Activities Prizes Facilities/Equipment Search by expertise, name or affiliation ULS: A Dual-Vth/High-K Nano-CMOS Universal Level Shifter for System-Level Power Management Mohanty SP, Dhiraj Pradhan Department of Computer Science Microelectronics Research output: Contribution to journal \u203a Article (Academic Journal) \u203a peer-review 7 Citations (Scopus) Overview Translated title of the contribution ULS: A Dual-Vth/High-K Nano-CMOS Universal Level Shifter for System-Level Power Management Original language English Article number 8:1-8-26 Journal ACM Journal on Emerging Technologies in 6(2) :'\u2026", "num_citations": "3\n", "authors": ["497"]}
{"title": "C-testable S-box implementation for secure advanced encryption standard\n", "abstract": " We propose a C-testable S-box implementation which is one of the most complex blocks in AES hardware implementation. Only 12 constant vectors are sufficient to achieve 100% fault coverage in the S-box. C-testability is achieved with an extra hardware overhead of 8.2 percent.", "num_citations": "3\n", "authors": ["497"]}
{"title": "Tabu search based gate leakage optimization using DKCMOS library in architecture synthesis\n", "abstract": " The gate-oxide (aka gate tunneling or gate) leakage due to quantum-mechanical direct tunneling of carriers across the gate dielectric of a device is a major source power dissipation for sub-65nm CMOS circuits. In this paper a high-level (aka architecture) synthesis algorithm is presented that simultaneously schedules operations and binds to modules for gate leakage optimization. The algorithm uses device-level gate leakage models for precharacterizing register-transfer level datapath component library. The algorithm minimizes the gate leakage for given resource and time constraints. The dual-K CMOS (DKCMOS) technology is used as a method for gate leakage power reduction in a data flow graph. The proposed algorithm is tested for several high-level synthesis benchmarks for two types of DKCMOS, SiO2-SiON and SiO2-Si3N4, for 45nm node. The experiments showed that gate leakage reduction in average 60% and 72% for SiO2-SiON and SiO2-Si3N4, respectively, could be achieved.", "num_citations": "3\n", "authors": ["497"]}
{"title": "Formal model for the reduction of the dynamic energy consumption in multi-layer memory subsystems\n", "abstract": " In real-time data-dominated communication and multimedia processing applications, a multi-layer memory hierarchy is typically used to enhance the system performance and also to reduce the energy consumption. Savings of dynamic energy can be obtained by accessing frequently used data from smaller on-chip memories rather than from large background memories. This paper focuses on the reduction of the dynamic energy consumption in the memory subsystem of multidimensional signal processing systems, starting from the high-level algorithmic specification of the application. The paper presents a formal model which identifies those parts of arrays more intensely accessed, taking also into account the relative lifetimes of the signals. Tested on a two-layer memory hierarchy, this model led to savings of dynamic energy from 40% to over 70% relative to the energy used in the case of flat memory designs.", "num_citations": "3\n", "authors": ["497"]}
{"title": "Evaluation of generalized LFSRs as test pattern generators in two-dimensional scan designs\n", "abstract": " Linear finite-state machines (LFSMs) such as linear feedback shift registers (LFSRs), cellular automata (CA), and ring generators (RGs) are used as test pattern generators in built-in self-test schemes that employ 2-D scan design. These mechanisms are usually accompanied by phase shifters (PSs) in order to avoid the degradation of the fault coverage caused by correlations/dependences in the produced test bit sequences. Given this context, we investigate in this paper the potential of generalized (or Galois) LFSRs (GLFSRs) as onboard test pattern generators. We compare GLFSRs with and without PSs against LFSMs with PSs (LFSM/PSs) for various types of LFSMs (LFSRs, CA, RGs, and dense RGs) on two accounts: channel separation and overall hardware cost. Experimental results show that GLFSRs achieve larger channel separation with lower hardware cost than LFSM/PS and attain higher fault coverage.", "num_citations": "3\n", "authors": ["497"]}
{"title": "Defect tolerance in nanotechnology switches using a greedy reconfiguration algorithm\n", "abstract": " Lithography based IC fabrication is rapidly approaching its limit in terms of feature size. The current alternative is nanotechnology based fabrication, which relies on self-assembly of nanotubes or nanowires. Such a process is subject to a high defect rate, which can be tolerated using carefully crafted defect tolerance techniques. This paper presents an algorithm for reconfiguration-based defect tolerance in nanotechnology switches. The algorithm offers an average switch density improvement of 50% to 100% to most recently published techniques", "num_citations": "3\n", "authors": ["497"]}
{"title": "An efficient graph based representation of circuits and calculation of their coefficients in finite field\n", "abstract": " An Efficient Graph Based Representation of Circuits and Calculation of Their Coefficients in Finite Field \u2014 University of Bristol Skip to main navigation Skip to search Skip to main content University of Bristol Logo Help & Terms of Use Home Profiles Research Units Research Outputs Projects Student theses Datasets Activities Prizes Facilities/Equipment Search by expertise, name or affiliation An Efficient Graph Based Representation of Circuits and Calculation of Their Coefficients in Finite Field A Jabir, D Pradhan Department of Computer Science Research output: Chapter in Book/Report/Conference proceeding \u203a Conference Contribution (Conference Proceeding) Overview Translated title of the contribution An Efficient Graph Based Representation of Circuits and Calculation of Their Coefficients in Finite Field Original language English Title of host publication Unknown Publication status Published - Jun 2005 note /: :/\u2026", "num_citations": "3\n", "authors": ["497"]}
{"title": "LPRAM: a low power DRAM with testability\n", "abstract": " To date all the proposal for low power designs of RAMs essentially focus on circuit level solutions. What we propose here is a novel architecture level solution. Our methodology provides a systematic trade off between power and area. Also, it allows tradeoff between test time and power consumed in test mode. Significantly, too, the proposed design has the potential to achieve performance improvements while reducing power. In this respect it stands apart from other approaches where the conventional wisdom of reducing power reduces speed.", "num_citations": "3\n", "authors": ["497"]}
{"title": "Recoverable mobile environments: Design and trade-o analysis\n", "abstract": " The mobile wireless environment poses challenging problems in designing fault-tolerant systems because of the dynamics of mobility, and limited bandwidth available on wireless links. Traditional fault-tolerance schemes, therefore, cannot be directly applied to these systems. Mobile systems are often subject to environmental conditions which can cause loss of communications or data. Because of the consumer orientation of most mobile systems, run-time faults must be corrected with minimal (if any) intervention from the user. The fault-tolerance capability must, therefore, be transparent to the user.Presented here are schemes for recovery upon a failure of a mobile host. This paper portrays the limitations of the mobile wireless environment, and their impact on recovery protocols. Toward this, adaptation of well-known recovery schemes are presented which suit the mobile environment. The performance of these schemes has been analyzed to determine those environments where a particular recovery scheme is bestsuited. The performance of the recovery schemes primarily depends on (i) the wireless bandwidth,(ii) the communication-mobility ratio of the user, and (iii) the failure rate of the mobile host.", "num_citations": "3\n", "authors": ["497"]}
{"title": "Scalability of binary deBruijn networks\n", "abstract": " This paper presents a technique to construct scalable binary deBruijn networks. Based on building larger binary deBruijn networks from smaller networks, this technique also provides for the capability of fault-tolerance for graceful degradation and multitasking. A new representation of the binary deBruijn network is presented which provides the basis for scalability.< >", "num_citations": "3\n", "authors": ["497"]}
{"title": "The effect of memory-management policies on system reliability\n", "abstract": " The impact of memory-management policies on memory reliability is discussed. The tradeoffs in performance and reliability are studied as a function of the block-miss reload time. A detailed analysis of how reliability is affected by the memory space allocated is presented. This can be used to understand the relationship between the amounts of memory allocated and reliability. Separate effects are measured, depending on the relative time to process a first-level memory miss. For very small memories, a very few page durations contribute to a majority of the total unreliability. Two techniques for further improving reliability are suggested to remove these long durations.< >", "num_citations": "3\n", "authors": ["497"]}
{"title": "Yield optimization of redundant multimegabit RAM's using the center-satellite model\n", "abstract": " Redundant wafer scale memories are analyzed using the center satellite model to determine the optimal redundancy organization for yield enhancement. It is suggested that the degree of redundancy for a memory module be determined depending on its distance from the periphery, as defect density increases as one moves toward the periphery. New analytical expressions for the yield of memory modules with extra rows and/or extra columns, coding, and coding with extra rows are formulated. Results suggest that coding can be more effective than extra rows and columns for higher levels of defect densities. On the other hand, for lower levels of defect densities, having only extra rows and columns may be sufficient. Using the model it is shown that, by taking into account the precise distributions of clusters on the wafer, defects in a cluster, and the radial variation of these defects, an optimal account of redundancy\u00a0\u2026", "num_citations": "3\n", "authors": ["497"]}
{"title": "A fast algorithm for optimum syndrome space compression\n", "abstract": " A procedure for multiple-output combinational circuits is presented that yields the optimum space compressor while using counting for time compression. The procedure is intended for the built-in selftest environment where output response data compression is appropriate. Optimum is defined as the minimum number of error patterns missed by the combination of space and time compression. The procedure uses the fast Walsh transform to determine the number of errors missed by each linear combination for all possible space-compression combinations. A illustrative example is included to show the effectiveness of the algorithm. A comparison between cases with and without space compression is included.< >", "num_citations": "3\n", "authors": ["497"]}
{"title": "Beam transport for heavy ion spectroscopy with high energy-resolution\n", "abstract": " [en] A method is given to adjust a beam-transport system to the requirements of high energy-resolution heavy ion spectroscopy. The results of a test experiment performed on a MP tandem with a 12 C beam are shown. A drastic improvement in energy resolution is obtained for a kinematical factor K=(1/p) dp/dTHETA approx. 0.12.(orig.)", "num_citations": "3\n", "authors": ["497"]}
{"title": "Some contributions to redundancy theory\n", "abstract": " It has long been recognized that the complex tasks of odern ultrareliable computers can only be accomplished through the judicious use of redundancy. Recent technology has contributed toward making component cost and size of secondary design importance. Improved reliability can be achieved by such design techniques as the use of redundan-cies, and of automatic self-testing procedures which switch the system, or parts of it, to spares whenever a failure is detected.", "num_citations": "3\n", "authors": ["497"]}
{"title": "Design of Single-Bit Fault-Tolerant Reversible Circuits\n", "abstract": " This article introduces redundant design approaches for reversible circuits that have the ability to detect and tolerate single-bit fault without the need of conventional voting scheme. Experiments preformed show that the proposed scheme reduces the gate cost on average with up to 28% as compared with tri-modular redundant circuits.", "num_citations": "2\n", "authors": ["497"]}
{"title": "Estimation of noise parameters for captured image\n", "abstract": " This article deals with the analysis of noise parameter estimation for captured image under motion blurring and illumination flickering. A captured image is first analysed for determination of motion blur parameters i.e., direction of blur and pixel displacement length (PDL) and it is carried out using edge information of the image. Subsequently a blur-free image is processed for estimation of illumination flicker noise parameters and then for the estimation of camera parameters-camera gain, mean and variance of Gaussian white noise and illumination flickering co-efficient.", "num_citations": "2\n", "authors": ["497"]}
{"title": "Adaptive checkpoint interval algorithm considering task deadline and lifetime reliability for real-time system\n", "abstract": " Checkpointing mechanism is used to tolerate the impact of transient faults by rollback operation. Recently, it has also been used as a mechanism to enhance system's lifetime by identifying and tolerating permanent fault 5,19,10,12. However, equidistant checkpoint interval may cause task deadline violation in the system. Here, we propose an adaptive checkpoint interval placement algorithm (ADeLiRACI) that meets all tasks deadline. The checkpoint intervals are adjusted to minimize the impact of stresses and permanent faults on the running hosts. This novel mechanism allows greater applicability in real time systems with hard deadline such as weather prediction, financial transactions etc. We compare the estimated completion time for increasing fault-rate in the system against five existing algorithms. For all applications, ADeLiRACI is able to meet the hard deadline along with enhancing lifetime reliability of the\u00a0\u2026", "num_citations": "2\n", "authors": ["497"]}
{"title": "Energy efficient lifetime reliability-aware checkpointing for real-time system\n", "abstract": " Due to continued technology scaling, reliability of today's integrated circuits (IC) is an emerging design challenge especially in varied range of operating environment. The lifetime reliability of modern system has been severely limited by higher wear-out and stress effects. Checkpointing has been extensively used as an effective method in fault-tolerant system design. Traditionally, it is used to tolerate the impact of transient faults through saving the intermediate results at predefined time and rolling-back to appropriate previously saved state whenever needed. In this paper, we proposed a new checkpointing mechanism for a duplex real-time system that achieves fault-tolerant against transient and permanent faults, and also provides a fault avoidance mechanism by migrating task from an unhealthy (perhaps near-to-die) host to a spare host. We developed a mathematical model for evaluating the performance of the\u00a0\u2026", "num_citations": "2\n", "authors": ["497"]}
{"title": "A Low-Complexity Multiple Error Correcting Architecture Using Novel Cross Parity Codes Over GF\n", "abstract": " This paper presents a novel low-complexity cross parity code, with a wide range of multiple bit error correction capability at a lower overhead, for improving the reliability in circuits over GF(2 m ). For an m input circuit, the proposed scheme can correct m \u2264 D w  \u2264 3 m/2  -1 multiple error combinations out of all the possible 2 m  - 1 errors, which is superior to many existing approaches. From the mathematical and practical evaluations, the best case error correction is m/2 bit errors. Tests on 80-bit parallel and, for the first time, on 163-bit Federal Information Processing Standard/National Institute of Standards and Technology (FIPS/NIST) standard word-level Galois field (GF) multipliers, suggest that it requires only 106% and 170% area overheads, respectively, which is lower than the existing approaches, while error injection-based behavioral analysis demonstrates its wider error correction capability.", "num_citations": "2\n", "authors": ["497"]}
{"title": "Diagnosis of gastric glomus tumour by endoscopic ultrasound\u2010guided fine needle aspiration cytology: a case report\n", "abstract": " Dear Editor, Glomus tumour (GT) is a distinct, benign, solitary cellular proliferation that arises from modified smooth muscle cells of the glomus body, a type of neuromyoarterial receptor which plays an important role in the regulation of arterial blood flow. 1 The majority of GTs occur in the deep dermis or subcutis of the upper or lower extremity, where arteriovenous anastomoses are numerous. 1 However, they may also develop at sites at which the glomus body may be sparse or even absent, such as bone and joints, skeletal muscle, soft tissue, mediastinum, trachea, kidney, uterus, vagina and stomach. 1\u20134 Although the histopathological features of gastric GT have been well described in the literature, its cytological features, which may help in a definitive preoperative diagnosis, have rarely been described. 1\u20135 We report a case of gastric GT diagnosed by endoscopic ultrasound (EUS)-guided fine needle aspiration\u00a0\u2026", "num_citations": "2\n", "authors": ["497"]}
{"title": "FastRec: A fast and robust text independent speaker recognition system for radio networks\n", "abstract": " This paper proposes a fast and robust text-independent speaker identification system for all types of radio networks. The radio-conversations contain speech from various speakers along with radio noise. A novel approach to segment the radio-conversations into speaker homogenous speech segments named as Reciever Noise Segmentation (RxNSeg) is proposed which first identifies the receiver radio-noise and then finds the boundaries for speaker homogeneous speech segments in the radio-conversation. Various techniques for clustering of speech segments to arrive at speaker homogenous clusters to train speaker models are evaluated. A novel top-down approach named as Find One Long Speech Segment (FOLSS) for finding at least one long speaker homogenous segment for each speaker present in a radio-conversation is proposed in lieu of traditional clustering techniques. Speaker modeling using\u00a0\u2026", "num_citations": "2\n", "authors": ["497"]}
{"title": "Effect of fungicidal seed treatment on seed borne mycoflora and seedling vigour of pigeonpea (Cajanus cajan (L.) Millsp).\n", "abstract": " Pigeonpea, a very important member of pulses, its seeds also harbours variety of micro-organism which deteriorates the quality of seed. In order to manage the seed borne mycoflora, seeds of pigeonpea variety Rajeev Lochan were treated with five fungicides fungicides Subject Category: Chemicals and Chemical Groups", "num_citations": "2\n", "authors": ["497"]}
{"title": "Write scheme for multiple Complementary Resistive Switch (CRS) cells\n", "abstract": " Amongst emerging technologies with the potential to usher in a new generation of Non Volatile Memory (NVM) is the memristor. The memristor makes it possible to build simple and highly dense memory structure via cross point architecture. Memristor array however suffers exponentially from sneak path leakages as array size increases, which leads to excessive power consumption and poor data integrity. Complementary Resistive Switch (CRS) was proposed to mitigate the sneak-path problem. However, when writing into multiple cells in CRS-based memory array, the state of unselected and and half-selected cell(s) in the array are affected in an undesired way depending on the polarity, magnitude and duration of the voltage applied during the write operation. The effect of these disturbance to non-selected cell(s) is a resultant corrupted output in subsequent read operation on these cell(s). In this paper, we\u00a0\u2026", "num_citations": "2\n", "authors": ["497"]}
{"title": "Low power and robust binary tree SRAM design for embedded systems\n", "abstract": " Low power consumption is a prime design requirement for modern embedded systems memories. However, low power design of these memories is highly challenging due to conflicting design requirements of high-performance and robustness under process-voltage-temperature (PVT) variations. In this paper, we propose a novel low power high-performance static random access memory (LPSRAM) design. In our proposed LPSRAM design, we divide the SRAM subsystem into modules, with inter-module connections organized in a binary tree. We show that due to such organization LPSRAM can benefit from low power consumption and dynamic reconfiguration during normal operational mode. Moreover, during test mode most of the SRAM cells can be switched off to provide with substantial leakage power reduction. We formulate the energy and read/write performance models of the proposed memory design\u00a0\u2026", "num_citations": "2\n", "authors": ["497"]}
{"title": "A Numerical Solution of Burgers Equation Based on Multigrid Method\n", "abstract": " in this article we discussed the numerical solution of Burgers\u2019 equation using multigrid method. We used implicit method for time discritization and Crank-Nicolson scheme for space discritization for fully discrete scheme. For improvement we used Multigrid method in fully discrete solution. And also Multigrid method accelerates convergence of a basics iterative method by global correction. Numerical results confirm our theoretical results.", "num_citations": "2\n", "authors": ["497"]}
{"title": "Attack tolerant cryptographic hardware design by combining error correction and uniform switching activity\n", "abstract": " Thwarting severe cryptographic hardware attacks requires new approaches to logic and physical designs. This paper presents a systematic design approach to fault tolerant cryptographic hardware designs by combining the concurrent error detection and correction, and uniform switching activity cells. The effectiveness of the Hamming code based error correction schemes as a fault tolerance method in stream ciphers is investigated. Coding is applied to Linear Feedback Shift Registers (LFSR) based stream cipher implementations. The method was implemented on industrial standard stream ciphers, e.g. A5/1(GSM), E0 (Bluetooth), RC4 (WEP), and W7. The performance of stream cipher algorithms with error detection and correction was studied by synthesising the designs on FPGA and custom Integrated Circuits. The hardware building blocks are investigated to minimise switching activity of a circuit for all possible\u00a0\u2026", "num_citations": "2\n", "authors": ["497"]}
{"title": "RAEF: a power normalized system-level reliability analysis and estimation framework\n", "abstract": " System-level reliability estimation is a crucial aspect in reliable design of embedded systems. Recently reported estimation techniques use separate measurements of power consumption and reliability to demonstrate the trade-offs between them. However, we will argue in this paper that such measurements cannot determine comparative reliability of system components with different power consumptions and hence a composite measurement of reliability and power consumption is required. Underpinning this argument, we propose a SystemC based system-level reliability analysis and estimation framework, RAEF, using a novel composite metric, power normalized reliability (PNR), defined as the ratio of reliability and power consumption. We show that PNR based estimation enables insightful reliability analysis of different system components. We evaluate the effectiveness of such estimation in RAEF using a case\u00a0\u2026", "num_citations": "2\n", "authors": ["497"]}
{"title": "\u2018Eco-friendly computing and communication systems\n", "abstract": " This book constitutes the refereed proceedings of the International Conference Eco-friendly Computing and Communication Systems, ICECCS 2012, held in Kochi, Kerala, India, in August 2012. The 50 revised full papers presented were carefully reviewed and selected from 133 submissions. The papers are organized in topical sections on energy efficient software system and applications; wireless communication systems; green energy technologies; image and signal processing; bioinformatics and emerging technologies; secure and reliable systems; mathematical modeling and scientific computing; pervasive computing and applications.", "num_citations": "2\n", "authors": ["497"]}
{"title": "STEP: a unified design methodology for secure test and IP core protection\n", "abstract": " Intellectual property (IP) core based embedded systems design is a pervasive practice in the semiconductor industry due to shorter time-to-market and tougher cost competitions. Protecting the design information in these IP cores and securing test from various attacks are two emerging challenges in today's embedded systems design. Recently reported techniques address these challenges considering secure test and IP core protection separately. However, for ensuring high security during IP core functionality and also during test, joint consideration of secure test and IP core protection is much needed. In this paper, we propose a novel and unified design methodology, called STEP (Secure TEst and IP core Protection), which addresses the joint objective of secure test and IP core protection. The aim of STEP design methodology is to achieve high security at low system cost using the same key integrated hardware\u00a0\u2026", "num_citations": "2\n", "authors": ["497"]}
{"title": "Variation-aware TED-based approach for nano-CMOS RTL leakage optimization\n", "abstract": " As technology scales down to nanometer regime the process variations have profound effect on circuit characteristics. Meeting timing and power constraints under such process variations in nano-CMOS circuit design is increasingly difficult. This causes a shifting from worst-case based analysis and optimization to statistical or probability based analysis and optimization at every level of circuit abstraction. This paper presents a TED (Taylor Expansion Diagram) based -multi-T ox  techniques during high-level synthesis (HLS). A variation-aware simultaneous scheduling and resource binding algorithm is proposed which maximizes the power yield under timing yield and performance constraint. For this purpose, a-multi-T ox  library is characterized under process variation. The delay and power distribution of different functional units are exhaustively studied. The proposed variation-aware algorithm uses those\u00a0\u2026", "num_citations": "2\n", "authors": ["497"]}
{"title": "A Taylor Expansion Diagram Approach for Nano-CMOS RTL Leakage Optimization\n", "abstract": " Due to exponential behavior of gate-oxide leakage current with temperature and technology scaling, leakage power plays important role in nano - CMOS circuit. In this paper, we present simultaneous scheduling and binding algorithm for optimizing leakage current during behavioral synthesis. It uses TED (Taylor Expansion Diagram) for generating optimized DFG (Data Flow Graph). Once DFG is obtained, it selectively binds non-critical components to corresponding functional unit consisting of transistors of high oxide thickness and critical components with low oxide thickness. As the algorithm considers time-constraint explicitly, it reduces leakage current without degrading the performance of the design. Experimental results on a set of behavioral synthesis benchmarks for 45 nm process show 30% to 70% reduction in leakage current compared to the results obtained by a conventional optimization flow.", "num_citations": "2\n", "authors": ["497"]}
{"title": "Evaluation of a new low cost software level fault tolerance technique to cope with soft errors\n", "abstract": " Increasing soft error rates make the protection of combinational logic against transient faults in future technologies a major issue for the fault tolerance community. Since not every transient fault leads to an error at application level, software level fault tolerance has been proposed by several authors as a better approach. In this paper, a new software level technique to detect and correct errors due to transient faults is proposed and compared to a classic one, and the costs of detection and correction for both approaches are compared and discussed.", "num_citations": "2\n", "authors": ["497"]}
{"title": "Effect of B. monnieri leaf extract targeted at adenosine receptor in diabetic neuropathic pain.\n", "abstract": " Diabetic neuropathic pain is generally considered to be one of the most troublesome complications affecting diabetic patients and current therapy provides inadequate pain relief. In the present study, the neuroprotective effect of Bacopa monnieri bacopa monnieri Subject Category: Organism Names", "num_citations": "2\n", "authors": ["497"]}
{"title": "Error detecting dual basis bit parallel systolic multiplication architecture over GF (2m)\n", "abstract": " This paper presents an error tolerant hardware efficient VLSI architecture for bit parallel systolic multiplication over dual base, which can be pipelined. This error tolerant architecture is well suited to VLSI implementation because of its regularity, modular structure, and unidirectional data flow. The length of the largest delay path and area of this architecture are less compared to the bit parallel systolic multiplication architectures reported earlier. The architecture is implemented using Austria Micro System's 0.35 mum CMOS technology. This architecture can also operate over both the dual-base and polynomial base.", "num_citations": "2\n", "authors": ["497"]}
{"title": "A Forecasting Approach on Development of Manufacturing Industry Using Support Vector Machine Combined with Grey System\n", "abstract": " In order to solve the manufacturing time series forecasting problem, a grey support vector machines (GSVM) with differential evolution algorithms is proposed. GM (1, N) model of grey system is used to add a grey layer before neural input layer and white layer after support vector machine layer. Differential evolution (DE) algorithm is used to determine free parameters of support vector machines. Evaluation method has been used for comparing the performance of forecasting techniques. The experiments show that the proposed model in this paper outperforms either GM (1, N) model or support vector machine model with DE algorithms in the field of forecast.", "num_citations": "2\n", "authors": ["497"]}
{"title": "Simulink based architecture prototyping of compressed domain mpeg-4 watermarking\n", "abstract": " We present a novel algorithm, architecture, and high-level Simulink prototyping for visible watermarking of MPEG-4 video streams. The watermark is inserted in the video stream during compression, resulting in an optimized compression/watermarking algorithm and system. Discrete Cosine Transform (DCT) watermarking, due to its robust nature, was chosen in this work to accomplish MPEG-4 video copyright protection. Drift compensation in the spatial domain is implemented for obtaining a stable watermark. The algorithm will be useful for insertion of broadcasters\u2019 logo and subtitling in real-time applications such as sports broadcasting in digital TV.", "num_citations": "2\n", "authors": ["497"]}
{"title": "De-bruijn graph based energy efficient routing in multi-layered architecture for wireless sensor networks\n", "abstract": " As dense wireless sensor networks are increasingly vulnerable to fault, network must continue processing data without affecting the faulty node. Fault aware routing is an effective way to mitigate such scenario. To this end, we propose a efficient multi-layered architecture with fault tolerance. We also analayze the end-to-end delay, energy consumption and average transmission ratio for the proposed architecture. Our Simulation results shows that as the number of nodes (or layers) increases our algorithm performs better. For instance, in a 1024 node network, the end to end delay is about 50 percent better than reported results. Furthermore, we show that, depending on the fault tolerance capability one wants, design requires higher redundancy.", "num_citations": "2\n", "authors": ["497"]}
{"title": "Multiple SEU tolerance in LUTs of FPGAs using protected schemes\n", "abstract": " Multiple upsets would be available in SRAM-based FPGAs which utilizes SRAM in different parts to implement circuit configuration and to implement circuit data. Moreover, configuration bits of SRAM-based FPGAs are more sensible to upsets compared to circuit data due to significant number of SRAM bits. In this paper, a new protected CLB and FPGA architecture is proposed which utilize multiple error correction (DEC) and multiple error detection. This is achieved by the incorporation of recently proposed coding technique Matrix code [13] in the FPGA. The power and area analysis of the proposed techniques show that these methods are more efficient than the traditional schemes such as duplication with comparison and TMR circuit design in the FPGAs.", "num_citations": "2\n", "authors": ["497"]}
{"title": "Area reliability trade-off in improved Reed Muller coding\n", "abstract": " Nanotechnology based fabrication, which relies on self-assembly of nanotubes or nanowires has been predicted to be an alternative to silicon technology since lithography based IC is approaching its limit in terms of feature size. However, such processes are expected to be less reliable, to have high defect density and to be handled with effective defect tolerant techniques. Thus, reliability is a major challenge in the future of IC design. To this end, different coding techniques have been proposed to improve reliability of future technologies. In this paper we analyze the trade-off between the area and the reliability added in each chip employing the Reed Muller coding as the coding technique. We estimate the reliability and area increase of different orders of the Reed Muller decoding and observed that while the area increases, the reliability decreases. Our approach is to define a framework and help\u00a0\u2026", "num_citations": "2\n", "authors": ["497"]}
{"title": "Reducing the dynamic energy consumption in the multi-layer memory of embedded multimedia processing systems\n", "abstract": " The memories in data-intensive signal processing systems\u2013including video and image processing, artificial vision, real-time 3-D rendering, advanced audio and speech coding, medical imaging applications\u2013have an important impact on the overall energy budget. This paper focuses on the reduction of the dynamic energy consumption in the memory subsystem, starting from the high-level algorithmic specification of the application. The approach to address this problem uses elements of the theory of polyhedra and relies on a variety of algebraic techniques specific to the data-flow analysis used in modern compilers.", "num_citations": "2\n", "authors": ["497"]}
{"title": "Highly Reliable Power Aware Memory Design\n", "abstract": " In this paper, an efficient technique for designing RAMs for on chip correction of double errors integrated on H-tree memory architecture is discussed. The reliability of the proposed design is improved by 8X while the Mean Time To Failure is improved 3X while comparing to traditional Hamming codes for a 256 Mbits memory chip. The area is sacrificed for these reliability improvements, significant power savings and the performance boost.", "num_citations": "2\n", "authors": ["497"]}
{"title": "CLB-based Detection and Correction of Bit-flip faults in SRAM-based FPGAs\n", "abstract": " This paper presents a bit-flip tolerance in SRAM-based FPGAs which suffers from high energy particles, alpha and neutrons in the atmosphere. For each of protections, the applicability, efficiency and implementation issues are discussed. Moreover, the area, the power and the protection capability of the methods are mentioned and compared with previous work. Based on the results of experiments and their analysis, one method is selected as best one. The selected method is much better than previous work e.g., duplication with comparison, triple modular redundancy which impose two and three area and power overheads, respectively.", "num_citations": "2\n", "authors": ["497"]}
{"title": "CAD-directed SEU susceptibility reduction in FPGA circuits designs\n", "abstract": " This paper presents a SEU-mitigative placement and route of circuits in the FPGAs which is based on the popular placement and route tool. The tool is modified so that during placement and routing, decisions are taken with awareness of SEU-mitigation and no redundancies during the placement and routing are used but the algorithms are based on the SEU avoidance. We have investigated the effect of this tool on several MCNC benchmarks and the results of the placement and routing have been compared to the traditional one. The evaluations of results show that placement and routing can decrease the SEU rate of circuits implemented on FPGAs about 22%. However, it increases critical path delay and power consumptions of the circuits.", "num_citations": "2\n", "authors": ["497"]}
{"title": "Online detection and correction of soft-errors in luts of sram-based FPGAs\n", "abstract": " Online Detection and Correction of Soft-Errors in LUTs of SRAM-based FPGAs \u2014 University of Bristol Skip to main navigation Skip to search Skip to main content University of Bristol Logo Help & Terms of Use Home Profiles Research Units Research Outputs Projects Student theses Datasets Activities Prizes Facilities/Equipment Search by expertise, name or affiliation Online Detection and Correction of Soft-Errors in LUTs of SRAM-based FPGAs Zarandi HR, Miremadi SG, Argyrides Costas, Dhiraj Pradhan Department of Computer Science Research output: Chapter in Book/Report/Conference proceeding \u203a Conference Contribution (Conference Proceeding) Overview Translated title of the contribution Online Detection and Correction of Soft-Errors in LUTs of SRAM-based FPGAs Original language English Title of host publication Proceedings of European Test Symposium (ETS) Publication status Published - 2007 : - /: \u2026", "num_citations": "2\n", "authors": ["497"]}
{"title": "A novel soft error tolerant low power RAM architecture\n", "abstract": " A Novel Soft Error Tolerant Low Power RAM Architecture \u2014 University of Bristol Skip to main navigation Skip to search Skip to main content University of Bristol Logo Help & Terms of Use Home Profiles Research Units Research Outputs Projects Student theses Datasets Activities Prizes Facilities/Equipment Search by expertise, name or affiliation A Novel Soft Error Tolerant Low Power RAM Architecture Argyrides Costas, Lisboa Carlo, [No Value] Luigi Carro, Dhiraj Pradhan Department of Computer Science Research output: Chapter in Book/Report/Conference proceeding \u203a Conference Contribution (Conference Proceeding) Overview Translated title of the contribution A Novel Soft Error Tolerant Low Power RAM Architecture Original language English Title of host publication 20th annual symposium on Integrated circuits and system design SBCCI '07 Publication status Published - 2007 Bibliographical note Other : - /: ':\u2026", "num_citations": "2\n", "authors": ["497"]}
{"title": "GASIM: a fast Galois field based simulator for functional model\n", "abstract": " This paper presents a fast logic simulator based on Galois field. This is designed to act as an underlying tool for all finite field applications considering the fact that simulation plays an important role in all these applications. Three approaches for finite field representation and its evaluation are discussed. In addition an approach for normalizing the finite field based decision diagrams is also presented. The experimental results show the trade-off that can be made by using different design representations between spatial complexity and speed. Also the results show that it can be used in conventional simulation environment to achieve speedup.", "num_citations": "2\n", "authors": ["497"]}
{"title": "Functional yield modeling\n", "abstract": " The development of models to estimate the functional yield of an integrated circuit (IC) on a manufacturing process technology is fundamental to many aspects of IC manufacturing. A model that results in accurate estimates of manufacturing yield can help predict product cost and profitability, determine the optimum utilization of wafer fabrication equipment, and be used as a metric for the manufacturing organization when evaluated against actual product yields. Yield models are also critical to support decisions regarding new technology developments, the benefits of scaling products to advanced technologies, and the identification of problem products.Functional yield is defined as those chips on a wafer that meet the nominal performance specification. In some cases, a product is fully functional but does not meet the specification sheet performance for one or more parameters (eg, speed, accuracy, or power) due to a parametric variability. Therefore, functional yield is often referred to as hard yield and parametric yield as soft yield. Hard yield loss (functional fail) results from an unintended alteration of the geometric pattern on a wafer. A hard modification of the intended geometric layout of a product may result in catastrophic failure. The modeling and analysis of these types of functional failures are the subject of this chapter.", "num_citations": "2\n", "authors": ["497"]}
{"title": "Case studies in fault-tolerant multiprocessor and distributed systems\n", "abstract": " Case studies in fault-tolerant multiprocessor and distributed systems | Fault-tolerant computer system design ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksFault-tolerant computer system designCase studies in fault-tolerant multiprocessor and distributed systems chapter Case studies in fault-tolerant multiprocessor and distributed systems Share on Author: Dhiraj Kumar Pradhan profile image Dhiraj K. Pradhan View Profile Authors Info & Affiliations Publication: Fault-tolerant computer system designFebruary 1996 Pages 236\u2013281 0citation", "num_citations": "2\n", "authors": ["497"]}
{"title": "A fault tolerant hybrid memory structure and memory management algorithms\n", "abstract": " This paper proposes a cost effective fault tolerant memory structure. It uses the modified status of virtual memory pages as the basis to propose a system with two classes of memory. One class is for modified pages, and the other is for pages not modified. The term hybrid memory system is used to describe this system. Results show the cost savings for a hybrid system over a traditional fault tolerant system. Hybrid virtual memory algorithms are proposed for the system. The traditional lifetime and space-time measures of virtual memory algorithms are extended for the hybrid algorithms. This includes \"cost-weighted\" measures to reflect the fact that the two classes of memory may have different resource allocation constraints. A theoretical result is presented for the effect of combining the hybrid lifetime functions. Finally, a framework for developing hybrid algorithms is presented with experimental results illustrating the\u00a0\u2026", "num_citations": "2\n", "authors": ["497"]}
{"title": "A Software Implemented Fault-Tolerance Layer for Reliable Computing on Massively Parallel Computers and Distributed Computing Systems\n", "abstract": " A novel architecture for a software-implemented fault-tolerance layer for application reliability on massively parallel computers and distributed computing systems is proposed. This is the rst attempt at providing a purely softwarebased, user-level solution for fault detection, recon guration, and recovery in a parallel environment. The symmetrically distributed, multi-tiered layer envelopes user applications, enabling it to perform fault-tolerance related actions apart from, and transparent to the application. It's modular design enables dynamic runtime selection of the most appropriate fault-tolerant algorithm, and is, therefore, not restricted to one particular fault-tolerant method. Performance and coverage measurements of a minimal implementation of the proposed layer are presented, and indicate that user-level software-implemented fault-tolerance is realistically doable and reasonably e cient and e ective.", "num_citations": "2\n", "authors": ["497"]}
{"title": "Fault Tolerant Multiprocessor Systems\n", "abstract": " Over the past decade, the motivation for higher throughput from existing technology has forced multiprocessor and parallel computing systems into the mainstream. A recent trend is massively parallel processors (MPP), where hundreds of computing nodes are interconnected to form an integrated system. From a recent article in the IEEE, Spectrum Zorpette (1990), Table 1 portrays that more than one thousand such parallel machines sold for more than two hundred million dollars. Despite such popularity, these new systems remain largely unsuitable for applications which, because of high failure rates, demand high reliability or prolonged availability.", "num_citations": "2\n", "authors": ["497"]}
{"title": "Subcube level time-sharing in hypercube multicomputers\n", "abstract": " A novel approach for subcube level time-sharing in hypercube multicomputers is proposed. Using this approach, multiple tasks may execute on the same processors. The tasks may be completely or partially overlapped with synchronous or asynchronous context switching. A dynamic binary tree is used for subcube allocation and deallocation. An incoming task is allocated to a subcube within which it will encounter minimum interference from other tasks. The allocation and deallocation time complexities are shown to be 0(n2). The proposed strategy has been implemented on an nCUBE 2. Measurement results indicate that the proposed strategy outperforms the FCFS-based batch-scheduling policy and an existing time-sharing policy by significantly reducing the average turn-around times.", "num_citations": "2\n", "authors": ["497"]}
{"title": "BDG-torus union graph-an efficient algorithmically specialized parallel interconnect\n", "abstract": " The binary de Bruijn graph (BDG) is a realizable alternative to the hypercube. An extension of the BDG by the edge set union with a torus is shown-union-graph (UG). This achieves graph capabilities/versatility comparable to the product shuffle (PS) graph and the hypercube within a fixed degree graph. The UG improves upon both in implementing pipelined and multi-phase algorithms. More importantly, the purpose being to design an algorithmically specialized interconnect, with the algorithmic features of a wide range of algorithms as well as direct architectural support for them, instead of simple providing for a set of graph embeddings in the interconnect. A set of examples demonstrate the UG's versatility in this aspect of algorithmic support.< >", "num_citations": "2\n", "authors": ["497"]}
{"title": "A graph theoretic solution to load levelling and fault recovery in distributed systems\n", "abstract": " This paper presents a graph theoretic formulation for the problem of load-leveling in a hori-zontal distributed system, in the context of fault-recovery. An algebraic solution is then presented, suitable for implementation in a distributed system. It should be noted that the results of this paper, although developed in the context of fault recovery, are applicable to the general load-balancing problem, as well.", "num_citations": "2\n", "authors": ["497"]}
{"title": "Further results on m-RMC expansions for m-valued functions\n", "abstract": " Reed-Muller like canonic (m-RMC) expansions for multivalued functions have been proposed earlier. For a n-variable m-valued function there are m n expansions. This paper is related to the problem of finding minimal m-RMC expansions. Each of the expansions are determined by m n unknown coefficients in them. Thus there are altogether m 2n coefficients. It is shown that only m (m+ 1)/n 2 coefficients are distinct and hence by computing these coefficients one can determine all the m n expansions. Further, it is shown that the number of distinct coefficients for symmetric functions is reduced to [equation].", "num_citations": "2\n", "authors": ["497"]}
{"title": "Synthesis of Fault-Tolerant Arithmetic and Logic Processors by Using Nonbinary Codes\n", "abstract": " LC Chang System Dev. Division IBM Corporation Poughkeepsie, New York is some power of prime other than 2. If do is the minimum distance between any two code words, we can d-1 errors in any code word.", "num_citations": "2\n", "authors": ["497"]}
{"title": "Recovery in Mobile Wireless Environment: Design and Trade-o Analysis\n", "abstract": " The mobile wireless environment poses challenging problems in designing faulttolerant systems because of the dynamics of mobility, and limited bandwidth available on wireless links. Traditional fault-tolerance schemes, therefore, cannot be directly applied to these systems. Mobile systems are often subject to environmental conditions which can cause loss of communications or data. Because of the consumer orientation of most mobile systems, run-time faults must be corrected with minimal (if any) intervention from the user. The fault-tolerance capability, consequently, must, be transparent to the user.Presented here are schemes for recovery from a failure of a mobile host. This paper portrays the limitations of the mobile wireless environment, and their impact on recovery protocols. Toward this, adaptation of well-known recovery schemes are presented which suit the mobile environment. The performance of these schemes has been analyzed to determine those environments where a particular recovery scheme is best-suited. The performance of the recovery schemes primarily depends on (i) the wireless bandwidth,(ii) the communication-mobility ratio of the user, and (iii) the failure rate of the mobile host.", "num_citations": "2\n", "authors": ["497"]}
{"title": "Reversible Logic: An Introduction\n", "abstract": " Reversible logic is one of the alternatives to meet the requirement of power, speed and size in EDA (Electronic Design Automation) industry because these circuits are theoretically proven for providing nearly energy free computation by preventing the loss of information during operations. This chapter describes about theory of reversible logic, basic gates, cost matrices used for synthesis and testing of these circuits and connection of reversible logic with quantum computation.", "num_citations": "1\n", "authors": ["497"]}
{"title": "Tissue extraction devices and related methods\n", "abstract": " In accordance with an aspect of the present disclosure, a tissue extraction device may include a bag having an interior and a plurality of cutting elements extending through the interior of the bag. The cutting elements can have a common end.", "num_citations": "1\n", "authors": ["497"]}
{"title": "Epidemiological studies on sheath blight disease of rice in Chhattisgarh Plains Agroclimatic Zone of Chhattisgarh, India\n", "abstract": " Rice is an important integral part of Indian dietary and staple food of more than 60 per cent population in India. Chhattisgarh state, famous as \u201cRice bowl\u201d of India, rice occupies an area of 3.7 million hectare with a production of 7.7 million metric tonnes (Anon., 2017). This state is very rich in rice germplasm and large number of indigenous collection is still maintained by the tribal farmers of the state. However, the productivity of rice in the state is much lower than national average productivity level. Chhattisgarh state (a part of the eastern zone) is the most congenial for rice cultivation as well as for disease development. The rice crop is known to suffer by many biotic and abiotic stresses and among biotic stresses, diseases are pivotal one. Among the diseases, bacterial blight, sheath blight, blast, sheath rot and false smut are the most important for this region causing economic yield losses. The rice diseases attack all the growth stages of the plant right from the nursery till the harvest of the crop.", "num_citations": "1\n", "authors": ["497"]}
{"title": "Effect of Seed Treatment and Seed Borne Mycoflora on Vigour of Mungbean [Vigna radiata (L.) Wilczek] Grown in Agro\u2013Climatic Zones of Chhattisgarh, India\n", "abstract": " Among the pulses, mungbean is popularly known as green gram or golden gram is one of the most important short duration pulse grown in India. The seeds are highly nutritious as it contains about 23.86% protein, 62.6% carbohydrates, 1.15% fat, 5.27% crude fibre, 3.32% ash besides rich in lysine (436 mg/g). It is also rich in Ca, Fe, and K is a good source of vitamins such as thiamine, niacin and vitamin A. The total area covered under mungbean in India was 30.41 lakh hectares with a total production of 14.24 lakh tonnes. The national yield average was 468 kg/ha. The lowest yield observed in the state of Karnataka (247 kg/ha) followed by Chhattisgarh (269 kg/ha) and Odisha (337 kg/ha)(Anon., 2016).Contaminated seeds can often result in poor germination and poor seedling vigour, resulting in an un-healthy crop. Field fungus associated with seeds causes deterioration of seed quality, affect viability and reduces germination (Shrivastava and Gupta, 1981). The infected seeds fail to germinate or seedlings and plants developed in the field", "num_citations": "1\n", "authors": ["497"]}
{"title": "Compression clip for fractured bone\n", "abstract": " Methods and devices for fixation of a lateral compression fracture are disclosed. At least one compression device may be provided in a deployer. The deployer may be positioned adjacent to a facture line of a fractured bone. The at least one compression device may be laparoscopically delivered from the deployer to the fractured bone and secured the fractured bone. A compression device may include a central portion and a plurality of arms. The central portion may have a first side surface configured to contact a bone fracture and a second side surface. Each arm may extend from a proximal end attached to the central portion and have a distal end that includes a locking mechanism. Each locking mechanism may include at least one of a conical projection, a barb hook, a claw hook, and a serrated hook.", "num_citations": "1\n", "authors": ["497"]}
{"title": "Seroprevalence of Hepatitis B, Hepatitis C, and human immunodeficiency virus and their risk factors in adolescents in East Sikkim, a Himalayan state of India\n", "abstract": " Background: Sikkim is a northeastern state of India, located in the Himalayas with migratory population from neighboring states and Nepal. Although there is high prevalence of human immunodeficiency virus (HIV) and Hepatitis B and C virus (HBV and HCV) in other northeastern states of India, currently, this information is lacking in Sikkim\u2019s adolescent population, which inspired the researchers to conduct this study. Methods: This is a cross-sectional study with 490 adolescent participants between the age group of13\u201320 years. Schools/colleges and the participants were randomly selected. Blood samples of selected participants were collected after their interview and were tested for anti-HIV, hepatitis B surface antigen and anti-HCV. Findings: Mean age of the participants was 16.96 years. Only 1 (0.2%) participant was positive for HBsAg and none was positive for anti-HIV and anti-HCV. About 92 (18.78%), 90 (18.37%), 79 (16.12%) and 12 (2.45%) participants had respectively undergone tattoo/body piercing, invasive (medical) procedure, shared personal items and had received blood transfusion but none of them provided information on their use of injectable drugs. A total of 33 (6.73%) participants expressed their involvement in heterosexual relation, of which 29 (29/215, 13.49%) were boys and 4 (4/275, 1.45%) were girls (p< 0.01). Among them, 13 (13/33, 39.39%) participants expressed their involvement with multiple sexual partners and16 (16/33, 48.49%) participants had taken protective measures. None of the girls provided history about their partner taking any protective measures. Interpretation: To the best of our knowledge, this is the\u00a0\u2026", "num_citations": "1\n", "authors": ["497"]}
{"title": "Effect of seed priming by seed-borne mycoflora on plant vigour of pigeonpea (Cajanus cajan (l.) millsp.)\n", "abstract": " Seed is the most important input for crop production. Pathogen free healthy seed is urgently needed for desired plant populations and good harvest. Seeds are the efficient carriers for survival, large scale and long distance spread of pathogenic organisms both externally and internally and pigeonpea seeds are not an exception. Pigeonpea seeds are the great sources of protein, amino acids, carbohydrates and a variety of minerals which make the seed liable to attack by a range of seed born mycoflora (Agrawal, 2003). Seed deterioration is an irreversible process and the physiology of seed deterioration is not well understood (McDonald, 1999). Infected or contaminated seeds prove hazardous for the seeds as they cause pre and post emergence losses and finally resulting in reduced germination of seeds, reduction of yield and also spoiled the quality of seeds during storage. Pigeonpea seeds as in other crops, serves as a source of perpetuation of the organisms. Seed health in general and particularly became federal concern due to vast exchange of seed materials within states and beyond the boundaries. The architect of pigeonpea plant is very sturdy yet it attracts 69 fungal, 3 bacterial and 19 viral pathogens causing various diseases (Nene et al. 1996). Detection of mycoflora associated with pigeonpea seeds by virtue of infection, revived the attention of several workers actively engaged in seed health evaluation. Seed health needs to the examined from two angles: First qualitatively, whether seed is infected with micro-organism or otherwise contaminated with such organisms and second to work out the level of such infections or\u00a0\u2026", "num_citations": "1\n", "authors": ["497"]}
{"title": "Software modification aided transient error tolerance for embedded systems: 16th Euromicro Conference on Digital System Design (Euromicro DSD/SEAA)\n", "abstract": " Software modification aided transient error tolerance for embedded systems: 16th Euromicro Conference on Digital System Design (Euromicro DSD/SEAA) \u2014 University of Bristol Skip to main navigation Skip to search Skip to main content University of Bristol Logo Help & Terms of Use Home Profiles Research Units Research Outputs Projects Student theses Datasets Activities Prizes Facilities/Equipment Search by expertise, name or affiliation Software modification aided transient error tolerance for embedded systems: 16th Euromicro Conference on Digital System Design (Euromicro DSD/SEAA) Rishad A Shafik, Jimson Mathew, Dhiraj K Pradhan Department of Computer Science Microelectronics Research output: Chapter in Book/Report/Conference proceeding \u203a Conference Contribution (Conference Proceeding) 2 Citations (Scopus) Overview Original language English Title of host publication 16th Euromicro on - .\u2026", "num_citations": "1\n", "authors": ["497"]}
{"title": "Single-Ended SRAM Bitcell Design\n", "abstract": " In this chapter, a case study of six-transistor (6T) Single-Ended Static Random Access Memory (SE-SRAM) bitcell with an isolated read-current path and its word-oriented array organization, suitable for low-V               DD              and low-power embedded systems is presented. The SE-SRAM has a strong 2. 65 \u00d7 worst-case read Static Noise Margin (SNM) compared to a standard 6T bitcell and equivalent to an 8T bitcell from existing literature. The previously proposed single-ended bitcell topologies and their advantages and disadvantages are also highlighted with respect SE 6T SRAM bitcell. The SE 6T bitcell and its word-orientation, and how it departs from the existing topologies are discussed in detail. A comparison of noise margins, power and performance with standard 6T and 8T SRAM bitcells is also presented.", "num_citations": "1\n", "authors": ["497"]}
{"title": "2-Port SRAM Bitcell Design\n", "abstract": " A low power, minimum transistor count and fast access Static Random Access Memories (SRAMs) are essential for embedded multimedia and communication applications realized using System-on-Chip (SoC) technology. Hence, simultaneous or parallel read/write (R/W) access multi-port SRAM bitcells are widely employed in such embedded systems to enhance the memory bandwidth. In this chapter, multi-port SRAM bitcells are studied and their merits and de-merits are highlighted. A case study of 2-port six transistors (6T) SRAM bitcell with multi-port capabilities at reduced area overhead as compared to existing 2-port 7T and 8T SRAM bitcells, is also presented. A major challenge in designing the multi-port SRAM bitcells is maintaining the simultaneous read and write access without hampering the stability of neighbouring bitcells is a prime concern for which an array organization is also discussed which\u00a0\u2026", "num_citations": "1\n", "authors": ["497"]}
{"title": "A variation-aware Taylor expansion diagram-based approach for nano-CMOS register-transfer level leakage optimization\n", "abstract": " As the CMOS technology scales down to nanometer regime the process variations have profound effect on circuit attributes. Meeting timing and power constraints under such process variations in nano-CMOS circuit design is becoming increasingly difficult. A shifting from worst-case based analysis and optimization to statistical or probability based analysis and optimization at every level of circuit abstraction has happened. This paper presents a Taylor Expansion Diagram (TED) based approach for statistical optimization during high-level synthesis (HLS). A variation-aware simultaneous scheduling and resource binding algorithm is proposed which maximizes the power yield under timing yield and performance constraint. For this purpose, a multiple-oxide thickness (multi-Tox ) library at 45 nm CMOS is characterized under process variation. The delay and power distribution of different functional units are accurately\u00a0\u2026", "num_citations": "1\n", "authors": ["497"]}
{"title": "Energy-efficient address generation units and their design methodology\n", "abstract": " Modern embedded systems, especially nomadic embedded systems, are becoming more and more complex, and they often require both high performance and low energy consumption. To achieve both requirements, exploiting ILP (instruction level parallelism) and DLP (data level parallelism) of embedded applications are well known to be good solutions. High-level compiler optimizations like data flow and loop transformations targeted toward data memory sub-systems have been shown to achieve high performance and low energy consumption. Such techniques transform C code to improve spatial and temporal locality of data and reduce unnecessary memory access. By improving data locality in the application loops, this data can be stored within a smaller memory footprint so that accesses to larger memories like level 1 (or higher) memories are drastically reduced. These transformations decrease the quantity\u00a0\u2026", "num_citations": "1\n", "authors": ["497"]}
{"title": "Computer-Aided Design for Energy Optimization in the Memory Architecture of Embedded Systems\n", "abstract": " Digital systems had initially only one main design metric: performance. Other cost parameters such as area, energy consumption, or testability were regarded as design constraints. In the early nineties, the role of power consumption changed from that of a design constraint to an actual design metric. This shift occurred due to technological reasons: higher integration and higher frequencies led to a significant increase in power consumption. 1 The technology used to implement a digital design influences the analysis of the power consumption. For instance, in the complementary metal-oxidesemiconductor (CMOS) device, there are three sources of power dissipation.", "num_citations": "1\n", "authors": ["497"]}
{"title": "DOE-ILP Based Simultaneous Power and Read Stability Optimization in Nano-CMOS SRAM\n", "abstract": " This paper presents a novel design flow and algorithms for simultaneous power-stability optimization of nano-CMOS static random access memory (SRAM) circuits. A 45 nm single-ended seven transistor SRAM has been used as case study. The SRAM cell is subjected to a dual-VTh assignment based on a novel combined Design of Experiments and Integer Linear Programming (DOE-ILP) approach, resulting in 50.6% power reduction (including leakage) and 43.9% increase in the read static noise margin over the baseline design. The process variation analysis of the optimized cell is performed considering the variability effect in twelve device parameters. An 8\u00d7 8 array is constructed to show the feasibility of the proposed SRAM cell. To the best of the authors' knowledge, this is the first research reporting the use of DOE and ILP for optimization of conflicting targets of power and stability in SRAM.", "num_citations": "1\n", "authors": ["497"]}
{"title": "Simplified bit parallel systolic multipliers for special class of galois field (2m) with testability\n", "abstract": " This study presents a simplified structure of bit parallel systolic multiplier over Galois fields (GFs) over the set GF(2 m ) suitable for cryptographic hardware implementation. A redundant standard basis representation with the irreducible all one polynomial is considered. The systolic multiplier consists of ( m +1) 2  identical cells, each consisting of one two-input AND gate, one two-input XOR gate and two one-bit latches. This architecture is well suited to very large-scale integration implementation because of its regularity modular structure and unidirectional data flow. The proposed multipliers have clock cycle latency of ( m  +1). This architecture has a total reduction of  m 2  D-flip-flops compared to earlier bit parallel systolic multiplication architecture. As the finite-field multiplier is one of the complex blocks in cryptographic hardware and need secure testability to avoid unwanted access into the on-chip security blocks\u00a0\u2026", "num_citations": "1\n", "authors": ["497"]}
{"title": "Fault tolerant nanocomputing\n", "abstract": " This chapter provides an overview of fault tolerant nanocomputing. In general, fault tolerant computing can be defined as the process by which a computing system continues to perform its specified tasks correctly in presence of faults with the goal of improving the dependability of the system. Principles of fault tolerant nanocomputing as well as applications of the fault tolerant nanocomputers are discussed. The chapter concludes by observing trends in the fault tolerant nanocomputing.", "num_citations": "1\n", "authors": ["497"]}
{"title": "On the synthesis of bit-parallel Galois field multipliers with on-line SEC and DED\n", "abstract": " In this paper, we present a systematic method for designing single error correcting (SEC) and double error detecting finite field (Galois field) multipliers over GF(2                   m                ). The detection and correction are done on-line. We use multiple Parity Predictions to detect and correct errors. Specifically, a structural approach is first presented. The predicted parity bits are derived from the primitive polynomials for generating the fields. Further, a hybrid approach is presented where the multipliers and PP circuits are synthesised, and the decoding and correction circuits are structurally combined to form the complete error correcting designs. Although the article considers only a finite field multiplier, without loss of generality, the technique could be applied to any combinational logic circuit. Our technique, when compared with existing techniques, gives better performance. We show that our SEC multipliers over GF(2\u00a0\u2026", "num_citations": "1\n", "authors": ["497"]}
{"title": "A novel error correction technique for adjacent errors\n", "abstract": " Memories are one of the most widely used elements in electronic systems, and their reliability when exposed to Single Events Upsets (SEUs) has been studied extensively. As transistor sizes shrink, Multiple Bits Upsets (MBUs) are becoming an increasingly important factor in the reliability of memories exposed to radiation effects. To address this issue, Built-in Current Sensors (BICS) or Parity codes have recently been applied in conjunction with Single Error Correction/Double Error Detection (SEC-DED) codes to protect memories from MBUs. In this paper, this approach is taken one step further, proposing specific codes optimized to provide protection against errors in adjacent bits in memories. By exploiting the locality of errors within an MBU and the error detection and location capabilities of parity codes, the proposed codes result in both a better protection level and a reduced cost. This techniques improves\u00a0\u2026", "num_citations": "1\n", "authors": ["497"]}
{"title": "Reliability aware yield improvement technique for nanotechnology based circuits\n", "abstract": " Lithography based IC manufacturing is approaching its physical limits in terms of feature size. In this scenario, nanotechnology based manufacturing, relying on self-assembly of nanotubes or nanowires, has been predicted as an alternative to CMOS technology. However, such processes are expected to have high defect density and therefore must be handled through effective defect tolerant techniques. In this paper, an innovative technique is proposed, which for a given circuit size utilizes different combinations of defect-free crossbars to build the desired circuit with improved yield. The goal of the proposed approach is to increase the number of defect free crossbars and the total yield, by connecting defect free subsets together. The reliability of the resulting circuits has been estimated, and the results have shown that the application of the proposed approach provides significant yield improvement, but also may\u00a0\u2026", "num_citations": "1\n", "authors": ["497"]}
{"title": "Introduction to design techniques for energy harvesting\n", "abstract": " There is a growing interest in emerging energy harvesting methods, which have become more realistic in recent years. Thus, energy scavenging approaches are now considered real contenders as an alternative for powering ubiquitously deployed mobile and wireless electronic devices such as sensor network nodes. Low-power and energy-efficient circuits and systems have always attracted attention, however, there is a significant increase in demand for their usage and research to improve them in recent years. This demand is driven by several factors such as increasing energy costs for medium-to-large systems and the lack of sufficient battery power for ever increasing functionality of small and mobile devices. Further, mobility makes energy harvesting even more crucial. This special issue reports the recent advances in the emerging energy harvesting area as well as in energy-efficient circuits and systems. In\u00a0\u2026", "num_citations": "1\n", "authors": ["497"]}
{"title": "Fast SEU Detection and LUT Configuration Bits of SRAM-based FPGAs\n", "abstract": " HR, Z., SG, M., Costas, A., & Pradhan, D.(2007). Fast SEU Detection and LUT Configuration Bits of SRAM-based FPGAs. In Proceedings of 14th IEEE Reconfigurable Architecture Workshop, in associated with IPDPS http://www. cs. bris. ac. uk/Publications/pub_master. jsp? id= 2000675", "num_citations": "1\n", "authors": ["497"]}
{"title": "Efficient Method to Tolerate Multiple Bit Upsets in SRAM Memory\n", "abstract": " Efficient Method to Tolerate Multiple Bit Upsets in SRAM Memory \u2014 University of Bristol Skip to main navigation Skip to search Skip to main content University of Bristol Logo Help & Terms of Use Home Profiles Research Units Research Outputs Projects Student theses Datasets Activities Prizes Facilities/Equipment Search by expertise, name or affiliation Efficient Method to Tolerate Multiple Bit Upsets in SRAM Memory Argyrides Costas, Zarandi HR, Dhiraj Pradhan Department of Computer Science Research output: Chapter in Book/Report/Conference proceeding \u203a Conference Contribution (Conference Proceeding) Overview Translated title of the contribution \u201cEfficient Method to Tolerate Multiple Bit Upsets in SRAM Memory\u201d Original language English Title of host publication Proceedings of European Test Symposium (ETS) Publication status Published - 2007 Bibliographical note Other page information: - /Title of : of \u2026", "num_citations": "1\n", "authors": ["497"]}
{"title": "Recent advances in verification, equivalence checking & SAT solvers\n", "abstract": " Design flow, RTL-verification, Simulation-based techniques, basic concepts of equivalence'checking, combinational equivatence checking, ATPG-based techniques, compare point matching, mitering, don't cares, solver overview (structura! verification, BDD-based so! vers, SAT-based solvers), Decision Diagrams (BDDs, zBDDs, mBdds).", "num_citations": "1\n", "authors": ["497"]}
{"title": "Cooperating diverse experts: a methodology to develop quality software for critical decision support systems\n", "abstract": " The problem of developing software for critical systems in the decision support context is considered. The limitations of existing software development methodologies are mentioned and a new methodology, cooperating diverse experts (CDE), is proposed. This new methodology draws upon techniques used in multiple version software and in distributed recovery blocks. The methodology relies upon the ultrareliable development of a parameterizable arbitrator to administer the cooperation of multiple diverse implementations (interpretations) of the decision support problem. CDE may be used to develop a single reliable software module or it may be used as an operational system in which some modules are multiply implemented.< >", "num_citations": "1\n", "authors": ["497"]}
{"title": "ATPG-based Transformations for Random-Pattern Testable Logic Synthesis\n", "abstract": " A new approach to designing random pattern testable logic circuits is introduced. The synthesis methodology proposed here begins with a multi-level circuit and synthesizes the circuit, optimizing its area and enhancing its random pattern testability. The method is based on ATPG-based transformations. A scheme is presented to guide the synthesis process and introduces certain new transformations which enhance the sensitivity of the circuit. Previous approaches either do not consider random pattern testability, or enhance random pattern testability only when beginning from a two-level circuit representation. The proposed method can take these synthesized multi-level circuits as inputs, further processing them to enhance random testability. In fact, the experimental results demonstrate that the proposed method can be successfully applied on circuits synthesized by a logic synthesis tool (tstfx), with a large reduction in area as well as a gain in random testability. It is possible that the new transformations introduced in the paper can cover new search spaces during optimization, thus aiding in area optimization.", "num_citations": "1\n", "authors": ["497"]}
{"title": "Issues in location man agement in mobile systems\n", "abstract": " Integrated voice and data applications will be used by millions of users often moving in a very heavy urban tra c conditions. In order to communicate with an user, one needs to know the user's location. Thus, the network faces a problem of continuously keeping track of the location of each and every user. Location management is one of the most important issues in distributed mobile computing. Location updates will become a major bottleneck in future PCNs, and mechanisms to control the cost of location updates are needed. A trade-o exists between the cost of updates and cost of searches. The goal of a good location management scheme should be to operate at the\\knee point\" of the update and search tradeo curve. In this paper we are going to present an overview of our work on location management in distributed mobile environments. We classify the space of location management based on di erent characteristics, and present schemes for each of them. The proposed schemes share a common goal of avoiding unnecessary updates without a ecting the search costs.", "num_citations": "1\n", "authors": ["497"]}
{"title": "A new algorithm for order statistic\n", "abstract": " A new algorithm for rank filtering and stack filtering is presented here. This algorithm is simple and results in fast and easy implementations. It is based on transforming the given sequence into equivalent rank preserving sequences by means of bit manipulation. The algorithm can also implement stack filters without requiring threshold decomposition.", "num_citations": "1\n", "authors": ["497"]}
{"title": "Application specific VLSI architectures based on De Bruijn graphs\n", "abstract": " The author provides an overview of various key features of De Bruijn graph-based VLSI architectures. The advantages of De Bruijn architectures over such other architectures as cube and shuffle-exchange are discussed. Important differences between De Bruijn interconnects and others are also described. The evolution of the De Bruijn interconnect is described. The FFT architecture and the Viterbi decoder for convolutional codes are examined in detail. The issues of routing and fault tolerance are addressed.< >", "num_citations": "1\n", "authors": ["497"]}
{"title": "Fault-tolerant computing: An introduction\n", "abstract": " FIFTEEN years ago, the term fault-tolerant computing made its first widespread appearance in the technical literature. In March of 1971, the Digest of the First International Symposium on Fault-Tolerant Computing appeared, followed in November by the First Special Issue on Fault- Tolerant Computing of the IEEE TRANSACTIONS ON COMPUTERS. More than any other, these two publications\u2014the Digests of the FTC Symposia and the Special Issues on Fault- Tolerant Computing\u2014have mirrored the advances in fault- tolerant computing over the last decade and a half. From over 100 submissions\u2014a record high\u2014received for this ninth Special Issue, 24 were selected for publication. These 9 papers and 15 correspondence items certainly continue this proud tradition.", "num_citations": "1\n", "authors": ["497"]}
{"title": "Testing for Delay Faults in a PLA\n", "abstract": " However, this is an impractical task for complex LSI and VLSI devices. This paper presents a test generation tech-nique to detect delay faults that are caused by an excessive propagation delay time in PLA logic. Due to unprogrammed devices in a PLA, the procedure should be different from that used for random logic circuits. It also shows that a test set for missing-device crosspoints faults con-stitutes a part of the test set for delay faults.", "num_citations": "1\n", "authors": ["497"]}
{"title": "A Fault-Diagnosis Technique for Closed Flow Networks.\n", "abstract": " Closed flow networks represent a mathematical model for transportation networks multiple resource computer systems and computer communication networks. A fault-diagnosis technique for these networks is presented which can locate all single edge failures in the network. This technique is based on a flow casualty relationship developed here. The number of edges that need to be monitored is shown to be n-1 for an n-node network. These edges constitute the branches of a tree in the network. AuthorDescriptors:", "num_citations": "1\n", "authors": ["497"]}
{"title": "Canonical Graph-based Representations for Verification of Logic and Arithmetic Designs\n", "abstract": " Dhiraj K. Pradhan Department of Computer Science University of Bristol Bristol BS8 1UB, UK E-mail: pradhan@ cs. bris. ac. uk", "num_citations": "1\n", "authors": ["497"]}