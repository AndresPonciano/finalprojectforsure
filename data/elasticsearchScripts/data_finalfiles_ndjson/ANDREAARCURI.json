{"title": "A practical guide for using statistical tests to assess randomized algorithms in software engineering\n", "abstract": " Randomized algorithms have been used to successfully address many different types of software engineering problems. This type of algorithms employ a degree of randomness as part of their logic. Randomized algorithms are useful for difficult problems where a precise solution cannot be derived in a deterministic way within reasonable time. However, randomized algorithms produce different results on every run when applied to the same problem instance. It is hence important to assess the effectiveness of randomized algorithms by collecting data from a large enough number of runs. The use of rigorous statistical tests is then essential to provide support to the conclusions derived by analyzing such data. In this paper, we provide a systematic review of the use of randomized algorithms in selected software engineering venues in 2009. Its goal is not to perform a complete survey but to get a representative snapshot\u00a0\u2026", "num_citations": "809\n", "authors": ["166"]}
{"title": "A hitchhiker's guide to statistical tests for assessing randomized algorithms in software engineering\n", "abstract": " Randomized algorithms are widely used to address many types of software engineering problems, especially in the area of software verification and validation with a strong emphasis on test automation. However, randomized algorithms are affected by chance and so require the use of appropriate statistical tests to be properly analysed in a sound manner. This paper features a systematic review regarding recent publications in 2009 and 2010 showing that, overall, empirical analyses involving randomized algorithms in software engineering tend to not properly account for the random nature of these algorithms. Many of the novel techniques presented clearly appear promising, but the lack of soundness in their empirical evaluations casts unfortunate doubts on their actual usefulness. In software engineering, although there are guidelines on how to carry out empirical analyses involving human subjects, those\u00a0\u2026", "num_citations": "420\n", "authors": ["166"]}
{"title": "Random testing: Theoretical results and practical implications\n", "abstract": " A substantial amount of work has shed light on whether random testing is actually a useful testing technique. Despite its simplicity, several successful real-world applications have been reported in the literature. Although it is not going to solve all possible testing problems, random testing appears to be an essential tool in the hands of software testers. In this paper, we review and analyze the debate about random testing. Its benefits and drawbacks are discussed. Novel results addressing general questions about random testing are also presented, such as how long does random testing need, on average, to achieve testing targets (e.g., coverage), how does it scale, and how likely is it to yield similar results if we rerun it on the same testing problem (predictability). Due to its simplicity that makes the mathematical analysis of random testing tractable, we provide precise and rigorous answers to these questions. Results\u00a0\u2026", "num_citations": "180\n", "authors": ["166"]}
{"title": "Adaptive random testing: An illusion of effectiveness?\n", "abstract": " Adaptive Random Testing (ART) has been proposed as an enhancement to random testing, based on assumptions on how failing test cases are distributed in the input domain. The main assumption is that failing test cases are usually grouped into contiguous regions. Many papers have been published in which ART has been described as an effective alternative to random testing when using the average number of test case executions needed to find a failure (F-measure). But all the work in the literature is based either on simulations or case studies with unreasonably high failure rates. In this paper, we report on the largest empirical analysis of ART in the literature, in which 3727 mutated programs and nearly ten trillion test cases were used. Results show that ART is highly inefficient even on trivial problems when accounting for distance calculations among test cases, to an extent that probably prevents its practical\u00a0\u2026", "num_citations": "159\n", "authors": ["166"]}
{"title": "On the automation of fixing software bugs\n", "abstract": " Software Testing can take up to half of the resources of the development of new software. Although there has been a lot of work on automating the testing phase, fixing a bug after its presence has been discovered is still a duty of the programmers. Techniques to help the software developers for locating bugs exist though, and they take name of Automated Debugging. However, to our best knowledge, there has been only little attempt in the past to completely automate the actual changing of the software for fixing the bugs. Therefore, in this paper we propose an evolutionary approach to automate the task of fixing bugs. The basic idea is to evolve the programs (eg, by using Genetic Programming) with a fitness function that is based on how many unit tests they are able to pass. If a formal specification of the buggy software is given, more sophisticated fitness functions can be designed. Moreover, by using the formal\u00a0\u2026", "num_citations": "146\n", "authors": ["166"]}
{"title": "Black-box system testing of real-time embedded systems using random and search-based testing\n", "abstract": " Testing real-time embedded systems (RTES) is in many ways challenging. Thousands of test cases can be potentially executed on an industrial RTES. Given the magnitude of testing at the system level, only a fully automated approach can really scale up to test industrial RTES. In this paper we take a black-box approach and model the RTES environment using the UML/MARTE international standard. Our main motivation is to provide a more practical approach to the model-based testing of RTES by allowing system testers, who are often not familiar with the system design but know the application domain well-enough, to model the environment to enable test automation. Environment models can support the automation of three tasks: the code generation of an environment simulator, the selection of test cases, and the evaluation of their expected results (oracles). In this paper, we focus on the second task (test\u00a0\u2026", "num_citations": "124\n", "authors": ["166"]}
{"title": "Evolutionary repair of faulty software\n", "abstract": " Testing and fault localization are very expensive software engineering tasks that have been tried to be automated. Although many successful techniques have been designed, the actual change of the code for fixing the discovered faults is still a human-only task. Even in the ideal case in which automated tools could tell us exactly where the location of a fault is, it is not always trivial how to fix the code. In this paper we analyse the possibility of automating the complex task of fixing faults. We propose to model this task as a search problem, and hence to use for example evolutionary algorithms to solve it. We then discuss the potential of this approach and how its current limitations can be addressed in the future. This task is extremely challenging and mainly unexplored in the literature. Hence, this paper only covers an initial investigation and gives directions for future work. A research prototype called JAFF and a case\u00a0\u2026", "num_citations": "117\n", "authors": ["166"]}
{"title": "It really does matter how you normalize the branch distance in search\u2010based software testing\n", "abstract": " The use of search algorithms for test data generation has seen many successful results. For structural criteria like branch coverage, heuristics have been designed to help the search. The most common heuristic is the use of approach level (usually represented with an integer) to reward test cases whose executions get close (in the control flow graph) to the target branch. To solve the constraints of the predicates in the control flow graph, the branch distance is commonly employed. These two measures are linearly combined. Since the approach level is more important, the branch distance is normalized, often in the range [0, 1]. In this paper, different types of normalizing functions are analyzed. The analyses show that the one that is usually employed in the literature has several flaws. The paper presents a different normalizing function that is very simple and does not suffer from these limitations. Empirical and\u00a0\u2026", "num_citations": "96\n", "authors": ["166"]}
{"title": "It does matter how you normalise the branch distance in search based software testing\n", "abstract": " The use of search algorithms for test data generation has seen many successful results. For structural criteria such as branch coverage, heuristics have been designed to help the search. The most common heuristic is the use of approach level (usually represented with an integer) to reward test cases whose executions get close (in the control flow graph)to the target branch. To solve the constraints of the predicates in the control flow graph, the branch distance is commonly employed. These two measures are linearly combined. Because the approach level is more important, the branch distance is normalised, often in the range. In this paper, we analyse different types of normalising functions. We found out that the one that is usually employed in the literature has several flaws. We hence propose a different normalizing function that is very simple and that does not suffer of these limitations. We carried out empirical\u00a0\u2026", "num_citations": "94\n", "authors": ["166"]}
{"title": "Formal analysis of the effectiveness and predictability of random testing\n", "abstract": " There has been a lot of work to shed light on whether random testing is actually a useful testing technique. Despite its simplicity, several successful real-world applications appear in the literature. Although it is not going to solve all possible testing problems, random testing is an essential tool in the hands of software testers. In this paper, we address general questions about random testing, such as how long random testing needs on average to achieve testing targets (eg, coverage), how does it scale and how likely is it to yield similar results if we re-run random testing on the same testing problem. Due to its simplicity that makes the mathematical analysis of random testing tractable, we provide precise and rigorous answers to these questions. Our formal results can be applied to most types of software and testing criteria. Simulations are carried out to provide further support to our formal results. The obtained results\u00a0\u2026", "num_citations": "91\n", "authors": ["166"]}
{"title": "A search-based OCL constraint solver for model-based test data generation\n", "abstract": " Model-based testing (MBT) aims at automated, scalable, and systematic testing solutions for complex industrial software systems. To increase chances of adoption in industrial contexts, software systems should be modeled using well-established standards such as the Unified Modeling Language (UML) and Object Constraint Language (OCL). Given that test data generation is one of the major challenges to automate MBT, this is the topic of this paper with a specific focus on test data generation from OCL constraints. Though search-based software testing (SBST) has been applied to test data generation for white-box testing (e.g., branch coverage), its application to the MBT of industrial software systems has been limited. In this paper, we propose a set of search heuristics based on OCL constraints to guide test data generation and automate MBT in industrial applications. These heuristics are used to develop an\u00a0\u2026", "num_citations": "77\n", "authors": ["166"]}
{"title": "Formal analysis of the probability of interaction fault detection using random testing\n", "abstract": " Modern systems are becoming highly configurable to satisfy the varying needs of customers and users. Software product lines are hence becoming a common trend in software development to reduce cost by enabling systematic, large-scale reuse. However, high levels of configurability entail new challenges. Some faults might be revealed only if a particular combination of features is selected in the delivered products. But testing all combinations is usually not feasible in practice, due to their extremely large numbers. Combinatorial testing is a technique to generate smaller test suites for which all combinations of t features are guaranteed to be tested. In this paper, we present several theorems describing the probability of random testing to detect interaction faults and compare the results to combinatorial testing when there are no constraints among the features that can be part of a product. For example, random\u00a0\u2026", "num_citations": "70\n", "authors": ["166"]}
{"title": "RESTful API automated test case generation with EvoMaster\n", "abstract": " RESTful APIs are widespread in industry, especially in enterprise applications developed with a microservice architecture. A RESTful web service will provide data via an API over the network using HTTP, possibly interacting with databases and other web services. Testing a RESTful API poses challenges, because inputs/outputs are sequences of HTTP requests/responses to a remote server. Many approaches in the literature do black-box testing, because often the tested API is a remote service whose code is not available. In this article, we consider testing from the point of view of the developers, who have full access to the code that they are writing. Therefore, we propose a fully automated white-box testing approach, where test cases are automatically generated using an evolutionary algorithm. Tests are rewarded based on code coverage and fault-finding metrics. However, REST is not a protocol but rather a set\u00a0\u2026", "num_citations": "67\n", "authors": ["166"]}
{"title": "Environment modeling and simulation for automated testing of soft real-time embedded software\n", "abstract": " Given the challenges of testing at the system level, only a fully automated approach can really scale up to industrial real-time embedded systems (RTES). Our goal is to provide a practical approach to the model-based testing of RTES by allowing system testers, who are often not familiar with the system\u2019s design but are application domain experts, to model the system environment in such a way as to enable its black-box test automation. Environment models can support the automation of three tasks: the code generation of an environment simulator to enable testing on the development platform or without involving actual hardware, the selection of test cases, and the evaluation of their expected results (oracles). From a practical standpoint\u2014and such considerations are crucial for industrial adoption\u2014environment modeling should be based on modeling standards (1) that are at an adequate level of\u00a0\u2026", "num_citations": "62\n", "authors": ["166"]}
{"title": "Empirical investigation of search algorithms for environment model-based testing of real-time embedded software\n", "abstract": " System testing of real-time embedded systems (RTES) is a challenging task and only a fully automated testing approach can scale up to the testing requirements of industrial RTES. One such approach, which offers the advantage for testing teams to be black-box, is to use environment models to automatically generate test cases and oracles and an environment simulator to enable earlier and more practical testing. In this paper, we propose novel heuristics for search-based, RTES system testing which are based on these environment models. We evaluate the fault detection effectiveness of two search-based algorithms, ie, Genetic Algorithms and (1+ 1) Evolutionary Algorithm, when using these novel heuristics and their combinations. Preliminary experiments on 13 carefully selected, non-trivial artificial problems, show that, under certain conditions, these novel heuristics are effective at bringing the environment into\u00a0\u2026", "num_citations": "58\n", "authors": ["166"]}
{"title": "Longer is better: On the role of test sequence length in software testing\n", "abstract": " In the presence of an internal state, often it is required a sequence of function calls to test software. In fact, to cover a particular branch of the code, a sequence of previous function calls might be required to put the internal state in the appropriate configuration. Internal states are not only present in object-oriented software, but also in procedural software(e.g., static variables in C programs). In the literature, there are many techniques to test this type of software. However, to our best knowledge, the properties related to choosing the length of these sequences have received only little attention in the literature. In this paper, we analyse the role that the length plays in software testing, in particular branch coverage. We show that on \u201cdifficult\u201d software testing benchmarks longer test sequences make their testing trivial. Hence, we argue that the choice of the length of the test sequences is very important in software testing.", "num_citations": "55\n", "authors": ["166"]}
{"title": "A theoretical and empirical analysis of the role of test sequence length in software testing for structural coverage\n", "abstract": " In the presence of an internal state, often a sequence of function calls is required to test software. In fact, to cover a particular branch of the code, a sequence of previous function calls might be required to put the internal state in the appropriate configuration. Internal states are not only present in object-oriented software, but also in procedural software (e.g., static variables in C programs). In the literature, there are many techniques to test this type of software. However, to the best of our knowledge, the properties related to the choice of the length of these sequences have received only a little attention in the literature. In this paper, we analyze the role that the length plays in software testing, in particular branch coverage. We show that, on \u201cdifficult\u201d software testing benchmarks, longer test sequences make their testing trivial. Hence, we argue that the choice of the length of the test sequences is very important in software\u00a0\u2026", "num_citations": "52\n", "authors": ["166"]}
{"title": "Environment modeling with UML/MARTE to support black-box system testing for real-time embedded systems: Methodology and industrial case studies\n", "abstract": " The behavior of real-time embedded systems (RTES) is driven by their environment. Independent system test teams normally focus on black-box testing as they have typically no easy access to precise design information. Black-box testing in this context is mostly about selecting test scenarios that are more likely to lead to unsafe situations in the environment. Our Model-Based Testing (MBT) methodology explicitly models key properties of the environment, its interactions with the RTES, and potentially unsafe situations triggered by failures of the RTES under test. Though environment modeling is not new, we propose a precise methodology fitting our specific purpose, based on a language that is familiar to software testers, that is the UML and its extensions, as opposed to technologies geared towards simulating natural phenomena. Furthermore, in our context, simulation should only be concerned with what\u00a0\u2026", "num_citations": "48\n", "authors": ["166"]}
{"title": "An experience report on applying software testing academic results in industry: we need usable automated test generation\n", "abstract": " What is the impact of software engineering research on current practices in industry? In this paper, I report on my direct experience as a PhD/post-doc working in software engineering research projects, and then spending the following five years as an engineer in two different companies (the first one being the same I worked in collaboration with during my post-doc). Given a background in software engineering research, what cutting-edge techniques and tools from academia did I use in my daily work when developing and testing the systems of these companies? Regarding validation and verification (my main area of research), the answer is rather short: as far as I can tell, only FindBugs. In this paper, I report on why this was the case, and discuss all the challenging, complex open problems we face in industry and which somehow are \u201cneglected\u201d in the academic circles. In particular, I will first discuss what\u00a0\u2026", "num_citations": "38\n", "authors": ["166"]}
{"title": "RESTful API automated test case generation\n", "abstract": " Nowadays, web services play a major role in the development of enterprise applications. Many such applications are now developed using a service-oriented architecture (SOA), where microservices is one of its most popular kind. A RESTful web service will provide data via an API over the network using HTTP, possibly interacting with databases and other web services. Testing a RESTful API poses challenges, as inputs/outputs are sequences of HTTP requests/responses to a remote server. Many approaches in the literature do black-box testing, as the tested API is a remote service whose code is not available. In this paper, we consider testing from the point of view of the developers, which do have full access to the code that they are writing. Therefore, we propose a fully automated white-box testing approach, where test cases are automatically generated using an evolutionary algorithm. Tests are rewarded\u00a0\u2026", "num_citations": "35\n", "authors": ["166"]}
{"title": "Test suite generation with the Many Independent Objective (MIO) algorithm\n", "abstract": " Context: Automatically generating test suites is intrinsically a multi-objective problem, as any of the testing targets (eg, statements to execute or mutants to kill) is an objective on its own. Test suite generation has peculiarities that are quite different from other more regular optimization problems. For example, given an existing test suite, one can add more tests to cover the remaining objectives. One would like the smallest number of small tests to cover as many objectives as possible, but that is a secondary goal compared to covering those targets in the first place. Furthermore, the amount of objectives in software testing can quickly become unmanageable, in the order of (tens/hundreds of) thousands, especially for system testing of industrial size systems. Objective: To overcome these issues, different techniques have been proposed, like for example the Whole Test Suite (WTS) approach and the Many-Objective\u00a0\u2026", "num_citations": "31\n", "authors": ["166"]}
{"title": "Theoretical analysis of local search in software testing\n", "abstract": " The field of search based software engineering lacks of theoretical foundations. In this paper we theoretically analyse local search algorithms applied to software testing. We consider an infinitely large class of software that has an easy search landscape. Although the search landscape is easy, the software can be arbitrarily complex and large. We prove that Hill Climbing asymptotically has a strictly better runtime than Random Search. However, we prove that a very fast variant of Hill Climbing on reasonable size of software actually does not scale up properly. Although that variant has an exponential runtime, we prove that asymptotically it is still better than Random Search. We show that even on the easiest software testing problems, more sophisticated algorithms than local search are still required to get better performance.", "num_citations": "31\n", "authors": ["166"]}
{"title": "Full theoretical runtime analysis of alternating variable method on the triangle classification problem\n", "abstract": " Runtime Analysis is a type of theoretical investigation that aims to determine, via rigorous mathematical proofs,the time a search algorithm needs to find an optimal solution.This type of investigation is useful to understand why a search algorithm could be successful, and it gives insight of how search algorithms work. In previous work,we proved the runtimes of different search algorithms on the test data generation for the Triangle Classification (TC)problem. We theoretically proved that Alternating Variable Method (AVM) has the best performance on the coverage of the most difficult branch in our empirical study. In this paper,we prove that the runtime of AVM on all the branches of TC is O((log n) 2 ). That is necessary and sufficient to prove that AVM has a better runtime on TC compared to the other search algorithms we previously analysed. The theorems in this paper are useful for future analyses. In fact, to state theta\u00a0\u2026", "num_citations": "27\n", "authors": ["166"]}
{"title": "Evomaster: Evolutionary multi-context automated system test generation\n", "abstract": " This paper presents EVOMASTER, an open-source tool that is able to automatically generate system level test cases using evolutionary algorithms. Currently, EVOMASTER targets RESTful web services running on JVM technology, and has been used to find several faults in existing open-source projects. We discuss some of the architectural decisions made for its implementation, and future work.", "num_citations": "25\n", "authors": ["166"]}
{"title": "Automatic software generation and improvement through search based techniques\n", "abstract": " Writing software is a difficult and expensive task. Its automation is hence very valuable. Search algorithms have been successfully used to tackle many software engineering problems. Unfortunately, for some problems the traditional techniques have been of only limited scope, and search algorithms have not been used yet. We hence propose a novel framework that is based on a co-evolution of programs and test cases to tackle these difficult problems. This framework can be used to tackle software engineering tasks such as Automatic Refinement, Fault Correction and Improving Non-functional Criteria. These tasks are very difficult, and their automation in literature has been limited. To get a better understanding of how search algorithms work, there is the need of a theoretical foundation. That would help to get better insight of search based software engineering. We provide first theoretical analyses for search based software testing, which is one of the main components of our co-evolutionary framework. This thesis gives the important contribution of presenting a novel framework, and we then study its application to three difficult software engineering problems. In this thesis we also give the important contribution of defining a first theoretical foundation.", "num_citations": "23\n", "authors": ["166"]}
{"title": "Insight knowledge in search based software testing\n", "abstract": " Software testing can be re-formulated as a search problem, hence search algorithms (eg, Genetic Algorithms) can be used to tackle it. Most of the research so far has been of empirical nature, in which novel proposed techniques have been validated on software testing benchmarks. However, only little attention has been spent to understand why meta-heuristics can be effective in software testing. This insight knowledge could be used to design novel more successful techniques. Recent theoretical work has tried to fill this gap, but it is very complex to carry out. This has limited its scope so far to only small problems. In this paper, we want to get insight knowledge on a difficult software testing problem. We combine together an empirical and theoretical analysis, and we exploit the benefits of both.", "num_citations": "19\n", "authors": ["166"]}
{"title": "Many independent objective (MIO) algorithm for test suite generation\n", "abstract": " Automatically generating test suites is intrinsically a multi-objective problem, as any of the testing targets (e.g., statements to execute or mutants to kill) is an objective on its own. Test suite generation has peculiarities that are quite different from other more regular optimisation problems. For example, given an existing test suite, one can add more tests to cover the remaining objectives. One would like the smallest number of small tests to cover as many objectives as possible, but that is a secondary goal compared to covering those targets in the first place. Furthermore, the amount of objectives in software testing can quickly become unmanageable, in the order of (tens/hundreds of) thousands, especially for system testing of industrial size systems. Traditional multi-objective optimisation algorithms can already start to struggle with just four or five objectives to optimize. To overcome these issues, different\u00a0\u2026", "num_citations": "16\n", "authors": ["166"]}
{"title": "Resource-based test case generation for restful web services\n", "abstract": " Nowadays, RESTful web services are widely used for building enterprise applications. In this paper, we propose an enhanced search-based method for automated system test generation for RESTful web services. This method exploits domain knowledge on the handling of HTTP resources, and it is integrated in the Many Independent Objectives (MIO) search algorithm. MIO is an evolutionary algorithm specialized for system test case generation with the aim of maximizing code coverage and fault finding. Our approach builds on top of the MIO by implementing a set of effective templates to structure test actions, based on the semantics of HTTP methods, used to manipulate the web services' resources. We propose four novel sampling strategies for the test cases that can use one or more of these test actions. The strategies are further supported with a set of new, specialized mutation operators that take into account\u00a0\u2026", "num_citations": "13\n", "authors": ["166"]}
{"title": "A search-based testing approach for XML injection vulnerabilities in web applications\n", "abstract": " In most cases, web applications communicate with web services (SOAP and RESTful). The former act as a front-end to the latter, which contain the business logic. A hacker might not have direct access to those web services (e.g., they are not on public networks), but can still provide malicious inputs to the web application, thus potentially compromising related services. Typical examples are XML injection attacks that target SOAP communications. In this paper, we present a novel, search-based approach used to generate test data for a web application in an attempt to deliver malicious XML messages to web services. Our goal is thus to detect XML injection vulnerabilities in web applications. The proposed approach is evaluated on two studies, including an industrial web application with millions of users. Results show that we are able to effectively generate test data (e.g., input values in an HTML form) that detect\u00a0\u2026", "num_citations": "12\n", "authors": ["166"]}
{"title": "Testability transformations for existing APIs\n", "abstract": " Search-based software testing (SBST) has been shown to be an effective technique to generate test cases automatically. Its effectiveness strongly depends on the guidance of the fitness function. Unfortunately, a common issue in SBST is the so called flag problem, where the fitness landscape presents a plateau that provides no guidance. In this paper, we provide a series of novel testability transformations aimed at providing guidance in the context of commonly used API calls. An example is when strings need to be converted into valid date/time objects. We implemented our novel techniques as an extension to EVOMASTER, a SBST tool that generates system level test cases. Experiments on six open-source REST web services, and an industrial one, show that our novel techniques improve performance significantly.", "num_citations": "9\n", "authors": ["166"]}
{"title": "Handling SQL databases in automated system test generation\n", "abstract": " Automated system test generation for web/enterprise systems requires either a sequence of actions on a GUI (e.g., clicking on HTML links and form buttons) or direct HTTP calls when dealing with web services (e.g., REST and SOAP). When doing white-box testing of such systems, their code can be analyzed, and the same type of heuristics (e.g., the branch distance) used in search-based unit testing can be employed to improve performance. However, web/enterprise systems do often interact with a database. To obtain higher coverage and find new faults, the state of the databases needs to be taken into account when generating white-box tests. In this work, we present a novel heuristic to enhance search-based software testing of web/enterprise systems, which takes into account the state of the accessed databases. Furthermore, we enable the generation of SQL data directly from the test cases. This is useful when\u00a0\u2026", "num_citations": "9\n", "authors": ["166"]}
{"title": "Software-testing education: A systematic literature mapping\n", "abstract": " ContextWith the rising complexity and scale of software systems, there is an ever-increasing demand for sophisticated and cost-effective software testing. To meet such a demand, there is a need for a highly-skilled software testing work-force (test engineers) in the industry. To address that need, many university educators worldwide have included software-testing education in their software engineering (SE) or computer science (CS) programs. Many papers have been published in the last three decades (as early as 1992) to share experience from such undertakings.ObjectiveOur objective in this paper is to summarize the body of experience and knowledge in the area of software-testing education to benefit the readers (both educators and researchers) in designing and delivering software testing courses in university settings, and to also conduct further education research in this area.MethodTo address the above\u00a0\u2026", "num_citations": "8\n", "authors": ["166"]}
{"title": "Recent trends in software testing education: A systematic literature review\n", "abstract": " Testing is a critical aspect of software development. Far too often software is released with critical faults. However, testing is often considered tedious and boring. Unfortunately, many graduates might join the work force without having had any education in software testing, which exacerbates the problem even further. Therefore, teaching software testing as part of a university degree in software engineering and is very important. But it is an open challenge how to teach software testing in an effective way that can successfully motivate students. In this paper, we have carried out a systematic literature review on the topic of teaching software testing. We analysed and reviewed 30 papers that were published between 2013 and 2017. The review points out to a few different trends, like the use of gamification to make the teaching of software testing less tedious.", "num_citations": "8\n", "authors": ["166"]}
{"title": "Automated Black-and White-Box Testing of RESTful APIs With EvoMaster\n", "abstract": " We apply EvoMaster to eight representational state transfer application programming interfaces; show how the tool can be used to automatically generate test cases that can find several bugs, even when using a naive black-box approach; and discuss challenges that must be taken into account.", "num_citations": "7\n", "authors": ["166"]}
{"title": "SQL data generation to enhance search-based system testing\n", "abstract": " Automated system test generation for web/enterprise systems requires either a sequence of actions on a GUI (eg, clicking on HTML links), or direct HTTP calls when dealing with web services (eg, REST and SOAP). However, web/enterprise systems do often interact with a database. To obtain higher coverage and find new faults, the state of the databases needs to be taken into account when generating white-box tests. In this work, we present a novel heuristic to enhance search-based software testing of web/enterprise systems, which takes into account the state of the accessed databases. Furthermore, we enable the generation of SQL data directly from the test cases. This is useful for when it is too difficult or time consuming to generate the right sequence of events to put the database in the right state. And it is also useful when dealing with databases that are''read-only''for the system under test, and the actual data\u00a0\u2026", "num_citations": "7\n", "authors": ["166"]}
{"title": "On search based software evolution\n", "abstract": " Writing software is a difficult and expensive task. Its automation is hence very valuable. Search algorithms have been successfully used to tackle many software engineering problems. Unfortunately, for some problems the traditional techniques have been of only limited scope, and search algorithms have not been used yet. We hence propose a novel framework that is based on a co-evolution of programs and test cases to tackle these difficult problems.This framework can be used to tackle software engineering tasks such as automatic refinement, fault correction,improving non-functional criteria and reverse engineering.While the programs evolve to accomplish one of these tasks, test cases are co-evolved at the the same time to find new faults in the evolving programs.", "num_citations": "6\n", "authors": ["166"]}
{"title": "Code generation from UML/MARTE/OCL environment models to support automated system testing of real-time embedded software\n", "abstract": " Given the challenges of testing at the system level, only a fully automated approach can really scale up to industrial real-time embedded systems (RTES). Our goal is to provide a practical approach to the model-based testing of RTES by allowing system testers, who are often not familiar with the system\u2019s design but are application domain experts, to model the system environment in such a way as to enable its black-box test automation. Environment models can support the automation of three tasks: the code generation of an environment simulator to enable testing on the development platform or without involving actual hardware, the selection of test cases, and the evaluation of their expected results (oracles). From a practical standpoint\u2015and such considerations are crucial for industrial adoption\u2015environment modeling should be based on modeling standards (1) that are at an adequate level of abstraction,(2) that software engineers are familiar with, and (3) that are well supported by commercial or open source tools. In this paper, we propose a precise environment modeling methodology fitting these requirements and discuss how these models can be used to generate environment simulators. The environment models are expressed using UML/MARTE and OCL, which are international standards for real-time systems and constraint modeling. The presented techniques are evaluated on a set of three artificial problems and on two industrial RTES.", "num_citations": "5\n", "authors": ["166"]}
{"title": "EvoMaster: A Search-Based System Test Generation Tool\n", "abstract": " Testing web/enterprise applications is complex and expensive when done manually. Often, software testing takes up to half of the development time and cost for a system. So much testing is needed because the cost of software failure is simply too large: for example, in 2017, 304 software failures (reported in the media) impacted 3.6 billion people and $1.7 trillion in assets worldwide (Tricentis, 2017). Unfortunately, due to its high cost, software testing is often left incomplete, and only applied partially.To address this problem, in Software Engineering (SE) research a lot of effort has been spent in trying to design and implement novel techniques aimed at automating several different tasks, where software testing is among the most studied tasks. Search-Based Software Testing (SBST)(Harman et al., 2012) casts the problem of software testing as an optimization problem, aimed at, for example, maximizing code coverage and fault detection.", "num_citations": "4\n", "authors": ["166"]}
{"title": "Evosuite at the sbst 2016 tool competition\n", "abstract": " EvoSuite at the SBST 2016 Tool Competition - Gordon Fraser Open Repository and Bibliography Login Home Help? EN FR University of Luxembourg Library You are here: ORBi lu Detailled reference Reference : EvoSuite at the SBST 2016 Tool Competition Document type : Scientific congresses, symposiums and conference proceedings : Paper published in a book Discipline(s) : Engineering, computing & technology : Computer science To cite this reference: http://hdl.handle.net/10993/25095 Title : EvoSuite at the SBST 2016 Tool Competition Language : English Author, co-author : Gordon, Fraser [] Arcuri, Andrea mailto [University of Luxembourg > Interdisciplinary Centre for Security, Reliability and Trust (SNT) > >] Publication date : 2016 Main document title : The 9th International Workshop on SEARCH-BASED SOFTWARE TESTING (SBST) Peer reviewed : Yes Event name : The 9th International Workshop on -() [\u2026", "num_citations": "4\n", "authors": ["166"]}
{"title": "Evolutionary robustness testing of data processing systems using models and data mutation (T)\n", "abstract": " System level testing of industrial data processing software poses several challenges. Input data can be very large, even in the order of gigabytes, and with complex constraints that define when an input is valid. Generating the right input data to stress the system for robustness properties (e.g. to test how faulty data is handled) is hence very complex, tedious and error prone when done manually. Unfortunately, this is the current practice in industry. In previous work, we defined a methodology to model the structure and the constraints of input data by using UML class diagrams and OCL constraints. Tests were automatically derived to cover predefined fault types in a fault model. In this paper, to obtain more effective system level test cases, we developed a novel search-based test generation tool. Experiments on a real-world, large industrial data processing system show that our automated approach can not only\u00a0\u2026", "num_citations": "3\n", "authors": ["166"]}
{"title": "Represi\u00f3n sexual y de g\u00e9nero en la confesi\u00f3n: los manuales de confesores de la edad moderna (siglos XVI-XVII)\n", "abstract": " La confesi\u00f3n de los pecados en \u00e1mbito cat\u00f3lico, especialmente a ra\u00edz del Concilio de Trento, constituy\u00f3 un medio eficaz para disciplinar las conductas individuales y sociales de los fieles. El objetivo primordial que me plante\u00e9 con este trabajo es el an\u00e1lisis de los discursos eclesi\u00e1sticos en torno a las mujeres ya las tem\u00e1ticas sexuales a trav\u00e9s de la lectura de una tipolog\u00eda de fuentes directamente relacionada con el sacramento de la penitencia: los manuales de confesores. M\u00ed hip\u00f3tesis es que estas obras de literatura confesional, por su valor did\u00e1ctico de adoctrinamiento de los sacerdotes, constituyeron un instrumento para endurecer la condici\u00f3n de subordinaci\u00f3n de las mujeres a lo largo de la Edad Moderna.", "num_citations": "2\n", "authors": ["166"]}
{"title": "Resource and dependency based test case generation for RESTful Web services\n", "abstract": " Nowadays, RESTful web services are widely used for building enterprise applications. REST is not a protocol, but rather it defines a set of guidelines on how to design APIs to access and manipulate resources using HTTP over a network. In this paper, we propose an enhanced search-based method for automated system test generation for RESTful web services, by exploiting domain knowledge on the handling of HTTP resources. The proposed techniques use domain knowledge specific to RESTful web services and a set of effective templates to structure test actions (ie, ordered sequences of HTTP calls) within an individual in the evolutionary search. The action templates are developed based on the semantics of HTTP methods and are used to manipulate the web services\u2019 resources. In addition, we propose five novel sampling strategies with four sampling methods (ie, resource-based sampling) for the test\u00a0\u2026", "num_citations": "1\n", "authors": ["166"]}
{"title": "Evaluating search-based techniques with statistical tests\n", "abstract": " This tutorial covers the basics of how to use statistical tests to evaluate and compare search-algorithms, in particular when applied on software engineering problems. Search-algorithms like Hill Climbing and Genetic Algorithms are randomised. Running such randomised algorithms twice on the same problem can give different results. It is hence important to run such algorithms multiple times to collect average results, and avoid so publishing wrong conclusions that were based on just luck. However, there is the question of how often such runs should be repeated. Given a set of n repeated experiments, is such n large enough to draw sound conclusions? Or should had more experiments been run? Statistical tests like the Wilcoxon-Mann-Whitney U-test can be used to answer these important questions.", "num_citations": "1\n", "authors": ["166"]}
{"title": "Journal first presentation of an experience report on applying software testing academic results in industry: we need usable automated test generation\n", "abstract": " What is the impact of software engineering research on current practices in industry? In this paper, I report on my direct experience as a PhD/post-doc working in software engineering research projects, and then spending the following five years as an engineer in two different companies (the first one being the same I worked in collaboration with during my post-doc). Given a background in software engineering research, what cutting-edge techniques and tools from academia did I use in my daily work when developing and testing the systems of these companies? Regarding validation and verification (my main area of research), the answer is rather short: as far as I can tell, only FindBugs. In this paper, I report on why this was the case, and discuss all the challenging, complex open problems we face in industry and which somehow are\" neglected\" in the academic circles. In particular, I will first discuss what actual\u00a0\u2026", "num_citations": "1\n", "authors": ["166"]}
{"title": "El control de las conciencias: el sacramento de la confesi\u00f3n y los manuales de confesores y penitentes\n", "abstract": " La pr\u00e1ctica de la confesi\u00f3n auricular represent\u00f3 uno de los instrumentos m\u00e1s relevantes de la acci\u00f3n de disciplinamiento social ejercida por la Iglesia cat\u00f3lica a lo largo de la Edad Moderna.A trav\u00e9s del an\u00e1lisis de algunos manuales de confesores de los siglos XVI y XVII, este art\u00edculo se propone un doble objetivo: por un lado poner de relieve la importancia de dichos manuales para la formaci\u00f3n del clero, por otro ofrecer una visi\u00f3n general del papel que los confesores tuvieron a la hora de disciplinar las conductas sociales e individuales de los fieles.", "num_citations": "1\n", "authors": ["166"]}
{"title": "Theoretical runtime analyses of search algorithms on the test data generation for the\n", "abstract": " Curriculum Vitae Page 1 Curriculum Vitae 1 Personal Information NAME Xin YAO WORK ADDRESS The Centre of Excellence for Research in Computational Intelligence and Applications (CERCIA) School of Computer Science, The University of Birmingham Edgbaston, Birmingham B15 2TT, UK Email: X.Yao@cs.bham.ac.uk URL: http://www.cs.bham.ac.uk/\u223cxin Phone: +44 121 414 3747, Fax: +44 121 414 2799 QUALIFICATIONS BSc (1982), MSc (1985), PhD (1990). MAJOR RECOGNITIONS IEEE Fellow; Royal Society Wolfson Research Merit Award; IEEE Computational Intelligence Society Evolutionary Computation Pioneer Award. 2 Employment History Jan. 2003 \u2013 : Director of The Centre of Excellence for Research in Computational Intelligence and Applications (CERCIA), the University of Birmingham, Edgbaston, Birmingham B15 2TT, UK. Apr. 1999 \u2013 : Chair of Computer Science, School of Computer , the of .\u2026", "num_citations": "1\n", "authors": ["166"]}