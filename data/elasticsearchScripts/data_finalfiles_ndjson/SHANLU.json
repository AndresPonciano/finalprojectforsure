{"title": "CP-Miner: A Tool for Finding Copy-paste and Related Bugs in Operating System Code.\n", "abstract": " Copy-pasted code is very common in large software because programmers prefer reusing code via copy-paste in order to reduce programming effort. Recent studies show that copy-paste is prone to introducing bugs and a significant portion of operating system bugs concentrate in copy-pasted code. Unfortunately, it is challenging to efficiently identify copy-pasted code in large software. Existing copy-paste detection tools are either not scalable to large software, or cannot handle small modifications in copy-pasted code. Furthermore, few tools are available to detect copy-paste related bugs.", "num_citations": "494\n", "authors": ["273"]}
{"title": "Understanding and detecting real-world performance bugs\n", "abstract": " Developers frequently use inefficient code sequences that could be fixed by simple patches. These inefficient code sequences can cause significant performance degradation and resource waste, referred to as performance bugs. Meager increases in single threaded performance in the multi-core era and increasing emphasis on energy efficiency call for more effort in tackling performance bugs. This paper conducts a comprehensive study of 110 real-world performance bugs that are randomly sampled from five representative software suites (Apache, Chrome, GCC, Mozilla, and MySQL). The findings of this study provide guidance for future work to avoid, expose, detect, and fix performance bugs. Guided by our characteristics study, efficiency rules are extracted from 25 patches and are used to detect performance bugs. 332 previously unknown performance problems are found in the latest versions of MySQL\u00a0\u2026", "num_citations": "375\n", "authors": ["273"]}
{"title": "Automated atomicity-violation fixing\n", "abstract": " Fixing software bugs has always been an important and time-consuming process in software development. Fixing concurrency bugs has become especially critical in the multicore era. However, fixing concurrency bugs is challenging, in part due to non-deterministic failures and tricky parallel reasoning. Beyond correctly fixing the original problem in the software, a good patch should also avoid introducing new bugs, degrading performance unnecessarily, or damaging software readability. Existing tools cannot automate the whole fixing process and provide good-quality patches.", "num_citations": "260\n", "authors": ["273"]}
{"title": "Automated concurrency-bug fixing\n", "abstract": " Concurrency bugs are widespread in multithreaded programs. Fixing them is time-consuming and error-prone. We present CFix, a system that automates the repair of concurrency bugs. CFix works with a wide variety of concurrency-bug detectors. For each failure-inducing interleaving reported by a bug detector, CFix first determines a combination of mutual-exclusion and order relationships that, once enforced, can prevent the buggy interleaving. CFix then uses static analysis and testing to determine where to insert what synchronization operations to force the desired mutual-exclusion and order relationships, with a best effort to avoid deadlocks and excessive performance losses. CFix also simplifies its own patches by merging fixes for related bugs.", "num_citations": "191\n", "authors": ["273"]}
{"title": "A Study of Linux File System Evolution\n", "abstract": " We conduct a comprehensive study of file-system code evolution. By analyzing eight years of Linux file-system changes across 5079 patches, we derive numerous new (and sometimes surprising) insights into the file-system development process; our results should be useful for both the development of file systems themselves as well as the improvement of bug-finding tools.", "num_citations": "167\n", "authors": ["273"]}
{"title": "ConMem: detecting severe concurrency bugs through an effect-oriented approach\n", "abstract": " Multicore technology is making concurrent programs increasingly pervasive. Unfortunately, it is difficult to deliver reliable concurrent programs, because of the huge and non-deterministic interleaving space. In reality, without the resources to thoroughly check the interleaving space, critical concurrency bugs can slip into production runs and cause failures in the field. Approaches to making the best use of the limited resources and exposing severe concurrency bugs before software release would be desirable. Unlike previous work that focuses on bugs caused by specific interleavings (e.g., races and atomicity-violations), this paper targets concurrency bugs that result in one type of severe effects: program crashes. Our study of the error-propagation process of realworld concurrency bugs reveals a common pattern (50% in our non-deadlock concurrency bug set) that is highly correlated with program crashes. We call\u00a0\u2026", "num_citations": "137\n", "authors": ["273"]}
{"title": "Caramel: Detecting and fixing performance problems that have non-intrusive fixes\n", "abstract": " Performance bugs are programming errors that slow down program execution. While existing techniques can detect various types of performance bugs, a crucial and practical aspect of performance bugs has not received the attention it deserves: how likely are developers to fix a performance bug? In practice, fixing a performance bug can have both benefits and drawbacks, and developers fix a performance bug only when the benefits outweigh the drawbacks. Unfortunately, for many performance bugs, the benefits and drawbacks are difficult to assess accurately. This paper presents CARAMEL, a novel static technique that detects and fixes performance bugs that have non-intrusive fixes likely to be adopted by developers. Each performance bug detected by CARAMEL is associated with a loop and a condition. When the condition becomes true during the loop execution, all the remaining computation performed by\u00a0\u2026", "num_citations": "131\n", "authors": ["273"]}
{"title": "Instrumentation and sampling strategies for cooperative concurrency bug isolation\n", "abstract": " Fixing concurrency bugs (or\" crugs\") is critical in modern software systems. Static analyses to find crugs such as data races and atomicity violations scale poorly, while dynamic approaches incur high run-time overheads. Crugs manifest only under specific execution interleavings that may not arise during in-house testing, thereby demanding a lightweight program monitoring technique that can be used post-deployment.", "num_citations": "127\n", "authors": ["273"]}
{"title": "Yak: A high-performance big-data-friendly garbage collector\n", "abstract": " Most \u201cBig Data\u201d systems are written in managed languages, such as Java, C#, or Scala. These systems suffer from severe memory problems due to the massive volume of objects created to process input data. Allocating and deallocating a sea of data objects puts a severe strain on existing garbage collectors (GC), leading to high memory management overheads and reduced performance.", "num_citations": "110\n", "authors": ["273"]}
{"title": "TaxDC: A taxonomy of non-deterministic concurrency bugs in datacenter distributed systems\n", "abstract": " We present TaxDC, the largest and most comprehensive taxonomy of non-deterministic concurrency bugs in distributed systems. We study 104 distributed concurrency (DC) bugs from four widely-deployed cloud-scale datacenter distributed systems, Cassandra, Hadoop MapReduce, HBase and ZooKeeper. We study DC-bug characteristics along several axes of analysis such as the triggering timing condition and input preconditions, error and failure symptoms, and fix strategies, collectively stored as 2,083 classification labels in TaxDC database. We discuss how our study can open up many new research directions in combating DC bugs.", "num_citations": "109\n", "authors": ["273"]}
{"title": "A study of interleaving coverage criteria.\n", "abstract": " Concurrency bugs are becoming increasingly important due to the prevalence of concurrent programs. A fundamental problem of concurrent program bug detection and testing is that the interleaving space is too large to be thoroughly explored. Practical yet effective interleaving coverage criteria are desired to systematically explore the interleaving space and effectively expose concurrency bugs.", "num_citations": "104\n", "authors": ["273"]}
{"title": "Do I use the wrong definition?: DeFuse: definition-use invariants for detecting concurrency and sequential bugs\n", "abstract": " Software bugs, such as concurrency, memory and semantic bugs, can significantly affect system reliability. Although much effort has been made to address this problem, there are still many bugs that cannot be detected, especially concurrency bugs due to the complexity of concurrent programs. Effective approaches for detecting these common bugs are therefore highly desired.", "num_citations": "103\n", "authors": ["273"]}
{"title": "Statistical debugging for real-world performance problems\n", "abstract": " Design and implementation defects that lead to inefficient computation widely exist in software. These defects are difficult to avoid and discover. They lead to severe performance degradation and energy waste during production runs, and are becoming increasingly critical with the meager increase of single-core hardware performance and the increasing concerns about energy constraints. Effective tools that diagnose performance problems and point out the inefficiency root cause are sorely needed. The state of the art of performance diagnosis is preliminary. Profiling can identify the functions that consume the most computation resources, but can neither identify the ones that waste the most resources nor explain why. Performance-bug detectors can identify specific type of inefficient computation, but are not suited for diagnosing general performance problems. Effective failure diagnosis techniques, such as\u00a0\u2026", "num_citations": "89\n", "authors": ["273"]}
{"title": "Flight data recorder: monitoring persistent-state interactions to improve systems management\n", "abstract": " Mismanagement of the persistent state of a system\u2014all the executable files, configuration settings and other data that govern how a system functions\u2014causes reliability problems, security vulnerabilities, and drives up operation costs. Recent research traces persistent state interactions\u2014how state is read, modified, etc.\u2014to help troubleshooting, change management and malware mitigation, but has been limited by the difficulty of collecting, storing, and analyzing the 10s to 100s of millions of daily events that occur on a single machine, much less the 1000s or more machines in many computing environments.", "num_citations": "84\n", "authors": ["273"]}
{"title": "Interruptible tasks: treating memory pressure as interrupts for highly scalable data-parallel programs\n", "abstract": " Real-world data-parallel programs commonly suffer from great memory pressure, especially when they are executed to process large datasets. Memory problems lead to excessive GC effort and out-of-memory errors, significantly hurting system performance and scalability. This paper proposes a systematic approach that can help data-parallel tasks survive memory pressure, improving their performance and scalability without needing any manual effort to tune system parameters. Our approach advocates interruptible task (ITask), a new type of data-parallel tasks that can be interrupted upon memory pressure---with part or all of their used memory reclaimed---and resumed when the pressure goes away.", "num_citations": "58\n", "authors": ["273"]}
{"title": "Understanding and Auto-Adjusting Performance-Sensitive Configurations\n", "abstract": " Modern software systems are often equipped with hundreds to thousands of configurations, many of which greatly affect performance. Unfortunately, properly setting these configurations is challenging for developers due to the complex and dynamic nature of system workload and environment. In this paper, we first conduct an empirical study to understand performance-sensitive configurations and the challenges of setting them in the real-world. Guided by our study, we design a systematic and general control-theoretic framework, SmartConf, to automatically set and dynamically adjust performance-sensitive configurations to meet required operating constraints while optimizing other performance metrics. Evaluation shows that SmartConf is effective in solving real-world configuration problems, often providing better performance than even the best static configuration developers can choose under existing\u00a0\u2026", "num_citations": "54\n", "authors": ["273"]}
{"title": "Production-run software failure diagnosis via hardware performance counters\n", "abstract": " Sequential and concurrency bugs are widespread in deployed software. They cause severe failures and huge financial loss during production runs. Tools that diagnose production-run failures with low overhead are needed. The state-of-the-art diagnosis techniques use software instrumentation to sample program properties at run time and use off-line statistical analysis to identify properties most correlated with failures. Although promising, these techniques suffer from high run-time overhead, which is sometimes over 100%, for concurrency-bug failure diagnosis and hence are not suitable for production-run usage. We present PBI, a system that uses existing hardware performance counters to diagnose production-run failures caused by sequential and concurrency bugs with low overhead. PBI is designed based on several key observations. First, a few widely supported performance counter events can reflect a\u00a0\u2026", "num_citations": "54\n", "authors": ["273"]}
{"title": "ConAir: featherweight concurrency bug recovery via single-threaded idempotent execution\n", "abstract": " Many concurrency bugs are hidden in deployed software and cause severe failures for end-users. When they finally manifest and become known by developers, they are difficult to fix correctly. To support end-users, we need techniques that help software survive hidden concurrency bugs during production runs. To help developers, we need techniques that fix exposed concurrency bugs.", "num_citations": "49\n", "authors": ["273"]}
{"title": "DCatch: Automatically Detecting Distributed Concurrency Bugs in Cloud Systems\n", "abstract": " In big data and cloud computing era, reliability of distributed systems is extremely important. Unfortunately, distributed concurrency bugs, referred to as DCbugs, widely exist. They hide in the large state space of distributed cloud systems and manifest non-deterministically depending on the timing of distributed computation and communication. Effective techniques to detect DCbugs are desired. This paper presents a pilot solution, DCatch, in the world of DCbug detection. DCatch predicts DCbugs by analyzing correct execution of distributed systems. To build DCatch, we design a set of happens-before rules that model a wide variety of communication and concurrency mechanisms in real-world distributed cloud systems. We then build runtime tracing and trace analysis tools to effectively identify concurrent conflicting memory accesses in these systems. Finally, we design tools to help prune false positives and trigger\u00a0\u2026", "num_citations": "48\n", "authors": ["273"]}
{"title": "Leveraging parallelism for multi-dimensional packetclassification on software routers\n", "abstract": " We present a software-based solution to the multi-dimensional packet classification problem which can operate at high line speeds, eg, in excess of 10 Gbps, using high-end multi-core desktop platforms available today. Our solution, called Storm, leverages a common notion that a subset of rules are likely to be popular over short durations of time. By identifying a suitable set of popular rules one can significantly speed up existing software-based classification algorithms. A key aspect of our design is in partitioning processor resources into various relevant tasks, such as continuously computing the popular rules based on a sampled subset of traffic, fast classification for traffic that matches popular rules, dealing with packets that do not match the most popular rules, and traffic sampling. Our results show that by using a single 8-core Xeon processor desktop platform, it is possible to sustain classification rates of more\u00a0\u2026", "num_citations": "43\n", "authors": ["273"]}
{"title": "Performance diagnosis for inefficient loops\n", "abstract": " Writing efficient software is difficult. Design and implementation defects can cause severe performance degradation. Unfortunately, existing performance diagnosis techniques like profilers are still preliminary. They can locate code regions that consume resources, but not the ones that waste resources. In this paper, we first design a root-cause and fix-strategy taxonomy for inefficient loops, one of the most common performance problems in the field. We then design a static-dynamic hybrid analysis tool, LDoctor, to provide accurate performance diagnosis for loops. We further use sampling techniques to lower the run-time overhead without degrading the accuracy or latency of LDoctor diagnosis. Evaluation using real-world performance problems shows that LDoctor can provide better coverage and accuracy than existing techniques, with low overhead.", "num_citations": "39\n", "authors": ["273"]}
{"title": "What change history tells us about thread synchronization\n", "abstract": " Multi-threaded programs are pervasive, yet difficult to write. Missing proper synchronization leads to correctness bugs and over synchronization leads to performance problems. To improve the correctness and efficiency of multi-threaded software, we need a better understanding of synchronization challenges faced by real-world developers. This paper studies the code repositories of open-source multi-threaded software projects to obtain a broad and in-depth view of how developers handle synchronizations. We first examine how critical sections are changed when software evolves by checking over 250,000 revisions of four representative open-source software projects. The findings help us answer questions like how often synchronization is an afterthought for developers; whether it is difficult for devel-opers to decide critical section boundaries and lock variables; and what are real-world over-synchronization\u00a0\u2026", "num_citations": "39\n", "authors": ["273"]}
{"title": "How not to structure your database-backed web applications: a study of performance bugs in the wild\n", "abstract": " Many web applications use databases for persistent data storage, and using Object Relational Mapping (ORM) frameworks is a common way to develop such database-backed web applications. Unfortunately, developing efficient ORM applications is challenging, as the ORM framework hides the underlying database query generation and execution. This problem is becoming more severe as these applications need to process an increasingly large amount of persistent data. Recent research has targeted specific aspects of performance problems in ORM applications. However, there has not been any systematic study to identify common performance anti-patterns in real-world such applications, how they affect resulting application performance, and remedies for them. In this paper, we try to answer these questions through a comprehensive study of 12 representative real-world ORM applications. We generalize 9\u00a0\u2026", "num_citations": "38\n", "authors": ["273"]}
{"title": "Efficient concurrency-bug detection across inputs\n", "abstract": " In the multi-core era, it is critical to efficiently test multi-threaded software and expose concurrency bugs before software release. Previous work has made significant progress in detecting and validating concurrency bugs under a given input. Unfortunately, software testing always faces large sets of test inputs, and existing techniques are still too expensive to be applied to every test input in practice. In this paper, we use open-source software to study how existing concurrency-bug detection tools work for a set of inputs. The study shows that an interleaving pattern, such as a data race or an atomicity violation, can often be exposed by many inputs. Consequently, existing bug detectors would inevitably waste their bug detection effort to generate duplicate bug reports, when applied to a set of inputs. Guided by the above study, we propose a coverage metric, Concurrent Function Pairs (CFP), to efficiently approximate\u00a0\u2026", "num_citations": "35\n", "authors": ["273"]}
{"title": "Thread interception and analysis\n", "abstract": " Apparatus and methods for intercepting and analyzing threads are disclosed. In one embodiment, a thread data recorder is configured to instrument one or more existing functions by modifying computer executable instructions in the functions to intercept threads calling the functions. In one possible implementation, the number of existing functions instrumented can be reduced by instrumenting choke point functions. The instrumented functions can also capture data associated with the threads as the threads execute at the function. This data can be saved to memory and compressed into logs. In one aspect, the data can be saved and/or compressed at a time when processor resources are being used at or below a predetermined level. The captured data can be used to analyze a functioning of a computer system in which the threads were produced.", "num_citations": "33\n", "authors": ["273"]}
{"title": "Understanding Database Performance Inefficiencies in Real-world Web Applications\n", "abstract": " Many modern database-backed web applications are built upon Object Relational Mapping (ORM) frameworks. While such frame-works ease application development by abstracting persistent data as objects, such convenience comes with a performance cost. In this paper, we studied 27 real-world open-source applications built on top of the popular Ruby on Rails ORM framework, with the goal to understand the database-related performance inefficiencies in these applications. We discovered a number of inefficiencies rang-ing from physical design issues to how queries are expressed in the application code. We applied static program analysis to identify and measure how prevalent these issues are, then suggested techniques to alleviate these issues and measured the potential performance gain as a result. These techniques significantly reduce database query time (up to 91%) and the webpage response time\u00a0\u2026", "num_citations": "32\n", "authors": ["273"]}
{"title": "Applying transactional memory to concurrency bugs\n", "abstract": " Multithreaded programs often suffer from synchronization bugs such as atomicity violations and deadlocks. These bugs arise from complicated locking strategies and ad hoc synchronization methods to avoid the use of locks. A survey of the bug databases of major open-source applications shows that concurrency bugs often take multiple fix attempts, and that fixes often introduce yet more concurrency bugs. Transactional memory (TM) enables programmers to declare regions of code atomic without specifying a lock and has the potential to avoid these bugs. Where most previous studies have focused on using TM to write new programs from scratch, we consider its utility in fixing existing programs with concurrency bugs. We therefore investigate four methods of using TM on three concurrent programs. Overall, we find that 29% of the bugs are not fixable by transactional memory, showing that TM does not address\u00a0\u2026", "num_citations": "32\n", "authors": ["273"]}
{"title": "AutoTap: synthesizing and repairing trigger-action programs using LTL properties\n", "abstract": " End-user programming, particularly trigger-action programming (TAP), is a popular method of letting users express their intent for how smart devices and cloud services interact. Unfortunately, sometimes it can be challenging for users to correctly express their desires through TAP. This paper presents AutoTap, a system that lets novice users easily specify desired properties for devices and services. AutoTap translates these properties to linear temporal logic (LTL) and both automatically synthesizes property-satisfying TAP rules from scratch and repairs existing TAP rules. We designed AutoTap based on a user study about properties users wish to express. Through a second user study, we show that novice users made significantly fewer mistakes when expressing desired behaviors using AutoTap than using TAP rules. Our experiments show that AutoTap is a simple and effective option for expressive end-user\u00a0\u2026", "num_citations": "31\n", "authors": ["273"]}
{"title": "Skyway: Connecting Managed Heaps in Distributed Big Data Systems\n", "abstract": " Managed languages such as Java and Scala are prevalently used in development of large-scale distributed systems. Under the managed runtime, when performing data transfer across machines, a task frequently conducted in a Big Data system, the system needs to serialize a sea of objects into a byte sequence before sending them over the network. The remote node receiving the bytes then deserializes them back into objects. This process is both performance-inefficient and labor-intensive: (1) object serialization/deserialization makes heavy use of reflection, an expensive runtime operation and/or (2) serialization/deserialization functions need to be hand-written and are error-prone. This paper presents Skyway, a JVM-based technique that can directly connect managed heaps of different (local or remote) JVM processes. Under Skyway, objects in the source heap can be directly written into a remote heap without\u00a0\u2026", "num_citations": "31\n", "authors": ["273"]}
{"title": "Leveraging the Short-Term Memory of Hardware to Diagnose Production-Run Software Failures\n", "abstract": " Failures caused by software bugs are widespread in production runs, causing severe losses for end users. Unfortunately, diagnosing production-run failures is challenging. Existing work cannot satisfy privacy, run-time overhead, diagnosis capability, and diagnosis latency requirements all at once.", "num_citations": "31\n", "authors": ["273"]}
{"title": "Efficient Scalable Thread-Safety-Violation Detection\n", "abstract": " Concurrency bugs are hard to find, reproduce, and debug. They often escape rigorous in-house testing, but result in large-scale outages in production. Existing concurrency-bug detection techniques unfortunately cannot be part of industry's integrated build and test environment due to some open challenges: how to handle code developed by thousands of engineering teams that uses a wide variety of synchronization mechanisms, how to report little/no false positives, and how to avoid excessive testing resource consumption.", "num_citations": "28\n", "authors": ["273"]}
{"title": "Understanding and generating high quality patches for concurrency bugs\n", "abstract": " Concurrency bugs are time-consuming to fix correctly by developers and a severe threat to software reliability. Although many auto-fixing techniques have been proposed recently for concurrency bugs, there is still a big gap between the quality of automatically generated patches and manually designed ones. This paper first conducts an in-depth study of manual patches for 77 real-world concurrency bugs, which provides both assessments for existing techniques and actionable suggestions for future research. Guided by this study, a new tool HFix is designed. It can automatically generate patches, which have matching quality as manual patches, for many concurrency bugs.", "num_citations": "27\n", "authors": ["273"]}
{"title": "Pcatch: automatically detecting performance cascading bugs in cloud systems\n", "abstract": " Distributed systems have become the backbone of modern clouds. Users often expect high scalability and performance isolation from distributed systems. Unfortunately, a type of poor software design, which we refer to as performance cascading bugs (PCbugs), can often cause the slowdown of non-scalable code in one job to propagate, causing global performance degradation and even threatening system availability.", "num_citations": "25\n", "authors": ["273"]}
{"title": "FCatch: Automatically Detecting Time-of-fault Bugs in Cloud Systems\n", "abstract": " It is crucial for distributed systems to achieve high availability. Unfortunately, this is challenging given the common component failures (i.e., faults). Developers often cannot anticipate all the timing conditions and system states under which a fault might occur, and introduce time-of-fault (TOF) bugs that only manifest when a node crashes or a message drops at a special moment. Although challenging, detecting TOF bugs is fundamental to developing highly available distributed systems. Unlike previous work that relies on fault injection to expose TOF bugs, this paper carefully models TOF bugs as a new type of concurrency bugs, and develops FCatch to automatically predict TOF bugs by observing correct execution. Evaluation on representative cloud systems shows that FCatch is effective, accurately finding severe TOF bugs.", "num_citations": "23\n", "authors": ["273"]}
{"title": "AI: a lightweight system for tolerating concurrency bugs\n", "abstract": " Concurrency bugs are notoriously difficult to eradicate during software testing because of their non-deterministic nature. Moreover, fixing concurrency bugs is time-consuming and error-prone. Thus, tolerating concurrency bugs during production runs is an attractive complementary approach to bug detection and testing. Unfortunately, existing bug-tolerating tools are usually either 1) constrained in types of bugs they can handle or 2) requiring roll-back mechanism, which can hitherto not be fully achieved efficiently without hardware supports. This paper presents a novel program invariant, called Anticipating Invariant (AI), which can help anticipate bugs before any irreversible changes are made. Benefiting from this ability of anticipating bugs beforehand, our software-only system is able to forestall the failures with a simple thread stalling technique, which does not rely on execution roll-back and hence has good\u00a0\u2026", "num_citations": "22\n", "authors": ["273"]}
{"title": "Understanding Real-World Timeout Problems in Cloud Server Systems\n", "abstract": " Timeouts are commonly used to handle unexpected failures in distributed systems. In this paper, we conduct a comprehensive study to characterize real-world timeout problems in 11 commonly used cloud server systems (e.g., Hadoop, HDSF, Spark, Cassandra, etc.). Our study reveals timeout problems are widespread among cloud server systems. We categorize those timeout problems in three aspects: 1) what are the root causes of those timeout problems? 2) what impact can timeout problems impose to cloud systems? 3) how are timeout problems currently diagnosed or misdiagnosed? Our results show that root causes of timeout problems include misused timeout, missing timeout, improper timeout handling, unnecessary timeout, and clock drifting. We further find timeout bugs impose serious impact (e.g., system hang or crash, job failure, performance degradation, data loss) to both applications and systems\u00a0\u2026", "num_citations": "19\n", "authors": ["273"]}
{"title": "Low-complexity 2-power transform for image/video compression\n", "abstract": " To encode image and video data using a transform having low computational complexity and high compression efficiency, all elements of the matrix can be expressed with power-of-2 elements, with a template of the matrix approximating a DCT matrix.", "num_citations": "19\n", "authors": ["273"]}
{"title": "Cooperative crug isolation\n", "abstract": " With the widespread deployment of multi-core hardware, writing concurrent programs has become inescapable. This has made fixing concurrency bugs (or crugs) critical in modern software systems. Static analysis techniques to find crugs such as data races and atomicity violations are not scalable, while dynamic approaches incur high run-time overheads. Crugs pose a greater challenge since they manifest only under specific execution interleavings that may not arise during in-house testing. Thus there is a pressing need for a low-overhead program monitoring technique that can be used post-deployment.", "num_citations": "17\n", "authors": ["273"]}
{"title": "A Lightweight System for Detecting and Tolerating Concurrency Bugs\n", "abstract": " Along with the prevalence of multi-threaded programs, concurrency bugs have become one of the most important sources of software bugs. Even worse, due to the non-deterministic nature of concurrency bugs, these bugs are both difficult to detect and fix even after the detection. As a result, it is highly desired to develop an all-around approach that is able to not only detect them during the testing phase but also tolerate undetected bugs during production runs. However, existing bug-detecting and bug-tolerating tools are usually either  1)  constrained in types of bugs they can handle or  2)  requiring specific hardware supports for achieving an acceptable overhead. In this paper, we present a novel program invariant, name Anticipating Invariant ( Ai ), that can detect most types of concurrency bugs. More importantly,  Ai  can be used to anticipate many concurrency bugs before any irreversible changes have been made\u00a0\u2026", "num_citations": "15\n", "authors": ["273"]}
{"title": "Automatic on-line failure diagnosis at the end-user site\n", "abstract": " Production run software failures cause endless grief to end-users, and endless challenges to programmers as they commonly have incomplete information about the bug, facing great hurdles to reproduce it. Users are often unable or unwilling to provide diagnostic information due to technical challenges and privacy concerns; even if the information is available, failure analysis is time-consuming.We propose performing initial diagnosis automatically and at the end user\u2019s site. The moment of failure is a valuable commodity programmers strive to reproduce\u2014leveraging it directly reduces diagnosis effort while simultaneously addressing privacy concerns. Additionally, we propose a failure diagnosis protocol. So far as we know, this is the first such automatic protocol proposed for on-line diagnosis. By mimicking the steps a human programmer follows dissecting a failure, we deduce important failure information. Beyond online use, this can also reduce the effort of in-house testing.", "num_citations": "15\n", "authors": ["273"]}
{"title": "Fixing, preventing, and recovering from concurrency bugs\n", "abstract": " Concurrency bugs are becoming widespread with the emerging ubiquity of multicore processors and multithreaded software. They manifest during production runs and lead to severe losses. Many effective concurrency-bug detection tools have been built. However, the dependability of multi-threaded software does not improve until these bugs are handled statically or dynamically. This article discusses our recent progresses on fixing, preventing, and recovering from concurrency bugs.", "num_citations": "14\n", "authors": ["273"]}
{"title": "DFix: automatically fixing timing bugs in distributed systems\n", "abstract": " Distributed systems nowadays are the backbone of computing society, and are expected to have high availability. Unfortunately, distributed timing bugs, a type of bugs triggered by non-deterministic timing of messages and node crashes, widely exist. They lead to many production-run failures, and are difficult to reason about and patch. Although recently proposed techniques can automatically detect these bugs, how to automatically and correctly fix them still remains as an open problem. This paper presents DFix, a tool that automatically processes distributed timing bug reports, statically analyzes the buggy system, and produces patches. Our evaluation shows that DFix is effective in fixing real-world distributed timing bugs.", "num_citations": "13\n", "authors": ["273"]}
{"title": "View-centric performance optimization for database-backed web applications\n", "abstract": " Web developers face the stringent task of designing informative web pages while keeping the page-load time low. This task has become increasingly challenging as most web contents are now generated by processing ever-growing amount of user data stored in back-end databases. It is difficult for developers to understand the cost of generating every web-page element, not to mention explore and pick the web design with the best trade-off between performance and functionality. In this paper, we present Panorama, a view-centric and database-aware development environment for web developers. Using database-aware program analysis and novel IDE design, Panorama provides developers with intuitive information about the cost and the performance-enhancing opportunities behind every HTML element, as well as suggesting various global code refactorings that enable developers to easily explore a wide\u00a0\u2026", "num_citations": "13\n", "authors": ["273"]}
{"title": "Gerenuk: thin computation over big native data using speculative program transformation\n", "abstract": " Big Data systems are typically implemented in object-oriented languages such as Java and Scala due to the quick development cycle they provide. These systems are executed on top of a managed runtime such as the Java Virtual Machine (JVM), which requires each data item to be represented as an object before it can be processed. This representation is the direct cause of many kinds of severe inefficiencies.", "num_citations": "12\n", "authors": ["273"]}
{"title": "Interdisciplinary research challenges in computer systems for the 2020s\n", "abstract": " The broad landscape of new technologies currently being explored makes the current times very exciting for computer systems research. The community is actively researching an extensive set of topics, ranging from the small (eg, energy-independent embedded devices) to the large (eg, brain-scale deep learning), simultaneously addressing technology discontinuities (End of Moore\u2019s Law and Energy Wall), new challenges in security and privacy, and the rise of artificial intelligence (AI).While industry is applying some of these technologies, its efforts are necessarily focused on only a few areas, and on relatively short-term horizons. This offers academic researchers the opportunity to attack the problems with a broader and longer-term view. Further, in recent times, the computer systems community has started to pay increasing attention to non-performance measures, such as security, complexity, and power. To make progress in this multi-objective world, the composition of research teams needs to change. Teams have to become inter-disciplinary, enabling the flow of ideas across computing fields. 1", "num_citations": "12\n", "authors": ["273"]}
{"title": "PowerStation: Automatically detecting and fixing inefficiencies of database-backed web applications in IDE\u2217\n", "abstract": " Modern web applications are built using a myriad of software components, and each of them exposes different programming models (eg, application logic expressed in an imperative language, database queries expressed using declarative SQL). To improve programmer productivity, Object Relational Mapping (ORM) frameworks have been developed to allow developers build web applications in an object-oriented manner. Despite such frameworks, prior work has found that developers still struggle in developing performant ORM-based web applications. This paper presents PowerStation, a RubyMine IDE plugin for optimizing web applications developed using the Ruby on Rails ORM. Using automated static analysis, PowerStation detects ORM-related inefficiency problems and suggests fixes to developers. Our evaluation using 12 real-world applications shows that PowerStation can automatically detects 1221\u00a0\u2026", "num_citations": "11\n", "authors": ["273"]}
{"title": "Statically inferring performance properties of software configurations\n", "abstract": " Modern software systems often have a huge number of configurations whose performance properties are poorly documented. Unfortunately, obtaining a good understanding of these performance properties is a prerequisite for performance tuning. This paper explores a new approach to discovering performance properties of system configurations: static program analysis. We present a taxonomy of how a configuration might affect performance through program dependencies. Guided by this taxonomy, we design LearnConf, a static analysis tool that identifies which configurations affect what type of performance and how. Our evaluation, which considers hundreds of configurations in four widely used distributed systems, demonstrates that LearnConf can accurately and efficiently identify many configurations' performance properties, and help performance tuning.", "num_citations": "10\n", "authors": ["273"]}
{"title": "Half-pixel motion estimation bypass based on a linear model\n", "abstract": " In hybrid video coding schemes, motion estimation at sub-pixel accuracy, such as 1/2 pixel and 1/4 pixel obviously possesses higher coding efficiency than that at integer-pixel accuracy only. However, it requires more computational overhead for additional processes such as interpolation and search on sub-pixels. We proposed a novel half-pixel motion estimation bypass algorithm based on a linear model. The key idea is to skip over blocks that do not benefit from half-pixel search, therefore we not only reduce the search points but also the interpolation process. Experimental results show that significant computation reduction is achieved while the degradation in video quality is negligible. The proposed algorithm is very suitable for scenarios where lowcomplexity computing is required, such as mobile video coding applications.", "num_citations": "10\n", "authors": ["273"]}
{"title": "DScope: Detecting Real-World Data Corruption Hang Bugs in Cloud Server Systems\n", "abstract": " Cloud server systems such as Hadoop and Cassandra have enabled many real-world data-intensive applications running inside computing clouds. However, those systems present many data-corruption and performance problems which are notoriously difficult to debug due to the lack of diagnosis information. In this paper, we present DScope, a tool that statically detects data-corruption related software hang bugs in cloud server systems. DScope statically analyzes I/O operations and loops in a software package, and identifies loops whose exit conditions can be affected by I/O operations through returned data, returned error code, or I/O exception handling. After identifying those loops which are prone to hang problems under data corruption, DScope conducts loop bound and loop stride analysis to prune out false positives. We have implemented DScope and evaluated it using 9 common cloud server systems. Our\u00a0\u2026", "num_citations": "9\n", "authors": ["273"]}
{"title": "Low-overhead and fully automated statistical debugging with abstraction refinement\n", "abstract": " Cooperative statistical debugging is an effective approach for diagnosing production-run failures. To quickly identify failure predictors from the huge program predicate space, existing techniques rely on random or heuristics-guided predicate sampling at the user side. However, none of them can satisfy the requirements of low cost, low diagnosis latency, and high diagnosis quality simultaneously, which are all indispensable for statistical debugging to be practical.", "num_citations": "8\n", "authors": ["273"]}
{"title": "Understanding, detecting and exposing concurrency bugs\n", "abstract": " Software is pervasive in our daily lives. Unfortunately, software bugs can severely affect the dependability and security of software systems. Among all types of software bugs, the concurrency bug is one of the most troublesome and important. Concurrency bugs widely exist in concurrent programs. They are difficult to detect and diagnose because of their unique non-determinism. In the real world, concurrency bugs have caused several disasters in the past and are generating increasingly severe problems in recent years with the prevalence of multi-core hardware and concurrent programs. Facing the challenge of concurrency bugs, this thesis proposes effective concurrency bug detection and concurrent program testing approaches based on a comprehensive characteristics study of real-world concurrency bugs.", "num_citations": "8\n", "authors": ["273"]}
{"title": "Analyzing persistent state interactions to improve state management\n", "abstract": " A primary challenge to building reliable and secure computer systems is managing the persistent state (PS) of the system: all the executable files, configuration settings and other data that govern how a system functions. The difficulty comes from the sheer volume of this persistent state, the frequency of changes to it, and the variety of workloads and requirements that require customization of persistent state. The cost of not managing a system\u2019s persistent state effectively is high: configuration errors are the leading cause of downtime at Internet services, troubleshooting configuration problems is a leading component of total cost of ownership in corporate environments, and malware\u2014effectively, unwanted persistent state\u2014is a serious privacy and security concern on personal computers [1, 6, 8].The first step to building better PS management tools is gaining a better understanding and characterization of how\u00a0\u2026", "num_citations": "8\n", "authors": ["273"]}
{"title": "Scalecheck: a single-machine approach for discovering scalability bugs in large distributed systems\n", "abstract": " We present ScaleCheck, an approach for discovering scalability bugs (a new class of bug in large storage systems) and for democratizing large-scale testing. ScaleCheck employs a program analysis technique, for finding potential causes of scalability bugs, and a series of colocation techniques, for testing implementation code at real scales but doing so on just a commodity PC. ScaleCheck has been integrated to several large-scale storage systems, Cassandra, HDFS, Riak, and Voldemort, and successfully exposed known and unknown scalability bugs, up to 512-node scale on a 16-core PC.", "num_citations": "7\n", "authors": ["273"]}
{"title": "Understanding and Automatically Detecting Conflicting Interactions between Smart Home IoT Applications\n", "abstract": " Smart home devices provide the convenience of remotely control-ling and automating home appliances. The most advanced smart home environments allow developers to write apps to make smart home devices work together to accomplish tasks, eg, home security and energy conservation. A smart home app typically implements narrow functionality and thus to fully implement desired functionality homeowners may need to install multiple apps. These different apps can conflict with each other and these conflicts can result in undesired actions such as locking the door during a fire.", "num_citations": "6\n", "authors": ["273"]}
{"title": "{ALERT}: Accurate Learning for Energy and Timeliness\n", "abstract": " An increasing number of software applications incorporate runtime Deep Neural Networks (DNNs) to process sensor data and return inference results to humans. Effective deployment of DNNs in these interactive scenarios requires meeting latency and accuracy constraints while minimizing energy, a problem exacerbated by common system dynamics.", "num_citations": "6\n", "authors": ["273"]}
{"title": "Hytrace: A hybrid approach to performance bug diagnosis in production cloud infrastructures\n", "abstract": " Server applications running inside production cloud infrastructures are prone to various performance problems (e.g., software hang, performance slowdown). When those problems occur, developers often have little clue to diagnose those problems. In this paper, we present Hytrace, a novel hybrid approach to diagnosing performance problems in production cloud infrastructures. Hytrace combines rule-based static analysis and runtime inference techniques to achieve higher bug localization accuracy than pure-static and pure-dynamic approaches for performance bugs. Hytrace does not require source code and can be applied to both compiled and interpreted programs such as C/C++ and Java. We conduct experiments using real performance bugs from seven commonly used server applications in production cloud infrastructures. The results show that our approach can significantly improve the performance bug\u00a0\u2026", "num_citations": "6\n", "authors": ["273"]}
{"title": "Trace2TAP: Synthesizing Trigger-Action Programs from Traces of Behavior\n", "abstract": " Two common approaches for automating IoT smart spaces are having users write rules using trigger-action programming (TAP) or training machine learning models based on observed actions. In this paper, we unite these approaches. We introduce and evaluate Trace2TAP, a novel method for automatically synthesizing TAP rules from traces (time-stamped logs of sensor readings and manual actuations of devices). We present a novel algorithm that uses symbolic reasoning and SAT-solving to synthesize TAP rules from traces. Compared to prior approaches, our algorithm synthesizes generalizable rules more comprehensively and fully handles nuances like out-of-order events. Trace2TAP also iteratively proposes modified TAP rules when users manually revert automations. We implemented our approach on Samsung SmartThings. Through formative deployments in ten offices, we developed a clustering/ranking\u00a0\u2026", "num_citations": "5\n", "authors": ["273"]}
{"title": "Applying Hardware Transactional Memory for Concurrency-Bug Failure Recovery in Production Runs\n", "abstract": " Concurrency bugs widely exist and severely threaten system availability. Techniques that help recover from concurrency-bug failures during production runs are highly desired. This paper proposes BugTM, an approach that leverages Hardware Transactional Memory (HTM) on commodity machines for production-run concurrency-bug recovery. Requiring no knowledge about where are concurrency bugs, BugTM uses static analysis and code transformation to insert HTM instructions into multi-threaded programs. These BugTM-transformed programs will then be able to recover from a concurrency-bug failure by rolling back and re-executing the recent history of a failure thread. BugTM greatly improves the recovery capability of state-of-the-art techniques with low run-time overhead and no changes to OS or hardware, while guarantees not to introduce new bugs.", "num_citations": "5\n", "authors": ["273"]}
{"title": "Understanding the interleaving-space overlap across inputs and software versions\n", "abstract": " In the multi-core era, it is critical to effectively test multithreaded software and expose concurrency bugs before software release. Previous work has made a lot of progress in exercising the interleaving space and detecting concurrency bugs under a given input. Unfortunately, since software often has many test inputs and constant pressure to release new versions, existing techniques are still too expensive in practice. In this position paper, we use open-source software to study how interleavings, data races and atomicity violations particularly, overlap across test inputs and software versions. We also conduct preliminary explorations to improve the testing efficiency of multi-threaded software by avoiding redundant analysis across inputs and software versions.", "num_citations": "5\n", "authors": ["273"]}
{"title": "Orthogonalized SGD and nested architectures for anytime neural networks\n", "abstract": " We propose a novel variant of SGD customized for training network architectures that support anytime behavior: such networks produce a series of increasingly accurate outputs over time. Efficient architectural designs for these networks focus on re-using internal state; subnetworks must produce representations relevant for both imme-diate prediction as well as refinement by subse-quent network stages. We consider traditional branched networks as well as a new class of re-cursively nested networks. Our new optimizer, Orthogonalized SGD, dynamically re-balances task-specific gradients when training a multitask network. In the context of anytime architectures, this optimizer projects gradients from later out-puts onto a parameter subspace that does not in-terfere with those from earlier outputs. Experi-ments demonstrate that training with Orthogonal-ized SGD significantly improves generalization accuracy of anytime networks.", "num_citations": "4\n", "authors": ["273"]}
{"title": "Managing data constraints in database-backed web applications\n", "abstract": " Database-backed web applications manipulate large amounts of persistent data, and such applications often contain constraints that restrict data length, data value, and other data properties. Such constraints are critical in ensuring the reliability and usability of these applications. In this paper, we present a comprehensive study on where data constraints are expressed, what they are about, how often they evolve, and how their violations are handled. The results show that developers struggle with maintaining consistent data constraints and checking them across different components and versions of their web applications, leading to various problems. Guided by our study, we developed checking tools and API enhancements that can automatically detect such problems and improve the quality of such applications.", "num_citations": "4\n", "authors": ["273"]}
{"title": "RDE: Replay DEbugging for Diagnosing Production Site Failures\n", "abstract": " Online service failures in production computing environments are notoriously difficult to debug. One of the key challenges is to allow the developer to replay the failure execution within an interactive debugging tool such as GDB. Previous work has proposed in-situ approaches to inferring the production-run failure path within the production environment. However, those tools may sometimes suggest failure execution paths that are infeasible to reach by any program inputs. Moreover, production site often does not record or provide failure-triggering inputs due to the user privacy concern. In this paper, we present RDE, a Replay DEbug system that can replay a production-site failure at the development site within an interactive debugging environment without requiring user inputs. RDE takes an inferred production failure path as input and performs execution synthesis using a new guided symbolic execution technique\u00a0\u2026", "num_citations": "4\n", "authors": ["273"]}
{"title": "Thread interception and analysis\n", "abstract": " Apparatus and methods for intercepting and analyzing threads are disclosed. In one embodiment, a thread data recorder is configured to instrument one or more existing functions by modifying computer executable instructions in the functions to intercept threads calling the functions. In one possible implementation, the number of existing functions instrumented can be reduced by instrumenting choke point functions. The instrumented functions can also capture data associated with the threads as the threads execute at the function. This data can be saved to memory and compressed into logs. In one aspect, the data can be saved and/or compressed at a time when processor resources are being used at or below predetermined level. The captured data can be used to analyze a functioning of a computer system in which the threads were produced.", "num_citations": "4\n", "authors": ["273"]}
{"title": "Visualizing Differences to Improve End-User Understanding of Trigger-Action Programs\n", "abstract": " Trigger-action programming lets end-users automate and connect IoT devices and online services through if-this-then-that rules. Early research demonstrated this paradigm's usability, but more recent work has highlighted complexities that arise in realistic scenarios. As users manually modify or debug their programs, or as they use recently proposed automated tools to the same end, they may struggle to understand how modifying a trigger-action program changes its ultimate behavior. To aid in this understanding, we prototype user interfaces that visualize differences between trigger-action programs in syntax, behavior, and properties.", "num_citations": "3\n", "authors": ["273"]}
{"title": "Automatically detecting distributed concurrency errors in cloud systems\n", "abstract": " A method for detecting distributed concurrency errors in a distributed cloud computing system includes tracing operations that access objects in functions involving inter-process messaging, applying a set of happens-before rules to the traced operations. Analyzing the traced operations to identify concurrent operations that access a common object to generate a list of potential distributed concurrency errors (DCbugs). Pruning the list of DCbugs to remove DCbugs having only local effect and that do not generate run-time errors.", "num_citations": "3\n", "authors": ["273"]}
{"title": "How are distributed bugs diagnosed and fixed through system logs?\n", "abstract": " ContextDistributed systems are the backbone of today\u2019s computing ecosystems. Debugging distributed bugs is crucial and challenging. There are still many unknowns about debugging real-world distributed bugs, especially through system logs.ObjectiveThis paper aims to provide a comprehensive study of how system logs can help diagnose and fix distributed bugs in practice.MethodThe study was carried out with three core research questions (RQs): How to identify failures in distributed bugs through logs? How to find and utilize bug-related log entries to figure out the root causes? How are distributed bugs fixed and how are logs and patches related? To answer these questions, we studied 106 real-world distributed bugs randomly sampled from five widely used distributed systems, and manually checked the bug report, the log, the patch, the source code and other related information for each of these bugs\u00a0\u2026", "num_citations": "2\n", "authors": ["273"]}
{"title": "View-Driven Optimization of Database-Backed Web Applications.\n", "abstract": " This paper describes HYPERLOOP, a system for optimizing databasebacked web applications (DBWAs). Current approaches in optimizing DBWAs focus on partitioning the application among the browser, application server, and the database, and rely on each component to optimize their portion individually without developer intervention. We argue that this approach misses the goal of DB-WAs in optimizing for end-user experience, and fails to leverage domain-specific knowledge that DBWA developers have. For instance, a news website might prioritize loading of the news headlines, even at the expense of slowing down loading of other visual elements on the page. HYPERLOOP illustrates the idea of viewdriven optimization by allowing developers to specify priorities for each of the elements on the webpage, and uses such information to drive optimization of the entire webpage. HYPERLOOP currently focus on optimizing for render time of webpage components, and our preliminary results show that this view-driven approach can substantially improve DBWA performance by leveraging developer provided application knowledge.", "num_citations": "2\n", "authors": ["273"]}
{"title": "ALERT: Accurate Anytime Learning for Energy and Timeliness\n", "abstract": " An increasing number of software applications incorporate runtime Deep Neural Network (DNN) inference for its great accuracy in many problem domains. While much prior work has separately tackled the problems of improving DNN-inference accuracy and improving DNN-inference efficiency, an important problem is under-explored: disciplined methods for dynamically managing application-specific latency, accuracy, and energy tradeoffs and constraints at run time. To address this need, we propose ALERT, a co-designed combination of runtime system and DNN nesting technique. The runtime takes latency, accuracy, and energy constraints, and uses dynamic feedback to predict the best DNN-model and system power-limit setting. The DNN nesting creates a type of flexible network that efficiently delivers a series of results with increasing accuracy as time goes on. These two parts well complement each other\u00a0\u2026", "num_citations": "2\n", "authors": ["273"]}
{"title": "A low complexity 2-power transform for video compression\n", "abstract": " Video applications in mobile devices call for low complexity video compression algorithms. This paper presents a low complexity 2-power transform for video compression. The elements of the transform matrix are all in 2's low-order power. The transform computation requires only 28 additions and 10 binary shifts. Computational complexity analysis, coding gains and RD curve comparison show that our 2-power transform is simpler than IntDCT and ICT, while its compression efficiency is similar to that of IntDCT, higher than that of ICT and much higher than that of DT and WHT. The low magnitude of the elements also avoids large memory consumption, a problem of many integer transforms.", "num_citations": "1\n", "authors": ["273"]}