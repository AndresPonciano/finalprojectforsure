{"title": "A systematic review of software maintainability prediction and metrics\n", "abstract": " This paper presents the results of a systematic review conducted to collect evidence on software maintainability prediction and metrics. The study was targeted at the software quality attribute of maintainability as opposed to the process of software maintenance. The evidence was gathered from the selected studies against a set of meaningful and focused questions. 710 studies were initially retrieved; however of these only 15 studies were selected; their quality was assessed; data extraction was performed; and data was synthesized against the research questions. Our results suggest that there is little evidence on the effectiveness of software maintainability prediction techniques and models.", "num_citations": "292\n", "authors": ["167"]}
{"title": "A comparative study of cost estimation models for web hypermedia applications\n", "abstract": " Software cost models and effort estimates help project managers allocate resources, control costs and schedule and improve current practices, leading to projects finished on time and within budget. In the context of Web development, these issues are also crucial, and very challenging given that Web projects have short schedules and very fluidic scope. In the context of Web engineering, few studies have compared the accuracy of different types of cost estimation techniques with emphasis placed on linear and stepwise regressions, and case-based reasoning (CBR). To date only one type of CBR technique has been employed in Web engineering. We believe results obtained from that study may have been biased, given that other CBR techniques can also be used for effort prediction. Consequently, the first objective of this study is to compare the prediction accuracy of three CBR techniques to estimate the\u00a0\u2026", "num_citations": "257\n", "authors": ["167"]}
{"title": "Web metrics-estimating design and authoring effort\n", "abstract": " Like any software process, Web application development would benefit from early-stage effort estimates. Using an undergraduate university course as a case study, we collected metrics corresponding to Web applications, developers and tools. Then we used those metrics to generate models for predicting design and authoring effort for future Web applications.", "num_citations": "163\n", "authors": ["167"]}
{"title": "Further comparison of cross-company and within-company effort estimation models for web applications\n", "abstract": " This paper extends a previous study, using data on 67 Web projects from the Tukutuku database, investigating to what extent a cross-company cost model can be successfully employed to estimate effort for projects that belong to a single company, where no projects from this company were used to build the cross-company model. Our within-company model employed data on 14 Web projects from a single Web company. Our results were similar to those from the previous study, showing that predictions based on the within-company model were significantly more accurate than those based on the cross-company model. We also found that predictions were very poor when the within-company cost model was used to estimate effort for 53 Web projects from different companies. We analysed the data using two techniques, forward stepwise regression and case-based reasoning. We found estimates produced using\u00a0\u2026", "num_citations": "161\n", "authors": ["167"]}
{"title": "Why comparative effort prediction studies may be invalid\n", "abstract": " Background: Many cost estimation papers are based on finding a\" new\" estimation method, trying out the method on one or two past datasets and\" proving\" that the new method is better than linear regression. Aim: This paper aims to explain why this approach to model comparison is often invalid and to suggest that the PROMISE repository may be making things worse. Method: We identify some of the theoretical problems with studies that compare different estimation models. We review some of the commonly used datasets from the viewpoint of the reliability of the data and the validity of the proposed linear regression models. Discussion points: It is invalid to select one or two datasets to\" prove\" the validity of a new technique because we cannot be sure that, of the many published datasets, those chosen are the only ones that favour the new technique. When new models are compared with regression models\u00a0\u2026", "num_citations": "159\n", "authors": ["167"]}
{"title": "Web engineering\n", "abstract": " Since its original inception back in 1989 the Web has changed into an environment where Web applications range from small-scale information dissemination applications, often developed by non-IT professionals, to large-scale, commercial, enterprise-planning and scheduling applications, developed by multidisciplinary teams of people with diverse skills and backgrounds and using cutting-edge, diverse technologies. As an engineering discipline, Web engineering must provide principles, methodologies and frameworks to help Web professionals and researchers develop applications and manage projects effectively. Mendes and Mosley have selected experts from numerous areas in Web engineering, who contribute chapters where important concepts are presented and then detailed using real industrial case studies. After an introduction into the discipline itself and its intricacies, the contributions range from Web effort estimation, productivity benchmarking and conceptual and model-based application development methodologies, to other important principles such as usability, reliability, testing, process improvement and quality measurement. This is the first book that looks at Web engineering from a measurement perspective. The result is a self-containing, comprehensive overview detailing the role of measurement and metrics within the context of Web engineering. This book is ideal for professionals and researchers who want to know how to use sound principles for the effective management of Web projects, as well as for courses at an advanced undergraduate or graduate level.", "num_citations": "157\n", "authors": ["167"]}
{"title": "Software productivity measurement using multiple size measures\n", "abstract": " Productivity measures based on a simple ratio of product size to project effort assume that size can be determined as a single measure. If there are many possible size measures in a data set and no obvious model for aggregating the measures into a single measure, we propose using the expression AdjustedSize/Effort to measure productivity. AdjustedSize is defined as the most appropriate regression-based effort estimation model, where all the size measures selected for inclusion in the estimation model have a regression parameter significantly different from zero (p<0.05). This productivity measurement method ensures that each project has an expected productivity value of one. Values between zero and one indicate lower than expected productivity, values greater than one indicate higher than expected productivity. We discuss the assumptions underlying this productivity measurement method and present an\u00a0\u2026", "num_citations": "155\n", "authors": ["167"]}
{"title": "Software process improvement success factors for small and medium Web companies: A qualitative study\n", "abstract": " ContextThe context of this research is software process improvement (SPI) in small and medium Web companies.ObjectiveThe primary objective of this paper is to identify software process improvement (SPI) success factors for small and medium Web companies.MethodTo achieve this goal, we conducted semi-structured, open-ended interviews with 21 participants representing 11 different companies in Pakistan, and analyzed the data qualitatively using the Glaserian strand of grounded theory research procedures. The key steps of these procedures that were employed in this research included open coding, focused coding, theoretical coding, theoretical sampling, constant comparison, and scaling up.ResultsAn initial framework of key SPI success factors for small and medium Web companies was proposed, which can be of use for small and medium Web companies engaged in SPI. The paper also differentiates\u00a0\u2026", "num_citations": "133\n", "authors": ["167"]}
{"title": "Bayesian network models for web effort prediction: a comparative study\n", "abstract": " The objective of this paper is to compare, using a cross-company dataset, several Bayesian network (BN) models for Web effort estimation. Eight BNs were built; four automatically using Hugin and PowerSoft tools with two training sets, each with 130 Web projects from the Tukutuku database; four using a causal graph elicited by a domain expert, with parameters automatically fit using the same training sets used in the automated elicitation (hybrid models). Their accuracy was measured using two validation sets, each containing data on 65 projects, and point estimates. As a benchmark, the BN-based estimates were also compared to estimates obtained using manual stepwise regression (MSWR), case-based reasoning (CBR), mean- and median-based effort models. MSWR presented significantly better predictions than any of the BN models built herein, and in addition was the only technique to provide significantly\u00a0\u2026", "num_citations": "120\n", "authors": ["167"]}
{"title": "A comparison of development effort estimation techniques for web hypermedia applications\n", "abstract": " Several studies have compared the prediction accuracy of different types of techniques with emphasis placed on linear and stepwise regressions, and case-based reasoning (CBR). We believe the use of only one type of CBR technique may bias the results, as there are others that can also be used for effort prediction. This paper has two objectives. The first is to compare the prediction accuracy of three CBR techniques to estimate the effort to develop Web hypermedia applications. The second objective is to compare the prediction accuracy of the best CBR technique, according to our findings, against three commonly used prediction models, namely multiple linear regression, stepwise regression and regression trees. One dataset was used in the estimation process and the results showed that different measures of prediction accuracy gave different results. MMRE and MdMRE showed better prediction accuracy for\u00a0\u2026", "num_citations": "114\n", "authors": ["167"]}
{"title": "Investigating web size metrics for early web cost estimation\n", "abstract": " This paper\u2019s aim is to bring light to this issue by identifying size metrics and cost drivers for early Web cost estimation based on current practices of several Web Companies worldwide. This is achieved using two surveys and a case study. The first survey (S1) used a search engine to obtain Web project quote forms employed by Web companies worldwide to provide initial quotes on Web development projects. The 133 Web project quote forms gathered data on size metrics, cost factors, contingency and possibly profit metrics. These metrics were organised into categories and ranked. Results indicated that the two most common size metrics used for Web cost estimation were \u201ctotal number of Web pages\u201d (70%) and \u201cwhich features/functionality to be provided by the application\u201d (66%).The results of S1 were then validated by a mature Web company that has more than 12\u00a0years of experience in Web development and a\u00a0\u2026", "num_citations": "111\n", "authors": ["167"]}
{"title": "A systematic review of Web engineering research\n", "abstract": " This paper uses a systematic literature review as means of investigating the rigor of claims arising from Web engineering research. Rigor is measured using criteria combined from software engineering research. We reviewed 173 papers and results have shown that only 5% would be considered rigorous methodologically. In addition to presenting our results, we also provide suggestions for improvement of Web engineering research based on lessons learnt by the software engineering community.", "num_citations": "110\n", "authors": ["167"]}
{"title": "Investigating pair-programming in a 2nd-year software development and design computer science course\n", "abstract": " This paper presents the results of a pair programming experiment conducted at the University of Auckland (NZ) during the first semester of 2004. It involved 300 second year Computer Science students attending a software design and construction course. We investigated similar issues to those reported in [26] and employed a subset of the questionnaires used by Laurie Williams et al. on the experiments presented in [26]. Our results support the use of pair programming as an effective programming/design learning technique.", "num_citations": "99\n", "authors": ["167"]}
{"title": "A comparison of case-based reasoning approaches\n", "abstract": " Over the years software engineering researchers have suggested numerous techniques for estimating development effort. These techniques have been classified mainly as algorithmic, machine learning and expert judgement. Several studies have compared the prediction accuracy of those techniques, with emphasis placed on linear regression, stepwise regression, and Case-based Reasoning (CBR). To date no converging results have been obtained and we believe they may be influenced by the use of the same CBR configuration. The objective of this paper is twofold. First, to describe the application of case-based reasoning for estimating the effort for developing Web hypermedia applications. Second, comparing the prediction accuracy of different CBR configurations, using two Web hypermedia datasets. Results show that for both datasets the best estimations were obtained with weighted Euclidean distance\u00a0\u2026", "num_citations": "98\n", "authors": ["167"]}
{"title": "The need for web engineering: An introduction\n", "abstract": " The objective of this chapter is three-fold. First, it provides an overview of differences between Web and software development with respect to their development processes, technologies, quality factors, and measures. Second, it provides definitions for terms used throughout the book. Third, it discusses the need for empirical investigations in Web engineering and presents the three main types of empirical investigations \u2014 surveys, case studies, and formal experiments.", "num_citations": "97\n", "authors": ["167"]}
{"title": "Comparison of Web size measures for predicting Web design and authoring effort\n", "abstract": " Software practitioners recognise the importance of realistic estimates of effort for the successful management of software projects, the Web being no exception. Estimates are necessary throughout the whole development life cycle. They are fundamental when bidding for a contract or when determining a project's feasibility in terms of cost-benefit analysis. In addition, they allow project managers and development organisations to manage resources effectively. Size, which can be described in terms of length, functionality and complexity, is often a major determinant of effort. Most effort prediction models to date concentrate on functional measures of size, although length and complexity are also essential aspects of size. A case study evaluation is described, in which size metrics characterising length, complexity and functionality are obtained and used to generate effort prediction models for Web authoring and design\u00a0\u2026", "num_citations": "91\n", "authors": ["167"]}
{"title": "A replicated experiment of pair-programming in a 2nd-year software development and design computer science course\n", "abstract": " This paper presents the results of a replicated pair programming experiment conducted at the University of Auckland (NZ) during the first semester of 2005. It involved 190 second year Computer Science students attending a software design and construction course. We replicated the experiment described in [18], investigating similar issues to those reported in [32] and employing a subset of the questionnaires used in [32]. Our results confirm the use of pair programming as an effective programming/design learning technique.", "num_citations": "82\n", "authors": ["167"]}
{"title": "A replicated comparison of cross-company and within-company effort estimation models using the isbsg database\n", "abstract": " Four years ago was the last time the ISBSG database was used to compare the effort prediction accuracy between cross-company and within-company cost models. Since then more than 2,000 projects have been volunteered to this database, which may have changed the trends previously observed. This paper therefore replicates a previous study by investigating how successful a cross-company cost model is: i) to estimate effort for projects that belong to a single company and were not used to build the cross-company model; ii) compared to a within-company cost model. Our within-company data set had data on 184 software projects from a single company and our cross-company data set employed data on 672 software projects. Our results did not corroborate those from the previous study, showing that predictions based on the within-company model were not significantly more accurate than those based on the\u00a0\u2026", "num_citations": "81\n", "authors": ["167"]}
{"title": "Applying moving windows to software effort estimation\n", "abstract": " Models for estimating software development effort are commonly built and evaluated using a set of historical projects. An important question is which projects to use as training data to build the model: should it be all of them, or a subset that seems particularly relevant? One factor to consider is project age: is it best to use the entire history of past projects, or is it more appropriate in a rapidly changing world to use a window of recent projects? We investigate the effect on estimation accuracy of using a moving window, using projects from the ISBSG data set. We find that using a moving window can improve accuracy, and we make some observations about factors that influence the range of possible window sizes and the best window size.", "num_citations": "77\n", "authors": ["167"]}
{"title": "A replicated assessment of the use of adaptation rules to improve Web cost estimation\n", "abstract": " Analogy-based estimation has, over the last 15 years, and particularly over the last 7 years, emerged as a promising approach with comparable accuracy to, or better than, algorithmic methods. In addition, it is potentially easier to both understand and apply; these two important factors can contribute to the successful adoption of estimation methods within Web development companies. We believe therefore, analogy-based estimation should be examined further. This paper replicates previous work that investigated the use of two types of adaptation rules as a contributing factor to better estimation accuracy. In addition, it also investigates the use of feature subset selection, in addition to adaptation rules. Two datasets are used in the analysis; results show that adaptation rules improved estimation accuracy for the less \"messy\" dataset. Feature subset selection also seems to help improve the adaptation results.", "num_citations": "76\n", "authors": ["167"]}
{"title": "Cross-company and single-company effort models using the ISBSG database: a further replicated study\n", "abstract": " Five years ago the ISBSG database was used by Jeffery et al.[6](S1) to compare the effort prediction accuracy between cross-and single-company effort models. Given that more than 2,000 projects were later volunteered to this database, in 2005 Mendes et al.[17](S2) replicated S1 but obtained different results. The difference in results between both studies could have resulted from legitimate differences in data set patterns but also could have been influenced by differences in experimental procedure. S2 was unable to employ exactly the same experimental procedure used in S1, as S1's procedure was not fully documented. Therefore this paper aimed to apply S2's experimental procedure to the ISBSG database version used in S1 (release 6) to assess if differences in experimental procedure would have contributed towards different results. Our results corroborated those from S1: we found that predictions based\u00a0\u2026", "num_citations": "74\n", "authors": ["167"]}
{"title": "Experiences conducting systematic reviews from novices\u2019 perspective\n", "abstract": " Background:  A systematic review (SR) is a sound methodology for collecting evidence on a research topic of interest and establishing the context of future research. Unlike ordinary or even expert literature reviews, SRs are systematic thus increasing the confidence in the findings from the previous published literature. SRs can be carried out by both experienced and novice researchers; however, while expert researchers. experiences with conducting SRs are important for improving the SR body of knowledge, we believe that novice researchers. experiences are equally important to establish what distinct problems they face while carrying out SRs. With a prior knowledge of these issues, novice researchers can better plan their SRs and seek guidance from expert researchers. Aim:  The aim of this paper is therefore to report on experiences conducting SRs from the perspective of novice researchers. The paper reports first hand experiences of novices conducting SRs and compares them with the experiences of an expert as well as with the experiences reported in the previous literature. Method:  An instrument was created and used to gather the experiences conducting SRs from three PhD students and their supervisor. The instrument covered all the SR steps; it was individually filled out by each of the participating subjects and its data was later on aggregated. Results:  The results show that the problems faced by novices in terms of time taken to conduct the review; defining the research questions, inclusion/exclusion criteria, data extraction and data synthesis forms are not faced by expert researchers. Moreover, problems faced by novices related\u00a0\u2026", "num_citations": "70\n", "authors": ["167"]}
{"title": "Early Web size measures and effort prediction for Web costimation\n", "abstract": " Size measures for Web costimation proposed in the literature are invariably related to implemented Web applications. Even when targeted at measuring functionality based on function point analysis, researchers only considered the final Web application, rather than requirements documentation generated using any existing Web development methods. This makes their usefulness as early effort predictors questionable. In addition, it is believed that company-specific data provide a better basis for accurate estimates. Many software engineering researchers have compared the accuracy of company-specific data with multiorganisation databases. However the datasets employed were comprised of data from conventional applications. To date no similar comparison has been adopted for Web project datasets. It has two objectives: The first is to present a survey where early size measures for Web costimation were\u00a0\u2026", "num_citations": "65\n", "authors": ["167"]}
{"title": "Investigating early web size measures for web cost estimation\n", "abstract": " This paper\u2019s aim is to bring light to this issue by identifying early size metrics and cost drivers for Web cost estimation based on current practices of several Web Companies worldwide. This is achieved using two surveys and a case study. The first survey (S1) used a search engine to obtain Web project quote forms employed by Web companies worldwide to provide initial quotes on Web development projects. The 133 Web project quote forms gathered data on early size metrics, cost factors, contingency and possibly profit metrics. These metrics were organised into categories and ranked. Results indicated that the two most common early size metrics used for Web cost estimation were \u201ctotal number of Web pages\u201d(70%) and \u201cwhich features/functionality to be provided by the application\u201d(66%). The results of S1 were then validated by a mature Web company that has more than 12 years of experience in Web development and a portfolio of more than 50 Web applications. The analysis was conducted using an interview. Finally, once the case study was finished, a second validation was conducted using a survey (S2) involving local New Zealand Web companies. The results of both validations were used to prepare Web project data entry forms to gather data on Web projects worldwide. After gathering data on 67 real Web projects worldwide, multivariate regression applied to the data confirmed that the number of Web pages and features/functionality provided by the application to be developed were the two most influential effort predictors.", "num_citations": "65\n", "authors": ["167"]}
{"title": "A systematic literature review of software process improvement in small and medium web companies\n", "abstract": " The objective of this paper is to identify existing Software Process Improvement (SPI) models and techniques used by small and medium Web companies. We performed a systematic review of studies that applied SPI models and techniques to Web companies. Four papers applied SPI techniques or models to Web companies, and our results showed that none suggested any customized model or technique to measure the SPI of Web companies. The SLR also revealed the characteristics of some small and medium companies and suggested that they have tight budget constraints, tight deadlines and a short term strategy. Finally, our SLR showed that the measures of success for small and medium Web companies included development team and client satisfaction, increase in productivity, compliance with standards and overall operational excellence. The results of this review showed that very few studies\u00a0\u2026", "num_citations": "62\n", "authors": ["167"]}
{"title": "Replicating studies on cross-vs single-company effort models using the ISBSG Database\n", "abstract": " In 2001 the ISBSG database was used by Jeffery et al. (Using public domain metrics to estimate software development effort. Proceedings Metrics\u201901, London, pp 16\u201327, 2001; S1) to compare the effort prediction accuracy between cross- and single-company effort models. Given that more than 2,000 projects were later volunteered to this database, in 2005 Mendes et al. (A replicated comparison of cross-company and within-company effort estimation models using the ISBSG Database, in Proceedings of Metrics\u201905, Como, 2005; S2) replicated S1 but obtained different results. The difference in results could have occurred due to legitimate differences in data set patterns; however, they could also have occurred due to differences in experimental procedure given that S2 was unable to employ exactly the same experimental procedure used in S1 because S1\u2019s procedure was not fully documented. Recently, we\u00a0\u2026", "num_citations": "61\n", "authors": ["167"]}
{"title": "Cost estimation techniques for web projects\n", "abstract": " Having realistic estimates of effort at an early stage in a Web project's life is vital to the successful management of resources. The principles of the prediction process are identifying the influencing factors, gathering past project data, generating an effort prediction model, and assessing the effectiveness of such prediction model. Cost Estimation Techniques for Web Projects provides a step-by-step methodology to improving cost estimation practices for Web projects. Utilizing such techniques as stepwise regression modeling, case-base reasoning, classification and regression trees, and expert opinion, this book is a powerful tool for scholars, researchers, and practitioners in the areas of Web development, Web engineering, project management, and software engineering.", "num_citations": "60\n", "authors": ["167"]}
{"title": "Measurement and effort prediction for Web applications\n", "abstract": " Accurate estimates of development effort play an important role in the successful management of larger Web development projects. However, estimating the effort required in developing Web applications can be a difficult task. By applying measurement principles to measure the quality of applications and their development processes, feedback can be obtained to help control, improve and predict products and processes. Although to date most work in software effort estimation has focused on algorithmic cost models, in recent years research in the field of effort estimation has started to move towards non-algorithmic models, where \u201cestimation by analogy\u201d is one of the available techniques. The first part of this paper describes a case study evaluation (CSE) where proposed metrics and the effort involved in authoring Web applications were measured. The second half presents the use of analogy and two\u00a0\u2026", "num_citations": "60\n", "authors": ["167"]}
{"title": "Using forward snowballing to update systematic reviews in software engineering\n", "abstract": " Background: A Systematic Literature Review (SLR) is a methodology used to aggregate relevant evidence related to one or more research questions. Whenever new evidence is published after the completion of a SLR, this SLR should be updated in order to preserve its value. However, updating SLRs involves significant effort. Objective: The goal of this paper is to investigate the application of forward snowballing to support the update of SLRs. Method: We compare outcomes of an update achieved using the forward snowballing versus a published update using the search-based approach, ie, searching for studies in electronic databases using a search string. Results: Forward snowballing showed a higher precision and a slightly lower recall. It reduced in more than five times the number of primary studies to filter however missed one relevant study. Conclusions: Due to its high precision, we believe that the use of\u00a0\u2026", "num_citations": "59\n", "authors": ["167"]}
{"title": "A systematic review of web resource estimation\n", "abstract": " Background: Web development plays an important role in today's industry, so an in depth view into Web resource estimation would be valuable. However a systematic review (SR) on Web resource estimation in its entirety has not been done.Aim: The aim of this paper is to present a SR of Web resource estimation in order to define the current state of the art, and to identify any research gaps that may be present.Method: Research questions that would address the current state of the art in Web resource estimation were first identified. A comprehensive literature search was then executed resulting in the retrieval of 84 empirical studies that investigated any aspect of Web resource estimation. Data extraction and synthesis was performed on these studies with these research questions in mind.Results: We have found that there are no guidelines with regards to what resource estimation technique should be used in a\u00a0\u2026", "num_citations": "58\n", "authors": ["167"]}
{"title": "The application of case-based reasoning to early Web project cost estimation\n", "abstract": " Literature shows that over the years numerous techniques for estimating development effort have been suggested, derived from late project measures. However, to the successful management of software projects, estimates are necessary throughout the whole development life cycle. The objective is twofold. First, we describe the application of case-based reasoning (CBR) for estimating Web hypermedia development effort using measures collected at different stages in the development cycle. Second, we compare the prediction accuracy of those measures, obtained using different CBR configurations. Contrary to the expected, late measures did not show statistically significant better predictions than early measures.", "num_citations": "58\n", "authors": ["167"]}
{"title": "Towards a theoretical framework of SPI success factors for small and medium web companies\n", "abstract": " ContextThe context of this research is software process improvement (SPI) success factors for small and medium Web companies.ObjectiveThe primary objective of this paper is to propose a theoretical framework of SPI success factors for small and medium Web companies.MethodThe theoretical framework presented in this study aggregated the results of three previous research phases by applying principles of theoretical integration and comparative analysis. Those three previous phases were all empirical in nature, and comprise: a systematic review of SPI in small and medium Web companies [1], [2]; a replication study [3] and a grounded theory-based initial exploratory framework of factors in small and medium Web companies [4].ResultsThe theoretical framework includes 18 categories of SPI success factors, 148 properties of these categories and 25 corresponding relationships, which bind these categories\u00a0\u2026", "num_citations": "49\n", "authors": ["167"]}
{"title": "The use of Bayesian networks for web effort estimation: further investigation\n", "abstract": " The objective of this paper is to further investigate the use of Bayesian Networks (BN) for Web effort estimation when using a cross-company dataset. Four BNs were built; two automatically using the Hugin tool with two training sets; two using a structure elicited by a domain expert, with parameters obtained from automatically fitting the network to the same training sets used in the automated elicitation (hybrid models). The accuracy of all four models was measured using two validation sets, and point estimates. As a benchmark, the BN-based predictions were also compared to predictions obtained using Manual StepWise Regression (MSWR), and Case-Based Reasoning (CBR). The BN model generated using Hugin presented similar accuracy to CBR and Mean effort-based predictions. Our results suggest that Hybrid BN models can provide significantly superior prediction accuracy. However, good results also\u00a0\u2026", "num_citations": "49\n", "authors": ["167"]}
{"title": "Further investigation into the use of cbr and stepwise regression to predict development effort for web hypermedia applications\n", "abstract": " To date studies using CBR for Web hypermedia effort prediction have not applied adaptation rules to adjust effort according to a given criterion. In addition, when applying n-fold cross-validation, their analysis has been limited to a maximum of three training sets, which according to recent studies, may lead to untrustworthy results. This paper has therefore two objectives. The first is to further investigate the use of CBR for Web hypermedia effort prediction by comparing the prediction accuracy of eight CBR techniques, of which three have previously been compared. The second objective is to compare the prediction accuracy of the best CBR technique against stepwise regression, using a twenty-fold cross-validation. All prediction accuracies were measured using Mean Magnitude of Relative Error (MMRE), Median Magnitude of Relative Error, Prediction at level 1 (1=25%), and boxplots of the residuals. One dataset\u00a0\u2026", "num_citations": "49\n", "authors": ["167"]}
{"title": "Measurement, prediction and risk analysis for Web applications\n", "abstract": " Accurate estimates of development effort play an important role in the successful management of larger Web development projects. By applying measurement principles to measure qualities of the applications and their development processes, feedback can be obtained to help understand, control and improve products and processes. The objective of this paper is to present a Web design and authoring prediction model based on a set of metrics which were collected using a case study evaluation (CSE). The paper is organised into three parts. Part I describes the CSE in which the metrics used in the prediction model were collected. These metrics were organised into five categories: effort metrics, structure metrics, complexity metrics, reuse metrics and size metrics. Part II presents the prediction model proposed, which was generated using a generalised linear model (GLM), and assesses its predictive power. Finally\u00a0\u2026", "num_citations": "49\n", "authors": ["167"]}
{"title": "Web development effort estimation using analogy\n", "abstract": " Although estimating the effort required in developing Web applications is a difficult task, accurate estimates of development effort have an important role to play in the successful management of Web development projects. In software development work to date, emphasis has focused on algorithmic cost models such as COCOMO and function points. Two disadvantages of these models are firstly, the need for calibration of a model for each individual measurement environment and, secondly, the variable accuracy levels achieved even after calibration. The paper describes the use of estimation by analogy to calculate the development effort of Web applications. Two datasets containing empirical Web development data were used in the case study. One set contained data relating to forty-one novice developers, the other to twenty-nine experienced developers. The ANGEL tool supporting the automatic collection\u00a0\u2026", "num_citations": "48\n", "authors": ["167"]}
{"title": "A comparison of techniques for web effort estimation\n", "abstract": " The objective of this paper is to extend the work by Mendes (2007), and to compare four techniques for Web effort estimation to identify which one provides best prediction accuracy. We employed four effort estimation techniques - Bayesian networks (BN), forward stepwise regression (SWR), case-based reasoning (CBR) and Classification and regression trees (CART) to obtain effort estimates. The dataset employed was of 150 Web projects from the Tukutuku dataset. Results showed that predictions obtained using a BN were significantly superior to those using other techniques. A model that incorporates the uncertainty inherent in effort estimation, can outperform other commonly used techniques, such as those used in this study.", "num_citations": "46\n", "authors": ["167"]}
{"title": "Empirical research methods in Web and software Engineering\n", "abstract": " Web and software engineering are not only about technical solutions. They are to a large extent also concerned with organisational issues, project management and human behaviour. For disciplines like Web and software engineering, empirical methods are crucial, since they allow for incorporating human behaviour into the research approach taken. Empirical methods are common practice in many other disciplines. This chapter provides a motivation for the use of empirical methods in Web and software engineering research. The main motivation is that it is needed from an engineering perspective to allow for informed and well-grounded decisions. The chapter continues with a brief introduction to four research methods: controlled experiments, case studies, surveys and post-mortem analyses. These methods are then put into an improvement context. The four methods are presented with the objective to\u00a0\u2026", "num_citations": "46\n", "authors": ["167"]}
{"title": "Comprehension of object-oriented software cohesion: the empirical quagmire\n", "abstract": " Chidamber and Kemerer (1991) proposed an object-oriented (OO) metric suite which included the Lack of Cohesion Of Methods (LCOM) metric. Despite considerable effort both theoretically and empirically since then, the software engineering community is still no nearer finding a generally accepted definition or measure of OO cohesion. Yet, achieving highly cohesive software is a cornerstone of software comprehension and hence, maintainability. In this paper, we suggest a number of suppositions as to why a definition has eluded (and we feel will continue to elude) us. We support these suppositions with empirical evidence from three large C++ systems and a cohesion metric based on the parameters of the class methods; we also draw from other related work. Two major conclusions emerge from the study. Firstly, any sensible cohesion metric does at least provide insight into the features of the systems being\u00a0\u2026", "num_citations": "39\n", "authors": ["167"]}
{"title": "Software cost estimation models using radial basis function neural networks\n", "abstract": " Radial Basis Function Neural Networks (RBFN) have been recently studied due to their qualification as an universal function approximation. This paper investigates the use of RBF neural networks for software cost estimation. The focus of this study is on the design of these networks, especially their middle layer composed of receptive fields, using two clustering techniques: the C-means and the APC-III algorithms. A comparison between a RBFN using C-means and a RBFN using APC-III, in terms of estimates accuracy, is hence presented. This study uses the COCOMO\u201981 dataset and data on Web applications from the Tukutuku database.", "num_citations": "38\n", "authors": ["167"]}
{"title": "Trends in Java code changes: the key to identification of refactorings?\n", "abstract": " Changes made to object-oriented (OO) systems over time provide an insight into both design robustness and changes in requirements. When expressed at a high level of abstraction, observing trends in changes to code can indicate opportunities for refactoring at the architectural level. In this paper, we empirically investigate the changes made to a set of fifty-two Java library classes over a three year period. The research attempts to support the hypothesis that certain types of changes made to Java code fall into distinct trends and, furthermore, are likely to be made at a high level of abstraction; in this case to method signatures. Our empirical results show that change trends are identifiable thus informing well-known refactorings, but not as we had envisaged. Control logic constructs were found to be the focus of most changes to the library classes examined.", "num_citations": "38\n", "authors": ["167"]}
{"title": "Machine learning and microsimulation techniques on the prognosis of dementia: A systematic literature review\n", "abstract": " Background Dementia is a complex disorder characterized by poor outcomes for the patients and high costs of care. After decades of research little is known about its mechanisms. Having prognostic estimates about dementia can help researchers, patients and public entities in dealing with this disorder. Thus, health data, machine learning and microsimulation techniques could be employed in developing prognostic estimates for dementia.   Objective The goal of this paper is to present evidence on the state of the art of studies investigating and the prognosis of dementia using machine learning and microsimulation techniques.   Method To achieve our goal we carried out a systematic literature review, in which three large databases\u2014Pubmed, Socups and Web of Science were searched to select studies that employed machine learning or microsimulation techniques for the prognosis of dementia. A single backward snowballing was done to identify further studies. A quality checklist was also employed to assess the quality of the evidence presented by the selected studies, and low quality studies were removed. Finally, data from the final set of studies were extracted in summary tables.   Results In total 37 papers were included. The data summary results showed that the current research is focused on the investigation of the patients with mild cognitive impairment that will evolve to Alzheimer\u2019s disease, using machine learning techniques. Microsimulation studies were concerned with cost estimation and had a populational focus. Neuroimaging was the most commonly used variable.   Conclusions Prediction of conversion from MCI to AD is the\u00a0\u2026", "num_citations": "36\n", "authors": ["167"]}
{"title": "Usage-based statistical testing of web applications\n", "abstract": " The large growth in the number of large Web applications currently developed brings concerns related to their quality, and more specifically their testing and reliability. Web application testing is still in its infancy and relies mostly upon traditional software coverage testing processes, which are highly impractical. Recent studies have looked at usage-based statistical models for testing Web applications. One of these studies, conducted by Kallepalli and Tian [8], used Unified Markov Models (UMMs), built from Web server access logs, as basis for test case selection. In addition, server error logs were also used to measure a Web application's reliability, and consequently to investigate the effectiveness of UMMs as a suitable testing mechanism. This paper describes two experiments that replicated Kallepalli and Tian's work. Our results showed that, in contrast to [8], multiple set UMMs were needed for trustworthy test\u00a0\u2026", "num_citations": "36\n", "authors": ["167"]}
{"title": "Investigating the use of duration-based moving windows to improve software effort prediction\n", "abstract": " To date most research in software effort estimation has not taken into account any form of chronological split when selecting projects for training and testing sets. A chronological split represents the use of a project's starting and completion dates, such that any model that estimates effort for a new project p only uses as its training set projects that were completed prior to p's starting date. Three recent studies investigated the use of chronological splits, using a type of chronological split called a moving window, which represented a subset of the most recent projects completed prior to a project p's starting date. They found some evidence in favour of using windows whenever projects were recent. These studies all defined window sizes as being fixed numbers of recent projects. In practice, we suggest that estimators are more likely to think in terms of elapsed time than the size of the data set, when deciding which\u00a0\u2026", "num_citations": "34\n", "authors": ["167"]}
{"title": "Predicting web development effort using a Bayesian network\n", "abstract": " The objective of this paper is to investigate the use of a Bayesian Network (BN) for Web effort estimation. We built a BN automatically using the HUGIN tool and data on 120 Web projects from the Tukutuku database. In addition the BN model and node probability tables were also validated by a Web project manager from a well-established Web company in Rio de Janeiro (Brazil). The accuracy was measured using data on 30 projects (validation set), and point estimates (1-fold cross-validation using a 80%-20% split). The estimates obtained using the BN were also compared to estimates obtained using forward stepwise regression (SWR) as this is one of the most frequently used techniques for software and Web effort estimation. Our results showed that BN-based predictions were better than previous predictions from Web-based cross-company models, and significantly better than predictions using SWR. Our results suggest that, at least for the dataset used, the use of a model that allows the representation of uncertainty, inherent in effort estimation, can outperform other commonly used models, such as those built using multivariate regression techniques.", "num_citations": "34\n", "authors": ["167"]}
{"title": "On the performance of hybrid search strategies for systematic literature reviews in software engineering\n", "abstract": " ContextWhen conducting a Systematic Literature Review (SLR), researchers usually face the challenge of designing a search strategy that appropriately balances result quality and review effort. Using digital library (or database) searches or snowballing alone may not be enough to achieve high-quality results. On the other hand, using both digital library searches and snowballing together may increase the overall review effort.ObjectiveThe goal of this research is to propose and evaluate hybrid search strategies that selectively combine database searches with snowballing.MethodWe propose four hybrid search strategies combining database searches in digital libraries with iterative, parallel, or sequential backward and forward snowballing. We simulated the strategies over three existing SLRs in SE that adopted both database searches and snowballing. We compared the outcome of digital library searches\u00a0\u2026", "num_citations": "33\n", "authors": ["167"]}
{"title": "Bone age assessment with various machine learning techniques: A systematic literature review and meta-analysis\n", "abstract": " BACKGROUND The assessment of bone age and skeletal maturity and its comparison to chronological age is an important task in the medical environment for the diagnosis of pediatric endocrinology, orthodontics and orthopedic disorders, and legal environment in what concerns if an individual is a minor or not when there is a lack of documents. Being a time-consuming activity that can be prone to inter- and intra-rater variability, the use of methods which can automate it, like Machine Learning techniques, is of value.   OBJECTIVE The goal of this paper is to present the state of the art evidence, trends and gaps in the research related to bone age assessment studies that make use of Machine Learning techniques.   METHOD A systematic literature review was carried out, starting with the writing of the protocol, followed by searches on three databases: Pubmed, Scopus and Web of Science to identify the relevant evidence related to bone age assessment using Machine Learning techniques. One round of backward snowballing was performed to find additional studies. A quality assessment was performed on the selected studies to check for bias and low quality studies, which were removed. Data was extracted from the included studies to build summary tables. Lastly, a meta-analysis was performed on the performances of the selected studies.   RESULTS 26 studies constituted the final set of included studies. Most of them proposed automatic systems for bone age assessment and investigated methods for bone age assessment based on hand and wrist radiographs. The samples used in the studies were mostly comprehensive or bordered the age\u00a0\u2026", "num_citations": "32\n", "authors": ["167"]}
{"title": "The use of a bayesian network for web effort estimation\n", "abstract": " The objective of this paper is to describe the use of a probabilistic approach to Web effort estimation by means of a Bayesian Network. A Bayesian Network is a model that embodies existing knowledge of a complex domain in a way that supports reasoning with uncertainty. Given that the causal system relative to Web effort estimation has an inherently uncertain nature the use of Bayesian model seemed a reasonable choice. We used a cross-company data set of 150 industrial Web projects volunteered from Web companies worldwide, which are part of the Tukutuku database. Results showed that the effort estimates obtained using a Bayesian Network were sound and significantly superior to the prediction based on two benchmark models, using the mean and median effort respectively.", "num_citations": "32\n", "authors": ["167"]}
{"title": "Object-oriented cohesion as a surrogate of software comprehension: an empirical study\n", "abstract": " The concept of software cohesion in both the procedural and object-oriented paradigm is well known and documented. What is not so well known or documented is the perception of what empirically constitutes a cohesive 'unit' by software engineers. In this paper, we describe an empirical investigation using object-oriented (OO) classes as a basis. Twenty-four subjects (drawn from IT experienced and IT inexperienced groups) were asked to rate ten classes sampled from two industrial systems in terms of their overall cohesiveness; a class environment was used to carry out the study. Four key results were observed. Firstly, class size (when expressed in terms of number of methods) did not tend to influence the perception of cohesion by any subjects. Secondly, well-commented classes were rated most highly amongst both IT experienced and inexperienced subjects. Thirdly, the empirical study suggests that\u00a0\u2026", "num_citations": "32\n", "authors": ["167"]}
{"title": "An extended systematic review of software process improvement in small and medium web companies\n", "abstract": " Objective-The objective of this paper is to present the current state of research in Software Process Improvement (SPI) models and techniques used by small and medium Web development companies. Method-A previously conducted systematic review (Sulayman and Mendes, 2009) has been updated and extended to identify the current state of research on the mentioned topic. Results Eight studies applied SPI techniques or models to small and medium Web companies. The selected studies did not suggest any customized model or technique to measure the SPI of small and medium Web companies. The characteristics of some small and medium companies such as tight budget constraints, tight deadlines and a short term strategy were also identified. The measures of success for small and medium Web companies, as per SR results, include development team and client satisfaction, increase in productivity\u00a0\u2026", "num_citations": "31\n", "authors": ["167"]}
{"title": "Investigating the use of chronological splitting to compare software cross-company and single-company effort predictions: a replicated study\n", "abstract": " CONTEXT: Three previous studies have investigated the use of chronological split to compare cross- to single-company effort predictions, where all used the ISBSG dataset release 10. Therefore there is a need for these studies to be replicated using different datasets such that the patterns previously observed can be compared and contrasted, and a better understanding with regard to the use of chronological splitting can be reached. OBJECTIVE: The aim of this study is to replicate [17] using the same chronological splitting; however a different database - the Finnish dataset. METHOD: Chronological splitting was compared with two forms of cross-validation. The chronological splitting used was the project-by-project chronological split, in which a validation set contains a single project, and a regression model is built from scratch using as training set the set of projects completed before the validation project\u2019s start date. We used 201 single-company projects and 593 cross-company projects from the Finnish dataset. RESULTS: Single-company models presented significantly better prediction than cross-company models. Chronological splitting provided significantly worse accuracy than leave-one and leave-two out cross-validations when based on single-company data; and provided similar accuracy when based on cross-company data. CONCLUSIONS: Results did not seem promising when using project-by-project splitting; however in a real scenario companies that use their own data can only apply some sort of chronological splitting when obtaining effort estimates for their new projects. Therefore we urge the use of chronological splitting in\u00a0\u2026", "num_citations": "31\n", "authors": ["167"]}
{"title": "Do adaptation rules improve web cost estimation?\n", "abstract": " Analogy-based estimation has, over the last 15 years, and particularly over the last 7 years, emerged as a promising approach with comparable accuracy to, or better than, algorithmic methods in some studies. In addition, it is potentially easier to understand and apply; these two important factors can contribute to the successful adoption of estimation methods within Web development companies. We believe therefore, analogy-based estimation should be examined further. This paper compares several methods of analogy-based effort estimation. In particular, it investigates the use of adaptation rules as a contributing factor to better estimation accuracy. Two datasets are used in the analysis; results show that the best predictions are obtained for the dataset that first, presents a continuous\" cost\" function, translated as a strong linear relationship between size and effort, and second, is more\" unspoiled\" in terms of\u00a0\u2026", "num_citations": "31\n", "authors": ["167"]}
{"title": "Investigating the use of duration-based moving windows to improve software effort prediction: A replicated study\n", "abstract": " ContextMost research in software effort estimation has not considered chronology when selecting projects for training and testing sets. A chronological split represents the use of a projects starting and completion dates, such that any model that estimates effort for a new project p only uses as training data projects that were completed prior to p\u2019s start. Four recent studies investigated the use of chronological splits, using moving windows wherein only the most recent projects completed prior to a projects starting date were used as training data. The first three studies (S1\u2013S3) found some evidence in favor of using windows; they all defined window sizes as being fixed numbers of recent projects. In practice, we suggest that estimators think in terms of elapsed time rather than the size of the data set, when deciding which projects to include in a training set. In the fourth study (S4) we showed that the use of windows\u00a0\u2026", "num_citations": "30\n", "authors": ["167"]}
{"title": "Investigating the use of a hybrid search strategy for systematic reviews\n", "abstract": " [Background] Systematic Literature Reviews (SLRs) are one of the important pillars when employing an evidence-based paradigm in Software Engineering. To date most SLRs have been conducted using a search strategy involving several digital libraries. However, significant issues have been reported for digital libraries and applying such search strategy requires substantial effort. On the other hand, snowballing has recently arisen as a potentially more efficient alternative or complementary solution. Nevertheless, it requires a relevant seed set of papers. [Aims] This paper proposes and evaluates a hybrid search strategy combining searching in a specific digital library (Scopus) with backward and forward snowballing. [Method] The proposed hybrid strategy was applied to two previously published SLRs that adopted database searches. We investigate whether it is able to retrieve the same included papers with\u00a0\u2026", "num_citations": "28\n", "authors": ["167"]}
{"title": "Practitioner\u2019s Knowledge Representation\n", "abstract": " The main goal in writing this book was to help organisations improve their effort estimates and their effort estimation processes by providing a step-by-step methodology that takes them through the building and validation of models that are based on their own knowledge and experience. Such models, once validated, can be used to obtain predictions, carry out risk analyses, help organisations with their decisionmaking when estimating effort for new projects and set a pathway to making those organisations into learning organisations.This methodology, called expert-based knowledge engineering of Bayesian networks (EKEBNs), has been adapted by the author as a result of several collaborations with six different companies in New Zealand and Brazil. Domain experts from each company participated in the elicitation of bespoke models for effort estimation. The building of such models led those companies to\u00a0\u2026", "num_citations": "28\n", "authors": ["167"]}
{"title": "When to update systematic literature reviews in software engineering\n", "abstract": " [Context] Systematic Literature Reviews (SLRs) have been adopted by the Software Engineering (SE) community for approximately 15 years to provide meaningful summaries of evidence on several topics. Many of these SLRs are now potentially outdated, and there are no systematic proposals on when to update SLRs in SE. [Objective] The goal of this paper is to provide recommendations on when to update SLRs in SE. [Method] We evaluated, using a three-step approach, a third-party decision framework (3PDF) employed in other fields, to decide whether SLRs need updating. First, we conducted a literature review of SLR updates in SE and contacted the authors to obtain their feedback relating to the usefulness of the 3PDF within the context of SLR updates in SE. Second, we used these authors\u2019 feedback to see whether the framework needed any adaptation; none was suggested. Third, we applied the 3PDF to\u00a0\u2026", "num_citations": "27\n", "authors": ["167"]}
{"title": "Building an expert-based web effort estimation model using Bayesian networks\n", "abstract": " OBJECTIVE - The objective of this paper is to describe a case study where Bayesian Networks (BNs) were used to construct an expert-based Web effort model. METHOD - We built a single-company BN model solely elicited from expert knowledge, where the domain expert was an experienced Web project manager from a small Web company in Auckland, New Zealand. This model was validated using data from eight past finished Web projects. RESULTS - The BN model has to date been successfully used to estimate effort for four Web projects, providing effort estimates superior to those based solely on expert opinion. CONCLUSIONS - Our results suggest that, at least for the Web Company that participated in this case study, the use of a model that allows the representation of uncertainty, inherent in effort estimation, can outperform expert-based estimates. Another five companies have also benefited from using Bayesian Networks, with very promising results.", "num_citations": "27\n", "authors": ["167"]}
{"title": "Evolution of Web Applications with Aspect-Oriented Design Patterns.\n", "abstract": " Evolution of Web Applications with Aspect-Oriented Design Patterns - eserved@d = *@let@token ICWE 2007 --- Como, Italy July 1 Page 1 Evolution of Web Applications with Aspect-Oriented Design Patterns Evolution of Web Applications with Aspect-Oriented Design Patterns ICWE 2007 \u2014 Como, Italy July 19, 2007 Michal Bebjak1 Valentino Vrani\u01071 Peter Dolog2 Institute of Informatics and Software Engineering Faculty of Informatics and Information Technology Slovak University of Technology, Ilkovi\u010dova 3, 84216 Bratislava 4, Slovakia bebjak02@student.fiit.stuba.sk,vranic@fiit.stuba.sk Department of Computer Science Aalborg University Fredrik Bajers Vej 7, building E DK-9220 Aalborg EAST dolog@cs.aau.dk July 19, 2007 1 / 15 Page 2 Evolution of Web Applications with Aspect-Oriented Design Patterns Overview 1 Changes as Crosscutting Concerns 2 Aspect-Oriented Change Realization Framework 3 Aspect--\u2026", "num_citations": "27\n", "authors": ["167"]}
{"title": "Investigating the use of chronological splitting to compare software cross-company and single-company effort predictions\n", "abstract": " CONTEXT: Numerous studies have investigated the use of cross-company datasets to estimate effort for single-company projects; however to date only one has compared the effect of using a chronological split instead of a random split to assign projects to a training set and a validation set, finding no significant differences. OBJECTIVE: The aim of this study is to extend [15] using a project-by-project chronological split, and also to investigate how this type of split affects the results when comparing within- to cross-company effort estimation. METHOD: Chronological splitting was compared with two forms of cross-validation. Here a more realistic form of chronological splitting than the one used in [15] is investigated, in which a validation set contains a single project, and a regression model is built from scratch using as training set the set of projects completed before the validation project\u2019s start date. We used 228 single-company projects and 678 cross-company projects from the ISBSG Release 10 repository. RESULTS: We obtained contradictory results when comparing cross- to single-company predictions for single-company projects. First, when results were compared using absolute residuals there were no differences between cross- and single-company predictions, or between techniques. However, when using z values, chronological splitting favoured cross-company models, and cross-validation (both types) favoured single-company models. CONCLUSIONS: Results were promising when using project-by-project splitting because: i) they favoured cross-company models; and ii) this type of splitting mimics an effort estimation scenario in a real\u00a0\u2026", "num_citations": "25\n", "authors": ["167"]}
{"title": "Towards a taxonomy of hypermedia and web application size metrics\n", "abstract": " Surveying and classifying previous work on a particular field have several benefits, which are: i) to help organise a given body of knowledge; ii) to provide results that can help identify gaps that need to be filled; iii) to provide a categorization that can also be applied or adapted to other surveys; iv) to provide a classification and summary of results that may benefit researchers who wish to carry out meta-analyses. This paper presents a survey literature of hypermedia and Web size metrics published within the last 12 years and classifies the surveyed studies according to a proposed taxonomy. In addition, we also discuss the changes, mainly in the motivation for size metrics, that have occurred during our review period.", "num_citations": "25\n", "authors": ["167"]}
{"title": "Using knowledge elicitation to improve web effort estimation: Lessons from six industrial case studies\n", "abstract": " This paper details our experience building and validating six different expert-based Web effort estimation models for ICT companies in New Zealand and Brazil. All models were created using Bayesian networks, via eliciting knowledge from domain experts, and validated using data from past finished projects. Post-mortem interviews with the participating companies showed that they found the entire process extremely beneficial and worthwhile, and that all the models created remained in use by those companies.", "num_citations": "24\n", "authors": ["167"]}
{"title": "Investigating the use of chronological split for software effort estimation\n", "abstract": " In previous studies, the authors investigated separately the use of two different types of chronological splits (project-by-project split and date-based split) for assigning projects to training sets and testing sets. The aim of this study is to compare the two types of chronological splits against each other, to see whether either leads to better prediction accuracy. Estimation models were built and evaluated using training and testing sets formed using project-by-project chronological splitting and date-based splitting using two different splitting dates. The authors used 906 projects from the ISBSG Release 10 repository. The authors found no significant differences between the accuracy of models built and evaluated with either of the different splitting methods. However, models built using later splitting dates were more accurate than models built using earlier splitting dates. Different accuracy with different splitting dates\u00a0\u2026", "num_citations": "24\n", "authors": ["167"]}
{"title": "Web metrics-Metrics for estimating effort to design and author Web applications\n", "abstract": " The World Wide Web (WWW) has become the best known example of a hypermedia system. To date, numerous organisations world-wide have developed thousands of commercial and/or educational Web applications. However, developing good quality applications has a high cost, mostly in time and amount of difficulty involved for the authors. By applying measurement principles to measure the quality of applications and their development processes, feedback can be obtained to help control, improve and predict products and processes. The first part of this paper describes a case study evaluation (CSE) where we collected metrics corresponding to Web applications, developers and tools used in the development. In addition, we also measured the effort involved in designing and authoring Web applications. The second half explores how we can use the measurements obtained to predict the effort for design and\u00a0\u2026", "num_citations": "23\n", "authors": ["167"]}
{"title": "A comparison of cross-versus single-company effort prediction models for web projects\n", "abstract": " Background: In order to address the challenges in companies having no or limited effort datasets of their own, cross-company models have been a focus of interest for previous studies. Further, a particular domain of investigation has been Web projects. Aim: This study investigates to what extent effort predictions obtained using cross-company (CC) datasets are effective in relation to the predictions obtained using single-company (SC) datasets within the domain of web projects. Method: This study uses the Tukutuku database. We employed data on 125 projects from eight different companies and built cross and single-company models with stepwise linear regression (SWR) with and without relevancy filtering. We also benchmarked these models against mean and median based models. We report a case-by-case analysis per company as well as a meta-analysis of the findings. Results: Results showed that CC\u00a0\u2026", "num_citations": "22\n", "authors": ["167"]}
{"title": "Hyper-authoring for education: a qualitative evaluation\n", "abstract": " The complexity involved in hypermedia authoring has lead to many different proposals of models, methodologies and systems. And this complexity can become even greater when the purpose is to develop applications for education.In this paper we describe a qualitative evaluation that analysed the processes involved in the authoring of hypermedia applications for education by interviewing both researchers and lecturers from the University of Southampton involved in the development of hypermedia. This study is part of a research project called SHAPE, the aim of which is to aid authors in the development of good quality large-scale applications for education. In the project, the quality characteristics considered are reusability of information, maintainability of applications and authoring effort.The results show that there is little point in trying to improve the authoring of hypermedia applications for education by\u00a0\u2026", "num_citations": "22\n", "authors": ["167"]}
{"title": "Guidelines for the search strategy to update systematic literature reviews in software engineering\n", "abstract": " ContextSystematic Literature Reviews (SLRs) have been adopted within Software Engineering (SE) for more than a decade to provide meaningful summaries of evidence on several topics. Many of these SLRs are now potentially not fully up-to-date, and there are no standard proposals on how to update SLRs in SE.ObjectiveThe objective of this paper is to propose guidelines on how to best search for evidence when updating SLRs in SE, and to evaluate these guidelines using an SLR that was not employed during the formulation of the guidelines.MethodTo propose our guidelines, we compare and discuss outcomes from applying different search strategies to identify primary studies in a published SLR, an SLR update, and two replications in the area of effort estimation. These guidelines are then evaluated using an SLR in the area of software ecosystems, its update and a replication.ResultsThe use of a single\u00a0\u2026", "num_citations": "20\n", "authors": ["167"]}
{"title": "Quantitative assessments of key success factors in software process improvement for small and medium web companies\n", "abstract": " This replicated study investigates SPI success factors for small and medium Web companies using data from 20 Pakistani Web companies and 72 respondents. It applies the same theoretical model of SPI success factors, techniques and data collection questionnaire proposed and employed in [17]; however, it differs from [17] in that Dyba investigated SPI success factors for software companies, whereas this study focuses solely on Web companies. Therefore the contribution of this work is twofold: i) to replicate Dyba's study assessing similarity of patterns within the context of small and medium Web companies; ii) to extend the theoretical model proposed in [19][21] to small and medium Web companies. The significance of six contributing independent variables, 42 sub-factors and the effects of two moderating variables on dependent variable SPI success have been analyzed.", "num_citations": "20\n", "authors": ["167"]}
{"title": "Using chronological splitting to compare cross-and single-company effort models: further investigation\n", "abstract": " Numerous studies have used historical datasets to build and validate models for estimating software development effort. Very few used a chronological split (where projects\u2019 end dates are used so that training sets only contain projects that were completed before the start date of each project in the validation set), and only one compared chronological split to random split. Therefore the aim of this study is to investigate further and compare the use of chronological and random splitting. We do so in the context of comparing cross-company and singlecompany models for effort estimation. We used 450 single-company projects and 741 cross-company projects from the ISBSG Release 10 repository, and estimates were obtained using manual stepwise regression. We found that with these data the use of chronological splitting, and different splitting dates, did not affect prediction accuracy. We were not able to obtain a converging set of findings when comparing cross-to single-company predictions given that different accuracy measures presented contradictory results.", "num_citations": "20\n", "authors": ["167"]}
{"title": "A probabilistic approach to web portal's data quality evaluation\n", "abstract": " Advances in technology and the use of the Internet have favoured the emergence of a large number of Web applications, including Web Portals. Web portals provide the means to obtain a large amount of information therefore it is crucial that the information provided is of high quality. In recent years, several research projects have investigated Web Data Quality; however none has focused on data quality within the context of Web Portals. Therefore, the contribution of this research is to provide a framework centred on the point of view of data consumers, and that uses a probabilistic approach for Web portal's data quality evaluation. This paper shows the definition of operational model, based in our previous work.", "num_citations": "20\n", "authors": ["167"]}
{"title": "Towards the prediction of development effort for hypermedia applications\n", "abstract": " Accurate estimates of development effort play an important role in the successful management of larger hypermedia development projects. By applying measurement principles to measure characteristics of the applications and their development processes, feedback can be obtained to help understand, control and improve future applications and corresponding processes.", "num_citations": "20\n", "authors": ["167"]}
{"title": "The relationship between personality and decision-making: A Systematic literature review\n", "abstract": " ContextFrom a point of view, software development is a set of decisions that need to be made while the software is developed. Many alternatives should be considered, such as the technology to employ, or the most important features to implement. However, many factors can influence one\u2019s decision-making, such as the decision maker\u2019s personality.ObjectiveThis paper reports the state of the art with regard to the relationship between decision-makers\u2019 personality and decision-making aspects.MethodWe conducted a Systematic Literature Review to search and analyze published primary studies that discuss the abovementioned relationship in the context of companies that develop any kind of product or service.ResultsDespite the recognized influence of personality in decision-making activities, we were not able to find any study in Software Engineering field that discusses this relationship. We included 15 studies\u00a0\u2026", "num_citations": "19\n", "authors": ["167"]}
{"title": "Investigating the use of moving windows to improve software effort prediction: a replicated study\n", "abstract": " To date most research in software effort estimation has not taken chronology into account when selecting projects for training and validation sets. A chronological split represents the use of a project\u2019s starting and completion dates, such that any model that estimates effort for a new project p only uses as its training set projects that have been completed prior to p\u2019s starting date. A study in 2009 (\u201cS3\u201d) investigated the use of chronological split taking into account a project\u2019s age. The research question investigated was whether the use of a training set containing only the most recent past projects (a \u201cmoving window\u201d of recent projects) would lead to more accurate estimates when compared to using the entire history of past projects completed prior to the starting date of a new project. S3 found that moving windows could improve the accuracy of estimates. The study described herein replicates S3 using three\u00a0\u2026", "num_citations": "19\n", "authors": ["167"]}
{"title": "Architectural level hypothesis testing through reverse engineering of object-oriented software\n", "abstract": " Comprehension of an object oriented (OO) system, its architecture and use of OO features such as aggregation, generalisation and other forms of association is a difficult task to undertake without the original design documentation for reference. A reverse engineering tool was used to reproduce the UML design documentation from code of three industrial sized systems. High level class metrics were then collected directly from the design documents. Three hypotheses were tested to establish relationships between these high level features and the low level class features of number of class methods and attributes. A further hypothesis was tested to determine features of key classes in a system. Results indicated that, whilst no clear patterns emerged for hypotheses relating to generalisation, there was a clear (positive) statistical significance for all three systems studied between aggregation, other types of association\u00a0\u2026", "num_citations": "19\n", "authors": ["167"]}
{"title": "A comparison of length, complexity & functionality as size measures for predicting web design & authoring effort\n", "abstract": " Software practitioners recognise the importance of realistic estimates of effort to the successful management of software projects, the Web being no exception. Estimates are necessary throughout the whole development life cycle. They are fundamental when bidding for a contract or when determining a project\u2019s feasibility in terms of cost-benefit analysis. In addition, they allow project managers and development organisations to manage resources effectively. Size, which can be described in terms of length, functionality and complexity, is often a major determinant of effort. Most effort prediction models to date concentrate on functional measures of size, although length and complexity are also essential aspects of size.The first half of this paper describes a case study evaluation in which size metrics characterising length, complexity and functionality were obtained and used to generate effort prediction models for Web authoring and design. The second half describes the comparison of those size metrics as effort predictors by generating corresponding prediction models and comparing their accuracy using boxplots of the residuals. Results suggest that in general all categories presented a similar prediction accuracy.", "num_citations": "18\n", "authors": ["167"]}
{"title": "Object-oriented cohesion subjectivity amongst experienced and novice developers: an empirical study\n", "abstract": " The concept of software cohesion in both the procedural and object-oriented paradigm is well known and documented. What is not so well known or documented is the perception of what empirically constitutes a cohesive 'unit' by software engineers. In this paper, we describe an empirical investigation using object-oriented (OO) classes as a basis. Twenty-four subjects (drawn from IT experienced and novice groups) were asked to rate ten classes sampled from two industrial systems in terms of their overall cohesiveness; a class environment was used to carry out the study. Three hypotheses were investigated as part of the study, relating to class size, the role of comment lines and the differences between the two groups in terms of how they rated cohesion. Several key results were observed. Firstly, class size (when expressed in terms of number of methods) only influenced the perception of cohesion by novice\u00a0\u2026", "num_citations": "16\n", "authors": ["167"]}
{"title": "Web effort estimation\n", "abstract": " Software effort models and effort estimates help project managers allocate resources, control costs, and schedule and improve current practices, leading to projects that are finished on time and within budget. In the context of Web development and maintenance, these issues are also crucial, and very challenging, given that Web projects have short schedules and a highly fluidic scope. Therefore this chapter has two main objectives. The first is to introduce the concepts related to effort estimation and in particular Web effort estimation. The second is to present a case study where a real effort prediction model based on data from completed industrial Web projects is constructed step by step.", "num_citations": "15\n", "authors": ["167"]}
{"title": "Exploring case-based reasoning for web hypermedia project cost estimation\n", "abstract": " This paper compares several methods of analogy-based effort estimation, including the use of adaptation rules as a contributing factor to better estimation accuracy. Two data sets are used in the analysis. Results show that best predictions were obtained for the dataset that presented a continuous 'cost' function and was more 'unspoiled'.", "num_citations": "15\n", "authors": ["167"]}
{"title": "Knowledge representation using Bayesian networks\u2014a case study in Web effort estimation\n", "abstract": " This paper's objective is twofold: i) to present a methodology employed to build company-specific effort estimation models that incorporate expert knowledge and the uncertainty inherent to this complex domain; ii) to report on a case study where one such model was completely built from expert-knowledge for a Multimedia company in Auckland (New Zealand). It contains 36 factors and 48 causal relationships, and was validated using data from 22 past finished projects. This model has to date been successfully used to estimate effort for the Web projects developed by that company.", "num_citations": "14\n", "authors": ["167"]}
{"title": "Web cost estimation and productivity benchmarking\n", "abstract": " Web cost estimation models and productivity analysis reports help project managers allocate resources more adequately, control costs, schedule and improve current practices, leading to projects that are finished on time and within budget. Therefore this chapter has two main objectives. The first is to introduce the concepts related to Web cost estimation & Web applications\u2019 sizing and present a case study where a real Web cost model is built; the second is to introduce the concepts of productivity measurement & benchmarking, and to also present a case study on productivity benchmarking.", "num_citations": "13\n", "authors": ["167"]}
{"title": "Comparing effort prediction models for web design and authoring using boxplots\n", "abstract": " Software practitioners recognise the importance of realistic estimates of effort to the successful management of software projects, the Web being no exception. Having realistic estimates at an early stage in a project's life-cycle allow project managers and development organisations to manage resources effectively. Prediction is a necessary part of an effective process, be it authoring, design, testing, or Web development as a whole. The first part of this paper describes a case study evaluation (CSE) where we measured the characteristics of Web applications and the effort involved in designing and authoring those applications. The second half presents two prediction models generated using statistical techniques, namely linear regression and stepwise multiple regression. The prediction power of the models employed is then compared using boxplots of the residuals. The results suggest that stepwise regression\u00a0\u2026", "num_citations": "13\n", "authors": ["167"]}
{"title": "Investigating the relationship between personalities and agile team climate of software professionals in a telecom company\n", "abstract": " ContextPrevious research found that the performance of a team not only depends on the team personality composition, but also on the interactive effects of team climate. Although investigation on personalities associated with software development has been an active research area over the past decades, there has been very limited research in relation to team climate.ObjectiveOur study investigates the association between the five factor model personality traits (openness to experience, conscientiousness, extraversion, agreeableness and neuroticism) and the factors related to team climate (team vision, participative safety, support for innovation and task orientation) within the context of agile teams working in a telecom company.MethodA survey was used to gather data on personality characteristics and team climate perceptions of 43 members from eight agile teams. The data was initially used for correlation\u00a0\u2026", "num_citations": "12\n", "authors": ["167"]}
{"title": "Key stakeholders\u2019 value propositions for feature selection in software-intensive products: An industrial case study\n", "abstract": " Numerous software companies are adopting value-based decision making. However, what does value mean for key stakeholders making decisions? How do different stakeholder groups understand value? Without an explicit understanding of what value means, decisions are subject to ambiguity and vagueness, which are likely to bias them. This case study provides an in-depth analysis of key stakeholders\u2019 value propositions when selecting features for a large telecommunications company's software-intensive product. Stakeholders\u2019 value propositions were elicited via interviews, which were analyzed using Grounded Theory coding techniques (open and selective coding). Thirty-six value propositions were identified and classified into six dimensions: customer value, market competitiveness, economic value/profitability, cost efficiency, technology & architecture, and company strategy. Our results show that\u00a0\u2026", "num_citations": "12\n", "authors": ["167"]}
{"title": "Building a Web Effort Estimation Model Through Knowledge Elicitation.\n", "abstract": " OBJECTIVE\u2013The objective of this paper is to describe a case study where Bayesian Networks (BNs) were used to construct an expert-based Web effort model. METHOD\u2013We built a single-company BN model solely elicited from expert knowledge, where the domain experts were two experienced Web project managers from a medium-size Web company in Auckland, New Zealand. This model was validated using data from eleven past finished Web projects. RESULTS\u2013The BN model has to date been successfully used to estimate effort for numerous Web projects. CONCLUSIONS\u2013Our results suggest that, at least for the Web Company that participated in this case study, the use of a model that allows the representation of uncertainty, inherent in effort estimation, can outperform expert-based estimates. Another nine companies have also benefited from using Bayesian Networks, with very promising results.", "num_citations": "12\n", "authors": ["167"]}
{"title": "Evaluating the Weighted Sum Algorithm for Estimating Conditional Probabilities in Bayesian Networks.\n", "abstract": " A Bayesian Network (BN) is a probabilistic modelling technique that allows for reasoning under uncertainty. BNs have been applied in many areas including: forecasting, estimation, classification, recognition, and inference [2, 3]. A BN consists of two components: The first is a Direct Acyclic Graph (DAG) that represents factors of interest (as nodes) and associated causal relations (as edges). For example, Figure 1 shows a naive BN for forecasting the rate of growth for a hypothetical plant, given the amount of sunlight and water it receives.", "num_citations": "12\n", "authors": ["167"]}
{"title": "Web usability measurement: Comparing logic scoring preference to subjective assessment\n", "abstract": " This paper investigates one of the existing methods for measuring usability \u2013 Logic Scoring Preference (LSP), and discusses the results of two formal experiments carried out to assess the extent to which LSP embodies the subjective perception of users in regards to Web usability. The two experiments used Computer Science students as experimental subjects. Our results suggest that scores obtained via LSP are significantly different from scores obtained via subjective opinion. In addition, we obtained contradictory results when investigating the consistency of LSP scores across subjects.", "num_citations": "12\n", "authors": ["167"]}
{"title": "Portfolio management method for deadline planning\n", "abstract": " We introduce a portfolio management method that uses effort estimates to build sets of feasible deadlines for software projects at the bidding stage. Effort estimates can involve considerable error, and this must be taken into account when selecting deadlines. We show how a simple probability model can allow for possible errors. The model is built using a single effort estimate for each current project, together with historical data on estimated and actual effort for former projects. The probability model is used in two ways: firstly to find the probability of successfully meeting a set of proposed deadlines; and secondly to select deadlines that deliver a fixed probability of success. Rather than treating projects in isolation, we work with the full company portfolio, enabling setbacks in some projects to be balanced by gain in others. Our method is implemented with demonstrations in the tool PROJMAN.", "num_citations": "12\n", "authors": ["167"]}
{"title": "Investigating metrics for a development effort prediction model of Web applications\n", "abstract": " Although there are metrics proposed in the hypermedia literature to measure hypermedia processes and products, many lack the necessary theoretical and empirical validation. To address these issues, this paper presents the results of a quantitative case study which validated empirically a set of metrics proposed to measure the development effort involved in authoring World Wide Web applications. These metrics adhere to the representational theory of measurement. The results obtained for the case study have shown that three out of four of the proposed metrics presented statistically significant correlations with development effort, suggesting that they may be useful parameters for a prediction model that estimates the effort involved in developing Web applications.", "num_citations": "11\n", "authors": ["167"]}
{"title": "Aggregating expert-driven causal maps for web effort estimation\n", "abstract": " Reliable Web effort estimation is one of the cornerstones of good Web project management. Hence the need to fully understand which factors affect a project\u2019s outcome and their causal relationships. The aim of this paper is to provide a wider understanding towards the fundamental factors affecting Web effort estimation and their causal relationships via combining six different Web effort estimation causal maps from six independent local Web companies, representing the knowledge elicited from several domain experts. The methodology used to combine these maps extended previous work by adding a mapping scheme to handle complex domains (e.g. effort estimation), and the use of an aggregation process that preserves all the causal relations in the original maps. The resultant map contains 67 factors, and also commonalities amongst Web companies relating to factors and causal relations, thus\u00a0\u2026", "num_citations": "10\n", "authors": ["167"]}
{"title": "Prognosis of dementia employing machine learning and microsimulation techniques: A systematic literature review\n", "abstract": " OBJECTIVE: The objective of this paper is to investigate the goals and variables employed in the machine learning and microsimulation studies for the prognosis of dementia.METHOD: According to preset protocols, the Pubmed, Socups and Web of Science databases were searched to find studies that matched the defined inclusion/exclusion criteria, and then its references were checked for new studies. A quality checklist assessed the selected studies, and removed the low quality ones. The remaining ones (included set) had their data extracted and summarized.RESULTS: The summary of the data of the 37 included studies showed that the most common goal of the selected studies was the prediction of the conversion from mild cognitive impairment to Alzheimer's Disease, for studies that used machine learning, and cost estimation for the microsimulation ones. About the variables, neuroimaging was the most\u00a0\u2026", "num_citations": "9\n", "authors": ["167"]}
{"title": "An overview of web effort estimation\n", "abstract": " A cornerstone of Web project management is sound effort estimation, the process by which effort is predicted and used to determine costs and allocate resources effectively, thus enabling projects to be delivered on time and within budget. Effort estimation is a complex domain where the causal relationship among factors is nondeterministic with an inherently uncertain nature. For example, assuming there is a relationship between development effort and developers\u2019 experience using the development environment, it is not necessarily true that higher experience will lead to decreased effort. However, as experience increases so does the probability of decreased effort. The objective of this chapter is to provide an introduction to the process of estimating effort, discuss existing techniques used for effort estimation, and explain how a Web company can take into account the uncertainty inherent to effort estimation when\u00a0\u2026", "num_citations": "9\n", "authors": ["167"]}
{"title": "Design level hypothesis testing through reverse engineering of object-oriented software\n", "abstract": " Comprehension of an object-oriented (OO) system, its design and use of OO features such as aggregation, generalisation and other forms of association is a difficult task to undertake without the original design documentation for reference. In this paper, we describe the collection of high-level class metrics from the UML design documentation of five industrial-sized C++ systems. Two of the systems studied were libraries of reusable classes. Three hypotheses were tested between these high-level features and the low-level class features of a number of class methods and attributes in each of the five systems. A further two conjectures were then investigated to determine features of key classes in a system and to investigate any differences between library-based systems and the other systems studied in terms of coupling.         Results indicated that, for the three application-based systems, no clear patterns emerged for\u00a0\u2026", "num_citations": "9\n", "authors": ["167"]}
{"title": "Using an engineering approach to understanding and predicting Web authoring and design\n", "abstract": " Software practitioners recognise the importance of realistic estimates of effort to the successful management of software projects, the Web being no exception. Having realistic estimates at an early stage in a project's life-cycle allows project managers and development organisations to manage resources effectively. Prediction is a necessary part of an effective process, whether it be authoring, design, testing or Web development as a whole. The first part of this paper describes a case study evaluation (CSE) where we measured characteristics of Web applications and the effort involved in designing and authoring those applications. The second half explores how we can use the measurements obtained to predict the effort involved in designing and authoring future Web applications. The prediction models employed were two algorithmic models - linear regression and stepwise multiple regression. Although the\u00a0\u2026", "num_citations": "9\n", "authors": ["167"]}
{"title": "Search strategy to update systematic literature reviews in software engineering\n", "abstract": " [Context] Systematic Literature Reviews (SLRs) have been adopted within the Software Engineering (SE) domain for more than a decade to provide meaningful summaries of evidence on several topics. Many of these SLRs are now outdated, and there are no standard proposals on how to update SLRs in SE. [Objective] The goal of this paper is to provide recommendations on how to best to search for evidence when updating SLRs in SE. [Method] To achieve our goal, we compare and discuss outcomes from applying different search strategies to identifying primary studies in a previously published SLR update on effort estimation. [Results] The use of a single iteration forward snowballing with Google Scholar, and employing the original SLR and its primary studies as a seed set seems to be the most cost-effective way to search for new evidence when updating SLRs. [Conclusions] The recommendations can be\u00a0\u2026", "num_citations": "8\n", "authors": ["167"]}
{"title": "An insight into the capabilities of professionals and teams in agile software development: A systematic literature review\n", "abstract": " Background: Previous studies investigated key characteristics of software engineers and factors influencing the performance of individuals, productivity of teams and project success within agile software development (ASD). They aided in the active investigation of human aspects in ASD. However, capability measurement and prediction with respect to agile workforce, owing to its importance, is an area that needs spotlight.Objective: The objective of this paper is to present the state of the art relating to capability measurement of software engineers and teams working in ASD projects.Method: We carried out a systematic literature review (SLR) focused on identifying attributes used for measuring and predicting the capabilities of individual software engineers and teams.Results: Evidence from 16 studies showed attributes that can measure capabilities of engineers and teams, and also attributes that can be used as\u00a0\u2026", "num_citations": "8\n", "authors": ["167"]}
{"title": "Assessing the weighted sum algorithm for automatic generation of probabilities in Bayesian networks\n", "abstract": " A Bayesian Network (BN) is a probabilistic reasoning technique, which to date has been used in a broad range of applications. One of the key challenges in constructing a BN is obtaining its Conditional Probability Tables (CPTs). CPTs can be learnt from data (when available), elicited from domain experts, or a combination of both. Eliciting from domain experts provides more flexibility; however, CPTs grow in size of exponentially, thus making their elicitation process very time consuming and costly. Previous work proposed a solution to this problem using the weighted sum algorithm (WSA) [9]; however no empirical results were given on the algorithm's elicitation reduction and prediction accuracy. Hence the aim of this paper is to present two empirical studies that assess the WSA's efficiency and prediction accuracy. Our results show that the estimates obtained using the WSA were highly accurate and make\u00a0\u2026", "num_citations": "8\n", "authors": ["167"]}
{"title": "RBTTool\u2013uma ferramenta de apoio \u00e0 abordagem de teste de software baseado em riscos\n", "abstract": " Risk-based Testing (RBT) consists of a set of activities regards risks identification related to software requirements. Once identified, the risks are prioritized according to its likelihood and impact and test cases are designed based on strategies for treatment of the identified risks. This article presents a tool which main goal is to provide an environment to RBT activities, giving a friendly user interface, confidence on the approach use and filling a lack that is perceived in this field.Resumo. O Teste baseado em Riscos (Risk-based Testing\u2013RBT) consiste em um conjunto de atividades relacionadas \u00e0 identifica\u00e7\u00e3o de riscos associados aos requisitos de software. Uma vez identificados, os riscos s\u00e3o priorizados de acordo com sua probabilidade e impacto e casos de teste s\u00e3o projetados para tratamento dos riscos. Este artigo apresenta a RBTTool, ferramenta, cujo principal prop\u00f3sito \u00e9 prover um ambiente de apoio \u00e0s\u00a0\u2026", "num_citations": "8\n", "authors": ["167"]}
{"title": "Using Bayesian networks to estimate strategic indicators in the context of rapid software development\n", "abstract": " Background: During Rapid Software Development, a large amount of project and development data can be collected from different and heterogeneous data sources. Aims: Design a methodology to process these data and turn it into relevant strategic indicators to help companies make meaningful decisions. Method: We adapt an existing methodology to create and estimate strategic indicators using Bayesian Networks in the context of Rapid Software Development, and applied it to a use case. Results: Applying the methodology in the use case, we create a model to predict product quality based on software factors and metrics, using companies' business knowledge and collected data. Conclusions: We proved the methodology's feasibility and obtained positive feedback from the company's use case.", "num_citations": "7\n", "authors": ["167"]}
{"title": "Improving software effort estimation using an expert-centred approach\n", "abstract": " A cornerstone of software project management is effort estimation, the process by which effort is forecasted and used as basis to predict costs and allocate resources effectively, so enabling projects to be delivered on time and within budget. Effort estimation is a very complex domain where the relationship between factors is non-deterministic and has an inherently uncertain nature, and where corresponding decisions and predictions require reasoning with uncertainty. Most studies in this field, however, have to date investigated ways to improve software effort estimation by proposing and comparing techniques to build effort prediction models where such models are built solely from data on past software projects - data-driven models. The drawback with such approach is threefold: first, it ignores the explicit inclusion of uncertainty, which is inherent to the effort estimation domain, into such models; second, it\u00a0\u2026", "num_citations": "7\n", "authors": ["167"]}
{"title": "Towards predicting maintainability for relational database-driven software applications: Extended evidence from software practitioners\n", "abstract": " The accurate maintainability prediction of relational database-driven software applications can improve the management of projects relating to these applications, thus benefitting software organisations. This paper gives an up-to-date account of the state of practice in maintainability prediction for relational database-driven software applications and provides a baseline for conducting further research in this area. The research involved conducting twelve semi-structured interviews with software professionals, which were then analysed using content analysis with the help of NVivo. The results provide both an account of the current state of practice in that area and also a list of potential maintainability predictors for relational database-driven software applications. These predictors relate to database schema, front-end application, and the interaction of database schema with the front-end application. These results provide the basis for further work involving the proposal and empirical validation of maintainability prediction models for relational database-driven software applications.", "num_citations": "7\n", "authors": ["167"]}
{"title": "Web hypermedia cost estimation: further assessment and comparison off cost estimation modelling techniques\n", "abstract": " Research into Web cost estimation is relatively new, where few studies have compared cost estimation modelling techniques for Web development, with an emphasis placed on techniques such as Case-based Reasoning (CBR), linear and stepwise regression. Although in a large subset of these studies CBR has given the best predictions, results were based on a simple type of CBR, where no adaptation rules were used to adjust the estimated effort obtained. In addition, when comparing the prediction accuracy of estimation models, analysis has been limited to a maximum of three training/validation sets, which according to recent studies, may lead to untrustworthy results. Since CBR is potentially easier to understand and apply (two important factors to the successful adoption of estimation methods within Web development companies), it should be examined further.             This paper has therefore two\u00a0\u2026", "num_citations": "7\n", "authors": ["167"]}
{"title": "The SHAPE of hypermedia authoring for education\n", "abstract": " The SHAPE of Hypermedia Authoring for Education - ePrints Soton The University of Southampton Courses University life Research Business Global About Visit Alumni Departments News Events Contact \u00d7 Search the Site Search Filter your search: All Courses Projects Staff University of Southampton Institutional Repository Search Advanced Search Policies & Help Latest Download Statistics Browse by Year Browse by Divisions LeftRight The SHAPE of Hypermedia Authoring for Education Mendes, MEX and Hall, W (1997) The SHAPE of Hypermedia Authoring for Education. Proceedings of ED-MEDIA &amp; ED-TELECOM 97, Calgary, Canada. Record type: Conference or Workshop Item (Other) Full text not available from this repository. More information Published date: May 1997 Venue - Dates: Proceedings of ED-MEDIA &amp; ED-TELECOM 97, Calgary, Canada, 1997-04-30 Organisations: Electronics & Learn : \u2026", "num_citations": "7\n", "authors": ["167"]}
{"title": "Applying knowledge elicitation to improve web effort estimation: A case study\n", "abstract": " OBJECTIVE - The objective of this paper is to describe a case study where Bayesian Networks (BNs) were used to construct an expert-based Web effort model. METHOD - We built a single-company BN model solely elicited from expert knowledge, where the domain expert was an experienced Web project manager from a small Web company in Auckland, New Zealand. This model was validated using data from 22 past finished Web projects. RESULTS - The BN model has to date been successfully used to estimate effort for numerous Web projects. CONCLUSIONS - Our results suggest that, at least for the Web Company that participated in this case study, the use of a model that allows the representation of uncertainty, inherent in effort estimation, can outperform expert-based estimates. Another nine companies have also benefited from using Bayesian Networks, with very promising results.", "num_citations": "6\n", "authors": ["167"]}
{"title": "Applying the Cognitive Flexibility Theory to Teaching Web Engineering.\n", "abstract": " Web engineering constitutes the employment of an engineering approach to the development of Web applications. Its main teaching objectives are for students to learn what an engineering approach represents and how measurement can be applied.", "num_citations": "6\n", "authors": ["167"]}
{"title": "An empirical study of hypermedia authoring for education\n", "abstract": " An Empirical Study of Hypermedia Authoring for Education - ePrints Soton The University of Southampton Courses University life Research Business Global About Visit Alumni Departments News Events Contact \u00d7 Search the Site Search Filter your search: All Courses Projects Staff University of Southampton Institutional Repository Search Advanced Search Policies & Help Latest Download Statistics Browse by Year Browse by Divisions LeftRight An Empirical Study of Hypermedia Authoring for Education Mendes, MEX and Hall, W (1997) An Empirical Study of Hypermedia Authoring for Education. Proceedings of CAL'97, Exeter, UK. Record type: Conference or Workshop Item (Other) Full text not available from this repository. More information Published date: March 1997 Venue - Dates: Proceedings of CAL'97, Exeter, UK, 1997-03-01 Organisations: Electronics & Computer Science Learn more about Electronics & ID: :\u2026", "num_citations": "6\n", "authors": ["167"]}
{"title": "Designing a capability-centric web tool to support agile team composition and task allocation: a work in progress\n", "abstract": " A significant number of studies reported models for competence profiling, measuring capabilities of professionals and recommendation systems for roles within agile software development (ASD). These models coordinated in human resource management within ASD. However, in the light of swift, incremental and iterative nature of ASD practices, designing solutions that easily integrate capability measurements with ongoing project management routines, is an important area for investigation. With the support of interviews, grounded theory procedure and workshops, we identified the aspects valued by our industrial collaborator while allocating professionals to tasks. This information was further utilized towards devising a framework for capability-centric Web tool. This tool provides a one-stop solution for project managers to create projects, keep track of capabilities and execute allocation routines.", "num_citations": "5\n", "authors": ["167"]}
{"title": "Web development versus software development\n", "abstract": " This chapter provides an overview of differences between Web and software development with respect to their development processes, technologies, quality factors and measures. It also defines terms used throughout the book.", "num_citations": "5\n", "authors": ["167"]}
{"title": "Improving project management of healthcare projects through knowledge elicitation\n", "abstract": " This chapter describes a case study where Bayesian Networks (BNs) were used to construct an expert-based software effort and risk prediction model for use by a large healthcare organisation in Auckland (New Zealand) to manage healthcare software projects delivered on the Web. This model was solely elicited from expert knowledge, with the participation of seven project managers, and was validated using data from 22 past finished projects. The model led to numerous changes in process and also in business. The company adapted their existing effort and risk management process to be in line with the model that was created, and the use of a mathematically based model also led to an increase in the number of projects being outsourced to this company by other company branches worldwide. Their predictions improved significantly too. The results suggest that the use of a model that allows the representation\u00a0\u2026", "num_citations": "5\n", "authors": ["167"]}
{"title": "Towards maintainability prediction for relational database-driven software applications: evidence from software practitioners\n", "abstract": " The accurate maintainability prediction of relational database-driven software applications can improve the project management for these applications, thus benefitting software organisations. This paper presents an up-to-date account of the state of practice in maintainability prediction for relational database-driven software applications. Twelve semi-structured interviews were conducted with software professionals. The results provide both an account of the current state of practice in that area and a list of potential maintainability predictors for relational database-driven software applications.", "num_citations": "5\n", "authors": ["167"]}
{"title": "A comparison of crosscompany and single-company effort estimation models for web applications\n", "abstract": " Five years ago the ISBSG database was used by Jeffery et al.[6](S1) to compare the effort prediction accuracy between cross-and single-company effort models. Given that more than 2,000 projects were later volunteered to this database, in 2005 Mendes et al.[17](S2) replicated S1 but obtained different results. The difference in results between both studies could have resulted from legitimate differences in data set patterns but also could have been influenced by differences in experimental procedure. S2 was unable to employ exactly the same experimental procedure used in S1, as S1\u2019s procedure was not fully documented. Therefore this paper aimed to apply S2\u2019s experimental procedure to the ISBSG database version used in S1 (release 6) to assess if differences in experimental procedure would have contributed towards different results. Our results corroborated those from S1: we found that predictions based on a single-company model were significantly more accurate than those based on a cross-company model.", "num_citations": "5\n", "authors": ["167"]}
{"title": "The cognitive flexibility theory0: an approach for teaching Hypermedia Engineering\n", "abstract": " Hypermedia engineering constitutes the employment of an engineering approach to the development of hypermedia applications. Its main teaching objectives are for students to learn what an engineering approach means and how measurement can be applied. This paper presents the application of the Cognitive Flexibility Theory as an instructional theory to teach Hypermedia Engineering principles. Early results have shown that students presented a greater learning variability (suggested by their exam marks) when exposed to the CFT as a teaching practice, compared to conventional methods.", "num_citations": "5\n", "authors": ["167"]}
{"title": "Towards the prediction of development effort for Web applications\n", "abstract": " To estimate the effort required to develop Web applications can be quite a difficult task, however accurate estimates of development effort play an important part in the successful management of major Web development projects. This paper describes the use of analogy to estimate the development effort of Web applications. Two datasets were used in the estimation process and the results were optimistic. As the estimation by analogy requires a considerable amount of computation, we have used an automated environment\u2013the ANGEL tool-that supports the collection, storage and identification of the most analogous projects in order to estimate the effort for a new project. We have shown that estimating by analogy is a candidate technique and that with the aid of an automated environment it is a practical technique to apply to Web development.", "num_citations": "5\n", "authors": ["167"]}
{"title": "A Systematic Mapping Study of Value-Based Software Engineering\n", "abstract": " Integrating value-oriented perspectives into the principles and practices of software engineering is critical to ensure that software development and management activities address all key stakeholders' views and also balance short-and-long-term goals. This is put forward in the discipline of Value-Based Software Engineering (VBSE). In this paper, a mapping study of VBSE is detailed. We classify evidence on VBSE principles and practices, research methods, and the research types. This mapping study includes 134 studies located from online searches, and backward snowballing of references. Our results show that VB Requirements Engineering (22%) and VB Planning and Control (19%) were the two principles and practices mostly investigated in the VBSE literature, whereas VB Risk Management, VB People Management and Value Creation (3% respectively) were the three less researched. In terms of the\u00a0\u2026", "num_citations": "4\n", "authors": ["167"]}
{"title": "The project management perspective on software value: a literature review\n", "abstract": " Context: To remain competitive, innovative and to grow, companies must change from cost-based decision-making to value-based decision-making where the decisions taken maximize software value and support company\u2019s overall value creation.Objective: The objective of this paper is to complement and expand an existing classification of value aspects within the context of product management and development with additional aspects relating to value within the context of project management and development.Method: In this study, we present the results from a snowballing literature review that focuses on software value in software project management. In the research for relevance literature we focus on software value aspects different than cost as cost is widely used in project management literature to estimate value. Results: We have identified nine primary studies in two snowball iterations. From these studies, we derived three categories of value aspects: financial, risk analysis and process improvement based on value identification.", "num_citations": "4\n", "authors": ["167"]}
{"title": "Maintainability predictors for relational database-driven software applications: Extended results from a survey\n", "abstract": " Software maintainability is a very important quality attribute. Its prediction for relational database-driven software applications can help organizations improve the maintainability of these applications. The research presented herein adopts a survey-based approach where a survey was conducted with 40 software professionals aimed at identifying and ranking the important maintainability predictors for relational database-driven software applications. The survey results were analyzed using frequency analysis. The results suggest that maintainability prediction for relational database-driven applications is not the same as that of traditional software applications in terms of the importance of the predictors used for this purpose. The results also provide a baseline for creating maintainability prediction models for relational database-driven software applications.", "num_citations": "4\n", "authors": ["167"]}
{"title": "Maintainability Predictors for Relational Database-Driven Software Applications: Results from a Survey.\n", "abstract": " Software maintainability is a very important quality attribute. Its prediction for relational database-driven software applications can help organizations improve the maintainability of these applications. The research presented herein adopts a survey-based approach where a survey was conducted with 40 software professionals aimed at identifying and ranking the important maintainability predictors for relational databasedriven software applications. The survey results were analyzed using frequency analysis, and results suggest that maintainability prediction for relational database-driven applications is not the same as that of traditional software applications. The results also provide a baseline for creating maintainability prediction models for relational database-driven software applications.", "num_citations": "4\n", "authors": ["167"]}
{"title": "Software and Web Process Improvement\u2013Predicting SPI Success for Small and Medium Companies\n", "abstract": " This study revisits our previous work in SPI success factors for small and medium companies [26] in order to investigate separately SPI success factors for Web companies that only develop Web applications (Web development companies (12 companies and 41 respondents)) from SPI success factors for Web companies that develop Web as well as software applications (Web & software development companies (8 companies and 31 respondents)). We have replicated Dyba\u2019s theoretical model of SPI success factors [12] in [26], and later also in this paper. However, the study described herein differs from [12] and [26] in that Dyba used data from both software and Web companies, and Sulayman and Mendes used data from Web companies that developed Web applications and sometimes also software applications by employing quantitative assessment techniques. The comparison was also performed\u00a0\u2026", "num_citations": "4\n", "authors": ["167"]}
{"title": "Using bayesian networks for web effort estimation\n", "abstract": " Web effort models and techniques provide the means for Web companies to formalise the way they estimate effort for their projects, and help in obtaining more accurate estimates. Accurate estimates are fundamental to help project managers allocate resources more adequately, thus supporting projects to be finished on time and within budget. The aim of this chapter is to introduce the concepts related to Web effort estimation and effort forecasting techniques, and to discuss effort prediction when the estimation technique used is Bayesian Networks.", "num_citations": "4\n", "authors": ["167"]}
{"title": "Web Productivity Measurement and Benchmarking\n", "abstract": " Project managers use software productivity measures to assess software development efficiency. Productivity is commonly measured as the ratio of output to input. Within the context of software development, output is often assumed to be product size and input to be effort. However, Web applications are often characterised using several different size measures and there is no standard model for aggregating those measures into a single size measure. This makes it difficult to measure Web application productivity.           In this chapter, we present a productivity measurement method, which allows for the use of different size measures. An advantage of the method is that it has a built-in interpretation scale. It ensures that each project has an expected productivity value of one. Values between zero and one indicate lower than expected productivity; values greater than one indicate higher than expected\u00a0\u2026", "num_citations": "4\n", "authors": ["167"]}
{"title": "What formal models cannot show us: people issues during the prototyping process\n", "abstract": " Modelling a process using techniques such as Role Activity Diagrams (RADs) [13] can illustrate a large amount of useful information about the process under study. What they cannot show as easily however, are the informal practices during that process. In this paper, we analyse the prototyping process as part of an IS development strategy across five companies. Interview text from project managers, prototypers and other development staff across the five companies was analysed. Interestingly, results point to several key recurring issues amongst staff. These include non-adherence to any prototyping guidelines or standards, sketchy change request procedures, concern over time and cost deadlines and the importance attached to developer experience during the overall process. The notion of prototyping as a simple and easily managed development strategy does not hold. Our analysis provides\u00a0\u2026", "num_citations": "4\n", "authors": ["167"]}
{"title": "Insights on the relationship between decision-making style and personality in software engineering\n", "abstract": " Context:Software development involves many activities, and decision making is an essential one. Various factors can impact a decision-making process, and by understanding such factors, one can improve the process. Since people are the ones making decisions, some human-related aspects are amongst those influencing factors. One such aspect is the decision maker\u2019s personality.Objective:This research investigates the relationship between decision-making style and personality within the context of software project development.Method:We conducted a survey in a population of Brazilian software engineers to gather data on their personality and decision-making style.Results:Data from 63 participants was gathered and resulted in the identification of seven statistically significant correlations between decision-making style and personality (personality factor and personality facets). Furthermore, we built a\u00a0\u2026", "num_citations": "3\n", "authors": ["167"]}
{"title": "Defining protocols of Systematic Literature Reviews in Software Engineering: a survey\n", "abstract": " Context: Despite being defined during the first phase of the Systematic Literature Review (SLR) process, the protocol is usually refined when other phases are performed. Several researchers have reported their experiences in applying SLRs in Software Engineering (SE) however, there is still a lack of studies discussing the iterative nature of the protocol definition, especially how it should be perceived by researchers conducting SLRs. Objective: The main goal of this study is to perform a survey aiming to identify: (i) the perception of SE researchers related to protocol definition; (ii) the activities of the review process that typically lead to protocol refinements; and (iii) which protocol items are refined in those activities. Method: A survey was performed with 53 SE researchers. Results: Our results show that: (i) protocol definition and pilot test are the two activities that most lead to further protocol refinements; (ii) data\u00a0\u2026", "num_citations": "3\n", "authors": ["167"]}
{"title": "Effort and risk prediction for healthcare software projects delivered on the web\n", "abstract": " This chapter describes a case study where Bayesian networks (BNs) were used to construct an expert-based software effort and risk-prediction model for use by a large healthcare organisation in Auckland (New Zealand) to manage healthcare software projects delivered on the Web. This model, which contains 38 factors and 37 corresponding relationships, was solely elicited from expert knowledge, with the participation of 7 project managers, and was validated using data from 22 past finished projects. The model led to numerous changes in process and also in business. The company adapted their existing effort and risk management process to be in line with the model that was created, and the use of a mathematically-based model also led to an increase in the number of projects being outsourced to this company by other company branches worldwide. In addition, their predictions improved significantly.", "num_citations": "3\n", "authors": ["167"]}
{"title": "Expert-based knowledge engineering of bayesian networks\n", "abstract": " Bayesian networks are models that enable reasoning under uncertainty, thus making them very strong contenders for use by organisations in domains that are complex and where decision making takes place under uncertainty. Such models can be built from existing datasets, from expert knowledge or from a combination of both. Within the context of this book we assume that expert knowledge is the source employed to build effort estimation models. This chapter details the process that we have used to build each of the six different effort estimation models that are later on described in the following chapters.", "num_citations": "3\n", "authors": ["167"]}
{"title": "Using CBR and CART to predict maintainability of relational database-driven software applications\n", "abstract": " Background: Relational database-driven software applications have gained significant importance in modern software development. Given that software maintainability is an important quality attribute, predicting these applications' maintainability can provide various benefits to software organizations, such as adopting a defensive design and more informed resource management. Aims: The aim of this paper is to present the results from employing two well-known prediction techniques to estimate the maintainability of relational database-driven applications. Method: Case-based reasoning (CBR) and classification and regression trees (CART) were applied to data gathered on 56 software projects from software companies. The projects concerned development and/or maintenance of relational database-driven applications. Unlike previous studies, all variables (28 independent and 1 dependent) were measured on a\u00a0\u2026", "num_citations": "3\n", "authors": ["167"]}
{"title": "Towards reliable web applications: ISO 19761\n", "abstract": " This research adopts a new scenario-based black box testing methodology for testing web applications. It combines a black box testing strategy with the functions (scenarios) measured by the COSMIC-FFP measurement procedure (ISO/IEC 19761 standard) to produce an optimal set of test cases. This testing approach shows its applicability during all the development phases. Moreover, it can be applied during the early development phase once the specifications have been documented as well as after the development phase where we don't have the access to the code. This paper also considers the use of a functional complexity measure for assigning priorities to the generated test cases. Finally, those concepts have been applied on part of Online Banking System as a case study.", "num_citations": "3\n", "authors": ["167"]}
{"title": "Cost estimation of web applications through knowledge elicitation\n", "abstract": " Objective \u2013 The objective of this paper is detail the use of tacit knowledge elicited from domain experts in the domain of Web effort estimation to build an expert-based Web effort model for a medium-size Web company In Auckland (New Zealand). Method \u2013 A single-company Web effort estimation model was built using Bayesian Networks (BN), using knowledge solely elicited from two domain experts who were experienced Web project managers. The model was validated using data from eleven past finished Web projects. Results \u2013 The BN model has to date been successfully used to estimate effort for numerous Web projects developed by this Company. Conclusions \u2013 Our results suggest that, at least for the Web Company that participated in the case study, the use of models that allow the representation of uncertainty, inherent in effort estimation, can outperform expert-based estimates. Thus far, another\u00a0\u2026", "num_citations": "3\n", "authors": ["167"]}
{"title": "Training software development practitioners in usability evaluations: an exploratory study of cross pollination\n", "abstract": " Successful integration of usability evaluation into software development processes requires software companies to employ personnel that possess skills within both usability and software development. However, the sheer lack of usability specialists and their cost are two limiting factors for software companies wanting to integrate usability evaluation. A possible solution to these problems is to cross pollinate by training existing personnel in conducting usability evaluations and analyzing the collected data. This exploratory study extends previous research by showing that it is possible to provide software development practitioners from industry with key knowledge on usability evaluation. Results show that a pair of practitioners can identify the same number of problems as one usability specialist after 14 hours of training. Furthermore, software practitioners are better at providing clear and precise problem descriptions than at describing the impact, cause, user actions and providing data support for observations.", "num_citations": "3\n", "authors": ["167"]}
{"title": "Size and frequency of class change from a refactoring perspective\n", "abstract": " A previous study by Bieman et al., investigated whether large, object-oriented classes were more susceptible to change than smaller classes. The measure of change used in the study was the frequency with which the features of a class had been changed over a specific period of time. From a refactoring perspective, the frequency of class change is of value But even for a relatively simple refactoring such as 'rename method', multiple classes may undergo minor modification without any net increase in class (and system) size. In this paper, we suggest that the combination of 'versions of a class and number of added lines of code ' in the bad code 'smell' detection process may give a better impression of which classes are most suitable candidates for refactoring; as such, effort in detecting bad code smells should apply to classes with a high growth rate as well as a high change frequency. To support our investigation\u00a0\u2026", "num_citations": "3\n", "authors": ["167"]}
{"title": "Does the linear size adjustment to estimated effort improve web applications effort estimation accuracy?\n", "abstract": " Over the last 16 years, and particularly over the last 8 years, Analogy-based effort estimation has been used to estimate effort for software projects and in several studies has presented comparable estimation accuracy to, or better than, algorithmic methods. The Analogy technique is also potentially easier to understand and apply by both researchers and practitioners. These two factors suggest that this technique has great potential as an effort estimation technique to be used within Companies.", "num_citations": "3\n", "authors": ["167"]}
{"title": "Metrics for improving the quality of hypermedia authoring.\n", "abstract": " British Library EThOS: Metrics for improving the quality of hypermedia authoring. New search | Advanced search | Search results Login / Register | About | Help | FAQ | Follow dividing line Use this URL to cite or link to this record in EThOS: https://ethos.bl.uk/OrderDetails.do?uin=uk.bl.ethos.287342 Title: Metrics for improving the quality of hypermedia authoring. Author: Mendes, Emilia. ISNI: University of Southampton Date of Award: 1999 Availability of Full Text: Full text unavailable from EThOS. Please contact the current institution\u2019s library for further details. Abstract: No abstract available Supervisor: Not available Sponsor: Not available Qualification Name: Thesis (Ph.D.) Qualification Level: Doctoral EThOS ID: uk.bl.ethos.287342 DOI: Not available Keywords: Multimedia; Process improvement Share: Terms and Conditions | Notice | \u2026", "num_citations": "3\n", "authors": ["167"]}
{"title": "An expert-based requirements effort estimation model using bayesian networks\n", "abstract": " [Motivation]: There are numerous software companies worldwide that split the software development life cycle into at least two separate projects \u2013 an initial project where a requirements specification document is prepared; and a follow-up project where the previously prepared requirements document is used as input to developing a software application. These follow-up projects can also be delegated to a third party, as occurs in numerous global software development scenarios. Effort estimation is one of the cornerstones of any type of project management; however, a systematic literature review on requirements effort estimation found hardly any empirical study investigating this topic. [Objective]: The goal of this paper is to describe an industrial case study where an expert-based requirements effort estimation model was built and validated for the Brazilian Navy. [Method]: A knowledge engineering of\u00a0\u2026", "num_citations": "2\n", "authors": ["167"]}
{"title": "Introduction to Effort Estimation\n", "abstract": " Good effort estimates are essential to help project managers allocate resources and control costs and schedule, which in turn enables projects to be finished on time and within budget. This chapter introduces the concepts related to effort estimation and also details the most common avenues that have been pursued by researchers who have investigated this area using models. The chapter ends with a discussion about issues with these common avenues and sets the scene for the technique that is detailed and used in further chapters. All the examples given are based on effort estimation relating to Web projects.", "num_citations": "2\n", "authors": ["167"]}
{"title": "Scholarly research process: investigating the effects of link type and directionality\n", "abstract": " Hypertext research has discovered new ways to explore, represent and visualise data and has led to many improvements in the usability and usefulness of systems. However, in the field of scholarly writing research, several studies discuss the need for improving the current state of affairs [18][24][29]. This research aimed to investigate whether typed and/or bi-directional links have an effect on users' performance and confidence when undertaking a literature survey [18], considered one of the phases of a scholarly writing process [29]. Two empirical studies were conducted-a survey and a formal experiment, and results showed that both typed and bi-directional links had significant effect on users' performance and confidence when undertaking common early scholarly writing tasks, specifically benefiting tasks relating to surveying existing literature.", "num_citations": "2\n", "authors": ["167"]}
{"title": "Cross-company and Single-company Effort Models Using Chronological Splitting\n", "abstract": " To date numerous studies in software and Web engineering have investigated the use of cross-company datasets to estimate effort for single-company projects; however only one study used a chronological split, where projects\u2019 end dates are used such that training sets only contain projects that have been completed before the start date of each of the projects part of the validation set. Therefore the aim of this study is to compare chronological and random splitting when investigating the use of cross-company models for effort estimation. We used 450 single-company projects and 741 crosscompany projects from the ISBSG Release 10 repository, and estimates were obtained using manual stepwise regression. We were not able to obtain a converging set of findings when comparing cross-to single-company predictions given that different prediction accuracy measures presented contradictory results. In addition, the use of chronological splits, and more than one split, did not improve prediction accuracy.", "num_citations": "2\n", "authors": ["167"]}
{"title": "The need for empirical web engineering: an Introduction\n", "abstract": " The objective of this chapter is to motivate the need for empirical investigations in Web engineering, and additionally to describe the three main types of empirical investigations that can be used by Web companies to understand, control, and improve the products they develop and the processes they use. These three main types of empirical investigations are surveys, case studies, and formal experiments. Although all these three types are described in this chapter, we focused our attention on formal experiments as these are the most difficult type of investigation to plan and execute.", "num_citations": "2\n", "authors": ["167"]}
{"title": "The'P'in prototyping is for'personality'\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "2\n", "authors": ["167"]}
{"title": "Using CBR to Estimate Development Effort for Web Hypermedia Applications.\n", "abstract": " Good estimates of development effort play an important role in the successful management of larger software development projects. This paper compares the prediction accuracy of three CBR techniques to estimate the effort to develop Web hypermedia applications. Most comparative studies have used one CBR technique. We believe this may bias the results, as there are several CBR techniques that may also be used for effort prediction. This paper shows that a weighted Euclidian similarity measure was the most accurate of the CBR techniques tested.", "num_citations": "2\n", "authors": ["167"]}
{"title": "A comparison of size measures for predicting web design and authoring effort\n", "abstract": " Software practitioners recognise the importance of realistic estimates of effort to the successful management of software projects, the Web being no exception. Estimates are necessary throughout the whole development life cycle. They are fundamental when bidding for a contract or when determining a project\u2019s feasibility in terms of cost-benefit analysis. In addition, they allow project managers and development organisations to manage resources effectively. Size, which can be described in terms of length, functionality and complexity, is often a major determinant of effort. Most effort prediction models to date concentrate on functional measures of size, although length and complexity are also essential aspects of size. The first half of this paper describes a case study evaluation in which size metrics characterising length, complexity and functionality were obtained and used to generate effort prediction models for Web authoring and design. The second half describes the comparison of those size metrics as effort predictors by generating corresponding prediction models and comparing their accuracy using boxplots of the residuals. Results suggest that in general all categories presented a similar prediction accuracy.", "num_citations": "2\n", "authors": ["167"]}
{"title": "Understanding the perceived relevance of capability measures: A survey of Agile Software Development practitioners\n", "abstract": " Context:In the light of the swift and iterative nature of Agile Software Development (ASD) practices, establishing deeper insights into capability measurement within the context of team formation is crucial, as the capability of individuals and teams can affect team performance and productivity Although a former Systematic Literature Review (SLR) synthesized the state of the art in relation to capability measurement in ASD \u2013 with a focus on selecting individuals to agile teams, and capabilities related to team performance, productivity and success determining to what degree the SLR\u2019s results apply to practice can provide progressive insights to both research and practice.Objective:Our study investigates how agile practitioners perceive the relevance of individual and team level measures for characterizing the capability of an agile team and its members. Here, the emphasis was also on selecting individuals to agile\u00a0\u2026", "num_citations": "1\n", "authors": ["167"]}
{"title": "A method to estimate software strategic indicators in software development: An industrial application\n", "abstract": " ContextExploiting software development related data from software-development intensive organizations to support tactical and strategic decision making is a challenge. Combining data-driven approaches with expert knowledge has been highlighted as a sensible approach for leading software-development intensive organizations to rightful decision-making improvements. However, most of the existing proposals lack of important aspects that hinders their industrial uptake such as: customization guidelines to fit the proposals to other contexts and/or automatic or semi-automatic data collection support for putting them forward in a real organization. As a result, existing proposals are rarely used in the industrial context.ObjectiveSupport software-development intensive organizations with guidance and tools for exploiting software development related data and expert knowledge to improve their decision making\u00a0\u2026", "num_citations": "1\n", "authors": ["167"]}
{"title": "A Theory of Value for Value-based Feature Selection in Software Engineering\n", "abstract": " Value-Based Software Engineering stresses the role of value in software related decisions. In the context of feature selection, software features judged to provide higher value take priority in the development process. This paper focuses on what value means when selecting software features. Using grounded theory, we conducted and analyzed semi-structured interviews with 21 key stakeholders (decision-makers) from three software/software-intensive companies, within a context where value-based decision-making was already established. Our analysis led to the building of a theory of value for value-based feature selection that identifies the nature of value propositions considered by key stakeholders when selecting software features (i.e. decision-making criteria for deciding upon software features, as suggested by Boehm (2003)). We found that some value propositions were common to all three company cases\u00a0\u2026", "num_citations": "1\n", "authors": ["167"]}
{"title": "Introduction to web resource estimation\n", "abstract": " Effort estimation is one of the main pillars of sound project management as its accuracy can affect significantly whether projects will be delivered on time and within budget. Numerous studies have investigated this topic within the context of either Web or software project management. However, given that, as already explained in Chap.                \u201cIntroduction to Knowledge Management\u201d                            , the emphasis of this book is on expert-based models to improve effort estimates for Web projects, the focus of this chapter is to only provide an overview of previous studies in Web effort estimation. A detailed overview of effort estimation within the context of software projects is given in Jorgensen and Shepperd (IEEE Trans Softw Eng 33:33\u201353, 2007).", "num_citations": "1\n", "authors": ["167"]}
{"title": "Applying a Knowledge Management Technique to Improve Risk Assessment and Effort Estimation of Healthcare Software Projects\n", "abstract": " One of the pillars for sound Software Project Management is reliable effort estimation. Therefore it is important to fully identify what are the fundamental factors that affect an effort estimate for a new project and how these factors are inter-related. This paper describes a case study where a Knowledge Management technique was employed to build an expert-based effort estimation model to estimate effort for healthcare software projects. This model was built with the participation of seven project managers, and was validated using data from 22 past finished projects. The model led to numerous changes in process and also in business. The company adapted their existing effort estimation process to be in line with the model that was created, and the use of a mathematically-based model also led to an increase in the number of projects being delegated to this company by other company branches worldwide.", "num_citations": "1\n", "authors": ["167"]}
{"title": "Using Expert-based Bayesian Networks as Decision Support Systems to Improve Project Management of Healthcare Software Projects.\n", "abstract": " One of the pillars for sound Software Project Management is reliable effort estimation. Therefore it is important to fully identify what are the fundamental factors that affect an effort estimate for a new project and how these factors are inter-related. This paper describes a case study where a Bayesian Network model to estimate effort for healthcare software projects was built. This model was solely elicited from expert knowledge, with the participation of seven project managers, and was validated using data from 22 past finished projects. The model led to numerous changes in process and also in business. The company adapted their existing effort estimation process to be in line with the model that was created, and the use of a mathematically-based model also led to an increase in the number of projects being delegated to this company by other company branches worldwide.", "num_citations": "1\n", "authors": ["167"]}
{"title": "The role of systematic reviews in identifying the state of the art in web resource estimation\n", "abstract": " The goal of this position paper is to motivate the importance of SRs, and to present a SR of Web resource estimation. The SR results suggest that there is plenty of work to be done in the field of Web resource estimation whether it be investigating a more comprehensive approach that considers more than a single resource facet, evaluating other possible resource predictors, or trying to determine guidelines that would help simplify the process of selecting a resource estimation technique.", "num_citations": "1\n", "authors": ["167"]}
{"title": "Web Engineering and Metrics\n", "abstract": " The objective of this chapter is three-fold. First, it provides an introduction to Web Engineering, and discusses the need for empirical investigations in this area. Second, it defines concepts such as metrics and measurement, and details the types of quantitative metrics that can be gathered when carrying out empirical investigations in Web Engineering. Third, it presents the three main types of empirical investigations \u2013 surveys, case studies, and formal experiments.", "num_citations": "1\n", "authors": ["167"]}
{"title": "How adequate are Hypermedia Systems, Models and Methodologies to Education?\n", "abstract": " This paper describes the results of a feature analysis aimed at evaluating how adequate hypermedia models, methodologies and systems are when applied to authoring for education. The requirements used in our work were identified by educational hypermedia authors and also by existing literature in the field of hypermedia authoring. Our objective was to assess whether or not hypermedia models, methodologies and systems offered features corresponding to the requirements identified by educational hypermedia authors/existing literature. The results obtained showed that none of the hypermedia models and methodologies used in our evaluation had features corresponding to the essential requirements that have been identified. Among the hypermedia systems, only three presented features which corresponded to requirements considered essential by hypermedia authors.", "num_citations": "1\n", "authors": ["167"]}
{"title": "Metrics Applied to Hypermedia Authoring for Education\n", "abstract": " Metrics Applied to Hypermedia Authoring for Education - ePrints Soton The University of Southampton Courses University life Research Business Global About Visit Alumni Departments News Events Contact \u00d7 Search the Site Search Filter your search: All Courses Projects Staff University of Southampton Institutional Repository Search Advanced Search Policies & Help Latest Download Statistics Browse by Year Browse by Divisions LeftRight Metrics Applied to Hypermedia Authoring for Education Mendes, MEX, Harrison, R and Hall, W (1998) Metrics Applied to Hypermedia Authoring for Education. Proceedings of ED-MEDIA'98 - World Conference on Educational Multimedia and Hypermedia, Freiburg, Germany. Record type: Conference or Workshop Item (Other) Full text not available from this repository. More information Published date: 1998 Venue - Dates: Proceedings of ED-MEDIA'98 - World Conference on and \u2026", "num_citations": "1\n", "authors": ["167"]}
{"title": "Measuring Reusability and Maintainability in Hypermedia Applications for Education\n", "abstract": " Measuring Reusability and Maintainability in Hypermedia Applications for Education - ePrints Soton The University of Southampton Courses University life Research Business Global About Visit Alumni Departments News Events Contact \u00d7 Search the Site Search Filter your search: All Courses Projects Staff University of Southampton Institutional Repository Search Advanced Search Policies & Help Latest Download Statistics Browse by Year Browse by Divisions LeftRight Measuring Reusability and Maintainability in Hypermedia Applications for Education Mendes, MEX, Harrison, R and Hall, W (1998) Measuring Reusability and Maintainability in Hypermedia Applications for Education. Proceddings of EASE'98 - Empirical Assessment and Evaluation in Software Engineering, UK. Record type: Conference or Workshop Item (Other) Full text not available from this repository. More information Published date: 1998 - : of '- :\u2026", "num_citations": "1\n", "authors": ["167"]}
{"title": "O Auxilo a Autopria de Aplicacoes Hipermedia Atraves da Aplicacao de Metricas\n", "abstract": " O Auxilo a Autopria de Aplicacoes Hipermedia Atraves da Aplicacao de Metricas - ePrints Soton The University of Southampton Courses University life Research Business Global About Visit Alumni Departments News Events Contact \u00d7 Search the Site Search Filter your search: All Courses Projects Staff University of Southampton Institutional Repository Search Advanced Search Policies & Help Latest Download Statistics Browse by Year Browse by Divisions LeftRight O Auxilo a Autopria de Aplicacoes Hipermedia Atraves da Aplicacao de Metricas Mendes, MEX, Harrison, R and Hall, W (1998) O Auxilo a Autopria de Aplicacoes Hipermedia Atraves da Aplicacao de Metricas. Proceedings of the Third Symposium on Educational Software Research and Development, Evora, Portugal. Record type: Conference or Workshop Item (Other) Full text not available from this repository. More information Published date: 1998 - : , \u2026", "num_citations": "1\n", "authors": ["167"]}
{"title": "Um Estudo Empirico Acerca de Autoria de Aplicacoes Hipermeio Aplicadas a Educacao\n", "abstract": " Um Estudo Empirico Acerca de Autoria de Aplicacoes Hipermeio Aplicadas a Educacao - ePrints Soton The University of Southampton Courses University life Research Business Global About Visit Alumni Departments News Events Contact \u00d7 Search the Site Search Filter your search: All Courses Projects Staff University of Southampton Institutional Repository Search Advanced Search Policies & Help Latest Download Statistics Browse by Year Browse by Divisions LeftRight Um Estudo Empirico Acerca de Autoria de Aplicacoes Hipermeio Aplicadas a Educacao Mendes, MEX and Hall, W (1997) Um Estudo Empirico Acerca de Autoria de Aplicacoes Hipermeio Aplicadas a Educacao. Proceedings of Segundo Simposio Investigacao e Desenvolvimento de Software Educativo, Coimbra, Portugal. Record type: Conference or Workshop Item (Other) Full text not available from this repository. More information Published : - \u2026", "num_citations": "1\n", "authors": ["167"]}
{"title": "Hyper-writing for Education: a cognitive perspective\n", "abstract": " Hyper-writing for Education: a Cognitive Perspective - ePrints Soton The University of Southampton Courses University life Research Business Global About Visit Alumni Departments News Events Contact \u00d7 Search the Site Search Filter your search: All Courses Projects Staff University of Southampton Institutional Repository Search Advanced Search Policies & Help Latest Download Statistics Browse by Year Browse by Divisions LeftRight Hyper-writing for Education: a Cognitive Perspective Mendes, MEX and Hall, W (1997) Hyper-writing for Education: a Cognitive Perspective. Proceedings of the Tenth Annual Writing and Computers Conference, Brighton, UK. Record type: Conference or Workshop Item (Other) Full text not available from this repository. More information Published date: September 1997 Venue - Dates: Proceedings of the Tenth Annual Writing and Computers Conference, Brighton, UK, 1997-08-31 : : \u2026", "num_citations": "1\n", "authors": ["167"]}
{"title": "Technical Report: papers found in the two updated SLRs\n", "abstract": " 83. Schultis, K.-B., Elsner, C., Lohmann, D., 2014. Architecture challenges for internal software ecosystems: A large-scale industry case study. In: Proceedings of the 22Nd ACM SIGSOFT International Symposium on Foundations of Software Engineering. FSE 2014. ACM, New York, NY, USA, pp. 542\u2013552.", "num_citations": "1\n", "authors": ["167"]}