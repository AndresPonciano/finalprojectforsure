{"title": "Open MPI: Goals, concept, and design of a next generation MPI implementation\n", "abstract": " A large number of MPI implementations are currently available, each of which emphasize different aspects of high-performance computing or are intended to solve a specific research problem. The result is a myriad of incompatible MPI implementations, all of which require separate installation, and the combination of which present significant logistical challenges for end users. Building upon prior research, and influenced by experience gained from the code bases of the LAM/MPI, LA-MPI, and FT-MPI projects, Open MPI is an all-new, production-quality MPI-2 implementation that is fundamentally centered around component concepts. Open MPI provides a unique combination of novel features previously unavailable in an open-source, production-quality implementation of MPI. Its component architecture provides both a stable platform for third-party research as well as enabling the run-time composition of\u00a0\u2026", "num_citations": "1960\n", "authors": ["508"]}
{"title": "Performance analysis of MPI collective operations\n", "abstract": " Previous studies of application usage show that the performance of collective communications are critical for high-performance computing. Despite active research in the field, both general and feasible solution to the optimization of collective communication problem is still missing.                 In this paper, we analyze and attempt to improve intra-cluster collective communication in the context of the widely deployed MPI programming paradigm by extending accepted models of point-to-point communication, such as Hockney, LogP/LogGP, and PLogP, to collective operations. We compare the predictions from models against the experimentally gathered data and using these results, construct optimal decision function for broadcast collective. We quantitatively compare the quality of the model-based decision functions to the experimentally-optimal one. Additionally, in this work, we also introduce a new form of\u00a0\u2026", "num_citations": "361\n", "authors": ["508"]}
{"title": "Algorithm-based fault tolerance applied to high performance computing\n", "abstract": " We present a new approach to fault tolerance for High Performance Computing system. Our approach is based on a careful adaptation of the Algorithm-Based Fault Tolerance technique [K. Huang, J. Abraham, Algorithm-based fault tolerance for matrix operations, IEEE Transactions on Computers (Spec. Issue Reliable & Fault-Tolerant Comp.) 33 (1984) 518\u2013528] to the need of parallel distributed computation. We obtain a strongly scalable mechanism for fault tolerance. We can also detect and correct errors (bit-flip) on the fly of a computation. To assess the viability of our approach, we have developed a fault-tolerant matrix\u2013matrix multiplication subroutine and we propose some models to predict its running time. Our parallel fault-tolerant matrix\u2013matrix multiplication scores 1.4 TFLOPS on 484 processors (cluster jacquard.nersc.gov) and returns a correct result while one process failure has happened. This represents\u00a0\u2026", "num_citations": "249\n", "authors": ["508"]}
{"title": "Open MPI: A high-performance, heterogeneous MPI\n", "abstract": " The growth in the number of generally available, distributed, heterogeneous computing systems places increasing importance on the development of user-friendly tools that enable application developers to efficiently use these resources. Open MPI provides support for several aspects of heterogeneity within a single, open-source MPI implementation. Through careful abstractions, heterogeneous support maintains efficient use of uniform computational platforms. We describe Open MPI's architecture for heterogeneous network and processor support. A key design features of this implementation is the transparency to the application developer while maintaining very high levels of performance. This is demonstrated with the results of several numerical experiments", "num_citations": "188\n", "authors": ["508"]}
{"title": "Fault tolerant high performance computing by a coding approach\n", "abstract": " As the number of processors in today's high performance computers continues to grow, the mean-time-to-failure of these computers are becoming significantly shorter than the execution time of many current high performance computing applications. Although today's architectures are usually robust enough to survive node failures without suffering complete system failure, most today's high performance computing applications can not survive node failures and, therefore, whenever a node fails, have to abort themselves and restart from the beginning or a stable-storage-based checkpoint. This paper explores the use of the floating-point arithmetic coding approach to build fault survivable high performance computing applications so that they can adapt to node failures without aborting themselves. Despite the use of erasure codes over Galois field has been theoretically attempted before in diskless checkpointing, few\u00a0\u2026", "num_citations": "137\n", "authors": ["508"]}
{"title": "UCX: an open source framework for HPC network APIs and beyond\n", "abstract": " This paper presents Unified Communication X (UCX), a set of network APIs and their implementations for high throughput computing. UCX comes from the combined effort of national laboratories, industry, and academia to design and implement a high-performing and highly-scalable network stack for next generation applications and systems. UCX design provides the ability to tailor its APIs and network functionality to suit a wide variety of application domains and hardware. We envision these APIs to satisfy the networking needs of many programming models such as Message Passing Interface (MPI), OpenSHMEM, Partitioned Global Address Space (PGAS) languages, task-based paradigms and I/O bound applications. To evaluate the design we implement the APIs and protocols, and measure the performance of overhead-critical network primitives fundamental for implementing many parallel programming\u00a0\u2026", "num_citations": "103\n", "authors": ["508"]}
{"title": "Extending the MPI specification for process fault tolerance on high performance computing systems\n", "abstract": " Application developers and end-users of high performance computing sys-4 tems have today access to larger machines and more processors than ever 5 before. High-end systems consist nowadays of thousands of processors. Ad-6 ditionally, not only the individual machines are getting bigger, but with the 7 recently increased network capacities, users have access to higher number of 8 machines and computing resources. Concurrently using several computing 9 resources, often referred to as Grid-or Metacomputing, further increases the 10 number of processors used in each single job as well as the overall number 11 of jobs, which a user can launch. 12With increasing number of processors however, the probability, that an 13 application is facing a node or link failure is also increasing. While on 14 earlier massively parallel processing systems (MPPs), a crashing node often 15 was identical to a system crash, current systems are more robust. Usually, 16 the application running on this node has to abort, however, the system 17 in general is not effected by a processor failure. In Grid environments, 18 a system may additionally become unavailable for a certain time due to 19 network problems, leading to a similar problem from the application point 20 of view like a crashing node on a single system. 21 The Message Passing Interface (MPI)[1, 2] is the de-facto standard for 22 the communication in scientific applications. However, MPI in its current 23 specification gives the user no possibility to handle the situation mentioned 24 above, where one or more processors are becoming unavailable during run-25 time. Current MPI specifications give the\u00a0\u2026", "num_citations": "98\n", "authors": ["508"]}
{"title": "Redesigning the message logging model for high performance\n", "abstract": " Over the past decade the number of processors used in high performance computing has increased to hundreds of thousands. As a direct consequence, and while the computational power follows the trend, the mean time between failures (MTBF) has suffered and is now being counted in hours. In order to circumvent this limitation, a number of fault\u2010tolerant algorithms as well as execution environments have been developed using the message passing paradigm. Among them, message logging has been proved to achieve a better overall performance when the MTBF is low, mainly due to a faster failure recovery. However, message logging suffers from a high overhead when no failure occurs. Therefore, in this paper we discuss a refinement of the message logging model intended to improve the failure\u2010free message logging performance. The proposed approach simultaneously removes useless memory copies\u00a0\u2026", "num_citations": "92\n", "authors": ["508"]}
{"title": "High performance RDMA protocols in HPC\n", "abstract": " Modern network communication libraries that leverage Remote Directory Memory Access (RDMA) and OS bypass protocols, such as Infiniband [2] and Myrinet [10] can offer significant performance advantages over conventional send/receive protocols. However, this performance often comes with hidden per buffer setup costs [4]. This paper describes a unique long-message MPI [9] library \u2018pipeline\u2019 protocol that addresses these constraints while avoiding some of the pitfalls of existing techniques. By using portable send/receive semantics to hide the cost of initializing the pipeline algorithm, and then effectively overlapping the cost of memory registration with RDMA operations, this protocol provides very good performance for any large-memory usage pattern. This approach avoids the use of non-portable memory hooks or keeping registered memory from being returned to the OS. Through this approach\u00a0\u2026", "num_citations": "77\n", "authors": ["508"]}
{"title": "Hierarchical dag scheduling for hybrid distributed systems\n", "abstract": " Accelerator-enhanced computing platforms have drawn a lot of attention due to their massive peak commutational capacity. Despite significant advances in the programming interfaces to such hybrid architectures, traditional programming paradigms struggle with mapping the resulting multi-dimensional heterogeneity and the expression of algorithm parallelism, resulting in sub-optimal effective performance. Task-based programming paradigms have the capability to alleviate some of the programming challenges on distributed hybrid many-core architectures. In this paper we take this concept a step further by showing that the potential of task-based programming paradigms can be greatly increased with minimal modification of the underlying runtime combined with the right algorithmic changes. We propose two novel recursive algorithmic variants for one-sided factorizations and describe the changes to the PaRSEC\u00a0\u2026", "num_citations": "72\n", "authors": ["508"]}
{"title": "Process fault tolerance: Semantics, design and applications for high performance computing\n", "abstract": " With increasing numbers of processors on current machines, the probability for node                 or link failures is also increasing. Therefore, application-level fault tolerance is                 becoming more of an important issue for both end-users and the institutions running                 the machines. In this paper we present the semantics of a fault-tolerant version of                 the message passing interface (MPI), the de-facto standard for communication in                 scientific applications, which gives applications the possibility to recover from a                 node or link error and continue execution in a well-defined way. We present the                 architecture of fault-tolerant MPI, an implementation of MPI using the semantics                 presented above as well as benchmark results with various applications. An example                 of a fault-tolerant parallel equation solver, performance results as well as the                 time for recovering\u00a0\u2026", "num_citations": "72\n", "authors": ["508"]}
{"title": "MPI collective algorithm selection and quadtree encoding\n", "abstract": " We explore the applicability of the quadtree encoding method to the run-time MPI collective algorithm selection problem. Measured algorithm performance data was used to construct quadtrees with different properties. The quality and performance of generated decision functions and in-memory decision systems were evaluated. Experimental data shows that in some cases, a decision function based on a quadtree structure with a mean depth of three, incurs on average as little as a 5% performance penalty. In all cases, experimental data can be fully represented with a quadtree containing a maximum of six levels. Our results indicate that quadtrees may be a feasible choice for both processing of the performance data and automatic decision function generation.", "num_citations": "68\n", "authors": ["508"]}
{"title": "The common communication interface (CCI)\n", "abstract": " There are many APIs for connecting and exchanging data between network peers. Each interface varies wildly based on metrics including performance, portability, and complexity. Specifically, many interfaces make design or implementation choices emphasizing some of the more desirable metrics (e.g., performance) while sacrificing others (e.g., portability). As a direct result, software developers building large, network-based applications are forced to choose a specific network API based on a complex, multi-dimensional set of criteria. Such trade-offs inevitably result in an interface that fails to deliver some desirable features. In this paper, we introduce a novel interface that both supports many features that have become standard (or otherwise generally expected) in other communication interfaces, and strives to export a small, yet powerful, interface. This new interface draws upon years of experience from network\u00a0\u2026", "num_citations": "64\n", "authors": ["508"]}
{"title": "Recovery patterns for iterative methods in a parallel unstable environment\n", "abstract": " Several recovery techniques for parallel iterative methods are presented. First, the implementation of checkpoints in parallel iterative methods is described and analyzed. Then a simple checkpoint-free fault-tolerant scheme for parallel iterative methods, the lossy approach, is presented. When one processor fails and all its data is lost, the system is recovered by computing a new approximate solution using the data of the nonfailed processors. The iterative method is then restarted with this new vector. The main advantage of the lossy approach over standard checkpoint algorithms is that it does not increase the computational cost of the iterative solver when no failure occurs. Experiments are presented that compare the different techniques. The fault-tolerant FT-MPI library is used. Both iterative linear solvers and eigensolvers are considered.", "num_citations": "64\n", "authors": ["508"]}
{"title": "Taking advantage of hybrid systems for sparse direct solvers via task-based runtimes\n", "abstract": " The ongoing hardware evolution exhibits an escalation in the number, as well as in the heterogeneity, of computing resources. The pressure to maintain reasonable levels of performance and portability forces application developers to leave the traditional programming paradigms and explore alternative solutions. PaStiX is a parallel sparse direct solver, based on a dynamic scheduler for modern hierarchical manycore architectures. In this paper, we study the benefits and limits of replacing the highly specialized internal scheduler of the PaStiX solver with two generic runtime systems: PaRSEC and StarPU. The tasks graph of the factorization step is made available to the two runtimes, providing them the opportunity to process and optimize its traversal in order to maximize the algorithm efficiency for the targeted hardware platform. A comparative study of the performance of the PaStiX solver on top of its native internal\u00a0\u2026", "num_citations": "61\n", "authors": ["508"]}
{"title": "A survey of MPI usage in the US exascale computing project\n", "abstract": " The Exascale Computing Project (ECP) is currently the primary effort in the United States focused on developing \u201cexascale\u201d levels of computing capabilities, including hardware, software, and applications. In order to obtain a more thorough understanding of how the software projects under the ECP are using, and planning to use the Message Passing Interface (MPI), and help guide the work of our own project within the ECP, we created a survey. Of the 97 ECP projects active at the time the survey was distributed, we received 77 responses, 56 of which reported that their projects were using MPI. This paper reports the results of that survey for the benefit of the broader community of MPI developers.", "num_citations": "60\n", "authors": ["508"]}
{"title": "Kernel assisted collective intra-node mpi communication among multi-core and many-core cpus\n", "abstract": " Shared memory is among the most common approaches to implementing message passing within multicorenodes. However, current shared memory techniques donot scale with increasing numbers of cores and expanding memory hierarchies -- most notably when handling large data transfers and collective communication. Neglecting the underlying hardware topology, using copy-in/copy-out memory transfer operations, and overloading the memory subsystem using one-to-many types of operations are some of the most common mistakes in today's shared memory implementations. Unfortunately, they all negatively impact the performance and scalability of MPI libraries -- and therefore applications. In this paper, we present several kernel-assisted intra-node collective communication techniques that address these three issues on many-core systems. We also present a new OpenMPI collective communication\u00a0\u2026", "num_citations": "53\n", "authors": ["508"]}
{"title": "Self-adapting numerical software (SANS) effort\n", "abstract": " The challenge for the development of next-generation software is the successful management of the complex computational environment while delivering to the scientist the full power of flexible compositions of the available algorithmic alternatives. Self-adapting numerical software (SANS) systems are intended to meet this significant challenge. The process of arriving at an efficient numerical solution of problems in computational science involves numerous decisions by a numerical expert. Attempts to automate such decisions distinguish three levels: algorithmic decision, management of the parallel environment, and processor-specific tuning of kernels. Additionally, at any of these levels we can decide to rearrange the user's data. In this paper we look at a number of efforts at the University of Tennessee to investigate these areas.", "num_citations": "53\n", "authors": ["508"]}
{"title": "A rough guide to scientific computing on the playstation 3\n", "abstract": " As much as the Sony PlayStation 3 (PS3) has a range of interesting features, its heart, the CELL processor is what the fuss is all about. CELL, a shorthand for CELL Broadband Engine Architecture, also abbreviated as CELL BE Architecture or CBEA, is a microprocessor jointly developed by the alliance of Sony, Toshiba and IBM, known as STI. The work started in 2000 at the STI Design Center in Austin, Texas, and for more than four years involved around 400 engineers and consumed close to half a billion dollars. The initial goal was to outperform desktop systems, available at the time of completion of the design, by an order of magnitude, through a dramatic increase in performance per chip area and per unit of power consumption. A quantum leap in performance would be achieved by abandoning the obsolete architectural model where performance relied on mechanisms like cache hierarchies and speculative execution, which those days brought diminishing returns in performance gains. Instead, the new architecture would rely on a heterogeneous multi-core design, with highly efficient data processors being at the heart. Their architecture would be stripped of costly and inefficient features like address translation, instruction reordering, register renaming and branch prediction. Instead they would be given powerful short vector SIMD capabilities and a massive register file. Cache hierarchies would be replaced by small and fast local memories and powerful DMA engines. This design approach resulted in a 200 million transistors chip, which today delivers performance barely approachable by its billion transistor counterparts and is available to\u00a0\u2026", "num_citations": "52\n", "authors": ["508"]}
{"title": "Reasons for a pessimistic or optimistic message logging protocol in MPI uncoordinated failure, recovery\n", "abstract": " With the growing scale of high performance computing platforms, fault tolerance has become a major issue. Among the various approaches for providing fault tolerance to MPI applications, message logging has been proved to tolerate higher failure rate. However, this advantage comes at the expense of a higher overhead on communications, due to latency intrusive logging of events to a stable storage. Previous work proposed and evaluated several protocols relaxing the synchronicity of event logging to moderate this overhead. Recently, the model of message logging has been refined to better match the reality of high performance network cards, where message receptions are decomposed in multiple interdependent events. According to this new model, deterministic and non-deterministic events are clearly discriminated, reducing the overhead induced by message logging. In this paper we compare\u00a0\u2026", "num_citations": "51\n", "authors": ["508"]}
{"title": "Binomial graph: A scalable and fault-tolerant logical network topology\n", "abstract": " The number of processors embedded in high performance computing platforms is growing daily to solve larger and more complex problems. The logical network topologies must also support the high degree of scalability in dynamic environments. This paper presents a scalable and fault tolerant topology called binomial graph (BMG). BMG provides desirable topological properties in terms of both scalability and fault-tolerance for high performance computing such as reasonable degree, regular graph, low diameter, symmetric graph, low cost factor, low message traffic density, optimal connectivity, low fault-diameter and strongly resilient. Several fault-tolerant routing algorithms are provided on BMG for various message types. More importantly, BMG is able to deliver broadcast messages from any node within log                 2 (n) steps.", "num_citations": "50\n", "authors": ["508"]}
{"title": "Fault tolerant communication library and applications for high performance computing\n", "abstract": " With increasing numbers of processors on todays machines, the probability for node or link failures is also increasing. Therefore, application level fault-tolerance is becoming more of an important issue for both end-users and the institutions running the machines. This paper presents the semantics of a fault tolerant version of the Message Passing Interface, the de-facto standard for communication in scientific applications, which gives applications the possibility to recover from a node or link error and continue execution in a well defined way. The architecture of FT-MPI, an implementation of MPI using the semantics presented above as well as benchmark results with various applications are presented. An example of a fault-tolerant parallel equation solver, performance results as well as the time for recovering from a process failure are furthermore detailed.", "num_citations": "50\n", "authors": ["508"]}
{"title": "HierKNEM: An adaptive framework for kernel-assisted and topology-aware collective communications on many-core clusters\n", "abstract": " Multicore Clusters, which have become the most prominent form of High Performance Computing (HPC) systems, challenge the performance of MPI applications with non uniform memory accesses and shared cache hierarchies. Recent advances in MPI collective communications have alleviated the performance issue exposed by deep memory hierarchies by carefully considering the mapping between the collective topology and the core distance, as well as the use of single-copy kernel assisted mechanisms. However, on distributed environments, a single level approach cannot encompass the extreme variations not only in bandwidth and latency capabilities, but also in the aptitude to support duplex communications or operate multiple concurrent copies simultaneously. This calls for a collaborative approach between multiple layers of collective algorithms, dedicating to extracting the maximum degree of\u00a0\u2026", "num_citations": "45\n", "authors": ["508"]}
{"title": "Self-healing network for scalable fault-tolerant runtime environments\n", "abstract": " The number of processors embedded on high performance computing platforms is growing daily to satisfy the user desire for solving larger and more complex problems. Scalable and fault-tolerant runtime environments are needed to support and adapt to the underlying libraries and hardware which require a high degree of scalability in dynamic large-scale environments.This paper presents a self-healing network (SHN) for supporting scalable and fault-tolerant runtime environments. The SHN is designed to support transmission of messages across multiple nodes while also protecting against recursive node and process failures. It will automatically recover itself after a failure occurs. SHN is implemented on top of a scalable fault-tolerant protocol (SFTP). The experimental results show that both the latest multicast and broadcast routing algorithms used in SHN are faster and more reliable than the original SFTP\u00a0\u2026", "num_citations": "42\n", "authors": ["508"]}
{"title": "Analysis of the component architecture overhead in Open MPI\n", "abstract": " Component architectures provide a useful framework for developing an extensible and maintainable code base upon which large-scale software projects can be built.Component methodologies have only recently been incorporated into applications by the High Performance Computing community, in part because of the perception that component architectures necessarily incur an unacceptable performance penalty.The Open MPI project is creating a new implementation of the Message Passing Interface standard, based on a custom component architecture the Modular Component Architecture (MCA) to enable straightforward customization of a high-performance MPI implementation. This paper reports on a detailed analysis of the performance overhead in Open MPI introduced by the MCA. We compare the MCA-based implementation of Open MPI with a modified version that bypasses the component\u00a0\u2026", "num_citations": "41\n", "authors": ["508"]}
{"title": "Implementation and Usage of the PERUSE-Interface in Open MPI\n", "abstract": " This paper describes the implementation, usage and experience with the MPI performance revealing extension interface (Peruse) into the Open MPI implementation. While the PMPI-interface allows timing MPI-functions through wrappers, it can not provide MPI-internal information on MPI-states and lower-level network performance. We introduce the general design criteria of the interface implementation and analyze the overhead generated by this functionality. To support performance evaluation of large-scale applications, tools for visualization are imperative. We extend the tracing library of the Paraver-toolkit to support tracing Peruse-events and show how this helps detecting performance bottlenecks. A test-suite and a real-world application are traced and visualized using Paraver.", "num_citations": "40\n", "authors": ["508"]}
{"title": "Retrospect: Deterministic replay of MPI applications for interactive distributed debugging\n", "abstract": " While high performance computing was eagerly adopted by users as a vehicle for satisfying a growing demand on computational power, some areas are still poorly explored. The MPI paradigm is considered as being the keystone for the large development of the HPC infrastructure over the last decade. However, even today the users have to face the lack of tools able to help increase the stability of the software stack and/or of the applications. In this paper we present and evaluate a tool designed to allow developers to further investigate the execution of parallel applications by enabling them to dynamically move back and forth in the execution timeline of a parallel application. Based on an unobtrusive message logging mechanism, deterministic replay is enforced, leading to a simpler and more efficient way to debug parallel software.", "num_citations": "38\n", "authors": ["508"]}
{"title": "TEG: A high-performance, scalable, multi-network point-to-point communications methodology\n", "abstract": " TEG is a new component-based methodology for point-to-point messaging. Developed as part of the Open MPI project, TEG provides a configurable fault-tolerant capability for high-performance messaging that utilizes multi-network interfaces where available. Initial performance comparisons with other MPI implementations show comparable ping-pong latencies, but with bandwidths up to 30% higher.", "num_citations": "37\n", "authors": ["508"]}
{"title": "Locality and topology aware intra-node communication among multicore CPUs\n", "abstract": " A major trend in HPC is the escalation toward manycore, where systems are composed of shared memory nodes featuring numerous processing units. Unfortunately, with scale comes complexity, here in the form of non-uniform memory accesses and cache hierarchies. For most HPC applications, harnessing the power of multicores is hindered by the topology oblivious tuning of the MPI library. In this paper, we propose a framework to tune every type of shared memory communications according to locality and topology. An implementation inside Open MPI is evaluated experimentally and demonstrates significant speedups compared to vanilla Open MPI and MPICH2.", "num_citations": "34\n", "authors": ["508"]}
{"title": "Non-blocking collective operations for MPI-2\n", "abstract": " We propose new non-blocking interfaces for the collective group communication functions defined in MPI-1 and MPI-2. This document is meant as a standard extension and written in the same way as the MPI standards. It covers the MPI-API as well as the semantics of the new operations.", "num_citations": "34\n", "authors": ["508"]}
{"title": "Flexible collective communication tuning architecture applied to Open MPI\n", "abstract": " Collective communications are invaluable to modern high performance applications, although most users of these communication patterns do not always want to know their inner most working. The implementation of the collectives are often left to the middle-ware developer such as those providing an MPI library. As many of these libraries are designed to be both generic and portable the MPI developers commonly offer internal tuning options suitable only for knowledgeable users that allow some level of customization. The work presented in this paper aims not only to provide a very efficient set of collective operations for use with the Open MPI implementation but also to make the control and tuning of them straightforward and flexible. Additionally this paper demonstrates a novel example of the proposed frameworks flexibility, by dynamically tuning a MPI Alltoallv algorithm during runtime.", "num_citations": "33\n", "authors": ["508"]}
{"title": "Open MPI\u2019s TEG point-to-point communications methodology: Comparison to existing implementations\n", "abstract": " TEG is a new methodology for point-to-point messaging developed as a part of the Open MPI project. Initial performance measurements are presented, showing comparable ping-pong latencies in a single NIC configuration, but with bandwidths up to 30% higher than that achieved by other leading MPI implementations. Homogeneous dual-NIC configurations further improved performance, but the heterogeneous case requires continued investigation.", "num_citations": "29\n", "authors": ["508"]}
{"title": "Scalable fault tolerant protocol for parallel runtime environments\n", "abstract": " The number of processors embedded on high performance computing platforms is growing daily to satisfy users desire for solving larger and more complex problems. Parallel runtime environments have to support and adapt to the underlying libraries and hardware which require a high degree of scalability in dynamic environments. This paper presents the design of a scalable and fault tolerant protocol for supporting parallel runtime environment communications. The protocol is designed to support transmission of messages across multiple nodes with in a self-healing topology to protect against recursive node and process failures. A formal protocol verification has validated the protocol for both the normal and failure cases. We have implemented multiple routing algorithms for the protocol and concluded that the variant rule-based routing algorithm yields the best overall results for damaged and incomplete\u00a0\u2026", "num_citations": "28\n", "authors": ["508"]}
{"title": "Scalable fault tolerant MPI: extending the recovery algorithm\n", "abstract": " Fault Tolerant MPI (FT-MPI) [6] was designed as a solution to allow applications different methods to handle process failures beyond simple check-point restart schemes. The initial implementation of FT-MPI included a robust heavy weight system state recovery algorithm that was designed to manage the membership of MPI communicators during multiple failures. The algorithm and its implementation although robust, was very conservative and this effected its scalability on both very large clusters as well as on distributed systems. This paper details the FT-MPI recovery algorithm and our initial experiments with new recovery algorithms that are aimed at being both scalable and latency tolerant. Our conclusions shows that the use of both topology aware collective communication and distributed consensus algorithms together produce the best results.", "num_citations": "28\n", "authors": ["508"]}
{"title": "Building fault survivable MPI programs with FT-MPI using diskless checkpointing\n", "abstract": " 8tg P 92\u00a6 d 3E\u00a4 f\u00a6\u00a9 w\u00a4 x\u00a6 v92\u00a6\u00a9\u00a4 d# 2$ B# F DF# F3E Dq (\"# FC 3E (V9Q\u00a6\u00a9 35#% \u00a7 92 7 C 0\u00a4 xW\u00a4\u00a9 9% DF\"\u00a4'7!\u00a9 3E D 9% 7I 92$ r\u00a6\u00a9 Y!\u00a5!\u00a9\"(0# Qy\"! 1@\u00a6 l 0!\u00a9 3E D \u00a7 9% I dfegWhg i 92& & b53E (V9Q\u00a6\u00a9 3E# F nR\u00a6\u00a9\"!\u00a9 q 9Q!\u00a9 k\u00a6 hPg# \u00a7 & 9QW! v9% CY\u00a6\u00a9\"!\u00a9\u00a4 f\u00a4 1 V7q\u00a6\u00a9#'\u00a4 1& 0 (\" 3E $@ q P 3E (YC# 87 0\u00a4 j\u00a6\u00a9 u 92& & bE3E (V9Q\u00a6\u00a9 35#% \u00a7 3E\u00a4 f!\u00a9 W 3E D t eu qe!\u00a9\u00a4 x\u00a6 T & 9Q! v9% C\"\u00a6\u00a9 Y! VR\u00a6\u00a9 4 A (0# FC 3E (V9Q\u00a6\u00a9#%! TC# 87 FAER 3E 7 3E (V92\u00a6\u00a9\"\u00a4 P9Q\u00a6 u 3E\u00a4 d\u00a6\u00a9\u00a4 x\u00a6 v92\u00a6\u00a9\u00a4 d#% $ p 9% mgi# F 8rx 0 (\"\u00a6 w 92$ r\u00a6\u00a9 Y! g!\u00a9 0 (0# Qy Y! 1@) ti dfegWhg i &!\u00a9# Qy8357 0\u00a4 T $ H# F! q 7 3f B\"!\u00a9 0)\u00a6 S (\"# FC 3E (V9Q\u00a6\u00a9#%! k C# 87 0\u00a4 0RB P 3E (v (V92\u00a4 1& 0 (03fe V7 P\" I\u00a4 x\u00a6 v92! 1\u00a6\u00a9 3E D \u00a7 \u00a6\u00a9 S 92& & bE3E (V9Q\u00a6\u00a9 35#%\u00a9\u00a4\u00a3'w'se\u00a4 2bE35 F w 9%)@ q#%\u00a6\u00a9\"! ggi 3E C& bE 0 C 0)\u00a6 v92\u00a6\u00a9 3E#% nR% dfegWhg i (V9% 92#%! 1\u00a6\u00a5# FI 9% Y! 1!\u00a9#%! Vt uup\u00a3 v\u00a4 $ H9% 3EbE V7c &!\u00a9#)(0 0\u00a4 1\u00a4 1\"\u00a4 q 92!\u00a9 q#%\u00a6 T!\u00a9 0& b592 (0 V7 R 92bEbf\u00a4 1!\u00a9 y83Ey8W 35 DI &!\u00a9#)(0 0\u00a4 1\u00a4 1 0\u00a4 q 9Vy q\u00a6\u00a9\u00a4\u00a9 9% C! v92 c 92\u00a4 S\" $ H# 2!\u00a9\u00a6\u00a9(\"! v9%\u00a4 1 9% 7G gi ww Sg gl'Tun 92\u00a4 \u00a7 \u00a6\u00a9\u00a4\u00a9 92 CI\u00a4 13E 0 c 9%\u00a4 C YW $ H#%!\u00a9% t'hv\u00a4 j $ a923Eb5 07 &!\u00a9#)(0 0\u00a4 1\u00a4 1\"\u00a4 9Q!\u00a9# 2\u00a6 C!\u00a9 0& b59%(\" V7 R# QPg 0y\"!\u00a6\u00a9 u\" P6 (0# FC 3E (V9Q\u00a6\u00a9#%! s 9Q $ r\u00a6\u00a9\"! s\u00a6\u00a9 u (Y! v9%\u00a4 1 \u00a7 9%\u00a4 s# A# FbE 0\u00a4 0A) 3E 3E\u00a6\u00a9\u00a4 d bE35\u00a4 x\u00a6 u#% $ n &!\u00a9#)(0 0\u00a4 1\u00a4 1\"\u00a4 0tu eu8\u00a4 0R &!\u00a9#)(0 0\u00a4 1\u00a4 1\"\u00a4 w C35D%)\u00a6 g 9QyF'9S YP! v9%'92$\u00a6\u00a9\"! p!\u00a9 0 (\"# 2yF\"! 1@ k 92 7'\u00a6\u00a9 s\u00a4 13E 0 s#% $ gi ww Sg gl''u P 35bEbn (Y 9% D% Ft'ts g un\u00a4 $ a923Eb5 07U &!\u00a9#)(0 0\u00a4 1\u00a4 1 0\u00a4'92!\u00a9 q!\u00a9\" W\u00a4 1& 90P V7BR\u00a4 1!\u00a9 y83Ey83E D &!\u00a9#)(0 0\u00a4 1\u00a4 1\"\u00a4 9QyF\u00a6\u00a9 o\u00a4\u00a9 92 C! v9% 9%\u00a4 c\" $ H# 2!\u00a9 Ft eu o TtfW g un C# 87 S 3E\u00a4\u00a5\u00a6\u00a9 q 7\u00a0\u2026", "num_citations": "27\n", "authors": ["508"]}
{"title": "Improvement of parallelization efficiency of batch pattern BP training algorithm using Open MPI\n", "abstract": " The use of tuned collective\u2019s module of Open MPI to improve a parallelization efficiency of parallel batch pattern back propagation training algorithm of a multilayer perceptron is considered in this paper. The multilayer perceptron model and the usual sequential batch pattern training algorithm are theoretically described. An algorithmic description of a parallel version of the batch pattern training method is introduced. The obtained parallelization efficiency results using Open MPI tuned collective\u2019s module and MPICH2 are compared. Our results show that (i) Open MPI tuned collective\u2019s module outperforms MPICH2 implementation both on SMP computer and computational cluster and (ii) different internal algorithms of MPI_Allreduce() collective operation give better results on different scenarios and different parallel systems. Therefore the properties of the communication network and user application should be taken\u00a0\u2026", "num_citations": "26\n", "authors": ["508"]}
{"title": "Decision trees and MPI collective algorithm selection problem\n", "abstract": " Selecting the close-to-optimal collective algorithm based on the parameters of the collective call at run time is an important step for achieving good performance of MPI applications. In this paper, we explore the applicability of C4.5 decision trees to the MPI collective algorithm selection problem. We construct C4.5 decision trees from the measured algorithm performance data and analyze both the decision tree properties and the expected run time performance penalty.               In cases we considered, results show that the C4.5 decision trees can be used to generate a reasonably small and very accurate decision function. For example, the broadcast decision tree with only 21 leaves was able to achieve a mean performance penalty of 2.08%. Similarly, combining experimental data for reduce and broadcast and generating a decision function from the combined decision trees resulted in less than 2.5% relative\u00a0\u2026", "num_citations": "26\n", "authors": ["508"]}
{"title": "Kernel-assisted and topology-aware MPI collective communications on multicore/many-core platforms\n", "abstract": " Multicore Clusters, which have become the most prominent form of High Performance Computing (HPC) systems, challenge the performance of MPI applications with non-uniform memory accesses and shared cache hierarchies. Recent advances in MPI collective communications have alleviated the performance issue exposed by deep memory hierarchies by carefully considering the mapping between the collective topology and the hardware topologies, as well as the use of single-copy kernel assisted mechanisms. However, on distributed environments, a single level approach cannot encompass the extreme variations not only in bandwidth and latency capabilities, but also in the capability to support duplex communications or operate multiple concurrent copies. This calls for a collaborative approach between multiple layers of collective algorithms, dedicated to extracting the maximum degree of parallelism from\u00a0\u2026", "num_citations": "25\n", "authors": ["508"]}
{"title": "OMPIO: a modular software architecture for MPI I/O\n", "abstract": " I/O is probably the most limiting factor on high-end machines for large scale parallel applications as of today. This paper introduces OMPIO, a new parallel I/O architecture for OpenMPI. OMPIO provides a highly modular approach to parallel I/O by separating I/O functionality into smaller units (frameworks) and an arbitrary number of modules in each framework. Furthermore, each framework has a customized selection criteria that determines which module to use depending on the functionality of the framework as well as external parameters.", "num_citations": "22\n", "authors": ["508"]}
{"title": "Adapt: An event-based adaptive collective communication framework\n", "abstract": " The increase in scale and heterogeneity of high-performance computing (HPC) systems predispose the performance of Message Passing Interface (MPI) collective communications to be susceptible to noise, and to adapt to a complex mix of hardware capabilities. The designs of state of the art MPI collectives heavily rely on synchronizations; these designs magnify noise across the participating processes, resulting in significant performance slowdown. Therefore, such design philosophy must be reconsidered to efficiently and robustly run on the large-scale heterogeneous platforms. In this paper, we present ADAPT, a new collective communication framework in Open MPI, using event-driven techniques to morph collective algorithms to heterogeneous environments. The core concept of ADAPT is to relax synchronizations, while mamtaining the minimal data dependencies of MPI collectives. To fully exploit the\u00a0\u2026", "num_citations": "21\n", "authors": ["508"]}
{"title": "Parsec in practice: Optimizing a legacy chemistry application through distributed task-based execution\n", "abstract": " Task-based execution has been growing in popularity as a means to deliver a good balance between performance and portability in the post-petascale era. The Parallel Runtime Scheduling and Execution Control (PARSEC) framework is a task-based runtime system that we designed to achieve high performance computing at scale. PARSEC offers a programming paradigm that is different than what has been traditionally used to develop large scale parallel scientific applications. In this paper, we discuss the use of PARSEC to convert a part of the Coupled Cluster (CC) component of the Quantum Chemistry package NWCHEM into a task-based form. We explain how we organized the computation of the CC methods in individual tasks with explicitly defined data dependencies between them and re-integrated the modified code into NWCHEM. We present a thorough performance evaluation and demonstrate that the\u00a0\u2026", "num_citations": "20\n", "authors": ["508"]}
{"title": "Power profiling of Cholesky and QR factorizations on distributed memory systems\n", "abstract": " This paper presents the power profile of two high performance dense linear algebra libraries on distributed memory systems, ScaLAPACK and DPLASMA. From the algorithmic perspective, their methodologies are opposite. The former is based on block algorithms and relies on multithreaded BLAS and a two-dimensional block cyclic data distribution to achieve high parallel performance. The latter is based on tile algorithms running on top of a tile data layout and uses fine-grained task parallelism combined with a dynamic distributed scheduler (DAGuE) to leverage distributed memory systems. We present performance results (Gflop/s) as well as the power profile (Watts) of two common dense factorizations needed to solve linear systems of equations, namely Cholesky and QR. The reported numbers show that DPLASMA surpasses ScaLAPACK not only in terms of performance (up to 2X speedup) but also in\u00a0\u2026", "num_citations": "20\n", "authors": ["508"]}
{"title": "A scalable tools communications infrastructure\n", "abstract": " The Scalable Tools Communication Infrastructure (STCI) is an open source collaborative effort intended to provide high-performance, scalable, resilient, and portable communications and process control services for a wide variety of user and system tools. STCI is aimed specifically at tools for ultrascale computing and uses a component architecture to simplify tailoring the infrastructure to a wide range of scenarios. This paper describes STCI's design philosophy, the various components that will be used to provide an STCI implementation for a range of ultrascale platforms, and a range of tool types. These include tools supporting parallel run-time environments, such as MPI, parallel application correctness tools and performance analysis tools, as well as system monitoring and management tools.", "num_citations": "20\n", "authors": ["508"]}
{"title": "Parallel reduction to hessenberg form with algorithm-based fault tolerance\n", "abstract": " This paper studies the resilience of a two-sided factorization and presents a generic algorithm-based approach capable of making two-sided factorizations resilient. We establish the theoretical proof of the correctness and the numerical stability of the approach in the context of a Hessenberg Reduction (HR) and present the scalability and performance results of a practical implementation. Our method is a hybrid algorithm combining an Algorithm Based Fault Tolerance (ABFT) technique with diskless checkpointing to fully protect the data. We protect the trailing and the initial part of the matrix with checksums, and protect finished panels in the panel scope with diskless checkpoints. Compared with the original HR (the ScaLAPACK PDGEHRD routine) our fault-tolerant algorithm introduces very little overhead, and maintains the same level of scalability. We prove that the overhead shows a decreasing trend as the size of\u00a0\u2026", "num_citations": "19\n", "authors": ["508"]}
{"title": "Local rollback for resilient MPI applications with application-level checkpointing and message logging\n", "abstract": " The resilience approach generally used in high-performance computing (HPC) relies on coordinated checkpoint/restart, a global rollback of all the processes that are running the application. However, in many instances, the failure has a more localized scope and its impact is usually restricted to a subset of the resources being used. Thus, a global rollback would result in unnecessary overhead and energy consumption, since all processes, including those unaffected by the failure, discard their state and roll back to the last checkpoint to repeat computations that were already done. The User Level Failure Mitigation (ULFM) interface \u2013 the last proposal for the inclusion of resilience features in the Message Passing Interface (MPI) standard \u2013 enables the deployment of more flexible recovery strategies, including localized recovery. This work proposes a local rollback approach that can be generally applied to Single\u00a0\u2026", "num_citations": "18\n", "authors": ["508"]}
{"title": "Gpu-aware non-contiguous data movement in open mpi\n", "abstract": " Due to better parallel density and power efficiency, GPUs have become more popular for use in scientific applica-tions. Many of these applications are based on the ubiquitous Message Passing Interface (MPI) programming paradigm, and take advantage of non-contiguous memory layouts to exchange data between processes. However, support for efficient non-contiguous data movements for GPU-resident data is still in its infancy, imposing a negative impact on the overall application performance.", "num_citations": "18\n", "authors": ["508"]}
{"title": "Extreme-scale task-based cholesky factorization toward climate and weather prediction applications\n", "abstract": " Climate and weather can be predicted statistically via geospatial Maximum Likelihood Estimates (MLE), as an alternative to running large ensembles of forward models. The MLE-based iterative optimization procedure requires the solving of large-scale linear systems that performs a Cholesky factorization on a symmetric positive-definite covariance matrix---a demanding dense factorization in terms of memory footprint and computation. We propose a novel solution to this problem: at the mathematical level, we reduce the computational requirement by exploiting the data sparsity structure of the matrix off-diagonal tiles by means of low-rank approximations; and, at the programming-paradigm level, we integrate PaRSEC, a dynamic, task-based runtime to reach unparalleled levels of efficiency for solving extreme-scale linear algebra matrix operations. The resulting solution leverages fine-grained computations to\u00a0\u2026", "num_citations": "17\n", "authors": ["508"]}
{"title": "Open mpi: A high performance, flexible implementation of mpi point-to-point communications\n", "abstract": " Open MPI's point-to-point communications abstractions, described in this paper, handle several different communications scenarios, with a portable, high-performance design and implementation. These abstractions support two types of low-level communication protocols \u2013 general purpose point-to-point communications, like the OpenIB interface, and MPI-like interfaces, such as Myricom's MX library. Support for the first type of protocols makes use of all communications resources available to a given application run, with optional support for communications error recovery. The latter provides a interface layer, relying on the communications library to guarantee correct MPI message ordering and matching. This paper describes the three point-to-point communications protocols currently supported in the Open MPI implementation, supported with performance data. This includes comparisons with other MPI\u00a0\u2026", "num_citations": "17\n", "authors": ["508"]}
{"title": "Online dynamic monitoring of MPI communications\n", "abstract": " As the complexity and diversity of computer hardware and the elaborateness of network technologies have made the implementation of portable and efficient algorithms more challenging, the need to understand application communication patterns has become increasingly relevant. This paper presents details of the design and evaluation of a communication-monitoring infrastructure developed in the Open MPI software stack that can expose a dynamically configurable level of detail concerning application communication patterns.", "num_citations": "16\n", "authors": ["508"]}
{"title": "Task bench: A parameterized benchmark for evaluating parallel runtime performance\n", "abstract": " We present Task Bench, a parameterized benchmark designed to explore the performance of distributed programming systems under a variety of application scenarios. Task Bench dramatically lowers the barrier to benchmarking and comparing multiple programming systems by making the implementation for a given system orthogonal to the benchmarks themselves: every benchmark constructed with Task Bench runs on every Task Bench implementation. Furthermore, Task Bench\u2019s parameterization enables a wide variety of benchmark scenarios that distill the key characteristics of larger applications.To assess the effectiveness and overheads of the tested systems, we introduce a novel metric, minimum effective task granularity (METG). We conduct a comprehensive study with 15 programming systems on up to 256 Haswell nodes of the Cori supercomputer. Running at scale, 100s-long tasks are the finest\u00a0\u2026", "num_citations": "15\n", "authors": ["508"]}
{"title": "Using software-based performance counters to expose low-level open MPI performance information\n", "abstract": " This paper details the implementation and usage of software-based performance counters to understand the performance of a particular implementation of the MPI standard, Open MPI. Such counters can expose intrinsic features of the software stack that are not available otherwise in a generic and portable way. The PMPI-interface is useful for instrumenting MPI applications at a user level, however it is insufficient for providing meaningful internal MPI performance details. While the Peruse interface provides more detailed information on state changes within Open MPI, it has not seen widespread adoption. We introduce a simple low-level approach that instruments the Open MPI code at key locations to provide fine-grained MPI performance metrics. We evaluate the overhead associated with adding these counters to Open MPI as well as their use in determining bottlenecks and areas for improvement both in user\u00a0\u2026", "num_citations": "15\n", "authors": ["508"]}
{"title": "An efficient distributed randomized algorithm for solving large dense symmetric indefinite linear systems\n", "abstract": " Randomized algorithms are gaining ground in high-performance computing applications as they have the potential to outperform deterministic methods, while still providing accurate results. We propose a randomized solver for distributed multicore architectures to efficiently solve large dense symmetric indefinite linear systems that are encountered, for instance, in parameter estimation problems or electromagnetism simulations. The contribution of this paper is to propose efficient kernels for applying random butterfly transformations and a new distributed implementation combined with a runtime (PaRSEC) that automatically adjusts data structures, data mappings, and the scheduling as systems scale up. Both the parallel distributed solver and the supporting runtime environment are innovative. To our knowledge, the randomization approach associated with this solver has never been used in public domain software\u00a0\u2026", "num_citations": "15\n", "authors": ["508"]}
{"title": "Reliability analysis of self-healing network using discrete-event simulation\n", "abstract": " The number of processors embedded on high performance computing platforms is continuously increasing to accommodate user desire to solve larger and more complex problems. However, as the number of components increases, so does the probability of failure. Thus, both scalable and fault-tolerance of software are important issues in this field. To ensure reliability of the software especially under the failure circumstance, the reliability analysis is needed. The discrete-event simulation technique offers an attractive a ternative to traditional Markovian-based analytical models, which often have an intractably large state space. In this paper, we analyze reliability of a self-healing network developed for parallel runtime environments using discrete-event simulation. The network is designed to support transmission of messages across multiple nodes and at the same time, to protect against node and process failures\u00a0\u2026", "num_citations": "15\n", "authors": ["508"]}
{"title": "Fault tolerance of MPI applications in exascale systems: The ULFM solution\n", "abstract": " The growth in the number of computational resources used by high-performance computing (HPC) systems leads to an increase in failure rates. Fault-tolerant techniques will become essential for long-running applications executing in future exascale systems, not only to ensure the completion of their execution in these systems but also to improve their energy consumption. Although the Message Passing Interface (MPI) is the most popular programming model for distributed-memory HPC systems, as of now, it does not provide any fault-tolerant construct for users to handle failures. Thus, the recovery procedure is postponed until the application is aborted and re-spawned. The proposal of the User Level Failure Mitigation (ULFM) interface in the MPI forum provides new opportunities in this field, enabling the implementation of resilient MPI applications, system runtimes, and programming language constructs able to\u00a0\u2026", "num_citations": "14\n", "authors": ["508"]}
{"title": "Impacts of Multi-GPU MPI collective communications on large FFT computation\n", "abstract": " Most applications targeting exascale, such as those part of the Exascale Computing Project (ECP), are designed for heterogeneous architectures and rely on the Message Passing Interface (MPI) as their underlying parallel programming model. In this paper we analyze the limitations of collective MPI communication for the computation of fast Fourier transforms (FFTs), which are relied on heavily for large-scale particle simulations. We present experiments made at one of the largest heterogeneous platforms, the Summit supercomputer at ORNL. We discuss communication models from state-of-the-art FFT libraries, and propose a new FFT library, named HEFFTE (Highly Efficient FFTs for Exascale), which supports heterogeneous architectures and yields considerable speedups compared with CPU libraries, while maintaining good weak as well as strong scalability.", "num_citations": "14\n", "authors": ["508"]}
{"title": "Give MPI threading a fair chance: A study of multithreaded MPI designs\n", "abstract": " The Message Passing Interface (MPI) has been one of the most prominent programming paradigms in high-performance computing (HPC) for the past decade. Lately, with changes in modern hardware leading to a drastic increase in the number of processor cores, developers of parallel applications are moving toward more integrated parallel programming paradigms, where MPI is used along with other, possibly node-level, programming paradigms, or MPI+X. MPI+threads emerged as one of the favorite choices in HPC community, according to a survey of the HPC community. However, threading support in MPI comes with many compromises to the overall performance delivered, and, therefore, its adoption is compromised. This paper studies in depth the MPI multi-threaded implementation design in one of the leading MPI implementations, Open MPI, and expose some of the shortcomings of the current design. We\u00a0\u2026", "num_citations": "14\n", "authors": ["508"]}
{"title": "Recovery patterns for iterative methods in a parallel unstable environment\n", "abstract": " A simple checkpoint-free fault-tolerant scheme for parallel iterative methods is given. Assuming that when one processor fails, all its data is lost and the system is recovered with a new processor, this scheme computes a new approximate solution from the data of the non-failed system. The iterative method is then restarted from this new vector. The main advantage of this technique over standard checkpoint is that there is no extra computation added in the iterative solver. In particular, if no failure occurs, the fault-tolerant application is the same as the original application. The main drawback is that the convergence after failure of the method is no longer the same as the original method. In this paper, we present this recovery technique as well as some implementations of checkpoints in iterative methods. Finally, experiments are presented to compare the two techniques. The fault tolerant MPI library is the FT-MPI library. Iterative linear solvers and iterative eigensolvers are considered.", "num_citations": "14\n", "authors": ["508"]}
{"title": "Efficient parallelization of batch pattern training algorithm on many-core and cluster architectures\n", "abstract": " The experimental research of the parallel batch pattern back propagation training algorithm on the example of recirculation neural network on many-core high performance computing systems is presented in this paper. The choice of recirculation neural network among the multilayer perceptron, recurrent and radial basis neural networks is proved. The model of a recirculation neural network and usual sequential batch pattern algorithm of its training are theoretically described. An algorithmic description of the parallel version of the batch pattern training method is presented. The experimental research is fulfilled using the Open MPI, Mvapich and Intel MPI message passing libraries. The results obtained on many-core AMD system and Intel MIC are compared with the results obtained on a cluster system. Our results show that the parallelization efficiency is about 95% on 12 cores located inside one physical AMD\u00a0\u2026", "num_citations": "13\n", "authors": ["508"]}
{"title": "Optimal routing in binomial graph networks\n", "abstract": " A circulant graph with n nodes and  jumps  j 1 , j 2 ,..., j m  is a graph in which each node i, 0 les i les n-1, is adjacent to all the vertices i plusmn j k   mod   n , where 1 les k les m. A binomial graph network (BMG) is a circulant graph where jk is the power of 2 that is less than or equal to n. This paper presents an optimal (shortest path) two-terminal routing algorithm for BMG networks. This algorithm uses only the destination address to determine the next hop in order to stay on the shortest path. Unlike the original algorithms, it does not require extra space for routing tables or additional information in the packet. The experimental results show that the new optimal algorithm is significantly faster than the original optimal algorithm.", "num_citations": "13\n", "authors": ["508"]}
{"title": "Plan b: Interruption of ongoing mpi operations to support failure recovery\n", "abstract": " Advanced failure recovery strategies in HPC system benefit tremendously from in-place failure recovery, in which the MPI infrastructure can survive process crashes and resume communication services. In this paper we present the rationale behind the specification, and an effective implementation of the Revoke MPI operation. The purpose of the Revoke operation is the propagation of failure knowledge, and the interruption of ongoing, pending communication, under the control of the user. We explain that the Revoke operation can be implemented with a reliable broadcast over the scalable and failure resilient Binomial Graph (BMG) overlay network. Evaluation at scale, on a Cray XC30 supercomputer, demonstrates that the Revoke operation has a small latency, and does not introduce system noise outside of failure recovery periods.", "num_citations": "12\n", "authors": ["508"]}
{"title": "Tuned: An Open MPI collective communications component\n", "abstract": " Collective communications are invaluable to modern high performance applications, although most users of these communication patterns do not always want to know their inner most working. The implementation of the collectives are often left to the middle-ware developer such as those providing an MPI library. As many of these libraries are designed to be both generic and portable the MPI developers commonly offer internal tuning options suitable only for knowledgeable users that allow some level of customization. The work presented in this paper aims not only to provide a very efficient set of collective operations for use with the Open MPI implementation but also to make the control and tuning of them straightforward and flexible.", "num_citations": "12\n", "authors": ["508"]}
{"title": "Performance analysis of tile low-rank Cholesky factorization using parsec instrumentation tools\n", "abstract": " This paper highlights the necessary development of new instrumentation tools within the PaRSE task-based runtime system to leverage the performance of low-rank matrix computations. In particular, the tile low-rank (TLR) Cholesky factorization represents one of the most critical matrix operations toward solving challenging large-scale scientific applications. The challenge resides in the heterogeneous arithmetic intensity of the various computational kernels, which stresses PaRSE's dynamic engine when orchestrating the task executions at runtime. Such irregular workload imposes the deployment of new scheduling heuristics to privilege the critical path, while exposing task parallelism to maximize hardware occupancy. To measure the effectiveness of PaRSE's engine and its various scheduling strategies for tackling such workloads, it becomes paramount to implement adequate performance analysis and profiling\u00a0\u2026", "num_citations": "11\n", "authors": ["508"]}
{"title": "CPU-GPU hybrid bidiagonal reduction with soft error resilience\n", "abstract": " Soft errors pose a real challenge to applications running on modern hardware as the feature size becomes smaller and the integration density increases for both the modern processors and the memory chips. Soft errors manifest themselves as bit-flips that alter the user value, and numerical software is a category of software that is sensitive to such data changes. In this paper, we present a design of a bidiagonal reduction algorithm that is resilient to soft errors, and we also describe its implementation on hybrid CPU-GPU architectures. Our fault-tolerant algorithm employs Algorithm Based Fault Tolerance, combined with reverse computation, to detect, locate, and correct soft errors. The tests were performed on a Sandy Bridge CPU coupled with an NVIDIA Kepler GPU. The included experiments show that our resilient bidiagonal reduction algorithm adds very little overhead compared to the error-prone code. At matrix\u00a0\u2026", "num_citations": "10\n", "authors": ["508"]}
{"title": "Matrices over runtime systems at exascale\n", "abstract": " The goal of Matrices Over Runtime Systems at Exascale (MORSE) project is to design dense and sparse linear algebra methods that achieve the fastest possible time to an accurate solution on large-scale multicore systems with GPU accelerators, using all the processing power that future high end systems can make available. In this poster, we propose a framework for describing linear algebra algorithms at a high level of abstraction and delegating the actual execution to a runtime system in order to design software whose performance is portable accross architectures. We illustrate our methodology on three classes of problems: dense linear algebra, sparse direct methods and fast multipole methods. The resulting codes have been incorporated into Magma, Pastix and ScalFMM solvers, respectively.", "num_citations": "10\n", "authors": ["508"]}
{"title": "Self-healing in binomial graph networks\n", "abstract": " The number of processors embedded in high performance computing platforms is growing daily to solve larger and more complex problems. However, as the number of components increases, so does the probability of failure. The logical network topologies must also support the fault-tolerant capability in such dynamic environments. This paper presents a self-healing mechanism to improve the fault-tolerant capability of a Binomial graph (BMG) network. The self-healing mechanism protects BMG from network bisection and helps maintain optimal routing even in failure circumstances. The experimental results show that self-healing with an adaptive method significantly reduces the overhead from reconstructing the networks.", "num_citations": "10\n", "authors": ["508"]}
{"title": "Runtime level failure detection and propagation in HPC systems\n", "abstract": " As the scale of high-performance computing (HPC) systems continues to grow, mean-time-to-failure (MTTF) of these HPC systems is negatively impacted and tends to decrease. In order to efficiently run long computing jobs on these systems, handling system failures becomes a prime challenge. We present here the design and implementation of an efficient runtime-level failure detection and propagation strategy targeting large-scale, dynamic systems that is able to detect both node and process failures. Multiple overlapping topologies are used to optimize the detection and propagation, minimizing the incurred overheads and guaranteeing the scalability of the entire framework. The resulting framework has been implemented in the context of a system-level runtime for parallel environments, PMIx Reference RunTime Environment (PRRTE), providing efficient and scalable capabilities of fault management to a large\u00a0\u2026", "num_citations": "9\n", "authors": ["508"]}
{"title": "Task-based programming for seismic imaging: Preliminary results\n", "abstract": " The level of hardware complexity of current supercomputers is forcing the High Performance Computing (HPC) community to reconsider parallel programming paradigms and standards. The high-level of hardware abstraction provided by task-based paradigms make them excellent candidates for writing portable codes that can consistently deliver high performance across a wide range of platforms. While this paradigm has proved efficient for achieving such goals for dense and sparse linear solvers, it is yet to be demonstrated that industrial parallel codes relying on the classical Message Passing Interface (MPI) standard and that accumulate dozens of years of expertise (and countless lines of code) may be revisited to turn them into efficient task-based programs. In this paper, we study the applicability of task-based programming in the case of a Reverse Time Migration (RTM) application for Seismic Imaging. The\u00a0\u2026", "num_citations": "9\n", "authors": ["508"]}
{"title": "Network fault tolerance in open MPI\n", "abstract": " High Performance Computing (HPC) systems are rapidly growing in size and complexity. As a result, transient and persistent network failures can occur on the time scale of application run times, reducing the productive utilization of these systems. The ubiquitous network protocol used to deal with such failures is TCP/IP, however, available implementations of this protocol provide unacceptable performance for HPC system users, and do not provide the high bandwidth, low latency communications of modern interconnects. This paper describes methods used to provide protection against several network errors such as dropped packets, corrupt packets, and loss of network interfaces while maintaining high-performance communications. Micro-benchmark experiments using vendor supplied TCP/IP and O/S bypass low-level communications stacks over InfiniBand and Myrinet are used to demonstrate the high\u00a0\u2026", "num_citations": "9\n", "authors": ["508"]}
{"title": "Efficient communications in training large scale neural networks\n", "abstract": " We consider the problem of how to reduce the cost of communication that is re-quired for the parallel training of a neural network. The state-of-the-art method, Bulk Synchronous Parallel Stochastic Gradient Descent (BSP-SGD), requires a many collective communication operations, like broadcasts of parameters or reduc-tions for sub-gradient aggregations, which for large messages quickly dominates overall execution time and limits parallel scalability. To address this problem, we develop a new technique for collective operations, referred to as Linear Pipelining (LP). It is tuned to the message sizes that arise in BSP-SGD, and works effectively on multi-GPU systems. Theoretically, the cost of LP is invariant to P, where P is the number of GPUs, while the cost of more conventional Minimum Spanning Tree (MST) scales like O (log P). LP also demonstrate up to 2x faster bandwidth than Bidirectional Exchange (BE) techniques that are widely adopted by current MPI implementations. We apply these collectives to BSP-SGD, showing that the proposed implementations reduce communication bottlenecks in practice while preserving the attractive convergence properties of BSP-SGD.", "num_citations": "8\n", "authors": ["508"]}
{"title": "Optimizations to enhance sustainability of MPI applications\n", "abstract": " Ultrascale computing systems are likely to reach speeds of two or three orders of magnitude greater than today's computing systems. However, to achieve this level of performance, we need to design and implement more sustainable solutions for ultra-scale computing systems, at both the hardware and software levels, while understanding sustainability in a holistic manner in order to address challenges in economy-of-scale, agile elastic scalability, heterogeneity, programmability, fault resilience, energy efficiency, and storage. Some solutions could be integrated into MPI, but others should be devised as higher level concepts, less general, but adapted to applicative domains, possibly as programming patterns or libraries. In this paper, we layout some proposals to extend MPI to cover major relevant domains in a move towards sustainability, including: MPI programming optimizations and programming models\u00a0\u2026", "num_citations": "8\n", "authors": ["508"]}
{"title": "Hash functions for datatype signatures in MPI\n", "abstract": " Detecting misuse of datatypes in an application code is a desirable feature for an MPI library. To support this goal we investigate the class of hash functions based on checksums to encode the type signatures of MPI datatype. The quality of these hash functions is assessed in terms of hashing, timing and comparing to other functions published for this particular problem (Gropp, 7th European PVM/MPI Users\u2019 Group Meeting, 2000) or for other applications (CRCs). In particular hash functions based on Galois Field enables good hashing, computation of the signature of unidatatype in (1) and computation of the concatenation of two datatypes in (1) additionally.", "num_citations": "8\n", "authors": ["508"]}
{"title": "Performance analysis of mpi collective operations\n", "abstract": " Previous studies of application usage show that the performance of collective communica-tions are critical for high performance computing and are often overlooked when compared to the point-to-point performance. In this paper we attempt to analyze and improve collective communication in the context of the widely deployed MPI programming paradigm by extending accepted models of point-to-point communication, such as Hockney, LogP/LogGP, and PLogP. The predictions from the models were compared to the experimentally gathered data and our findings were used to optimize the implementation of collective operations in the FT-MPI library. 1", "num_citations": "8\n", "authors": ["508"]}
{"title": "Impact of kernel-assisted mpi communication over scientific applications: Cpmd and fftw\n", "abstract": " Collective communication is one of the most powerful message passing concepts, enabling parallel applications to express complex communication patterns while allowing the underlying MPI to provide efficient implementations to minimize the cost of the data movements. However, with the increase in the heterogeneity inside the nodes, more specifically the memory hierarchies, harnessing the maximum compute capabilities becomes increasingly difficult. This paper investigates the impact of kernel-assisted MPI communication, over two scientific applications: 1) Car-Parrinello molecular dynamics(CPMD), a chemical molecular dynamics application, and 2) FFTW, a Discrete Fourier Transform (DFT). By focusing on the usage of Message Passing Interface (MPI), we found the communication characteristics and patterns of each application. Our experiments indicate that the quality of the collective\u00a0\u2026", "num_citations": "7\n", "authors": ["508"]}
{"title": "Efficient communications in training large scale neural networks\n", "abstract": " We consider the problem of how to reduce the cost of communication that is required for the parallel training of a neural network. The state-of-the-art method, Bulk Synchronous Parallel Stochastic Gradient Descent (BSP-SGD), requires many collective communication operations, like broadcasts of parameters or reductions for partial gradient aggregations, which for large messages quickly dominates overall execution time and limits parallel scalability. To address this problem, we develop a new technique for collective operations, referred to as Linear Pipelining (LP). It is tuned to the message sizes that arise in BSP-SGD, and works effectively on multi-GPU systems. Theoretically, the cost of LP is invariant to P, where P is the number of GPUs, while the cost of the more conventional Minimum Spanning Tree (MST) scales like O (log P). LP also demonstrates up to 2x higher bandwidth than Bidirectional Exchange (BE\u00a0\u2026", "num_citations": "6\n", "authors": ["508"]}
{"title": "Kernel assisted collective intra-node communication among multicore and manycore CPUs\n", "abstract": " More memory hierarchies, NUMA architectures and network-style interconnection are widely used in modern many-core CPU design to achieve performance scalability. As a leading intra-node programming model, Message Passing Interface (MPI) implementations must exploit these architectures to provide reliable performance portability. These new architectures not only require specialized MPI point-to-point messaging protocols, they also require carefully designed and tuned algorithms for MPI collective operations. Multiple issues must be taken into account: 1) minimizing the number of copies required, 2) minimizing traffic to ''remote'' NUMA memory, and 3) carefully avoiding memory bottlenecks for ''rooted'' collective operations. In this paper, we present a kernel assisted intra-node collective module addressing those three issues on many-core systems. A kernel level inter-process memory copy module, called KNEM, is used by a novel Open MPI collective module to implement several improved strategies based on decreasing the number of intermediate memory copies and improving locality to reduce both the pressure on the memory banks and the cache pollution. The collective topology is mapped onto the NUMA topology to minimize cross traffic on inter-socket links. Experiments illustrate that the KNEM enabled Open MPI collective module can achieve up to a threefold speedup on synthetic benchmarks, resulting in a 12% improvement for a parallel graph shortest path discovery application.", "num_citations": "6\n", "authors": ["508"]}
{"title": "An evaluation of Open MPI\u2019s matching transport layer on the Cray XT\n", "abstract": " Open MPI was initially designed to support a wide variety of high-performance networks and network programming interfaces. Recently, Open MPI was enhanced to support networks that have full support for MPI matching semantics. Previous Open MPI efforts focused on networks that require the MPI library to manage message matching, which is sub-optimal for some networks that inherently support matching. We describes a new matching transport layer in Open MPI, present results of micro-benchmarks and several applications on the Cray XT platform, and compare performance of the new and the existing transport layers, as well as the vendor-supplied implementation of MPI.", "num_citations": "6\n", "authors": ["508"]}
{"title": "Je rey M\n", "abstract": " Atteint du syndrome de Treacher-Collins (malformation du visage, multiples handicaps), J\u00e9r\u00e9my a une particularit\u00e9: il r\u00e9alise tous ses r\u00eaves. Il a \u00e9t\u00e9 re\u00e7u par C\u00e9line Dion et Ren\u00e9 Angelil \u00e0 Las Vegas, a chant\u00e9 pour le pape\u2026 Il aurait pu subir son existence, mais il a d\u00e9cid\u00e9 de la rendre la plus belle possible. Pour lui, et pour les autres. Une magnifique le\u00e7on de vie.", "num_citations": "6\n", "authors": ["508"]}
{"title": "FFT-based Gradient Sparsification for the Distributed Training of Deep Neural Networks\n", "abstract": " The performance and efficiency of distributed training of Deep Neural Networks (DNN) highly depend on the performance of gradient averaging among participating processes, a step bound by communication costs. There are two major approaches to reduce communication overhead: overlap communications with computations (lossless), or reduce communications (lossy). The lossless solution works well for linear neural architectures, eg VGG, AlexNet, but more recent networks such as ResNet and Inception limit the opportunity for such overlapping. Therefore, approaches that reduce the amount of data (lossy) become more suitable. In this paper, we present a novel, explainable lossy method that sparsifies gradients in the frequency domain, in addition to a new range-based float point representation to quantize and further compress gradients. These dynamic techniques strike a balance between compression\u00a0\u2026", "num_citations": "5\n", "authors": ["508"]}
{"title": "Understanding scalability and fine-grain parallelism of synchronous data parallel training\n", "abstract": " In the age of big data, deep learning has emerged as a powerful tool to extract insight and exploit its value, both in industry and scientific applications. With increasing complexity of learning models and amounts of training data, data-parallel approaches based on frequent all-reduce synchronization steps are increasingly popular. Despite the fact that high-performance computing (HPC) technologies have been designed to address such patterns efficiently, the behavior of data-parallel approaches on HPC platforms is not well understood. To address this issue, in this paper we study the behavior of Horovod, a popular data-parallel approach that relies on MPI, on Theta, a pre-Exascale machine at Argonne National Laboratory. Using two representative applications, we explore two aspects: (1) how performance and scalability is affected by important parameters such as number of nodes, number of workers, threads\u00a0\u2026", "num_citations": "5\n", "authors": ["508"]}
{"title": "Exploiting a Parametrized Task Graph model for the parallelization of a sparse direct multifrontal solver\n", "abstract": " The advent of multicore processors requires to reconsider the design of high performance computing libraries to embrace portable and effective techniques of parallel software engineering. One of the most promising approaches consists in abstracting an application as a directed acyclic graph (DAG) of tasks. While this approach has been popularized for shared memory environments by the OpenMP 4.0 standard where dependencies between tasks are automatically inferred, we investigate an alternative approach, capable of describing the DAG of task in a distributed setting, where task dependencies are explicitly encoded. So far this approach has been mostly used in the case of algorithms with a regular data access pattern and we show in this study that it can be efficiently applied to a higly irregular numerical algorithm such as a sparse multifrontal QR method. We present the resulting implementation\u00a0\u2026", "num_citations": "5\n", "authors": ["508"]}
{"title": "Surviving errors with openshmem\n", "abstract": " Unexpected error conditions stem from a variety of underlying causes, including resource exhaustion, network failures, hardware failures, or program errors. As the scale of HPC systems continues to grow, so does the probability of encountering a condition that causes a failure; meanwhile, error recovery and run-through failure management are becoming mature, and interoperable HPC programming paradigms are beginning to feature advanced error management. As a result from these developments, it becomes increasingly desirable to gracefully handle error conditions in OpenSHMEM. In this paper, we present the design and rationale behind an extension of the OpenSHMEM API that can (1) notify user code of unexpected erroneous conditions, (2) permit customized user response to errors without incurring overhead on an error-free execution path, (3) propagate the occurence of an error condition to\u00a0\u2026", "num_citations": "5\n", "authors": ["508"]}
{"title": "Predicting MPI collective communication performance using machine learning\n", "abstract": " The Message Passing Interface (MPI) defines the semantics of data communication operations, while the implementing libraries provide several parameterized algorithms for each operation. Each algorithm of an MPI collective operation may work best on a particular system and may be dependent on the specific communication problem. Internally, MPI libraries employ heuristics to select the best algorithm for a given communication problem when being called by an MPI application. The majority of MPI libraries allow users to override the default algorithm selection, enabling the tuning of this selection process. The problem then becomes how to select the best possible algorithm for a specific case automatically. In this paper, we address the algorithm selection problem for MPI collective communication operations. To solve this problem, we propose an auto-tuning framework for collective MPI operations based on\u00a0\u2026", "num_citations": "4\n", "authors": ["508"]}
{"title": "Multirate: A flexible mpi benchmark for fast assessment of multithreaded communication performance\n", "abstract": " As the modern hardware landscape continues to drastically change, the degree of parallelism required to maintain a high occupancy of resources has substantially increased. These hardware changes have highlighted the limitations of the traditional method of using one process per processing unit, which indicates that a more flexible programming paradigm is necessary. In the context of the message passing paradigm, MPI needs a significant improvement in threaded performance in order to fully utilize all hardware capabilities. However, for developers to know what needs to be improved, and for users to know what performance to expect, benchmarks are needed to quickly assess the capabilities and performance of MPI implementations. This paper introduces a new communication benchmark designed to replicate typical application communication patterns and assess their performance with a varied amount of\u00a0\u2026", "num_citations": "4\n", "authors": ["508"]}
{"title": "Assembly operations for multicore architectures using task-based runtime systems\n", "abstract": " Traditionally, numerical simulations based on finite element methods consider the algorithm as being divided in three major steps: the generation of a set of blocks and vectors, the assembly of these blocks in a matrix and a big vector, and the inversion of the matrix. In this paper we tackle the second step, the block assembly, where no parallel algorithm is widely available. Several strategies are proposed to decompose the assembly problem while relying on a scheduling middle-ware to maximize the overlap between stages and increase the parallelism and thus the performance. These strategies are quantified using examples covering two extremes in the field, large number of non-overlapping small blocks for CFD-like problems, and a smaller number of larger blocks with significant overlap which can be met in sparse linear algebra solvers.", "num_citations": "4\n", "authors": ["508"]}
{"title": "Flexible Data Redistribution in a Task-Based Runtime System\n", "abstract": " Data redistribution aims to reshuffle data to optimize some objective for an algorithm. The objective can be multi-dimensional, such as improving computational load balance or decreasing communication volume or cost, with the ultimate goal to increase the efficiency and therefore decrease the time-to-solution for the algorithm. The classical redistribution problem focuses on optimally scheduling communications when reshuffling data between two regular, usually block-cyclic, data distributions. Recently, task-based runtime systems have gained popularity as a potential candidate to address the programming complexity on the way to exascale. In addition to an increase in portability against complex hardware and software systems, task-based runtime systems have the potential to be able to more easily cope with less-regular data distribution, providing a more balanced computational load during the lifetime of the\u00a0\u2026", "num_citations": "3\n", "authors": ["508"]}
{"title": "Asynchronous receiver-driven replay for local rollback of MPI applications\n", "abstract": " With the increase in scale and architectural complexity of supercomputers, the management of failures has become integral to successfully executing a long-running high-performance computing application. In many instances, failures have a localized scope, usually impacting a subset of the resources being used, yet widely used failure recovery strategies (like checkpoint/restart) fail to take advantage and rely on global, synchronous recovery actions. Even with local rollback recovery, in which only the fault impacted processes are restarted from a checkpoint, the consistency of further progress in the execution is achieved through the replay of communication from a message log. This theoretically sound approach encounters some practical limitations: the presence of collective operations forces a synchronous recovery that prevents survivor processes from continuing their execution, removing any possibility for\u00a0\u2026", "num_citations": "3\n", "authors": ["508"]}
{"title": "Evaluation of programming models to address load imbalance on distributed multi-core CPUs: A case study with block low-rank factorization\n", "abstract": " To minimize data movement, many parallel ap- plications statically distribute computational tasks among the processes. However, modern simulations often encounters ir- regular computational tasks whose computational loads change dynamically at runtime or are data dependent. As a result, load imbalance among the processes at each step of simulation is a natural situation that must be dealt with at the programming level. The de facto parallel programming approach, flat MPI (one process per core), is hardly suitable to manage the lack of balance, imposing significant idle time on the simulation as processes have to wait for the slowest process at each step of simulation. One critical application for many domains is the LU factor- ization of a large dense matrix stored in the Block Low-Rank (BLR) format. Using the low-rank format can significantly reduce the cost of factorization in many scientific applications\u00a0\u2026", "num_citations": "3\n", "authors": ["508"]}
{"title": "Using MPI-3 RMA for active messages\n", "abstract": " Most applications targeting exascale, such as those part of the Exascale Computing Project (ECP), are designed for heterogeneous architectures and rely on the Message Passing Interface (MPI) as their underlying parallel programming model. In this paper we analyze the limitations of collective MPI communication for the computation of fast Fourier transforms (FFTs), which are relied on heavily for large-scale particle simulations. We present experiments made at one of the largest heterogeneous platforms, the Summit supercomputer at ORNL. We discuss communication models from state-of-the-art FFT libraries, and propose a new FFT library, named HEFFTE (Highly Efficient FFTs for Exascale), which supports heterogeneous architectures and yields considerable speedups compared with CPU libraries, while maintaining good weak as well as strong scalability.", "num_citations": "3\n", "authors": ["508"]}
{"title": "Online dynamic monitoring of MPI communications: scientific user and developper guide\n", "abstract": " Understanding application communication patterns became increasingly relevant as the complexity and diversity of the underlying hardware along with elaborate network topologies are making the implementation of portable and efficient algorithms more challenging.  Equipped with the knowledge of the communication patterns, external tools can predict and improve the performance of applications either by modifying the process placement or by changing the communication infrastructure parameters to refine the match between the application requirements and the message passing library capabilities.  This report presents the design and evaluation of a communication monitoring infrastructure developed in the Open MPI software stack and able to expose a dynamically configurable level of detail about the application communication patterns, accompanied by a user documentation and a technical report about the implementation details.", "num_citations": "3\n", "authors": ["508"]}
{"title": "Toward a supernodal sparse direct solver over DAG runtimes\n", "abstract": " Toward a supernodal sparse direct solver over DAG runtimes - Universit\u00e9 de Bordeaux Acc\u00e9der directement au contenu Acc\u00e9der directement \u00e0 la navigation Toggle navigation CCSD HAL HAL HALSHS TEL M\u00e9diHAL Liste des portails AUR\u00e9HAL API Data Documentation Episciences.org Episciences.org Revues Documentation Sciencesconf.org Support Universit\u00e9 de Bordeaux Archive Ouverte HAL Accueil Consultation Liste des articles Liste par domaine Liste par auteurs Rechercher hal-00769030, version 1 Communication dans un congr\u00e8s Toward a supernodal sparse direct solver over DAG runtimes George Bosilca 1 Mathieu Faverge 1 Xavier Lacoste 2 Ichitaro Yamazaki 1 Pierre Ramet 2, 3 D\u00e9tails 1 ICL - Innovative Computing Laboratory [Knoxville] 2 HiePACS - High-End Parallel Algorithms for Challenging Numerical Simulations LaBRI - Laboratoire Bordelais de Recherche en Informatique, Inria Bordeaux - \u2026", "num_citations": "3\n", "authors": ["508"]}
{"title": "Using Advanced Vector Extensions AVX-512 for MPI Reductions\n", "abstract": " As the scale of high-performance computing (HPC) systems continues to grow, researchers are devoted themselves to explore increasing levels of parallelism to achieve optimal performance. The modern CPU\u2019s design, including its features of hierarchical memory and SIMD/vectorization capability, governs algorithms\u2019 efficiency. The recent introduction of wide vector instruction set extensions (AVX and SVE) motivated vectorization to become of critical importance to increase efficiency and close the gap to peak performance.", "num_citations": "2\n", "authors": ["508"]}
{"title": "HAN: a Hierarchical AutotuNed Collective Communication Framework\n", "abstract": " High-performance computing (HPC) systems keep growing in scale and heterogeneity to satisfy the increasing computational need, and this brings new challenges to the design of MPI libraries, especially with regard to collective operations. To address these challenges, we present \u201cHAN,\u201d a new hierarchical autotuned collective communication framework in Open MPI, which selects suitable homogeneous collective communication modules as submodules for each hardware level, uses collective operations from the submodules as tasks, and organizes these tasks to perform efficient hierarchical collective operations. With a task-based design, HAN can easily swap out submodules, while keeping tasks intact, to adapt to new hardware. This makes HAN suitable for the current platform and provides a strong and flexible support for future HPC systems. To provide a fast and accurate autotuning mechanism, we present\u00a0\u2026", "num_citations": "2\n", "authors": ["508"]}
{"title": "Using Arm Scalable Vector Extension to Optimize OPEN MPI\n", "abstract": " As the scale of high-performance computing (HPC) systems continues to grow, increasing levels of parallelism must be implored to achieve optimal performance. Recently, the processors support wide vector extensions, vectorization becomes much more important to exploit the potential peak performance of target architecture. Novel processor architectures, such as the Armv8-A architecture, introduce Scalable Vector Extension (SVE) - an optional separate architectural extension with a new set of A64 instruction encodings, which enables even greater parallelisms.In this paper, we analyze the usage and performance of the SVE instructions in Arm SVE vector Instruction Set Architecture (ISA); and utilize those instructions to improve the memcpy and various local reduction operations. Furthermore, we propose new strategies to improve the performance of MPI operations including datatype packing/unpacking and\u00a0\u2026", "num_citations": "2\n", "authors": ["508"]}
{"title": "SuperNeurons: FFT-based Gradient Sparsification in the Distributed Training of Deep Neural Networks\n", "abstract": " The performance and efficiency of distributed training of Deep Neural Networks highly depend on the performance of gradient averaging among all participating nodes, which is bounded by the communication between nodes. There are two major strategies to reduce communication overhead: one is to hide communication by overlapping it with computation, and the other is to reduce message sizes. The first solution works well for linear neural architectures, but latest networks such as ResNet and Inception offer limited opportunity for this overlapping. Therefore, researchers have paid more attention to minimizing communication. In this paper, we present a novel gradient compression framework derived from insights of real gradient distributions, and which strikes a balance between compression ratio, accuracy, and computational overhead. Our framework has two major novel components: sparsification of gradients in the frequency domain, and a range-based floating point representation to quantize and further compress gradients frequencies. Both components are dynamic, with tunable parameters that achieve different compression ratio based on the accuracy requirement and systems' platforms, and achieve very high throughput on GPUs. We prove that our techniques guarantee the convergence with a diminishing compression ratio. Our experiments show that the proposed compression framework effectively improves the scalability of most popular neural networks on a 32 GPU cluster to the baseline of no compression, without compromising the accuracy and convergence speed.", "num_citations": "2\n", "authors": ["508"]}
{"title": "The next frontier\n", "abstract": " Today, multi/many core systems have become prevalent, with architectures more or less exotic and heterogeneous. The overall theoretical computational power of the new generation processors has thus greatly increased, but their programmability still lacks certainty. The many changes in the newest architectures have come so rapidly that we are still deficient in taking advantage of all the new features, in terms of high performance libraries and applications. Simultaneously, application requirements growat least at the same pace.Obviously,more computations require more data in order to feed the deepest processor pipelines.More data means either faster access to the memory or faster access to the network. But the improvement in access speed to all types of memory (network included) lags behind the increase in computational power. As a result, while extracting the right performance of the current and\u00a0\u2026", "num_citations": "2\n", "authors": ["508"]}
{"title": "A Comparison of Application Performance Using Open MPI and Cray MPI\n", "abstract": " Open MPI is the result of an active international Open-Source collaboration of Industry, National Laboratories, and Academia. This implementation is becoming the production MPI implementation at many sites, including some of DOE\u2019s largest Linux production systems. This paper presents the results of a study comparing the application performance of VH-1, GTC, the Parallel Ocean Program, and S3D on the Cray XT4 at Oak Ridge National Laboratory, with data collected on up to 1024 process runs. The results show that the application performance using Open MPI is comparable to slightly better than that obtained using Cray-MPI, even though platform specific optimizations, beyond a basic port, have yet to be done in Open MPI.", "num_citations": "2\n", "authors": ["508"]}
{"title": "Accelerating Geostatistical Modeling and Prediction With Mixed-Precision Computations: A High-Productivity Approach with PaRSEC\n", "abstract": " Geostatistical modeling is an efficient technique for climate and environmental analysis and prediction. A primary computational kernel of stationary spatial statistics is the evaluation of the Gaussian maximum log-likelihood estimation (MLE) function, whose central data structure is a dense, symmetric, and positive-definite covariance matrix of the dimension of the number of correlated observations. The MLE approach requires the application of its inverse and evaluation of its determinant, rendered through the Cholesky decomposition and triangular solution. In this paper, we migrate geostatistics to three precisions approximation by exploiting the mathematical structure of the dense covariance matrix. We illustrate application-expected accuracy worthy of double-precision from a majority half-precision computation, in a context where all single precision is by itself insufficient. We deploy PaRSEC runtime system with\u00a0\u2026", "num_citations": "1\n", "authors": ["508"]}
{"title": "Callback-based completion notification using MPI Continuations\n", "abstract": " Asynchronous programming models (APM) are gaining more and more traction, allowing applications to expose the available concurrency to a runtime system tasked with coordinating the execution. While MPI has long provided support for multi-threaded communication and non-blocking operations, it falls short of adequately supporting APMs as correctly and efficiently handling MPI communication in different models is still a challenge. We have previously proposed an extension to the MPI standard providing operation completion notifications using callbacks, so-called MPI Continuations. This interface is flexible enough to accommodate a wide range of different APMs.In this paper, we present an extension to the previously described interface that allows for finer control of the behavior of the MPI Continuations interface. We then present some of our first experiences in using the interface in the context of different\u00a0\u2026", "num_citations": "1\n", "authors": ["508"]}
{"title": "Leveraging PaRSEC runtime support to tackle challenging 3D data-sparse matrix problems\n", "abstract": " The task-based programming model associated with dynamic runtime systems has gained popularity for challenging problems because of workload imbalance, heterogeneous resources, or extreme concurrency. During the last decade, low-rank matrix approximations\u2014where the main idea consists of exploiting data sparsity, typically by compressing off-diagonal tiles up to an application-specific accuracy threshold\u2014have been adopted to address the curse of dimensionality at extreme scale. In this paper, we create a bridge between the runtime and the linear algebra by communicating knowledge of the data sparsity to the runtime. We design and implement this synergistic approach with high user productivity in mind, in the context of the PaRSEC runtime system and the HiCMA numerical library. This requires extending PaRSEC with new features to integrate rank information into the dataflow so that proper\u00a0\u2026", "num_citations": "1\n", "authors": ["508"]}
{"title": "Getting it right with open mpi: Best practices for deployment and tuning of open mpi\n", "abstract": " Objectives\u2022 Which version of Open MPI to use and how to build it\u2022 Options for tuning/debugging Open MPI at runtime\u2022 Special considerations for ECP platforms, esp. those with GPU accelerators\u2022 A little about containers and Open MPI", "num_citations": "1\n", "authors": ["508"]}
{"title": "Is Japanese HPC another Galapagos?-Interim Report of MPI International Survey\n", "abstract": " We have been conducting questionnaire survey targeting MPI users of the whole world. At the time of this writing, we get more than 800 answers from more than 40 countries. We analyzed the currently available answers and have found some interesting results which indicate that the Japanese MPI users are different from the MPI users of the rest of the world. This paper focuses on those possible specificities of Japanese MPI users and warns the future of Japanese HPC community based on the resuklt of the survey. Since the survey is still open and accepting answers, this is an interim report of the survey.", "num_citations": "1\n", "authors": ["508"]}
{"title": "Fault detection in fortran 2015\n", "abstract": " With the increase in the number of hardware components and layers of the so ware stack in High Performance Computing (HPC) there will likely be an increment in number of hardware and so ware failures. Even under the most optimistic assumptions about the individual components reliability, probabilistic ampli cation from using millions of nodes has a dramatic impact on the Mean Time", "num_citations": "1\n", "authors": ["508"]}
{"title": "An efficient distributed randomized solver with application to large dense linear systems\n", "abstract": " Randomized algorithms are gaining ground in high-performance computing applications as they have the potential to outperform deterministic methods, while still providing accurate results. In this paper, we propose a randomized algorithm for distributed multicore architectures to efficiently solve large dense symmetric indefinite linear systems that are encountered, for instance, in parameter estimation problems or electromagnetism simulations. This solver combines an efficient implementation of a multiplicative preconditioning based on recursive random matrices, with a runtime (DAGuE) that automatically adjusts data structures, data mappings, and the scheduling as systems scale up. Both the solver and the supporting runtime environment are innovative. To our knowledge, this is the first parallel distributed solver for large dense symmetric indefinite systems, and the randomization approach associated with this solver has never been used in public domain software for such systems. The underlying runtime framework allows seamless data mapping and task scheduling, mapping its capabilities to the underlying hardware features of heterogeneous distributed architectures. The performance of our software is similar to that obtained for symmetric positive definite systems, but requires only half the execution time and half the amount of data storage of a general dense solver.", "num_citations": "1\n", "authors": ["508"]}
{"title": "Disaster Survival Guide in Petascale Computing: An Algo-rithmic Approach\n", "abstract": " George Bosilca Innovative Computing Laboratory University of Tennessee, Department of Electrical Engineering and Computer Science [email protected]", "num_citations": "1\n", "authors": ["508"]}
{"title": "A New Approach to MPI Collective Communication Implementations\n", "abstract": " Recent research into the optimization of collective MPI operations has resulted in a wide variety of algorithms and corresponding implementations, each typically only applicable in a relatively narrow scope: on a specific architecture, on a specific network, with a specific number of processes, with a specific data size and/or data-type\u2013or any combination of these (or other) factors. This situation presents an enormous challenge to portable MPI implementations which are expected to provide optimized collective operation performance on all platforms. Many portable implementations have attempted to provide a token number of algorithms that are intended to realize good performance on most systems. However, many platform configurations are still left without well-tuned collective operations. This paper presents a proposal for a framework that will allow a wide variety of collective algorithm implementations and a\u00a0\u2026", "num_citations": "1\n", "authors": ["508"]}
{"title": "ECP Milestone Report A Survey of MPI Usage in the US Exascale Computing Project WBS 2.3. 1.11 Open MPI for Exascale (OMPI-X)(formerly WBS 1.3. 1.13), Milestone STPM13-1/ST-PR\u00a0\u2026\n", "abstract": " The Exascale Computing Project (ECP) is currently the primary effort in the United States focused on developing \u201cexascale\u201d levels of computing capability, including hardware, software and applications. In order to obtain a more thorough understanding of how the software projects under the ECP are using, and planning to use the Message Passing Interface (MPI), and help guide the work of our own project within the ECP, we created a survey. Of the 97 ECP projects active at the time the survey was distributed, we received 77 responses, 56 of which reported that their projects were using MPI. This paper reports the results of that survey for the benefit of the broader community of MPI developers", "num_citations": "1\n", "authors": ["508"]}