{"title": "Software cost estimation methods: A review\n", "abstract": " Project planning is one of the most important activities in software projects. Poor planning often leads to project faults and dramatic outcomes for the project team. If cost and effort are determined pessimistic in software projects, suitable occasions can be missed; whereas optimistic predictions can be caused to some resource losing. Nowadays software project managers should be aware of the increasing of project failures. The main reason for this problem is imprecision of the estimation. In this paper, several existing methods for software cost estimation are illustrated and their aspects will be discussed. Comparing the features of the methods could be applied for clustering based on abilities; it is also useful for selecting the special method for each project. The history of using each estimation model leads to have a good choice for an especial software project. In this paper an example of estimation is also presented in an actual software project. Keywords-Cost Estimation; project fail; Cocomo; Accuracy I.", "num_citations": "173\n", "authors": ["1216"]}
{"title": "Intuitionistic fuzzy set vs. fuzzy set application in medical pattern recognition\n", "abstract": " ObjectiveOne of the toughest challenges in medical diagnosis is uncertainty handling. The detection of intestinal bacteria such as Salmonella and Shigella which cause typhoid fever and dysentery, respectively, is one such challenging problem for microbiologists. They detect the bacteria by the comparison with predefined classes to find the most similar one. Consequently, we observe uncertainty in determining the similarity degrees, and therefore, in the bacteria classification. In this paper, we take an intelligent approach towards the bacteria classification problem by using five similarity measures of fuzzy sets (FSs) and intuitionistic fuzzy sets (IFSs) to examine their capabilities in encountering uncertainty in the medical pattern recognition.MethodsFSs and IFSs are two strong frameworks for uncertainty handling. The membership degree in FSs and both membership and non-membership degrees in IFSs are the\u00a0\u2026", "num_citations": "154\n", "authors": ["1216"]}
{"title": "The Sailfish Optimizer: A novel nature-inspired metaheuristic algorithm for solving constrained engineering optimization problems\n", "abstract": " Nature-inspired optimization algorithms, especially swarm based algorithms (SAs), solve many scientific and engineering problems due to their flexibility and simplicity. These algorithms are applicable for optimization problems without structural modifications. This work presents a novel nature-inspired metaheuristic optimization algorithm, called SailFish Optimizer (SFO), which is inspired by a group of hunting sailfish. This method consists of two tips of populations, sailfish population for intensification of the search around the best so far and sardines population for diversification of the search space. The SFO algorithm is evaluated on 20 well-known unimodal and multimodal mathematical functions to test different characteristics of the algorithm. In addition, SFO is compared with the six state-of-art metaheuristic algorithms in low and high dimensions. It also indicates competitive results for improvement of exploration\u00a0\u2026", "num_citations": "146\n", "authors": ["1216"]}
{"title": "Satin bowerbird optimizer: A new optimization algorithm to optimize ANFIS for software development effort estimation\n", "abstract": " Accurate software development effort estimation is crucial to efficient planning of software projects. Due to complex nature of software projects, development effort estimation has become a challenging issue which must be seriously considered at the early stages of project. Insufficient information and uncertain requirements are the main reasons behind unreliable estimations in this area. Although numerous effort estimation models have been proposed during the last decade, accuracy level is not satisfying enough. This paper presents a new model based on a combination of adaptive neuro-fuzzy inference system (ANFIS) and satin bower bird optimization algorithm (SBO) to reach more accurate software development effort estimations. SBO is a novel optimization algorithm proposed to adjust the components of ANFIS through applying small and reasonable changes in variables. The proposed hybrid model is an\u00a0\u2026", "num_citations": "120\n", "authors": ["1216"]}
{"title": "A fuzzy-evidential hybrid inference engine for coronary heart disease risk assessment\n", "abstract": " In many engineering problems, we encounter vagueness in information and uncertainty in decision making, so as these phenomena cause we could not reach to certain results for our proposed solution. In this paper, a novel inference engine named fuzzy-evidential hybrid inference engine has been proposed using Dempster\u2013Shafer theory of evidence and fuzzy sets theory. This hybrid engine operates in two phases. In the first phase, it models the input information\u2019s vagueness through fuzzy sets. In following, extracting the fuzzy rule set for the problem, it applies the fuzzy inference rules on the acquired fuzzy sets to produce the first phase results. At second phase, the acquired results of previous stage are assumed as basic beliefs for the problem propositions and in this way, the belief and plausibility functions (or the belief interval) are set. Gathering information from different sources, they provide us with diverse\u00a0\u2026", "num_citations": "103\n", "authors": ["1216"]}
{"title": "Poor and rich optimization algorithm: A new human-based and multi populations algorithm\n", "abstract": " This paper presents a new optimization algorithm called poor and rich optimization (PRO). This algorithm is inspired by the efforts of the two groups of the poor and the rich to achieve wealth and improve their economic situation. The rich always try to increase their class gap with the poor by gaining wealth from different ways. The rich are always trying to increase their class gap with the poor by acquiring wealth from different ways. On the other hand, the poor try to gain wealth and reduce their class gap with the rich. On the other hand, the poor try to gain wealth and reduce their class gap by modeling the rich. This struggle is always going on and should be mention that the poor may get rich and vice versa. The proposed algorithm is evaluated using 33 test functions and the simulation results are compared with a number of new and well-known optimization algorithms. The evaluation domain includes uni-modal\u00a0\u2026", "num_citations": "52\n", "authors": ["1216"]}
{"title": "A neuro-fuzzy inference engine for Farsi numeral characters recognition\n", "abstract": " Character recognition of Farsi and Arabic texts as an open and demanding problem needs to encounter sophisticated specifications of the characters such as their shapes, continuity, dots and also, different fonts. Utilizing fuzzy set theory as a tolerant approach toward uncertainty and vagueness and artificial neural networks as a machine learning method in this paper, we propose a neuro-fuzzy inference engine to recognize the Farsi numeral characters. This engine takes holistic approach of character recognition through the comparison of the unknown character\u2019s features with the features of the existing characters that itself is characterized through Mamdani inference engine on fuzzy rules which is largely enhanced with a multi layer perceptron neural network\u2019s learning on features of the different fonts\u2019 characters which leads to more comprehensive recognition of Farsi numeral characters in the proposed system\u00a0\u2026", "num_citations": "32\n", "authors": ["1216"]}
{"title": "Software defect prediction using a high performance neural network\n", "abstract": " Predicting the existing defects in software products is one of the considerable issues in software engineering that contributes a lot toward saving time in software production and maintenance process. In fact, finding the desirable models for predicting software defects has nowadays turned into one of the main goals of software engineers. Since intricacies and restrictions of software development are increasing and unwilling consequences such as failure and errors decrease software quality and customer satisfaction, producing error-free software is very difficult and challenging. One of the efficient models in this field is multilayer neural network with proper learning algorithm. Many of the learning algorithms suffer from extra overfitting in the learning datasets. In this article, setting multilayer neural network method was used in order to improve and increase generalization capability of learning algorithm in predicting software defects. In order to solve the existing problems, a new method is proposed by developing new learning methods based on support vector machine principles and using evolutionary algorithms. The proposed method prevents from overfitting issue and maximizes classification margin. Efficiency of the proposed algorithm has been validated against 11 machine learning models and statistical methods within 3 NASA datasets. Results reveal that the proposed algorithm provides higher accuracy and precision compared to the other models.", "num_citations": "25\n", "authors": ["1216"]}
{"title": "TASA: A new task scheduling algorithm in cloud computing\n", "abstract": " Cloud computing refers to services that run in a distributed network and are accessible through common internet protocols. It merges a lot of physical resources and offers them to users as services according to service level agreement. Therefore, resource management alongside with task scheduling has direct influence on cloud networks\u2019 performance and efficiency. Presenting a proper scheduling method can lead to efficiency of resources by decreasing response time and costs. This paper studies the existing approaches of task scheduling and resource allocation in cloud infrastructures and assessment of their advantages and disadvantages. Afterwards, a compound algorithm is presented in order to allocate tasks to resources properly and decrease runtime. The proposed algorithm is built according to conditions of compounding Min-min and Sufferage algorithms. In the proposed algorithm, task allocation between machines takes place alternatively and with continuous change of scheduling algorithms. The main idea of the proposed algorithm is to concentrate on the number of tasks instead of the existing resources. The simulation results reveal that the proposed algorithm can achieve higher performance in decreasing response time.", "num_citations": "18\n", "authors": ["1216"]}
{"title": "A new task scheduling algorithm using firefly and simulated annealing algorithms in cloud computing\n", "abstract": " Task scheduling is a challenging and important issue, which considering increases in data sizes and large volumes of data, has turned into an NP-hard problem. This has attracted the attention of many researchers throughout the world since cloud environments are in fact homogenous systems for maintaining and processing practical applications needed by users. Thus, task scheduling has become extremely important in order to provide better services to users. In this regard, the present study aims at providing a new task-scheduling algorithm using both firefly and simulated annealing algorithms. This algorithm takes advantage of the merits of both firefly and simulated annealing algorithms. Moreover, efforts have been made in regards to changing the primary population or primary solutions for the firefly algorithm. The presented algorithm uses a better primary solution. Local search was another aspect considered for the new algorithm. The presented algorithm was compared and evaluated against common algorithms. As indicated by the results, compared to other algorithms, the presented method performs effectively better in reducing to make span using different number of tasks and virtual machines.", "num_citations": "16\n", "authors": ["1216"]}
{"title": "Model to estimate the software development effort based on in-depth analysis of project attributes\n", "abstract": " Over the past years, numerous models have been proposed to estimate the development effort in the early stages of a software project. The existing models have mostly relied on soft computing techniques and weighting methods. Although they have reduced the complexity and vagueness of software project attributes, attempts are ongoing to develop more accurate and reliable estimation models. This paper is concentrated on selective classification of software projects based on underlying attributes to localise the development effort estimation process in a widely used model called analogy-based estimation (ABE). The proposed model is a combination of ABE, selective classification and a weighting system in which the attributes of different software projects are assigned different weights. In fact, the process of attribute weighting is customised based on the nature of project being estimated. A real data set was\u00a0\u2026", "num_citations": "16\n", "authors": ["1216"]}
{"title": "A survey of advanced LEACH-based protocols\n", "abstract": " In recent years, wireless sensor networks (WSNs) have been utilized widely. Clustering is one of the methods for applying these networks energy-efficiently. In this field, many protocols have been introduced. LEACH is one of the most important clustering protocols which has attracted the attention of researchers. Therefore, prior studies have endeavored to improve it through removing some of disadvantages. As the result, many protocols have been developed during the recent years. In this paper, less studied protocols are investigated and compared with regard to different criteria such as cluster count, homogeneity or heterogeneity level, multi-levels attributes, the role of cluster head cycle, inter-cluster and intra-cluster connectivity.", "num_citations": "12\n", "authors": ["1216"]}
{"title": "Improvement of effort estimation accuracy in software projects using a feature selection approach\n", "abstract": " In recent years, utilization of feature selection techniques has become an essential requirement for processing and model construction in different scientific areas. In the field of software project effort estimation, the need to apply dimensionality reduction and feature selection methods has become an inevitable demand. The high volumes of data, costs, and time necessary for gathering data , and also the complexity of the models used for effort estimation are all reasons to use the methods mentioned. Therefore, in this article, a genetic algorithm has been used for feature selection in the field of software project effort estimation. This technique has been tested on well-known data sets. Implementation results indicate that the resulting subset, compared to the original data set, has produced better outcomes in terms of effort estimation accuracy. This article showed that genetic algorithms are ideal methods for selecting a subset of features and improving effort estimation accuracy.", "num_citations": "9\n", "authors": ["1216"]}
{"title": "A note on unique solvability of the absolute value equation\n", "abstract": " It is proved that applying sufficient regularity conditions to the interval matrix , we can create a new unique solvability condition for the absolute value\u00a0equation , since regularity of interval matrices implies unique solvability of\u00a0their corresponding absolute value equation. This condition is formulated in terms of positive\u00a0de niteness of a certain point matrix. Special case  is veri ed too as an application.", "num_citations": "9\n", "authors": ["1216"]}
{"title": "A new support vector machine-genetic algorithm (SVM-GA) based method for stock market forecasting\n", "abstract": " Since analysis of time series is so hard to do, a support vector machine can be more proper for the purpose of forecasting in field of stock market. The support vector machine (SVM) can explore suitable knowledge from so vague data, which usually is necessary to interpret the financial data. But single SVM cannot achieve accurate results. Subsequently, in this paper a combinational intelligent strategy is presented. The proposed strategy consists of genetic algorithm (GA) and SVM for the purpose of stock market forecasting. The genetic algorithm is useful to choose the most informative input indicators from among all the technical indicators. A variety of indicators from the technical analysis field of study are used as input features. Based on obtained results, the hybrid GA-SVM system performs better than Neural Network system.       Key words: Stock price forecast, genetic algorithm, support vector machine.", "num_citations": "9\n", "authors": ["1216"]}
{"title": "Towards improvement of analogy-based software development effort estimation: A review\n", "abstract": " In this paper a systematic review is conducted to investigate the structure, components, techniques, evaluation procedure, and comparison scope related to prior ABE-based studies. The undeniable role of accurate development effort estimation in the success of software project management has attracted the attention of researchers over the past few years. Among various algorithmic and non-algorithmic estimation methods, analogy based estimation (ABE) is a widely accepted method due to its simplicity and estimation capability. This paper investigates the improvement process of ABE method during 2000 to 2012. Six research questions are defined to be addressed through evaluation of prior ABE-based studies. The review domain includes 24 papers selected through a tough filtration process. The results show that improvement of ABE can be performed through adjustment, grey theory, attribute weighting and\u00a0\u2026", "num_citations": "8\n", "authors": ["1216"]}
{"title": "A new optimized hybrid model based On COCOMO to increase the accuracy of software cost estimation\n", "abstract": " The literature review shows software development projects often neither meet time deadlines, nor run within the allocated budgets. One common reason can be the inaccurate cost estimation process, although several approaches have been proposed in this field. Recent research studies suggest that in order to increase the accuracy of this process, estimation models have to be revised. The Constructive Cost Model (COCOMO) has often been referred as an efficient model for software cost estimation. The popularity of COCOMO is due to its flexibility; it can be used in different environments and it covers a variety of factors. In this paper, we aim to improve the accuracy of cost estimation process by enhancing COCOMO model. To this end, we analyze the cost drivers using meta-heuristic algorithms. In this method, the improvement of COCOMO is distinctly done by effective selection of coefficients and reconstruction of COCOMO. Three meta-heuristic optimization algorithms are applied synthetically to enhance the process of COCOMO model. Eventually, results of the proposed method are compared to COCOMO itself and other existing models. This comparison explicitly reveals the superiority of the proposed method.", "num_citations": "7\n", "authors": ["1216"]}
{"title": "The effects of perceived organizational support and organizational citizenship behaviors on continuance intention of enterprise resource planning\n", "abstract": " Although perceived organizational support (POS) and organizational citizenship behaviors (OCBs) have long received research attention, little is known of the effects of POS and OCBs in the IS usage context, specifically in the context of enterprise resource planning (ERP) continuance. In this study, the authors integrate three research streams, including POS, OCBs, and ERP continuance intention into one model in order to investigate whether POS and OCBs: altruism, conscientiousness, courtesy, civic virtue, and sportsmanship affect ERP users' continuance intention. Grounded on social exchange theory (SET), this study examined the influence of POS on OCBs, satisfaction, and continuance. In addition, the authors also assessed the mediating effects of OCBs between POS and continuance. A survey utilizing a questionnaire was used to collect data and a total of 250 usable responses were analyzed by using\u00a0\u2026", "num_citations": "7\n", "authors": ["1216"]}
{"title": "An optimization-based method to increase the accuracy of software development effort estimation\n", "abstract": " Software development effort estimation has become a challenging issue for developers, managers and customers during the last years. Some of the reasons behind this challenge are inconsistency of software projects, complexity of production process, intensive role of humans, unclear requirements and so on. In order to remedy the challenge, quite many estimation methods have been proposed in the last decades; and the attempts to increase the accuracy of estimates have not been stopped yet. Among all the existing estimation methods, analogy based estimation (ABE) is the most popular one that has been extensively used in field of software development effort estimation. This is because ABE is applicable to be used at early stages of software projects based on a smooth and clear estimation process. Despite advantages, ABE is confronted by high number of outliers and irrelevant projects frequently appeared in software project datasets. This paper proposes a hybrid model in which the genetic algorithm and ABE are combined to make a high performance estimation model. Indeed, the process of attribute weighting is adjusted so that the performance of ABE is improved. A real dataset is utilized to evaluate the accuracy of the proposed hybrid model. The comparison between the proposed model and different types of ABE certified that the performance metrics have been improved by the proposed model.", "num_citations": "7\n", "authors": ["1216"]}
{"title": "An Improved COCOMO based Model to Estimate the Effort of Software Projects\n", "abstract": " One of important aspects of software projects is estimating the cost and time required to develop projects. Nowadays, this issue has become one of the key concerns of project managers. Accurate estimation of essential effort to produce and develop software is heavily effective on success or failure of software projects and it is highly regarded as a vital factor. Failure to achieve convincing accuracy and little flexibility of current models in this field have attracted the attention of researchers in the last few years. Despite improvements to estimate effort, no agreement was obtained to select estimation model as the best one. One of effort estimation methods which is highly regarded is COCOMO. It is an extremely appropriate method to estimate effort. Although COCOMO was invented many years ago, it enjoys the effort estimation capability in software projects. Researchers have always attempted to improve the effort estimation capability in COCOMO through improving its structure. However, COCOMO results are not always satisfactory. The present study introduces a hybrid model for increasing the accuracy of COCOMO estimation. Combining bee colony algorithm with COCOMO estimation method, the proposed method obtained more efficient coefficient relative to the basic mode of COCOMO. Selecting the best coefficients maximizes the efficiency of the proposed method. The simulation results revealed the superiority of the proposed model based on MMRE and PRED (0.15).", "num_citations": "6\n", "authors": ["1216"]}
{"title": "Optimization task scheduling algorithm in cloud computing\n", "abstract": " Since software systems play an important role in applications more than ever, the security has become one of the most important indicators of softwares.Cloud computing refers to services that run in a distributed network and are accessible through common internet protocols. Presenting a proper scheduling method can lead to efficiency of resources by decreasing response time and costs. This research studies the existing approaches of task scheduling and resource allocation in cloud infrastructures and assessment of their advantages and disadvantages. Afterwards, a compound algorithm is presented in order to allocate tasks to resources properly and decrease runtime. In this paper we proposed a new method for task scheduling by learning automata (LA). This method where has named RAOLA is trained by historical information of task execution on the cloud, then divide task to many classes and evaluate them. Next, manage virtual machine for capture physical resources at any period based on rate of task classes, such that improve efficiency of cloud network.", "num_citations": "4\n", "authors": ["1216"]}
{"title": "Insightful analogy-based software development effort estimation through selective classification and localization\n", "abstract": " Accurate development effort estimation is a challenging issue in the management of software projects because it can considerably affect the planning and scheduling of a software project. Over the past few years, many algorithmic and non-algorithmic methods have been proposed to estimate the development effort in the early stages of project. Due to simplicity and estimation capability, analogy-based estimation (ABE) method has been widely accepted by researchers in this area. In spite of the fact that ABE is an efficient estimation method, it suffers from the non-normality and heterogeneous nature of software project datasets. Although prior studies have strived to remedy this issue by weighting, soft computing, and clustering techniques, the estimate accuracy is still not convincing and attempts are ongoing to reach more reliable estimates. The problem is that prior ABE-based studies have not considered\u00a0\u2026", "num_citations": "4\n", "authors": ["1216"]}
{"title": "The application of meta-heuristic based clustering techniques in wireless sensor networks\n", "abstract": " Wireless sensor networks are normally utilized for monitoring and controlling of specific environments. They are made out of a large number of low-cost sensor nodes which are densely separated in distributed environments. The information collected by sensors should be transmitted to a base station. Recent developments indicate that the interest in applications of wireless sensor networks has increased and expanded on a large scale. One of the most important issues in this type of networks is limited energy. Clustering is a suitable method for increasing network lifetime that protects the limited sensor resources by energy saving. Meta-heuristic algorithms have been widely used for clustering of wireless sensor networks. In most complicated problems, it is required to evaluate a multitude of possible modes, to determine an accurate answer. Meta-heuristic algorithms can provide an answer in acceptable time constraints. They play an effective role in solving such problems by optimizing the energy consumption of the networks that has a significant impact on the network lifetime. In this paper, the application of clustering algorithms in wireless sensor networks has been investigated. The selected clustering methods are based on the meta-heuristic algorithms.", "num_citations": "4\n", "authors": ["1216"]}
{"title": "Connection availability analysis in the WiMAX mesh networks\n", "abstract": " The WiMAX (Worldwide Interoperability for Microwave Access) Mesh network is based on IEEE 802.16 standard. It was developed with the goal of providing easy, fast and cost-effective network set-up, deployment and extension. One of the important challenges for the mesh WiMAX is to know the availability of the system. In the WiMAX Mesh mode, multiple nodes are available to select a sponsor node. The multiple node technique increases the fault tolerance and the availability of the network. The objective of this paper is to propose a generalized connection availability model based on multinode for a sponsor node selection to measure the availability. An analytical modeling framework also is developed to determine the availability of the network. Finally, the effective factor on the availability of WiMAX mesh networks is presented. The simulation results show that the model has increased the connection availability\u00a0\u2026", "num_citations": "3\n", "authors": ["1216"]}
{"title": "Correcting real-word spelling errors: A new hybrid approach\n", "abstract": " Spelling correction is one of the main tasks in the field of Natural Language Processing. Contrary to common spelling errors, real-word errors cannot be detected by conventional spelling correction methods. The real-word correction model proposed by Mays, Damerau, and Mercer showed a great performance in different evaluations. In this research, however, a new hybrid approach is proposed which relies on statistical and syntactic knowledge to detect and correct real-word errors. In this model, Constraint Grammar is used to discriminate among sets of correction candidates in the search space. Mays, Damerau, and Mercer\u2019s trigram approach is manipulated to estimate the probability of syntactically well-formed correction candidates. The approach proposed here is tested on the Wall Street Journal corpus. The model can prove to be more practical than some other models, such as WordNet-based method of\u00a0\u2026", "num_citations": "2\n", "authors": ["1216"]}
{"title": "The application of meta-heuristic algorithms to improve the performance of software development effort estimation models\n", "abstract": " One of the major activities in effective and efficient production of software projects is the precise estimation of software development effort. Estimation of the effort in primary steps of software development is one of the most important challenges in managing software projects. Some reasons for these challenges such as: discordant software projects, the complexity of the manufacturing process, special role of human and high level of obscure and unusual features of software projects can be noted. Predicting the necessary efforts to develop software using meta-heuristic optimization algorithms has made significant progressions in this field. These algorithms have the potent to be used in estimation of the effort of the software. The necessity to increase estimation precision urged the authors to survey the efficiency of some meta-heuristic optimization algorithms and their effects on the software projects. To do so, in this\u00a0\u2026", "num_citations": "2\n", "authors": ["1216"]}
{"title": "Application domain of recommender system: a survey\n", "abstract": " nowadays recommender systems have attracted the attention of many researchers. Actually, today's world is dependent to this scope. Recommender systems emerged to help users to find the items that match their interests and preferences. Due to the lake of an appropriate survey for showing the applications of recommender systems, principles and fundamentals of recommender system are described and some of its most important applications that are essential for the contemporary life are expressed in this paper. Moreover, advantages and disadvantages of recent provided systems have been discussed in order to achieve high performance recommendation systems. In general, the recommender systems are divided into two individual and group types. Both types of systems have been considered in this paper. In addition, the latest techniques in the field of recommender systems are described and analyzed. The results of this survey can be used as a basic reference for improving and optimizing existing systems.", "num_citations": "2\n", "authors": ["1216"]}
{"title": "Polynomial analogy\u2010based software development effort estimation using combined particle swarm optimization and simulated annealing\n", "abstract": " Software development effort estimation is an effective factor in the success or failure of software projects. There are several methods to estimate the effort of software projects, the most common of which is analogy\u2010based estimation (ABE). In this article, a polynomial version of ABE (named PABE) is presented, in which, the project effort is calculated based on a polynomial ensemble of different ABE models. To optimize the controllable parameters of the PABE model, a combined global\u2013local search metaheuristic algorithm based on particle swarm optimization and simulated annealing is utilized in two steps. At the first step, for each similarity and adaptation function, the optimized ABE model is determined by exploiting the optimal value of feature weights, the number of similar projects, and other parameters of the ABE model. Then, at the second step, the amount of effort attained by the optimized models is used for\u00a0\u2026", "num_citations": "1\n", "authors": ["1216"]}
{"title": "A Novel ICA-based Estimator for Software Cost Estimation\n", "abstract": " One of the most important and valuable goal of software development life cycle is software cost estimation or SCE. During the recent years, SCE has attracted the attention of researchers due to huge amount of software project requests. There have been proposed so many models using heuristic and meta-heuristic algorithms to do machine learning process for SCE. COCOMO81 is one of the most popular models for SCE proposed by Barry Boehm in 1981. However COCOMO81 is an old estimation model, it has been widely used for the purpose of cost estimation in its new forms. In this paper, the Imperialism Competition Algorithm (ICA) has been employed to tune the COCOMO81 parameters. Experimental results show that in the separated COCOMO81 dataset, ICA can estimate the COCOMO81 model parameters such that the performance parameters are significantly improved. The proposed hybrid model is flexible enough to tune the parameters for any data sets in form of COCOMO81.", "num_citations": "1\n", "authors": ["1216"]}
{"title": "The Application of Automated Tools to Improve the Software Testing Process\n", "abstract": " Software testing is the major challenge of complex software systems. In this field, accuracy and running time are two major performance factors frequently employed to evaluate the reliability of software testing. Automated software testing is a technique which significantly improves these performance factors. There are various automated testing tools dealing with design features however this paper focuses on the comparison of the testing tools exclusively used for. Net applications. We attempted to search for high performance testing tools including popular software testing environments so that the obtained results can be extended to a wide domain of software developers. The main goal of this paper is to analyze and compare the automated software testing tools using practical examples and review the performance of these tools in terms of software reliability determination.", "num_citations": "1\n", "authors": ["1216"]}
{"title": "Job Scheduling Algorithms in the Cloud: A review\n", "abstract": " Cloud computing refers to services that are implemented in a distributed network and are available via common internet protocols. Cloud architecture integrates a large number of physical resources and provides them for the user as services under the service level agreements. Therefore, resource management along with task scheduling method has a direct impact on cloud network performance and productivity of its resources. Providing a suitable scheduling method can lead to resources utilization by reducing the response time of tasks and decreasing the costs. This article aims to investigate the current methods of task scheduling and allocation of resources in cloud infrastructure and to assess its advantages and shortcomings. Then, the challenges and open issues in the field of cloud computing scheduling will be discussed as the future research areas.", "num_citations": "1\n", "authors": ["1216"]}