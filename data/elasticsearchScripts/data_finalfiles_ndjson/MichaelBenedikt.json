{"title": "XPath satisfiability in the presence of DTDs\n", "abstract": " We study the satisfiability problem associated with XPath in the presence of DTDs. This is the problem of determining, given a query p in an XPath fragment and a DTD D, whether or not there exists an XML document T such that T conforms to D and the answer of p on T is nonempty. We consider a variety of XPath fragments widely used in practice, and investigate the impact of different XPath operators on the satisfiability analysis. We first study the problem for negation-free XPath fragments with and without upward axes, recursion and data-value joins, identifying which factors lead to tractability and which to NP-completeness. We then turn to fragments with negation but without data values, establishing lower and upper bounds in the absence and in the presence of upward modalities and recursion. We show that with negation the complexity ranges from PSPACE to EXPTIME. Moreover, when both data values and\u00a0\u2026", "num_citations": "335\n", "authors": ["1892"]}
{"title": "E-services: a look behind the curtain\n", "abstract": " The emerging paradigm of electronic services promises to bring to distributed computation and services the flexibility that the web has brought to the sharing of documents. An understanding of fundamental properties of e-service composition is required in order to take full advantage of the paradigm. This paper examines proposals and standards for e-services from the perspectives of XML, data management, workflow, and process models. Key areas for study are identified, including behavioral service signatures, verification and synthesis techniques for composite services, analysis of service data manipulation commands, and XML analysis applied to service specifications. We give a sample of the relevant results and techniques in each of these areas.", "num_citations": "315\n", "authors": ["1892"]}
{"title": "Relational expressive power of constraint query languages\n", "abstract": " The expressive power of first-order query languages with several classes of equality and inequality constraints is studied in this paper. We settle the conjecture that recursive queries such as parity test and transitive closure cannot be expressed in the relational calculus augmented with polynomial inequality constraints over the reals. Furthermore, noting that relational queries exhibit several forms of genericity, we establish a number of collapse results of the following form: The class of generic Boolean queries expressible in the relational calculus augmented with a given class of constraints coincides with the class of queries expressible in the relational calculus (with or without an order relation). We prove such results for both the natural and active-domain semantics. As  a consequence, the relational calculus augmented with polynomial inequalities expresses the same classes of generic Boolean queries under\u00a0\u2026", "num_citations": "172\n", "authors": ["1892"]}
{"title": "XPath leashed\n", "abstract": " This survey gives an overview of formal results on the XML query language XPath. We identify several important fragments of XPath, focusing on subsets of XPath 1.0. We then give results on the expressiveness of XPath and its fragments compared to other formalisms for querying trees, algorithms, and complexity bounds for evaluation of XPath queries, as well as static analysis of XPath queries.", "num_citations": "158\n", "authors": ["1892"]}
{"title": "Efficient network aware search in collaborative tagging sites\n", "abstract": " The popularity of collaborative tagging sites presents a unique opportunity to explore keyword search in a context where query results are determined by the opinion of a network of taggers related to a seeker. In this paper, we present the first in-depth study of network-aware search. We investigate efficient top-k processing when the score of an answer is computed as its popularity among members of a seeker's network. We argue that obvious adaptations of top-k algorithms are too space-intensive, due to the dependence of scores on the seeker's network. We therefore develop algorithms based on maintaining score upper-bounds. The global upper-bound approach maintains a single score upper-bound for every pair of item and tag, over the entire collection of users. The resulting bounds are very coarse. We thus investigate clustering seekers based on similar behavior of their networks. We show that finding the\u00a0\u2026", "num_citations": "153\n", "authors": ["1892"]}
{"title": "Method and apparatus for generating program code for world wide web service applications\n", "abstract": " A new application language called the MAWL language and a compiler for the new application language called the MAWL compiler are provided for use by programmers of World Wide Web services. The MAWL language and the MAWL compiler may be used to provide any World Wide Web service, but they are especially useful for programming interactive services. The MAWL language provides an expressive typing capability. Through this expressive ability World Wide Web services that have defined states, sequences and sessions are straightforward where previously such capabilities do not exist. Further, the MAWL compiler performs error checking for common errors and self-consistency before actual compiling so run-time error checking is avoided. Together the MAWL language and the MAWL compiler greatly increase the productivity of the World Wide Web programmer and the complexity of the World Wide\u00a0\u2026", "num_citations": "132\n", "authors": ["1892"]}
{"title": "Structural properties of XPath fragments\n", "abstract": " We study structural properties of each of the main sublanguages of XPath [8] commonly used in practice. First, we characterize the expressive power of these language fragments in terms of both logics and tree patterns. Second, we investigate closure properties, focusing on the ability to perform basic Boolean operations while remaining within the fragment. We give a complete picture of the closure properties of these fragments, treating XPath expressions both as functions of arbitrary nodes in a document tree, and as functions that are applied only at the root of the tree. Finally, we provide sound and complete axiom systems and normal forms for several of these fragments. These results are useful for simplification of XPath expressions and optimization of XML queries.", "num_citations": "123\n", "authors": ["1892"]}
{"title": "Structural properties of XPath fragments\n", "abstract": " We study structural properties of each of the main sublanguages of navigational XPath (W3c Recommendation) commonly used in practice. First, we characterize the expressive power of these language fragments in terms of both logics and tree patterns. Second, we investigate closure properties, focusing on the ability to perform basic Boolean operations while remaining within the fragment. We give a complete picture of the closure properties of these fragments, treating XPath expressions both as functions of arbitrary nodes in a document tree, and as functions that are applied only at the root of the tree. Finally, we provide sound and complete axiom systems and normal forms for several of these fragments. These results are useful for simplification of XPath expressions and optimization of XML queries.", "num_citations": "97\n", "authors": ["1892"]}
{"title": "Benchmarking the chase\n", "abstract": " The chase is a family of algorithms used in a number of data management tasks, such as data exchange, answering queries under dependencies, query reformulation with constraints, and data cleaning. It is well established as a theoretical tool for understanding these tasks, and in addition a number of prototype systems have been developed. While individual chase-based systems and particular optimizations of the chase have been experimentally evaluated in the past, we provide the first comprehensive and publicly available benchmark---test infrastructure and a set of test scenarios---for evaluating chase implementations across a wide range of assumptions about the dependencies and the data. We used our benchmark to compare chase-based systems on data exchange and query answering tasks with one another, as well as with systems that can solve similar tasks developed in closely related communities\u00a0\u2026", "num_citations": "90\n", "authors": ["1892"]}
{"title": "LTL model checking of interval Markov chains\n", "abstract": " Interval Markov chains (IMCs) generalize ordinary Markov chains by having interval-valued transition probabilities. They are useful for modeling systems in which some transition probabilities depend on an unknown environment, are only approximately known, or are parameters that can be controlled. We consider the problem of computing values for the unknown probabilities in an IMC that maximize the probability of satisfying an \u03c9-regular specification. We give new upper and lower bounds on the complexity of this problem. We then describe an approach based on an expectation maximization algorithm. We provide some analytical guarantees on the algorithm, and show how it can be combined with translation of logic to automata. We give experiments showing that the resulting system gives a practical approach to model checking IMCs.", "num_citations": "85\n", "authors": ["1892"]}
{"title": "Capturing both types and constraints in data integration\n", "abstract": " We propose a framework for integrating data from multiple relational sources into an XML document that both conforms to a given DTD and satisfies predefined XML constraints. The framework is based on a specification language, AIG, that extends a DTD by (1) associating element types with semantic attributes (inherited and synthesized, inspired by the corresponding notions from Attribute Grammars),(2) computing these attributes via parameterized SQL queries over multiple data sources, and (3) incorporating XML keys and inclusion constraints. The novelty of AIG consists in semantic attributes and their dependency relations for controlling context-dependent, DTD-directed construction of XML documents, as well as for checking XML constraints in parallel with document-generation. We also present cost-based optimization techniques for efficiently evaluating AIGs, including algorithms for merging queries and\u00a0\u2026", "num_citations": "74\n", "authors": ["1892"]}
{"title": "Stability theory, permutations of indiscernibles, and embedded finite models\n", "abstract": " We show that the expressive power of first-order logic over finite models embedded in a model  is determined by stability-theoretic properties of . In particular, we show that if  is stable, then every class of finite structures that can be defined by embedding the structures in , can be defined in pure first-order logic. We also show that if  does not have the independence property, then any class of finite structures that can be defined by embedding the structures in , can be defined in first-order logic over a dense linear order. This extends known results on the definability of classes of finite structures and ordered finite structures in the setting of embedded finite models. These results depend on several results in infinite model theory. Let  be a set of indiscernibles in a model  and suppose  is elementarily equivalent to  where  is -saturated. If  is stable and  is saturated, then every permutation of  extends to an automorphism of  and the theory of \u00a0\u2026", "num_citations": "63\n", "authors": ["1892"]}
{"title": "Challenges in searching online communities\n", "abstract": " An ever-growing number of users participate in online communities such as Flickr, del. icio. us, and YouTube, making friends and sharing content. Users come to these sites to find out about general trends\u2013the most popular tags, or the most recently tagged item\u2013as well as for more specific information, such as the recent posts of one of their friends. While these activities correspond to different user needs, they all can be seen as the filtering of resources in communities by various search criteria. We provide a survey of these search tasks and discuss the challenges in their efficient and effective evaluation. 1", "num_citations": "62\n", "authors": ["1892"]}
{"title": "Definable relations and first-order query languages over strings\n", "abstract": " We study analogs of classical relational calculus in the context of strings. We start by studying string logics. Taking a classical model-theoretic approach, we fix a set of string operations and look at the resulting collection of definable relations. These form an algebra---a class of n-ary relations for every n, closed under projection and Boolean operations. We show that by choosing the string vocabulary carefully, we get string logics that have desirable properties: computable evaluation and normal forms. We identify five distinct models and study the differences in their model-theory and complexity of evaluation. We identify a subset of these models that have additional attractive properties, such as finite VC dimension and quantifier elimination.Once you have a logic, the addition of free predicate symbols gives you a string query language. The resulting languages have attractive closure properties from a database point\u00a0\u2026", "num_citations": "58\n", "authors": ["1892"]}
{"title": "Safe constraint queries\n", "abstract": " We extend some of the classical characterization theorems of relational database theory---particularly those related to query safety---to the context where database elements come with fixed interpreted structure and where formulae over elements of that structure can be used in queries. We show that the addition of common interpreted functions, such as real addition and multiplication, to the relational calculus preserves important characterization theorems of the relational calculus and also preserves certain combinatorial properties of queries. Our main result of the first kind is that there is a syntactic characterization of the collection of safe queries over the relational calculus supplemented by a wide class of interpreted functions---a class that includes addition, multiplication, and exponentiation---and that this characterization gives us an interpreted analog of the concept of range-restricted query from the\u00a0\u2026", "num_citations": "57\n", "authors": ["1892"]}
{"title": "Regular tree languages definable in FO\n", "abstract": " We consider regular languages of ranked labeled trees. We give an algebraic characterization of the regular languages over such trees that are definable in first-order logic in the language of labeled graphs. These languages are the analog on ranked trees of the \u201clocally threshold testable\u201d languages on strings. We show that this characterization yields a decision procedure for determining whether a regular collection of trees is first-order definable: the procedure is polynomial time in the minimal automaton presenting the regular language.", "num_citations": "51\n", "authors": ["1892"]}
{"title": "Rewriting guarded negation queries\n", "abstract": " The Guarded Negation Fragment (GNFO) is a fragment of first-order logic that contains all unions of conjunctive queries, a restricted form of negation that suffices for expressing some common uses of negation in SQL queries, and a large class of integrity constraints. At the same time, as was recently shown, the syntax of GNFO is restrictive enough so that static analysis problems such as query containment are still decidable. This suggests that, in spite of its expressive power, GNFO queries are amenable to novel optimizations. In this paper we provide further evidence for this, establishing that GNFO queries have distinctive features with respect to rewriting. Our results include effective preservation theorems for GNFO, Craig Interpolation and Beth Definability results, and the ability to express the certain answers of queries with respect to GNFO constraints within very restricted logics.", "num_citations": "50\n", "authors": ["1892"]}
{"title": "On the structure of queries in constraint query languages\n", "abstract": " We study the structure of first-order and second-order queries over constraint databases. Constraint databases are formally modeled as finite relational structures embedded in some fixed infinite structure. We concentrate on problems of elimination of constraints, reducing quantification range to the active domain of the database and obtaining new complexity bounds. We show that for a large class of signatures, including real arithmetic constraints, unbounded quantification can be eliminated. That is, one can transform a sentence containing unrestricted quantification over the infinite universe to get an equivalent sentence in which quantifiers range over the finite relational structure. We use this result to get a new complexity upper bound on the evaluation of real arithmetic constraints. We also expand upon techniques for getting upper bounds on the expressiveness of constraint query languages, and apply it to a\u00a0\u2026", "num_citations": "47\n", "authors": ["1892"]}
{"title": "Verifiable properties of database transactions\n", "abstract": " It is often necessary to ensure that database transactions preserve integrity constraints that specify valid database states. While it is possible to monitor for violations of constraints at run-time, rolling back transactions when violations are detected, it is preferable to verify correctness statically,beforetransactions are executed. This can be accomplished if we can verify transaction safety with respect to a set of constraints by means of calculatingweakest preconditions. We study properties of weakest preconditions for a number of transaction and specification languages. We show that some simple transactions do not admit weakest preconditions over first-order logic and some of its extensions such as first-order logic with counting and monadic\u03a311. We also show that the class of transactions that admit weakest preconditions over first-order logic cannot be captured by any transaction language. We consider a strong local\u00a0\u2026", "num_citations": "45\n", "authors": ["1892"]}
{"title": "Querying with access patterns and integrity constraints\n", "abstract": " Traditional query processing involves a search for plans formed by applying algebraic operators on top of primitives representing access to relations in the input query. But many querying scenarios involve two interacting issues that complicate the search. On the one hand, the search space may be limited by access restrictions associated with the interfaces to datasources, which require certain parameters to be given as inputs. On the other hand, the search space may be extended through the presence of integrity constraints that relate sources to each other, allowing for plans that do not match the structure of the user query. In this paper we present the first optimization approach that attacks both these difficulties within a single framework, presenting a system in which classical cost-based join optimization is extended to support both access-restrictions and constraints. Instead of iteratively exploring subqueries of\u00a0\u2026", "num_citations": "43\n", "authors": ["1892"]}
{"title": "Relational queries over interpreted structures\n", "abstract": " We rework parts of the classical relational theory when the underlying domain is a structure with some interpreted operations that can be used in queries. We identify parts of the classical theory that go through 'as before' when interpreted structure is present, parts that go through only for classes of nicely behaved structures, and parts that only arise in the interpreted case. The first category include a number of results on language equivalence and expressive power characterizations for the active-domain semantics for a variety of logics. Under this semantics, quantifiers range over elements of a relational database. The main kind of results we prove here are generic collapse results: for generic queries, adding operations beyond order, does not give us extra   power.  The second category includes results on the natural semantics, under which quantifiers range over the entire interpreted structure. We prove, for a\u00a0\u2026", "num_citations": "43\n", "authors": ["1892"]}
{"title": "Languages for relational databases over interpreted structures\n", "abstract": " We rework parts of the classical relational theory when the underlying domain is a structure with some interpreted operations that can be used in queries. We identify parts of the classical theory that go through \u2018as before\u2019when interpreted structure is present, parts that go through only for classes of nicely-behaved structures, and parts that only arise in the interpreted case. The first category includes a number of results on equivalence of query languages, as well as expressive power characterizations for the active-domain semantics for a variety of logics. The second category includes most of our results on the natural semantics, including results on cases where the natural semantics collapses to the active semantics. While these collapse results have been proved by nonconstructive means for first-order logic in previous work, we here give a set of algorithms for eliminating unbounded quantifications in favor of\u00a0\u2026", "num_citations": "39\n", "authors": ["1892"]}
{"title": "Automata vs. logics on data words\n", "abstract": " The relationship between automata and logics has been investigated since the 1960s. In particular, it was shown how to determine, given an automaton, whether or not it is definable in first-order logic with label tests and the order relation, and for first-order logic with the successor relation. In recent years, there has been much interest in languages over an infinite alphabet. Kaminski and Francez introduced a class of automata called finite memory automata (FMA), that represent a natural analog of finite state machines. A FMA can use, in addition to its control state, a (bounded) number of registers to store and compare values from the input word. The class of data languages recognized by FMA is incomparable with the class of data languages defined by firstorder formulas with the order relation and an additional binary relation for data equality.               We first compare the expressive power of several\u00a0\u2026", "num_citations": "38\n", "authors": ["1892"]}
{"title": "Regular tree languages definable in FO and in FOmod\n", "abstract": " We consider regular languages of labeled trees. We give an effective characterization of the regular languages over such trees that are definable in first-order logic in the language of labeled graphs. These languages are the analog on trees of the \u201clocally threshold testable\u201d languages on strings. We show that this characterization yields a decision procedure for determining whether a regular tree language is first-order definable: The procedure is polynomial time in the minimal automaton presenting the regular language. We also provide an algorithm for deciding whether a regular language is definable in first-order logic supplemented with modular quantifiers.", "num_citations": "38\n", "authors": ["1892"]}
{"title": "Towards a characterization of order-invariant queries over tame graphs\n", "abstract": " This work deals with the expressive power of logics on finite graphs with access to an additional \u201carbitrary\u201d linear order. The queries that can be expressed this way are the order-invariant queries for the logic. For the standard logics used in computer science, such as first-order logic, it is known that access to an arbitrary linear order increases the expressiveness of the logic. However, when we look at the separating examples, we find that they have satisfying models whose Gaifman Graph is complex \u2013 unbounded in valence and in treewidth. We thus explore the expressiveness of order-invariant queries over well-behaved graphs. We prove that first-order order-invariant queries over strings and trees have no additional expressiveness over first-order logic in the original signature. We also prove new upper bounds on order-invariant queries over bounded treewidth and bounded valence graphs. Our results make\u00a0\u2026", "num_citations": "37\n", "authors": ["1892"]}
{"title": "SPARQLByE: Querying RDF data by example\n", "abstract": " Semantic Web technologies such as RDF and its query language, SPARQL, offer the possibility of opening up the use of public datasets to a great variety of ordinary users. But a key obstacle to the use of open data is the unfamiliarity of users with the structure of data or with SPARQL. To deal with these issues, we introduce a system for querying RDF data by example. At its core is a technique for reverse-engineering SPARQL queries by example. We demonstrate how reverse engineering along with other techniques, such as query relaxation, enables our system, SPARQLByE, to guide users who are unfamiliar with both the dataset and with SPARQL to the desired query and result set.", "num_citations": "36\n", "authors": ["1892"]}
{"title": "Generating plans from proofs: the interpolation-based approach to query reformulation\n", "abstract": " Query reformulation refers to a process of translating a source query\u2014a request for information in some high-level logic-based language\u2014into a target plan that abides by certain interface restrictions. Many practical problems in data management can be seen as instances of the reformulation problem. For example, the problem of translating an SQL query written over a set of base tables into another query written over a set of views; the problem of implementing a query via translating to a program calling a set of database APIs; the problem of implementing a query using a collection of  web services.   In this book we approach query reformulation in a very general setting that encompasses all the problems above, by relating it to a line of research within mathematical logic. For many decades logicians have looked at the problem of converting  \"implicit definitions\" into \"explicit definitions,\" using an approach known as\u00a0\u2026", "num_citations": "36\n", "authors": ["1892"]}
{"title": "Monadic datalog containment\n", "abstract": " We reconsider the problem of containment of monadic datalog (MDL) queries in unions of conjunctive queries (UCQs). Prior work has dealt with special cases, but has left the precise complexity characterization open. We begin by establishing a 2EXPTIME lower bound on the MDL/UCQ containment problem, resolving an open problem from the early 90\u2019s. We then present a general approach for getting tighter bounds on the complexity, based on analysis of the number of mappings of queries into tree-like instances. We use the machinery to present an important case of the MDL/UCQ containment problem that is in co-NEXPTIME, and a case that is in EXPTIME. We then show that the technique can be used to get a new tight upper bound for containment of tree automata in UCQs. We show that the new MDL/UCQ upper bounds are tight.", "num_citations": "36\n", "authors": ["1892"]}
{"title": "What you must remember when processing data words\n", "abstract": " We provide a Myhill-Nerode-like theorem that characterizes the class of data languages recognized by deterministic nite-memory automata (DMA). As a byproduct of this characterization result, we obtain a canonical representation for any DMA-recognizable language. We then show that this canonical automaton is minimal in a strong sense: it has the minimal number of control states and also the minimal amount of internal storage.", "num_citations": "36\n", "authors": ["1892"]}
{"title": "Probabilistic XML via Markov chains\n", "abstract": " We show how Recursive Markov Chains (RMCs) and their restrictions can define probabilistic distributions over XML documents, and study tractability of querying over such models. We show that RMCs subsume several existing probabilistic XML models. In contrast to the latter, RMC models (i) capture probabilistic versions of XML schema languages such as DTDs, (ii) can be exponentially more succinct, and (iii) do not restrict the domain of probability distributions to be finite. We investigate RMC models for which tractability can be achieved, and identify several tractable fragments that subsume known tractable probabilistic XML models. We then look at the space of models between existing probabilistic XML formalisms and RMCs, giving results on the expressiveness and succinctness of RMC subclasses, both with each other and with prior formalisms.", "num_citations": "35\n", "authors": ["1892"]}
{"title": "From XQuery to relational logics\n", "abstract": " Predicate logic has long been seen as a good foundation for querying relational data. This is embodied in the correspondence between relational calculus and first-order logic, and can also be seen in mappings from fragments of the standard relational query language SQL to extensions of first-order logic (e.g. with counting). A key question is what is the analog to this correspondence for querying tree-structured data, as seen, for example, in XML documents. We formalize this as the question of the appropriate logical query language for defining transformations on tree-structured data. The predominant practitioner paradigm for defining such transformations is top-down tree building. This is embodied by the XQuery query language, which builds the output tree in parallel starting at the root, based on variable bindings and nodeset queries in the XPath language. The goal of this article is to compare the\u00a0\u2026", "num_citations": "33\n", "authors": ["1892"]}
{"title": "Reachability and connectivity queries in constraint databases\n", "abstract": " It is known that standard query languages for constraint databases lack the power to express connectivity properties. Such properties are important in the context of geographical databases, where one naturally wishes to ask queries about connectivity (What are the connected components of a given set?) or reachability (Is there a path from A to B that lies entirely in a given region?). No existing constraint query languages that allow closed-form evaluation can express these properties. In the first part of the paper, we show that, in principle, there is no obstacle to getting closed languages that can express connectivity and reachability queries. In fact, we show that adding any topological property to standard languages like FO+Lin and FO+Poly results in a closed language. In the second part of the paper, we look for tractable closed languages for expressing reachability and connectivity queries. We introduce path logic\u00a0\u2026", "num_citations": "33\n", "authors": ["1892"]}
{"title": "Verification of tree updates for optimization\n", "abstract": " With the rise of XML as a standard format for representing tree-shaped data, new programming tools have emerged for specifying transformations to tree-like structures. A recent example along this line are the update languages of [16,15,8] which add tree update primitives on top of the declarative query languages XPath and XQuery. These tree update languages use a \u201csnapshot semantics\u201d, in which all querying is performed first, after which a generated sequence of concrete updates is performed in a fixed order determined by query evaluation. In order to gain efficiency, one would prefer to perform updates as soon as they are generated, before further querying. This motivates a specific verification problem: given a tree update program, determine whether generated updates can be performed before all querying is completed. We formalize this notion, which we call \u201cBinding Independence\u201d. We give an\u00a0\u2026", "num_citations": "32\n", "authors": ["1892"]}
{"title": "Complexity of two-variable logic on finite trees\n", "abstract": " Verification of properties expressed in the two-variable fragment of first-order logic FO2 has been investigated in a number of contexts. The satisfiability problem for FO2 over arbitrary structures is known to be NEXPTIME-complete, with satisfiable formulas having exponential-sized models. Over words, where FO2 is known to have the same expressiveness as unary temporal logic, satisfiability is again NEXPTIME-complete. Over finite labelled ordered trees, FO2 has the same expressiveness as navigational XPath, a popular query language for XML documents. Prior work on XPath and FO2 gives a 2EXPTIME bound for satisfiability of FO2 over trees. This work contains a comprehensive analysis of the complexity of FO2 on trees, and on the size and depth of models. We show that different techniques are required depending on the vocabulary used, whether the trees are ranked or unranked, and the encoding of\u00a0\u2026", "num_citations": "31\n", "authors": ["1892"]}
{"title": "Adding Updates to XQuery: Semantics, Optimization, and Static Analysis.\n", "abstract": " The need to extend XQuery to support updates has been recognized both in the research and the standards community. Several language proposals and prototype implementations have been put forward, and update language requirements are being defined within the W3C. Most proposals center around the use of update primitives applied to XQuery expressions, along with a variant of the FLWR loop construct binding variables within a block of basic update statements. In defining a precise semantics for such statements a number of issues arise: one must decide how conflicts among updates are to be resolved, and how query evaluation interacts with update application. In this work we provide a framework for defining alternative semantics for updates, and identify within this space what is (thus far) the consensus choice: that semantics involves a twostage execution process, in which query evaluation is performed first, after which a generated sequence of concrete updates is applied in a fixed order determined by query output. This results in a clean deterministic semantics which facilitates analysis. A drawback is that the evaluation of the language can be inefficient. One would prefer to perform updates eagerly before further evaluation, or to re-order the update operations. We focus on an optimization of the \u201cstandard semantics\u201d, in which updates are performed as soon as they are generated. We present a static analysis for determining when this optimization can be exploited. Experiments on the implementation of this analysis, implemented on top of Galax, show that the overhead is minimal.", "num_citations": "31\n", "authors": ["1892"]}
{"title": "Methods and apparatus for generating and using safe constraint queries\n", "abstract": " Methods and apparatus are provided for ensuring that queries presented to a database are safe thus providing solutions to both undecidability and lack of effective syntax issues. In a one aspect of the invention, a method for use in a database system includes obtaining an original query entered by a user. The invention then provides for pre-processing the query before submittal to a database engine associated with the database system wherein a result of the pre-processing operation is to ensure that a query provided to the engine is safe. Safety has a different meaning depending on the application. For example, safety may include ensuring that a query will return an output with finite results or it may include ensuring that certain geometric properties in the query are preserved in the output.", "num_citations": "31\n", "authors": ["1892"]}
{"title": "Efficient and expressive tree filters\n", "abstract": " We investigate streaming evaluation of filters on XML documents, evaluated both at the root node and at an arbitrary node. Motivated by applications in protocol processing, we are interested in algorithms that make one pass over the input, using space that is independent of the data and polynomial in the filter. We deal with a logic equivalent to the XPath language, and also an extension with an Until operator. We introduce restricted sublanguages based on looking only at \u201creversed\u201d axes, and show that these allow polynomial space streaming implementations. We further show that these fragments are expressively complete. Our results make use of techniques developed for the study of Linear Temporal Logic, applied to XML filtering.", "num_citations": "30\n", "authors": ["1892"]}
{"title": "System and method for XML data integration\n", "abstract": " A framework is provided for integrating data from multiple relational sources into an XML document that both conforms to a given DTD and satisfies predefined XML constraints. The framework is based on a specification language, designated Attribute Integration Grammar (AIG), that extends a DTD by (1) associating element types with semantic attributes,(2) computing these attributes via parameterized SQL queries over multiple data sources, and (3) incorporating XML keys and inclusion constraints. The AIG uniquely operates on semantic attributes and their dependency relations for controlling context-dependent, DTD-directed construction of XML documents, and, as well as checks XML constraints in parallel with document-generation.", "num_citations": "28\n", "authors": ["1892"]}
{"title": "A model-theoretic approach to regular string relations\n", "abstract": " We study algebras of definable string relations, classes of regular n-ary relations that arise as the definable sets within a model whose carrier is the set of all strings. We show that the largest such algebra-the collection of regular relations-has some quite undesirable computational and model-theoretic properties. In contrast, we exhibit several definable relation algebras that have much tamer behavior: for example, they admit quantifier elimination, and have finite VC dimension. We show that the properties of a definable relation algebra are not at all determined by the one-dimensional definable sets. We give models whose definable sets are all star-free, but whose binary relations are quite complex, as well as models whose definable sets include all regular sets, but which are much more restricted and tractable than the full algebra of regular relations.", "num_citations": "28\n", "authors": ["1892"]}
{"title": "Method for performing information-preserving DTD schema embeddings\n", "abstract": " Method for performing information-preserving DTD schema embeddings between a source schema when matching a source schema and a target schema. The preservation is realized by a matching process between the two schemas that finds a first string marking of the target schema, evaluates a legality of the first string marking, determines an estimated minimal cost of the first string marking and subsequently adjusts the estimated minimal cost based upon one to one mapping of source schema and target schema subcomponents.", "num_citations": "27\n", "authors": ["1892"]}
{"title": "Stream firewalling of XML constraints\n", "abstract": " As XML-based messages have become common in many client-server protocols, there is a need to protect application servers from invalid or dangerous messages. This leads to the XML stream firewalling problem; that of applying integrity constraints against a large number of simultaneous streams. We conduct the first investigation of a constraint engine optimized for the generation of XML stream firewalls. We isolate a class of DTDs and XPath constraints which support the generation of low-space filters, and provide algorithms for generating firewalls with low per-input-character time and per-stream space. We give experimental results which show that we have achieved these goals in practice.", "num_citations": "27\n", "authors": ["1892"]}
{"title": "Expressive power of unary counters\n", "abstract": " We compare the expressive power on finite models of two extensions of first order logic L with equality. L(Ct) is formed by adding an operator count x\u2236\u03d5, which builds a term of sort N that counts the number of elements of the finite model satisfying a formula \u03d5. Our main result shows that the stronger operator count t(x)\u2236\u03d5, where t(x) is a term of sort N, cannot be expressed in L(Ct). That is, being able to count elements does not allow one to count terms.             This paper also continues our interest in new proof techniques in database theory. The proof of the unary counter combines a number of model-theoretic techniques that give powerful tools for expressivity bounds: in particular, we discuss here the use of indiscernibles, the Paris-Harrington form of Ramsey's theorem, and nonstandard models of arithmetic.", "num_citations": "27\n", "authors": ["1892"]}
{"title": "Logical foundations of information disclosure in ontology-based data integration\n", "abstract": " Ontology-based data integration systems allow users to effectively access data sitting in multiple sources by means of queries over a global schema described by an ontology. In practice, data sources often contain sensitive information that the data owners want to keep inaccessible to users. Our aim in this paper is to lay the logical foundations of information disclosure in ontology-based data integration. Our focus is on the semantic requirements that a data integration system should satisfy before it is made available to users for querying, as well as on the computational complexity of checking whether such requirements are fulfilled. In particular, we formalise and study the problem of determining whether a given data integration system discloses a source query to an attacker. We consider disclosure on a particular dataset, and also whether a schema admits a dataset on which disclosure occurs. We provide\u00a0\u2026", "num_citations": "26\n", "authors": ["1892"]}
{"title": "Polynomial automata: Zeroness and applications\n", "abstract": " We introduce a generalisation of weighted automata over a field, called polynomial automata, and we analyse the complexity of the Zeroness Problem in this model, that is, whether a given automaton outputs zero on all words. While this problem is non-primitive recursive in general, we highlight a subclass of polynomial automata for which the Zeroness Problem is primitive recursive. Refining further, we identify a subclass of affine VAS for which coverability is in 2EXPSPACE. We also use polynomial automata to obtain new proofs that equivalence of streaming string transducers is decidable, and that equivalence of copyless streaming string transducers is in PSPACE.", "num_citations": "26\n", "authors": ["1892"]}
{"title": "The complexity of boundedness for guarded logics\n", "abstract": " Given a formula phi(x, X) positive in X, the bounded ness problem asks whether the fix point induced by phi is reached within some uniform bound independent of the structure (i.e. Whether the fix point is spurious, and can in fact be captured by a finite unfolding of the formula). In this paper, we study the bounded ness problem when phi is in the guarded fragment or guarded negation fragment of first-order logic, or the fix point extensions of these logics. It is known that guarded logics have many desirable computational and model theoretic properties, including in some cases decidable bounded ness. We prove that bounded ness for the guarded negation fragment is decidable in elementary time, and, making use of an unpublished result of Colcombet, even 2EXPTIME-complete. Our proof extends the connection between guarded logics and automata, reducing bounded ness for guarded logics to a question about\u00a0\u2026", "num_citations": "26\n", "authors": ["1892"]}
{"title": "PDQ: Proof-driven query answering over web-based data\n", "abstract": " The data needed to answer queries is often available through Web-based APIs. Indeed, for a given query there may be many Web-based sources which can be used to answer it, with the sources overlapping in their vocabularies, and differing in their access restrictions (required arguments) and cost. We introduce PDQ (Proof-Driven Query Answering), a system for determining a query plan in the presence of web-based sources. It is: (i) constraint-aware -- exploiting relationships between sources to rewrite an expensive query into a cheaper one, (ii) access-aware -- abiding by any access restrictions known in the sources, and (iii) cost-aware -- making use of any cost information that is available about services. PDQ takes the novel approach of generating query plans from proofs that a query is answerable. We demonstrate the use of PDQ and its effectiveness in generating low-cost plans.", "num_citations": "26\n", "authors": ["1892"]}
{"title": "Determining relevance of accesses at runtime\n", "abstract": " Consider the situation where a query is to be answered using Web sources that restrict the accesses that can be made on backend relational data by requiring some attributes to be given as input of the service. The accesses provide lookups on the collection of attributes values that match the binding. They can differ in whether or not they require arguments to be generated from prior accesses. Prior work has focused on the question of whether a query can be answered using a set of data sources, and in developing static access plans (eg, Datalog programs) that implement query answering. We are interested in dynamic aspects of the query answering problem: given partial information about the data, which accesses could provide relevant data for answering a given query? We consider immediate and long-term notions of\" relevant accesses\", and ascertain the complexity of query relevance, for both conjunctive\u00a0\u2026", "num_citations": "26\n", "authors": ["1892"]}
{"title": "Generating low-cost plans from proofs\n", "abstract": " We look at generating plans that answer queries over restricted interfaces, making use of information about source integrity constraints, access restrictions, and access costs. Our method can exploit the integrity constraints to find low-cost access plans even when there is no direct access to relations appearing in the query. The key idea of our method is to move from a search for a plan to a search for a proof that a query is answerable, and then\\emph {generate a plan from a proof}. Discovery of one proof allows us to find a single plan that answers the query; exploration of several alternative proofs allows us to find low-cost plans. We start by overviewing a correspondence between proofs and restricted-interface plans in the context of arbitrary first-order constraints, based on interpolation. The correspondence clarifies the connection between preservation and interpolation theorems and reformulation problems, while\u00a0\u2026", "num_citations": "25\n", "authors": ["1892"]}
{"title": "Bisimilarity of pushdown automata is nonelementary\n", "abstract": " Given two pushdown automata, the bisimilarity problem asks whether the infinite transition systems they induce are bisimilar. While this problem is known to be decidable our main result states that it is nonelementary, improving EXPTIME-hardness, which was the best previously known lower bound for this problem. Our lower bound result holds for normed pushdown automata as well.", "num_citations": "25\n", "authors": ["1892"]}
{"title": "Exact and approximate aggregation in constraint query languages\n", "abstract": " Michael Benedikt Leonid Libkin Bell Laboratories Bell Laboratories 1000 E Warrenville Rd 600 Mountain Avenue Naperville, IL 60566 Murray Hill, NJ 07974 E-mail: benediktObell-labs. com Email: libkinQbell-labs. comWe investigate the problem of how to extend constraint query languages with aggregate operators. We deal with standard relational aggregation, and also with aggregates specific to spatial, data, such as volume. We study several approaches, including the addition of a new class of approximate aggregate operators which allow an error tolerance in the computation. We show how techniques based on VC-dimension can be used to give languages with approximation operators, but also show that these languages have a number of shortcomings. We then give a set of results showing that it is impossible to get constraint-based languages that admit definable aggregation operators, both for exact\u00a0\u2026", "num_citations": "24\n", "authors": ["1892"]}
{"title": "Access patterns and integrity constraints revisited\n", "abstract": " We consider which queries are answerable in the presence of access restrictions and integrity constraints, and which portions of the schema are accessible in the presence of access restrictions and constraints. Unlike prior work, we focus on integrity constraint languages that subsume inclusion dependencies. We also use a semantic definition of answerability: a query is answerable if the accessible information is sufficient to determine its truth value. We show that answerability is decidable for the class of guarded dependencies, which includes all inclusion dependencies, and also for constraints given in the guarded fragment of first-order logic. We also show that answerable queries have\" query plans\" in a restricted language. We give corresponding results for extractability of portions of the schema. Our results relate querying with limited access patterns, determinacy-vs-rewriting, and analysis of guarded constraints.", "num_citations": "23\n", "authors": ["1892"]}
{"title": "Managing XML data: An abridged overview\n", "abstract": " XML's flexibility makes it a natural format for both exchanging and integrating data from diverse data sources. In this survey, the authors give an overview of issues in managing XML data, discuss existing solutions, and outline the current technology's open problems and limitations.", "num_citations": "23\n", "authors": ["1892"]}
{"title": "Querying visible and invisible information\n", "abstract": " We provide a wide-ranging study of the scenario where a subset of the relations in the schema are visible---that is, their complete contents are known---while the remaining relations are invisible. We also have integrity constraints (invariants given by logical sentences) which may relate the visible relations to the invisible ones. We want to determine which information about a query (a positive existential sentence) can be inferred from the visible instance and the constraints. We consider both positive and negative query information, that is, whether the query or its negation holds. We consider the instance-level version of the problem, where both the query and the visible instance are given, as well as the schema-level version, where we want to know whether truth or falsity of the query can be inferred in some instance of the schema.", "num_citations": "22\n", "authors": ["1892"]}
{"title": "Effective interpolation and preservation in guarded logics\n", "abstract": " Desirable properties of a logic include decidability, and a model theory that inherits properties of first-order logic, such as interpolation and preservation theorems. It is known that the Guarded Fragment (GF) of first-order logic is decidable and satisfies some preservation properties from first-order model theory; however, it fails to have Craig interpolation. The Guarded Negation Fragment (GNF), a recently defined extension, is known to be decidable and to have Craig interpolation. Here we give the first results on effective interpolation for extensions of GF. We provide an interpolation procedure for GNF whose complexity matches the doubly exponential upper bound for satisfiability of GNF. We show that the same construction gives not only Craig interpolation, but Lyndon interpolation and relativized interpolation, which can be used to provide effective proofs of some preservation theorems. We provide upper bounds\u00a0\u2026", "num_citations": "22\n", "authors": ["1892"]}
{"title": "Regular repair of specifications\n", "abstract": " What do you do if a computational object (e.g. program trace) fails a specification? An obvious approach is to perform repair: modify the object minimally to get something that satisfies the constraints. In this paper we study repair of temporal constraints, given as automata or temporal logic formulas. We focus on determining the number of repairs that must be applied to a word satisfying a given input constraint in order to ensure that it satisfies a given target constraint. This number may well be unbounded; one of our main contributions is to isolate the complexity of the \"bounded repair problem\", based on a characterization of the pairs of regular languages that admit such a repair. We consider this in the setting where the repair strategy is unconstrained and also when the strategy is restricted to use finite memory. Although the streaming setting is quite different from the general setting, we find that there are surprising\u00a0\u2026", "num_citations": "21\n", "authors": ["1892"]}
{"title": "Logical definability and query languages over ranked and unranked trees\n", "abstract": " We study relations on trees defined by first-order constraints over a vocabulary that includes the tree extension relation T \u227a T\u2032 (holding if and only if every branch of T extends to a branch of T\u2032), unary node-tests, and a binary relation checking whether the domains of two trees are equal. We consider both ranked and unranked trees. These are trees with and without a restriction on the number of children of nodes. We adopt the model-theoretic approach to tree relations and study relations definable over the structure consisting of the set of all trees and the aforementioned predicates. We relate definability of sets and relations of trees to computability by tree automata. We show that some natural restrictions correspond to familiar logics in the more classical setting where every tree is a structure over a fixed vocabulary, and to logics studied in the context of XML pattern languages. We then look at relational calculi\u00a0\u2026", "num_citations": "21\n", "authors": ["1892"]}
{"title": "Query answering with transitive and linear-ordered data\n", "abstract": " We consider entailment problems involving powerful constraint languages such as frontier-guarded existential rules in which we impose additional semantic restrictions on a set of distinguished relations. We consider restricting a relation to be transitive, restricting a relation to be the transitive closure of another relation, and restricting a relation to be a linear order. We give some natural variants of guardedness that allow inference to be decidable in each case, and isolate the complexity of the corresponding decision problems. Finally we show that slight changes in these conditions lead to undecidability.", "num_citations": "20\n", "authors": ["1892"]}
{"title": "Aggregating semantic annotators\n", "abstract": " A growing number of resources are available for enriching documents with semantic annotations. While originally focused on a few standard classes of annotations, the ecosystem of annotators is now becoming increasingly diverse. Although annotators often have very different vocabularies, with both high-level and specialist concepts, they also have many semantic interconnections. We will show that both the overlap and the diversity in annotator vocabularies motivate the need for semantic annotation integration: middleware that produces a unified annotation on top of diverse semantic annotators. On the one hand, the diversity of vocabulary allows applications to benefit from the much richer vocabulary available in an integrated vocabulary. On the other hand, we present evidence that the most widely-used annotators on the web suffer from serious accuracy deficiencies: the overlap in vocabularies from individual\u00a0\u2026", "num_citations": "20\n", "authors": ["1892"]}
{"title": "The impact of virtual views on containment\n", "abstract": " Virtual views are a mechanism that facilitates re-use and makes queries easier to express. However the use of iterative view definitions makes very simple query evaluation and analysis problems more complex. In this paper we study classical containment and equivalence problems for queries built up through simple unions of conjunctive queries and view definitions. More precisely, we determine the complexity of containment and equivalence for non-recursive Datalog. We show that the problem is much harder than its classical counterpart -- complete for co-NEXPTIME. We then show that this remains true even with restrictions on the schema and queries in place. Finally, we isolate subcases that are more tractable, ranging from NP to PSPACE.", "num_citations": "19\n", "authors": ["1892"]}
{"title": "XML subtree queries: Specification and composition\n", "abstract": " A frequent task encountered in XML processing is to filter an input document to produce a subdocument; that is, a document whose root-to-leaf paths are root-to-leaf paths of the original document and which inherits the tree structure of the original document. These are what we mean by subtree queries, and while they are similar to XPath filters, they cannot be naturally specified either in XPath or in XQuery. Special-purpose subtree query languages provide a natural idiom for specifying this class of queries, but both composition and evaluation are problematic. In this paper we show that for natural fragments of XPath, the resulting subtree query languages are closed under composition. This closure property allows a sequence of subtree queries to be rewritten as a single subtree query, which can then be evaluated either by a subtree-query specific evaluator or via translation to XQuery. We provide a set of\u00a0\u2026", "num_citations": "19\n", "authors": ["1892"]}
{"title": "A step up in expressiveness of decidable fixpoint logics\n", "abstract": " Guardedness restrictions are one of the principal means to obtain decidable logics - operators such as negation are restricted so that the free variables are contained in an atom. While guardedness has been applied fruitfully in the setting of first-order logic, the ability to add fixpoints while retaining decidability has been very limited. Here we show that one of the main restrictions imposed in the past can be lifted, getting a richer decidable logic by allowing fixpoints in which the parameters of the fixpoint can be unguarded. Using automata, we show that the resulting logics have a decidable satisfiability problem, and provide a fine study of the complexity of satisfiability. We show that similar methods apply to decide questions concerning the elimination of fixpoints within formulas of the logic.", "num_citations": "18\n", "authors": ["1892"]}
{"title": "String operations in query languages\n", "abstract": " We study relational calculi with support for string operations. While SQL restricts the ability to mix string pattern-matching and relational operations, prior proposals for embedding SQL in a compositional calculus were based on adding the operation of concatenation to first-order logic. These latter proposals yield compositional query languages extending SQL, but are unfortunately computationally complete. The unbounded expressive power in turn implies strong limits on the ability to perform optimization and static analysis of properties such as query safety in these languages.", "num_citations": "17\n", "authors": ["1892"]}
{"title": "Expressive power: The finite case\n", "abstract": " As we have seen in the previous chapter, usual relational databases are just a special case of the constraint model; indeed, a tuple    can be represented as a constraint    in free variables x               1,..., x                                n               . A relation    is then represented by a formula    stating that the interpretation of a tuple (x               1 ,..., x               n) must be among the    Consequently, constraint query languages, over a structure   , can be considered as query languages over ordinary relational databases whose elements come from the set u. For example, FO + Lin and FO + Poly, the relational calculus with linear and polynomial constraints, can be considered as query languages over ordinary relational databases that store numbers.", "num_citations": "17\n", "authors": ["1892"]}
{"title": "Towards a characterization of order-invariant queries over tame structures\n", "abstract": " This work deals with the expressive power of logics on finite structures with access to an additional \u201carbitrary\u201d linear order. The queries that can be expressed this way are the order-invariant queries for the logic. For the standard logics used in computer science, such as first-order logic, it is known that access to an arbitrary linear order increases the expressiveness of the logic. However, when we look at the separating examples, we find that they have satisfying models whose Gaifman Graph is complex \u2013 unbounded in valence and in treewidth. We thus explore the expressiveness of order-invariant queries over graph-theoretically well-behaved structures. We prove that first-order order-invariant queries over strings and trees have no additional expressiveness over first-order logic in the original signature. We also prove new upper bounds on order-invariant queries over bounded treewidth and bounded\u00a0\u2026", "num_citations": "15\n", "authors": ["1892"]}
{"title": "Tree extension algebras: logics, automata, and query languages\n", "abstract": " We study relations on trees defined by first-order constraints over a vocabulary that includes the tree extension relation \u00cc \u00cc\u00bc, holding if and only if every branch of \u00cc extends to a branch of \u00cc\u00bc, unary node-tests, and a binary relation checking if the domains of two trees are equal. We show that from such a formula one can generate a tree automaton that accepts the set of tuples of trees defined by the formula, and conversely that every automaton over tree-tuples is captured by such a formula. We look at the fragment with only extension inequalities and leaf tests, and show that it corresponds to a new class of automata on tree tuples, which is strictly weaker then general tree-tuple automata. We use the automata representations to show separation and expressibility results for formulae in the logic. We then turn to relational calculi over the logic defined here: that is, from constraints we extend to queries that have second-order parameters for a finite set of tree tuples. We give normal forms for queries, and use these to get bounds on the data complexity of query evaluation, showing that while general query evaluation is unbounded within the polynomial hierarchy, generic query evaluation has very low complexity, giving strong bounds on the expressive power of relational calculi with tree extension constraints. We also give normal forms for safe queries in the calculus.", "num_citations": "14\n", "authors": ["1892"]}
{"title": "DTD-directed publishing with attribute translation grammars\n", "abstract": " Publisher SummaryThis chapter presents formalism and ATGs, for publishing relational data in XML with respect to a predefined DTD, and gives efficient algorithms for evaluating ATGs. There are key differences between ATGs and traditional attribute grammars. A traditional AG is defined with a context free grammar and more complicated attributes (synthesized and inherited). It takes a string as an input, parses the string with the grammar, and computes attributes. In contrast, it is not possible to \u201cparse\u201d a relational database with a DTD; thus, an ATG extracts relevant data from the database via queries, and then constructs a parse tree of the DTD using the data. There have also been applications of AGs to databases, for example, for constructing query automata and for querying text files. These are mild variations of traditional AGs and are quite different from ATGs.", "num_citations": "14\n", "authors": ["1892"]}
{"title": "Ultrafilters which extend measures\n", "abstract": " We study classes of ultrafilters on \u03c9 defined by a natural property of the Loeb measure in the Nonstandard Universe corresponding to the ultrafilter. This class, the Property M ultrafilters, is shown to contain all ultrafilters built up by taking iterated products over collections of pairwise nonisomorphic selective ultrafilters. Results on Property M ultrafilters are applied to the construction of extensions of probability measures, and to the study of measurable reductions between ultrafilters.", "num_citations": "14\n", "authors": ["1892"]}
{"title": "Generating plans from proofs\n", "abstract": " We present algorithms for answering queries making use of information about source integrity constraints, access restrictions, and access costs. Our method can exploit the integrity constraints to find plans even when there is no direct access to relations appearing in the query. We look at different kinds of plans, depending on the kind of relational operators that are permitted within their commands. To each type of plan, we associate a semantic property that is necessary for having a plan of that type. The key idea of our method is to move from a search for a plan to a search for a proof of the corresponding semantic property, and then generate a plan from a proof. We provide algorithms for converting proofs to plans and show that they will find a plan of the desired type whenever such a plan exists. We show that while discovery of one proof allows us to find a single plan that answers the query, we can explore\u00a0\u2026", "num_citations": "13\n", "authors": ["1892"]}
{"title": "Querying schemas with access restrictions\n", "abstract": " We study verification of systems whose transitions consist of accesses to a Web-based data-source. An access is a lookup on a relation within a relational database, fixing values for a set of positions in the relation. For example, a transition can represent access to a Web form, where the user is restricted to filling in values for a particular set of fields. We look at verifying properties of a schema describing the possible accesses of such a system. We present a language where one can describe the properties of an access path, and also specify additional restrictions on accesses that are enforced by the schema. Our main property language, AccLTL, is based on a first-order extension of linear-time temporal logic, interpreting access paths as sequences of relational structures. We also present a lower-level automaton model, Aautomata, which AccLTL specifications can compile into. We show that AccLTL and A-automata can express static analysis problems related to \"querying with limited access patterns\" that have been studied in the database literature in the past, such as whether an access is relevant to answering a query, and whether two queries are equivalent in the accessible data they can return. We prove decidability and complexity results for several restrictions and variants of AccLTL, and explain which properties of paths can be expressed in each restriction.", "num_citations": "13\n", "authors": ["1892"]}
{"title": "Interpreting tree-to-tree queries\n", "abstract": " We establish correspondences between top-down tree building query languages and predicate logics. We consider the expressive power of the query language XQ, a clean core of the practitioner\u2019s language XQuery. We show that all queries in XQ with only atomic equality are equivalent to \u201cfirst-order interpretations\u201d, an analog to first-order logic (FO) in the setting of transformations of tree-structured data. When XQ is considered with deep equality, we find that queries can be translated into FO with counting (FO(Cnt)). We establish partial converses to this, characterizing the subset of the FO resp. FO(Cnt) interpretations that correspond to XQ. Finally, we study the expressive power of fragments of XQ and obtain partial characterizations in terms of existential FO and a fragment of FO that is two-variable if the tree node labeling alphabet is assumed fixed.", "num_citations": "13\n", "authors": ["1892"]}
{"title": "Aggregate operators in constraint query languages\n", "abstract": " We investigate the problem of how to extend constraint query languages with aggregate operators. We deal with standard relational aggregation, and also with aggregates specific to spatial data, such as volume. We study several approaches, including the addition of a new class of approximate aggregate operators which allow an error tolerance in the computation. We show how techniques of M. Karpinski and A. Macintyre (in \u201cStructures in Logic and Computer Science: A Selection of Essays in Honor of A. Ehrenfeucht,\u201d Springer Lecture Notes on Computer Science 1261, pp. 162\u2013173, Springer-Verlag, Berlin, 1997) and P. Koiran (in \u201cFOCS '95,\u201d pp. 134\u2013141) based on VC-dimension can be used to give languages with approximation operators, but also show that these languages have a number of shortcomings. We then give a set of results showing that it is impossible to get constraint-based languages that admit\u00a0\u2026", "num_citations": "13\n", "authors": ["1892"]}
{"title": "Embedded finite models, stability theory, and the impact of order\n", "abstract": " We extend bounds on the expressive power of first-order logic over finite structures and over ordered finite structures, by generalizing to the situation where the finite structures are embedded in an infinite structure M, where M satisfies some simple combinatorial properties studied in model-theoretic stability theory. We first consider first-order logic over finite structures embedded in a stable structure, and show that it has the same generic expressive power as first-order logic on unordered finite structures. It follows from this that having the additional structure of, for example, an abelian group or an equivalence relation, does not allow one to define any new generic queries. We also consider first-order logic over finite structures living within any model M that lacks the independence property and show that its expressive power is bounded by first-order logic over finite ordered structures. This latter result gives an\u00a0\u2026", "num_citations": "13\n", "authors": ["1892"]}
{"title": "Finite open-world query answering with number restrictions\n", "abstract": " Open-world query answering is the problem of deciding, given a set of facts, conjunction of constraints, and query, whether the facts and constraints imply the query. This amounts to reasoning over all instances that include the facts and satisfy the constraints. We study finite open-world query answering (FQA), which assumes that the underlying world is finite and thus only considers the finite completions of the instance. The major known decidable cases of FQA derive from the following: the guarded fragment of first-order logic, which can express referential constraints (data in one place points to data in another) but cannot express number restrictions such as functional dependencies, and the guarded fragment with number restrictions but on a signature of arity only two. In this paper, we give the first decidability results for FQA that combine both referential constraints and number restrictions for arbitrary signatures\u00a0\u2026", "num_citations": "12\n", "authors": ["1892"]}
{"title": "Bounded repairability of word languages\n", "abstract": " What do you do if a computational object (e.g. program trace) fails a specification? An obvious approach is to perform a repair: modify the object minimally to get something that satisfies the constraints. This approach has been investigated in the database community, for integrity constraints, and in the AI community for propositional logics. Here we study how difficult it is to repair a document in the form of a string. Specifically, we consider number of edits that must be applied to an input string in order to satisfy a given target language. This number may be unbounded; our main contribution is to isolate the complexity of the bounded repair problem based on a characterization of the regular languages that admit bounded repairr. We consider the settings where the repair strategy is unconstrained and when the editing must be produced in a streaming way, i.e. by a letter-to-letter transducer.", "num_citations": "12\n", "authors": ["1892"]}
{"title": "Determinacy and rewriting of top-down and MSO tree transformations\n", "abstract": " A query is determined by a view, if the result to the query can be reconstructed from the result of the view. We consider the problem of deciding for two given tree transformations, whether one is determined by the other. If the view transformation is induced by a tree transducer that may copy, then determinacy is undecidable, even for identity queries. For a large class of non-copying views, namely compositions of functional extended linear top-down tree transducers with regular look-ahead, we show that determinacy is decidable, where queries are given by deterministic top-down tree transducers with regular look-ahead or by MSO tree transducers. We also show that if a query is determined, then it can be rewritten into a query that works directly over the view and is in the same class as the given query. The proof relies on the decidability of equivalence for the two considered classes of queries, and on their\u00a0\u2026", "num_citations": "12\n", "authors": ["1892"]}
{"title": "Some model theory of guarded negation\n", "abstract": " The Guarded Negation Fragment (GNFO) is a fragment of first-order logic that contains all positive existential formulas, can express the first-order translations of basic modal logic and of many description logics, along with many sentences that arise in databases. It has been shown that the syntax of GNFO is restrictive enough so that computational problems such as validity and satisfiability are still decidable. This suggests that, in spite of its expressive power, GNFO formulas are amenable to novel optimizations. In this article we study the model theory of GNFO formulas. Our results include effective preservation theorems for GNFO, effective Craig Interpolation and Beth Definability results, and the ability to express the certain answers of queries with respect to a large class of GNFO sentences within very restricted logics.", "num_citations": "11\n", "authors": ["1892"]}
{"title": "When can we answer queries using result-bounded data interfaces?\n", "abstract": " We consider answering queries on data available through access methods, that provide lookup access to the tuples matching a given binding. Such interfaces are common on the Web; further, they often have bounds on how many results they can return, eg, because of pagination or rate limits. We thus study result-bounded methods, which may return only a limited number of tuples. We study how to decide if a query is answerable using result-bounded methods, ie, how to compute a plan that returns all answers to the query using the methods, assuming that the underlying data satisfies some integrity constraints. We first show how to reduce answerability to a query containment problem with constraints. Second, we show\" schema simplification''theorems describing when and how result bounded services can be used. Finally, we use these theorems to give decidability and complexity results about answerability for\u00a0\u2026", "num_citations": "11\n", "authors": ["1892"]}
{"title": "Data Visualization for Design Thinking: Applied Mapping\n", "abstract": " Data Visualization for Design Thinking helps you make better maps. Treating maps as applied research, you\u2019ll be able to understand how to map sites, places, ideas, and projects, revealing the complex relationships between what you represent, your thinking, the technology you use, the culture you belong to, and your aesthetic practices. More than 100 examples illustrated with over 200 color images show you how to visualize data through mapping. Includes five in-depth cases studies and numerous examples throughout.", "num_citations": "11\n", "authors": ["1892"]}
{"title": "The cost of traveling between languages\n", "abstract": " We show how to calculate the maximum number of edits per character needed to convert any string in one regular language to a string in another language. Our algorithm makes use of a local determinization procedure applicable to a subclass of distance automata. We then show how to calculate the same property when the editing needs to be done in streaming fashion, by a finite state transducer, using a reduction to mean-payoff games. We show that the optimal streaming editor can be produced in PTIME.", "num_citations": "11\n", "authors": ["1892"]}
{"title": "Positive higher-order queries\n", "abstract": " We investigate a higher-order query language that embeds operators of the positive relational algebra within the simply-typed \u03bb-calculus. Our language allows one to succinctly define ordinary positive relational algebra queries (conjunctive queries and unions of conjunctive queries) and, in addition, second-order query functionals, which allow the transformation of CQs and UCQs in a generic (ie, syntax-independent) way. We investigate the equivalence and containment problems for this calculus, which subsumes traditional CQ/UCQ containment. Query functionals are said to be equivalent if the output queries are equivalent, for each possible input query, and similarly for containment. These notions of containment and equivalence depend on the class of (ordinary relational algebra) queries considered. We show that containment and equivalence are decidable when query variables are restricted to positive\u00a0\u2026", "num_citations": "11\n", "authors": ["1892"]}
{"title": "A characterization of first-order topological properties of planar spatial data\n", "abstract": " Planar spatial datasets can be modeled by closed semi-algebraic sets in the plane. We establish a characterization of the topological properties of such datasets expressible in the relational calculus with real polynomial constraints. The characterization is in the form of a query language that can only point that can only talk about points in the set and the \u201ccones\u201d around these points.", "num_citations": "11\n", "authors": ["1892"]}
{"title": "Interpolation with decidable fixpoint logics\n", "abstract": " A logic satisfies Craig interpolation if whenever one formula \u03c6 1  in the logic entails another formula \u03c6 2  in the logic, there is an intermediate formula - one entailed by \u03c6 1  and entailing \u03c6 2  - using only relations in the common signature of \u03c6 1  and \u03c6 2 . Uniform interpolation strengthens this by requiring the interpolant to depend only on \u03c6 1  and the common signature. A uniform interpolant can thus be thought of as a minimal upper approximation of a formula within a subsignature. For first-order logic, interpolation holds but uniform interpolation fails. Uniform interpolation is known to hold for several modal and description logics, but little is known about uniform interpolation for fragments of predicate logic over relations with arbitrary arity. Further, little is known about ordinary Craig interpolation for logics over relations of arbitrary arity that have a recursion mechanism, such as fixpoint logics. In this work we take a step\u00a0\u2026", "num_citations": "10\n", "authors": ["1892"]}
{"title": "The per-character cost of repairing word languages\n", "abstract": " We show how to calculate the maximum number of edits per character needed to convert any string in one regular language to a string in another language. Our algorithm makes use of a local determinization procedure applicable to a subclass of distance automata. We then show how to calculate the same property when the editing needs to be done in streaming fashion, by a finite state transducer, using a reduction to mean-payoff games. In this case, we show that the optimal streaming editor can be produced in P.", "num_citations": "9\n", "authors": ["1892"]}
{"title": "Two variable vs. linear temporal logic in model checking and games\n", "abstract": " Verification tasks have non-elementary complexity for properties of linear traces specified in first-order logic, and thus various limited logical languages are employed. In this paper we consider two restricted specification logics, linear temporal logic (LTL) and two-variable first-order logic (FO2). LTL is more expressive, but FO2 is often more succinct, and hence it is not clear which should be easier to verify. In this paper we take a comprehensive look at the issue, giving a comparison of verification problems for FO2, LTL, and the subset of LTL expressively equivalent to FO2, unary temporal logic (UTL). We give two logic-to-automata translations which can be used to give upper bounds for FO2 and UTL; we apply these to get new bounds for both non-deterministic systems (hierarchical and recursive state machines, games) and for probabilistic systems (Markov chains, recursive Markov chains, and Markov\u00a0\u2026", "num_citations": "9\n", "authors": ["1892"]}
{"title": "Reformulating Queries: Theory and Practice.\n", "abstract": " We consider a setting where a user wants to pose a query against a dataset where background knowledge, expressed as logical sentences, is available, but only a subset of the information can be used to answer the query. We thus want to reformulate the user query against the subvocabulary, arriving at a query equivalent to the user\u2019s query assuming the background theory, but using only the restricted vocabulary. We consider two variations of the problem, one where we want any such reformulation and another where we restrict the size. We present a classification of the complexity of the problem, then provide algorithms for solving the problems in practice and evaluate their performance.", "num_citations": "8\n", "authors": ["1892"]}
{"title": "Characterizing definability in decidable fixpoint logics\n", "abstract": " We look at characterizing which formulas are expressible in rich decidable logics such as guarded fixpoint logic, unary negation fixpoint logic, and guarded negation fixpoint logic. We consider semantic characterizations of definability, as well as effective characterizations. Our algorithms revolve around a finer analysis of the tree-model property and a refinement of the method of moving back-and-forth between relational logics and logics over trees.", "num_citations": "8\n", "authors": ["1892"]}
{"title": "Source information disclosure in ontology-based data integration\n", "abstract": " Ontology-based data integration systems allow users to effectively access data sitting in multiple sources by means of queries over a global schema described by an ontology. In practice, datasources often contain sensitive information that the data owners want to keep inaccessible to users. In this paper, we formalize and study the problem of determining whether a given data integration system discloses a source query to an attacker. We consider disclosure on a particular dataset, and also whether a schema admits a dataset on which disclosure occurs. We provide lower and upper bounds on disclosure analysis, in the process introducing a number of techniques for analyzing logical privacy issues in ontology-based data integration.", "num_citations": "8\n", "authors": ["1892"]}
{"title": "Analysis of schemas with access restrictions\n", "abstract": " We study verification of systems whose transitions consist of accesses to a Web-based data source. An access is a lookup on a relation within a relational database, fixing values for a set of positions in the relation. For example, a transition can represent access to a Web form, where the user is restricted to filling in values for a particular set of fields. We look at verifying properties of a schema describing the possible accesses of such a system. We present a language where one can describe the properties of an access path and also specify additional restrictions on accesses that are enforced by the schema. Our main property language, AccessLTL, is based on a first-order extension of linear-time temporal logic, interpreting access paths as sequences of relational structures. We also present a lower-level automaton model, A-automata, into which AccessLTL specifications can compile. We show that AccessLTL and A\u00a0\u2026", "num_citations": "8\n", "authors": ["1892"]}
{"title": "Higher\u2212 Order Functions and Structured Datatypes\n", "abstract": " Recent proposals from the World Wide Web consortium propose adding support for higher-order functions within the XQuery standard. In this work we explore languages adding higher-order features on top of XML and other structured datatypes. We define a higher-order extension for Core XQuery, along with a higher-order algebra over complex values which has the same complexity as the XML-based language. We discuss our language and its relation with proposed extensions to the XQuery standard, study the complexity of evaluation, and briefly discuss our approach to implementing the language.", "num_citations": "8\n", "authors": ["1892"]}
{"title": "Complexity of higher-order queries\n", "abstract": " While relational algebra and calculus are a well-established foundation for classical database query languages, it is less clear what the analog is for higher-order functions, such as query transformations. Here we study a natural way to add higher-order functionality to query languages, by adding database query operators to the \u03bb-calculus as constants. This framework, which we refer to as \u03bb-embedded query languages, was introduced in [BPV10]. That work had a restricted focus: the containment and equivalence problems for query-to-query functions, in the case where only positive relational operators are allowed as constants. In this work we take an in-depth look at the most basic issue for such languages: the evaluation problem. We give a full picture of the complexity of evaluation for \u03bb-embedded query languages, looking at a number of variations: with negation and without; with only relational algebra operators\u00a0\u2026", "num_citations": "8\n", "authors": ["1892"]}
{"title": "How big must complete XML query languages be?\n", "abstract": " Marx and de Rijke have shown that the navigational core of the w3c XML query language XPath is not first-order complete--that is it cannot express every query definable in firstorder logic over the navigational predicates. How can one extend XPath to get a first-order complete language? Marx has shown that Conditional XPath--an extension of XPath with an\" Until\" operator--is first order complete. The completeness argument makes essential use of the presence of upward axes in Conditional XPath. We examine whether it is possible to get\" forward-only\" languages that are first-order complete for XML Boolean queries. It is easy to see that a variant of the temporal logic CTL* is first-order complete; the variant has path quantifiers for downward, leftward and rightward paths, while along a path one can check arbitrary formulas of linear temporal logic (LTL). This language has two major disadvantages: it requires path\u00a0\u2026", "num_citations": "8\n", "authors": ["1892"]}
{"title": "Philosophischer Empirismus\n", "abstract": " Michael Benedikt, Philosophischer Empirismus - PhilPapers Sign in | Create an account PhilPapers PhilPeople PhilArchive PhilEvents PhilJobs PhilPapers home Syntax Advanced Search Syntax Advanced Search Syntax Advanced Search Philosophischer Empirismus Michael Benedikt (1998) Abstract This article has no associated abstract. (fix it) Keywords Kant, Immanuel Philosophy Practice Empiricism Categories No categories specified (categorize this paper) Buy this book $43.99 used Amazon page ISBN(s) 3851321812 3851321812 Options Edit this record Mark as duplicate Export citation Find it on Scholar Request removal from index Translate to english Revision history Download options PhilArchive copy Upload a copy of this paper Check publisher's policy Papers currently archived: 59,848 External links This entry has no external links. Add one. Setup an account with your affiliations in order to access \u2026", "num_citations": "8\n", "authors": ["1892"]}
{"title": "Relational expressive power of constraint query languages\n", "abstract": " The expressive power of first-order query languages with several classes of equality and inequality constraints is studied in this paper. We settle the conjecture that recursive queries such as parity test and transitive closure cannot be expressed in the relational calculus augmented with polynomial inequality constraints over the reals. Furthermore, noting that relational queries exhibit several forms of genericity, we establish a number of collapse results of the following form: The class of generic boolean queries expressible in the relational calculus augmented with a given class of constraints coincides with the class of queries expressible in the relational calculus (with or without an order relation). We prove such results for both the natural and active-domain semantics. As a consequence, the relational calculus augmented with polynomial inequalities expresses the same classes of generic boolean queries under both the natural and active-domain semantics. In the course of proving...", "num_citations": "8\n", "authors": ["1892"]}
{"title": "Containment of shape expression schemas for RDF\n", "abstract": " We study the problem of containment of shape expression schemas ShEx for RDF graphs. We identify a subclass of ShEx that has a natural graphical representation in the form of shape graphs and whose semantics is captured with a tractable notion of embedding of an RDF graph in a shape graph. When applied to pairs of shape graphs, an embedding is a sufficient condition for containment, and for a practical subclass of deterministic shape graphs, it is also a necessary one, thus yielding a subclass with tractable containment. Containment for general shape graphs is EXP-complete. Finally, we show that containment for arbitrary ShEx is decidable.", "num_citations": "7\n", "authors": ["1892"]}
{"title": "Reasoning about disclosure in data integration in the presence of source constraints\n", "abstract": " Data integration systems allow users to access data sitting in multiple sources by means of queries over a global schema, related to the sources via mappings. Data sources often contain sensitive information, and thus an analysis is needed to verify that a schema satisfies a privacy policy, given as a set of queries whose answers should not be accessible to users. Such an analysis should take into account not only knowledge that an attacker may have about the mappings, but also what they may know about the semantics of the sources. In this paper, we show that source constraints can have a dramatic impact on disclosure analysis. We study the problem of determining whether a given data integration system discloses a source query to an attacker in the presence of constraints, providing both lower and upper bounds on source-aware disclosure analysis.", "num_citations": "7\n", "authors": ["1892"]}
{"title": "Goal-driven query answering for existential rules with equality\n", "abstract": " Inspired by the magic sets for Datalog, we present a novel goal-driven approach for answering queries over terminating existential rules with equality (aka TGDs and EGDs). Our technique improves the performance of query answering by pruning the consequences that are not relevant for the query. This is challenging in our setting because equalities can potentially affect all predicates in a dataset. We address this problem by combining the existing singularization technique with two new ingredients: an algorithm for identifying the rules relevant to a query and a new magic sets algorithm. We show empirically that our technique can significantly improve the performance of query answering, and that it can mean the difference between answering a query in a few seconds or not being able to process the query at all.", "num_citations": "6\n", "authors": ["1892"]}
{"title": "XML Update Facility for an XQuery Processor\n", "abstract": " An XML update facility is disclosed for an XQuery processor A modular system for updating an XML document comprises a query generator for converting one or more updates to the XML documents into one or more queries; an existing XML query engine for processing the one or more queries to generate one or more point updates that each update a node in the XML document; an update converter that converts the one or more point updates to one or more abstract interface representations of the one or more point updates, wherein the one or more abstract interface representations are executable units that can be individually executed using a point update facility; and an update evaluator that applies the one or more abstract interface representations to the XML document to update the XML document", "num_citations": "6\n", "authors": ["1892"]}
{"title": "Veriweb: Automatically testing dynamic web sites\n", "abstract": " VeriWeb:Automatically Testing Dynamic Web Sites Page 1 Juliana Freire 1 WWW2002 VeriWeb:Automatically Testing Dynamic Web Sites Juliana Freire http://www-db.bell-labs.com/~juliana Bell Labs Joint work with Michael Benedikt and Patrice Godefroid Page 2 Juliana Freire 2 WWW2002 Web pages became very complex \u25c6 Almost 90 different actions (85 links and 3 forms); \u25c6 96 gif images; \u25c6 113 lines of JavaScript code; \u25c6 ~570 lines of HTML Page 3 Juliana Freire 3 WWW2002 5 navigation steps, 650kb transferred Web navigation became very complex Go to travelocity.com Enter login info Choose 9 best itineraries Enter itinerary Flight list Page 4 Juliana Freire 4 WWW2002 Microsoft JET Database Engine error '80004005' Could not find file 'e:\\\u2026..\\cgi-bin\\db\\unimagem.mdb'. /cgi-bin/\u2026./main.asp, line 695 Many things can go wrong \u25c6 Interactions between HTML pages \u25c6 Applications that run in Web pages (\u2026", "num_citations": "6\n", "authors": ["1892"]}
{"title": "How Can Reasoners Simplify Database Querying (And Why Haven't They Done It Yet)?\n", "abstract": " The last few decades have seen vast progress in computational reasoning. This has included significant developments in theory, increasing maturity of tools both in performance and usability, and the evolution of standards and benchmarks. The purpose of this article is to reflect on the use of reasoning for rewriting and simplifying relational database queries. We undertake a review of some of the results and reasoning algorithms that have been developed with a motivation from query evaluation, and add to this a look at open problems in the area as well as a critique of prior work from the point of view of practice.", "num_citations": "5\n", "authors": ["1892"]}
{"title": "Looking through Freud's photos\n", "abstract": " A moody Freud posed against a background of holiday pictures pinned to a wall; or lurking at the very edge of a large family group; or lost in a crowd of nineteenth-century scientists. These snapshots or posed portraits not only tell stories, they also carry a specific emotional charge. The earlier essays in this book follow traces of Freud's early years through the evidence of such album photographs; the later essays use them to reconstruct the stories of various family members. An unknown photo of his half-brother Emanuel initiates an investigation into the Manchester Freuds. An identity photo of his daughter Anna, and the document to which it is attached, throw light on the critical final days of her trip to England in 1914. A faded idyllic print of children playing evolves into a discussion of Ernst Freud's luck and childhood. The suicide of Anna's artist cousin, Tom Seidmann Freud, emerges from a snap of her infant daughter Angela.", "num_citations": "5\n", "authors": ["1892"]}
{"title": "Verification of two-variable logic revisited\n", "abstract": " Two-variable logic is a fragment of first-order logic that allows for decidable verification problems. In previous work, we developed an approach to FO 2  verification that is particularly useful for probabilistic systems, based on analysis of the translation of FO 2  to automata. In this work we show that the techniques introduced there can be applied to give information on other logics, and can be used in conjunction with automata-theoretic techniques for Linear Temporal Logic (LTL) in the context of probabilistic verification. First we revisit the technique of our prior work starting with FO 2  without the successor relation. Making use of recent results by Weis we show here that we can get quite small automata for these formula. We then show that we can recapture the automata size bounds for general FO 2  formulas by bootstrapping results for FO 2  without successor. Next, we look at combining FO 2  verification techniques\u00a0\u2026", "num_citations": "5\n", "authors": ["1892"]}
{"title": "ProFoUnd: program-analysis-based form understanding\n", "abstract": " An important feature of web search interfaces are the restrictions enforced on input values-those reflecting either the semantics of the data or requirements specific to the interface. Both integrity constraints and\" access restrictions\" can be of great use to web exploration tools. We demonstrate here a novel technique for discovering constraints that requires no form submissions whatsoever. We work via statically analyzing the JavaScript client-side code used to enforce the constraints, when such code is available. We combine custom recognizers for JavaScript functions relevant to constraint checking with a generic program analysis layer. Integrated with a web browser, our system shows the constraints detected on accessed web forms, and allows a user to see the corresponding JavaScript code fragment.", "num_citations": "5\n", "authors": ["1892"]}
{"title": "Minimal memory automata\n", "abstract": " We provide a Myhill-Nerode-like theorem that characterizes the class of data languages recognized by deterministic finite-memory automata (DMA). As a byproduct of this characterization result, we obtain a canonical representation for any DMA-recognizable language. We then show that this canonical automaton is minimal in a strong sense: it has the minimal number of control states and also the minimal amount of internal storage. We finally show how this minimal automaton can be computed.", "num_citations": "5\n", "authors": ["1892"]}
{"title": "VeriWeb: A platform for automating web site testing\n", "abstract": " VeriWeb: A Platform for Automating Web Site Testing \u2014 NYU Scholars Skip to main navigation Skip to search Skip to main content NYU Scholars Logo Help & FAQ Home Profiles Research Units Research Output VeriWeb: A Platform for Automating Web Site Testing M. Benedikt, Juliana Freire, P. Godefroid Urban Initiative Research output: Chapter in Book/Report/Conference proceeding \u203a Chapter (peer-reviewed) Overview Original language English (US) Title of host publication Proceedings of the World Wide Web Conference (WWW) \u2013 Web Engineering track State Published - 2002 Cite this APA Standard Harvard Vancouver Author BIBTEX RIS Benedikt, M., Freire, J., & Godefroid, P. (2002). VeriWeb: A Platform for Automating Web Site Testing. In Proceedings of the World Wide Web Conference (WWW) \u2013 Web Engineering track VeriWeb : A Platform for Automating Web Site Testing. / Benedikt, M. ; Freire, Juliana; \u2026", "num_citations": "5\n", "authors": ["1892"]}
{"title": "Nonstandard analysis and special ultrafilters.\n", "abstract": " Degree: Ph. D.DegreeYear: 1993Institute: The University of Wisconsin-MadisonLet U be a selective ultrafilter, and  V be a nonstandard universe formed by taking the ultrapower over U. Let  be a complete metric space. We show that sets that are -open and S-dense in  X contain nonmeagrely many standard elements, that the S-topology on  X is T , and that continuous functions from -compact subsets of  X that are disjoint from the star of their standard part extend to standard continuous functions on X. We show that, if  is a Borel probability measure on X, that the image of the Loeb measure formed over  in  X under the map S (S) defines an extension of the measure  to a larger -algebra on X. This extension process can be carried out even when the ultrafilter U satisfies a property weaker than selectivity, defined in this thesis as\" Property M\". It is shown that products of nonisomorphic selective\u00a0\u2026", "num_citations": "5\n", "authors": ["1892"]}
{"title": "Scalable querying of nested data\n", "abstract": " While large-scale distributed data processing platforms have become an attractive target for query processing, these systems are problematic for applications that deal with nested collections. Programmers are forced either to perform non-trivial translations of collection programs or to employ automated flattening procedures, both of which lead to performance problems. These challenges only worsen for nested collections with skewed cardinalities, where both handcrafted rewriting and automated flattening are unable to enforce load balancing across partitions. In this work, we propose a framework that translates a program manipulating nested collections into a set of semantically equivalent shredded queries that can be efficiently evaluated. The framework employs a combination of query compilation techniques, an efficient data representation for nested collections, and automated skew-handling. We provide an extensive experimental evaluation, demonstrating significant improvements provided by the framework in diverse scenarios for nested collection programs.", "num_citations": "4\n", "authors": ["1892"]}
{"title": "Biological web services: Integration, optimization, and reasoning\n", "abstract": " A vast amount of biological data is now available via web services. Yet the usefulness of this data is limited by the difficulty in performing queries that require data spanning multiple services. We overview a platform which offers integrated data access with minimal user awareness. Users pose high-level queries to this platform, and the system applies a combination of reasoning techniques and cost-based optimization to generate an efficient and reliable implementation on top of the services. We briefly explain the platform\u2019s reasoning paradigm, which is based on exact reformulation; we then overview the platform\u2019s use on a set of bioinformatics sources, and provide some preliminary results concerning its performance.", "num_citations": "4\n", "authors": ["1892"]}
{"title": "The complexity of higher-order queries\n", "abstract": " Higher-order transformations are ubiquitous within data management. In relational databases, higher-order queries appear in numerous aspects including query rewriting and query specification. This work investigates languages that combine higher-order transformations with ordinary relational database query languages. We study the two most basic computational problems associated with these query languages \u2013 the evaluation problem and the containment problem. We isolate the complexity of evaluation at every order, in an analysis similar to that for that standard typed lambda calculus. We show that the containment problem (and hence, the equivalence problem) is decidable in several important subcases, particularly in the case where query constants and variables range over the positive relational operators. The main decidability result relies on techniques that differ from those used in classical query\u00a0\u2026", "num_citations": "4\n", "authors": ["1892"]}
{"title": "Grammar and method for integrating XML data from multiple sources\n", "abstract": " A grammar for mapping a first grouping of XML data into a second grouping of XML data and a method for accomplishing same to incorporate the first grouping into the second grouping. The grammar includes a first rule for computing a first child element attribute and a second rule for computing a second parent element attribute. The first rule and second rule vary according to a production of an element type of the first grouping. The element types include PCDATA, disjunctive, conjunctive and Kleene star, each having a unique rule set for defining inherited and synthesized attributes of the parent and child elements. The method includes the step of executing a mapping of a first grouping having at least one parent element and a set of corresponding child elements into a second grouping in accordance with the grammar rules based on the production of the element type.", "num_citations": "4\n", "authors": ["1892"]}
{"title": "Model Checking Markov Chains Against Unambiguous Buchi Automata\n", "abstract": " We give a polynomial-time algorithm for model checking finite Markov chains against omega-regular specifications given as unambiguous Buchi automata.", "num_citations": "4\n", "authors": ["1892"]}
{"title": "QUASAR: querying annotation, structure, and reasoning\n", "abstract": " An increasing number of systems provide the ability to semantically annotate documents. OpenCalais [4], Evri API [2], Zemanta [6], and Alchemy API [1] are web-hosted systems that return annotated documents, ie documents with annotations that are overlayed on the document structure. Many of the annotations can be linked to standard ontologies, such as DBpedia and YAGO. These annotations give insight as to the meaning of documents in a variety of ways, identifying entities and relationships inside them, classifying them according to topic or theme, and giving the attitude or sentiment of a document or document fragment. In order for users (or applications) to make use of these annotations with a means to access and manipulate documents that contain them, we provide a query language for doing this and demonstrate its utility on a demo system built on top of diverse semantic annotators and external\u00a0\u2026", "num_citations": "4\n", "authors": ["1892"]}
{"title": "Analysis of declarative updates: invited talk\n", "abstract": " Declarative XML update languages are harder to analyze than queries. Static type inference and type checking are certainly more difficult, and even more basic effect analysis problems are complex--what parts of a document does an update impact? I will begin by surveying the previous results on analysis of XML updates, and their relation to problems in XPath/XQuery. I will then focus on one interaction problem: do an update and a query interact? I will explain why this problem lies at the core of many optimization problems, particularly view maintenance under declarative updates and minimization of number of passes in update evaluation.", "num_citations": "4\n", "authors": ["1892"]}
{"title": "Definability over linear constraints\n", "abstract": " We settle a number of questions concerning definability in first order logics with an extra predicate symbol ranging over semi-linear sets. These questions are motivated by the constraint database model for representing spatial data. We give new results both on the positive and negative side: we show that in first-order logic one cannot query a semi-linear set as to whether or not it contains a line, or whether or not it contains the line segment between two given points. However, we show that some of these queries become definable if one makes small restrictions on the semi-linear sets considered.", "num_citations": "4\n", "authors": ["1892"]}
{"title": "Generating collection transformations from proofs\n", "abstract": " Nested relations, built up from atomic types via product and set types, form a rich data model. Over the last decades the nested relational calculus, NRC, has emerged as a standard language for defining transformations on nested collections. NRC is a strongly-typed functional language which allows building up transformations using tupling and projections, a singleton-former, and a map operation that lifts transformations on tuples to transformations on sets.   In this work we describe an alternative declarative method of describing transformations in logic. A formula with distinguished inputs and outputs gives an implicit definition if one can prove that for each input there is only one output that satisfies it. Our main result shows that one can synthesize transformations from proofs that a formula provides an implicit definition, where the proof is in an intuitionistic calculus that captures a natural style of reasoning about\u00a0\u2026", "num_citations": "3\n", "authors": ["1892"]}
{"title": "Two variable logic with ultimately periodic counting\n", "abstract": " We consider the extension of two variable logic with quantifiers that state that the number of elements where a formula holds should belong to a given ultimately periodic set. We show that both satisfiability and finite satisfiability of the logic are decidable. We also show that the spectrum of any sentence is definable in Presburger arithmetic. In the process we present several refinements to the ``biregular graph method''. In this method, decidability issues concerning two-variable logics are reduced to questions about Presburger definability of integer vectors associated with partitioned graphs, where nodes in a partition satisfy certain constraints on their in- and out-degrees.", "num_citations": "3\n", "authors": ["1892"]}
{"title": "Nonstandard analysis in selective universes\n", "abstract": " A natural counterpart to the investigations is to look at models that are in some sense as \u2018small\u2019as possible. A nonstandard universe formed using a selective ultrafilter is definitely as small as an \u03c9 1-saturated nonstandard universe can get: no nonstandard universe can be properly embedded in it. This chapter outlines some unique features of nonstandard universes formed using selective ultrafilters and ultrafilters satisfying various weakenings of selectivity. It discusses distinguishing features of selective ultrafilters with respect to topology and measure theory, respectively. The chapter examines nonstandard topology in a selective universe, focusing on the S-topology and also discusses some properties of the Loeb measure in selective universes. It aims to identify the properties that distinguish nonstandard topology in a selective universe from topology in run-of-the-mill nonstandard universes. A major goal in\u00a0\u2026", "num_citations": "3\n", "authors": ["1892"]}
{"title": "Form filling based on constraint solving\n", "abstract": " We describe a system for analyzing form-based websites to discover sequences of actions and values that result in a valid form submission. Rather than looking at the text or DOM structure of the form, our method is driven by solving constraints involving the underlying client-side JavaScript code. In order to deal with the complexity of client-side code, we adapt a method from program analysis and testing, concolic testing, which mixes concrete code execution, symbolic code tracing, and constraint solving to find values that lead to new code paths. While concolic testing is commonly used for detecting bugs in stand-alone code with developer support, we show how it can be applied to the very different problem of filling Web forms. We evaluate our system on a benchmark of both real and synthetic Web forms.", "num_citations": "3\n", "authors": ["1892"]}
{"title": "Querying visible and invisible tables in the presence of integrity constraints\n", "abstract": " We provide a wide-ranging study of the scenario where a subset of the tables in a relational schema are visible to a user\u2014that is, their complete contents are known\u2013while the remaining tables are invisible. The schema also has a set of integrity constraints, which may relate the visible tables to invisible ones but also may constrain both the visible and invisible instances. We want to determine whether information about a user query can be inferred using only the visible information and the constraints. We consider whether positive information about the query can be inferred, and also whether negative information (the query does not hold) can be inferred. We further consider both the instance-level version of the problem (the visible table extensions are given) and the schema-level version, where we want to know whether information can be leaked in some instance of the schema. Our instance-level results classify the complexity of these problems, both as a function of all inputs, and in the size of the instance alone. Our schema-level results exhibit an unusual dividing line between decidable and undecidable cases.", "num_citations": "3\n", "authors": ["1892"]}
{"title": "Combining existential rules and description logics\n", "abstract": " Query answering under existential rules\u2014implications with existential quantifiers in the head\u2014is known to be decidable when imposing restrictions on the rule bodies such as frontier-guardedness [Baget et al., 2010; Baget et al., 2011a]. Query answering is also decidable for description logics [Baader, 2003], which further allow disjunction and functionality constraints (assert that certain relations are functions); however, they are focused on ER-type schemas, where relations have arity two. This work investigates how to get the best of both worlds: having decidable existential rules on arbitrary arity relations, while allowing rich description logics, including functionality constraints, on arity-two relations. We first show negative results on combining such decidable languages. Second, we introduce an expressive set of existential rules (frontier-one rules with a certain restriction) which can be combined with powerful constraints on arity-two relations (eg GC2, ALCQIb) while retaining decidable query answering. Further, we provide conditions to add functionality constraints on the higher-arity relations.", "num_citations": "3\n", "authors": ["1892"]}
{"title": "Bisimilarity of pushdown systems is nonelementary\n", "abstract": " Given two pushdown systems, the bisimilarity problem asks whether they are bisimilar. While this problem is known to be decidable our main result states that it is nonelementary, improving EXPTIME-hardness, which was the previously best known lower bound for this problem. Our lower bound result holds for normed pushdown systems as well.", "num_citations": "3\n", "authors": ["1892"]}
{"title": "HOMES: A higher-order mapping evaluation system\n", "abstract": " We describe a system that integrates querying and query transformation in a single higher-order query language. The system allows users to write queries that integrate and combine query transformations. The power of higher-order functions also allows one to succinctly write complex relational queries. Our demonstration shows the utility of the system, explains the implementation architecture on top of a relational DBMS, and explains optimizations that combine subquery caching techniques from relational databases with sharing detection schemes from functional programming.", "num_citations": "3\n", "authors": ["1892"]}
{"title": "Hierarchies of measure-theoretic ultrafilters\n", "abstract": " We study relations between measure-theoretic classes of ultrafilters, such as the Property M ultrafilters of [4], with other well-known ultrafilter classes. We define several classes of measure theoretic ultrafilters, of which the Property M ultrafilters are the strongest. We show which containments are provable in ZFC between these measure-theoretic ultrafilters and boolean combinations of well-known ultrafilters such as the selective, semi-selective, and P-point ultrafilters. We also list some of the containment results between measure-theoretic ultrafilters and several other ultrafilter classes, such as the Arrow and Property C ultrafilters.", "num_citations": "3\n", "authors": ["1892"]}
{"title": "Logic and learning (dagstuhl seminar 19361)\n", "abstract": " The goal of building truly intelligent systems has forever been a central problem in computer science. While logic-based approaches of yore have had their successes and failures, the era of machine learning, specifically deep learning is also coming upon significant challenges. There is a growing consensus that the inductive reasoning and complex, high-dimensional pattern recognition capabilities of deep learning models need to be combined with symbolic (even programmatic), deductive capabilities traditionally developed in the logic and automated reasoning communities in order to achieve the next step towards building intelligent systems, including making progress at the frontier of hard problems such as explainable AI. However, these communities tend to be quite separate and interact only minimally, often at odds with each other upon the subject of the``correct approach''to AI. This report documents the efforts of Dagstuhl Seminar 19361 on``Logic and Learning''to bring these communities together in order to:(i) bridge the research efforts between them and foster an exchange of ideas in order to create unified formalisms and approaches that bear the advantages of both research methodologies;(ii) review and analyse the progress made across both communities;(iii) understand the subtleties and difficulties involved in solving hard problems using both perspectives;(iv) make attempts towards a consensus on what the hard problems are and what the elements of good solutions to these problems would be. The three focal points of the seminar were the strands of``Logic for Machine Learning'',``Machine Learning for Logic'', and``Logic vs\u00a0\u2026", "num_citations": "2\n", "authors": ["1892"]}
{"title": "Monadic datalog, tree validity, and limited access containment\n", "abstract": " We reconsider the problem of containment of monadic datalog (MDL) queries in unions of conjunctive queries (UCQs). Prior work has dealt with special cases of the problem but has left the precise complexity characterization open. In addition, the complexity of one important special case, that of containment under access patterns, was not known before. We start by revisiting the connection between MDL/UCQ containment and containment problems involving regular tree languages. We then present a general approach for getting tighter bounds on the complexity of query containment, based on analysis of the number of mappings of queries into tree-like instances. We give two applications of the machinery. We first give an important special case of the MDL/UCQ containment problem that is in EXPTIME, and we use this bound to show an EXPTIME bound on containment under access patterns. Second, we show\u00a0\u2026", "num_citations": "2\n", "authors": ["1892"]}
{"title": "Pspace hardness of mixed world query answering for atomic queries under guarded tgds\n", "abstract": " Consider a vocabulary divided into open-world relations O and closed-world relations C, a set of logical sentences (\u201cintegrity constraints\u201d henceforward) \u03a3, a boolean query Q, and an instance D. We say that Q is certain with respect to O, C, \u03a3, D if: for every instance D that extends D and agrees with D on relations in C, Q holds on D.As in most prior work, we focus on the case in which Q is a conjunctive query, an existential quantification of conjunctions of atoms, and the case where Q is a disjunction of conjunctive queries. We will be interested in the data complexity of the problem: fixing O, C, \u03a3, Q and varying D. It is well-known that even when the constraints \u03a3 have a very restricted form, the data-complexity can be coNP-hard [AD98]. coNP-hardness in data complexity can even occur when the arity of relations is at most 2 [LSW15, LSW13].[BBPtC16] provided examples of schemas with arity larger than 2 where the situation is even worse. We can get O, C, \u03a3, Q such that the data complexity is ExpTime-hard and: Q is a UCQ, while \u03a3 consists of linear TGDs. Linear TGDs are sentences of the form", "num_citations": "2\n", "authors": ["1892"]}
{"title": "Determinacy and rewriting of functional top\u2013down and MSO tree transformations\n", "abstract": " A query is determined by a view, if the result of the query can be reconstructed from the result of the view. We consider the problem of deciding for two given (functional) tree transformations, whether one is determined by the other. If the view transformation is induced by a tree transducer that may copy, then determinacy is undecidable. For a large class of noncopying views, namely compositions of extended linear top\u2013down tree transducers, we show that determinacy is decidable, where queries are either deterministic top\u2013down tree transducers (with regular look-ahead) or deterministic MSO tree transducers. We also show that if a query is determined by a view, then it can be rewritten into a query that works over the view and is in the same class of transducers as the query. The proof relies on the decidability of equivalence for the considered classes of queries, and on their composition closure.", "num_citations": "2\n", "authors": ["1892"]}
{"title": "Generalizing finite model theory\n", "abstract": " We overview work on languages for querying finite structures, where the finite structures \u201clive\u201d inside some infinite interpreted structure. The goal is to take the query languages that have been investigated in finite model theory\u2014first-order logic, second-order logic, fixpoint logic, etc.\u2014and find natural extensions of them that take into account the ambient structure. Most of our discussion will be on first-order query languages. From the point of view of model theory, this means we fix an infinite structure and look at first-order formulas with additional relational predicates that range over finite sets; thus our languages lie between first-order logic and weak second order logic. The bulk of the survey consists of characterization theorems stating what sorts of queries can be defined in these logics. Not surprisingly, the expressiveness of first-order queries is determined by the model theory of the infinite structure. When the structure has a decision procedure, one can ask how complex it is to evaluate these formulas, in terms of the size of the finite structure that is plugged in for the free relational parameters. That is, we can consider formulas in these logics as templates for standard formulas, and ask how decision procedures behave as the templates are instantiated differently. The model-theoretic perspective and the symbolic computation perspective turn out to be closely connected. We also discuss applications of the results to spatial databases and to abstract complexity.", "num_citations": "2\n", "authors": ["1892"]}
{"title": "ROSeAnn: Reconciling opinions of semantic annotators\n", "abstract": " Named entity extractors can be used to enrich both text and Web documents with semantic annotations. While originally focused on a few standard entity types, the ecosystem of annotators is becoming increasingly diverse, with recognition capabilities ranging from generic to specialised entity types. Both the overlap and the diversity in annotator vocabularies motivate the need for managing and integrating semantic annotations: allowing users to see the results of multiple annotations and to merge them into a unified solution. We demonstrate ROSEANN, a system for the management of semantic annotations. ROSEANN provides users with a unified view over the opinion of multiple independent annotators both on text and Web documents. It allows users to understand and reconcile conflicts between annotations via ontology-aware aggregation. ROSEANN incorporates both supervised aggregation, appropriate\u00a0\u2026", "num_citations": "2\n", "authors": ["1892"]}
{"title": "Controlling the depth, size, and number of subtrees for two-variable logic on trees\n", "abstract": " Verification of properties of first order logic with two variables FO2 has been investigated in a number of contexts. Over arbitrary structures it is known to be decidable with NEXPTIME complexity, with finitely satisfiable formulas having exponential-sized models. Over word structures, where FO2 is known to have the same expressiveness as unary temporal logic, the same properties hold. Over finite labelled ordered trees FO2 is also of interest: it is known to have the same expressiveness as navigational XPath, a common query language for XML documents. Prior work on XPath and FO2 gives a 2EXPTIME bound for satisfiability of FO2. In this work we give the first in-depth look at the complexity of FO2 on trees, and on the size and depth of models. We show that the doubly-exponential bound is not tight, and neither do the NEXPTIME-completeness results from the word case carry over: the exact complexity varies depending on the vocabulary used, the presence or absence of a schema, and the encoding used for labels. Our results depend on an analysis of subformula types in models of FO2 formulas, including techniques for controlling the number of distinct subtrees, the depth, and the size of a witness to finite satisfiability for FO2 sentences over trees.", "num_citations": "2\n", "authors": ["1892"]}
{"title": "Higher-order queries and applications\n", "abstract": " Higher-order transformations are ubiquitous within data management. In relational databases, higher-order queries appear in numerous aspects including query rewriting and query specification. In XML databases, higher-order functions are natural due to the close connection of XML query languages with functional programming.The thesis investigates higher-order query languages that combine higherorder transformations with ordinary database query languages. We define higher-order query languages based on Relational Algebra, Monad Algebra, and XQuery. The thesis also studies basic problems for these query languages including evaluation, containment, and type inference. We show that even though evaluating these higher-order query languages is non-elementary, there are subclasses that are polynomially reducible to evaluation for ordinary query languages.", "num_citations": "2\n", "authors": ["1892"]}
{"title": "An insider's guide to logic in telecommunications data\n", "abstract": " Most of the functionality of modern telecommunication systems has migrated to software, and much of that software consists of code for manipulating data: data describing either subscriber features or equipment configuration. The data is generally hierarchically structured but extremely complex - it consists of hundreds or even thousands of \"classes\" (roughly speaking, distinct labels on a tree), with the same information occurring in different formats across many classes in a hierarchy. The data is also required to satisfy a gigantic number of integrity constraints, vital to the correct routing of phone calls. The challenge is to create tools for populating this data, updating the data, and propagating these updates to derived data; all without violating these integrity constraints. The aim of this article is to give an overview of recent projects at Bell Labs that tackle this problem. Declarative languages play a key role. Indeed, we\u00a0\u2026", "num_citations": "2\n", "authors": ["1892"]}
{"title": "Balancing expressiveness and inexpressiveness in view design\n", "abstract": " We study the design of data publishing mechanisms that allow a collection of autonomous distributed data sources to collaborate to support queries. A common mechanism for data publishing is via views: functions that expose derived data to users, usually specified as declarative queries. Our autonomy assumption is that the views must be on individual sources, but with the intention of supporting integrated queries. In deciding what data to expose to users, two considerations must be balanced. The views must be sufficiently expressive to support queries that users want to ask\u2014the utility of the publishing mechanism. But there may also be some expressiveness restrictions. Here, we consider two restrictions, a minimal information requirement, saying that the views should reveal as little as possible while supporting the utility query, and a non-disclosure requirement, formalizing the need to prevent external users\u00a0\u2026", "num_citations": "1\n", "authors": ["1892"]}
{"title": "Generating collection queries from proofs\n", "abstract": " Nested relations, built up from atomic types via tupling and set types, form a rich data model. Over the last decades the nested relational calculus, NRC, has emerged as a standard language for defining transformations on nested collections. NRC is a strongly-typed functional language which allows building up queries using products and projections, a singleton-former, and a map operation that lifts queries on tuples to queries on sets. In this work we show that NRC has a strong connection with first-order logic: it contains exactly the transformations that are implicitly definable by formulas  in first-order logic with quantification suited for nested collections. We also prove an effective variant of our result, providing a procedure that synthesizes an NRC expression in polynomial time from a proof witnessing that  provides an implicit definition for one subset of its free variables in terms of another subset of the variables\u00a0\u2026", "num_citations": "1\n", "authors": ["1892"]}
{"title": "Definability and interpolation within decidable fixpoint logics\n", "abstract": " We look at characterizing which formulas are expressible in rich decidable logics such as guarded fixpoint logic, unary negation fixpoint logic, and guarded negation fixpoint logic. We consider semantic characterizations of definability, as well as effective characterizations. Our algorithms revolve around a finer analysis of the tree-model property and a refinement of the method of moving back and forth between relational logics and logics over trees.", "num_citations": "1\n", "authors": ["1892"]}
{"title": "Report on the first Workshop on Innovative Querying of Streams\n", "abstract": " INnovative QUErying of STreams (INQUEST) was held on September 25-27, 2012 in the Department of Computer Science of the University of Oxford (UK). It was sponsored by the UK\u2019s Engineering and Physical Sciences Research Council (EPSRC), as part of the project \u201cEnforcement of Constraints on XML Streams\u201d. Stream processing represents a thriving area of research across the algorithms, databases, networking, programming languages, and systems research communities. Within the database community, a \u201cclassical\u201d problem is query processing on streams of discrete tuple-oriented data. One goal of the workshop considers the way recent developments add complexity to this problem:\u2022 how does the setting change when data to be considered by queries is not relational, but has nested structure, such as XML or JSON?\u2022 conversely, how does the setting change when data to be considered consists of RDF\u00a0\u2026", "num_citations": "1\n", "authors": ["1892"]}
{"title": "Report on PODS 2012\n", "abstract": " The 31st edition of the ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Databases (PODS) took place from May 21 to May 23, 2012, in Scottsdale, Arizona. As in all recent years, the symposium was organized jointly with the ACM SIGMOD International Conference on Management of Data (SIGMOD), with PODS focusing on theoretical aspects of data management systems and techniques. The proceedings of the conference are published by ACM Press, and can also be found both on the SIGMOD website (http://www. sigmod. org), as well as in the ACM Digital Library (http://www. acm. org/dl). The conference program included a keynote talk by Surajit Chaudhuri, two invited tutorials (by Michael Mahoney and Benjamin Pierce), and 26 papers that were selected by the Program Committee from 101 submissions. As always, most of the papers are extended abstracts, and many of them will appear in more\u00a0\u2026", "num_citations": "1\n", "authors": ["1892"]}
{"title": "Determining relevance of accesses at runtime (extended version)\n", "abstract": " Consider the situation where a query is to be answered using Web sources that restrict the accesses that can be made on backend relational data by requiring some attributes to be given as input of the service. The accesses provide lookups on the collection of attributes values that match the binding. They can differ in whether or not they require arguments to be generated from prior accesses. Prior work has focused on the question of whether a query can be answered using a set of data sources, and in developing static access plans (e.g., Datalog programs) that implement query answering. We are interested in dynamic aspects of the query answering problem: given partial information about the data, which accesses could provide relevant data for answering a given query? We consider immediate and long-term notions of \"relevant accesses\", and ascertain the complexity of query relevance, for both conjunctive queries and arbitrary positive queries. In the process, we relate dynamic relevance of an access to query containment under access limitations and characterize the complexity of this problem; we produce several complexity results about containment that are of interest by themselves.", "num_citations": "1\n", "authors": ["1892"]}
{"title": "Definability with a predicate for a semi-linear set\n", "abstract": " We settle a number of questions concerning definability in first order logic with an extra predicate symbol ranging over semi-linear sets. We give new results both on the positive and negative side: we show that in first-order logic one cannot query a semi-linear set as to whether or not it contains a line, or whether or not it contains the line segment between two given points. However, we show that some of these queries become definable if one makes small restrictions on the semi-linear sets considered.", "num_citations": "1\n", "authors": ["1892"]}
{"title": "XPath: Looking Forward\n", "abstract": " CiNii \u8ad6\u6587 - XPath : Looking Forward CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e \u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 XPath : Looking Forward BENEDIKT Michael \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 BENEDIKT Michael \u53ce\u9332\u520a\u884c\u7269 Proc. EDBT 2002 Workshops Proc. EDBT 2002 Workshops, 2002 \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 \u6728\u57cb\u3081\u8fbc\u307f\u95a2\u4fc2\u306b\u57fa\u3065\u304f XML\u30b9\u30ad\u30fc\u30de\u9032\u5316\u306b\u5fdc\u3058\u305f XPath \u554f\u5408\u305b\u5909\u63db \u68ee\u672c \u5353\u723e , \u6a4b\u672c \u5065\u4e8c , \u77f3\u539f \u9756\u54f2 , \u85e4\u539f \u878d \u96fb\u5b50\u60c5\u5831 \u901a\u4fe1\u5b66\u4f1a\u6280\u8853\u7814\u7a76\u5831\u544a. DE, \u30c7\u30fc\u30bf\u5de5\u5b66 107(131), 109-114, 2007-07-02 \u53c2\u8003\u6587\u732e4\u4ef6 Tweet \u5404\u7a2e\u30b3\u30fc\u30c9 NII\u8ad6\u6587ID(NAID) 10019617370 \u8cc7\u6599\u7a2e\u5225 \u4f1a\u8b70\u8cc7\u6599 \u30c7\u30fc\u30bf\u63d0\u4f9b\u5143 CJP\u5f15\u7528 \u66f8\u304d\u51fa\u3057 RefWorks\u306b\u66f8\u304d\u51fa\u3057 EndNote\u306b\u66f8\u304d\u51fa\u3057 Mendeley\u306b\u66f8\u304d\u51fa\u3057 Refer/BiblX\u3067\u8868\u793a RIS\u3067\u8868\u793a \u2026", "num_citations": "1\n", "authors": ["1892"]}
{"title": "Query Safety with Constraints\n", "abstract": " The power of classical query languages is linked to the fact that they express a restricted class of declarative programs. The class of semantic objects expressible through queries in the relational calculus, for example, is limited in a number of ways: They have PTIME data complexity, and their expressiveness is well understood. Although relational calculus queries may not return finite results, a natural subclass of the relational calculus does; namely the class of range-restricted queries. This class gives guarantees of finite output, and is complete in this respect, capturing all relational calculus queries whose outputs are always finite, the safe queries.", "num_citations": "1\n", "authors": ["1892"]}