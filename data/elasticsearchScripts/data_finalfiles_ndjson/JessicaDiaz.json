{"title": "Agile product line engineering\u2014a systematic literature review\n", "abstract": " Software Product Line Engineering (SPLE) demands upfront long\u2010term investment in (i) designing a common set of core\u2010assets and (ii) managing variability across the products from the same family. When anticipated changes in these core\u2010assets have been predicted with certain accuracy, SPLE has proved significant improvements. However, when large/complex software product line projects have to deal with changing market conditions, alternatives to supplement SPLE are required. Agile Software Development (ASD) may be an alternative, as agile processes harness change for the customer's competitive advantage. However, when the aim is to scale Agile projects up to effectively manage reusability and variability across the products from the same family, alternatives to supplement agility are also required. As a result, a new approach called Agile Product Line Engineering (APLE) advocates integrating\u00a0\u2026", "num_citations": "92\n", "authors": ["614"]}
{"title": "Plastic Partial Components: A solution to support variability in architectural components\n", "abstract": " Software product line engineering is becoming widely used due to the improvement it means when developing software products of the same family. The commonalities and variabilities of software product lines (SPL) are identified during the domain engineering process and then, they are realized in the software architecture. Therefore, mechanisms to explicitly specify the commonalities and variabilities of SPLs at the architectural level are required. Most of the current mechanisms specify variations on the architecture by adding or removing architectural elements. However, it is also necessary to specify variations inside components. In this paper, we propose the notion of plastic partial components to support internal variations. The specification of these components is performed using invasive software composition techniques and without tangling the core and product architectures of the SPL. This contribution is\u00a0\u2026", "num_citations": "53\n", "authors": ["614"]}
{"title": "An exploratory study in communication in Agile Global Software Development\n", "abstract": " Global software development (GSD) is gaining ever more relevance. Although communication is key in the exchange of information between team members, multi-site software development has introduced additional obstacles (different time-zones and cultures, IT infrastructure, etc.) and delays into the act of communication, which is already problematic. Communication is even more critical in the case of Agile Global Software Development (AGSD) in which communication plays a primary role. This paper reports an exploratory study of the effects of tools supporting communication in AGSD. More precisely, this paper analyses the perception of team members about communication infrastructures in AGSD. The research question to which this study responds concerns how development teams perceive the communication infrastructure while developing products using agile methodologies. Most previous studies have\u00a0\u2026", "num_citations": "52\n", "authors": ["614"]}
{"title": "Providing a Consensus Definition for the Term\" Smart Product\"\n", "abstract": " The term \"Smart Product\" has become commonly used in recent years. This is because there has been an increasing interest in these kinds of products as part of the consumer goods industry, impacting everyday life and industry. Nevertheless, the term \"Smart Product\" is used with different meanings in different contexts and application domains. The use of the term \"Smart Product\" with different meanings and underlying semantics can create important misunderstandings and dissent. The aim of this paper is to analyze the different definitions of Smart Product available in the literature, and to explore and analyze their commonalities and differences, in order to provide a consensus definition that satisfies, and can therefore be used by, all parties. To embrace the identified definitions, the concept of \"Smart Thing\" is introduced. The methodology used was a systematic literature review. The definition is expressed as an\u00a0\u2026", "num_citations": "46\n", "authors": ["614"]}
{"title": "Agile product-line architecting in practice: A case study in smart grids\n", "abstract": " ContextSoftware Product Line Engineering implies the upfront design of a Product-Line Architecture (PLA) from which individual product applications can be engineered. The big upfront design associated with PLAs is in conflict with the current need of \u201cbeing open to change\u201d. To make the development of product-lines more flexible and adaptable to changes, several companies are adopting Agile Product Line Engineering. However, to put Agile Product Line Engineering into practice it is still necessary to make mechanisms available to assist and guide the agile construction and evolution of PLAs.ObjectiveThis paper presents the validation of a process for \u201cthe agile construction and evolution of product-line architectures\u201d, called Agile Product-Line Architecting (APLA). The contribution of the APLA process is the integration of a set of models for describing, documenting, and tracing PLAs, as well as an algorithm for\u00a0\u2026", "num_citations": "44\n", "authors": ["614"]}
{"title": "Change impact analysis in product-line architectures\n", "abstract": " Change impact analysis is fundamental in software evolution, since it allows one to determine potential effects upon a system resulting from changing requirements. While prior work has generically considered change impact analysis at architectural level, there is a distinct lack of support for the kinds of architectures used to realize software product lines, so-called product-line architectures (PLAs). In particular, prior approaches do not account for variability, a specific characteristic of software product lines. This paper presents a new technique for change impact analysis that targets product-line architectures. We propose to join a traceability-based algorithm and a rule-based inference engine to effectively traverse modeling artifacts that account for variability. In contrast to prior approaches, our technique supports the mechanisms for (i)\u00a0specifying variability in PLAs, (ii)\u00a0documenting PLA knowledge, and (iii\u00a0\u2026", "num_citations": "38\n", "authors": ["614"]}
{"title": "Large-scale smart grids as system of systems\n", "abstract": " Smart Grids are advanced power networks that introduce intelligent management, control, and operation systems to address the new challenges generated by the growing energy demand and the appearance of renewal energies. In the literature, Smart Grids are presented as an exemplar SoS: systems composed of large heterogeneous and independent systems that leverage emergent behavior from their interaction. Smart Grids are currently scaling up the electricity service to millions of customers. These Smart Grids are known as Large-Scale Smart Grids. From the experience in several projects about Large-Scale Smart Grids, this paper defines Large-Scale Smart Grids as a SoS that integrate a set of SoS and conceptualizes the properties of this SoS. In addition, the paper defines the architectural framework for deploying the software architectures of Large-Scale Smart Grid SoS.", "num_citations": "24\n", "authors": ["614"]}
{"title": "Self-service cybersecurity monitoring as enabler for devsecops\n", "abstract": " Current IoT systems are highly distributed systems that integrate cloud, edge, and fog computing approaches depending on where intelligence and processing capabilities are allocated. This distribution and heterogeneity make development and deployment pipelines very complex and fragmented with multiple delivery endpoints above hardware. This fact prevents rapid development and makes the operation and monitoring of production systems a difficult and tedious task, including cybersecurity event monitoring. The DevSecOps can be defined as a cultural approach to improve and accelerate the delivery of business value by making dev/sec/ops teams' collaboration effective. This paper focuses on self-service cybersecurity monitoring as an enabler to introduce security practices in a DevOps environment. To that end, we have defined and formalized an activity that supports `Fast and Continuous Feedback from\u00a0\u2026", "num_citations": "23\n", "authors": ["614"]}
{"title": "A model-driven engineering process for autonomic sensor-actuator networks\n", "abstract": " Cyber-Physical Systems (CPS) are the next generation of embedded ICT systems designed to be aware of the physical environment by using sensor-actuator networks to provide users with a wide range of smart applications and services. Many of these smart applications are possible due to the incorporation of autonomic control loops that implement advanced processing and analysis of historical and real-time data measured by sensors; plan actions according to a set of goals or policies; and execute plans through actuators. The complexity of this kind of systems requires mechanisms that can assist the system's design and development. This paper presents a solution for assisting the design and development of CPS based on Model-Driven Development: MindCPS (doMaIN moDel for CPS) solution. MindCPS solution is based on a model that provides modelling primitives for explicitly specifying the autonomic\u00a0\u2026", "num_citations": "22\n", "authors": ["614"]}
{"title": "A model for tracing variability from features to product-line architectures: a case study in smart grids\n", "abstract": " In current software systems with highly volatile requirements, traceability plays a key role to maintain the consistency between requirements and code. Traceability between artifacts involved in the development of software product line (SPL) is still more critical because it is necessary to guarantee that the selection of variants that realize the different SPL products meet the requirements. Current SPL traceability mechanisms trace from variability in features to variations in the configuration of product-line architecture (PLA) in terms of adding and removing components. However, it is not always possible to materialize the variable features of a SPL through adding or removing components, since sometimes they are materialized inside components, i.e., in part of their functionality: a class, a service, and/or an interface. Additionally, variations that happen inside components may crosscut several components of\u00a0\u2026", "num_citations": "21\n", "authors": ["614"]}
{"title": "Tailoring the Scrum Development Process to Address Agile Product Line Engineering\n", "abstract": " Software Product Line Engineering (SPLE) is becoming widely used due to the improvement it means when developing software products of the same family. However, SPLE demands long-term investment on a product-line platform that might not be profitable due to rapid changing business settings. Since Agile Software Development (ASD) approaches are being successfully applied in volatile markets, several companies have suggested the idea of integrating SPLE and ASD when a family product has to be developed. Agile Product Line Engineering (APLE) advocates the integration of SPLE and ASD to address their lacks when they are individually applied to software development. A previous literature review of experiences and practices on APLE revealed important challenges about how to fully put APLE into practice. Our contribution address several of these challenges by tailoring the agile method Scrum by means of three concepts that we have defined: plastic partial components, working PL-architectures, and reflective reuse.", "num_citations": "21\n", "authors": ["614"]}
{"title": "Guiding flexibility investment in agile architecting\n", "abstract": " Agile software development pursues to deal with continuous change. But software product architectures without enough flexibility can restrict how products cope with change. However, designing for flexibility often entails high costs and risk that comes with the assumption that change will happen. Actually, in software architecture the flexibility investment decision making problem has become challenging. This paper presents a process to assist architects in Making decisions about Flexibility investment in Software Architecture (MAKE Flexi). MAKE Flexi is based on technical debt and real options approaches. Technical debt allows for estimating the additional cost derived from the lack of flexibility in software architectures, whereas the real options valuation allows for estimating the value of the flexibility that a design option could provide. MAKE Flexi has been applied to an industry project for smart grids to assist\u00a0\u2026", "num_citations": "19\n", "authors": ["614"]}
{"title": "Towards a reference architecture for large-scale smart grids system of systems\n", "abstract": " Large-Scale Smart Grids are advanced power networks that introduce intelligent management, control, and operation systems to service electricity to millions of customers and to combine traditional and renewal energies. Large-Scale Smart Grids are presented as an exemplar of System of System (SoS), since they are composed of large heterogeneous and independent systems that leverage emergent behavior from their interaction. The architectural framework of a Large-Scale Smart Grid SoS is composed of two main dimensions: the systems dimension, which is composed by the systems of the Large-Scale Smart Grid SoS, and the functional dimension, which is composed by the common functionality that these systems have to provide. In this paper, we present an architecture for Large-Scale Smart Grid SoS based on our previous experience in several industrial projects. This architecture decomposes these two\u00a0\u2026", "num_citations": "18\n", "authors": ["614"]}
{"title": "Flexible Working Architectures: Agile Architecting Using PPCs\n", "abstract": " Software systems need software architectures to improve their scalability and maintenance. However, many agile practitioners claim that the upfront design of software architectures is an investment that does not pay off, since customers can rarely appreciate the value delivered by architectures. Furthermore, conventional architectural practices may be considered unacceptable from the Agile values and principles perspective. In this paper, the development of working architectures in agile iterations is presented as an attempt to solve the problem of designing software architectures in Agile. This contribution is based on the new concept of Plastic Partial Component (PPC). PPCs are highly malleable components that can be partially described, what increases the flexibility of architecture design. PPCs based architectures let reinforce some of the agile values and principles. Our experience of putting this\u00a0\u2026", "num_citations": "18\n", "authors": ["614"]}
{"title": "Change-impact driven agile architecting\n", "abstract": " Software architecture is a key factor to scale up Agile Software Development (ASD) in large software-intensive systems. Currently, software architectures are more often approached through mechanisms that enable to incrementally design and evolve software architectures (aka. agile architecting). Agile architecting should be a light-weight decision-making process, which could be achieved by providing knowledge to assist agile architects in reasoning about changes. This paper presents the novel solution of using change-impact knowledge as the main driver for agile architecting. The solution consists of a Change Impact Analysis technique and a set of models to assist agile architects in the change (decision-making) process by retrieving the change-impact architectural knowledge resulting from adding or changing features iteration after iteration. To validate our approach, we have put our solution into practice by\u00a0\u2026", "num_citations": "15\n", "authors": ["614"]}
{"title": "Software product line engineering approach for enhancing agile methodologies\n", "abstract": " One of the main principles of Agile methodologies consists in the early and continuous delivery of valuable software by short time-framed iterations. After each iteration, a working product is delivered according to the requirements defined at the beginning of the iteration. Testing tools facilitate the task of checking if the system provides the expected behavior according to the specified requirements. However, since testing tools need to be adapted in order to test new working products in each iteration, a significant effort has to be invested. This work presents a Software Product Line Engineering (SPLE) approach that allows flexibility in the adaption of testing tools with the working products in an iterative way. A case study is also presented using PLUM (Product Line Unified Modeller) as the tool suite for SPL implementation and management.", "num_citations": "12\n", "authors": ["614"]}
{"title": "DevOps in practice: an exploratory case study\n", "abstract": " DevOps is a cultural movement and technical solution that plays a fundamental role for software-intensive organizations whose business greatly depends on how efficient development and operation are. DevOps is relatively recent, and thus little is known about best practices and the real value and barriers associated with DevOps in industry. To conduct an analysis on practicing DevOps in various software development companies in order to provide patterns of DevOps practices and identify their benefits and barriers. An exploratory case study based on the interviews to relevant stakeholders of 11 (multinational) software-intensive companies. The study is currently ongoing. This study aims to help practitioners and researchers to better understand some DevOps improvement practices as well as real DevOps projects and the contexts where the practices worked, and benefits and barriers appeared. This, hopefully\u00a0\u2026", "num_citations": "11\n", "authors": ["614"]}
{"title": "Conceptualizing a framework for cyber-physical systems of systems development and deployment\n", "abstract": " Cyber-physical systems (CPS) refer to the next generation of embedded ICT systems that are interconnected, collaborative and that provide users and businesses with a wide range of smart applications and services. Software in CPS applications ranges from small systems to large systems, aka. Systems of Systems (SoS), such as smart grids and cities. CPSoS require managing massive amounts of data, being aware of their emerging behavior, and scaling out to progressively evolve and add new systems. Cloud computing supports processing and storing massive amounts of data, hosting and delivering services, and configuring self-provisioned resources. Therefore, cloud computing is the natural candidate to solve CPSoS needs. However, the diversity of platforms and the low-level cloud programming models make difficult to find a common solution for the development and deployment of CPSoS. This paper\u00a0\u2026", "num_citations": "11\n", "authors": ["614"]}
{"title": "Why are many businesses instilling a DevOps culture into their organization?\n", "abstract": " ObjectiveThis paper aims to help practitioners and researchers to better understand the context and the problems that many companies face day to day in their organizations when they try to accelerate software delivery and the main drivers that move these companies to adopting DevOps.MethodWe conducted an exploratory study by leveraging in depth, semi-structured interviews to relevant stakeholders of 30 multinational software-intensive companies, together with industrial workshops and observations at organizations\u2019 facilities that supported triangulation. Additionally, we conducted an inter-coder agreement analysis, which is not usually addressed in qualitative studies in software engineering, to increase reliability and reduce authors bias of the drawn findings.ResultsThe research explores the problems and expected outcomes that moved companies to adopt DevOps and reveals a set of patterns and anti\u00a0\u2026", "num_citations": "10\n", "authors": ["614"]}
{"title": "Systematic literature reviews in software engineering\u2014Enhancement of the study selection process using Cohen\u2019s kappa statistic\n", "abstract": " Abstract Context: Systematic literature reviews (SLRs) rely on a rigorous and auditable methodology for minimizing biases and ensuring reliability. A common kind of bias arises when selecting studies using a set of inclusion/exclusion criteria. This bias can be decreased through dual revision, which makes the selection process more time-consuming and remains prone to generating bias depending on how each researcher interprets the inclusion/exclusion criteria. Objective: To reduce the bias and time spent in the study selection process, this paper presents a process for selecting studies based on the use of Cohen\u2019s Kappa statistic. We have defined an iterative process based on the use of this statistic during which the criteria are refined until obtain almost perfect agreement (k> 0.8). At this point, the two researchers interpret the selection criteria in the same way, and thus, the bias is reduced. Starting from this\u00a0\u2026", "num_citations": "10\n", "authors": ["614"]}
{"title": "DevOps for IoT systems: Fast and continuous monitoring feedback of system availability\n", "abstract": " Current Internet-of-Things (IoT) systems are highly distributed systems, which integrate cloud, fog, and edge computing approaches. Accelerating their maintenance and continuous improvement, while ensuring their availability, is complex. DevOps promotes fast and continuous feedback from operations to development to detect problems before customers are impacted, among other benefits. However, there is not any formal definition of how to do this. This article defines the \u201cfast and continuous monitoring feedback of system availability\u201d activity (F&CF availability) that supports automatic and continuous monitoring feedback from operations to the development of the IoT system availability. This activity has been formalized through the software and systems process engineering metamodel (SPEM). Its implementation is demonstrated in a real scenario that provides evidence that the formalization of the F&CF\u00a0\u2026", "num_citations": "10\n", "authors": ["614"]}
{"title": "A generic gateway for testing heterogeneous components in acceptance testing tools\n", "abstract": " Acceptance testing tools and Systems Under Test (SUT) require a gateway that will set up the communication link between them. Nevertheless, SUTs are often large systems composed of heterogeneous components that are executed in heterogeneous networks and platforms. Therefore, a non trivial communication problem between testing tools and these SUT heterogeneous components arises. A significant effort is invested in designing and implementing gateways for each specific component interface to cope with heterogeneity. This problem may be addressed through the use of middleware technologies that hide heterogeneity. However, this solution is too specific for each SUT domain. It may require a noteworthy effort to support the wide range of currently available interface standards that are provided by the different platforms and networks. An approach for testing heterogeneous components based on a\u00a0\u2026", "num_citations": "10\n", "authors": ["614"]}
{"title": "Software architectures for health care cyber\u2010physical systems: A systematic literature review\n", "abstract": " Cyber\u2010physical systems (CPS) refer to the next generation of Information and Communication Technology systems that mainly integrate sensing, computing, and communication to monitor, control, and interact with a physical process to provide citizens and businesses with smart applications and services: health care, smart homes, smart cities, and so on. In recent years, health care has become one of the most important services due to the continuous increases in its costs. This has motivated extensive research on health care CPS, and some of that research has focused on describing the software architecture behind these systems. However, there is no secondary study to consolidate the research. This paper aims to identify and compare existing research on software architectures for health care CPS in order to determine successful solutions that could guide other architects and practitioners in their health care\u00a0\u2026", "num_citations": "9\n", "authors": ["614"]}
{"title": "Self-Balancing Distributed Energy in Power Grids: An Architecture Based on Autonomic Computing\n", "abstract": " The management of distributed and intermittent energy generation is a critical challenge within the power domain. This challenge has emerged due to the increase of distributed and renewable energy resources in power networks. Smart Grids are a solution to integrate intermittent and dispersed renewable energy and to increase energy efficiency through the introduction of Information and Communication Technologies. However, Smart Grids require new and innovative models, and software architectures that enable Smart Grids to operate in an intelligent and self-managing way. To deal with the intelligent operation of power grids, this paper presents a reference architecture for autonomic power grids. Specifically, this paper focuses on the capability of self-balancing distributed and intermittent energy. It illustrates how this self-balancing capability is implemented and its usefulness for a scenario of a microgrid\u00a0\u2026", "num_citations": "9\n", "authors": ["614"]}
{"title": "Devops in practice\u2013a preliminary analysis of two multinational companies\n", "abstract": " DevOps is a cultural movement that aims the collaboration of all the stakeholders involved in the development, deployment and operation of software to deliver a quality product or service in the shortest possible time. DevOps is relatively recent, and companies have developed their DevOps practices largely from scratch. Our research aims to conduct an analysis on practicing DevOps in +20 software-intensive companies to provide patterns of DevOps practices and identify their benefits and barriers. This paper presents the preliminary analysis of an exploratory case study based on the interviews to relevant stakeholders of two (multinational) companies. The results show the benefits (software delivery performance) and barriers that these companies are dealing with, as well as DevOps team topology they approached during their DevOps transformation. This study aims to help practitioners and researchers\u00a0\u2026", "num_citations": "8\n", "authors": ["614"]}
{"title": "Analyzing software product innovation assessment by using a systematic literature review\n", "abstract": " Innovation is a driver of global economy growth. Software intensive systems (SiSs) are embedded in the systems of various leading sectors, such as the automotive, robotics, and mobile phone industries and they are creating new opportunities for innovation. However, SiSs are affected by a rapidly changing market and a reduced time to market. Software product innovation assessment is becoming important because firms need to know as soon as possible if their products are aligned with the market and customer demands. However, this is not a simple process. To identify the existing assessment schemas applicable to software product innovation, we have undertaken a systematic literature review. We found no studies specific to the development of software, but several approaches for products in general are applicable to software even when no one finding is conclusive. Therefore, this is just the first stage for\u00a0\u2026", "num_citations": "7\n", "authors": ["614"]}
{"title": "An open tool for assisting in technical debt management\n", "abstract": " Technical debt monitoring is one of the activities that have to be performed in technical debt management. To do that, there are different techniques that can be used to estimate technical debt and different tools that implement those different techniques. This paper presents TEDMA Tool, a tool for monitoring technical debt over the software evolution and that it is open to integrate third party tools. TEDMA is based on the analysis of source code repositories and is useful for researching using empirical data extracted from software projects. Currently, it is been used to analyze big projects in the execution of several case studies. The expected evolution of TEDMA will make the tool useful for software development industry.", "num_citations": "6\n", "authors": ["614"]}
{"title": "A framework for positioning and assessing innovation capability from an organizational perspective\n", "abstract": " The evolution of a new information society and new technologies has led to the involvement of organizations in a highly competitive business market where innovation plays a key role. Improving the understanding of the innovation process will help organizations bring more competitive solutions to society more promptly. Currently, there are still too few mechanisms that help organizations to model innovation knowledge and measure their innovation capability. To deal with this gap, this paper presents the Innovation Capability Framework that models innovation knowledge and assesses the innovation capability of organizations for guiding future innovation processes. This framework comprises a conceptual model, a graphical modeling language, and an Innovation Positioning System (IPS), which are supported by an Inno Modeling Tool (InnoTool). Modeling capabilities and the IPS mechanism have been\u00a0\u2026", "num_citations": "6\n", "authors": ["614"]}
{"title": "A process for documenting variability design rationale of flexible and adaptive PLAs\n", "abstract": " Variability is a means for evolution of component-based architectures, driving flexible and adaptive architectures. In recent years, researches have emphasized the need for documenting architectural knowledge to maintain and evolve software, i.e. the need for documenting not only the design of the solution, but also the decisions driving the design and their rationale. However, few approaches document the architectural knowledge behind variability, known as variability design rationale. This paper presents the process for documenting variability design rationale of flexible and adaptive architectures alongside their architectural description. This process is supported by the metamodels Flexible-PLA and Product-Line Architectural Knowledge which define the modeling primitives to completely describe the structure of product-line architectures and to document variability design rationale, respectively. The\u00a0\u2026", "num_citations": "6\n", "authors": ["614"]}
{"title": "Model-to-code transformation from product-line architecture models to aspectj\n", "abstract": " Software Product Line Engineering has significant advantages in family-based software development. The common and variable structure for all products of a family is defined through a Product-Line Architecture (PLA) that consists of a common set of reusable components and connectors which can be configured to build the different products. The design of PLA requires solutions for capturing such configuration (variability). The Flexible-PLA Model is a solution that supports the specification of external variability of the PLA configuration, as well as internal variability of components. However, a complete support for product-line development requires translating architecture specifications into code. This complex task needs automation to avoid human error. Since Model-Driven Development allows automatic code generation from models, this paper presents a solution to automatically generate AspectJ code from\u00a0\u2026", "num_citations": "4\n", "authors": ["614"]}
{"title": "A systematic process for implementing gateways for test tools\n", "abstract": " Test automation is facing a new challenge because tools, as well as having to provide conventional test functionalities, must be capable to interact with ever more heterogeneous complex systems under test (SUT). The number of existing software interfaces to access these systems is also a growing number. The problem cannot be analyzed only from a technical or engineering perspective; the economic perspective is as important. This paper presents a process to systematically implement gateways which support the communication between test tools and SUTs with a reduced cost. The proposed solution does not preclude any interface protocol at the SUT side. This process is supported using a generic architecture of a gateway defined on top of OSGi. Any test tool can communicate with the gateway through a unique defined interface. To communicate the gateway and the SUT, basically, the driver corresponding\u00a0\u2026", "num_citations": "4\n", "authors": ["614"]}
{"title": "Agile Software Architecture: Chapter 9. Bridging User Stories and Software Architecture: A Tailored Scrum for Agile Architecting\n", "abstract": " Agile architecting is a key issue to scale agile to develop large software systems. This chapter describes a set of mechanisms that make agile architecting feasible. These mechanisms are smoothly integrated in a tailored Scrum for agile architecting by (1) defining product requirements in terms of features by using feature pools and feature trees to provide the portfolio and roadmap visions of a product,(2) designing highly flexible architecture called working architecture,(3) bridging user stories and software architecture through features and design decisions as traceability mechanisms, and (4) systematically assisting agile practitioners by conducting change impact analysis of features through various iterations of the agile process. This tailored Scrum for agile architecting has been successfully put into practice to develop several projects, which have been deployed in a software factory set up in collaboration between the Technical University of Madrid (UPM) and the company Indra. In this chapter, one of these projects is used to illustrate how this tailored Scrum has been applied and how it can be adopted.", "num_citations": "3\n", "authors": ["614"]}
{"title": "TOPEN data model and analysis for systems validation\n", "abstract": " TOPEN Data Model and Analysis for Systems Validation Page 1 TOPEN Data Model and Analysis for Systems Validation STV06 - Potsdam, March 30th, 2006 TOPEN Data Model and Analysis for Systems Validation Pedro P. Alarc\u00f3n Juan Garbajosa Agust\u00edn Yag\u00fce Jessica D\u00edaz Universidad Polit\u00e9cnica de Madrid (Technical University of Madrid) System and Software Technology Group http://syst.eui.upm.es (speaker) Page 2 TOPEN Data Model and Analysis for Systems Validation STV06 - Potsdam, March 30th, 2006 Contents \u220e TOPEN testing environment \u220e TOPEN data model \u220e System Under Test \u220e Test procedures specification and execution \u220e Tests results evaluation \u220e Conclusions Page 3 TOPEN Data Model and Analysis for Systems Validation STV06 - Potsdam, March 30th, 2006 TOPEN Environment \u220e Test and OPeration ENvironment: TOPEN \u220e Features \u220e Assists the process of defining and executing tests \u2026", "num_citations": "3\n", "authors": ["614"]}
{"title": "DevOps Research-based Teaching Using Qualitative Research and Inter-Coder Agreement\n", "abstract": " DevOps is becoming a main competency required by the software industry. However, academic institutions have been slow to provide DevOps training in software engineering (SE) curricula. One reason for this is the fact that problems addressed by DevOps may be hard to understand to students who have not previously worked in the industry or on projects of meaningful size and complexity. This paper shows an experience that integrates DevOps in SE curricula through research-based teaching (RBT). We aim to expose students to the problems that have led companies to adopt DevOps by researching and analyzing real cases of companies, thereby placing students at the center of learning. The contribution of this work is to innovate the application of RBT in software engineering by using (i) qualitative analysis, specifically coding techniques, to discover knowledge and (ii) inter-coder agreement (ICA), specifically\u00a0\u2026", "num_citations": "2\n", "authors": ["614"]}
{"title": "Estudio del Soporte a la Variabilidad en la Nube en un entorno con Multitenencia: Plataforma GPaaS\n", "abstract": " Los requisitos de la sociedad actual y la nueva era de Internet de las Cosas (Internet of Things, IoT), entre otros m\u00faltiples factores, explican el auge del software como servicio (Software as a Service, SaaS)) y el paradigma de computaci\u00f3n en la nube (Cloud Computing). La tendencia en el desarrollo software apunta hacia la producci\u00f3n de software cada vez m\u00e1s flexible, din\u00e1mico y personalizado, que a su vez, es accesible a trav\u00e9s de Internet (off-premises), sin necesidad de ser instalado y gestionado localmente (on-premises). Una de las propiedades clave de Cloud Computing es la multitenencia: la instanciaci\u00f3n de varias ocurrencias software a partir de una aplicaci\u00f3n base o recursos compartidos. En este art\u00edculo se presenta:(i) un estudio de la multitenencia y el soporte a la variabilidad en la nube; y (ii) una experiencia de desarrollo SaaS cuyo objetivo es analizar la capacidad de la multitenencia para soportar la flexibilidad, adaptabilidad y variabilidad del software en la nube, as\u00ed como sus limitaciones, con el fin identificar l\u00edneas de investigaci\u00f3n futuras. En particular, el estudio y an\u00e1lisis se ha realizado en los laboratorios de la iSmart Software Factory (iSSSF) de la Universidad Polit\u00e9cnica de Madrid (UM) utilizando la plataforma en la nube de Minsait (Indra), llamada GPaaS,", "num_citations": "2\n", "authors": ["614"]}
{"title": "Continuous delivery of customized SaaS edge applications in highly distributed IoT systems\n", "abstract": " Edge computing is a reality for the current IoT systems that need fast processing and quick response time to make real-time decisions and IoT systems without permanent connectivity to the cloud (e.g., car manufacturing, precision agriculture, or cattle raising). Additionally, these industries are facing the need for rapid and continuous innovation by accelerating the delivery of over-the-air (OTA) software updates in edge devices. DevOps promotes collaboration between development and operation teams and automation at all steps of software construction to achieve continuous delivery (CD) of business value. Although DevOps has demonstrated numerous successful cases in the Web domain, in the IoT domain and, more specifically, at the edge, there are few reported cases. This work presents a success case of CD of customized software as a service software as a service (SaaS) updates at the IoT Edge. This may\u00a0\u2026", "num_citations": "2\n", "authors": ["614"]}
{"title": "Modeling product-line architectural knowledge\n", "abstract": " The documentation of architectural knowledge helps to understand and prevent the violation of previous decisions. Documenting the architectural knowledge of product lines is more complex than in the case of single-product architectures because it requires considering the existing variability in a product family. This implies having the capability to describe design decisions and relationships related to variability. This paper presents the concept of Product-Line Architectural Knowledge (PLAK): the knowledge of product line architecture and its variability. This concept has been realized through a solution based on models and traceability between models called the PLAK Model.", "num_citations": "2\n", "authors": ["614"]}
{"title": "Un primer paso a la agilidad: retrospectivas para el aprendizaje de la Ingenier\u00eda del SW\n", "abstract": " En los \u00faltimos a\u00f1os la industria software demanda, cada vez m\u00e1s, ingenieros que posean conocimientos y experiencia en la aplicaci\u00f3n de metodolog\u00edas \u00e1giles. Los principios y valores en los que se basan las metodolog\u00edas \u00e1giles fomentan la adquisici\u00f3n de competencias como la capacidad de organizaci\u00f3n, el trabajo en equipo, la comunicaci\u00f3n, o el liderazgo, entre otras, denominadas en el marco del Espacio Europeo de Educaci\u00f3n Superior (EEES) como competencias generales o transversales. Ambas razones justifican la adopci\u00f3n de las metodolog\u00edas \u00e1giles como m\u00e9todos de aprendizaje activos, es decir, la implantaci\u00f3n de metodolog\u00edas \u00e1giles durante el ciclo formativo del ingeniero software. Esta apuesta se ha materializado en el proyecto de innovaci\u00f3n educativa Agile Learning Aprendizaje \u00e1gil, cuyos primeros pasos, resultados y lecciones aprendidas se presentan en este art\u00edculo.", "num_citations": "2\n", "authors": ["614"]}
{"title": "An\u00e1lisis emp\u00edrico del papel de las competencias generales en el marco de los estudios superiores\n", "abstract": " En plena implantaci\u00f3n de los nuevos planes de estudio de acuerdo al EEES, las universidades se enfrentan a un nuevo modelo educativo basado en competencias: competencias espec\u00edficas y competencias generales. Las competencias espec\u00edficas est\u00e1n asociadas a la adquisici\u00f3n y desarrollo de conocimientos de un \u00e1rea en particular, mientras que las competencias generales son transversales al plan de estudios y definen capacidades, habilidades y/o aptitudes que el alumno debe desarrollar para aplicarlas a lo largo de su carrera profesional. El objetivo de este trabajo es proporcionar una gu\u00eda al docente sobre las posibles mejoras para tratar el mayor n\u00famero de competencias generales satisfactoriamente. Concretamente, se ha analizado la manera en la que los docentes est\u00e1n promoviendo y desarrollando las competencias generales con el objetivo de detectar carencias, mejoras y necesidades. El an\u00e1lisis se ha realizado sobre el profesorado de la Titulaci\u00f3n de Graduado en Ingenier\u00eda del Software de la Universidad Polit\u00e9cnica de Madrid.", "num_citations": "2\n", "authors": ["614"]}
{"title": "A traceability semantics approach for supporting product value analysis\n", "abstract": " Product requirements prioritization approaches identify the most valuable requirements according to customer value, requirements risk, volatility, cost or other market parameters. However, it is still a challenge in Value-Based Engineering to manage the requirement values for incrementing the product value. The analysis of the product value requires a better understanding of interdependencies among various artifacts of the software development lifecycle, particularly, requires to get a better understanding of how the value chain is preserved from the problem space to the solution space. In this position paper our aim is to study the feasibility of using traceability as the backbone to preserve the value chain between the prioritized product requirements and the product architecture. We propose traceability semantics to address this aim. Some initial findings from our research are presented.", "num_citations": "2\n", "authors": ["614"]}
{"title": "Estudio sobre la correspondencia entre pr\u00e1cticas CMMI y pr\u00e1cticas \u00e1giles y su aplicaci\u00f3n en PYMES\n", "abstract": " El Modelo de Madurez y Capacidad integrado (Capability Maturity Model Integration -CMMI) ha sido adoptado en grandes compa\u00f1\u00edas muy ventajosamente para dar lugar a mejoras en la calidad de los procesos y los productos, cumplimiento de los presupuestos, y satisfacci\u00f3n de los clientes. Sin embargo, las estrategias de Mejora de Procesos Software (Software Process Improvement \u2013 SPI) basadas en CMMI for Development (CMMI-DEV) requieren de procesos de desarrollo software \u201cpesados\u201d y una gran inversi\u00f3n en t\u00e9rminos de coste y tiempo que muchas peque\u00f1as y medianas compa\u00f1\u00edas no pueden asumir. Aun pudiendo permit\u00edrselo, una gran organizaci\u00f3n necesita de un largo camino para llegar a una madurez en los procesos.  Los procesos de desarrollo \u00e1gil de software como Agile Software Development (ASD) tratan de superar estos desaf\u00edos. ASD realiza un especial \u00e9nfasis en el desarrollo incremental del software con iteraciones muy cortas, promoci\u00f3n de la colaboraci\u00f3n con el cliente y dentro del equipo de desarrollo, simplicidad, planificaci\u00f3n flexible y adaptable, y creaci\u00f3n de productos que tengan un valor claro para el cliente intentando prescindir de aquellas caracter\u00edsticas que no aportan valor.  La producci\u00f3n \u00e1gil de software representa un cambio de paradigma en la industria, demostrando su efectividad en entornos turbulentos y en proyectos con requerimientos muy cambiantes. Ser\u00eda m\u00e1s que conveniente ser capaces de introducir m\u00e9todos \u00e1giles como Scrum o XP conforme a un modelo de procesos como CMMI. Por ello, esta tesis tiene como objetivo principal realizar un estudio sobre la relaci\u00f3n de correspondencia\u00a0\u2026", "num_citations": "2\n", "authors": ["614"]}
{"title": "A Cost-Benefit Analysis Model for Technical Debt Management Considering Uncertainty and Time\n", "abstract": " In the last few years, technical debt [1] has been used as a useful means for making the intrinsic cost of the internal software quality weaknesses visible. This visibility is made possible by quantifying this cost. Specifically, technical debt is expressed in terms of two main concepts: principal and interest [2]. The principal is the cost of eliminating\u2014or reducing\u2014the impact of a, so called, technical debt item in a software system; whereas the interest is the recurring cost, over a time period, of not eliminating a technical debt item. Previous works about technical debt [2] are mainly focused on estimating principal and interest, and on performing a cost-benefit analysis. This cost-benefit analysis allows one to determine if to remove technical debt is profitable and to prioritize which items incurring in technical debt should be fixed first. Nevertheless, for these previous works technical debt is flat along the time. However the introduction of new factors to estimate technical debt may produce non flat models that allow us to produce more accurate predictions. These factors should be used to estimate principal and interest, and to perform costbenefit analysis related to technical debt. In this paper, we take a step forward introducing the uncertainty about the interest, and the time frame factors so that it becomes possible to depict a number of possible future scenarios. Estimations obtained without considering the possible evolution of the interest over time may be less accurate as they consider simplistic scenarios without changes. This assertion is elaborated in the following paragraphs within this section.Interest uncertainty is the probability that no extra cost is derived\u00a0\u2026", "num_citations": "1\n", "authors": ["614"]}
{"title": "Designing and simulating smart grids\n", "abstract": " Growing energy demands and the increased use of renewal energies have changed the landscape of power networks leading to new challenges. Smart Grids have emerged to cope with these challenges by facilitating the integration of traditional and renewable energy resources in distributed, open, and self-managed ways. Innovative models are needed to design energy infrastructures that can enable self-management of the power grid. Software architectures smoothly integrate the software that provides self-management to Smart Grids and their hardware infrastructures. We present a framework to design the software architectures of autonomous Smart Grids in an intuitive domain-oriented way and to simulate their execution by automatically generating the code from the designed autonomous smart grid architectures.", "num_citations": "1\n", "authors": ["614"]}
{"title": "Prioritization of features in agile product line engineering\n", "abstract": " Agile Software Development (ASD) and Software Product Line Engineering (SPLE) methodologies have proved significant benefits in software development. Although they pursue common promises (faster time-to-market, better quality and lower cost), many of their foundations are completely different. ASD focuses on requirements at hand and proposes continuous delivery of valuable software by short time-framed iterations.Instead, SPLE exploits the commonality across the products of a same family by investing on an upfront design of reusable assets (domain engineering) which are assembled into customer-specific products (application engineering).", "num_citations": "1\n", "authors": ["614"]}