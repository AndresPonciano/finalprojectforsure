{"title": "Patterns in property specifications for finite-state verification\n", "abstract": " Despite the automation, users of finite-state verification tools still must be able to specify the system requirements in the specification language of the tool. This is more challenging than it might at first appear. For example, consider the following requirement for an elevator: Between the time an elevator is called at a floor and the time it opens its doors at that floor, the elevator can arrive at that floor\u2019at most twice. To verify this property with a linear temporal logic (LTL) model checker, a developer would have to translate this informal requirement into the following LTL formula: q ((cal1 A Oopen)+", "num_citations": "1901\n", "authors": ["1627"]}
{"title": "Property specification patterns for finite-state verification\n", "abstract": " Finite-state verification(eg, model checking) provides a powerful means to detect errors that are often subtle and difficult to reproduce. Nevertheless, the transition of this technology from research to practice has been slow. While there are a number of potential causes for reluctance in adopting such formal methods in practice, we believe that a primary cause rests with the fact that practitioners are unfamiliar with specification processes, notations, and strategies. Recent years have seen growing success in leveraging experience with design and coding patterns. We propose a pattern-based approach to the presentation, codification and reuse of property specifications for finite-state verification.", "num_citations": "660\n", "authors": ["1627"]}
{"title": "Single-peaked functions and the theory of preference.\n", "abstract": " Dependent variables such as preference, hedonic tone, aesthetic appreciation, stimulus generalization, degree of interest or attention, exploratory behavior, developmental stages, and intensity of attitudes are frequently observed to be single-peaked functions of the independent variables. The problem of deriving, from more elementary underlying processes, a preference function that rises monotonically to a peak and then falls monotonically is discussed. Psychological principles are proposed for the perception and processing of good and bad attributes such as pleasure and pain and an elimination principle that affects the options that are available. It is shown that single-peakedness is inevitable if there is only 1 component, is quite likely if there are 2, and must be contrived if there are 3 or more components. Results are generalized for approach-avoidance, approach-approach, and avoidance-avoidance conflict\u00a0\u2026", "num_citations": "483\n", "authors": ["1627"]}
{"title": "The structure of conflict\n", "abstract": " A theory that attempts to bring order to the chaotic variety of conflict usually begins by distinguishing types of conflict and formulating general explanatory principles that relate and integrate them. In contrast to traditional methods, this book describes and explores the structural aspects of different types of conflicts, and discusses the important implications involved for both choosing and achieving methods for resolving conflict. Two important facets of conflict structure are recognized: the individuals involved and the behavioral principles that govern them; and the existence of options and their structural relation.", "num_citations": "183\n", "authors": ["1627"]}
{"title": "Automated analysis of concurrent systems with the constrained expression toolset\n", "abstract": " The constrained expression approach to analysis of concurrent software systems has several attractive features, including the facts that it can be used with a variety of design and programming languages and that it does not require a complete enumeration of the set of reachable states of the concurrent system. This paper reports on the construction of a toolset automating the main constrained expression analysis techniques and the results of experiments with that toolset. The toolset is capable of carrying out completely automated analyses of a variety of concurrent systems, starting from source code in an Ada-like design language and producing system traces displaying the properties represented by the analyst's queries. It has been successfully used with designs that involve hundreds of concurrent processes.", "num_citations": "146\n", "authors": ["1627"]}
{"title": "Quillen stratification for modules\n", "abstract": " Let G be a finite group and ka fixed algebraically closed field of characteristic p> 0. If p is odd, let H (; be the subring of H*(G, k) consisting of elements of even degree; following [20-22] we take H~= H*(G, k) if p= 2, though one could just as well use the subring of elements of even degree for all p. H a is a finitely generated commutative k-algebra [13], and we let Va denote its associated affine variety Max Hc. If M is any finitely generated kG-module, then the cohomology variety Vc (M) of M may be defined as the support in V~ of the H~-module H*(G, M) if G is a p-group, and in general as the largest support of H*(G, L| where L is any kG-module [4, 9]. A module L with each irreducible kG-module as a direct summand will serve. D. Quillen [20-22] proved a number of beautiful results relating V~ to the varieties l/t: associated with the various elementary abelian p-subgroups E of G, culminating in his stratification theorem [20\u00a0\u2026", "num_citations": "146\n", "authors": ["1627"]}
{"title": "An efficient algorithm for computing MHP information for concurrent Java programs\n", "abstract": " Information about which statements in a concurrent program may happen in parallel (MHP) has a number of important applications. It can be used in program optimization, debugging, program understanding tools, improving the accuracy of data flow approaches, and detecting synchronization anomalies, such as data races. In this paper we propose a data flow algorithm for computing a conservative estimate of the MHP information for Java programs that has a worst-case time bound that is cubic in the size of the program.We present a preliminary experimental comparison between our algorithm and a reachability analysis algorithm that determines the \u201cideal\u201d static MHP information for concurrent Java programs. This initial experiment indicates that our data flow algorithm precisely computed the ideal MHP information in the vast majority of cases we examined. In the two out of 29 cases where the MHP\u00a0\u2026", "num_citations": "145\n", "authors": ["1627"]}
{"title": "A conservative data flow algorithm for detecting all pairs of statements that may happen in parallel\n", "abstract": " Information about which pairs of statements in a concurrent program can execute in parallel is important for optimizing and debugging programs, for detecting anomalies, and for improving the accuracy of data flow analysis. In this paper, we describe a new data flow algorithm that finds a conservative approximation of the set of all such pairs. We have carried out an initial comparison of the precision of our algorithm and that of the most precise of the earlier approaches, Masticola and Ryder's non-concurrency analysis [8], using a sample of 159 concurrent Ada programs that includes the collection assembled by Masticola and Ryder. For these examples, our algorithm was almost always more precise than non-concurrency analysis, in the sense that the set of pairs identified by our algorithm as possibly happening in parallel is a proper subset of the set identified by non-concurrency analysis. In 132 cases, we were\u00a0\u2026", "num_citations": "127\n", "authors": ["1627"]}
{"title": "Combining symbolic execution with model checking to verify parallel numerical programs\n", "abstract": " We present a method to verify the correctness of parallel programs that perform complex numerical computations, including computations involving floating-point arithmetic. This method requires that a sequential version of the program be provided, to serve as the specification for the parallel one. The key idea is to use model checking, together with symbolic execution, to establish the equivalence of the two programs. In this approach the path condition from symbolic execution of the sequential program is used to constrain the search through the parallel program. To handle floating-point operations, three different types of equivalence are supported. Several examples are presented, demonstrating the approach and actual errors that were found. Limitations and directions for future research are also described.", "num_citations": "99\n", "authors": ["1627"]}
{"title": "Data flow analysis for checking properties of concurrent Java programs\n", "abstract": " In this paper we show how the FLAVERS data flow analysis technique, originally formulated for systems using a rendezvous concurrency model, can be applied to the various concurrency models used in Java programs. The general approach of FLAVERS is based on modeling a concurrent system as a flow graph and, using a data flow analysis algorithm over this graph, statically checking if a property holds on all (or no) executions of the program. The accuracy of this analysis can be iteratively improved, as needed, by supplying additional constraints, represented as finite state automata, to the data flow analysis algorithm. In this paper we present an approach for analyzing Java programs that uses the constraint mechanism to model the possible communications among threads in Java programs, instead of representing them directly in the flow graph model. We also discuss a number of error-prone thread\u00a0\u2026", "num_citations": "91\n", "authors": ["1627"]}
{"title": "Constrained expressions: Adding analysis capabilities to design methods for concurrent software systems\n", "abstract": " An approach to the design of concurrent software systems based on the constrained expression formalism is described. This formalism provides a rigorous conceptual model for the semantics of concurrent computations, thereby supporting analysis of important system properties as part of the design process. This approach allows designers to use standard specification and design languages, rather than forcing them to deal with the formal model explicitly or directly. As a result, the approach attains the benefits of formal rigor without the associated pain of unnatural concepts or notations for its users. The conceptual model of concurrency underlying the constrained expression formalism treats the collection of possible behaviors of a concurrent system as a set of sequences of events. The constrained expression formalism provides a useful closed-form description of these sequences. Algorithms were developed for\u00a0\u2026", "num_citations": "90\n", "authors": ["1627"]}
{"title": "Breaking up is hard to do: An evaluation of automated assume-guarantee reasoning\n", "abstract": " Finite-state verification techniques are often hampered by the state-explosion problem. One proposed approach for addressing this problem is assume-guarantee reasoning, where a system under analysis is partitioned into subsystems and these subsystems are analyzed individually. By composing the results of these analyses, it can be determined whether or not the system satisfies a property. Because each subsystem is smaller than the whole system, analyzing each subsystem individually may reduce the overall cost of verification. Often the behavior of a subsystem is dependent on the subsystems with which it interacts, and thus it is usually necessary to provide assumptions about the environment in which a subsystem executes. Because developing assumptions has been a difficult manual task, the evaluation of assume-guarantee reasoning has been limited. Using recent advances for automatically\u00a0\u2026", "num_citations": "88\n", "authors": ["1627"]}
{"title": "Using integer programming to verify general safety and liveness properties\n", "abstract": " Analysis of concurrent systems is plagued by the state explosion problem. We describe an analysis technique that uses necessary conditions, in the form of linear inequalities, to verify certain properties of concurrent systems, thus avoiding the enumeration of the potentially explosive number of reachable states of the system. This technique has been shown to be capable of verifying simple safety properties, like freedom from deadlock, that can be expressed in terms of the number of certain events occurring in a finite execution, and has been successfully used to analyze a variety of concurrent software systems. In this paper, we extend the technique to the verification of more complex safety properties that involve the order of events and to the verification of liveness properties, which involve infinite executions.", "num_citations": "86\n", "authors": ["1627"]}
{"title": "User guidance for creating precise and accessible property specifications\n", "abstract": " Property specifications concisely describe aspects of what a system is supposed to do. No matter what notation is used to describe them, however, it is difficult to represent these properties correctly, since there are often subtle, but important, details that need to be considered. Propel aims to guide users through the process of creating properties that are both accessible and mathematically precise, by providing templates for commonly-occurring property patterns. These templates explicitly represent these subtle details as options. In this paper, we present a new representation of these templates, a Question Tree that asks users a hierarchical sequence of questions about their intended properties. The Question Tree representation is particularly useful for helping users select the appropriate template, but it also complements the finite-state automaton and disciplined natural language representations provided by\u00a0\u2026", "num_citations": "85\n", "authors": ["1627"]}
{"title": "Using model checking with symbolic execution to verify parallel numerical programs\n", "abstract": " We present a method to verify the correctness of parallel programs that perform complex numerical computations, including computations involving floating-point arithmetic. The method requires that a sequential version of the program be provided, to serve as the specification for the parallel one. The key idea is to use model checking, together with symbolic execution, to establish the equivalence of the two programs.", "num_citations": "83\n", "authors": ["1627"]}
{"title": "Verification of MPI-based software for scientific computation\n", "abstract": " We explore issues related to the application of finite-state verification techniques to scientific computation software employing the widely-used Message-Passing Interface (MPI). Many of the features of MPI that are important for programmers present significant difficulties for model checking. In this paper, we examine a small parallel program that computes the evolution in time of a discretized function u defined on a 2-dimensional domain and governed by the diffusion equation. Although this example is simple, it makes use of many of the problematic features of MPI. We discuss the modeling of these features and use Spin and INCA to verify several correctness properties for various configurations of this program. Finally, we describe some general theorems that can be used to justify simplifications in finite-state models of MPI programs and that guarantee certain properties must hold for any program using\u00a0\u2026", "num_citations": "67\n", "authors": ["1627"]}
{"title": "Breaking up is hard to do: an investigation of decomposition for assume-guarantee reasoning\n", "abstract": " Finite-state verification techniques are often hampered by the stateexplosion problem. One proposed approach for addressing this problem is assume-guarantee reasoning. Using recent advances in assume-guarantee reasoning that automatically generate assumptions, we undertook a study to determine if assume-guarantee reasoning provides an advantage over monolithic verification. In this study, we considered all two-way decompositions for a set of systems and properties, using two different verifiers, FLAVERS and LTSA. By increasing the number of repeated tasks, we evaluated the decompositions as the systems were scaled. In only a few cases could assume-guarantee reasoning verify properties on larger systems than monolithic verification and, in these cases, assumeguarantee reasoning could only verify these properties on systems a few sizes larger than monolithic verification. This discouraging\u00a0\u2026", "num_citations": "58\n", "authors": ["1627"]}
{"title": "Modeling wildcard-free MPI programs for verification\n", "abstract": " We give several theorems that can be used to substantially reduce the state space that must be considered in applying finite-state verification techniques, such as model checking, to parallel programs written using a subset of MPI. We illustrate the utility of these theorems by applying them to a small but realistic example.", "num_citations": "57\n", "authors": ["1627"]}
{"title": "An empirical comparison of static concurrency analysis techniques\n", "abstract": " Developers of concurrent software need cost-effective analysis techniques to acquire confidence in the reliability of that software. Analysis of concurrent programs is difficult because, in many cases, the patterns of communication among the various parts of the program are complicated and the number of possible communications is large.", "num_citations": "53\n", "authors": ["1627"]}
{"title": "Analyzing partially-implemented real-time systems\n", "abstract": " Most analysis methods for real-time systems assume that all the components of the system are at roughly the same stage of development and can be expressed in a single notation, such as a specification or programming language. There are, however, many situations in which developers would benefit from tools that could analyze partially-implemented systems: those for which some components are given only as high-level specifications while others are fully implemented in a programming language. In this paper, we propose a method for analyzing such partially-implemented real-time systems. We consider real-time concurrent systems for which some components are implemented in Ada and some are partially specified using regular expressions and graphical interval logic (GIL), a real-time temporal logic. We show how to construct models of the partially-implemented systems that account for such properties\u00a0\u2026", "num_citations": "47\n", "authors": ["1627"]}
{"title": "Comparing finite-state verification techniques for concurrent software\n", "abstract": " Finite-state verification provides software developers with a powerful tool to detect errors. Many different analysis techniques have been proposed and implemented, and the limited amount of empirical data available shows that the performance of these techniques varies enormously from system to system. Before this technology can be transferred from research to practice, the community must provide guidance to developers on which methods are best for different kinds of systems. We describe a substantial case study in which several finite-state verification tools were applied to verify properties of the Chiron user interface system, a real Ada program of substantial size. Our study provides important data comparing these different analysis methods, and points out a number of difficulties in conducting fair comparisons of finite-state verification tools.", "num_citations": "39\n", "authors": ["1627"]}
{"title": "Constrained expressions: Toward broad applicability of analysis methods for distributed software systems\n", "abstract": " It is extremely difficult to characterize the possible behaviors of a distributed software system through informal reasoning. Developers of distributed systems require tools that support formal reasoning about properties of the behaviors of their systems. These tools should be applicable to designs and other preimplementation descriptions of a system, as well as to completed programs. Furthermore, they should not limit a developer's choice of development languages. In this paper we present a basis for broadly applicable analysis methods for distributed software systems. The constrained expression formalism can be used with a wide variety of distributed system development notations to give a uniform closed-form representation of a system's behavior. A collection of formal analysis techniques can then be applied with this representation to establish properties of the system. Examples of these formal analysis\u00a0\u2026", "num_citations": "36\n", "authors": ["1627"]}
{"title": "Verification of halting properties for MPI programs using nonblocking operations\n", "abstract": " We show that many important properties of certain MPI programs can be verified by considering only a class of executions in which all communication takes place synchronously. In previous work, we showed that similar results hold for MPI programs that use only blocking communication (and avoid certain other constructs, such as MPI_ANY_SOURCE); in this paper we show that the same conclusions hold for programs that also use the nonblocking functions MPI_ISEND, MPI_IRECV, and MPI_WAIT. These facts can be used to dramatically reduce the number of states explored when using model checking techniques to verify properties such as freedom from deadlock in such programs.", "num_citations": "31\n", "authors": ["1627"]}
{"title": "Annihilators of cohomology modules\n", "abstract": " Let G be a finite group, k a field of characteristic p> 0, and U a kG-module. Recently, Alperin and Evens [l] proved that the complexity of U, a numerical invariant defined in terms of the minimal projective resolution of U, is determined by the restrictions of U to elementary abelian p-subgroups. This result has also been obtained by Carlson [2], as a consequence of a theorem concerning the dimension of the sum of the nonprojective components of such a restriction. In this paper we focus on annihilators of modules for the cohomology ring H*(G, k) and show how to obtain the Alperin-Evens theorem and some of its corollaries from a decomposition theorem for certain ideals.", "num_citations": "31\n", "authors": ["1627"]}
{"title": "A theorem on single-peaked preference functions in one dimension\n", "abstract": " With simple stimuli like amount of sugar in coffee or grade expectations in courses, the preference orders of individuals can be represented by single-peaked functions of an underlying ordering. When stimuli are more complex, as in candidates for office or automobiles, there is usually no natural ordering underlying the stimuli, and hence the preference orders cannot be single-peaked functions in one dimension. Is the existence of an underlying ordering necessary and sufficient to ensure that all preference orders will be single-peaked and if not, just what further conditions must be met? An understanding of the precise mathematical conditions will be useful in the interpretation of preferential choice data and will show experimenters how to essentially guarantee that all subjects will be single-peaked. The theorem presented here is essential to an understanding of the intimate relation between single-peaked functions and preferential choice behavior and deals with the general case of options which may differ in more than two components. The application of the theorem to the special cases of options which differ in only one or two components has been extensively developed and has appeared elsewhere (Coombs & Avrunin, 1977). Given a set of options S, we will assume that each attribute of the options in S which is relevant to the decision process, whether it be a physical, psychological, or social attribute, can be expressed in terms of a numerical scale. We can then represent each option in S as a vector, each component of which corresponds to a particular attribute of the options. Thus we can regard S as a subset of IF for some n depending\u00a0\u2026", "num_citations": "29\n", "authors": ["1627"]}
{"title": "Heuristic-guided counterexample search in FLAVERS\n", "abstract": " One of the benefits of finite-state verification (FSV) tools, such as model checkers, is that a counterexample is provided when the property cannot be verified. Not all counterexamples, however, are equally useful to the analysts trying to understand and localize the fault. Often counterexamples are so long that they are hard to understand. Thus, it is important for FSV tools to find short counterexamples and to do so quickly. Commonly used search strategies, such as breadth-first and depth-first search, do not usually perform well in both of these dimensions. In this paper, we investigate heuristic-guided search strategies for the FSV tool FLAVERS and propose a novel two-stage counterexample search strategy. We describe an experiment showing that this two-stage strategy, when combined with appropriate heuristics, is extremely effective at quickly finding short counterexamples for a large set of verification problems.", "num_citations": "28\n", "authors": ["1627"]}
{"title": "Symbolic model checking using algebraic geometry\n", "abstract": " In this paper, I show that methods from computational algebraic geometry can be used to carry out symbolic model checking using an encoding of Boolean sets as the common zeros of sets of polynomials. This approach could serve as a useful supplement to symbolic model checking methods based on Ordered Binary Decision Diagrams and may provide important theoretical insights by bringing the powerful mathematical machinery of algebraic geometry to bear on the model checking problem.", "num_citations": "28\n", "authors": ["1627"]}
{"title": "Benchmarking finite-state verifiers\n", "abstract": " A variety of largely automated methods have been proposed for finite-state verification of computer systems. Although anecdotal accounts of success are widely reported, there is very little empirical data on the relative strengths and weaknesses of those methods across a broad range of analysis questions and systems. This information, however, is critical for the transfer of the technology from research to practice. We review some of the problems involved in obtaining this information and suggest several ways in which the community can facilitate empirical evaluation of finite-state verification tools.", "num_citations": "27\n", "authors": ["1627"]}
{"title": "Describing and analyzing distributed software system designs\n", "abstract": " In this paper we outline an approach to describing and analyzing designs for distributed software systems. A descriptive notation is introduced, and analysis techniques applicable to designs expressed in that notation are presented. The usefulness of the approach is illustrated by applying it to a realistic distributed software-system design problem involving mutual exclusion in a computer network.", "num_citations": "25\n", "authors": ["1627"]}
{"title": "Automated derivation of time bounds in uniprocessor concurrent systems\n", "abstract": " The successful development of complex real-time systems depends on analysis techniques that can accurately assess the timing properties of those systems. This paper describes a technique for deriving upper and lower bounds on the time that can elapse between two given events in an execution of a concurrent software system running on a single processor under arbitrary scheduling. The technique involves generating linear inequalities expressing conditions that must be satisfied by all executions of such a system and using integer programming methods to find appropriate solutions to the inequalities. The technique does not require construction of the state space of the system and its feasibility has been demonstrated by using an extended version of the constrained expression toolset to analyze the timing properties of some concurrent systems with very large state spaces.< >", "num_citations": "23\n", "authors": ["1627"]}
{"title": "Experiments in automated analysis of concurrent software systems\n", "abstract": " It is unlikely that any single approach to analysis of concurrent software systems will meet all the needs of software developers throughout the development process. Thus, experimental evaluation of different analysis techniques is needed to determine their relative strengths and practical limitations. Such evaluation requires automated tools implementing the analysis techniques. This paper describes a prototype toolset automating the constrained expression approach to the analysis of concurrent software systems. The results of preliminary experiments with the toolset are reported and the implications of these experiments are discussed.", "num_citations": "20\n", "authors": ["1627"]}
{"title": "A practical technique for bounding the time between events in concurrent real-time systems\n", "abstract": " Showing that concurrent systems satisfy timing constraints on their behavior is difficult, but may be essential for critical applications. Most methods are based on some form of reachability analysis and require construction of a state space of size that is, in general, exponential in the number of components in the concurrent system. In an earlier paper with L. K. Dillon and J. E. Wileden, we described a technique for finding bounds on the time between events without enumerating the state space, but the technique applies chiefly to the case of logically concurrent systems executing on a uniprocessor, in which events do not overlap in time. In this paper, we extend that technique to obtain upper bounds on the time between events in maximally parallel concurrent systems. Our method does not require construction of the state space and the results of preliminary experiments show that, for at least some systems with large\u00a0\u2026", "num_citations": "19\n", "authors": ["1627"]}
{"title": "Modeling MPI programs for verification\n", "abstract": " We investigate the application of formal verification techniques to parallel programs that employ the Message Passing Interface (MPI). We develop a formal model sufficient to represent programs that use a particular subset of MPI, and then prove a number of theorems about that model that ameliorate the state explosion problem or that show that certain properties of particular programs must necessarily hold. Most of these theorems require that the programs use neither MPI_ANY_SOURCE nor MPI_ANY_TAG. As an example, we show that for such programs, to verify freedom from deadlock, it suffices to consider only synchronous executions. While our motivation is to prove theorems that make finite state verification techniques more tractable, the same results could also assist theorem-proving or other formal methods.", "num_citations": "18\n", "authors": ["1627"]}
{"title": "From natural language requirements to rigorous property specifications\n", "abstract": " Abstract\u2212 Property specifications concisely describe selected aspects of what a software system is supposed to do. It is surprisingly difficult to write these properties correctly. Although there are rigorous mathematical formalisms for representing properties, these are often difficult to use. No matter what notation is used, however, there are often subtle, but important, details that need to be considered. The PROPEL tool aims to make the job of writing and understanding properties easier by providing templates that explicitly capture these details as options for commonly-occurring property patterns. These templates are represented using \u201cdisciplined\u201d natural language, decision trees, and finite-state automata, allowing the developer to easily move between these representations.", "num_citations": "17\n", "authors": ["1627"]}
{"title": "Analysis of MPI programs\n", "abstract": " We investigate the application of formal verification techniques to parallel programs that employ the Message Passing Interface (MPI). We develop a formal model of a subset of MPI, and then prove a number of theorems about that model that ameliorate or eliminate altogether the state explosion problem. As an example, we show that if one wishes to verify freedom from deadlock, it suffices to consider only synchronous executions.", "num_citations": "16\n", "authors": ["1627"]}
{"title": "Improving the precision of INCA by eliminating solutions with spurious cycles\n", "abstract": " The Inequality Necessary Condition Analyzer (INCA) is a finite-state verification tool that has been able to check properties of some very large concurrent systems. INCA checks a property of a concurrent system by generating a system of inequalities that must have integer solutions if the property can be violated. There may, however, be integer solutions to the inequalities that do not correspond to an execution violating the property. INCA thus accepts the possibility of an inconclusive result in exchange for greater tractability. We describe here a method for eliminating one of the two main sources of these inconclusive results.", "num_citations": "16\n", "authors": ["1627"]}
{"title": "Towards scalable compositional analysis\n", "abstract": " Due to the state explosion problem, analysis of large concurrent programs will undoubtedly require compositional techniques. Existing compositional techniques are based on the idea of replacing complex subsystems with simpler processes with the same interfaces to their environments, and using the simpler processes to analyze the full system. Most algorithms for proving equivalence between two processes, however, require enumerating the states of both processes. When part of a concurrent system consists of many highly coupled processes, it may not be possible to decompose the system into components that are both small enough to enumerate and have simple interfaces with their enviornments. In such cases, analysis of the systems by standard methods will be infeasible.In this paper, we describe a technique for proving trace equivalence of deterministic and divergence-free systems without enumerating\u00a0\u2026", "num_citations": "16\n", "authors": ["1627"]}
{"title": "Toward automating analysis support for developers of distributed software\n", "abstract": " Developing large-srale, reliahle software capable of exploiting the potential of diatribut, ed hardware systenis will demand the support of powerful automated tools, especially analysis tools. Our constrninzd ezpression approach to analyzing such software systems seems to have several advant, ages, including broad applicability and reasonahle effiriency, relat, ive t, o other proposed approarhes. Results of initial experiments with our approarh, based on manual application and preliminary prototypes of some of the needed tools, have been encouraging. They have also demonstrated the need for us, and all researchers working on distributed software analysis, to undertake more extensive experimentation with larger, more realistic examples. In this paper, we report on our initial experimentation with constrained expression analysis and describe our plans for constructing the more robust, flexible and efficient prototype tool implementations needed to support more extensive experimentation.", "num_citations": "16\n", "authors": ["1627"]}
{"title": "Experiments with an improved constrained expression toolset\n", "abstract": " At TAV3, we described a prelimimu-y version of the constrained expression toolset, and reported on the results of our initial experiments with it, Through those experiments we discovered shortcomings in some of the tools that limited the size of the examples that we could analyze. We have since redesigned and reimplementcd several components of the toolset, with performance improvements of more than two orders of magnitude in some cases. The improved toolset has been successfully used with designs that involve hundreds of concurrent processes. In this paper, we describe several experiments with the new version of the toolset, including preliminary experiments with a technique for analyzing systems that include an essentially arbitrary number of identical components.", "num_citations": "15\n", "authors": ["1627"]}
{"title": "Integer programming in the analysis of concurrent systems\n", "abstract": " Large computer systems are frequently organized as collections of cooperating asynchronous processes. Their size and the presence of nondetcrminacy make it extremely dii~ cult to understand and predict the behavior of such systems. Rigorous analysis methods with automated support will therefore be necessary for the production of reliable software. In this paper, we describe a method for generating and solving systems of inequalities that can be used effectively in the analysis of large computer systems. We also briefly discuss our experience in using this approach in the analysis of concurrent system designs written in an Ada-based design language. Underlying our approach to analysis is a model in which each asynchronous process in such a system is represented by a finite state automaton (FSA) accepting a language over an alphabet of symbols corresponding to events occurring in executions of that\u00a0\u2026", "num_citations": "15\n", "authors": ["1627"]}
{"title": "Generic cohomology for twisted groups\n", "abstract": " Let  be a simple algebraic group defined and split over , and let  be a surjective endomorphism of  with finite fixed-point set . We give conditions under which cohomology groups of  are isomorphic to cohomology groups of .", "num_citations": "13\n", "authors": ["1627"]}
{"title": "Development of an interactive dashboard to analyze cognitive workload of surgical teams during complex procedural care\n", "abstract": " In the surgical setting, team members constantly deal with a high-demand operative environment that requires simultaneously processing a large amount of information. In certain situations, high demands imposed by surgical tasks and other sources may exceed team member's cognitive capacity, leading to cognitive overload which may place patient safety at risk. In the present study, we describe a novel approach to integrate an objective measure of team member's cognitive load with procedural, behavioral and contextual data from real-life cardiac surgeries. We used heart rate variability analysis, capturing data simultaneously from multiple team members (surgeon, anesthesiologist and perfusionist) in a real-time and unobtrusive manner. Using audio-video recordings, behavioral coding and a hierarchical surgical process model, we integrated multiple data sources to create an interactive surgical dashboard\u00a0\u2026", "num_citations": "12\n", "authors": ["1627"]}
{"title": "Finite-state verification for high performance computing\n", "abstract": " A glance at the list of the world's most powerful computing systems (top500. org) reveals that high performance computing has become practically synonymous with parallel computing. Yet parallel programs are notoriously difficult to get right. It is hard enough to verify that an ordinary sequential program computes what it is intended to compute, and parallelism introduces an entirely new layer of complexity. Moreover, parallel programs can behave non-deterministically, in the sense that they can produce different results when run with different numbers of processors, or when run on different platforms, and sometimes even when run twice on the same platform. Experience has shown that just to detect or reproduce these problems---let alone to pinpoint their causes and correct them---can be extremely time-consuming and labor-intensive.", "num_citations": "11\n", "authors": ["1627"]}
{"title": "An Automatic Failure Mode and Effect Analysis Technique for Processes Defined in the Little-JIL Process Definition Language.\n", "abstract": " Many processes are safety critical and therefore could benefit from proactive safety analysis techniques that attempt to identify weaknesses of such processes before they are put into use. In this paper, we propose an approach that automatically derives Failure Mode and Effect Analysis (FMEA) information from processes modeled in the Little-JIL process definition language. Typically FMEA information is created manually by skilled experts, an approach that is usually considered to be timeconsuming, error-prone, and tedious when applied to complex processes. Although great care must be taken in creating an accurate process definition, with our approach this definition can then be used to create FMEA representations for a wide range of potential failures. In addition, our approach provides a complementary Fault Tree Analysis (FTA), thereby supporting two of the most widely used safety analysis techniques.", "num_citations": "10\n", "authors": ["1627"]}
{"title": "Process-based derivation of requirements for medical devices\n", "abstract": " One goal of medical device certification is to show that a given medical device satisfies its requirements. The requirements that should be met by a device, however, depend on the medical processes in which the device is to be used. Such processes may be complex and, thus, critical requirements may be specified inaccurately or incompletely, or even missed altogether. We are investigating a requirement derivation approach that takes as input a model of the way the device is used in a particular medical process and a requirement that should be satisfied by that process. This approach tries to produce a derived requirement for the medical device that is sufficient to prevent any violations of the process requirement. Our approach combines a method for generating assumptions for assume-guarantee reasoning with one for interface synthesis to automate the derivation of the medical device requirements. The\u00a0\u2026", "num_citations": "9\n", "authors": ["1627"]}
{"title": "Architectural building blocks for plug-and-play system design\n", "abstract": " One of the distinguishing features of distributed systems is the importance of the interaction mechanisms that are used to define how the sequential components interact with each other. Given the complexity of the behavior that is being described and the large design space of various alternatives, choosing appropriate interaction mechanisms is difficult. In this paper, we propose a component-based specification approach that allows designers to experiment with alternative interaction semantics. Our approach is also integrated with design-time verification to provide feedback about the correctness of the overall system design. In this approach, connectors representing specific interaction semantics are composed from reusable building blocks. Standard communication interfaces for components are defined to reduce the impact of changing interactions on components\u2019 computations. The increased reusability\u00a0\u2026", "num_citations": "9\n", "authors": ["1627"]}
{"title": "Heuristic-based model refinement for FLAVERS\n", "abstract": " FLAVERS is a finite-state verification approach that allows an analyst to incrementally add constraints to improve the precision of the model of the system being analyzed. Except for trivial systems, however, it is impractical to compute which constraints should be selected to produce precise results for the least cost. Thus, constraint selection has been a manual task, guided by the intuition of the analyst. In this paper, we investigate several heuristics for selecting task automaton constraints, a kind of constraint that tends to reduce infeasible task interactions. We describe an experiment showing that one of these heuristics is extremely effective at improving the precision of the analysis results without significantly degrading performance.", "num_citations": "9\n", "authors": ["1627"]}
{"title": "Nilpotency degree of cohomology rings in characteristic two\n", "abstract": " In this paper, we consider the cohomology ring of a finite -group with coefficients in a field of characteristic two. We show that, for any positive integer , there exists a -group whose cohomology ring has elements of nilpotency degree  and all smaller degrees.", "num_citations": "9\n", "authors": ["1627"]}
{"title": "A vanishing theorem for second degree cohomology\n", "abstract": " In this paper we give conditions for the cohomology group H2 (G, V) to vanish, in the case where G is a finite group, V is a KG-module for some field K of characteristic p and G has a normal p-Sylow subgroup acting trivially on V. Interpreting these conditions when G is a Bore1 subgroup of L (K), a group of Lie type over K, we obtain a vanishing condition for P@(K), V) depending only on relations between roots and weights. The main theorem is proved in Section 1 and is applied to groups of Lie type in Section 2. In Section 3 we list the cases in which the vanishing conditions have been shown to hold and briefly describe what is known in some of the cases where the conditions fail.", "num_citations": "9\n", "authors": ["1627"]}
{"title": "Plug-and-play architectural design and verification\n", "abstract": " In software architecture, components represent the computational units of a system and connectors represent the interactions among those units. Making decisions about the semantics of these interactions is a key part of the design process. It is often difficult, however, to choose the appropriate interaction semantics due to the wide range of alternatives and the complexity of the system behavior affected by those choices. Techniques such as finite-state verification can be used to evaluate the impact of these design choices on the overall system behavior.               This paper presents the Plug-and-Play approach that allows designers to experiment with alternative design choices of component interactions in a plug-and-play manner. With this approach, connectors representing specific interaction semantics are composed from a library of predefined, reusable building blocks. In addition, standard interfaces for\u00a0\u2026", "num_citations": "8\n", "authors": ["1627"]}
{"title": "Considerations for online deviation detection in medical processes\n", "abstract": " Medical errors are a major cause of unnecessary suffering and even death. To address this problem, we are investigating an approach for automatically detecting when an executing process deviates from a set of recommended ways to perform that process. Such deviations could represent errors and, thus, detecting and reporting deviations as they occur could help catch errors before something bad happens. This paper presents the proposed deviation detection approach, identifies some of the major research issues that arise, and discusses strategies to address these issues. A preliminary evaluation is performed by applying the approach to a part of a detailed process model. This model has been developed in an in-depth case study on modeling and analyzing a blood transfusion process.", "num_citations": "6\n", "authors": ["1627"]}
{"title": "A Quillen stratification theorem for modules\n", "abstract": " Let G be a finite group and k a fixed algebraically closed field of characteristic p> 0. If p is odd, let HG be the subring of//*(G, k) consisting of elements of even degree; take HG=//*(G, k) if p= 2. HG is a finitely generated commutative fc-algebra, and we let VG denote its associated affine variety Max HG. If M is any finitely generated fcG-module, the cohomology variety VG (M) of M may be defined as the support in VG of the HG-module H*(G, M) if G is a p-group, and in general as the largest support of//*(G, L\u00ae M) where L is any kG-module. A module L with each irreducible fcG-module as a direct summand will do [3].D. Quillen [9, 10] proved a number of beautiful results relating VG to the varieties VE associated with the elementary abelian p-subgroups E of Gf culminating in his stratification theorem. This theorem gives a piecewise description of VG in terms of the subgroups E and their normalizers in G. Some of Quillen's\u00a0\u2026", "num_citations": "6\n", "authors": ["1627"]}
{"title": "Assessing the effectiveness of five process elicitation methods: A case study of chemotherapy treatment plan review\n", "abstract": " To reduce the probability of failures and to improve outcomes of safety-critical human-intensive processes, such as health care processes, it is important to be able to rigorously analyze such processes. The quality of that analysis often depends on having an accurate, detailed, and sufficiently complete understanding of the process being analyzed, where this understanding is typically represented as a formal process model that could then drive various rigorous analysis approaches. Developing this understanding and the corresponding formal process model may be difficult and, thus, a variety of process elicitation methods are often used. The work presented in this paper evaluates the effectiveness of five common elicitation methods in terms of their ability to elicit detailed process information necessary to support rigorous process analysis. These methods are employed to elicit typical steps and steps for responding\u00a0\u2026", "num_citations": "5\n", "authors": ["1627"]}
{"title": "Online deviation detection for medical processes\n", "abstract": " Human errors are a major concern in many medical processes. To help address this problem, we are investigating an approach for automatically detecting when performers of a medical process deviate from the acceptable ways of performing that process as specified by a detailed process model. Such deviations could represent errors and, thus, detecting and reporting deviations as they occur could help catch errors before harm is done. In this paper, we identify important issues related to the feasibility of the proposed approach and empirically evaluate the approach for two medical procedures, chemotherapy and blood transfusion. For the evaluation, we use the process models to generate sample process executions that we then seed with synthetic errors. The process models describe the coordination of activities of different process performers in normal, as well as in exceptional situations. The evaluation results\u00a0\u2026", "num_citations": "5\n", "authors": ["1627"]}
{"title": "Experiments in constrained expression analysis\n", "abstract": " This report describes some experiments in analyzing concurrent software sys-tems using the constrained expression formalism [1, 6]. The primary analysis techniques used are the inequality-based methods of [1] and [2], and the major goal of these experiments is the identification of useful heuristics for generat-ing the necessary systems of inequalities. In particular, we are interested in determining the extent to which this process can be automated. A couple of warnings to the reader are in order. First, this report is a description of the actual analysis of some distributed systems, and not an outline of how such an analysis might be most efficiently or elegantly conducted. We learned many things about our methods during these experiments, and this is reflected in changes in their application as the analysis progressed. Second, we assume that the reader has some familiarity with the constrained expression formalism\u00a0\u2026", "num_citations": "5\n", "authors": ["1627"]}
{"title": "-cohomology of some unitary groups\n", "abstract": " In [1], we showed that the 2-cohomology of the group SU (n, q) with coefficients in the standard module V l is generally zero. For SU (2, q), which is, of course, equal to SL (2, q2), the only exceptions occur at q 2k with k _> 2; in unpublished work, McLaughlin has shown thatthe second cohom-ology group hasdimension 1 over Fq2. For n> 2 and q> 3, the only possible exceptions are at n 3 with q 4 or 3k and n 4 with q 4. In this paper, we prove that H2 (SU (n, q), V) has dimension 1 over Fq2 in the first case and vanishes in the second. We also show that H2 (SU (3, 3), V) is zero. In Section l, we outline some basic results on the cohomology of groups. In the second section, we compute HE (su (3, q), V) with q 4 or 3k, k> 1, while the 2-cohomology of SU (4, 4) is determined in the third section. Finally, we show H2 (SU (3, 3), V)= 0 in the fourth section. I. In this section, we describe some results on the cohomology of groups\u00a0\u2026", "num_citations": "5\n", "authors": ["1627"]}
{"title": "Managing space for finite-state verification\n", "abstract": " Finite-state verification (FSV) techniques attempt to prove properties about a model of a system by examining all possible behaviors of that model. This approach suffers from the state-explosion problem, where the size of the model or the analysis costs may be exponentially large with respect to the size of the system. Using symbolic data structures to represent subsets of the state space has been shown to usually be an effective optimization approach for hardware verification. The value for software verification, however, is still unclear. In this paper, we investigate applying two symbolic data structures, Binary Decision Diagrams (BDDs) and Zero-suppressed Binary Decision Diagrams (ZDDs), in two FSV tools, LTSA and FLAVERS. We describe an experiment showing that these two symbolic approaches can improve the performance of both FSV tools and are more efficient than two other algorithms that store the\u00a0\u2026", "num_citations": "4\n", "authors": ["1627"]}
{"title": "Experimental design for comparing static concurrency analysis techniques\n", "abstract": " ABSTRACT formally, experimentation can help develop estimates of Software engineering has suffered from a shortage of empirical studies. We recently undertook a study in an area that seems well suited to empirical investigation, comparing the performance of several static analysis tools for evaluating properties of concurrent software. During the course of that study, we encountered a number of significant issues that make designing a sound and unbiased study surprisingly difficult. It is these issues, and the tradeoffs they necessitate, that are the focus of this paper. average case performance for each of the techniques. In addition to performance, experimentation can provide information about the types of properties and programs each tool can verify, the accuracy of the analysis results, and the frequency of failure. Corbett [4, 5] carried out empirical studies comparing the performance of several tools in detecting deadlock in Ada tasking programs. Our goal was to extend Corbett's work by adding data flow analysis to the repertoire of techniques, by examining program-specific properties in addition to deadlock, by considering analysis accuracy and other measures of performance, and by carrying out careful statistical analysis of the results to check for various biases and to quantify the predictive power of our results. Thus, we undertook an experimental evaluation of several of the major analysis techniques as applied to many of the concurrency analysis programs that have appeared in the literature [2].", "num_citations": "4\n", "authors": ["1627"]}
{"title": "Automatic generation of inequality systems for constrained expression analysis\n", "abstract": " This report describes a prototype tool for automating the generation of systems of inequalities, and for aiding in the interpretation of the solutions of such systems, in the analysis of constrained expressions. The constrained expression approach to the analysis of concurrent and distributed software systems is described in 4, 5]; more detailed descriptions of the use of inequalities in such analysis are given in 2, 5, 6]. This prototype implements a piece of a toolset supporting automated analysis of distributed system designs written in the CEDL design language 11], which is based on Ada. The structure of the toolset and its application are described brie y in the next section and in more detail in 4]. Detailed discussions of the other components of the toolset are given in 1, 7, 9, 12]. This document describes version 2.0 of the prototype, whose implementation has been completed recently. Version 2.0 of the prototype extends signi cantly an earlier version, described in 3], and incorporates algorithms and some portions of code from that version. A number of major areas have been changed. One such change is the added capability to generate inequalities from deterministic nite-state automata (DFAs) and a hybrid form we call regular expression deterministic nite-state automata (REDFAs) in addition to regular expressions. In some cases, these automata are signi cantly more compact representations of event sequences than their equivalent regular expressions and thus produce much smaller inequality systems. Also, if a task expression has been run through the constraint eliminator, and thus converted to a DFA or an REDFA, no time must then be spent\u00a0\u2026", "num_citations": "4\n", "authors": ["1627"]}
{"title": "Considering the exceptional: Incorporating exceptions into property specifications\n", "abstract": " Property specifications concisely describe aspects of what a system is supposed to do. It is important that these specifications be correct, describing all the desired behavior and ruling out undesired behavior. Our experience shows that properties are sometimes specified incorrectly because specifiers fail to take into account some exceptional behaviors of the system. In previous work we presented PROPEL, a tool that guides specifiers through the process of creating understandable yet precise property specifications. Here we describe extensions to PROPEL that allow specifiers of a property to indicate what exceptions should be considered and what impact those exceptions should have on the acceptability of system behavior. Although the description is given in terms of the framework provided by PROPEL, the issues specifiers must consider would apply to other specification formalisms.", "num_citations": "3\n", "authors": ["1627"]}
{"title": "Property inference from program executions\n", "abstract": " Software verification techniques require properties that define the intended behavior of a system be specified. Generating such properties is often very difficult and serves as an impediment to the adoption of verification techniques. Techniques that leverage program executions to infer these properties are a promising avenue for automatically generating these properties. In this paper, we propose a property inference approach that leverages event traces derived from program executions to efficiently infer properties that are subtle variations of commonly occurring properties. We define inference templates that represent sets of these properties and describe our inference algorithm that refines these templates based on event traces.", "num_citations": "3\n", "authors": ["1627"]}
{"title": "Constrained expression analysis of real-time systems\n", "abstract": " THE CONSTRAINED EXPRESSION FORMALISM AND ITS ASSOCIATED ANALYSIS TECH- NIQUES WERE ORIGINALLY DEVELOPED FOR DESCRIBING AND ANALYZING LOGICAL PROP- ERTIES OF CONCURRENT SYSTEM BEHAVIOR. WE HAVE RECENTLY BEGUN EXPLORING THEIR APPLICATION TO ANALYZING TIMING PROPERTIES. IN THIS PAPER WE DESCRIBE OUR INITIAL APPROACH TO CONSTRAINED EXPRESSION ANALYSIS OF REAL-TIME SYSTEMS AND REPORT THE RESULTS OF A PRELIMINARY EXPERIMENT USING THIS APPROACH. WE THEN DISCUSS THE PROSPECTS FOR EXTENDING BOTH THE CONSTRAINED EXPRESSION FORMALISM AND OUR EXISTING PROTOTYPE TOOLSET TO SUPPORT ANALYSIS OF REAL-TIME CONCURRENT SOFTWARE SYSTEMS.", "num_citations": "3\n", "authors": ["1627"]}
{"title": "SECOND DEGREE COHOMOLOGY OF GROUPS OF LIE TYPE.\n", "abstract": " My advisor, Professor Jack E. McLaughlin, has been a constant source of encouragement, advice and mathematical wisdom since he introduced me to the theory of groups in my sophomore year of college. It is a pleasure to acknowledge his contribution to ents thesis, and to my mathematical career.", "num_citations": "3\n", "authors": ["1627"]}
{"title": "Modal abstraction view of requirements for medical devices used in healthcare processes\n", "abstract": " Medical device requirements often depend on the healthcare processes in which the device is to be used. Since such processes may be complex, critical requirements may be specified inaccurately, or even missed altogether. We are investigating an automated requirement derivation approach that takes as input a model of the healthcare process along with a model of the device and tries to derive the requirements for that device. Our initial experience with this approach has shown that when the process and device involve complex behaviors, the derived requirements are also often complex and difficult to understand. In this paper, we describe an approach for creating a modal abstraction view of the derived requirements that decomposes each requirement based on its modes, and thus appears to improve understandability.", "num_citations": "2\n", "authors": ["1627"]}
{"title": "Verification support for plug-and-play architectural design\n", "abstract": " In software architecture, connectors are intended to represent the specific semantics of how components interact with each other, capturing some of the most important yet subtle aspects of a system. In practice, choosing the appropriate interaction semantics for the connectors in a system tends to be very difficult. The typical design process often involves not only a choice from commonly used interaction mechanisms, such as remote procedure call, message passing, and publish/subscribe, but also decisions about such details as the particular type and size of a message buffer or whether a communication should be synchronous or asynchronous. Given such a large design space, it is important that designers be able to get feedback about the appropriateness of their design decisions on interaction semantics, based on the correctness of the overall system behavior. In particular, one would like to be able to propose\u00a0\u2026", "num_citations": "2\n", "authors": ["1627"]}
{"title": "Experimental design for comparing static concurrency analysis\n", "abstract": " This paper reports the results of an empirical comparison of several static analysis tools for evaluating properties of concurrent software and also reports the resuilts of our attempts to build predictive models for each of the tools based on program and property characteristics. Although this area seems well suited to empirical investigation, we encountered a number of significant issues that make designing a sound and unbiased study surprisingly difficult. These experiment design issues are also discussed in this paper.", "num_citations": "2\n", "authors": ["1627"]}
{"title": "Sharpening bounds on the time between events in maximally parallel systems\n", "abstract": " A recent paper 3] describes a method for obtaining bounds on the time that can elapse between two given events in an execution of a concurrent software system running on a single processor under arbitrary scheduling. The technique involves generating linear inequalities expressing conditions that must be satis ed by all executions of such a system and using integer programming methods to nd appropriate solutions to the inequalities. Corbett 4, 5] has extended this approach to obtain upper bounds on the time between events in executions of multi-processor concurrent systems in which each process proceeds unless forced to wait to communicate with another, the case of maximal parallelism, and processes communicate by synchronous message passing. Corbett's method does not strictly enforce the maximal parallelism assumption, however, and may thus give poor (though valid) bounds in some cases. In this paper, I show how to modify Corbett's method to obtain sharper bounds.", "num_citations": "2\n", "authors": ["1627"]}
{"title": "The image of the restriction map on 2-cohomology\n", "abstract": " The problem of determining the image of the restriction map also arises in a generalization of the extension problem for groups. The usual extension problem asks for the groups G with a given normal subgroup N and quotient isomorphic to a given group Q such that conjugation in G induces a given homomorphism from Q to the outer automorphism group of N. More generally, given a collection of groups and appropriate homomorphisms, one can ask for the groups having a normal series whose factors are the given collection, with conjugation inducing the given homomorphisms.Consider, then, a pair of groups N and Q, and let V be an N-module. Choose a homomorphism Q-~ Out N, and an action of Q on V, up to the action ofN. A group E, with normal series 1<] V<] M<] E having factors M~ V.~ N and E/M---Q and inducing the given actions by conjugation, determines extensions", "num_citations": "2\n", "authors": ["1627"]}