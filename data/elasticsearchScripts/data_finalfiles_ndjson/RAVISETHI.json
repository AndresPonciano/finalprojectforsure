{"title": "Compilers, principles, techniques\n", "abstract": " \u0393\u00c7\u00f3 Try observe HTML codes and CSS generated by Expression Web to familiarize yourself with HTML. If you are already familiar with HTML, try to predict what kind of tags Expression Web will generate for you.\u0393\u00c7\u00f3 Try to be curious about the functions & formats provided by Expression Web.", "num_citations": "17692\n", "authors": ["30"]}
{"title": "The complexity of flowshop and jobshop scheduling\n", "abstract": " NP-complete problems form an extensive equivalence class of combinatorial problems for which no nonenumerative algorithms are known. Our first result shows that determining a shortest-length schedule in an m-machine flowshop is NP-complete for m \u0393\u00eb\u00d1 3. (For m = 2, there is an efficient algorithm for finding such schedules.) The second result shows that determining a minimum mean-flow-time schedule in an m-machine flowshop is NP-complete for every m \u0393\u00eb\u00d1 2. Finally we show that the shortest-length schedule problem for an m-machine jobshop is NP-complete for every m \u0393\u00eb\u00d1 2. Our results are strong in that they hold whether the problem size is measured by number of tasks, number of bits required to express the task lengths, or by the sum of the task lengths.", "num_citations": "3252\n", "authors": ["30"]}
{"title": "Scheduling independent tasks to reduce mean finishing time\n", "abstract": " Sequencing to minimize mean finishing time (or mean time in system) is not only desirable to the user, but it also tends to minimize at each point in time the storage required to hold incomplete tasks. In this paper a deterministic model of independent tasks is introduced and new results are derived which extend and generalize the algorithms known for minimizing mean finishing time. In addition to presenting and analyzing new algorithms it is shown that the most general mean-finishing-time problem for independent tasks is polynomial complete, and hence unlikely to admit of a non-enumerative solution.", "num_citations": "671\n", "authors": ["30"]}
{"title": "Programming languages concepts and constructs\n", "abstract": " Sethi's \u0393\u00c7\u00a3teddy bear book\u0393\u00c7\u00a5 is one of the popular undergraduate texts on comparative programming languages. Like the first edition [1], this second edition is intended for use in a third-or fourth-year course on programming languages whose prerequisite is an introductory programming course. The author also indicates that it could serve in a graduate course if the material were supplemented. This new edition differs from the original mainly in organization, and is definitely stronger than the first, in part due to its use of language paradigms as its organizational framework. In addition, the coverage of the major paradigms uses fewer languages and goes into more depth. Other parts of the book have benefited from minor reorganization. For example, the section on techniques for syntax description has been improved through a more detailed early introduction and the inclusion of more examples. In the first edition, that\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "512\n", "authors": ["30"]}
{"title": "Variations on the common subexpression problem\n", "abstract": " Let G be a directed graph such that for each vertex v in G, the successors of v are ordered Let C be any equivalence relation on the vertices of G. The congruence closure C* of C is the finest equivalence relation containing C and such that any two vertices having corresponding successors equivalent under C* are themselves equivalent under C* Efficient algorithms are described for computing congruence closures in the general case and in the following two special cases. 0) G under C* is acyclic, and (it) G is acychc and C identifies a single pair of vertices. The use of these algorithms to test expression eqmvalence (a problem central to program verification) and to test losslessness of joins in relational databases is described", "num_citations": "481\n", "authors": ["30"]}
{"title": "Efficient optimization of a class of relational expressions\n", "abstract": " The design of several database query languages has been influenced by Codd's relational algebra. This paper discusses the difficulty of optimizing queries based on the relational algebra operations select, project, and join. A matrix, called a tableau, is proposed as a useful device for representing the value of a query, and optimization of queries is couched in terms of finding a minimal tableau equivalent to a given one. Functional dependencies can be used to imply additional equivalences among tableaux. Although the optimization problem is NP-complete, a polynomial time algorithm exists to optimize tableaux that correspond to an important subclass of queries.", "num_citations": "442\n", "authors": ["30"]}
{"title": "An ideal model for recursive polymorphic types\n", "abstract": " We will consider types as somehow being or generating constraints on expressions in a language. A consistent type discipline will ensure that any expression satisfying the constraints will not produce a run-time error. For example during any evaluation of the expression f (x), the value off must be a function; otherwise, a run-time error occurs because the computation cannot proceed. As we want to guarantee the absence of such run-time errors, the constraints on the values off and x must be spelled out further. In particular, if the value of x satisfies constraint s, then it suffices that f is a function that is applicable to all such values. For instance, f might satisfy the constraint of sending all values satisfying s to values satisfying another constraint t. These constraints on the values off and x will bc written as:", "num_citations": "437\n", "authors": ["30"]}
{"title": "From regular expressions to deterministic automata\n", "abstract": " The main theorem allows an elegant algorithm to be refined into an efficient one. The elegant algorithm for constructing a finite automaton from a regular expression is based on \u0393\u00c7\u00ffderivatives of\u0393\u00c7\u00d6regular expressions; the efficient algorithm is based on \u0393\u00c7\u00ffmarking of\u0393\u00c7\u00d6regular expressions. Derivatives of regular expressions correspond to state transitions in finite automata. When a finite automaton makes a transition under input symbol a, a leading a is stripped from the remaining input. Correspondingly, if the input string is generated by a regular expression E, then the derivative of E by a generates the remaining input after a leading a is stripped. Brzozowski (1964) used derivatives to construct finite automata; the state for expression E has a transition under a to the state for the derivative of E by a. This approach extends to regular expressions with new operators, including intersection and complement; however, explicit\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "430\n", "authors": ["30"]}
{"title": "The generation of optimal code for arithmetic expressions\n", "abstract": " The problem of evaluating arithmetic expressions on a machine with N \u0393\u00eb\u00d1 1 general purpose registers is considered. It is initially assumed that no algebraic laws apply to the operators and operands in the expression. An algorithm for evaluation of expressions under this assumption is proposed, and it is shown to take the shortest possible number of instructions. It is then assumed that certain operators are commutative or both commutative and associative. In this case a procedure is given for finding an expression equivalent to a given one and having the shortest possible evaluation sequence. It is then shown that the algorithms presented here also minimize the number of storage references in the evaluation.", "num_citations": "393\n", "authors": ["30"]}
{"title": "Compiladores: principios, t\u251c\u2310cnicas y herramientas\n", "abstract": " Esta nueva edici\u251c\u2502n se ha revisado por completo para incluir los desarrollos m\u251c\u00eds recientes en la compilaci\u251c\u2502n. El libro ofrece una introducci\u251c\u2502n detallada al dise\u251c\u2592o de compiladores y contin\u251c\u2551a haciendo \u251c\u2310nfasis en la capacidad de aplicar la tecnolog\u251c\u00a1a de compiladores a una amplia gama de problemas en el dise\u251c\u2592o y desarrollo de software.", "num_citations": "381\n", "authors": ["30"]}
{"title": "Complete register allocation problems\n", "abstract": " The search for efficient register allocation algorithms dates back to the time of the first FORTRAN compiler for the IBM 704. The model we use in this paper is a single processor with an arbitrarily large number of general registers. The objective is to use as few registers as possible, under the,constraint that no stores into memory are permitted. The programs under consideration are sequences of assignment instructions. We show that, given a program and an integer k, determining if the program can be computed using k registers is polynomial complete. It should be noted that k can be any integer.", "num_citations": "351\n", "authors": ["30"]}
{"title": "Compilerbau\n", "abstract": " Compilerbau De Gruyter De Gruyter EN English Deutsch EUR \u0393\u00e9\u00bc GBP \u252c\u00fa USD $ 0 \u251c\u00f9 Your purchase has been completed. Your documents are now available to view. \u251c\u00f9 Changing the currency will empty your shopping cart. Confirm Cancel Alfred V. Aho, Ravi Sethi and Jeffrey D. Ullman Compilerbau Teil 1 Oldenbourg Wissenschaftsverlag | 1999 Share Cite Overview About this book Jeder kennt das Drachenbuch: \"Principles of Compiler Design\" von Alfred V. Aho und Jeffrey D. Ullman, den Meilenstein in der Literatur zum Compilerbau. Der \"neue Drache\", geschrieben von der Arbeitsgruppe Alfred V. Aho, Ravi Sethi und Jeffrey D. Ullman und \u251c\u255dbersetzt von Prof. Dr. Gerhard Barth und seinen Mitarbeitern, bietet die gleichen Basis-Informationen wie der alte, befa\u251c\u0192t sich dabei aber auch mit den j\u251c\u255dngsten Forschungen auf dem Gebiet, zB: - Pragmatik der Compiler-Entwicklung - syntaxgesteuerte \u251c\u00a3bersetzung, , Laufzeit-, --- . \u0393\u00c7\u00aa", "num_citations": "343\n", "authors": ["30"]}
{"title": "Computing sequences with addition chains\n", "abstract": " Given a sequence  of positive integers, what is the smallest number of additions needed to compute all m integers starting with 1? This generalization of the addition chain () problem will be called the addition-sequence problem. We show that the sequence  can be computed with  additions, and that  is a lower bound. This lower bound result is applied to show that the addition-sequence problem is NP-complete.", "num_citations": "200\n", "authors": ["30"]}
{"title": "A level algorithm for preemptive scheduling\n", "abstract": " Muntz and Coffman give a level algorithm that constructs optimal preemptive schedules on identical processors when the task system is a tree or when there are only two processors available. Their algorithm is adapted here to handle processors of different speeds. The new algorithm is optimal for independent tasks on any number of processors and for arbitrary task systems on two processors, but not on three or more processors, even for trees. By taking the algorithm as a heuristic on m processors and using the ratio of the lengths of the constructed and optimal schedules as a measure, an upper bound on its performance is derived in terms of the speeds of the processors. It is further shown that 1.23\u0393\u00ea\u00dcm is an upper bound over all possible processor speeds and that the 1.23\u0393\u00ea\u00dcm bound can be improved at most by a constant factor, by giving an example of a system for which the bound 0.35\u0393\u00ea\u00dcm can be approached\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "186\n", "authors": ["30"]}
{"title": "Code generation for a one-register machine\n", "abstract": " The majority of computers that have been built have performed all computations in devices called accumulators, or registers. In this paper, it is shown that the problem of generating minimal-length code for such machines is hard in a precise sense; specifically it is shown that the problem is NP-complete. The result is true even when the programs being translated are arithmetic expressions. Admittedly, the expressions in question can become complicated.", "num_citations": "142\n", "authors": ["30"]}
{"title": "Worst case analysis of two scheduling algorithms\n", "abstract": " Coffman and Graham give an algorithm to schedule unit execution time task systems nonpreemptively. On two processors, their algorithm is optimal. We show that in general, if  is the length of a schedule produced by their algorithm and  the length of an optimal schedule, then , where m is the number of processors. The preemptive equivalent of the above algorithm has been considered by Muntz and Coffman. Again we show that the ratio of the lengths of theirs and an optimal schedule is bounded by . In both the nonpreemptive and the preemptive cases there exist task systems for which the ratio  can be approached arbitrarily closely. On a small number of machines,  is not too far from 1. In particular, as noted above, on two machines the ratio is 1.", "num_citations": "127\n", "authors": ["30"]}
{"title": "Storage requirements for deterministic polynomialtime recognizable languages\n", "abstract": " An intriguing question is whether (log n)2 space is enough to recognize the class  of languages recognizable in deterministic polynomial time. This question has earlier been narrowed down to the storage required to recognize a particular language called SP. SP is clearly in  and it has been shown that if SP has tape complexity (log n)k, then every member of  has tape complexity (log n)k. This paper presents further evidence in support of the conjecture that SP cannot be recognized using storage (log n)k for any k. We have no techniques at present for proving such a statement for Turing machines in general; we prove the result for a suitably restricted device.", "num_citations": "124\n", "authors": ["30"]}
{"title": "Scheduling graphs on two processors\n", "abstract": " Consider a directed acyclic graph (dag) D with n nodes and e edges. D represents a task system; a node corresponds to a task, and an edge  means that task x must be finished before task y can be started. We shall restrict attention to systems in which all tasks require the same processing time. Coffman and Graham give an algorithm for determining nonpreemptive schedules on two processors for such systems. The first part of their algorithm assigns unique labels to nodes. The second part uses these labels to construct a list schedule (in the sense of Graham). The time taken for each part is . We give an algorithm to determine the labeling in  steps. Similar algorithms have independently been devised to test undirected graphs for chordality. We give a second algorithm to construct a schedule from the labeling in  steps.  is an almost constant function of n.", "num_citations": "122\n", "authors": ["30"]}
{"title": "Complexity of trie index construction\n", "abstract": " Trie structures are a convenient way of indexing files in which keys are specified by values of attributes. Records correspond to leaves in the trie. Retrieval proceeds by following a path from the root to a leaf, the choice of edges being determined by attribute values. The size of a trie for a file depends on the order in which attributes are tested. We show that determining minimal size tries is an NP-complete problem for several variants of tries. For tries in which leaf chains are deleted we show that determining the trie for which average access time is minimal is also an NP-complete problem. Our results hold even for files in which attribute values are chosen from a binary or ternary alphabet.", "num_citations": "114\n", "authors": ["30"]}
{"title": "Compilateurs\n", "abstract": " Compilateurs Page 1 A. Aho, M. Lam, R. Sethi et J. Ullman www.pearsoneducation.fr Le \u252c\u00bd Dragon \u252c\u2557, l\u0393\u00c7\u00d6ouvrage de r\u251c\u2310f\u251c\u2310rence en mati\u251c\u00bfre de compilation, revient avec une \u251c\u2310dition enti\u251c\u00bfrement actualis\u251c\u2310e et qui prend en compte toutes les \u251c\u2310volutions r\u251c\u2310centes du domaine. Les auteurs, enseignants dans les universit\u251c\u2310s am\u251c\u2310ricaines les plus prestigieuses, ont adopt\u251c\u2310 une pr\u251c\u2310sentation encore plus p\u251c\u2310dagogique, abondamment illustr\u251c\u2310e d\u0393\u00c7\u00d6exemples concrets et d\u0393\u00c7\u00d6exercices. Le livre couvre tous les aspects th\u251c\u2310oriques et pratiques de la compilation des langages de programmation. Il s\u0393\u00c7\u00d6attache \u251c\u2310galement \u251c\u00e1 d\u251c\u2310montrer la pertinence du recours \u251c\u00e1 la compilation pour r\u251c\u2310soudre les probl\u251c\u00bfmes les plus fr\u251c\u2310quemment rencontr\u251c\u2310s lors de la conception de logiciels de traitement des langages. La compilation permet en effet de rechercher des erreurs dans des logiciels ou de d\u251c\u2310couvrir des failles de s\u251c\u2310curit\u251c\u2310 dans les codes existants. La partie l\u0393\u00c7\u00aa", "num_citations": "105\n", "authors": ["30"]}
{"title": "A generalized bound on LPT sequencing\n", "abstract": " In this paper we shall generalize Graham's result so as to include a parameter characterizing the number of tasks assigned to processors by the LPT rule. The new result will show that the worst-case performance bound for LPT sequencing approaches unity approximately as 1+ 1/k, where k is the least number of tasks on any processor, or where k is the number of tasks on a processor whose last task terminates the schedule. Thus, we shall have a result very similar to the parameterized bounds for bin-packing heuristics [JDUGG]. We shall also obtain out of the analysis an alternate proof of Graham's result.", "num_citations": "89\n", "authors": ["30"]}
{"title": "Testing for the Church-Rosser property\n", "abstract": " The central notion in a replacement system is one of a transformation on a set of objects. Starting with a given object, in one \u0393\u00c7\u00a3move\u0393\u00c7\u00a5 it is possible to reach one of a set of objects. An object from which no move is possible is called irreducible. A replacement system is Church-Rosser if starting with any object a unique irreducible object is reached. A generalization of the above notion is a replacement system (S, \u0393\u00e7\u00c6, \u0393\u00eb\u00ed), where S is a set of objects, \u0393\u00e7\u00c6 is a transformation, and \u0393\u00eb\u00ed is an equivalence relation on S. A replacement system is Church-Rosser if starting with objects equivalent under \u0393\u00eb\u00ed, equivalent irreducible objects are reached. Necessary and sufficient conditions are determined that simplify the task of testing if a replacement system is Church-Rosser. Attention will be paid to showing that a replacement system (S, \u0393\u00e7\u00c6, \u0393\u00eb\u00ed) is Church-Rosser using information about parts of the system, i.e. considering cases where \u0393\u00e7\u00c6\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "82\n", "authors": ["30"]}
{"title": "A semantic model of types for applicative languages\n", "abstract": " If integer constants are added to the syntax of the pure lambda calculus, then primitive integer values have to be added to the underlying domain V of values. Unlike functions, primitive values should not be applied; we want a run-time error to occur if an attempt is made to apply them as functions. Expressions that might lead to run-time errors are separated out by imposing a \u0393\u00c7\u00a3type\u0393\u00c7\u00a5 structure on expressions. A systematic model of types is developed, in which types are formalized as \u0393\u00c7\u00a3ideals\u0393\u00c7\u00a5(sets with a certain structure). Polymorphic functions are handled by introducing a quantifier for taking conjunctions of types. Operations for constructing new types from old lead to the consideration of higher-order or meta types, which are called \u0393\u00c7\u00a3kinds\u0393\u00c7\u00a5 to avoid confusion with types. Finally, the semantic model of types is applied to show the soundness of a proof system for inferring the types of expressions.", "num_citations": "75\n", "authors": ["30"]}
{"title": "On the complexity of mean flow time scheduling\n", "abstract": " There are n tasks lo be scheduled for processing on a set of identical parallel machines. We are interested in minimizing the mean flow time, which is related to the sum of the finishing times of all tasks. When tasks can be processed in any order, optimal schedules can be constructed in O(n log n) time on any number of identical machines. With arbitrary precedence constraints the problem becomes NP-complete even on one machine. However, for series-parallel precedence constraints an O(n log n) algorithm is known for one machine. We show that on two or more machines, the problem is NP-complete even if the precedence constraints are tree-like. We prove the result both for in-trees in which the root is the last task to be processed, and out-trees in which the root is the first task to be processed.", "num_citations": "63\n", "authors": ["30"]}
{"title": "Inhibition of HIV-1 gene expression by retroviral vector-mediated small-guide RNAs that direct specific RNA cleavage by tRNase ZL\n", "abstract": " The tRNA 3\u0393\u00c7\u2593-processing endoribonuclease (tRNase Z or 3\u0393\u00c7\u2593 tRNase; EC 3.1.26.11) is an essential enzyme that removes the 3\u0393\u00c7\u2593 trailer from pre-tRNA. The long form (tRNase ZL) can cleave a target RNA              in vitro              at the site directed by an appropriate small-guide RNA (sgRNA). Here, we investigated whether this sgRNA/tRNase ZL strategy could be applied to gene therapy for AIDS. We tested the ability of four sgRNA-expression plasmids to inhibit HIV-1 gene expression in COS cells, using a transient-expression assay. The three sgRNAs guide inhibition of HIV-1 gene expression in cultured COS cells. Analysis of the HIV-1 mRNA levels suggested that sgRNA directed the tRNase ZL to mediate the degradation of target RNA. The observation that sgRNA was localized primarily in nuclei suggests that tRNase ZL cleaves the HIV-1 mRNA when complexed with sgRNA in this location. We also\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "52\n", "authors": ["30"]}
{"title": "Control flow aspects of semantics-directed compiling\n", "abstract": " This paper focuses on the part of a compiler between syntax a. nalysis and code generation. We demonstrate that efficient compilers can quickly be generated for the control flow aspects of typical languages. Starting in Section 3 with a language containing conditional and while statements, we gradually add: break and continue statements (Section 5), restricted gotos that do not jump into the bodies of while or conditional statements (Section 6), gotos that can go anywhere (Section 7), and a switch statement (Section 9). With the addition of two variants of the while statement in Section 8, the final language will contain all the statement constructs of the C programming language [27].(No knowledge of C is assumed; C is just a convenient vehicle since it has statement types found in a number of other languages.) The actual specification from which a compiler has been generated is shown, along with some indication of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "48\n", "authors": ["30"]}
{"title": "Assignment commands with array references\n", "abstract": " Stratght line programs with assignment statements involving both simple and array variables are considered Two such programs are equivalent if they compute the same values as a function of the inputs. Testing the equivalence of array programs ts shown to be NP-hard If array variables are updated but never subsequently referenced, equivalence can be tested in polynomial time Programs without array varmbles can be tested for equivalence in expected linear t~ me", "num_citations": "47\n", "authors": ["30"]}
{"title": "Algorithms minimizing mean flow time: schedule-length properties\n", "abstract": " The mean flow time of a schedule provides a measure of the average time that a task spends within a computer system, and also the average number of unfinished tasks in the system. The mean flow time of a schedule is defined to be the sum of the finishing times of all tasks in the system. On a system of identical processors O(nlog n) algorithms exist for determining minimal mean flow time schedules for n independent tasks. In general, there will be a large class C of schedules, of widely differing lengths, that all minimize mean flow time. The problem of finding the shortest schedule in C is NP-complete. We give heuristics that find schedules in C that are no more than 25% longer than the shortest schedule in C. The advantage of a short schedule is that processor utilization is high.", "num_citations": "41\n", "authors": ["30"]}
{"title": "Useless actions make a difference: Strict serializability of database updates\n", "abstract": " When several transactions read and write~ tems in a database, the question of consistency of the database arises. Consistency s maintained if transacUons are serial, the read and write acuons of a transacuon execute complete! y before the actions of the next transaction begin A particular history of interleaved read and write actions belonging to several transactions~ s correct if it~ s equivalent to a serial history. Since senahzablhty of hlstones is known to be NP-complete, subclasses of senahzable histories have been stu&ed. One such class consists of htstones senahzable in a strict sense, transacuons that are already m serial in a history must remain m the same relative order When there are no useless actions m a history, it is shown that strict sermlizabdity can be determined m polynomial time If useless actions are permitted, then strict serializabihty becomes NP-complete The above results apply to two-step\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "39\n", "authors": ["30"]}
{"title": "Pebble games for studying storage sharing\n", "abstract": " Pebble games are played on a directed acyclic graph (dag). Placing a pebble on a vertex may be thought of as entering the value of the subexpression represented by the vertex into accessible storage. In some applications, there are types associated with vertices e.g. some vertices may represent functions, others may represent function values. We are interested in determining if vertices of the same type can share storage. The problem considered is as follows. We are given a labelled dag to be pebbled. A pebble may be placed on a vertex if all sons of the vertex have pebbles\u0393\u00c7\u00f6in fact it is legal to move a pebble from a son to a father. Pebbles may be picked up at any time. The objective is to pebble each vertex exactly once. We will be interested in \u0393\u00c7\u00ffone pebblings of l vertices\u0393\u00c7\u00d6 in which there is at most one pebble on vertices with label l, at all times; and \u0393\u00c7\u00ffstack pebblings of l vertices\u0393\u00c7\u00d6 in which the pebbled vertices with\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "33\n", "authors": ["30"]}
{"title": "A formal approach to code optimization\n", "abstract": " We examine from a formal point of view some problems which arise in code optimization and present some of the results which can come from such an approach. Specifically, a set of transformations which characterize optimization algorithms for straight line code is presented. Then we present an algorithm which produces machine code for evaluating arithmetic expressions on machines with N \u0393\u00eb\u00d1 1 general purpose registers. We can prove that this algorithm produces optimal code when the cost criterion is the length of machine code generated.", "num_citations": "33\n", "authors": ["30"]}
{"title": "Terminal call processing in Esterel\n", "abstract": " Each physical device attached to a node in a data network has corresponding call processes that run within the node; specifically, within a control computer in the node. A call process is responsible for the set-up and take-down of calls to and from a device. Call processes are typically complex state machines that react to hardware signals and user input. This paper describes an implementation of a terminal call process in Esterel, a special language designed for programming reactive systems. We conclude that Esterel allows clear and concise code specifications for terminal call processes; furthermore, the specifications compile into implementations.", "num_citations": "32\n", "authors": ["30"]}
{"title": "Constructing call-by-value continuation semantics\n", "abstract": " The problem of transforming one semantic description for a language into another related description of the same language is considered. Since direct and continuation semantics have been studied in some detail, they are obvious test-beds for suggesting the problems that might be encountered in the process. One of the problems is that the semantic objects in two descriptions of a language may be quite dissimilar. For example, function values of procedures in direct semantics are quite different from function values in continuation semantics. MiMe and Reynolds have defined predicates which can be used to relate the two kinds of function values. Starting with such predicates, transformations are defined, and it is then shown that the transformations preserve the predicates. The transformations are used to construct continuation semantics, starting from a direct semantics of a language with procedures called by value.", "num_citations": "32\n", "authors": ["30"]}
{"title": "Efficient computation of expressions with common subexpressions\n", "abstract": " Previous results have shown that it~ s easy to generate optimal code from express, on trees, and that optimal code generauon becomes very difficult ff arbitrary common subexpress, ons are handled In this paper a class of expressions containing restricted common subexpressions from which optimal code can be generated effictentty is studied. These expressions are represented by a class of series-parallel graphs, which the authors call collapsible graphs, that mchide trees and are general enough to permit large common subexpresslons, but from which optmml code can be generated m polynomml time for a class of stack machines", "num_citations": "32\n", "authors": ["30"]}
{"title": "A review of the neurobiological underpinning of comorbid substance use and mood disorders\n", "abstract": " BackgroundThere is evidence that substance use disorders and other mental disorders may have shared biological mechanisms. However, the neurobiological basis of this comorbidity remains only partially explained. This review describes the historical evolution of the dual disorders concept and approach, and reviews the existing literature on neurobiological findings specifically regarding comorbid substance use and mood disorders.MethodsSearches were conducted using PubMed and Scopus in December 2017. A Boolean search was performed using combinations of \u0393\u00c7\u00a3dual diagnosis\u0393\u00c7\u00a5 or \u0393\u00c7\u00a3dual disorder\u0393\u00c7\u00a5 or \u0393\u00c7\u00a3depression\u0393\u00c7\u00a5 or \u0393\u00c7\u00a3bipolar\u0393\u00c7\u00a5 or \u0393\u00c7\u00a3affective disorder\u0393\u00c7\u00a5 or \u0393\u00c7\u00a3mood disorder\u0393\u00c7\u00a5 and \u0393\u00c7\u00a3substance use\u0393\u00c7\u00a5 or \u0393\u00c7\u00a3substance abuse\u0393\u00c7\u00a5 and \u0393\u00c7\u00a3neurobiology\u0393\u00c7\u00a5 or \u0393\u00c7\u00a3functional neuroimaging\u0393\u00c7\u00a5 or \u0393\u00c7\u00a3genetics\u0393\u00c7\u00a5 or \u0393\u00c7\u00a3neurotransmitters\u0393\u00c7\u00a5 or \u0393\u00c7\u00a3neuroendocrinology\u0393\u00c7\u00a5 in the title or abstract, or as keywords, using no language restriction.Results32 studies\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "31\n", "authors": ["30"]}
{"title": "Task Sequencing in a Batch Environment with Setup Times.\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u251c\u00actre utilis\u251c\u2310 dans le cadre d\u0393\u00c7\u00d6une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u251c\u2592alado antes, el contenido de este registro bibliogr\u251c\u00edfico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "31\n", "authors": ["30"]}
{"title": "Correct computation rules for recursive languages\n", "abstract": " This paper considers simple, LISP-like languages for the recursive definition of functions. We focus on the connections between formal computation rules for calculation with recursive definitions, and the mathematical semantics of such definitions. A computation rule is correct when it is capable of computing the least fixpoint of a recursive definition. We give necessary and sufficient conditions for the correctness of rules under (a) all possible interpretations and (b) particular interpretations.", "num_citations": "31\n", "authors": ["30"]}
{"title": "Control flow aspects of semantics directed compiling (Summary)\n", "abstract": " We focus on the part of a compiler between syntax analysis and code generation. A language is specified by adding semantic rules in a functional notation to the syntax of the language. Starting with a small sublanguage of while statements, the semantics of the statement constructs of C is built up incrementally. Using a small ad hoc code generator, a compiler has automatically been constructed from the semantics. The semantic description is analogous to a syntax directed construction of a flow diagram for a program. In analogy with grammars and parser generators, minimal knowledge of the underlying theory is required.", "num_citations": "29\n", "authors": ["30"]}
{"title": "Yacc: a parser generator\n", "abstract": " Since the early 1970s. W-l'('('has been used to implement hundreds of languages, big and small. Its applications range from small desk calculators. to medium-sized preprocessors for typesetting, to large compiler front ends for complete programming languages. A _\\\u0393\u00c7\u00fftJ't.'{\u0393\u00c7\u00ffspeci\u2229\u00bc\u00fccation is l-iased on a collection of grammar rules that describe the syntax of a language: _t'acc turns the specitication into a syntax analyzer. A pure syntax analyzer merely checks whether or not an input string conforms to the syntax of the language. We can go beyond pure syntax analysis by attaching code in C or C++ to a grammar rule: such code is called an action. and is esecuted whenever the rule is applied during syntax analysis. Thus. a desk calculator might use actions to evaluate an expression. and a compiler front end might use actions to emit intennediate code. Yorc allows us to build paisers from L.~\\LRt ll grammars v.-itltout\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "21\n", "authors": ["30"]}
{"title": "The global storage needs of a subcomputation\n", "abstract": " A defining characteristic of \u0393\u00c7\u00a3functional\u0393\u00c7\u00a5 specifications is the absence of assignments: updates of tables and data structures are expressed by giving the relationship between the new and old values. An obvious implementation allocates separate space for new and old values and may consume a lot of storage. However, even when updates of attributes like symbol tables are expressed functionally, we would like to avoid making copies of the symbol table during attribute evaluation. In other words, if possible, the implementation should have a single global copy of the table that is updated using assignments. Since the value of the global copy changes during computation, the order of evaluation has to be chosen carefully. In this paper, we partition attributes into classes, the problem being to determine if there exists an evaluation order that allows each class to share a global storage area. The solution extends to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "21\n", "authors": ["30"]}
{"title": "New directions in services management\n", "abstract": " The combined effects of the Internet and the rapid and continuing decrease in the cost of bandwidth are changing the nature of telecommunications and network management systems. This paper describes a number of research projects undertaken within Bell Labs to address the need for next\u0393\u00c7\u00c9generation management systems. Included are systems that will help providers plan and manage their networks and supply the tools providers need to offer on\u0393\u00c7\u00c9line service to their customers. Examples of the work under way to help providers plan their networks are the Spider dense wavelength division multiplexing (DWDM) design tool and the Teranet long\u0393\u00c7\u00c9range investment, pricing, and technology planning system. Recent networking applications projects include the IPWorX\u0393\u00e4\u00f3 content distribution system, the NetBlitz\u0393\u00e4\u00f3 Web accelerator browsing system, and the QTM\u0393\u00e4\u00f3, or Quick\u0393\u00c7\u00c9To\u0393\u00c7\u00c9Market, real\u0393\u00c7\u00c9time transaction\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "20\n", "authors": ["30"]}
{"title": "Circular expressions: elimination of static environments\n", "abstract": " Consider the connection between denotational semantics for a language with goto statements and flow diagrams for programs in such a language. The main point of interest is that the denotational semantics uses a recursively defined environment to give the meaning of labels, while a flow diagram merely has a jump to the appropriate program point. A simple reduction called \u0393\u00c7\u00a3indirection elimination\u0393\u00c7\u00a5 strips away the environment from the denotational semantics and extracts an expression with cycles (circular expression) that is very close to the flow diagram of a program. The same idea applies to associating bodies with recursive procedures, or to any construct whose semantics is not wedded to the syntax. Circular expressions are offered as a useful data structure and conceptual device. Expressions with cycles are well defined mathematical objects \u0393\u00c7\u00f6 their semantics can be given by unfolding them into\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "20\n", "authors": ["30"]}
{"title": "A model of concurrent database transactions\n", "abstract": " When several transactions (processes) read and write items in a database, the question of consistency of the database arises. Consistency is maintained if transactions are serial: all actions of a transaction execute completely before the actions of the next transaction begin. A particular history of interleaved actions belonging to several transactions is correct if it is equivalent to a serial history. We provide a natural framework for studying serializability that encompasses models that have been considered in the literature. A history is represented by a dag in which there is a vertex for each instantaneous value taken by an item in the database. The main tool for determining serializability are \"exclusion rules\" which determine implied orderings between vertices. For example, a vertex that uses a value must be serialized before the value is overwritten. An exclusion closure -- the result of applying the rules as long as\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "19\n", "authors": ["30"]}
{"title": "Properties of a notation for combining functions\n", "abstract": " A combmator called a pipe is proposed for combining functions in a hnear order. Examples suggest that semantic rules using pipes are easy to read and understand, even for readers with little knowledge of semantics The readability is a consequence ot the operational mtunion associated with pipes The operatJonal v~ ew is that each function connected by a pipe is handed a finite sequence of values Each function takes zero or more arguments from the right end of the sequence, replaces the arguments by zero or more results, and passes the sequence to the next function The new idea is that a function may skip over some number of values before picking up its arguments. This approach Is suited to expressing the composition of operations on machine states in a programming language. Pipes allow continuation semantics to be written with direct operators instead of the operator having to worry about its\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "18\n", "authors": ["30"]}
{"title": "A case study in specifying the semantics of a programming language\n", "abstract": " On and off over the period of about a year I have worked on a semantic specification for the C programming language My objective was to construct a readable and precise specification of C, aimed at compiler writers, maintainers, and language pundits. This paper is a report on the project.", "num_citations": "15\n", "authors": ["30"]}
{"title": "Conditional expressions with equality tests\n", "abstract": " Condmonal expressions of the form\" if E= F then G else H,\" where E, F, G, H may themselves be such expressions, have long been used to describe the semantics of assignments. We consider the problem of deciding if two nested condmonals of the above form compute the same values Three transformahons are used to solve the problem A dtstrtbutwe transformation converts any conditional to the sampler form if A= B then G else H, where A and B are variables rather than expressions. An trn-phed test transformation finds all tests in subexpresslons whose outcome as Jmphed by prevtous tests. Finally, the useless test transformation is used to reduce expressions of the form if A= B then C else C to C When all tests are between variables and the expressions are represented by trees, then equivalence of expressions can be tested in polynomial time The remaining cases have been shown elsewhere to be NP-hard", "num_citations": "15\n", "authors": ["30"]}
{"title": "A review of the pharmacological and clinical profile of newer atypical antipsychotics as treatments for bipolar disorder: considerations for use in older patients\n", "abstract": " Bipolar disorder prevalence rates vary in the older adult population (defined as age \u0393\u00eb\u00d1\u0393\u00c7\u00eb65\u252c\u00e1years), ranging from 1% in community dwellers to as high as 8\u0393\u00c7\u00f410% in hospital inpatients. Although older agents, including lithium and valproic acid, offer significant antimanic efficacy, as supported by a recent randomized controlled trial (RCT), there is growing interest in using atypical antipsychotics to treat bipolar disorder in older adults. Newer atypical antipsychotics are of interest based on their tolerability and efficacy in the general adult bipolar population. The aim of this review was to systematically examine efficacy and tolerability of newer atypical antipsychotics for older adult bipolar disorder (OABD). We conducted a systematic search utilizing the MEDLINE, EMBASE, PsycINFO and Cochrane Library electronic databases, with the aim of identifying all RCTs comparing newer atypical antipsychotics approved\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "14\n", "authors": ["30"]}
{"title": "Off-line and on-line algorithms for deducing equalities\n", "abstract": " The classical common subexpression problem in program optimization is the detection of identical subexpressions. Suppose we have some extra information and are given pairs of expressions e i1= e i2 which must have the same value, and expressions f j1\u0393\u00eb\u00e1 f j2 which must have different values. We ask if as a result, h 1= h 2, or h 1\u0393\u00eb\u00e1 h 2. This has been called the uniform word problem for finitely presented algebras, and has application in theorem-proving and code optimization. We show that such questions can be answered in O (nlogn) time, where n is the number of nodes in a graph representation of all relevant expressions. A linear time algorithm for detecting common subexpressions is derived. Algorithms which process equalities, inequalities and deductions on-line are discussed.", "num_citations": "14\n", "authors": ["30"]}
{"title": "Uniform syntax for type expressions and declarators\n", "abstract": " A declaration mechanism is proposed that allows common type information to be factored into a type expression, yet allows related but distinct types to be declared together. The mechanism is a unification of declarations in Pascal and C. The choice of syntax is quite important. The proposed syntax uses a postfix operator for dereferencing pointers instead of the prefix operator * for pointer dereferencing in C.", "num_citations": "13\n", "authors": ["30"]}
{"title": "A note on implementing parallel assignment instructions\n", "abstract": " Consider a permutation n on a set of integers {I, 2+.... n). n can be represented by the string n (l) lp (2)... n (n). Ibus, with rcferena to the string fo: a permutation, it makes sens to lexicographically order yermutatimrs on [1, 2,,.., n). Given a permutation (the string reahy), a simplified program to find the next higher permutation IJ given below.Consider the permutation 625431. Since S> 4> 3> 1, any reordering of the digits in positions 3-6 can only lead to a lower permutation. Ihe program starts at the right end and determines that 2 is the first digit snutler than the digit to its right. The prognuninmr&nges2and3 (3beingthe5rstdi~ t greater than 2) to form 635421, and then inverts the last four digits to give the desired rtiult, 631245. Other programs for the sanLe task may $ e found ti l3, & 101.", "num_citations": "13\n", "authors": ["30"]}
{"title": "Improving software quality as customers perceive it\n", "abstract": " A proposed data-driven software quality improvement method has three elements. First, the downstream Customer Quality Metric (CQM) quantifies quality as customers perceive it. On the basis of data collected after systems are deployed, it measures how serious defects affect customers. Second, the upstream Implementation Quality Index (IQI) measures the effectiveness of error removal during development. IQI predicts future customer quality; it has a positive correlation with CQM. Finally, prioritization tools and techniques help focus limited development resources on the riskiest files in the code. This research is based on a multiyear program to improve the quality of delivered systems at Avaya, a global provider of business communication and collaboration systems. Regular reviews with Avaya's R&D Quality Council provided governance for the program.", "num_citations": "12\n", "authors": ["30"]}
{"title": "Control software for virtual-circuit switches: Call processing\n", "abstract": " The software architecture in this paper has evolved through a sequence of research projects at AT&T Bell Laboratories. We review the architecture and describe an experimental reimplementation.             Calls from each device attached to a virtual-circuit switch are managed by a software process, called a line process; the line process translates call requests from the device into a uniform device-independent internal protocol. Host computers and trunks can have numerous lines multiplexed over a single physical link. This process-per-line architecture leads to a profusion of specialized processes, most of them idle, with very simple contexts. Previous implementations used machinedependent code to manage the processes.             The experimental implementation does basic call processing and was completed largely by three people in three months. It is portable. The architecture was reused, but the code\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "11\n", "authors": ["30"]}
{"title": "Instruction sets for evaluating arithmetic expressions\n", "abstract": " The evaluation of anthmeuc expressions on both register-oriented and stack-oriented machines can be stud~ ed using the same model because registers can be treated as a stack during the evaluation of express~ on trees, without loss m code efficiency The machine model in this paper has a hardware stack m which all computatmns take place. Reg~ ster-regmer and regmer-memory instructions are modeled by considering four possible instrucuons for each binary operator, depending on whether one or two operands are taken from the stack and on whether the left or the right operand~ s on top of the stack. There is a cost assocJated wtth each operation code, as well as costs for accessing a value in a register or in memory. The mtmmum cost of computing an expression tree~ s used to compare machines. The comparisons fall into two classes (1) By keeping the instruction set fixed, the effect of increasing the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "9\n", "authors": ["30"]}
{"title": "Analysis of a level algorithm for preemptive scheduling\n", "abstract": " Muntz and Coffman give a level algorithm that constructs optimal preemptive schedules on identical processors when the task system is a tree or when there are only two processors. A variation of their algorithm is adapted for processors of different speeds. The algorithm is shown to be optimal on two processors for arbitrary task systems, but not on three or more processors even for trees. Taking the algorithm as a heuristic on m processors and using the ratio of the lengths of the constructed and optimal schedules as a measure, we show that, on identical processors, its performance is bounded by 2-2/m. Moreover 2-2/m is a best bound in that there exist task systems for which this ratio is approached arbitrarily closely. On processors of different speeds, we derive an upper bound of its performance in terms of the speeds of the given processor system and show that@@@@ 1.5 m is an upper bound over all processor\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "9\n", "authors": ["30"]}
{"title": "How hard is compiler code generation?\n", "abstract": " Over the past two decades great strides have been made in understanding how to design lexical and syntactic analyzers for programming-language compilers. Theory and practice have proceeded to the point where usable lexical and syntactic analyzers can be generated automatically from notations based on regular expressions and context-free grammars [Aho and Ullman (1977), Johnson (1975), Lesk (1975)].Unfortunately, our understanding of code generation has not kept pace with the developments in the syntactic domain. Recently, however, a number of theoretical results have been obtained which suggest how well and how extensively code generation can be automated. This paper summarizes these results and discusses the problems that still remain to be solved.", "num_citations": "8\n", "authors": ["30"]}
{"title": "Scheduling independent tasks to reduce mean finishing-time\n", "abstract": " In this paper we study the problem of scheduling a set of independent tasks on m\u0393\u00eb\u00d1 1 processors to minimize the mean finishing-time (mean time in system). The importance of the mean finishing-time criterion is that its minimization tends to reduce the mean number of unfinished tasks in the system. In the paper we give a reduction of our scheduling problem to a transportation problem and thereby extend the class of known non enumerative scheduling algorithms [1]. Next we show that the inclusion of weights (weighted mean finishing-time) complicates the problem and speculate that there may be no non enumerative algorithm for this case. For the special case of identical processors we study the maximum finishing-time properties of schedules which are optimal with respect to mean finishing-time. Finally we give a scheduling algorithm having desirable properties with respect to both maximum finishing-time and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["30"]}
{"title": "Maintaining cross references in manuscripts\n", "abstract": " In this note, we show how a few UNIX\u0393\u00e4\u00f3 commands can be combined to create a flexible reference assembler that automatically maintains the consistency of cross references in manuscripts. The reference assembler can be used in conjunction with any text formatter.", "num_citations": "6\n", "authors": ["30"]}
{"title": "An architecture for call processing\n", "abstract": " Archos is a software architecture for call processing in switching networks. The goals are exibility, portability, switch independence, scalability and extensibility in the software. Archos is written as a C++ application of the Choices object-oriented operating system framework. The object-oriented approach provides consistent partitioning of call features, easy maintenance and simple prototyping of new features. Because Choices is a multiprocessor operating system, parallel processing can scale performance of the switch as utilization grows. iii", "num_citations": "5\n", "authors": ["30"]}
{"title": "Assignment commands and array structures\n", "abstract": " Straight line programs in which array elements can be referenced and set are considered. Two programs are equivalent if they compute the same expression as a function of the inputs. Testing the equivalence of programs with arrays is shown to be NP-complete, while programs without arrays can be tested for equivalence in linear time. Equivalence testing takes polynomial time when programs have either no references or no assignments to array elements.", "num_citations": "5\n", "authors": ["30"]}
{"title": "Programming Languages, Concepts and Constructs\n", "abstract": " How should a book on programming languages be organized? Some possibilities include dividing it into chapters that constitute mini-language primers, by concepts, along historical lines, or some combination of these. In his book, Programming Languages, Concepts and Constructs, Sethi seems to have struck just the right balance. The main part of the book is divided into seven chapters, each devoted to a concept that serves as the central idea, or even philosophy, around which a language may be designed. The careful choice of topics gives the reader a look at traditional languages (such as imperative languages) and also some newer ideas in language design (such as in the languages that emerged in the 1980s). Sethi illustrates each concept with two working languages, and by doing so, allows the reader to study language design choices. Using two languagesand no more-enables Sethi to penetrate the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["30"]}
{"title": "Parallelism as a Structuring Technique: Call Processing using the Estrel Language\n", "abstract": " Parallelism as a Structuring Technique | Proceedings of the IFIP 12th World Computer Congress on Algorithms, Software, Architecture - Information Processing '92, Volume 1 - Volume I ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleProceedingsProceedings of the IFIP 12th World Computer Congress on Algorithms, Software, Architecture - Information Processing '92, Volume 1 - Volume IParallelism as a Structuring Technique: Call Processing using the Estrel Language ARTICLE Parallelism as a Structuring Technique: Call Processing using the Estrel Language Share on Authors: Garyjames Murakami profile image Gary J. Murakami , : \u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["30"]}
{"title": "Constructing call-by-value continuation semantics\n", "abstract": " The primary motivation behind this paper is an interest in transforming one semantic description for a language into another related description of the same language. Since direct and continuation semantics have been studied in some detail, they are obvious test-beds for suggesting the problems that might be encountered in the process. One of the problems is that the semantic objects in two descriptions of a language may be quite dissimilar. For example, function values of procedures in direct semantics are quite different from function values in continuation semantics. Milne and Reynolds have defined predicates which can be used to relate the two kinds of function values. Starting with such predicates we define transformations and then show that the transformations preserve the predicates. The transformations are used to construct continuation semantics, starting from a direct semantics of a language\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["30"]}
{"title": "A comparison of instruction sets for stack machines\n", "abstract": " Suppose you are approached by a computer designer who wants to select a machine architecture and instruction set that is desirable from a compiler writers standpoint. What would you recommend, and why?", "num_citations": "3\n", "authors": ["30"]}
{"title": "A characterization ofLL(1) grammars\n", "abstract": " A new characterization ofLL(1) grammars that lends itself to testing for theLL(1) property is given. The characterization calls for the testing of intersections of FIRST sets for individual symbols rather than for right hand sides of productions.", "num_citations": "3\n", "authors": ["30"]}
{"title": "Correct computation rules for recursive languages\n", "abstract": " This paper considers simple LISP-like languages for the recursive definition of functions, focusing upon the connections between formal computation rules for calculation and the mathematical semantics of recursive definitions. A computation rule is correct when it is capable of computing the minimal fixpoint of a recursive definition. We give necessary and sufficient conditions for the correctness of rules under (a) all possible interpretations and (b) particular interpretations.", "num_citations": "3\n", "authors": ["30"]}
{"title": "Validating register allocations for straight line programs\n", "abstract": " Straight line programs are essentially sequences of assignment statements. A general program consists of straight line segments with flow of control between these segments. The interfaces between a straight line segment and the rest of the program place constraints on register allocations for the segment. These constraints may render a register allocation for a straight line program unrealizable. An algorithm is given to determine if a register allocation for a straight line program is realizable. It is shown that the algorithm takes 0 (n 3) steps, where n is the number of statements in the program. An unrealizable assignment may be made realizable by introducing stores into memory at appropriate points. It is shown how the minimum number of such stores may be found.", "num_citations": "3\n", "authors": ["30"]}
{"title": "Preprocessing embedded actions\n", "abstract": " Some parser generators allow the user to attach actions, consisting of executable code, to syntax rules. Actions are usually in the local programming language, so they are simply copied into the generated parser. However, we show two situations in which it is convenient to allow actions to be in a different notation. A preprocessor is used to translate such notations into the local programming language. A preprocessor must know where to find actions and how to translate them. We show how these two activities can be programmed separately. Often, the user only has to worry about the second part: once the parser generator is known, the placement of the actions is known as well, so routines for finding actions can be separately compiled and linked in. Examples in the paper are based on the parser generator Yacc, but the approach is not limited to Yacc, or even to parser generators. Certain compositions of syntax\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["30"]}
{"title": "Tr\u251c\u00bcnh bi\u251c\u00acn d\u00df\u2557\u00efch: Nguy\u251c\u00acn l\u251c\u255c k\u00df\u2557\u2563 thu\u00df\u2551\u00a1t v\u251c\u00e1 c\u251c\u2524ng c\u00df\u2557\u00d1-T\u00df\u2551\u00a1p 1\n", "abstract": " Tr\u251c\u00bcnh bi\u251c\u00acn d\u00df\u2557\u00efch: Nguy\u251c\u00acn l\u251c\u255c k\u00df\u2557\u2563 thu\u00df\u2551\u00a1t v\u251c\u00e1 c\u251c\u2524ng c\u00df\u2557\u00d1 - T\u00df\u2551\u00a1p 1 | Th\u255e\u2591 vi\u00df\u2557\u00e7n s\u00df\u2557\u00e6 \u2500\u00c9\u00df\u2551\u00edi h\u00df\u2557\u00ecc B\u251c\u00e1 R\u00df\u2557\u00efa - V\u253c\u2310ng T\u251c\u00e1u Skip navigation DSpace logo Home Browse Communities & Collections Browse Items by: Issue Date Author Title Subject Language Ti\u00df\u2551\u2510ng Vi\u00df\u2557\u00e7t English Register Sign on to: My DSpace Receive email updates Edit Profile DSpace JSPUI DSpace preserves and enables easy and open access to all types of digital content including text, images, moving images, mpegs and data sets Learn More 1.Th\u255e\u2591 vi\u00df\u2557\u00e7n s\u00df\u2557\u00e6 \u2500\u00c9\u00df\u2551\u00edi h\u00df\u2557\u00ecc B\u251c\u00e1 R\u00df\u2557\u00efa - V\u253c\u2310ng T\u251c\u00e1u 2.. Gi\u251c\u00edo tr\u251c\u00bcnh, t\u251c\u00e1i li\u00df\u2557\u00e7u tham kh\u00df\u2551\u00fao 3.C\u251c\u2524ng ngh\u00df\u2557\u00e7 th\u251c\u2524ng tin - \u2500\u00c9i\u00df\u2557\u00e7n - \u2500\u00c9i\u00df\u2557\u00e7n t\u00df\u2557\u00a1 4.CNTT Please use this identifier to cite or link to this item: http://thuvienso.bvu.edu.vn/handle/TVDHBRVT/13054 Title: Tr\u251c\u00bcnh bi\u251c\u00acn d\u00df\u2557\u00efch: Nguy\u251c\u00acn l\u251c\u255c k\u00df\u2557\u2563 thu\u00df\u2551\u00a1t v\u251c\u00e1 c\u251c\u2524ng c\u00df\u2557\u00d1 - T\u00df\u2551\u00a1p 1 Authors: Aho, Alfred V. Sethi, Ravi Ullman, Jeffrey D. Tr\u00df\u2551\u00ban, \u2500\u00c9\u00df\u2557\u2310c Quang Keywords: Tr\u251c\u00bcnh bi\u251c\u00acn d\u00df\u2557\u00efch (Ch\u255e\u2591\u255e\u00edng tr\u251c\u00bcnh m\u251c\u00edy t\u251c\u00a1nh) Issue Date: 2000 Publisher: : ://\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["30"]}
{"title": "Compilers: Principles, Techniques, and Tools</TITLE\n", "abstract": " \u0393\u00c7\u00f3 The Frame ontology (Gruber, 1993)\u0393\u00a3\u00ec partial vocabulary of the Frame ontology relation subclass-of (? child-class? parent-class) relation superclass-of (? parent-class? child-class) relation subrelation-of (? child-relation? parent-relation) relation direct-instance-of (? individual? class) relation direct-subclass-of (? child-class? parent-class)", "num_citations": "1\n", "authors": ["30"]}
{"title": "SCHEDULING GRAPHS ON TWO PROCESSORS.\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u251c\u00actre utilis\u251c\u2310 dans le cadre d\u0393\u00c7\u00d6une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u251c\u2592alado antes, el contenido de este registro bibliogr\u251c\u00edfico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "1\n", "authors": ["30"]}