{"title": "A framework for expressing the relationships between multiple views in requirements specification\n", "abstract": " Composite systems are generally comprised of heterogeneous components whose specifications are developed by many development participants. The requirements of such systems are invariably elicited from multiple perspectives that overlap, complement, and contradict each other. Furthermore, these requirements are generally developed and specified using multiple methods and notations, respectively. It is therefore necessary to express and check the relationships between the resultant specification fragments. We deploy multiple ViewPoints that hold partial requirements specifications, described and developed using different representation schemes and development strategies. We discuss the notion of inter-ViewPoint communication in the context of this ViewPoints framework, and propose a general model for ViewPoint interaction and integration. We elaborate on some of the requirements for expressing\u00a0\u2026", "num_citations": "783\n", "authors": ["1448"]}
{"title": "Inconsistency handling in multiperspective specifications\n", "abstract": " The development of most large and complex systems necessarily involves many people-each with their own perspectives on the system defined by their knowledge, responsibilities, and commitments. To address this we have advocated distributed development of specifications from multiple perspectives. However, this leads to problems of identifying and handling inconsistencies between such perspectives. Maintaining absolute consistency is not always possible. Often this is not even desirable since this can unnecessarily constrain the development process, and can lead to the loss of important information. Indeed since the real-world forces us to work with inconsistencies, we should formalize some of the usually informal or extra-logical ways of responding to them. This is not necessarily done by eradicating inconsistencies but rather by supplying logical rules specifying how we should act on them. To achieve\u00a0\u2026", "num_citations": "716\n", "authors": ["1448"]}
{"title": "Weaving together requirements and architectures\n", "abstract": " Software development organizations often choose between alternative starting points-requirements or architectures. This invariably results in a waterfall development process that produces artificially frozen requirements documents for use in the next step in the development life cycle. Alternatively, this process creates systems with constrained architectures that restrict users and handicap developers by resisting inevitable and desirable changes in requirements. The spiral life-cycle model addresses many drawbacks of a waterfall model by providing an incremental development process, in which developers repeatedly evaluate changing project risks to manage unstable requirements and funding. An even finer-grain spiral life cycle reflects both the realities and necessities of modern software development. Such a life cycle acknowledges the need to develop software architectures that are stable, yet adaptable, in\u00a0\u2026", "num_citations": "687\n", "authors": ["1448"]}
{"title": "Security requirements engineering: A framework for representation and analysis\n", "abstract": " This paper presents a framework for security requirements elicitation and analysis. The framework is based on constructing a context for the system, representing security requirements as constraints, and developing satisfaction arguments for the security requirements. The system context is described using a problem-oriented notation, then is validated against the security requirements through construction of a satisfaction argument. The satisfaction argument consists of two parts: a formal argument that the system can meet its security requirements and a structured informal argument supporting the assumptions expressed in the formal argument. The construction of the satisfaction argument may fail, revealing either that the security requirement cannot be satisfied in the context or that the context does not contain sufficient information to develop the argument. In this case, designers and architects are asked to\u00a0\u2026", "num_citations": "534\n", "authors": ["1448"]}
{"title": "Managing inconsistent specifications: reasoning, analysis, and action\n", "abstract": " In previous work, we advocated continued development of specifications in the presence of inconsistency. To support this, we used classical logic to represent partial specifications and to identify inconsistencies between them. We now present an adaptation of classical logic, which we term quasi-classical (QC) logic, that allows continued reasoning in the presence of inconsistency. The adaptation is a weakening of classical logic that prohibits all trivial derivations, but still allows all resolvants of the assumptions to be derived. Furthermore, the connectives behave in a classical manner. We then present a development called labeled QC logic that records and tracks assumptions used in reasoning. This facilitates a logical analysis of inconsistent information. We discuss that  application of labeled QC logic in the analysis of multiperspective specifications. Such specifications are developed by multiple particpants who\u00a0\u2026", "num_citations": "267\n", "authors": ["1448"]}
{"title": "Hypermedia support for argumentation-based rationale\n", "abstract": " Having developed, used and evaluated some of the early IBIS-based approaches to design rationale (DR) such as gIBIS and QOC in the late 1980s/mid-1990s, we describe the subsequent evolution of the argumentation-based paradigm through software support, and perspectives drawn from modeling and meeting facilitation. Particular attention is given to the challenge of negotiating the overheads of capturing this form of rationale. Our approach has maintained a strong emphasis on keeping the representational scheme as simple as possible to enable real time meeting mediation and capture, attending explicitly to the skills required to use the approach well, particularly for the sort of participatory, multistakeholder requirements analysis demanded by many design problems. However, we can then specialize the notation and the way in which the tool is used in the service of specific methodologies, supported by a\u00a0\u2026", "num_citations": "231\n", "authors": ["1448"]}
{"title": "Relating software requirements and architectures using problem frames\n", "abstract": " Problem frames provide a means of analyzing and decomposing problems. They emphasise the world outside of the computer, helping the developer to focus on the problem domain, instead of drifting into inventing solutions. However, even modestly complex problems can force us into detailed consideration of the architecture of the solution. This is counter to the intention of the problem frames approach, which is to delay consideration of the solution space until a good understanding of the problem is gained. We therefore extend problem frames, allowing architectural structures, services and artifacts to be considered as part of the problem domain. Through a case study, we show how this extension enhances the applicability of problem frames in permitting an architecture-based approach to software development. We conclude that, through our extension, the applicability of problem frames is extended to include\u00a0\u2026", "num_citations": "226\n", "authors": ["1448"]}
{"title": "A framework for security requirements engineering\n", "abstract": " This paper presents a framework for security requirements elicitation and analysis, based upon the construction of a context for the system and satisfaction arguments for the security of the system. One starts with enumeration of security goals based on assets in the system. These goals are used to derive security requirements in the form of constraints. The system context is described using a problem-centered notation, then this context is validated against the security requirements through construction of a satisfaction argument. The satisfaction argument is in two parts: a formal argument that the system can meet its security requirements, and a structured informal argument supporting the assumptions expressed in the formal argument. The construction of the satisfaction argument may fail, revealing either that the security requirement cannot be satisfied in the context, or that the context does not contain sufficient\u00a0\u2026", "num_citations": "172\n", "authors": ["1448"]}
{"title": "Identifying nocuous ambiguities in natural language requirements\n", "abstract": " We present a novel technique that automatically alerts authors of requirements to the presence of potentially dangerous ambiguities. We first establish the notion of nocuous ambiguities, which are those that are likely to lead to misunderstandings. We test our approach on coordination ambiguities, which occur when words such as and or are used. Our starting point is a dataset of ambiguous phrases from a requirements corpus and associated human judgements about their interpretation. We then use heuristics, based largely on word distribution information, to automatically replicate these judgements. The heuristics eliminate ambiguities which people interpret easily, leaving the nocuous ones to be analysed and rewritten by hand. We report on a series of experiments that evaluate our heuristics' performance against the human judgements. Many of our heuristics achieve high precision, and recall is greatly\u00a0\u2026", "num_citations": "153\n", "authors": ["1448"]}
{"title": "Ariane 5: who dunnit?\n", "abstract": " Risk management is not practiced in mission critical projects like Ariane 5--the launcher that exploded about 37 seconds after takeoff. Nuseibeh discusses the software errors that occurred before the explosion.", "num_citations": "144\n", "authors": ["1448"]}
{"title": "Security requirements engineering: When anti-requirements hit the fan\n", "abstract": " Everyone agrees that security is a problem, ranging from Microsoft to the banks that have been recent victims of rogue traders. What is paradoxical is that there does not seem to be a wholehearted commitment by both academics and industry to treat this topic systematically at the top level of requirements engineering. Our vision is of a future in which we inform the security requirements engineering process by organisational theory. This would act as the bridge between the well-ordered world of the software project informed by conventional requirements and the unexpected world of anti-requirements associated with the malicious user. We frame a vision for the requirements engineering community that would involve the community solving six difficult problems.", "num_citations": "141\n", "authors": ["1448"]}
{"title": "Analysing anaphoric ambiguity in natural language requirements\n", "abstract": " Many requirements documents are written in natural language (NL). However, with the flexibility of NL comes the risk of introducing unwanted ambiguities in the requirements and misunderstandings between stakeholders. In this paper, we describe an automated approach to identify potentially nocuous ambiguity, which occurs when text is interpreted differently by different readers. We concentrate on anaphoric ambiguity, which occurs when readers may disagree on how pronouns should be interpreted. We describe a number of heuristics, each of which captures information that may lead a reader to favor a particular interpretation of the text. We use these heuristics to build a classifier, which in turn predicts the degree to which particular interpretations are preferred. We collected multiple human judgements on the interpretation of requirements exhibiting anaphoric ambiguity and showed how the\u00a0\u2026", "num_citations": "136\n", "authors": ["1448"]}
{"title": "Architecture-driven problem decomposition\n", "abstract": " Jackson's problem frames provide a means of analysing and decomposing problems. They emphasise the world outside the computer helping the developer to focus on the problem domain instead of drifting into inventing solutions. The intention is to delay consideration of the solution space until a good understanding of the problem is gained. In contrast, early consideration of a solution architecture is common practice in software development. Software is usually developed by including existing components and/or reusing existing frameworks and architectures. This has the advantage of shortening development time through reuse, and increasing the robustness of a system through the application of tried and tested solutions. In This work, we show how these two views can be reconciled and demonstrate how a choice of architecture can facilitate problem analysis, decomposition and subsequent recomposition\u00a0\u2026", "num_citations": "134\n", "authors": ["1448"]}
{"title": "Keeping ubiquitous computing to yourself: A practical model for user control of privacy\n", "abstract": " As with all the major advances in information and communication technology, ubiquitous computing (ubicomp) introduces new risks to individual privacy. Our analysis of privacy protection in ubicomp has identified four layers through which users must navigate: the regulatory regime they are currently in, the type of ubicomp service required, the type of data being disclosed, and their personal privacy policy. We illustrate and compare the protection afforded by regulation and by some major models for user control of privacy. We identify the shortcomings of each and propose a model which allows user control of privacy levels in a ubicomp environment. Our model balances the user's privacy preferences against the applicable privacy regulations and incorporates five types of user controlled \u201cnoise\u201d to protect location privacy by introducing ambiguities. We also incorporate an economics-based approach to assist users\u00a0\u2026", "num_citations": "130\n", "authors": ["1448"]}
{"title": "Deriving security requirements from crosscutting threat descriptions\n", "abstract": " It is generally accepted that early determination of the stakeholder requirements assists in the development of systems that better meet the needs of those stakeholders. General security requirements frustrate this goal because it is difficult to determine how they affect the functional requirements of the system. This paper illustrates how representing threats as crosscutting concerns aids in determining the effect of security requirements on the functional requirements. Assets (objects that have value in a system) are first enumerated, and then threats on these assets are listed. The points where assets and functional requirements join are examined to expose vulnerabilities to the threats. Security requirements, represented as constraints, are added to the functional requirements to reduce the scope of the vulnerabilities. These requirements are used during the analysis and specification process, thereby incorporating\u00a0\u2026", "num_citations": "130\n", "authors": ["1448"]}
{"title": "Introducing abuse frames for analysing security requirements\n", "abstract": " We are developing an approach using Jackson's Problem Frames to analyse security problems in order to determine security vulnerabilities. We introduce the notion of an anti-requirement as the requirement of a malicious user that can subvert an existing requirement. We incorporate anti-requirements into so-called abuse frames to represent the notion of a security threat imposed by malicious users in a particular problem context. We suggest how abuse frames can provide a means for bounding the scope of security problems in order to analyse security threats and derive security requirements.", "num_citations": "128\n", "authors": ["1448"]}
{"title": "Using language as related stimuli for concept generation\n", "abstract": " This paper examines the use of language, specifically verbs, as stimuli for concept generation. Because language has been shown to be important to the reasoning process in general as well as to specific reasoning processes that are central to the design process, we are investigating the relationship between language and conceptual design. The use of language to facilitate different stages of the design process has been investigated in the past. Our previous work, and the work of others, showed that ideas produced can be expressed through related hierarchical lexical relationships, so we investigated the use of verbs within these hierarchical relationships as stimuli for ideas. Participants were provided with four problems and related verb stimuli, and asked to develop concepts using the stimuli provided. The stimuli sets were generated by exploring verb hierarchies based on functional words from the problem\u00a0\u2026", "num_citations": "115\n", "authors": ["1448"]}
{"title": "Lightweight validation of natural language requirements\n", "abstract": " In this paper, we report on our experiences of using lightweight formal methods for the partial validation of natural language requirements documents. We describe our approach to checking properties of models obtained by shallow parsing of natural language requirements, and apply it to a case study based on part of a NASA specification of the Node Control Software on the International Space Station. The experience reported supports our position that it is feasible and useful to perform automated analysis of requirements expressed in natural language. Indeed, we identified a number of errors in our case study that were also independently discovered and corrected by NASA's Independent Validation and Verification Facility in a subsequent version of the same document, and others that were not discovered. The paper describes the techniques we used, the errors we found and reflects on the lessons learned\u00a0\u2026", "num_citations": "113\n", "authors": ["1448"]}
{"title": "Inconsistency handling in multi-perspective specifications\n", "abstract": " The development of most large and complex systems necessarily involves many people \u2014 each with their own perspectives on the system defined by their knowledge, responsibilities, and commitments. To address this we have advocated distributed development of specifications from multiple perspectives. However, this leads to problems of identifying and handling inconsistencies between such perspectives. Maintaining absolute consistency is not always possible. Often this is not even desirable since this can unnecessarily constrain the development process, and can lead to the loss of important information. Indeed since the real-world forces us to work with inconsistencies, we should formalise some of the usually informal or extra-logical ways of responding to them. This is not necessarily done by eradicating inconsistencies but rather by supplying logical rules specifying how we should act on them. To\u00a0\u2026", "num_citations": "113\n", "authors": ["1448"]}
{"title": "To be and not to be: On managing inconsistency in software development\n", "abstract": " The development of software systems involves the detection and handling of inconsistencies. These inconsistencies arise in system requirements, design specifications and, quite often in the descriptions that form the final implemented software product. The paper presents a critical review of approaches that explicitly tolerate and manage inconsistencies, and explores different kinds of inconsistencies that arise during different stages of software development. Managing inconsistency refers not only to the detection and removal of inconsistencies, but also to activities that facilitate continued development in their presence. Such activities include procedures for controlled amelioration or avoidance of inconsistency, which in turn may require analysis and reasoning in the presence of inconsistency.", "num_citations": "108\n", "authors": ["1448"]}
{"title": "Using abuse frames to bound the scope of security problems\n", "abstract": " Security problems arise from the concern for protecting assets from security threats. In a systems development process, the security protection of a system is specified by security requirements, identified from the analysis of the threats to the system. However, as it is often not possible to obtain a full system description until late in the RE process, a security problem often has to be described in the context of a bounded scope, that is, one containing only the domains relevant to some part of the functionality of the full system. By binding the scope of a security problem, it can be described more explicitly and precisely, thereby facilitating the identification and analysis of threats, which in turn drive the elicitation and elaboration of security requirements. In this poster, we elaborate on an approach we developed based on abuse frames and suggest how it can provide a means for structuring and bounding the scope security\u00a0\u2026", "num_citations": "105\n", "authors": ["1448"]}
{"title": "From spaces to places: emerging contexts in mobile privacy\n", "abstract": " Mobile privacy concerns are central to Ubicomp and yet remain poorly understood. We advocate a diversified approach, enabling the cross-interpretation of data from complementary methods. However, mobility imposes a number of limitations on the methods that can be effectively employed. We discuss how we addressed this problem in an empirical study of mobile social networking. We report on how, by combining a variation of experience sampling and contextual interviews, we have started focusing on a notion of context in relation to privacy, which is subjectively defined by emerging socio-cultural knowledge, functions, relations and rules. With reference to Gieryn's sociological work, we call this place, as opposed to a notion of context that is objectively defined by physical and factual elements, which we call space. We propose that the former better describes the context for mobile privacy.", "num_citations": "103\n", "authors": ["1448"]}
{"title": "An abductive approach for analysing event-based requirements specifications\n", "abstract": " We present a logic and logic programming based approach for analysing event-based requirements specifications given in terms of a system\u2019s reaction to events and safety properties. The approach uses a variant of Kowalski and Sergot\u2019s Event Calculus to represent such specifications declaratively and an abductive reasoning mechanism for analysing safety properties. Given a system description and a safety property, the abductive mechanism is able to identify a complete set of counterexamples (if any exist) of the property in terms of symbolic \u201ccurrent\u201d states and associated event-based transitions. A case study of an automobile cruise control system specified in the SCR framework is used to illustrate our approach. The technique described is implemented using existing tools for abductive logic programming.", "num_citations": "101\n", "authors": ["1448"]}
{"title": "Model-based security engineering of distributed information systems using UMLsec\n", "abstract": " Given the explosive growth of digitally stored information in modern enterprises, distributed information systems together with search engines are increasingly used in companies. By enabling the user to search all relevant information sources with one single query, however, crucial risks concerning information security arise. In order to make these applications secure, it is not sufficient to penetrate- and-patch past system development, but security analysis has to be an integral part of the system design process for such distributed information systems. This work presents the experiences and results of the security analysis of a search engine in the intranet of a German car manufacturer, by making use of an approach to model-based security engineering that is based on the UML extension UMLsec. The focus lies on the application's single-sign-on-mechanism, which was analyzed using the UMLsec method and tools\u00a0\u2026", "num_citations": "100\n", "authors": ["1448"]}
{"title": "Viewpoints: A vehicle for method and tool integration\n", "abstract": " This paper proposes an object-based framework for the development of heterogeneous, composite systems. Such systems require the use of multiple notations and development strategies to describe multiple developer perspectives. The framework employs coarse-grain objects, called ViewPoints, that represent \u201cagents\u201d having \u201crolesin\u201d and \u201cviews-of\u201d a problem domain. These ViewPoints are loosely coupled, locally managed encapsulations, integrated via inter-ViewPoint consistency relations and transformations.Tool integration is treated as a special case of method integration, and is demonstrated by The\u221a iewer-a prototype support environment presented in this paper. The\u221a iewer supports the proposed framework, and illustrates how ViewPoints may be used for method design, description, integration and use. Developed in Objectworks/Smalltalk, it maps the object-based framework onto an object-oriented implementation. The top level architecture and implementation of The\u221a iewer is also briefly presented.", "num_citations": "100\n", "authors": ["1448"]}
{"title": "Method engineering for multi-perspective software development\n", "abstract": " This paper examines the role of the method engineer in the context of multi-perspective software development. Such development is characterized by the existence of multiple development participants who hold multiple views on a system and its domain. These views may be described and developed using multiple representation schemes and development strategies respectively. The paper outlines the Viewpoints framework\u2014an organizational framework developed to model such a scenario\u2014and then examines the method engineering process required to support the kind of multi-perspective development described. The role of tool support in this context is also explored.", "num_citations": "95\n", "authors": ["1448"]}
{"title": "Composing requirements using problem frames\n", "abstract": " Problem frames are a systematic approach to the decomposition of problems that allows us to relate requirements, domain properties, and machine specifications. Having decomposed a problem, one approach to solving it is through a process of composing solutions to sub-problems. In This work, we contribute to supporting such a process by providing a way to compose multiple problem frames. We develop a systematic approach to composing inconsistent requirements. We introduce composition frames, a requirements construct that models relevant aspects of composition and thus deals with unwanted effects, such as interference of overlapping reactions to events. Throughout the paper, we use a simple case study to illustrate and validate our ideas.", "num_citations": "94\n", "authors": ["1448"]}
{"title": "Modelling access policies using roles in requirements engineering\n", "abstract": " Pressures are increasing on organisations to take an early and more systematic approach to security. A key to enforcing security is to restrict access to valuable assets. We regard access policies as security requirements that specify such restrictions. Current requirements engineering methods are generally inadequate for eliciting and analysing these types of requirements, because they do not allow complex organisational structures and procedures that underlie policies to be represented adequately. This paper discusses roles and why they are important in the analysis of security. The paper relates roles to organisational theory and how they could be employed to define access policies. A framework is presented, based on these concepts, for analysing access policies.", "num_citations": "88\n", "authors": ["1448"]}
{"title": "Privacy-by-design framework for assessing internet of things applications and platforms\n", "abstract": " The Internet of Things (IoT) systems are designed and developed either as standalone applications from the ground-up or with the help of IoT middleware platforms. They are designed to support different kinds of scenarios, such as smart homes and smart cities. Thus far, privacy concerns have not been explicitly considered by IoT applications and middleware platforms. This is partly due to the lack of systematic methods for designing privacy that can guide the software development process in IoT. In this paper, we propose a set of guidelines, a privacy by-design framework, that can be used to assess privacy capabilities and gaps of existing IoT applications as well as middleware platforms. We have evaluated two open source IoT middleware platforms, namely OpenIoT and Eclipse SmartHome, to demonstrate how our framework can be used in this way.", "num_citations": "85\n", "authors": ["1448"]}
{"title": "Core security requirements artefacts\n", "abstract": " Although security requirements engineering has recently attracted increasing attention, it has lacked a context in which to operate. A number of papers have described how security requirements may be violated, but apart from a few hints in the general literature, none have described satisfactorily what security requirements are.This paper proposes a framework of core security requirements artefacts, which unifies the concepts of the two disciplines of requirements engineering and security engineering. From requirements engineering it takes the concept of functional goals, which are operationalised into functional requirements, with appropriate constraints. From security engineering it takes the concept of assets, together with threats of harm to those assets. Security goals aim to protect from those threats, and are operationalised into security requirements, which take the form of constraints on the functional requirements.", "num_citations": "82\n", "authors": ["1448"]}
{"title": "Requirements-driven adaptive security: Protecting variable assets at runtime\n", "abstract": " Security is primarily concerned with protecting assets from harm. Identifying and evaluating assets are therefore key activities in any security engineering process - from modeling threats and attacks, discovering existing vulnerabilities, to selecting appropriate countermeasures. However, despite their crucial role, assets are often neglected during the development of secure software systems. Indeed, many systems are designed with fixed security boundaries and assumptions, without the possibility to adapt when assets change unexpectedly, new threats arise, or undiscovered vulnerabilities are revealed. To handle such changes, systems must be capable of dynamically enabling different security countermeasures. This paper promotes assets as first-class entities in engineering secure software systems. An asset model is related to requirements, expressed through a goal model, and the objectives of an attacker\u00a0\u2026", "num_citations": "80\n", "authors": ["1448"]}
{"title": "Analysing inconsistent specifications\n", "abstract": " In previous work we advocated continued development of specifications in the presence of inconsistency. To support this we presented quasi-classical (QC) logic for reasoning with inconsistent specifications. The logic allows the derivation of non-trivial classical inferences from inconsistent information. In this paper we present a development called labelled QC logic, and some associated analysis tools, that allows the tracking and diagnosis of inconsistent information. The results of analysis are then used to guide further development in the presence of inconsistency. We illustrate the logic and our tools by specifying and analysing parts of the London Ambulance Service. We argue that the scalability of our approach is made possible by deploying the ViewPoints framework for multi-perspective development, such that our analysis tools are only used on partial specifications of a manageable size.", "num_citations": "80\n", "authors": ["1448"]}
{"title": "Social adaptation: when software gives users a voice\n", "abstract": " Adaptive systems are characterized by the ability to monitor changes in their volatile world and react to monitored changes when needed. The ultimate goal of adaptation is that users\u2019 requirements are always met correctly and efficiently. Adaptation is traditionally driven by the changing state of the system internal and its surrounding environment. Such state should be monitored and analyzed to decide upon a suitable alternative behaviour to adopt. In this paper, we introduce another driver for adaptation which is the users\u2019 collective judgement on the alternative behaviors of a system. This judgmenet should be infered from the individual users\u2019 feedback given iteratviely during the lifetime of a system. Users\u2019 feedback reflects their main interest which is the validity and the quality of a system behaviour as a means to meet their requirements. We propose social adaptation which is a specific kind of adaptation that treats users\u2019 feedback, obtained during the software lifetime, as a primary driver in planning and guiding adaptation. We propose a novel requirements engineering modelling and analysis approach meant for systems adopting social adaptation. We evaluate our approach by applying it in practice and report on the results.", "num_citations": "77\n", "authors": ["1448"]}
{"title": "Contravision: exploring users' reactions to futuristic technology\n", "abstract": " How can we best explore the range of users' reactions when developing future technologies that may be controversial, such as personal healthcare systems? Our approach--ContraVision--uses futuristic videos, or other narrative forms, that convey either negative or positive aspects of the proposed technology for the same scenarios. We conducted a user study to investigate what range of responses the different versions elicited. Our findings show that the use of two systematically comparable representations of the same technology can elicit a wider spectrum of reactions than a single representation can. We discuss why this is so and the value of obtaining breadth in user feedback for potentially controversial technologies.", "num_citations": "77\n", "authors": ["1448"]}
{"title": "Automatic detection of nocuous coordination ambiguities in natural language requirements\n", "abstract": " Natural language is prevalent in requirements documents. However, ambiguity is an intrinsic phenomenon of natural language, and is therefore present in all such documents. Ambiguity occurs when a sentence can be interpreted differently by different readers. In this paper, we describe an automated approach for characterizing and detecting so-called nocuous ambiguities, which carry a high risk of misunderstanding among different readers. Given a natural language requirements document, sentences that contain specific types of ambiguity are first extracted automatically from the text. A machine learning algorithm is then used to determine whether an ambiguous sentence is nocuous or innocuous, based on a set of heuristics that draw on human judgments, which we collected as training data. We implemented a prototype tool for Nocuous Ambiguity Identification (NAI), in order to illustrate and evaluate our\u00a0\u2026", "num_citations": "69\n", "authors": ["1448"]}
{"title": "Engineering adaptive privacy: on the role of privacy awareness requirements\n", "abstract": " Applications that continuously gather and disclose personal information about users are increasingly common. While disclosing this information may be essential for these applications to function, it may also raise privacy concerns. Partly, this is due to frequently changing context that introduces new privacy threats, and makes it difficult to continuously satisfy privacy requirements. To address this problem, applications may need to adapt in order to manage changing privacy concerns. Thus, we propose a framework that exploits the notion of privacy awareness requirements to identify runtime privacy properties to satisfy. These properties are used to support disclosure decision making by applications. Our evaluations suggest that applications that fail to satisfy privacy awareness requirements cannot regulate users' information disclosure. We also observe that the satisfaction of privacy awareness requirements is\u00a0\u2026", "num_citations": "68\n", "authors": ["1448"]}
{"title": "On the impact of real-time feedback on users' behaviour in mobile location-sharing applications\n", "abstract": " Effective privacy management requires that mobile systems' users be able to make informed privacy decisions as their experience and knowledge of a system progresses. Prior work has shown that making such privacy decisions is a difficult task for users because systems do not provide support for awareness, visibility and accountability when sharing privacy-sensitive information. This paper reports results of our investigation into the efficacy of realtime feedback as a mechanism for incorporating these features of social translucence in location-sharing applications, in order to help users make better privacy decisions. We explored the role of real-time feedback in the context of Buddy Tracker, a mobile location-sharing application. Our work focuses on ways in which real-time feedback affects people's behaviour in order to identify the main criteria for acceptance of this technology. Based on the data from a three week\u00a0\u2026", "num_citations": "68\n", "authors": ["1448"]}
{"title": "Using trust assumptions with security requirements\n", "abstract": " Assumptions are frequently made during requirements analysis of a system about the trustworthiness of its various components (including human components). These trust assumptions, whether implicit or explicit, affect the scope of the analysis, derivation of security requirements, and in some cases how functionality is realized. This paper presents trust assumptions in the context of analysis of security requirements. A running example shows how trust assumptions can be used by a requirements engineer to help define and limit the scope of analysis and to document the decisions made during the process. The paper concludes with a case study examining the impact of trust assumptions on software that uses the secure electronic transaction specification.", "num_citations": "67\n", "authors": ["1448"]}
{"title": "A multi-perspective framework for method integration\n", "abstract": " The development of large and complex systems necessarily involves many people-each with their own perspective on the system, defined by their skills, responsibilities and expertise. This is particularly true for composite systems, that is, systems which deploy multiple component technologies. The intersections between perspectives however, are far from obvious because the knowledge within each is represented in different ways. Furthermore, because development may be carried out concurrently by those involved, different perspectives may be at different stages of elaboration, and may be subject to different development strategies. The problem of how to guide and organise systems development in this setting, we term the \u201cmultiple perspectives problem\u201d.", "num_citations": "67\n", "authors": ["1448"]}
{"title": "A framework for security requirements engineering\n", "abstract": " Although security requirements engineering has recently attracted increasing attention, it has lacked a context in which to operate. A number of papers have described how security requirements may be violated, but apart from a few hints in the general literature, none have described satisfactorily what security requirements are.This paper proposes a framework which unifies the concepts of the two disciplines of requirements engineering and security engineering. From requirements engineering it takes the concept of functional goals, which are operationalised into functional requirements, with appropriate constraints. From security engineering it takes the concept of assets, together with threats of harm to those assets. Security goals aim to protect from those threats, and are operationalised into security requirements, which take the form of constraints on the functional requirements.", "num_citations": "66\n", "authors": ["1448"]}
{"title": "The effect of trust assumptions on the elaboration of security requirements\n", "abstract": " Assumptions are frequently made during requirements analysis of a system-to-be about the trustworthiness of its various components (including human components). These trust assumptions can affect the scope of the analysis, derivation of security requirements, and in some cases, how functionality is realized. This work presents trust assumptions in the context of analysis of security requirements. A running example shows how trust assumptions can be used by a requirements engineer to help define and limit the scope of analysis and to document the decisions made during the process. The paper concludes with a case study examining the impact of trust assumptions on software that uses the secure electronic transaction (SET) specification.", "num_citations": "65\n", "authors": ["1448"]}
{"title": "A hybrid model for automatic emotion recognition in suicide notes\n", "abstract": " We describe the Open University team's submission to the 2011 i2b2/VA/Cincinnati Medical Natural Language Processing Challenge, Track 2 Shared Task for sentiment analysis in suicide notes. This Shared Task focused on the development of automatic systems that identify, at the sentence level, affective text of 15 specific emotions from suicide notes. We propose a hybrid model that incorporates a number of natural language processing techniques, including lexicon-based keyword spotting, CRF-based emotion cue identification, and machine learning-based emotion classification. The results generated by different techniques are integrated using different vote-based merging strategies. The automated system performed well against the manually-annotated gold standard, and achieved encouraging results with a micro-averaged F-measure score of 61.39% in textual emotion recognition, which was ranked 1st\u00a0\u2026", "num_citations": "64\n", "authors": ["1448"]}
{"title": "Arguing security: Validating security requirements using structured argumentation\n", "abstract": " This paper proposes using both formal and structured informal arguments to show that an eventual realized system can satisfy its security requirements. These arguments, called 'satisfaction arguments', consist of two parts: a formal argument based upon claims about domain properties, and a set of informal arguments that justify the claims. Building on our earlier work on trust assumptions and security requirements, we show how using satisfaction arguments assists in clarifying how a system satisfies its security requirements, in the process identifying those properties of domains that are critical to the requirements.", "num_citations": "60\n", "authors": ["1448"]}
{"title": "On the interplay between cyber and physical spaces for adaptive security\n", "abstract": " Ubiquitous computing is resulting in a proliferation of cyber-physical systems that host or manage valuable physical and digital assets. These assets can be harmed by malicious agents through both cyber-enabled or physically-enabled attacks, particularly ones that exploit the often ignored interplay between the cyber and physical world. The explicit representation of spatial topology is key to supporting adaptive security policies. In this paper we explore the use of Bigraphical Reactive Systems to model the topology of cyber and physical spaces and their dynamics. We utilise such models to perform speculative threat analysis through model checking to reason about the consequences of the evolution of topological configurations on the satisfaction of security requirements. We further propose an automatic planning technique to identify an adaptation strategy enacting security policies at runtime to prevent\u00a0\u2026", "num_citations": "58\n", "authors": ["1448"]}
{"title": "Feature interaction: The security threat from within software systems\n", "abstract": " Security engineering is about protecting assets from harm. The feature interaction problem occurs when the composition of features leads to undesirable system behaviours. Usually, this problem manifests itself as conflicting actions of features on a shared context. Security requirements may be violated by feature interactions creating security vulnerabilities which can potentially be exploited by attackers. In this paper, we discuss the feature interaction problem and some of its possible implications for security requirements. The paper concludes that (1) the detection of the violation of security requirements by feature interactions is not different from other types of requirements-what differs is the impact of such violation; and (2) feature interaction detection approaches can be used as a means for vulnerability analysis.", "num_citations": "57\n", "authors": ["1448"]}
{"title": "Speculative requirements: Automatic detection of uncertainty in natural language requirements\n", "abstract": " Stakeholders frequently use speculative language when they need to convey their requirements with some degree of uncertainty. Due to the intrinsic vagueness of speculative language, speculative requirements risk being misunderstood, and related uncertainty overlooked, and may benefit from careful treatment in the requirements engineering process. In this paper, we present a linguistically-oriented approach to automatic detection of uncertainty in natural language (NL) requirements. Our approach comprises two stages. First we identify speculative sentences by applying a machine learning algorithm called Conditional Random Fields (CRFs) to identify uncertainty cues. The algorithm exploits a rich set of lexical and syntactic features extracted from requirements sentences. Second, we try to determine the scope of uncertainty. We use a rule-based approach that draws on a set of hand-crafted linguistic\u00a0\u2026", "num_citations": "54\n", "authors": ["1448"]}
{"title": "Extending nocuous ambiguity analysis for anaphora in natural language requirements\n", "abstract": " This paper presents an approach to automatically identify potentially nocuous ambiguities, which occur when text is interpreted differently by different readers of requirements written in natural language. We extract a set of anaphora ambiguities from a range of requirements documents, and collect multiple human judgments on their interpretations. The judgment distribution is used to determine if an ambiguity is nocuous or innocuous. We investigate a number of antecedent preference heuristics that we use to explore aspects of anaphora which may lead a reader to favour a particular interpretation. Using machine learning techniques, we build an automated tool to predict the antecedent preference of noun phrase candidates, which in turn is used to identify nocuous ambiguity. We report on a series of experiments that we conducted to evaluate the performance of our automated system. The results show that the\u00a0\u2026", "num_citations": "54\n", "authors": ["1448"]}
{"title": "Communication patterns of agile requirements engineering\n", "abstract": " An agile software development team relies on communication and collaboration to perform requirements engineering activities, rather than on dedicated analysis tools or documentation. Evidence from practice indicates that two simple physical artefacts (story cards and the wall), used in a particular and disciplined manner, and supported by appropriate social activity, are key to the success of co-located agile teams. However, little is known about this social activity or how communication and collaboration supports requirements activities in this setting. This paper reports an empirical study of a commercial agile team to investigate this issue. Using a combination of qualitative data collection and cognitive analysis techniques, we found evidence of gathering, evolving and clarifying requirements that are managed through patterns of communication. These patterns suggest that a form of situated conceptualization\u00a0\u2026", "num_citations": "52\n", "authors": ["1448"]}
{"title": "Towards an analytical role modelling framework for security requirements\n", "abstract": " Pressures are increasing on organisations to take a more systematic approach to incorporating security into their software development process. The key to this is analysing security requirements early on, rather than treating security as an add-on, as is often the case. An important component of security requirements is access control, and roles have been found to provide an effective basis for defining access restrictions. Current requirements engineering methods are generally inadequate for eliciting and analysing these types of requirements, because they do not allow the complex organisational structures and procedures that form the basis of role-based security policy to be represented adequately. In this paper, we outline the concepts that underpin role-based access control, and relate these to organisational theory, to give a basis for defining roles. We then propose an analytical role modelling framework that enables us to model and analyse access restrictions based on these concepts. The framework is illustrated by a detailed example taken from the healthcare domain.", "num_citations": "52\n", "authors": ["1448"]}
{"title": "Lightweight validation of natural language requirements: a case study\n", "abstract": " The authors report on their experiences of using lightweight formal methods for the partial validation of natural language (NL) requirements documents. They describe a case study based on part of NASA's specification of the Node Control Software of the International Space Station, and apply to it their method of checking properties on models obtained by shallow parsing of natural language requirements. These experiences support the position that it is feasible and useful to perform automated analysis of requirements expressed in natural language. Indeed the authors identified a number of errors in their case study that were also independently discovered and corrected by NASA's IV and V Facility in a subsequent version of the same document. The paper describes the techniques used, the errors found, and reflects on the lessons learned.", "num_citations": "52\n", "authors": ["1448"]}
{"title": "Crosscutting requirements\n", "abstract": " Evidence is mounting that aspect-oriented programming is useful for (re-) structuring the many concerns that software is designed to address. Many of these concerns often arise in the problem domain, and, therefore, there is a growing effort to examine'early aspects'-to identify and represent concerns that arise during software requirements engineering and design, and to determine how these concerns interact. But can one seek to identify aspects too early? While identifying concerns during requirements elicitation may indeed be profitable, the notion of crosscutting concerns, indeed of crosscutting requirements, may only make sense when elements of a solution also begin to be explored. There are two consequences of this: a case for more interleaving of the processes of requirements engineering and design, and a case for the explicit development of specifications that map the problem and solution structures\u00a0\u2026", "num_citations": "49\n", "authors": ["1448"]}
{"title": "Designing privacy-aware internet of things applications\n", "abstract": " Internet of Things (IoT) applications typically collect and analyse personal data that can be used to derive sensitive information about individuals. However, thus far, privacy concerns have not been explicitly considered in software engineering processes when designing IoT applications. With the advent of behaviour driven security mechanisms, failing to address privacy concerns in the design of IoT applications can also have security implications. In this paper, we explore how a Privacy-by-Design (PbD) framework, formulated as a set of guidelines, can help software engineers integrate data privacy considerations into the design of IoT applications. We studied the utility of this PbD framework by studying how software engineers use it to design IoT applications. We also explore the challenges in using the set of guidelines to influence the IoT applications design process. In addition to highlighting the benefits of\u00a0\u2026", "num_citations": "48\n", "authors": ["1448"]}
{"title": "Security requirements engineering for evolving software systems: A survey\n", "abstract": " Long-lived software systems often undergo evolution over an extended period. Evolution of these systems is inevitable as they need to continue to satisfy changing business needs, new regulations and standards, and introduction of novel technologies. Such evolution may involve changes that add, remove, or modify features; or that migrate the system from one operating platform to another. These changes may result in requirements that were satisfied in a previous release of a system not being satisfied in subsequent versions. When evolutionary changes violate security requirements, a system may be left vulnerable to attacks. In this paper we review current approaches to security requirements engineering and conclude that they lack explicit support for managing the effects of software evolution. We then suggest that a cross fertilisation of the areas of software evolution and security engineering would address the\u00a0\u2026", "num_citations": "48\n", "authors": ["1448"]}
{"title": "On modelling access policies: Relating roles to their organisational context\n", "abstract": " The restriction of access is a mechanism by which organisations protect their information assets. Requirements models use actor definitions to describe users and to specify their access policies. Actors normally represent roles that users adopt, while roles can represent different things, such as a position in an organisation or the assignment of a task. Current requirements modelling approaches do not provide a systematic way of defining roles for incorporation into access policies. We address this issue by proposing a framework that facilitates the derivation of role definitions from their wider organisational context. We illustrate how our framework can be used to extend a formal version of i* - to define and verify access policies definitions -and demonstrate its applicability via a case study.", "num_citations": "48\n", "authors": ["1448"]}
{"title": "Analysing security threats and vulnerabilities using abuse frames\n", "abstract": " In this paper, we present an approach using problem frames to analyse security problems in order to determine security threats and vulnerabilities. We use problem frames to capture and bound the base system that is to be protected. We consider threats to this base problem frame from the point of view of the attacker. For each class of threats, their successful realisation is regarded as the anti-requirement in an abuse frame. Antirequirements are quantified existentially: that is, the attacker succeeds by realising the threat in any one instance. For a threat to be realised, its abuse frame must be composed with the base problem frame in the sense that the asset attacked in the abuse frame must overlap, or be identified with, a domain of the base problem frame. We explain the process of composition and some of its variations. We illustrate and assess our approach using a case study of a medical information system, and suggest how abuse frames can provide a means for bounding the scope of and reasoning about security problems in order to analyse security threats and identify vulnerabilities. We conclude with an agenda for future work.", "num_citations": "48\n", "authors": ["1448"]}
{"title": "Distilling privacy requirements for mobile applications\n", "abstract": " As mobile computing applications have become commonplace, it is increasingly important for them to address end-users\u2019 privacy requirements. Privacy requirements depend on a number of contextual socio-cultural factors to which mobility adds another level of contextual variation. However, traditional requirements elicitation methods do not sufficiently account for contextual factors and therefore cannot be used effectively to represent and analyse the privacy requirements of mobile end users. On the other hand, methods that do investigate contextual factors tend to produce data that does not lend itself to the process of requirements extraction. To address this problem we have developed a Privacy Requirements Distillation approach that employs a problem analysis framework to extract and refine privacy requirements for mobile applications from raw data gathered through empirical studies involving end users\u00a0\u2026", "num_citations": "47\n", "authors": ["1448"]}
{"title": "Combining abductive reasoning and inductive learning to evolve requirements specifications\n", "abstract": " The development of requirements specifications inevitably involves modification and evolution. To support modification while preserving particular requirements goals and properties, the use of a cycle composed of two phases: analysis and revision is proposed. In the analysis phase, a desirable property of the system is checked against a partial specification. Should the property be violated, diagnostic information is provided. In the revision phase, the diagnostic information is used to help modify the specification in such a way that the new specification no longer violates the original property. An instance of the above analysis\u2013revision cycle that combines new techniques of logical abduction and inductive learning to analyse and revise specifications, respectively is investigated. More specifically, given an (event-based) system description and a system property, abductive reasoning is applied in refutation mode to\u00a0\u2026", "num_citations": "46\n", "authors": ["1448"]}
{"title": "Adaptive sharing for online social networks: A trade-off between privacy risk and social benefit\n", "abstract": " Online social networks such as Facebook allow users to control which friend sees what information, but it can be a laborious process for users to specify every receiver for each piece of information they share. Therefore, users usually group their friends into social circles, and select the most appropriate social circle to share particular information with. However, social circles are not formed for setting privacy policies, and even the most appropriate social circle still cannot adapt to the changes of users' privacy requirements influenced by the changes in context. This problem drives the need for better privacy control which can adaptively filter the members in a selected social circle to satisfy users' requirements while maintaining users' social needs. To enable such adaptive sharing, this paper proposes a utility-based trade-off framework that models users' concerns (i.e. Potential privacy risks) and incentives of sharing (i\u00a0\u2026", "num_citations": "44\n", "authors": ["1448"]}
{"title": "In the best families: tracking and relationships\n", "abstract": " A growing body of research has been exploring the use of control mechanisms to address the privacy concerns raised by location-tracking technology. We report on a qualitative study of two family groups who used a custom-built tracking application for an extended period of time. Akin to sociological breaching experiments, the study focuses on the interferences between location tracking and relationship management. We analyze the tensions that can arise between affordances of the technology and uses that the contracts between family members legitimize. We describe how, by fostering misperceptions and'nudging'behaviors, location-tracking technology can generate anxieties and conflicts even in close relationships. We discuss their vulnerability to the overreaching effects of tracking, against which the use of mechanisms such as location-sharing preferences and feedback may not be socially viable.", "num_citations": "44\n", "authors": ["1448"]}
{"title": "Linking the selection of requirements to market value: A portfolio-based approach\n", "abstract": " Determining which requirements are selected for implementation of software applications is crucial to the satisfaction of customers. In a commercial setting, the value assigned by markets to a publicly held company is the ultimate measure of the degree to which the company meets its business goals--satisfies its customers. We argue that portfolio theory provides a market driven, systematic, and more objective approach to selecting requirements and also accounts for uncertainty and incomplete knowledge in the real world. We illustrate through two examples, that the economic dimension is an important factor of software engineering decision-making because it facilitates the calibration of our estimates of limited resources. The underlying point is that the success or otherwise of software systems in commercial settings can be better ascertained by making the connection to market-assigned value explicit. Our particular application of portfolio-based reasoning is a step in contributing towards this objective.", "num_citations": "42\n", "authors": ["1448"]}
{"title": "Weaving the software development process between requirements and architecture\n", "abstract": " This position paper argues for the concurrent, iterative development of requirements and architectures during the development of software systems. It presents the \u201cTwin Peaks\u201d model\u2013a partial and simplified version of the spiral model\u2013that illustrates the distinct, yet intertwined activities of requirements engineering and architectural design. The paper suggests that the use of various kinds of patterns\u2013of requirements, architectures, and designs\u2013may provide a way to increase software development productivity and stakeholder satisfaction in this setting.", "num_citations": "41\n", "authors": ["1448"]}
{"title": "Using abduction to evolve inconsistent requirements specification\n", "abstract": " Requirements specifications are often inconsistent. Inconsistencies may arise because multiple conflicting requirements are embodied in these specifications, or because the specifications themselves are in a transient stage of evolutionary development. In this paper we argue that such inconsistencies, rather than being undesirable, are actually useful drivers for changing the requirements specifications in which they arise. We present a formal technique to reason about inconsistency handling changes. Our technique is an adaptation of logical abduction-adapted to generate changes that address some specification inconsistencies, while leaving others. We represent our specifications in quasi-classical (QC) logic-an adaptation of classical logic that allows continued reasoning in the presence of inconsistency. The paper develops a sound algorithm for automating our abductive reasoning technique and presents illustrative examples drawn from a library system case study.", "num_citations": "41\n", "authors": ["1448"]}
{"title": "Topology aware adaptive security\n", "abstract": " Adaptive security systems aim to protect valuable assets in the face of changes in their operational environment. They do so by monitoring and analysing this environment, and deploying security functions that satisfy some protection (security, privacy, or forensic) requirements. In this paper, we suggest that a key characteristic for engineering adaptive security is the topology of the operational environment, which represents a physical and/or a digital space-including its structural relationships, such as containment, proximity, and reachability. For adaptive security, topology expresses a rich representation of context that can provide a system with both structural and semantic awareness of important contextual characteristics. These include the location of assets being protected or the proximity of potentially threatening agents that might harm them. Security-related actions, such as the physical movement of an actor from\u00a0\u2026", "num_citations": "40\n", "authors": ["1448"]}
{"title": "Fine-grain process modelling\n", "abstract": " We propose the use of fine-grain process modelling as an aid to software development. We suggest the use of two levels of granularity, one at the level of the individual developer and another at the level of the representation scheme used by that developer. The advantages of modelling the software development process at these two levels, we argue, include respectively: the production of models that better reflect actual development processes because they are oriented towards the actors who enact them; and models that are vehicles for providing guidance because they may be expressed in terms of the actual representation schemes employed by those actors. We suggest that the previously published approach (A. Finkelstein et al., 1990; 1992) of using multiple \"ViewPoints\" to model software development participants, the perspectives that they hold, the representation schemes that they deploy and the process\u00a0\u2026", "num_citations": "37\n", "authors": ["1448"]}
{"title": "Assessing the privacy of mhealth apps for self-tracking: heuristic evaluation approach\n", "abstract": " Background: The recent proliferation of self-tracking technologies has allowed individuals to generate significant quantities of data about their lifestyle. These data can be used to support health interventions and monitor outcomes. However, these data are often stored and processed by vendors who have commercial motivations, and thus, they may not be treated with the sensitivity with which other medical data are treated. As sensors and apps that enable self-tracking continue to become more sophisticated, the privacy implications become more severe in turn. However, methods for systematically identifying privacy issues in such apps are currently lacking.Objective: The objective of our study was to understand how current mass-market apps perform with respect to privacy. We did this by introducing a set of heuristics for evaluating privacy characteristics of self-tracking services.Methods: Using our heuristics, we conducted an analysis of 64 popular self-tracking services to determine the extent to which the services satisfy various dimensions of privacy. We then used descriptive statistics and statistical models to explore whether any particular categories of an app perform better than others in terms of privacy.Results: We found that the majority of services examined failed to provide users with full access to their own data, did not acquire sufficient consent for the use of the data, or inadequately extended controls over disclosures to third parties. Furthermore, the type of app, in terms of the category of data collected, was not a useful predictor of its privacy. However, we found that apps that collected health-related data (eg, exercise and weight\u00a0\u2026", "num_citations": "36\n", "authors": ["1448"]}
{"title": "Feed me, feed me: an exemplar for engineering adaptive software\n", "abstract": " The Internet of Things (IoT) promises to deliver improved quality of life for citizens, through pervasive connectivity and quantified monitoring of devices, people, and their environment. As such, the IoT presents a major new opportunity for research in adaptive software engineering. However, there are currently no shared exemplars that can support software engineering researchers to explore and potentially address the challenges of engineering adaptive software for the IoT, and to comparatively evaluate proposed solutions. In this paper, we present Feed me, Feed me, an exemplar that represents an IoT-based ecosystem to support food security at different levels of granularity: individuals, families, cities, and nations. We describe this exemplar using animated videos which highlight the requirements that have been informally observed to play a critical role in the success or failure of IoT-based software systems\u00a0\u2026", "num_citations": "36\n", "authors": ["1448"]}
{"title": "Engineering topology aware adaptive security: Preventing requirements violations at runtime\n", "abstract": " Adaptive security systems aim to protect critical assets in the face of changes in their operational environment. We have argued that incorporating an explicit representation of the environment's topology enables reasoning on the location of assets being protected and the proximity of potentially harmful agents. This paper proposes to engineer topology aware adaptive security systems by identifying violations of security requirements that may be caused by topological changes, and selecting a set of security controls that prevent such violations. Our approach focuses on physical topologies; it maintains at runtime a live representation of the topology which is updated when assets or agents move, or when the structure of the physical space is altered. When the topology changes, we look ahead at a subset of the future system states. These states are reachable when the agents move within the physical space. If security\u00a0\u2026", "num_citations": "36\n", "authors": ["1448"]}
{"title": "Text filtering and ranking for security bug report prediction\n", "abstract": " Security bug reports can describe security critical vulnerabilities in software products. Bug tracking systems may contain thousands of bug reports, where relatively few of them are security related. Therefore finding unlabelled security bugs among them can be challenging. To help security engineers identify these reports quickly and accurately, text-based prediction models have been proposed. These can often mislabel security bug reports due to a number of reasons such as class imbalance, where the ratio of non-security to security bug reports is very high. More critically, we have observed that the presence of security related keywords in both security and non-security bug reports can lead to the mislabelling of security bug reports. This paper proposes FARSEC, a framework for filtering and ranking bug reports for reducing the presence of security related keywords. Before building prediction models, our\u00a0\u2026", "num_citations": "35\n", "authors": ["1448"]}
{"title": "Securing the skies: In requirements we trust\n", "abstract": " The authors describe their experiences applying a security requirements analysis to an air traffic control project using a framework that offers different forms of structured argumentation. In deploying the framework, they also learned several lessons about security requirements.", "num_citations": "33\n", "authors": ["1448"]}
{"title": "Restructuring requirements specifications for managing inconsistency and change: A case study\n", "abstract": " The paper describes our experiences in restructuring multi perspective requirements specifications in order to identify and analyse inconsistencies and manage change. A partial, heterogeneous and reasonably large requirements specification from a NASA project was analysed and decomposed into a structure of \"viewpoints\", where each viewpoint encapsulates partial requirements of some system components described in the specification. Relationships between viewpoints were identified which included not only the interactions explicitly stated in the requirements but also some implicit and potentially problematic inter dependencies. The restructuring process and a first informal analysis of the resulting relationships enabled the detection of inconsistencies and the definition of some interesting domain dependent consistency rules. We believe that this restructuring into view points also facilitated requirements\u00a0\u2026", "num_citations": "33\n", "authors": ["1448"]}
{"title": "Privacy dynamics: Learning privacy norms for social software\n", "abstract": " Privacy violations in online social networks (OSNs) often arise as a result of users sharing information with unintended audiences. One reason for this is that, although OSN capa- bilities for creating and managing social groups can make it easier to be selective about recipients of a given post, they do not provide enough guidance to the users to make informed sharing decisions. In this paper we present Pri- vacy Dynamics, an adaptive architecture that learns privacy norms for dierent audience groups based on users' sharing behaviours. Our architecture is underpinned by a formal model inspired by social identity theory, a social psychology framework for analysing group processes and intergroup re- lations. Our formal model comprises two main concepts, the group membership as a Social Identity (SI) map and privacy norms as a set of con ict rules. In our approach a privacy norm is specied in terms of the\u00a0\u2026", "num_citations": "32\n", "authors": ["1448"]}
{"title": "I know what you did last summer: risks of location data leakage in mobile and social computing\n", "abstract": " Advances in mobile and web technologies have brought unwanted access to often sensitive data, ranging from our personal details, where we work, where we live and even behavioral patterns. The increasing use of social networks and location-aware mobile applications raise a number of concerns, including the issue of ensuring users\u201f privacy. In order to explore those concerns we conducted an exploratory study in re-identifying people based on their movements and publicly available information. We observed anonymous users of a location-based social networking application in their natural environment and demonstrated how to re-identify them based on that data. In addition to discovering location-based private data, we were also able to find quite a number of facts from their private lives. This article reports on the methodology we used, ethical issues related to informed consent and user\u201f s reaction to the fact of being re-identified.", "num_citations": "32\n", "authors": ["1448"]}
{"title": "Composing features by managing inconsistent requirements\n", "abstract": " One approach to system development is to decompose the requirements into features and specify the individual features before composing them. A major limitation of deferring feature composition is that inconsistency between the solutions to individual features may not be uncovered early in the development, leading to unwanted feature interactions. Syntactic inconsistencies arising from the way software artefacts are described can be addressed by the use of explicit, shared, domain knowledge. However, behavioural inconsistencies are more challenging: they may occur within the requirements associated with two or more features as well as at the level of individual features. Whilst approaches exist that address behavioural inconsistencies at design time, these are over-restrictive in ruling out all possible conflicts and may weaken the requirements further than is desirable. In this paper, we present a lightweight approach to dealing with behavioural inconsistencies at run-time. Requirement Composition operators are introduced that specify a run-time prioritisation to be used on occurrence of a feature interaction. This prioritisation can be static or dynamic. Dynamic prioritisation favours some requirement according to some runtime criterion, for example, the extent to which it is already generating behaviour.", "num_citations": "32\n", "authors": ["1448"]}
{"title": "Problem frames: A case for coordination\n", "abstract": " We show how principles of separation of Coordination from Computation can be used to endow the Problem Frames approach to problem analysis with representation schemes. These representation schemes facilitate the way evolution of requirements or of the application domain can be reflected in the decomposition structure, making it easier to change.", "num_citations": "30\n", "authors": ["1448"]}
{"title": "Requirements-driven collaborative choreography customization\n", "abstract": " Evolving business needs call for customizing choreographed interactions. However, conventional choreography description languages provide only a partial view of the interaction. Business goals of each participant and organizational dependencies motivating the interaction are not captured in the specification of messaging. Absence of this critical business knowledge makes it hard to reason if a particular customization satisfies the goals of participants. Furthermore, there is no systematic means to assess the impact of change in one participant\u2019s process (local view) on the choreography (global view) as well as on other participants\u2019 processes. To this end, we argue for the benefits of representing choreography at the level of requirements motivating the interaction. We propose a framework that allows participants to collaborate on customizing choreographed interactions, while reconciling their competing\u00a0\u2026", "num_citations": "29\n", "authors": ["1448"]}
{"title": "Specifying features of an evolving software system\n", "abstract": " Software development is increasingly concerned with maintaining and extending existing software systems to meet the evolving user requirements. Many of these systems are feature\u2010rich and are developed incrementally. As structures of existing software systems\u2014in addition to the user requirements\u2014influence the specifications, specifying these systems poses unique challenges. This paper reports on our experience of applying an engineering approach to specifying an evolving feature\u2010rich television software system. In this approach, features are specified modularly by first fitting their problems to known problem patterns, and then analyzing typical concerns\u2014meaning the potential causes of errors\u2014associated with those patterns. In cases where the existing design poses difficulties when fitting problems to patterns, we transform its structure using known design mechanisms so that the problems fit the patterns\u00a0\u2026", "num_citations": "29\n", "authors": ["1448"]}
{"title": "Guest editors' introduction: Evolving critical systems\n", "abstract": " We believe that the software engineering community must concentrate efforts on the techniques, methodologies, and tools needed to design, implement, and maintain critical software systems that evolve successfully. This special issue summarizes many of the topics discussed and embodies what we believe to be some of the most important research challenges for evolving critical software systems\u2014without incurring prohibitive costs.", "num_citations": "28\n", "authors": ["1448"]}
{"title": "Conflicting requirements: when the customer is not always right\n", "abstract": " Conflicting requirements: When the customer is not always right: Requirements Engineering: Vol 1, No 1 ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Requirements Engineering Periodical Home Latest Issue Archive Authors Affiliations Award Winners More HomeBrowse by TitlePeriodicalsRequirements EngineeringVol. , No. Conflicting requirements: When the customer is not always right article Conflicting requirements: When the customer is not always right Share on Author: Bashar Nuseibeh profile image Bashar Nuseibeh Department of Computing, Imperial College, London, UK Department of Computing, Imperial College, London, UK View Profile Authors Info & Affiliations Publication: \u2026", "num_citations": "28\n", "authors": ["1448"]}
{"title": "Using problem descriptions to represent variabilities for context-aware applications\n", "abstract": " This paper investigates the potential use of problem descriptions to represent and analyse variability in context-aware software products. By context-aware, we refer to recognition of changes in properties of external domains, which are recognised as affecting the behaviour of products. There are many reasons for changes in the operating environment, from fluctuating resources upon which the product relies, to different operating locations or the presence of objects. There is an increasing expectation for software intensivedevices to be context-aware which, in turn, adds further variability to problem description and analysis. However, we argue in this paper that the capture of contextual variability on current variability representations and analyses has yet to be explored. We illustrate the representation of this type of variability in a pilot study, and conclude with lessons learnt and an agenda for further work.", "num_citations": "26\n", "authors": ["1448"]}
{"title": "Towards a framework for managing inconsistency between multiple views\n", "abstract": " Supporting multiple views in software development in general and requirements engineering in particular is desirable. For example, multiple views on system requirements inevitably arise, and their explicit capture and representation using views facilitates requirements (knowledge) acquisition. However, multiple views often lead to inconsistencies between these views-particularly when these views represent, say, different stakeholder perspectives or alternative design solutions. In general, inconsistencies are regarded as undesirable, and development participants often seek to prevent them from arising or attempt to eradicate them as soon as they are detected.", "num_citations": "26\n", "authors": ["1448"]}
{"title": "Adaptive evidence collection in the cloud using attack scenarios\n", "abstract": " The increase in crimes targeting the cloud is increasing the amount of data that must be analysed during a digital forensic investigation, exacerbating the problem of processing such data in a timely manner. Since collecting all possible evidence proactively could be cumbersome to analyse, evidence collection should mainly focus on gathering the data necessary to investigate potential security breaches that can exploit vulnerabilities present in a particular cloud configuration. Cloud elasticity can also change the attack surface available to an adversary and, consequently, the way potential security breaches can arise. Therefore, evidence collection should be adapted depending on changes in the cloud configuration, such as those determined by allocation/deallocation of virtual machines. In this paper, we propose to use attack scenarios to configure more effective evidence collection for cloud services. In particular\u00a0\u2026", "num_citations": "25\n", "authors": ["1448"]}
{"title": "Ariadne: Topology aware adaptive security for cyber-physical systems\n", "abstract": " This paper presents Ariadne, a tool for engineering topology aware adaptive security for cyber-physical systems. It allows security software engineers to model security requirements together with the topology of the operational environment. This model is then used at runtime to perform speculative threat analysis to reason about the consequences that topological changes arising from the movement of agents and assets can have on the satisfaction of security requirements. Our tool also identifies an adaptation strategy that applies security controls when necessary to prevent potential security requirements violations.", "num_citations": "25\n", "authors": ["1448"]}
{"title": "Privacy arguments: Analysing selective disclosure requirements for mobile applications\n", "abstract": " Privacy requirements for mobile applications offer a distinct set of challenges for requirements engineering. First, they are highly dynamic, changing over time and locations, and across the different roles of agents involved and the kinds of information that may be disclosed. Second, although some general privacy requirements can be elicited a priori, users often refine them at runtime as they interact with the system and its environment. Selectively disclosing information to appropriate agents is therefore a key privacy management challenge, requiring carefully formulated privacy requirements amenable to systematic reasoning. In this paper, we introduce privacy arguments as a means of analysing privacy requirements in general and selective disclosure requirements (that are both content- and context-sensitive) in particular. Privacy arguments allow individual users to express personal preferences, which are then\u00a0\u2026", "num_citations": "25\n", "authors": ["1448"]}
{"title": "OpenArgue: Supporting argumentation to evolve secure software systems\n", "abstract": " When software systems are verified against security requirements, formal and informal arguments provide a structure for organizing the software artifacts. Our recent work on the evolution of security-critical software systems demonstrates that our argumentation technique is useful in limiting the scope of change and in identifying changes to security properties. In support of this work, we have developed OpenArgue, a tool for syntax checking, visualizing, formalizing, and reasoning about incremental arguments. OpenArgue has been integrated with requirements engineering tools for Problem Frames and i*, and applied to an Air Traffic Management (ATM) case study.", "num_citations": "25\n", "authors": ["1448"]}
{"title": "Adding static and dynamic semantics to building information models\n", "abstract": " Smart cyber-physical spaces indicate spatial environments which include both cyber and physical elements interacting with each other. In the construction industry, Building Information Models are the de facto standard for specifying complex information about building infrastructures, a representation which can also be extended for the specification of cyber-physical spaces. By providing formal static and dynamic semantics in terms of topological concepts of locality and connectivity of entities it is possible to support many forms of advanced analyses typically performed in software engineering. Static semantics aim to broadly support reasoning about latent qualities of a design. Dynamic semantics aim to deal with the dynamism that a space exhibits when additionally considering the ways it may change along with entities inhabiting it. Motivated by the setting of a smart hospital, we show how both qualitative and\u00a0\u2026", "num_citations": "24\n", "authors": ["1448"]}
{"title": "Problem analysis of traditional it-security risk assessment methods\u2013an experience report from the insurance and auditing domain\n", "abstract": " Traditional information technology (IT) security risk assessment approaches are based on an analysis of events, probabilities and impacts. In practice, security experts often find it difficult to determine IT risks reliably with precision. In this paper, we review the risk determination steps of traditional risk assessment approaches and report on our experience of using such approaches. Our experience is based on performing IT audits and IT business insurance cover assessments within a reinsurance company. The paper concludes with a summary of issues concerning traditional approaches that are related to the identification and evaluation of events, probabilities and impacts. We also conclude that there is a need to develop alternative approaches, and suggest a security requirements-based risk assessment approach without events and probabilities.", "num_citations": "24\n", "authors": ["1448"]}
{"title": "PrimAndroid: privacy policy modelling and analysis for android applications\n", "abstract": " The rapid growth of mobile applications has imposed new threats to privacy: users often find it challenging to ensure that their privacy policies are consistent with the requirements of a diverse range of of mobile applications that access personal information under different contexts. This problem exacerbates when applications depend on each other and therefore share permissions to access resources in ways that are opaque to an end-user. To meet the needs of representing privacy requirements and of resolving dependencies issues in privacy policies, we pro-pose an extension to the P-RBAC model for reasoning about plausible scenarios that can exploit such weaknesses of mobile systems. This work has been evaluated using the case studies on several Android mobile applications.", "num_citations": "24\n", "authors": ["1448"]}
{"title": "Machine Learning for Dynamic Software Analysis\n", "abstract": " Machine learning of software artefacts is an emerging area of interaction between the machine learning (ML) and software analysis (SA) communities. Increased productivity in software engineering hinges on the creation of new adaptive, scalable tools that can analyze large and continuously changing software systems. For example: Agile software development using continuous integration and delivery can require new documentation models, static analyses, proofs and tests of millions of lines of code every 24 h. These needs are being addressed by new SA techniques based on ML, such as learning-based software testing, invariant generation, or code synthesis. ML is a powerful paradigm for SA that provides novel approaches to automating the generation of models and other essential artefacts. However, the ML and SA communities are traditionally separate, each with its own agenda. This book is a follow-up of\u00a0\u2026", "num_citations": "23\n", "authors": ["1448"]}
{"title": "Protecting privacy in the cloud: Current practices, future directions\n", "abstract": " Cloud computing has become popular because of its benefits to users, which include having access to the resources they need at any time without having to invest in or manage an extensive computing infrastructure. However, users also lose control of the systems they depend on, which creates privacy and security concerns.", "num_citations": "23\n", "authors": ["1448"]}
{"title": "SecuriTAS: a tool for engineering adaptive security\n", "abstract": " This paper presents SecuriTAS, a tool to engineer adaptive security. It allows software designers to model security concerns together with the requirements of a system. This model is then used at runtime to analyze changes in security concerns and select the best set of security controls necessary to protect the system.", "num_citations": "23\n", "authors": ["1448"]}
{"title": "Model-based argument analysis for evolving security requirements\n", "abstract": " Software systems are made to evolve in response to changes in their contexts and requirements. As the systems evolve, security concerns need to be analysed in order to evaluate the impact of changes on the systems. We propose to investigate such changes by applying a meta-model of evolving security requirements, which draws on requirements engineering approaches, security analysis, argumentation and software evolution. In this paper, we show how the meta-model can be instantiated using a formalism of temporal logic, called the Event Calculus. The main contribution is a model based approach to argument analysis, supported by a tool which generates templates for formal descriptions of the evolving system. We apply our approach to several examples from an Air Traffic Management case study.", "num_citations": "23\n", "authors": ["1448"]}
{"title": "Logging you, logging me: A replicable study of privacy and sharing behaviour in groups of visual lifeloggers\n", "abstract": " Low cost digital cameras in smartphones and wearable devices make it easy for people to automatically capture and share images as a visual lifelog. Having been inspired by a US campus based study that explored individual privacy behaviours of visual lifeloggers, we conducted a similar study on a UK campus, however we also focussed on the privacy behaviours of groups of lifeloggers. We argue for the importance of replicability and therefore we built a publicly available toolkit, which includes camera design, study guidelines and source code. Our results show some similar sharing behaviour to the US based study: people tried to preserve the privacy of strangers, but we found fewer bystander reactions despite using a more obvious camera. In contrast, we did not find a reluctance to share images of screens but we did find that images of vices were shared less. Regarding privacy behaviours in groups of\u00a0\u2026", "num_citations": "22\n", "authors": ["1448"]}
{"title": "Automating trade-off analysis of security requirements\n", "abstract": " A key aspect of engineering secure systems is identifying adequate security requirements to protect critical assets from harm. However, security requirements may compete with other requirements such as cost and usability. For this reason, they may only be satisfied partially and must be traded off against other requirements to achieve \u201cgood-enough security\u201d. This paper proposes a novel approach to automate security requirements analysis in order to determine maximum achievable satisfaction level for security requirements and identify trade-offs between security and other requirements. We also propose a pruning algorithm to reduce the search space size in the analysis. We represent security concerns and requirements using asset, threat, and goal models, initially proposed in our previous work. To deal with uncertainty and partial requirements, satisfaction security concerns are quantified by\u00a0\u2026", "num_citations": "22\n", "authors": ["1448"]}
{"title": "Specifying and detecting meaningful changes in programs\n", "abstract": " Software developers are often interested in particular changes in programs that are relevant to their current tasks: not all changes to evolving software are equally important. However, most existing differencing tools, such as diff, notify developers of more changes than they wish to see. In this paper, we propose a technique to specify and automatically detect only those changes in programs deemed meaningful, or relevant, to a particular development task. Using four elementary annotations on the grammar of any programming language, namely Ignore, Order, Prefer and Scope, developers can specify, with limited effort, the type of change they wish to detect. Our algorithms use these annotations to transform the input programs into a normalised form, and to remove clones across different normalised programs in order to detect non-trivial and relevant differences. We evaluate our tool on a benchmark of programs to\u00a0\u2026", "num_citations": "22\n", "authors": ["1448"]}
{"title": "Towards forensic-ready software systems\n", "abstract": " As software becomes more ubiquitous, and the risk of cyber-crimes increases, ensuring that software systems are forensic-ready (i.e., capable of supporting potential digital investigations) is critical. However, little or no attention has been given to how well-suited existing software engineering methodologies and practices are for the systematic development of such systems. In this paper, we consider the meaning of forensic readiness of software, define forensic readiness requirements, and highlight some of the open software engineering challenges in the face of forensic readiness. We use a real software system developed to investigate online sharing of child abuse media to illustrate the presented concepts.", "num_citations": "21\n", "authors": ["1448"]}
{"title": "Data privacy: Users\u2019 thoughts on quantified self personal data\n", "abstract": " The logging of personal data has been shown to offer many benefits for those wanting to, for example, get fitter, get stronger or get to know themselves better. In this chapter, we concentrate on the privacy values attributed to Quantified-Self (QS) data. Using evidence taken from research interviews, this chapter reviews privacy in relation to personal data and offers an empirical perspective on how QS users view and value the data they collect, and often display publically, as well as their attitudes towards the handling of their data by QS device manufacturers. We question appreciations of privacy in QS data and elaborate on how users value their QS privacy.", "num_citations": "21\n", "authors": ["1448"]}
{"title": "Arguing satisfaction of security requirements\n", "abstract": " This chapter presents a process for security requirements elicitation and analysis, based around the construction of a satisfaction argument for the security of a system. The process starts with the enumeration of security goals based on assets in the system, then uses these goals to derive security requirements in the form of constraints. Next, a satisfaction argument for the system is constructed, using a problem-centered representation, a formal proof to analyze properties that can be demonstrated, and structured informal argumentation of the assumptions exposed during construction of the argument. Constructing the satisfaction argument can expose missing and inconsistent assumptions about system context and behavior that effect security, and a completed argument provides assurances that a system can respect its security requirements.", "num_citations": "21\n", "authors": ["1448"]}
{"title": "The conundrum of categorising requirements: managing requirements for learning on the move\n", "abstract": " This work reports on our experience of eliciting and managing requirements on a large European-based multinational project, whose purpose is to create a system to support learning using mobile technology. The project used an adapted database version of the Volere shell and template (Robertson and Robertson, 2003). We provide details about the project, describe the Volere tools, and explain how and why we used a flexible categorisation scheme to manage the requirements. Finally, we discuss three lessons learned: (1) provide a flexible mechanism for organising requirements, (2) plan ahead for the RE process, and (3) use the 'waiting room'.", "num_citations": "21\n", "authors": ["1448"]}
{"title": "Restructuring requirements specifications\n", "abstract": " This paper describes the restructuring of multi-perspective requirements specifications to facilitate the identification and analysis of inconsistencies and the management of change. A partial, heterogeneous and reasonably large requirements specification from a NASA project is analysed and decomposed into a structure of viewpoints, where each viewpoint encapsulates partial requirements of some system components described in the specification. Relationships between viewpoints are identified and include, not only the interactions explicitly stated in the requirements, but also some implicit and potentially problematic inter-dependencies. The restructuring process and a first informal analysis of the resulting relationships enable the detection of inconsistencies and the definition of some interesting domain-dependent consistency rules. It is believed that this restructuring into viewpoints also facilitates requirements\u00a0\u2026", "num_citations": "21\n", "authors": ["1448"]}
{"title": "An anatomy of security conversations in Stack Overflow\n", "abstract": " As software-intensive digital systems become an integral part of modern life, ensuring that these systems are developed to satisfy security and privacy requirements is an increasingly important societal concern. This paper examines how secure coding practice is supported on Stack Overflow. Although there are indications that on-line environments are not robust or accurate sources of security information, they are used by large numbers of developers. Findings demonstrate that developers use conversation within the site to actively connect with and tend to security problems, fostering knowledge, exchanging information and providing assistance to one another.", "num_citations": "20\n", "authors": ["1448"]}
{"title": "Resolving vulnerability identification errors using security requirements on business process models\n", "abstract": " Purpose \u2013 In any information security risk assessment, vulnerabilities are usually identified by information\u2010gathering techniques. However, vulnerability identification errors \u2013 wrongly identified or unidentified vulnerabilities \u2013 can occur as uncertain data are used. Furthermore, businesses' security needs are not considered sufficiently. Hence, security functions may not protect business assets sufficiently and cost\u2010effectively. This paper aims to resolve vulnerability errors by analysing the security requirements of information assets in business process models.Design/methodology/approach \u2013 Business process models have been selected for use, because there is a close relationship between business process objectives and risks. Security functions are evaluated in terms of the information flow of business processes regarding their security requirements. The claim that vulnerability errors can be resolved was validated\u00a0\u2026", "num_citations": "20\n", "authors": ["1448"]}
{"title": "Computer-Aided Inconsistency Management in Software Development\n", "abstract": " The incremental development of software systems involves the detection and handling of inconsistencies. These inconsistencies arise in system requirements, design specifications and, quite often, in the final implemented software product. In this paper we explore different kinds of inconsistency that arise during different stages of software development, and examine the scope and role of computer-based tool support for managing inconsistency in this setting. In addition to detecting and removing inconsistencies, managing inconsistency also includes a wide range of activities that facilitate continued development in the presence of inconsistency. These include procedures for controlled amelioration and avoidance of inconsistencies. The paper uses the ViewPoints framework for multi-perspective software development as a vehicle for the discussion, and as a test bed for tool support. The framework facilitates the development and composition of multiple partial specifications (ViewPoints), and is itself supported by automated tools that check and handle inconsistencies (The Viewer).", "num_citations": "20\n", "authors": ["1448"]}
{"title": "Adaptive security and privacy in smart grids: A software engineering vision\n", "abstract": " Despite the benefits offered by smart grids, energy producers, distributors and consumers are increasingly concerned about possible security and privacy threats. These threats typically manifest themselves at runtime as new usage scenarios arise and vulnerabilities are discovered. Adaptive security and privacy promise to address these threats by increasing awareness and automating prevention, detection and recovery from security and privacy requirements' failures at runtime by re-configuring system controls and perhaps even changing requirements. This paper discusses the need for adaptive security and privacy in smart grids by presenting some motivating scenarios. We then outline some research issues that arise in engineering adaptive security. We particularly scrutinize published reports by NIST on smart grid security and privacy as the basis for our discussions.", "num_citations": "19\n", "authors": ["1448"]}
{"title": "E-assessment using latent semantic analysis\n", "abstract": " E-assessment is an important component of e-learning and e-qualification. Formative and summative assessment serve different purposes and both types of evaluation are critical to the pedagogical process. While students are studying, practicing, working, or revising, formative assessment provides direction, focus, and guidance. Summative assessment provides the means to evaluate a learner\u2019s achievement and communicate that achievement to interested parties. Latent Semantic Analysis (LSA) is a statistical method for inferring meaning from a text. Applications based on LSA exist that provide both summative and formative assessment of a learner\u2019s work. However, the huge computational needs are a major problem with this promising technique. This paper explains how LSA works, describes the breadth of existing applications using LSA, explains how LSA is particularly suited to e-assessment, and proposes research to exploit the potential computational power of the Grid to overcome one of LSA\u2019s drawbacks.", "num_citations": "19\n", "authors": ["1448"]}
{"title": "Using software specification methods for measurement instrument systems: Part 1: Structured methods\n", "abstract": " Investigation has been undertaken into the use of software specification methods for instrument systems specification. In the first part of this paper, some of the well-known structured software specification methods are briefly evaluated against a set of criteria we established, in the context of measuring instrument systems. We then conduct a case study in the widely used CORE method. It has been established that CORE can provide systematic and effective support for functional requirement analysis of complex instruments and instrument systems. Its decomposition-based analysis helps to create complete and consistent functional requirement specification.", "num_citations": "19\n", "authors": ["1448"]}
{"title": "Analysing monitoring and switching problems for adaptive systems\n", "abstract": " In the field of pervasive and ubiquitous computing, context-aware adaptive systems need to monitor changes in their environment in order to detect violations of requirements and switch their behaviour in order to continue satisfying requirements. In a complex and rapidly changing environment, identifying what to monitor and deciding when and how to switch behaviours effectively is difficult and error prone. The goal of our research is to provide systematic and, where possible, automated support for the software engineer developing such adaptive systems.In this paper, we investigate the necessary and sufficient conditions for both monitoring and switching in order to adapt the system behaviours as the problem context varies. Necessary and sufficient conditions provide complementary safeguards to ensure that not too much and not too little monitoring and switching are carried out. Our approach encodes\u00a0\u2026", "num_citations": "18\n", "authors": ["1448"]}
{"title": "Picking battles: The impact of trust assumptions on the elaboration of security requirements\n", "abstract": " This position paper describes work on trust assumptions in the context of security requirements. We show how trust assumptions can affect the scope of the analysis, derivation of security requirements, and in some cases how functionality is realized. An example shows how trust assumptions are used by a requirements engineer to help define and limit the scope of analysis and to document the decisions made during the process.", "num_citations": "18\n", "authors": ["1448"]}
{"title": "Culture and climate change: Recordings\n", "abstract": " \"Culture and Climate Change: Recordings\" is a book based on a series of discussions (available as podcasts) which maps out this new field in the arts and sciences. Contributors include academics, communicators, artists and journalists, such as Mike Hulme, Tim Smit, Siobhan Davies, Roger Harrabin and Marcus Brigstocke. The publication supplements the conversations with an extensive timeline, resources, and footnotes.  It is one output from the Open University's Mediating Change research group.", "num_citations": "17\n", "authors": ["1448"]}
{"title": "Decentralised process modelling\n", "abstract": " In this paper, we advocate decentralised process modelling and suggest that understanding and modelling the development processes of individual development participants is the key to supporting collaborative development. Our approach relies on recognising individual developers' states (\u201csituations\u201d) by analysing local development histories. Different situations can be used to trigger a variety of further development actions, such as consistency checks between process models of different development participants. We report on experience using regular expressions to specify particular situations and rules to associate actions with these situations.", "num_citations": "17\n", "authors": ["1448"]}
{"title": "Are you ready? towards the engineering of forensic-ready systems\n", "abstract": " As security incidents continue to impact organisations, there is a growing demand for systems to be `forensic-ready' - to maximise the potential use of evidence whilst minimising the costs of an investigation. Researchers have supported organisational forensic readiness efforts by proposing the use of policies and processes, aligning systems with forensics objectives and training employees. However, recent work has also proposed an alternative strategy for implementing forensic readiness called forensic-by-design. This is an approach that involves integrating requirements for forensics into relevant phases of the systems development lifecycle with the aim of engineering forensic-ready systems. While this alternative forensic readiness strategy has been discussed in the literature, no previous research has examined the extent to which organisations actually use this approach for implementing forensic readiness\u00a0\u2026", "num_citations": "16\n", "authors": ["1448"]}
{"title": "Towards adaptive systems through requirements@ runtime\n", "abstract": " Software systems must adapt their behavior in response to changes in the environment or in the requirements they are supposed to meet. Despite adaptation capabilities could be modeled with great detail at design time, anticipating all possible adaptations is not always feasible. To address this problem the requirements model of the system, which also includes the adaptation capabilities, is conceived as a runtime entity. This way, it is possible to trace requirements/adaptation changes and propagate them onto the application instances. This paper leverages the FLAGS [1] methodology, which provides a goal model to represent adaptations and a runtime infrastructure to manage requirements@ runtime. First, this paper explains how the FLAGS infrastructure can support requirements@ runtime, by managing the interplay between the requirements and the executing applications. Finally, it describes how this infrastructure can be used to adapt the system, and, consequently, support the evolution of requirements.", "num_citations": "16\n", "authors": ["1448"]}
{"title": "Using Trust Assumptions in Security Requirements Engineering\n", "abstract": " Assumptions about the trustworthiness of the various components of a system (including human components) can have a significant effect on the specifications derived from the system\u2019s requirements. This position paper presents some early efforts to understand the relationships between general requirements, security requirements, and trust assumptions made during problem analysis. An outline of an approach for reasoning about security requirements and trust assumptions is provided.", "num_citations": "16\n", "authors": ["1448"]}
{"title": "Guest editorial: Introduction to the special section\n", "abstract": " In response to a special call for papers in September 1997, we received 67 submissions; five papers appeared in a first special section in November 1998 [l], while five appear in this special section. Two of these papers address the notion of conflict, two papers address process inconsistency issues, and one paper addresses standards compliance.", "num_citations": "16\n", "authors": ["1448"]}
{"title": "Requirements-driven mediation for collaborative security\n", "abstract": " Security is concerned with the protection of assets from intentional harm. Secure systems provide capabilities that enable such protection to satisfy some security requirements. In a world increasingly populated with mobile and ubiquitous computing technology, the scope and boundary of security systems can be uncertain and can change. A single functional component, or even multiple components individually, are often insufficient to satisfy complex security requirements on their own.", "num_citations": "15\n", "authors": ["1448"]}
{"title": "A methodology for automatic identification of nocuous ambiguity\n", "abstract": " Nocuous ambiguity occurs when a linguistic expression is interpreted differently by different readers in a given context. We present an approach to automatically identify nocuous ambiguity that is likely to lead to misunderstandings among readers. Our model is built on a machine learning architecture. It learns from a set of heuristics each of which predicts a factor that may lead a reader to favor a particular interpretation. An ambiguity threshold indicates the extent to which ambiguity can be tolerated in the application domain. Collections of human judgments are used to train heuristics and set ambiguity thresholds, and for evaluation. We report results from applying the methodology to coordination and anaphora ambiguity. Results show that the method can identify nocuous ambiguity in text, and may be widened to cover further types of ambiguity. We discuss approaches to evaluation.", "num_citations": "15\n", "authors": ["1448"]}
{"title": "On presuppositions in requirements\n", "abstract": " Tacit knowledge in requirements documents can lead to miscommunication between software engineers and other stakeholders. One way in which the presence of tacit knowledge is signalled in text is by linguistic presuppositions. In this paper, we present a brief introduction to tacit knowledge, presuppositions and the links between them. Our aim is to build a theoretically grounded system which is able to automatically highlight all the presuppositions that might have a negative impact on communication through requirements documents.", "num_citations": "15\n", "authors": ["1448"]}
{"title": "Using Problem Frames and projections to analyze requirements for distributed systems\n", "abstract": " Subproblems in a problem frames decomposition frequently make use of projections of the complete problem context. One specific use of projec-tions occurs when an eventual implementation will be distributed, in which case a subproblem must interact with (use) the machine in a projection that represents another subproblem. We refer to subproblems used in this way as services, and propose an extension to projections to represent services as a spe-cial connection domain between subproblems. The extension provides signifi-cant benefits: verification of the symmetry of the interfaces, exposure of the machine-to-machine interactions, and prevention of accidental introduction of shared state. The extension\u2019s usefulness is validated using a case study.", "num_citations": "15\n", "authors": ["1448"]}
{"title": "An investigation of security conversations in stack overflow: Perceptions of security and community involvement\n", "abstract": " Developers turn to Stack Overflow and other on-line sources to find solutions to security problems, but little is known about how they engage with and guide one another in these environments or the perceptions of software security this may encourage. This study joins recent calls to understand more about how developers use Internet sources to solve security problems. Using qualitative methods, a set of questions within the security channel of Stack Overflow were selected and examined for themes. Preliminary findings reveal more about this community of practitioners: who are the askers and commenters, how security questions are asked and how developers frame technical information using social and experience-based perceptions of security.", "num_citations": "14\n", "authors": ["1448"]}
{"title": "On the use of logical abduction in software engineering\n", "abstract": " In this paper, we survey recent work on the use of abduction as a knowledge-based reasoning technique for analyzing software specifications. We present a general overview of logical abduction and describe two abductive reasoning techniques, developed from the logic and expert system communities. We then focus on two applications of abduction in software engineering, namely, analysis and revision of specifications. Specifically, we discuss and illustrate, with examples, how the above two abductive reasoning techniques can be deployed to reason about specifications, detect errors, such as logical inconsistencies, provide diagnostic information about these errors, and identify (possible) changes to revise incorrect specifications. We then conclude with a discussion of open research issues.", "num_citations": "14\n", "authors": ["1448"]}
{"title": "Software process modelling and technology\n", "abstract": " Software process modelling and technology | Guide books ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksSoftware process modelling and technology ABSTRACT No abstract available. Index Terms 1.Software process modelling and technology 1.Social and professional topics 1.Professional topics 1.Management of computing and information systems 1.Project and people management 2.Software and its engineering 1.Software creation and management 1.Software development process management 2.Software notations and tools 1.Development frameworks and environments 2.Software configuration management and \u2026", "num_citations": "14\n", "authors": ["1448"]}
{"title": "Feature-driven mediator synthesis: Supporting collaborative security in the internet of things\n", "abstract": " As the number, complexity, and heterogeneity of connected devices in the Internet of Things (IoT) increase, so does our need to secure these devices, the environment in which they operate, and the assets they manage or control. Collaborative security exploits the capabilities of these connected devices and opportunistically composes them to protect assets from potential harm. By dynamically composing these capabilities, collaborative security implements the security controls that satisfy both security and non-security requirements. However, this dynamic composition is often hampered by the heterogeneity of the devices available in the environment and the diversity of their behaviours. In this article, we present a systematic, tool-supported approach for collaborative security where the analysis of requirements drives the opportunistic composition of capabilities to realise the appropriate security control in the\u00a0\u2026", "num_citations": "13\n", "authors": ["1448"]}
{"title": "Requirements and specifications for adaptive security: concepts and analysis\n", "abstract": " In an adaptive security-critical system, security mechanisms change according to the type of threat posed by the environment. Specifying the behavior of these systems is difficult because conditions of the environment are difficult to describe until the system has been deployed and used for a length of time. This paper defines the problem of adaptation in security-critical systems, and outlines the RELAIS approach for expressing requirements and specifying the behavior in a way that helps identify the need for adaptation, and the appropriate adaptation behavior at runtime. The paper introduces the notion of adaptation via input approximation and proposes statistical machine learning techniques for realizing it. The approach is illustrated with a running example and is applied to a realistic security example from a cloud-based file-sharing application. Bayesian classification and logistic regression methods are used to\u00a0\u2026", "num_citations": "13\n", "authors": ["1448"]}
{"title": "On evidence preservation requirements for forensic-ready systems\n", "abstract": " Forensic readiness denotes the capability of a system to support digital forensic investigations of potential, known incidents by preserving in advance data that could serve as evidence explaining how an incident occurred. Given the increasing rate at which (potentially criminal) incidents occur, designing so\u2030 ware systems that are forensic-ready can facilitate and reduce the costs of digital forensic investigations. However, to date, little or no attention has been given to how forensic-ready so\u2030 ftware systems can be designed systematically. In this paper we propose to explicitly represent evidence preservation requirements prescribing preservation of the minimal amount of data that would be relevant to a future digital investigation. We formalise evidence preservation requirements and propose an approach for synthesising specifications for systems to meet these requirements. We present our prototype\u00a0\u2026", "num_citations": "13\n", "authors": ["1448"]}
{"title": "Towards adaptive compliance\n", "abstract": " Mission critical software is often required to comply with multiple regulations, standards or policies. Recent paradigms, such as cloud computing, also require software to operate in heterogeneous, highly distributed, and changing environments. In these environments, compliance requirements can vary at runtime and traditional compliance management techniques, which are normally applied at design time, may no longer be sufficient. In this paper, we motivate the need for adaptive compliance by illustrating possible compliance concerns determined by runtime variability. We further motivate our work by means of a cloud computing scenario, and present two main contributions. First, we propose and justify a process to support adaptive compliance that extends the traditional compliance management lifecycle with the activities of the Monitor-Analyse-Plan-Execute (MAPE) loop, and enacts adaptation through re\u00a0\u2026", "num_citations": "13\n", "authors": ["1448"]}
{"title": "Requirements-driven adaptive digital forensics\n", "abstract": " We propose the use of forensic requirements to drive the automation of a digital forensics process. We augment traditional reactive digital forensics processes with proactive evidence collection and analysis activities, and provide immediate investigative suggestions before an investigation starts. These activities adapt depending on suspicious events, which in turn might require the collection and analysis of additional evidence. The reactive activities of a traditional digital forensics process are also adapted depending on the investigation findings.", "num_citations": "13\n", "authors": ["1448"]}
{"title": "Learning to adapt requirements specifications of evolving systems (NIER track)\n", "abstract": " We propose a novel framework for adapting and evolving software requirements models. The framework uses model checking and machine learning techniques for verifying properties and evolving model descriptions. The paper offers two novel contributions and a preliminary evaluation and application of the ideas presented. First, the framework is capable of coping with errors in the specification process so that performance degrades gracefully. Second, the framework can also be used to re-engineer a model from examples only, when an initial model is not available. We provide a preliminary evaluation of our framework by applying it to a Pump System case study, and integrate our prototype tool with the NuSMV model checker. We show how the tool integrates verification and evolution of abstract models, and also how it is capable of re-engineering partial models given examples from an existing system.", "num_citations": "13\n", "authors": ["1448"]}
{"title": "\" Privacy-shake\", a haptic interface for managing privacy settings in mobile location sharing applications\n", "abstract": " We describe the\" Privacy-Shake\", a novel interface for managing coarse grained privacy settings. We built a prototype that enables users of Buddy Tracker, an example location sharing application, to change their privacy preferences by shaking their phone. Users can enable or disable location sharing and change the level of granularity of disclosed location by shaking and sweeping their phone. In this poster we present and motivate our work on Privacy-Shake and report on a lab-based evaluation of the interface with 16 participants.", "num_citations": "13\n", "authors": ["1448"]}
{"title": "\" Hopefully We Are Mostly Secure\": Views on Secure Code in Professional Practice\n", "abstract": " Security of software systems is of general concern, yet breaches caused by common vulnerabilities still occur. Software developers are routinely called upon to \"do more\" to address this situation. However there has been little focus on the developers' point of view, and understanding how security features in their day-to-day activities. This paper reports preliminary findings of semi-structured interviews taken during an ethnographic study of professional software developers in one organization who are not security experts. The overall study aims to understand how security features in day-to-day practice, while analysis of the interview data asks whether developers are responsible for security. The study reveals that awareness around security matters is raised through several paths including processes, standards, practices and company training and that a focus on security is driven by contextual factors. Security is\u00a0\u2026", "num_citations": "12\n", "authors": ["1448"]}
{"title": "Compositional verification of self-adaptive cyber-physical systems\n", "abstract": " Cyber-Physical Systems (CPSs) must often self-adapt to respond to changes in their operating environment. However, using formal verification techniques to provide assurances that critical requirements are satisfied can be computationally intractable due to the large state space of self-adaptive CPSs. In this paper we propose a novel language, Adaptive CSP, to model self-adaptive CPSs modularly and provide a technique to support compositional verification of such systems. Our technique allows system designers to identify (a subset of) the CPS components that can affect satisfaction of given requirements, and define adaptation procedures of these components to preserve the requirements in the face of changes to the system's operating environment. System designers can then use Adaptive CSP to represent the system including potential self-adaptation procedures. The requirements can then be verified only\u00a0\u2026", "num_citations": "12\n", "authors": ["1448"]}
{"title": "Caprice: a tool for engineering adaptive privacy\n", "abstract": " In a dynamic environment where context changes frequently, users\u2019 privacy requirements can also change. To satisfy such changing requirements, there is a need for continuous analysis to discover new threats and possible mitigation actions. A frequently changing context can also blur the boundary between public and personal space, making it difficult for users to discover and mitigate emerging privacy threats. This challenge necessitates some degree of self-adaptive privacy management in software applications.", "num_citations": "12\n", "authors": ["1448"]}
{"title": "Bridging requirements and architecture for systems of systems\n", "abstract": " A system of systems (SoS) is formed from existing independent component systems. Some reasons these independent systems might be combined include a merger or acquisition, a temporary partnership, because of the formation of an integrated supply chain, or if a service-oriented architecture is used. SoSs are difficult to analyze because of the scale of the integration, the components\u2019 independent existence, and the (potentially) conflicting nature of their requirements. We propose bridging between requirements analysis and architecture of an SoS by using an interdisciplinary approach. From Software Engineering we take iterating between requirements and architecture, and from Philosophy we take structured argumentation. Iterating between requirements and architecture is ideal for exposing issues with constructing a system of systems from existing artifacts. Structured argumentation is used to explore these\u00a0\u2026", "num_citations": "12\n", "authors": ["1448"]}
{"title": "Schr\u00f6dinger's security: opening the box on app developers' security rationale\n", "abstract": " Research has established the wide variety of security failures in mobile apps, their consequences, and how app developers introduce or exacerbate them. What is not well known is why developers do so-what is the rationale underpinning the decisions they make which eventually strengthen or weaken app security? This is all the more complicated in modern app development's increasingly diverse demographic: growing numbers of independent, solo, or small team developers who do not have the organizational structures and support that larger software development houses enjoy. Through two studies, we open the box on developer rationale, by performing a holistic analysis of the rationale underpinning various activities in which app developers engage when developing an app. The first study does so through a task-based study with app developers (  ) incorporating six distinct tasks for which this developer\u00a0\u2026", "num_citations": "11\n", "authors": ["1448"]}
{"title": "Systems and methods for runtime adaptive security to protect variable assets\n", "abstract": " A method of adapting a security configuration of a data processing application at runtime, and a system, together with its computing architecture, are disclosed. The system stores a causal network comprising a plurality of nodes and a plurality of incoming and outgoing causal links associated therewith, wherein each node of the causal network is associated with a security concern or a requirement that can be affected by any configuration of the security controls. The current value of assets nodes, as well as those of the security concerns that can be affected by monitored contextual factors, are updated. The control nodes corresponding to the security controls is updated according to the security configuration whose utility is evaluated by the causal network. The node corresponding to the at least one variable is updated with the determined current value, which is propagated through the causal network through the\u00a0\u2026", "num_citations": "11\n", "authors": ["1448"]}
{"title": "Meta-CASE support for method-based software development\n", "abstract": " This paper defines the scope and context of meta-CASE technology in software engineering. It then outlines the role of meta-CASE tools in \u201cmulti-perspective software development\u201d; that is, development in which multiple participants deploy multiple methods to specify their respective areas of concern.CONTEXT: SOFTWARE ENGINEERING", "num_citations": "11\n", "authors": ["1448"]}
{"title": "On the automated management of security incidents in smart spaces\n", "abstract": " The proliferation of smart spaces, such as smart buildings, is increasing opportunities for offenders to exploit the interplay between cyber and physical components, in order to trigger security incidents. Organizations are obliged to report security incidents to comply with recent data protection regulations. Organizations can also use incident reports to improve security of the smart spaces where they operate. Incident reporting is often documented in structured natural language. However, reports often do not capture relevant information about cyber and physical vulnerabilities present in a smart space that are exploited during an incident. Moreover, sharing information about security incidents can be difficult, or even impossible, since a report may contain sensitive information about an organization. In previous work, we provided a meta-model to represent security incidents in smart spaces. We also developed an\u00a0\u2026", "num_citations": "10\n", "authors": ["1448"]}
{"title": "Talking about security with professional developers\n", "abstract": " This paper describes materials developed to engage professional developers in discussions about security. First, the work is framed in the context of ethnographic studies of software development, highlighting how the method is used to explore and investigate research aims for the Motivating Jenny research project. A description is given of a series of practitioner engagements, that were used to develop a reflection and discussion tool using security stories taken from media and internet sources. An explanation is given for how the tool has been used to collect data within field sites, offering a way to clarify and member check findings, and to provide a different view on practice and process. The report concludes with observations and notes about future aims for supporting and encouraging professionals to engage with security in practice.", "num_citations": "10\n", "authors": ["1448"]}
{"title": "Dragonfly: a tool for simulating self-adaptive drone behaviours\n", "abstract": " Drone simulators can provide an abstraction of different applications of drones and facilitate reasoning about distinct situations, in order to evaluate the effectiveness of these applications. In this paper we describe Dragonfly, a simulator of the behaviours of individual and collection of drones in various environments, involving random contextual variables and different environmental settings. Dragonfly supports the use of several drones in applications and evaluates the satisfaction of requirements under normal and exceptional situations. It simulates adaptive behaviours of drones due to exceptional situations. The adaption of drones is based on the use of wrappers implemented using aspect-oriented programming.", "num_citations": "10\n", "authors": ["1448"]}
{"title": "Privacy itch and scratch: on body privacy warnings and controls\n", "abstract": " In the age of ubiquitous computing increasing amounts of personal data are being logged and shared, making privacy management a challenging task that must be integrated into our daily lives. In this paper, we explore the metaphors of'privacy itch'for warnings and'privacy scratch'for control of privacy preferences through real time, on-body, haptic interaction technologies. To assess the utility of these concepts, we implemented a forearm wearable prototype: the Privacy Band, and conducted a small lab-based user study.", "num_citations": "10\n", "authors": ["1448"]}
{"title": "Patterns for service-oriented information exchange requirements\n", "abstract": " Service-Oriented Computing (SOC) is an emerging computing paradigm that supports loosely-coupled inter-enterprise interactions. SOC interactions are predominantly specified in a procedural manner that defines message sequences intermixing implementation with business requirements. In this paper we present a set of patterns concerning requirements of information exchange between participants engaging in service-oriented interactions. The patterns aim at explicating and elaborating the business requirements driving the interaction and separating them from implementation concerns.", "num_citations": "10\n", "authors": ["1448"]}
{"title": "On the role of primary and secondary assets in adaptive security: An application in smart grids\n", "abstract": " Adaptive security aims to protect valuable assets managed by a system, by applying a varying set of security controls. Engineering adaptive security is not an easy task. A set of effective security countermeasures should be identified. These countermeasures should not only be applied to (primary) assets that customers desire to protect, but also to other (secondary) assets that can be exploited by attackers to harm the primary assets. Another challenge arises when assets vary dynamically at runtime. To accommodate these variabilities, it is necessary to monitor changes in assets, and apply the most appropriate countermeasures at runtime. The paper provides three main contributions for engineering adaptive security. First, it proposes a modeling notation to represent primary and secondary assets, along with their variability. Second, it describes how to use the extended models in engineering security requirements\u00a0\u2026", "num_citations": "9\n", "authors": ["1448"]}
{"title": "An aspect-oriented approach to relating security requirements and access control\n", "abstract": " Affecting multiple parts in software systems, security requirements often tangle with functional requirements. In order to separate crosscutting concerns and increase modularity, we propose to represent security requirements as aspects that can be woven into functional requirements. Using problem frames to model the functional requirements, weaving is achieved by composing the modules representing security aspects with the requirement models. Moreover, we provide guidance on how such security aspects are structured to implement a particular access control solution. As a result, such security aspects become reusable solution patterns to refine the structure of security-related problem.", "num_citations": "9\n", "authors": ["1448"]}
{"title": "Towards context-aware product-family architectures\n", "abstract": " The product-family paradigm is predicated on the definition of a general product architecture from which a number of different architectures can be derived, each addressing the needs of a separate market segment, with a high level of component reuse. The way this is achieved is through the identification of variability points within a generic product architecture, from which variant product architectures are generated, each product with a specific range of functionality.", "num_citations": "9\n", "authors": ["1448"]}
{"title": "Workshop on multi-dimensional separation of concerns in software engineering\n", "abstract": " Separation of concerns has been central to software engineering for decades, yet its many advantages are still not fully realized. A key reason is that traditional modularization mechanisms do not allow simultaneous decomposition according to multiple kinds of (overlapping and interacting) concerns. This workshop was intended to bring together researchers working on more advanced modularization mechanisms, and practitioners who have experienced the need for them, as a step towards a common understanding of the issues, problems and research challenges.", "num_citations": "9\n", "authors": ["1448"]}
{"title": "On the Consequences of Acting in the Presence of Inconsistency\n", "abstract": " Managing inconsistency in specifications covers a range of activities from consistency checking and inconsistency analysis to inconsistency handling through action. We argue that inconsistency analysis is insufficient to determine the choice of actions to take in the presence of inconsistency. Rather, we propose that some form of 'hypothetical reasoning' is needed in order to determine the consequences of different actions and thereby facilitate the decision making process. We suggest some logic based techniques and associated heuristics for analysing the consequences of acting in the presence of inconsistency.", "num_citations": "9\n", "authors": ["1448"]}
{"title": "I've seen this before: Sharing cyber-physical incident knowledge\n", "abstract": " An increasing number of security incidents in cyber-physical systems (CPSs) arise from the exploitation of cyber and physical components of such systems. Knowledge about how such incidents arose is rarely captured and used systematically to enhance security and support future incident investigations. In this paper, we propose an approach to represent and share incidents knowledge. Our approach captures incident patterns-common aspects of incidents occurring in different CPSs. Our approach then allows incident patterns to be instantiated for different systems to assess if and how such patterns can manifest again. To support our approach, we provide two meta-models that represent, respectively, incident patterns and the cyber-physical systems themselves. The incident meta-model captures the characteristics of incidents, such as assets and activities. The system meta-model captures cyber and physical\u00a0\u2026", "num_citations": "8\n", "authors": ["1448"]}
{"title": "Topology-aware access control of smart spaces\n", "abstract": " Smart spaces are becoming increasingly vulnerable from the interplay of cyber and physical entities. A representation of the spaces' topology can reveal security-relevant contextual characteristics, and a visualization tool allows security analysts to edit space topology and verify that access-control policies meet security requirements.", "num_citations": "8\n", "authors": ["1448"]}
{"title": "Software engineering challenges for investigating cyber-physical incidents\n", "abstract": " Cyber-Physical Systems (CPS) are characterized by the interplay between digital and physical spaces. This characteristic has extended the attack surface that could be exploited by an offender to cause harm. An increasing number of cyber-physical incidents may occur depending on the configuration of the physical and digital spaces and their interplay. Traditional investigation processes are not adequate to investigate these incidents, as they may overlook the extended attack surface resulting from such interplay, leading to relevant evidence being missed and testing flawed hypotheses explaining the incidents. The software engineering research community can contribute to addressing this problem, by deploying existing formalisms to model digital and physical spaces, and using analysis techniques to reason about their interplay and evolution. In this paper, supported by a motivating example, we describe some\u00a0\u2026", "num_citations": "8\n", "authors": ["1448"]}
{"title": "Using/* to Model Access Policies: Relating Actors to Their Organizational Context.\n", "abstract": " Security incidents can be costly; Nick Leeson\u2019s trading resulted in losses of over\u00a3 800 million, thus causing the bankruptcy of Barings Bank (Brown & Steenbeek, 2001), and John Rusnak defrauded the Allied Irish Bank of a similar amount in 2002. They both exploited weaknesses in the computer systems used to control their trading activities. Thus, while there is a need to keep outsiders from breaking in, there is also a need to prevent users with legitimate access rights from abusing their privileges. Many organizations have procedural controls, de\ufb01ned as policies, to prevent such abuse. The procedures are often enforced by computer systems, which restrict access. We believe that early understanding and speci\ufb01cation of access policies are key to e\u00a4 ective access control. Access policies are rules that specify which users can carry out which actions to enforce principles of management control (Mo\u00a4 ett & Sloman, 1988). In this chapter we focus on access policies that enforce one of these principles, that of minimum privileges (Anderson, 2001). This principle states that users can access only the functions and resources that they require to carry out their duties.Many requirements models represent users as actors or agents that are assigned to actions. These assignments can be used to represent access policies (Crook, Ince, & Nuseibeh, 2003, 2005; Liu, Yu, & Mylopoulos, 2003). An actor de\ufb01nition usually represents a role rather than a speci\ufb01c person. However, the use of the notion of a role can vary from the assignment of a task, as proposed by Yu (1995), to a position within an organizational hierarchy (Sandhu, Coyne, Feinstein, & Youman, 1996\u00a0\u2026", "num_citations": "8\n", "authors": ["1448"]}
{"title": "Early identification of problem interactions: A tool-supported approach\n", "abstract": " [Context and motivation] The principle of \u201cdivide and conquer\u201d suggests that complex software problems should be decomposed into simpler problems, and those problems should be solved before considering how they can be composed. The eventual composition may fail if solutions to simpler problems interact in unexpected ways. [Question/problem] Given descriptions of individual problems, early identification of situations where composition might fail remains an outstanding issue. [Principal ideas/results] In this paper, we present a tool-supported approach for early identification of all possible interactions between problems, where the composition cannot be achieved fully. Our tool, called the OpenPF, (i) provides a simple diagramming editor for drawing problem diagrams and describing them using the Event Calculus, (ii) structures the Event Calculus formulae of individual problem diagrams for the\u00a0\u2026", "num_citations": "8\n", "authors": ["1448"]}
{"title": "Are your lights off? Using problem frames to diagnose system failures\n", "abstract": " This paper reports on our experience of investigating the role of software systems in the power blackout that affected parts of the United States and Canada on 14 August 2003. Based on a detailed study of the official report on the blackout, our investigation has aimed to bring out requirements engineering lessons that can inform development practices for dependable software systems. Since the causes of failures are typically rooted in the complex structures of software systems and their world contexts, we have deployed and evaluated a framework that looks beyond the scope of software and into its physical context, directing attention to places in the system structures where failures are likely to occur. We report that (i) Problem Frames were effective in diagnosing the causes of failures and documenting the causes in a schematic and accessible way, and (ii) errors in addressing the concerns of biddable domains\u00a0\u2026", "num_citations": "8\n", "authors": ["1448"]}
{"title": "Privacy rights management for mobile applications\n", "abstract": " With mobile telephony and GPS devices becoming ubiquitous, there are many tracking and monitoring devices being developed that have a range of potential applications, from supporting mobile learning to remote health monitoring of the elderly and chronically ill. However, do users actually understand how much of their personal information is being shared with others? In general, there will be a trade off between usefulness of disclosing private information and the risk of it being misused. In this position paper, we describe the Privacy Rights Management for Mobile Applications (PRiMMA) project, where we are investigating techniques for protecting the private information typically generated from ubiquitous computing applications from malicious or accidental misuse. Consider the following scenario:\u201cAlice and Bob\u2019s son Charles is involved in many after school activities. Concerned for his safety whilst travelling to and from these activities, Charles\u2019 parents buy him a new mobile phone that has a GPS tracking feature together with a Privacy Manager (PM) tool. To prevent Charles from unintentionally disclosing is location to others Bob configures the PM with a policy that states that only Alice and Bob can read Charles\u2019 location information.", "num_citations": "8\n", "authors": ["1448"]}
{"title": "A privacy preference model for pervasive computing\n", "abstract": " Widespread acceptance of e-government and m-government (and for that matter pervasive-Government) services will only take place when citizens are satisfied that personal data is stored, transmitted and processed with respect to their privacy. We compare and contrast data protection regimes found around the World and suggest that these have directly influenced the uptake of existing private-sector mobile services. Citizen uptake of e-government services will be encouraged by strong regulatory regimes dedicated to the protection of personal data. Consumers will entrust personal data where they can exert some measure of control over the release of that data to other parties. We examine a number of such controlling mechanisms and suggest a new privacy architecture intended for mobile service provision.", "num_citations": "8\n", "authors": ["1448"]}
{"title": "Cautious adaptation of defiant components\n", "abstract": " Systems-of-systems are formed by the composition of independently created software components. These components are designed to satisfy their individual requirements, rather than the global requirements of the systems-of-systems. We refer to components that cannot be adapted to meet both individual and global requirements as \"defiant\" components. In this paper, we propose a \"cautious\" adaptation approach which supports changing the behaviour of such defiant components under exceptional conditions to satisfy global requirements, while continuing to guarantee the satisfaction of the components' individual requirements. The approach represents both normal and exceptional conditions as scenarios; models the behaviour of exceptional conditions as wrappers implemented using an aspect-oriented technique; and deals with both single and multiple instances of defiant components with different\u00a0\u2026", "num_citations": "7\n", "authors": ["1448"]}
{"title": "Enabling end-users to protect their privacy\n", "abstract": " In this paper we present our ongoing work to build an approach to empower users of IoT-based cyber physical systems to protect their privacy by themselves. Our approach allows users to identify the privacy risks involved in sharing private data with a data consumer, assess the value of their private data based on identified risks and take a pragmatic data sharing decision balancing the risks with the benefits generated by the sharing. Our approach features a knowledgebase, called the Privacy Oracle, that exploits the power of the Semantic Web to determine how raw metadata can be combined by data consumers to infer privacy-sensitive information as well as the privacy risks associated with the disclosure of inferred information.", "num_citations": "7\n", "authors": ["1448"]}
{"title": "\u201cWhy can\u2019t I do that?\u201d: tracing adaptive security decisions\n", "abstract": " One of the challenges of any adaptive system is to ensure that users can understand how and why the behaviour of the system changes at runtime. This is particularly important for adaptive security behaviours which are essential for applications that are used in many different contexts, such as those hosted in the cloud. In this paper, we propose an approach for using traceability information, enriched with causality relations and contextual attributes of the deployment environment, when providing feedback to the users. We demonstrate, using a cloud storage-as-a-service environment, how our approach provides users of cloud applications better information, explanations and assurances about the security decisions made by the system. This enables the user to understand why a certain security adaptation has occurred, how the adaptation is related to current context of use of the application, and a guarantee that the application still satisfies its security requirements after an adaptation.", "num_citations": "7\n", "authors": ["1448"]}
{"title": "Contravision: presenting contrasting visions of future technology\n", "abstract": " How can we best explore the range of users' reactions when developing future technologies that may be controversial, such as personal healthcare systems? Our approach-ContraVision-uses futuristic videos, or other narrative forms, that convey both negative and positive aspects of the proposed technology for the same scenarios.", "num_citations": "7\n", "authors": ["1448"]}
{"title": "From organizational requirements to service choreography\n", "abstract": " Choreography is emerging as a standard for specifying multiparticipant interactions. However, conventional choreography descriptions provide only a partial view of the interaction. They do not capture critical business-domain knowledge including: goals motivating participants to interact, organizational dependencies that enable the interaction, and physical activities that are part of the interaction contract. In the absence of this knowledge, it is hard to argue if a choreography description satisfies the business goals of participants. This deficiency is critical when the need arises to adapt the choreography to changes in business requirements. In this paper, we argue for representing choreography at the level of requirements motivating the interaction. To bridge the two worlds of choreographed messaging and requirements, we propose an automated technique for deriving choreography descriptions. Utilizing the\u00a0\u2026", "num_citations": "7\n", "authors": ["1448"]}
{"title": "Customizing choreography: Deriving conversations from organizational dependencies\n", "abstract": " Evolving business needs call for customizable choreographed interactions. However, choreography descriptions do not capture the problem-domain knowledge required to perform the customization effectively. Hence, we propose performing the customization to models of organizational requirements motivating the interaction. To facilitate the derivation of the resulting choreography description, we propose an alignment between conversations and organizational dependencies. We employ the domain knowledge and formal semantics of requirements models to find customization alternatives and reason about them. Using the alignment, we derive constraints on conversations systematically from customized requirements models.", "num_citations": "7\n", "authors": ["1448"]}
{"title": "Recovering problem structures to support the evolution of software systems\n", "abstract": " Software systems evolve in response to changes in stakeholder requirements. Lack of documentation about the original system requirements can make it difficult to analyse and implement new requirements. Although the recovery of requirements from an implementation is usually not possible, we suggest that the recovery of problem structures, which in turn inform the problem analysis of new requirements, is feasible and useful. In this paper, we propose a tool-supported approach to recover and maintain structures of problems, solutions, and their relationships, for specific new features in an existing system. We show how these recovered structures help with requirements assessment, as they highlight early in the evolutionary development whether it is feasible to implement a new requirement. We validate our approach using a case study of a mediumsized open-source software system.", "num_citations": "7\n", "authors": ["1448"]}
{"title": "The process road between requirements and design\n", "abstract": " The software engineering literature contains many examples of methods, tools and techniques that claim to facilitate a variety of requirements engineering and design activities. Guidance on how these activities are related within a coherent software development process is much less apparent. A central problem that makes such guidance difficult to achieve is that requirements engineering addresses problem domains whereas design addresses solution domains. This is in the face of frequent changes in requirements contrasted with the need for stable design solutions.", "num_citations": "7\n", "authors": ["1448"]}
{"title": "Verifiable limited disclosure: Reporting and handling digital evidence in police investigations\n", "abstract": " Police investigations involving digital evidence tend to focus on forensic examination of storage units on personal electronic devices (laptops, smartphones, etc). However, a number of factors are making digital forensic tools increasingly ineffective: (i) storage capacities of electronic devices have increased, and so has the amount of personal information held on them, (ii) cyber crimes are increasingly committed on social media, and evidence of crimes are held on social media platforms, not necessarily on personal devices, (iii) there is a greater need for protecting digital privacy, especially when examining digital evidence from witnesses and victims of cyber crimes. These factors pose a number of practical challenges for both law enforcement agencies and citizens when disclosing and handling the digital evidence. This paper defines and illustrates the key challenges, and proposes the concept of verifiable limited\u00a0\u2026", "num_citations": "6\n", "authors": ["1448"]}
{"title": "Social adaptation at runtime\n", "abstract": " One of the main goals of software adaptation is that users get their dynamic requirements met efficiently and correctly. Adaptation is traditionally driven by changes in the system internally and its operational environment. An adaptive system has to monitor and analyse such changes and, if needed, switch to the right behaviour to meet its requirements. In this paper, we advocate another essential driver for adaptation which is the collective judgement of users on the different behaviours of a system. This judgement is based on the feedback iteratively collected from users at run-time. Users feedback should be related to their main interest which is the ability and quality of the system in reaching their requirements. We propose a novel approach to requirements-driven adaptation that gives the collective judgement of users, inferred from their individual feedback, a primary role in planning and guiding adaptation\u00a0\u2026", "num_citations": "6\n", "authors": ["1448"]}
{"title": "What makes a publication archival?\n", "abstract": " ARE journals more archival than conference proceedings? I don't think so. Most published conference proceedings live in libraries, digital or otherwise, and in that sense they are as archival as any other library publication. So what is it that distinguishes a conference paper from a journal paper? If it is the additional detail that a longer journal paper allows, then this may explain why many readers tell me that they often find journal papers hard to read. I think it is more than just detail though. Could it be the additional evaluation that journal publication demands? This is certainly a reason that many editors and reviewers give me. However, I have sat on many conference program committees in recent years, and I have observed expectations for high standards of evaluation, especially at the so-called top conferences. So, for such conference papers, is there much to distinguish them from journal papers? I must admit, I\u00a0\u2026", "num_citations": "6\n", "authors": ["1448"]}
{"title": "Analysing monitoring and switching requirements using constraint satisfiability\n", "abstract": " Context-aware applications monitor changes in their environment and switch their behaviour in order to continue satisfying requirements. Specifying monitoring and switching in such applications can be difficult due to their dependence on varying environmental properties. Two problems require analysis: the monitoring of environmental properties to assess their impact on continual requirements satisfaction, and the selection of appropriate behaviours that ensure requirements satisfaction. To address these problems, we provide concepts for refining contextual properties which we then use to formulate two theorems for monitoring and switching. These enable us to formally analyse the impact of context on monitoring and switching problems. We have instantiated our general approach by encoding monitoring and switching problems into propositional logic constraints, which we analyse automatically using a standard SAT solver. The approach is applied to an industrial case study to assess its efficacy.", "num_citations": "6\n", "authors": ["1448"]}
{"title": "Won't take no for an answer: resource-driven requirements adaptation\n", "abstract": " Adaptive composition dynamically and opportunistically uses and combines resources to best satisfy user requirements. However, when available resources cannot satisfy those requirements, no guidance or alternative options are offered by existing composition solutions. In this paper we address this issue by presenting an approach that tries to find substitutions for unavailable resources while satisfying the initial requirements. If no satisfactory substitutions are found, the requirements are adapted based on the resources available. Given that such requirements adaptation might be unbounded, we limit the search space guided by the available resources. Our approach ensures that alternative compositions given to users are achievable using available resources. We demonstrate the validity of our approach by implementing a prototype tool and applying it to support individuals in meal planning to reduce food waste.", "num_citations": "5\n", "authors": ["1448"]}
{"title": "Specifying software features for composition: A tool-supported approach\n", "abstract": " Development of several computing and communication technologies is enabling the widespread availability of pervasive systems. In smart home applications, household appliances\u2014such as security alarms, heating systems, doors and windows\u2014are connected to home digital networks. These applications offer features that are typically developed by disparate vendors, and when composed together, these features are expected to work together harmoniously. Engineering these systems poses two main challenges. The first challenge is: how can developers of individual features specify the features in order to make them composable with other hitherto unknown features? The second challenge is: when composition of features does not produce the desired behaviour, what can be done to resolve this non-intrusively? This article argues that the two issues are intrinsically related, and proposes an approach that\u00a0\u2026", "num_citations": "5\n", "authors": ["1448"]}
{"title": "An empirical study of security requirements in planning bug fixes for an open source software project\n", "abstract": " it is often difficult to estimate the resources needed to plan for bug fixing activities in software development projects. Security bug fixes are commonly implemented as patches in response to emergent common vulnerability and exposure (CVE) reports. In this paper we investigate how to plan for bug fixing, and whether security related bug fixes are different from other bugs. In a preprocessing step, we classify security and nonsecurity bugs by using a definition of security requirements to elicit the keywords such as' protection','assets' and'malicious attackers', and by ranking their frequency of occurrences in the bug descriptions. We then create two release-planning inputs: one about the entire bug fixing activities, and another about bug fixes related to security requirements only. The results of the release plans are compared, with the bug fixing events recorded in the software repositories. Through a Samba case study, we show that it is possible to fix more high-priority bugs within limited given resource, and that bugs related to security requirements are materially different from other kinds of bugs.", "num_citations": "5\n", "authors": ["1448"]}
{"title": "Childless older women: combating a deficit identity?\n", "abstract": " Government proposals on care for older people often elicit responses on the need to return to the attitude that it\u2019s the family\u2019s responsibility to look after its older members. Indeed social policy has tended to rely on the role of families when reducing the provision of social care through tax-supported services. How do people who don\u2019t have any children experience the ageing process, and with reference to childlessness what kind of discursive work and conversational moves do they undertake in interview? The normative expectations of a life progressing through stages associated with the heterosexual family, including love, marriage and parenthood, suggest that non-parenthood conjures up notions of loss and deficit \u2013 already an identity which can be attributed to single women (Reynolds and Wetherell, 2002; Reynolds and Taylor, 2005).  In this paper I revisit narratives from childless women first interviewed as living alone in their fifties and sixties some thirteen years ago. Women demonstrated rhetorical work in discussing their handling of questions on whether or not they have children. What does non-parenting mean to them now they are in the sixties and more? How does generativity (more usually associated with having children and grandchildren) play for women entering later life? What sort of expectations or anxieties do they have about the ageing process and possible future needs for care and support?   References Reynolds, J. and Wetherell, M. (2003) \u2018The discursive climate of singleness: the consequences for women\u2019s negotiation of a single identity\u2019, Feminism & Psychology, 13(4) pp. 489\u2013510. Reynolds, J. and Taylor, S. (2005\u00a0\u2026", "num_citations": "5\n", "authors": ["1448"]}
{"title": "Feature interaction as a context sharing problem\n", "abstract": " We argue that the feature interaction problem arises primarily from sharing of context and hence features should be structured and analysed through a notation that makes context explicit. We support this argument with three sets of evidence. Firstly, we express feature interaction through Zave and Jackson\u2019s entailment relation. With the entailment relation, we structure a feature as a relation between three sets of descriptions: requirement, context, and specification. We show that feature interactions arise due to shared context. Secondly, we examine the literature on sources of feature interactions and conclude that inconsistencies between requirements are ultimately manifested on shared context. Finally, we study feature interaction taxonomies and show that in the characterisation of feature interactions in taxonomies, context sharing is central.", "num_citations": "5\n", "authors": ["1448"]}
{"title": "Zombie Networks: An investigation into the use of anti-forensic techniques employed by botnets\n", "abstract": " My thanks and appreciation is given to Dr. Ian Newman, the supervisor of this project. Comments, criticism, advice, and above all, a steady hand at the tiller, were gratefully received.", "num_citations": "5\n", "authors": ["1448"]}
{"title": "Relating software requirements and architectures\n", "abstract": " Requirements engineering and software architecture have become established areas of software engineering research, education, and practice. Requirements engineering is concerned with discovering the purpose of a software system and the contexts in which it will be used (Nuseibeh and Easterbrook, 2000). Software architecture is concerned with the study of the structure of software, including its topology, properties, constituent components and their relationships and patterns of combination (Perry and Wolf, 1992). There have been significant research advances made in both software requirements and architectures, and fundamental differences and relationships between the two areas have come to light which are outlined.", "num_citations": "5\n", "authors": ["1448"]}
{"title": "Validating security requirements using structured toulmin-style argumentation\n", "abstract": " This paper proposes using structured informal argumentation to assist with determining whether the security requirements for a system satisfy the security goals, and whether an eventual realized system can satisfy the security requirements. We call these arguments' satisfaction arguments', and propose a systematic approach for their construction. A satisfaction argument is typically probabilistic and unique to the system in its context. We use the argument form proposed by Toulmin for evidence-based argumentation, consisting of claims, grounds, warrants, and rebuttals. Building on our earlier work on trust assumptions and security requirements, we show how using satisfaction arguments assists both in locating inconsistencies between security requirements and their respective goals, and in exposing tacit or inconsistent assumptions about the properties of domains and their possible effects on the eventual security of a system.", "num_citations": "5\n", "authors": ["1448"]}
{"title": "Technology transfer: software engineering and engineering design\n", "abstract": " Software engineering has made significant contributions to 'engineering-in-the-large'. The nature of the software process has been researched, and computer-based tools and environments have been built to support this process. Other more established engineering disciplines, such as instrument design, have developed professional practices, mature mathematical frameworks for system modelling and accepted quality standards lacking in software engineering. Little effort, however, has been devoted to the cross-fertilisation of software engineering and engineering design, or indeed the exploitation of the frequently observed commonalities between them. The Software Engineering and Engineering Design (SEED) project described has attempted to address these issues through the study of heterogeneous, composite systems. This has resulted in a model of the engineering design process, an organisational\u00a0\u2026", "num_citations": "5\n", "authors": ["1448"]}
{"title": "LiveBox: A self-adaptive forensic-ready service for drones\n", "abstract": " Unmanned Aerial Vehicles (UAVs), or drones, are increasingly expected to operate in spaces populated by humans while avoiding injury to people or damaging property. However, incidents and accidents can, and increasingly do, happen. Traditional investigations of aircraft incidents require on-board flight data recorders (FDRs); however, these physical FDRs only work if the drone can be recovered. A further complication is that physical FDRs are too heavy to mount on light drones, hence not suitable for forensic digital investigations of drone flights. In this paper, we propose a self-adaptive software architecture, LiveBox, to make drones both forensic-ready and regulation compliant. We studied the feasibility of using distributed technologies for implementing the LiveBox reference architecture. In particular, we found that updates and queries of drone flight data and constraints can be treated as transactions using\u00a0\u2026", "num_citations": "4\n", "authors": ["1448"]}
{"title": "Learning to share: engineering adaptive decision-support for online social networks\n", "abstract": " Some online social networks (OSNs) allow users to define friendship-groups as reusable shortcuts for sharing information with multiple contacts. Posting exclusively to a friendship-group gives some privacy control, while supporting communication with (and within) this group. However, recipients of such posts may want to reuse content for their own social advantage, and can bypass existing controls by copy-pasting into a new post; this cross-posting poses privacy risks. This paper presents a learning to share approach that enables the incorporation of more nuanced privacy controls into OSNs. Specifically, we propose a reusable, adaptive software architecture that uses rigorous runtime analysis to help OSN users to make informed decisions about suitable audiences for their posts. This is achieved by supporting dynamic formation of recipient-groups that benefit social interactions while reducing privacy risks. We\u00a0\u2026", "num_citations": "4\n", "authors": ["1448"]}
{"title": "Live blackboxes: Requirements for tracking and verifying aircraft in motion\n", "abstract": " The Malaysian Airlines (MH370) aircraft went missing somewhere over the Indian Ocean two years ago. After intensive search since then, international team still has not been able to locate any first-hand evidence from the missing plane\u2019s flight data recorders (also known as \u2018blackboxes\u2019). To mitigate similar problems, a proposal has been made to analyse live streamed flight data using cloud computing; however, satellite communication is constrained by bandwidth and scalability challenges. i In this paper, we propose five requirements for addressing these challenges. These requirements frame a class of monitoring problems that share some similar accuracy concerns around safety and security. We evaluate these requirements to assess the readiness of the proposed technology-which we call \u201clive blackboxes\u201d\u2013by using actual global scale data and performing an analysis of different live streaming intervals\u00a0\u2026", "num_citations": "4\n", "authors": ["1448"]}
{"title": "Managing security control assumptions using causal traceability\n", "abstract": " Security control specifications of software systems are designed to meet their security requirements. It is difficult to know both the value of assets and the malicious intention of attackers at design time, hence assumptions about the operational environment often reveal unexpected flaws. To diagnose the causes of violations in security requirements it is necessary to check these design-time assumptions. Otherwise, the system could be vulnerable to potential attacks. Addressing such vulnerabilities requires an explicit understanding of how the security control specifications were defined from the original security requirements. However, assumptions are rarely explicitly documented and monitored during system operation. This paper proposes a systematic approach to monitoring design-time assumptions explicitly as logs, by using trace ability links from requirements to specifications. The work also helps identify which\u00a0\u2026", "num_citations": "4\n", "authors": ["1448"]}
{"title": "Traceability for adaptive information security in the cloud\n", "abstract": " One of the key challenges in cloud computing is the security of the consumer data stored and processed by cloud machines. When the usage context of a cloud application changes, or when the context is unknown, there is a risk that security policies are violated. To minimize this risk, cloud applications need to be engineered to adapt their security policies to maintain satisfaction of security requirements despite changes in their usage context. We call such adaptation capability Adaptive Information Security. The paper argues that one of the prerequisites to adaptive information security is the use of traceability as a means to understanding the relationship between security requirements and security policies. Using an example, we motivate the need for improving traceability in the development of cloud applications.", "num_citations": "4\n", "authors": ["1448"]}
{"title": "Aspect interactions: a requirements engineering perspective\n", "abstract": " The principle of Separation of Concerns encourages developers to divide complex problems into simpler ones and solve them individually. Aspect-Oriented Programming (AOP) languages provide mechanisms to modularise concerns that affect several software components, by means of joinpoints, advice and aspect weaving. In a software system with multiple aspects, a joinpoint can often be matched with advice from several aspects, thus giving rise to emergent behaviours that may be unwanted. This issue is often known as the aspect interaction problem. AOP languages provide various composition operators: the precedence operator of AspectJ, for instance, instructs the aspect weaver about the ordering of aspects when advice from several of them match one joinpoint. This ordering of conflicting aspects is usually done at compile-time. This chapter discusses a type of problem where conflicting aspects\u00a0\u2026", "num_citations": "4\n", "authors": ["1448"]}
{"title": "Misuse case techniques for mobile privacy\n", "abstract": " 1) Fake driver arrives city centre 2) Fake driver sends request for notification of available near-by parking spaces 3) Fake driver receives notification of available near-by parking spaces 4) Fake driver views details of available near-by parking spaces 5) Fake driver arrives at notified empty parking space", "num_citations": "4\n", "authors": ["1448"]}
{"title": "Managing requirements for mobile learning\n", "abstract": " This paper reports on the experience of eliciting and managing requirements on a large Europeanbased multinational project, whose purpose is to create a system to support learning using mobile technology. The project used the socio-cognitive engineering methodology for human-centered design [1] and the Volere shell and template [2] to document requirements.We provide details about the project below, describe the Volere tools, and explain how and why we used a flexible categorization scheme to manage the requirements. Finally, we discuss three lessons learned:(1) provide a flexible mechanism for organizing requirements,(2) plan ahead for the RE process, and (3) do not forget the waiting room.", "num_citations": "4\n", "authors": ["1448"]}
{"title": "Privacy Care: A Tangible Interaction Framework for Privacy Management\n", "abstract": " The emergence of ubiquitous computing (UbiComp) environments has increased the risk of undesired access to individuals\u2019 physical space or their information, anytime and anywhere, raising potentially serious privacy concerns. Individuals lack awareness and control of the vulnerabilities in everyday contexts and need support and care in regulating disclosures to their physical and digital selves. Existing GUI-based solutions, however, often feel physically interruptive, socially disruptive, time-consuming and cumbersome. To address such challenges, we investigate the user interaction experience and discuss the need for more tangible and embodied interactions for effective and seamless natural privacy management in everyday UbiComp settings. We propose the Privacy Care interaction framework, which is rooted in the literature of privacy management and tangible computing. Keeping users at the center\u00a0\u2026", "num_citations": "3\n", "authors": ["1448"]}
{"title": "OASIS: Weakening User Obligations for Security-critical Systems\n", "abstract": " Security-critical systems typically place some requirements on the behaviour of their users, obliging them to follow certain instructions when using those systems. Security vulnerabilities can arise when users do not fully satisfy their obligations. In this paper, we propose an approach that improves system security by ensuring that attack scenarios are mitigated even when the users deviate from their expected behaviour. The approach uses structured transition systems to present and reason about user obligations. The aim is to identify potential vulnerabilities by weakening the assumptions on how the user will behave. We present an algorithm that combines iterative abstraction and controller synthesis to produce a new software specification that maintains the satisfaction of security requirements while weakening user obligations. We demonstrate the feasibility of our approach through two examples from the e-voting\u00a0\u2026", "num_citations": "3\n", "authors": ["1448"]}
{"title": "How are you feeling? Using tangibles to log the emotions of older adults\n", "abstract": " The global population is ageing, leading to shifts in healthcare needs. Home healthcare monitoring systems currently focus on physical health, but there is an increasing recognition that psychological wellbeing also needs support. This raises the question of how to design devices that older adults can interact with to log their feelings. We designed three tangible prototypes, based on existing paper-based scales of affect. We report findings from a lab study in which participants used the prototypes to log the emotion from standardised emotional vignettes. We found that the prototypes allowed participants to accurately record identified emotions in a reasonable time. Our participants expressed a perceived need to record emotions, either to share with family/carers or for self-reflection. We conclude that our work demonstrates the potential for in-home tangible devices for recording the emotions of older adults to support\u00a0\u2026", "num_citations": "3\n", "authors": ["1448"]}
{"title": "Incidents are meant for learning, not repeating: Sharing knowledge about security incidents in cyber-physical systems\n", "abstract": " Cyber-physical systems (CPSs) are part of most critical infrastructures such as industrial automation and transportation systems. Thus, security incidents targeting CPSs can have disruptive consequences to assets and people. As prior incidents tend to re-occur, sharing knowledge about these incidents can help organizations be more prepared to prevent, mitigate or investigate future incidents. This paper proposes a novel approach to enable representation and sharing of knowledge about CPS incidents across different organizations. To support sharing, we represent incident knowledge (incident patterns) capturing incident characteristics that can manifest again, such as incident activities or vulnerabilities exploited by offenders. Incident patterns are a more abstract representation of specific incident instances and, thus, are general enough to be applicable to various systems - different than the one in which the incident occurred. They can also avoid disclosing potentially sensitive information about an organization's assets and resources. We provide an automated technique to extract an incident pattern from a specific incident instance. To understand how an incident pattern can manifest again in other cyber-physical systems, we also provide an automated technique to instantiate incident patterns to specific systems. We demonstrate the feasibility of our approach in the application domain of smart buildings. We evaluate correctness, scalability, and performance using two substantive scenarios inspired by real-world systems and incidents.", "num_citations": "3\n", "authors": ["1448"]}
{"title": "Knowledge-based architecture for recognising activities of older people\n", "abstract": " The world is facing an ageing population phenomenon, coupled with health and social problems, which affect older people\u2019s ability to live independently. This situation challenges the viability of health and social services. Smart home technology can play a significant role in easing the pressure on caregivers, as well as reduce the financial costs of health and social services. Activity of Daily Living (ADL) recognition is an essential step to translate sensor data into activities at high semantic levels. Supervised Machine Learning (ML) algorithms are the most commonly used techniques for this application. However, a common problem is a lack of availability of enough annotated data to train these algorithms. Collecting annotated data is expensive, time consuming, and may violate people\u2019s privacy. Intra- and inter-personal variation in performing complex activities is another challenge for an ML-based activity\u00a0\u2026", "num_citations": "3\n", "authors": ["1448"]}
{"title": "Generating privacy zones in smart cities\n", "abstract": " Smart cities offer a variety of services to provide citizens with efficient transport, water distribution, crime prevention, and traffic control. Such services are personalized by automatically capturing, storing, and processing personally identifiable data. The disclosure of such data to a service provider raises privacy concerns for application users. As a result, research has recognized the need for privacy aware services in smart cities. In this paper we present PrivacyZones, a privacy awareness framework which requires the service provider to share meaningful features of the data collected by their application (such as the number of users in proximity to a location). Using this information an application user will know the potential privacy risk prior to sharing their data. The framework can also recommend the actions a user can take to mitigate privacy risks, such as when, where and what data to share with a service provider\u00a0\u2026", "num_citations": "3\n", "authors": ["1448"]}
{"title": "The Many Facets of Mediation: A Requirements-Driven Approach for Trading Off Mediation Solutions\n", "abstract": " Mediation aims at enabling dynamic composition of multiple components by making them interact successfully in order to satisfy given requirements. Through dynamic composition, software systems can adapt their structure and behavior in dynamic and heterogeneous environments such as ubiquitous computing environments. This paper provides a review of existing mediation approaches and their key characteristics and limitations. We claim that only a multifaceted approach that brings together and enhances the solutions of mediation from different perspectives is viable in the long term. We discuss how requirements can help identify synergies and trade-offs between these approaches and drive the selection of the appropriate mediation solution. We also highlight the open issues and future research directions in the area.", "num_citations": "3\n", "authors": ["1448"]}
{"title": "Personal informatics for non-geeks: lessons learned from ordinary people\n", "abstract": " We have been studying how ordinary people use personal informatics technologies for several years. In this paper we briefly describe our early studies, which influenced our design decisions in a recent pilot study that included junior doctors in a UK hospital. We discuss a number of failures in compliance and data collection as well as lessons learned.", "num_citations": "3\n", "authors": ["1448"]}
{"title": "From model-driven software development processes to problem diagnoses at runtime\n", "abstract": " Following the \u201cconvention over configuration\u201d paradigm, model-driven software development (MDSD) generates code to implement the \u201cdefault\u201d behaviour that has been specified by a template separate from the input model. On the one hand, developers can produce end-products without a full understanding of the templates; on the other hand, the tacit knowledge in the templates is subtle to diagnose when a runtime software failure occurs. Therefore, there is a gap between templates and runtime adapted models. Generalising from the concrete problematic examples in MDSD processes to a model-based problem diagnosis, the chapter presents a procedure to separate the automated fixes from those runtime gaps that require human judgments.", "num_citations": "3\n", "authors": ["1448"]}
{"title": "Requirements-driven design of service-oriented interactions\n", "abstract": " Service-oriented architecture (SOA) enables interenterprise service interactions. Services provide platform-independent abstractions around software systems, thereby enabling interoperability between heterogeneous systems. It is supported by a tool, Chreq(Choreograpy requirements) that automatically generates messaging protocols from requirements models. Chreq also generates comments, interleaved with the protocol, to indicate points at which physical activities should execute. Several languages are emerging as standards for describing interfaces and interaction protocols that specify service-oriented systems.", "num_citations": "3\n", "authors": ["1448"]}
{"title": "Mobile privacy requirements on demand\n", "abstract": " Process and product improvements are noble goals. Structured, document-driven processes have played an important part in the development of some mission critical systems. Likewise, agile and lean development processes are showing increasing promise in competitive, changing environments. The \u2019software as a service\u2019 paradigm is adding a further challenging dimension to the mix, and is redefining the notion of a software product.", "num_citations": "3\n", "authors": ["1448"]}
{"title": "Predators and prey: ubiquitous tracking, privacy and the social contract\n", "abstract": " Previous work examining privacy interfaces and user attitudes towards location tracking have relied on irregular manual updates from users, imprecise location information or information obtained via specialized equipment. We present a field study where 12 participants used their own mobile phones with automatic accurate location tracking over a 3-week period. We recorded over 1000 user tracking events, over 300 extended experience sampling entries and more than 15 hours of debriefing interviews. Taking an evolutionary perspective on location tracking, we observe how predator-prey dynamics interact with the social contracts that define our relationships and present a threetire framework accounting for the complexity of users\u2019 responses to location tracking technology. We also discuss how the limitations of the technology currently available contribute to misperceptions and misinterpretations impacting on an individual\u2019s social interactions and how ubiquitous location tracking encroaches on the individual\u2019s fundamental need to safely withdraw from social interaction.", "num_citations": "3\n", "authors": ["1448"]}
{"title": "Software Requirements and Design: The Work of Michael Jackson\n", "abstract": " Subtitled \"The Work of Michael Jackson,\" this book spans the career of one of software engineering's most important figures. Half the chapters are an anthology of Jackson's past writings, exemplifying the clarity, wisdom, and wit for which he is so well known. The other half of the book is new: Jackson and his colleagues gives their latest views on requirements, specifications, design, problem frames, and programming methods. Although many people have observed that software development should be more of an engineering discipline, few have drawn from the wider engineering literature more deeply or usefully than Jackson. Because of his work, many software engineers have a better perspective on their software and the real world it is intended to serve.", "num_citations": "3\n", "authors": ["1448"]}
{"title": "\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u8981\u6c42\u5de5\u5b66\u306e\u5b9f\u52b9\u6027: 1. \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u8981\u6c42\u5de5\u5b66\u306e\u6982\u8981\u3068\u5c55\u671b\n", "abstract": " \u8ad6\u6587\u6284\u9332\u3055\u307e\u3056\u307e\u306a\u30a4\u30f3\u30d5\u30e9\u304c IT \u5316\u3055\u308c, \u4fbf\u5229\u306b\u306a\u308b\u306b\u5f93\u3044, \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u306e\u554f\u984c\u306f\u793e\u4f1a\u306e\u6839\u5e79\u306b\u304b\u304b\u308f\u308b\u91cd\u5927\u306a\u554f\u984c\u306b\u306a\u3063\u3066\u304d\u3066\u3044\u308b. \u672c\u7a3f\u3067\u306f, \u307e\u305a, \u5b89\u5168\u306a\u30b7\u30b9\u30c6\u30e0\u3092\u69cb\u7bc9\u3059\u308b\u305f\u3081\u306b\u5fc5\u8981\u306a\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u5de5\u5b66\u306e 1 \u3064\u3067\u3042\u308b\u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u8981\u6c42\u5de5\u5b66\u306b\u7126\u70b9\u3092\u7d5e\u3063\u3066, \u73fe\u72b6\u3068\u5c55\u671b\u3092\u89e3\u8aac\u3059\u308b. \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u5de5\u5b66\u3068\u306f, \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u306e\u95a2\u5fc3\u4e8b\u3092, \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u3068\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u5de5\u5b66\u306e\u5c02\u9580\u5bb6\u306e\u53cc\u65b9\u306b\u3088\u308a, \u8981\u6c42\u5de5\u5b66, \u30e2\u30c7\u30ea\u30f3\u30b0, \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3, \u30c7\u30b6\u30a4\u30f3\u3084\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u5de5\u5b66\u306e\u5b9f\u8df5\u306b\u7d71\u5408\u3057\u3088\u3046\u3068\u3059\u308b\u7814\u7a76\u306e 1 \u3064\u3067\u3042\u308a, \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u8981\u6c42\u5de5\u5b66\u306f\u305d\u306e\u6700\u3082\u4e0a\u6d41\u5de5\u7a0b\u306b\u4f4d\u7f6e\u3059\u308b. \u672c\u7a3f\u3067\u306f, \u307e\u305a\u305d\u306e\u5fc5\u8981\u6027\u3092\u8aac\u660e\u3057\u305f\u5f8c, \u5b9a\u7fa9\u304a\u3088\u3073, \u305d\u306e\u96e3\u3057\u3055\u3092\u6574\u7406\u3059\u308b. \u305d\u3057\u3066, \u305d\u308c\u306b\u5bfe\u3057\u3066\u4f55\u3092\u3059\u3079\u304d\u304b\u3092\u6982\u8ad6\u3059\u308b.", "num_citations": "3\n", "authors": ["1448"]}
{"title": "Requirements engineering research in some future worlds: An exercise in scenario planning\n", "abstract": " We hope this will be a panel discussion with a difference. Each of our panel members has been given a scenario description of the world in 2020, significantly different from our own.", "num_citations": "3\n", "authors": ["1448"]}
{"title": "The Learning Grid and E-Assessment using Latent Semantic Analysis.\n", "abstract": " E-assessment is an important component of e-learning and equalification. Formative and summative assessment serves different purposes and both types of evaluation are critical to the pedagogical process. While students are studying, practicing, working, or revising, formative assessment provides direction, focus, and guidance. Summative assessment provides the means to evaluate a learner\u2019s achievement and communicate that achievement to interested parties. Latent Semantic Analysis (LSA) is a statistical method for inferring meaning from a text. Applications based on LSA exist that provide both summative and formative assessment of a learner\u2019s work. However, the huge computational needs are a major problem with this promising technique. This paper explains how LSA works, describes the breadth of existing applications using LSA, explains how LSA is particularly suited to e-assessment, and proposes research to exploit the potential computational power of the Grid to overcome one of LSA\u2019s drawbacks.", "num_citations": "3\n", "authors": ["1448"]}
{"title": "Nocuous ambiguities in requirements specifications\n", "abstract": " In this paper we present a novel approach that automatically alerts authors of requirements specifications to the presence of potentially dangerous ambiguities in their text. We first establish the notion of\" nocuous\" ambiguities, ie those that are likely to lead to misunderstandings. We focus on coordination ambiguity, which occurs when words such as \u201cand\u201d and \u201cor\u201d are used. Our starting point is a dataset of ambiguous phrases from a corpus of requirements specifications, and a collection of associated human judgements about their interpretation. We then use machine learning techniques combined with syntactic, semantic and word distribution heuristics to eliminate instances of text which people interpret easily. We report on a series of experiments and evaluate the performance of our approach against the collection of human judgements. Our machine learning algorithm has an accuracy of 75% compared to a 59.6% baseline.", "num_citations": "3\n", "authors": ["1448"]}
{"title": "An example using problem frames: Analysis of a lighting control system\n", "abstract": " A reasonably complex lighting control system is decomposed using problem frames. The merits of various decompositions are examined. The paper concludes with a discussion of unresolved problem concerns exposed by the decomposition.", "num_citations": "3\n", "authors": ["1448"]}
{"title": "Managing inconsistent specifications: Reasoning, analysis, and action\n", "abstract": " In previous work, we advocated continued development of speci cations in the presence of inconsistency. To support this, we used classical logic to represent partial speci cations and to identify inconsistencies between them. We now present an adaptation of classical logic, which we term quasi-classical (QC) logic, that allows continued reasoning in the presence of inconsistency. The adaptation is a weakening of classical logic that prohibits all trivial derivations, but still allows all resolvants of the assumptions to be derived. Furthermore, the connectives behave in a classical manner. We then present a development called labelled QC logic that records and tracks assumptions used in reasoning. This facilitates a logical analysis of inconsistent information. We discuss the application of labelled QC logic in the analysis of multi-perspective speci cations. Such speci cations are developed by multiple participants who hold overlapping, often inconsistent, views of the systems they are developing.", "num_citations": "3\n", "authors": ["1448"]}
{"title": "Making requirements measurable (tutorial)\n", "abstract": " Increasingly sophisticated technology makes it possible to build more complex systems more quickly. However a system is only useful to the customer if it addresses the real requirements. Eliciting and specifying customer requirements in a precise and unambiguous way is critical to the success of a project. Customers often find it difficult to articulate their requirements, and for large, complex systems these requirements are often conflicting.This full-day tutorial focuses on guiding participants through the requirements definition process. After presenting an overview of requirements engineering activities, the tutorial focuses on how to assess (\u201cmeasure\u201d) requirements for testability, relevance, completeness, consistency, coherence, traceability and satisfaction. A requirements template is used as a guide to discovering requirements and building the specification. A requirement is regarded as \u201cmeasurable\u201d if there is an\u00a0\u2026", "num_citations": "3\n", "authors": ["1448"]}
{"title": "Building bridges: on the development of complex software\n", "abstract": " Gazing across Sydney Harbour for the first time a few months ago, I was awed, as most visitors are, by the two beautiful feats of engineering that dominated the scene: the Sydney Harbour Bridge built in the first half of the century, and the Sydney Opera House completed in the 1970s. Later on during my visit to Sydney, I was given some thought-provoking statistics about these two structures", "num_citations": "3\n", "authors": ["1448"]}
{"title": "Security but not for security's sake: The impact of social considerations on app developers' choices\n", "abstract": " We explore a dataset of app developer reasoning to better understand the reasons that may inadvertently promote or demote app developers' prioritization of security. We identify a number of reasons: caring vs. fear of users, the impact of norms, and notions of'otherness' and'self'in terms of belonging to groups. Based on our preliminary findings, we propose an interdisciplinary research agenda to explore the impact of social identity (a psychological theory) on developers' security rationales, and how this could be leveraged to guide developers towards making more secure choices.", "num_citations": "2\n", "authors": ["1448"]}
{"title": "Altruism and anxiety: Engagement with online community support initiatives (OCSIs) during Covid-19 lockdown in the UK and Ireland\n", "abstract": " Given concerns about mental health during periods of Covid-19 lockdown, it important to understand how engagement with online Covid-19 related material can affect mood. In the UK and Ireland, online community support initiatives (OCSIs) have emerged to help people manage their lives. Yet, little is known about how people engaged with these or whether they influenced subsequent mood. We conducted surveys to explore how people in the UK and Ireland engaged with OCSIs, and found that 70% did so to offer support (e.g. to provide company). Those who did so reported feeling significantly calmer afterwards, those who engaged for general concerns (e.g. in response to anti-social behaviour) reported feeling significantly more anxious afterwards, but there was no difference in reported mood for those who engaged for other reasons (e.g. to share experiences or views). Thus, engaging with an OCSI for altruistic purposes might help to make people feel calmer.", "num_citations": "2\n", "authors": ["1448"]}
{"title": "Optimal by Design: Model-Driven Synthesis of Adaptation Strategies for Autonomous Systems\n", "abstract": " Many software systems have become too large and complex to be managed efficiently by human administrators, particularly when they operate in uncertain and dynamic environments and require frequent changes. Requirements-driven adaptation techniques have been proposed to endow systems with the necessary means to autonomously decide ways to satisfy their requirements. However, many current approaches rely on general-purpose languages, models and/or frameworks to design, develop and analyze autonomous systems. Unfortunately, these tools are not tailored towards the characteristics of adaptation problems in autonomous systems. In this paper, we present Optimal by Design (ObD ), a framework for model-based requirements-driven synthesis of optimal adaptation strategies for autonomous systems. ObD proposes a model (and a language) for the high-level description of the basic elements of self-adaptive systems, namely the system, capabilities, requirements and environment. Based on those elements, a Markov Decision Process (MDP) is constructed to compute the optimal strategy or the most rewarding system behaviour. Furthermore, this defines a reflex controller that can ensure timely responses to changes. One novel feature of the framework is that it benefits both from goal-oriented techniques, developed for requirement elicitation, refinement and analysis, and synthesis capabilities and extensive research around MDPs, their extensions and tools. Our preliminary evaluation results demonstrate the practicality and advantages of the framework.", "num_citations": "2\n", "authors": ["1448"]}
{"title": "Monetize this? Marketized-commons platforms, new opportunities and challenges for collective action\n", "abstract": " In this paper we argue that recent developments in peer-to-peer platforms, including those underpinned by distributed-ledger technology (or blockchains), represent a new model for organizing collective action, which we term the \u201cmarketized-commons\u201d model. Drawing on social psychological and economic theory, we compare this concept to established modes of organizing collective action. We also consider the marketized-commons model in relation to other peer-to-peer economies. We consider why individuals might be motivated to create and use platforms underpinned by the marketized-commons model, as well as how it might be counterproductive for cooperation, collaboration, participation and social goals. Finally, we recommend implications for those interested in designing peer-to-peer platforms to support collective action. Ultimately, we argue that to develop effective platforms in this context\u00a0\u2026", "num_citations": "2\n", "authors": ["1448"]}
{"title": "A Sensor Platform for Non-invasive Remote Monitoring of Older Adults in Real Time\n", "abstract": " The population of older adults is increasing across the globe; this growth is predicted to continue into the future. Most older adults prefer to live in their own home, but many live alone without immediate support. Living longer is often coupled with health and social problems and difficulty managing daily activities. Therefore, some level of care is required, but this is costly. Technological solutions may help to mitigate these problems by recognising subtle changes early and intervening before problems become unmanageable. Understanding a person\u2019s usual behaviour when carrying out Activities of Daily Living (ADL) makes it possible to detect and respond to anomalies. However, current commercial and research monitoring systems do not offer an analysis of ADL and are unable to detect subtle changes. To address this gap, we propose the STRETCH (Socio-Technical Resilience for Enhancing Targeted\u00a0\u2026", "num_citations": "2\n", "authors": ["1448"]}
{"title": "On the disappearing boundary between digital, physical, and social spaces: Who, what, where and when?\n", "abstract": " Boundaries play a critical role in the systems development process. In software engineering, boundaries are used to scope the real world problems that the software is required to address, and to scope the design solutions through which the software will meet its requirements. In security engineering, boundaries delimit the points at which assets may be legitimately accessed or the defences that attackers seek to breach. Cyber physical systems (CPS) add another set of boundaries that require consideration-the boundaries between the digital and the physical spaces that the CPS inhabit, as well as the boundaries with the social spaces in which such systems will operate. These boundaries have been the bedrock upon which developers build software, systems, and security capabilities. They help manage complexity of systems, organise their development, and manage their deployment. However, the views and\u00a0\u2026", "num_citations": "2\n", "authors": ["1448"]}
{"title": "On Protecting Privacy in the Cloud\n", "abstract": " Cloud computing has now emerged as popular computing paradigm for data storage and computation for enterprises and individuals. Its major characteristics include the pay-per-use pricing model, where users pay only for the resources they consume with no upfront cost for hardware/software infrastructures, and the capability of providing scalable and unlimited storage and computation resources to meet changing business needs of enterprises with minimal management overhead [1]. The cloud, however, presents a major limitation to enterprises and individuals who move to public clouds: they lose control over the systems that manage their data and applications, leading to increased security and privacy concerns [2, 3, 4].In this article, we examine cloud privacy concerns, and provide an overview of current and emerging solutions for protecting privacy of data and applications deployed in the cloud. Based on this, we suggest a set of recommendations for practitioners and researchers to improve privacy protection of cloud users.", "num_citations": "2\n", "authors": ["1448"]}
{"title": "Getting at ephemeral flaws\n", "abstract": " Software rarely works as intended when it is initially written. Things go wrong, and developers are commonly understood to form theories and strategies to deal with them. Much of this knowledge relates to ephemeral flaws rather than reported bugs, and is not captured in the software record. As a result, these flaws and understanding about them are neglected in software engineering research. In this paper we describe a study designed to elicit stories from software developers about problems they encounter in their daily work. We also offer preliminary thoughts about the utility of retrospective interviewing in getting at information about ephemeral flaws.", "num_citations": "2\n", "authors": ["1448"]}
{"title": "Towards self-protecting smart metering: investigating requirements for the MAPE loop\n", "abstract": " Smart grids are increasingly proliferating all over the world to leverage electricity infrastructures with information technology. Smart metering, particularly Advanced Metering Infrastructure (AMI), is an enabling technology for realizing smart grids by collecting and processing energy consumption logs and managing energy for customers and utility companies. Security is one of the main concerns of smart metering, and potential threats and attacks to this technology have been discussed since the early initiatives. Considering the unbounded and changing nature of security problems, especially in complex and critical cyber-physical systems, smart metering security concerns can not be always addressed at design time. Autonomic self-protection promises to address runtime security concerns in proactive and reactive ways. In this paper, we focus on the customer domain of smart metering, and investigate potential reactive self-protection scenarios by concentrating on requirements. To this aim, we analyze a sample set of published security requirements from the AMISEC forum [1] to derive self-protection requirements. Then we discuss how these requirements can be linked to the MAPE loop [2] in the autonomic computing architecture.", "num_citations": "2\n", "authors": ["1448"]}
{"title": "Towards learning to detect meaningful changes in software\n", "abstract": " Software developers are often concerned with particular changes that are relevant to their current tasks: not all changes to evolving software are equally important. Specified at the language-level, we have developed an automated technique to detect only those changes that are deemed meaningful, or relevant, to a particular development task [1]. In practice, however, it is realised that programmers are not always familiar with the production rules of a programming language. Rather, they may prefer to specify the meaningful changes using concrete program examples. In this position paper, we are proposing an inductive learning procedure that involves the programmers in constructing such language-level specifications through examples. Using the efficiently generated meaningful changes detector, programmers are presented with quicker feedback for adjusting the learnt specifications. An illustrative example is\u00a0\u2026", "num_citations": "2\n", "authors": ["1448"]}
{"title": "Learning from context: a field study of privacy awareness system for mobile devices\n", "abstract": " In this paper we investigate the effectiveness of context-awareness and machine learning in ensuring social acceptance of real-time feedback in a social location tracking system. Real-time feedback is a novel privacy feature supporting bi-directional function of privacy management. Its main function is to deliver feedback to the user by using an appropriate form of notification every time a user\u201f s location has been checked. We evaluated our technology in the context of Buddy Tracker, our context-aware, location-sharing application for mobile devices. We report on our experience from the development process and also discuss findings of our field study with 15 participants. The findings show that contextawareness and machine learning can minimize the intrusiveness of real-time feedback, therefore making this important function socially more acceptable thus allowing users to benefit from the increased level of awareness that real-time feedback affords. We conclude with recommendations on how a better understanding of the user and application-specific context can improve the user experience and social acceptance of the system.", "num_citations": "2\n", "authors": ["1448"]}
{"title": "How Special Should Issues Be?\n", "abstract": " SOFTWARE testing and analysis continue to be areas in which IEEE Transaction on Software Engineering (TSE) receives many submissions. In this issue, Barbara Ryder and Andreas Zeller guest edit a special section of selected papers from ISSTA 2008, the original papers having undergone significant revision, extension, and substantive peer review. I would like to thank Barbara and Andreas for all their work in putting this special section together over a long period of time, and to the authors for their contributions and their patience while waiting for their papers to be published. Special issues are a prominent feature of TSE and other journals, and there are a number of forthcoming issues in the TSE publication pipeline. I\u2019d be interested to hear readers\u2019 views about the usefulness of such special issues. I understand that they can provide a useful thematic resource for researchers and practitioners working in\u00a0\u2026", "num_citations": "2\n", "authors": ["1448"]}
{"title": "Readers, Writers, Reviewers, and Editors\n", "abstract": " Dave Parnas, TSE\u2019s Emeritus Associate Editor, often reminds me that TSE should serve its readers above all others. I agree with him, although I also realize of course that it is authors and reviewers who keep the TSE ecosystem running. However, even as authors, reviewers, and editors complain that bibliometrics dominate our research assessments, very few of us also complain that our readers are not assessing what we write. Why is this so? If you are a reader, are you satisfied with what you are getting in each issue of TSE? Are you reading at least some of the papers? If so, what papers in 2009 did you like most and why? If we are to reduce our reliance on citation numbers and impact factors, perhaps we should look for other forms of assessing significance and influence? What better than getting the qualitative feedback from readers\u2014researchers and practitioners\u2014who have benefitted from reading papers\u00a0\u2026", "num_citations": "2\n", "authors": ["1448"]}
{"title": "A New Decade of TSE\n", "abstract": " I am honored to be taking over as Editor in Chief of the IEEE Transactions of Software Engineering (TSE). Jeff Kramer will be a hard act to follow, but I am immensely grateful to him for handing over the journal in such a healthy state, and for helping me learn the new job to ensure a smooth transition. It goes without saying that my primary goal as Editor is to maintain the journal\u2019s reputation and standing as the leading forum for publishing the highest quality of research in software engineering. However, these are exciting and changing times in the world of publishing and in the discipline of software engineering, and I believe that TSE must lead the way by finding innovative ways to disseminate software engineering research and by contributing to setting and reflecting the research agenda in the field. To this end I have three medium term goals for my tenure as Editor: 1. To reemphasize the broad scope of the journal\u00a0\u2026", "num_citations": "2\n", "authors": ["1448"]}
{"title": "A multi-pronged empirical approach to mobile privacy investigation\n", "abstract": " We describe the design of three empirical studies planned as part of an investigation into privacy when mobile. The studies exemplify complementary investigation strands, whose aim is to uncover the multi-faceted nature of privacy for mobile computing applications.", "num_citations": "2\n", "authors": ["1448"]}
{"title": "Guest editors\u2019 introduction: special section on software engineering for secure systems\n", "abstract": " THE proliferation of computers in society has meant that organizational and personal assets are increasingly stored and manipulated by software systems. The scale of misuse of these assets has also increased because of their worldwide accessibility through the Internet and the automation of systems. Security is concerned with the prevention of such misuse. While no system can be made completely secure, understanding the context in which a system will be deployed and used, the risks and threats of its misuse, and the systematic development of its software are increasingly recognized as critical to its success. The cross-fertilization of systems development techniques from software engineering and security engineering offers opportunities to minimize duplication of research efforts in both areas and, more importantly, to bridge gaps in our knowledge of how to develop secure softwareintensive systems. The aim of this special issue is to publish novel research work that draws upon software engineering to develop secure systems more effectively. Its scope covers the processes, techniques, technology, people, and knowledge bases that have, or need, the capability to contribute to producing more secure software-intensive systems. In response to the call for papers for this special section, we received 41 submissions, regarding software engineering issues addressing the requirements, design, coding, testing, and maintenance of secure software systems. Each paper was reviewed by at least three expert referees. After two rounds of reviewing, we selected six papers which focus on requirements and design of secure software. The first two\u00a0\u2026", "num_citations": "2\n", "authors": ["1448"]}
{"title": "Degradation archaeology: studying software flaws\u2019 evolution\n", "abstract": " Given that software evolution depends on the ability to keep the knowledge about the system and the architectural integrity, research has been focussed on how to ease code comprehension and how to avoid architectural decay. Although these approaches have demonstrated to be useful, the lack of understanding of software degradation inhibits us to tackle it more adequately. Our position is that by studying the evolution of structural problems based on source code evidence (like bad smells, violation of design rules and bad programming styles), theory and practice of software evolution can be enhanced. The study proposes experiments to analyse these structural problems along several versions to detect their relations and evolution and to evaluate how structural changes impact them. The evolution of structural problems is considered in two ways how a structural problem degrades with time, by studying them in isolated compilation units and how related structural problems evolve as a group. The impact of restructuring is also considered by identifying the sets of refactorings applied to successfully remove structural problems in a compilation unit (individually) or in a certain version (as a group). By studying the causes of structural flaws through different sources of information like metrics, design snapshots and the CVS repository, we will obtain a high-level view that will allow us to generate predictive and evaluative models for supporting decision making in software evolution.", "num_citations": "2\n", "authors": ["1448"]}
{"title": "Composing problems: Deriving specifications from inconsistent requirements\n", "abstract": " In this paper we demonstrate an approach to system development based on problem decomposition and subsequent (re) composition of sub-problem specifications. We illustrate the work using Problem Frames, an approach to the decomposition of problems that relates requirements, domain properties, and machine specifications. Having decomposed a problem, one approach to solving it is through a process of composing solutions to sub-problems. In this paper, we show that by formalizing system requirements and domain properties using an Event Calculus, we can both systematically derive machine specifications and solve composition problems. We add a prohibit predicate to the event calculus, that prohibits an event over a given time period. This allows a sub-solution to be formalized in a way that provides for run-time conflict resolution. We develop our earlier work on Composition Frames, an approach to composing inconsistent requirements, by adding systematic support and factoring out domain-dependent details. Throughout the paper we use a simple case study to illustrate and validate our ideas.", "num_citations": "2\n", "authors": ["1448"]}
{"title": "Architecture-driven problem decomposition\n", "abstract": " Jackson\u2019s Problem Frames provide a means of analysing and decomposing problems. They emphasise the world outside of the computer helping the developer to focus on the problem domain instead of drifting into inventing solutions. The intention is to delay consideration of the solution space until a good understanding of the problem is gained. In contrast, early consideration of a solution architecture is common practice in software development. Software is usually developed by including existing components and/or reusing existing frameworks and architectures. This has the advantage of shortening development time though reuse, and increasing the robustness of a system through the application of tried and tested solutions. In this paper, we show how these two views can be reconciled and demonstrate how a choice of architecture can facilitate problem analysis and decomposition within the Problem Frames framework. In particular, we introduce Architectural Frames\u2013combinations of architectural styles and Problem Frames\u2013and illustrate their use in problem decomposition by applying them to a well-known problem from the literature. 1", "num_citations": "2\n", "authors": ["1448"]}
{"title": "Calibrating value estimates of requirements\n", "abstract": " Selecting requirements for implementation of software applications depends on the subjective judgements of the stakeholders who participate in the task. We claim that portfolio analysis provides a market driven, systematic, and more objective approach to supplement the selection of requirements, and also accounts for uncertainty and incomplete knowledge in the real world. We illustrate through two examples, how portfolio-based reasoning facilitates calibrating\u2013that is, aligning\u2013our value estimates of requirements with capital market valuations.", "num_citations": "2\n", "authors": ["1448"]}
{"title": "Validating Inconsistent Re\u00d5uirements Models using Graph-based Abduction\n", "abstract": " Multiple viewpoints are often used in re\u00d5uirements engineering to facilitate traceability to stakeholders to structure the re\u00d5uirements process and to provide richer modeling by incorporating multiple conflicting descriptions. Toleration of inconsistency is a key advantage. However inconsistency introduces considerable extra complexity when reasoning about re\u00d5uirements. This complexity may limit our ability to maintain a lazy approach to consistency management when we want to validate re\u00d5uirements models. In this paper we describe a series of experiments with graph-based abduction for multiple world reasoning over inconsistent re\u00d5uirements models. Our abductive algorithm HT4 sorts an inconsistent model into a number of consistent worlds that support answers to specific \u00d5ueries about the model. This approach avoids the trivialization that occurs in classical deductive inference in the presence of inconsistency. Experiments with this approach reveal that surprisingly few worlds are generated. This result is robust over a range of different models different amounts of data available from the domain and different modeling primitives for representing time. To explore the implications of this result we developed a second algorithm HT0 that extracts a single world at random from an inconsistent model. Experimentally HT0 runs fast even for very large models and supports most of the \u00d5ueries addressed by HT4. The paper discusses possible reasons for this finding and the implications it has for software engineering in general. We conclude that it is not difficult to support reasoning in the presence of inconsistency even in large models.", "num_citations": "2\n", "authors": ["1448"]}
{"title": "Use of a software component library in student projects\n", "abstract": " Use of a Software Component Library in Student Projects - Infoscience English Fran\u00e7ais login Home > Use of a Software Component Library in Student Projects Infoscience Information Usage statistics Files Use of a Software Component Library in Student Projects Strohmeier, Alfred ; Finkelstein, A. ; Nuseibeh, B. Published in: ACM/IEEE International Workshop on Software Education, Sorrento (Italie), 1994, 319-326 Year: 1994 Note: May 21 1994 Laboratories: LGL Record appears in: Scientific production and competences > Archives > I&C - School of Computer and Communication Sciences > LGL - Software Engineering Laboratory Conference Papers Work produced at EPFL Published Export as: BibTeX | MARC | MARCXML | DC | EndNote | NLM | RefWorks | RIS View as: MARC | MARCXML | DC Add to your basket: Back to search Record created 2005-09-20, last modified 2020-07-30 Rate this document: 1 2 3 4 \u2026", "num_citations": "2\n", "authors": ["1448"]}
{"title": "Directions in software process modeling and technology\n", "abstract": " XX Preface documentation; we can enact (execute, animate) these processes; we can use these enactable models to control the invocation of simple tools; we can use a process model in conjunction with a structured repository of software development objects. These are substantial accomplishments, and the extent to which we have made progress from the previous debates should not be underestimated. We now have some, albeit crude, proof-of-concept and we are able to establish the potential of software process modelling and associated technologies. This new found\" critical faculty\" has enabled us to reject certain clearly unpromising lines of research: the megalomaniac, do-it-all environment; the rigid prescriptive model of the development process; the\" yet another\u201d(a new lease of life for a dead specification language) software process modelling scheme. We have created a coherent research community, internationally and within Europe. More importantly, we are able to identify the key research problems which prevent us from realising the potential of software process modelling and associated technologies. These problems are raised where appropriate in the contributions and form the basis for further joint work between the research groups in the Promoter Working Group established under the aegis of, and with funding from, the Esprit III programme in Basic Research. This work will concentrate on: the capture and construction of process models; the support for cooperation and team work within software process model based environments; and, architectural support for such environments.The critical point is reflected more generally in a\u00a0\u2026", "num_citations": "2\n", "authors": ["1448"]}
{"title": "Method integration and support for distributed software development: An overview\n", "abstract": " Our main objective is to develop an integrated methodology and associated support tools for the development and management of distributed software systems. Our use of the term \u201cdistributed software development\u201d is deliberately ambiguous as it is intended to cover both the development of distributed software and distributed development of software by teams of personnel. This paper overviews our work on methods such as the Constructive Design Approach and integration frameworks such as ViewPoints, but, in the interests of brevity, makes no attempt to compare it with current related work.", "num_citations": "2\n", "authors": ["1448"]}
{"title": "Efficient Predictive Monitoring of Linear Time-Invariant Systems Under Stealthy Attacks\n", "abstract": " Attacks on Industrial Control Systems (ICS) can lead to significant physical damage. While offline safety and security assessments can provide insight into vulnerable system components, they may not account for stealthy attacks designed to evade anomaly detectors during long operational transients. In this paper, we propose a predictive online monitoring approach to check the safety of the system under potential stealthy attacks. Specifically, we adapt previous results in reachability analysis for attack impact assessment to provide an efficient algorithm for online safety monitoring for Linear Time-Invariant (LTI) systems. The proposed approach relies on an offline computation of symbolic reachable sets in terms of the estimated physical state of the system. These sets are then instantiated online, and safety checks are performed by leveraging ideas from ellipsoidal calculus. We illustrate and evaluate our approach using the Tennessee-Eastman process. We also compare our approach with the baseline monitoring approaches proposed in previous work and assess its efficiency and scalability. Our evaluation results demonstrate that our approach can predict in a timely manner if a false data injection attack will be able to cause damage, while remaining undetected. Thus, our approach can be used to provide operators with real-time early warnings about stealthy attacks.", "num_citations": "1\n", "authors": ["1448"]}
{"title": "Loneliness in older people and COVID-19: Applying the social identity approach to digital intervention design\n", "abstract": " The COVID-19 pandemic is increasing older people's existing challenges in engaging with their physical and social worlds, and is thereby likely to worsen their loneliness. Digital technology has been offered as a potential aid for social connectedness during social distancing/isolation. However, many popular digital communication tools have not been designed to specifically address the needs of older adults impacted by social isolation. We propose that the social identity approach to health and the Social Identity Model of Identity Change (SIMIC) could be a foundation for digital interventions to address loneliness. While SIMIC applies to maintaining wellbeing during life transitions, it has not previously been rigorously applied to digital interventions. There are known challenges to integrating psychological theory to the design of digital technology, such as efficacy, user-autonomy, and engagement. The interdisciplinary field of Human Computer Interaction has a history of drawing on models originating from psychology to improve the design of digital technology and to design technologies in an appropriate manner. Drawing on key lessons from this literature, we consolidate design guidelines that could assist in applying SIMIC to digital interventions for loneliness in older people affected by the pandemic.", "num_citations": "1\n", "authors": ["1448"]}
{"title": "Up Close & Personal: Exploring User-preferred Image Schemas for Intuitive Privacy Awareness and Control\n", "abstract": " Effective end-user privacy management in everyday ubiquitous computing environments requires giving users complex, contextual information about potential privacy breaches and enabling management of these breaches in a timely, engaging and intuitive manner. In this paper, we propose using empirically grounded image schema-based metaphors to help design these interactions. Results from our exploratory user study (N= 22) demonstrate end users\u2019 preferences for changes in physical attributes and spatial properties of objects for privacy awareness. For privacy control, end users prefer to exert force and create spatial movement. The study also explores user preferences for wearable vs. ambient form-factors for managing privacy and concludes that a hybrid solution would work for more users across more contexts. We thus provide a combination of form factor preferences, and a focused set of image\u00a0\u2026", "num_citations": "1\n", "authors": ["1448"]}
{"title": "Engineering Adaptive Software Systems: Communications of NII Shonan Meetings\n", "abstract": " The first Shonan Meeting on Engineering Adaptive Systems (EASy)[1], which was held in 2012, generated heated discussions on the problems and challenges about self-managing systems. Participants from multiple disciplinaries reached the consent that EASy has by no means an easy solution in software engineering alone, not to mention many other challenges in general system engineering. The organisers of the following Shonan meetings [2, 3] decided to focus on the problems and solutions that can help engineer adaptive software, hence a change of the focus to Engineering Adaptive Software Systems (EASSy). The technical reports above have gathered from abstracts of all individual participants; however, there has not yet been a full report on the crux of interesting viewpoints, which could collaboratively pave the way to solve some aspects of the long-standing research problems.This book is a collection\u00a0\u2026", "num_citations": "1\n", "authors": ["1448"]}
{"title": "Use of organisational topologies for forensic investigations\n", "abstract": " In today's highly regulated business environment, it is becoming increasingly important that organisations implement forensic-ready systems and architectures to aid the investigation of security incidents and data breaches. Previously, different solutions have been proposed for implementing forensic readiness within organisations. One of these solutions is that organisations implement an organisational structure that takes into consideration digital forensics by establishing roles and responsibilities to assist with investigations. However, no previous research has defined how this can actually be accomplished within an organisation. In this paper, we put forth the idea of using the topology of an organisation's structure to define the roles and responsibilities to assist with handling a forensic investigation. In the past, the role of topology has been examined from various perspectives, including software engineering. We\u00a0\u2026", "num_citations": "1\n", "authors": ["1448"]}
{"title": "Learning to share: Using probabilistic models for adaptive sharing in online social networks\n", "abstract": " Online social networks allow users to define groups of \u201cfriends\u201d as reusable shortcuts for sharing information with a number of social contacts. The static nature of these groups can lead to privacy breaches that are hard to detect; for example, when a member of the group begins to breach the informal contract of privacy implicit in the social connection. We propose a learning to share approach that models user\u2019s interactions with each group member as a parametric Markov chain whose transition probabilities are learnt at runtime. Our approach enables adaptive refinement of the groups with whom a user shares information. To this end, continual Markov chain verification is used to establish the privacy risk and social benefit of sharing information with each group member, to dynamically discover risky friendships, and to guide the user on whether or not to share sensitive information with specific members. We evaluate our approach using a simulated Facebook workflow and scenarios comprising group members exhibiting a variety of non-privacy preserving behavioural patterns, in addition to a privacycompliant pattern. The experimental results demonstrate the efficacy of our approach.", "num_citations": "1\n", "authors": ["1448"]}
{"title": "Towards explaining rebuttals in security arguments\n", "abstract": " The satisfaction of software security requirements can be argued using supporting facts and domain assumptions. Sometimes, these facts or assumptions may be questioned, as more knowledge about vulnerabilities becomes available. This results in rebuttals that can be derived from the new information. In this paper, we outline an extension of our OpenArgue tool with an explanation facility that makes a rebuttal more transparent by showing, step by step, why the original security argument does not hold. We achieve this by using the output of the Alligator theorem prover, which constructs explicit and checkable proof objects. We illustrate the feasibility of this approach by applying it to an existing case study of a PIN entry device which involves a security argument that has been rebutted. The output of the prover enables us to unpack the logical reasoning behind the rebuttal at a much greater level of detail. This promises to be useful for argument explanation.", "num_citations": "1\n", "authors": ["1448"]}
{"title": "Enriching traceability with context for adaptive information security in the cloud\n", "abstract": " Cloud applications enjoy a diverse community of users to store and process a variety of data in different conditions in their execution environment. We refer to the attributes that determine these conditions as context. Therefore these applications have a variety of security requirements, the satisfaction of which depends on the application adapting on the users\u2019 context. We call such adaptation capability Adaptive Information Security. The paper argues that one of the key prerequisites for adaptive information security in the cloud is the use of traceability as a means to reasoning the relationship between security requirements and the policies that satisfy those requirements. However, current approaches to traceability do not provide support for taking into account contextual attributes. This makes it challenging to reason about satisfaction of the security requirement at runtime. We propose an approach to traceability that addresses this challenge by making context explicit. Our approach uses entailment relationships to capture and enrich traceability links with context. We use these links to diagnose the violation of security requirements. We applied our approach to an open-source cloud application (ownCloud) which we re-engineered for adaptive access control.", "num_citations": "1\n", "authors": ["1448"]}
{"title": "Maintaining security requirements of software systems using evolving crosscutting dependencies\n", "abstract": " Security requirements are concerned with protecting assets of a system from harm. Implemented as code aspects to weave protection mechanisms into the system, security requirements need to be validated when changes are made to the programs during system evolution. However, it was not clear for developers whether existing validation procedures such as test cases are sufficient for security and when the implemented aspects need to adapt. In this chapter, we propose an approach for detecting any change to the satisfaction of security requirements in three steps: (1) identify the asset variables in the systems that are only accessed by a join-point method; (2) trace these asset variables to identify both control and data dependencies between the non-aspect and aspect functions; and (3) update the test cases ac-cording to implementation of these dependencies to strengthen the protection when a change happens. These steps are illustrated by a case study of a meeting scheduling system where security is a critical concern.", "num_citations": "1\n", "authors": ["1448"]}
{"title": "Engineering Adaptive Privacy: A requirementsdriven approach for mitigating mobile privacy threats\n", "abstract": " Mobile devices are an increasingly common part of everyday life. These devices gather and manipulate personal information from and about their users, raising substantial privacy concerns. Frequent changes in the context of use of such devices can blur the boundary between users\u2019 public and personal spaces, adding further uncertainty to these concerns. In particular, changing privacy threats can make it difficult for users to adapt their mobile applications to continue to satisfy their privacy requirements, and some degree of automated self-adaptation is essential. There has been little engineering work on studying the impact of a changing context on the design of privacy critical systems. In this paper, we propose a novel approach for software engineering of adaptive privacy in mobile applications. We view privacy threats as the inappropriate disclosure of personally identifiable information. Our approach uses privacy policies, and associated domain and software behavioural models, to logically reason over the contexts that threaten privacy. We generate possible mitigation actions, such as ignoring, preventing, reacting, and terminating interactions that threaten privacy. We implement and evaluate our approach in a prototype tool called Caprice. We demonstrate that our approach is computationally feasible, and enables designers to identify plausible privacy threats and to select effective mitigation actions.", "num_citations": "1\n", "authors": ["1448"]}
{"title": "Thrashing, tolerating and compromising in software development\n", "abstract": " Software engineering research into error commonly examines how developers pass judgement: to isolate faults, establish their causes and remove them. By contrast this research examines how developers experience and learn from things that go wrong. This paper presents an analysis of retrospective accounts of software development gathered from a single organisation. The report includes  ndings of how work is conducted in this organisation, and three themes that have emerged in analysis are discussed: thrashing, tolerating and compromising. Finally, limitations and implications for future research are given.", "num_citations": "1\n", "authors": ["1448"]}
{"title": "And in Conclusion\n", "abstract": " AS 2010 draws to an end, I reflect with some relief that my first year as Editor-in-Chief of IEEE Transactions on Software Engineering (TSE) has passed without any adverse consequences. I am also aware of opportunities for further development of the journal in ways that continue to attract the very best software engineering research and that present this research in ways that are accessible and useful to readers. I thank all of you who took the time to write to me during the year with suggestions, comments, and questions. You may recall that in a previous issue I wrote about the need to recognize authors of high quality papers, and to recognize colleagues who have produced high quality reviews. To this end, in 2011, I would like to introduce a TSE \u201cBest Research Paper\u201d award (selected from papers published in TSE in 2010) and a \u201cReviewer of the Year\u201d award (for papers reviewed\u2014but not necessarily published\u00a0\u2026", "num_citations": "1\n", "authors": ["1448"]}
{"title": "Evolving critical systems\n", "abstract": " Guest Editors\u2019 Introduction: Evolving Critical Systems by Lorcan Coyle, Mike Hinchey, Bashar Nuseibeh, and Jos\u00e9 Luiz Fiadeiro", "num_citations": "1\n", "authors": ["1448"]}
{"title": "Verifying implementations of security protocols in c\n", "abstract": " Recent years have seen great progress both in static software analysis and in automatic verification of cryptographic protocols. Unfortunately there has been very little overlap between the two: typical software analyses are designed for simpler properties than cryptographic security and most cryptographic verification tools work on high-level formal models of protocols and thus cannot be applied directly to software, especially not to low-level languages like C. The goal of my project is to bridge this gap by creating a tool that would analyse existing implementations of security protocols in C for cryptographic security. Static software analysis is concerned with proving program correctness or finding bugs in programs without actually running them. It is developing rapidly and has been producing rather impressive results. For instance, the static checker Calysto [Babic and Hu, 2008] is fully automatically finding real bugs in programs with hundreds of thousands of lines of code with very low (below 23%) false error rate. Software firms like Microsoft have integrated static analysis tools like SLAM [Ball et al., 2004] or Prefix [Bush et al., 2000] into their production cycle. However, despite this rapid growth there have been very few attempts to apply static analysis to verification of cryptographic security. In section 2.3 I shall describe some of the difficulties that are responsible for this. There have been numerous projects specifically aiming at verifying security properties, but most work with high-level representations of the protocols. An important example are the tools ProVerif [Blanchet, 2009] and CryptoVerif [Blanchet, 2008] that accept \u03c0-calculus representations\u00a0\u2026", "num_citations": "1\n", "authors": ["1448"]}
{"title": "A framework for developing feature-rich software systems\n", "abstract": " In response to changing requirements and other environmental influences, software systems are increasingly developed incrementally. Successful implementation of new features in existing software is often difficult, whilst many software systems simply 'break' when features are introduced. Size and complexity of modern software, poor software design, and lack of appropriate tools are some of the factors that often confound the issue. In this paper, we report on a successful industrial experience of evolving a feature-rich program analysis tool for dependable software systems. The experience highlights the need for a development framework to maintain rich traceability between development artifacts, and to satisfy certain conditions of artifacts during and after the implementation of a new feature.", "num_citations": "1\n", "authors": ["1448"]}
{"title": "Tool support to derive specifications for conflict-free composition\n", "abstract": " Finding specification of pervasive systems is difficult because it requires making certain environmental assumptions explicit at design-time, and describing the software in a way that facilitates runtime composition. This paper describes how a systematic refinement of specifications from descriptions of the system\u2019s environment and requirements can be automated. Our notion of requirements allows individual features in the system to be inconsistent with each other. Resolution of conflicts at design-time is often over-restrictive because it uses the strongest possible conditions for conjunctions and rules out many possible interactions between features. In order to support runtime resolution, our tool examines specifications for potential conflicts and augments them with information to enable detection at runtime. We use a form of temporal logic, the Event Calculus, as our formalism, and characterize the refinement of requirements as a kind of abductive planning. This allows us to use an existing Event Calculus planning tool, implemented in Prolog, as a basis to develop a reasoning tool for obtaining specifications from potentially inconsistent requirements. We validate our tool by applying it to find specifications of smart home software.", "num_citations": "1\n", "authors": ["1448"]}
{"title": "Placing computer security at the heart of learning\n", "abstract": " In this paper we present the approach adopted at the UK\u2019s Open University for teaching computer security to large numbers of students at a distance through supported open learning. We discuss how the production of learning materials at the university has had to change to reflect the ever-increasing rate of technological, legislative and social change within the computing discipline, and how the university has had to rethink the role of the academic in the course development process. We argue that computer security is best taught starting at the earliest level of undergraduate teaching and continuing through in-depth postgraduate study. We discuss our approach which combines the traditional technical aspects of security with discussions on the professional and ethical issues surrounding security and privacy. This approach presents computer security and privacy in the light of relevant legislative and regulatory regimes, thus the students have a firm grounding in the relevant national and international laws. We discuss the importance of international standards for information security risk assessment and management and as well as the relevance of forensic computing to a computer security curriculum. We conclude with an examination of our course development methodology and argue for a practitioner-led approach to teaching.", "num_citations": "1\n", "authors": ["1448"]}
{"title": "Gathering requirements for a grid-based automatic marking system\n", "abstract": " This paper reports on our experiences using a Creative Requirements [1] workshop approach to elicit requirements for a Grid-based automatic marking system. The research was conducted for ELeGI, an EU funded project whose goal is to provide a European Learning Grid infrastructure to promote a learning paradigm shift from a teacher-centred approach to a learner-centred approach. The automatic marking system uses Latent Semantic Analysis (LSA) to assess the meaning of essays written by computer science students. We foresee the marking system to be a service offered by the Learning Grid. The Creative Requirements Workshop used eight creativity triggers and testimony from an expert witness to elicit creative requirements from the participants. The participants in the workshop produced over 200 requirements in about two hours.", "num_citations": "1\n", "authors": ["1448"]}
{"title": "Introduction to research papers\n", "abstract": " Why is it so hard, even for professional writers, to prevent reader problems from occurring in documents? In this paper, we focus on one crucial aspect of the anticipation process: the assessment of problem detections. We report on an exploratory study in which experts had to judge and motivate the likelihood and severity of a set of reader problems. Based on this study, we present six cognitive shortcuts we distinguished that may bother experts in their attempts to focus on readers.", "num_citations": "1\n", "authors": ["1448"]}
{"title": "Going on-line on a shoestring: An experiment in concurrent development of requirements and architecture\n", "abstract": " A number of on-line applications were built for a small university using a micro-sized development team. Four ideas were tested during the project: the Twin Peaks development model, using fully functional prototypes in the requirements elicitation process, some core practices of Extreme Programming, and the use of open-source software in a production environment. Certain project management techniques and their application to a micro-sized development effort were also explored. These ideas and techniques proved effective in developing many significant Internet and networked applications in a short time and at very low cost.", "num_citations": "1\n", "authors": ["1448"]}