{"title": "Debugging C++ template metaprograms\n", "abstract": " Template metaprogramming is an emerging new direction in C++ programming for executing algorithms in compilation time. Despite all of its already proven benefits and numerous successful applications, it is yet to be accepted in industrial projects. One reason is the lack of professional software tools supporting the development of template metaprograms. A strong analogue exists between traditional runtime programs and compile-time metaprograms. This connection presents the possibility for creating development tools similar to those already used when writing runtime programs. This paper introduces Templight, a debugging framework that reveals the steps executed by the compiler during the compilation of C++ programs with templates. Templight's features include following the instantiation chain, setting breakpoints, and inspecting metaprogram information. This framework aims to take a step forward to help\u00a0\u2026", "num_citations": "49\n", "authors": ["1220"]}
{"title": "Towards a general template introspection library\n", "abstract": " To ensure the correctness of template based constructions in C++, constraints on template parameters are especially useful. Unlike other languages (Ada, Eiffel, etc.), C++ does not directly support checking requirements on template parameters (i.e., concept checking). However, many articles introduce ad hoc solutions based on special language features. In this paper we propose a structure for a general introspection library which supports easy expression and combination of basic orthogonal requirements, providing the possibility to avoid reimplementation of simple checks for every similar concept. Based on these building blocks, it is possible to express highly complex constraints on template parameters, contrary to languages having builtin support for a limited set of constraints only. Our library enables a checking method that takes the advantages of previous solutions, such as REQUIRE-like macros\u00a0\u2026", "num_citations": "43\n", "authors": ["1220"]}
{"title": "Meta< fun>-towards a functional-style interface for C++ template metaprograms\n", "abstract": " Template metaprogramming is an emerging new direction in C++ programming for executing algorithms in compilation time. Despite that template metaprogramming has a strong relationship with functional programming, existing template metaprogram libraries do not follow the requirements of the functional paradigm. In this paper we discuss the possibility to enhance the syntactical expressivity of template metaprograms using an embedded functional language. Clean\u2013a general-purpose purely functional lazy programming language was chosen as embedded language. The graph-rewriting system of Clean has been implemented as a compile-time template metaprogram library using standard C++ language features. Lazy evaluation of infinite data structures is implemented to demonstrate the feasibility of the approach.", "num_citations": "30\n", "authors": ["1220"]}
{"title": "Domain-specific language integration with compile-time parser generator library\n", "abstract": " Smooth integration of domain-specific languages into a general purpose host language requires absorbing of domain code written in arbitrary syntax. The integration should cause minimal syntactical and semantic overhead and introduce minimal dependency on external tools. In this paper we discuss a DSL integration technique for the C++ programming language. The solution is based on compile-time parsing of the DSL code. The parser generator is a C++ template metaprogram reimplementation of a runtime Haskell parser generator library. The full parsing phase is executed when the host program is compiled. The library uses only standard C++ language features, thus our solution is highly portable. As a demonstration of the power of this approach, we present a highly efficient and type-safe version of printf and the way it can be constructed using our library. Despite the well known syntactical difficulties of\u00a0\u2026", "num_citations": "27\n", "authors": ["1220"]}
{"title": "Functional programming with C++ template metaprograms\n", "abstract": " Template metaprogramming is an emerging new direction of generative programming. With the clever definitions of templates we can force the C++ compiler to execute algorithms at compilation time. Among the application areas of template metaprograms are the expression templates, static interface checking, code optimization with adaption, language embedding and active libraries. However, as template metaprogramming was not an original design goal, the C++ language is not capable of elegant expression of metaprograms. The complicated syntax leads to the creation of code that is hard to write, understand and maintain. Although template metaprogramming has a strong relationship with functional programming, this is not reflected in the language syntax and existing libraries. In this paper we give a short and incomplete introduction to C++ templates and the basics of template metaprogramming. We\u00a0\u2026", "num_citations": "27\n", "authors": ["1220"]}
{"title": "Measuring the complexity of aspect-oriented programs with multiparadigm metric\n", "abstract": " Aspect-oriented programming (AOP) is a promising new software development technique claimed to improve code modularization and therefore reduce complexity of object-oriented programs. However, exact quantitative inspections on the problem details are still under way. In this paper we describe a multiparadigm software metric and its extension to AspectJ. We use the metric to compute structural complexity of all the object-oriented, aspect-related and procedural components of AOP code. We tested our metric on two functionally equal implementations of GoF design patterns made in aspect-oriented way and in pure object-oriented style and compared the results.", "num_citations": "27\n", "authors": ["1220"]}
{"title": "Towards soundness examination of the C++ Standard Template Library\n", "abstract": " The Standard Template Library (STL) is an essential part of professional C++ programs. STL is a type-safe template library which is based on the generic programming paradigm and helps to avoid some possible dangerous C++ constructions. With its usage, increases the efficiency, safety and quality of the code. However, the C++ standard gives the definition of STL by informal description that can lead to ambiguous explanations. In this paper we create a formal specification of STL. With these instruments we prove the soundness of STL implementations, libraries over the STL and programs that use STL. Our solution is based on the Hoare-method, that we extend to describe the claims of the generic programming paradigm.", "num_citations": "23\n", "authors": ["1220"]}
{"title": "Cross-language program slicing in the .NET framework\n", "abstract": " Dynamic program slicing methods are very attractive for debugging because many statements can be ignored in the process of localizing a bug. Although language interoperability is a key concept in modern development platforms, current slicing techniques are still restricted to a single language. In this paper a cross-language dynamic program slicing technique is introduced for the .NET environment. The method is utilizing the CLR Debugging Services API, hence it can be applied to large multi-language applications.", "num_citations": "21\n", "authors": ["1220"]}
{"title": "The structured complexity of object-oriented programs\n", "abstract": " There are several methods measuring the complexity of object-oriented programs. Most of them are based on some special object-oriented feature: number of methods/classes, cohesion of classes, inheritance, etc. In practice, however, object-oriented programs are constructed with the help of the same control structures as traditional ones. Moreover, recent ideas of multiparadigm programming (i.e., emerging use of generic programming and aspect-oriented programming) has the effect that in modern programs\u2014and even in class libraries\u2014object-orientation is only one (however major) construction tool among others. An adequate measure therefore should not be based on special features of one paradigm, but on basic language elements and construction rules which could be applied to many different paradigms.In our model discussed here, the complexity of a program is the sum of three components: the\u00a0\u2026", "num_citations": "21\n", "authors": ["1220"]}
{"title": "Codecompass: an open software comprehension framework for industrial usage\n", "abstract": " CodeCompass is an open source LLVM/Clang-based tool developed by Ericsson Ltd. and E\u00f6tv\u00f6s Lor\u00e1nd University, Budapest to help the understanding of large legacy software systems. Based on the LLVM/Clang compiler infrastructure, CodeCompass gives exact information on complex C/C++ language elements like overloading, inheritance, the usage of variables and types, possible uses of function pointers and virtual functions-features that various existing tools support only partially. Steensgaard's and Andersen's pointer analysis algorithms are used to compute and visualize the use of pointers/references. The wide range of interactive visualizations extends further than the usual class and function call diagrams; architectural, component and interface diagrams are a few of the implemented graphs. To make comprehension more extensive, CodeCompass also utilizes build information to explore the system\u00a0\u2026", "num_citations": "17\n", "authors": ["1220"]}
{"title": "Extension of iterator traits in the C++ Standard Template Library\n", "abstract": " The C++ Standard Template Library is the flagship example for libraries based on the generic programming paradigm. The usage of this library is intended to minimize classical C/C++ error, but does not warrant bug-free programs. Furthermore, many new kinds of errors may arise from the inaccurate use of the generic programming paradigm, like dereferencing invalid iterators or misunderstanding remove-like algorithms. In this paper we present typical scenarios, that can cause runtime problems. We emit warnings while these constructs are used without any modification in the compiler. We argue for an extension of the STL's iterator traits in order to emit these warnings. We also present a general approach to emit \u201ccustomized\u201d warnings. We support the so-called believe-me marks to disable warnings.", "num_citations": "16\n", "authors": ["1220"]}
{"title": "On multiparadigm software complexity metrics\n", "abstract": " Structural complexity metrics play important role in modern software engineering. Based on software metrics we can identify critical parts of software, give recommendations, and define coding conventions for the development of sound and manageable code. With the emerging of the object-oriented paradigm, research efforts focused on metrics based on special object-oriented features. However, in modern software construction a multiparadigm design is frequently used. Since metrics might report false results when applied to different paradigms than the one they were designed for, there is an urgent need for paradigm-neutral metrics. In this article a rigorous definition is given for a multiparadigm metric. We discuss the metric on procedural and object-oriented paradigms, and evaluate it in more details applied on aspect-oriented programming.", "num_citations": "15\n", "authors": ["1220"]}
{"title": "C++ metastring library and its applications\n", "abstract": " C++ template metaprogramming is an emerging direction of generative programming: with proper template definitions we can enforce the C++ compiler to execute algorithms at compilation time. Template metaprograms have become essential part of today\u2019s C++ programs of industrial size; they provide code adoptions, various optimizations, DSL embedding, etc. Besides the compilation time algorithms, template metaprogram data-structures are particularly important. From simple typelists to more advanced STL-like data types there are a variety of such constructs. Interesting enough, until recently string, as one of the most widely used data type of programming, has not been supported. Although, boost::mpl::string is an advance in this area, it still lacks the most fundamental string operations. In this paper, we analysed the possibilities of handling string objects at compilation time with a metastring library. We\u00a0\u2026", "num_citations": "14\n", "authors": ["1220"]}
{"title": "Implementation of a finite state machine with active libraries in C++\n", "abstract": " Active libraries are code parts playing an active role during compilation. In C++ active libraries are implemented with the help of template metaprogramming (TMP) techniques. In this paper we present an active library designed as an implementation tool for Finite state machines. With the help of various TMP constructs, our active library carries out compile-time actions like optimizations via state-minimalization, and more sophisticated error-detection steps. Our library provides extended functionality to the Boost::Statechart library, the popular FSM implementation of the Boost library. We describe the implementation and analyze the efficiency.", "num_citations": "14\n", "authors": ["1220"]}
{"title": "A new concept of effective regression test generation in a C++ specific environment\n", "abstract": " During regression testing test cases from an existing test suite are run against a modified version of a program in order to assure that the underlying modifications do not cause any side effects that would demolish the integrity and consistency of the system. Since the ultimate goal of a regression test set is to effectively test all modifications and reveal errors in the earliest possible stage, the maintenance of a relevant test set containing effective test cases is of utmost importance. In this paper we present an efficient, C++ specific framework to automatically manage the regression test suite. Our two main contributions are a new interpretation of reliable test cases and a dynamic forward impact analyzer method that eases the transformation of existing tests to meet the definition of reliability. Using this approach we complement the test set with test cases that pass through a modification and have an impact on at least one output. Our approach is designed to be applicable to large-scale applications.", "num_citations": "13\n", "authors": ["1220"]}
{"title": "Implementing monads for C++ template metaprograms\n", "abstract": " C++\u00a0template metaprogramming is used in various application areas, such as expression templates, static interface checking, active libraries, etc. Its recognized similarities to pure functional programming languages\u2013like Haskell\u2013make the adoption of advanced functional techniques possible. Such a technique is using monads, programming structures representing computations. Using them actions implementing domain logic can be chained together and decorated with custom code. C++\u00a0template metaprogramming could benefit from adopting monads in situations like advanced error propagation and parser construction. In this paper we present an approach for implementing monads in C++\u00a0template metaprograms. Based on this approach we have built a monadic framework for C++\u00a0template metaprogramming. As real world examples we present a generic error propagation solution for C++\u00a0template\u00a0\u2026", "num_citations": "12\n", "authors": ["1220"]}
{"title": "Expressing C++ template metaprograms as lambda expressions\n", "abstract": " Expressing C++ Template Metaprograms as Lambda expressions Page 1 Outline Template metaprogramming Lambda expressions Implementation details Evaluation Conclusion and future works Expressing C++ Template Metaprograms as Lambda expressions \u00c1bel Sinkovics, Zolt\u00e1n Porkol\u00e1b June 3, 2009 \u00c1bel Sinkovics, Zolt\u00e1n Porkol\u00e1b Expressing C++ Template Metaprograms as Lambda expressions Page 2 Outline Template metaprogramming Lambda expressions Implementation details Evaluation Conclusion and future works Template metaprogramming Lambda expressions Implementation details Evaluation Conclusion and future works \u00c1bel Sinkovics, Zolt\u00e1n Porkol\u00e1b Expressing C++ Template Metaprograms as Lambda expressions Page 3 Outline Template metaprogramming Lambda expressions Implementation details Evaluation Conclusion and future works Template metaprogramming \u25ba Motivation \u2026", "num_citations": "10\n", "authors": ["1220"]}
{"title": "Runtime access control in C# 3.0 using extension methods\n", "abstract": " Encapsulation is one of the most important features of objectoriented programming. Reducing the interface where software components can communicate with each other increases software quality, security and decreases development cost. Compile time or runtime visibility and access control checking that support encapsulation is the key part of modern languages and runtime environments. They enforce responsibility separation, implementation and security policies. Most modern programming languages like C++, C# and Java do not have sophisticated access control mechanisms. They employ a subset or combination of public, private, protected, internal and friend access modifiers. However, this is not true for the Eiffel programming language that defines sophisticated selective access control called selective export. In this paper first we describe the existing access control features of C++, C#, Java, Eiffel and other popular programming languages. After that we show an example where the current access control features of C# (and most object-oriented languages) are insufficient. We introduce a method level access control checking mechanism to C# 3.0 using extension methods. Our method is able to enforce Eiffellike selective export in runtime. The implementation does not require the modification of the compiler and the caller, only the callee, and introduces minimal syntactic and performance overhead. It can be a practical solution for modular systems where runtime security is important.", "num_citations": "10\n", "authors": ["1220"]}
{"title": "Domain-specific language integration with c++ template metaprogramming\n", "abstract": " Domain specific language integration has to provide the right balance between the expressive power of the DSL and the implementation and maintenance cost of the applied integration techniques. External solutions may perform poorly as they depend on third party tools which should be implemented, tested and then maintained during the whole lifetime of the project. Ideally a self-contained solution can minimize third-party dependencies. The authors propose the use of C++ template metaprograms to develop a domain specific language integration library based on only the standard C++ language features. The code in the domain specific language is given as part of the C++ source code wrapped into C++ templates. When the C++ source is compiled, the C++ template metaprogram library implementing a full-featured parser infrastructure is executed. As the authors\u2019 approach does not require other tool than a\u00a0\u2026", "num_citations": "9\n", "authors": ["1220"]}
{"title": "Type-preserving heap profiler for C++\n", "abstract": " Memory profilers are essential tools to understand the dynamic behaviour of complex modern programs. They help to reveal memory handling details: the wheres, the whens and the whats of memory allocations. Most heap profilers provide sufficient information about which part of the source code is responsible for the memory allocations by showing us the relevant call stacks. The sequence of allocations inform us about their order. However, in case of some strongly typed programming languages, like C++, the question what has been allocated is not trivial. Reporting the actual allocation size gives minimal or no information about the structure or type of the allocated objects. Though this information can be retrieved from the location and time of allocation, it cannot be easily automated, if at all. Therefore in large software systems programmers do not have an overall picture of which data structures are responsible for\u00a0\u2026", "num_citations": "9\n", "authors": ["1220"]}
{"title": "Automatic classification of semantic user interface services\n", "abstract": " Current user interfaces are ad hoc, application dependent and constantly change while offering the same functionalities in many different ways. This article investigates methods for creating semantic user interfaces, which are much easier to develop, learn, teach and use. The basic idea of semantic user interfaces is to analyze specific application domains (like word processing, file handling or application deployment), organize domain concepts into ontologies, associate user interface presentation attributes (like icons, menu labels and line mode commands) to ontology nodes, and to use the ontology as a central control entity of application development and execution. The ontology is used inside a service oriented semantic user interface framework, whose elements and potential benefits are also explained.", "num_citations": "9\n", "authors": ["1220"]}
{"title": "Semantic user interfaces\n", "abstract": " Semantic User Interfaces (SUIs), are sets of interrelated, static, domain specific documents having layout and content, whose interpretation is defined through semantic decoration. SUIs are declarative in nature. They allow program composition by the user herself at the user interface level. The operation of SUI based applications follow a service oriented approach. SUI elements referenced in user requests are automatically mapped to reusable service provider components, whose contracts are specified in domain ontologies. This assures semantic separation of user interface components from elements of the underlying application system infrastructure, which allows full separation of concerns during system development; real, application independent, reusable components; user editable applications and generic learnability. This article presents the architecture and components of a SUI framework, basic elements\u00a0\u2026", "num_citations": "9\n", "authors": ["1220"]}
{"title": "Towards the modularization of C++ concept maps\n", "abstract": " Concept is a new and powerful language element being introduced in the next C++ standard. With the help of concepts we can define the properties a template requires from its type arguments. If a type does not fulfill the requirements syntactically, but semantically, the connection must be declared with the use of a concept_map. Often the description of the semantic matching results in long codes that need to be modularized. In this paper we present an extension to the concept_map language constructs that enables this transformation. We introduce the well-known public, protected, private class arrangement scheme into concept_maps. We present our preprocessor, that transforms the modularized code into regular code to be compiled by ConceptGCC, the experimental Concept C++ compiler.", "num_citations": "9\n", "authors": ["1220"]}
{"title": "A method for calculating acknowledged project effort using a quality index\n", "abstract": " Zolt\u00e1n Porkol\u00e1b E\u00f6tv\u00f6s Lor\u00e1nd University, Faculty of Informatics P\u00e1zm\u00e1ny P\u00e9ter s\u00e9t\u00e1ny 1/C, H-1117 Budapest, Hungary E-mail: gsd@ elte. hu", "num_citations": "9\n", "authors": ["1220"]}
{"title": "Towards effective runtime trace generation techniques in the .NET framework\n", "abstract": " Effective runtime trace generation is vital for understanding, analyzing, and maintaining large scale applications. In this paper two cross-language trace generation methods are introduced for the .NET platform. The nonintrusive methods are based on the .NET Debugging and Profiling Infrastructure; consequently, neither additional development tools, nor the .NET Framework SDK is required to be installed on the target system. Both methods are applied to a test set of real-size executables and compared by performance and applicability.", "num_citations": "9\n", "authors": ["1220"]}
{"title": "Analysis of Include Dependencies in C++ Source Code.\n", "abstract": " The C++ Standard Template Library (STL) is the flagship example for libraries based on the generic programming paradigm. The usage of this library is intended to minimize classical C/C++ errors, but does not warrant bug-free programs. Furthermore, many new kinds of errors may arise from the inaccurate use of the generic programming paradigm, like dereferencing invalid iterators or misunderstanding remove-like algorithms.Unfortunately, the C++ Standard does not define which standard header includes another standard headers. It is easy to write code that works perfectly on an implementation but fails to compile with another implementation of STL. These unportable codes should be result in compilation error with every STL implementation. However, in this case the compiler does not warn us that this code is erroneous.", "num_citations": "8\n", "authors": ["1220"]}
{"title": "Necessary test cases for decision coverage and modified condition/decision coverage\n", "abstract": " Test coverage refers to the extent to which a given software verification activity satisfies its objectives. Several types of coverage analysis exist to check code correctness. Less strict analysis methods require fewer test cases to satisfy their requirements and consume less resources. Choosing test methods is a compromise between the code correctness and the available resources. However this selection should be based on quantitative consideration. In this paper we concern the Decision Coverage and the more strict Modified Condition/Decision Coverage. We examined several projects written in Ada programming language. Some of them are developed in the industry and the others are open source. We analyzed them in several aspects: Mc-Cabe metric, nesting and maximal argument number in decisions. We discuss how these aspects are affected by difference of the necessary test cases for these testing methods.", "num_citations": "8\n", "authors": ["1220"]}
{"title": "Towards better symbol resolution for C/C++ programs: A cluster-based solution\n", "abstract": " Resolving symbol references is an important part of many application areas from development environments to various static analyser tools, especially when it is used for code comprehension purposes. Different occurrences of the same program elements, like function definitions and their call sites, variable declarations and their usage, or type definitions and their applications should be connected. In case of the C++ programming language, the most current tools use mangled names to correlate symbols, e.g. when implementing actions like \"go to definition\" or \"list all references\". However, for large projects, where multiple binaries are created, symbol resolution based on mangled names can be, and usually is, ambiguous. This leads to inaccurate behaviour even in major development tools. In this paper we explore the reason of this ambiguity, and propose our clustering algorithm based on essential build\u00a0\u2026", "num_citations": "7\n", "authors": ["1220"]}
{"title": "Visualization of C++ template metaprograms\n", "abstract": " Template metaprograms have become an essential part of today's C++ programs: with proper template definitions we can force the C++ compiler to execute algorithms at compilation time. Among the application areas of template metaprograms are the expression templates, static interface checking, code optimization with adaptation, language embedding and active libraries. Despite all of its already proven benefits and numerous successful applications there are surprisingly few tools for creating, supporting, and analyzing C++ template metaprograms. As metaprograms are executed at compilation time they are even harder to understand. In this paper we present a code visualization tool, which is utilizing Tem plight, our previously developed C++ template metaprogram debugger. Using the tool it is possible to visualize the instantiation chain of C++ templates and follow the execution of metaprograms. Various\u00a0\u2026", "num_citations": "7\n", "authors": ["1220"]}
{"title": "C++ template metaprogramming with embedded Haskell\n", "abstract": " Template metaprogramming is an emerging new direction of generative programming: with the clever definitions of templates we can enforce the C++ compiler to execute algorithms at compilation time. Among the application areas of template metaprograms are the expression templates, static interface checking, code optimization with adaption, language embedding and active libraries. However, as this capability of C++ was not a primary design goal, the language is not capable of clean expression of template metaprograms. The complicated syntax leads to the creation of code that is hard to write, understand and maintain. Despite that template metaprogramming has a strong relationship with functional programming paradigm, existing libraries do not follow these requirements. In this paper we discuss the possibility to enhance the syntactical expressiveness of template metaprograms using an embedded functional language. Programmers can write metaprograms in Haskell syntax embedded in native C++ code and a translator tool transfers it to template metaprograms. The Haskell code snippets inter-operate with their C++ environment.", "num_citations": "7\n", "authors": ["1220"]}
{"title": "Analysis of profiling techniques for C++ template metaprograms\n", "abstract": " Template metaprogramming (TMP) is an emerging new direction in C++ programming for executing algorithms in compilation time. Despite all of its already proven benefits, and numerous successful applications, TMP is yet to become an accepted technique in industrial projects. One reason is the lack of professional software tools supporting the development of template metaprograms. On the other hand, a strong analogue between traditional runtime programs and compile-time metaprograms presents the possibility for creating development tools similar to those already used when writing runtime programs. This paper presents two methods for metaprogram profiling. Firstly, Templight, a debugging and profiling framework is introduced. The framework reveals the steps executed by the compiler during the compilation of C++ programs with templates. Thus Templight is capable of adding timestamps to template instantiations, and measuring their times. The second method uses compiler modification acquiring instantiation profiling data from the compiler itself.", "num_citations": "7\n", "authors": ["1220"]}
{"title": "High-level C++ implementation of the read-copy-update pattern\n", "abstract": " Concurrent programming with classical mutex/lock techniques does not scale well when reads are way more frequent than writes. Such situation happens in operating system kernels among other performance critical multithreaded applications. Read copy update (RCU) is a well know technique for solving the problem. RCU guarantees minimal overhead for read operations and allows them to occur concurrently with write operations. RCU is a favourite concurrent pattern in low level, performance critical applications, like the Linux kernel. Currently there is no high-level abstraction for RCU for the C++ programming language. In this paper, we present our C++ RCU class library to support efficient concurrent programming for the read-copy-update pattern. The library has been carefully designed to optimise performance in a heavily multithreaded environment, in the same time providing high-level abstractions, like\u00a0\u2026", "num_citations": "6\n", "authors": ["1220"]}
{"title": "Energy consumption measurement of c/c++ programs using clang tooling\n", "abstract": " The green computing has an important role in today's software technology. Either speaking about small IoT devices or large cloud servers, there is a generic requirement of minimizing energy consumption. For this purpose, we usually first have to identify which parts of the system is responsible for the critical energy peaks. In this paper we suggest a new method to measure the energy consumption based on Low Level Virtual Machine (LLVM)/Clang tooling. The method has been tested on 2 open source systems and the output is visualized via the well-known Kcachegrind tool.", "num_citations": "6\n", "authors": ["1220"]}
{"title": "Towards profiling C++ template metaprograms\n", "abstract": " Template metaprogramming (TMP) is an emerging new direction in C++ programming for executing algorithms in compilation time. Despite all of its already proven benefits, and numerous successful applications, TMP is yet to become an accepted technique in industrial projects. One reason is the lack of professional software tools supporting the development of template metaprograms. On the other hand, a strong analogue between traditional runtime programs and compile-time metaprograms presents the possibility for creating development tools similar to those already used when writing runtime programs. This paper presents two methods for metaprogram profiling. Firstly, Templight, a debugging and profiling framework is introduced. The framework reveals the steps executed by the compiler during the compilation of C++ programs with templates. Thus Templight is capable of adding timestamps to template instantiations, and measuring their times. The second method uses compiler modification acquiring instantiation profiling data from the compiler itself.", "num_citations": "6\n", "authors": ["1220"]}
{"title": "On the correctness of template metaprograms\n", "abstract": " C++ template mateprogramming (TMP) is a recently emerged programming paradigm that assists the creation of efficient code and flexible libraries. On the other hand, TMP is not yet widely used, due to the lack of coding standards and methodologies applicable when writing metaprograms. In this paper we present methods for writing efficient and reliable metaprograms. We define the correctness of metaprograms and the possible types of failures to meet the specification. We describe the methods for creating metaprograms meeting their specifications. One method is checking for expected properties of types and constants (concept checking). Another tool is static assert, a construct capable of halting the compilation of an erroneous program.", "num_citations": "6\n", "authors": ["1220"]}
{"title": "Teaching multiparadigm programming based on object-oriented experiences\n", "abstract": " Multiparadigm programming is an emerging practice in computer technology. Co-existence of object-oriented, generic and functional techniques can better handle variability of projects. The present paper gives an overview of teaching multiparadigm programming approach through typical language concepts, tools in higher education. Students learning multiparadigm-oriented subjects would gain considerable expertise, which is highly needed by the industrial side in large-scale application development.", "num_citations": "6\n", "authors": ["1220"]}
{"title": "Comparison of Object-Oriented and Paradigm Independent Software Complexity Metrics\n", "abstract": " Structural complexity metrics play important role in modern software engineering. Testing, bug-fixing and maintenance covers more and more percentage of the software lifecycle. The cost of software maintenance is mostly depends on the structural complexity of the code. A good complexity measurement tool can trigger critical parts of the software even in development phase, measure the quality of the code, predict the cost of testing efforts and later modifications.With the raise of object-oriented paradigm, research efforts at both the academic world and the IT industry has focused metrics based on special objectoriented features, like number of classes, depth of inheritance or number of children. Several implementations of such metrics are available for the most popular languages (like Java, C++,...) and platforms (like Eclipse). However object-orientation is not the only programming style used in software construction. We still have large number of legacy code written in procedural or even unstructured-way. For these codes, object-oriented metrics are not suitable. Also in modern programming languages (most importantly in C++) multiparadigm design is frequently used. An adequate measure therefore should not be based on special features of one paradigm, but on basic language elements and construction rules applied to different paradigms. In this article, we make both theoretical and empirical comparison between such multiparadigm metrics and well-known object-oriented ones to decide their scope, identify strong and week points, and make suggestions on their practical usage.", "num_citations": "6\n", "authors": ["1220"]}
{"title": "Life without implicit casts: safe type system in C++\n", "abstract": " This paper contains the findings about our ongoing research to make safe type system in C++ to avoid unwanted implicit casts. Our related research revealed vulnerabilities in current mainstream programming languages, and gave recommendations for coding styles and designing a new programming language.", "num_citations": "5\n", "authors": ["1220"]}
{"title": "Rule-based assignment of comments to AST nodes in C++ programs\n", "abstract": " Comments are essential components of programming languages: they preserve the developer's intentions, help the maintainers to understand hidden concepts, and may act as a source of automatic documentation generation. However most of the software maintenance tools (refactorers, slicing and analyser tools) ignore them therefore they lose an important part of information about the software. One of the reasons why tools neglect comments is that there is no single well-defined location in the software's AST where to place them. The relationship between the program's control structure and the comments depend on code conventions and human habits. Our research--part of a project to develop a software maintenance tool--focuses on the code comprehension process of large legacy C++ projects and heavily utilize code comments. We evaluated the commenting behaviour used in large projects and categorized\u00a0\u2026", "num_citations": "5\n", "authors": ["1220"]}
{"title": "The Distributed D\u2010Clean Model Revisited by Templates\n", "abstract": " D\u2010Clean is a functional coordination language for distributed computation. The language was designed for the need of high\u2010level process description and communication coordination of functional programs distributed over a cluster. The pure functional computational nodes required language primitives to control the dataflow in a distributed process\u2010network. Therefore, in order to achieve parallel features, we created an extension for the lazy functional programming language Clean using new language elements.D\u2010Clean is compiled to an intermediate level language called D\u2010Box, which is designed for the description of the computational nodes. Every D\u2010Clean construct generates a D\u2010Box expression. The D\u2010Box expressions hide the low level implementation details and enable direct control over the process\u2010network. The asynchronous communication is based on language\u2010independent middleware services\u00a0\u2026", "num_citations": "5\n", "authors": ["1220"]}
{"title": "Features of C++ template metaprograms\n", "abstract": " Template metaprogramming is an emerging new direction in C++ programming for executing algorithms at compilation time in a functional way. With the assistant of template metaprogramming one can optimize runtime programs, emitting warnings and errors, implementing active libraries, developing domain-specific languages.We present our framework, called Templight, which is able to debug code of C++ template metaprograms, and profile the compilation process. This framework is based on instrumentation, it extends the template code to emit warnings. We extract the trace from the warning messages. From the trace we can generate debugging and profiling data. We have also developed a graphical user interface to make the debugging process easier. In this application programmers can put down breakpoints, use step-in and step-out features, or continue the instantiations, etc.. We have measured the compilation time of some well-known template metaprogramming libraries to find bottlenecks in these codes.", "num_citations": "5\n", "authors": ["1220"]}
{"title": "Towards detailed trace generation using the profiler in the .NET Framework\n", "abstract": " Effective runtime trace generation is vital for understanding, analyzing, and maintaining large-scale applications. In this paper an effective detailed runtime trace generation approach is introduced for the .NET platform. The non-intrusive method is based on the .NET Profiler; consequently, neither additional development tools, nor the .NET Framework SDK is required to be installed on the target system. The method is applied to a test set of real-size executables and compared by performance and applicability to the original program.", "num_citations": "5\n", "authors": ["1220"]}
{"title": "HypereiDoc\u2013An XML Based Framework Supporting Cooperative Text Editions\n", "abstract": " HypereiDoc is an XML based framework supporting distributed, multi-layered, version-controlled processing of epigraphical, papyrological or similar texts in a modern critical edition. Such studies are typically based on independent work of philologists using annotation systems like the Leiden Conventions. Current initiatives like TEI and Epidoc have definitive limitations both in expressional power and the way how individual results can form a cooperative product. The HypereiDoc framework provides XML schema definition for a set of annotation-based layers connected by an extensive reference system, validating and building tools, and an editor on-line visualizing the base text and the annotations. The framework makes scholars able to work on the same text in a cooperative and distributed way. Our framework has been successfully tested by philologists working on the Hypereides palimpsest.", "num_citations": "5\n", "authors": ["1220"]}
{"title": "Lazy Data Types in C++ Template Metaprograms\n", "abstract": " As the implementation of compile-time recursion and conditional statements is possible, TMP is Turing-complete. Accordingly, in theory the expressive power of TMP is equivalent to that of today\u2019s programming languages. On the other hand, TMP is not yet a widely used programming style, so the boundaries of its practical applicability are yet to be determined. TMP has already been successfully applied in a number of important fields: expression templates (optimizing calculations in compile-time [9]), compile-time code adaptation, implementation of active libraries [6], and others.", "num_citations": "5\n", "authors": ["1220"]}
{"title": "Automatic checking of the usage of the C++ move semantics\n", "abstract": " The C++ programming language is a favorable choice when implementing high performance applications, like real-time and embedded programming, large telecommunication systems, financial simulations, as well as a wide range of other speed sensitive programs. While C++ has all the facilities to handle the computer hardware without compromises, the copy based value semantics of assignment is a common source of performance degradation. New language features, like the move semantics were introduced recently to serve an instrument to avoid unnecessary copies. Unfortunately, correct usage of move semantics is not trivial, and unintentional expensive copies of C++ objects-like copying containers instead of using move semantics-may determine the main (worst-case) time characteristics of the programs. In this paper we introduce a new approach of investigating performance bottlenecks for C++ programs, which operates at language source level and targets the move semantics of the C++ programming language. We detect copies occurring in operations marked as move operations, ie intended not containing expensive copy actions. Move operations are marked with generalized attributes-a new language feature introduced to C++ 11 standard. We implemented a tool prototype to detect such copy/move semantic errors in C++ programs. Our prototype is using the open source LLVM/Clang parser infrastructure, therefore highly portable.", "num_citations": "4\n", "authors": ["1220"]}
{"title": "Towards safer programming language constructs\n", "abstract": " Most of the current programming languages inherit their syntax and semantics from technology of the 20th century. Due to the backward compatibility, these properties are still unchanged, however newer technologies require different language constructs and different semantics. Instead of redefining the programming language, the developers enhance the language with new library functions, or they add some\u2013occasionally ambiguous\u2013elements to the syntax. Some languages provide very loose syntax, which is harmful, because it leads to critical errors. In other case the interleaving\u201d normal\u201d code and exception handling code can obfuscate the developer itself and the subsequent developers. This paper highlights several aspects of language elements such as basic and potentially unsafe elements of the syntax, control flow constructs, elements used in const-correctness, type-system, elements of multiparadigm programming\u2013generative and functional\u2013, capabilities of embedding a DSL, parallelism support, and taking account of branch prediction. These aspects determine the usablity, safety and learnability of a language. This paper also gives recommendation for a new and safe experimental programming language.", "num_citations": "4\n", "authors": ["1220"]}
{"title": "Towards more sophisticated access control\n", "abstract": " Encapsulation and information hiding play a crucial role in object-oriented software development. While assisting the creation of abstractions they minimize the dependencies among distinct modules. Modern languages have different approaches to access control, but in statically typed object-oriented languages the simple public-protectedprivate categorization is the most common. Unfortunately, the expressive power of this categorization is not sufficient for fine-grained access control, since services are exported to clients in an anonymous way. In this paper the visibility strategies of modern programming languages are compared first. Scenarios are described where more delicate access control is necessary. Our earlier experiments have proved that a library based solution for selective access would produce unacceptable syntactical overhead on the programmer. Therefore, we propose here a language extension\u00a0\u2026", "num_citations": "4\n", "authors": ["1220"]}
{"title": "COMPILE-TIME FUNCTION CALL INTERCEPTION FOR TESTING IN C/C++.\n", "abstract": " In C/C++, during the test development process we often have to modify the public interface of a class to replace existing dependencies; eg supplementary setter or constructor functions or extra template parameters are added for dependency injection. These solutions may have serious detrimental effects on the code structure and sometimes on the run-time performance as well. We introduce a new technique that makes dependency replacement possible without the modification of the production code, thus it provides an alternative way to add unit tests. Our new compile-time instrumentation technique enables us to intercept function calls and replace them in runtime. Contrary to existing function call interception (FCI) methods, we instrument the call expression instead of the callee, thus we can avoid the modification and recompilation of the function in order to intercept the call. This has a clear advantage in case of system libraries and third party shared libraries, thus it provides an alternative way to automatize tests for legacy software. We created a prototype implementation based on the LLVM compiler infrastructure which is publicly available for testing.", "num_citations": "3\n", "authors": ["1220"]}
{"title": "The codecompass comprehension framework\n", "abstract": " CodeCompass is an open source LLVM/Clang based tool developed by Ericsson Ltd. and the E\u00f6tv\u00f6s Lor\u00e1nd University, Budapest to help understanding large legacy software systems. Based on the LLVM/Clang compiler infrastructure, CodeCompass gives exact information on complex C/C++ language elements like overloading, inheritance, the usage of variables and types, possible uses of function pointers and the virtual functions-features that various existing tools support only partially. Steensgaard's and Andersen's pointer analysis algorithm are used to compute and visualize the use of pointers/references. The wide range of interactive visualizations extends further than the usual class and function call diagrams; architectural, component and interface diagrams are a few of the implemented graphs. To make comprehension more extensive, CodeCompass is not restricted to the source code. It also utilizes build\u00a0\u2026", "num_citations": "3\n", "authors": ["1220"]}
{"title": "Towards a High-Level C++ Abstraction to Utilize the Read-Copy-Update Pattern\n", "abstract": " Concurrent programming with classical mutex/lock techniques does not scale well when reads are way more frequent than writes. Such situation happens in operating system kernels among other performance critical multithreaded applications. Read copy update (RCU) is a well know technique for solving the problem. RCU guarantees minimal overhead for read operations and allows them to occur concurrently with write operations. RCU is a favourite concurrent pattern in low level, performance critical applications, like the Linux kernel. Currently there is no high-level abstraction for RCU for the C++ programming language. In this paper, we present our C++ RCU class library to support efficient concurrent programming for the read-copy-update pattern. The library has been carefully designed to optimise performance in a heavily multithreaded environment, in the same time providing high-level abstractions, like smart pointers and other C++ 11/14/17 features.", "num_citations": "3\n", "authors": ["1220"]}
{"title": "Performance issues with implicit resolution in Scala\n", "abstract": " Scala is an emerging programming language that supports multiple programming paradigms. It has been designed to support high levels of expressiveness and to allow writing concise code. To achieve this, it supports many features, including but not limited to macros, DSLs as well as implicit type conversions and implicit argument lists to functions. Due to the wide range of language features and the advanced static type system, the Scala compiler possesses a non-trivial implementation. We have analyzed the performance characteristics of the compiler and have found that the major part of compilation time is spent on typing syntax trees. This includes implicit resolution, thus we have focused our efforts on investigating this specific language feature. We have analyzed how typical usage patterns that involve implicit resolution affect compilation times. Based on this analysis we have managed to assemble a list of recommendations for programming style and code management that allow programmers to leverage implicits to their full potential, but lead to drastically reduced compilation times.", "num_citations": "3\n", "authors": ["1220"]}
{"title": "Unit testing in C++ with compiler instrumentation and friends\n", "abstract": " In C++, test code is often interwoven with the unit we want to test. During the test development process we often have to modify the public interface of a class to replace existing dependencies; eg a supplementary setter or constructor function is added for dependency injection. In many cases, extra template parameters are used for the same purpose. All existing solutions have serious detrimental effects on the code structure and sometimes on the run-time performance as well. In this paper, we overview existing dependency replacement techniques of C++ and we evaluate their advantages and disadvantages. We introduce our non-intrusive, compiler instrumentation based testing approach that does not have such disadvantages. All non-intrusive testing methods (including our new method) require access to an object\u2019s internal state in order to setup a test. Thus, to complement our new solution, we also present different approaches to conveniently access private members in C++. To evaluate these techniques, we created a proof-of-concept implementation which is publicly available for further testing.", "num_citations": "3\n", "authors": ["1220"]}
{"title": "C++ COMPILE-TIME REFLECTION AND MOCK OBJECTS.\n", "abstract": " Reflection is an important tool for serializing objects, creating mock objects for testing, creating object relational mappings and many other cases. Without standardized C++ compile-time reflection these tasks are repetitive and error-prone. Therefore the ISO C++ started a study group (SG7) to examine the possibilities of compile-time reflection in C++. With compile-time reflection it would be possible to have a generic library for serialization or for object relational mappings. There are several potential notions about how to approach this kind of reflection, like introducing high-level new language elements like static for, or creating library interfaces which are hiding compiler intrinsics for each specific reflection subtask. In this paper an alternative C++ compile-time reflection approach is discussed in favor of finding a generic solution for this task. The approach is based on introducing new library elements. Under the hood\u00a0\u2026", "num_citations": "3\n", "authors": ["1220"]}
{"title": "DSL in C++ template metaprogram\n", "abstract": " Domain specific language integration has to provide the right balance between the expressive power of the DSL and the implementation and maintenance cost of the applied integration techniques. In this paper we discuss a DSL integration technique for the C++ programming language. The solution is based on compile-time parsing of the DSL code using the C++ template metaprogramming library called Metaparse. The parser generator is the C++ template metaprogram reimplementation of a runtime Haskell parser generator library. The full parsing phase is executed when the host program is compiled. The library uses only standard C++ language features, thus our solution is highly portable. As a demonstration of the power of this approach, we present a highly efficient and type-safe version of printf and the way it can be constructed using our library. Despite the well known syntactical difficulties of C\u00a0\u2026", "num_citations": "3\n", "authors": ["1220"]}
{"title": "Towards a software metric for generic programming paradigm\n", "abstract": " Since McCabe\u2019s cyclometric measure, structural complexity have been playing an important role measuring the complexity of programs. Complexity metrics are used to achieve more maintainable code with the least bugs possible.C++ Standard Template Library (STL) is the most popular library based on the generic programming paradigm. This paradigm allows implementation of algorithms and containers in an abstract way to ensure the configurability and collaboration of the abstract components. STL is widely used in industrial softwares because STL\u2019s appropriate application decreases the complexity of the code significantly.", "num_citations": "3\n", "authors": ["1220"]}
{"title": "Runtime Access Control in C#\n", "abstract": " Compile time or runtime visibility and access control checking is the key part of modern languages and runtime environments. They enforce responsibility separation, implementation and security policies. The Eiffel programming language defines sophisticated selective access control, but most modern programming languages like C++, C# and Java do not have this feature only a subset or combination of the following access modifiers: public, private, protected, internal and friend. The .NET Framework enforces some security policies in runtime called Code Access Security but this additional mechanism is capable only to restrict external resource access for programs written in any .NET-language like C#.In this paper we describe the existing access control features of the C# language then show a scenario where a more sophisticated access control is required. We introduce a method level access control checking mechanism to C# which is able to enforce Eiffellike selective export in runtime. Our implementation does not require the modification of the compiler and the caller, only the callee, and introduces minimal syntactic overhead. It can be a practical solution for modular systems where runtime security is important.", "num_citations": "3\n", "authors": ["1220"]}
{"title": "An anomaly of subtype relations at component refinement, and a generative solution in C++\n", "abstract": " An extension to the subtype relationship in C++ Page 1 1 An anomaly of subtype relations at component refinement and a generative solution in C++ Zolt\u00e1n Porkol\u00e1b, Istv\u00e1n Z\u00f3lyomi E\u00f6tv\u00f6s Lor\u00e1nd University, Budapest, Hungary {gsd | scamel}@elte.hu Page 2 2 Example (Harold Ossher) OpEval OpCheck OpDisplay PlusCheck PlusEval Operator Plus PlusDisplay Page 3 3 Possible solutions \u2022 Virtual inheritance \u2022 Intrusive: specified in base classes \u2022 More concerns implies exponential number of virtual bases \u2022 Traits \u2022 No subtype relationship using hierarchies in traits \u2022 AOP \u2022 are extensions to standard C++ \u2022 Signature \u2022 Promising, but non-standard, available only for Gnu compiler \u2022 Eiffel: ADOPT \u2022 CSet: subtype relationship implemented with metaprogramming \u2022 Non-intrusive solution based on the C++ standard Page 4 4 C++ Templates \u2022 Macro-like type parameters \u2013 Strong type checking \u2022 Templates alone form a \u2026", "num_citations": "3\n", "authors": ["1220"]}
{"title": "The Role of Implicit Conversions in Erroneous Function Argument Swapping in C++\n", "abstract": " Argument selection defects, in which the programmer has chosen the wrong argument to a function call is a widely investigated problem. The compiler can detect such misuse of arguments based on the argument and parameter type in case of statically typed programming languages. When adjacent parameters have the same type, or they can be converted between one another, the potential error will not be diagnosed. Related research is usually confined to exact type equivalence, often ignoring potential implicit or explicit conversions. However, in current mainstream languages, like C++, built-in conversions between numerics and user-defined conversions may significantly increase the number of mistakes to go unnoticed. We investigated the situation for C and C++ languages where functions are defined with multiple adjacent parameters that allow arguments to pass in the wrong order. When implicit\u00a0\u2026", "num_citations": "2\n", "authors": ["1220"]}
{"title": "Detecting C++ lifetime errors with symbolic execution\n", "abstract": " One of the reasons why it is so hard to statically analyze C++ source code is because of its Standard Template Library (STL). The STL is a monstrous collection of complex code base whose semantics is hard for static analyzers to understand. Unfortunately, many of the most serious memory management bugs in C++ are connected to the lifetimes of STL containers. This paper describes a method of adding knowledge of STL ownership semantics to a static analysis engine. It was implemented in an open-source symbolic execution framework widely used in the industry, and produced new and serious lifetime-related error reports in popular open-source projects.", "num_citations": "2\n", "authors": ["1220"]}
{"title": "Selective friends in C++\n", "abstract": " There is a strong prejudice against the friendship access control mechanism in C++. People claim that friendship breaks the encapsulation, reflects bad design, and creates too strong coupling. However, friends appear even in the most carefully designed systems, and if it is used judiciously (like using the attorney\u2010client idiom), they may be better choice than widening the public interface of the class. In this paper, we investigate how the friendship mechanism is used in C++ programs. We have made measurements on several open source projects to understand the current use of friends. Our results show various holes and errors in friend usage, like friend functions accessing only public members or not accessing members at all or the class, which declare friends has no private members at all. The results also show that friend functions actually use only a low percentage of the private members they were granted to\u00a0\u2026", "num_citations": "2\n", "authors": ["1220"]}
{"title": "Utilize Syntax Tree Transformations as a C/C++ Test Seam.\n", "abstract": " In C/C++, test code often influences the source code of the unit we want to test. During the test development process we often have to introduce new interfaces to replace existing dependencies, eg a supplementary setter or constructor function has to be added to a class for dependency injection. In many cases, extra template parameters are used for the same purpose. These solutions may have serious detrimental effects on the code structure and sometimes on the run-time performance as well. We can use non-intrusive tests (tests which does not require any modification in the production code) to avoid these disadvantages. Also, in legacy code bases often there are few or no unit tests. Refactoring such code in order to provide tests is almost impossible because we cannot verify correctness without having unit tests; hence it is a vicious circle. We can break the circle with non-intrusive tests, ie without actually modifying the production code. The different non-intrusive testing methods have different weaknesses. In this paper we introduce our new non-intrusive testing approach which complements the existing techniques. Our solution transforms certain parts of the original abstract syntax tree of the production code for the purpose of testing.", "num_citations": "2\n", "authors": ["1220"]}
{"title": "Welltype: Language elements for multiparadigm programming.\n", "abstract": " Modern programming languages try to provide a balance between flexibility to support rapid development and implementing as much validation on the program as possible to avoid expensive runtime errors. This trade-off is reflected in the language syntax, the type system and even in the method how the program produces the runtime binary. While the balance seems to be slightly moved today from safety to effectiveness, there is still a high demand for thoroughly checked, safe, but still effective programming languages. In this paper we introduce our experimental, imperative programming language, Welltype, which is designed to demonstrate that effective development can be accommodated with increased safety. Our language design decisions are based on current real-life problems and their solutions. We describe key features such as syntax improvement, fail-safe type system, and binary compatibility via dynamic linking.", "num_citations": "2\n", "authors": ["1220"]}
{"title": "Unit Testing and Friends in C+\n", "abstract": " Unit testing of object-oriented code requires two fundamental artifacts: replacing some of the original code with some kind of test doubles (aka dependency injection), and providing extra access to these private dependencies. In most cases we cannot apply link-time or preprocessor based dependency injection, therefore a typical testable unit uses additional interfaces or template type parameters for pure testing purposes. Thus a unit which we developed without testing in mind might have to be changed intrusively for testing. These changes can take us far away from the original natural design of the unit. As a result, in C++, test code is often badly interwoven with the unit we want to test. We\u2019ve seen such interleaving in the software world before: exceptions and aspect oriented programming were both invented to try to eliminate this kind of interleaving of independent aspects. In this paper we demonstrate the above\u00a0\u2026", "num_citations": "2\n", "authors": ["1220"]}
{"title": "Backward compatibility violations and their detection in C++ legacy code using static analysis\n", "abstract": " Programming languages evolve as the need for higher abstraction level increases. To satisfy these needs, languages introduce new features, which are usually additional elements, but many times these are not orthogonal to the existing ones. The C++ programming language is planned with backward compatibility kept in mind between particular releases. However, some of the new features introduced by C++ 11, like move semantics or multi-threading required the change of the standard library API and this leads to deviation in the meaning of existing programs. In this article we draw the attention on some of these semantic changes and provide a tool for automatically detecting them.", "num_citations": "2\n", "authors": ["1220"]}
{"title": "Friendship in Service of Testing\n", "abstract": " G\u00e1bor M\u00e1rton, martongabesz@gmail.com Zolt\u00e1n Porkol\u00e1b, gsd@elte.hu Page 1 / 47 Friendship in Service of Testing G\u00e1bor M\u00e1rton, martongabesz@gmail.com Zolt\u00e1n Porkol\u00e1b, gsd@elte.hu 1 Page 2 / 47 Agenda \u2022 Introduction, principals \u2022 Case study (running example) \u2022 Making the example better \u2022 Vision 2 Page 3 / 47 Functional Programming std::size_t fibonacci(std::size_t); ASSERT(fibonacci(0u) == 0u); ASSERT(fibonacci(1u) == 1u); ASSERT(fibonacci(2u) == 1u); ASSERT(fibonacci(3u) == 2u); ... ASSERT(fibonacci(7u) == 13u); ASSERT(fibonacci(8u) == 21u); \u2022 Immutability \u2022 Thread safe \u2022 Easy to test! 3 Page 4 / 47 OOP \u2022 States \u2022 Dependencies (eg Strategy pattern) \u2022 Bad patterns -> Side Effects (singleton) 4 Page 5 / 47 OOP - SOLID \u2022 Loosely coupled system \u2022 Interface (ptr or ref) 5 Page 6 / 47 UUT/SUT dependency dependency Production Test Double Mock Stub Fake Often very heavy, eg requires network Inter-\u2026", "num_citations": "2\n", "authors": ["1220"]}
{"title": "C/C++ preprocessing with modern data storage devices\n", "abstract": " The progress of hardware evolution cannot be stopped. Not just new CPUs and memory modules are invented but new kind of data storage devices appeared. Typically the programming languages do not follow all the changes in hardware. Solid-state drives (SSD) are improved data storage devices in order to reach must faster read and write speed than hard disk drives. Nowadays the solid-state drives have become popular. The high number of I/O operations have some performance drawbacks during build. In this paper we analyze how the data storage device affects C/C++ preprocessor operations because this is an I/O-intensive task and many researches target the speed-up of preprocessing workflow. We present our measurement framework that helps us to analyze different approaches. We focus on the following questions: Is it worth to use unity build or another technique when SSD is available? How can\u00a0\u2026", "num_citations": "2\n", "authors": ["1220"]}
{"title": "THE EFFECTS OF USING EXCEPTION HANDLING ON SOFTWARE COMPLEXITY.\n", "abstract": " Exception handling is the definitive way to handle errors of any kind and exceptional circumstances in modern software. There has been a long way before software methodlogy arrived to creating and using the notion of exceptions. We automatically assume that using exception handling makes our software more readable, more maintainable and easier to understand {ie less complex than when we use any other error management (let it be using return values, ERRNO or any other kind). Is this really the case? Measuring software complexity can be done using software metrics. There are several trivial, well-known candidates-lines of code, cyclomatic complexity or McCabe-metrics and AV {for this purpose, however these metrics do not measure exception contructs, therefor their usage can lead to distorted results [12]. In this paper, we extend the definitions of two metrics to the case of exceptions and analyze how\u00a0\u2026", "num_citations": "2\n", "authors": ["1220"]}
{"title": "Rapid prototyping for distributed D-Clean using C++ templates\n", "abstract": " Earlier we have designed two coordination languages, D-Clean and D-Box for high-level process description and communication coordination of functional programs distributed over a cluster. D-Clean is the high level coordination language for functional distributed computations. The language coordinates the pure functional computational nodes required by language primitives, and it controls the dataflow in a distributed processnetwork. In order to achieve parallel features, D-Clean extends the lazy functional programming language Clean with new language primitives. Every D-Clean construct generates a D-Box expression. D-Box is an intermediate level language and describes in details the computational nodes hiding the low level implementation details and enabling direct control over the process-network. Practical experiences of the two language usage showed the difficulties of distributed program development, especially in testing and debugging. This paper aims to provide software comprehension application for a better way of understanding and utilizing the D-Clean language. Here we provide a new modeling approach of the coordination language elements and a new view of the D-Clean distributed system behaviour using C++ templates. The strong type system of C++ templates guarantees the correctness of the model. Using templates we can achieve impressive efficiency by avoiding run-time overhead.", "num_citations": "2\n", "authors": ["1220"]}
{"title": "docx2tex: Word 2007 to TEX\n", "abstract": " Docx2tex is a small command line tool to support users of Word 2007 to publish documents when typography is important or only papers produced by TEX are accepted. Behind the scenes, docx2tex uses common technologies to interpret Word 2007 OOXML format without utilizing the API of Word 2007. Docx2tex is published as a free and open source utility that is accessible and extensible by everyone. The source code and the binary executable of the application can be downloaded from http://codeplex. com/docx2tex/. This paper was originally written in Word 2007 and later converted to TEX using docx2tex.", "num_citations": "2\n", "authors": ["1220"]}
{"title": "FC#: Designing an Internal Functional DSL to C# 3.0\n", "abstract": " Based on the improvements of the C# programming language towards functional programming support, and motivated by the FC++ functional library for C++, we introduce the FC# functional library for C#. FC# itself is an internal Domain Specific Language (DSL) for C#, therefore solutions created using FC# can be embedded into native C#. FC# has a couple of useful features for programmers who like functional concepts or who write multi-paradigm programs. The most important features we support are lazy lists, basic list filtering and composition operations, high performance, extensibility, and easy integration with C#. To achieve it the following capabilities of the C# 3.0 language are exploited: enumerators, lambda expressions, type inference, currying, and extension methods. Beside expressiveness and high level of usability, FC# has also an efficient implementation that we also show in the performance comparison charts. The latest version of FC# can be downloaded from the following URL: http://www. codeplex. com/fcs/.", "num_citations": "2\n", "authors": ["1220"]}
{"title": "The AV-graph in SQL-Based Environment\n", "abstract": " Software metrics play an important role in software engineering because the cost of testing and maintenance depends on the complexity of the software. Multiparadigm metrics can be used in various environments and they are applicable when more different paradigms are used in the same time. AV-graph is a multiparadigm metric that arises from imperative approach.Structured Query Language (SQL) is the most common language for managing databases. SQL is a declarative language which is standardized. Most complex software systems use database support for store and manipulate information, compute calculations. Usually SQL appears as an embedded language in a high-level host language (for example C++, Java or C#). SQL queries are often string objects with no other type information in the host language. Most metrics do handle string objects without any semantical examination, but in SQL supported programs complexity of query strings may differ. In this paper we examine the AV-graph in SQL-based environment. The AV-graph metric is interpreted in the database realm and extended for SQL statements. We compare the behaviour of the metric to the expected functionality. We refine our multiparadigm metric for SQL supported software systems.", "num_citations": "2\n", "authors": ["1220"]}
{"title": "Templight, a template metaprogram debugger\n", "abstract": " Template metaprogramming (TMP) is an emerging new direction in C++ programming for executing algorithms in compilation time. Metaprograms are widely used for the following purposes:\u2022 optimizing runtime programs (eg expression templates)\u2022 enforcing certain semantic checks.\u2022 emitting error messages\u2022 implementing active librariesUnfortunately, template metaprogramming is not yet supported with sufficient software tools (eg debugger, profiler, etc.). Our poster introduces Templight, a debugging framework that reveals the steps executed by the compiler during the compilation of C++ programs with templates. Templight\u2019s features include following the instantiation chain, setting breakpoints, and inspecting metaprogram information. This framework aims to take a step forward to help template metaprogramming become more accepted in the software industry.", "num_citations": "2\n", "authors": ["1220"]}
{"title": "A feature composition problem and a solution based on C++ template metaprogramming\n", "abstract": " Separation of concerns and collaboration based design is usually a suitable concept for library implementation: it results in easily scalable and maintainable code. After specifying and implementing orthogonal features, we aim to easily assemble library components. In real life, components can be used only after appropriate refinement steps, progressively adding features in each step. Therefore the specific solution for a particular task can be produced by composing a set of refined components. Unfortunately, a subtype anomaly occurs in object-oriented languages between such composite components that have different numbers of features from different refinement stages. In this article we analyse this anomaly that we named chevron-shape inheritance and present a framework based on standard C++ template metaprogramming.", "num_citations": "2\n", "authors": ["1220"]}
{"title": "A generative approach for family polymorphism in C++\n", "abstract": " The object-oriented paradigm provides safe and flexible use of objects of classes that can be arranged to inheritance hierarchies. Late binding ensures that we use the appropriate function body when we call a method on an actual object via polymorphic references. In the same time we have compile-time guarantees to use only valid calls.The problem arises when we use two or more independent hierarchies of classes together. In this case the collaborating\u201d families\u201d may consist of similar but not interchangeable classes. Because there can be subtype relationship between classes in the different groups, it is not obvious to implement a constraint ensuring that only classes of the same family are used together. Traditional object-oriented languages are not able to handle this situation. Proposed solutions vary from run-time assertions to family polymorphism extensions of existing programming languages. Family polymorphism\u2013strongly investigated by Erik Ernst and others\u2013takes traditional polymorphism to the multi-object level.", "num_citations": "2\n", "authors": ["1220"]}
{"title": "Code Generation from UML models\n", "abstract": " Creating a generic, object-oriented, component-based, transactional business system, which covers the whole lifecycle, is possible only with the integration of commercial tools, component technologies, newly developed class libraries and by using code generators. Most of the recently used tools for development techniques are focusing on only one of the layers of the model from the code generation point of view. As a consequence, the inter-layer connections are lost in the generated code. In this article, we describe a code generator technique which uses a UML model as a starting point and generates several layers directly. While generating the code, it preserves the original interlayer relationships originated in the model. Based on our experiences with 4GL systems it is obvious that there is a need to provide customisation in the generated code. We offer a multi-paradigm approach [1] to let the developer choose the appropriate solution for her or his implementation.", "num_citations": "2\n", "authors": ["1220"]}
{"title": "Compile-Time Function Call Interception to Mock Functions in C/C++\n", "abstract": " In C/C++, test code is often interwoven with the production code we want to test. During the test development process we often have to modify the public interface of a class to replace existing dependencies; eg a supplementary setter or constructor function is added for dependency injection. In many cases, extra template parameters are used for the same purpose. These solutions may have serious detrimental effects on the code structure and sometimes on the run-time performance as well. We introduce a new technique that makes dependency replacement possible without the modification of the production code, thus it provides an alternative way to add unit tests. Our new compile-time instrumentation technique enables us to intercept function calls and replace them in runtime. Contrary to existing function call interception (FCI) methods, we instrument the call expression instead of the callee, thus we can avoid the modification and recompilation of the function in order to intercept the call. This has a clear advantage in case of system libraries and third party shared libraries, thus it provides an alternative way to automatize tests for legacy software. We created a prototype implementation based on the LLVM compiler infrastructure which is publicly available for testing.", "num_citations": "2\n", "authors": ["1220"]}
{"title": "Towards more reliable C++ template metaprograms\n", "abstract": " Writing reliable software is challenging in the domain of C++ template metaprograms. Among other factors, the relatively complex syntax, the lack of good error handling techniques and the shortcomings of existing test methods can be named as sources of unreliability in metaprograms. In this paper we suggest a unit testing framework for C++ template metaprograms that guarantees the execution of all test cases and provides proper summary-report with enhanced and portable error reporting. Neither of these elements serve as a silver bullet for implementing compile-time algorithms, but together they may form an important step towards writing more reliable C++ template metaprograms.", "num_citations": "2\n", "authors": ["1220"]}
{"title": "Unambiguity of Python Language Elements for Static Analysis\n", "abstract": " Static analysis is a technique for gathering some meaningful information during compilation-time and using it for further processing. This technique is applied in bug finding, code comprehension and in many other areas. However, static analysis gives a static view of the source and provides limited information about the dynamic behavior of a program. This limitation is generally considered to be a major barrier for dynamically typed languages, like Python, since in many situations it is hard to derive the most basic properties of variables or functions, sometimes we can\u2019t even find the location of their definition. In this paper we present our experimental results that show this is not necessary a hard barrier in practical industrial projects. We analyzed open-source Python libraries, including the Python Standard Library itself as part of the CodeCompass code comprehension framework, and found that in a high number of\u00a0\u2026", "num_citations": "1\n", "authors": ["1220"]}
{"title": "Detecting Uninitialized Variables in C++ with the Clang Static Analyzer\n", "abstract": " Uninitialized variables have been a source of errors since the beginning of software engineering. Some programming languages (eg Java and Python) will automatically zero-initialize such variables, but others, like C and C++, leave their state undefined. While laying aside initialization in C and C++ might be a performance advantage if an initial value can't be supplied, working with such variables is an undefined behavior, and is a common source of instabilities and crashes. To avoid such errors, whenever meaningful initialization is possible, it should be used. Tools for detecting these errors run time have existed for decades, but those require the problematic code to be executed. Since in many cases the number of possible execution paths are combinatoric, static analysis techniques emerged as an alternative. In this paper, we overview the technique for detecting uninitialized C++ variables using the Clang Static Analyzer, and describe various heuristics to guess whether a specific variable was left in an undefined state intentionally. We implemented a prototype tool based on our idea and successfully tested it on large open source projects.", "num_citations": "1\n", "authors": ["1220"]}
{"title": "Type Inference of Simple Recursive Functions in Scala\n", "abstract": " Scala is a well-established multi-paradigm programming language known for its terseness that includes advanced type inference features. Unfortunately this type inferring algorithm does not support typing of recursive functions. This is both against the original design philosophies of Scala and puts an unnecessary burden on the programmer. In this paper we propose a method to compute the return types for simple recursive functions in Scala. We make a heuristic assumption on the return type based on the non-recursive execution branches and provide a proof of this method's correctness. The algorithm does not have a significant effect on the compilation speed. We implemented our method as an extension prototype in the Scala compiler and used it to successfully test our method on various examples. The compiler extension prototype is available for further tests.", "num_citations": "1\n", "authors": ["1220"]}
{"title": "A comprehensive review on software comprehension models\n", "abstract": " Software comprehension is one of the most important among software development tasks since most developers do not start a brand new software every time they switch jobs or get transferred from one project to another but join long-running software projects. Every experienced and expert developer has their own established methods of understanding complex software systems. These methods might be different for everyone but they still have common aspects by which multiple well-defined code comprehension models can be constructed. Furthermore, the degree of understanding of a software can be categorized as well, according to the ability of the programmer to modify or develop a certain part of the software system. This paper is intended to provide a review of the cognitive software comprehension models established by extensive research in this topic as well as describe the dimensions of understanding software. It also determines the editor support of cognition models by examining common editor functionalities and categorizing code editors based on the availability of functionalities of each cognition approach.", "num_citations": "1\n", "authors": ["1220"]}
{"title": "The role of the version control information in code comprehension\n", "abstract": " Most software comprehension frameworks use the source code as the main resource for information retrieval. Advanced code comprehension process, however, requires the utilization of the full knowledge portfolio of the software system. In this paper we investigate how the version control information of the project can be utilized for extending our apprehension of large legacy systems providing a better understanding of the software under examination. We show that some of the hidden structural connections between the elements of the program can be revealed most easily by the development history of the system. A prototype implementation of the method using git version control information has been implemented as an open source extension of the CodeCompass software comprehension framework.", "num_citations": "1\n", "authors": ["1220"]}
{"title": "Towards More Sophisticated Static Analysis Methods of Python Programs\n", "abstract": " Static analysis is a software verification method which is analyzing the source code without executing it for detecting code smells and possible software bugs. Various analysis methods have been successfully applied for languages with static type system, such as C, C++ and Java. Python is an important programming language with dynamic type system, used in many emerging areas, including data science, machine learning and web applications. The dynamic behavior of the Python language requires different static analysis approaches compared to the ones with static type system. In this paper we overview these methods and investigate their advantages and shortages. We compare the symbolic execution with the generally used Abstract Syntax Tree based approach and show its advantages based on concrete examples. We also highlight the restrictions of current tools and suggest further research directions to\u00a0\u2026", "num_citations": "1\n", "authors": ["1220"]}
{"title": "Survey on Static Analysis Tools of Python Programs.\n", "abstract": " Static program analysis is a popular software technique performed by automated tools for verifying large scale software systems. It works without executing the program, just analyzing the source code and applying various heuristics to find possible errors, code smells and style discrepancies. Programming languages with strong static type system, like C, C++, Java are the usual targets of static analysis, as their type system provides additional information for the analyzer. However, there is a growing demand for applying static analysis for dynamically typed languages, like Python. In this paper we overview the current methods and tools available for static analysis on Python code base and describe some new research directions.", "num_citations": "1\n", "authors": ["1220"]}
{"title": "Visualising compiler-generated special member functions of C++ types\n", "abstract": " In the C++ programming language, special member functions are either user-defined or automatically generated by the compiler. The detailed rules for when and how these methods are generated are complex and many times surprise developers. As generated functions never appear in the source code it is challenging to comprehend them. For a better understanding of the details under the hood, we provide a visualisation method which presents generated special functions in the form of C++ source code that in effect identical to their implicit versions.", "num_citations": "1\n", "authors": ["1220"]}
{"title": "Detecting binary incompatible software components using dynamic loader\n", "abstract": " Modern programming languages support modular development dividing the system into separate translation units and compile them individually. A linker is used then to assemble together these units either statically or dynamically. This process, however, introduces implicit dependences between the translation units. When one or more units are modified in inconsistent way binary incompatibility occurs and may result in unexpected program behavior. Current mainstream programming languages neither specify what are the binary compatibility rules nor provide tools to check them.", "num_citations": "1\n", "authors": ["1220"]}
{"title": "Two Dimensional Visualization of Software Metrics.\n", "abstract": " Two dimensional visualization of software metrics Page 1 Two dimensional visualization of software metrics Tibor Brunner1 Zolt\u00e1n Porkol\u00e1b1 1E\u00f6tv\u00f6s Lor\u00e1nd University September 12, 2017 Tibor Brunner, Zolt\u00e1n Porkol\u00e1b Two dimensional visualization of software metrics Page 2 Subject Writing code from scratch is easy Maintenance of large legacy codes is expensive Code comprehension tools can help Examine and estimate their quality Which parts need refactoring? Tibor Brunner, Zolt\u00e1n Porkol\u00e1b Two dimensional visualization of software metrics Page 3 Architecture Tibor Brunner, Zolt\u00e1n Porkol\u00e1b Two dimensional visualization of software metrics Page 4 Function call diagram Tibor Brunner, Zolt\u00e1n Porkol\u00e1b Two dimensional visualization of software metrics Page 5 Code browsing Tibor Brunner, Zolt\u00e1n Porkol\u00e1b Two dimensional visualization of software metrics Page 6 Quality indicators Metrics Lines of code \u2026", "num_citations": "1\n", "authors": ["1220"]}
{"title": "Code complexity estimation for Java programs\n", "abstract": " Estimating algorithmic complexity of complex software systems is important as based on such estimations we can approximate certain run-time properties of the software, like worst-case execution time or latency of critical components. These estimations are also necessary e.g. to plan with the required hardware capacity to run the software. While software design usually deals with algorithmic complexity, the actual implementation may vary from the plans. In case of industry-scale complex systems such differences are very hard to detect with manual code inspections. In this paper we propose a new approach for source level worst-case time estimation for Java programs. Knowing the presumed complexity, we try to prove whether the worst-case execution of the program suits the complexity requirements. These requirements are given in a specific DSL embedded into the code. When the supposed upper limit does\u00a0\u2026", "num_citations": "1\n", "authors": ["1220"]}
{"title": "Tool for detecting standardwise differences in C++ legacy code\n", "abstract": " Programming languages are continuously evolving as the experiences are accumulated, developers face new problems and other requirements such as increasing support for multi-threading is emerging. These changes are reflected in new language standards and compiler versions. Although these changes are carefully planned to keep reverse compatibility with previous versions to keep the syntax and the semantics of earlier written code, sometimes languages break this rule. In case of silent semantic changes, when the earlier written code is recompiled with the new version, this is especially harmful. The new C++11 standard introduced major changes in the core language. This changes are widely believed to be reverse compatible, i.e. a simple recompilation of earlier written code will keep the old semantics. Recently we found examples that the backward compatibility between language versions is broken\u00a0\u2026", "num_citations": "1\n", "authors": ["1220"]}
{"title": "Language Support for High-level Worst-case Execution Time Estimation\n", "abstract": " There are many ways to implement one specific task, but some of them are faster than the others. In general we can specify an acceptable complexity that we can validate based on the source code or the object file. However, the validation requires external tool, which cause undesired dependency from a third-party utility. A better solution when the compiler provides language support for checking the expected worst-case execution time for each functions. Validating the expected worst-case execution time should be an aspect of the correctness of the program, because it guarantees high-level correctness at design time. Therefore, the complexity of program will not exceed an expected value. It is important to note that, our goal is to give an expected upper limit for the complexity at design time. In this paper, we first define the method to estimate the worst-case execution time of a function. This is a structural algorithm\u00a0\u2026", "num_citations": "1\n", "authors": ["1220"]}
{"title": "EVALUATING COMMENT-TO-AST ASSIGNMENT HEURISTICS FOR C++ PROGRAMS.\n", "abstract": " Comments are integral part of the source code of software. They preserve the intentions of the developers, document constraints and highlight implementation details. Good comments help us to understand the codebase and make maintenance easier. Most of the software tools ignore comments because they take no part in code generation. However, there are cases when comments should be taken into account: refactoring tools need to move code along with their comments and code comprehension tools need to show comments related to a given context. Since these tools are working on the abstract syntax tree (AST), comments should be assigned to the appropriate AST nodes. Assigning comments to AST nodes is a non-straightforward task. Most methods use heuristics that place the comment to the proper AST node. This article improves existing heuristics. We identify corresponding AST nodes by distance\u00a0\u2026", "num_citations": "1\n", "authors": ["1220"]}
{"title": "Domain-specific languages with custom operators\n", "abstract": " Embedded domain-specific languages have become more popular due to their expressive power. The tasks are composed at the level of the problem domain. This paper shows the key elements and the benefits of implementing embedded domain-specific languages in strongly typed imperative programming languages. These ideas are useful for those people who use or implement embedded domain-specific languages but they are not professionals in functional programming and prefer imperative programming languages instead. The most common host language of the domain-specific languages is a functional programming language, because of the freedom to introduce custom operators. The investigation is based on a strongly typed imperative language which allows to define such operators. Domain-specific languages increase abstraction level and hide details. This paper explores other aspects of domain-specific languages for functional programmers. The key language element is in functional languages to define custom operators. These language elements must be found in the host language for implementing an efficient embedded domain-specific language. In this paper there is an example language to demonstrate the expressive power. The investigation concludes that the benefits of using an imperative language to implement an embedded domain-specific language are the increased expressiveness by eliminating redundant parentheses\u2019 and unnecessary verbose function names from the source code. Based on the strong static type system the custom types preserve the type-correctness. This paper shows ideas and\u00a0\u2026", "num_citations": "1\n", "authors": ["1220"]}
{"title": "Comparison of DC and MC/DC code coverages\n", "abstract": " In software development testing plays the most important role to discover bugs and to verify that the product satisfies its requirements. Several tests methods exist to check code correctness trying to find the best balance between precision and cost. Less strict ones require fewer test cases and consume less resources, however they may discover fewer errors. Chosing test methods is always a compromise between the code correctness and the available resources. In this paper we analyse two important testing methods, the Decision Coverage and the more strict Modified Condition/Decision Coverage in several aspects. We discuss how these aspects are affected by the difference of the necessary test cases for the testing methods. The analysis is done on open source programs written in C++.", "num_citations": "1\n", "authors": ["1220"]}
{"title": "Random number generator for C++ template metaprograms\u22c6\n", "abstract": " Template metaprogramming is a widely used programming paradigm to develop libraries in C++. With the help of cleverly defined templates the programmer can execute algorithms at compilation time. C++ template metaprograms are proven to be Turing-complete, thus wide scale of algorithms can be executed in compilation time. Applying randomized algorithms and data structures is, however, troublesome due to the deterministic nature of template metaprograms. In this paper we describe a C++ template metaprogram library that generates pseudorandom numbers at compile time. Random number engines are responsible to generate pseudorandom integer sequences with a uniform distribution. Random number distributions transform the generated pseudorandom numbers into different statistical distributions. Our goal was to provide similar functionality to the run-time random generator module of the Standard Template Library, thus programmers familiar with STL can easily adopt our library.", "num_citations": "1\n", "authors": ["1220"]}
{"title": "A\u00b4 practical survey on programming paradigms\n", "abstract": " Programming paradigm has a key role in software technology as represents the directives in creating abstractions. The paradigm is the principle by which a problem can be comprehended and decomposed into manageable components [2]. During the software development there are several questions regarding abstractions and components. the paradigm which is applied sets up the rules and properties, but also offers tools for developing applications.Programming paradigms evolved from the early epoch of automatic programming to the current advanced techniques such as aspect-oriented programming [5] and generic programming [1]. During this half century of software technology we introduced and later exceeded paradigms like structured programming [4], then object-orientation [6] and the development is continous. In this paper we overview the most important programming paradigms and evaluate their\u00a0\u2026", "num_citations": "1\n", "authors": ["1220"]}
{"title": "TOWARDS AXIOM-BASED TEST GENERATION IN .NET APPLICATIONS\n", "abstract": " Unit testing is an important aspect of developing highly reliable and dependable applications. Although theoretically it offers the capability of testing a piece of code (typically a method) in isolation, the challenge of constructing a test set that appropriately tests the whole functionality remains open and is usually a task that programmers need to solve on an ad-hoc basis or using extreme approaches like test-driven development. This paper proposes a way how algebraic software specification can be applied to programs running on the .NET platform, how it can serve as the basis of automatic test generation and how it can replace ad-hoc testing throughout the software development process, especially during refactoring. The authors introduce the definition of a concept and an axiom, and also overview axiom-based testing in general. A mapping between the abstract definitions and the language constructs of the C# 4 programming language will be specified. Services provided by the .NET platform like attributes, reflection and call interception will be introduced and employed during implementation. It will be described how axioms differ from the contracts of the Eiffel programming language and why they are more suitable for generating test cases. The authors give the detailed description of the main components of the axiom-based test generation framework, which was implemented using .NET 4/C# 4 and show a case study in order to demonstrate the feasibility of the solution.", "num_citations": "1\n", "authors": ["1220"]}
{"title": "Syntax Check of Embedded SQL in C++ with Proto\n", "abstract": " The SQL is the most frequently used language to manipulate databases. However SQL is not a general purpose programming language, thus it is not appropriate to develop applications with. In the most cases SQL statements are embed into another programming language, like C++, Java or C#, allowing us to describe the general algorithms with a general purpose language and the database specific ones with SQL. Beside of the obvious benefit this solution has some disadvantages too. The compiler of the general purpose language do not know the syntax of SQL, thus it is not able to perform syntactical and semantical checking on SQL code in compilation time. That way, the errors of SQL codes are figured out only in run time which lowers the quality of our code and makes debugging more difficult. However the template facility of C++ programming language\u2013using it in a special way\u2013allows us to run algorithms in compilation time. This paradigm is called Template Metaprogramming. With proper metaprograms the C++ compiler can be forced to check the syntax of SQL statements. In this paper we present a solution how perform SQL syntax checking of embedded SQL statements during the compilation of C++ source codes.", "num_citations": "1\n", "authors": ["1220"]}
{"title": "Quantitative comparison of MC/DC and DC test methods\n", "abstract": " Coverage refers to the extent to which a given verification activity has satisfied its objectives. There are several type of coverage analysis exists to check the code correctness. Usually the less strict analysis methods require fewer test cases to satisfy their requirements and the more strict ones require more. But it is not clear how much is the\u201d more\u201d. In this paper we concern to the Decision Coverage and the more strict Modified Condition/Decision Coverage. We examined several projects used in the industry by several aspects: McCabe metric, nesting and maximal argument number in decisions. We discuss how these aspects are affected the difference of the necessary test cases for these testing methods.", "num_citations": "1\n", "authors": ["1220"]}
{"title": "Application of OO metrics to estimate .NET project software size\n", "abstract": " One of the key questions in software development is software size estimation. For systematic software size estimation, different methods are used, all of which have their roots in the Function Point Analysis (FPA) method. However, the elements and constructs of the FPA method are not directly applicable to object-oriented concepts: a mapping of object-oriented concepts to FPA elements is required. There are proposals for such mappings, but a serious calibration and validation process is required to ensure that the various parameters have been chosen in the most appropriate way. Such a validation implies the creation of effective product metrics working in environments like the industrial standard .NET platform.Since .NET is a typical multi-language environment, a product metric capturing all languages and producing comparable and accumulable results is hard and expensive to produce. Therefore we propose to solve the problem in the .NET Common Interface Language level: thus only one metric is capable to calibrate and validate the FPA mappings.", "num_citations": "1\n", "authors": ["1220"]}
{"title": "Improving Size Estimates with .NET Product Metrics\n", "abstract": " Software projects often fail regardless of the technological changes in recent years. One of the primary reasons is the intuitive assessment of project size, effort, costs and duration. Project size is an independent value where effort, costs and duration are derived values directly related to project size. For size estimates, several methodological approaches are available and in use today. However the Function Point Analysis (FPA) method tends to be predominant in practice as well as in research. In this paper, the use of the FPA method for a project developed in the .NET environment is briefly discussed and linked with source code metrics in order to improve size estimates and get more information related to derived values such as effort, costs and duration.", "num_citations": "1\n", "authors": ["1220"]}
{"title": "Autonomous Applications-Towards a Better Data Integration Model.\n", "abstract": " One of the most important and critical part of integrating already existing standalone applications is to design and implement a common data model and the corresponding data access layer which makes both data sources and processed results being shared and accessible over the applications in question. In case of even well-architected applications or application systems, establishing a common data model and the layer that gives access to data costs relatively large human and computer development resources. The problem of integration may be investigated from several aspects. The esence of these aproaches are the same: trying to achieve run-time environment independent applications\u2019 logic. One aspect is OMG\u2019s Model Driven Architecture Frame Work [5]. The primary goals of OMG\u2019s MDA are portability, interoperability and resuability through architectural concernes of specifying Application\u2019s logic, their operational environments, and technical aspects of their implementation details, and mappings between them. This paper views the same problem but with focus on different structural apearances of applications\u2019 data, mappings between them, and possible integration of such data models. We call applications autonomous, if they are independent of their all time run-time data access environment. Concerning applications\u2019 autonomy, our base idea is that the most natural media that is able to carry information on structural apperance of data and mappings between them are data themselves, using Document Data Model also presented here.", "num_citations": "1\n", "authors": ["1220"]}
{"title": "Why code complexity metrics fail on the C++ standard template library\n", "abstract": " Since McCabe\u2019s cyclometric measure, structural complexity have been playing an important role measuring the complexity of programs. Complexity metrics are used to achieve more maintainable code with the least bugs possible.C++ Standard Template Library (STL) is the most popular library based on the generic programming paradigm. This paradigm allows implementation of algorithms and containers in an abstract way to ensure the configurability and collaboration of the abstract components. STL is widely used in industrial softwares because STL\u2019s appropriate application decreases the complexity of the code significantly.", "num_citations": "1\n", "authors": ["1220"]}