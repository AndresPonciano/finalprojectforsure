{"title": "Hyrax: Cloud computing on mobile devices using MapReduce\n", "abstract": " Todays smartphones operate independently of each other, using only local computing, sensing, networking, and storage capabilities and functions provided by remote Internet services. It is generally difficult or expensive for one smartphone to share data and computing resources with another. Data is shared through centralized services, requiring expensive uploads and downloads that strain wireless data networks. Collaborative computing is only achieved using ad hoc approaches. Coordinating smartphone data and computing would allow mobile applications to utilize the capabilities of an entire smartphone cloud while avoiding global network bottlenecks. In many cases, processing mobile data in-place and transferring it directly between smartphones would be more efficient and less susceptible to network limitations than off loading data and processing to remote servers. We have developed Hyrax, a platform derived from Hadoop that supports cloud computing on Android smartphones. Hyrax allows client applications to conveniently utilize data and execute computing jobs on networks of smartphones and heterogeneous networks of phones and servers. By scaling with the number of devices and tolerating node departure, Hyrax allows applications to use distributed resources abstractly, oblivious to the physical nature of the cloud. The design and implementation of Hyrax is described, including experiences in porting Hadoop to the Android platform and the design of mobile specific customizations. The scalability of Hyrax is evaluated experimentally and compared to that of Hadoop. Although the performance of Hyrax is poor for CPU-bound\u00a0\u2026", "num_citations": "606\n", "authors": ["516"]}
{"title": "Causes of failure in web applications\n", "abstract": " This report investigates the causes and prevalence of failure in Web applications. Data was collected by surveying case studies of system failures and by examining incidents of website outages listed on technology websites such as CNET. com and eweek. com. These studies suggest that software failures and human error account for about 80% of failures. The report also contains an appendix that serves as a quick reference for common failures observed in Web applications. This appendix lists over 40 incidents of real-world site outages, outlining how these failures were detected, the estimated downtime, and the subsequent recovery action.Acknowledgements: We thank the members and companies of the PDL Consortium (including EMC, Hewlett-Packard, Hitachi, IBM, Intel, Microsoft, Network Appliance, Oracle, Panasas, Seagate, Sun, and Veritas) for their interest, insights, feedback, and support.", "num_citations": "241\n", "authors": ["516"]}
{"title": "Consistent Object Replication in the Eternal System\n", "abstract": " The Eternal system replicates CORBA objects to provide fault tolerance, high availability, and evolution of live objects. By exploiting the IIOP interface, Eternal renders the replication transparent to the application objects, and also to the ORB and thus works with standard commercial CORBA ORBs. To maintain replica consistency, Eternal uses operations communicated in totally ordered multicast messages, detection of duplicate invocations and duplicate responses, transfer of state between the object replicas, consistent scheduling of concurrent operations, and fulfillment operations for restoring a consistent state after network partitioning and remerging. The difficult issues of replication, consistency, fault detection, and recovery are handled by Eternal and are hidden from the application programmer. \u00a9 1998 John Wiley & Sons, Inc.", "num_citations": "187\n", "authors": ["516"]}
{"title": "Sluice: Secure dissemination of code updates in sensor networks\n", "abstract": " Existing network reprogramming protocols target the efficient, reliable, multi-hop dissemination of application updates in sensor networks, but assume correct or fail-stop behavior from participating sensors. Compromised nodes can subvert such protocols to result in the propagation and remote installation of malicious code. Sluice aims for the progressive, resource-sensitive verification of updates in sensor networks to ensure that malicious updates are not disseminated or installed, while trusted updates continue to be efficiently disseminated. Our verification mechanism provides authenticity and integrity through a hash-chain construction that amortizes the cost of a single digital signature over an entire update. We integrate Sluice with an existing network reprogramming protocol and empirically evaluate its effectiveness both in a real sensor testbed and through simulation.", "num_citations": "171\n", "authors": ["516"]}
{"title": "Using interceptors to enhance CORBA\n", "abstract": " The integration of distributed computing and the object model leads to distributed object computing, in which objects rather than processes are distributed across multiple computers. A well-established standard for distributed object computing is the Common Object Request Broker Architecture (CORBA). Previously, you would have had to create-and enable the application to use-the components that provide such additional capabilities. Using these components requires specialized knowledge and understanding of problems outside the application domain. With the advent of interceptors-non-application components that can alter application behavior-you can enhance CORBA applications at runtime with components whose operation is transparent to both the application and the CORBA framework, modifying application behavior without modifying the application or the CORBA framework.", "num_citations": "163\n", "authors": ["516"]}
{"title": "Experiences, strategies, and challenges in building fault-tolerant CORBA systems\n", "abstract": " It has been almost a decade since the earliest reliable CORBA implementation and, despite the adoption of the fault-tolerant CORBA (FT-CORBA) standard by the Object Management Group, CORBA is still not considered the preferred platform for building dependable distributed applications. Among the obstacles to FT-CORBA's widespread deployment are the complexity of the new standard, the lack of understanding in implementing and deploying reliable CORBA applications, and the fact that current FT-CORBA do not lend themselves readily to complex, real-world applications. We candidly share our independent experiences as developers of two distinct reliable CORBA infrastructures (OGS and Eternal) and as contributors to the FT-CORBA standardization process. Our objective is to reveal the intricacies, challenges, and strategies in developing fault-tolerant CORBA systems, including our own. Starting with\u00a0\u2026", "num_citations": "158\n", "authors": ["516"]}
{"title": "Thema: Byzantine-fault-tolerant middleware for web-service applications\n", "abstract": " Distributed applications composed of collections of Web services may call for diverse levels of reliability in different parts of the system. Byzantine fault tolerance (BFT) is a general strategy that has recently been shown to be practical for the development of certain classes of survivable, client-server, distributed applications; however, little research has been done on incorporating it into selective parts of multi-tier, distributed applications like Web services that have heterogeneous reliability requirements. To understand the impacts of combining BFT and Web services, we have created Thema, a new BFT middleware system that extends the BFT and Web services technologies to provide a structured way to build Byzantine-fault-tolerant, survivable Web services that application developers can use like other Web services. From a reliability perspective, our enhancements are also novel in that they allow Byzantine-fault\u00a0\u2026", "num_citations": "157\n", "authors": ["516"]}
{"title": "SALSA: analyzing logs as state machines\n", "abstract": " SALSA examines system logs to derive state-machine views of the sytem\u2019s execution, along with controlflow, data-flow models and related statistics. Exploiting SALSA\u2019s derived views and statistics, we can effectively construct higher-level useful analyses. We demonstrate SALSA\u2019s approach by analyzing system logs generated in a Hadoop cluster, and then illustrate SALSA\u2019s value by developing visualization and failure-diagnosis techniques, for three different Hadoop workloads, based on our derived state-machine views and statistics.", "num_citations": "154\n", "authors": ["516"]}
{"title": "Dependability benchmarking for computer systems\n", "abstract": " A comprehensive collection of benchmarks for measuring dependability in hardware-software systems As computer systems have become more complex and mission-critical, it is imperative for systems engineers and researchers to have metrics for a system's dependability, reliability, availability, and serviceability. Dependability benchmarks are useful for guiding development efforts for system providers, acquisition choices of system purchasers, and evaluations of new concepts by researchers in academia and industry. This book gathers together all dependability benchmarks developed to date by industry and academia and explains the various principles and concepts of dependability benchmarking. It collects the expert knowledge of DBench, a research project funded by the European Union, and the IFIP Special Interest Group on Dependability Benchmarking, to shed light on this important area. It also provides a large panorama of examples and recommendations for defining dependability benchmarks. Dependability Benchmarking for Computer Systems includes contributions from a credible mix of industrial and academic sources: IBM, Intel, Microsoft, Sun Microsystems, Critical Software, Carnegie Mellon University, LAAS-CNRS, Technical University of Valencia, University of Coimbra, and University of Illinois. It is an invaluable resource for engineers, researchers, system vendors, system purchasers, computer industry consultants, and system integrators.", "num_citations": "143\n", "authors": ["516"]}
{"title": "Mochi: visual log-analysis based tools for debugging hadoop\n", "abstract": " Mochi, a new visual, log-analysis based debugging tool correlates Hadoop\u2019s behavior in space, time and volume, and extracts a causal, unified control-and dataflow model of Hadoop across the nodes of a cluster. Mochi\u2019s analysis produces visualizations of Hadoop\u2019s behavior using which users can reason about and debug performance issues. We provide examples of Mochi\u2019s value in revealing a Hadoop job\u2019s structure, in optimizing real-world workloads, and in identifying anomalous Hadoop behavior, on the Yahoo! M45 Hadoop cluster.", "num_citations": "97\n", "authors": ["516"]}
{"title": "MEAD: support for Real\u2010Time Fault\u2010Tolerant CORBA\n", "abstract": " The OMG's Real\u2010Time CORBA (RT\u2010CORBA) and Fault\u2010Tolerant CORBA (FT\u2010CORBA) specifications make it possible for today's CORBA implementations to exhibit either real\u2010time or fault tolerance in isolation. While real\u2010time requires a priori knowledge of the system's temporal operation, fault tolerance necessarily deals with faults that occur unexpectedly, and with possibly unpredictable fault recovery times. The MEAD (Middleware for Embedded Adaptive Dependability) system attempts to identify and to reconcile the conflicts between real\u2010time and fault tolerance, in a resource\u2010aware manner, for distributed CORBA applications. MEAD supports transparent yet tunable fault tolerance in real\u2010time, proactive dependability, resource\u2010aware system adaptation to crash, communication and timing faults with bounded fault detection and fault recovery. Copyright \u00a9 2005 John Wiley & Sons, Ltd.", "num_citations": "93\n", "authors": ["516"]}
{"title": "Trinetra: Assistive technologies for grocery shopping for the blind\n", "abstract": " Trinetra aims for cost-effective, assistive technologies to provide blind people with a greater degree of independence in their daily activities. The overall objective is to improve the quality of life for the blind by harnessing the collective capability of diverse networked embedded devices to support grocery shopping, transportation, etc. This paper describes our research and development of the Trinetra system, a barcode-based solution comprising COTS components, such as an Internet-and Bluetooth-enabled cell phone, text-to-speech software and a portable barcode reader. We describe our experiences with the first deployment of Trinetra at the Carnegie Mellon University\u2019s campus store, Entropy.", "num_citations": "92\n", "authors": ["516"]}
{"title": "Transparent fault tolerance for CORBA\n", "abstract": " Applications are increasingly being programmed using the CORBA distributed object standard. CORBA's Internet Inter-ORB Protocol (IIOP) and its mediating Object Request Broker (ORB) allow CORBA objects to interact, transcending differences in their locations, hardware architectures, operating systems and programming languages.", "num_citations": "92\n", "authors": ["516"]}
{"title": "Replica consistency of CORBA objects in partitionable distributed systems\n", "abstract": " The Eternal system enhances the CORBA standard to provide fault tolerance within distributed systems that are susceptible to network partitioning. Fault tolerance is achieved through consistent replication of both client and server objects. Objects may be actively or passively replicated, and replicated objects of both types may coexist. Nested operations involving both active and passive objects are accommodated. Suppression of duplicate operations is ensured by unique message and operation identifiers. Continued operation is allowed in all components of a partitioned network. State transfer mechanisms and fulfilment operations restore the consistency of the states of the replicas when communication is re-established and the components remerge.", "num_citations": "88\n", "authors": ["516"]}
{"title": "Black-box problem diagnosis in parallel file systems\n", "abstract": " We focus on automatically diagnosing different performance problems in parallel file systems by identifying, gathering and analyzing OS-level, black-box performance metrics on every node in the cluster. Our peercomparison diagnosis approach compares the statistical attributes of these metrics across I/O servers, to identify the faulty node. We develop a root-cause analysis procedure that further analyzes the affected metrics to pinpoint the faulty resource (storage or network), and demonstrate that this approach works commonly across stripe-based parallel file systems. We demonstrate our approach for realistic storage and network problems injected into three different file-system benchmarks (dd, IOzone, and Post-Mark), in both PVFS and Lustre clusters.", "num_citations": "85\n", "authors": ["516"]}
{"title": "Tiresias: Black-box failure prediction in distributed systems\n", "abstract": " Faults in distributed systems can result in errors that manifest in several ways, potentially even in parts of the system that are not collocated with the root cause. These manifestations often appear as deviations (or \"errors\") in performance metrics. By transparently gathering, and then identifying escalating anomalous behavior in, various node-level and system-level performance metrics, the Tiresias system makes black-box failure-prediction possible. Through the trend analysis of performance metrics, Tiresias provides a window of opportunity (look-ahead time) for system recovery prior to impending crash failures. We empirically validate the heuristic rules of the Tiresias system by analyzing fault-free and faulty performance data from a replicated middleware-based system.", "num_citations": "83\n", "authors": ["516"]}
{"title": "Enforcing determinism for the consistent replication of multithreaded CORBA applications\n", "abstract": " In CORBA-based applications that depend on object replication for fault tolerance, inconsistencies in the states of the replicas of an object can arise when concurrent threads within those replicas perform updates in different orders. By imposing a single logical thread of control on every replicated multithreaded CORBA client or server object, and by providing deterministic scheduling of threads and operations a cross the replicas of each object, the Eternal system achieves consistent object replication. The Eternal system does this transparently, with no modification to the application, the ORB, or the concurrency model employed by the ORB.", "num_citations": "82\n", "authors": ["516"]}
{"title": "Visual, log-based causal tracing for performance debugging of MapReduce systems\n", "abstract": " The distributed nature and large scale of MapReduce programs and systems poses two challenges in using existing profiling and debugging tools to understand MapReduce programs. Existing tools produce too much information because of the large scale of MapReduce programs, and they do not expose program behaviors in terms of Maps and Reduces. We have developed a novel non-intrusive log-analysis technique which extracts state-machine views of the control- and data-flows in MapReduce behavior from the native logs of Hadoop MapReduce systems, and it synthesizes these views to create a unified, causal view of MapReduce program behavior. This technique enables us to visualize MapReduce programs in terms of MapReduce-specific behaviors, aiding operators in reasoning about and debugging performance problems in MapReduce systems. We validate our technique and visualizations using a\u00a0\u2026", "num_citations": "77\n", "authors": ["516"]}
{"title": "Exploiting the Internet Inter-ORB Protocol interface to provide CORBA with fault tolerance\n", "abstract": " The Eternal system is a CORBA 2.0-compliant system that provides, in addition to the location transparency and the interoperability inherent in the CORBA standard, support for replicated objects and thus fault tolerance. Eternal exploits the Internet Inter-ORB Protocol (IIOP) interface to``attach''itself transparently to objects operating over a commercial CORBA Object Request Broker (ORB). The Eternal Interceptor captures the IIOP system calls of the objects, and the Eternal Replication Manager maps these system calls onto a reliable totally ordered multicast group communication system. No modification to the internal structure of the ORB is necessary, and fault tolerance is provided in a manner that is transparent to both the application and the ORB.", "num_citations": "76\n", "authors": ["516"]}
{"title": "Providing support for survivable CORBA applications with the Immune system\n", "abstract": " The Immune system aims to provide survivability to CORBA applications, enabling them to continue to operate despite malicious attacks, accidents or faults. Every object within the CORBA application is actively replicated by the Immune system, with majority voting applied on incoming invocations and responses to each replica of the object. Secure multicast protocols are employed to enable the majority voting to be effective, even when processors within the network and objects within the application become corrupted.", "num_citations": "73\n", "authors": ["516"]}
{"title": "Eternal\u2014a component\u2010based framework for transparent fault\u2010tolerant CORBA\n", "abstract": " Enterprises are increasingly involved in worldwide round\u2010the\u2010clock e\u2010commerce and e\u2010business, which requires them to be operational 24 hours per day, 7 days per week. With outages leading to loss of revenue, reputation and customers, fault tolerance becomes increasingly important. By mixing the fault tolerance logic into the application logic, existing fault tolerance practices render applications more complex, more prone to errors, and more difficult to maintain and build. The Eternal system is a component\u2010based middleware framework that provides transparent fault tolerance for enterprise applications, and that ensures continuous 24\\times7 operation without requiring special skills of the application programmers. The Eternal system implements the new Fault\u2010Tolerant CORBA standard. Copyright\u00a9 2002 John Wiley & Sons, Ltd.", "num_citations": "67\n", "authors": ["516"]}
{"title": "A fault tolerance framework for CORBA\n", "abstract": " We describe a fault tolerance framework for CORBA that provides fault tolerance management and core services, implemented above the ORB for ease of use and customization, and fault tolerance mechanisms, implemented beneath the ORB for transparency and efficiency. Strong replica consistency is facilitated by a multicast engine that provides reliable totally ordered delivery of multicast messages to the replicas of an object. Transparency to the application allows application programmers to focus on their applications rather than on fault tolerance, and transparency to the ORE allows existing commercial CORBA ORBs to be used without modification. The fault tolerance framework adheres to CORBA's objective of interoperability by ensuring that different implementations of the specifications of the framework can interoperate and that non-fault-tolerant objects can interwork with fault-tolerant objects.", "num_citations": "66\n", "authors": ["516"]}
{"title": "Reconciling replication and transactions for the end-to-end reliability of CORBA applications\n", "abstract": " The CORBA standard now incorporates support for reliability through two distinct mechanisms \u2014 replication (using the Fault Tolerant CORBA standard) and transactions (using the CORBA Object Transaction Service). Transactions represent a roll-back reliability mechanism, and handle a fault by reverting to the last committed state, and by discarding operations that were in progress at the time of the fault. Replication represents a roll-forward reliability mechanism, and handles a fault by re-playing any operations that were in progress at another operational replica of the crashed server. Most of today\u2019s enterprise applications have a three-tier structure, with simple clients in the first tier, servers in the middle-tier to perform the processing, and databases in the third tier to store information. For such applications, replication is required to protect the middle-tier processing, while transactions are required to\u00a0\u2026", "num_citations": "58\n", "authors": ["516"]}
{"title": "State synchronization and recovery for strongly consistent replicated CORBA objects\n", "abstract": " The Eternal system provides transparent fault tolerance for CORBA applications, without requiring the modification of either the application or the ORB. Eternal replicates the application objects, and ensures strong replica consistency by employing reliable totally-ordered multicast messages for conveying the IIOP messages of the application. To maintain replica consistency even as replicas fail and are recovered, Eternal ensures the retrieval, assignment and transfer of the three kinds of state, application-level, ORB/POA-level and infrastructure-level state, that are associated with each replicated object. Eternal's mechanisms for recovery include the synchronization of the the state retrieval and the state assignment messages, as well as the logging and replay of messages and checkpoints.", "num_citations": "54\n", "authors": ["516"]}
{"title": "Strongly consistent replication and recovery of fault-tolerant CORBA applications\n", "abstract": " The Eternal system provides transparent fault tolerance for CORBA applications, without requiring the modification of either the application or the ORB. Eternal replicates the application objects, and ensures strong replica consistency by employing a reliable totally-ordered multicast protocol for conveying the IIOP messages of the application. To achieve strong replica consistency during recovery, Eternal retrieves and transfers the three kinds of state\u2013applicationlevel state, ORB/POA-level state and infrastructure-level state\u2013from an existing replica to a new or recovering replica, and logs and replays messages.", "num_citations": "49\n", "authors": ["516"]}
{"title": "Strong replica consistency for fault-tolerant CORBA applications\n", "abstract": " The Eternal system provides transparent fault tolerance for CORBA applications, without requiring modifications to the application or to the object request broker (ORB), and without requiring special skills of the CORBA application programmers. Eternal maintains strong replica consistency as replicas of objects perform operations, and even as they fail and are recovered. Eternal implements the new fault-tolerant CORBA standard.", "num_citations": "49\n", "authors": ["516"]}
{"title": "The interception approach to reliable distributed CORBA objects\n", "abstract": " The Eternal system is a CORBA 2.0-compliant system that enhances the CORBA standard with replication and thus fault tolerance. The novel interception approach implemented in the Eternal system involves capturing IIOP-specific system calls made by the ORB, and subsequently mapping these calls onto a reliable multicast group communication system. The motivation for the use of this approach is that fault tolerance is transparent to the application objects, as well as to the ORB, and that any commercial ORB can be used with no internal modification. The interception approach exploits the performance of the underlying multicast group communication system to provide good performance.", "num_citations": "43\n", "authors": ["516"]}
{"title": "Precog: prefetching for image recognition applications at the edge\n", "abstract": " Image recognition applications are on the rise. Increasingly, applications on edge devices such as mobile smartphones, drones and cars, are relying on recognition techniques to provide interactive and intelligent functionality. Given the complexity of these techniques, and resource constrained nature of edge devices, applications rely on offloading compute intensive recognition tasks to the cloud. This has also lead to the rise of cloud-based recognition services. This involves sending captured images to remote servers across the Internet, which leads to slower responses. With the rising numbers of edge devices, both, the network and such centralized cloud-based solutions, are likely to be under stress, and lead to further slower responses. To reduce the recognition latency, and provide better scalability to the cloud-based solutions, we propose Precog. Precog employs selective computation on the devices to\u00a0\u2026", "num_citations": "42\n", "authors": ["516"]}
{"title": "Diagnosis in Automotive Systems: A Survey\n", "abstract": " Modern automotive electronic control systems are distributed, networked embedded systems. Diagnostic routines implemented on individual components cannot adequately identify the true cause of anomalous behavior because their view is restricted to component-local information. A growing trend in diagnostics research for these systems is to use system-level approaches to diagnose anomalous behavior and provide a consistent, global view of the system\u2019s health. Current approaches are typically motivated by a desire to improve either off-line maintenance or run-time safety.Acknowledgements: This research was supported in part by General Motors Company.", "num_citations": "42\n", "authors": ["516"]}
{"title": "Performance troubleshooting in data centers: an annotated bibliography?\n", "abstract": " In the emerging cloud computing era, enterprise data centers host a plethora of web services and applications, including those for e-Commerce, distributed multimedia, and social networks, which jointly, serve many aspects of our daily lives and business. For such applications, lack of availability, reliability, or responsiveness can lead to extensive losses. For instance, on June 29th 2010, Amazon. com experienced three hours of intermittent performance problems as the normally reliable website took minutes to load items, and searches came back without product links. Customers were also unable to place orders. Based on their 2010 quarterly revenues, such downtime could cost Amazon up to $1.75 million per hour, thus making rapid problem resolution critical to its business. In another serious incident, on July 7th, 2010, DBS bank in Singapore suffered a 7-hour outage which crippled its Internet banking systems\u00a0\u2026", "num_citations": "41\n", "authors": ["516"]}
{"title": "Failure diagnosis of complex systems\n", "abstract": " Failure diagnosis is the process of identifying the causes of impairment in a system\u2019s function based on observable symptoms, i.e., determining which fault led to an observed failure. Since multiple faults can often lead to very similar symptoms, failure diagnosis is often the first line of defense when things go wrong - a prerequisite before any corrective actions can be undertaken. The results of diagnosis also provide data about a system\u2019s operational fault profile for use in offline resilience evaluation. While diagnosis has historically been a largely manual process requiring significant human input, techniques to automate as much of the process as possible have significantly grown in importance in many industries including telecommunications, Internet services, automotive systems, and aerospace. This chapter presents a survey of automated failure diagnosis techniques including both model-based and model\u00a0\u2026", "num_citations": "41\n", "authors": ["516"]}
{"title": "Proactive recovery in distributed corba applications\n", "abstract": " Unanticipated runtime events, such as faults, can lead to missed deadlines in real-time systems. While it is not always possible to know when a fault will occur, we can sometimes exploit pre-fault \"symptoms\" to initiate proactive (rather than reactive) fault-recovery. In this paper, we describe the design and implementation of a proactive recovery strategy for distributed CORBA applications in the presence of resource-exhaustion faults. We analyze the effect of different proactive recovery schemes on client/server response times, and we demonstrate a significant reduction, both in jitter and in the number of client-side failures.", "num_citations": "40\n", "authors": ["516"]}
{"title": "To upgrade or not to upgrade: impact of online upgrades across multiple administrative domains\n", "abstract": " Online software upgrades are often plagued by runtime behaviors that are poorly understood and difficult to ascertain. For example, the interactions among multiple versions of the software expose the system to race conditions that can introduce latent errors or data corruption. Moreover, industry trends suggest that online upgrades are currently needed in large-scale enterprise systems, which often span multiple administrative domains (eg, Web 2.0 applications that rely on AJAX client-side code or systems that lease cloud-computing resources). In such systems, the enterprise does not control all the tiers of the system and cannot coordinate the upgrade process, making existing techniques inadequate to prevent mixed-version races. In this paper, we present an analytical framework for impact assessment, which allows system administrators to directly compare the risk of following an online-upgrade plan with the\u00a0\u2026", "num_citations": "38\n", "authors": ["516"]}
{"title": "Experiences with a CANoe-based fault injection framework for AUTOSAR\n", "abstract": " Standardized software architectures, such as AUTomotive Open System ARchitecture (AUTOSAR), are being pursued within the automotive industry in order to reduce the cost of developing new vehicle features. Many of these features will need to be highly dependable. Fault injection plays an important role during the dependability analysis of such software. This work evaluates the feasibility of leveraging the CANoe simulation environment to develop software-based methods for injecting faults into AUTOSAR applications. We describe a proof-of-concept fault-injection framework with example fault-injection scenarios, as well as implementation issues faced and addressed, lessons learned, and the suitability of using CANoe as a fault-injection environment.", "num_citations": "38\n", "authors": ["516"]}
{"title": "Smartphone-based assistive technologies for the blind\n", "abstract": " This paper describes our experiences with developing cost-effective assistive technologies for the visually impaired, with a focus on using commercial off-the-shelf technologies as much as possible. Trinetra involves three specific technologies--the grocery shopping assistant, the currency identifier and the transportation assistant--all supported on standard mobile phones with text-to-speech, commonly used by the visually impaired.", "num_citations": "34\n", "authors": ["516"]}
{"title": "Krowd: A key-value store for crowded venues\n", "abstract": " Attendees of live events want to capture and share rich content using their mobile devices, during the events. However, the infrastructure at venues that host live events provide poor, low-bandwidth connectivity. Instead of relying on infrastructure provided by the venue, we propose to stand up a temporary\" infrastructure\" using the very devices that need it, to enable content-sharing with nearby devices. To this end, we developed Krowd, a novel system that provides a key-value store abstraction to applications that share content among local, nearby users. We evaluated Krowd using over 200 hours of real-world traces from sold-out NBA and NHL playoffs and show that it is 50% faster and consumes 50% less bandwidth than alternative systems. We believe that Krowd is the only decentralized and distributed system to provide a key-value store made for neighboring mobile devices and of neighboring mobile devices.", "num_citations": "30\n", "authors": ["516"]}
{"title": "Theia: Visual signatures for problem diagnosis in large Hadoop clusters\n", "abstract": " Diagnosing performance problems in large distributed systems can be daunting as the copious volume of monitoring information available can obscure the root-cause of the problem. Automated diagnosis tools help narrow down the possible root-causes\u2014however, these tools are not perfect thereby motivating the need for visualization tools that allow users to explore their data and gain insight on the root-cause. In this paper we describe Theia, a visualization tool that analyzes application-level logs in a Hadoop cluster, and generates visual signatures of each job's performance. These visual signatures provide compact representations of task durations, task status, and data consumption by jobs. We demonstrate the utility of Theia on real incidents experienced by users on a production Hadoop cluster.", "num_citations": "29\n", "authors": ["516"]}
{"title": "Fingerpointing correlated failures in replicated systems\n", "abstract": " Replicated systems are often hosted over underlying group communication protocols that provide totally ordered, reliable delivery of messages. In the face of a performance problem at a single node, these protocols can cause correlated performance degradations at even non-faulty nodes, leading to potential red herrings in failure diagnosis. We propose a fingerpointing approach that combines node-level (local) anomaly detection, followed by system-wide (global) fingerpointing. The local anomaly detection relies on threshold-based analyses of system metrics, while global fingerpointing is based on the hypothesis that the root-cause of the failure is the node with an \u201codd-man-out\u201d view of the anomalies. We compare the results of applying three classifiers\u2013a heuristic algorithm, an unsupervised learner (k-means clustering), and a supervised learner (k-nearest-neighbor)\u2013to fingerpoint the faulty node.", "num_citations": "29\n", "authors": ["516"]}
{"title": "Systems and methods for providing interactive video services\n", "abstract": " An apparatus includes a plurality of content sources providing content relevant to an event at a venue, one or more wireless access points positioned at the venue, a plurality of servers distributing the content signals to the wireless access points, and a plurality of wireless communication devices, each using a browser to retrieve the content through one of the wireless access points. A method performed by the apparatus is also provided.", "num_citations": "28\n", "authors": ["516"]}
{"title": "Living with nondeterminism in replicated middleware applications\n", "abstract": " Application-level nondeterminism can lead to inconsistent state that defeats the purpose of replication as a fault-tolerance strategy. We present Midas, a new approach for living with nondeterminism in distributed, replicated, middleware applications. Midas exploits (i) the static program analysis of the application\u2019s source code prior to replica deployment and (ii) the online compensation of replica divergence even as replicas execute. We identify the sources of nondeterminism within the application, discriminate between actual and superficial nondeterminism, and track the propagation of actual nondeterminism. We evaluate our techniques for the active replication of servers using micro-benchmarks that contain various sources (multi-threading, system calls and propagation) of nondeterminism.", "num_citations": "25\n", "authors": ["516"]}
{"title": "Light-weight black-box failure detection for distributed systems\n", "abstract": " Detecting failures in distributed systems is challenging, as modern datacenters run a variety of applications. Current techniques for detecting failures often require training, have limited scalability, or have results that are hard to interpret. We present LFD, a light-weight technique to quickly detect performance problems in distributed systems using only correlations of OS metrics. LFD is based on our hypothesis of server application behavior, does not require training, and detects failures with complexity linear in the number of nodes, with results that are interpretable by sysadmins. We further show that LFD is versatile, and can diagnose faults in Hadoop MapReduce systems and on multi-tier web request systems, and show how LFD is intuitive to sysadmins.", "num_citations": "24\n", "authors": ["516"]}
{"title": "Eye of the Beholder: Phone-based text-recognition for the visually-impaired\n", "abstract": " Blind and visually-impaired people cannot access essential information in the form of written text in our environment (e.g., on restaurant menus, street signs, door labels, product names and instructions, expiration dates). In this paper, we present and evaluate a mobile text-recognition system capable of extracting written information from a wide variety of sources and communicating it on-demand to the user. The user needs no additional hardware except an ordinary, Internet- enabled mobile camera-phone - a device that many visually-impaired individuals already own. This approach fills a gap in assistive technologies for the visually- impaired because it makes users aware of textual information not available to them through any other means.", "num_citations": "24\n", "authors": ["516"]}
{"title": "Fault-tolerant architectures for space and avionics applications\n", "abstract": " Over the past half century, computing systems have experienced over three orders of magnitude improvement in average time to failure and over seven orders of magnitude improvement in work accomplished between outages. This paper surveys, compares and contrasts the architectural techniques used to improve system reliability in space and avionics applications. The generic techniques are instantiated by actual system examples taken from the space and avionics domains. The paper concludes by observing trends and projecting future developments.", "num_citations": "24\n", "authors": ["516"]}
{"title": "Trinetra: Assistive technologies for the blind\n", "abstract": " Trinetra aims to develop cost-effective assistive technologies to provide blind people with a greater degree of independence in their daily activities. The overall objective of the Trinetra system is to improve the quality of life for the blind by harnessing the collective capability of diverse networked embedded devices to support navigation, grocery shopping, transportation, etc. This paper describes our research and development of the original Trinetra prototype, a barcode-based solution comprising a combination of off-the-shelf components, such as an Internet-and Bluetooth-enabled cell phone, text-tospeech software and a portable barcode reader. We also describe our experiences with the first deployment and evaluation of Trinetra to aid grocery shopping for the blind at the Carnegie Mellon University\u2019s campus convenience store, Entropy.", "num_citations": "23\n", "authors": ["516"]}
{"title": "Causes of Failure in Web Applications (CMU-PDL-05-109)\n", "abstract": " This report investigates the causes and prevalence of failure in Web applications. Data was collected by surveying case studies of system failures and by examining incidents of website outages listed on technology websites such as CNET. com and eweek. com. These studies suggest that software failures and human error account for about 80% of failures. The report also contains an appendix that serves as a quick reference for common failures observed in Web applications. This appendix lists over 40 incidents of real-world site outages, outlining how these failures were detected, the estimated downtime, and the subsequent recovery action.Acknowledgements: We thank the members and companies of the PDL Consortium (including EMC, Hewlett-Packard, Hitachi, IBM, Intel, Microsoft, Network Appliance, Oracle, Panasas, Seagate, Sun, and Veritas) for their interest, insights, feedback, and support.", "num_citations": "23\n", "authors": ["516"]}
{"title": "Fault tolerant approaches for distributed real-time and embedded systems\n", "abstract": " Fault tolerance (FT) is a crucial design consideration for mission-critical distributed real-time and embedded (DRE) systems, which combine the real-time characteristics of embedded platforms with the dynamic characteristics of distributed platforms. Traditional FT approaches do not address features that are common in DRE systems, such as scale, heterogeneity, real-time requirements, and other characteristics. Most previous R&D efforts in FT have focused on client-server object systems, whereas DRE systems are increasingly based on component-oriented architectures, which support more complex interaction patterns, such as peer-to-peer. This paper describes our current applied R&D efforts to develop FT technology for DRE systems. First, we describe three enhanced FT techniques that support the needs of DRE systems: a transparent approach to mixed-mode communication, auto-configuration of dynamic\u00a0\u2026", "num_citations": "22\n", "authors": ["516"]}
{"title": "Trade-offs between real-time and fault tolerance for middleware applications\n", "abstract": " The OMG\u2019s Real-Time CORBA (RT-CORBA) and Fault-Tolerant CORBA (FT-CORBA) specifications make it possible for today\u2019s CORBA implementations to exhibit either real-time or fault tolerance in isolation. While real-time requires a priori knowledge of the system\u2019s temporal operation, fault tolerance necessarily deals with faults that occur unexpectedly, and with possibly unpredictable fault recovery times. When both realtime and fault-tolerance are required to be satisfied within the same system, it is rather likely that trade-offs are made during the composition. The contribution of this paper is the identification of the conflicts between real-time and fault tolerance.", "num_citations": "22\n", "authors": ["516"]}
{"title": "Benchmarking wireless protocols for feasibility in supporting crowdsourced mobile computing\n", "abstract": " Recent advances in mobile device technology have triggered research on using their aggregate computational and/or storage resources to form edge-clouds. Whilst traditionally viewed as simple clients, smartphones and tablets today have hardware resources that allow more sophisticated software to be installed, and can be used as thick clients or even thin servers. Simultaneously, new standards and protocols, such as Wi-Fi Direct and Wi-Fi TDLS (Tunneled Direct Link Setup), have been established that allow mobile devices to talk directly with each other, as opposed to over the Internet or across Wi-Fi access points. This can, potentially, lead to ubiquitous, low-latency, device-to-device (D2D) communication. In this paper, we study whether D2D protocols can support mobile-edge clouds by benchmarking different protocols and configurations for a specific application. The results show that decentralized\u00a0\u2026", "num_citations": "21\n", "authors": ["516"]}
{"title": "Fault-tolerant middleware and the magical 1%\n", "abstract": " Through an extensive experimental analysis of over 900 possible configurations of a fault-tolerant middleware system, we present empirical evidence that the unpredictability inherent in such systems arises from merely 1% of the remote invocations. The occurrence of very high latencies cannot be regulated through parameters such as the number of clients, the replication style and degree or the request rates. However, by selectively filtering out a \u201cmagical 1%\u201d of the raw observations of various metrics, we show that performance, in terms of measured end-to-end latency and throughput, can be bounded, easy to understand and control. This simple statistical technique enables us to guarantee, with some level of confidence, bounds for percentile-based quality of service (QoS) metrics, which dramatically increase our ability to tune and control a middleware system in a predictable manner.", "num_citations": "21\n", "authors": ["516"]}
{"title": "Architecting and implementing versatile dependability\n", "abstract": " Distributed applications must often consider and select the appropriate trade-offs among three important aspects \u2013 fault-tolerance, performance and resources. We introduce a novel concept, called versatile dependability, that provides a framework for analyzing and reasoning about these trade-offs in dependable software architectures. We present the architecture of a middleware framework that implements versatile dependability by providing the appropriate \u201dknobs\u201d to tune and re-calibrate the trade-offs. Our framework can adjust the properties and the behavior of the system at development-time, at deployment-time, and throughout the application\u2019s life-cycle. This renders the versatile dependability approach useful both to applications that require static fault-tolerance configurations supporting the loss/addition of resources and changing workloads, as well as to applications that evolve in terms of their\u00a0\u2026", "num_citations": "21\n", "authors": ["516"]}
{"title": "The Starfish system: Providing intrusion detection and intrusion tolerance for middleware systems\n", "abstract": " We introduce the Starfish system, a new system that provides intrusion detection and intrusion tolerance for middleware applications operating in an asynchronous distributed system. The Starfish system contains a central, highly secure and tightly coupled core. This core is augmented by \"arms\" that are less tightly coupled and that have less stringent security guarantees, each of which can be removed from the core if a significant security breach occurs. New arms can be \"grown\" as needed. The Starfish system employs a number of techniques for providing intrusion detection and intrusion tolerance. The specific challenges that we address are infrastructural support for voting and end-to-end intrusion detection.", "num_citations": "21\n", "authors": ["516"]}
{"title": "Challenges and opportunities for embedded computing in retail environments\n", "abstract": " In the retail industry, real-time product location tends to be a multi-million-dollar problem because of seasonal restocking, varying store layouts, personnel training, diversity of products, etc. Stores maintain planograms, which are detailed product-level maps of the store layout. Unfortunately, these planograms are obsolete by the time that they are constructed (because it takes weeks to get them right), thereby significantly diminishing their value to the store staff, to consumers, and to product manufacturers/suppliers. The AndyVision project at Carnegie Mellon focuses on the fundamental problem of real-time planogram construction and planogram integrity. This problem, if solved correctly, has the potential to transform the retail industry, both in the back-office operations and in the front-of-the-store consumer experience.", "num_citations": "20\n", "authors": ["516"]}
{"title": "To Auto Scale or not to Auto Scale\n", "abstract": " YinzCam is a cloud-hosted service that provides sports fans with real-time scores, news, photos, statistics, live radio, streaming video, etc., on their mobile devices. YinzCam\u2019s infrastructure is currently hosted on Amazon Web Services (AWS) and supports over 7 million downloads of the official mobile apps of 40+ professional sports teams and venues. YinzCam\u2019s workload is necessarily multi-modal (eg, pre-game, in-game, post-game, game-day, non-gameday, in-season, off-season) and exhibits large traffic spikes due to extensive usage by sports fans during the actual hours of a game, with normal game-time traffic being twenty-fold of that on non-game days.", "num_citations": "19\n", "authors": ["516"]}
{"title": "Exploring symmetric cryptography for secure network reprogramming\n", "abstract": " Recent secure code-update protocols for sensor networks have been based on asymmetric-cryptographic primitives such as digital signatures. Our approach, Castor, explores the feasibility of securing an existing code-update protocol, Deluge, using symmetric-cryptographic mechanisms that are more suited to the resource constraints of sensor nodes. Castor involves a synergistic combination of a oneway hash-chain, a one-way key-chain, and a sequence of message authentication codes (MACs) with delayed key- disclosure to enable sensor nodes to verify the update's authenticity. We guarantee that no correct node will ever install or forward a compromised part of an update, while addressing the performance issues related to delayed key- disclosure.", "num_citations": "19\n", "authors": ["516"]}
{"title": "Assistive embedded technologies\n", "abstract": " Embedded computing technologies are not only an integral part of traditional safety- critical applications such as jet engine and automotive brake control, they are also being used to improve people's quality of life. Trinetra integrates embedded devices to let blind users enjoy cost-effective, independent shopping. The day-to-day needs of a typical blind user greatly influenced our design and evaluation of the Trinetra system. From the beginning, the user of our system also proved instrumental in helping design and tests the system", "num_citations": "19\n", "authors": ["516"]}
{"title": "Message packing as a performance enhancement strategy with application to the Totem protocols\n", "abstract": " Packing a number of messages into a single packet for transmission can be used as a strategy to improve the performance of communication protocols. We investigate this technique and its application to the Totem reliable ordered multicast protocols. The mechanism underlying message packing is also analyzed by means of a buffer model with exponential message lengths and exponential interarrival times between messages. The results obtained from the analysis and from the implementation of this strategy in the Totem protocols show that message packing is a very effective technique for improving the performance, especially for messages of small length.", "num_citations": "19\n", "authors": ["516"]}
{"title": "The Blind Men and the Elephant: Piecing Together Hadoop for Diagnosis\n", "abstract": " Google\u2019s MapReduce framework enables distributed, data-intensive, parallel applications by decomposing a massive job into smaller (Map and Reduce) tasks and a massive data-set into smaller partitions, such that each task processes a different partition in parallel. However, performance problems in a distributed MapReduce system can be hard to diagnose and to localize to a specific node or a set of nodes. On the other hand, the structure of large number of nodes performing similar tasks naturally affords us opportunities for observing the system from multiple viewpoints. We present a \u201cBlind Men and the Elephant\u201d(BliMeE) framework in which we exploit this structure, and demonstrate how problems in a MapReduce system can be diagnose by corroborating the multiple viewpoints. More specifically, we present algorithms within the BliMeE framework based on OS-level performance counters, on white-box metrics extracted from logs, and on application-level heartbeats. We show that our BliMeE algorithms are able to capture a variety of faults including resource hogs and application hangs, and to localize the fault to subsets of slave nodes in the MapReduce system. In addition, we discuss how the diagnostic algorithms\u2019 outcomes can be further synthesized in a repeated application of the BliMeE approach. We present a simple supervised learning technique which allows us to identify a fault if it has been previously observed.", "num_citations": "18\n", "authors": ["516"]}
{"title": "Architectural support for mode-driven fault tolerance in distributed applications\n", "abstract": " Many distributed applications exhibit different types of system behaviors, or modes, during the course of their operation. Each such mode may have different functional and non-functional requirements (such as fault tolerance, availability, and security). A static software fault-tolerance solution can not cater to the needs of every mode, and also does not utilize system resources intelligently. A flexible architecture is required to provide dependability that can be tailored for such applications. We propose a novel mode-driven fault-tolerance approach that includes:(i) a generic framework to extend the specification of modes with fault-tolerance requirements, and (ii) a software architecture that uses this description to provide the appropriate fault tolerance for each mode at runtime. We also present a case study using a distributed multi-modal CORBA application to demonstrate the effectiveness of our approach.", "num_citations": "17\n", "authors": ["516"]}
{"title": "Gateways for accessing fault tolerance domains\n", "abstract": " Enterprise applications can be structured as domains, where each domain contains objects that are replicated for fault tolerance, with the replication being managed by a fault tolerance infrastructure local to the domain. Gateways can allow unreplicated clients to benefit from the fault tolerance services of the replicated servers, without compromising replica consistency within the fault tolerance domain. For CORBA-based enterprise applications, the gateway mechanisms can be implemented transparently to the ORB and to the application using interception; specific enhancements to existing ORBs make it possible for unreplicated clients to enjoy a higher degree of reliability.", "num_citations": "16\n", "authors": ["516"]}
{"title": "Multicast group communication for CORBA\n", "abstract": " Multicast group communication is a useful augmentation to CORBA both for fault-tolerant and highly available applications and for groupware and cooperative work applications. However, different multicast group communication protocols are appropriate in different environments, e.g. local area vs. wide area networks, and Internet vs. ATM. In this paper, we present a multicast group communication engine and bridge for CORBA that allows different multicast group communication protocols to cooperate. The group communication engine places Lamport timestamps on messages, and multicasts messages to object groups using one or more group communication protocols. The group communication protocols reliably deliver the timestamped messages in timestamp order to the group communication engine, which integrates these streams of messages into a single stream for delivery in timestamp order.", "num_citations": "16\n", "authors": ["516"]}
{"title": "Gumshoe: Diagnosing performance problems in replicated file-systems\n", "abstract": " Replicated file-systems can experience degraded performance that might not be adequately handled by the underlying fault-tolerant protocols. We describe the design and implementation of Gumshoe, a system that aims to diagnose performance problems in replicated file-systems. Gumshoe periodically gathers OS and protocol metrics and then analyzes these metrics to automatically localize the performance problem to the culprit node(s). We describe our results and experiences with problem diagnosis in two replicated file-systems (replicated-CoreFS and BFS) using two file-system benchmarks (Postmark and IOzone).", "num_citations": "15\n", "authors": ["516"]}
{"title": "Proactive containment of malice in survivable distributed systems\n", "abstract": " The uncontrolled propagation of faults due to malicious intrusion can severely decrease system performance and survivability. Our goal is to employ available information about known or suspected faults in order to provide collusionavoidance and epidemic-avoidance. We proactively make use of knowledge of faults to notify potentially damaged areas of the system, in order to contain the tainted parts. Our objective is to lessen the impact of an intrusion, by spreading the performance cost of recovery over a controlled period of time.", "num_citations": "15\n", "authors": ["516"]}
{"title": "Ecotopia: An ecological framework for change management in distributed systems\n", "abstract": " Dynamic change management in an autonomic, service-oriented infrastructure is likely to disrupt the critical services delivered by the infrastructure. Furthermore, change management must accommodate complex real-world systems, where dependability and performance objectives are managed across multiple distributed service components and have specific criticality/value models. In this paper, we present Ecotopia, a framework for change management in complex service-oriented architectures (SOA) that is ecological in its intent: it schedules change operations with the goal of minimizing the service-delivery disruptions by accounting for their impact on the SOA environment. The change-planning functionality of Ecotopia is split between multiple objective-advisors and a system-level change-orchestrator component. The objective advisors assess the change-impact on service delivery by estimating the\u00a0\u2026", "num_citations": "14\n", "authors": ["516"]}
{"title": "Disseminating Code Updates in Sensor Networks: Survey of Protocols and Security Issues\n", "abstract": " Network reprogramming allows for over-the-air application updates in sensor networks. We describe the operation of a number of network reprogramming protocols that have emerged for the TinyOS sensor network operating system. We go on to discuss potential security issues that arise from the operation of network reprogramming protocols.", "num_citations": "14\n", "authors": ["516"]}
{"title": "Decentralized Resource Management and Fault-Tolerance for Distributed CORBA Applications.\n", "abstract": " Assigning an application\u2019s fault-tolerance properties (eg, replication style, checkpointing frequency) statically, and in an arbitrary manner, can lead to the application not achieving its target resilience and performance. The resource management infrastructure that we have developed transparently determines a CORBA application\u2019s resource usage and its rate/pattern of invocation across a distributed system. Using this information, our infrastructure makes more informed decisions about the application\u2019s fault-tolerance properties, and dynamically adapts these decisions, as faults occur, and as resources are added and removed from the system. We have designed our prototype to be decentralized so that it is scalable and does not itself constitute a single point of failure.", "num_citations": "14\n", "authors": ["516"]}
{"title": "Experiences with fault-injection in a Byzantine fault-tolerant protocol\n", "abstract": " The overall performance improvement in Byzantine fault-tolerant state machine replication algorithms has made them a viable option for critical high-performance systems. However, the construction of the proofs necessary to support these algorithms are complex and often make assumptions that may or may not be true in a particular implementation. Furthermore, the transition from theory to practice is difficult and can lead to the introduction of subtle bugs that may break the assumptions that support these algorithms. To address these issues we have developed Hermes, a fault-injector framework that provides an infrastructure for injecting faults in a Byzantine fault-tolerant state machine. Our main goal with Hermes is to help practitioners in the complex process of debugging their implementations of these algorithms, and at the same time increase the confidence of possible adopters, e.g., systems\u00a0\u2026", "num_citations": "13\n", "authors": ["516"]}
{"title": "No downtime for data conversions: Rethinking hot upgrades\n", "abstract": " Unavailability in enterprise systems is usually the result of planned events, such as upgrades, rather than failures. Major system upgrades entail complex data conversions that are difficult to perform on the fly, in the face of live workloads. Minimizing the downtime imposed by such conversions is a time-intensive and error-prone manual process. We present Imago, a system that aims to simplify the upgrade process, and we show that it can eliminate all the causes of planned downtime recorded during the upgrade history of one of the ten most popular websites. Building on the lessons learned from past research on live upgrades in middleware systems, Imago trades off a need for additional storage resources for the ability to perform end-to-end, enterprise upgrades online, with minimal application-specific knowledge.Acknowledgements: We would like to thank Alan Downing, Jim Stamos and Byron Wang of Oracle for their feedback during the early stage of this research project.", "num_citations": "13\n", "authors": ["516"]}
{"title": "Lightweight Fault-Tolerance for Peer-to-Peer Middleware\n", "abstract": " We address the problem of providing transparent, lightweight, fault-tolerance mechanisms for generic peer-to-peer middleware systems. The main idea is to use the peer-to-peer overlay to provide for fault-tolerance rather than support it higher up in the middleware architecture, e.g. in the form of services. To evaluate our approach we have implemented a fault-tolerant middleware prototype that uses a hierarchical peer-to-peer overlay in which the leaf peers connect to sensors that provide data streams. Clients connect to the root of the overlay and request streams that are routed upwards through intermediate peers in the overlay up to the client. We report encouraging preliminary results for latency, jitter and resource consumption for both the non-faulty and faulty cases.", "num_citations": "12\n", "authors": ["516"]}
{"title": "Behavior-based problem localization for parallel file systems\n", "abstract": " We present a behavior-based problem-diagnosis approach for PVFS that analyzes a novel source of instrumentation\u2014CPU instruction-pointer samples and function-call traces\u2014to localize the faulty server and to enable root-cause analysis of the resource at fault. We validate our approach by injecting realistic storage and network problems into three different workloads (dd, IO-zone, and PostMark) on a PVFS cluster.", "num_citations": "12\n", "authors": ["516"]}
{"title": "Transparent system call based performance debugging for cloud computing\n", "abstract": " Problem diagnosis and debugging in distributed environments such as the cloud and popular distributed systems frameworks has been a hard problem. We explore an evaluation of a novel way of debugging distributed systems, such as the MapReduce framework, by using system calls. Performance problems in such systems can be hard to diagnose and to localize to a specific node or a set of nodes. Additionally, most debugging systems often rely on forms of instrumentation and signatures that sometimes cannot truthfully represent the state of the system (logs or application traces for example). We focus on evaluating the performance debugging of these frameworks using a low level of abstraction-system calls. By focusing on a small set of system calls, we try to extrapolate meaningful information on the control flow and state of the framework, providing accurate and meaningful automated debugging.", "num_citations": "11\n", "authors": ["516"]}
{"title": "Static analysis meets distributed fault-tolerance: enabling state-machine replication with nondeterminism\n", "abstract": " Midas is an inter-disciplinary approach to supporting state-machine replication for nondeterministic distributed applications. The approach exploits compile-time static analysis to identify both first-hand and second-hand sources of nondeterminism. Subsequent runtime compensation occurs through either the transfer of nondeterministic checkpoints or the reexecution of inserted code, and restores consistency among replicas before each new client request. The approach avoids the need for lock-step synchronization and leverages application-level insight to address only the nondeterminism that matters. Our preliminary evaluation demonstrates Midas\u2019 feasibility and current performance overheads.", "num_citations": "11\n", "authors": ["516"]}
{"title": "Using program analysis to identify and compensate for nondeterminism in fault-tolerant, replicated systems\n", "abstract": " Fault-tolerant replicated applications are typically assumed to be deterministic, in order to ensure reproducible, consistent behavior and state across a distributed system. Real applications often contain nondeterministic features that cannot be eliminated. Through the novel application of program analysis to distributed CORBA applications, we decompose an application into its constituent structures, and discover the kinds of nondeterminism present within the application. We target the instances of nondeterminism that can be compensated for automatically, and highlight to the application programmer those instances of nondeterminism that need to be manually rectified. We demonstrate our approach by compensating for specific forms of nondeterminism and by quantifying the associated performance overheads. The resulting code growth is typically limited to one extra line for every instance of nondeterminism, and\u00a0\u2026", "num_citations": "11\n", "authors": ["516"]}
{"title": "Middleware for embedded adaptive dependability\n", "abstract": " The Middleware for Embedded Adaptive Dependability (MEAD) infrastructure enhances large-scale distributed real-time embedded middleware applications with novel capabilities, including (i) transparent, yet tunable, fault tolerance in real time,(ii) proactive dependability,(iii) resource-aware system adaptation to crash, communication, partitioning and timing faults with (iv) scalable and fast fault-detection and fault-recovery.", "num_citations": "11\n", "authors": ["516"]}
{"title": "Hardware performance counter-based problem diagnosis for e-commerce systems\n", "abstract": " Black-box instrumentation can support problem diagnosis in distributed systems without the need to modify the application code or to understand its semantics. We explore a novel, low-overhead black-box instrumentation source - CPU/hardware performance counters - for problem diagnosis. Based on our hypothesis that performance problems manifest as observable, anomalous changes in CPU performance counter-values collected across the nodes of a distributed system, we develop a diagnosis approach that is able to detect and localize performance problems injected into RUBiS, a three-tier e-commerce system.", "num_citations": "10\n", "authors": ["516"]}
{"title": "Lessons learned in building a fault-tolerant CORBA system\n", "abstract": " The Eternal system pioneered the interception approach to providing transparent fault tolerance for CORBA, which allows it to make a CORBA application reliable with little or no modification to the application or the ORB. The design and implementation of the Eternal system has influenced industrial practices by providing the basis for the specifications of the fault-tolerant CORBA standard that the Object Management Group adopted. We discuss our experience in developing the Eternal system, with particular emphasis on the challenges that we encountered and the lessons that we learned.", "num_citations": "10\n", "authors": ["516"]}
{"title": "Consistency of partitionable object groups in a CORBA framework\n", "abstract": " The Eternal system provides a novel methodology for the consistent replication of objects in an adaptive, fault-tolerant, CORBA-compliant distributed system that is susceptible to partitioning. Passive and active replication schemes are supported in Eternal, and mechanisms are provided for the interaction of objects with different replication schemes. Nested operations for both passive and active objects are accommodated. Suppression of duplicate operations is ensured by unique message and operation identifiers. Continued operation is allowed in all components of a partitioned system. State transfer mechanisms and fulfillment operations restore the consistency of the states of replicas within the components of a partitioned system when communication is reestablished and the components remerge.", "num_citations": "10\n", "authors": ["516"]}
{"title": "Object-oriented programming of complex fault-tolerant real-time systems\n", "abstract": " The challenge is to build, on top of standard operating systems, complex fault tolerant real time systems that operate fast enough to meet real time deadlines even under fault conditions, using an approach that simplifies the application programming. The Realize system, being developed at the University of California, Santa Barbara, aims to meet that challenge.", "num_citations": "10\n", "authors": ["516"]}
{"title": "Zephyr: First-person wireless analytics from high-density in-stadium deployments\n", "abstract": " Zephyr is a first-person wireless-performance data-collection approach to study the end-user's perspective of the wireless-network's performance using an OTT video-streaming service used in 35 mobile applications and 25 sports stadiums. We use Zephyr to provide insights into user behavior and user disengagement from production traces gathered over 2+ years. We identify the different types of failures that we've observed, and describe how frequently they occur. Finally, we correlate low-level Wi-Fi performance data with application-level failures and describe the trends that we observe. The data from Zephyr reveals that 50% of users disengage if video playback does not begin within 12 seconds, and also if video playback stalls, instream, for more than 6 seconds. The most dominant failure type for video playback is cancellation during the initial buffering phase, which accounts for 30% of all streams.", "num_citations": "9\n", "authors": ["516"]}
{"title": "Towards fingerpointing in the emulab dynamic distributed system\n", "abstract": " In the large-scale Emulab distributed system, the many failure reports make skilled operator time a scarce and costly resource, as shown by statistics on failure frequency and root cause. We describe the lessons learned with error reporting in Emulab, along with the design, initial implementation, and results of a new local erroranalysis approach that is running in production. Through structured error reporting, association of context with each error-type, and propagation of both error-type and context, our new local analysis locates the most prominent failure at the procedure, script, or session level. Evaluation of this local analysis for a targeted set of common Emulab failures suggests that this approach is generally accurate and will facilitate global fingerpointing, which will aim for reliable suggestions as to the root-cause of the failure at the system level.", "num_citations": "9\n", "authors": ["516"]}
{"title": "Separation of concerns: functionality vs. quality of service\n", "abstract": " The development of complex future applications will depend on the separation of concerns between the functional behavior of the application, probably represented by an object-oriented program, and the resource management of the application. In particular, effective fault tolerance will depend on hiding the replication of objects and their distribution to multiple processors.", "num_citations": "9\n", "authors": ["516"]}
{"title": "YinzCam: Experiences with in-venue mobile video and replays\n", "abstract": " YinzCam allows sport fans inside NFL/NHL/NBA venues to enjoy replays and live-camera angles from different perspectives, on their smartphones. We describe the evolution of the system infrastructure, starting from the initial installation in 2010 at one venue, to its use across a dozen venues today. We address the challenges of scaling the system through a combination of techniques, including distributed monitoring, remote administration, and automated replay-generation. In particular, we take an in-depth look at our unique automated replay-generation, including the dashboard, the remote management, the remote administration, and the resulting efficiency, using data from a 2013 NBA Playoffs game.", "num_citations": "8\n", "authors": ["516"]}
{"title": "Trone: Trustworthy and resilient operations in a network environment\n", "abstract": " Cloud infrastructures play an increasingly important role for telecom operators, because they enable internal consolidation of resources with the corresponding savings in hardware and management costs. However, this same consolidation exposes core services of the infrastructure to very disruptive attacks. This is indeed the case with monitoring, which needs to be dependable and secure to ensure proper operation of large datacenters and cloud infrastructures. We argue that currently existing centralized monitoring approaches (e.g., relying on a single solution provider, using single point of failure components) represent a huge risk, because a single vulnerability may compromise the entire monitoring infrastructure. In this paper, we describe the TRONE approach to trustworthy monitoring, which relies on multiple components to achieve increased levels of reliance on the monitoring data and hence increased\u00a0\u2026", "num_citations": "8\n", "authors": ["516"]}
{"title": "Real-time tracking of game assets in American football for automated camera selection and motion capture\n", "abstract": " In fast-paced games like American football, the action (and the viewers\u2019 interest) often revolves around the location of key game assets, such as the football. It is difficult to track the football because it is often obscured or moving rapidly, essentially meaning that the broadcast-camera operators must manually track the football to provide feeds of the most interest. In this paper we describe the design and implementation of sensor-system that uses received signal strength data from multiple strategically placed sensor nodes to localize the game asset to an accurate camera region within a latency of 100ms. Using this real-time localization strategy, we can automate the control of broadcast cameras even in a fast-paced game with dramatically gamechanging moments (such as a kickoff return for a touchdown). This paper describes the design of the sensors, the network protocol, and the architecture of a deployable\u00a0\u2026", "num_citations": "8\n", "authors": ["516"]}
{"title": "Service-Oriented Computing-ICSOC 2007: Fifth International Conference, Vienna, Austria, September 17-20, 2007, Proceedings\n", "abstract": " Thisvolumecontainsallofthe Research-Track, Industry-TrackandDemo-Track papers that were selected for presentation at the Fifth International Conference on Service-Oriented Computing (ICSOC 2007), which was held in Vienna, A-tria, September 17\u201320, 2007. ICSOC 2007 followed the footsteps of four previous successful editions of the International Conference on Service-Oriented Computing that were held in Chicago, USA (2006), Amsterdam, TheNetherlands (2005), NewYorkCity, USA (2004) and Trento, Italy (2003). ICSOC is recognized as the? agship conference for service-oriented computing research and best practices. ICSOC covers the entire spectrum from theoretical and foundational results to empirical eval-tion, as well as practical and industrial experiences. ICSOC 2007 continued this tradition while introducing several new themes to further these goals. Service-orientedcomputingbringstogetherideasandtechnologiesfrommany diverse? elds in an evolutionary manner in order to address research challenges including service-based application modeling, service composition, discovery,-tegration, monitoring and management of services, service quality and security, methodologies for supporting service development, grid services, and novel t-ics including information as a service and service-oriented architecture (SOA) governance. To provide a balanced coverage and an equal emphasis across all aspects of service-oriented computing, ICSOC 2007\u2019s topics were divided into seven major areas: Business Service Modeling, Service Assembly, and Service Management, addressing research issues and best practices in the primary\u00a0\u2026", "num_citations": "8\n", "authors": ["516"]}
{"title": "Nondeterminism in ORBs: The perception and the reality\n", "abstract": " Nondeterminism is a source of problems for distributed replication because it makes it difficult to keep replicas consistent as they execute, process invocations and modify their internal states. Even if a middleware application is completely deterministic, the underlying middleware, e.g., the ORB, can continue to remain a source of nondeterminism. The paper presents our analysis of an open-source ORB from the viewpoint of nondeterminism. Our approach identifies the various sources of nondeterminism within the ORB. Our results demonstrate that while ORBs can contain several apparently nondeterministic system calls and functions, only a fraction of them manifest as actual nondeterminism and pose a threat to replica consistency", "num_citations": "8\n", "authors": ["516"]}
{"title": "Secure dissemination of code updates in sensor networks\n", "abstract": " Existing code update protocols target efficiency and assume correct behavior from participating sensor nodes. This work aims for the progressive, resource sensitive verification of code updates in sensor networks to ensure that unauthorized updates from malicious nodes are not propagated, while correct updates continue to be efficiently disseminated.", "num_citations": "8\n", "authors": ["516"]}
{"title": "Toward upgrades-as-a-service in distributed systems\n", "abstract": " Unavailability in distributed enterprise systems is usually the result of planned events, such as upgrades, rather than failures. Major system upgrades entail complex data conversions that are difficult to perform on the fly, in the face of live workloads. Minimizing the downtime imposed by such conversions is a time-intensive and error-prone manual process. We propose upgrades-as-a-service, a novel approach that can eliminate all the causes of planned downtime recorded during the upgrade history of one of the ten most popular websites. Building on the lessons learned from past research on live upgrades in middleware systems, upgrades-as-a-service trade off a need for additional hardware resources during the upgrade for the ability to perform end-to-end upgrades online, with minimal application-specific knowledge.", "num_citations": "7\n", "authors": ["516"]}
{"title": "System-call based problem diagnosis for PVFS\n", "abstract": " We present a syscall-based approach to automatically diagnose performance problems, server-to-client propagated errors, and server crashhang problems in PVFS. Our approach compares the statistical and semantic attributes of syscalls across PVFS servers in order to diagnose the culprit server, under these problems, for different file-system benchmarks-dd, PostMark and IOzone-in a PVFS cluster.Descriptors:", "num_citations": "7\n", "authors": ["516"]}
{"title": "Prato: databases on demand\n", "abstract": " Database configuration can be a daunting task as database administrators are often presented with a myriad of configuration options that are difficult to sift through. Prato, a project at HP Labs, is a prototype of a self-managing DBMS service provider that eases this burden by using economic incentives to guide automated DBMS setup and management. Prato offers customers private, virtual, DBMS appliances that can each be sized up to several hundred nodes, and made available on demand, in just a few minutes.", "num_citations": "7\n", "authors": ["516"]}
{"title": "Dynamic change management for minimal impact on dependability and performance in autonomic service-oriented architectures\n", "abstract": " Dynamic change management in an autonomic, service-oriented infrastructure is likely to disrupt the critical services delivered by the infrastructure. Furthermore, change management must accommodate complex real-world systems, where dependability and performance objectives are managed across multiple distributed service components. This paper presents a change management framework that enables the assessment and minimization of service delivery disruptions. The framework builds on a few general principles. First, change management systems handle both external change requests, like software upgrades, and changes to mitigate internal events, like faults. Second, the impact on service delivery is assessed as the impact on the business values of the performance and dependability objectives across all services. The goal is to schedule change operations in order to maximize the business value across all service objectives over a long time horizon. These principles are achieved with a distributed design: change operation scheduling and business value optimization are performed by an orchestrator, while the impact assessment on specific objectives is distributed to objective-specific modules that employ domain-specific models for estimation and prediction.", "num_citations": "7\n", "authors": ["516"]}
{"title": "Retrofitting networked applications to add autonomic reconfiguration\n", "abstract": " To reduce user maintenance is an important goal for applications that must dynamically adapt based on their environments. There are many existing popular applications that lack support for this autonomic reconfiguration, but that are beginning to be used in these dynamic environments, in which they must update themselves frequently; not all of these applications will be completely redesigned and redeveloped in order to support autonomic features. In this paper, we explore how to retrofit pre-existing networked applications to add support for autonomic reconfiguration. To illustrate our methods, we retrofit a popular open-source intrusion detection system, Snort, to enable it to reconfigure itself using online program updates and information about its environment.", "num_citations": "7\n", "authors": ["516"]}
{"title": "An architecture for versatile dependability\n", "abstract": " An Architecture for Versatile Dependability Page 1 Carnegie Mellon An Architecture for Versatile Dependability Tudor Dumitra\u015f and Priya Narasimhan Electrical and Computer Engineering Department Carnegie Mellon University USA Page 2 2 Carnegie Mellon \u00a92004 Tudor Dumitra\u015f MEAD: Real-Time Fault-Tolerant Middleware Motivation The requirements of dependable systems are often conflicting Example: meeting deadlines in the presence of faults Meeting deadlines requires a predictable system, while faults are inherently unpredictable! These conflicts must be seen as a trade-off Usually, dependable systems hard-code such trade-offs in their design choices Architectures should become tunable to provide support for: Configuring the system before deployment Adapting to changes in the environment during run-time Maintaining the system throughout its life-cycle Page 3 3 Carnegie Mellon \u00a92004 Tudor \u2026", "num_citations": "7\n", "authors": ["516"]}
{"title": "A middleware for dependable distributed real-time systems\n", "abstract": " New middleware is proposed to support the development of dependable distributed real-time systems for avionics, sensor and shipboard computing. Many of these systems require distributed computing in order to perform increasingly complex missions. They also require real-time performance, dependable software, and may face constraints that limit hardware redundancy. Real-time performance and fault tolerance are not easily combined. A reusable approach to achieving fault tolerance in distributed real-time systems is proposed in MEAD, a Middleware for Embedded Adaptive Dependability.", "num_citations": "7\n", "authors": ["516"]}
{"title": "MetaBot: Automated and dynamically schedulable robotic behaviors in retail environments\n", "abstract": " The ever-increasing popularity of online stores is reshaping traditional commerce models. In particular, brick-and-mortar stores are presently facing the challenge of reinventing themselves and their business models to offer attractive yet low-cost alternatives to e-commerce. Other industries have already introduced new concepts to fight inefficiency (i.e., \u201cJust-in-Time\u201d inventory management in Automotive), retail stores face a more challenging environment which these models cannot accommodate. Stores remain heavily vested in battling the overhead costs of personnel management when, instead, a robotic automation scheme with retail-oriented behaviors could reduce the detection latency of out-of-stock and compliance error phenomena throughout the store. These behaviors must be automated, multi-purpose, and schedulable; they must also ensure that the robot coordinates store nuances to adapt its\u00a0\u2026", "num_citations": "6\n", "authors": ["516"]}
{"title": "Towards a Holistic Approach to Fault Management: Wheels Within a Wheel\n", "abstract": " Systems with high dependability requirements are increasingly relying on complex on-line fault management systems. Such fault management systems involve a combination of multiple steps\u2013monitoring, data analysis, planning, and execution\u2013that are typically independently developed and optimized. We argue that it is inefficient and ineffective to improve any particular fault management step without taking into account its interactions and dependencies with the rest of the steps. Through six real-life examples, we demonstrate this inefficiency and how it results in systems that either under-perform or are over-budget. We propose a holistic approach to fault management that is aware of all relevant aspects, and explicitly considers the couplings between the different fault management steps. We believe it will produce systems that will better meet cost, performance, and dependability objectives.", "num_citations": "6\n", "authors": ["516"]}
{"title": "Group communication: Helping or obscuring failure diagnosis\n", "abstract": " Replicated client-server systems are often based on underlying group communication protocols that provide totally ordered, reliable delivery of messages. However, in the face of a performance fault (eg, memory leak, packet loss) at a single node, group communication protocols can cause correlated performance degradations at non-faulty nodes. We explore the impact of performance-degradation faults on token-ring and quorum-based group communication protocols in replicated systems. By empirically evaluating these protocols, in the presence of a variety of injected faults, we investigate which metrics are the most/least appropriate for failure diagnosis. We show that group communication protocols can both help and obscure root-cause analysis, and present an approach for fingerpointing the faulty node by monitoring OS-level and protocol-level metrics. Our empirical evaluation suggests that the root-cause of the failure is either the node exhibiting the most anomalies in a given window of time or the node with an \u201codd-man-out\u201d behavior, eg, if a node displays a surge in context-switch rate while the other nodes display a dip in the same metric.", "num_citations": "6\n", "authors": ["516"]}
{"title": "Handling cascading failures: the case for topology-aware fault-tolerance\n", "abstract": " Large distributed systems contain multiple components that can interact in sometimes unforeseen and complicated ways; this emergent \u201cvulnerability of complexity\u201d increases the likelihood of cascading failures that might result in widespread disruption. Our research explores whether we can exploit the knowledge of the system\u2019s topology, the application\u2019s interconnections and the application\u2019s normal fault-free behavior to build proactive fault-tolerance techniques that could curb the spread of cascading failures and enable faster system-wide recovery. We seek to characterize what the topology knowledge would entail, quantify the benefits of our approach and understand the associated tradeoffs.", "num_citations": "6\n", "authors": ["516"]}
{"title": "A versatile, proactive dependability approach to handling unanticipated events in distributed systems\n", "abstract": " The MEAD system that we are developing employs a synergistic combination of a reactive and a proactive fault-tolerance approach in order to address unanticipated events and hazards in real-time, fault-tolerant distributed systems. The reactive fault-tolerance approach involves active monitoring of the system to adapt the provided QoS and to allocate resources based on current conditions in the system. The proactive approach involves monitoring both the distributed applications and the network to seek pre-cursors to imminent failures, and then to trigger fault-recovery mechanisms in advance of the occurrence of the failure. The underlying ideas of the MEAD system have demonstrated initial promise through our enhanced capabilities to handle failures and unanticipated events, and to reduce jitter under faulty conditions.", "num_citations": "6\n", "authors": ["516"]}
{"title": "Elephant: Network intrusion detection systems that don't forget\n", "abstract": " Modern Network Intrusion Detection Systems (NIDSs) maintain state that helps them accurately detect attacks. Because most NIDSs are signature-based, it is critical to update their rule-sets frequently; unfortunately, doing so can result in downtime that causes state to be lost, leading to vulnerabilities of attack misclassification. In this paper, we show that such vulnerabilities do exist and provide a way to avoid them. Using the open-source NIDS Snort, we present Elephant, an approach and implementation for updating rule-sets that provides a way to cause Snort to enter a safe quiescent point, load the new rules into memory, and remove the old rules from memory-all while preserving the state that is required to make sure that the NIDS does not miss attacks. We provide a critique and performance evaluation of our technique.", "num_citations": "6\n", "authors": ["516"]}
{"title": "A multicast group communication protocol, engine, and bridge for corba\n", "abstract": " Multicast group communication is needed for fault\u2010tolerant distributed systems and, in particular, for the  new Fault Tolerant CORBA standard, to maintain strong replica consistency. However, different multicast group communication protocols are appropriate for different environments, which makes it difficult to define a single standard multicast protocol. In this paper, we present a multicast group communication engine and bridge for CORBA that allows multiple group communication protocols to be used concurrently. We also present the Fault Tolerant Multicast Protocol, a group communication protocol that allows different fault tolerance systems to interoperate. The group communication engine and bridge places Lamport timestamps on messages, and multicasts messages to groups, using one or more group communication protocols. The group communication protocols reliably deliver the timestamped messages\u00a0\u2026", "num_citations": "6\n", "authors": ["516"]}
{"title": "Interactive shopping experience through immersive store environments\n", "abstract": " In the era of high competition with E-commerce and online shops, brick-and-mortar retail industry seeks new opportunities to enhance shopping experience through engaging technologies. Even though retailers are applying their omnichannel strategies to attract more shoppers through technology-driven solutions including websites, mobile apps, and so forth, we find that these technologies are somewhat basic and do not represent the \u201cdisruptive\u201d innovations. Along with these current technologies, retailers should leverage their store physical real estate, and transform it into immersive store environments (ISEs) that allow shoppers to navigate in 3D store aisles through rich media interface ported onto networked devices. Therefore, we propose our own study of what ISE use-cases are most desirable by customers and retailers in such contexts; we describe the implementation of our cloud-based interactive\u00a0\u2026", "num_citations": "5\n", "authors": ["516"]}
{"title": "Stheno, a real-time fault-tolerant P2P middleware platform for light-train systems\n", "abstract": " Large scale information systems, such as public information systems for light-train/metro networks, must be able to fulfill contractualized Service Level Agreements (SLAs) in terms of end-to-end latencies and jitter, even in the presence of faults. Failure to do so has potential legal and financial implications for the software developers. Current middleware solutions have a hard time coping with these demands due, fundamentally, to a lack of adequate, simultaneous, support for fault-tolerance (FT) and real-time (RT) tasks. In this paper we present Stheno, a general purpose peer-to-peer (P 2 P) middleware system that builds on previous work from TAO and MEAD to provide:(a) configurable, transparent, FT support by taking advantage of the P 2 P layer topology awareness to efficiently implement Common Of The Shelf (COTS) replication algorithms and replica management strategies, and;(b) kernel-level resource\u00a0\u2026", "num_citations": "5\n", "authors": ["516"]}
{"title": "A fault model for upgrades in distributed systems\n", "abstract": " Recent studies, and a large body of anecdotal evidence, suggest that upgrades are unreliable and often end in failure, causing downtime and data-loss. While this is sometimes due to software defects in the new version, most upgradefailures are the result of faults in the upgrade procedure, such as broken dependencies. In this paper, we present data on upgrade failures from three independent sources\u2014a user study, a survey and a field study\u2014and, through statistical cluster analysis, we construct a novel fault model for upgrades in distributed systems. We identify four distinct types of faults:(1) simple configuration errors (eg, typos);(2) semantic configuration errors (eg, misunderstood effects of parameters);(3) broken environmental dependencies (eg, incorrect libraries, port conflicts); and (4) complex procedural errors. We estimate that, on average, Type 1 faults occur in 15.2% of upgrades, and Type 4 faults occur in 16.8% of upgrades.", "num_citations": "5\n", "authors": ["516"]}
{"title": "Fault-tolerant CORBA: From specification to reality\n", "abstract": " Based on 10 years' personal experience implementing academic prototypes of FT-CORBA, helping to establish the FT-CORBA standard, and subsequently developing and selling its commercial implementations, this critique provides an overview of the FT-CORBA standard's specifications from the viewpoint of realizing its concrete implementation for real-world applications", "num_citations": "5\n", "authors": ["516"]}
{"title": "Metrics for the evaluation of proactive and reactive survivability\n", "abstract": " Current Byzantine-fault-tolerant survivable systems [5, 6] rely on strong theoretical properties to guarantee survivability. Evaluations of such systems generally focus on the performance overhead of the mechanisms in the fault-free case: a metric that, in itself, is not a good evaluator of survivability. This dearth of metrics makes the objective comparison of the survivability of different implementations of systems\u2014even those that employ similar algorithms\u2014nearly impossible. To solve this problem, we develop metrics to characterize and evaluate survivability. We intend to employ these metrics to evaluate survivable systems, such as the Starfish system [3], which we are currently developing.If malicious faults propagate faster than traditional reactive mechanisms (which typically wait to detect a fault before reacting to recover from it) are able to recover the system, then, the survivability of the system may ultimately be compromised. This could lead to an epidemic [4]\u2014a situation in which the system is, as a consequence of faults, no longer able to recover. To curtail propagating faults, a system can instead employ proactive survivability [4] mechanisms. P roactively survivable systems differ from reactively survivable systems in that proactive systems may act (i) to increase resistance,(ii) to initiate recovery, or (iii) to adapt: before or concurrently with the recognition of a problem in the system. There are two important categories of operation for any survivable system:(i) the fault-free case; and (ii) the faulty case, under which the system\u2019s resistance\u2014though not necessarily its survivability\u2014has been overcome, ie, a fault, either latent or active, now exists in the\u00a0\u2026", "num_citations": "5\n", "authors": ["516"]}
{"title": "Edge-caches for vision applications\n", "abstract": " One of the thrusts of mobile and pervasive computing is supporting vision-based perception applications. Vision-based applications, such as augmented reality, are those that help users augment their understanding of the physical world through the camera(s) on their mobile devices. Such applications need to provide a seamless experience and hence require minimal end-to-end latency. However, these applications cannot be executed entirely on the devices. The recognition algorithms that these applications utilize, such as feature extraction and matching, need intensive computation and access to \"big data\", such as large labeled image datasets, for them to be fast and accurate. Such data and computational resources are not available locally on the device. Hence, they rely on offloading intensive tasks to the cloud. The devices send captured images to the cloud, which then executes the recognition algorithms\u00a0\u2026", "num_citations": "4\n", "authors": ["516"]}
{"title": "A study of unpredictability in fault-tolerant middleware\n", "abstract": " In enterprise applications relying on fault-tolerant middleware, it is a common engineering practice to establish service-level agreements (SLAs) based on the 95th or the 99th percentiles of the latency, to allow a margin for unexpected variability. However, the extent of this unpredictability has not been studied systematically. We present an extensive empirical study of unpredictability in 16 distributed systems, ranging from simple transport protocols to fault-tolerant, middleware-based enterprise applications, and we show that the inherent unpredictability in the systems examined arises from at most 1% of the remote invocations. In the normal, fault-free operating mode most remote invocations have a predictable end-to-end latency, but the maximum latency follows unpredictable trends and is comparable with the time needed to recover from a fault. The maximum latency is not influenced by the system\u2019s workload\u00a0\u2026", "num_citations": "4\n", "authors": ["516"]}
{"title": "Automated viewer-centric personalized sports broadcast\n", "abstract": " Mobile handheld devices and online media are currently reaching a stage where it is possible to watch streaming video/TV on them, such as a live sports game broadcast. However, current sports broadcast methods are designed to replicate the same feed to many different TV viewers, which makes it difficult to personalize the feed for each individual viewer. Clearly, since TV viewers have different tastes, this generic broadcast is not likely to satisfy the preferences (e.g., favorite player, specific camera angle) of every viewer. Advertisers already target their audiences with commercials during sports broadcasts in a personalized way (e.g., targeting commercials to specific demographics that are the expected viewers of a game), and it seems reasonable to expect the next step to be the personalization of the sports broadcast feed itself in a viewer-centric way. Adding human directors to create different personalized\u00a0\u2026", "num_citations": "4\n", "authors": ["516"]}
{"title": "TwitterJacket: An automated activity and health monitoring solution for the elderly\n", "abstract": " This paper explores automation in monitoring the well-being of senior adults. Namely, it introduces TwitterJacket, an automated activity and health monitoring solution through the use of wearable sensors and mobile devices. The system takes advantage of wearable electrocardiography (ECG) monitoring and accelerometer data to recognize user activity and publish on Twitter. In this paper, we discuss the motivation behind such platforms, the TwitterJacket architecture, and the present implementation.", "num_citations": "4\n", "authors": ["516"]}
{"title": "Myron: Smart footballs for automated coaching\n", "abstract": " Our goal is to develop a system that a football player can use to independently assess his performance, without any individual or extra attention from a coach. Based on real-time acceleration data from a smart, instrumented football, the Myron project aims to classify and evaluate various football actions and to discriminate between throwing and other actions (eg, punt, running). Our smart football is under regulation weight and does not differ significantly from a standard-issue football in terms of its trajectory.", "num_citations": "4\n", "authors": ["516"]}
{"title": "Castor: Secure code updates using symmetric cryptosystems\n", "abstract": " We present Castor, a secure code-update protocol for sensor networks that exploits symmetric cryptoystems. Through a synergistic combination of a one-way hash-chain, two one-way key-chains with the delayed disclosure of symmetric keys, and multiple message authentication codes (MACs), Castor enables untrusted sensor nodes to verify an update's authenticity and guarantees that no correct node will ever install or forward a compromised part of a code-update image. We describe an implementation of Castor that hardens the TinyOS-based update protocol, Deluge, against node compromise. We experimentally compare Castor's computational and communication costs with those of Deluge and with those of a contemporary secure update protocol, Sluice, that uses asymmetric cryptosystems (digital signatures) instead. Our results demonstrate that Castor incurs reasonable overheads as compared to Deluge\u00a0\u2026", "num_citations": "4\n", "authors": ["516"]}
{"title": "Estimating faultdetection and fail-over times for nested real-time CORBA applications\n", "abstract": " Today\u2019s middleware applications tend to be compli-cated, and consist of tiers that form a nested chain of objects or processes. For a real-time nested application, predictability is crucial, even when faults and restarts occur. Nested applications make it challenging to predict the processing time when faults occurs. The fault-detection and recovery times are influenced by the number of tiers, the tier in which the fault occurs, the state of the end-to-end processing when the fault occurs, and the processing time of each tier. We investigate the behavior of nested CORBA applications when faults occur in different tiers, and at different stages of the nested processing. We present a model for predicting the worst-case fault-detection and fail-over times for such nested applications.", "num_citations": "4\n", "authors": ["516"]}
{"title": "Panoptes: crowd-sourced cars with a cause\n", "abstract": " There is no consolidated, integral, quantifiable, granular, updated source of information for the roads we traverse and the environment we live in everyday. This leads to ambiguity about road conditions, which is tolerable during normal conditions but extremely problematic in adverse conditions such as snow blockages, water-logging due to storms, degraded roads and potholes. Without such knowledge, city authorities cannot take effective action against such problems. Also, one only has knowledge about ones immediate surroundings in a car, and not what to expect further down the road. Our approach is to deploy a number of embedded modules capable of sensing, computing and reporting, each of which can simply be plugged into any vehicle. Hence this enables each vehicle's connectivity to the cloud and larger coverage as compared to static sensors. The data reported by each module itself might be prone\u00a0\u2026", "num_citations": "3\n", "authors": ["516"]}
{"title": "Middleware 2012\n", "abstract": " This edition marks the 13th ACM/IFIP/USENIX Middleware Conference. The first conference was held in the Lake District of England in 1998, and its origins reflected the growing importance of middleware and the realization that middleware represented an active, rigorous, growing and evolving research discipline in its own right. The definition of the term \u201cmiddleware\u201d has also evolved in the past decade, but retains, at its core, the notion of different levels/layers of abstractions in distributed-computing systems. Since its inception, the Middleware Conference has remained a premier forum for the discussion of innovations and recent advances in the design, implementation, experimentation, deployment, and usage of middleware systems.The 2012 Middleware Conference included a variety of papers spanning the design, implementation, deployment, and evaluation of middleware for nextgeneration platforms such\u00a0\u2026", "num_citations": "3\n", "authors": ["516"]}
{"title": "Fault tolerant architectures for space and avionics\n", "abstract": " \u25c6 Cross-Checking Between Units-Either physical or functional redundancy may be used. When a unit is physically duplicated, one is designated as an on-line unit and the other as a monitor. The monitor checks all the outputs of the on-line unit. Alternatively, there may be disjoint units capable of performing the same function. The less precise calculation can be used as a sanity check on the more precise units.", "num_citations": "3\n", "authors": ["516"]}
{"title": "Experimental research in dependable computing at carnegie mellon university\n", "abstract": " This paper aims to capture the decades of experimental research, results and impact in the field of dependable computing and systems at Carnegie Mellon University (CMU), starting from the 1970\u2019s to the present day. This research has spanned a diverse array of topics, such as modeling, abstractions, testing, anomaly detection, trend analysis and distributed systems. We also present the current state of our dependability research at CMU, outlining the potential directions for our work in the decade to come.", "num_citations": "3\n", "authors": ["516"]}
{"title": "The architecture of the Starfish system: Mapping the survivability space\n", "abstract": " Starfish1 is a new system that provides intrusion detection and intrusion tolerance for middleware applications operating in an asynchronous distributed system. The Starfish system contains a central, highly secure and tightly coupled \u201cbody.\u201d This body is augmented by \u201carms\u201d that are less tightly coupled and that have less stringent security guarantees, each of which can be removed from the body if a significant security breach occurs. New arms can be \u201cgrown\u201d as needed. Residing between the body and arms are \u201cshoulders\u201d that have intermediate guarantees. The Starfish system aims to employ a number of techniques for providing proactive survivability, allowing the system to provide critical services even after the occurrence of attacks, accidents, or faults. Starfish is aimed at supporting distributed applications such as Web Services. The specific contributions that we make in this paper are to present dimensions in the survivability space, to provide a mapping of a number of prior systems to the survivability space, and to give a mapping of the three regions in Starfish to that space. We describe the architecture of the Starfish system, and identify specific mechanisms present in each of the regions of Starfish.", "num_citations": "3\n", "authors": ["516"]}
{"title": "Middleware for Embedded Adaptive Dependability (MEAD)\n", "abstract": " Looks at the object\u2019s containing process and ORB interactions Not comprehensive: unable to predict dynamic memory allocations Runtime predictor: Object execution and memory allocation profile Intercepts and observes runtime memory allocations (eg, object instantiation, library loading), connection establishment, etc. Prepares for the worst-case replica recovery time", "num_citations": "3\n", "authors": ["516"]}
{"title": "Practical considerations in making CORBA services fault-tolerant\n", "abstract": " This paper examines the CORBA Naming, Event, Notification, Trading, Time and Security Services, with the objective of identifying the issues that must be addressed in order make these services fault-tolerant. The reliability considerations for each of these services involves strategies for replicating the service objects, and for keeping the states of the replicas consistent. Of particular interest are the sources of non-determinism in each of these services, along with the means for addressing the non-deterministic behavior in the interests of ensuring strong fault tolerance.", "num_citations": "3\n", "authors": ["516"]}
{"title": "Transparent fault tolerance for enterprise applications\n", "abstract": " Enterprises are increasingly involved in world-wide round-the-clock e-commerce and e-business, which requires them to be operational 24 hours per day, 7 days per week. With outages leading to loss of revenue, reputation and customers, fault tolerance becomes increasingly important. The Eternal system provides transparent fault tolerance for enterprise applications that ensures continuous 24x7 operation without requiring special skills of the application programmers. The Eternal system implements the new Fault Tolerant CORBA standard.", "num_citations": "3\n", "authors": ["516"]}
{"title": "Tutorial on fault tolerant CORBA\n", "abstract": " \u2022 Interoperability limitations\u2013All replicas of an object must be hosted by infrastructure from the same vendor\u2022 Non-determinism may compromise strong replica consistency\u2022 No support for partitioned systems\u2022 No commission (wrong result) faults\u2022 No software design faults\u2022 Vendors can provide proprietary products that overcome these limitations", "num_citations": "3\n", "authors": ["516"]}
{"title": "BUFS: Towards bottom-up foundational security for software in the Internet-of-Things\n", "abstract": " The Internet-of-Things (IoT) is a rapidly growing phenomenon. While IoT-enabled objects can provide rich features that can improve users' lives, security failures can lead to severe consequences, particularly in safety-critical domains such as medical devices and automobiles. In this poster abstract, we propose BUFS, a bottom-up and foundational approach for verifying the security of the software stack in an IoT system, to provide guarantees for how the software is secure. BUFS is a secure-by-construction approach that verifies that IoT software is secure in a bottom-up and foundational way. The BUFS approach provides tools for aiding and automating parts of the software development and verification process for programmers, and is intended for safety-critical domains, where high-assurance is required.", "num_citations": "2\n", "authors": ["516"]}
{"title": "When good-enough is enough: Complex queries at fixed cost\n", "abstract": " Collections of time-series data appear in a wide variety of contexts. To gain insight into the underlying phenomenon (that the data represents), one must analyze the time-series data. Analysis can quickly become challenging for very large data (~terabytes or more) sets, and it may be infeasible to scan the entire data-set on each query due to time limits or resource constraints. To avoid this problem, one might pre-compute partial results by scanning the data-set (usually as the data arrives). However, for complex queries, where the value of a new data record depends on all of the data previously seen, this might be infeasible because incorporating a large amount of historical data into a query requires a large amount of storage. We present an approach to performing complex queries over very large data-sets in a manner that is (i) practical, meaning that a query does not require a scan of the entire data-set, and (ii\u00a0\u2026", "num_citations": "2\n", "authors": ["516"]}
{"title": "Is devops the future of sysadmin?\n", "abstract": " \u201cDevOps\u201d as the theme of the LISA\u201911 conference. For some at the time, this was a controversial choice. Indeed, for a long time it had not been clear what DevOps even was about. Like \u201ccloud,\u201d DevOps had been suspiciously vaporous, vaguely connected to Web operations, and there was brewing skepticism that there was anything new, more a crowd of novices re-learning old lessons; however, Ben Rockwood\u2019s excellent keynote at LISA\u201911 changed that, in many minds.For the first time, in my view, Ben convincingly linked DevOps to a topic that has been close to my own heart for several years: the extent to which system administration is business relevant in the modern world (actually a topic introduced by my friend Claudio Bartolini of HP research as early as 2006). For the first time, I realized that this grassroots movement in the IT world was saying the two important things:", "num_citations": "2\n", "authors": ["516"]}
{"title": "Diagnostic Fusion for Time-Triggered Automotive Networks\n", "abstract": " Modern vehicles with semi-autonomous (driver-assistance systems) and autonomous capabilities require sophisticated on-board and off-board diagnostics for safe operation, and to reduce unnecessary component replacements at the service garage. We present a diagnostic approach that strategically fuses different sources of instrumentation available in a time-triggered automotive network (Flex Ray) for vehicle control, and learns patterns or signatures of different faults. These patterns ease the classification of faults during runtime or in the service garage. We evaluate our approach through fault-injection experiments on an automotive test bench, and demonstrate that by fusing different sources of instrumentation we can diagnose protocol-level and physical faults with over 98% accuracy. We also show that our approach is applicable across different network topologies.", "num_citations": "2\n", "authors": ["516"]}
{"title": "A scalable search index for binary files\n", "abstract": " The ability to locate specific byte-sequences in large collections of binary files is important in many applications, especially malware analysis. However, it can be a time consuming process. Researchers and analysts, such as those at CERT, often have to search terabytes of data for characteristic patterns and signatures, which can take upwards of days to complete. Although many search systems, designed specifically to expedite text and metadata queries, exist, these tools are unsuitable for searching files containing arbitrary bytes. By using probabilistic techniques to pre-filter likely search candidates, we present a scalable architecture for searching and indexing terabyte-size collections of binary files. Our implementation performs searches in minutes that would required days to complete using iterative techniques. It also reduces storage costs by balancing the amount of data indexed with the total time required to\u00a0\u2026", "num_citations": "2\n", "authors": ["516"]}
{"title": "Supporting Synthetic Data-Driven Diagnosis through Automated Fault-Injection\n", "abstract": " Given the lack of empirical data available from automotive serial-communication networks, an automated faultinjection environment can be used to create synthetic datasets for training and testing data-driven diagnosis algorithms. We use commercial fault-injection hardware with custom software to implement such an environment. A small pilot study using injected physical-layer faults shows promise in producing identifiable error-patterns.", "num_citations": "2\n", "authors": ["516"]}
{"title": "Got predictability? Experiences with fault-tolerant middleware\n", "abstract": " Unpredictability in COTS-based systems often manifests as occasional instances of uncontrollably-high response times. A particular category of COTS systems, fault-tolerant (FT) middleware, is used in critical enterprise and embedded applications where predictability is of paramount importance. Our prior empirical study, which used a client-server microbenchmark, suggested that hard bounds for the maximum latency are hard to establish a priori, but that the unpredictability may be confined to less than 1% of the requests. In this paper, we present empirical data, from 7 different three-tier, FT-middleware applications, that shows strong evidence supporting this\" magical 1%\" hypothesis. We conducted a controlled experiment with 7 teams of students from a graduate-level course at Carnegie Mellon University. Each team, starting from a common three-tier architecture, independently implemented and evaluated an\u00a0\u2026", "num_citations": "2\n", "authors": ["516"]}
{"title": "Tradeoffs in configuring secure data dissemination in sensor networks: An empirical outlook\n", "abstract": " Network-reprogramming is a valuable service for maintaining sensor networks. Network-reprogramming services need to be not only efficient and reliable, but secure as well. A number of strategies for providing authentication and integrity have been proposed and evaluated, but the tradeoff space has yet to be explored to any significant depth. The recently proposed strategies are mainly distinguished through their structure, granularity and strength of hashing. We propose a configurable, secure data dissemination scheme that uses a different hash-structure to allow for a high degree of flexibility in choosing from a full spectrum of hash granularities and strengths. Using this structure, we are able to experimentally explore the tradeoffs inherent in choosing a hash-granularity under different attack scenarios and densities.", "num_citations": "2\n", "authors": ["516"]}
{"title": "Service-oriented Computing: ICSOC 2007\n", "abstract": " This volume contains all of the Research-Track, Industry-Track and Demo-Track papers that were selected for presentation at the Fifth International Conference on Service-Oriented Computing (ICSOC 2007), which was held in Vienna, Austria, September 17\u201320, 2007.ICSOC 2007 followed the footsteps of four previous successful editions of the International Conference on Service-Oriented Computing that were held in Chicago, USA (2006), Amsterdam, The Netherlands (2005), New York City, USA (2004) and Trento, Italy (2003). ICSOC is recognized as the flagship conference for service-oriented computing research and best practices. ICSOC covers the entire spectrum from theoretical and foundational results to empirical evaluation, as well as practical and industrial experiences. ICSOC 2007 continued this tradition while introducing several new themes to further these goals. Service-oriented computing brings\u00a0\u2026", "num_citations": "2\n", "authors": ["516"]}
{"title": "Proactive Fault-Recovery in Distributed Systems\n", "abstract": " Supporting both real-time and fault-tolerance properties in systems is challenging because real-time systems require predictable end-to-end schedules and bounded temporal behavior in order to meet task deadlines. However, system failures, which are typically unanticipated events, can disrupt the predefined realtime schedule and result in missed task deadlines. Such disruptions to the real-time schedule are aggravated in asynchronous distributed systems by two main factors: first, delays in failure detection, and second, increased latencies due to the reactive fault-recovery routines that are set into motion once a failure is detected.In this thesis, we present a general framework for proactive (rather than the classical reactive) fault-recovery that reduces the latencies incurred by the fault-recovery routines. Proactive fault-recovery is a technique that exploits fault prediction mechanisms in order to compensate for failures even before they occur, thereby providing bounded temporal behavior in real-time and fault-tolerant systems for certain classes of faults. In our framework, we also show how to exploit knowledge of the underlying system topology to apply the benefits of proactive fault-recovery to multi-tiered distributed systems.", "num_citations": "2\n", "authors": ["516"]}
{"title": "Making problem diagnosis work for large-scale, production storage systems\n", "abstract": " Intrepid has a very-large, production GPFS storage system consisting of 128 file servers, 32 storage controllers, 1152 disk arrays, and 11,520 total disks. In such a large system, performance problems are both inevitable and difficult to troubleshoot. We present our experiences, of taking an automated problem diagnosis approach from proof-of-concept on a 12-server test-bench parallel-filesystem cluster, and making it work on Intrepid\u2019s storage system. We also present a 15-month case study, of problems observed from the analysis of 624GB of Intrepid\u2019s instrumentation data, in which we diagnose a variety of performance-related storage-system problems, in a matter of hours, as compared to the days or longer with manual approaches.", "num_citations": "1\n", "authors": ["516"]}
{"title": "Failure\u2010Tolerant Architectures for Health Management\n", "abstract": " Over the past half century, computing systems have experienced over three orders of magnitude improvement in average time to failure and over seven orders of magnitude improvement in work accomplished between outages. This chapter surveys, compares, and contrasts the architectural techniques used to improve system reliability in space and aviation applications. The generic techniques are instantiated by actual system examples taken from the space and aviation domains. The chapter concludes by observing trends and projecting future developments.", "num_citations": "1\n", "authors": ["516"]}
{"title": "Diagnostic Fusion for Dependable Vehicle Architectures\n", "abstract": " Despite extensive design processes, emergent and anomalous behavior can still appear at runtime in dependable automotive systems. This occurs due to the existence of unexpected interactions and unidentified dependencies between independently-developed components. Therefore, system-level mechanisms must be provided to quickly diagnose such behavior and determine an appropriate corrective action. DIAGNOSTIC FUSION describes a holistic process for synthesizing data across design stages and component boundaries in order to provide an actionable diagnosis.", "num_citations": "1\n", "authors": ["516"]}
{"title": "Software Technologies for Embedded and Ubiquitous Systems: 7th IFIP WG 10.2 International Workshop, SEUS 2009 Newport Beach, CA, USA, November 16-18, 2009 Proceedings\n", "abstract": " The 7th IFIP Workshop on Software Technologies for Future Embedded and Ubiquitous Systems (SEUS) followed on the success of six previous editions in Capri, Italy (2008), Santorini, Greece (2007), Gyeongju, Korea (2006), Seattle, USA (2005), Vienna, Austria (2004), and Hokodate, Japan (2003), establishing SEUS as one of the emerging workshops in the? eld of embedded and ubiq-tous systems. SEUS 2009 continued the tradition of fostering cross-community scienti? c excellence and establishing strong links between researchand industry. The? elds of both embedded computing and ubiquitous systems have seen considerable growth over the past few years. Given the advances in these? elds, and also those in the areas of distributed computing, sensor networks, midd-ware, etc., the area of ubiquitous embedded computing is now being envisioned as the wayof the future. The systems and technologies that will arise in support of ubiquitous embedded computing will undoubtedly need to address a variety of issues, including dependability, real-time, human\u2013computer interaction,-tonomy, resource constraints, etc. All of these requirements pose a challenge to the research community. The purpose of SEUS 2009 was to bring together-searchersand practitioners with an interest in advancing the state of the artand the state of practice in this emerging? eld, with the hope of fostering new ideas, collaborations and technologies. SEUS 2009 would not have been possible without the e? ort of many people.", "num_citations": "1\n", "authors": ["516"]}
{"title": "Wheels within Wheels: Making Fault Management Cost-Effective\n", "abstract": " Local design and optimization of the components of a fault management system results in sub-optimal decisions. This means that the target system will likely not meet its objectives (under-performs) or cost too much if conditions, objectives, or constraints change. We can fix this by applying a nested, management system for the fault-management system itself. We believe that doing so will produce a more resilient, self-aware, system that can operate more effectively across a wider range of conditions, and provide better behavior at closer to optimal cost. This document summarizes the results of the Working Group 7-``Cost-Effective Fault Management''-at the Dagstuhl Seminar 09201``Self-Healing and Self-Adaptive Systems''(organized by A. Andrzejak, K. Geihs, O. Shehory and J. Wilkes). The seminar was held from May 10th 2009 to May 15th 2009 in Schloss Dagstuhl~--~ Leibniz Center for Informatics.", "num_citations": "1\n", "authors": ["516"]}
{"title": "SALSA: Analyzing Logs as StAte Machines (CMU-PDL-08-111)\n", "abstract": " SALSA examines system logs to derive state-machine views of the sytem\u2019s execution, along with control-flow, data-flow models and related statistics. Exploiting SALSA\u2019s derived views and statistics, we can effectively construct higher-level useful analyses. We demonstrate SALSA\u2019s approach by analyzing system logs generated in a Hadoop cluster, and then illustrate SALSA\u2019s value by developing visualization and failure-diagnosis techniques, for three different Hadoop workloads, based on our derived statemachine views and statistics.Acknowledgements: This work is partially supported by the NSF CAREER Award CCR-0238381, NSF Award CCF-0621508, and the Army Research Office grant number DAAD19-02-1-0389 (\" Perpetually Available and Secure Information Systems\") to the Center for Computer and Communications Security at Carnegie Mellon University.", "num_citations": "1\n", "authors": ["516"]}
{"title": "Handling Emergent Nondeterminism in Replicated Services\n", "abstract": " When distributed applications are replicated for fault tolerance, the presence of even a single nondeterministic service can lead to emergent system-wide nondeterminism that compromises replica consistency. Our approach, Midas identifies and addresses multiple sources of nondeterminism (including system calls, multithreading, etc.) in a multi-service replicated distributed architecture. Midas involves a synergistic combination of compile-time dependency, concurrency and nondeterminism analyses, followed by the performance-sensitive compensation of nondeterminism at runtime. This approach upholds existing application semantics and allows services to continue to be nondeterministic, while yet maintaining their replicas consistent. We demonstrate Midas\u2019 scalability through a microbenchmark that shows the underlying tradeoffs under different kinds of dependencies between clients, services and\u00a0\u2026", "num_citations": "1\n", "authors": ["516"]}
{"title": "Designing Fault tolerant Mission-Critical Middleware Infrastructure for Distributed Real-time and Embedded Systems\n", "abstract": " Fault tolerance is a crucial design consideration for missioncritical distributed real-time and embedded (DRE) systems, such as avionics mission computing systems, and supervisory control and data acquisition systems. Increasingly more of these systems are created using emerging middleware standards, such as publish-subscribe communication services and component based architectures. Most previous R&D efforts in fault tolerance middleware has focused on client-server object systems. Application of this research to concrete domains frequently requires specialization, hand-tailoring, and customization to accommodate for the real world challenges of these systems, including nondeterminism, scale, and interaction patterns.This paper describes our current applied R&D efforts to develop fault tolerance technology for a specific piece of mission critical DRE infrastructure, a dynamic resource manager, built using CORBA components and exhibiting characteristics representative of real-world DRE systems. This paper makes three contributions to the design and implementation of fault tolerant support in DRE system. First, we describe the fault tolerance challenges presented by these systems, including support for component infrastructure, mixed mode FT techniques (supporting active and passive fault tolerance), support for nondeterminism, issues of scale (limiting the spread of the FT infrastructure to those elements that require it), and the need for predictable and bounded recovery times. Second, we describe the design of our fault tolerant DRE architecture. Finally, we illustrate the fault recovery times in our FT DRE infrastructure in the\u00a0\u2026", "num_citations": "1\n", "authors": ["516"]}
{"title": "Impact-Sensitive Framework for Dynamic Change-Management\n", "abstract": " Impact-Sensitive Framework for Dynamic Change Management Page 1 Carnegie Mellon Impact-Sensitive Framework for Dynamic Change Management Tudor Dumitra\u015f, Priya Narasimhan (Carnegie Mellon University) Daniela Ro\u015fu, Asit Dan (IBM Research) Page 2 2 Carnegie Mellon \u00a92006 Tudor Dumitra\u015f Research Problem Generate List of Change Operations Generate Change Schedule Requests for HW & SW Upgrade System Management Events (eg, faults) & expected workload changes Timed Change Schedule Enterprise SLAs Orchestrator Change management in a live system: \u25aa Minimize service disruption & meet change request objectives \u25aa Optimize the overall business value of the live system over the change time horizon Change management in a live system: \u25aa Minimize service disruption & meet change request objectives \u25aa Optimize the overall business value of the live system over the change time \u2026", "num_citations": "1\n", "authors": ["516"]}
{"title": "Middleware-Based Software Infrastructures for the Transparent Composition of System Properties\n", "abstract": " As applications become more complicated, and yet demand even more system properties, such as reliability, realtime, security, \u00d8, software developers face the challenges of building real-world critical applications without unduly increasing the application complexity. This paper presents a novel middleware-based infrastructure that allows multiple system properties to be composed and provided simultaneously to the application. By operating transparently, the infrastructure allows unmodified middleware-based applications to reap the benefits of these system properties, without any increase in the application\u2019s complexity or any additional effort on the application programmer\u2019s part.While processors are becoming faster, and memory is becoming cheaper, the computer applications of today and of the future are becoming more complicated. The challenge that software developers face, and will continue to face, is to build useful real-world software applications while avoiding the pitfalls that accompany any increase in the application\u2019s complexity. This becomes increasingly difficult as applications place more stringent demands\u2013in terms of the system properties (\u201c-ilities\u201d, such as reliability, scalability, interoperability, real-time, security, performance, etc.) that they require\u2013that today\u2019s commercial off-the-shelf (COTS) infrastructures are simply not capable of satisfying. Thus, if an application programmer today wants his/her application to exhibit one of these system properties, he/she cannot rely on the infrastructure to provide support for this system property and must, therefore, resort to some other means. For instance, consider a system property such\u00a0\u2026", "num_citations": "1\n", "authors": ["516"]}