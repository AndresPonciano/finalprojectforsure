{"title": "Recommender system application developments: a survey\n", "abstract": " A recommender system aims to provide users with personalized online product or service recommendations to handle the increasing online information overload problem and improve customer relationship management. Various recommender system techniques have been proposed since the mid-1990s, and many sorts of recommender system software have been developed recently for a variety of applications. Researchers and managers recognize that recommender systems offer great opportunities and challenges for business, government, education, and other domains, with more recent successful developments of recommender systems for real-world applications becoming apparent. It is thus vital that a high quality, instructive review of current trends should be conducted, not only of the theoretical research results but more importantly of the practical developments in recommender systems. This paper\u00a0\u2026", "num_citations": "1174\n", "authors": ["1068"]}
{"title": "Multi-objective group decision making: methods, software and applications with fuzzy set techniques\n", "abstract": " This book proposes a set of models to describe fuzzy multi-objective decision making (MODM), fuzzy multi-criteria decision making (MCDM), fuzzy group decision making (GDM) and fuzzy multi-objective group decision-making problems, respectively. It also gives a set of related methods (including algorithms) to solve these problems. One distinguishing feature of this book is that it provides two decision support systems software for readers to apply these proposed methods. A set of real-world applications and some new directions in this area are then described to further instruct readers how to use these methods and software in their practice.", "num_citations": "593\n", "authors": ["1068"]}
{"title": "Transfer learning using computational intelligence: A survey\n", "abstract": " Transfer learning aims to provide a framework to utilize previously-acquired knowledge to solve new but similar problems much more quickly and effectively. In contrast to classical machine learning methods, transfer learning methods exploit the knowledge accumulated from data in auxiliary domains to facilitate predictive modeling consisting of different data patterns in the current domain. To improve the performance of existing transfer learning methods and handle the knowledge transfer process in real-world systems, computational intelligence has recently been applied in transfer learning. This paper systematically examines computational intelligence-based transfer learning techniques and clusters related technique developments into four main categories: (a) neural network-based transfer learning; (b) Bayes-based transfer learning; (c) fuzzy transfer learning, and (d) applications of computational intelligence\u00a0\u2026", "num_citations": "567\n", "authors": ["1068"]}
{"title": "A kernel fuzzy c-means clustering based fuzzy support vector machine algorithm for classification problems with outliers or noises\n", "abstract": " The support vector machine (SVM) has provided higher performance than traditional learning machines and has been widely applied in real-world classification problems and nonlinear function estimation problems. Unfortunately, the training process of the SVM is sensitive to the outliers or noises in the training set. In this paper, a common misunderstanding of Gaussian-function-based kernel fuzzy clustering is corrected, and a kernel fuzzy c-means clustering-based fuzzy SVM algorithm (KFCM-FSVM) is developed to deal with the classification problems with outliers or noises. In the KFCM-FSVM algorithm, we first use the FCM clustering to cluster each of two classes from the training set in the high-dimensional feature space. The farthest pair of clusters, where one cluster comes from the positive class and the other from the negative class, is then searched and forms one new training set with membership degrees\u00a0\u2026", "num_citations": "362\n", "authors": ["1068"]}
{"title": "A personalized e-learning material recommender system\n", "abstract": " Erlearning environments are mainly based on a range of delivery and interactive services. Web-based personalized learning recommender systems can, as a kind of services in e-Iearning environment, provide learning recommendations to students. This research proposes a framework of a personalized learning recommender system, which aims to help students find learning materials they would need to read. Two related technologies are developed under the framework: one is a multi-attribute evaluation method tojustify a student's need, and another is a fuzzy matching method to find suitable learning materials to best meet each student need. The implementation of this proposed personalized learni ng recommender system can support students online learn ing more effectively and assist large class online teaching with muiti-background students.", "num_citations": "243\n", "authors": ["1068"]}
{"title": "Task-based system load balancing in cloud computing using particle swarm optimization\n", "abstract": " Live virtual machine (VM) migration is a technique for achieving system load balancing in a cloud environment by transferring an active VM from one physical host to another. This technique has been proposed to reduce the downtime for migrating overloaded VMs, but it is still time- and cost-consuming, and a large amount of memory is involved in the migration process. To overcome these drawbacks, we propose a Task-based System Load Balancing method using Particle Swarm Optimization (TBSLB-PSO) that achieves system load balancing by only transferring extra tasks from an overloaded VM instead of migrating the entire overloaded VM. We also design an optimization model to migrate these extra tasks to the new host VMs by applying Particle Swarm Optimization (PSO). To evaluate the proposed method, we extend the cloud simulator (Cloudsim) package and use PSO as its task scheduling model\u00a0\u2026", "num_citations": "231\n", "authors": ["1068"]}
{"title": "Ontology-supported case-based reasoning approach for intelligent m-Government emergency response services\n", "abstract": " There is a critical need to develop a mobile-based emergency response system (MERS) to help reduce risks in emergency situations. Existing systems only provide short message service (SMS) notifications, and the decision support is weak, especially in man-made disaster situations. This paper presents a MERS ontology-supported case-based reasoning (OS-CBR) method, with implementation, to support emergency decision makers to effectively respond to emergencies. The advantages of the OS-CBR approach is that it builds a case retrieving process, which provides a more convenient system for decision support based on knowledge from, and solutions provided for past disaster events. The OS-CBR approach includes a set of algorithms that have been successfully implemented in four components: data acquisition; ontology; knowledge base; and reasoning; as a sub-system of the MERS framework. A set of\u00a0\u2026", "num_citations": "201\n", "authors": ["1068"]}
{"title": "A hybrid fuzzy-based personalized recommender system for telecom products/services\n", "abstract": " The Internet creates excellent opportunities for businesses to provide personalized online services to their customers. Recommender systems are designed to automatically generate personalized suggestions of products/services to customers. Because various uncertainties exist within both product and customer data, it is a challenge to achieve high recommendation accuracy. This study develops a hybrid recommendation approach which combines user-based and item-based collaborative filtering techniques with fuzzy set techniques and applies it to mobile product and service recommendation. It particularly implements the proposed approach in an intelligent recommender system software called Fuzzy-based Telecom Product Recommender System (FTCP-RS). Experimental results demonstrate the effectiveness of the proposed approach and the initial application shows that the FTCP-RS can effectively help\u00a0\u2026", "num_citations": "187\n", "authors": ["1068"]}
{"title": "Decider: A fuzzy multi-criteria group decision support system\n", "abstract": " Multi-criteria group decision making (MCGDM) aims to support preference-based decision over the available alternatives that are characterized by multiple criteria in a group. To increase the level of overall satisfaction for the final decision across the group and deal with uncertainty in decision process, a fuzzy MCGDM process (FMP) model is established in this study. This FMP model can also aggregate both subjective and objective information under multi-level hierarchies of criteria and evaluators. Based on the FMP model, a fuzzy MCGDM decision support system (called Decider) is developed, which can handle information expressed in linguistic terms, boolean values, as well as numeric values to assess and rank a set of alternatives within a group of decision makers. Real applications indicate that the presented FMP model and the Decider\u00a0 software are able to effectively handle fuzziness in both subjective and\u00a0\u2026", "num_citations": "169\n", "authors": ["1068"]}
{"title": "An integrated group decision-making method dealing with fuzzy preferences for alternatives and individual judgments for selection criteria\n", "abstract": " Organizations often require decisions to be made by a group, and decision makers often have fuzzy preferences for alternatives and individual judgments when attempting to reach an optimal solution. In order to deal with the fuzziness of preference of decision makers, this paper proposes an integrated fuzzy group decision-making method. This method allows group members to express fuzzy preferences for alternatives and individual judgments for solution selection criteria. It also allowed for the weighting of group members. The method then aggregates these elements into a compromise group decision which is the most acceptable for the group as a whole. This method has been implemented and tested. An example is presented to illustrate the method.", "num_citations": "168\n", "authors": ["1068"]}
{"title": "Optimal cloud resource auto-scaling for web applications\n", "abstract": " In the on-demand cloud environment, web application providers have the potential to scale virtual resources up or down to achieve cost-effective outcomes. True elasticity and cost-effectiveness in the pay-per-use cloud business model, however, have not yet been achieved. To address this challenge, we propose a novel cloud resource auto-scaling scheme at the virtual machine (VM) level for web application providers. The scheme automatically predicts the number of web requests and discovers an optimal cloud resource demand with cost-latency trade-off. Based on this demand, the scheme makes a resource scaling decision that is up or down or NOP (no operation) in each time-unit re-allocation. We have implemented the scheme on the Amazon cloud platform and evaluated it using three real-world web log datasets. Our experiment results demonstrate that the proposed scheme achieves resource auto\u00a0\u2026", "num_citations": "163\n", "authors": ["1068"]}
{"title": "An extended Kuhn\u2013Tucker approach for linear bilevel programming\n", "abstract": " Kuhn\u2013Tucker approach has been applied with remarkable success in linear bilevel programming (BLP). However, it still has some extent unsatisfactory and incomplete. One principle challenges is that it could not well handle a linear BLP problem when the constraint functions at the upper-level are of arbitrary linear form. This paper describes theoretical foundation of Kuhn\u2013Tucker approach and proposes an extended Kuhn\u2013Tucker approach to deal with the problem. The results have demonstrated that the extended Kuhn\u2013Tucker approach can solve a wider class of linear BLP problems can than current capabilities permit.", "num_citations": "162\n", "authors": ["1068"]}
{"title": "A trust-semantic fusion-based recommendation approach for e-business applications\n", "abstract": " Collaborative Filtering (CF) is the most popular recommendation technique but still suffers from data sparsity, user and item cold-start problems, resulting in poor recommendation accuracy and reduced coverage. This study incorporates additional information from the users' social trust network and the items' semantic domain knowledge to alleviate these problems. It proposes an innovative Trust\u2013Semantic Fusion (TSF)-based recommendation approach within the CF framework. Experiments demonstrate that the TSF approach significantly outperforms existing recommendation algorithms in terms of recommendation accuracy and coverage when dealing with the above problems. A business-to-business recommender system case study validates the applicability of the TSF approach.", "num_citations": "154\n", "authors": ["1068"]}
{"title": "Web-page recommendation based on web usage and domain knowledge\n", "abstract": " Web-page recommendation plays an important role in intelligent Web systems. Useful knowledge discovery from Web usage data and satisfactory knowledge representation for effective Web-page recommendations are crucial and challenging. This paper proposes a novel method to efficiently provide better Web-page recommendation through semantic-enhancement by integrating the domain and Web usage knowledge of a website. Two new models are proposed to represent the domain knowledge. The first model uses an ontology to represent the domain knowledge. The second model uses one automatically generated semantic network to represent domain terms, Web-pages, and the relations between them. Another new model, the conceptual prediction model, is proposed to automatically generate a semantic network of the semantic Web usage knowledge, which is the integration of domain knowledge and\u00a0\u2026", "num_citations": "150\n", "authors": ["1068"]}
{"title": "Multi-level decision making\n", "abstract": " Multi-level decision-making (MLDM) handles problems that require compromise between the objectives of two or more interacting entities which are arranged within a hierarchical structure with independent and perhaps conflicting objectives. Bilevel decision-making is a special and particularly popular case of MLDM, in which only two levels of decision entities are involved, each of which tries to optimize their individual objectives under certain constraints, and to act and react in a sequential manner. The MLDM problem appears naturally in critical resource management, production and transportation planning, and organizational policy making. There are two fundamental issues to address in dealing with an MLDM problem. One is how to model a multi-level decision problem, and the other is how to find an optimal solution to the problem. This monograph presents the new developments in multi-level (in particular\u00a0\u2026", "num_citations": "147\n", "authors": ["1068"]}
{"title": "On bilevel multi-follower decision making: General framework and solutions\n", "abstract": " Within the framework of any bilevel decision problem, a leader\u2019s decision is influenced by the reaction of his or her follower. When multiple followers who may have had a share in decision variables, objectives and constraints are involved in a bilevel decision problem, the leader\u2019s decision will be affected, not only by the reactions of these followers, but also by the relationships among these followers. This paper firstly identifies nine different kinds of relationships (S1 to S9) amongst followers by establishing a general framework for bilevel multi-follower decision problems. For each of the nine a corresponding bilevel multi-follower decision model is then developed. Also, this paper particularly proposes related theories focusing on an uncooperative decision problem (i.e., S1 model), as this model is the most basic one for bilevel multi-follower decision problems over the nine kinds of relationships. Moreover, this paper\u00a0\u2026", "num_citations": "146\n", "authors": ["1068"]}
{"title": "Topic analysis and forecasting for science, technology and innovation: Methodology with a case study focusing on big data research\n", "abstract": " The number and extent of current Science, Technology & Innovation topics are changing all the time, and their induced accumulative innovation, or even disruptive revolution, will heavily influence the whole of society in the near future. By addressing and predicting these changes, this paper proposes an analytic method to (1) cluster associated terms and phrases to constitute meaningful technological topics and their interactions, and (2) identify changing topical emphases. Our results are carried forward to present mechanisms that forecast prospective developments using Technology Roadmapping, combining qualitative and quantitative methodologies. An empirical case study of Awards data from the United States National Science Foundation, Division of Computer and Communication Foundation, is performed to demonstrate the proposed method. The resulting knowledge may hold interest for R&D\u00a0\u2026", "num_citations": "145\n", "authors": ["1068"]}
{"title": "Operation properties and \u03b4-equalities of complex fuzzy sets\n", "abstract": " A complex fuzzy set is a fuzzy set whose membership function takes values in the unit circle in the complex plane. This paper investigates various operation properties and proposes a distance measure for complex fuzzy sets. The distance of two complex fuzzy sets measures the difference between the grades of two complex fuzzy sets as well as that between the phases of the two complex fuzzy sets. This distance measure is then used to define \u03b4-equalities of complex fuzzy sets which coincide with those of fuzzy sets already defined in the literature if complex fuzzy sets reduce to real-valued fuzzy sets. Two complex fuzzy sets are said to be \u03b4-equal if the distance between them is less than 1-\u03b4. This paper shows how various operations between complex fuzzy sets affect given \u03b4-equalities of complex fuzzy sets. An example application of signal detection demonstrates the utility of the concept of \u03b4-equalities of\u00a0\u2026", "num_citations": "143\n", "authors": ["1068"]}
{"title": "Particle swarm optimization for bi-level pricing problems in supply chains\n", "abstract": " With rapid technological innovation and strong competition in hi-tech industries such as computer and communication organizations, the upstream component price and the downstream product cost usually decline significantly with time. As a result, an effective pricing supply chain model is very important. This paper first establishes two bi-level pricing models for pricing problems with the buyer and the vendor in a supply chain designated as the leader and the follower, respectively. A particle swarm optimization (PSO) based algorithm is developed to solve problems defined by these bi-level pricing models. Experiments illustrate that this PSO based algorithm can achieve a profit increase for buyers or vendors if they are treated as the leaders under some situations, compared with the existing methods.", "num_citations": "137\n", "authors": ["1068"]}
{"title": "Multilevel decision-making: A survey\n", "abstract": " Multilevel decision-making techniques aim to deal with decentralized management problems that feature interactive decision entities distributed throughout a multiple level hierarchy. Significant efforts have been devoted to understanding the fundamental concepts and developing diverse solution algorithms associated with multilevel decision-making by researchers in areas of both mathematics/computer science and business areas. Researchers have emphasized the importance of developing a range of multilevel decision-making techniques to handle a wide variety of management and optimization problems in real-world applications, and have successfully gained experience in this area. It is thus vital that a high quality, instructive review of current trends should be conducted, not only of the theoretical research results but also the practical developments in multilevel decision-making in business. This paper\u00a0\u2026", "num_citations": "133\n", "authors": ["1068"]}
{"title": "Competitive strategic bidding optimization in electricity markets using bilevel programming and swarm technique\n", "abstract": " Competitive strategic bidding optimization is now a key issue in electricity generator markets. Digital ecosystems provide a powerful technological foundation and support for the implementation of the optimization. This paper presents a new strategic bidding optimization technique which applies bilevel programming and swarm intelligence. In this paper, we first propose a general multileader-one-follower nonlinear bilevel (MLNB) optimization concept and related definitions based on the generalized Nash equilibrium. By analyzing the strategic bidding behavior of generating companies, we create a specific MLNB decision model for day-ahead electricity markets. The MLNB decision model allows each generating company to choose its biddings to maximize its individual profit, and a market operator can find its minimized purchase electricity fare, which is determined by the output power of each unit and the uniform\u00a0\u2026", "num_citations": "133\n", "authors": ["1068"]}
{"title": "Intelligent e\u2010government services with personalized recommendation techniques\n", "abstract": " Information overload is becoming one of the problems that hinder the effectiveness of e\u2010government services. Intelligent e\u2010government services with personalized recommendation techniques can provide a solution for this problem. Existing recommendation approaches have not entirely considered the influences of attributes of various online services and may result in no guarantee of recommendation accuracy. This study proposes a new approach to handle recommendation issues of one\u2010and\u2010only items in e\u2010government services. The proposed approach integrates the techniques of semantic similarity and the traditional item\u2010based collaborative filtering. A recommender system named Smart Trade Exhibition Finder has been developed to implement the proposed recommendation approach. The recommender system can be applied in e\u2010government services to improve the quality of government\u2010to\u2010business\u00a0\u2026", "num_citations": "131\n", "authors": ["1068"]}
{"title": "Development, distribution and evaluation of online tourism services in China\n", "abstract": " The development of electronic commerce (E-commerce) has led to great changes in the tourism industry in many countries around the world including China. The Chinese tourism industry has invested large amounts of money over last few years in the development of what is known as the 'Golden Tourism Project.' This study sheds more light on this project by investigating online tourism service development in China from three perspectives: the tourism website, the tourism website user and the tourism website provider. The results show that the majority of tourism website providers are regional tourism destination organizations that mainly provide comprehensive local tourism information and online services. The results also show the level of regional economic development has a significant impact on the construction of these local tourism websites. Through conducting a questionnaire survey, this paper\u00a0\u2026", "num_citations": "131\n", "authors": ["1068"]}
{"title": "A new index and classification approach for load pattern analysis of large electricity customers\n", "abstract": " Conducting load pattern analysis is an important task in obtaining typical load profiles (TLPs) of customers and grouping them into classes according to their load characteristics. When using clustering techniques to obtain the load patterns of electricity customers, choosing a suitable clustering algorithm and determining an appropriate cluster number are always important and difficult issues. Therefore, this paper proposes a stability index for choosing the most suitable clustering algorithm and a priority index (based on the stability index) for determining the priority rank of clusters. Based on three known clustering algorithms, an analysis approach is presented to demonstrate the use of these indices. In the approach, all load curves of customers are first clustered with the clustering algorithms under a serial given number of clusters. The two above-mentioned indices are then calculated. Following this, the most\u00a0\u2026", "num_citations": "130\n", "authors": ["1068"]}
{"title": "Scaling-up item-based collaborative filtering recommendation algorithm based on hadoop\n", "abstract": " Collaborative filtering (CF) techniques have achieved widespread success in E-commerce nowadays. The tremendous growth of the number of customers and products in recent years poses some key challenges for recommender systems in which high quality recommendations are required and more recommendations per second for millions of customers and products need to be performed. Thus, the improvement of scalability and efficiency of collaborative filtering (CF) algorithms become increasingly important and difficult. In this paper, we developed and implemented a scaling-up item-based collaborative filtering algorithm on MapReduce, by splitting the three most costly computations in the proposed algorithm into four Map-Reduce phases, each of which can be independently executed on different nodes in parallel. We also proposed efficient partition strategies not only to enable the parallel computation in\u00a0\u2026", "num_citations": "128\n", "authors": ["1068"]}
{"title": "A semantic enhanced hybrid recommendation approach: A case study of e-Government tourism service recommendation system\n", "abstract": " Recommender systems are effectively used as a personalized information filtering technology to automatically predict and identify a set of interesting items on behalf of users according to their personal needs and preferences. Collaborative Filtering (CF) approach is commonly used in the context of recommender systems; however, obtaining better prediction accuracy and overcoming the main limitations of the standard CF recommendation algorithms, such as sparsity and cold-start item problems, remain a significant challenge. Recent developments in personalization and recommendation techniques support the use of semantic enhanced hybrid recommender systems, which incorporate ontology-based semantic similarity measure with other recommendation approaches to improve the quality of recommendations. Consequently, this paper presents the effectiveness of utilizing semantic knowledge of items to\u00a0\u2026", "num_citations": "124\n", "authors": ["1068"]}
{"title": "Formulation of fuzzy linear programming problems as four-objective constrained optimization problems\n", "abstract": " This paper concerns the solution of fuzzy linear programming (FLP) problems which involve fuzzy numbers in coefficients of objective functions. Firstly, a number of concepts of optimal solutions to FLP problems are introduced and investigated. Then, a number of theorems are developed so as to convert the FLP to a multi-objective optimization problem with four-objective functions. Finally, two illustrative examples are given to demonstrate the solution procedure. It also shows that our method of solution includes an existing method as a special case.", "num_citations": "123\n", "authors": ["1068"]}
{"title": "One-and-only item recommendation with fuzzy logic techniques\n", "abstract": " Recommender systems anticipate users\u2019 needs by suggesting items that are likely to interest them. Most existing systems employ collaborative filtering (CF) techniques, searching for regularities in the way users have rated items. While in general a successful approach, CF cannot cope well with so-called one-and-only items, that is: items of which there is only one single instance (like an event), and which as such cannot be repetitively \u201csold\u201d. Typically such items are evaluated only after they have ceased being available, thereby thwarting the classical CF strategy. In this paper, we develop a conceptual framework for recommending one-and-only items. It uses fuzzy logic, which allows to reflect the graded/uncertain information in the domain, and to extend the CF paradigm, overcoming limitations of existing techniques. A possible application in the context of trade exhibition recommendation for e-government is\u00a0\u2026", "num_citations": "114\n", "authors": ["1068"]}
{"title": "A fuzzy tree matching-based personalized e-learning recommender system\n", "abstract": " The rapid development of e-learning systems provides learners with great opportunities to access learning activities online, and this greatly supports and enhances the learning practices. However, an issue reduces the success of application of e-learning systems; too many learning activities (such as various leaning materials, subjects, and learning resources) are emerging in an e-learning system, making it difficult for individual learners to select proper activities for their particular situations/requirements because there is no personalized service function. Recommender systems, which aim to provide personalized recommendations for products or services, can be used to solve this issue. However, e-learning systems need to be able to handle certain special requirements: 1) leaning activities and learners' profiles often present tree structures; 2) learning activities contain vague and uncertain data, such as the\u00a0\u2026", "num_citations": "107\n", "authors": ["1068"]}
{"title": "A fuzzy preference tree-based recommender system for personalized business-to-business e-services\n", "abstract": " The Web creates excellent opportunities for businesses to provide personalized online services to their customers. Recommender systems aim to automatically generate personalized suggestions of products/services to customers (businesses or individuals). Although recommender systems have been well studied, there are still two challenges in the development of a recommender system, particularly in real-world B2B e-services: (1) items or user profiles often present complicated tree structures in business applications, which cannot be handled by normal item similarity measures and (2) online users' preferences are often vague and fuzzy, and cannot be dealt with by existing recommendation methods. To handle both these challenges, this study first proposes a method for modeling fuzzy tree-structured user preferences, in which fuzzy set techniques are used to express user preferences. A recommendation\u00a0\u2026", "num_citations": "107\n", "authors": ["1068"]}
{"title": "Multirelational social recommendations via multigraph ranking\n", "abstract": " Recommender systems aim to identify relevant items for particular users in large-scale online applications. The historical rating data of users is a valuable input resource for many recommendation models such as collaborative filtering (CF), but these models are known to suffer from the rating sparsity problem when the users or items under consideration have insufficient rating records. With the continued growth of online social networks, the increased user-to-user relationships are reported to be helpful and can alleviate the CF rating sparsity problem. Although researchers have developed a range of social networkbased recommender systems, there is no unified model to handle multirelational social networks. To address this challenge, this paper represents different user relationships in a multigraph and develops a multigraph ranking model to identify and recommend the nearest neighbors of particular users in\u00a0\u2026", "num_citations": "101\n", "authors": ["1068"]}
{"title": "Cognition in business decision support systems\n", "abstract": " Cognition plays a key role in decision making for complex, ill-structured situations. Cognitive decision support is one of the major objectives in the design and development of DSS. In Chapter 3, we analyzed some important concepts and models in managerial cognition. Managers\u2019 rich SA and mental models are two prerequisites for and likely lead to successful decisions according NDM theory. In this chapter, we will look at the role of managers\u2019 cognition on decision-making processes from an information system (IS) perspective. The first two sections of this chapter discuss the basic characteristics of decision-making tasks in business domain, and how managers\u2019 cognition can influence on business decision making. The last section summarizes some typical systems that take cognition as an important consideration.", "num_citations": "101\n", "authors": ["1068"]}
{"title": "Member contribution-based group recommender system\n", "abstract": " Developing group recommender systems (GRSs) is a vital requirement in many online service systems to provide recommendations in contexts in which a group of users are involved. Unfortunately, GRSs cannot be effectively supported using traditional individual recommendation techniques because it needs new models to reach an agreement to satisfy all the members of this group, given their conflicting preferences. Our goal is to generate recommendations by taking each group member's contribution into account through weighting members according to their degrees of importance. To achieve this goal, we first propose a member contribution score (MCS) model, which employs the separable non-negative matrix factorization technique on a group rating matrix, to analyze the degree of importance of each member. A Manhattan distance-based local average rating (MLA) model is then developed to refine\u00a0\u2026", "num_citations": "100\n", "authors": ["1068"]}
{"title": "An intelligent situation awareness support system for safety-critical environments\n", "abstract": " Operators handling abnormal situations in safety-critical environments need to be supported from a cognitive perspective to reduce their workload, stress, and consequent error rate. Of the various cognitive activities, a correct understanding of the situation, i.e. situation awareness (SA), is a crucial factor in improving performance and reducing error. However, existing system safety researches focus mainly on technical issues and often neglect SA. This study presents an innovative cognition-driven decision support system called the situation awareness support system (SASS) to manage abnormal situations in safety-critical environments in which the effect of situational complexity on human decision-makers is a concern. To achieve this objective, a situational network modeling process and a situation assessment model that exploits the specific capabilities of dynamic Bayesian networks and risk indicators are first\u00a0\u2026", "num_citations": "100\n", "authors": ["1068"]}
{"title": "Fuzzy regression transfer learning in Takagi\u2013Sugeno fuzzy models\n", "abstract": " Data science is a research field concerned with processes and systems that extract knowledge from massive amounts of data. In some situations, however, data shortage renders existing data-driven methods difficult or even impossible to apply. Transfer learning has recently emerged as a way of exploiting previously acquired knowledge to solve new yet similar problems much more quickly and effectively. In contrast to classical data-driven machine learning methods, transfer learning methods exploit the knowledge accumulated from data in auxiliary domains to facilitate predictive modeling in the current domain. A significant number of transfer learning methods that address classification tasks have been proposed, but studies on transfer learning in the case of regression problems are still scarce. This study focuses on using transfer learning techniques to handle regression problems in a domain that has\u00a0\u2026", "num_citations": "96\n", "authors": ["1068"]}
{"title": "BizSeeker: a hybrid semantic recommendation system for personalized government\u2010to\u2010business e\u2010services\n", "abstract": " Purpose \u2013 The purpose of this paper is to develop a hybrid semantic recommendation system to provide personalized government to business (G2B) e\u2010services, in particular, business partner recommendation e\u2010services for Australian small to medium enterprises (SMEs).Design/methodology/approach \u2013 The study first proposes a product semantic relevance model. It then develops a hybrid semantic recommendation approach which combines item\u2010based collaborative filtering (CF) similarity and item\u2010based semantic similarity techniques. This hybrid approach is implemented into an intelligent business\u2010partner\u2010locator recommendation\u2010system prototype called BizSeeker.Findings \u2013 The hybrid semantic recommendation approach can help overcome the limitations of existing recommendation techniques. The recommendation system prototype, BizSeeker, can recommend relevant business partners to individual\u00a0\u2026", "num_citations": "95\n", "authors": ["1068"]}
{"title": "a web\u2010based personalized business partner recommendation system using fuzzy semantic techniques\n", "abstract": " The web provides excellent opportunities to businesses in various aspects of development such as finding a business partner online. However, with the rapid growth of web information, business users struggle with information overload and increasingly find it difficult to locate the right information at the right time. Meanwhile, small and medium businesses (SMBs), in particular, are seeking \u201cone\u2010to\u2010one\u201d e\u2010services from government in current highly competitive markets. How can business users be provided with information and services specific to their needs, rather than an undifferentiated mass of information? An effective solution proposed in this study is the development of personalized e\u2010services. Recommender systems is an effective approach for the implementation of Personalized E\u2010Service which has gained wide exposure in e\u2010commerce in recent years. Accordingly, this paper first presents a hybrid fuzzy\u00a0\u2026", "num_citations": "94\n", "authors": ["1068"]}
{"title": "A cross-domain recommender system with consistent information transfer\n", "abstract": " Recommender systems provide users with personalized online product and service recommendations and are a ubiquitous part of today's online entertainment smorgasbord. However, many suffer from cold-start problems due to a lack of sufficient preference data, and this is hindering their development. Cross-domain recommender systems have been proposed as one possible solution. These systems transfer knowledge from one domain that has adequate preference information to another domain that does not. The outlook for cross-domain recommendation is promising, but existing methods cannot ensure the knowledge extracted from the source domain is consistent with the target domain, which may impact the accuracy of the recommendations. To address this challenging issue, we propose a cross-domain recommender system with consistent information transfer (CIT). Knowledge consistency is based on\u00a0\u2026", "num_citations": "93\n", "authors": ["1068"]}
{"title": "A hybrid trust\u2010enhanced collaborative filtering recommendation approach for personalized government\u2010to\u2010business e\u2010services\n", "abstract": " The information overload on the World Wide Web results in the underuse of some existing e\u2010government services within the business domain. Small\u2010to\u2010medium businesses (SMBs), in particular, are seeking \u201cone\u2010to\u2010one'' e\u2010services from government in current highly competitive markets, and there is an imperative need to develop Web personalization techniques to provide business users with information and services specific to their needs, rather than an undifferentiated mass of information. This paper focuses on how e\u2010governments can support businesses on the problem of selecting a trustworthy business partner to perform reliable business transactions. In the business partner selection process, trust or reputation information is crucial and has significant influence on a business user's decision regarding whether or not to do business with other business entities. For this purpose, an intelligent trust\u2010enhanced\u00a0\u2026", "num_citations": "91\n", "authors": ["1068"]}
{"title": "Website development and evaluation in the Chinese tourism industry\n", "abstract": " The web-based technologies have become a strategic necessity for tourism organizations. Through switching to online services, tourism organizations are achieving better positions in the digital-based competitive market. The Chinese tourism industry is investing in the development of a \u2018Golden Tourism Project\u2019which includes tourism E-commerce website development and evaluation as one of main parts. This study investigates tourism E-commerce website development in China from three perspectives: the tourism website functionality, the tourism website user and the tourism website provider. Based on a web search and a questionnaire survey, this paper analyses the distribution and classifications of tourism websites, explores the functionality of these websites, and assesses user satisfaction for current tourism websites. The results show that the majority of tourism website providers are regional tourism\u00a0\u2026", "num_citations": "91\n", "authors": ["1068"]}
{"title": "A fuzzy reliability assessment of basic events of fault trees through qualitative data processing\n", "abstract": " Probabilistic approaches are common in the analysis of reliability of complex engineering systems. However, they require quantitative historical failure data for determining reliability characteristics. In many real-world areas, such as e.g., nuclear engineering, quantitative historical failure data are unavailable or become inadequate and only qualitative data such as expert opinions, which are described in linguistic terms, can be collected and then used to assess system reliability. Moreover, experts are more comfortable justifying event failure likelihood using linguistic terms, which capture uncertainties rather than by expressing judgments in a quantitative manner. New techniques are therefore needed that will help construct models of reliability of complex engineering system without being confined to quantitative historical failure data. The objective of this study is to develop a fuzzy reliability algorithm to effectively\u00a0\u2026", "num_citations": "90\n", "authors": ["1068"]}
{"title": "Evolutionary algorithm-based multi-objective task scheduling optimization model in cloud environments\n", "abstract": " Optimizing task scheduling in a distributed heterogeneous computing environment, which is a nonlinear multi-objective NP-hard problem, plays a critical role in decreasing service response time and cost, and boosting Quality of Service (QoS). This paper, considers four conflicting objectives, namely minimizing task transfer time, task execution cost, power consumption, and task queue length, to develop a comprehensive multi-objective optimization model for task scheduling. This model reduces costs from both the customer and provider perspectives by considering execution and power cost. We evaluate our model by applying two multi-objective evolutionary algorithms, namely Multi-Objective Particle Swarm Optimization (MOPSO) and Multi-Objective Genetic Algorithm (MOGA). To implement the proposed model, we extend the Cloudsim toolkit by using MOPSO and MOGA as its task scheduling\u00a0\u2026", "num_citations": "88\n", "authors": ["1068"]}
{"title": "Decentralized multi-objective bilevel decision making with fuzzy demands\n", "abstract": " Decisions in a decentralized organization often involve two levels. The leader at the upper level attempts to optimize his/her objective but is affected by the follower; the follower at the lower level tries to find an optimized strategy according to each of possible decisions made by the leader. When model a real-world bilevel decision problem, it also may involve fuzzy demands which appear either in the parameters of objective functions or constraints of the leader or the follower or both. Furthermore, the leader and the follower may have multiple conflict objectives that should be optimized simultaneously in achieving a solution. This study addresses both fuzzy demands and multi-objective issues and propose a fuzzy multi-objective bilevel programming model. It then develops an approximation branch-and-bound algorithm to solve multi-objective bilevel decision problems with fuzzy demands. Finally, two case-based\u00a0\u2026", "num_citations": "88\n", "authors": ["1068"]}
{"title": "A model for evaluating e-commerce based on cost/benefit and customer satisfaction\n", "abstract": " Today's business managers face increased pressures to make sure that E-commerce (EC) investment has certain paybacks. They are attempting to find which investment will contribute effectively to their business benefits, thus determining whether money should be spent on these results. This paper develops a conceptual framework for evaluating web-based business-to-customer EC applications. The framework includes EC cost/benefit, EC functionality and customer satisfaction categories, each consisting of a set of factors. This paper then critically examines the inter-dependent and interrelated relationships among these factors through a group testing of hypotheses. The research is conducted based on a web exploration and two respective surveys: customer-oriented and company (supplier)-oriented. Through data analysis, findings are expressed into a factor-relationship model. The model shows how\u00a0\u2026", "num_citations": "88\n", "authors": ["1068"]}
{"title": "Technology roadmapping for competitive technical intelligence\n", "abstract": " Understanding the evolution and emergence of technology domains remains a challenge, particularly so for potentially breakthrough technologies. Though it is well recognized that emergence of new fields is complex and uncertain, to make decisions amidst such uncertainty, one needs to mobilize various sources of intelligence to identify known\u2013knowns and known\u2013unknowns to be able to choose appropriate strategies and policies. This competitive technical intelligence cannot rely on simple trend analyses because breakthrough technologies have little past to inform such trends, and positing the directions of evolution is challenging. Neither do qualitative tools, embracing the complexities, provide all the solutions, since transparent and repeatable techniques need to be employed to create best practices and evaluate the intelligence that comes from such exercises. In this paper, we present a hybrid roadmapping\u00a0\u2026", "num_citations": "87\n", "authors": ["1068"]}
{"title": "An extended Kth-best approach for linear bilevel programming\n", "abstract": " Kth-best approach is one of the three popular and workable approaches for linear bilevel programming. However, it could not well deal with a linear bilevel programming problem when the constraint functions at the upper-level are of arbitrary linear form. Based on our previous work, this paper proposes theoretical properties of linear bilevel programming and presents an extended Kth-best approach for linear bilevel programming which can effectively solve above problem.", "num_citations": "80\n", "authors": ["1068"]}
{"title": "Emergency management evaluation by a fuzzy multi-criteria group decision support system\n", "abstract": " Emergency risk management (ERM) is a process which involves dealing with risks to the community arising from emergency events. Emergency management evaluation as one of the important parts of ERM aims assessing and improving social preparedness and organizational ability in identifying, analyzing, and treating emergency risks. This study first develops an emergency management evaluation model. It then proposes an extended fuzzy multi-criteria group evaluation method, which can deal with both subjective and objective criteria under multi-levels by a group of evaluators, for emergency management evaluation. A fuzzy multi-criteria group decision support system (FMCGDSS) is then developed to implement the proposed method for the case of emergency operating center/system evaluation.", "num_citations": "76\n", "authors": ["1068"]}
{"title": "Gesture recognition using a bioinspired learning architecture that integrates visual data with somatosensory data from stretchable sensors\n", "abstract": " Gesture recognition using machine-learning methods is valuable in the development of advanced cybernetics, robotics and healthcare systems, and typically relies on images or videos. To improve recognition accuracy, such visual data can be combined with data from other sensors, but this approach, which is termed data fusion, is limited by the quality of the sensor data and the incompatibility of the datasets. Here, we report a bioinspired data fusion architecture that can perform human gesture recognition by integrating visual data with somatosensory data from skin-like stretchable strain sensors made from single-walled carbon nanotubes. The learning architecture uses a convolutional neural network for visual processing and then implements a sparse neural network for sensor data fusion and recognition at the feature level. Our approach can achieve a recognition accuracy of 100% and maintain recognition\u00a0\u2026", "num_citations": "75\n", "authors": ["1068"]}
{"title": "Task scheduling optimization in cloud computing applying multi-objective particle swarm optimization\n", "abstract": " Optimizing the scheduling of tasks in a distributed heterogeneous computing environment is a nonlinear multi-objective NP-hard problem which is playing an important role in optimizing cloud utilization and Quality of Service (QoS). In this paper, we develop a comprehensive multi-objective model for optimizing task scheduling to minimize task execution time, task transferring time, and task execution cost. However, the objective functions in this model are in conflict with one another. Considering this fact and the supremacy of Particle Swarm Optimization (PSO) algorithm in speed and accuracy, we design a multi-objective algorithm based on multi-objective PSO (MOPSO) method to provide an optimal solution for the proposed model. To implement and evaluate the proposed model, we extend Jswarm package to multi-objective Jswarm (MO-Jswarm) package. We also extend Cloudsim toolkit applying MO\u00a0\u2026", "num_citations": "75\n", "authors": ["1068"]}
{"title": "An extended branch and bound algorithm for linear bilevel programming\n", "abstract": " For linear bilevel programming, the branch and bound algorithm is the most successful algorithm to deal with the complementary constraints arising from Kuhn\u2013Tucker conditions. However, one principle challenge is that it could not well handle a linear bilevel programming problem when the constraint functions at the upper-level are of arbitrary linear form. This paper proposes an extended branch and bound algorithm to solve this problem. The results have demonstrated that the extended branch and bound algorithm can solve a wider class of linear bilevel problems can than current capabilities permit.", "num_citations": "75\n", "authors": ["1068"]}
{"title": "Uncertainty analysis for the keyword system of web events\n", "abstract": " Webpage recommendations for hot Web events can assist people to easily follow the evolution of these Web events. At the same time, there are different levels of semantic uncertainty underlying the amount of Webpages for a Web event, such as recapitulative information and detailed information. Apparently, the grasp of the semantic uncertainty of Web events could improve the satisfactoriness of Webpage recommendations. However, traditional hit-rate-based or clustering-based Webpage recommendation methods have overlooked these different levels of semantic uncertainty. In this paper, we propose a framework to identify the different underlying levels of semantic uncertainty in terms of Web events, and then utilize these for Webpage recommendations. Our idea is to consider a Web event as a system composed of different keywords, and the uncertainty of this keyword system is related to the uncertainty of the\u00a0\u2026", "num_citations": "72\n", "authors": ["1068"]}
{"title": "On the definition of linear bilevel programming solution\n", "abstract": " Linear bilevel programming theory has been studied for many years by a number of researchers from different aspects, yet it still remains to some extent unsatisfactory and incomplete. The main challenge is how to solve a linear bilevel programming problem when the upper-level's constraint functions are of arbitrary linear form. This paper proposes a definition for linear bilevel programming solution. The performance comparisons have demonstrated that the new model can solve a wider class of problems than current capabilities permit.", "num_citations": "72\n", "authors": ["1068"]}
{"title": "Intelligent multi-criteria fuzzy group decision-making for situation assessments\n", "abstract": " Organizational decisions and situation assessment are often made in groups, and decision and assessment processes involve various uncertain factors. To increase efficiently group decision-making, this study presents a new rational\u2013political model as a systematic means of supporting group decision-making in an uncertain environment. The model takes advantage of both rational and political models and can handle inconsistent assessment, incomplete information and inaccurate opinions in deriving the best solution for the group decision under a sequential framework. The model particularly identifies three uncertain factors involved in a group decision-making process: decision makers\u2019 roles, preferences for alternatives, and judgments for assessment-criteria. Based on this model, an intelligent multi-criteria fuzzy group decision-making method is proposed to deal with the three uncertain factors\u00a0\u2026", "num_citations": "71\n", "authors": ["1068"]}
{"title": "Cost benefit factor analysis in e\u2010services\n", "abstract": " This paper first presents a research framework for e\u2010service evaluation within four categories: cost, benefit, functions and development, each incorporating a number of factors. Through data analysis and hypotheses testing, inter\u2010relationships among the factors of the four categories are examined. The results show that the development type of an e\u2010service has a significant effect on the degree of user satisfaction. Expertise, technique and expense are the principle factors limiting current e\u2010service adoption. The most significant finding is that, in the development of e\u2010services, certain cost factors are significantly more important than others in relation to certain benefit factors. The finding is presented as a cost\u2010benefit factor\u2010relation model. This provides an insight into whether investment in certain areas of e\u2010service applications is more important than in others for particular business objectives. These results have the\u00a0\u2026", "num_citations": "71\n", "authors": ["1068"]}
{"title": "Robust vehicle routing problem with hard time windows under demand and travel time uncertainty\n", "abstract": " Due to an increase in customer-oriented service strategies designed to meet more complex and exacting customer requirements, meeting a scheduled time window has become an important part of designing vehicle routes for logistics activities. However, practically, the uncertainty in travel times and customer demand often means vehicles miss these time windows, increasing service costs and decreasing customer satisfaction. In an effort to find a solution that meets the needs of real-world logistics, we examine the vehicle routing problem with hard time windows under demand and travel time uncertainty. To address the problem, we build a robust optimization model based on novel route-dependent uncertainty sets. However, due to the complex nature of the problem, the robust model is only able to tackle small-sized instances using standard solvers. Therefore, to tackle large instances, we design a two-stage\u00a0\u2026", "num_citations": "70\n", "authors": ["1068"]}
{"title": "Detecting and predicting the topic change of Knowledge-based Systems: A topic-based bibliometric analysis from 1991 to 2016\n", "abstract": " The journal Knowledge-based Systems (KnoSys) has been published for over 25 years, during which time its main foci have been extended to a broad range of studies in computer science and artificial intelligence. Answering the questions: \u201cWhat is the KnoSys community interested in?\u201d and \u201cHow does such interest change over time?\u201d are important to both the editorial board and audience of KnoSys. This paper conducts a topic-based bibliometric study to detect and predict the topic changes of KnoSys from 1991 to 2016. A Latent Dirichlet Allocation model is used to profile the hotspots of KnoSys and predict possible future trends from a probabilistic perspective. A model of scientific evolutionary pathways applies a learning-based process to detect the topic changes of KnoSys in sequential time slices. Six main research areas of KnoSys are identified, i.e., expert systems, machine learning, data mining, decision\u00a0\u2026", "num_citations": "70\n", "authors": ["1068"]}
{"title": "A method for multiple periodic factor prediction problems using complex fuzzy sets\n", "abstract": " Multiple periodic factor prediction (MPFP) problems exist widely in multisensor data fusion applications. Development of an effective prediction method should integrate information for multiple periodically changing factors. Because the uncertainty and periodicity coexist in the information used, the prediction method should be able to handle them simultaneously. In this study, complex fuzzy sets are used to represent the information with uncertainty and periodicity. A product-sum aggregation operator (PSAO) is developed for a set of complex fuzzy sets, which is used to integrate information with uncertainty and periodicity, and a PSAO-based prediction (PSAOP) method is then proposed to generate a solution of MPFP problems. This study illustrates the details of the PSAOP method through two real applications in annual sunspot number prediction and bushfire danger rating prediction. Experiments indicate that the\u00a0\u2026", "num_citations": "67\n", "authors": ["1068"]}
{"title": "A cross-domain recommender system with kernel-induced knowledge transfer for overlapping entities\n", "abstract": " The aim of recommender systems is to automatically identify user preferences within collected data, then use those preferences to make recommendations that help with decisions. However, recommender systems suffer from data sparsity problem, which is particularly prevalent in newly launched systems that have not yet had enough time to amass sufficient data. As a solution, cross-domain recommender systems transfer knowledge from a source domain with relatively rich data to assist recommendations in the target domain. These systems usually assume that the entities either fully overlap or do not overlap at all. In practice, it is more common for the entities in the two domains to partially overlap. Moreover, overlapping entities may have different expressions in each domain. Neglecting these two issues reduces prediction accuracy of cross-domain recommender systems in the target domain. To fully exploit\u00a0\u2026", "num_citations": "66\n", "authors": ["1068"]}
{"title": "Scientific evolutionary pathways: Identifying and visualizing relationships for scientific topics\n", "abstract": " Whereas traditional science maps emphasize citation statistics and static relationships, this paper presents a term\u2010based method to identify and visualize the evolutionary pathways of scientific topics in a series of time slices. First, we create a data preprocessing model for accurate term cleaning, consolidating, and clustering. Then we construct a simulated data streaming function and introduce a learning process to train a relationship identification function to adapt to changing environments in real time, where relationships of topic evolution, fusion, death, and novelty are identified. The main result of the method is a map of scientific evolutionary pathways. The visual routines provide a way to indicate the interactions among scientific subjects and a version in a series of time slices helps further illustrate such evolutionary pathways in detail. The detailed outline offers sufficient statistical information to delve into\u00a0\u2026", "num_citations": "66\n", "authors": ["1068"]}
{"title": "A Fuzzy Relational Approach to Event Recommendation.\n", "abstract": " Most existing recommender systems employ collaborative filtering (CF) techniques in making projections about which items an eservice user is likely to be interested in, ie they identify correlations between users and recommend items which similar users have liked in the past. Traditional CF techniques, however, have difficulties when confronted with sparse rating data, and cannot cope at all with time-specific items, like events, which typically receive their ratings only after they have finished. Content-based (CB) algorithms, which consider the internal structure of items and recommend items similar to those a user liked in the past can partly make up for that drawback, but the collaborative feature is totally lost on them. In this paper, modelling user and item similarities as fuzzy relations, which allow to flexibly reflect the graded/uncertain information in the domain, we develop a novel, hybrid CF-CB approach whose\u00a0\u2026", "num_citations": "65\n", "authors": ["1068"]}
{"title": "Granular fuzzy regression domain adaptation in Takagi\u2013Sugeno fuzzy models\n", "abstract": " In classical data-driven machine learning methods, massive amounts of labeled data are required to build a high-performance prediction model. However, the amount of labeled data in many real-world applications is insufficient, so establishing a prediction model is impossible. Transfer learning has recently emerged as a solution to this problem. It exploits the knowledge accumulated in auxiliary domains to help construct prediction models in a target domain with inadequate training data. Most existing transfer learning methods solve classification tasks; only a few are devoted to regression problems. In addition, the current methods ignore the inherent phenomenon of information granularity in transfer learning. In this study, granular computing techniques are applied to transfer learning. Three granular fuzzy regression domain adaptation methods to determine the estimated values for a regression target are\u00a0\u2026", "num_citations": "64\n", "authors": ["1068"]}
{"title": "Theme-based comprehensive evaluation in new product development using fuzzy hierarchical criteria group decision-making method\n", "abstract": " One of the features of the digital ecosystem is the integration of human cognition and socio-economic themes into the process of new product development (NPD). In a socio-economic theme-based NPD, ranking a set of product prototypes that have been designed always requires the participation of multiple evaluators and consideration of multiple evaluation criteria. Using the well-being theme-based garment NPD as a background, this paper first presents a fuzzy hierarchical criteria group decision-making (FHCGDM) method which can effectively calculate final ranking results through fusing all assessment data from human beings and machines. It then presents a garment NPD comprehensive evaluation model with hierarchical criteria under the well-being theme through identifying a set of marketing tactics from a consumer acceptance survey. It further provides an establishment process for an NPD evaluation\u00a0\u2026", "num_citations": "64\n", "authors": ["1068"]}
{"title": "Model and approach of fuzzy bilevel decision making for logistics planning problem\n", "abstract": " Purpose \u2013 This study aims to develop a decision making model and approach for logistics planning problem which naturally involves two or more decision units at a hierarchical structure. Such a decision problem in practice often involves uncertain and imprecise factors with the parameters of a bilevel decision model, either in the objective functions or constraints.Design/methodology/approach \u2013 This paper proposes a fuzzy bilevel decision making model for a general logistics planning problem and develops a fuzzy number based Kth\u2010best approach to find an optimal solution for the proposed fuzzy bilevel decision problem.Findings \u2013 The proposed approach illustrates an optimal solution in logistics management, which meets maximally/minimally the objectives of both supplier and distributor (or other parts of the logistics chain). The proposed fuzzy bilevel decision approach can have a wide range of logistics\u00a0\u2026", "num_citations": "62\n", "authors": ["1068"]}
{"title": "Fuzzy refinement domain adaptation for long term prediction in banking ecosystem\n", "abstract": " Long-term bank failure prediction is a challenging real world problem in banking ecosystem and machine learning methods have been recently applied to improve the prediction accuracy. However, traditional machine learning methods assume that the training data and the test data are drawn from the same distribution, which is hard to be met in real world banking applications. This paper proposes a novel algorithm known as fuzzy refinement domain adaptation to solve this problem based on the ecosystem-oriented architecture. The algorithm utilizes the fuzzy system and similarity/dissimilarity concepts to modify the target instances' labels which were initially predicted by a shift-unaware prediction model. It employs a classifier to modify the label values of target instances based on their similarity/dissimilarity to the candidate positive and negative instances in mixture domains. Thirty six experiments are performed\u00a0\u2026", "num_citations": "61\n", "authors": ["1068"]}
{"title": "Fuzzy bilevel programming with multiple objectives and cooperative multiple followers\n", "abstract": " Classic bilevel programming deals with two level hierarchical optimization problems in which the leader attempts to optimize his/her objective, subject to a set of constraints and his/her follower\u2019s solution. In modelling a real-world bilevel decision problem, some uncertain coefficients often appear in the objective functions and/or constraints of the leader and/or the follower. Also, the leader and the follower may have multiple conflicting objectives that should be optimized simultaneously. Furthermore, multiple followers may be involved in a decision problem and work cooperatively according to each of the possible decisions made by the leader, but with different objectives and/or constraints. Following our previous work, this study proposes a set of models to describe such fuzzy multi-objective, multi-follower (cooperative) bilevel programming problems. We then develop an approximation Kth-best algorithm to\u00a0\u2026", "num_citations": "61\n", "authors": ["1068"]}
{"title": "Does deep learning help topic extraction? A kernel k-means clustering method with word embedding\n", "abstract": " Topic extraction presents challenges for the bibliometric community, and its performance still depends on human intervention and its practical areas. This paper proposes a novel kernel k-means clustering method incorporated with a word embedding model to create a solution that effectively extracts topics from bibliometric data. The experimental results of a comparison of this method with four clustering baselines (i.e., k-means, fuzzy c-means, principal component analysis, and topic models) on two bibliometric datasets demonstrate its effectiveness across either a relatively broad range of disciplines or a given domain. An empirical study on bibliometric topic extraction from articles published by three top-tier bibliometric journals between 2000 and 2017, supported by expert knowledge-based evaluations, provides supplemental evidence of the method\u2019s ability on topic extraction. Additionally, this empirical analysis\u00a0\u2026", "num_citations": "58\n", "authors": ["1068"]}
{"title": "Opinion dynamics-based group recommender systems\n", "abstract": " With the accessibility to information, users often face the problem of selecting one item (a product or a service) from a huge search space. This problem is known as information overload. Recommender systems (RSs) personalize content to a user's interests to help them select the right item in information overload scenarios. Group RSs (GRSs) recommend items to a group of users. In GRSs, a recommendation is usually computed by a simple aggregation method for individual information. However, the aggregations are rigid and overlook certain group features, such as the relationships between the group members' preferences. In this paper, it is proposed a GRS based on opinion dynamics that considers these relationships using a smart weights matrix to drive the process. In some groups, opinions do not agree, hence the weights matrix is modified to reach a consensus value. The impact of ensuring agreed\u00a0\u2026", "num_citations": "58\n", "authors": ["1068"]}
{"title": "An effective recommender system by unifying user and item trust information for B2B applications\n", "abstract": " Although Collaborative Filtering (CF)-based recommender systems have received great success in a variety of applications, they still under-perform and are unable to provide accurate recommendations when users and items have few ratings, resulting in reduced coverage. To overcome these limitations, we propose an effective hybrid user-item trust-based (HUIT) recommendation approach in this paper that fuses the users' and items' implicit trust information. We have also considered and computed user and item global reputations into this approach. This approach allows the recommender system to make an increased number of accurate predictions, especially in circumstances where users and items have few ratings. Experiments on four real-world datasets, particularly a business-to-business (B2B) case study, show that the proposed HUIT recommendation approach significantly outperforms state-of-the-art\u00a0\u2026", "num_citations": "58\n", "authors": ["1068"]}
{"title": "A hybrid multi-criteria semantic-enhanced collaborative filtering approach for personalized recommendations\n", "abstract": " Recommender systems aim to assist web users to find only relevant information to their needs rather than an undifferentiated mass of information. Collaborative filtering (CF) techniques are probably the most popular and widely adopted techniques in recommender systems. Despite of their success in various applications, CF-based techniques still encounter two major limitations, namely sparsity and cold-start problems. More recently, semantic information of items has been successfully used in recommender systems to alleviate such problems. Moreover, the incorporation of multi-criteria ratings in recommender systems can help to produce more accurate recommendations. Thereby, in this paper, we propose a hybrid Multi-Criteria Semantic-enhanced CF (MC-SeCF) approach. The MC-SeCF approach integrates the enhanced MC item-based CF and the item-based semantic filtering approaches to alleviate current\u00a0\u2026", "num_citations": "57\n", "authors": ["1068"]}
{"title": "Collaborative filtering with entropy\u2010driven user similarity in recommender systems\n", "abstract": " Collaborative filtering (CF) is the most popular approach in personalized recommender systems. Although CF approaches have successfully been used and have the advantage in that it is unnecessary to analyze item content when generating recommendations, they nevertheless suffer from problems with accuracy. In this paper, we propose a new CF approach to improve recommendation performance. First, a new information entropy\u2010driven user similarity measure model is proposed to measure the relative difference between ratings. A Manhattan distance\u2010based model is then developed to address the fat tail problem by estimating the alternative active user average rating. The effectiveness of the proposed approach is analyzed on public and private data sets. As a result of the introduction of the new similarity measure and average rating estimation, we demonstrate that the proposed new CF recommendation\u00a0\u2026", "num_citations": "56\n", "authors": ["1068"]}
{"title": "The Kth-Best Approach for Linear Bilevel Multi-follower Programming\n", "abstract": " The majority of research on bilevel programming has centered on the linear version of the problem in which only one leader and one follower are involved. This paper addresses linear bilevel multi-follower programming (BLMFP) problems in which there is no sharing information among followers. It explores the theoretical properties of linear BLMFP, extends the Kth-best approach for solving linear BLMFP problems and gives a computational test for this approach.", "num_citations": "56\n", "authors": ["1068"]}
{"title": "Topic-based technological forecasting based on patent data: A case study of Australian patents from 2000 to 2014\n", "abstract": " The study of technological forecasting is an important part of patent analysis. Although fitting models can provide a rough tendency of a technical area, the trend of the detailed content within the area remains hidden. It is also difficult to reveal the trend of specific topics using keyword-based text mining techniques, since it is very hard to track the temporal patterns of a single keyword that generally represents a technological concept. To overcome these limitations, this research proposes a topic-based technological forecasting approach, to uncover the trends of specific topics underlying massive patent claims using topic modelling. A topic annual weight matrix and a sequence of topic-based trend coefficients are generated to quantitatively estimate the developing trends of the discovered topics, and evaluate to what degree various topics have contributed to the patenting activities of the whole area. To demonstrate\u00a0\u2026", "num_citations": "54\n", "authors": ["1068"]}
{"title": "A hybrid similarity measure method for patent portfolio analysis\n", "abstract": " Similarity measures are fundamental tools for identifying relationships within or across patent portfolios. Many bibliometric indicators are used to determine similarity measures; for example, bibliographic coupling, citation and co-citation, and co-word distribution. This paper aims to construct a hybrid similarity measure method based on multiple indicators to analyze patent portfolios. Two models are proposed: categorical similarity and semantic similarity. The categorical similarity model emphasizes international patent classifications (IPCs), while the semantic similarity model emphasizes textual elements. We introduce fuzzy set routines to translate the rough technical (sub-) categories of IPCs into defined numeric values, and we calculate the categorical similarities between patent portfolios using membership grade vectors. In parallel, we identify and highlight core terms in a 3-level tree structure and compute the\u00a0\u2026", "num_citations": "53\n", "authors": ["1068"]}
{"title": "E-service intelligence\n", "abstract": " Many business organizations and government departments are nowadays developing and providing Internet based electronic services (e-services) featuring various intelligent functions. This form of e-services is commonly called e-service intelligence (ESI). ESI integrates intelligent technologies and methodologies into e-service systems for realizing intelligent Internet information searching, presentation, provision, recommendation, online system design, implementation, and assessment to Internet users. These intelligent technologies include machine learning, soft computing, intelligent languages, and data mining etc. ESI has been recently identified as a new direction for the future development stage of e-services. E-services offer great opportunities and challenges for many areas of services, such as government, education, tourism, commerce, marketing, finance, and logistics. They thus involve various online\u00a0\u2026", "num_citations": "52\n", "authors": ["1068"]}
{"title": "Model, solution concept, and Kth-best algorithm for linear trilevel programming\n", "abstract": " Trilevel programming refers to hierarchical optimization problems in which the top-level, middle-level, and bottom-level decision entities all attempt to optimize their individual objectives, but are impacted by the actions and partial control exercised by decision entities located at other levels. To solve this complex problem, in this study first we propose the use of a general linear trilevel programming (LTLP) subsequently, we develop a trilevel Kth-best algorithm to solve LTLP problems. A user-friendly trilevel decision support tool is also developed. A case study further illustrates the effectiveness of the proposed method.", "num_citations": "51\n", "authors": ["1068"]}
{"title": "Integration of ontology data through learning instance matching\n", "abstract": " Information integration with the aid of ontology can roughly be divided into two levels: schema level and data level. Most research has been focused on the schema level, i.e., mapping/matching concepts and properties in different ontologies with each other. However, the data level integration is equally important, especially in the decentralized semantic Web environment. Noticing that ontology data (in the form of instances of concepts) from different sources often have different perspectives and may overlap with each other, we develop a matching method that utilizes the features of ontology and employs the machine learning approach to integrate those instances. By exploring ontology features, this method performs better than other general methods, which is revealed in our experiments. Through the process that implements the matching method, ontology data can be integrated together to offer more sophisticated\u00a0\u2026", "num_citations": "51\n", "authors": ["1068"]}
{"title": "The Definition of Optimal Solution and Extended Kuhn-Tucker Approach for Fuzzy Linear Bilevel Programming\n", "abstract": " Organizational belivel decision-making, such as planning of land-use, transportation and water resource, all may involve uncertain factors. The parameters shown in a bileved programming model, either in the objective functions or constraints, are thus often imprecise, which is called fuzzy parameter bilevel programming (FPBLP) problem. Following our previous work [1, 2]. This study first proposes a model of FPBLP. It then gives the definition of solution for FPBLP problem. Based on the definition of solution and related theorems, this study develops a fuzzy number based Kuhn-Tucher approach to solve the proposed FPBLP problem. Finally, an example further illustrates the power of the fuzzy number based Kuhn-Tucher approach.", "num_citations": "51\n", "authors": ["1068"]}
{"title": "Mining key information of web pages: A method and its application\n", "abstract": " Web content mining aims to discover useful information and generate desired knowledge from a large amount of web pages. Key information, such as distinctive menu items, navigation indicators, which is embedded in web pages, can help classify the main contents of web pages and reflect certain taxonomy knowledge. Therefore, mining key information is significant in helping acquire domain knowledge and build catalogue classifiers. Current web content mining methods cannot mine such key information effectively. \u201cNoise information\u201d (such as advertisements) is a problem for the performance of web mining tasks. This paper proposes a method to extract key information out of web pages which contain noisy information. The method contains two steps: to extract a list of candidate key information, and then apply entropy measure to filter noisy information and discover key information. Experiment results show that\u00a0\u2026", "num_citations": "50\n", "authors": ["1068"]}
{"title": "Learning deep kernels for non-parametric two-sample tests\n", "abstract": " We propose a class of kernel-based two-sample tests, which aim to determine whether two sets of samples are drawn from the same distribution. Our tests are constructed from kernels parameterized by deep neural nets, trained to maximize test power. These tests adapt to variations in distribution smoothness and shape over space, and are especially suited to high dimensions and complex data. By contrast, the simpler kernels used in prior kernel testing work are spatially homogeneous, and adaptive only in lengthscale. We explain how this scheme includes popular classifier-based two-sample tests as a special case, but improves on them in general. We provide the first proof of consistency for the proposed adaptation method, which applies both to kernels on deep features and to simpler radial basis kernels or multiple kernel learning. In experiments, we establish the superior performance of our deep kernels in hypothesis testing on benchmark and real-world data. The code of our deep-kernel-based two-sample tests is available at github. com/fengliu90/DK-for-TST.", "num_citations": "49\n", "authors": ["1068"]}
{"title": "A ${\\bm\\lambda} $-Cut and Goal-Programming-Based Algorithm for Fuzzy-Linear Multiple-Objective Bilevel Optimization\n", "abstract": " Bilevel-programming techniques are developed to handle decentralized problems with two-level decision makers, which are leaders and followers, who may have more than one objective to achieve. This paper proposes a \u03bb-cut and goal-programming-based algorithm to solve fuzzy-linear multiple-objective bilevel (FLMOB) decision problems. First, based on the definition of a distance measure between two fuzzy vectors using \u03bb-cut, a fuzzy-linear bilevel goal (FLBG) model is formatted, and related theorems are proved. Then, using a \u03bb-cut for fuzzy coefficients and a goal-programming strategy for multiple objectives, a \u03bb-cut and goal-programming-based algorithm to solve FLMOB decision problems is presented. A case study for a newsboy problem is adopted to illustrate the application and executing procedure of this algorithm. Finally, experiments are carried out to discuss and analyze the performance of this\u00a0\u2026", "num_citations": "48\n", "authors": ["1068"]}
{"title": "A linguistic intelligent user guide for method selection in multi-objective decision support systems\n", "abstract": " Some multi-objective decision-making (MODM) methods are more effective than others for particular decision problems and/or particular decision makers. It is therefore necessary to provide a set of MODM methods in a multi-objective decision support system (MODSS) to support a wide range of problem solving. However, it is always difficult for decision makers to select the most suitable method for individual cases because MODM methods involve a deep knowledge of mathematics. To handle this difficulty, this study develops a MODM method selection guide supported by a fuzzy matching optimization method.In this paper, we first present the modelling process for the knowledge of characteristics of the main MODM methods. We then present related matching techniques between the characteristics of a real-world decision-making situation and a set of predefined situation descriptions (characteristics of a MODM\u00a0\u2026", "num_citations": "48\n", "authors": ["1068"]}
{"title": "Web-based multi-criteria group decision support system with linguistic term processing function.\n", "abstract": " Organizational decisions are often made in groups where group members may be distributed geographically in different locations. Furthermore, a decision-making process, in practice, frequently involves various uncertain factors including linguistic expressions of decision makers\u2019 preferences and opinions. This study first proposes a rational-political group decision-making model which identifies three uncertain factors involved in a group decision-making process: decision makers\u2019 roles in a group reaching a satisfactory solution, preferences for alternatives and judgments for assessment-criteria. Based on the model, a linguistic term oriented multi-criteria group decision-making method is developed. The method uses general fuzzy number to deal with the three uncertain factors described by linguistic terms and aggregates these factors into a group satisfactory decision that is in a most acceptable degree of the group. Moreover, this study implements the method by developing a web-based group decision support system. This system allows decision makers to participate a group decision-making through the web, and manages the group decision-making process as a whole, from criteria generation, alternative evaluation, opinions interaction to decision aggregation. Finally, an application of the system is presented to illustrate the web-based group decision support system.", "num_citations": "48\n", "authors": ["1068"]}
{"title": "A solution to bi/tri-level programming problems using particle swarm optimization\n", "abstract": " Multilevel (including bi-level and tri-level) programming aims to solve decentralized decision-making problems that feature interactive decision entities distributed throughout a hierarchical organization. Since the multilevel programming problem is strongly NP-hard and traditional exact algorithmic approaches lack efficiency, heuristics-based particle swarm optimization (PSO) algorithms have been used to generate an alternative for solving such problems. However, the existing PSO algorithms are limited to solving linear or small-scale bi-level programming problems. This paper first develops a novel bi-level PSO algorithm to solve general bi-level programs involving nonlinear and large-scale problems. It then proposes a tri-level PSO algorithm for handling tri-level programming problems that are more challenging than bi-level programs and have not been well solved by existing algorithms. For the sake of\u00a0\u2026", "num_citations": "46\n", "authors": ["1068"]}
{"title": "A situation risk awareness approach for process systems safety\n", "abstract": " Promoting situation awareness is an important design objective for a wide variety of domains, especially for process systems where the information flow is quite high and poor decisions may lead to serious consequences. In today\u2019s process systems, operators are often moved to a control room far away from the physical environment, and increasing amounts of information are passed to them via automated systems, they therefore need a greater level of support to control and maintain the facilities in safe conditions. This paper proposes a situation risk awareness approach for process systems safety where the effect of ever-increasing situational complexity on human decision-makers is a concern. To develop the approach, two important aspects \u2013 addressing hazards that arise from hardware failure and reducing human error through decision-making \u2013 have been considered. The proposed situation risk awareness\u00a0\u2026", "num_citations": "46\n", "authors": ["1068"]}
{"title": "Model and extended Kuhn\u2013Tucker approach for bilevel multi-follower decision making in a referential-uncooperative situation\n", "abstract": " When multiple followers are involved in a bilevel decision problem, the leader\u2019s decision will be affected, not only by the reactions of these followers, but also by the relationships among these followers. One of the popular situations within this bilevel multi-follower issue is where these followers are uncooperatively making their decisions while having cross reference to decision information of the other followers. This situation is called a referential-uncooperative situation in this paper. The well-known Kuhn\u2013Tucker approach has been previously successfully applied to a one-leader-and-one-follower linear bilevel decision problem. This paper extends this approach to deal with the above-mentioned linear referential-uncooperative bilevel multi-follower decision problem. The paper first presents a decision model for this problem. It then proposes an extended Kuhn\u2013Tucker approach to solve this problem\u00a0\u2026", "num_citations": "46\n", "authors": ["1068"]}
{"title": "Deep uncertainty quantification: A machine learning approach for weather forecasting\n", "abstract": " Weather forecasting is usually solved through numerical weather prediction (NWP), which can sometimes lead to unsatisfactory performance due to inappropriate setting of the initial states. In this paper, we design a data-driven method augmented by an effective information fusion mechanism to learn from historical data that incorporates prior knowledge from NWP. We cast the weather forecasting problem as an end-to-end deep learning problem and solve it by proposing a novel negative log-likelihood error (NLE) loss function. A notable advantage of our proposed method is that it simultaneously implements single-value forecasting and uncertainty quantification, which we refer to as deep uncertainty quantification (DUQ). Efficient deep ensemble strategies are also explored to further improve performance. This new approach was evaluated on a public dataset collected from weather stations in Beijing, China\u00a0\u2026", "num_citations": "45\n", "authors": ["1068"]}
{"title": "A mobile\u2010based emergency response system for intelligent m\u2010government services\n", "abstract": " Purpose \u2013 The purpose of this paper is to present an intelligent mobile based emergency response system (MERS) framework, a text information extraction and aggregation algorithm to integrate information from multiple sources in the MERS system, and an ontology\u2010supported case\u2010based reasoning system for the MERS system.Design/methodology/approach \u2013 The paper explains the components of information extraction and aggregation process, and a CBR\u2010Ontology approach for the MERS system.Findings \u2013 The result of this study will offer a new opportunity to the interaction between government, citizens, responders, and other non\u2010government agencies in emergency situations, and therefore improve the services of the government in an emergency situation.Originality/value \u2013 The paper indicates the need for usage of mobile technologies to assist the government to get information and make decisions in\u00a0\u2026", "num_citations": "45\n", "authors": ["1068"]}
{"title": "Multistep Fuzzy Bridged Refinement Domain Adaptation Algorithm and Its Application to Bank Failure Prediction\n", "abstract": " Machine learning plays an important role in data classification and data-based prediction. In some real-world applications, however, the training data (coming from the source domain) and test data (from the target domain) come from different domains or time periods, and this may result in the different distributions of some features. Moreover, the values of the features and/or labels of the datasets might be nonnumeric and involve vague values. Traditional learning-based prediction and classification methods cannot handle these two issues. In this study, we propose a multistep fuzzy bridged refinement domain adaptation algorithm, which offers an effective way to deal with both issues. It utilizes a concept of similarity to modify the labels of the target instances that were initially predicted by a shift-unaware model. It then refines the labels using instances that are most similar to a given target instance. These instances\u00a0\u2026", "num_citations": "44\n", "authors": ["1068"]}
{"title": "A linguistic multi-criteria group decision support system for fabric hand evaluation\n", "abstract": " Fabric hand evaluation (FHE) is the main measure in textile material selection for fashion design and development. Fabric hand evaluation requires considering multiple evaluation aspects/criteria by a group of evaluators. Some fabric features can also be measured using instruments. The evaluation often uses linguistic terms in the weights of criteria, and the weights and judgments of evaluators. To support a FHE-based material selection, this study first develops a fabric hand-based textile material evaluation model. It then proposes a human-machine measure integrated fuzzy multi-criteria group decision-making method. A software tool is also developed, which implements the proposed method and is applied in fabric hand-based textile material evaluation.", "num_citations": "44\n", "authors": ["1068"]}
{"title": "Unsupervised heterogeneous domain adaptation via shared fuzzy equivalence relations\n", "abstract": " Unsupervised domain adaptation (UDA) aims to recognize newly emerged patterns in target domains, which may be unlabeled, by leveraging knowledge from patterns learnt from source domains. However, existing UDA models and algorithms still suffer from heterogeneous domains, known as the heterogeneous unsupervised domain adaptation (HeUDA) issue. To address this issue, this paper presents a novel HeUDA model via n-dimensional fuzzy geometry and fuzzy equivalence relations, called F-HeUDA. The n-dimensional fuzzy geometry is used to propose a metric to measure the similarity between features on one domain. Then, based on this metric, shared fuzzy equivalence relations (SFER) are proposed. The SFER can allow two domains to use the same \u03b1 to get the same number of clustering categories. Through these clustering categories, knowledge from the heterogeneous source domain can be\u00a0\u2026", "num_citations": "43\n", "authors": ["1068"]}
{"title": "A knowledge-based multi-role decision support system for ore blending cost optimization of blast furnaces\n", "abstract": " Literature illustrates the difficulties in obtaining the lowest-cost optimal solution to an ore blending problem for blast furnaces by using the traditional trial-and-error method in iron and steel enterprises. To solve this problem, we developed a cost optimization model which we have implemented in a multi-role-based decision support system (DSS). On the basis of analyzing the business flow and working process of ore blending, we propose an architecture of DSS which is built based on multi-roles. This DSS construction pre-processes the data for materials and elements, builds a general database, abstracts the related optimal operations research models and introduces the reasoning mechanism of an expert system. A non-linear model of ore blending for blast furnaces and its solutions are provided. A database, a model base and a knowledge base are integrated into the expert system-based multi-role DSS to meet\u00a0\u2026", "num_citations": "43\n", "authors": ["1068"]}
{"title": "m-Government: A framework of mobile-based emergency response systems\n", "abstract": " Mobile government (m-Government) is the next inevitable direction of evolution of e-Government. A mobile-based emergency response system (MERS) is one of the important m-Government services. A MERS under m-Government platform is a mobile-based information system designed to let people get help from the government in an emergency situation. It also makes the use of mobile technologies to assist the government to get information and make decisions in responding disasters anytime and anywhere. This paper presents a framework of MERS which has five main components (register, monitoring, analysis, decision support, and warning) aiming to provide a new function and service to m-Government. The proposed MERS framework would also offer a new opportunity to interact between government, citizens, responders, and other non-government agencies in emergency situations.", "num_citations": "43\n", "authors": ["1068"]}
{"title": "An extended branch and bound algorithm for bilevel multi-follower decision making in a referential-uncooperative situation\n", "abstract": " Within the framework of any bilevel decision problem, a leader's decision at the upper level is influenced by the reaction of their follower at the lower level. When multiple followers are involved in a bilevel decision problem, the leader's decision will not only be affected by the reactions of those followers, but also by the relationships among those followers. One of the popular situations within this framework is where these followers are uncooperatively making decisions while having cross reference of decision information, called a referential-uncooperative situation in this paper. The well-known branch and bound algorithm has been successfully applied to a one-leader-and-one-follower linear bilevel decision problem. This paper extends this algorithm to deal with the above-mentioned linear bilevel multi-follower decision problem by means of a linear referential-uncooperative bilevel multi-follower decision model. It\u00a0\u2026", "num_citations": "43\n", "authors": ["1068"]}
{"title": "Structural property-aware multilayer network embedding for latent factor analysis\n", "abstract": " Multilayer network is a structure commonly used to describe and model the complex interaction between sets of entities/nodes. A three-layer example is the author-paper-word structure in which authors are linked by co-author relation, papers are linked by citation relation, and words are linked by semantic relation. Network embedding, which aims to project the nodes in the network into a relatively low-dimensional space for latent factor analysis, has recently emerged as an effective method for a variety of network-based tasks, such as collaborative filtering and link prediction. However, existing studies of network embedding both focus on the single-layer network and overlook the structural properties of the network, e.g., the degree distribution and communities, which are significant for node characterization, such as the preferences of users in a social network. In this paper, we propose four multilayer network\u00a0\u2026", "num_citations": "42\n", "authors": ["1068"]}
{"title": "A safety-critical decision support system evaluation using situation awareness and workload measures\n", "abstract": " To ensure the safety of operations in safety-critical systems, it is necessary to maintain operators\u05f3 situation awareness (SA) at a high level. A situation awareness support system (SASS) has therefore been developed to handle uncertain situations [1]. This paper aims to systematically evaluate the enhancement of SA in SASS by applying a multi-perspective approach. The approach consists of two SA metrics, SAGAT and SART, and one workload metric, NASA-TLX. The first two metrics are used for the direct objective and subjective measurement of SA, while the third is used to estimate operator workload. The approach is applied in a safety-critical environment called residue treater, located at a chemical plant in which a poor human-system interface reduced the operator\u05f3s SA and caused one of the worst accidents in US history. A counterbalanced within-subjects experiment is performed using a virtual environment\u00a0\u2026", "num_citations": "42\n", "authors": ["1068"]}
{"title": "A new approximate algorithm for solving multiple objective linear programming problems with fuzzy parameters\n", "abstract": " Many business decision problems involve multiple objectives and can thus be described by multiple objective linear programming (MOLP) models. When a MOLP problem is being formulated, the parameters of objective functions and constraints are normally assigned by experts. In most real situations, the possible values of these parameters are imprecisely or ambiguously known to the experts. Therefore, it would be more appropriate for these parameters to be represented as fuzzy numerical data that can be represented by fuzzy numbers. In this paper, a new approximate algorithm is developed for solving fuzzy multiple objective linear programming (FMOLP) problems involving fuzzy parameters in any form of membership functions in both objective functions and constraints. A detailed description and analysis of the algorithm are supplied. In addition, an example is given to illustrate the approximate algorithm.", "num_citations": "42\n", "authors": ["1068"]}
{"title": "Heterogeneous domain adaptation: An unsupervised approach\n", "abstract": " Domain adaptation leverages the knowledge in one domain\u2014the source domain\u2014to improve learning efficiency in another domain\u2014the target domain. Existing heterogeneous domain adaptation research is relatively well-progressed but only in situations where the target domain contains at least a few labeled instances. In contrast, heterogeneous domain adaptation with an unlabeled target domain has not been well-studied. To contribute to the research in this emerging field, this article presents: 1) an unsupervised knowledge transfer theorem that guarantees the correctness of transferring knowledge and 2) a principal angle-based metric to measure the distance between two pairs of domains: one pair comprises the original source and target domains and the other pair comprises two homogeneous representations of two domains. The theorem and the metric have been implemented in an innovative transfer\u00a0\u2026", "num_citations": "40\n", "authors": ["1068"]}
{"title": "An assessment for internet-based electronic commerce development in businesses of New Zealand\n", "abstract": " As a preliminary study of our research project this paper investigates the status of Internet-based electronic commerce (EC) development and applications in businesses of New Zealand. This paper also analyses the features of EC activities between different industry sectors and finds that there is an obvious difference between different sectors in EC activities. Finally, Internet-based EC activities are assessed and customer satisfaction for Internetbased EC applications to business is measured. This paper is based on a desk survey of 400 randomly selected New Zealand business websites. As a further work, the factors to successful Internet-based EC development are explored by identifying cost, benefit and business satisfaction, then a relationship model between cost, benefit and success of EC is currently undertaken.", "num_citations": "39\n", "authors": ["1068"]}
{"title": "Tri-level decision-making with multiple followers: Model, algorithm and case study\n", "abstract": " Tri-level decision-making arises to address compromises among interacting decision entities distributed throughout a three-level hierarchy; these entities are respectively termed the top-level leader, the middle-level follower and the bottom-level follower. This study considers an uncooperative situation where multiple followers at the same (middle or bottom) level make their individual decisions independently but consider the decision results of their counterparts as references through information exchanged among themselves. This situation is called a reference-based uncooperative multi-follower tri-level (MFTL) decision problem which appears in many real-world applications. To solve this problem, we need to find an optimal solution achieving both the Stackelberg equilibrium in the three-level vertical structure and the Nash equilibrium among multiple followers at the same horizontal level. In this paper, we first\u00a0\u2026", "num_citations": "36\n", "authors": ["1068"]}
{"title": "An abnormal situation modeling method to assist operators in safety-critical systems\n", "abstract": " One of the main causes of accidents in safety-critical systems is human error. In order to reduce human errors in the process of handling abnormal situations that are highly complex and mentally taxing activities, operators need to be supported, from a cognitive perspective, in order to reduce their workload, stress, and the consequent error rate. Of the various cognitive activities, a correct understanding of the situation, i.e. situation awareness (SA), is a crucial factor in improving performance and reducing errors. Despite the importance of SA in decision-making in time- and safety-critical situations, the difficulty of SA modeling and assessment means that very few methods have as yet been developed. This study confronts this challenge, and develops an innovative abnormal situation modeling (ASM) method that exploits the capabilities of risk indicators, Bayesian networks and fuzzy logic systems. The risk indicators\u00a0\u2026", "num_citations": "36\n", "authors": ["1068"]}
{"title": "A semantic classification approach for online product reviews\n", "abstract": " With the fast growth of e-commerce, product reviews on the Web have become an important information source for customers' decision making when they plan to buy products online. As the reviews are often too many for customers to go through, how to automatically classify them into different semantic orientations (i.e. recommend/not recommend) has become a research problem. Different from traditional approaches that treat a review as a whole, our approach performs semantic classifications at the sentence level by realizing reviews often contain mixed feelings or opinions. In this approach, a typical feature selection method based on sentence tagging is employed and a naive Bayes classifier is used to create a base classification model, which is then combined with certain heuristic rules for review sentence classification. Experiments show that this approach achieves better results than using general naive\u00a0\u2026", "num_citations": "36\n", "authors": ["1068"]}
{"title": "Multiobjective e-commerce recommendations based on hypergraph ranking\n", "abstract": " Recommender systems are emerging in e-commerce as important promotion tools to assist customers to discover potentially interesting items. Currently, most of these are single-objective and search for items that fit the overall preference of a particular user. In real applications, such as restaurant recommendations, however, users often have multiple objectives such as group preferences and restaurant ambiance. This paper highlights the need for multi-objective recommendations and provides a solution using hypergraph ranking. A general User\u2013Item\u2013Attribute\u2013Context data model is proposed to summarize different information resources and high-order relationships for the construction of a multipartite hypergraph. This study develops an improved balanced hypergraph ranking method to rank different types of objects in hypergraph data. An overall framework is then proposed as a guideline for the implementation\u00a0\u2026", "num_citations": "35\n", "authors": ["1068"]}
{"title": "Open set domain adaptation: Theoretical bound and algorithm\n", "abstract": " The aim of unsupervised domain adaptation is to leverage the knowledge in a labeled (source) domain to improve a model's learning performance with an unlabeled (target) domain--the basic strategy being to mitigate the effects of discrepancies between the two distributions. Most existing algorithms can only handle unsupervised closed set domain adaptation (UCSDA), i.e., where the source and target domains are assumed to share the same label set. In this article, we target a more challenging but realistic setting: unsupervised open set domain adaptation (UOSDA), where the target domain has unknown classes that are not found in the source domain. This is the first study to provide learning bound for open set domain adaptation, which we do by theoretically investigating the risk of the target classifier on unknown classes. The proposed learning bound has a special term, namely, open set difference, which\u00a0\u2026", "num_citations": "34\n", "authors": ["1068"]}
{"title": "FACETS: A cognitive business intelligence system\n", "abstract": " A cognitive decision support system called FACETS was developed and evaluated based on the situation retrieval (SR) model. The aim of FACETS is to provide decision makers cognitive decision support in ill-structured decision situations. The design and development of FACETS includes novel concepts, models, algorithms and system architecture, such as ontology and experience representation, situation awareness parsing, data warehouse query construction and guided situation presentation. The experiments showed that FACETS is able to play a significant role in supporting ill-structured decision making through developing and enriching situation awareness.", "num_citations": "34\n", "authors": ["1068"]}
{"title": "Adaptive pruning algorithm for least squares support vector machine classifier\n", "abstract": " As a new version of support vector machine (SVM), least squares SVM (LS-SVM) involves equality instead of inequality constraints and works with a least squares cost function. A well-known drawback in the LS-SVM applications is that the sparseness is lost. In this paper, we develop an adaptive pruning algorithm based on the bottom-to-top strategy, which can deal with this drawback. In the proposed algorithm, the incremental and decremental learning procedures are used alternately and a small support vector set, which can cover most of the information in the training set, can be formed adaptively. Using this set, one can construct the final classifier. In general, the number of the elements in the support vector set is much smaller than that in the training set and a sparse solution is obtained. In order to test the efficiency of the proposed algorithm, we apply it to eight UCI datasets and one benchmarking\u00a0\u2026", "num_citations": "34\n", "authors": ["1068"]}
{"title": "The Kth-best approach for linear bilevel multifollower programming with partial shared variables among followers\n", "abstract": " In a real world bilevel decision-making, the lower level of a bilevel decision usually involves multiple decision units. This paper proposes the Kth-best approach for linear bilevel multifollower programming problems with shared variables among followers. Finally a numeric example is given to show how the Kth-best approach works.", "num_citations": "33\n", "authors": ["1068"]}
{"title": "Fuzzy transfer learning using an infinite gaussian mixture model and active learning\n", "abstract": " Transfer learning is gaining considerable attention due to its ability to leverage previously acquired knowledge to assist in completing a prediction task in a related domain. Fuzzy transfer learning, which is based on fuzzy system (especially fuzzy rule-based models), has been developed because of its capability to deal with the uncertainty in transfer learning. However, two issues with fuzzy transfer learning have not yet been resolved: choosing an appropriate source domain and efficiently selecting labeled data for the target domain. This paper proposes an innovative method based on fuzzy rules that combines an infinite Gaussian mixture model (IGMM) with active learning to enhance the performance and generalizability of the constructed model. An IGMM is used to identify the data structures in the source and target domains providing a promising solution to the domain selection dilemma. Further, we exploit the\u00a0\u2026", "num_citations": "32\n", "authors": ["1068"]}
{"title": "Fuzzy rule-based domain adaptation in homogeneous and heterogeneous spaces\n", "abstract": " Domain adaptation aims to leverage knowledge acquired from a related domain (called a source domain) to improve the efficiency of completing a prediction task (classification or regression) in the current domain (called the target domain), which has a different probability distribution from the source domain. Although domain adaptation has been widely studied, most existing research has focused on homogeneous domain adaptation, where both domains have identical feature spaces. Recently, a new challenge proposed in this area is heterogeneous domain adaptation where both the probability distributions and the feature spaces are different. Moreover, in both homogeneous and heterogeneous domain adaptation, the greatest efforts and major achievements have been made with classification tasks, while successful solutions for tackling regression problems are limited. This paper proposes two innovative\u00a0\u2026", "num_citations": "32\n", "authors": ["1068"]}
{"title": "Deep additive least squares support vector machines for classification with model transfer\n", "abstract": " The additive kernel least squares support vector machine (AK-LS-SVM) has been well used in classification tasks due to its inherent advantages. For example, additive kernels work extremely well for some specific tasks, such as computer vision classification, medical research, and some specialized scenarios. Moreover, the analytical solution using AK-LS-SVM can formulate leave-one-out cross-validation error estimates in a closed form for parameter tuning, which drastically reduces the computational cost and guarantee the generalization performance especially on small and medium datasets. However, AK-LS-SVM still faces two main challenges: 1) improving the classification performance of AK-LS-SVM and 2) saving time when performing a grid search for model selection. Inspired by the stacked generalization principle and the transfer learning mechanism, a layer-by-layer combination of AK-LS-SVM\u00a0\u2026", "num_citations": "32\n", "authors": ["1068"]}
{"title": "A bi-objective two-stage robust location model for waste-to-energy facilities under uncertainty\n", "abstract": " Waste-to-energy (WTE) facilities have begun to play an increasingly important role in the management of municipal solid waste (MSW) worldwide. However, due to the environmental and economic impacts they impose on urban sustainability, the location of WTE facilities is always a sensitive issue. With the frequent involvement of private investors in WTE projects in recent years, the uncertainties associated with MSW generation often impose a huge financial risk on both the private investors involved and the government. Therefore, decision support for the location planning of WTE facilities is necessary and critical. A bi-objective two-stage robust model has been developed to help governments identify cost-effective and environmental-friendly WTE facility location strategies under uncertainty, in which one objective is to minimize worst-case annual government spending, while the other minimizes environmental\u00a0\u2026", "num_citations": "32\n", "authors": ["1068"]}
{"title": "A framework of hybrid recommender system for personalized clinical prescription\n", "abstract": " General practitioners are faced with a great challenge of clinical prescription owing to the increase of new drugs and their complex functions to different diseases. A personalized recommender system can help practitioners discover mass of medical knowledge hidden in history medical records to deal with information overload problem in prescription. To support practitioner's decision making in prescription, this paper proposes a framework of a hybrid recommender system which integrates artificial neural network and case-based reasoning. Three issues are considered in this system framework: (1) to define a patient's need by giving his/her symptom, (2) to mine features from free text in medical records and (3) to analyze temporal efficiency of drugs. The proposed recommender system is expected to help general practitioners to improve their efficiency and reduce risks of making errors in daily clinical consultation\u00a0\u2026", "num_citations": "31\n", "authors": ["1068"]}
{"title": "The role of situation awareness in accidents of large-scale technological systems\n", "abstract": " In the last two decades, several serious accidents at large-scale technological systems that have had grave consequences, such as that at Bhopal, have primarily been attributed to human error. However, further investigations have revealed that humans are not the primary cause of these accidents, but have inherited the problems and difficulties of working with complex systems created by engineers. The operators have to comprehend malfunctions in real time, respond quickly, and make rapid decisions to return operational units to normal conditions, but under these circumstances, the mental workload of operators rises sharply, and a mental workload that is too high increases the rate of error. Therefore, cognivitive human features such as situation awareness (SA)\u2014one of the most important prerequisite for decision-making\u2014should be considered and analyzed appropriately. This paper applys the SA Error\u00a0\u2026", "num_citations": "31\n", "authors": ["1068"]}
{"title": "A fuzzy multi-objective bilevel decision support system\n", "abstract": " In a bilevel decision problem, both the leader and the follower may have multiple objectives, and the coefficients involved in these objective functions or constraints may be described by some uncertain values. To express such a situation, a fuzzy multi-objective bilevel (FMOBL) programming model and related solution methods are introduced. This research develops a FMOBL decision support system through implementing the proposed FMOBL methods.", "num_citations": "31\n", "authors": ["1068"]}
{"title": "Fuzzy linear bilevel optimization: solution concepts, approaches and applications\n", "abstract": " Bilevel programming provides a means of supporting two level non-cooperative decision-making. When a decision maker at the upper level (the leader) attempts to optimize an objective, the decision maker at the lower level (the follower) tries to find an optimized strategy according to each of the possible decisions made by the leader. A bilevel decision model is normally based on experts\u2019 understanding of possible choices made by decision makers at both levels. The parameters, either in the objective functions or constraints of the leader or the follower in a bilevel decision model, are therefore hard to characterize by precise values. Hence this study proposes a fuzzy parameter linear bilevel programming model and its solution concept. It then develops three approaches to solve the proposed fuzzy linear bilevel programming problems by applying fuzzy set techniques. Finally, a numerical example and a\u00a0\u2026", "num_citations": "31\n", "authors": ["1068"]}
{"title": "A deeper graph neural network for recommender systems\n", "abstract": " Interaction data in recommender systems are usually represented by a bipartite user\u2013item graph whose edges represent interaction behavior between users and items. The data sparsity problem, which is common in recommender systems, is the result of insufficient interaction data in the link prediction on graphs. The data sparsity problem can be alleviated by extracting more interaction behavior from the bipartite graph, however, stacking multiple layers will lead to over-smoothing, in which case, all nodes will converge to the same value. To address this issue, we propose a deeper graph neural network in this paper that can predict links on a bipartite user\u2013item graph using information propagation. An attention mechanism is introduced to our method to address the problem that variable size inputs for each node on a bipartite graph. Our experimental results demonstrate that our proposed method outperforms five\u00a0\u2026", "num_citations": "30\n", "authors": ["1068"]}
{"title": "TruGRC: Trust-aware group recommendation with virtual coordinators\n", "abstract": " In recent years, an increase in group activities on websites has led to greater demand for highly-functional group recommender systems. The goal of group recommendation is to capture and distill the preferences of each group member into a single recommendation list that meets the needs of all group members. Existing aggregation functions perform well in harmonious and congruent scenarios, but tend not to generate satisfactory results when group members hold conflicting preferences. Moreover, most of current studies improve group recommendation only based on a single aggregation strategy and explicit trust information is still ignored in group recommender systems. Motivated by these concerns, this paper presents TruGRC, a novel Trust-aware Group Recommendation method with virtual Coordinators, that combines two different aggregation strategies: result aggregation and profile aggregation. As each\u00a0\u2026", "num_citations": "29\n", "authors": ["1068"]}
{"title": "Fuzzy clustering-based adaptive regression for drifting data streams\n", "abstract": " Current models and algorithms have been increasingly required to learn in a nonstationary environment because the phenomenon of concept drift (or pattern shift) may occur, that is, the assumption that data are identically distributed may be invalid in data streams. Once the data pattern changes, a well-trained model built on the previous, now obsolete data cannot provide an accurate prediction for future data. To obtain reliable prediction, it is important to understand the existing patterns in the data stream and to know which pattern the current examples belong to during the modeling process. However, it is ambiguous to classify an example to a certain pattern in many real-world cases. In this paper, we propose a novel adaptive regression approach, called FUZZ-CARE, to dynamically recognize, train, and store patterns, and assign the membership degree of the upcoming examples belonging to these patterns\u00a0\u2026", "num_citations": "29\n", "authors": ["1068"]}
{"title": "Risk management in decision making\n", "abstract": " Organizational decision making often occurs in the face of uncertainty about whether a decision maker\u2019s choices will lead to benefit or disaster. Risk is the potential that a decision will lead to a loss or an undesirable outcome. In fact, almost any human decision carries some risk, but some decisions are much more risky than others. Risk and decision making are two inter-related factors in organizational management, and they are both related to various uncertainties.", "num_citations": "29\n", "authors": ["1068"]}
{"title": "Cost-benefit factor analysis in e-services using bayesian networks\n", "abstract": " This study applies Bayesian network techniques to analyze and verify the relationships among cost factors and benefit factors in e-service systems. This study first establishes a Bayesian network for e-service cost-benefit factor relationships based on our previous study [Lu, J. & Zhang, G. Q. (2003). Cost benefit factor analysis in e-services. International Journal of Service Industry Management (IJSIM), 14(5), 570\u2013595]. It then calculates conditional probability distributions among these factors shown in the Bayesian network. Finally it runs a Junction-tree algorithm to conduct inference for verifying these cost-benefit factor relationships, and the data collected through a survey is as evidences in the inference process. Through the above application of Bayesian network techniques a set of useful findings is obtained for the costs involved in e-service developments against the benefits received by adopting these e-service\u00a0\u2026", "num_citations": "29\n", "authors": ["1068"]}
{"title": "Support vector machine-based multi-source multi-attribute information integration for situation assessment\n", "abstract": " Understanding any given situation requires integrating many pieces of information. Such information has in most cases multiple attributes and is obtained from multiple data sources within multiple time slots. Situation assessors\u2019 experience and preference will naturally influence the result of information integration, and hence influence the awareness generated for a situation. This study focuses on how multi-source multi-attribute information about a situation is integrated and how the awareness information for the situation is derived. A learning-based information integration approach, which embeds the fuzzy least squares support vector machine (FLS-SVM) technique, is developed in this study. This approach can assess a situation through integrating and inference obtained information and analyzing related data sources. A series of experiments show that the proposed approach has an accuracy learning ability\u00a0\u2026", "num_citations": "29\n", "authors": ["1068"]}
{"title": "Doubly nonparametric sparse nonnegative matrix factorization based on dependent Indian buffet processes\n", "abstract": " Sparse nonnegative matrix factorization (SNMF) aims to factorize a data matrix into two optimized nonnegative sparse factor matrices, which could benefit many tasks, such as document-word co-clustering. However, the traditional SNMF typically assumes the number of latent factors (i.e., dimensionality of the factor matrices) to be fixed. This assumption makes it inflexible in practice. In this paper, we propose a doubly sparse nonparametric NMF framework to mitigate this issue by using dependent Indian buffet processes (dIBP). We apply a correlation function for the generation of two stick weights associated with each column pair of factor matrices while still maintaining their respective marginal distribution specified by IBP. As a consequence, the generation of two factor matrices will be columnwise correlated. Under this framework, two classes of correlation function are proposed: 1) using bivariate Beta distribution\u00a0\u2026", "num_citations": "28\n", "authors": ["1068"]}
{"title": "Regularizing knowledge transfer in recommendation with tag-inferred correlation\n", "abstract": " Traditional recommender systems suffer from the data sparsity problem. However, user knowledge acquired in one domain can be transferred and exploited in several other relevant domains. In this context, cross-domain recommender systems have been proposed to create a new and effective recommendation paradigm in which to exploit rich data from auxiliary domains to assist recommendations in a target domain. Before knowledge transfer takes place, building reliable and concrete domain correlation is the key ensuring that only relevant knowledge will be transferred. Social tags are used to explicitly link different domains, especially when neither users nor items overlap. However, existing models only exploit a subset of tags that are shared by heterogeneous domains. In this paper, we propose a complete tag-induced cross-domain recommendation (CTagCDR) model, which infers interdomain and\u00a0\u2026", "num_citations": "27\n", "authors": ["1068"]}
{"title": "Cross-cultural education: learning methodology and behaviour analysis for Asian students in IT field of Australian universities\n", "abstract": " Australian tertiary education of information technology (IT) has attracted a large number of international students, particularly from Asia. Cultural factors have affected the quality of learning of international students and the teaching approaches adopted by Australian lecturers. Therefore, cross-cultural teaching and learning situations have become an important issue in Australian universities. This study intends to improve the understanding of Asian students' cultural backgrounds, their previous learning approaches and their perspectives on Australian culture and educational mode, with the objective of helping international students from different cultural backgrounds to overcome the difficulties of cross-cultural study. This study has completed a questionnaire survey of 1026 students, including 292 Information Technology (28.5%) students from five universities in Australia. Among these IT students, there are 100 (34.25%) local students and 192 (65.75%) international students from 39 other countries. The questionnaire contains 55 questions within six question sections and one information section. This paper presents comparison-based data analysis results of this survey on learning methodology and behaviours of Asian students in IT field of Australian universities. It particularly reveals the main difference for students between the universities in their home countries and in Australia, also the difficulties of these students during their study in Australian university through qualitative analysis on open questions of the survey. This paper also reports the research methodology and main findings in cross-culture teaching and learning generated from this\u00a0\u2026", "num_citations": "27\n", "authors": ["1068"]}
{"title": "Fuzzy bilevel programming: multi-objective and multi-follower with shared variables\n", "abstract": " Bilevel programming deals with hierarchical optimization problems in which the leader at the upper level attempts to optimize his or her objectives, but subject to a set of constraints and the follower's reactions. Typical bilevel programming considers one leader one follower situation and supposes each of them has only one objective. In real world situations, multiple followers may be involved and they may be with different relationships such as sharing decision variables or not, sharing objectives or not. Therefore, the leader's decision will be affected not only by those followers' reactions but also by their relationships. In addition, any of the leader and/or these followers may have multiple conflict objectives that should be optimized simultaneously. Furthermore, the parameters of a bilevel programming model may be described by uncertain values. This paper addresses all these three issues as a whole by particularly\u00a0\u2026", "num_citations": "27\n", "authors": ["1068"]}
{"title": "Team situation awareness using web-based fuzzy group decision support systems\n", "abstract": " Situation awareness (SA) is an important element to support responses and decision making to crisis problems. Decision making for a complex situation often needs a team to work cooperatively to get consensus awareness for the situation. Team SA is characterized including information sharing, opinion integration and consensus SA generation. In the meantime, various uncertainties are involved in team SA during information collection and awareness generation. Also, the collaboration between team members may be across distances and need web-based technology to facilitate. This paper presents a web-based fuzzy group decision support system (WFGDSS) and demonstrates how this system can provide a means of support for generating team SA in a distributed team work context with the ability of handling uncertain information.", "num_citations": "27\n", "authors": ["1068"]}
{"title": "Fuzzy bi-level decision-making techniques: a survey\n", "abstract": " Bi-level decision-making techniques aim to deal with decentralized management problems that feature interactive decision entities distributed throughout a bi-level hierarchy. A challenge in handling bi-level decision problems is that various uncertainties naturally appear in decision-making process. Significant efforts have been devoted that fuzzy set techniques can be used to effectively deal with uncertain issues in bi-level decision-making, known as fuzzy bi-level decision-making techniques, and researchers have successfully gained experience in this area. It is thus vital that an instructive review of current trends in this area should be conducted, not only of the theoretical research but also the practical developments. This paper systematically reviews up-to-date fuzzy bi-level decisionmaking techniques, including models, approaches, algorithms and systems. It also clusters related technique developments into\u00a0\u2026", "num_citations": "26\n", "authors": ["1068"]}
{"title": "A patent time series processing component for technology intelligence by trend identification functionality\n", "abstract": " Technology intelligence indicates the concept and applications that transform data hidden in patents or scientific literatures into technical insight for technology strategy-making support. The existing frameworks and applications of technology intelligence mainly focus on obtaining text-based knowledge with text mining components. However, what is the corresponding technological trend of the knowledge over time is seldom taken into consideration. In order to capture the hidden trend turning points and improve the framework of existing technology intelligence, this paper proposes a patent time series processing component with trend identification functionality. We use piecewise linear representation method to generate and quantify the trend of patent publication activities, then utilize the outcome to identify trend turning points and provide trend tags to the existing text mining component, thus making it\u00a0\u2026", "num_citations": "26\n", "authors": ["1068"]}
{"title": "A three-level-similarity measuring method of participant opinions in multiple-criteria group decision supports\n", "abstract": " Measuring opinion similarity between participants is an important strategy to reduce the chance of making and applying inappropriate decisions in multi-criteria group decision making applications. Due to the small-sized opinion data and the varieties of opinion representations, measuring the similarity between opinions is difficult and has not been well-studied in developing decision support. Considering that the similarity changes with the number of concerned criteria, this paper develops a gradual aggregation algorithm and establishes a three-level-similarity measuring (TLSM) method based on it to measure the opinion similarity at the assessment level, the criterion level and the problem level. Two applications of the TLSM method on social policy selection and energy policy evaluation are conducted. The study indicates that the TLSM method can effectively measure the similarity between opinions in small-size\u00a0\u2026", "num_citations": "26\n", "authors": ["1068"]}
{"title": "Multifollower trilevel decision making models and system\n", "abstract": " In a trilevel hierarchical decision problem, the objectives and variables of each decision entity at one level are controlled, in part, by the decision entities at other levels. The choice of values for the decision variables at each level may influence the decisions made at other levels, and may thereby improve/reduce the objective for each level. When multiple decision entities are involved at the middle and bottom levels of a trilevel decision problem, the top-level entity's decision will be affected, not only by these followers' individual reactions, but also by the relationships between them. We call this problem a multifollower trilevel (MFTL) decision. This paper firstly defines and analyzes various kinds of relationships between decision entities in an MFTL decision problem. We then propose an MFTL decision making framework, in which 64 standard MFTL decision situations and their possible combinations are identified. To\u00a0\u2026", "num_citations": "26\n", "authors": ["1068"]}
{"title": "On a generalized fuzzy goal optimization for solving fuzzy multi-objective linear programming problems\n", "abstract": " Many organizational decision problems can be formulated by multi-objective linear programming (MOLP) models. Referring to the imprecision inherent in human judgments, uncertainty may be incorporated in the parameters of an MOLP model when it is established, which is called a Fuzzy MOLP (FMOLP) problem. What is an optimal solution for an FMOLP problem is the first issue to deal with in this study. The second issue is how to effectively derive an optimal solution for an FMOLP problem since uncertainty is also reflected in a solution process of an FMOLP problem. By introducing three types of comparison of fuzzy numbers and an adjustable satisfactory degree \u03b1 in this study, a new solution concept of FMOLP is given. For handling the second issue, this study develops an interactive fuzzy goal optimization method which provides an interactive fashion with decision makers during their solution process and\u00a0\u2026", "num_citations": "26\n", "authors": ["1068"]}
{"title": "Fuzzy multiple-source transfer learning\n", "abstract": " Transfer learning is gaining increasing attention due to its ability to leverage previously acquired knowledge to assist in completing a prediction task in a related domain. Fuzzy transfer learning, which is based on fuzzy systems and particularly fuzzy rule-based models, was developed due to its capacity to deal with uncertainty. However, one issue with fuzzy transfer learning, even in the area of general transfer learning, has not been resolved: how to combine and then use knowledge when multiple-source domains are available. This study presents new methods for merging fuzzy rules from multiple domains for regression tasks. Two different settings are separately explored: homogeneous and heterogeneous space. In homogeneous situations, knowledge from the source domains is merged in the form of fuzzy rules. In heterogeneous situations, knowledge is merged in the form of both data and fuzzy rules\u00a0\u2026", "num_citations": "25\n", "authors": ["1068"]}
{"title": "Discovering and forecasting interactions in big data research: A learning-enhanced bibliometric study\n", "abstract": " As one of the most impactful emerging technologies, big data analytics and its related applications are powering the development of information technologies and are significantly shaping thinking and behavior in today's interconnected world. Exploring the technological evolution of big data research is an effective way to enhance technology management and create value for research and development strategies for both government and industry. This paper uses a learning-enhanced bibliometric study to discover interactions in big data research by detecting and visualizing its evolutionary pathways. Concentrating on a set of 5840 articles derived from Web of Science covering the period between 2000 and 2015, text mining and bibliometric techniques are combined to profile the hotspots in big data research and its core constituents. A learning process is used to enhance the ability to identify the interactive\u00a0\u2026", "num_citations": "25\n", "authors": ["1068"]}
{"title": "Hierarchy visualization for group recommender systems\n", "abstract": " Most recommender systems (RSs), especially group RSs, focus on methods and accuracy but lack explanations, hence users find them difficult to trust. We present a hierarchy visualization method for group recommender (HVGR) systems to provide visual presentation and intuitive explanation. We first use a hierarchy graph to organize all the entities using nodes (e.g., neighbor nodes and recommendation nodes) and illustrate the overall recommender process using edges. Second, a pie chart is attached to every entity node in which each slice represents a single member, which makes it easy to track the influence of each member on a specific entity. HVGR can be extended to adapt different pseudouser modeling methods by resizing group member nodes and pseudouser nodes. It can also be easily extended to individual RSs through the use of a single member group. An implementation has been developed and\u00a0\u2026", "num_citations": "25\n", "authors": ["1068"]}
{"title": "An entropy-based indicator system for measuring the potential of patents in technological innovation: rejecting moderation\n", "abstract": " How to evaluate the value of a patent in technological innovation quantitatively and systematically challenges bibliometrics. Traditional indicator systems and weighting approaches mostly lead to \u201cmoderation\u201d results; that is, patents ranked to a top list can have only good-looking values on all indicators rather than distinctive performances in certain individual indicators. Orienting patents authorized by the United States Patent and Trademark Office (USPTO), this paper constructs an entropy-based indicator system to measure their potential in technological innovation. Shannon\u2019s entropy is introduced to quantitatively weight indicators and a collaborative filtering technique is used to iteratively remove negative patents. What remains is a small set of positive patents with potential in technological innovation as the output. A case study with 28,509 USPTO-authorized patents with Chinese assignees, covering the\u00a0\u2026", "num_citations": "25\n", "authors": ["1068"]}
{"title": "A framework for delivering personalized e-government services from a citizen-centric approach\n", "abstract": " E-government is becoming more attentive towards providing intelligent personalized online services to citizens so that citizens can receive better services with less time and effort. This paper proposes a new conceptual framework for delivering personalized e-government services to citizens from a citizen-centric approach, called Pe-Gov service framework. This framework outlines the main components and their interconnections. Detailed explanations about these components are given and the special features of this framework are highlighted. The Pe-Gov framework has the potential to outperform the existing e-Gov service systems as illustrated by two real life examples.", "num_citations": "25\n", "authors": ["1068"]}
{"title": "Using general fuzzy number to handle uncertainty and imprecision in group decision-making\n", "abstract": " In order to handle uncertain or imprecise opinions of decision makers in group decision-making, this paper proposes an integrated fuzzy group decision-making algorithm and a related method. The method allows decision makers using linguistic terms to describe their fuzzy opinions, including their fuzzy preferences for alternative solutions, fuzzy judgments for solution selection criteria and fuzzy weights of group members in a group decision-making. This method deals with simultaneously and aggregates the three groups of linguistic terms to arrive a group consensus decision. The group consensus decision is the most acceptable one for the group as a whole. Particularly, the proposed algorithm uses general fuzzy number to describe the uncertainty and imprecision happened to decision individuals and decision processes. It can therefore use any forms of fuzzy number including triangular fuzzy number\u00a0\u2026", "num_citations": "25\n", "authors": ["1068"]}
{"title": "Artificial intelligence in recommender systems\n", "abstract": " Recommender systems provide personalized service support to users by learning their previous behaviors and predicting their current preferences for particular products. Artificial intelligence (AI), particularly computational intelligence and machine learning methods and algorithms, has been naturally applied in the development of recommender systems to improve prediction accuracy and solve data sparsity and cold start problems. This position paper systematically discusses the basic methodologies and prevailing techniques in recommender systems and how AI can effectively improve the technological development and application of recommender systems. The paper not only reviews cutting-edge theoretical and practical contributions, but also identifies current research issues and indicates new research directions. It carefully surveys various issues related to recommender systems that use AI, and\u00a0\u2026", "num_citations": "24\n", "authors": ["1068"]}
{"title": "Fuzzy bridged refinement domain adaptation: Long-term bank failure prediction\n", "abstract": " Machine learning methods, such as neural network (NN) and support vector machine, assume that the training data and the test data are drawn from the same distribution. This assumption may not be satisfied in many real world applications, like long-term financial failure prediction, because the training and test data may each come from different time periods or domains. This paper proposes a novel algorithm known as fuzzy bridged refinement-based domain adaptation to solve the problem of long-term prediction. The algorithm utilizes the fuzzy system and similarity concepts to modify the target instances' labels which were initially predicted by a shift-unaware prediction model. The experiments are performed using three shift-unaware prediction models based on nine different settings including two main situations: (1) there is no labeled instance in the target domain; (2) there are a few labeled instances in the\u00a0\u2026", "num_citations": "24\n", "authors": ["1068"]}
{"title": "Incremental collaborative filtering based on Mahalanobis distance and fuzzy membership for recommender systems\n", "abstract": " Recommender systems, as an effective personalization approach, can suggest best-suited items (products or services) to particular users based on their explicit and implicit preferences by applying information filtering technology. Collaborative filtering (CF) method is currently the most popular and widely adopted recommendation approach. It works by collecting user ratings for items in a given domain and by computing the similarity between the profiles of several users in order to recommend items. Current similarity measures and models updated by traditional model-based CF have, however, shortcomings with respect to accuracy of prediction and scalability of recommender systems. To overcome these problems, here an incremental CF algorithm based on the Mahalanobis distance is presented. The algorithm has two phases: the learning phase, in which models of similar users are constructed incrementally\u00a0\u2026", "num_citations": "24\n", "authors": ["1068"]}
{"title": "Multi-criteria group decision support with linguistic variables in long-term scenarios for belgian energy policy\n", "abstract": " Real world decisions often made in the presence of multiple, conflicting, and incommensurate criteria. Decision making requires multiple perspectives of different individuals as more decisions are made now in groups than ever before. This is particularly true when the decision environment becomes more complex such as sustainability policies study in environmental and energy sectors. Group decision making processes judgments or solutions for decision problems based on the input and", "num_citations": "24\n", "authors": ["1068"]}
{"title": "Enhancing fashion recommendation with visual compatibility relationship\n", "abstract": " With the increasing of online shopping services, fashion recommendation plays an important role in daily online shopping scenes. A lot of recommender systems have been developed with visual information. However, few works take into account compatibility relationship when they are generating recommendations. The challenge is that fashion concept is often subtle and subjective for different customers. In this paper, we propose a fashion compatibility knowledge learning method that incorporates visual compatibility relationships as well as style information. We also propose a fashion recommendation method with domain adaptation strategy to alleviate the distribution gap between the items in target domain and the items of external compatible outfits. Our results indicate that the proposed method is capable of learning visual compatibility knowledge and outperforms all the baselines.", "num_citations": "23\n", "authors": ["1068"]}
{"title": "A multi-objective load balancing system for cloud environments\n", "abstract": " Virtual machine (VM) live migration has been applied to system load balancing in cloud environments for the purpose of minimizing VM downtime and maximizing resource utilization. However, the migration process is both time- and cost-consuming as it requires the transfer of large size files or memory pages and consumes a huge amount of power and memory for the origin and destination physical machine (PM), especially for storage VM migration. This process also leads to VM downtime or slowdown. To deal with these shortcomings, we develop a Multi-objective Load Balancing (MO-LB) system that avoids VM migration and achieves system load balancing by transferring extra workload from a set of VMs allocated on an overloaded PM to other compatible VMs in the cluster with greater capacity. To reduce the time factor even more and optimize load balancing over a cloud cluster, MO-LB contains a CPU\u00a0\u2026", "num_citations": "23\n", "authors": ["1068"]}
{"title": "Diffusion-based recommendation with trust relations on tripartite graphs\n", "abstract": " The diffusion-based recommendation approach is a vital branch in recommender systems, which successfully applies physical dynamics to make recommendations for users on bipartite or tripartite graphs. Trust links indicate users' social relations and can provide the benefit of reducing data sparsity. However, traditional diffusion-based algorithms only consider rating links when making recommendations. In this paper, the complementarity of users' implicit and explicit trust is exploited, and a novel resource-allocation strategy is proposed, which integrates these two kinds of trust relations on tripartite graphs. Through empirical studies on three benchmark datasets, our proposed method obtains better performance than most of the benchmark algorithms in terms of accuracy, diversity and novelty. According to the experimental results, our method is an effective and reasonable way to integrate additional features into\u00a0\u2026", "num_citations": "23\n", "authors": ["1068"]}
{"title": "An area defuzzification technique to assess nuclear event reliability data from failure possibilities\n", "abstract": " Reliability data is essential for a nuclear power plant probabilistic safety assessment by fault tree analysis to assess the performance of the safety-related systems. The limitation of conventional reliability data arises from insufficient historical data for probabilistic calculation. This study describes a new approach to calculate nuclear event reliability data by utilizing the concept of failure possibilities, which are expressed in qualitative natural languages, mathematically represented by membership functions of fuzzy numbers, and subjectively justified by a group of experts based on their working experience and expertise. We also propose an area defuzzification technique to convert the membership function into nuclear event reliability data. The actual event reliability data, which are collected from the operational experiences of the reactor protection system in Babcock & Wilcox pressurized water reactor between 1984\u00a0\u2026", "num_citations": "23\n", "authors": ["1068"]}
{"title": "A state-based knowledge representation approach for information logical inconsistency detection in warning systems\n", "abstract": " Detecting logical inconsistency in collected information is a vital function when deploying a knowledge-based warning system to monitor a specific application domain for the reason that logical inconsistency is often hidden from seemingly consistent information and may lead to unexpected results. Existing logical inconsistency detection methods usually focus on information stored in a knowledge base by using a well-defined general purpose knowledge representation approach, and therefore cannot fulfill the demands of a domain-specific situation. This paper first proposes a state-based knowledge representation approach, in which domain-specific knowledge is expressed by combinations of the relevant objects\u2019 states. Based on this approach, a method for information logical inconsistency detection (ILID) is developed which can flexibly handle the demands of various domain-specific situations through reducing\u00a0\u2026", "num_citations": "23\n", "authors": ["1068"]}
{"title": "Multilevel Life-event Abstraction Framework for E-government Service Integration\n", "abstract": " One of the fundamental attributes of modern government service delivery mechanism is the ability to offer a citizen-centric view of the government model. Life-event model is the most widely adopted paradigm supporting the idea of composing a single complex service that corresponds to an event in a citizen's life. Elementary building blocks of Life-event are based on atomic services offered from multiple government agencies. Composite services are desirable mainly because of their added value to businesses and government agencies. This study found that the methodological mechanics of service integration, and in particular, the requirements engineering for services integration has been overlooked. It introduces a multilevel modelling framework for analysis and design of Life-event within the government service integration context based on the principle of abstraction. It also proposes a top down multilevel abstraction approach to model Life-event candidates and elicit their requirements and specification. This study explains the problem space of e-government service delivery integration, and stresses the ontology analysis and modelling as one of the essential requirements for modelling Life-events.", "num_citations": "23\n", "authors": ["1068"]}
{"title": "Handbook on decision making: Vol 2: Risk management in decision making\n", "abstract": " This book presents innovative theories, methodologies, and techniques in the field of risk management and decision making. It introduces new research developments and provides a comprehensive image of their potential applications to readers interested in the area. The collection includes: computational intelligence applications in decision making, multi-criteria decision making under risk, risk modelling, forecasting and evaluation, public security and community safety, risk management in supply chain and other business decision making, political risk management and disaster response systems. The book is directed to academic and applied researchers working on risk management, decision making, and management information systems.", "num_citations": "22\n", "authors": ["1068"]}
{"title": "Recommendation technique-based government-to-business personalized e-services\n", "abstract": " One of the new directions in current e-government development is to provide personalized online services to citizens and businesses. Recommendation techniques can bring a possible solution for this issue. This study proposes a hybrid recommendation approach to provide personalized government to business (G2B) e-services. The approach integrates fuzzy sets-based semantic similarity and traditional item-based collaborative filtering methods to improve recommendation accuracy. A recommender system named Intelligent Business Partner Locator (IBPL) is designed to apply the proposed recommendation approach for supporting government agencies to recommend business partners.", "num_citations": "22\n", "authors": ["1068"]}
{"title": "A Bayesian nonparametric model for multi-label learning\n", "abstract": " Multi-label learning has become a significant learning paradigm in the past few years due to its broad application scenarios and the ever-increasing number of techniques developed by researchers in this area. Among existing state-of-the-art works, generative statistical models are characterized by their good generalization ability and robustness on large number of labels through learning a low-dimensional label embedding. However, one issue of this branch of models is that the number of dimensions needs to be fixed in advance, which is difficult and inappropriate in many real-world settings. In this paper, we propose a Bayesian nonparametric model to resolve this issue. More specifically, we extend a Gamma-negative binomial process to three levels in order to capture the label-instance-feature structure. Furthermore, a mixing strategy for Gamma processes is designed to account for the multiple labels\u00a0\u2026", "num_citations": "21\n", "authors": ["1068"]}
{"title": "Bayesian nonparametric relational topic model through dependent gamma processes\n", "abstract": " Traditional relational topic models provide a successful way to discover the hidden topics from a document network. Many theoretical and practical tasks, such as dimensional reduction, document clustering, and link prediction, could benefit from this revealed knowledge. However, existing relational topic models are based on an assumption that the number of hidden topics is known a priori, which is impractical in many real-world applications. Therefore, in order to relax this assumption, we propose a nonparametric relational topic model using stochastic processes instead of fixed-dimensional probability distributions in this paper. Specifically, each document is assigned a Gamma process, which represents the topic interest of this document. Although this method provides an elegant solution, it brings additional challenges when mathematically modeling the inherent network structure of typical document network, i.e\u00a0\u2026", "num_citations": "21\n", "authors": ["1068"]}
{"title": "A fuzzy dynamic bayesian network-based situation assessment approach\n", "abstract": " Situation awareness (SA), a state in the mind of a human, is essential to conduct decision-making activities. It is about the perception of the elements in the environment, the comprehension of their meaning, and the projection of their status in the near future. Two decades of investigation and analysis of accidents have showed that SA was behind of many serious large-scale technological systems' accidents. This emphasizes the importance of SA support systems development for complex and dynamic environments. This paper presents a fuzzy dynamic Bayesian network-based situation assessment approach to support the operators in decision making process in hazardous situations. The approach includes a dynamic Bayesian network-based situational network to model the hazardous situations where the existence of the situations can be inferred by sensor observations through the SCADA monitoring system\u00a0\u2026", "num_citations": "21\n", "authors": ["1068"]}
{"title": "An online fuzzy decision support system for resource management in cloud environments\n", "abstract": " Cloud computing is a large-scale distributed computing paradigm driven by economies of scale, in which a pool of abstracted, virtualized, dynamically-scalable, managed computing power, storage, platforms, and services are delivered on demand to external customers over the Internet. Although a significant amount of studies have been developed to optimize resource management and task scheduling in cloud computing, none of them considered the impact of task scheduling patterns on resource management and vice versa. To overcome this drawback, and considering the lack of resources in cloud environments and growing customer demands for cloud services, this paper proposes an Online Resource Management Decision Support System (ORMDSS) that addresses both tasks scheduling and resource management optimization in a unique system. In addition, ORMDSS contains a fuzzy prediction method\u00a0\u2026", "num_citations": "21\n", "authors": ["1068"]}
{"title": "Government-to-business personalized e-services using semantic-enhanced recommender system\n", "abstract": " The information overload problem results in the under-use of some existing e-Government services. Recommender systems have proven to be an effective solution to the information overload problem by providing users with information and services specific to their needs, rather than an undifferentiated mass of information. This paper focuses on how e-Governments can support businesses, which are seeking \u2018one-to-one\u2019 e-services, on the problem of finding adequate business partners. For this purpose, a Hybrid Semantic-enhanced Collaborative Filtering (HSeCF) recommendation approach to provide personalized Government-to-Business (G2B) e-services, and in particular, business partner recommendation e-services for Small to Medium Businesses is proposed. Experimental results on two data sets, MovieLens and BizSeeker, show that the proposed HSeCF approach significantly outperforms the\u00a0\u2026", "num_citations": "21\n", "authors": ["1068"]}
{"title": "Modelling heterogeneity among experts in multi-criteria group decision making problems\n", "abstract": " Heterogeneity in group decision making problems has been recently studied in the literature. Some instances of these studies include the use of heterogeneous preference representation structures, heterogeneous preference representation domains and heterogeneous importance degrees. On this last heterogeneity level, the importance degrees are associated to the experts regardless of what is being assessed by them, and these degrees are fixed through the problem. However, there are some situations in which the experts\u2019 importance degrees do not depend only on the expert. Sometimes we can find sets of heterogeneously specialized experts, that is, experts whose knowledge level is higher on some alternatives and criteria than it is on any others. Consequently, their importance degree should be established in accordance with what is being assessed. Thus, there is still a gap on heterogeneous\u00a0\u2026", "num_citations": "21\n", "authors": ["1068"]}
{"title": "Integrating multi-criteria collaborative filtering and trust filtering for personalized recommender systems\n", "abstract": " Recommender Systems are information systems that attempt to recommend items of interest to particular users based on their explicit and implicit preferences. Multi-Criteria Decision Making (MCDM) aims at assisting the decision maker in the decision making process, or giving the decision maker a recommendation, concerning a set of actions, alternatives, items etc. Thus, despite their differences, Recommender Systems and Multi-Criteria Decision Making share the same objective which is supporting the decision making process and reducing information overload. In this paper we propose a novel hybrid Multi-Criteria Trust-enhanced CF (MC-TeCF) approach. The proposed MC-TeCF approach combines the MC user-based CF and the MC user-based Trust filtering approaches to alleviate the standard Single-Criteria user-based CF limitations. Empirical results demonstrate the significance and effectiveness of the\u00a0\u2026", "num_citations": "21\n", "authors": ["1068"]}
{"title": "Power distribution system planning evaluation by a fuzzy multi-criteria group decision support system\n", "abstract": " The evaluation of solutions is an important phase in power distribution system planning (PDSP) which allows issues such as quality of supply, cost, social service and environmental implications to be considered and usually involves the judgments of a group of experts. The planning problem is thus suitable for the multi-criteria group decision-making (MCGDM) method. The evaluation process and evaluation criteria often involve uncertainties incorporated in quantitative analysis with crisp values and qualitative judgments with linguistic terms; therefore, fuzzy sets techniques are applied in this study. This paper proposes a fuzzy multi-criteria group decision-making (FMCGDM) method for PDSP evaluation and applies a fuzzy multi-criteria group decision support system (FMCGDSS) to support the evaluation task. We introduce a PDSP evaluation model, which has evaluation criteria within three levels, based on the\u00a0\u2026", "num_citations": "21\n", "authors": ["1068"]}
{"title": "A transfer-based additive LS-SVM classifier for handling missing data\n", "abstract": " The performance of a classifier might greatly deteriorate due to missing data. Many different techniques to handle this problem have been developed. In this paper, we solve the problem of missing data using a novel transfer learning perspective and show that when an additive least squares support vector machine (LS-SVM) is adopted, model transfer learning can be used to enhance the classification performance on incomplete training datasets. A novel transfer-based additive LS-SVM classifier is accordingly proposed. This method also simultaneously determines the influence of classification errors caused by each incomplete sample using a fast leave-one-out cross validation strategy, as an alternative way to clean the training data to further improve the data quality. The proposed method has been applied to seven public datasets. The experimental results indicate that the proposed method achieves at least\u00a0\u2026", "num_citations": "20\n", "authors": ["1068"]}
{"title": "Tri-level decision-making for decentralized vendor-managed inventory\n", "abstract": " Vendor-managed inventory (VMI) is a common inventory management policy which allows the vendor to manage the buyer's inventory based on the information shared in the course of supply chain management. One challenge in VMI is that both the vendor and buyer are manufacturers who try to achieve an inventory as small as possible or even a zero inventory; it is therefore difficult to manage inventory coordination between them. This paper considers a decentralized VMI problem in a three-echelon supply chain network in which multiple distributors (third-party logistics companies) are selected to balance the inventory between a vendor (manufacturer) and multiple buyers (manufacturers). To handle this issue, this paper first proposes a tri-level decision model to describe the decentralized VMI problem, which allows us to examine how decision members coordinate with each other in respect of decentralized VMI\u00a0\u2026", "num_citations": "20\n", "authors": ["1068"]}
{"title": "A multi-objective optimization model for virtual machine mapping in cloud data centres\n", "abstract": " Modern cloud computing environments exploit virtualization for efficient resource management to reduce computational cost and energy budget. Virtual machine (VM) migration is a technique that enables flexible resource allocation and increases the computation power and communication capability within cloud data centers. VM migration helps cloud providers to successfully achieve various resource management objectives such as load balancing, power management, fault tolerance, and system maintenance. However, the VM migration process can affect the performance of applications unless it is supported by smart optimization methods. This paper presents a multi-objective optimization model to address this issue. The objectives are to minimize power consumption, maximize resource utilization (or minimize idle resources), and minimize VM transfer time. Fuzzy particle swarm optimization (PSO), which\u00a0\u2026", "num_citations": "20\n", "authors": ["1068"]}
{"title": "Long term bank failure prediction using fuzzy refinement-based transductive transfer learning\n", "abstract": " Machine learning algorithms, which have been considered as robust methods in different computational fields, assume that the training and test data are drawn from the same distribution. This assumption may be violated in many real world applications like bank failure prediction because training and test data may come from different time periods or domains. An efficient novel algorithm known as Fuzzy Refinement (FR) is proposed in this paper to solve this problem and improve the performance. The algorithm utilizes the fuzzy system and similarity concept to modify the instances' labels in target domain which was initially predicted by shift-unaware Fuzzy Neural Network (FNN) proposed by [1]. The experiments are performed using bank failure financial data of United States to evaluate the algorithm performance. The results address a significant improvement in the predictive accuracy of FNN due to applying the\u00a0\u2026", "num_citations": "20\n", "authors": ["1068"]}
{"title": "A framework of hybrid recommendation system for government-to-business personalized e-services\n", "abstract": " One of the challenges facing e-governments is how to provide businesses with services and information specific to their needs, rather than an undifferentiated mass of information. One way to achieve this is through the design and development of personalized government e-services using recommendation systems. To this purpose, this study presents a personalized hybrid recommender system framework to handle personalized recommendations in G2B e-services, in particular, business partner matching e-services. The proposed framework employs a hybrid trust-based multi-criteria recommendation model which integrates the techniques of trust-based filtering with the multi-criteria CF. The proposed system can be used to reduce the time, cost and risk of businesses involved in entering international markets and thus improve the quality of G2B e-services.", "num_citations": "20\n", "authors": ["1068"]}
{"title": "Personalized e-government services: Tourism recommender system framework\n", "abstract": " Most governments around the globe use the internet and information technologies to deliver information and services for citizens and businesses. One of the main directions in the current e-government (e-Gov) development strategy is to provide better online services to citizens such that the required information can be located by citizens with less time and effort. Tourism is one of the main focused areas of e-Gov development strategy because it is one of the major profitable industries. Significant efforts have been devoted by governments to improve tourism services. However, the current e-Gov tourism services are limited to simple online presentation; intelligent e-Gov tourism services are highly desirable. Personalization techniques, particularly recommendation systems, are the most promising techniques to deliver personalized e-Gov (Pe-Gov) tourism services. This study proposes ontology-based\u00a0\u2026", "num_citations": "20\n", "authors": ["1068"]}
{"title": "Decision Making in Multi-Issue e-Market Auction Using Fuzzy Attitudes,\n", "abstract": " Online auctions are one of the most effective ways of negotiation of salable goods over the internet. Software agents are increasingly being used to represent humans in online auctions. These agents can systematically monitor a wide variety of auctions and can make rapid decisions about what bids to place in what auctions. To be successful in open multi-agent environments, agents must be capable of adapting different strategies and tactics to their prevailing circumstances. This paper presents a software test-bed for studying autonomous bidding strategies in simulated auctions for procuring goods. It shows that agents\u2019 bidding strategy explore the attitudes and behaviors that help agents to manage dynamic assessment of prices of goods given the different criteria and scenario conditions. Our agent also uses fuzzy techniques for the decision making: to make decisions about the outcome of auctions, and to alter the agent\u2019s bidding strategy in response to the different criteria and market conditions.", "num_citations": "20\n", "authors": ["1068"]}
{"title": "An algorithm for fuzzy multi-objective multi-follower partial cooperative bilevel programming\n", "abstract": " In a bilevel decision problem, both the leader and the follower may have multiple objectives to optimize under certain constraints. In the meantime, these objective functions and constraints may contain some uncertain parameters. In addition, there may have multiple followers involved in a bilevel decision problem. These followers may share their individual decision variables with each other but keep individual objectives in reacting any of the leader's decisions, which is a common situation in real bilevel decision activities. This study deals with all above three issues, fuzzy parameters, multi-objectives, and multi-followers in a partial cooperative situation, at the same time. After a set of models for describing different cases of the fuzzy multi-objective multi-follower bilevel programming with partial cooperation (FMMBP-PC) problem, this paper develops an approximation branch-and-bound algorithm to solve this problem.", "num_citations": "20\n", "authors": ["1068"]}
{"title": "Two-stage fuzzy multiple kernel learning based on Hilbert\u2013Schmidt independence criterion\n", "abstract": " Multiple kernel learning (MKL) is a principled approach to kernel combination and selection for a variety of learning tasks, such as classification, clustering, and dimensionality reduction. In this paper, we develop a novel fuzzy multiple kernel learning model based on the Hilbert-Schmidt independence criterion (HSIC) for classification, which we call HSIC-FMKL. In this model, we first propose an HSIC Lasso-based MKL formulation, which not only has a clear statistical interpretation that minimum redundant kernels with maximum dependence on output labels are found and combined, but also enables the global optimal solution to be computed efficiently by solving a Lasso optimization problem. Since the traditional support vector machine (SVM) is sensitive to outliers or noises in the dataset, fuzzy SVM (FSVM) is used to select the prediction hypothesis once the optimal kernel has been obtained. The main advantage\u00a0\u2026", "num_citations": "19\n", "authors": ["1068"]}
{"title": "The explosion at institute: Modeling and analyzing the situation awareness factor\n", "abstract": " In 2008 a runaway chemical reaction caused an explosion at a methomyl unit in West Virginia, USA, killing two employees, injuring eight people, evacuating more than 40,000 residents adjacent to the facility, disrupting traffic on a nearby highway and causing significant business loss and interruption. Although the accident was formally investigated, the role of the situation awareness (SA) factor, i.e., a correct understanding of the situation, and appropriate models to maintain SA, remain unexplained. This paper extracts details of abnormal situations within the methomyl unit and models them into a situational network using dynamic Bayesian networks. A fuzzy logic system is used to resemble the operator\u2019s thinking when confronted with these abnormal situations. The combined situational network and fuzzy logic system make it possible for the operator to assess such situations dynamically to achieve accurate SA\u00a0\u2026", "num_citations": "19\n", "authors": ["1068"]}
{"title": "Similarity measure models and algorithms for hierarchical cases\n", "abstract": " Many business situations such as events, products and services, are often described in a hierarchical structure. When we use case-based reasoning (CBR) techniques to support business decision-making, we require a hierarchical-CBR technique which can effectively compare and measure similarity between two hierarchical cases. This study first defines hierarchical case trees (HC-trees) and discusses related features. It then develops a similarity evaluation model which takes into account all the information on nodes\u2019 structures, concepts, weights, and values in order to comprehensively compare two hierarchical case trees. A similarity measure algorithm is proposed which includes a node concept correspondence degree computation algorithm and a maximum correspondence tree mapping construction algorithm, for HC-trees. We provide two illustrative examples to demonstrate the effectiveness of the\u00a0\u2026", "num_citations": "19\n", "authors": ["1068"]}
{"title": "A bilevel model for railway train set organizing optimization\n", "abstract": " The 2007 International Conference Proceedings on Intelligent Systems and Knowledge Engineering (ISKE2007) contain 284 final accepted papers from 797 online submissions for ISEKE2007. ISKE2007 is the 2nd in a series of conferences on Intelligent Systems and Knowledge Engineering. It follows the successful ISKE2006 in Shanghai, and is held at Southwest Jiaotong University, Chengdu, PR China, Oct. 15\u201316, 2007. All submitted papers went through a rigorous review process with an acceptance ratio of 36%.", "num_citations": "19\n", "authors": ["1068"]}
{"title": "Developing a knowledge-based multi-objective decision support system\n", "abstract": " Decision support systems under multiple objectives (MODSS) has been classified as a specific type of system within the broad family of DSS and has been one of the most active areas of research. However, despite its theoretical development large scale real-world applications of multiobjective decision-making (MODM) methods had been seriously lacking due to the technical knowledge and expertise needed to select and apply the most appropriate method. This paper explores the possibility of embedding intelligent guidance within MODSS, and outlines a specific guidance framework for the design of knowledge-based guidance for the selection of a suitable MODM method. This framework has been implemented as an intelligent and graphical user interface based multiple objective decision support system prototype. The prototype, with its database, methodology base of MODM and knowledge based system\u00a0\u2026", "num_citations": "19\n", "authors": ["1068"]}
{"title": "Driving fatigue prediction with pre-event electroencephalography (EEG) via a recurrent fuzzy neural network\n", "abstract": " We propose an electroencephalography (EEG) prediction system based on a recurrent fuzzy neural network (RFNN) architecture to assess drivers' fatigue degrees during a virtual-reality (VR) dynamic driving environment. Prediction of fatigue degrees is a crucial and arduous biomedical issue for driving safety, which has attracted growing attention of the research community in the recent past. Meanwhile, combined with the benefits of measuring EEG signals facilitates, many EEG-based brain-computer interfaces (BCIs) have been developed for use in real-time mental assessment. In the literature, EEG signals are severely blended with stochastic noise; therefore, the performance of BCIs is constrained by low resolution in recognition tasks. For this rationale, independent component analysis (ICA) is usually used to find a source mapping from original data that has been blended with unrelated artificial noise\u00a0\u2026", "num_citations": "18\n", "authors": ["1068"]}
{"title": "A situation retrieval model for cognitive decision support in digital business ecosystems\n", "abstract": " This paper presents a novel situation retrieval (SR) model for supporting cognition-driven decision processes in digital business ecosystems. Cognitive decision support in digital ecosystems is concerned with decision makers' cognitive processes. This study aims to facilitate cognitive decision support to decision makers on the basis of current business intelligence (BI) platform. Underlying foundations of the SR model are two types of mental constructs: situation awareness (SA) and mental models of decision makers and the model of naturalistic decision making (NDM). These mental constructs and NDM are integrated into the BI application framework. Our experiments showed that the SR model was playing a nontrivial role to help decision makers develop enhanced SA and reuse their past experience to make better decisions.", "num_citations": "18\n", "authors": ["1068"]}
{"title": "Pricing analysis in online auctions using clustering and regression tree approach\n", "abstract": " Auctions can be characterized by distinct nature of their feature space. This feature space may include opening price, closing price, average bid rate, bid history, seller and buyer reputation, number of bids and many more. In this paper, a price forecasting agent (PFA) is proposed using data mining techniques to forecast the end-price of an online auction for autonomous agent based system. In the proposed model, the input auction space is partitioned into groups of similar auctions by k-means clustering algorithm. The recurrent problem of finding the value of k in k-means algorithm is solved by employing elbow method using one way analysis of variance (ANOVA). Based on the transformed data after clustering, bid selector nominates the cluster for the current auction whose price is to be forecasted. Regression trees are employed to predict the end-price and designing the optimal bidding strategies for the\u00a0\u2026", "num_citations": "18\n", "authors": ["1068"]}
{"title": "A Hybrid approach for fault tree analysis combining probabilistic method with fuzzy numbers\n", "abstract": " Conventional fault tree analysis in safety analysis of complex engineering systems calculates the occurrence probability of the top undesired event using probabilistic failure rates. However, it is often very difficult to obtain those failure rates well in advance due to insufficient data, environment changing or new components. Fuzzy numbers can be applied to estimate failure rates by handling linguistic terms. This study proposes a hybrid approach of Fuzzy Numbers and Fault Tree Analysis to solve the conventional problem and describes its procedures using a case study of emergency core cooling system of a typical nuclear power plant.", "num_citations": "18\n", "authors": ["1068"]}
{"title": "A course recommender system using multiple criteria decision making method\n", "abstract": " A recommender system is a specific type of information filtering technique that presents the user-relevant information, which is implemented by creating a user's profile and comparing it to the other existing reference characteristics stored in the database. This paper developed a course recommender system capable of helping prospective students to choose relevant post graduate courses by multiple criteria decision making method. First, the multiple criteria decision making method was given. Then, the system prototype, which aimed at amalgamating the multiple criteria decision making model and the collaborative filtering recommendation system, was described. Finally the system architecture was illustrated.", "num_citations": "18\n", "authors": ["1068"]}
{"title": "Effectiveness of e-government online services in Australia\n", "abstract": " Electronic government (e-government) breaks down the barrier of distance and time, and offers the potential for government to better deliver its contents and services, and interact with citizens and businesses. Australia has been recognized as one of e-government leaders internationally. All the three levels (federal, state and local) of Australian government organizations have increasingly embraced e-government. With few years of e-government practices in Australia, it is critical to evaluate the current applications and explore more effective strategies for the next phase of e-government. This study aims to identify what factors affect the effectiveness of Australian e-government online services. In the study, a research model is proposed and data collections are completed based on two questionnaire-based surveys from internal and external users of Australian e-government Web sites respectively. Furthermore, data\u00a0\u2026", "num_citations": "18\n", "authors": ["1068"]}
{"title": "Butterfly: A panacea for all difficulties in wildly unsupervised domain adaptation\n", "abstract": " In unsupervised domain adaptation (UDA), classifiers for the target domain (TD) are trained with clean labeled data from the source domain (SD) and unlabeled data from TD. However, in the wild, it is hard to acquire a large amount of perfectly clean labeled data in SD given limited budget. Hence, we consider a new, more realistic and more challenging problem setting, where classifiers have to be trained with noisy labeled data from SD and unlabeled data from TD\u2014we name it wildly UDA (WUDA). We show that WUDA provably ruins all UDA methods if taking no care of label noise in SD, and to this end, we propose a Butterfly framework, a panacea for all difficulties in WUDA. Butterfly maintains four models (eg, deep networks) simultaneously, where two take care of all adaptations (ie, noisy-toclean, labeled-to-unlabeled, and SD-to-TD-distributional) and then the other two can focus on classification in TD. As a consequence, Butterfly possesses all the necessary components for all the challenges in WUDA. Experiments demonstrate that under WUDA, Butterfly significantly outperforms existing baseline methods.", "num_citations": "17\n", "authors": ["1068"]}
{"title": "Mixed similarity diffusion for recommendation on bipartite networks\n", "abstract": " In recommender systems, collaborative filtering technology is an important method to evaluate user preference through exploiting user feedback data, and has been widely used in industrial areas. Diffusion-based recommendation algorithms inspired by diffusion phenomenon in physical dynamics are a crucial branch of collaborative filtering technology, which use a bipartite network to represent collection behaviors between users and items. However, diffusion-based recommendation algorithms calculate the similarity between users and make recommendations by only considering implicit feedback but neglecting the benefits from explicit feedback data, which would be a significant feature in recommender systems. This paper proposes a mixed similarity diffusion model to integrate both explicit feedback and implicit feedback. First, cosine similarity between users is calculated by explicit feedback, and we integrate\u00a0\u2026", "num_citations": "17\n", "authors": ["1068"]}
{"title": "A bilevel optimization model and a PSO-based algorithm in day-ahead electricity markets\n", "abstract": " Strategic bidding problems are becoming key issues in competitive electricity markets. This paper applies bilevel optimization theory to deal with this issue. We first analyze generating company strategic bidding behaviors and build a bilevel optimization model for a day-ahead electricity market. In this bilevel optimization model, each generating company will choose their bids in order to maximize their individual profits. A market operator will determine the output power for each unit and uniform marginal price based on the minimization purchase electricity fare. For solving this competitive strategic bidding problem described by the bilevel optimization model, a particle swarm optimization (PSO)-based algorithm is. Experiment results have demonstrated the validity of the PSO-based algorithm in solving the competitive strategic bidding problems for a day-ahead electricity market.", "num_citations": "17\n", "authors": ["1068"]}
{"title": "Fuzzy multi-objective bilevel decision making by an approximation K th-best approach\n", "abstract": " Many industrial decisions problems are decentralized in which decision makers are arranged at two levels, called bilevel decision problems. Bilevel decision making may involve uncertain parameters which appear either in the objective functions or constraints of the leader or the follower or both. Furthermore, the leader and the follower may have multiple conflict decision objectives that should be optimized simultaneously. This study proposes an approximation K th-best approach to solve the fuzzy multiobjective bilevel problem. Two case based examples further illustrate how to use the approach to solve industrial decision problems. \u00a9 2008 Old City Publishing. Inc.", "num_citations": "17\n", "authors": ["1068"]}
{"title": "An \u03b1-Fuzzy Goal Approximate Algorithm for Solving Fuzzy Multiple Objective Linear Programming Problems\n", "abstract": " Multiple conflicting objectives in many decision making problems can be well described by multiple objective linear programming (MOLP) models. This paper deals with the vague and imprecise information in a multiple objective problem by fuzzy numbers to represent parameters of an MOLP model. This so-called fuzzy MOLP (or FMOLP) model will reflect some uncertainty in the problem solution process since most decision makers often have imprecise goals for their decision objectives. This study proposes an approximate algorithm based on a fuzzy goal optimization under the satisfactory degree \u03b1 to handle both fuzzy and imprecise issues. The concept of a general fuzzy number is used in the proposed algorithm for an FMOLP problem with fuzzy parameters. As a result, this algorithm will allow decision makers to provide fuzzy goals in any form of membership functions.", "num_citations": "17\n", "authors": ["1068"]}
{"title": "Semantic structure-based word embedding by incorporating concept convergence and word divergence\n", "abstract": " Representing the semantics of words is a fundamental task in text processing. Several research studies have shown that text and knowledge bases (KBs) are complementary sources for word embedding learning. Most existing methods only consider relationships within word-pairs in the usage of KBs. We argue that the structural information of well-organized words within the KBs is able to convey more effective and stable knowledge in capturing semantics of words. In this paper, we propose a semantic structure-based word embedding method, and introduce concept convergence and word divergence to reveal semantic structures in the word embedding learning process. To assess the effectiveness of our method, we use WordNet for training and conduct extensive experiments on word similarity, word analogy, text classification and query expansion. The experimental results show that our method outperforms state-of-the-art methods, including the methods trained solely on the corpus, and others trained on the corpus and the KBs.", "num_citations": "16\n", "authors": ["1068"]}
{"title": "Modeling technological topic changes in patent claims\n", "abstract": " Patent claims usually embody the most essential terms and the core technological scope to define the protection of an invention, which makes them the ideal resource for patent content and topic change analysis. However, manually conducting content analysis on massive technical terms is very time consuming and laborious. Even with the help of traditional text mining techniques, it is still difficult to model topic changes over time, because single keywords alone are usually too general or ambiguous to represent a concept. Moreover, term frequency which used to define a topic cannot separate polysemous words that are actually describing a different theme. To address this issue, this research proposes a topic change identification approach based on Latent Dirichlet Allocation to model and analyze topic changes with minimal human intervention. After textual data cleaning, underlying semantic topics hidden in\u00a0\u2026", "num_citations": "16\n", "authors": ["1068"]}
{"title": "Text categorization by fuzzy domain adaptation\n", "abstract": " Machine learning methods have attracted attention of researches in computational fields such as classification/categorization. However, these learning methods work under the assumption that the training and test data distributions are identical. In some real world applications, the training data (from the source domain) and test data (from the target domain) come from different domains and this may result in different data distributions. Moreover, the values of the features and/or labels of the data sets could be non-numeric and contain vague values. In this study, we propose a fuzzy domain adaptation method, which offers an effective way to deal with both issues. It utilizes the similarity concept to modify the target instances' labels, which were initially classified by a shift-unaware classifier. The proposed method is built on the given data and refines the labels. In this way it performs completely independently of the shift\u00a0\u2026", "num_citations": "16\n", "authors": ["1068"]}
{"title": "Failure possibilities for nuclear safety assessment by fault tree analysis\n", "abstract": " Fault tree analysis (FTA) is a deductive tool to assess the safety of nuclear power plants. This analysis can only be implemented if all basic events in the tree have their corresponding failure rates. Therefore, safety analysts have to provide those failure rates well in advance. However, it is often difficult to obtain those failure rates due to insufficient data, changing environment or new components. This paper proposes a failure possibility based FTA approach to overcome the limitation of the conventional FTA for nuclear safety assessment. It utilises the concept of failure possibilities to evaluate basic event failure without historical data, fuzzy numbers to map component failure possibilities into mathematical form and defuzzification algorithms to convert fuzzy numbers into component failure rates. A case study on evaluating a typical high pressure core spray system of a boiling water reactor illustrates the applicability of\u00a0\u2026", "num_citations": "16\n", "authors": ["1068"]}
{"title": "Adaptive Inference-based learning and rule generation algorithms in fuzzy neural network for failure prediction\n", "abstract": " Creating an applicable and precise failure prediction system is highly desirable for decision makers and regulators in the finance industry. This study develops a new Failure Prediction (FP) approach which effectively integrates a fuzzy logic-based adaptive inference system with the learning ability of a neural network to generate knowledge in the form of a fuzzy rule base. This FP approach uses a preprocessing phase to deal with the imbalanced data-sets problem and develops a new Fuzzy Neural Network (FNN) including an adaptive inference system in the learning algorithm along with its network structure and rule generation algorithm as a means to reduce prediction error in the FP approach.", "num_citations": "16\n", "authors": ["1068"]}
{"title": "The design of a knowledge-based guidance system for an intelligent multiple objective decision support system (IMODSS)\n", "abstract": " This paper describes a project that extends the multiple objective decision support system (MODSS) by offering knowledge-based guidance to an intelligent multiple objective decision support system (IMODSS).  This IMODSS integrates expert system (ES), multiple objective decision-making (MODM) methodologies, graphical user interface (GUI) and decision support systems (DSS) technologies.  This IMODSS uses an expert system shell CLIPS to build a knowledge base to guide the decision-makers (DMs) to select the most suitable MODM method(s) from the MODM methodology base in order to solve their particular decision problems.  This IMODSS has been implemented and tested.  This paper mainly discusses the design and implementation of the knowledge-based intelligent guidance subsystem in IMODSS.", "num_citations": "16\n", "authors": ["1068"]}
{"title": "Multi-source heterogeneous unsupervised domain adaptation via fuzzy-relation neural networks\n", "abstract": " In unsupervised domain adaptation (UDA), classifier for a target domain is trained with labeled source data and unlabeled target data. Existing UDA methods assume that the source data come from the same source domain (i.e., single-source scenario) or from multiple source domains whose feature spaces have the same dimension (homogeneous) but different distributions (i.e., multi-homogeneous-source scenario). However, in the real world, for a specific target domain, we probably have multiple different-dimension (heterogeneous) source domains, which does not satisfy the assumption of existing UDA methods. To remove this assumption and move forward to a realistic UDA problem, this paper presents a shared-fuzzy-equivalence-relations neural network (SFERNN) for addressing multi-source heterogeneous unsupervised domain adaptation problem. SFERNN is a five-layer neural network containing c\u00a0\u2026", "num_citations": "15\n", "authors": ["1068"]}
{"title": "Fuzzy user-interest drift detection based recommender systems\n", "abstract": " Recommender systems aim to provide personalized suggestions to users by modeling user-interests to deal with information overload problem, which is extremely severe in the era of big data. Since user-interests are drifting due to their taste variation on items, recommender systems without considering that will suffer degradation of prediction accuracy. There are two challenges about adapting to user-interest drift in recommender systems: 1) accurately modeling user-interests is not easy since the drift of user-interests may occur in different direction for each user; 2) item features and user-interests are often incomplete and vague, which makes it more difficult to model user-interests. To handle these two issues, this study proposes a fuzzy user-interest drift detection based recommender system that adapts to user-interest drift and improves prediction accuracy. A fuzzy user-interest consistency model is built based on\u00a0\u2026", "num_citations": "15\n", "authors": ["1068"]}
{"title": "Infinite author topic model based on mixed gamma-negative binomial process\n", "abstract": " Incorporating the side information of text corpus, i.e., authors, time stamps, and emotional tags, into the traditional text mining models has gained significant interests in the area of information retrieval, statistical natural language processing, and machine learning. One branch of these works is the so-called Author Topic Model (ATM), which incorporates the authors's interests as side information into the classical topic model. However, the existing ATM needs to predefine the number of topics, which is difficult and inappropriate in many real-world settings. In this paper, we propose an Infinite Author Topic (IAT) model to resolve this issue. Instead of assigning a discrete probability on fixed number of topics, we use a stochastic process to determine the number of topics from the data itself. To be specific, we extend a gamma-negative binomial process to three levels in orderto capture the author-document-keyword\u00a0\u2026", "num_citations": "15\n", "authors": ["1068"]}
{"title": "Intelligent financial warning model using fuzzy neural network and case-based reasoning\n", "abstract": " Creating an applicable and precise financial early warning model is highly desirable for decision makers and regulators in the financial industry. Although Business Failure Prediction (BFP) especially banks has been extensively a researched area since late 1960s, the next critical step which is the decision making support scheme has been ignored. This paper presents a novel model for financial warning which combines a fuzzy inference system with the learning ability of neural network as a Fuzzy Neural Network (FNN) to predict organizational financial status and also applies reasoning capability of Fuzzy Case-Based Reasoning (FCBR) to support decision makers measuring appropriate solutions. The proposed financial warning model generates an adaptive fuzzy rule base to predict financial status of target case and then if it is predicted to fail, the FCBR is used to find similar survived cases. Finally according\u00a0\u2026", "num_citations": "15\n", "authors": ["1068"]}
{"title": "Life-event modelling framework for e-government integration\n", "abstract": " Ability to offer a citizen-centric view of government model is the key to a successful e-government service. Life-event model is the most widely adopted paradigm supporting the idea of composing a single complex e-government service that corresponds to an event in a citizen's life. Elementary building blocks of Life-event are based on atomic services offered from multiple government agencies. This study found that methodological mechanics of service integration and in particular the requirements engineering for composite services has been overlooked. Purpose of this study is to define obstacles of achieving e-government service delivery integration, and suggests a framework based on ontological analysis and modelling. Proposed framework that shall be called E-Service Integration Modelling (E-SIM) is based on the extensive use of Life-event concept. This paper proposes a top-down abstraction approach in\u00a0\u2026", "num_citations": "15\n", "authors": ["1068"]}
{"title": "An Extended Kth-Best Approach For Referential-Uncooperative Bilevel Multi-Follower Decision Making\n", "abstract": " Bilevel decision techniques have been mainly developed for solving decentralized management problems with decision makers in a hierarchical organization. When multiple followers are involved in a bilevel decision problem, called a bilevel multi-follower (BLMF) decision problem, the leader's decision will be affected, not only by the reactions of these followers, but also by the relationships among these followers. The referential-uncooperative situation is one of the popular cases of BLMF decision problems where these multiple followers don't share decision variables with each other but may take others' decisions as references to their decisions. This paper presents a model for the referential-uncooperative BLMF decision problem. As the kth-best approach is one of the most successful approaches in dealing with normal bilevel decision problems, this paper then proposes an extended kth-best approach to solve\u00a0\u2026", "num_citations": "15\n", "authors": ["1068"]}
{"title": "A methodological framework for e-government service delivery integration\n", "abstract": " Non-interoperability between government agency e-service delivery mechanisms posing the technical challenge, and the lack of formulated modelling and implementation framework is the main methodological problem in achieving seamless E-government integration. In this paper integration of E-government is investigated (at Service Delivery Level) to achieve a seamless and cost-effective transition to one-stop-shop E-government service delivery. This paper proposes a methodological solution for a seamless and optimal intelligent E-government service delivery system. The solution consists of two distinct yet related components. The first component is an integration methodology driven from generic classical software development methodologies to help formulise the integration process. The second component is an implementation framework that will insure an integrated common interface to provide a unified presentation and functional structure for all government agencies at all levels of government.", "num_citations": "15\n", "authors": ["1068"]}
{"title": "Clarinet: A one-step approach towards budget-friendly unsupervised domain adaptation\n", "abstract": " In unsupervised domain adaptation (UDA), classifiers for the target domain are trained with massive true-label data from the source domain and unlabeled data from the target domain. However, it may be difficult to collect fully-true-label data in a source domain given a limited budget. To mitigate this problem, we consider a novel problem setting where the classifier for the target domain has to be trained with complementary-label data from the source domain and unlabeled data from the target domain named budget-friendly UDA (BFUDA). The key benefit is that it is much less costly to collect complementary-label source data (required by BFUDA) than collecting the true-label source data (required by ordinary UDA). To this end, the complementary label adversarial network (CLARINET) is proposed to solve the BFUDA problem. CLARINET maintains two deep networks simultaneously, where one focuses on classifying complementary-label source data and the other takes care of the source-to-target distributional adaptation. Experiments show that CLARINET significantly outperforms a series of competent baselines.", "num_citations": "14\n", "authors": ["1068"]}
{"title": "Output based transfer learning with least squares support vector machine and its application in bladder cancer prognosis\n", "abstract": " Two dilemmas frequently occur in many real-world clinical prognoses. First, the on-hand data cannot be put entirely into the existing prediction model, since the features from new data do not perfectly match those of the model. As a result, some unique features collected from the patients in the current domain of interest might be wasted. Second, the on-hand data is not sufficient enough to learn a new prediction model. To overcome these challenges, we propose an output-based transfer learning approach with least squares support vector machine (LS-SVM) to make the maximum use of the small dataset and guarantee an enhanced generalization capability. The proposed approach can learn a current domain of interest with limited samples effectively by leveraging the knowledge from the predicted outputs of the existing model in the source domain. Also, the extent of output knowledge transfer from the source\u00a0\u2026", "num_citations": "14\n", "authors": ["1068"]}
{"title": "Concept drift detection based on equal density estimation\n", "abstract": " An important problem that remains in online data mining systems is how to accurately and efficiently detect changes in the underlying distribution of large data streams. The challenge for change detection methods is to maximise the accumulative effect of changing regions with unknown distribution, while at the same time providing sufficient information to describe the nature of the changes. In this paper, we propose a novel change detection method based on the estimation of equal density regions, with the aim of overcoming the issues of instability and inefficiency that underlie methods of predefined space partitioning schemes. Our method is general, nonparametric and requires no prior knowledge of the data distribution. A series of experiments demonstrate that our method effectively detects concept drift in single dimension as well as high dimension data, and is also able to explain the change by locating the\u00a0\u2026", "num_citations": "14\n", "authors": ["1068"]}
{"title": "Task based system load balancing approach in cloud environments\n", "abstract": " Live virtual machine (VM) migration is a technique for transferring an active VM from one physical host to another without disrupting the VM. This technique has been proposed to reduce the downtime for migrated overload VMs. As VMs migration takes much more times and cost in comparison with tasks migration, this study develops a novel approach to confront with the problem of overload VM and achieving system load balancing, by assigning the arrival task to another similar VM in a cloud environment. In addition, we propose a multi-objective optimization model to migrate these tasks to a new VM host applying multi-objective genetic algorithm (MOGA). In the proposed approach, there is no need to pause VM during migration time. In addition, as contrast to tasks migration, VM live migration takes longer to complete and needs more idle capacity in host physical machine (PM), the proposed approach will\u00a0\u2026", "num_citations": "14\n", "authors": ["1068"]}
{"title": "A fuzzy tree similarity measure and its application in telecom product recommendation\n", "abstract": " The recommender systems field has been well developed in the last few years to provide item recommendations to related users. Existing recommendation approaches, however, assume that an item is described by a single value or a vector. Unfortunately, some items in real world applications, such as telecom products, could have a tree structure. This paper aims to handle this issue by developing a comprehensive fuzzy tree similarity measure. The fuzzy tree similarity measure compares both the concepts and values in two trees of items. The focus of this study is primarily on the fuzzy value similarity between two trees. In the similarity measure, each attribute is associated with a set of linguistic terms to express the value granularly. The node values are first transformed to membership vectors related to the linguistic terms, and the values of the conceptual corresponding nodes are then compared. These local\u00a0\u2026", "num_citations": "14\n", "authors": ["1068"]}
{"title": "Determining pattern similarity in a medical recommender system\n", "abstract": " As recommender systems have proven their effectiveness in other areas, it is aimed to transfer this approach for use in medicine. Particularly, the diagnoses of physicians made in rural hospitals of developing countries, in remote areas or in situations of uncertainty are to be complemented by machine recommendations drawing on large bases of expert knowledge in order to reduce the risk to patients. Recommendation is mainly based on finding known patterns similar to a case under consideration. To search for such patterns in rather large databases, a weighted similarity distance is employed, which is specially derived for medical knowledge. For collaborative filtering an incremental algorithm, called W-InCF, is used working with the Mahalanobis distance and fuzzy membership. W-InCF consists of a learning phase, in which a cluster model of patients\u2019 medical history is constructed incrementally, and a\u00a0\u2026", "num_citations": "14\n", "authors": ["1068"]}
{"title": "Delta-equalities of complex fuzzy relations\n", "abstract": " A complex fuzzy relation is defined as a fuzzy relation whose membership function takes values in the unit circle on a complex plane. This paper first investigates various operation properties of a complex fuzzy relation. It then defines the distance measure of two complex fuzzy relations that can measure the differences between the grades as well as the phases of two complex fuzzy relations. This distance measure is used to define \u03b4-equalities of complex fuzzy relations that coincide with those of fuzzy relations already defined in the literature if complex fuzzy relations reduce to real-valued fuzzy relations. Two complex fuzzy relations are said to be \u03b4-equal if the distance between them is less than 1-\u03b4. This paper shows how various operations between complex fuzzy relations, including T-norms and S-norms, affect given \u03b4-equalities of complex fuzzy relations. Finally, fuzzy inference is examined in the framework of\u00a0\u2026", "num_citations": "14\n", "authors": ["1068"]}
{"title": "Solution concepts and an approximation Kuhn\u2013Tucker approach for fuzzy multiobjective linear bilevel programming\n", "abstract": " When modeling an organizational bilevel decision problem, uncertainty often appears in the parameters of either objective functions or constraints of the leader and the follower. Furthermore, the leader and the follower may have multiple objectives to consider simultaneously in their decision making. To deal with the two issues, this study builds a fuzzy multiobjective linear bilevel programming (FMOLBLP) model. It then proposes the definitions of optimal solutions and related theorems for solving a FMOLBLP problem. Based on these theorems, it develops an approximation Kuhn\u2013Tucker approach to solve the FMOLBLP problem where fuzzy parameters can be described by any form of membership functions of fuzzy numbers. An example illustrates the applications of the proposed approach.", "num_citations": "14\n", "authors": ["1068"]}
{"title": "An approximation branch-and-bound algorithm for fuzzy bilevel decision making problems\n", "abstract": " Organizational decision making often involves two decision levels. When the leader at the upper level attempts to optimize his/her objective, the follower at the lower level tries to find an optimized strategy according to each of possible decisions made by the leader. Furthermore, such bilevel decision making may involve uncertain parameters which appear either in the objective functions or constraints of the leader or the follower. Following our previous work on fuzzy bilevel decision making, this study proposes a solution concept and related theorems for general- fuzzy-number based fuzzy parameter bilevel programming problems. It then develops an approximation Branch-and-bound algorithm to solve the proposed problem. \u00a9 2006 PIPS.", "num_citations": "14\n", "authors": ["1068"]}
{"title": "Combining one class classification models for avian influenza outbreaks\n", "abstract": " The prediction of avian influenza outbreak animal cases is a genuine one class classification issue because the real world outliers are impractical to obtain. In this paper, a new combining one class classification method has been presented and illustrated on the avian influenza outbreak dataset. The presented combining methods outperform the previous combining methods both on the original avian influenza outbreak dataset and dimension reduction one. The new one classification combining model can be adapted to the warning surveillance purpose and proved to be practical on the avian influenza outbreak prediction tasks.", "num_citations": "13\n", "authors": ["1068"]}
{"title": "An exploratory cognitive business intelligence system\n", "abstract": " An exploratory study of Web-based cognitive business intelligence systems (CBIS) is presented in this paper. The underpinning concepts and theories are situation awareness, mental model, and naturalistic decision making (NDM). The CBIS is an extension of the traditional business intelligence system with cognitive orientation. It focuses on developing, enriching, and utilizing the executive's situation awareness, mental models, and other past experience during human-computer interaction, which drives the decision process to approach a naturalistic decision.", "num_citations": "13\n", "authors": ["1068"]}
{"title": "How does the Combined Risk Affect the Performance of Unsupervised Domain Adaptation Approaches?\n", "abstract": " Unsupervised domain adaptation (UDA) aims to train a target classifier with labeled samples from the source domain and unlabeled samples from the target domain. Classical UDA learning bounds show that target risk is upper bounded by three terms: source risk, distribution discrepancy, and combined risk. Based on the assumption that the combined risk is a small fixed value, methods based on this bound train a target classifier by only minimizing estimators of the source risk and the distribution discrepancy. However, the combined risk may increase when minimizing both estimators, which makes the target risk uncontrollable. Hence the target classifier cannot achieve ideal performance if we fail to control the combined risk. To control the combined risk, the key challenge takes root in the unavailability of the labeled samples in the target domain. To address this key challenge, we propose a method named E-MixNet. E-MixNet employs enhanced mixup, a generic vicinal distribution, on the labeled source samples and pseudo-labeled target samples to calculate a proxy of the combined risk. Experiments show that the proxy can effectively curb the increase of the combined risk when minimizing the source risk and distribution discrepancy. Furthermore, we show that if the proxy of the combined risk is added into loss functions of four representative UDA methods, their performance is also improved.", "num_citations": "12\n", "authors": ["1068"]}
{"title": "Cross-domain recommendation with semantic correlation in tagging systems\n", "abstract": " The tagging system provides users with a platform to express their preferences as they annotate terms or keywords to items. Tag information is a bridge between two domains for transferring knowledge and helping to alleviate the data sparsity problem, which is a crucial and challenging problem in most recommender systems. Existing methods incorporate correlations extracted from overlapping tags at a lexical level in cross-domain recommendation, but they neglect semantical relationships between different tags, which impairs prediction accuracy in the target domain. To solve this challenging problem, we propose a cross-domain recommendation method with semantic correlation in tagging systems. This method automatically captures the semantic relationships between non-identical tags and applies them to the recommendation. The word2vec technique is used to learn the latent representations of tags\u00a0\u2026", "num_citations": "12\n", "authors": ["1068"]}
{"title": "Requirement-oriented core technological components\u2019 identification based on SAO analysis\n", "abstract": " Technologies play an important role in the survival and development of enterprises. Understanding and monitoring the core technological components (e.g., technology process, operation method, function) of a technology is an important issue for researchers to develop R&D policy and manage product competitiveness. However, it is difficult to identify core technological components from a mass of terms, and we may experience some difficulties with describing complete technical details and understanding the terms-based results. This paper proposes a Subject-Action-Object (SAO)-based method, in which (1) a syntax-based approach is constructed to extract the SAO structures describing the function, relationship and operation in specified topics; (2) a systematic method is built to extract and screen technological components from SAOs; and (3) we propose a \u201crelevance indicator\u201d to calculate the relevance\u00a0\u2026", "num_citations": "12\n", "authors": ["1068"]}
{"title": "Pessimistic bilevel optimization model for risk-averse production-distribution planning\n", "abstract": " Production-distribution (PD) planning problems are often addressed in an organizational hierarchy in which a distribution company that utilizes several depots is the leader and the manufacturing companies are the followers. The classical objective function of the leader is to minimize the total operating cost of the distribution company, and the followers optimize their respective production cost. However, the distribution company (the leader) frequently cannot obtain complete production information from the manufacturing companies, and may thus become risk-averse. In this case, a better description of the leader\u2019s objective function is the minimization of the maximum possible operating cost (Min-Max). In this paper, this type of PD problem is called a risk-averse PD planning problem and is formulated as a pessimistic mixed-integer bilevel optimization (PMIBO) model from the worst-case point of view. To solve the\u00a0\u2026", "num_citations": "12\n", "authors": ["1068"]}
{"title": "A fuzzy content matching-based e-commerce recommendation approach\n", "abstract": " E-Commerce products often come with rich and tree-structured content information describing the attributes. To well utilize the content information, this study proposed a fuzzy content matching-based recommendation approach to assist e-Commerce customers to choose their truly interested items. In this paper, users' ratings and preferences are represented using fuzzy numbers to remain uncertainties. Tree-structured content information is transformed to a set of descriptors, and users' preferences on these descriptors are derived from fuzzy ratings by using fuzzy number operations. A kind of preference dependence relations is established between descriptors to explore the relations of different content features, and as a base to sketch the complete profile of users. While the extended preference profile of a user is established, given a new item, the fuzzy match degree of the user preference and the item content\u00a0\u2026", "num_citations": "12\n", "authors": ["1068"]}
{"title": "Solving tri-level programming problems using a particle swarm optimization algorithm\n", "abstract": " Tri-level programming, a special case of multilevel programming, arises to deal with decentralized decision-making problems that feature interacting decision entities distributed throughout three hierarchical levels. As tri-level programming problems are strongly NP-hard and the existing solution approaches lack universality in solving such problems, the purpose of this study is to propose an intelligence-based heuristic algorithm to solve tri-level programming problems involving linear and nonlinear versions. In this paper, we first propose a general tri-level programming problem and discuss related theoretical properties. A particle swarm optimization (PSO) algorithm is then developed to solve the tri-level programming problem. Lastly, a numerical example is adopted to illustrate the effectiveness of the proposed PSO algorithm.", "num_citations": "12\n", "authors": ["1068"]}
{"title": "Investigation of sequential pattern mining techniques for web recommendation\n", "abstract": " Increased application of sequence mining in web recommender systems (WRS) requires a better understanding of the performance and a clear identification of the strengths and weaknesses of existing algorithms. Among the commonly used sequence mining methods, the tree-based approach, such as pre-order linked WAP-tree mining algorithm (PLWAP-Mine) and conditional sequence mining algorithm (CS-Mine), has demonstrated high performance in web mining applications. However, its advantages over other mining methods are not well explained and understood in the context of WRS. This paper firstly reviews the existing sequence mining algorithms, and then studies the performance of two outstanding algorithms, i.e., the PLWAP-Mine and CS-Mine algorithms, with respect to their sensitivity to the dataset variability, and their practicality for web recommendation. The results show that CS-Mine performs\u00a0\u2026", "num_citations": "12\n", "authors": ["1068"]}
{"title": "Data mining driven agents for predicting online auction's end price\n", "abstract": " Auctions can be characterized by distinct nature of their feature space. This feature space may include opening price, closing price, average bid rate, bid history, seller and buyer reputation, number of bids and many more. In this paper, a clustering based method is used to forecast the end-price of an online auction for autonomous agent based system. In the proposed model, the input auction space is partitioned into groups of similar auctions by k-means clustering algorithm. The recurrent problem of finding the value of k in k-means algorithm is solved by employing elbow method using one way analysis of variance (ANOVA). Then k numbers of regression models are employed to estimate the forecasted price of an online auction. Based on the transformed data after clustering and the characteristics of the current auction, bid selector nominates the regression model for the current auction whose price is to be\u00a0\u2026", "num_citations": "12\n", "authors": ["1068"]}
{"title": "Probabilistic safety assessment in nuclear power plants by fuzzy numbers\n", "abstract": " Probabilistic safety assessment in nuclear power plants (NPPs) greatly considers plant safety and optimal plant design. Plant specific data are usually recommended to analyze safety in NPPs. However, such NPP specific data are not always available in practice. This paper presents an approach by combining fuzzy numbers and expert justification to assess an NPP probabilistic failure rate in the absence of statistical data. The proposed approach illustrates a case study for high pressure core spray systems of boiling water reactors.", "num_citations": "12\n", "authors": ["1068"]}
{"title": "Ontology-style web usage model for semantic web applications\n", "abstract": " Current semantic recommender systems aim to exploit the website ontologies to produce valuable web recommendations. However, Web usage knowledge for recommendation is presented separately and differently from the domain ontology, this leads to the complexity of using inconsistent knowledge resources. This paper aims to solve this problem by proposing a novel ontology-style model of Web usage to represent the non-taxonomic visiting relationship among the visited pages. The output of this model is an ontology-style document which enables the discovered web usage knowledge to be sharable and machine-understandable in semantic Web applications, such as recommender systems. A case study is presented to show how this model is used in conjunction of the web usage mining and web recommendation. Two real-world datasets are used in the case study.", "num_citations": "12\n", "authors": ["1068"]}
{"title": "A hybrid knowledge-based prediction method for avian influenza early warning\n", "abstract": " High pathogenic avian influenza remains rampant and the epidemic size has been growing in the world. The early warning system (EWS) for avian influenza becomes increasingly essential to militating against the risk of outbreak crisis. An EWS can generate timely early warnings to support decision makers in identifying underlying vulnerabilities and implementing relevant strategies. This paper addresses this crucial issue and focuses on how to make full use of previous events to perform comprehensive forecasting and generate reliable warning signals. It proposes a hybrid knowledge-based prediction (HKBP) method which combines case-based reasoning (CBR) with the fuzzy logic technique. The method can improve the prediction accuracy for avian influenza in a specific region at a specific time. An example is presented to illustrate the capabilities and procedures of the HKBP method.", "num_citations": "12\n", "authors": ["1068"]}
{"title": "A \u03bb-cut approximate algorithm for goal-based bilevel risk management systems\n", "abstract": " Bilevel programming techniques are developed for decentralized decision problems with decision makers located in two levels. Both upper and lower decision makers, termed as leader and follower, try to optimize their own objectives in solution procedure but are affected by those of the other levels. When a bilevel decision model is built with fuzzy coefficients and the leader and/or follower have goals for their objectives, we call it fuzzy goal bilevel (FGBL) decision problem. This paper first proposes a \u03bb-cut set based FGBL model. A programmable \u03bb-cut approximate algorithm is then presented in detail. Based on this algorithm, a FGBL software system is developed to reach solutions for FGBL decision problems. Finally, two examples are given to illustrate the application of the proposed algorithm.", "num_citations": "12\n", "authors": ["1068"]}
{"title": "Fuzzy multi-criteria group decision support in long-term options of Belgian energy policy\n", "abstract": " Decision making requires multiple perspectives of different people as one single decision maker may have not enough knowledge to well solve a problem alone. This is particularly true when the decision environment becomes more complex. More organizational decisions are made now in groups than ever before. Group decision making is thus a process of arriving at a judgment or a solution for a decision problem based on the input and feedback of multiple individuals. At the same time in practice, multi-criteria problems at tactical and strategic levels often involve fuzziness in their criteria and decision makers' judgments. Relevant alternatives are evaluated according to a number of criteria. Fuzzy logic based multi-criteria group decision support is justified to analysis long-term options for Belgian energy policy in this paper.", "num_citations": "12\n", "authors": ["1068"]}
{"title": "Deep multi-task learning for air quality prediction\n", "abstract": " Predicting the concentration of air pollution particles has been an important task of urban computing. Accurately measuring and estimating makes the citizen and governments can behave with suitable decisions. In order to predict the concentration of several air pollutants at multiple monitoring stations throughout the city region, we proposed a novel deep multi-task learning framework based on residual Gated Recurrent Unit (GRU). The experimental results on the real world data from London region substantiate that the proposed deep model has manifest superiority than shallow models and outperforms 9 baselines.", "num_citations": "11\n", "authors": ["1068"]}
{"title": "A comparison of bidding strategies for online auctions using fuzzy reasoning and negotiation decision functions\n", "abstract": " Bidders often feel challenged when looking for the best bidding strategies to excel in the competitive environment of multiple and simultaneous online auctions for same or similar items. Bidders face complicated issues for deciding which auction to participate in, whether to bid early or late, and how much to bid. In this paper, we present the design of bidding strategies, which aim to forecast the bid amounts for buyers at a particular moment in time based on their bidding behavior and their valuation of an auctioned item. The agent develops a comprehensive methodology for final price estimation, which designs bidding strategies to address buyers' different bidding behaviors using two approaches: Mamdani method with regression analysis and negotiation decision functions. The experimental results show that the agents who follow fuzzy reasoning with a regression approach outperform other existing agents in most\u00a0\u2026", "num_citations": "11\n", "authors": ["1068"]}
{"title": "A Tribute to Prof. Dr. Da Ruan\n", "abstract": " This volume is a tribute to Professor Dr Da Ruan, who passed away suddenly on July 31, 2011, aged 50. The flood of emails that spread throughout the fuzzy logic research community with the tragic news was testimony to the respect and liking felt for this remarkable man. Da was a hardworking, highly productive scientist who, during his short life, published 35 books and more than 250 research papers in highly ranked journals and conference proceedings. He established two successful conferences, FLINS and ISKE, as well as the international journal, JCIS. This book is a collection of contributions from 88 of Da's academic friends from 47 institutes, presented in 60 chapters and over 70 pictures. A Foreword by Lotfi Zadeh begins Da's story. Section 1 provides an overview of Da's funeral on August 6, 2011. Part II outlines Da\u2019s scientific life, his education, scientific career, publications and keynote talks. Part III presents testimonials by Da's colleagues of academic activities, including guest professorships and his many visits to foreign institutes. Part IV contains thirty contributions from colleagues and friends across the world to describe their collaborative experience with Da. We hope this book will keep the memory of Da alive\u2013great scientist, great friend, great humanitarian. He will remain in our hearts forever.", "num_citations": "11\n", "authors": ["1068"]}
{"title": "A fuzzy dual expert system for managing situation awareness in a safety supervisory system\n", "abstract": " Safety supervisory systems continue to increase in degree of automation and complexity as operators are decreasing. As a result, each operator must be able to comprehend and respond to an ever increasing amount of available risky status and alert information. They generally have no difficulty in performing their tasks physically but they are stressed by the task of understanding what is going on in the situation. So in the last two decades, situation awareness has been recognized as a critical foundation for successful decision making across a broad range of complex and dynamic systems. This paper develops a fuzzy dual expert system based approach to enhance situation awareness. The proposed approach has ability to support the operators' understanding and assessing the situations, and to deal with uncertainties, applying fuzzy risk assessment concepts.", "num_citations": "11\n", "authors": ["1068"]}
{"title": "Fuzzy failure rate for nuclear power plant probabilistic safety assessment by fault tree analysis\n", "abstract": " Reliability data is essential for a nuclear power plant probabilistic safety assessment by fault tree analysis to assess the performance of the safety-related systems. The limitation of the conventional reliability data comes from insufficient historical data for probabilistic calculation. This chapter proposes and discusses a failure possibility-based reliability algorithm to assess nuclear event reliability data from failure possibilities, which are expressed in qualitative natural languages, mathematically represented by membership functions of fuzzy numbers, and subjectively justified by a group of experts based on their working experience and expertise. We also discuss an area defuzzification technique, which has been developed, to defuzzify nuclear event failure possibilities into their corresponding fuzzy failure rates, which are similar to the probabilistic failure rates probabilistically calculated from historical failure\u00a0\u2026", "num_citations": "11\n", "authors": ["1068"]}
{"title": "Semantic web for e-government service delivery integration\n", "abstract": " Repeatability is one of the most fundamental components of any methodology or framework in any engineering discipline. Many research projects attempting to formulate some modelling strategies as the new technologies and development techniques are being proposed in service oriented architecture (SOA) domain. In absence of a documented best common practice of design and modelling techniques for e-service composition, it would be greatly beneficial to discover such common practices and describe the detail specifications of a repeatable methodology for e- service composition projects. This paper will discuss some proposed e-government integration models, and then it will introduce some e-service integration practices and classifications of e-service composition strategies. The main contribution of this paper is to propose detailed specifications of a repeatable methodology for e-service composition\u00a0\u2026", "num_citations": "11\n", "authors": ["1068"]}
{"title": "Cognitive orientation in business intelligence systems\n", "abstract": " With the increasing importance of cognitive aspects in decision making, this research addresses how human cognitive abilities, mainly situation awareness and mental models, can be used to drive the decision process in complex decision situations. Cognitive orientation has long been regarded as an important consideration in the development and application of decision support systems (DSS). Rather than cognitive orientation, a data-driven DSS emphasizes access to and manipulation of a series of company internal and external data, compared to a model-driven DSS underpinned by statistical, financial, optimization or simulation models. A business intelligence (BI) system is essentially a kind of data-driven DSS therefore shares the similar drawbacks with traditional DSS. A framework of cognitive BI system is firstly developed. A model of cognition-driven decision process is then proposed based on the system\u00a0\u2026", "num_citations": "11\n", "authors": ["1068"]}
{"title": "Kth best algorithm for fuzzy bilevel programming\n", "abstract": " Organizational decision making often involves two decision levels. When the leader at the upper level attempts to optimize hislher objective, the follower at the lower level tries to find an optimized strategy according to each of possible decisions made by the leader. Furthermore, such bilevel decision making may involve uncertain parameters which appear either in the objective functions or constraints of the leader or the follower. Following our previous work, this study first proposes a fuzzy parameter bilevel programming model and related theories. It then develops an approximation Kth-Best algorithm for solving such fuzzy bilevel programming problems. A numerical example further illustrates the proposed algorithm.", "num_citations": "11\n", "authors": ["1068"]}
{"title": "An alpha-Fuzzy Max Order and Solution of Linear Constrained Fuzzy Optimization Problems\n", "abstract": " In this paper, we introduce a new concept, the a-fuzzy max order, and then use the concept in the study of fuzzy linear constrained optimization problems. For constraints given by 11 inequalities involving fuzzy numbers with isosceles triangle membership functions, we prove that the feasible solution space is determined by 3/1 non-fuzzy inequalities. For constraints involving fuzzy numbers with other forms of membership functions, we develop two nwnerical algorithms respectively for the determination of the feasible solution space and the solution of the fuzzy optimization problem. An illuminative example is also given in this paper to demonstrate the validity of the methods and algorithms developed.", "num_citations": "11\n", "authors": ["1068"]}
{"title": "A mobile telematics pattern recognition framework for driving behavior extraction\n", "abstract": " Mobile telematics is a relatively new innovation that involves collecting data on driving behavior using the internal sensors in a smartphone rather than from an in-vehicle data recorder. However, telematics data are usually not labeled, which makes extracting driving patterns from them very difficult. Therefore, unsupervised learning algorithms play an important role in this field. In addition, most current research is based on datasets developed in a laboratory or from site investigations and questionnaires, which are very different from real-world driving behaviors. To advance unsupervised learning techniques in this field, and to fill the gap in findings based on real-world data, we have developed an unsupervised pattern recognition framework for mobile telematics data. The framework comprises three main components: a self-organizing map, a nine-layers deep auto-encoder, and partitive clustering algorithms. The\u00a0\u2026", "num_citations": "10\n", "authors": ["1068"]}
{"title": "Cross-domain network representations\n", "abstract": " The purpose of network representation is to learn a set of latent features by obtaining community information from network structures to provide knowledge for machine learning tasks. Recent research has driven significant progress in network representation by employing random walks as the network sampling strategy. Nevertheless, existing approaches rely on domain-specifically rich community structures and fail in the network that lack topological information in its own domain. In this paper, we propose a novel algorithm for cross-domain network representation, named as CDNR. By generating the random walks from a structural rich domain and transferring the knowledge on the random walks across domains, it enables a network representation for the structural scarce domain as well. To be specific, CDNR is realized by a cross-domain two-layer node-scale balance algorithm and a cross-domain two-layer\u00a0\u2026", "num_citations": "10\n", "authors": ["1068"]}
{"title": "A survey on Bayesian nonparametric learning\n", "abstract": " Bayesian (machine) learning has been playing a significant role in machine learning for a long time due to its particular ability to embrace uncertainty, encode prior knowledge, and endow interpretability. On the back of Bayesian learning\u2019s great success, Bayesian nonparametric learning (BNL) has emerged as a force for further advances in this field due to its greater modelling flexibility and representation power. Instead of playing with the fixed-dimensional probabilistic distributions of Bayesian learning, BNL creates a new \u201cgame\u201d with infinite-dimensional stochastic processes. BNL has long been recognised as a research subject in statistics, and, to date, several state-of-the-art pilot studies have demonstrated that BNL has a great deal of potential to solve real-world machine-learning tasks. However, despite these promising results, BNL has not created a huge wave in the machine-learning community. Esotericism\u00a0\u2026", "num_citations": "10\n", "authors": ["1068"]}
{"title": "Predicting the dynamics of scientific activities: A diffusion\u2010based network analytic methodology\n", "abstract": " With the rapid explosion of information and the dramatic development of bibliometric techniques in the past decades, it becomes a challenge to comprehensively, extensively, and efficiently understand science maps. Aim\u2010ing to explore in\u2010depth insights from science maps and predict the dynamics of scientific activities, this paper, based on the co\u2010occurrence statistics of terms derived from scientific documents, proposes a diffusion\u2010based network analytic methodology to conduct the prediction study from two aspects: the research interest of scien\u2010tific researchers and the evolutionary directions of scientific topics. A case study on academic articles down\u2010loaded from three leading journals in the field of bibliometrics demonstrates the feasibility of the methodology. The future directions of bibliometrics are identified, such as the application of information technologies to tradi\u2010tional bibliometric data, the interactions\u00a0\u2026", "num_citations": "10\n", "authors": ["1068"]}
{"title": "Heterogeneous unsupervised crossdomain transfer learning\n", "abstract": " Transfer learning addresses the problem of how to leverage previously acquired knowledge (a source domain) to improve the efficiency of learning in a new domain (the target domain). Although transfer learning has been widely researched in the last decade, existing research still has two restrictions: 1) the feature spaces of the domains must be homogeneous; and 2) the target domain must have at least a few labeled instances. These restrictions significantly limit transfer learning models when transferring knowledge across domains, especially in the big data era. To completely break through both of these bottlenecks, a theorem for reliable unsupervised knowledge transfer is proposed to avoid negative transfers, and a Grassmann manifold is applied to measure the distance between heterogeneous feature spaces. Based on this theorem and the Grassmann manifold, this study proposes two heterogeneous unsupervised knowledge transfer (HeUKT) models\u2013known as RLG and GLG. The random linear monotonic map geodesic flow kernel model (RLG) uses a linear monotonic map (LMM) to reliably project two heterogeneous feature spaces onto a latent feature space and applies geodesic flow kernel (GFK) model to transfers knowledge between two the projected domains. The Grassmann LMM GFK (GLG) optimizes the LMM to achieve the highest possible accuracy and guarantees that the geometric properties of the domains remain unchanged during the transfer process. To test the overall effectiveness of two models, this paper reorganizes five public datasets into ten heterogeneous cross-domain tasks across three application fields: credit\u00a0\u2026", "num_citations": "10\n", "authors": ["1068"]}
{"title": "Measuring the semantic uncertainty of news events for evolution potential estimation\n", "abstract": " The evolution potential estimation of news events can support the decision making of both corporations and governments. For example, a corporation could manage its public relations crisis in a timely manner if a negative news event about this corporation is known with large evolution potential in advance. However, existing state-of-the-art methods are mainly based on time series historical data, which are not suitable for the news events with limited historical data and bursty properties. In this article, we propose a purely content-based method to estimate the evolution potential of the news events. The proposed method considers a news event at a given time point as a system composed of different keywords, and the uncertainty of this system is defined and measured as the Semantic Uncertainty of this news event. At the same time, an uncertainty space is constructed with two extreme states: the most uncertain\u00a0\u2026", "num_citations": "10\n", "authors": ["1068"]}
{"title": "Guest editorial: A special issue on intelligent decision support and warning systems\n", "abstract": " Guest Editorial: A special issue on Intelligent Decision Support and Warning Systems: Knowledge-Based Systems: Vol 23, No 1 ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Knowledge-Based Systems Periodical Home Latest Issue Archive Authors Affiliations Award Winners More HomeBrowse by TitlePeriodicalsKnowledge-Based SystemsVol. , No. Guest Editorial: A special issue on Intelligent Decision Support and Warning Systems article Guest Editorial: A special issue on Intelligent Decision Support and Warning Systems Share on Authors: Jie Lu University of Technology Sydney, PO Box 123, Broadway, NSW 2007, Australia. Tel.: +61 02 95141838; fax: +61 02 95144535. University of Technology \u2026", "num_citations": "10\n", "authors": ["1068"]}
{"title": "Strategies and approaches to teaching and learning cross cultures\n", "abstract": " Australian tertiary education has attracted a large number of international students, particularly from Asia. Cultural factors have affected the quality of learning of international students and the teaching approaches adopted by Australian lecturers. Therefore, cross-cultural teaching and learning situations have become an important issue in Australian universities. This project intends to identify the influence of the trend towards increasing numbers of cross-cultural students on teaching and learning approaches in an Australian educational environment. It aims to improve the understanding of Asian students' cultural backgrounds, their previous learning approaches and their perspectives on Australian culture and modes of education, with the objective of helping international students to overcome the difficulties of cross-cultural study. In the process, we anticipate bringing new ideas to lecturers and education managers to improve the quality of cross-cultural teaching and learning. We also expect to develop strategies through recognising the factors which influence teaching and learning in the cross-cultural environment, and to propose a set of guidelines and suggestions that can enhance the quality of teaching and learning in Australian universities.In 2008, we conducted a student questionnaire survey at the University of Technology, Sydney, Curtin University of Technology, The University of Sydney, Edith Cowan University and Southern Cross University. As Business and Information Technology attract the majority of Asian international students, we selected these two schools/faculties in the five universities within which to conduct the survey. We\u00a0\u2026", "num_citations": "10\n", "authors": ["1068"]}
{"title": "Computational intelligence in decision and control\n", "abstract": " FLINS, originally an acronym for Fuzzy Logic and Intelligent Technologies in Nuclear Science, is now extended to Computational Intelligence for applied research. The contributions to the eighth edition in the series of FLINS conferences cover state-of-the-art research, development, and technology for computational intelligence systems in general, and for intelligent decision and control in particular.", "num_citations": "10\n", "authors": ["1068"]}
{"title": "A particle swarm optimization based algorithm for fuzzy bilevel decision making\n", "abstract": " Bilevel decision techniques are developed for decentralized planning problems with decision makers located in a two-level system. This study develops a particle swarm optimization based algorithm to solve fuzzy linear bilevel (FLBL) decision problems. A main advantage of this algorithm is that the optimization technique is adopted directly on FLBL problems by fully considering the original information carried by the fuzzy parameters, thus minimizing information loss. Experiments reveal that this algorithm can effectively solve the fuzzy linear bilevel decision problems.", "num_citations": "10\n", "authors": ["1068"]}
{"title": "A fuzzy multi-criteria group decision support system for nonwoven based cosmetic product development evaluation\n", "abstract": " Product prototype evaluation is an important phase in new product development (NPD). Such evaluation often requires multiple criteria that are within a hierarchy and a group of evaluators. The evaluation process and these evaluation criteria often involve uncertain and fuzzy data in the weights of these criteria and the judgments of these evaluators. To evaluate nonwoven cosmetic product prototypes, this study first develops a NPD evaluation model, which has evaluation criteria within three levels, based on the features of nonwoven products. It then proposes a fuzzy (multi-level) multi-criteria group decision-making (FMCGDM) method for supporting the evaluation task. A fuzzy multi-criteria group decision support system (FMCGDSS) is developed to implement the proposed method and applied in nonwoven cosmetic product development evaluation.", "num_citations": "10\n", "authors": ["1068"]}
{"title": "An Approximation Kuhn\u2013Tucker Approach for Fuzzy Linear Bilevel Decision Making\n", "abstract": " In bilevel decision making, the leader aims to achieve an optimal solution by considering the follower's optimized strategy to react each of his/her possible decisions. In a real-world bilevel decision environment, uncertainty must be considered when modeling the objective functions and constraints of the leader and the follower. Following our previous work, this chapter proposes a fuzzy bilevel decision making model to describe bilevel decision making under uncertainty. After giving the definitions of optimal solutions and related theorems for fuzzy bilevel decision problems this chapter develops an approximation Kuhn\u2013Tucker approach to solve the problem. Finally, an example of reverse logistics management illustrates the application of this proposed fuzzy bilevel decision making approach.", "num_citations": "10\n", "authors": ["1068"]}
{"title": "A situation assessment approach using support vector machines as a learning tool\n", "abstract": " In order to assess a situation and support decision makers' awareness for the situation, this study first proposes a situation assessment model with mathematical description. It then develops a Support Vector Machine based assessment approach, which has the ability to learn the rules from the previous assessment results and generate necessary warnings for a situation. Finally, a set of experiments is conducted to illustrate and validate the proposed approach.", "num_citations": "10\n", "authors": ["1068"]}
{"title": "Bayesian network based cost benefit factor inference in eservices\n", "abstract": " AbsIract-This paper applies Bayesian network tecbnique to model and inference tbe uncertain relationsbips among cost factors and benefit factors in E-services. A cost-benefit factor-relation modelproposed in our previous study is considered as domain knowledgeand tbe data collectedtbrougb a survey is as evidence to conduct inference. Tbrough calculating conditional probability distribution among factors and conducting inference, this paper identifies tbat certain cost factors are significantly more important tban others to certain benefit factors. In particular, this study found tbat'increased investment in maintaining E-services' would significantly contribute to'enbancing perceived company image'and'gaining competitive advantages', and'increased investment in staff training'would significant contribute to'realizing business strategies'. These results bave the potential to improve the strategic planning of companies by determining more effectiveinvestment areas and adopting more suitable development activities wbere &services are concerned.", "num_citations": "10\n", "authors": ["1068"]}
{"title": "Explicitly and implicitly exploiting the hierarchical structure for mining website interests on news events\n", "abstract": " After a news event, many different websites publish coverage of that event, each expressing their own unique commentary, perspectives, and viewpoints. Websites form around a specific set of interests to cater to different audiences, and discovering these interests can help audiences C especially people and organizations that are interested in news C select the most appropriate websites to use as their sources of information. This paper presents three methods for formally defining and mining a websites interests, each of which is explicitly or implicitly based on a hierarchial structure: website-webpage-keyword. The first, and most straightforward, method explicitly uses keyword-layer network communities and the mapping relations between websites and keywords. The second method expands upon the first method with an iterative algorithm that combines both the mapping relations and the network relations from\u00a0\u2026", "num_citations": "9\n", "authors": ["1068"]}
{"title": "A human-system interface risk assessment method based on mental models\n", "abstract": " In many safety\u2013critical systems, it is necessary to maintain operators\u2019 situation awareness at a high level to ensure the safety of operations. Today, in many such systems, operators have to rely on the principles and design of human-system interfaces (HSIs) to observe and comprehend the overwhelming amount of process data. Thus, poor HSIs may cause serious consequences, such as occupational accidents and diseases including stress, and they have therefore been considered an emerging risk. Despite the importance of this, very few methods have as yet been developed to assess the risk of HSIs. This paper presents a new risk assessment method that relies upon operators\u2019 mental models, human reliability analysis (HRA) event tree, and the situation awareness global assessment technique (SAGAT) to produce a risk profile for the intended HSI. In the proposed method, the operator\u2019s understanding (i.e\u00a0\u2026", "num_citations": "9\n", "authors": ["1068"]}
{"title": "A fuzzy approach for measuring development of topics in patents using Latent Dirichlet Allocation\n", "abstract": " Technology progress brings the very rapid growth of patent publications, which increases the difficulty of domain experts to measure the development of various topics, handle linguistic terms used in evaluation and understand massive technological content. To overcome the limitations of keyword-ranking type of text mining result in existing research, and at the same time deal with the vagueness of linguistic terms to assist thematic evaluation, this research proposes a fuzzy set-based topic development measurement (FTDM) approach to estimate and evaluate the topics hidden in a large volume of patent claims using Latent Dirichlet Allocation. In this study, latent semantic topics are first discovered from patent corpus and measured by a temporal-weight matrix to reveal the importance of all topics in different years. For each topic, we then calculate a temporal-weight coefficient based on the matrix, which is\u00a0\u2026", "num_citations": "9\n", "authors": ["1068"]}
{"title": "A new similarity measure-based collaborative filtering approach for recommender systems\n", "abstract": " Collaborative filtering (CF) is the most popular recommendation approach in personalization techniques but still suffers from poor recommendation accuracy. This study incorporates fuzzy set technique and user-relevant analysis to improve the CF approach. It proposes an innovative fuzzy similarity measure (FSM) and user-relevant aggregation (URA) on recommendation approach. Experiments demonstrate that the FSM-URA approach significantly improves the prediction accuracy comparing to the existing recommendation approaches.", "num_citations": "9\n", "authors": ["1068"]}
{"title": "A failure possibility-based reliability algorithm for nuclear safety assessment by fault tree analysis\n", "abstract": " Reliability data are essential for nuclear power plant probabilistic safety assessment by fault tree analysis. The limitation of conventional reliability data comes from the insufficient reliable historical data for probabilistic calculation. This paper proposes an algorithm to calculate nuclear event reliability data using possibility approach as an alternative to probabilistic approach. Nuclear events are evaluated by a group of experts based on their working experience and expertise, which are expressed in qualitative natural languages and mathematically represented by membership functions of fuzzy numbers. Every expert is given a justification weight to represent his/her knowledge level of the safety system under investigation. A case study on emergency core cooling system of a typical nuclear power plant is given to mathematically verify the proposed algorithm. The results show that this proposed algorithm is a very good alternative to assess nuclear event data when historical data for probabilistic calculation is not available.", "num_citations": "9\n", "authors": ["1068"]}
{"title": "Models and algorithm for fuzzy multi-objective multi-follower linear bilevel programming\n", "abstract": " Basic bilevel programming deals with hierarchical optimization problems in which the leader at the upper level attempts to optimize his/her objective, subject to a set of constraints and his/her follower's solution, and the follower at the lower level tries to find an optimized strategy according to each of possible decisions made by the leader. Three issues may be involved in a basic bilevel decision problem. One is that bilevel decision making model may involve uncertain parameters which appear either in the objective functions or constraints of the leader or the follower or both. Second, the leader and the follower may have multiple conflict objectives that should be optimized simultaneously. Third, there may have multiple followers in a real decision situation. Following our previous work, this study proposes a set of fuzzy multi-objective multi-follower linear bilevel programming models to describe the three issues. It also\u00a0\u2026", "num_citations": "9\n", "authors": ["1068"]}
{"title": "Cost and benefit analysis for e-service applications\n", "abstract": " Companies are adopting Internet-based electronic services (E-services) attracting customers, sharing of business information, maintaining business relationships and conducting business transactions. Companies in the earlier stages of employing E-services have little information and knowledge on its potential organizational and relational impacts. Through few years practice of E-services, companies have obtained related knowledge. They urgently need to assess the costs to move service online against the benefitsE-service applications in Australia have had rapid growth in past few years. International benchmarks consistently place Australia among the top ten countries in the world in the terms of adoption and use of E-business (E-service has been extraordinarily affected by the development of E-business). Through assessing connectivity, business environment, E-commerce consumer and business adoption, legal and regulatory environment, supporting an E-service, and social and cultural infrastructure, the US based Economist Intelligence Unit [6] published its second set of \u201cE-business Readiness Rankings\u201d for over 60 countries in", "num_citations": "9\n", "authors": ["1068"]}
{"title": "Data-Driven Decision-Making (D3M): Framework, Methodology, and Directions\n", "abstract": " A decision problem, according to traditional principles, is approached by finding an optimal solution to an analytical programming decision model, which is known as model-driven decision-making. The fidelity of the model determines the quality and reliability of the decision-making; however, the intrinsic complexity of many real-world decision problems leads to significant model mismatch or infeasibility in deriving a model using the first principle. To overcome the challenges that are present in the big data era, both researchers and practitioners emphasize the importance of making decisions that are backed up by data related to decision tasks, a process called data-driven decision-making (D 3 M). By building on data science, not only can decision models be predicted in the presence of uncertainty or unknown dynamics, but also inherent rules or knowledge can be extracted from data and directly utilized to\u00a0\u2026", "num_citations": "8\n", "authors": ["1068"]}
{"title": "Enhancing cross domain recommendation with domain dependent tags\n", "abstract": " One challenge in recommender system is to deal with data sparsity. To handle this issue, social tags are utilized to bring disjoint domains together for knowledge transfer in cross-domain recommendation. The most intuitive way is to use common tags that present in both source and target domains. However, it is difficult to obtain a strong domain connection by exploiting a small amount of common tags, especially when the tagging data in target domain is too scarce to share enough common tags with source domain. In this paper we propose a novel framework, called Enhanced Tag-induced Cross Domain Collaborative Filtering (ETagiCDCF), to integrate the rich information contained in domain dependent tags into recommendation procedure. We perform experiments on two public datasets and compare with several single and cross domain recommendation approaches, the results demonstrate that ETagiCDCF\u00a0\u2026", "num_citations": "8\n", "authors": ["1068"]}
{"title": "An intelligent group decision-support system and its application for project performance evaluation\n", "abstract": " Purpose                \u2013 In any organization there are main goals, with lots of projects designed to achieve these goals. It is important for any organization to determine how much these projects affect the achievement of these goals. The purpose of this paper is to develop a fuzzy multiple attribute-based group decision-support system (FMAGDSS) to evaluate projects\u2019 performance in promoting the organization's goals utilizing simple additive weighting (SAW) algorithm and technique for order of preference by similarity to ideal solution (TOPSIS) algorithm. The proposed FMAGDSS deals with choosing the most appropriate fuzzy ranking algorithm for solving a given fuzzy multi attribute decision making (FMADM) problem with both qualitative and quantitative criteria (attributes), and uncertain judgments of decision makers.                                        Design/methodology/approach                \u2013 In this paper, a FMAGDSS\u00a0\u2026", "num_citations": "8\n", "authors": ["1068"]}
{"title": "A human situation awareness support system to avoid technological disasters\n", "abstract": " In many complex technological systems, accidents have primarily been attributed to human error. In the majority of these accidents the human operators were striving against significant challenges. They have to face data overload, the challenge of working with a complex system and the stressful task of understanding what is going on in the situation. Therefore, to design and implement complex technological systems where the information flow is quite high, and poor decisions may lead to serious consequences, Situation Awareness (SA) should be appropriately considered. A level 1 SA is highly supported in these systems through the various heterogeneous sensors and signal-processing methods but, for levels 2 and 3 there is still a need for concepts and methods. This work develops a system called the Human Situation Awareness Support System (HSASS) that supports the safety operators in an ever\u00a0\u2026", "num_citations": "8\n", "authors": ["1068"]}
{"title": "Collaborative management of web ontology data with flexible access control\n", "abstract": " The creation and management of ontology data on web sites (e.g. instance data that is used to annotate web pages) is important technical support for the growth of the semantic web. This study identifies some key issues for web ontology data management and describes an ontology data management system, called robinet, to perform the management. This paper presents the structure of the system and introduces a Web ontology data management model that enables a flexible access control mechanism. This model adds rules into the robinet system to utilize the semantics of ontology for controlling the access to ontology data. The implementation of the rule-based access control mechanism and related testing are also discussed.", "num_citations": "8\n", "authors": ["1068"]}
{"title": "Creating and managing ontology data on the web: a semantic wiki approach\n", "abstract": " The creation of ontology data on web sites and proper management of them would help the growth of the semantic web. This paper proposes a semantic wiki approach to tackle this issue. Desirable functions that a semantic wiki approach should implement to offer a better solution to this issue are discussed. Along with that, some key problems such as usability, data reliability and data quality are identified and analyzed. Based on that, a system framework is presented to show how such functions are designed. These functions are further explained along with the description of our implemented prototype system. By addressing the identified key problems, our semantic wiki approach is expected to be able to create and manage web ontology data more effectively.", "num_citations": "8\n", "authors": ["1068"]}
{"title": "Guest editorial preface: intelligent knowledge engineering systems\n", "abstract": " Guest Editorial Preface: Intelligent knowledge engineering systems: Knowledge-Based Systems: Vol 20, No 5 ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Knowledge-Based Systems Periodical Home Latest Issue Archive Authors Affiliations Award Winners More HomeBrowse by TitlePeriodicalsKnowledge-Based SystemsVol. , No. Guest Editorial Preface: Intelligent knowledge engineering systems article Guest Editorial Preface: Intelligent knowledge engineering systems Share on Authors: Jie Lu profile image Jie Lu UTS, Sydney, Australia UTS, Sydney, Australia View Profile , Da Ruan profile image Da Ruan SCK-CEN, Mol and UGent, Gent, Belgium SCK-CEN, Mol and UGent, Gent, Belgium View \u2026", "num_citations": "8\n", "authors": ["1068"]}
{"title": "Learning from a Complementary-label Source Domain: Theory and Algorithms\n", "abstract": " In unsupervised domain adaptation (UDA), a classifier for the target domain is trained with massive true-label data from the source domain and unlabeled data from the target domain. However, collecting true-label data in the source domain can be expensive and sometimes impractical. Compared to the true label (TL), a complementary label (CL) specifies a class that a pattern does not belong to, and hence, collecting CLs would be less laborious than collecting TLs. In this article, we propose a novel setting where the source domain is composed of complementary-label data, and a theoretical bound of this setting is provided. We consider two cases of this setting: one is that the source domain only contains complementary-label data [completely complementary UDA (CC-UDA)] and the other is that the source domain has plenty of complementary-label data and a small amount of true-label data [partly\u00a0\u2026", "num_citations": "7\n", "authors": ["1068"]}
{"title": "Distributionally robust optimization for power trading of waste-to-energy plants under uncertainty\n", "abstract": " Waste-to-energy (WTE) plants are operated worldwide to address the management of municipal solid waste. Against this background, an increasing number of WTE plants serve as combined heat and power (CHP) producers that supply heat to the heating systems in local districts and trade electricity in the regional power markets. This paper studies a short-term operation planning problem of determining effective power trading strategies for WTE CHP plants that participate in day-ahead markets. A two-stage distributionally robust optimization (DRO) model is developed with the consideration of uncertain electricity prices, waste supply, and district heating demand. These different kinds of uncertainty are captured by an ambiguity set that contains a collection of possible probability distributions of the uncertain parameters. The two-stage DRO model seeks to ascertain a power trading strategy that maximizes the\u00a0\u2026", "num_citations": "7\n", "authors": ["1068"]}
{"title": "Operations scheduling of waste-to-energy plants under uncertainty\n", "abstract": " Waste-to-energy (WTE) technologies provide effective solutions to the compelling challenges of waste management and the energy crisis globally. Many WTE plants utilize the combined heat and power (CHP) operation mode where both electricity and heat can be generated simultaneously. Thus, these WTE CHP plants can supply heat to the local district heating systems and trade power in the electricity markets. As such plants have the responsibilities of treating waste and of fulfilling the allocated district heating demand, necessary operational tasks such as preventive maintenance actions for the production units should be scheduled and performed periodically to ensure their continuous and reliable operations. This paper studies the scheduling of operational tasks in WTE CHP plants that participate in electricity markets and are connected to district heating networks. Firstly, we formulate a two-stage robust\u00a0\u2026", "num_citations": "7\n", "authors": ["1068"]}
{"title": "Bayesian deep reinforcement learning via deep kernel learning\n", "abstract": " \u00a9 2018, the Authors. Reinforcement learning (RL) aims to resolve the sequential decision-making under uncertainty problem where an agent needs to interact with an unknown environment with the expectation of optimising the cumulative long-term reward. Many real-world problems could benefit from RL, e.g., industrial robotics, medical treatment, and trade execution. As a representative model-free RL algorithm, deep Q-network (DQN) has recently achieved great success on RL problems and even exceed the human performance through introducing deep neural networks. However, such classical deep neural network-based models cannot well handle the uncertainty in sequential decision-making and then limit their learning performance. In this paper, we propose a new model-free RL algorithm based on a Bayesian deep model. To be specific, deep kernel learning (i.e., a Gaussian process with deep kernel) is adopted to learn the hidden complex action-value function instead of classical deep learning models, which could encode more uncertainty and fully take advantage of the replay memory. The comparative experiments on standard RL testing platform, i.e., OpenAI-Gym, show that the proposed algorithm outweighs the DQN. Further investigations will be directed to applying RL for supporting dynamic decision-making in complex environments.", "num_citations": "7\n", "authors": ["1068"]}
{"title": "A reducibility method for the weak linear bilevel programming problems and a case study in principal-agent\n", "abstract": " A weak linear bilevel programming (WLBP) problem often models problems involving hierarchy structure in expert and intelligent systems under the pessimistic point. In the paper, we deal with such a problem. Using the duality theory of linear programming, the WLBP problem is first equivalently transformed into a jointly constrained bilinear programming problem. Then, we show that the resolution of the jointly constrained bilinear programming problem is equivalent to the resolution of a disjoint bilinear programming problem under appropriate assumptions. This may give a possibility to solve the WLBP problem via a single-level disjoint bilinear programming problem. Furthermore, some examples illustrate the solution process and feasibility of the proposed method. Finally, the WLBP problem models a principal-agent problem under the pessimistic point that is also compared with a principal-agent problem under the\u00a0\u2026", "num_citations": "7\n", "authors": ["1068"]}
{"title": "A signed trust-based recommender approach for personalized government-to-business e-services\n", "abstract": " Recently recommender systems are introduced into the web-based government applications which expect to provide personalized Government-to-Business (G2B) e-Services. For more personalization, we illustrate a subjective signed trust relationship between users, and based on such trust we proposed a recommendation framework for G2B e-services. A case study is conducted as an example of implementing our approach in e-government applications. Empirical analysis is also conducted to compare our approach with other models, which shows that our approach is of the highest. In conclusion, the signed trust relationship can reflect the real preferences of users, and the proposed recommendation framework is believed to be reliable and applicable.", "num_citations": "7\n", "authors": ["1068"]}
{"title": "A fuzzy tree similarity based recommendation approach for telecom products\n", "abstract": " Due to the huge product assortments and complex descriptions of telecom products, it is a great challenge for customers to select appropriate products. A fuzzy tree similarity based hybrid recommendation approach is proposed to solve this issue. In this study, fuzzy techniques are used to deal with the various uncertainties existing within the product and customer data. A fuzzy tree similarity measure is developed to evaluate the semantic similarity between tree structured products or user profiles. The similarity measures for items and users both integrate the collaborative filtering (CF) and semantic similarities. The final recommendation hybridizes item-based and user-based CF recommendation techniques. A telecom product recommendation case study is given to show the effectiveness of the proposed approach.", "num_citations": "7\n", "authors": ["1068"]}
{"title": "A proficient and dynamic bidding agent for online auctions\n", "abstract": " E-consumers face biggest challenge of opting for the best bidding strategies for competing in an environment of multiple and simultaneous online auctions for same or similar items. It becomes very complicated for the bidders to make decisions of selecting which auction to participate in, place single or multiple bids, early or late bidding and how much to bid. In this paper, we present the design of an autonomous dynamic bidding agent (ADBA) that makes these decisions on behalf of the buyers according to their bidding behaviors. The agent develops a comprehensive method for initial price prediction and an integrated model for bid forecasting. The initial price prediction method selects an auction to participate in and then predicts its closing price (initial price). Then the bid forecasting model forecasts the bid amount by designing different bidding strategies followed by the late bidders. The experimental\u00a0\u2026", "num_citations": "7\n", "authors": ["1068"]}
{"title": "An area defuzzification technique and essential fuzzy rules for defuzzifying nuclear event failure possibilities into reliability data\n", "abstract": " A fuzzy reliability approach is a good alternative for a probabilistic reliability approach to assess event reliability data when event historical data is unavailable or inadequate for statistical calculation. It applies possibility theory to represent event failure in qualitative natural languages and fuzzy set theory to represent those qualitative natural languages in mathematical form. In this study, we develop a new area defuzzification technique and propose it to assess nuclear event reliability data from their corresponding failure possibilities. To justify the applicability of the new technique, we define five fuzzy rules to be satisfied by the technique and use five sets of fuzzy subsets to mathematically confirm the technique. The results show that the new area defuzzification technique is suitable for assessing nuclear event reliability data in the fuzzy reliability approach.", "num_citations": "7\n", "authors": ["1068"]}
{"title": "A similarity measure on tree structured business data\n", "abstract": " In many business situations, products or user profile data are so complex that they need to be described by use of tree structures. Evaluating the similarity between tree-structured data is essential in many applications, such as recommender systems. To evaluate the similarity between two trees, concept corresponding nodes should be identified by constructing an edit distance mapping between them. Sometimes, the intension of one concept includes the intensions of several other concepts. In that situation, a one-to-many mapping should be constructed from the point of view of structures. This paper proposes a tree similarity measure model that can construct this kind of mapping. The similarity measure model takes into account all the information on nodes\u2019 concepts, weights, and values. The conceptual similarity and the value similarity between two trees are evaluated based on the constructed mapping, and the final similarity measure is assessed as a weighted sum of their conceptual and value similarities. The effectiveness of the proposed similarity measure model is shown by an illustrative example and is also demonstrated by applying it into a recommender system.", "num_citations": "7\n", "authors": ["1068"]}
{"title": "An innovative self-adaptive configuration optimization system in cloud computing\n", "abstract": " Cloud computing has emerging as an extremely popular and cost-effective computational service model using pay-as-you-go executing environments that scale transparently to the user. However, cloud providers should tackle the challenge of configuring their systems to provide maximal performance while minimizing customer's cost of computing resources, which satisfy the customers' various workload requirements. To solve the above challenge, in this paper, we propose an innovative architecture of self-adaptive configuration optimization system which supports dynamic reconfiguration when workloads change. In addition, we develop an optimization algorithm by using genetic algorithm for this system. By using queuing theory and statistic techniques, we model and compute the SLAs metrics which are defined as the fitness function in the optimization algorithm. This optimization system can guide cloud\u00a0\u2026", "num_citations": "7\n", "authors": ["1068"]}
{"title": "A Hybrid Knowledge-based Risk Prediction Method Using Fuzzy Logic and CBR for Avian Inluenza Early Warning.\n", "abstract": " The threat of highly pathogenic avian influenza persists, with the size of the epidemic growing worldwide. Various methods have been applied to measure and predict the threat. This paper outlines our research which develops a knowledge-based method that makes full use of previous knowledge to perform a comprehensive forecast of the risk of avian influenza and generate reliable warning signals for a specific region at a specific time. The method contains a risk estimation model and a knowledge-based prediction method using fuzzy logic and case-based reasoning (CBR) to generate timely early warnings to support decision makers to identify underlying vulnerabilities and implement relevant strategies. An example is presented that illustrates the capabilities and procedures of the proposed method in avian influenza early warning systems.", "num_citations": "7\n", "authors": ["1068"]}
{"title": "A hybrid recommendation approach for hierarchical items\n", "abstract": " Recommender systems aim to recommend items that are likely to be of interest to the user. In many business situations, complex items are described by hierarchical tree structures, which contain rich semantic information. To recommend hierarchical items accurately, the semantic information of the hierarchical tree structures must be considered comprehensively. In this study, a new hybrid recommendation approach for complex hierarchical tree structured items is proposed. In this approach, a comprehensive semantic similarity measure model for hierarchical tree structured items is developed. It is integrated with the traditional item-based collaborative filtering approach to generate recommendations.", "num_citations": "7\n", "authors": ["1068"]}
{"title": "Information inconsistencies detection using a rule-map technique\n", "abstract": " Timely detecting information inconsistencies (anomalies) in real-time information provides strong support for decision-making in a dynamic decision-making situation. Existing techniques for information inconsistencies detection mainly focus on stored information by using a single structured-fixed descriptive model which always requires support from sufficient prior knowledge. The aim of this study is to develop a method for information inconsistencies detection for real-time information in dynamic decision-making situation where prior knowledge is insufficient by using multiple descriptive models. First, a rule-map technique is presented. A rule-map is a hierarchical directed graph, whose vertexes are selected descriptive models and whose arcs represent the covering relationship between descriptive models. A rule-map provides a strategy for selecting detecting descriptive models by means of the covering\u00a0\u2026", "num_citations": "7\n", "authors": ["1068"]}
{"title": "A fuzzy decision support system for garment new product development\n", "abstract": " Garment new product development (NPD) evaluation requires considering multiple criteria under a hierarchical structure. The evaluation process often involves uncertainty and fuzziness in both the relationships between criteria and the judgments of evaluators. This study first presents a garment NPD evaluation model under a well-being concept. It then proposes a fuzzy multi-criteria group decision-making (FMCGDM) method to evaluate garment NPD. The advantages of the FMCGDM method include handling criteria in a hierarchical structure, dealing with three kinds of uncertainties simultaneously, and using suitable types of fuzzy numbers to describe linguistic terms. A fuzzy multi-criteria group decision support system (FMCGDSS) is developed to implement the proposed method. Finally a garment NPD evaluation case study demonstrates the proposed method and software system.", "num_citations": "7\n", "authors": ["1068"]}
{"title": "An ontology data matching method for web information integration\n", "abstract": " The emerging Semantic Web relies on the development of ontologies and the deployment of data annotated by ontologies. For a certain domain with a suitable ontology developed, its ontology annotated data (or simply ontology data) from different sources is often overlapping. Similar to a data warehousing process that transforms and merges data from different databases, an integration over the Semantic Web data sources needs to match relevant ontology data among them. This study develops a matching method to address the issue of ontology data matching. This method is different from other data matching or merging methods applied to database or data warehouse cleansing in that it employs more similarity measurements by exploring ontology features. Our experiments show that this proposed method increases matching accuracy.", "num_citations": "7\n", "authors": ["1068"]}
{"title": "Bridging the theoretical bound and deep algorithms for open set domain adaptation\n", "abstract": " In the unsupervised open set domain adaptation (UOSDA), the target domain contains unknown classes that are not observed in the source domain. Researchers in this area aim to train a classifier to accurately: 1) recognize unknown target data (data with unknown classes) and 2) classify other target data. To achieve this aim, a previous study has proven an upper bound of the target-domain risk, and the open set difference, as an important term in the upper bound, is used to measure the risk on unknown target data. By minimizing the upper bound, a shallow classifier can be trained to achieve the aim. However, if the classifier is very flexible [e.g., deep neural networks (DNNs)], the open set difference will converge to a negative value when minimizing the upper bound, which causes an issue where most target data are recognized as unknown data. To address this issue, we propose a new upper bound of target-domain risk\u00a0\u2026", "num_citations": "6\n", "authors": ["1068"]}
{"title": "Ethics and privacy of artificial intelligence: Understandings from bibliometrics\n", "abstract": " Artificial intelligence (AI) and its broad applications are disruptively transforming the daily lives of human beings and a discussion of the ethical and privacy issues surrounding AI is a topic of growing interest, not only among academics but also the general public This review identifies the key entities (i.e., leading research institutions and their affiliated countries/regions, core research journals, and communities) that contribute to the research on the ethical and privacy issues in relation to AI and their intersections using co-occurrence analysis. Topic analyses profile the topical landscape of AI ethics using a topical hierarchical tree and the changing interest of society in AI ethics over time through scientific evolutionary pathways. We also paired 15 selected AI techniques with 17 major ethical issues and identify emerging ethical issues from a core set of the most recent articles published in Nature, Science, and\u00a0\u2026", "num_citations": "6\n", "authors": ["1068"]}
{"title": "DeepPIPE: A distribution-free uncertainty quantification approach for time series forecasting\n", "abstract": " Time series forecasting is a challenging task as the underlying data generating process is dynamic, nonlinear, and uncertain. Deep learning such as LSTM and auto-encoder can learn representations automatically and has attracted considerable attention in time series forecasting. However, current approaches mainly focus on point estimation, which leads to the inability to quantify uncertainty. Meantime, existing deep uncertainty quantification methods suffer from various limitations in practice. To this end, this paper presents a novel end-to-end framework called deep prediction interval and point estimation (DeepPIPE) that simultaneously performs multi-step point estimation and uncertainty quantification for time series forecasting. The merits of this approach are threefold: first, it requires no prior assumption on the distribution of data noise; second, it utilizes a novel hybrid loss function that improves the accuracy\u00a0\u2026", "num_citations": "6\n", "authors": ["1068"]}
{"title": "Unsupervised domain adaptation with sphere retracting transformation\n", "abstract": " Unsupervised domain adaptation aims to leverage the knowledge in training data (source domain) to improve the performance of tasks in the remaining unlabeled data (target domain) by mitigating the effect of the distribution discrepancy. Existing approaches resolve this problem mainly by 1) mapping data into a latent space where the distribution discrepancy between two domains is reduced; or 2) reducing the domain shift by weighting the source domain. However, most of these approaches share a common issue that they neglect inter-class margins while matching distributions, which has a significant impact on classification performance. In this paper, we analyze the issue from the theoretical aspect and propose a novel unsupervised domain adaptation approach: Sphere Retracting Transformation (SRT), which reduces the distribution discrepancy and increases inter-class margins. We implement SRT\u00a0\u2026", "num_citations": "6\n", "authors": ["1068"]}
{"title": "A fuzzy kernel c-means clustering model for handling concept drift in regression\n", "abstract": " Concept drift, given the huge volume of high-speed data streams, requires traditional machine learning models to be self-adaptive. Techniques to handle drift are especially needed in regression cases for a wide range of applications in the real world. There is, however, a shortage of research on drift adaptation for regression cases in the literature. One of the main obstacles to further research is the resulting model complexity when regression methods and drift handling techniques are combined. This paper proposes a self-adaptive algorithm, based on a fuzzy kernel c-means clustering approach and a lazy learning algorithm, called FKLL, to handle drift in regression learning. Using FKLL, drift adaptation first updates the learning set using lazy learning, then fuzzy kernel c-means clustering is used to determine the most relevant learning set. Experiments show that the FKLL algorithm is better able to respond to drift\u00a0\u2026", "num_citations": "6\n", "authors": ["1068"]}
{"title": "Model and algorithm for multi-follower tri-level hierarchical decision-making\n", "abstract": " Tri-level decision-making addresses compromises among interacting decision entities that are distributed throughout a three-level hierarchy. Decision entities at the three hierarchical levels are respectively termed as the top-level leader, the middle-level follower and the bottom-level follower. When multiple followers are involved at the middle and bottom levels, the leader\u2019s decision will be affected not only by reactions of the followers but also by various relationships among them. To support such a multi-follower tri-level (MFTL) decision-making process, this study first proposes a general MFTL decision model for the situation involving both cooperative and uncooperative relationships among multiple followers. It then develops a MFTL Kth-Best algorithm to find an optimal solution to the model. Lastly, we use the proposed MFTL decision techniques to deal with a supply chain management problem in\u00a0\u2026", "num_citations": "6\n", "authors": ["1068"]}
{"title": "A situation analysis decision support system based on dynamic object oriented Bayesian networks\n", "abstract": " This paper proposes a situation analysis decision support system (SADSS) for safety of safety-critical systems where the operators are stressed by the task of understanding what is going on in the situation. The proposed SADSS is developed based on a new model-driven engineering approach for hazardous situations modeling based on dynamic object oriented Bayesian networks to reduce the complexity of the decision-making process by aiding operators\u2019 cognitive activities. The SADSS includes four major elements: a situation data collection based on observable variables such as sensors, a situation knowledgebase which consists of dynamic object oriented Bayesian networks to model hazardous situations, a situation analysis which shows the current state of hazardous situations based on risk concept and possible near future state, and a humancomputer interface. Finally two evaluation methods for partial and full validation of SADSS are presented.", "num_citations": "6\n", "authors": ["1068"]}
{"title": "A price prediction model for online auctions using fuzzy reasoning techniques\n", "abstract": " E-consumers are urged to opt for the best bidding strategies to excel in the competitive environment of multiple and simultaneous online auctions for same or similar items. It becomes very complicated for the bidders to make the decisions of selecting which auction to participate in, place single or multiple bids, early or late bidding and how much to bid. In this paper, we present the design of an autonomous dynamic bidding agent (ADBA) that makes these decisions on behalf of the buyers according to their bidding behaviors. The agent develops a comprehensive methodology for initial price estimation and an integrated model for final price prediction. The initial price estimation methodology selects an auction to participate in and assesses the value (initial price) of the auctioned item. Then the final price prediction model forecasts the bid amount by designing different bidding strategies using fuzzy reasoning\u00a0\u2026", "num_citations": "6\n", "authors": ["1068"]}
{"title": "Human-centric cognitive decision support system for ill-structured problems\n", "abstract": " The solutions to ill-structured decision problems greatly rely upon the intuition and cognitive abilities of a decision maker because of the vague nature of such problems. To provide decision support for these problems, a decision support system (DSS) must be able to support a user\u2019s cognitive abilities, as well as facilitate seamless communication of knowledge and cognition between itself and the user. This study develops a cognitive decision support system (CDSS) based on human-centric semantic de-biased associations (SDA) model to improve ill-structured decision support. The SDA model improves ill-structured decision support by refining a user\u2019s cognition through reducing or eliminating bias and providing the user with validated domain knowledge. The use of semantics in the SDA model facilitates the natural representation of the user\u2019s cognition, thus making the transfer of knowledge/cognition\u00a0\u2026", "num_citations": "6\n", "authors": ["1068"]}
{"title": "A time-series-based technology intelligence framework by trend prediction functionality\n", "abstract": " Technology Intelligence (TI) indicates the concept and applications that transform data hidden in patents or scientific literature into technical insight for technology development planning and strategies formulation. Although much effort has been put into technology trend analysis in existing research, the majority of the results are still obtained from expert opinions on the basis of historical trends presented by content-based Technology Intelligence tools. To improve this situation, this paper proposes a time-series-based framework for TI that enables the system to be more effective when dealing with trend prediction requirements. Time-series analysis module is first applied in TI framework to process patent time series for technology trend predictions in a real sense, at the same time overcome the problem that prediction of future data points' values is insufficient to support TI construction. Based on explicit patent\u00a0\u2026", "num_citations": "6\n", "authors": ["1068"]}
{"title": "An ontology for e-government service integration\n", "abstract": " Composition and delivery of e-government web services is a challenging task. The lack of semantics in the current Web Services Description Language (WSDL) prevents automatic discovery and hence, automatic invocation and composition of those services. This paper presents a knowledgebase design, which provides technical support for the implementation of dynamic integration of e-government web services in an intuitive and coherent framework by using and extending the Ontology Web Language for Services (OWL-S). This new ontology is a logical extension of OWL-S that is designed to overcome the shortcoming of OWL-S in composition of services from different WSDLs. We extend this existing approach to enable the design of a Metamodel that is used as an alterable workflow for a composite service. The resulting ontology covers specific web services semantic concepts to implement the phenomenon of LifeEvent in the context of e-government, by: (1 ) facilitating the construction of alternative service composition workflows from different web service providers; (2) enabling the repair or re-configuration of workflows in runtime. \u00a92012 CRL Publishing Ltd.", "num_citations": "6\n", "authors": ["1068"]}
{"title": "Supporting situation awareness using neural network and expert system\n", "abstract": " Situation awareness (SA) is a critical factor for human decision making and performance in dynamic environments. Actually SA is a mental model of the current state of the environment and includes many types of complex systems such as safety supervisory systems. The current paper employs two focus areas including neural network and expert system for maintaining SA in a safety supervisory system. The neural network components provide adaptive mechanisms for perception, and the expert system offers the ability to support comprehension and projection.", "num_citations": "6\n", "authors": ["1068"]}
{"title": "A personalized recommender system for telecom products and services\n", "abstract": " The Internet brings excellent opportunities to businesses for providing personalized online services to their customers. Recommender systems are designed to automatically generate personalized recommendations of products and services. This study develops a hybrid recommendation approach which combines user-based and item-based collaborative filtering techniques for mobile product and service recommendation. It particularly implements the approach into an intelligent recommendation system called telecom product recommender system (TCPRS). Experimental results show that the TCPRS can effectively help new customer selecting the most suitable mobile products and services.", "num_citations": "6\n", "authors": ["1068"]}
{"title": "Team situation awareness measure using semantic utility functions for supporting dynamic decision-making\n", "abstract": " Team decision-making is a remarkable feature in a complex dynamic decision environment, which can be supported by team situation awareness. In this paper, a team situation awareness measure (TSAM) method using a semantic utility function is proposed. The semantic utility function is used to clarify the semantics of qualitative information expressed in linguistic terms. The individual and team situation awareness are treated as linguistic possibility distributions on the potential decisions in a dynamic decision environment. In the TSAM method, team situation awareness is generated through reasoning and aggregating individual situation awareness based on a multi-level hierarchy mental model of the team. Individual and team mental models are composed of key drivers and significant variables. An illustrative example in telecoms customer churn prediction is given to explain the effectiveness and the\u00a0\u2026", "num_citations": "6\n", "authors": ["1068"]}
{"title": "A particle swarm optimization based algorithm for fuzzy bilevel decision making with constraints-shared followers\n", "abstract": " In a bilevel decision problem, decision making may involve multiple followers and fuzzy demands. This research focuses on the problem of fuzzy linear bilevel decision making with multiple followers who share common constraints (FBCSF). Based on the ranking relationship among fuzzy sets defined by cut set and satisfactory degree \u03b1, a FBCSF model is presented and a particle swarm optimization based algorithm is developed. The experiments reveal that solutions obtained by this algorithm are reasonable and stable.", "num_citations": "6\n", "authors": ["1068"]}
{"title": "A constrained clustering approach to duplicate detection among relational data\n", "abstract": " This paper proposes an approach to detect duplicates among relational data. Traditional methods for record linkage or duplicate detection work on a set of records which have no explicit relations with each other. These records can be formatted into a single database table for processing. However, there are situations that records from different sources can not be flattened into one table and records within one source have certain (semantic) relations between them. The duplicate detection issue of these relational data records/instances can be dealt with by formatting them into several tables and applying traditional methods to each table. However, as the relations among the original data records are ignored, this approach generates poor or inconsistent results. This paper analyzes the characteristics of relational data and proposes a particular clustering approach to perform duplicate detection. This\u00a0\u2026", "num_citations": "6\n", "authors": ["1068"]}
{"title": "A lambda-cut approximate approach to supporting Fuzzy Goal based Bilevel Decision Making in risk management\n", "abstract": " Bilevel decision making techniques are developed to handle the decentralized problem, in many areas such as risk management, with two-level decision makers, the leader and the follower, who may set goals for their fuzzy objective functions. This paper proposes a X-cut approximate approach to solving the Fuzzy Goal based Bilevel Decision Making (FGBLDM) problem. Firstly, the X-cut set based FGBLDM model and related definitions and theo-rems are given. Then, the programmable algorithm for FGBLDM is presented in detail. Finally, a numerical example is given to illustrate the executing procedure of this algorithm.", "num_citations": "6\n", "authors": ["1068"]}
{"title": "A novel fuzzy attitude based bidding strategy for multi-attribute auction\n", "abstract": " Auctions have recently commanded a lot of attention in the field of multi-agent systems. To be successful in open multi-attribute auctions, agents must be capable of adapting different strategies and tactics to their prevailing circumstances. This paper presents a software test-bed for studying autonomous bidding strategies in simulated auctions for procuring goods. It shows that agents' bidding strategy explore the attitudes and behaviors that help agents to manage dynamic assessment of alternative prices of goods given the different scenario conditions. Our agent also uses fuzzy techniques for the decision making: to make decisions about the outcome of auctions, and to alter the agent's bidding strategy in response to the different criteria and market conditions", "num_citations": "6\n", "authors": ["1068"]}
{"title": "Applying web personalization techniques in E-government services\n", "abstract": " Many E-commerce websites attempt to develop personalized features to encourage users' repetitive visits. Yet, there is less attention about the applications of personalization technologies in E-government services. In this study, we present a classification of personalization techniques. Also, a novel recommendation approach is proposed to improve the existing techniques by the integration of user-based and item-based collaborative filtering recommendation techniques. A recommender system prototype, named Smart Trade Exhibitions Finder, is developed to help companies choosing the right trade exhibitions. The outcome of this study will have tremendous significance in overcoming the drawback of existing recommendation approaches. \u00a9 2005. Xuetao Guo, Jie Lu & Simeon Simoff.", "num_citations": "6\n", "authors": ["1068"]}
{"title": "Recommending trade exhibitions by integrating semantic information with collaborative filtering\n", "abstract": " Recommender systems have gained successfully applications particular in e-commerce domain. However, existing recommendation approaches can not effectively deal with recommendation issue of one-and-only items occurred in government-to-business services, e.g. recommendation of trade exhibitions. Thus, in this study, we propose a novel approach by integrating semantic information with the traditional item-based collaborative filtering, and attempt to help the businesses choose the right trade exhibitions at the right time. The outcome of this study have tremendous significance in overcoming the 'new item' problem of existing recommendation approaches.", "num_citations": "6\n", "authors": ["1068"]}
{"title": "Multi-follower linear bilevel programming: model and kuhn-tucker approach\n", "abstract": " The majority of research on bilevel programming has centered on the linear version of the problem in which only one leader and single follower are involved. This paper proposes a general model and Kuhn-Tucker approach for linear bilevel programming problems in which one leader and multiple follower (s) are involved, and there may (not) be sharing variables among the followers. Finally, a numeric example is given to show how the Kuhn-Tucker approach is applied to solve multi-follower linear bilevel problems.", "num_citations": "6\n", "authors": ["1068"]}
{"title": "Preselectable optical fingerprints of heterogeneous upconversion nanoparticles\n", "abstract": " The control in optical uniformity of single nanoparticles and tuning their diversity in multiple dimensions, dot to dot, holds the key to unlocking nanoscale applications. Here we report that the entire lifetime profile of the single upconversion nanoparticle (\u03c42 profile) can be resolved by confocal, wide-field, and super-resolution microscopy techniques. The advances in both spatial and temporal resolutions push the limit of optical multiplexing from microscale to nanoscale. We further demonstrate that the time-domain optical fingerprints can be created by utilizing nanophotonic upconversion schemes, including interfacial energy migration, concentration dependency, energy transfer, and isolation of surface quenchers. We exemplify that three multiple dimensions, including the excitation wavelength, emission color, and \u03c42 profile, can be built into the nanoscale derivative \u03c42-dots. Creating a vast library of individually\u00a0\u2026", "num_citations": "5\n", "authors": ["1068"]}
{"title": "Exploring the genetic basis of diseases through a heterogeneous bibliometric network: A methodology and case study\n", "abstract": " Literature-based knowledge (LBD) discovery is a practical approach to inferring the associations between diseases and genetic factors from unstructured biomedical data, i.e., the literature. However, most of the contemporary LBD methods are designed for specific cases and rely heavily on prior knowledge. In this paper, we propose an adaptable and transferable methodology that not only summarizes the genetic factors known to be associated with a queried disease but also predicts likely associations that have yet to be identified. The framework incorporates different biomedical entities in a heterogeneous co-occurrence network. Three centrality indicators, coupled with a novel measure based on intersection ratios, capture the importance and specificity of each factor to the disease under study. Undiscovered, but likely, associations are identified through a semantic similarity matrix generated by our Bioentity2Vec\u00a0\u2026", "num_citations": "5\n", "authors": ["1068"]}
{"title": "A deep-ensemble-level-based interpretable Takagi-Sugeno-Kang fuzzy classifier for imbalanced data\n", "abstract": " Existing research reveals that the misclassification rate for imbalanced data depends heavily on the problematic areas due to the existence of small disjoints, class overlap, borderline, and rare data samples. In this study, by stacking zero-order Takagi-Sugeno-Kang (TSK) fuzzy subclassifiers on the minority class and its problematic areas in the deep ensemble, a novel deep-ensemble-level-based TSK fuzzy classifier (IDE-TSK-FC) for imbalanced data classification tasks is presented to achieve both promising classification performance and high interpretability of zero-order TSK fuzzy classifiers. Simultaneously, according to the stacked generalization principle, the proposed classifier lifts up oversampling from the data level to the deep ensemble level with a guarantee of enhanced generalization capability for class imbalance learning. In the structure of IDE-TSK-FC, the first interpretable zero-order TSK fuzzy\u00a0\u2026", "num_citations": "5\n", "authors": ["1068"]}
{"title": "AUC-based extreme learning machines for supervised and semi-supervised imbalanced classification\n", "abstract": " Extreme learning machines (ELMs) has been theoretically and experimentally proved to achieve promising performance at a fast learning speed for supervised classification tasks. However, it does not perform well on imbalanced binary classification tasks and tends to get biased toward the majority class. Besides, since a large amount of training data with labels are not always available in the real world, there is an urgent demand to develop an efficient semi-supervised version of ELM for imbalanced binary classification tasks. In this article, owing to the distinct insensitivity of area under the ROC curve (AUC) to both class skews and changes of class distributions, we focus the study on integrating AUC maximization into the ELM framework to tackle with imbalanced binary classification tasks well. By demystifying the AUC metric with the ELM framework, we develop a new AUC-based ELM called AUC-ELM for\u00a0\u2026", "num_citations": "5\n", "authors": ["1068"]}
{"title": "Cross-domain recommendation with probabilistic knowledge transfer\n", "abstract": " Recommender systems have drawn great attention from both academic and practical area. One challenging and common problem in many recommendation methods is data sparsity, due to the limited number of observed user interaction with the products/services. To alleviate the data sparsity problem, cross-domain recommendation methods are developed to share group-level knowledge in several domains so that recommendation in the domain with scarce data can benefit from domains with relatively abundant data. However, divergence exists in the data of similar domains so that the extracted group-level knowledge is not always suitable to be applied in the target domain, thus recommendation accuracy in the target domain is impaired. In this paper, we propose a cross-domain recommendation method with probabilistic knowledge transfer. The proposed method maintain two sets of group-level\u00a0\u2026", "num_citations": "5\n", "authors": ["1068"]}
{"title": "A self-adaptive fuzzy network for prediction in non-stationary environments\n", "abstract": " Prediction in non-stationary environments, where data streams are ever-changing at very high speeds, has become more and more important in real-world applications. The uncertainty in data streams caused by changes in data distribution is described as concept drift. The appearance of concept drift in a data stream results in inconsistencies between the existing data and incoming data. Such inconsistencies pose a great challenge to conventional machine learning methods, given they are built on the assumption of independent and identically distributed data and cannot adapt to unpredictable changes in knowledge patterns. To solve such data stream uncertainty problem, this paper presents a window-based self-adaptive fuzzy network called adaptive fuzzy network (AFN), which can continuously modify the network through identifying new knowledge from the previous data samples. Three components are\u00a0\u2026", "num_citations": "5\n", "authors": ["1068"]}
{"title": "Explore uncertainty in residual networks for crowds flow prediction\n", "abstract": " The residual network has witnessed a great success in computer vision particularly on classification tasks, however, it has not been well studied in regression. In this work, we show its competence in a regression task - crowds flow prediction, which has strong implication to city safety and management. The problem of crowds flow prediction is challenging due to its fast dynamics. To address this issue, we explore residual learning with Gaussian regularization and propose a novel convolutional neural network called Gaussian noise residual networks (Noise-ResNet). Compared with the benchmark ST-ResNet on crowds flow prediction, the proposed architecture has three advantages: 1) Superior performance. Especially, it attains the state-of-the-art results on benchmark dataset BikeNYC. 2) Light architecture. Noise-ResNet only utilises one residual unit rather than STResNet with multiple ones, which greatly\u00a0\u2026", "num_citations": "5\n", "authors": ["1068"]}
{"title": "Applying dynamic Bayesian tree in property sales price estimation\n", "abstract": " Accurate prediction of Residential Property Sale Price is very important and significant in the operation of the real estate market. Property sellers and buyers/Investors wish to know a fair value for their properties in particular at the time of the sales transaction. The main reason to build an Automated Valuation Model is to be accurate enough to replace human. To select a most suitable model for the property sale price prediction, this paper examined seven Tree-based machine learning models including Dynamic Bayesian Tree (online learning method), Random Forest, Stochastic Gradient Boosting, CART, Bagged CART, Tree Bagged Ensembles and Boosted Tree (batch learning methods) by comparing their RMSE and MAE performances. The performance of these models are tested on 1967 records of unit sales from 19 suburbs of Sydney, Australia. The main purpose of this study is to compare the performance of\u00a0\u2026", "num_citations": "5\n", "authors": ["1068"]}
{"title": "Heterogeneous unsupervised domain adaptation based on fuzzy feature fusion\n", "abstract": " Domain adaptation is a transfer learning approach that has been widely studied in the last decade. However, existing works still have two limitations: 1) the feature spaces of the domains are homogeneous, and 2) the target domain has at least a few labeled instances. Both limitations significantly restrict the domain adaptation approach when knowledge is transferred across domains, especially in the current era of big data. To address both issues, this paper proposes a novel fuzzy-based heterogeneous unsupervised domain adaptation approach. This approach maps the feature spaces of the source and target domains onto the same latent space constructed by fuzzy features. In the new feature space, the label spaces of two domains are maintained to reduce the probability of negative transfer occurring. The proposed approach delivers superior performance over current benchmarks, and the heterogeneous\u00a0\u2026", "num_citations": "5\n", "authors": ["1068"]}
{"title": "Transfer learning in hierarchical feature spaces\n", "abstract": " Transfer learning provides an approach to solve target tasks more quickly and effectively by using previously acquired knowledge learned from source tasks. As one category of transfer learning approaches, feature-based transfer learning approaches aim to find a latent feature space shared between source and target domains. The issue is that the sole feature space can't exploit the relationship of source domain and target domain fully. To deal with this issue, this paper proposes a transfer learning method that uses deep learning to extract hierarchical feature spaces, so knowledge of source domain can be exploited and transferred in multiple feature spaces with different levels of abstraction. In the experiment, the effectiveness of transfer learning in multiple feature spaces is compared and this can help us find the optimal feature space for transfer learning.", "num_citations": "5\n", "authors": ["1068"]}
{"title": "Handling uncertainty in cloud resource management using fuzzy Bayesian networks\n", "abstract": " The success of cloud services depends critically on the effective management of virtualized resources. This paper aims to design and implement a decision support method to handle uncertainties in resource management from the cloud provider perspective that enables underlying complexity, automates resource provisioning and controls client-perceived quality of service. The paper includes a probabilistic decision making module that relies upon a fuzzy Bayesian network to determine the current situation status of a cloud infrastructure, including physical and virtual machines, and predicts the near future state, that will help the hypervisor to migrate or expand the VMs to reduce execution time and meet quality of service requirements. First, the framework of resource management is presented. Second, the decision making module is developed. Lastly, a series of experiments to investigate the performance of the\u00a0\u2026", "num_citations": "5\n", "authors": ["1068"]}
{"title": "Feature spaces-based transfer learning\n", "abstract": " Transfer learning provides an approach to solve target tasks more quickly and effectively by using previouslyacquired knowledge learned from source tasks. Most of transfer learning approaches extract knowledge of source domain in the given feature space. The issue is that single perspective can\u201f t mine the relationship of source domain and target domain fully. To deal with this issue, this paper develops a method using Stacked Denoising Autoencoder (SDA) to extract new feature spaces for source domain and target domain, and define two fuzzy sets to analyse the variation of prediction accuracy of target task in new feature spaces.", "num_citations": "5\n", "authors": ["1068"]}
{"title": "Preface: intelligent techniques for data science\n", "abstract": " With the extraordinary spread of computers and sensors, enormous amounts of data are generated every day in a range of areas\u2014search engines, social media, healthcare organizations, insurance companies, financial industry, retail, and many others. Data science refers to the theories, methods, and applications for extracting previously unavailable and potentially highly useful information from data. This field has evolved as a hybrid of research in data mining, machine learning, computational intelligence, databases, algorithms, statistics, operations research, visualization, privacy and security. It is helping us make sense out of vast quantities of information. However, how to use these data by an effective and ethical way is a significant challenge to science and to society as a whole. Intelligent techniques, including artificial intelligence, neural networks, fuzzy logic, granular computing, rough sets, expert systems, case-based reasoning, evolutionary algorithms and swarm computing, have been successfully applied in many fields including data science. This special issue is devoted to the use of intelligent techniques for data science that reflects their current development obtained from selected papers submitted to the 8th International Conference on Intelligent Systems and Knowledge Engineering (ISKE2013) held in Shenzhen, China, during November 20-23, 2013. This issue encompasses seven papers that present the application of different intelligent techniques to different data science problems ranging from recommender systems to recognition processes passing by others like activity simulation, fuzzy trading systems, deep learning and\u00a0\u2026", "num_citations": "5\n", "authors": ["1068"]}
{"title": "A fuzzy tri-level decision making algorithm and its application in supply chain\n", "abstract": " In this paper, we develop a fuzzy tri-level decision making (FTLDM) model to deal with decentralized decision making problems with three levels of decision makers. Based on the -cut of fuzzy set, we transform an FTLDM problem into a multiobjective tri-level decision making problem. Based on the linear tri-level Kth-best algorithm, the global optimal solution can be obtained. A case study for third-party logistics decision making in supply chain is utilized to illustrate the effectiveness of the proposed algorithm. \u00a9 2013. The authors-Published by Atlantis Press.", "num_citations": "5\n", "authors": ["1068"]}
{"title": "Risk-based decision making framework for investment in the real estate industry\n", "abstract": " Investment in the real estate industry is subject to high risk, especially when there are a large number of uncertainty factors in a project. Risk analysis has been widely used to make decisions for real estate investment. Accordingly, risk-based decision making is a vital process that should be considered when a list of projects and constraints are being assessed. This chapter proposes a risk-based decision making (RBDM) framework for risk analysis of investment in the real estate industry, based on a review of the research. The framework comprises the basic concepts, process, sources and factors, techniques/approaches, and issues and challenges of RBDM. The framework can be applied to problem solving different issues involved in the decision making process when risk is a factor. Decision makers need to understand the terms and concepts of their problems and be familiar with the processes involved\u00a0\u2026", "num_citations": "5\n", "authors": ["1068"]}
{"title": "A new approach for choosing the most appropriate fuzzy ranking algorithm for solving MADM problems\n", "abstract": " There are many fuzzy ranking algorithms available to solve multi-attribute decision making (MADM) problems. Some are more suitable than others for particular decision problems. This paper proposes a new method for choosing the most appropriate fuzzy ranking algorithm for solving MADM problems based on the type and number of attributes and the number of alternatives, considering the least time consumption and the least computation for ranking alternatives. In addition, we develop a software to simulate three main fuzzy ranking algorithms: SAW, Negi, and Chen and Hwang (Chen and Hwang 1992). This software can be used in any MADM decision support system.", "num_citations": "5\n", "authors": ["1068"]}
{"title": "A framework for delivering personalized e-Government tourism services\n", "abstract": " E-government (e-Gov) has become one of the most important parts of government strategies. Significant efforts have been devoted to e-Gov tourism services in many countries because tourism is one of the major profitable industries. However, the current e-Gov tourism services are limited to simple online presentation of tourism information. Intelligent e-Gov tourism services, such as the personalized e-Gov (Pe-Gov) tourism services, are highly desirable for helping users decide \"where to go, and what to do/see\" amongst massive number of destinations and enormous attractiveness and activities. This paper proposes a framework of Pe-Gov tourism services using recommender system techniques and semantic ontology. This framework has the potential to enable tourism information seekers to locate the most interesting destinations with the most suitable activities with the least search efforts. Its workflow and some outstanding features are depicted with an example.", "num_citations": "5\n", "authors": ["1068"]}
{"title": "Web ontology data matching for integration: method and framework\n", "abstract": " Purpose \u2013 Matching relevant ontology data for integration is vitally important as the amount of ontology data increases along with the evolving Semantic web, in which data are published from different individuals or organizations in a decentralized environment. For any domain that has developed a suitable ontology, its ontology annotated data (or simply ontology data) from different sources often overlaps and needs to be integrated. The purpose of this paper is to develop intelligent web ontology data matching method and framework for data integration.Design/methodology/approach \u2013 This paper develops an intelligent matching method to solve the issue of ontology data matching. Based on the matching method, it also proposes a flexible peer\u2010to\u2010peer framework to address the issue of ontology data integration in a distributed Semantic web environment.Findings \u2013 The proposed matching method is different from\u00a0\u2026", "num_citations": "5\n", "authors": ["1068"]}
{"title": "Generation and Matching of Ontology Data for the Semantic Web in a Peer-to-peer Framework\n", "abstract": " The abundance of ontology data is very crucial to the emerging semantic web. This paper proposes a framework that supports the generation of ontology data in a ptop environment. It not only enables users to convert existing structured data to ontology data aligned with given ontology schemas, but also allows them to publish new ontology data with ease. Besides ontology data generation, the common issue of data overlapping over the peers is addressed by the process of ontology data matching in the framework. This process helps turn the implicitly related data among the peers caused by overlapping into explicitly interlinked ontology data, which increases the overall quality of the ontology data. To improve matching accuracy, we explore ontology related features in the matching process. Experiments show that adding these features achieves better overall performance than using traditional features only.", "num_citations": "5\n", "authors": ["1068"]}
{"title": "A rule-map based technique for information inconsistency verification\n", "abstract": " This paper focuses on the problem of verifying information inconsistencies in acquired information. A rule-map based technique for data inconsistency is presented, where rule-map is used to describe hierarchical structure of rules and estimate judgment standard for consistency dynamically. Moreover, a state-based knowledge representation technique for logical inconsistency is investigated, in which knowledge is illustrated as states set of related objects and logical inconsistency is determined by the relationships between those state-sets. To illustrate the presented techniques, two examples are given.", "num_citations": "5\n", "authors": ["1068"]}
{"title": "E-service cost benefit evaluation and analysis\n", "abstract": " # Department of Automatic Control Beijing University of Aeronautics and Astronautics bcg@ buaa. edu. cn cost-benefit factor-relation model is proposed through analyzing a questionnaire survey results. The factor-relation model is then considered as domain knowledge, and the data collected is as evidence to the inferencebased verification. This study applies Bayesian network technique to analyze and verify the relationships among cost factors and benefit factors in the development of e-services. A set of useful findings have been obtained for the costs involved in moving services online against the benefits received by adopting e-service applications. These findings have potential to improve the strategic planning of businesses by determining more effective investment items and adopting more suitable development activities in eservices development.", "num_citations": "5\n", "authors": ["1068"]}
{"title": "A new approximate algorithm for solving multiple objective linear programming with fuzzy parameters\n", "abstract": " Many business decisions can be modeled as multiple objective linear programming (MOLP) problems. When formulating a MOLP problem, objective functions and constraints involve many parameters which possible values are assigned by the experts who are often imprecisely or ambiguously known. So, it would be certainly more appropriate to interpret the experts\u2019 understanding of the parameters as fuzzy numerical data which can be represented by fuzzy numbers. This paper focuses on fuzzy multiple objective linear programming (FMOLP) problems with fuzzy parameters in any form of membership function in both objective functions and constraints. Based on the related results of fuzzy linear programming (FLP) and linear programming problems with fuzzy equality and inequality constraints proposed by Zhang et al, this paper firstly proposes related definitions and concepts about FMOLP problems with fuzzy parameters. It then proposes a new approximate algorithm developed for solving the corresponding MOLP problems and the FMOLP problems. Finally, the use of related concepts, theorems, and the proposed approximate algorithm is illustrated by an example involving different cases which include setting various iterate steps, tolerances, weights, and satisfaction levels.", "num_citations": "5\n", "authors": ["1068"]}
{"title": "Framework and implementation of a Web-based multi-objective decision support system: WMODSS\n", "abstract": " This paper presents a web-based general decision support system for solving multi-objective decision problems. This is referred to WMODSS. The system provides three decision-making methods in its method base. They deal with a wide range of linear multiobjective decision-making problems and different user requirements for the solution process. In particular, the WMODSS provides an intelligent guide to help users select a most suitable method from the method base by evaluating the relevant problems and user requirements. A satisfactory solution can thus be obtained in an interactive andflexible manner.", "num_citations": "5\n", "authors": ["1068"]}
{"title": "Tourism website development and user requirements: who are tourism website users and what are their requirements in China\n", "abstract": " China tourism industry is investing to develop a \u201cGolden Tourism Project\u201d. One of the main objectives of this project is to improve web-based tourism online service quality and implement tourism e-commerce. In order to develop successfully the project it is necessary to investigate who are main tourism website users, what are their requirements for online tourism services and how do they assess current tourism websites. The main purposes of this study are to identify current tourism website users, analyse user requirements for tourism online services and explore how design tourism websites to attract users, promote tourism landscape points and improve online tourism service quality in China. Through conducting a survey and analysing the survey resu lts, this paper shows the behaviour characters of current tourism website users, discusses their preferences and requirements for online tourism websites, and identifies the major factors that users concern for tourism website construction in China. Components of tourism websites are analyzed and an evolution model for tourism websites in China is proposed.", "num_citations": "5\n", "authors": ["1068"]}
{"title": "A framework and prototype for intelligent multiple objectives group decision support systems.\n", "abstract": " The objectives of this research are threefold: (i) to develop a conceptual framework and a prototype in order to extend the application capability of a category of multiple objective decision support systems (MODSS) techniques; (ii) to explore the combined functionalities of knowledge-based expert systems (ES) and MODSS through embedding an intelligent front-end, and (iii) to develop a new system and process of dealing with multiple objective decision making (MODM) models in a group decision support system (GDSS) framework. Ultimately, a system that integrates MODSS, ES and GDSS is generated, which is then evaluated in a laboratory experimental setup. This integrated system contains a sufficient number of MODM methods to solve MODM problems, provides an ES-based guide to select and use the most suitable MODM method, and has the capability to aggregate individual decision makers' preferences to produce a compromise solution of an MODM problem in different forms and styles of group meetings. The system is supported by a set of group decision making (GDM) methods which combine the preferences of the individual group members and thus increases the confidence of each group member in the compromise solution.The research is conducted using a multiple-methodologies approach using the system development methodology as the backbone. The conceptual framework of the integrated system is elaborated to integrate multiple system elements into one facility at the application system level based on functional and resource integration. A prototype implements this conceptual framework as an intelligence-based and\u00a0\u2026", "num_citations": "5\n", "authors": ["1068"]}
{"title": "Domain-specific meta-embedding with latent semantic structures\n", "abstract": " Meta-embedding aims at assembling pre-trained embeddings from various sources and producing more expressively powerful word representations. Many natural language processing (NLP) tasks in a specific domain benefit from meta-embedding, especially when the task suffers from low resources. This paper proposes an unsupervised meta-embedding method that jointly models background knowledge from the source embeddings and domain-specific knowledge from the task domain. Specifically, embeddings from multiple sources for a word are dynamically aggregated to a single meta-embedding by a differentiable attention module. The embeddings derived from pre-training on a large-scale corpus provide complete background knowledge of word usage. Then, the meta-embedding is further enriched by exploring domain-specific knowledge from each task domain in two ways. First, contextual information\u00a0\u2026", "num_citations": "4\n", "authors": ["1068"]}
{"title": "A fuzzy word similarity measure for selecting top-k similar words in query expansion\n", "abstract": " Top-k words selection is a technique used to detect and return the k most similar words to a given word from a candidate set. This is a crucial and widely used tool in various tasks. The key issue in top-k words selection is how to measure the similarity between words. One popular and effective solution is to use a word embedding-based similarity measure, which represents words as low-dimensional vectors and measures the similarities between words according to the similarity of the vectors, using a metric. However, most word embedding methods only consider the local proximity properties of two words in a corpus. To mitigate this issue, we propose to use association rules for measuring word similarity at a global level, and a fuzzy similarity measure for top-k words selection that jointly encodes the local and the global similarities. Experiments on a real-world query task with three benchmark datasets, i.e., TREC\u00a0\u2026", "num_citations": "4\n", "authors": ["1068"]}
{"title": "Guest editorial: special issue on new advances in deep-transfer learning\n", "abstract": " The papers in this special issue aim to present the most recent advances in deep transfer learning (DTL). While deep learning has achieved great success in big data applications, transfer learning (TL) is an important paradigm mainly for small/insufficient data applications, which utilizes the data/knowledge in one task to facilitate the learning in another relevant task. How to integrate DL and TL to combine their advantages is an interesting and important research topic. DTL is proposed to address this issue. Deep learning extracts knowledge from big data, which can then be used by TL for a new task/domain with small/insufficient data.", "num_citations": "4\n", "authors": ["1068"]}
{"title": "RsyGAN: Generative adversarial network for recommender systems\n", "abstract": " Many recommender systems rely on the information of user-item interactions to generate recommendations. In real applications, the interaction matrix is usually very sparse, as a result, the model cannot be optimised stably with different initial parameters and the recommendation performance is unsatisfactory. Many works attempted to solve this problem, however, the parameters in their models may not be trained effectively due to the sparse nature of the dataset which results in a lower quality local optimum. In this paper, we propose a generative network for making user recommendations and a discriminative network to guide the training process. An adversarial training strategy is also applied to train the model. Under the guidance of a discriminative network, the generative network converges to an optimal solution and achieves better recommendation performance on a sparse dataset. We also show that the\u00a0\u2026", "num_citations": "4\n", "authors": ["1068"]}
{"title": "A noise-tolerant fuzzy c-means based drift adaptation method for data stream regression\n", "abstract": " Concept drift referring to the changes of data distributions has been one critical challenge typically associated with mining data streams. Current drift detection and adaptation methods focus on how to immediately detect the distribution changes once the concept drift occurs and swiftly update the model to be applicable to the newly arrived data instances. Most of those methods assume the data does not have noise or the noise is too weak to affect the modeling procedure. However, realworld data are normally contaminated, and denoise techniques are highly preferred as a necessary preprocess. This issue is more complex for a data stream with concept drift because the noise is very likely to be confused with drift. Motivated by that, this paper proposes a Noise-tolerant Fuzzy c-means based drift Adaptation method (NFA) which can adapt to the changing distributions and is suitable for noisy data streams. The\u00a0\u2026", "num_citations": "4\n", "authors": ["1068"]}
{"title": "A novel fuzzy neural network for unsupervised domain adaptation in heterogeneous scenarios\n", "abstract": " How to leverage knowledge from labelled domain (source) to help classify unlabeled domain (target) is a key problem in the machine learning field. Unsupervised domain adaptation (UDA) provides a solution to this problem and has been well developed for two homogeneous domains. However, when the target domain is unlabeled and heterogeneous with the source domain, current UDA models cannot accurately transfer knowledge from a source domain to a target domain. Benefiting from development of neural networks, this paper presents a new neural network, shared fuzzy equivalence relations neural network (SFER-NN), to address the heterogeneous UDA (HeUDA) problem. SFER-NN transfers knowledge across two domains according to shared fuzzy equivalence relations that can simultaneously cluster features of two domains into several categories. Based on the clustered categories, SFER-NN is\u00a0\u2026", "num_citations": "4\n", "authors": ["1068"]}
{"title": "Domain selection of transfer learning in fuzzy prediction models\n", "abstract": " Transfer learning has emerged as a solution for the cases where little or no labeled data are available in the training process. It leverages the previously acquired knowledge (a source domain with a large amount of labeled data) to facilitate solving the current tasks (a target domain with little labeled data). Many transfer learning methods have been proposed, and especially fuzzy transfer learning method, which is based on fuzzy systems, has been developed because of its capability to deal with the uncertainty in transfer learning. However, there is one issue with fuzzy transfer learning that has not yet been resolved: the domain selection problem, which is heavily depended on the knowledge transfer method and the applied prediction model. In this work, we explore the domain selection problem in TakagiSugeno fuzzy model when multiple source domains are accessible, and define the similarity between the\u00a0\u2026", "num_citations": "4\n", "authors": ["1068"]}
{"title": "Cooperative hierarchical Dirichlet processes: Superposition vs. maximization\n", "abstract": " The cooperative hierarchical structure is a common and significant data structure observed in, or adopted by, many research areas, such as: text mining (author\u2013paper\u2013word) and multi-label classification (label\u2013instance\u2013feature). Renowned Bayesian approaches for cooperative hierarchical structure modeling are mostly based on hierarchical Bayesian models. However, these approaches suffer from a serious issue in that the number of hidden topics/factors needs to be fixed in advance and an inappropriate number may lead to overfitting or underfitting. One elegant way to resolve this issue is Bayesian nonparametric learning, but existing work in this area still cannot be applied to cooperative hierarchical structure modeling.In this paper, we propose a cooperative hierarchical Dirichlet process (CHDP) to fill this gap. Each node in a cooperative hierarchical structure is assigned a Dirichlet process to model its\u00a0\u2026", "num_citations": "4\n", "authors": ["1068"]}
{"title": "Counterfactual inference with hidden confounders using implicit generative models\n", "abstract": " In observational studies, a key problem is to estimate the causal effect of a treatment on some outcome. Counterfactual inference tries to handle it by directly learning the treatment exposure surfaces. One of the biggest challenges in counterfactual inference is the existence of unobserved confounders, which are latent variables that affect both the treatment and outcome variables. Building on recent advances in latent variable modelling and efficient Bayesian inference techniques, deep latent variable models, such as variational auto-encoders (VAEs), have been used to ease the challenge by learning the latent confounders from the observations. However, for the sake of tractability, the posterior of latent variables used in existing methods is assumed to be Gaussian with diagonal covariance matrix. This specification is quite restrictive and even contradictory with the underlying truth, limiting the quality of the\u00a0\u2026", "num_citations": "4\n", "authors": ["1068"]}
{"title": "Unconstrained fuzzy feature fusion for heterogeneous unsupervised domain adaptation\n", "abstract": " Domain adaptation can transfer knowledge from the source domain to improve pattern recognition accuracy in the target domain. However, it is rarely discussed when the target domain is unlabeled and heterogeneous with the source domain, which is a very challenging problem in the domain adaptation field. This paper presents a new feature reconstruction method: unconstrained fuzzy feature fusion. Through the reconstructed features of a source and a target domain, a geodesic flow kernel is applied to transfer knowledge between them. Furthermore, the original information of the target domain is also preserved when reconstructing the features of the two domains. Compared to the previous work, this work has two advantages: 1) the sum of the memberships of the original features to fuzzy features no longer must be one, and 2) the original information of the target domain is persevered. As a result of these\u00a0\u2026", "num_citations": "4\n", "authors": ["1068"]}
{"title": "RNN-based traffic flow prediction for dynamic reversible lane control decision\n", "abstract": " Accurate and real-time traffic flow prediction is the basis of dynamic reversible lane control decision, which plays an important role in alleviating congestion. However, the existing methods could hardly memorize long-term dependencies to produce accurate result of sequence prediction. In the paper, a Long Short-Term Memory (LSTM) and a Gated Recurrent Units (GRU) Recurrent Neural Network (RNN) are adapted to accurately predict traffic flow. A dynamic reversible lane management model is then conducted based on the prediction outcome. The result shows that RNNs obviously outperform the existing feed forward neural network (FFNN) model in terms of accuracy, and therein the forecasting error of GRU is lower than LSTM. Moreover, the result presents that the dynamic reversible lane control plan based on GRU RNN could reduce the total travel time by 0.76% than LSTM and 9.30% than FFNN.", "num_citations": "4\n", "authors": ["1068"]}
{"title": "Generating a risk profile for car insurance policyholders: A deep learning conceptual model\n", "abstract": " In recent years, technological improvements have provided a variety of new opportunities for insurance companies to adopt telematics devices in line with usage-based insurance models. This paper sheds new light on the application of big data analytics for car insurance companies that may help to estimate the risks associated with individual policyholders based on complex driving patterns. We propose a conceptual framework that describes the structural design of a risk predictor model for insurance customers and combines the value of telematics data with deep learning algorithms. The model\u2019s components consist of data transformation, criteria mining, risk modelling, driving style detection, and risk prediction. The expected outcome is our methodology that generates more accurate results than other methods in this area.", "num_citations": "4\n", "authors": ["1068"]}
{"title": "Fuzzy transfer learning in data-shortage and rapidly changing environments\n", "abstract": " The emergence of big data greatly promotes the development of data-driven machine learning technologies. The common assumption in machine learning that the training data and the test data have identical feature spaces with underlying distributions impedes the development of machine learning. To deal with this issue, transfer learning is studied to exploit the knowledge accumulated from data in auxiliary domains to facilitate predictive modelling consisting of different data patterns in the current domain. There have been a significant number of methods proposed to address the classification, as the task, through transfer learning, but the studies targeted at regression problems are still scarce. In this paper, we propose a new transfer learning method to deal with the regression task in the target domain where few data are available. Takagi-Sugeno fuzzy model is used to construct the model for regression task in\u00a0\u2026", "num_citations": "4\n", "authors": ["1068"]}
{"title": "An intelligent system by fuzzy reliability algorithm in fault tree analysis for nuclear power plant probabilistic safety assessment\n", "abstract": " Fault tree analysis for nuclear power plant probabilistic safety assessment is an intricate process. Personal computer-based software systems have therefore been developed to conduct this analysis. However, all existing fault tree analysis software systems only accept quantitative data to characterized basic event reliabilities. In real-world applications, basic event reliabilities may not be represented by quantitative data but by qualitative justifications. The motivation of this work is to develop an intelligent system by fuzzy reliability algorithm in fault tree analysis, which can accept not only quantitative data but also qualitative information to characterized reliabilities of basic events. In this paper, a newly-developed system called InFaTAS-NuSA is presented and its main features and capabilities are discussed. To benchmark the applicability of the intelligent concept implemented in InFaTAS-NuSA, a case study is\u00a0\u2026", "num_citations": "4\n", "authors": ["1068"]}
{"title": "A BI\u2010LEVEL DECISION MODEL FOR CUSTOMER CHURN ANALYSIS\n", "abstract": " This paper develops a bi\u2010level decision model and a solution approach to optimizing service features for a company to reduce its customer churn rate. First, a bi\u2010level decision model, together with its modeling approach, are developed to describe the gaming relationship between decision makers in a company (service provider) and its customers. Then, a practical solution approach to reaching solutions for the bi\u2010level\u2010modeled customer churn problem is developed. Finally, experiments and case studies are conducted to illustrate the bi\u2010level decision model and the solution approach.", "num_citations": "4\n", "authors": ["1068"]}
{"title": "Mining websites preferences on web events in big data environment\n", "abstract": " On the web, there are numerous websites publishing web pages to cover the events occurring in society. The web events data satisfies the well-accepted attributes of big data: Volume, Velocity, Variety and Value. As a great value of web events data, website preferences can help the followers of web events, e.g. peoples or organizations, to select the proper websites to follow their interested aspects of web events. However, the big volume, fast evolution speed, multisource and unstructured data all together make the value of website preferences mining very challenging. In this paper, website preference is formally defined at first. Then, according to the hierarchical attribute of web events data, we propose a hierarchical network model to organize big data of a web event from different organizations, different areas and different nations at a given time stamp. With this hierarchical network structure in hand, two\u00a0\u2026", "num_citations": "4\n", "authors": ["1068"]}
{"title": "An incremental collaborative filtering algorithm for recommender systems\n", "abstract": " Recommender systems are effective approaches to implement personalised e-services. In recent years, they have gained widespread applications in e-commerce. Current recommender systems still need, however, further improvements with respect to the accuracy of prediction and to solve the scalability problem. To this end, an incremental collaborative filtering (InCF) algorithm based on the Mahalanobis distance is presented for recommender systems. Furthermore, the Mahalanobis radial basis function with ellipsoidal shape is employed to determine the decision boundaries of clusters. Experimental results show that the algorithm proposed can lead to improved prediction accuracy and that it turns out to be scalable in recommender applications.", "num_citations": "4\n", "authors": ["1068"]}
{"title": "Mobile-based emergency response system using ontology-supported information extraction\n", "abstract": " This chapter describes an algorithm within a Mobile-based Emergency Response System (MERS) to automatically extract information from Short Message Service (SMS). The algorithm is based on an ontology concept, and a maximum entropy statistical model. Ontology has been used to improve the performance of an information extraction system. A maximum entropy statistical model with various predefined features offers a clean way to estimate the probability of certain token occurring with a certain SMS text. The algorithm has four main functions: to collect unstructured information from an SMS emergency text message; to conduct information extraction and aggregation; to calculate the similarity of SMS text messages; and to generate query and results presentation.", "num_citations": "4\n", "authors": ["1068"]}
{"title": "A dynamic fuzzy multi-criteria group decision support system for manager selection\n", "abstract": " In any organization, because of the importance of management responsibility and its effect on efficiency improvement, the selection of the appropriate person as a manager is one of the important decision making subjects. This paper proposes a new fuzzy multiple attribute-based decision support system (DSS) for choosing suitable managers as such a selection may involve both quantitative and qualitative assessment attributes. There are many fuzzy ranking methods available to solve multi-attribute decision making (MADM) problems. Some are more suitable than other for particular decision problems. The proposed DSS has ability to choose the most appropriate fuzzy ranking method for solving given MADM problem, based on the type of attributes and the size of the problem, considering the least computation and time consumption for ranking alternatives. A DSS software prototype has been developed\u00a0\u2026", "num_citations": "4\n", "authors": ["1068"]}
{"title": "A recommender system for personalized G2B e-services using metadata-based ontology and focused web crawler\n", "abstract": " Providing personalized online services to businesses is one of the main challenges in current e-Government development Recommendation techniques can provide a possible solution for this issue. This study presents an e-Government to Business Recommender System (eGBRS) based on the Multi-Attribute Utility Theory (MAUT) to handle personalized Government-to-Business (G2B) e-Services. Specifically, the proposed system uses web information crawling and metadata-based ontology techniques for building a business-based knowledge base with multiattribute recommendation capabilities. The proposed eGBRS can be used by e-government agencies to provide business partner matching recommendation services to their business users according to their needs and preferences.", "num_citations": "4\n", "authors": ["1068"]}
{"title": "A fuzzy bilevel model and a PSO-based algorithm for day-ahead electricity market strategy making\n", "abstract": " This paper applies bilevel optimization techniques and fuzzy set theory to model and support bidding strategy making in electricity markets. By analyzing the strategic bidding behavior of generating companies, we build up a fuzzy bilevel optimization model for day-ahead electricity market strategy making. In this model, each generating company chooses the bids to maximize the individual profit. A market operator solves an optimization problem based on the minimization purchase electricity fare to determine the output power for each unit and uniform marginal price. Then, a particle swarm optimization (PSO)-based algorithm is developed for solving problems defined by this model.", "num_citations": "4\n", "authors": ["1068"]}
{"title": "A particle swarm optimization based algorithm for fuzzy bilevel decision making with objective-shared followers\n", "abstract": " A bilevel decision problem may have multiple followers as the lower decision units and have fuzzy demands simultaneously. This paper focuses on problems of fuzzy linear bilevel decision making with multiple followers who share a common objective but have different constraints (FBOSF). Based on the ranking relationship among fuzzy sets defined by cut set and satisfactory degree, a FBOSF model is presented and a particle swarm optimization based algorithm is developed.", "num_citations": "4\n", "authors": ["1068"]}
{"title": "Fuzzy-set decision support for a Belgian long-term sustainable energy strategy\n", "abstract": " This chapter addresses the methodological challenges of developing relevant scientific knowledge for a sustainable energy system transition in an innovative way. We argue that scientific contributions to sustainable development do not follow the \u2018linear\u2019 procedure from empirical knowledge production to policy advice. Instead, they consist of problem-oriented combinations of explanatory, orientationand action-guiding knowledge. Society and policy makers not only have to be \u2018provided\u2019 with action-guiding knowledge, but also with an awareness of the manner in which this knowledge is to be interpreted, and where the inevitable uncertainties lie. Since the sustainability question is inherently multi-dimensional, participation of social groups is an essential element of a strategy aimed at sustainable development. Multi-criteria decision support provides a platform to accommodate a process of arriving at a judgment or a\u00a0\u2026", "num_citations": "4\n", "authors": ["1068"]}
{"title": "Fuzzy multi-objective decision-making models and approaches\n", "abstract": " Multi-objective linear programming (MOLP) techniques are widely used to model many organizational decision problems. Referring to the imprecision inherent in human judgments, uncertainty may be incorporated in some parameters of an established MOLP model that is also called a fuzzy MOLP (FMOLP) problem. This chapter first reviews the development of fuzzy multi-objective decision-making (FMODM) models and approaches and then proposes an effective way for an optimal solution in the FMOLP problem. By introducing an adjustable satisfactory degree \u03b1, a new concept of FMOLP and a solution transformation theorem are given in this chapter. This chapter thus develops an interactive fuzzy goal multi-objective decision-making method, which provides an interactive fashion with decision makers during their solution process and allows decision makers to give their fuzzy goals in any form of\u00a0\u2026", "num_citations": "4\n", "authors": ["1068"]}
{"title": "An effective pruning algorithm for least squares support vector machine classifier\n", "abstract": " A well-known drawback in the least squares support vector machine (LS-SVM) is that the sparseness is lost. In this study, an effective pruning algorithm is developed to deal with this problem. To avoid solving the primal set of linear equations, the bottom to the top strategy is adopted in the proposed algorithm. During the training process of the algorithm, the chunking incremental and decremental learning procedures are used alternately. A small support vector set, which can cover most of the information in the training set, can be formed adaptively. Using the support vector set, one can construct the final classifier. In order to test the validation of the proposed algorithm, it has been applied to five benchmarking UCI datasets. In order to show the relationships among the chunking size, the number of support vector machine, the training time, and the testing accuracy, different chunking sizes are tested. The experimental results show that the proposed algorithm can adaptively obtain the sparse solutions without almost losing generalization performance when the chunking size is equal to 2, and also its training speed is much faster than that of the sequential minimal optimization (SMO) algorithm. The proposed algorithm can also be applied to the least squares support vector regression machine as well as LS-SVM classifier.", "num_citations": "4\n", "authors": ["1068"]}
{"title": "A special issue on e\u2010service intelligence\n", "abstract": " Electronic-service (e-service) intelligence is a new research field that deals with fundamental roles, social impacts, and practical applications of various intelligent technologies and methodologies on Internet-based e-services. It has been recently identified as a novel direction and a next stage of e-services for current and future development.E-services involve various types, delivery systems, advanced information technologies, methodologies, and applications of online services that are provided by e-government, e-business, e-commerce, e-market, e-finance, and e-learning systems, to name a few. They thus offer great opportunities and challenges for many areas, such as government, business, commerce, marketing, finance, and education. E-service intelligence comes from real-world requirements, where many government and business organizations are nowadays developing their e-service systems with\u00a0\u2026", "num_citations": "4\n", "authors": ["1068"]}
{"title": "Information integration based team situation assessment in an uncertain environment\n", "abstract": " Understanding a situation requires integrating many pieces of information which can be obtained by a group of data collectors from multiple data sources. Uncertainty is involved in situation assessment. How to integrate multi-source multi-member uncertain information to derive situation awareness is an important issue in supporting decision making for crisis problems. The study focuses on how uncertain situation information is presented, integrated and finally how situation awareness information is derived. A multi-sources team information integration approach is developed in the study to support a team's assessment for a situation in an uncertain environment. A numerical example is then shown for illustrating the proposed approach.", "num_citations": "4\n", "authors": ["1068"]}
{"title": "Group decision making method with fuzzy preference of decision makers\n", "abstract": " A decision is often made in a group and decision makers often utilize fuzzy judgments in attempting to reach an optimal solution. In order to deal with the fuzziness of decision makers' judgments in solutions, this paper proposes a fuzzy group decision-making method for multi-objective decision problems. The method allows group members to express their fuzzy preferences for decision objectives, fuzzy judgements for solution selection rules and weights for group members. A [mal decision can be made based on a group selection matrix. This group decision-making method aggregates all group members' fuzzy opinions and judgments into the final group decision in a most acceptable degree.", "num_citations": "4\n", "authors": ["1068"]}
{"title": "A Prototype of Multi-Objective Group decision support system with a group aggregation method base\n", "abstract": " This study develops a framework of integrating multi-objective decision support systems (MODSS), expert systems (\u00a3 S) and group decision support systems (GDSS) effectively to deal with multi-objective decisionmaking problems in a group under knowledge-based intelligent guide. The three dimensions, MODSS,\u00a3 S, GDSS, are combined to overcome the limitations of each basic system and maximally enhance the competence of the integrated system. As part of this study, this paper proposes a two-level multi-objective based group decision systems framework andfive group aggregation methods. A group subsystem is then developed to include thefive aggregation methods in a method base. This makes the exploration of group satisfactory solution more flexible and effective.", "num_citations": "4\n", "authors": ["1068"]}
{"title": "Profiling COVID-19 Genetic Research: A Data-Driven Study Utilizing Intelligent Bibliometrics\n", "abstract": " The COVID-19 pandemic constitutes an ongoing worldwide threat to human society and has caused massive impacts on global public health, the economy and the political landscape. The key to gaining control of the disease lies in understanding the genetics of SARS-CoV-2 and the disease spectrum that follows infection. This study leverages traditional and intelligent bibliometric methods to conduct a multi-dimensional analysis on 5,632 COVID-19 genetic research papers, revealing that 1) the key players in the field include research institutions from the US, China, Britain and Canada; 2) research topics in this field predominantly focus on virus infection mechanisms, virus testing, gene expression related to the immune reactions and patient clinical manifestation; 3) studies in this field originated from the comparison of SARS-CoV-2 to previous human coronaviruses, following which research directions diverge into the analysis of virus molecular structure and genetics, the human immune response, vaccine development and gene expression related to immune responses; 4) genes that are frequently highlighted include ACE2, IL6, TMPRSS2, and TNF. Emerging genes in this field consist of FURIN, CXCL10, OAS1, OAS2, OAS3, ISG15. This study demonstrates that our suite of novel bibliometric tools could help biomedical researchers follow this rapidly growing field and provide substantial evidence for policymakers\u2019 decision-making on research policies.", "num_citations": "3\n", "authors": ["1068"]}
{"title": "Multi-Source Contribution Learning for Domain Adaptation\n", "abstract": " Transfer learning becomes an attractive technology to tackle a task from a target domain by leveraging previously acquired knowledge from a similar domain (source domain). Many existing transfer learning methods focus on learning one discriminator with single-source domain. Sometimes, knowledge from single-source domain might not be enough for predicting the target task. Thus, multiple source domains carrying richer transferable information are considered to complete the target task. Although there are some previous studies dealing with multi-source domain adaptation, these methods commonly combine source predictions by averaging source performances. Different source domains contain different transferable information; they may contribute differently to a target domain compared with each other. Hence, the source contribution should be taken into account when predicting a target task. In this article\u00a0\u2026", "num_citations": "3\n", "authors": ["1068"]}
{"title": "A cross-domain recommender system through information transfer for medical diagnosis\n", "abstract": " The electronic diagnostic records of patients, primarily collected by hospitals, comprise valuable data for the development of recommender systems to support physicians in predicting the risks associated with various diseases. For some diseases, the diagnostic record data are not sufficient to train a prediction model to generate recommendations; this is referred to as the data sparsity problem. Cross-domain recommender systems offer a solution to this problem by transferring knowledge from a similar domain (source domain) with sufficient data for modeling to facilitate prediction in the current domain (target domain). However, building a cross-domain recommender system for medical diagnosis presents two challenges: (1) uncertain representations, such as the symptoms characterized by interval numbers, are often used in medical records, and (2) given two different diseases, the feature spaces of the two\u00a0\u2026", "num_citations": "3\n", "authors": ["1068"]}
{"title": "PAC-Bayes Bounds for Meta-learning with Data-Dependent Prior\n", "abstract": " By leveraging experience from previous tasks, meta-learning algorithms can achieve effective fast adaptation ability when encountering new tasks. However it is unclear how the generalization property applies to new tasks. Probably approximately correct (PAC) Bayes bound theory provides a theoretical framework to analyze the generalization performance for meta-learning. We derive three novel generalisation error bounds for meta-learning based on PAC-Bayes relative entropy bound. Furthermore, using the empirical risk minimization (ERM) method, a PAC-Bayes bound for meta-learning with data-dependent prior is developed. Experiments illustrate that the proposed three PAC-Bayes bounds for meta-learning guarantee a competitive generalization performance guarantee, and the extended PAC-Bayes bound with data-dependent prior can achieve rapid convergence ability.", "num_citations": "3\n", "authors": ["1068"]}
{"title": "Bayesian Nonparametric Unsupervised Concept Drift Detection for Data Stream Mining\n", "abstract": " Online data stream mining is of great significance in practice because of its ubiquity in many real-world scenarios, especially in the big data era. Traditional data mining algorithms cannot be directly applied to data streams due to (1) the possible change of underlying data distribution over time (i.e., concept drift) and (2) delayed, short, or even no labels for streaming data in practice. A new research area, named unsupervised concept drift detection, has emerged to tackle this difficulty mainly based on two-sample hypothesis tests, such as the Kolmogorov\u2013Smirnov test. However, it is surprising that none of the existing methods in this area exploit the Bayesian nonparametric hypothesis test, which has clear interpretability and straightforward prior knowledge encoding ability and no strict or unrealistic requirement of prefixing the form for the underlying data distribution. In this article, we present a Bayesian\u00a0\u2026", "num_citations": "3\n", "authors": ["1068"]}
{"title": "Recommender Systems: Advanced Developments\n", "abstract": " Recommender systems provide users (businesses or individuals) with personalized online recommendations of products or information, to address the problem of information overload and improve personalized services. Recent successful applications of recommender systems are providing solutions to transform online services for e-government, e-business, e-commerce, e-shopping, e-library, e-learning, e-tourism, and more. This unique compendium not only describes theoretical research but also reports on new application developments, prototypes, and real-world case studies of recommender systems. The comprehensive volume provides readers with a timely snapshot of how new recommendation methods and algorithms can overcome challenging issues. Furthermore, the monograph systematically presents three dimensions of recommender systems\u2014basic recommender system concepts, advanced recommender system methods, and real-world recommender system applications. By providing state-of-the-art knowledge, this excellent reference text will immensely benefit researchers, managers, and professionals in business, government, and education to understand the concepts, methods, algorithms and application developments in recommender systems.", "num_citations": "3\n", "authors": ["1068"]}
{"title": "Cross-Domain Recommendation with Multiple Sources\n", "abstract": " Data sparsity remains a challenging and common problem in real-world recommender systems, which impairs the accuracy of recommendation thus damages user experience. Cross-domain recommender systems are developed to deal with data sparsity problem through transferring knowledge from a source domain with relatively abundant data to the target domain with insufficient data. However, two challenging issues exist in cross-domain recommender systems: 1) domain shift which makes the knowledge from source domain inconsistent with that in the target domain; 2) knowledge extracted from only one source domain is insufficient, while knowledge is potentially available in many other source domains. To handle the above issues, we develop a cross-domain recommendation method in this paper to extract group-level knowledge from multiple source domains to improve recommendation in a sparse target\u00a0\u2026", "num_citations": "3\n", "authors": ["1068"]}
{"title": "Cross-domain recommendation with consistent knowledge transfer by subspace alignment\n", "abstract": " Recommender systems have drawn great attention from both academic area and practical websites. One challenging and common problem in many recommendation methods is data sparsity, due to the limited number of observed user interaction with the products/services. Cross-domain recommender systems are developed to tackle this problem through transferring knowledge from a source domain with relatively abundant data to the target domain with scarce data. Existing cross-domain recommendation methods assume that similar user groups have similar tastes on similar item groups but ignore the divergence between the source and target domains, resulting in decrease in accuracy. In this paper, we propose a cross-domain recommendation method transferring consistent group-level knowledge through aligning the source subspace with the target one. Through subspace alignment, the\u00a0\u2026", "num_citations": "3\n", "authors": ["1068"]}
{"title": "Decision Support Systems with Uncertainties in Big Data Environments\n", "abstract": " In a Big Data environment, organizations and individuals benefit from increased prediction accuracy and real-time data analysis results. Currently, Big Data continues to increase in complexity, particularly in respect of the uncertainty of the environments in which decisions are made, and many business decisions need to be made under a range of data uncertainties, eg, ambiguous data or unlabelled data. This issue results in the business decision-making process itself becoming more dynamic, since big data distributions change over time, and the change is irreducible. Decision-makers must react quickly to insights to take full advantage of such dynamic data environments. More importantly, many organizational decisions need to be made across multiple dimensions, multiple data sources and/or multiple data types, such as text data or image data, and sometimes in time-critical situations. The increasing\u00a0\u2026", "num_citations": "3\n", "authors": ["1068"]}
{"title": "First-order causal process for causal modelling with instantaneous and cross-temporal relations\n", "abstract": " Motivated by the real damped simple harmonic oscillator (SHO) system, in this paper, we propose a process interpretation of causality and the first-order causal process (FoCP) model for temporal causal modelling. Compared with existing causal models that are able to model feedbacks, such as the structural equation model (SEM) and the structure vector autoregressive (SVAR) model, the FoCP model entails a novel 2-stage evolution semantic for instantaneous and cross-temporal causal relations existing in many real world dynamic systems. Graphical representations are developed to illustrate the causal structure compactly. Useful properties of the new model are identified and used to develop a conditional independence based algorithm for learning the causal structure from a multivariate time series dataset. Experiments on both simulated and real data validate the feasibility of the method to discover simple\u00a0\u2026", "num_citations": "3\n", "authors": ["1068"]}
{"title": "Heterogeneous transfer learning: An unsupervised approach\n", "abstract": " Transfer learning leverages the knowledge in one domain\u2013the source domain\u2013to improve learning efficiency in another domain\u2013the target domain. Existing transfer learning research is relatively well-progressed, but only in situations where the feature spaces of the domains are homogeneous and the target domain contains at least a few labeled instances. However, transfer learning has not been well-studied in heterogeneous settings with an unlabeled target domain. To contribute to the research in this emerging field, this paper presents:(1) an unsupervised knowledge transfer theorem that prevents negative transfer; and (2) a principal angle-based metric to measure the distance between two pairs of domains. The metric shows the extent to which homogeneous representations have preserved the information in original source and target domains. The unsupervised knowledge transfer theorem sets out the transfer conditions necessary to prevent negative transfer. Linear monotonic maps meet the transfer conditions of the theorem and, hence, are used to construct homogeneous representations of the heterogeneous domains, which in principle prevents negative transfer. The metric and the theorem have been implemented in an innovative transfer model, called a Grassmann-LMM-geodesic flow kernel (GLG), that is specifically designed for knowledge transfer across heterogeneous domains. The GLG model learns homogeneous representations of heterogeneous domains by minimizing the proposed metric. Knowledge is transferred through these learned representations via a geodesic flow kernel. Notably, the theorem presented in this\u00a0\u2026", "num_citations": "3\n", "authors": ["1068"]}
{"title": "A motor imagery based brain-computer interface system via swarm-optimized fuzzy integral and its application\n", "abstract": " A brain-computer interface (BCI) system provides a convenient means of communication between the human brain and a computer, which is applied not only to healthy people but also for people that suffer from motor neuron diseases (MNDs). Motor imagery (MI) is one well-known basis for designing Electroencephalography (EEG)-based real-life BCI systems. However, EEG signals are often contaminated with severe noise and various uncertainties, imprecise and incomplete information streams. Therefore, this study proposes spectrum ensemble based on swam-optimized fuzzy integral for integrating decisions from sub-band classifiers that are established by a sub-band common spatial pattern (SBCSP) method. Firstly, the SBCSP effectively extracts features from EEG signals, and thereby the multiple linear discriminant analysis (MLDA) is employed during a MI classification task. Subsequently, particle swarm\u00a0\u2026", "num_citations": "3\n", "authors": ["1068"]}
{"title": "Uncertainty Modelling In Knowledge Engineering And Decision Making-Proceedings Of The 12th International Flins Conference (Flins 2016)\n", "abstract": " FLINS, originally an acronym for Fuzzy Logic and Intelligent Technologies in Nuclear Science, is now extended to include Computational Intelligence for applied research. The contributions to the 12th of FLINS conference cover state-of-the-art research, development, and technology for computational intelligence systems, both from the foundations and the applications points-of-view.", "num_citations": "3\n", "authors": ["1068"]}
{"title": "Multiple science data-oriented Technology Roadmapping method\n", "abstract": " Since its first engagement with industry decades ago, Technology Roadmapping (TRM) is taking a more and more important role for technical intelligence in current R&D planning and innovation tracking. Important topics for both science policy and engineering management researchers involves with the approaches that refer to the real-world problems, explore value-added information from the complex data sets, fuse the analytic results and expert knowledge effectively and reasonable, and demonstrate to the decision makers visually and understandable. Moreover, the growing variety of science data sources in the Big Data Age increases these challenges and opportunities. Addressing these concerns, this paper proposes a TRM composing method with a clustering-based topic identification model, a multiple science data sources integration model, and a semi-automated fuzzy set-based TRM composing model\u00a0\u2026", "num_citations": "3\n", "authors": ["1068"]}
{"title": "Hybridizing social filtering for recommender systems\n", "abstract": " Users send requests to recommender systems for getting suggested products or services. Collaborative filtering is a popular technique for making such suggestions efficiently, but it suffers from a drawback known as \u201ccold-start\u201d problem. Social filtering may succeed for such users, since it utilize the extra social relations of users. It gives us opportunities to eliminate the limitations by hybridizing social filtering into traditional collaborative filtering. To handle this issue, differing from previous fusion models that only combine the final results, this paper proposed a new neighborhood fusion model to make hybridization at an earlier and deeper stage. Experiment-based comparative analyses are also conducted. The results show that our model is of a higher recommendation quality, on different datasets.", "num_citations": "3\n", "authors": ["1068"]}
{"title": "A unique case of Chinese language and music dissociation with tumor located in Broca's area: multimodal mapping for tumor resection and functional preservation.\n", "abstract": " A unique case of Chinese language and music dissociation with tumor located in Broca's area: multimodal mapping for tumor resection and functional preservation. - Abstract - Europe PMC Sign in or create an account https://orcid.org Europe PMC Menu About About Europe PMC Preprints in Europe PMC Funders Joining Europe PMC Governance Roadmap Outreach Tools Tools overview ORCID article claiming Journal list Grant finder External links service RSS feeds Annotations Annotations submission service Developers Developer resources Articles RESTful API Grants RESTful API API use cases SOAP web service Annotations API OAI service Bulk downloads Developers Forum Help Help using Europe PMC Search syntax reference Contact us Contact us Helpdesk Feedback Twitter Blog Tech blog Developer Forum Europe PMC plus Search worldwide, life-sciences literature Search Advanced Search Recent \u2026", "num_citations": "3\n", "authors": ["1068"]}
{"title": "Publications\n", "abstract": " 2. Kabak, \u00d6., Ruan, D.: A cumulative belief degree-based approach for missing values in nuclear safeguards evaluation. IEEE Transactions on Knowledge and Data Engineering (2011)(accepted, in press) 3. He, XX, Xu, Y., Liu, J., Ruan, D.: \u03b1-Lock resolution method for lattice-valued logic based on lattice implication algebra. Engineering Applications of Artificial Intelligence (accepted, in press)(2011) 4. He, XX, Liu, J., Xu, Y., Mart\u00ednez, L., Ruan, D.: On \u03b1-satisfiability and its \u03b1-Lock resolution in a finite lattice-valued logic. Logic Journal of the IGPL (2011), doi: 10.1093/jigpal/JZR007", "num_citations": "3\n", "authors": ["1068"]}
{"title": "Semantic de-biased associations (SDA) model to improve ill-structured decision support\n", "abstract": " Decision makers are subject to rely upon their biased mental models to solve ill-structured decision problems. While mental models prove to be very helpful in understanding and solving ill-structured problems, the inherent biases often lead to poor decision making. This study deals with the issue of biases by proposing Semantic De-biased Associations (SDA) model. SDA model assists user to make more informed decisions by providing de-biased, and validated domain knowledge. It employs techniques to mitigate biases from mental models; and incorporates semantics to automate the integration of mental models. The effectiveness of SDA model in solving ill-structured decision problems is illustrated in this paper through a case study.", "num_citations": "3\n", "authors": ["1068"]}
{"title": "A seasonal auto-regressive model based support vector regression prediction method for H5N1 avian influenza animal events\n", "abstract": " The time series prediction of avian influenza epidemics is a complex issue, because avian influenza has latent seasonality which is difficult to identify. Although researchers have applied a neural network (NN) model and the Box-Jenkins model for the seasonal epidemic series research area, the results are limited. In this study, we develop a new prediction seasonal auto-regressive-based support vector regression (SAR-SVR) model which combines the seasonal auto-regressive (SAR) model with a support vector regression (SVR) model to address this prediction problem to overcome existing limitations. Fast Fourier transformation is also merged into this method to identify the latent seasonality inside the time series. The experiments demonstrate that the developed SAR-SVR method out-performs SVR, Box-Jenkins models and two layer feed forward NN model-both in accuracy and stability in the avian influenza\u00a0\u2026", "num_citations": "3\n", "authors": ["1068"]}
{"title": "Lifeevent ontology oriented e-government service integration\n", "abstract": " From e-government integration viewpoint, LifeEvent is a collection of actions including at least one public service, which executed in its designated workflow to fulfil request of a citizen arising from a new real-life situation. The purpose of this study is to provide technical guidelines for extending Ontology Web Language for Services (OWL-S), which can provide technical support for LifeEvent Ontology Oriented Service Integration within the e-government domain. This study suggests a framework based on ontological analysis and modelling. Proposed framework is based on the extensive use of LifeEvent concept to achieve dynamically configured automated delivery of integrated e-government services. This paper proposes the LifeEvent Ontology that is a logical extension of OWL-S for implementation of E-Service Integration Modelling framework proposed in prior research.", "num_citations": "3\n", "authors": ["1068"]}
{"title": "Towards semantic-aware and ontology-based e-government service integration\u2013An applicative case study of Saudi Arabia\u2019s King Abdullah Scholarship Program\n", "abstract": " By improving the quality of e-government services by enabling access to services across different government agencies through one portal, services integration plays a key role in e-government development. This paper proposes a conceptual framework of ontology based e-government service integration, using Saudi Arabia\u2019s King Abdullah Scholarship Program (SAKASP) as a case study. SAKASP is a multi-domain program in which students must collect information from various Ministries to complete applications and the administering authority must verify the information supplied by the Ministries. The current implementation of SAKASP is clumsy because it is a mixture of online submission and manual collection and verification of information; its time-consuming and tedious procedures are inconvenient for the applicants and inefficient for the administrators. The proposed framework provides an\u00a0\u2026", "num_citations": "3\n", "authors": ["1068"]}
{"title": "A fuzzy bi-level pricing model and a PSO based algorithm in supply chains\n", "abstract": " Due to rapid technological innovation and severe competition, the upstream component price and the downstream product cost in hi-tech industries usually decline significantly with time. In building a pricing supply chain model, some coefficients are generally obtained from experiments and cannot be defined as crisp numbers. Thus, an effective fuzzy pricing supply chain model becomes crucial. This paper establishes a fuzzy bi-level pricing model for buyers and vendors in supply chains. Then, a particle swarm optimization (PSO) based algorithm is developed to solve problems defined by this model. Experiments show that this PSO-based algorithm can solve fuzzy bi-level pricing problems effectively.", "num_citations": "3\n", "authors": ["1068"]}
{"title": "Impute Missing Assessments by Opinion Clustering in Multi-Criteria Group Decision Making Problems.\n", "abstract": " Multi-criteria group decision-making and evaluation (MCGDME) method typically aggregates information in evaluation tables. For various reasons, evaluation tables (decision matrix) often include missing data that highly affect correct decision-making and evaluation. Most existing imputation methods of missing data are based on statistical features which do not exist in an MCGDME setting. This paper proposes an imputation method of missing data (IMD) in evaluation tables. The IMD method measures the similarity betweent two evaluators\u2019 mental models. Evaluators are then classed into several groups based on their similarities by using fuzzy clustering methods. Finally, missing data are imputated under the assumption that the imputated value of missing data does not change the previous clustering results. The proposed IMD method is implemented and tested in two numerical experiments.", "num_citations": "3\n", "authors": ["1068"]}
{"title": "Fuzzy set techniques in e-Service applications\n", "abstract": " E-services involve various types, delivery systems, advanced information technologies, methodologies and applications of online services that are provided by e-government, e-business, e-commerce, e-market, e-finance, e-learning systems, to name a few. They offer great opportunities and challenges for many areas, such as government, business, commerce, marketing, finance and education. E-service intelligence is a new research field that deals with fundamental roles, social impacts and practical applications of various intelligent technologies on the Internet based e-services. This chapter aims to offer a thorough introduction and systematic overview of the new field e-service intelligence mainly based on fuzzy set related techniques. It covers the state-of-the-art of the research and development in various aspects including both theorems and applications, of e-service intelligence by applying fuzzy set\u00a0\u2026", "num_citations": "3\n", "authors": ["1068"]}
{"title": "E-service Intelligence: Methodology, Technologies and Applications\n", "abstract": " Business organizations and governments are nowadays developing and providing internet based electronic services (e-services) featuring various intelligent functions. E-Service Intelligence integrates intelligent techniques into e-service systems for realizing intelligent internet information searching, presentation, provision, recommendation, online system design, implementation, and assessment to internet users. This book offers a thorough introduction and systematic overview of the new field and covers the state-of-the-art of the research and development in E-Service Intelligence ranging from e-services and/or intelligent techniques to web information presentation, search, and mining, to personalization, privacy, and trust in e-services, to e-service evaluation, optimization and knowledge discovery, and to intelligent e-service system developments.", "num_citations": "3\n", "authors": ["1068"]}
{"title": "Customer online shopping behaviours analysis using Bayesian networks\n", "abstract": " This study applies Bayesian network technique to analyse the relationships among customer online shopping behaviours and customer requirements. This study first proposes an initial behaviour-requirement relationship model as domain knowledge. Through conducting a survey customer data is collected as evidences for inference of the relationships among the factors described in the model. After creating a graphical structure, this study calculates conditional probability distribution among these factors, and then conducts inference by using the Junction-tree algorithm. A set of useful findings has been obtained for customer online shopping behaviours and their requirements with motivations. These findings have potential to help businesses adopting more suitable online system development.", "num_citations": "3\n", "authors": ["1068"]}
{"title": "A fast data preprocessing procedure for support vector regression\n", "abstract": " A fast data preprocessing procedure (FDPP) for support vector regression (SVR) is proposed in this paper. In the presented method, the dataset is firstly divided into several subsets and then K-means clustering is implemented in each subset. The clusters are classified by their group size. The centroids with small group size are eliminated and the rest centroids are used for SVR training. The relationships between the group sizes and the noisy clusters are discussed and simulations are also given. Results show that FDPP cleans most of the noises, preserves the useful statistical information and reduces the training samples. Most importantly, FDPP runs very fast and maintains the good regression performance of SVR.", "num_citations": "3\n", "authors": ["1068"]}
{"title": "A decision support system for multiple objective linear programming\n", "abstract": " A new approximate algorithm has been developed by Wu et al. for solving fuzzy multiple objective linear programming (FMOLP) problems with fuzzy parameters in any form of membership function in both objective functions and constraints. Based on the approximate algorithm, a fuzzy multiple objective decision support system (FMODSS) is developed. We focus on the description of use for FMODSS in detail, and an example is presented for demonstrating how to solve a FMOLP problem by the FMODSS.", "num_citations": "3\n", "authors": ["1068"]}
{"title": "Development, distribution and classification of online tourism services in China\n", "abstract": " The internet has introduced new, virtual market spaces in addition o the traditional physical tourism market spaces. Tourism organizations are moving more and more products and services online. More and more customers are getting destination information and booking accommodation by accessing the Internet. China, as a developing country, is developing its tourism E-commerce. This paper presents the current development and distribution of online tourism services in China. This paper also proposes who classifications and function distribution for tourism website development in China. Finally, this paper analyses main barriers and challenges to develop online tourism service in China.", "num_citations": "3\n", "authors": ["1068"]}
{"title": "Bi-layer network analytics: A methodology for characterizing emerging general-purpose technologies\n", "abstract": " Despite the tremendous contributions bibliometrics has made to profiling technological landscapes and identifying emerging topics, reliable methods for predicting potential technological changes are still elusive. To fill this gap, we propose a methodology based on bi-layer network analytics that characterizes emerging general-purpose technologies. The framework incorporates three novel indicators that quantify a technology\u2019s technical potential and social impacts, not just in one specific technological area but in a wide range of domains. Missing links in the network are extrapolated through a refined link prediction method, and a weighted resource allocation index ranks both current technologies and their predicted evolutions to reveal candidate innovations for further empirical and/or expert analysis. A case study on information science incorporating quanlitative and qualitative validations demonstrates the methodology to be feasible and reliable. Researchers and policymakers in information science and bibliometrics should find valuable decision support from the empirical insights presented.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Least squares support vector machines with fast leave-one-out AUC optimization on imbalanced prostate cancer data\n", "abstract": " Quite often, the available pre-biopsy data for early prostate cancer detection are imbalanced. When the least squares support vector machines (LS-SVMs) are applied to such scenarios, it becomes naturally desirable for us to introduce the well-known AUC performance index into the LS-SVMs framework to avoid bias towards majority classes. However, this may result in high computational complexity for the minimal leave-one-out error. In this paper, by introducing the parameter , a generalized Area under the ROC curve (AUC) performance index  is developed to theoretically guarantee that  linearly depends on the classical AUC performance index . Based on both  and the classical LS-SVM, a new AUC-based least squares support vector machine called AUC-LS-SVMs is proposed for directly and effectively classifying imbalanced prostate cancer data. The distinctive advantage of the\u00a0\u2026", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Multi-Source Domain Adaptation with Distribution Fusion and Relationship Extraction\n", "abstract": " Transfer learning is gaining increasing attention due to its ability to leverage previously acquired knowledge to assist in completing a prediction task in a similar domain. While many existing transfer learning methods deal with single source and single target problem without considering the fact that a target domain maybe similar to multiple source domains, this work proposes a multi-source domain adaptation method based on a deep neural network. Our method contains common feature extraction, specific predictor learning and target predictor estimation. Common feature extraction explores the relationship between source domains and target domain by distribution fusion and guarantees the strength of similar source domains during training, something which has not been well considered in existing works. Specific predictor learning trains source tasks with cross-domain distribution constraint and cross-domain\u00a0\u2026", "num_citations": "2\n", "authors": ["1068"]}
{"title": "A Fuzzy Drift Correlation Matrix for Multiple Data Stream Regression\n", "abstract": " How to handle concept drift problem is a big challenge for algorithms designed for the data streams. Currently, techniques related to the concept drift problem focus on single data stream. However, it normally needs to handle multiple relevant data streams in the real-world application. Current concept drift methods can not be directly used in the multistream setting. They can only be limitedly applied on each stream separately, which omits the drift correlation between streams. In the multi-stream scenario, when drift occurs in a stream, other streams may face or have faced a similar drift problem as well. This pattern of simultaneous or delayed occurrence of drift is critical to analyze and predict multiple streams as a whole dynamic system. To fill the gap in the multi-stream scenario, this paper proposes a fuzzy drift variance (FDV) to measure the correlated drift patterns among streams. FDA is able to present how the\u00a0\u2026", "num_citations": "2\n", "authors": ["1068"]}
{"title": "A Novel Non-parametric Two-Sample Test on Imprecise Observations\n", "abstract": " In kernel non-parametric two-sample test, we aim to determine whether two sets of precise observations (i.e., samples) are from the same distribution based on a selected kernel. However, in real world, precise observations may be unavailable. For example, readings on an analogue measurement equipment are not precise numbers but intervals since there is only a finite number of decimals available. Hence, we consider a new and more realistic problem setting-two-sample test on imprecise observations. We show that the test power of existing kernel two- sample tests will drop significantly if they do not take care of the vagueness of the imprecise observations, and to this end, we propose a fuzzy-based maximum mean discrepancy (F-MMD), a powerful two-sample test on imprecise observations. F-MMD is based on a novel fuzzy-based kernel function that can measure the discrepancy between two imprecise\u00a0\u2026", "num_citations": "2\n", "authors": ["1068"]}
{"title": "A causal dirichlet mixture model for causal inference from observational data\n", "abstract": " Estimating causal effects by making causal inferences from observational data is common practice in scientific studies, business decision-making, and daily life. In today\u2019s data-driven world, causal inference has become a key part of the evaluation process for many purposes, such as examining the effects of medicine or the impact of an economic policy on society. However, although the literature contains some excellent models, there is room to improve their representation power and their ability to capture complex relationships. For these reasons, we propose a novel prior called Causal DP and a model called CDP. The prior captures the complex relationships between covariates, treatments, and outcomes in observational data using a rational probabilistic dependency structure. The model is Bayesian, nonparametric, and generative and is not based on the assumption of any parametric distribution. CDP is\u00a0\u2026", "num_citations": "2\n", "authors": ["1068"]}
{"title": "A choquet fuzzy integral vertical bagging classifier for mobile telematics data analysis\n", "abstract": " Mobile app development in recent years has resulted in new products and features to improve human life. Mobile telematics is one such development that encompasses multidisciplinary fields for transportation safety. The application of mobile telematics has been explored in many areas, such as insurance and road safety. However, to the best of our knowledge, its application in gender detection has not been explored. This paper proposes a Choquet fuzzy integral vertical bagging classifier that detects gender through mobile telematics. In this model, different random forest classifiers are trained by randomly generated features with rough set theory, and the top three classifiers are fused using the Choquet fuzzy integral. The model is implemented and evaluated on a real dataset. The empirical results indicate that the Choquet fuzzy integral vertical bagging classifier outperforms other classifiers.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "A Continuous-Time Recurrent Neural Network for Sparse Signal Reconstruction Via \u21131 Minimization\n", "abstract": " This paper presents a neurodynamic model for solving \u2113 1  minimization problems for sparse signal reconstruction. The essence of the proposed approach lies in its capability to operate in continuous time, which enables it to outperform most existing iterative \u2113 1 -solvers in dynamic environments. The model is described by a goal-seeking recurrent neural network and it evolves according to its deterministic neurodynamics. It is proved that the model globally converges to the optimal solution to the \u2113 1 -minimization problem under study. The connection weights of the neural network model are determined by using subgradient projection methods and the activation function is designed based on subdifferential. Due to its simple structure, the hardware implementation of this neurodynamic model is viable and cost-effective, which sheds light on real-time sparse signal recovery via large scale \u2113 1  minimization formulations.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Semi-supervised transfer learning in Takagi-Sugeno fuzzy models\n", "abstract": " Transfer learning aims to leverage knowledge acquired from a related domain (called source domain) to improve the efficiency of completing a prediction task in the current domain (called target domain) which has different probability distribution from the source domain. Although transfer learning has been widely studied, most existing research on transfer learning has focused on classification tasks. This paper presents a fuzzy rule-based method that explores the information in the target domain to assist the regression tasks in transfer learning process.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Causal inference with Gaussian processes for support of terminating or maintaining an existing program\n", "abstract": " Decision makers often face a problem to decide to maintain or terminate an existing program with only observational data available. Within the potential outcomes framework, we show the problem could be modelled as a causal inference problem to estimate the conditional average treatment effect of the treatment on the treated (CATT). In this paper, we propose a model with separate Gaussian processes to estimate average treatment effect for the treated group and the control group. We conduct experiments on an empirical case and show that our method could contribute to decision making in the kind of problem described above.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Guest editorial special section on fuzzy systems in data science\n", "abstract": " The papers in this special section address the use of fuzzy systems in data science. Fuzzy Systems in Data Science data science employs theories and techniques drawn from many fields to achieve knowledge extraction from large volumes of data. To facilitate and automate the achievement of useful insights, predictions, and decisions from collected data sets, scientists and engineers turned to Machine Learning solutions. Currently, with the birth of Big Data, the set of opportunities for inquiry has grown exponentially, thanks to these large and complex data sets. Being able to exploit this massive data effectively provides useful knowledge for decision-making or the exploration and comprehension of the phenomenon that produced the data. Data science includes several problems and tasks depending on the nature of the data and the type of knowledge that is to be extracted. From predictive and descriptive analysis\u00a0\u2026", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Fuzzy rule-based transfer learning for label space adaptation\n", "abstract": " As the age of big data approaches, methods of massive scale data management are rapidly evolving. The traditional machine learning methods can no longer satisfy the exponential development of big data; there is a common assumption in these data-driving methods that the distribution of both the training data and testing data should be equivalent. A model built using today's data will not adequately address the classification tasks tomorrow if the distribution of the data item values has changed. Transfer learning is emerging as a solution to this issue, and many methods have been proposed. Few of the existing methods, however, explicitly indicate the solution to the case where the labels' distributions in two domains are different. This work proposes the fuzzy rule-based methods to deal with transfer learning problems where the discrepancy between the two domains shows in the label spaces. The presented\u00a0\u2026", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Detecting overlapping protein complexes in dynamic protein-protein interaction networks by developing a fuzzy clustering algorithm\n", "abstract": " Protein complexes play important roles in proteinprotein interaction networks. Recent studies reveal that many proteins have multiple functions and belong to more than one different complexes. To get better complex division, we need to consider time-dependent information of networks. However, only few studies can be found to concentrate on detecting overlapping clusters in time-dependent networks. To solve this problem, we propose integrated model of time-dependent network (IM-TDN) to describe time-dependent networks. On the base of this model, we propose similarity based dynamic fuzzy clustering (SDFC) algorithm to detect overlapping clusters. We apply the algorithm to synthetic data and real world protein-protein interaction network dataset. The results showed that our algorithm by using the model which we proposed achieved better results over the state-of-the-art baseline algorithms.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Scalable Inference for Nested Chinese Restaurant Process Topic Models\n", "abstract": " Nested Chinese Restaurant Process (nCRP) topic models are powerful nonparametric Bayesian methods to extract a topic hierarchy from a given text corpus, where the hierarchical structure is automatically determined by the data. Hierarchical Latent Dirichlet Allocation (hLDA) is a popular instance of nCRP topic models. However, hLDA has only been evaluated at small scale, because the existing collapsed Gibbs sampling and instantiated weight variational inference algorithms either are not scalable or sacrifice inference quality with mean-field assumptions. Moreover, an efficient distributed implementation of the data structures, such as dynamically growing count matrices and trees, is challenging. In this paper, we propose a novel partially collapsed Gibbs sampling (PCGS) algorithm, which combines the advantages of collapsed and instantiated weight algorithms to achieve good scalability as well as high model quality. An initialization strategy is presented to further improve the model quality. Finally, we propose an efficient distributed implementation of PCGS through vectorization, pre-processing, and a careful design of the concurrent data structures and communication strategy. Empirical studies show that our algorithm is 111 times more efficient than the previous open-source implementation for hLDA, with comparable or even better model quality. Our distributed implementation can extract 1,722 topics from a 131-million-document corpus with 28 billion tokens, which is 4-5 orders of magnitude larger than the previous largest corpus, with 50 machines in 7 hours.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "A fast load pattern extraction approach based on dimension reduction and sampling\n", "abstract": " This paper proposes a fast load pattern extraction approach to solve the time consuming problem in using a traditional k-means clustering method for large volumes of load curves. The approach, based on dimension reduction and sampling, segments and averages sampling characteristic points to reduce the load curve's dimensions, then reduces the overall size of the sample data set using representative random sampling. K-means clustering algorithm is used to extract load patterns from the representative data set, which will be used to classify the full data set. Reducing the size and dimension of the data set allows use of a less complex algorithm, and thus greatly improves the clustering speed. The validity of the approach is proven by experiments designed to evaluate the trade-off between complexity and consistency.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Sensitivity Level-Based Citizen Personal Information Model for Privacy Protection.\n", "abstract": " Citizens\u2019 privacy concerns have become a major barrier to their acceptance of e-government services, and the question of how to address these privacy issues effectively is increasingly important as government pushes service delivery online. Good protection of citizens\u2019 privacy will contribute significantly to the success of e-government services. Therefore, it is highly desirable to take into account privacy issues in e-government service integration to ensure the success of e-government services. On the one hand, there are many challenges in addressing the privacy issues in e-government service integration because users\u2019 personal information is often required for consuming e-government services and can potentially be accessed by different types of users (citizens and employees) at various government agencies. In addition, many aspects should be addressed in designing a privacy model. Several solutions have been recently proposed in the literature to deal with privacy concerns. However, there are few practical approaches for helping citizens to create their preferences for privacy protection. Ontology is considered one of the most powerful conceptual approaches to capture knowledge relevant to privacy aspects. Though ontologies for privacy have been suggested, they do not support citizens in setting up their privacy preferences based on various aspects of privacy policy, such as purpose, retention and consent. This paper proposes a new Sensitivity Level-Based Citizen Personal Information Model (SLBCPIM) that can facilitate citizens\u2019 role in controlling privacy preferences. This model organises the personal data item of a citizen into a\u00a0\u2026", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Bi-level multi-follower decision making\n", "abstract": " A bi-level decision problem may involve multiple decision entities (decision units or decision makers) at the lower level, and these followers may have different reactions for a possible decision made by the leader.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Improving Group Recommendations by Identifying Homogenous Subgroups\n", "abstract": " Recommender systems have proven their effectiveness in supporting personalised purchasing decisions and e-service intelligence. In order to support members in user groups of recommender systems, recently designed group recommender systems search for data relevant to all group members and discover the agreements between members of online communities. This paper focuses on achieving common satisfaction for groups or communities by, e.g. finding a restaurant for a family or shoes for a group of cheerleaders. It establishes an algorithm, called I-GRS, to devise group recommender systems based on incremental model-based collaborative filtering and applying the Mahalanobis distance and fuzzy membership to create groups of users with similar interests. Finally, an algorithm and related design strategy to build group recommender systems is proposed. A set of experiments is set up to\u00a0\u2026", "num_citations": "2\n", "authors": ["1068"]}
{"title": "An enhanced mental model elicitation technique to improve mental model accuracy\n", "abstract": " The causal mental model representation has been used extensively in decision support. Due to limited information requirements of this representation, that is concepts and relationships, the users are required to articulate only the mental models, without invoking the corresponding experiential knowledge stored in associative memory. The elicitation of mental models without being endorsed by experiential knowledge may lead to inaccurate, invalidated or biased mental models, and espoused theories, being stored for decision making. We introduce SDA articulation/ elicitation cycle, which invokes a user\u2019s associative memory during the articulation/elicitation process to validate mental models. It is argued in this paper that by engaging associative memory during the mental model articulation/elicitation process, the accuracy and validity of mental models can be improved, the biases can be reduced, and the\u00a0\u2026", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Denotational mathematical models of an air traffic control system (ATCS-II): Process models of functions in RTPA\n", "abstract": " An Air Traffic Control System (ATCS) is a highly complex, real-time, and mission-critical system in software engineering, computer engineering, mathematical engineering, and design science. A general and rigorous methodology for complex system modeling and refinement via a closed loop of analysis-synthesis is presented in denotational mathematics where the entire behaviors of a system are embodied as a synthesis of all analytic behaviors at the component level. The formal analysis-synthesis methodology is elaborated in a design paradigm of ATCS. An efficient denotational mathematics, Real-Time Process Algebra (RTPA), is adopted for modeling and refining the structures and functions of ATCS. In the analysis phase, the architectural models of ATCS are created and refined by a set of formal structure models (SMs), while the functional models of ATCS are specified and refined by a set of behavioral\u00a0\u2026", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Price forecasting using dynamic assessment of market conditions and agent\u2019s bidding behavior\n", "abstract": " Multiple online auctions need complex bidding decisions for selecting which auction to participate in, whether to place single or multiple bids, do early or late bidding and how much to bid. This paper designs a novel fuzzy dynamic bidding agent (FDBA) which uses a comprehensive method for initial price estimation and price forecasting. First, FDBA selects an auction to participate in and calculates its initial price based on clustering and bid selection approach. Then the price of the auction is forecasted based on the estimated initial price, attitude of the bidders to win the auction and the competition assessment for the late bidders using fuzzy reasoning technique. The experiments demonstrated improved price forecasting outcomes using the proposed approach.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "An extended version of the fuzzy multicriteria group decision-making method in evaluation processes\n", "abstract": " Evaluation processes are a key element used in quality inspection, marketing and other fields in industrial companies. In these processes, it is very common that a group of evaluators assess a set of evaluated elements, according to a set of criteria, which may have different nature and usually present uncertainty. In this context, the fuzzy multicriteria group decision-making (FMCGDM) method has been successfully applied to different evaluation problems. This method provides a closeness coefficient of each evaluated element in order to generate a final raking. However, its applications to complex evaluation processes that requires the understandability of the closeness coefficient drive us to propose the use of the linguistic 2-tuple representation model to extend the FMCGDM method, in order to provide linguistic closeness coefficients, which are easy to understand. Moreover, we apply the extended\u00a0\u2026", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Personalized Multidimensional Process Framework For Dynamic Risk Analysis In The Real Estate Industry\n", "abstract": " The risk analysis for real estate property investment is subject to high risk. It is qualitatively and quantitatively assessed by various techniques such as the analytical hierarchy process (AHP) and the analytic network process (ANP) which determine the risk factors based on expert survey, weight and rank the factors using algorithm and mathematical formula and decide the best investment based on performance index of the alternatives given. However, experts from the field have different opinions and judgments about the environment of the real estate industry and this scenario will affect the result of the risk factor weight and ranking. Moreover, different investors have different goals and objectives to be achieve. Thus, this paper will propose a new personalized multidimensional process (PMP) framework based on knowledge discovery. This framework comprises of two new methods namely the personalized association mapping (PAM) method and the personalized multidimensional sensitivity analysis (PM-SA) method. The innovations of this research are the justification of risk factor weight and ranking. It will be based on deterministic approach using historical data driven to decision support using knowledge discovery in database and the heuristic approach which is refers to investors personalization of the risk factors which fulfil their requirements.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "A Fuzzy Hierarchical Multiple Criteria Group Decision Support System\u2013Decider\u2013and Its Applications\n", "abstract": " Decider is a Fuzzy Hierarchical Multiple Criteria Group Decision Support System (FHMC-GDSS) designed for dealing with subjective, in particular linguistic, information and objective information simultaneously to support group decision making particularly on evaluation. In this chapter, the fuzzy aggregation decision model, functions and structure of Decider are introduced. The ideas to resolve decision and evaluation problems we have faced in the development and application of Decider are presented. Two real applications of the Decider system are briefly illustrated. Finally, we discuss our further research in this area.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Trust-based decision making in dynamic environments\n", "abstract": " Recent developments in information technology shift the computing paradigm towards greater dynamism and unpredictability, which raises new challenges. In dynamic computing environments, the relationship between transacting entities is not pre-determined, and these entities may not necessarily have previous knowledge or experience of each other. In such a context, the potential for these transacting entities to find a service peer or provider is greatly increased, but this also brings uncertainty, i.e., how does the entity know which is the best candidate among a vast number of peers. Based on our previous research work, MobiPass. This paper proposes a technique for establishing trusted interaction by certifying the information passed between transacting entities, calculating the trust value for each entity in a global perspective, then incorporating the computed trust value with other certified information by using\u00a0\u2026", "num_citations": "2\n", "authors": ["1068"]}
{"title": "A knowledge-based efficiency assessment system for distribution network using data envelopment analysis\n", "abstract": " Distribution network is the most important asset in electric utilities, to increase its efficiency, there is a need to effectively assess the efficiency of distribution network and provide solution for improvement. This paper presents a knowledge-based efficiency assessment system for distribution network using data envelopment analysis (DEA). From an input-output view, DEA method is used to calculate the efficiency of distribution lines and obtain gap information. Knowledge base is used to store facts and rules, facts include input-outputs data of DEA and other information about structure and operation of distribution lines. The rules can be empirical rules from domain expert or extracted from industry guidelines or government standards by knowledge worker. Considering the service requirements of power supply in rules, DEA assessment results can be effectively used or provided in the solution of improvement by\u00a0\u2026", "num_citations": "2\n", "authors": ["1068"]}
{"title": "A fuzzy matching based recommendation approach for mobile products/services\n", "abstract": " Due to the huge product assortments and complex descriptions of mobile products/services, it is a great challenge for new customers to select appropriate products. To solve this issue, a fuzzy matching based recommendation approach for mobile products/services is proposed in this paper. In this approach, a new customer's requirements are obtained through asking a set of questions and represented by linguistic terms. When modeling the characteristics of mobile products/services, both their attributes and related users' usage records are considered. A fuzzy matching approach is applied to find the products that are most matched to the customer's requirements. A framework of the recommender system for mobile products/services applying the proposed approach is developed.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "A bi-level pricing model and a PSO based algorithm in supply chains\n", "abstract": " Due to rapid technological innovation and severe competition, in hi-tech industries such as computers and communication, the upstream component price and the downstream product cost usually decline significantly with time. In such a background, an effective pricing supply chain model becomes crucial. This paper first establishes a bi-level pricing model for pricing problems for a buyer and a vendor in a supply chain. Then, a particle swarm optimization (PSO) based algorithm is developed to solve the problem defined by this model. Experiments illustrate that this algorithm can achieve more profits for both a buyer and a vendor compared with the existing methods.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Text information extraction and aggregation in a mobile-based emergency response system\n", "abstract": " A mobile\u2014based emergency response sys\u2014tem (MERS), as one of the important Mobile Government (m-Government) services, aims to reduce risks in an emergency situation. This paper describes an algorithm within MERS applications to automatically extract information from SMS data based on an ontology concept, a maximum entropy statistical model, and a set of fuzzy rules. The algorithm has four main functions: collect unstructured information from Short Message SerVice (SMS) emergency text message; conduct information extraction and aggregation including leXical analysis, name entity recognition, merging structure, and normalization and duplication; calculate similarity of SMS text messages; and gen~ crate query and results presentation.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Enriching executives' situation awareness and mental models: A conceptual ESS framework\n", "abstract": " Regardless of cognitive orientation of increasing importance, most executive support systems (ESS) and other decision support systems (DSSs) focus on providing behavioural support to executives' decisionmaking. In this paper, we suggest that cognitive orientation in information systems is twofold: situation awareness (SA) and mental model. A literature review of SA and mental models from different fields shows that both the two human mental constructs play very important roles in human decision-making, particularly in the naturalistic settings with time pressure, dynamics, complexity, uncertainty, and high personal stakes. Based on a discussion of application problems of present ESSs, a conceptual ESS framework on cognitive orientation is developed. Under this framework, executives' SA and mental models can be developed and enriched, which eventually increases the probability of good decision-making and good performance.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Apply support vector machine for CRM problem\n", "abstract": " Data mining in the CRM aiming at learning available knowledge from the customer relationship by machine learning or statistical method to instruct the strategic behavior so that obtain the most profit. In recent years, Support vector machine (SVMs) has been proposed as a power tool in machine leaning and data mining. This paper applies the SVMs to resolve the practical CRM problem in a company. The final results report the good general performance of SVMs for CRM problem.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Enterprise integration strategy of interoperability\n", "abstract": " Decision, analysis and design are key steps in building the skeleton of enterprise integration. We deal with the design stage by introducing the micro process and interconnectivity concept as the foundation of the service component design, this work is based on the common component concept we implemented in previous research and on the component-based design foundation", "num_citations": "2\n", "authors": ["1068"]}
{"title": "An intelligent classification method in bank customer relationship management\n", "abstract": " Customer classification is one of the major tasks in customer relationship management. Customers often have both static characteristics and dynamic behavioral features. Using both kinds of data to conduct comprehensive analysis can enhance the reasonability of customer classification. In the proposed classification method, customer dynamic data is clustered using a hybrid genetic algorithm. The result is then combined with customer static data to give reasonable customer segmentation supported by neural network technique. A bank dataset-based experiment shows that applying the proposed method can obviously improve the accuracy of customer classification comparing with the traditional methods where only static data is used.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Models and algorithms for fuzzy multi-objective multi-follower linear bilevel programming in a partial cooperative situation\n", "abstract": " Basic bilevel programming deals with hierarchical optimization problems in which the leader at the upper level attempts to optimize his/her objective, subject to a set of constraints and his/her follower's solution, and the follower at the lower level tries to find an optimized strategy according to each of possible decisions made by the leader. Three issues may be involved in a basic bilevel decision problem. One is that bilevel decision making model may involve uncertain parameters which appear either in the objective functions or constraints of the leader or the follower or both. Second, the leader and the follower may have multiple conflict objectives that should be optimized simultaneously. Third, there may have multiple followers and partial shared their decision variables among followers in a real decision situation. Following our previous work, this study proposes a set of fuzzy multi-objective Inulti-follower linear\u00a0\u2026", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Development and implementation on a fuzzy multiple objective decision support system\n", "abstract": " A fuzzy-goal optimization-based method has been developed for solving fuzzy multiple objective linear programming (FMOLP) problems where fuzzy parameters in both objective functions and constraints and fuzzy goals of objectives can be in any form of membership function. Based on the method, a fuzzy multiple objective decision support system (FMODSS) is developed. This paper focuses on the development and use of FMODSS in detail. An example is presented for demonstrating how to solve a FMOLP problem by using the FMODSS interactively.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "An fuzzy goal approximate algorithm for fuzzy multiple objective linear programming problems\n", "abstract": " Many business decision problems involve multiple objectives and can be described by multiple objective linear programming (MOLP) models, Referring to the imprecision or fuzziness inherent in human judgments, two types of inaccuracies should be incorporated in MOLP problems, One is the experts' ambiguous understanding of the nature of the parameters in the problem formulation process, and the other is the fuzzy goals of the decision maker (OM) for each of the objective functions, Consider these two fuzziness features, this paper proposes an a-fuzzy goal approximate (a-FGA) algorithm for achieving the fuzzy goals for the objective functions specified by the OM in dealing with fuzzy multiple objective linear programming (FMOLP) problems with fuzzy parameters under the different satisfactory degree a, The detail description and analysis to the algorithm are supplied,", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Experimental evaluation of an intelligent multiple objective group decision support system (IMOGDSS)\n", "abstract": " An intelligent multiple objective group decision support system (IMOGDSS) has been developed to solve multiple objective decision-making (MODM) problems in a decision group under a knowledge-based intelligent guide. In order to evaluate the effectiveness of IMOGDSS framework and the independence of the IMOGDSS for decision-makers in applications, this study designs a number of hypotheses and then organizes an experiment to test the proposed hypotheses.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "An intelligence-based multi-objective group decision support system and its application\n", "abstract": " An intelligent multiple objective group decision support system (IMOGDSS) is proposed in this research to deal with multiple objective decision making (MODM) problems in a group environment under an intelligent guidance. The paper reviews the related research areas of IMOGDSS and presents a framework of IMOGDSS. The framework consists of two decision support levels, an MODM method based and a group aggregation method based level. A prototype of IMOGDSS has been developed. The paper highlights how an IMOGDSS prototype is designed and implemented. An application for the prototype is also discussed.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "\u53d1\u5c55\u4fe1\u606f\u670d\u52a1\u4e1a\u7684\u96be\u9898\u4e0e\u5bf9\u7b56\n", "abstract": " \u6539\u9769\u5f00\u653e\u4ee5\u6765, \u6211\u56fd\u4fe1\u606f\u670d\u52a1\u4e1a\u5f00\u59cb\u8fdb\u5165\u7531\u4f20\u7edf\u4fe1\u606f\u670d\u52a1\u4e1a\u5411\u73b0\u4ee3\u4fe1\u606f\u670d\u52a1\u4e1a\u8f6c\u578b\u7684\u65b0\u9636\u6bb5, \u5e76\u53d6\u5f97\u4e86\u5f88\u5927\u6210\u5c31, \u4f46\u540c\u65f6\u4e5f\u5b58\u5728\u4ea7\u4e1a\u7ed3\u6784\u4e0d\u591f\u5408\u7406, \u7edf\u4e00\u7684\u4fe1\u606f\u5e02\u573a\u6ca1\u6709\u5f62\u6210\u4ee5\u53ca\u4ea7\u4e1a\u8c03\u63a7\u4f53\u7cfb\u5c1a\u672a\u5efa\u7acb\u7b49\u95ee\u9898. \u4e3a\u6b64, \u9700\u8981\u6211\u4eec\u7ee7\u7eed\u6df1\u5316\u4fe1\u606f\u670d\u52a1\u4e1a\u7684\u6539\u9769, \u5f3a\u5316\u5168\u6c11\u4fe1\u606f\u610f\u8bc6, \u5efa\u7acb\u5065\u5168\u4fe1\u606f\u5e02\u573a\u5236\u5ea6, \u53d1\u5c55\u4fe1\u606f\u5e02\u573a\u8425\u9500\u7cfb\u7edf, \u589e\u52a0\u4fe1\u606f\u670d\u52a1\u4e1a\u6295\u5165, \u4ee5\u4fbf\u52a0\u5feb\u4fe1\u606f\u670d\u52a1\u4e1a\u7684\u53d1\u5c55\u901f\u5ea6. \u672c\u6587\u9996\u5148\u6982\u8981\u5730\u9610\u8ff0\u4e86\u4fe1\u606f\u670d\u52a1\u4e1a\u7684\u4f5c\u7528\u53ca\u5176\u7ec4\u6210\u4f53\u7cfb, \u7ee7\u800c\u5206\u6790\u4e86\u5f53\u524d\u4fe1\u606f\u670d\u52a1\u4e1a\u4e2d\u5b58\u5728\u7684\u4e00\u4e9b\u95ee\u9898, \u6700\u540e\u63d0\u51fa\u4e86\u53d1\u5c55\u6211\u56fd\u4fe1\u606f\u670d\u52a1\u4e1a\u7684\u51e0\u70b9\u5bf9\u7b56.", "num_citations": "2\n", "authors": ["1068"]}
{"title": "Statistical generalization performance guarantee for meta-learning with data dependent prior\n", "abstract": " Meta-learning aims to leverage experience from previous tasks to achieve an effective and fast adaptation ability when encountering new tasks. However, it is unclear how the generalization property applies to new tasks. Probably approximately correct (PAC) Bayes bound theory provides a theoretical framework to analyze the generalization performance for meta-learning with an explicit numerical generalization error upper bound. A tighter upper bound may achieve better generalization performance. However, for the PAC-Bayes meta-learning bound, the prior distribution is selected randomly which results in poor generalization performance.In this paper, we derive three novel generalization error upper bounds for meta-learning based on the PAC-Bayes relative entropy bound. Furthermore, in order to avoid randomly prior distribution, based on the empirical risk minimization (ERM) method, a data-dependent\u00a0\u2026", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Optical Fingerprint Classification of Single Upconversion Nanoparticles by Deep Learning\n", "abstract": " Highly controlled synthesis of upconversion nanoparticles (UCNPs) can be achieved in the heterogeneous design, so that a library of optical properties can be arbitrarily produced by depositing multiple lanthanide ions. Such a control offers the potential in creating nanoscale barcodes carrying high-capacity information. With the increasing creation of optical information, it poses more challenges in decoding them in an accurate, high-throughput, and speedy fashion. Here, we reported that the deep-learning approach can recognize the complexity of the optical fingerprints from different UCNPs. Under a wide-field microscope, the lifetime profiles of hundreds of single nanoparticles can be collected at once, which offers a sufficient amount of data to develop deep-learning algorithms. We demonstrated that high accuracies of over 90% can be achieved in classifying 14 kinds of UCNPs. This work suggests new\u00a0\u2026", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Recommender Systems in E-learning\n", "abstract": " In this era when every aspect of society is accelerating, people are always seeking improvement to stay competitive in their careers. E-learning systems fit into the ever challenging situation and provide learners with remote learning opportunities and abundant learning resources. Facing with the numerous resources online, users need support in deciding which course to take, thus recommender systems are applied in E-learning to provide learners with personalized services by automatically identifying their preferences. This position paper systematically discusses the main recommendation techniques employed in in E-learning and identifies new research directions. Three main recommendation techniques are reviewed in this paper: content-based, collaborative filtering-based and knowledge-based recommendations. The basic mechanism of these technique together with how they are used to fulfill the specific requirements in the context of E-learning are highlighted and presented. The observations in this paper could support researchers and practitioners to better understand the current development and future directions of recommender systems in E-learning.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Wide-field Decodable Orthogonal Fingerprints of Single Nanoparticles Unlock Multiplexed Digital Assays\n", "abstract": " The control in optical uniformity of single nanoparticles and tuning their diversity in orthogonal dimensions, dot to dot, holds the key to unlock nanoscience and applications. Here we report that the time-domain emissive profile from single upconversion nanoparticle, including the rising, decay and peak moment of the excited state population (T2 profile), can be arbitrarily tuned by upconversion schemes, including interfacial energy migration, concentration dependency, energy transfer, and isolation of surface quenchers. This allows us to significantly increase the coding capacity at the nanoscale. We further implement both time-resolved wide-field imaging and deep-learning techniques to decode these fingerprints, showing high accuracies at high throughput. These high-dimensional optical fingerprints provide a new horizon for applications spanning from sub-diffraction-limit data storage, security inks, to high-throughput single-molecule digital assays and super-resolution imaging.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Deep cross-output knowledge transfer using stacked-structure least-squares support vector machines\n", "abstract": " This article presents a new deep cross-output knowledge transfer approach based on least-squares support vector machines, called DCOT-LS-SVMs. Its aim is to improve the generalizability of least-squares support vector machines (LS-SVMs) while avoiding the complicated parameter tuning process that occurs in many kernel machines. The proposed approach has two significant characteristics: 1) DCOT-LS-SVMs is inspired by a stacked hierarchical architecture that combines several layer-by-layer LS-SVMs modules. The module that forms the higher layer has additional input features that consider the predictions from all previous modules and 2) cross-output knowledge transfer is used to leverage knowledge from the predictions of the previous module to improve the learning process in the current module. With this approach, the model's parameters, such as a tradeoff parameter C and a kernel width \u03b4, can be\u00a0\u2026", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Developments Of Artificial Intelligence Technologies In Computation And Robotics-Proceedings Of The 14th International Flins Conference (Flins 2020)\n", "abstract": " FLINS, an acronym introduced in 1994 and originally for Fuzzy Logic and Intelligent Technologies in Nuclear Science, is now extended into a well-established international research forum to advance the foundations and applications of computational intelligence for applied research in general and for complex engineering and decision support systems. The principal mission of FLINS is bridging the gap between machine intelligence and real complex systems via joint research between universities and international research institutions, encouraging interdisciplinary research and bringing multidiscipline researchers together. FLINS 2020 is the fourteenth in a series of conferences on computational intelligence systems.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Framework of Computational Intelligence-Enhanced Knowledge Base Construction: Methodology and A Case of Gene-Related Cardiovascular Disease\n", "abstract": " Knowledge base construction (KBC) aims to populate knowledge bases with high-quality information from unstructured data but how to effectively conduct KBC from scientific documents with limited preknowledge is still elusive. This paper proposes a KBC framework by applying computational intelligent techniques through the integration of intelligent bibliometrics\u2014eg, co-occurrence analysis is used for profiling research topics/domains and identifying key players, and recommending potential collaborators based on the incorporation of a link prediction approach; an approach of scientific evolutionary pathways is exploited to trace the evolution of research topics; and a search engine incorporating with fuzzy logics, word embedding, and genetic algorithm is developed for knowledge searching and ranking. Aiming to examine and demonstrate the reliability of the proposed framework, a case of gene-related cardiovascular diseases is selected, and a knowledge base is constructed, with the validation of domain experts.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Recommending scientific collaborators: Bibliometric networks for medical research entities\n", "abstract": " Aiming to recommend potential collaborators for academic entities such as researchers and institutions, this paper develops a social recommender system through bibliometric indicators and network analytics. Targeting to scholarly articles, the proposed recommender system exploits co-authorships as established social relations and proposes a link prediction model for discovering such potential relations in terms of a co-authorship network. A case study recommending scientific collaborators for research entities on generelated diseases demonstrates the reliability of this study.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "A cross-domain group recommender system with a generalized aggregation strategy\n", "abstract": " Developing group recommender systems has been a vital requirement due to the prevalence of group activities. However, existing group recommender systems still suffer from data sparsity problem because they rely on individual recommendation methods with a predefined aggregation strategy. To solve this problem, we propose a cross-domain group recommender system with a generalized aggregation strategy in this paper. A generalized aggregation strategy is developed to build group profile in the target domain with the help of individual preferences extracted from a source domain with sufficient data. By adding the constraints between the individual preference and the group profile, knowledge is transferred to assist in the group recommendation task in the target domain. Experiments on a real-world dataset justify the effectiveness and rationality of our proposed cross-domain recommender systems. The\u00a0\u2026", "num_citations": "1\n", "authors": ["1068"]}
{"title": "A Recommender System for Cold-start Items: A Case Study in the Real Estate Industry\n", "abstract": " The recommender systems provide users with what they prefer and filter unnecessary information. In the fierce marketing environment, it is crucial to recommend items to users in an early stage to keep user\u2019s interests and loyalty. With the fast product renewal, classical recommendation methods such as collaborative filtering cannot handle the cold-start item problem. In many real-world applications, content information of items or users is available and can be used to assist recommendation. Besides, user may interact with the items in different behaviors such as view, click or subscribe. How to use the complex content information and multiple user behaviors are real problems that are not well solved in applications. In this paper, we propose a content-based recommender system to deal with the practical problem. Boosting tree model also added to the system to avoid potential Spam. We applied our developed\u00a0\u2026", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Distributed model predictive control of linear systems with coupled constraints based on collective neurodynamic optimization\n", "abstract": " Distributed model predictive control explores an array of local predictive controllers that synthesize the control of subsystems independently yet they communicate to efficiently cooperate in achieving the closed-loop control performance. Distributed model predictive control problems naturally result in sequential distributed optimization problems that require real-time solution. This paper presents a collective neurodynamic approach to design and implement the distributed model predictive control of linear systems in the presence of globally coupled constraints. For each subsystem, a neurodynamic model minimizes its cost function using local information only. According to the communication topology of the network, neurodynamic models share information to their neighbours to reach consensus on the optimal control actions to be carried out. The collective neurodynamic models are proven to guarantee\u00a0\u2026", "num_citations": "1\n", "authors": ["1068"]}
{"title": "A framework of transferring structures across large-scale information networks\n", "abstract": " The existing domain-specific methods for mining information networks in machine learning aims to represent the nodes of an information network into a vector format. However, the real-world large-scale information network cannot make well network representations by one network. When the information of the network structure transferred from one network to another network, the performance of network representation might decrease sharply. To achieve these ends, we propose a novel framework to transfer useful information across relational large-scale information networks (FTLSIN). The framework consists of a 2-layer random walks to measure the relations between two networks and predict links across them. Experiments on real-world datasets demonstrate the effectiveness of the proposed model.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Detection of structural breaks and perceptionally important points in time series\n", "abstract": " In this paper we suggest to use special fuzzy modeling techniques for detection of structural breaks and perceptionally important points in time series, namely the fuzzy (F-)transform and one method of Fuzzy Natural Logic (FNL). The idea is based on application of the F1-transform which makes it possible to estimate effectively slope of time series over an imprecisely specified area (ignoring its possible volatility) and its evaluation by a suitable evaluative linguistic expression. The method is computationally very effective.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "A workforce health insurance plan recommender system\n", "abstract": " Big data appearing in health domain bring great opportunities to develop a workforce health insurance plan recommender system, which can help workforce users select proper insurance plans efficiently. There are two challenges in the development of health insurance plan recommender system: (1) plan and user data present hierarchical tree structures; (2) user requirements are complex and hard to get accurately and completely. To handle both these challenges, this paper proposes a tree matching-based health insurance plan recommender system for workforce. It models the plans and user requirement as plan trees and user requirement trees, and develops user requirement tree construction method and a tree matching based recommendation method.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Pareto-smoothed inverse propensity weighing for causal inference\n", "abstract": " Causal inference has received great attention across different fields ranging from economics, statistics, biology, medicine, to machine learning. Observational causal inference is challenging because confounding variables may influence both the treatment and outcome. Propensity score based methods are theoretically able to handle this confounding bias problem. However, in practice, propensity score estimation is subject to extreme values, leading to small effective sample size and making the estimators unstable or even misleading. Two strategies \u2014 truncation and normalization \u2014 are usually adopted to address this problem. In this paper, we propose a new Pareto-smoothing strategy to tackle this problem. Simulations and a real-world example validate the effectiveness.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Road traffic flow prediction using deep transfer learning\n", "abstract": " Traffic flow prediction is a long-standing problem. Over the recent years, deep learning has gradually achieved a satisfying success on this task, but it depends on abundant historical traffic data. A realistic problem is that some new-established transportation networks only have few data which is not enough to train a robust deep learning model. To address this problem, we first explore and apply the transfer learning and fine-tuning to the field of transportation and propose a novel transferable traffic deep learning model, called TT-DL which can predict real-time traffic flow in data-strapped roads by transferring knowledge from data-rich roads. Our experimental results show that transfer learning is better than any other initialization methods. This indicates that traffic network has its special structure and there exists transferable knowledge between different traffic areas.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Fast concept drift detection using singular vector decomposition\n", "abstract": " Data stream mining is widely used in online applications such as sensor networks, financial transactions, etc. Such systems generate data at high velocity and their underlying distributions may change over time. This is referred to as concept drift problem and it is considered to be the root cause of performance degradation of online machine learning models. To tackle this problem, a reliable and fast drift detection method is required to achieve real time responsiveness to the drifts. This paper presents a fast and accurate drift detection method, namely KS-SVD test - KSSVD, to monitor the distribution changes of the data stream. Our method employs the SVD technique to first check the direction change of the data, followed by a KS test on each direction to detect the univariate distribution changes. Experiments show that our method is efficient and accurate, especially in high dimension situation.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "An output-based knowledge transfer approach and its application in bladder cancer prediction\n", "abstract": " Many medical applications face a situation that the on-hand data cannot fully fit an existing predictive model or on-line tool, since these models or tools only use the most common predictors and the other valuable features collected in the current scenario are not considered altogether. On the other hand, the training data in the current scenario is not sufficient to learn a predictive model effectively yet. In order to overcome these problems and construct an efficient classifier, for these real situations in medical fields, in this work we present an approach based on the least squares support vector machine (LS-SVM), which utilizes a transfer learning framework to make maximum use of the data and guarantee its enhanced generalization capability. The proposed approach is capable of effectively learning a target domain with limited samples by relying on the probabilistic outputs from the other previously learned model\u00a0\u2026", "num_citations": "1\n", "authors": ["1068"]}
{"title": "A Humble Tribute to 50 Years of Fuzzy Sets\n", "abstract": " 2015 was the 50th anniversary of the first contribution on Fuzzy Sets 1 and from the International Journal of Computational Intelligence Systems we want to take this opportunity to pay tribute to Lofti Zadeh, the father of Fuzzy Sets theory, which has guided many researchers and resulted in important advances in various fields of modern society. We also recognise and thank all the researchers who have devoted their careers to studying, developing and applying Fuzzy Sets theory across these 50 years. We want to show our respect, admiration and appreciation to all of them.This Special Issue does not aim to simply be a comprehensive review of the history of Fuzzy Sets; rather, it intends to provide multiple views of these 50 years by incorporating contributions that either survey the use of Fuzzy Sets in different topics, or validate its application in real-world problems or its links with other theories. To achieve this, relevant and well-known researchers from the Fuzzy Sets and computational intelligence fields have contributed seven papers to this issue.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "SEIR immune strategy for instance weighted Naive Bayes classification\n", "abstract": " Naive Bayes (NB) has been popularly applied in many classification tasks. However, in real-world applications, the pronounced advantage of NB is often challenged by insufficient training samples. Specifically, the high variance may occur with respect to the limited number of training samples. The estimated class distribution of a NB classier is inaccurate if the number of training instances is small. To handle this issue, in this paper, we proposed a SEIR (Susceptible, Exposed, Infectious and Recovered) immune-strategy-based instance weighting algorithm for naive Bayes classification, namely SWNB. The immune instance weighting allows the SWNB algorithm adjust itself to the data without explicit specification of functional or distributional forms of the underlying model. Experiments and comparisons on 20 benchmark datasets demonstrated that the proposed SWNB algorithm outperformed existing state-of\u00a0\u2026", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Decision Making and Soft Computing-Proceedings of the 11th International Flins Conference\n", "abstract": " FLINS, originally an acronym for Fuzzy Logic and Intelligent Technologies in Nuclear Science, is now extended to Computational Intelligence for applied research. The contributions to the 11th of FLINS conference cover state-of-the-art research, development, and technology for computational intelligence systems, both from the foundations and the applications points-of-view.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Extension of similarity measures in VSM: From orthogonal coordinate system to affine coordinate system\n", "abstract": " Similarity measures are the foundations of many research areas, e.g. information retrieval, recommender system and machine learning algorithms. Promoted by these application scenarios, a number of similarity measures have been proposed and proposing. In these state-of-the-art measures, vector-based representation is widely accepted based on Vector Space Model (VSM) in which an object is represented as a vector composed of its features. Then, the similarity between two objects is evaluated by the operations on two corresponding vectors, like cosine, extended jaccard, extended dice and so on. However, there is an assumption that the features are independent of each others. This assumption is apparently unrealistic, and normally, there are relations between features, i.e. the co-occurrence relations between keywords in text mining area. In this paper, a space geometry-based method is proposed to\u00a0\u2026", "num_citations": "1\n", "authors": ["1068"]}
{"title": "A hybrid bayesian network for safety of chemical plants\n", "abstract": " In today\u2019s process systems, operators must consider an overwhelming amount of information which is passed to them via automated systems, and make decisions very quickly. Since the decision-making in a time-critical situation is extremely complicated, the use of automated systems to aid decision making is highly recommended. This paper proposes a hybrid Bayesian network (HBN) to support process operators in hazardous situations. The proposed HBN includes three parts: an evidence preparation, a situational network, and risk estimation. The evidence preparation part provides soft evidence based on the online conditions and process monitoring system. The situational network is developed based on dynamic Bayesian networks to model the hazardous situations, and the risk estimation part calculates the risk level of every situation dynamically to show whether the risk level of situations is acceptable or not. The threefold HBN is explained through a case from US Chemical Safety Board (CSB) investigation report. According to the CSB report, following an operator error at a paint manufacturing plant, the explosion and subsequent fire destroyed a facility, injured ten residents, and heavily damaged dozens of nearby homes and businesses. Finally a sensitivity analysis is presented to evaluate the proposed HBN.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Multidimensional and Data Mining Analysis for Property Investment Risk Analysis\n", "abstract": " Property investment in the real estate industry has a high risk due to the uncertainty factors that will affect the decisions made and high cost. Analytic hierarchy process has existed for some time in which referred to an expert-s opinion to measure the uncertainty of the risk factors for the risk analysis. Therefore, different level of experts-experiences will create different opinion and lead to the conflict among the experts in the field. The objective of this paper is to propose a new technique to measure the uncertainty of the risk factors based on multidimensional data model and data mining techniques as deterministic approach. The propose technique consist of a basic framework which includes four modules: user, technology, end-user access tools and applications. The property investment risk analysis defines as a micro level analysis as the features of the property will be considered in the analysis in this paper.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Decision support and warning systems for business intelligence\n", "abstract": " This presentation presents our recent developments in intelligent decision support systems and early warning systems as well as their applications for business intelligence. It reports our research results from two projects in particular: a bi-level decision making technique for competitive strategic bidding optimization in electricity markets, and an intelligent financial warning system using transferable adaptive inference-based fuzzy neural network.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "A fuzzy group decision support system for projects evaluation\n", "abstract": " In any organization there are some main goals and lots of projects for achieving these goals. For any organization, it is important to determine how much these projects affect on achieving the main goals. This paper proposes a new fuzzy multiple attribute-based decision support system (DSS) for evaluating projects in promoting the goals as such a selection may involve both quantitative and qualitative assessment attributes. There are many fuzzy ranking methods available to solve multi-attribute decision making (MADM) problems. Some are more suitable than other for particular decision problems. The proposed DSS has ability to choose the most appropriate fuzzy ranking method for solving given MADM problem. In addition it contains sensitivity analysis system which provides opportunity for analyzing the impacts of attributes\u2019 weights and projects\u2019 performance on achieving organizations\u2019 goals. A DSS\u00a0\u2026", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Personalized Recommender Systems for e-Government and e-Business Intelligence\n", "abstract": " Web personalisation is an interdisciplinary topic that has been discussed in the literature about information systems, web intelligence, customer relationship management and marketing. Web personalisation is defined as any set of actions that tailor the web experience to a specific user or set of users, anticipating user needs to provide them with what they want or require without having to ask for it explicitly. A number of ebusiness and e-government development stage models have been proposed in the literature that focuses on classifying functions and features offered by current e-business and e-government. Most of these models have a common final stage which concentrates on providing fully integrated and personalised e-services for their constituents. Recommender systems have gained considerable attention in recent years and are the most successful implementation of web personalisation. Recommender\u00a0\u2026", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Guest editorial: a special issue on optimization techniques for business intelligence systems\n", "abstract": " Business Intelligence refers to computer-based technologies, methodologies, tools, and systems for collecting, integrating, analyzing, and presenting large volumes of information to enable better business decision making. Increasingly, as businesses become more automated, data-driven, and real-time, business intelligence architecture evolves to support both strategic and operational levels of business decision making, which requires more advanced techniques and technical support. Aiming at better supporting business decision-making, business intelligence system is naturally a decision support system (DSS) in practice. Among many core techniques of DSS, an optimization-based DSS whose various optimization methodologies and techniques are applied, aims to arrive at the best or most satisfactory decision out of a multitude of possible alternatives for business decision problems. Decision making has\u00a0\u2026", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Cross-cultural learning challenges and teaching strategies for first-year Asian students in Australian universities\n", "abstract": " With the dramatic increase in the number of Asian students in the past few years, the cross-cultural teaching and learning situation becomes an important issue in Australian universities. To tickle this issue, we conducted a survey to students studying Information Technology and Business courses in five Australian universities. A total of 639 international students and 387 local students completed the questionnaire survey. Our survey results revealed a number of leaning challenges facing international students, especially first year Asian students. Student and staff interviews were also conducted to discover further facts that may not be covered by the questionnaire, and to check whether or not the survey (and interview) results represent the similar view from the staff side. The initial interview outcome, based on an incomplete number of interviews, generally supported the findings from the student survey. This paper is to examine the challenges, especially those from language and cultural aspects that face Asian students studying in Australian universities, and summarize some responses to relevant survey/interview questions from both local and international students. Some teaching strategies on how to improve language ability and classroom skills for first-year Asian international students are initiated.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "AN ONTOLOGY-SUPPORTED CBR SYSTEM FOR A MOBILE-BASED EMERGENCY RESPONSE SYSTEM\n", "abstract": " A mobile-based emergency response system (MERS), as one of the important Mobile Government (m-Government) services, aims to reduce risks in an emergency situation. This paper presents a system based on case-based reasoning (CBR) approach combined with domain ontology to support emergency decision makers for the MERS. The benefit of using this system is to let the retrieving process more convenient in order to depict conclusions and to give recommendations based on the knowledge from the past disaster event occurs. The system mainly consists of five components: data acquisition; ontology; knowledge base; CBR system; and situation assessment.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "A decision making model for vendor-buyer inventory systems\n", "abstract": " In a vendor-buyer supply chain, the buyer\u2019s economic order quantity and the vendor\u2019s optimal number of deliveries are derived either independently or collaboratively. In this paper, we establish a two-stage vendor-buyer inventory system decision model by using bi-level decision making approach. The experimental result shows that the proposed bi-level decision model can effectively handle two-stage vendor-buyer inventory problems and obtain better results than the existing methods.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "A fuzzy multi-criteria group decision support system for textile material fabric-hand evaluation\n", "abstract": " Fabric-hand evaluation is one of the key features and measures in textile material selection for fashion design. Fabric-hand evaluation requires considering multiple criteria with in a group of evaluators. The evaluation process often involves fuzziness in the weights of criteria and the judgments of evaluators. This study first develops a multi-level textile material fabric-hand evaluation model. It then proposes a fuzzy multi-criteria group decision-making (FMCGDM) method for the evaluation. A fuzzy multi-criteria group decision support system (FMCGDSS) is developed to implement the proposed method and applied in textile material fabric-hand evaluation.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "The validation process and component analysis in enterprise integration\n", "abstract": " In a rapidly changing development environment, componentisation is crucial as both reuse and agility are basic requirements for maintaining a consistent responsiveness between business and IT. This study proposes a framework of metadata-based component development aiming to achieve service virtualisation through multidisciplines and multisteps process. It also develops service interoperability which can identify and validate component easily. Based on the strategy, a roadmap is provided in full life cycle. The proposed techniques, the multidisciplines and dimensional services, have been applied in industry in constructing the skeleton of service-based architecture and consequently constructing the foundation of service virtualisation.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "The development of a fuzzy multi-objective group decision support system\n", "abstract": " This paper deals with multi-objective decisionmaking problem with fuzzy parameters under a group environment, called fuzzy multi-objective group decisionmaking (FMOGDM). It first presents an FMOGDM method, which integrates fuzzy multi-objective linear programming (FMOLP) with fuzzy group decision making techniques. Based on the method, a fuzzy multiple objective group decision support system (FMOGDSS) is developed. Finally, it gives a case-based example to demonstrate how an FMOLP problem is solved in a group supported by the FMOGDSS.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Decision Making\n", "abstract": " The following sections are included:Decision and Decision MakersDecision Making ProcessProblem Modelling and OptimisationComputerised Decision Support", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Group Decision Making\n", "abstract": " All material on this site has been provided by the respective publishers and authors. You can help correct errors and omissions. When requesting a correction, please mention this item's handle: RePEc: wsi: wschap: 9781860948596_0003. See general information about how to correct material in RePEc.For technical questions regarding this item, or to correct its authors, title, abstract, bibliographic or download information, contact:(Tai Tone Lim). General contact details of provider: http://www. worldscientific. com/page/worldscibooks.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Warning message generation by information filtering techniques\n", "abstract": " This paper proposes a two-stage model for generating warning messages by using information filtering techniques. In this model, information is represented by its attributes and processed through two stages. At the first stage, exceptions are separated from normal information by the cognitive filtering technique. At the second stage, a warning message is generated from critical exceptions by the collaborative filtering approach. An example is discussed to illustrate the proposed model.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "An extended branch-and-bound algorithm for fuzzy linear bilevel programming\n", "abstract": " This paper presents an extended Branch-and-Bound algorithm for solving fuzzy linear bilevel programming problems. In a fuzzy bilevel programming model, the leader attempts to optimize his/her fuzzy objective with a consideration of overall satisfaction, and the follower tries to find an optimized strategy, under himself fuzzy objective, according to each of possible decisions made by the leader. This paper first proposes a new solution concept for fuzzy linear bilevel programming. It then presents a fuzzy number based extended Branch-and-bound algorithm for solving fuzzy linear bilevel programming problems.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Environmental/economic dispatch using genetic algorithm and fuzzy number ranking method\n", "abstract": " This paper establishes a novel environmental/economic load dispatch model in which the cost and emission functions are with uncertain coefficients. To solve the problem, this study first converts the model into a single objective optimization problem by using a novel weighting ideal point method. A hybrid genetic algorithm with quasi-simplex techniques is then developed to solve the corresponding single objective optimization problem. Fuzzy number ranking method is also applied to compare all fuzzy function values of different points for the single objective function. The test results have convinced the validity of the model and effectiveness of the algorithm used for achieving a solution for the economic dispatch problem.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Personalized Multi-Stage Decision Support in Reverse Logistics Management\n", "abstract": " Abstract                          Reverse logistics has gained increasing importance as a profitable and sustainable business strategy. As a reverse logistics chain has strong internal and external linkages, the management of a reverse logistics chain becomes an area of organizational competitive advantage, in particular, with the growth of e-commerce applications. To effectively manage a reverse logistics chain always involves a decision optimization issue in which uncertain information, individual situation, multiple criteria and dynamic environment all need to be considered. This paper addresses the need of supporting reverse logistics managers in selecting an optimal alternative for goods return under their business objectives. Through analyzing the characteristics of reverse logistics chain, this paper proposes a personalized multi-stage decisionsupport model for reverse logistics management. It then presents a\u00a0\u2026", "num_citations": "1\n", "authors": ["1068"]}
{"title": "A Text Mining Model by Using Weighting Technology\n", "abstract": " In Latent Semantic Indexing (LSI) has been proven to be a valuable analysis tool with a wide range of applications. However choosing an appropriate number of dimensions for LSI is still a crucial challenge. This paper provides a document vector model, by using weighting technology, to deal with this problem. Our experimental results have demonstrated that this model can detect a dataset structure, help determine an appropriate number of dimensions for LSI.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "A recommender system by two-level collaborative filtering.\n", "abstract": " A RECOMMENDER SYSTEM BY TWO-LEVEL COLLABORATIVE FILTERING Xuetao Guo, Jie Lu, Guangquan Zhang Faculty of Information Technology, University of Technology Sydney 1 Broadway, Ultimo, NSW 2007 Australia {xguo, jielu, zhangg}@it.uts.edu.au ABSTRACT A vast of information and services on the web have caused the information overload problem. Search engines are pretty difficult to locate appropriate information due to the huge number of search results. In the last a few years, recommender system techniques have gained much attention. Most recommender systems adopt two types of techniques: content-based and collaborative filtering approach. In this study, a subject recommender system has been developed and implemented in an education environment. The system aims to locate right subject information to right students according to their individual needs and interests. With a technical \u2026", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Choosing LSI dimensions by document linear association analysis\n", "abstract": " Latent Semantic Indexing (LSI) has proven to be a valuable analysis tool with a wide range of applications, however the crucial question, choosing an appropriate number of dimensions for LSI, is still unsolved. In this paper, a new method which is to deal with this problem is described. It finds that a sum of total dot products between all document vectors reaches the maximum value at a specific number of dimensions for a given dataset. With this reduced dimensions LSI achieves the best performance. The performance evaluations have demonstrated that this method can choose an appropriate number of dimensions for LSI and effective detect the data structure for a dataset.", "num_citations": "1\n", "authors": ["1068"]}
{"title": "Lattice-valued Zp-pan-integrals I: For lattice-valued simple functions on lattice\n", "abstract": " OPUS at UTS: Lattice-valued Zp-Pan-integrals I: For lattice-valued Simple Functions on Lattice - Open Publications of UTS Scholars Skip navigation OPUS at UTS | Open Publications of UTS Scholars Statistics Help About OPUS How to Deposit Managing Copyright Notice Browse UTS Organisational Groups Browse Items by: Issue Date Author Title Type ARC/NHRMC Funded Search OPUS 1.OPUS at UTS 2.Faculty of Engineering and Information Technology 3.General Collection Lattice-valued Zp-Pan-integrals I: For lattice-valued Simple Functions on Lattice Zhang, G ORCID badge Wu, Y Lu, J ORCID badge Permalink Export RIS format Publisher: International Fuzzy mathematics Institute, USA Publication Type: Journal Article Citation: The Journal of Fuzzy mathematics, 2002, 10 (1), pp. 213 - 226 Issue Date: 2002-01 Closed Access Filename Description Size Thumbnail 2004002921.pdf 419.65 kB Adobe PDF View\u2026", "num_citations": "1\n", "authors": ["1068"]}
{"title": "\u4e13\u5bb6\u51b3\u7b56\u652f\u6301\u7cfb\u7edf (EDSS) \u7684\u6846\u67b6\u7ed3\u6784\u4e0e\u4e09\u5e93\u7edf\u4e00\u95ee\u9898\n", "abstract": " \u4e13\u5bb6\u51b3\u7b56\u652f\u6301\u7cfb\u7edf (EDSS) \u662f\u51b3\u7b56\u652f\u6301\u7cfb\u7edf (DSS) \u548c\u4e13\u5bb6\u7cfb\u7edf (ES) \u7684\u96c6\u6210\u7cfb\u7edf, \u662f\u8ba1\u7b97\u673a\u5e94\u7528\u7684\u6700\u65b0\u7814\u7a76\u9886\u57df\u4e4b\u4e00. \u672c\u6587\u7814\u7a76\u4e86 EDSS \u7684\u53d1\u5c55\u548c EDSS \u7684\u6846\u67b6\u7ed3\u6784, \u5e76\u4ee5\u96c6\u6210\u5316\u7684\u89c2\u70b9\u63a2\u8ba8\u4e86 EDSS \u4e2d\u6570\u636e\u5e93 (DB), \u6a21\u578b\u5e93 (MB), \u77e5\u8bc6\u5e93 (KB) \u7684\u7edf\u4e00\u8868\u793a\u4e0e\u7ba1\u7406\u95ee\u9898.", "num_citations": "1\n", "authors": ["1068"]}