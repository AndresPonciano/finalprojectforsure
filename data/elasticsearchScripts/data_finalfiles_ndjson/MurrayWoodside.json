{"title": "Evaluating the scalability of distributed systems\n", "abstract": " Many distributed systems must be scalable, meaning that they must be economically deployable in a wide range of sizes and configurations. This paper presents a scalability metric based on cost-effectiveness, where the effectiveness is a function of the system's throughput and its quality of service. It is part of a framework which also includes a sealing strategy for introducing changes as a function of a scale factor, and an automated virtual design optimization at each scale factor. This is an adaptation of concepts for scalability measures in parallel computing. Scalability is measured by the range of scale factors that give a satisfactory value of the metric, and good scalability is a joint property of the initial design and the scaling strategy. The results give insight into the scaling capacity of the designs, and into how to improve the design. A rapid simple bound on the metric is also described. The metric is demonstrated in\u00a0\u2026", "num_citations": "337\n", "authors": ["708"]}
{"title": "Enhanced modeling and solution of layered queueing networks\n", "abstract": " Layered queues are a canonical form of extended queueing network for systems with nested multiple resource possession, in which successive depths of nesting define the layers. The model has been applied to most modern distributed systems, which use different kinds of client-server and master-slave relationships, and scales up well. The layered queueing network (LQN) model is described here in a unified fashion, including its many more extensions to match the semantics of sophisticated practical distributed and parallel systems. These include efficient representation of replicated services, parallel and quorum execution, and dependability analysis under failure and reconfiguration. The full LQN model is defined here and its solver is described. A substantial case study to an air traffic control system shows errors (compared to simulation) of a few percent. The LQN model is compared to other models and\u00a0\u2026", "num_citations": "235\n", "authors": ["708"]}
{"title": "Performance modeling from software components\n", "abstract": " When software products are assembled from pre-defined components, performance prediction should be based on the components also. This supports rapid model-building, using previously calibrated sub-models or \"performance components\", in sync with the construction of the product. The specification of a performance component must be tied closely to the software component specification, but it also includes performance related parameters (describing workload characteristics and demands), and it abstracts the behaviour of the component in various ways (for reasons related to practical factors in performance analysis). A useful set of abstractions and parameters are already defined for layered performance modeling. This work extends them to accommodate software components, using a new XML-based language called Component-Based Modeling Language (CBML). With CBML, compatible components\u00a0\u2026", "num_citations": "203\n", "authors": ["708"]}
{"title": "An intermediate metamodel with scenarios and resources for generating performance models from UML designs\n", "abstract": " Performance analysis of a software specification in a language such as UML can assist a design team in evaluating performance-sensitive design decisions and in making design trade-offs that involve performance. Annotations to the design based on the UML Profile for Schedulability, Performance and Time provide necessary information such as workload parameters for a performance model, and many different kinds of performance techniques can be applied. The Core Scenario Model (CSM) described here provides a metamodel for an intermediate form which correlates multiple UML diagrams, extracts the behaviour elements with the performance annotations, attaches important resource information that is obtained from the UML, and supports the creation of many different kinds of performance models. Models can be made using queueing networks, layered queues, timed Petri nets, and it is proposed\u00a0\u2026", "num_citations": "136\n", "authors": ["708"]}
{"title": "Software performance models from system scenarios in use case maps\n", "abstract": " Software performance concerns begin at the very outset of a new project. The first definition of a software system may be in the form of Use Cases, which may be elaborated as scenarios: this work creates performance models from scenarios. The Use Case Maps notation captures the causal flow of intended execution in terms of responsibilities, which may be allocated to components, and which are annotated with expected resource demands. The SPT algorithm was developed to transform scenario models into performance models. The UCM2LQN tool implements SPT and converts UCM scenario models to layered queueing performance models, allowing rapid evaluation of an evolving scenario definition. The same reasoning can be applied to other scenario models such as Message Sequence Charts, UML Activity Graphs (or Collaboration Diagrams, or Sequence Diagrams), but UCMs are particularly\u00a0\u2026", "num_citations": "129\n", "authors": ["708"]}
{"title": "Tutorial introduction to layered modeling of software performance\n", "abstract": " This note introduces the conceptual basis of layered queueing networks (LQNs) as a performance model for software systems, and then leads the reader through the features provided by the LQML modeling language. Layered queueing is an elegant compact notation for Extended Queueing Networks, which incorporates a number of features which are common in software systems (and other kinds of systems too). The central feature is a kind of structured \u201csimultaneous resource possession\u201d, common in layered and client-server architectures, which gives it the name Layered Queueing.There is also a User Manual for the LQNS solver and LQSIM simulator, and a thesis and more recent technical paper which summarize the underlying mathematics; these and other materials can be found on the layeredqueues. org web site, and on the LQNS page at www. sce. carleton. ca/rads/lqns.", "num_citations": "92\n", "authors": ["708"]}
{"title": "Performance modeling and prediction of enterprise JavaBeans with layered queuing network templates\n", "abstract": " Component technologies, such as Enterprise Java Beans (EJB) and .NET, are used in enterprise servers with requirements for high performance and scalability. This work considers performance prediction from the design of an EJB system, based on the modular structure of an application server and the application components. It uses layered queueing models, which are naturally structured around the software components. This paper describes a framework for constructing such models, based on layered queue templates for EJBs, and for their inclusion in the server. The resulting model is calibrated and validated by comparison with an actual system.", "num_citations": "84\n", "authors": ["708"]}
{"title": "A metamodel for generating performance models from UML designs\n", "abstract": " Several different kinds of performance models can be generated from sets of scenarios that describe typical responses of a system, and their use of re-sources. The Core Scenario Model described here integrates the scenario and resource elements defined in a UML model with performance annotations, preparatory to generating performance models. It is based on, and aligned with the UML Profile for Schedulability, Performance and Time, and supports the generation of predictive performance models using queueing networks, layered queueing, or timed Petri nets. It is proposed to develop it as an intermediate language for all performance formalisms.", "num_citations": "82\n", "authors": ["708"]}
{"title": "Using regression splines for software performance analysis\n", "abstract": " To make software performance prediction more powerful, execution demand functions must be measured over ranges of system parameters, preferably using scripts to automate the collection of large numbers of cases. Once data is collected it is natural to represent it by a regression function, and to interpolate using the function, to obtain parameters for models as they are needed. Although some practitioners have used linear functions, recent experience has shown that simple polynomial regression functions are often inadequate for these \u201cresource functions\u201d. They may be very irregular, even jagged. Regression splines offer a simple representation that can adapt to very irregular functions, and which can be fitted automatically.Resource functions offer an opportunity to gather enough data to provide whatever accuracy we require, by going back for more data after doing a partial fit. However regression splines do\u00a0\u2026", "num_citations": "76\n", "authors": ["708"]}
{"title": "Performance-related completions for software specifications\n", "abstract": " To evaluate a software specification for its performance potential, it is necessary to supply additional information, not required for functional specification. Examples range from the execution cost of operations and details of deployment, up to missing subsystems and layers. The term\" completions\" is used here to include all such additions, including annotations, component insertions, environment infrastructure, deployment, communication patterns, design refinements and scenario or design transformations which correspond to a given deployment style. Completions are related to the purpose of evaluation, so they are tailored to describing the performance at a suitable level of detail. Completions for evaluating other attributes such as reliability or security are also possible. The paper describes how completions are added to a specification regardless of the language used (provided that it describes the system\u00a0\u2026", "num_citations": "69\n", "authors": ["708"]}
{"title": "Automated performance modeling of software generated by a design environment\n", "abstract": " Automation is needed to make performance modeling faster and more accessible to software designers. This paper describes a prototype tool that exploits recently developed techniques for automatic model construction from traces. The performance model is a layered queuing model and it is based on traces captured for certain selected scenarios which are determined to be important for performance. The prototype tool has been integrated with a commercial software design environment that generates code with heavy use of standard libraries. The execution costs of the libraries has also been captured and used in the automatic model creation. The approach not only automates building early models, but also gives models which can be maintained during development, using traces gathered from the implementations. The paper describes the tool, the process by which it is applied, the process of capturing and\u00a0\u2026", "num_citations": "63\n", "authors": ["708"]}
{"title": "Analysing software requirements specifications for performance\n", "abstract": " The earliest moment when performance issues can be addressed is the initial specification of a software system, during the formulation of the architecture, and well before the design stage. A common form of specification at this stage is a set of scenarios to be executed by the system, which embody the Use Cases, and identify the sequence of responsibilities to be carried out in different kinds of responses. On the basis that earlier analysis is better, a performance modeling capability has been installed in a scenario modeling tool for Use Case Maps that is part of a proposed standard for User Requirements Notation. Using examples, the paper shows how this kind of early analysis can address high-level performance questions, at a comparable level of abstraction to the specification. The imprecision of early knowledge, and the risk of ignoring some performance limitations, are key factors whose impact is addressed.", "num_citations": "57\n", "authors": ["708"]}
{"title": "Interaction tree algorithms to extract effective architecture and layered performance models from traces\n", "abstract": " Models of software architecture and software performance both depend on identifying and describing the interactions between the components, during typical responses. This work identifies the components and interactions that are active during a tracing experiment, hence the name \u201ceffective architecture\u201d and also derives layered performance models. The System Architecture and Model Extraction Technique (SAMEtech) described here overcomes a weakness of previous work with \u201cangio traces\u201d in two ways. It only requires standard trace formats (rather than a custom format which captures causality) and it uses a simpler algorithm which scales up linearly for very large traces. It accepts some limitations: components must not have internal parallelism with forking and joining of the flow of execution. SAMEtech uses pattern matching based on \u201cinteraction trees\u201d for detecting various types of interactions\u00a0\u2026", "num_citations": "55\n", "authors": ["708"]}
{"title": "Performance of multi-level client-server systems with parallel service operations\n", "abstract": " Abstract l\u2019arcrllel extcufzon can enhance the performance of dzsfrzhufed claen, f-server systems, but the enhancement ma, y he less than expected. Evaluatzons of such deszgns must rn, clude the complex eflects of overheads, heterogeneous parallel branch, es, contention by the parallel parts for servers in lower levels, and simultaneous resource possession effects. A \u201ccompensated complelnentary delay\u201d approximation is described which explozis layered queuean, g approEzmations for layered re-. sources tuhach occur in client-server architectures, based on synchronazation dela, y estimates and adjusted levels of conieniion. The new approximataon uses the overlap of parallel branches and a new fast calculation of join drlalys. II gives acceptable errors (averaging about two percent), and has an enormously lower computational cost compared to the competang approach based on decompositzon. The new\u00a0\u2026", "num_citations": "53\n", "authors": ["708"]}
{"title": "Layered analytic performance modelling of a distributed database system\n", "abstract": " Very few analytic models have been reported for distributed database systems, perhaps because of complex relationships of the different kinds of resources in them. Layered queueing models seem to be a natural framework for these systems, capable of modelling all the different features which are important for performance (e.g. devices, communications, multithreaded processes, locking). To demonstrate the suitability of the layered framework, a previous queueing study of the CARAT distributed testbed has been recast as a layered model. Whereas the queueing model bears no obvious resemblance to the database system, the layered model directly reflects its architecture. The layered model predictions have about the same accuracy as the queueing model.", "num_citations": "49\n", "authors": ["708"]}
{"title": "A wideband approach to integrating performance prediction into a software design environment\n", "abstract": " Performance predictions for software designs are needed to give early warnings of problems such as resource saturation or excessive delays. A wideband approach to performance prediction is one which can be applied to a wide range of design descriptions and parameters, ranging from incomplete early descriptions and estimates, to target system measurement data. The paper describes a practical development of such an approach, designed to be integrated with an existing software design environment called ObjecTime. It uses a performance model to make predictions about performance measures such as the average time an actor or processor is busy, the communication overhead of a scenario, or the delays in processing an input event. Automation shrinks the cost and time for model building, and synchronizes the design and model as the design develops. The wideband approach can be applied\u00a0\u2026", "num_citations": "48\n", "authors": ["708"]}
{"title": "Automatic generation of layered queuing software performance models from commonly available traces\n", "abstract": " Performance models of software designs can give early warnings of problems such as resource saturation or excessive delays. However models are seldom used because of the considerable effort needed to construct them. Software Architecture and Model Extraction (SAME) is a lightweight model building technique that extracts communication patterns from executable designs or prototypes that use message passing, to develop a Layered Queuing Network model in an automated fashion. It is a formal, traceable model building process. The transformation follows a series of well-defined transformation steps, from input domain,(an executable software design or the implementation of software itself) to output domain, a Layered Queuing Network (LQN) Performance model. The SAME technique is appropriate for a message passing distributed system where tasks interact by point-to-point communication. With SAME\u00a0\u2026", "num_citations": "43\n", "authors": ["708"]}
{"title": "Performance validation at early stages of software development\n", "abstract": " We consider what aspects of software performance can be validated during the early stages of development, before the system is fully implemented, and how this can be approached. There are mature and successful methods available for immediate use, but there are also difficult aspects that need further research. Ease of use and integration of performance engineering with software development are important examples. This paper describes issues in early performance validation, methods, successes and difficulties, and conclusions.", "num_citations": "35\n", "authors": ["708"]}
{"title": "On the effect of traffic model to the performance evaluation of multicast protocols in MANET\n", "abstract": " While efforts have been made recently to evaluate the performance of multicasting protocols in mobile ad hoc networks (MANET) and to evaluate the capacity of ad hoc networks, very little is understood or known about the traffic characteristics of mobile ad hoc networks and its effect on the performance of the existing multicasting protocols. In this paper, traffic models for multicast protocols in MANET are outlined. A literature survey for multicast protocols in MANET is conducted. Classification for most MANET multicast protocols is presented. A research to evaluate the performance of the existing multicast protocols in MANET using self-similarity traffic model is proposed & justified", "num_citations": "34\n", "authors": ["708"]}
{"title": "Component based performance prediction\n", "abstract": " Component Based Software Engineering (CBSE) exploits re-usability of configurable components to generate software products more quickly, and with higher quality. CBSE offers potential advantages for performance engineering. If most of a new system consists of existing software components, it should be possible to predict properties like performance more easily, than if all of the software is new. The performance-sensitive properties of the components can be extracted and stored in a library, and used to build a predictive model for the performance of a proposed product. This paper describes an approach based on performance submodels for each component, and a system assembly model to describe the binding together of library components and new components into a product. In this work a component can be arbitrarily complex, including a subsystem of concurrent processes. The description pays particular attention to identifying the information that must be provided with the components, and with the bindings, and to providing for parameterization to describe different configurations and workloads.", "num_citations": "34\n", "authors": ["708"]}
{"title": "Scalability metrics and analysis of mobile agent systems\n", "abstract": " Scalability is a many-sided property which can be captured in a scalability metric that balances cost, volume, timeliness and other attirbutes of value in the system, as a function of its size. Studies of typical metrics can reveal which parts of the agent infrastructure are most critical for scalability. Simple metrics are investigated for systems dominated by agent behaviour. As a system is scaled up, the length of the average tour increases and this has a major effect on performance and scalability limits. Senstivity experiments show that infrastructure improvements can improve scalability but they will not alter the general conclusions.", "num_citations": "33\n", "authors": ["708"]}
{"title": "Resource function capture for performance aspects of software components and sub-systems\n", "abstract": " The performance of a software system is determined by its resource demands, and the degree of competition for such resources during execution. The demands are in part determined by pre-existing software components including libraries, operating systems, middleware, and increasingly, also by application level components. A suitable description of the resource demands of a component can be used for rapid performance and capacity analysis of a planned system. Resource demands may be found by theoretical analysis (as in big-O complexity analysis), or by measurement, as considered here. This paper describes the general notion of a workbench and repository for the gathering and maintenance of resource demand data, in the form of resource functions, and two research prototypes. The key elements are a test harness for each software component, automation based on a stored plan for running\u00a0\u2026", "num_citations": "32\n", "authors": ["708"]}
{"title": "Services supporting management of distributed applications and systems\n", "abstract": " A distributed computing system consists of heterogeneous computing devices, communication networks, operating system services, and applications. As organisations move toward distributed computing environments, there will be a corresponding growth in distributed applications central to the enterprise. The design, development, and management of distributed applications presents many difficult challenges. As these systems grow to hundreds or even thousands of devices and similar or greater magnitude of software components, it will become increasingly difficult to manage them without appropriate support tools and frameworks. Further, the design and deployment of additional applications and services will be, at best, ad hoc without modelling tools and timely data on which to base design and configuration decisions. This paper presents a framework for management of distributed applications and systems\u00a0\u2026", "num_citations": "31\n", "authors": ["708"]}
{"title": "From annotated software designs (UML SPT/MARTE) to model formalisms\n", "abstract": " The extraction of a performance model from an annotated software design is largely a matter of taking maximum advantage of the annotations. A serious issue is the fact that a design document directed to producing a product may not be the most convenient for annotation for any given evaluation; there may be a problem to capture the necessary information within the context of the document, without modifying it to clarify the performance concern. Sometimes such a clarification can be of value, but in general we do not wish to disturb the design, just to add the evaluation information. Approaches to using the SPT/MARTE annotations to capture important performance features are described in this paper. Features include completions of the design such as platform operations, composition of component submodels, four uses of state machine definitions, and four ways to describe communications costs and\u00a0\u2026", "num_citations": "30\n", "authors": ["708"]}
{"title": "Software performance models from system scenarios\n", "abstract": " The earliest definition of a software system may be in the form of Use Cases, which may be elaborated as scenarios. In this work, performance models are created from scenarios, to permit the earliest possible analysis of potential performance issues. Suitable forms of scenario models include Unified Modeling Language (UML) Activity or Sequence Diagrams (SD), and Use Case Maps (UCM) from the User Requirements Notation (URN) standard. They capture the causal flow of intended execution, and the operations, activities or responsibilities which may be allocated to components, with their expected resource demands. The Scenario to Performance (S2P) algorithm described here automatically transforms scenario models into performance models, and the LQNGenerator tool implements S2P to convert UCM scenario models into layered queueing performance models. S2P can, in principle, also be applied to\u00a0\u2026", "num_citations": "30\n", "authors": ["708"]}
{"title": "Solving layered queueing networks of large client-server systems with symmetric replication\n", "abstract": " Large distributed client-server systems often contain subsystems which are either identical to each other, or very nearly so, and this simplifies the system description for planning purposes. These replicated components and subsystems all have the same workload and performance parameters. It is known how to exploit this symmetry to simplify the solution of some kinds of performance models, using state aggregation in Markov Chains. This work considers the same problem for layered queueing models, using mean value analysis. The mean values are found for each group of replicas just once, and then are inserted appropriately into the solution of the system as a whole. An algorithm has been implemented in the Layered Queueing Network Solver (LQNS), including approximations to deal with interactions among the replicas, and is evaluated for accuracy and for efficiency. The resulting solver is insensitive (in\u00a0\u2026", "num_citations": "28\n", "authors": ["708"]}
{"title": "ATOM: Model-driven autoscaling for microservices\n", "abstract": " Microservices based architectures are increasingly widespread in the cloud software industry. Still, there is a shortage of auto-scaling methods designed to leverage the unique features of these architectures, such as the ability to independently scale a subset of microservices, as well as the ease of monitoring their state and reciprocal calls. We propose to address this shortage with ATOM, a model-driven autoscaling controller for microservices. ATOM instantiates and solves at run-time a layered queueing network model of the application. Computational optimization is used to dynamically control the number of replicas for each microservice and its associated container CPU share, overall achieving a fine-grained control of the application capacity at run-time. Experimental results indicate that for heavy workloads ATOM offers around 30%-37% higher throughput than baseline model-agnostic controllers based on\u00a0\u2026", "num_citations": "26\n", "authors": ["708"]}
{"title": "Heuristic optimization of scheduling and allocation for distributed systems with soft deadlines\n", "abstract": " This paper studies optimal deployment and priorities for a class of distributed real-time systems which have complex server tasks, many concurrent scenarios, operations with deterministic or stochastic execution demands, arbitrary precedence between operations, and hard or soft deadline requirements. The soft deadlines take the form of a required percentage of responses falling within the deadline. This work improves on an earlier optimization approach which was only applied to hard deadlines. As before, heuristic measures derived from solutions of layered queueing models are used to guide step-by-step improvement of the priorities and allocation, searching for a feasible solution which meets the soft deadline requirements. Effectiveness is demonstrated on a range of examples including thousands of individual cases.", "num_citations": "25\n", "authors": ["708"]}
{"title": "Software performance evaluation by models\n", "abstract": " To assess the performance of a software design or product on a particular platform, performance measures such as response time and throughput are determined, and compared to required values. If they miss the mark some changes may be made in the design while it is still being shaped. Early analysis and corrections save time and money and reduce the risk of project failure through performance failure, as has been argued eloquently by Smith [1] and Hesselgrave [2]. Fig. 1 shows how different performance information is connected to different aspects of software development.", "num_citations": "23\n", "authors": ["708"]}
{"title": "Automation support for software performance engineering\n", "abstract": " To evaluate the performance of a software design one must create a model of the software, together with the execution platform and configuration. Assuming that the\" platform\":(processors, networks, and operating systems) are specified by the designer, a good\" configuration\"(the allocation of tasks to processors, priorities, and other aspects of the installation) must be determined. Finding one may be a barrier to rapid evaluation; it is a more serious barrier if there are many platforms to be considered. This paper describes an automated heuristic procedure for configuring a software system described by a layered architectural software model, onto a set of processors, and choosing priorities. The procedure attempts to meet a soft-real-time performance specification, in which any number of scenarios have deadlines which must be realized some percentage of the time. It has been successful in configuring large systems\u00a0\u2026", "num_citations": "21\n", "authors": ["708"]}
{"title": "Efficient performance models for layered server systems with replicated servers and parallel behaviour\n", "abstract": " Capacity planning for large computer systems may require very large performance models, which are difficult or slow to solve. Layered queueing models solved by mean value analysis can be scaled to dozens of servers and hundreds of service classes, with large class populations, but this may not be enough. A common feature of planning models for large systems is structural repetition expressed through replicated subsystems, which can provide both scalability and reliability, and this replication can be exploited to scale the solution technique. A model has recently been described for symmetrically replicated layered servers, and their integration into the system, with a mean-value solution approximation. However, parallelism is often combined with replication; high-availability systems use parallel data-update operations on redundant replicas, to enhance reliability, and grid systems use parallel computations for\u00a0\u2026", "num_citations": "20\n", "authors": ["708"]}
{"title": "Effectiveness of early replies in client\u2013server systems\n", "abstract": " A common performance optimization for a server process is to send the reply to each request as early as possible, before final operations that are not in the critical path (such as buffer cleanup, state updates, logging and file updates). The operations after the reply form a `second phase' of service. This does not delay the current request from the client, but may delay succeeding requests. The net performance improvement depends on the number of clients at a server, its utilization, and the proportion of the total work which is placed in the second phase. This dependence is explored using analytic models that include an improved special approximation for two phases service in queueing networks, and layered queueing networks The result is an approximate analysis for large and complex client\u2013server systems, with second phases.", "num_citations": "19\n", "authors": ["708"]}
{"title": "Guest editors' introduction: Application-level QoS\n", "abstract": " Application-level quality of service (QoS) is the Achilles' heel of services offered overthe Internet. The articles in this special issue cover various aspects of this complex problem, while exposing the challenges we have yet to overcome.", "num_citations": "18\n", "authors": ["708"]}
{"title": "Multiclass multiservers with deferred operations in layered queueing networks, with software system applications\n", "abstract": " Layered queueing networks describe the simultaneous-resource behaviour of servers that request lower-layer services and wait for them to complete. Layered software systems often follow this model, with messages to request service and receive the results. Their performance has been computed successfully using mean-value queueing approximations. Such systems also have multiservers (which model multi-threaded software processes), multiple classes of service, and what we call deferred operations or \"second phases\", which are executed after sending the reply message to the requester. Three established MVA approximations for multiclass multiservers are extended to include deferred service, and evaluated within the layered queueing context. Errors ranged from 1% up to about 15%. These servers were then used to model the network file system, as implemented on Linux, to show that the method scales\u00a0\u2026", "num_citations": "17\n", "authors": ["708"]}
{"title": "Automated performance modeling from scenarios and SDL designs of distributed systems\n", "abstract": " An automated approach is described for deriving a performance model directly from a software design of a complex system. The goal is to model performance early in the design cycle, in a way that is tightly coupled to the design process. Automating the performance model-building process gives several advantages: it ensures that the model tracks the design, it reduces errors and it creates less work for the design team. The starting point is a design (in an asynchronous style) expressed in SDL processes, and a set of scenarios. To build a performance model, the SDL model is executed for a set of scenarios, traces are recorded for each scenario, and the model structure and data is extracted from the traces. A layered queueing model is then constructed. Other early design products, such as Use Cases or prototypes, can in principle also provide inputs to the same model-building process.", "num_citations": "17\n", "authors": ["708"]}
{"title": "The relationship of performance models to data\n", "abstract": " Performance engineering of software could benefit from a closer integration of the use of performance models, and the use of measured data. Models can contribute to early warning of problems, exploration of solutions, and scalability evaluation, and when they are fitted to data they can summarize the data as a special powerful form of fitted function. Present industrial practice virtually ignores models, because of the effort to create them, and concern about how well they fit the system when it is implemented. The first concern is being met by automated generation from software specifications. The second concern can be met by fitting the models to data as it becomes available. This will adapt the model to the new situation and validate it, in a single step. The present paper summarizes the fitting process, using standard tools of nonlinear regression analysis, and shows it in action on examples of queueing and\u00a0\u2026", "num_citations": "16\n", "authors": ["708"]}
{"title": "Managing Distributed Applications and Systems: An Architectural Experiment\n", "abstract": " A distributed computing system consists of heterogeneous computing devices, communication networks, operating system services, and applications. As organisations move toward distributed computing environments, there will be a corresponding growth in distributed applications central to the enterprise. The design, development, and management of distributed applications presents many di cult challenges. As these systems grow to hundreds or even thousands of devices and similar or greater magnitude of software components, it will become increasingly di cult to manage them without appropriate support tools and frameworks. Further, the design and deployment of additional applications and services will be, at best, ad hoc without modelling tools and timely data on which to base design and con guration decisions. This paper presents a framework for management of distributed applications and systems. It\u00a0\u2026", "num_citations": "15\n", "authors": ["708"]}
{"title": "Performance techniques for cots systems\n", "abstract": " COTS components can provide much of the functionality of distributed information systems. These components range from stand-alone elements, such as a Web server or database system, to platform software or an operating system, to embedded functional components, such as a calendar manager or an inventory-management JavaBean. COTS-based software performance demands more powerful investigative methods than custom software. This performance is particularly important when components include internal concurrency, as is the case in J2EE application servers. We need component-based performance modeling to drive system planning, using layered modeling when considering concurrency, and we need high-level traces to capture measurements related to these structures and diagnose performance issues.", "num_citations": "14\n", "authors": ["708"]}
{"title": "A calibration framework for capturing and calibrating software performance models\n", "abstract": " Software performance engineering could benefit from combining modeling and testing techniques, if performance models could be derived more cheaply and more easily. This work investigates how known testing and estimation methodologies can be combined in a calibration framework, to provide and maintain performance models in sync with a developing product or component library. There are two main aspects. The first addresses a major barrier in practice, the calibration of model parameters that represent quantities that cannot easily be measured directly. This work calibrates these \u201chidden parameters\u201d efficiently using a Kalman Filter. The second is the exploitation of the filter estimator to control the calibration framework, for example to terminate a test when accuracy is sufficient, and to design tests for parameter coverage. The technique is demonstrated on simulated data and on an implemented\u00a0\u2026", "num_citations": "11\n", "authors": ["708"]}
{"title": "Template-driven performance modeling of Enterprise Java Beans\n", "abstract": " System designers find it difficult to obtain insight into the potential performance, and performance problems, of enterprise applications based on component technologies like Enterprise Java Beans (EJBs) or .NET. One problem is the presence of layered resources, which have complicated effects on bottlenecks. Layered queueing network (LQN) performance models are able to capture these effects, and have a modular structure close to that of the system. This work describes templates for EJB components that can be instantiated from the platform-independent description of an application, and composed in a component-based LQN. It describes the process of instantiation, and the interpretation of the model predictions.", "num_citations": "11\n", "authors": ["708"]}
{"title": "Efficient evaluation of alternatives for assembly of services\n", "abstract": " Component based software engineering (CBSE) provides rapid development using well-tested components with established properties. Performance and other nonfunctional properties can also be analyzed by building models from sub-models, calibrated for the components. Further there can be many choices of components to build-systems, which can provide alternatives. The choice can be governed by goal functions which evaluate the predicted performance. This paper describes a systematic approach to find the feasible combinations of alternatives, and to rank them based on predicted performance. It extends the CBML (component based modeling language) for defining components in layered queuing models for software performance.", "num_citations": "10\n", "authors": ["708"]}
{"title": "Seeking optimal policies for adaptive distributed computer systems with multiple controls\n", "abstract": " Abstract\u2212 Modern distributed applications, such as distributed multi-media and mobile applications, face unpredictable operating conditions and load variations. Performance cannot be designed into such applications in advance; they have to be able to tune themselves into unexpected environments and to adapt to changes over time. Single adaptations in applications and middleware are common, but the opportunities are greater if many features of the system, at all layers, are adaptive. This paper describes an architecture to support coordinated adaptive changes in all layers (application, middleware and operating system), with an optimal controller at its core. The controller uses optimal policies based on Markov Decision Processes (MDP), which seek to satisfy a set of system quality-of-service and resource-usage goals.", "num_citations": "8\n", "authors": ["708"]}
{"title": "Simplifying layered queuing network models\n", "abstract": " The amount of detail to include in a performance model is usually regarded as a judgment to be made by an expert modeler and the question \u201chow much detail is necessary?\u201d is seldom asked and is difficult to answer. However, if a simpler model gives essentially the same performance predictions, it may be more useful than a detailed model. It may solve more quickly, for instance, and may be easier to understand. Or a model for a complex sub-system such as a database server may be usefully simplified so it can be included in larger system models. This paper describes an aggregation process for layered queuing models that reduces the number of queues (called tasks and processors, in layered models) while preserving the total execution demand and the bottleneck characteristics of the detailed model. It demonstrates that this process can greatly reduce the number of tasks and processors with a very\u00a0\u2026", "num_citations": "6\n", "authors": ["708"]}
{"title": "Resource architecture and continuous performance engineering\n", "abstract": " The concept of resource architecture has been introduced to describe the association of operations with resources, and interactions between these operations. This paper explains resource architecture with examples, and how it can be used in performance engineering throughout the life of a project.", "num_citations": "6\n", "authors": ["708"]}
{"title": "Layered Performance Modeling and Layered Queueing: Quick Tutorial\n", "abstract": " Layered modeling describes a system by the sets of resources that are used by its operations. Every operation requires one or more resources, and the model defines a resource context and an architecture context for each operation. The architecture context is a software object to execute the operation, and the resource context is a set of software and hardware entities required by the operation.Every resource includes an aspect of an authority to proceed and use it, which is controlled by a discipline and a queue (which may be explicit or implicit). In layered modeling the resources are ordered into layers (typically with user processes near the top and hardware at the bottom) to provide a structured order of requesting them. With layering a graph of all possible sequences of requests is acyclic, and deadlock among requests is impossible. For this and perhaps for other reasons, layered resources are very common in practice. Layering provides an order; requests may jump over layers.", "num_citations": "6\n", "authors": ["708"]}
{"title": "Fast estimation of probabilities of soft deadline misses in layered software performance models\n", "abstract": " Quality of service requirements are normally given in terms of soft deadlines, such as\" 90% of responses should complete within one second\". To estimate the probability of meeting the target delay, one must estimate the distribution of response time, or at least its tail. Exact analytic methods based on state-space analysis suffer from state explosion, and simulation, which is also feasible, is very time consuming. Rapid approximate estimation would be valuable, especially for those cases which do not demand great precision, and which require the exploration of many alternative models. This work adapts layered queueing analysis, which is highly scalable and provides variance estimates as well as mean values, to estimate soft deadline success rates. It evaluates the use of an approximate Gamma distribution fitted to the mean and variance, and its application to examples of software systems. The evaluation finds\u00a0\u2026", "num_citations": "5\n", "authors": ["708"]}
{"title": "Guest editors' introduction-workshop on software and performance\n", "abstract": " The first Workshop on Software and Performance (WOSP'98) was motivated by a desire to pull together the scattered efforts being made, from many different starting points, to create a methodology for this problem. Performance is a problem in many software development projects and anecdotal evidence suggests that it is one of the principal reasons behind cases where projects fail totally. There is a disconnect between the techniques being developed for software analysis and design and the techniques that are available for performance analysis. It is the hope of the workshop organizers that a community will emerge that will tackle this problem and bridge this gap.", "num_citations": "5\n", "authors": ["708"]}
{"title": "Some Requirements for Quantitative Annotations of Software Designs\n", "abstract": " Various initiatives, including the RFP for MARTE [6], call for annotations that define quantitative measures and values to be added to software designs. In MARTE these annotations will indicate timing and memory-use properties of the software and of its behaviour, as well as timing, capacity and utilization properties of resources. Other kinds of non-functional requirement analysis need different types of properties; for instance reliability analysis calls for properties such as failure rates and probabilities. This paper defines general requirements for quantitative annotations, related to their function in evaluating non-functional requirements of software specifications and to their usability. It considers how two previous profiles, SPT [4] and QOS [5], address these requirements, and raises issues and questions related to defining a profile for MARTE [6].", "num_citations": "4\n", "authors": ["708"]}
{"title": "Optimistic scheduling with geographically replicated services in the cloud environment (COLOR)\n", "abstract": " This paper proposes a system model that unifies different optimistic algorithms designed for deploying geographically replicated services in a cloud environment. The proposed model thereby enables a generalized solution (COLOR) by which well-specified safety and timeliness guarantees are achievable in conjunction with tunable performance requirements. The proposed solution explicitly takes advantage of the unique client-cloud interface in specifying how the level of consistency violation may be bounded, for instance using probabilistic rollbacks or restarts as parameters. The solution differs from traditional Eventual Consistency models in that inconsistency is solved concurrently with online client-cloud interactions over strongly connected networks. We believe that such an approach will bring clarity to the role and limitations of the ever-popular Eventual Consistency model in cloud services.", "num_citations": "3\n", "authors": ["708"]}
{"title": "Regression techniques for performance parameter estimation\n", "abstract": " This tutorial describes how to use nonlinear regression techniques to fit the parameters of any kind of performance model to performance data measured at the boundaries of the system. The advantage of this approach, which has never been a standard practice in performance work, is that it avoids the need for intrusive monitoring of execution paths, such as profiling.", "num_citations": "3\n", "authors": ["708"]}
{"title": "Performance modeling of a quorum pattern in layered service systems\n", "abstract": " Quorum consensus protocols execute requests in parallel and proceed once K out of N responses are received. The performance of a system depends on the value of K, the distributions of the quorum response delays, and on the use of system resources by the N concurrent requests. An analytic approximation is given for the delay to achieve the quorum, which also accounts for the contention and delay caused by the (N - K) delayed responses. Compared to simulation results, our approximation gives reasonable accuracy; about 5% in most cases. Our method is shown to be rapid and scalable.", "num_citations": "3\n", "authors": ["708"]}
{"title": "A composable performance model for service/resource systems\n", "abstract": " More and more systems have an architecture made up of resources which offer services at interfaces. An algebra with operators to compose services with each other and with resources, and to compose subsystems into systems, would make possible powerful compact descriptions of such systems, taking advantage of their particular structure. Practical modeling also often requires composition of submodels obtained from partial studies. Such an algebra can also support analysis models of many kinds; here we consider layered performance analysis. This paper outlines an algebra for composing layered queueing models.", "num_citations": "3\n", "authors": ["708"]}
{"title": "Extending the UML Profile for Schedulability Performance and Time (SPT) for component-based systems\n", "abstract": " Component Based Software Engineering (CBSE) is emerging as a paradigm for the development of large complex software systems. CBSE promises to yield cheaper and higher quality assembled systems by reusing configurable generic components that were developed separately [5]. UML 2.0 has extended and improved the representation of components and component-based systems. In UML 2.0, a component is an autonomous unit which has one or more well-defined interfaces (potentially exposed via ports), and its internals are hidden and inaccessible other than as provided by its interfaces [3]. The interfaces provided by a component define a formal contract of services offered to the outside world, whereas the interfaces required by a component define the services needed from elsewhere. In the performance domain there is a growing interest in modeling component based systems (eg,[6]). This paper proposes a number of extensions to the STP Profile [2](more exactly to its Performance Sub-Profile) in regard to component modeling.", "num_citations": "3\n", "authors": ["708"]}
{"title": "Choice of aggregation groups for layered performance model simplification\n", "abstract": " The authors previously showed that a complex layered performance model could be simplified by aggregating the contributions of subsystems, following a few simple principles which give good accuracy in many cases. The question of which subsystems to merge in layered performance models is further examined here, leading to identifying groups of subsystems (corresponding to\" tasks\" in layered queuing models) which can be safely aggregated. The grouping begins by identifying tasks which should be preserved, not aggregated, including those which are (or might become) bottlenecks. Then the groups are defined by their relationship to these preserved tasks. Aggregation by groups provides adequate accuracy in the vast majority of cases examined.", "num_citations": "2\n", "authors": ["708"]}
{"title": "Exploring SOA pattern performance using coupled transformations and performance models\n", "abstract": " Service Oriented Architecture (SOA) patterns can be applied to improve different qualities of SOA designs. The performance impact of a pattern (improvement or degradation) may affect its use, so we assess its impact by automatically generated performance models for the original design and for each candidate pattern and pattern variation. This paper proposes a technique to incrementally propagate the changes from the software to the performance model. The technique formally records the refactoring of the design model when applying a pattern, and uses this record to generate a coupled transformation of the performance model. The SOA design is modeled in UML extended with two profiles, SoaML and MARTE; the patterns are specified using Role Based Modeling and the performance model is expressed in Layered Queuing Networks. Application of the process, and pattern performance exploration, is demonstrated on a case study.", "num_citations": "2\n", "authors": ["708"]}
{"title": "Multi-threaded servers with high service time variation for layered queueing networks\n", "abstract": " Distributed application systems are often implemented as layers of software services. The services provide functions, which we refer to as service entries, that can have significantly different demands on resources such as CPUs and on requests for service from other service entries. Significantly different demands within service entries lead to high service time variation for a service. Such services are typically deployed within application server containers each having some bound on its level of concurrency refered to as its maximum threading level. We have modeled such systems using a layered queueing network approach. Each queue represents a first-come-first-served multi-threaded server with multiple entries that may have high service time variation. This chapter describes a simple and intuitive residence time expression for such queues. Simulation results show that the technique is both fast and accurate\u00a0\u2026", "num_citations": "2\n", "authors": ["708"]}
{"title": "An Aggregation Approach to Constructing Hybrid Layered Queueing Models\n", "abstract": " Layered queueing network (LQN) models are effective for large systems but lack the capability to model some kinds of decision logic that may be important for system performance. This paper describes the use of a \u201ccomplementary model\u201d which focuses on the decision logic, and which provides the results of the logic in a form that the LQN can use. The complementary model is constructed from the same base information as the LQN but system elements away from the focal point are approximated in reduced detail, by aggregating them. The complementary model is thus made consistent with the LQN. The two models together form a \u201chybrid\u201d multi-formalism model, which is solved by a fixed point iteration. The approach is described through an example which uses Stochastic Petri Nets for the complementary submodel.", "num_citations": "2\n", "authors": ["708"]}
{"title": "Compositional layered performance modeling of peer-to-peer routing software\n", "abstract": " Models can help to understand the performance aspects of a computer system from the software architecture and its configurations, but ease of model creation is critical. A compositional model-building approach is described here, in which component submodels are generated from the scenarios they participate in. Submodel classes are derived from an analysis of behaviour patterns as the scenarios traverse the software components. Then submodels are instantiated and combined in the overall system model. The approach is particularly effective in peer-to-peer systems in which subsystems inherit most of their behaviour from a few shared patterns, termed \"behaviour-inheriting peer\" (BIP) systems. A model-building algorithm is described, and is demonstrated on a prototype emulator for a network of routers. The emulator, called CGNet, can be configured for its deployment and for traffic patterns and routes. An\u00a0\u2026", "num_citations": "2\n", "authors": ["708"]}
{"title": "Incorporating Performance Analysis in the Early Stages of Software Development Using Generative Programming Principles\n", "abstract": " The incorporation of performance analysis in the early stages of software development has proven to be an elusive goal. Since the appearance of Connie Smith\u2019s seminal work on Software Performance Engineering (SPE) in 1990 [13], numerous approaches to and methodologies for linking design and performance analysis have been studied and developed, as can be seen in [16],[17], and [1]. Yet through all of this, industry is not applying SPE. This is due to the high overhead of creating performance models from design specifications by traditional means. A comprehensive approach using Generative Programming principles is proposed to solve this problem and remove a major obstacle in the implementation of the SPE methodology.Starting with Use Case Map (UCM)[3][2] design specifications created using the UCM Navigator editing tool [9], the software design can be augmented with resource demands and client arrival information. Layered Queueing Network (LQN) preliminary performance models are then generated automatically using the UCM2LQN converter. The LQN models are then solved analytically using the LQN Solver (LQNS)[6] or simulated using the ParaSol simulator for Stochastic Rendez-Vous Networks (ParaSRVN). The resulting performance metrics can be used to identify performance concerns and refine the design model accordingly.", "num_citations": "2\n", "authors": ["708"]}
{"title": "Generating a Performance Model from a Design Specification\n", "abstract": " The Early Performance Aware Development (E-PAD) process uses generative programming principles in order to incorporate performance analysis in the early stages of software development. Starting with a Use Case Map (UCM)[1] design specification that has been augmented with performance information, we automatically generate a Layered Queueing Network (LQN) preliminary performance model. The LQN model is analyzed using automated solvers and the results can then be incorporated back into the design specification.The E-PAD process can be further enhanced through the adoption of component-based approach that makes use of pre-existing components in order to build the system under development [6]. The existing components should have known performance parameters which provide a more accurate starting point for augmenting the UCM design specifications with performance data. Furthermore, a component-based approach can also provide designers with a choice of available components that could be used to address performance concerns possibly arising from the analysis of the generated LQN model.", "num_citations": "2\n", "authors": ["708"]}
{"title": "Tunable Performance and Consistency Tradeoffs for Geographically Replicated Cloud Services (COLOR)\n", "abstract": " COLOR (client-oriented layered optimistic replication) is a combination of optimistic and conservative data replication that allows cloud services to be replicated across widely distributed locations without suffering from the latency overhead of strict algorithms, and with quantifiable and controllable tradeoffs between performance and consistency guarantees. The COLOR solution adopts a layered approach to enable optimistic delivery of client messages on top of any existing storage layer that manages the strict replication of the cloud service. When clients may be temporarily exposed to inconsistent states due to replication failures, such inconsistency is made recoverable similar to \"optimistic concurrency control\" for clients that cache the server state. COLOR supports different numeric parameters to trade the strict consistency for better performance to possibly match Eventual Consistency, while the end-to-end\u00a0\u2026", "num_citations": "1\n", "authors": ["708"]}
{"title": "WOSP-C'15: Workshop on Challenges in Performance Methods for Software Development\n", "abstract": " The first ACM Workshop on Challenges in Performance Methods for Software Development is held in Austin, Texas, on Jan. 31 2015, and is co-located with the 2015 ACM/SPEC International Conference on Performance Engineering (ICPE). Its purpose is to open up new avenues of research on methods for software developers to address performance problems. The software world is changing, and there are new challenges. As its name implies, the workshop includes the description of problems as well as solutions. The acronym WOSP-C also recalls the original discussion-heavy format of WOSP, the ACM International Workshop on Software and Performance, which has been a co-organizer of ICPE since 2010.", "num_citations": "1\n", "authors": ["708"]}
{"title": "Optimistic Open Groups for Fault-Tolerant Replication\n", "abstract": " Total order multicast [3] of Group Communication Systems (GCSs)[2] has been widely used in building fault-tolerant distributed systems through software-based replication techniques such as active replication. The replication techniques commonly follow the State Machine approach to ensure consistent state replication across all replicas of a distributed service. Two different architectures for such replicated systems are \u201cclosed groups\u201d and \u201copen groups\u201d. In closed groups, clients and server replicas are included in the same GCS multicast group; in open groups, each client interacts only with one server replica that acts as its proxy to disseminate client requests to the server replica group. When the system contains a large number of clients, especially shortlived clients, the open group architecture significantly reduces the size of the multicast group and improves the scalability and stability of the GCS multicast that relies on a group membership service.In contrast with closed groups, open groups introduce specific consistency requirements on the overall system state due to the fact that clients are excluded from the GCS multicast and interact directly with only a single server replica. The client state consistency needs be defined separately from the server state consistency. A generic clientserver interaction model supports asynchronous client-server interactions as well as synchronous interactions, and distinguishes query (read-only) requests, which are not multicast, from update requests. Existing research [1] on the consistency requirements of open groups does not fully address this question and is limited to extending GCS multicast message\u00a0\u2026", "num_citations": "1\n", "authors": ["708"]}