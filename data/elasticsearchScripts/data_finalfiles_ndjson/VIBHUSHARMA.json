{"title": "Cloud computing security--trends and research directions\n", "abstract": " Cloud Computing is increasingly becoming popular as many enterprise applications and data are moving into cloud platforms. However, a major barrier for cloud adoption is real and perceived lack of security. In this paper, we take a holistic view of cloud computing security - spanning across the possible issues and vulnerabilities connected with virtualization infrastructure, software platform, identity management and access control, data integrity, confidentiality and privacy, physical and process security aspects, and legal compliance in cloud. We present our findings from the points of view of a cloud service provider, cloud consumer, and third-party authorities such as Govt. We also discuss important research directions in cloud security in areas such as Trusted Computing, Information Centric Security and Privacy Preserving Models. Finally, we sketch a set of steps that can be used, at a high level, to assess security\u00a0\u2026", "num_citations": "193\n", "authors": ["235"]}
{"title": "Method and system for managing user state for applications deployed on platform as a service (PaaS) clouds\n", "abstract": " The REsilient LOosely Coupled (ReLoC) system and method implement a session-state management architecture for cloud computing that uses loosely-coupled services and platform agnostic scalable messaging technology to propagate and save session states. Maintaining the state of applications and user sessions is difficult in large scale web-based software systems, particularly in the context of cloud computing (eg, platform as a service (PaaS) vendors, do not explicitly support state management infrastructure, such as clustering). In a PaaS environment, a user has little or no access and control over the server platform and session management layer. The platform tiers are generally loosely coupled and service-oriented, which make traditional session-state management techniques non-usable. The ReLoC system and method provides a high level of tolerance to failures of the platform tiers without\u00a0\u2026", "num_citations": "64\n", "authors": ["235"]}
{"title": "Method and system for software developer guidance based on analyzing project events\n", "abstract": " In systems and methods for providing assistance to software developers, a profile of a software developer is accessed. The profile contains a software development history of the software developer. Event data is developed comprising data related to at least one software code event associated with a software development project and with the software developer. Guidance is selected for use by the software developer in resolving a software development problem, based on an analysis of the event data, data related to the software development project, data related to an environment in which the at least one software code event occurred, and the profile. Feedback regarding progress of the software developer in the development project is also developed from the event data and the profile. The guidance and feedback are presented to the software developer via an interactive console unit.", "num_citations": "41\n", "authors": ["235"]}
{"title": "Collection and processing of code development information\n", "abstract": " Within each of a plurality of developer workstations contributing to a software development project, event data concerning at least one quality-related issue is collected via a development tool implemented by the developer workstation. The event data is stored locally and periodically output as at least part of code development information. The code development information is provided to a quality management component for subsequent processing, particularly the determination of one or more quality metrics. At least a portion of such quality metrics may be subsequently provided to the developer workstation for display on a suitable display device.", "num_citations": "35\n", "authors": ["235"]}
{"title": "A social network based study of software team dynamics\n", "abstract": " Members of software project teams have specific roles and responsibilities which are formally defined during project inception or at the start of a life cycle activity. Often, the team structure undergoes spontaneous changes as delivery deadlines draw near and critical tasks have to be completed. Some members--depending on their skill or seniority--need to take on more responsibilities, while others end up being peripheral to the project's execution. We posit that this kind of ad hoc reorganization of a team's structure can be discerned from the project's bug tracker. In this paper, we extract a social network from the bug log of a real life software system and apply ideas from social network analysis to understand how the positions of individual team members in the network relate to their organizational seniority, project roles, and geographic locations that define the formal team structure. In addition to providing insights on\u00a0\u2026", "num_citations": "25\n", "authors": ["235"]}
{"title": "A framework for identifying and analyzing non-functional requirements from text\n", "abstract": " Early identification of Non-Functional Requirements (NFRs) is important as this has direct bearing on the design and architecture of the system. NFRs form the basis for architects to create the technical architecture of the system which acts as the scaffolding in which the functionality of the same is delivered. Failure to identify and analyze NFRs early-on can result in unclassified, incomplete or conflicting NFRs, and this typically results in costly rework in later stages of the software development. In practice, this activity is primarily done manually. In this paper, we present a framework to automatically detect and classify non-functional requirements from textual natural language requirements. Our approach to identify NFRs is based on extracting multiple features by parsing the natural language requirement whereby the presence of a certain combination of and relationship among the features uniquely identifies the\u00a0\u2026", "num_citations": "21\n", "authors": ["235"]}
{"title": "Rule merging in system for monitoring adherence by developers to a software code development process\n", "abstract": " In a rule-based system for monitoring process adherence, first and second processing patterns are received and merged to provide a merged processing pattern. Each processing pattern, which may be expressed in a state graph representation, embodies at least a portion of a desired software code development process. Optionally, the merged processing pattern may be presented to a subject-matter expert to obtain feedback thereon. The merged processing pattern may then be converted into an executable process verification rule for use in monitoring process adherence. In an embodiment, development process event data is compared to the executable process verification rules. Violations of the rules result in the generation of failure indications that may be stored and subsequently reported as needed. In this manner, efficiency of automated process adherence monitoring systems may be improved when\u00a0\u2026", "num_citations": "20\n", "authors": ["235"]}
{"title": "Post-release reliability growth in software products\n", "abstract": " Most software reliability growth models work under the assumption that reliability of software grows due to the removal of bugs that cause failures. However, another phenomenon has often been observed\u2014the failure rate of a software product following its release decreases with time even if no bugs are corrected. In this article we present a simple model to represent this phenomenon. We introduce the concept of initial transient failure rate of the product and assume that it decays with a factor \u03b1 per unit time thereby increasing the product reliability with time. When the transient failure rate decays away, the product displays a steady state failure rate. We discuss how the parameters in this model\u2014initial transient failure rate, decay factor, and steady state failure rate\u2014can be determined from the failure and sales data of a product. We also describe how, using the model, we can determine the product stabilization time\u00a0\u2026", "num_citations": "19\n", "authors": ["235"]}
{"title": "An immersive future for software engineering: avenues and approaches\n", "abstract": " Software systems are increasingly becoming more intricate and complex, necessitating new ways to be able to comprehend and visualize them. At the same time, the nature of software engineering teams itself is changing with people playing more fluid roles often needing seamless and contextual intelligence, for faster and better decisions. Moreover, the next-generation of software engineers will all be post-millennials, which may have totally different expectations from their software engineering workplace. Thus, we believe that it is important to have a re-look at the way we traditionally do software engineering and immersive technologies have a huge potential here to help out with such challenges. However, while immersive technologies, devices and platforms, have matured in past few years, there has been very little research on studying how these technologies can influence software engineering. In this paper\u00a0\u2026", "num_citations": "18\n", "authors": ["235"]}
{"title": "Migration assessment for cloud computing platforms\n", "abstract": " Various embodiments provide an assessment tool that enables an automated functional assessment of applications for migration to target cloud computing platforms, such as a Platform as a Service (PaaS). The technical capabilities of various types of applications in a traditional non-platform deployment are studied and support for these technical capabilities is evaluated relative to the target platform.", "num_citations": "17\n", "authors": ["235"]}
{"title": "Pivot: Project insights and visualization toolkit\n", "abstract": " An in-process view into a software development project's health is critical for its success. However, in services organizations, a typical software development team employs a heterogeneous set of tools based on client requirements through the different phases of the software project. The use of disparate tools with non-compatible outputs makes it very difficult to extract one coherent picture of the project's health and status. Existing project management tools either work at the process layer and rely on manually entered information, or are activity centric, without a holistic view. In this paper, we present PIVoT, a metric-based framework for automated, non-invasive, and in-process data collection and analysis in heterogeneous software project environments, that provides rich, multi-dimensional insights into the project's health and trajectory. Here, we introduce the different analyses, insights and metrics, and discuss their\u00a0\u2026", "num_citations": "17\n", "authors": ["235"]}
{"title": "What do developers want?: an advisor approach for developer priorities\n", "abstract": " On a typical work day, a software developer is swamped to know answers to a multitude of questions to gain diverse insights into the project environment, spanning multiple categories including code, quality and guidance. Due to client mandates, the project environment employs a lot of heterogeneous tools, thus making the relevant information retrieval process fairly complex and therefore it is important to know which insights are most important to the developer. In this paper, we present results from a survey we conducted on a pool of 27 developers from the development team in the delivery center, by asking them to rate a set of 25 Questions, prioritising them as most, moderate and least important to be answered automatically during the software evolution process. We also introduce the concept of Smart Advisor for developers, an intelligence augmentation framework that employs domain and knowledge\u00a0\u2026", "num_citations": "14\n", "authors": ["235"]}
{"title": "Deploying software components for performance\n", "abstract": " Performance is a critical attribute of software systems and depends heavily on the software architecture. Though the impact of the component and connector architecture on performance is well appreciated and modeled, the impact of component deployment has not been studied much. For a given component and connector architecture, the system performance is also affected by how components are deployed onto hardware resources. In this work we first formulate this problem of finding the deployment that maximizes performance, and then present a heuristic-based solution approach for it. Our approach incorporates the software architecture, component resource requirements, and the hardware specifications of the system. We break the problem into two sub-problems and formulate heuristics for suggesting the best deployment in terms of performance. Our evaluation indicates that the proposed heuristic\u00a0\u2026", "num_citations": "13\n", "authors": ["235"]}
{"title": "A gamification approach for distributed agile delivery\n", "abstract": " Large organizations need to be nimble in delivering software solutions for meeting rapidly changing business requirements and technology landscape. Following Agile principles of software development is a natural choice. However, to truly leverage the power of Agile, big organizations need to be able to utilize distributed teams effectively. Agile relies hugely on shared context and awareness among team members and this can become a stumbling block among such geographically dispersed teams. Moreover, in such large projects there is a need for incentivizing quick delivery of user stories so that the teams have a constructive sense of competition and are recognized in-process. Here, we describe a gamification based approach which promotes quicker completion and acceptance of user stories in such distributed Agile projects. Our approach captures important events from the development environment and\u00a0\u2026", "num_citations": "12\n", "authors": ["235"]}
{"title": "Multi-data analysis based proactive defect detection and resolution\n", "abstract": " Multi-data analysis based proactive defect detection and resolution may include analyzing operational data for an application to determine whether a functionality related to the application is below a predetermined threshold associated with the functionality related to the application, and based on the analysis, generating an indication to perform defect analysis related to the functionality related to the application. A sentiment analysis may be performed on consumer data related to the application to determine a sentiment of the consumer data related to the application, and a natural language processing (NLP) analysis may be performed on the consumer data related to the application to determine a function associated with a negative sentiment. Application code and process data related to the application may be analyzed to determine a defect associated with the application. Further, a code of the application may be\u00a0\u2026", "num_citations": "11\n", "authors": ["235"]}
{"title": "Implementing a resilient application architecture for state management on a paas cloud\n", "abstract": " Platform as a Service Clouds typically lack direct support for application state management, and traditional state management techniques like clustering are not applicable as PaaS platforms offer little support for changing the underlying platform configuration. In this paper we build upon our earlier work where we proposed a session-state management architecture for Cloud called ReLoC, that uses loosely-coupled services and platform agnostic scalable messaging technology to propagate and save session states. Here, we present an actual implementation of the ReLoC onto a PaaS platform and an empirical evaluation of the original hypotheses of scalability and resilience of the proposed application architecture. We also present the challenges faced in implementing ReLoC on Heroku. The results indicate that ReLoC indeed allows applications to scale well and mitigates failures in individual application\u00a0\u2026", "num_citations": "10\n", "authors": ["235"]}
{"title": "Detecting performance antipatterns before migrating to the cloud\n", "abstract": " Performance is one of the key drivers for migrating existing systems to Cloud. While Cloud computing platforms come with a promise of scaling on demand, simple lift and shift of an existing application to Cloud would often not be the best solution. The design of a software system has a significant bearing on its performance and while migrating to Cloud, certain design patterns, can be detrimental to software performance. The area of detecting performance antipatterns automatically in context of Cloud migration and assessing their effects on performance is however unstudied. In this paper we present an approach to assess a system for known performance antipatterns, before Cloud migration. Our approach leverages static analysis and also factors in information about the prospective deployment on Cloud to evaluate whether certain antipatterns become prominent if the system is migrated to Cloud. We have found\u00a0\u2026", "num_citations": "9\n", "authors": ["235"]}
{"title": "Studying team evolution during software testing\n", "abstract": " Software development teams are one of the most dynamic entities of any software development project. While the individuals are assigned planned roles at the start of any project, during the course of the project, the team constitution, structure, relationships and roles change. Such changes are often spontaneous and constitute the evolution of the team along different phases of the software development lifecycle. As software development is a team effort, these dynamics may have a significant effect on the development lifecycle itself. This work is aimed at studying the evolution of project teams and gathering insights that can be correlated with project health and outcomes. In this study we apply social network analysis techniques to investigate team evolution in a project in its testing phase. While the questions and insights that we investigate in this paper are valid and useful for all phases of the software development\u00a0\u2026", "num_citations": "9\n", "authors": ["235"]}
{"title": "Stabilization time-a quality metric for software products\n", "abstract": " In software products, often the failure rate decreases after installation, eventually reaching a steady state. The time it takes for a product to reach its steady state reliability depends on different product parameters. In this paper we propose a new metric for software products called stabilization time which is the time taken after installation for the reliability of the product to stabilize. This metric can be used for comparing products, and can be useful for organizations and individuals using the product as well as for the product vendor. We also present an approach for determining the stabilization time of a product from its failure and sales data. We apply the approach to three real life products using their failure and sales data after release", "num_citations": "9\n", "authors": ["235"]}
{"title": "MAT: A Migration Assessment Toolkit for PaaS Clouds\n", "abstract": " Different PaaS (Platform as a Service) Clouds offer different set of capabilities and services and have different constraints on types of application that can be hosted on their platforms. Migrating existing enterprise applications to such platforms thus is non-trivial and needs a thorough assessment of the system to be migrated. In this paper, we present a novel approach for automated assessment of applications for migration to a target PaaS platform. We take an approach of systematically studying typical external technical services that different types of applications need in a traditional non-PaaS deployment and evaluate support for each of services in major PaaS environments. We have created rich sets of repositories each for technical capabilities and services used by typical enterprise applications as well as for the different technical services exposed for use by PaaS platforms along with their limitations and\u00a0\u2026", "num_citations": "8\n", "authors": ["235"]}
{"title": "ReLoC: A Resilient Loosely Coupled Application Architecture for State Management in the Cloud\n", "abstract": " Maintaining the state of applications and user sessions is difficult in large scale web-based software systems. This problem is particularly accentuated in the context of Cloud computing as Cloud providers, especially Platform as a Service (PaaS) vendors, do not explicitly support state management infrastructure - such as clustering. In a PaaS environment, a user has little or no access and control over the server platform and session management layer. Additionally, the platform tiers are generally loosely coupled and service-oriented. These make traditional session-state management techniques non-usable. In this work, we present ReLoC - a session-state management architecture for Cloud that uses loosely-coupled services and platform agnostic scalable messaging technology to propagate and save session states. Preliminary experiments show a very high level of tolerance to failures of the platform tiers without\u00a0\u2026", "num_citations": "8\n", "authors": ["235"]}
{"title": "Functional design creation tool\n", "abstract": " A functional design creation tool generates a functional design diagram for visual presentation on a display. The functional design creation tool extracts content from a processed requirements specification including one or more processed requirement statements. The functional design creation tool applies one or more glossaries and a set of heuristic rules to the extracted content. Functional design diagram components may be generated by the functional design creation tool based on the application of the glossaries and set of heuristic rules. The functional design tool may generate a functional design diagram based on the functional design diagram components. The functional design diagram may be transmitted to a display.", "num_citations": "7\n", "authors": ["235"]}
{"title": "Agile Workbench: Tying People, Process, and Tools in Distributed Agile Delivery\n", "abstract": " Agile software development approaches are becoming mainstream as organizations recognize that their delivery methodology has to be nimble and flexible to accommodate new technologies and evolving customer requirements. However, large organizations depend on a global software delivery model wherein software teams are geographically distributed, and such an environment seems unsuited for Agile to succeed. In such scenarios, it is a challenge to be able to bring together the organization's Agile methodology, development environment, and distributed teams together in a standardized way, to be able to implement and govern the distributed delivery process objectively. Here, we present our approach to govern the adoption, usage and progress thereof of a distributed Agile methodology, that ties together the team and tool aspects with it. This becomes a single window to quickly bootstrap distributed\u00a0\u2026", "num_citations": "6\n", "authors": ["235"]}
{"title": "Performance antipatterns: Detection and evaluation of their effects in the cloud\n", "abstract": " The way an application is designed and certain patterns thereof, play a significant role and might have a positive or a negative effect on the performance of the application. Some design patterns that have a negative effect on performance, also called performance antipatterns, may become important when evaluating migrating the application to the Cloud. Although there has been work done in the past related to defining performance antipatterns, there has been none that highlights the importance and effects of these performance antipatterns when an application is migrated to Cloud. In this work we present an approach to automatically detect important performance antipatterns in an application, by leveraging static code analysis and information about prospective deployment of the application components on the Cloud. We also experimentally show that these antipatterns may become prominent and pull down the\u00a0\u2026", "num_citations": "6\n", "authors": ["235"]}
{"title": "Adoption and use of new metrics in a large organization: A case study\n", "abstract": " The success of a software development project is linked to the ability of the project team to deliver high quality artifacts within the budget and on schedule. Thus, a holistic and in-process view of various software metrics that help characterize the current health and future trajectory of the project is crucial. However, these metrics need to be at the right level of granularity and be derived objectively from the project environment to be effective and useful. While the metric literature is rich with proposals of specific metrics and their formulation, there are very few studies which discuss how organizations respond to introduction of such metrics and how they are used and adopted. In this paper, we present such a study on a set of metrics embodied by a framework called PIVoT. This study aims at evaluating the impact of PIVoT, a tool for in-process and non-invasive monitoring of project health, and performing a fine-grained\u00a0\u2026", "num_citations": "6\n", "authors": ["235"]}
{"title": "Intent and bot based query guidance\n", "abstract": " According to an example, intent and bot based query guidance may include receiving a query associated with a domain, and identifying, based on an analysis of the query, an intent of the query by extracting an action associated with the query and an entity associated with the query. An intent model associated with the query may be generated based on a mapping of the action and the entity with a domain model of the domain. An intent domain specific language representation of the intent model associated with the query may be generated. Based on an analysis of the intent domain specific language representation, a plurality of bots may be identified, and a parameterized bot chain may be generated to respond to the query. A runtime binding of bots of the parameterized bot chain may be performed, and invoked to generate the response to the query.", "num_citations": "5\n", "authors": ["235"]}
{"title": "Software Development Analytics: Experiences and the Way Forward\n", "abstract": " Software development analytics plays an important role in bridging the gap between purely process-centric software development management and the on-ground realities resulting from the inherent complexities of software development. Lack of high-fidelity data, potential data manipulation by humans, absence of real-time / near real-time analysis and sub-optimal insights design causes issues in governing software development. We have worked with development projects to understand the gaps, and design insights and tools for offering early warnings to different project stakeholders. In this paper, we discuss our approach to designing a insights framework and learning from pilots with industrial software development projects. Going forward our work is influenced by changes in technology and new workforce models. We present them, as they would have a significant impact on the future actionable insights\u00a0\u2026", "num_citations": "5\n", "authors": ["235"]}
{"title": "Insights into component testing process\n", "abstract": " Effective component testing (or commonly termed as Unit Testing) is important to control defect slippage into the testing stage. Often testing teams lack in-process visibility into the effectiveness of ongoing component testing. Using project data such as code coverage and schedule and effort estimates, we generate temporal and rate-based insights into component testing effectiveness. A simple composite metric is used for measuring and forecasting the health of the component testing process. The early warning signals, based on the forecast and associated insights, lead teams to take proactive actions for improving component testing. In our ongoing experimental studies, we have observed that use of these insights cause a substantial reduction in defect slippage.", "num_citations": "5\n", "authors": ["235"]}
{"title": "Partitioning based migration of systems to container and microservice based platforms\n", "abstract": " According to an example, partitioning based migration of systems to container and micro-service based-platforms may include determining, based on an analysis of source code for an application that is to be partitioned, an entity model corresponding to the application, identifying resources associated with the application, and determining a mapping of the identified resources to entities of the entity model. Further, partitioning based migration of systems to container and micro-service based-platforms may include identifying dependencies for each of the mapped resources, generating dependency and control flow metrics for the application, generating affinity values between the mapped resources, generating a resource affinity graph, determining an affinity score between each of the mapped resources, and generating resource clusters that correspond to partitions of the application.", "num_citations": "4\n", "authors": ["235"]}
{"title": "SYSTEM FOR DEVELOPMENT OF IoT SYSTEM ARCHITECTURE\n", "abstract": " A system may include one or more server devices. The system may provide a set of questions, to a user of a user device, to characterize an Internet of things system. The system may obtain responses from the user of the user device associated with each of the set of questions. The system may automatically create an Internet of things system architecture that defines the Internet of things system by applying associated Internet of things system architecture rules to the responses.", "num_citations": "4\n", "authors": ["235"]}
{"title": "Shifting testing beyond the deployment boundary\n", "abstract": " Optimization of software testing has typically relied on a philosophy of'shift left'where the focus is on using automation to start testing as early as possible in a software development life-cycle. With enterprises striving for continual business transformation, it becomes essential to focus on rapid and iterative software development. Moreover, understanding customer reactions, feedback and needs, and translating them as actionable insights to software development teams. This requires testing to'shift right', ie move beyond the deployment boundary, and adopt a data-driven approach leveraging post-release production data and customer feedback. In this position paper we articulate the need for continuous, shift right testing, define a taxonomy for structuring testing types, analyses and data requirements. We end by providing a conceptual framework for applying shift right testing for Digital apps.", "num_citations": "4\n", "authors": ["235"]}
{"title": "System for requirement identification and analysis based on capability model structure\n", "abstract": " A textual analysis system is configured to compare textual content of textual statements. The textual analysis system is configured to score the textual content of a first textual statement and a second textual statement. Based on the score, the textual analysis system may determine a level of correspondence between the first textual statement and the second textual statement. The textual analysis system is configured to generate an interactive visual representation of the correspondence levels between the first statement and the second statement. The visual representation may be transmitted to a display.", "num_citations": "4\n", "authors": ["235"]}
{"title": "CDI: Cost of development index\n", "abstract": " Managing costs and yet delivering high quality is an essential balancing act in software development projects. Usually, cost management is perceived as a process concern, leading to a disjoint view of team costs and delivered quality. We have proposed a new metric, CDI, that integrates the cost parameter with the quality of the code, to provide managers in a coherent understanding of the trade-off between cost management and quality. The metric is integrated in to an automated tool, making it easy for project teams to adopt the metric in real-life large projects.", "num_citations": "4\n", "authors": ["235"]}
{"title": "A Scalable Master-Worker Architecture for PaaS Clouds\n", "abstract": " Clouds provide an attractive infrastructural option to deploy highly-scalable distributed applications. Platform as a Service (PaaS) clouds offer basic software stack and services along with the execution containers to simplify the hosting of user applications. However, traditional many task computing architectures cannot be hosted as-is on current PaaS platforms due to certain limitations. This paper describes a novel modified architecture for master-worker, a well-known many task computing paradigm, to take advantage of the fast scalability provided by PaaS. The architecture is transformed into a multiagent system where the distributed agents use a message broker for communication and to store the computation progress. The agents are capable of dynamically shifting between a master and a worker role based on the information available with a durable message broker. This state-less feature of the agents makes\u00a0\u2026", "num_citations": "4\n", "authors": ["235"]}
{"title": "An Automated Contextual Collaboration approach for Distributed Agile Delivery\n", "abstract": " The Agile way of developing and delivering software systems is gaining mainstream adoption due to the imperatives of a quickly changing technical landscape, business requirements and customer expectations. To truly leverage the power of Agile, big organizations need to be able to utilize distributed teams effectively. However, Agile delivery relies hugely on collaboration among team members and this can become a stumbling block among such geographically dispersed teams. Moreover, in such large projects the development and process layer needs to be monitored for any problematic patterns or events that could potentially cause the Sprints to fail. Here, we describe an automated approach which allows for contextual collaboration in such distributed Agile projects. The approach captures important events from the process and the development environment and uses a rule based approach to then\u00a0\u2026", "num_citations": "3\n", "authors": ["235"]}
{"title": "Test optimization from release insights: an analytical hierarchy approach\n", "abstract": " Software Testing is an essential aspect to ensure software quality, reliability and consistent user experience. Digital applications such as mobile app usually follow rapid software delivery which consists of various releases. It typically uses insights from the development data such as defects, test logs for test execution optimization. Once the application is released and deployed, there is rich availability of untapped heterogeneous data which can also be effectively utilized for the next release test execution optimization. The data from the release includes direct customer feedback, application monitoring data such as user behavioral traces, device usages, release logs. In this position paper, we discuss about the various data sources and the multiple insights which can be derived from them. We also propose a framework which uses Analytical Hierarchy Process to prioritize the tests based on these insights available\u00a0\u2026", "num_citations": "2\n", "authors": ["235"]}
{"title": "Application Layer Encryption for Cloud\n", "abstract": " As we move to the next generation of networks such as Internet of Things (IoT), the amount of data generated and stored on the cloud is going to increase by several orders of magnitude. Traditionally, storage or middleware layer encryption has been used for protecting data at rest. However, such mechanisms are not suitable for cloud databases. More sophisticated methods include user-layer-encryption (ULE) (where the encryption is performed at the end-user's browser) and application-layer-encryption (ALE) (where the encryption is done within the web-app). In this paper, we study security and functionality aspects of cloud encryption and present an ALE framework for Java called JADE that is designed to protect data in the event of a server compromise.", "num_citations": "2\n", "authors": ["235"]}
{"title": "A XaaS Savvy Automated Approach to Composite Applications\n", "abstract": " Applications have evolved significantly over time - from monolithic and self contained, to numerous plug gable apps available on various platforms these days. Modern applications their functionality as services in varying level of granularity and domains. This paradigm of Everything as a Service (XaaS), provides a dynamic environment wherein multiple smaller applications can be rapidly composed to create complex applications. Such composite applications would allow for efficient re-use of the existing applications and their services, instead of more traditional model of building everything from scratch. The intent of this paper is to demonstrate our initial work to implement an end-to-end delivery system in an enterprise scenario. We propose an automated algorithm to utilize a composer's input to match available services and create a composite plan or a manifest which is then used to quickly orchestrate the\u00a0\u2026", "num_citations": "2\n", "authors": ["235"]}
{"title": "Parameter estimation for a reliability growth model for software products\n", "abstract": " Traditionally, the improvement in reliability of a software product with time is attributed to the removal of defects from the software. Many software reliability growth models have been proposed to capture this growth. However in popular software products, the failure rate of the software seems to decrease as perceived by the user, without any actual defect removal or code modification. A new reliability growth model has been proposed to capture this phenomenon. In this model there is an initial failure rate which decays with time to approach a steady state failure value. In this paper we present an analytical approach for estimating the parameters for the model, which predicts the abovementioned phenomenon. We provide detailed equations based on the nonlinear least square regression method for finding the parameters when product failure data is available and also show the application to real data.", "num_citations": "2\n", "authors": ["235"]}
{"title": "Performance and Reliability Analysis of Software Architectures\n", "abstract": " Software performance and reliability are key attributes of systems that provide services to a large number of clients or handle time and mission critical applications. The software architecture of a system is the highest level of abstraction of its structure and the relationships among its components. Analysis of system performance and reliability at the architectural level can be useful for assessing if a proposed architecture can meet the desired specifications, so that the necessary architectural changes can be done, if needed. Such changes are much harder and more expensive to do later.To ensure that a system with a particular architecture meets the performance and reliability requirements, some key issues have to be addressed. These include, evaluating the system performance under the expected workload; if the predicted performance is unsatisfactory, ascertaining the changes needed for achieving the desired\u00a0\u2026", "num_citations": "1\n", "authors": ["235"]}
{"title": "A Multiple Class Prioritized Model for Web Servers\n", "abstract": " The exploding popularity of the World Wide Web has led to exponentially increasing traffic on the Internet. In this paper, we have presented a multiple class model for serving Web requests. We have evaluated the impact of assigning different priorities to different domains on Web document access time for single server as well as multiple servers serving the requests. The priorities of domains can be altered in the supervisory mode on the server side. The main parameter considered here is the average waiting time of requests originating from different domains.", "num_citations": "1\n", "authors": ["235"]}
{"title": "Markov Chains and Queueing Networks\n", "abstract": " Quantitative analysis of computer systems has become very important as they are being used to handle various mission critical and performance intensive applications. In this independent study I studied methods to model computer systems for analyzing them for reliability, availability, and performance metrics. The techniques that were covered include modeling using Discrete Time Markov Chains (DTMC), Continuous Time Markov Chains (CTMC) and Queueing Networks. Each of the topics, which were studied, are very extensive and have many books devoted solely to each one of them. Thus, in this report I present a summary of the important definitions, assumptions, and results pertaining to each one of these as well as provide some handle on using them practically.", "num_citations": "1\n", "authors": ["235"]}