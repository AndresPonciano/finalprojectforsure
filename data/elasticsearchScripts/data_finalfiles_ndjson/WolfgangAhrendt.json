{"title": "Reasoning about abstract state machines: The WAM case study\n", "abstract": " This paper describes the first half of the formal verification of a Prolog compiler with the KIV Karlsruhe Interactive Verifier\" system. Our work is based on BR95, where an operational Prolog semantics is defined using the formalism of Gurevich Abstract State Machines, and then refined in several steps to the Warren Abstract Machine WAM. We define a general translation of sequential Abstract State Machines to Dynamic Logic, which formalizes correctness of such refinement steps as a deduction problem. A proof technique for verification is presented, which corresponds to the informal use of proof maps. 6 of the 12 given refinement steps were verified. We found that the proof sketches given in BR95 hide a lot of implicit assumptions. We report on our experiences in uncovering these assumptions incrementally during formal verification, and the support KIV offers for suchevolutionary'correctness proofs.", "num_citations": "91\n", "authors": ["697"]}
{"title": "A system for compositional verification of asynchronous objects\n", "abstract": " We present a semantics, calculus, and system for compositional verification of Creol, an object-oriented modelling language for concurrent distributed applications. The system is an instance of KeY, a framework for object-oriented software verification, which has so far been applied foremost to sequential Java. Building on KeY characteristic concepts, like dynamic logic, sequent calculus, symbolic execution via explicit substitutions, and the taclet rule language, the presented system addresses functional correctness of Creol models featuring local cooperative thread parallelism and global communication via asynchronous method calls. The calculus heavily operates on communication histories specified by the interfaces of Creol units. Two example scenarios demonstrate the usage of the system. This article extends the conference paper of Ahrendt and Dylla (2009) [5] with a denotational semantics of Creol and an\u00a0\u2026", "num_citations": "59\n", "authors": ["697"]}
{"title": "The WAM case study: Verifying compiler correctness for Prolog with KIV\n", "abstract": " This chapter describes the first half of the formal, machine-supported verification of a Prolog compiler with the KIV system.", "num_citations": "50\n", "authors": ["697"]}
{"title": "Automatic validation of transformation rules for Java verification against a rewriting semantics\n", "abstract": " This paper presents a methodology for automatically validating program transformation rules that are part of a calculus for Java source code verification. We target the Java Dynamic Logic calculus which is implemented in the interactive prover of the KeY system. As a basis for validation, we take an existing SOS style rewriting logic semantics for Java, formalized in the input language of the Maude system. That semantics is \u2018lifted\u2019 to cope with schematic programs like the ones appearing in program transformation rules. The rewriting theory is further extended to generate valid initial states for involved program fragments, and to check the final states for equivalence. The result is used in frequent validation runs over the relevant fragment of the calculus in the KeY system.", "num_citations": "36\n", "authors": ["697"]}
{"title": "Hilbert\u2019s\u2208-Terms in Automated Theorem Proving\n", "abstract": " \u2208-terms, introduced by David Hilbert [8], have the form \u2208x.\u03c6, where x is a variable and \u03c6 is a formula. Their syntactical structure is thus similar to that of a quantified formulae, but they are terms, denoting \u2018an element for which \u03c6 holds, if there is any\u2019.               The topic of this paper is an investigation into the possibilities and limits of using \u2208-terms for automated theorem proving. We discuss the relationship between \u2208-terms and Skolem terms (which both can be used alternatively for the purpose of \u2203-quantifier elimination), in particular with respect to efficiency and intuition. We also discuss the consequences of allowing \u2208-terms in theorems (and cuts). This leads to a distinction between (essentially two) semantics and corresponding calculi, one enabling efficient automated proof search, and the other one requiring human guidance but enabling a very intuitive (i.e. semantic) treatment of \u2208-terms. We give a\u00a0\u2026", "num_citations": "28\n", "authors": ["697"]}
{"title": "Deductive search for errors in free data type specifications using model generation\n", "abstract": " The presented approach aims at identifying false conjectures about free data types. Given a specification and a conjecture, the method performs a search for a model of an according counter specification. The model search is tailor-made for the semantical setting of free data types, where the fixed domain allows to describe models just in terms of interpretations. For sake of interpretation construction, a theory specific calculus is provided. The concrete rules are \u2018executed\u2019 by a procedure known as model generation. As most free data types have infinite domains, the ability of automatically solving the non-consequence problem is necessarily limited. That problem is addressed by limiting the instantiation of the axioms. This approximation leads to a restricted notion of model correctness, which is discussed. At the same time, it enables model completeness for free data types, unlike approaches based on\u00a0\u2026", "num_citations": "19\n", "authors": ["697"]}
{"title": "Verifying (in-) stability in floating-point programs by increasing precision, using smt solving\n", "abstract": " When computing with floating-point numbers, programmers choose a certain floating-point precision (like, for instance, float or double) upfront, for each variable. However, whether the chosen precision is appropriate for the computation at hand, and vice versa, is difficult to judge. One way is to increase the precision, and observe whether the result of the computation changes too much, in which case the computation with the original precisions is considered 'unstable'. This effect may be exhibited with certain inputs, and not with others. With a classical testing approach, inputs that show instability can be very difficult to find. Moreover, testing can only show instability, not stability. In this paper, we present an approach, and its implementation, which can formally prove that an increased precision causes only a limited (quantified) change of the result. Alternatively, if the computation is not stable, the method returns inputs\u00a0\u2026", "num_citations": "18\n", "authors": ["697"]}
{"title": "Real-time java API specifications for high coverage test generation\n", "abstract": " We present the test case generation method and tool KeY-TestGen in the context of real-time Java applications and libraries. The generated tests feature strong coverage criteria, like the Modified Condition/Decision Criterion, by construction. This is achieved by basing the test generation on formal verification techniques, namely the KeY system for Java source code verification. Moreover, we present formal specifications for the classes and methods in the real-time Java API. These specifications are used for symbolic execution when generating tests for real-time Java applications, and for oracle construction when generating tests for realtime Java library implementations. The latter application exhibited a mismatch between a commercial library implementation and the official RTSJ documentation. Even if there is a rationale behind this particular inconsistency, it demonstrates the effectiveness of our method on\u00a0\u2026", "num_citations": "17\n", "authors": ["697"]}
{"title": "Abstract object creation in dynamic logic\n", "abstract": " In this paper we give a representation of a weakest precondition calculus for abstract object creation in dynamic logic, the logic underlying the KeY theorem prover. This representation allows to both specify and verify properties of objects at the abstraction level of the (object-oriented) programming language. Objects which are not (yet) created never play any role, neither in the specification nor in the verification of properties. Further, we show how to symbolically execute abstract object creation.", "num_citations": "15\n", "authors": ["697"]}
{"title": "A verification system for distributed objects with asynchronous method calls\n", "abstract": " We present a verification system for Creol, an object-oriented modeling language for concurrent distributed applications. The system is an instance of KeY, a framework for object-oriented software verification, which has so far been applied foremost to sequential Java. Building on KeY characteristic concepts, like dynamic logic, sequent calculus, explicit substitutions, and the taclet rule language, the system presented in this paper addresses functional correctness of Creol models featuring local cooperative thread parallelism and global communication via asynchronous method calls. The calculus heavily operates on communication histories which describe the interfaces of Creol units. Two example scenarios demonstrate the usage of the system.", "num_citations": "14\n", "authors": ["697"]}
{"title": "Von PROLOG zur WAM, Verifikation der Prozedur ubersetzung mit KIV\n", "abstract": " Die vollst andig formale Veri kation von Compilern ist bisher ein in der Informatik noch kaum bearbeitetes Gebiet. Dies mag daran liegen, da sich daf ur geeignete Formalisierungen der Problemstellung nicht unmittelbar aufdr angen (um das vorsichtig auszudr ucken); zumindest nicht, wenn sie eine handhabbare (!) Basis bilden sollen f ur die Veri kation. Zun achsteinmal ben otigen wir die rigorose De nition einer Semantik sowohl der Quell-als auch der Zielsprache. 1 Beides ist keineswegs eine Selbstverst andlichkeit. 2 Erst dann lat sich ein korrekter Compiler spezi zieren, und zwar in etwa mit der Gleichung: SEM (Db)= 3SEM0 (compile (Db))(1.1)", "num_citations": "10\n", "authors": ["697"]}
{"title": "Verification of Decision Making Software in an Autonomous Vehicle: An Industrial Case Study\n", "abstract": " Correctness of autonomous driving systems is crucial as incorrect behaviour may have catastrophic consequences. Many different hardware and software components (e.g. sensing, decision making, actuation, and control) interact to solve the autonomous driving task, leading to a level of complexity that brings new challenges for the formal verification community. Though formal verification has been used to prove correctness of software, there are significant challenges in transferring such techniques to an agile software development process and to ensure widespread industrial adoption. In the light of these challenges, the identification of appropriate formalisms, and consequently the right verification tools, has significant impact on addressing them. In this paper, we evaluate the application of different formal techniques from supervisory control theory, model checking, and deductive verification to verify\u00a0\u2026", "num_citations": "8\n", "authors": ["697"]}
{"title": "Reasoning about loops using vampire in key\n", "abstract": " We describe symbol elimination and consequence finding in the first-order theorem prover Vampire for automatic generation of quantified invariants, possibly with quantifier alternations, of loops with arrays. Unlike the previous implementation of symbol elimination in Vampire, our work is not limited to a specific programming language but provides a generic framework by relying on a simple guarded command representation of the input loop. We also improve the loop analysis part in Vampire by generating loop properties more easily handled by the saturation engine of Vampire. Our experiments show that, with our changes, the number of generated invariants is decreased, in some cases, by a factor of 20. We also provide a framework to use our approach to invariant generation in conjunction with pre- and post-conditions of program loops. We use the program specification to find relevant invariants as well\u00a0\u2026", "num_citations": "8\n", "authors": ["697"]}
{"title": "Proof-based Test Case Generation\n", "abstract": " KeYTestGen is a white-box test generator for Java methods based on  KeY's program analysis and symbolic execution. KeYTestGen generates a JUnit  test harness (test driver) which does not only initialize method parameters  but also the global state that is defined by the (potentially private)  fields of objects and classes. For example, a complex linked data structure  may be created as test input.  The tests can satisfy different test criteria  such as branch coverage, path coverage, and MC/DC coverage. The user may  also provide a specification in the Java Modeling Language (JML) from which  a test oracle can be generated or which can be used as an abstraction for a  loop or method call.  KeYTestGen can be used either as a simple stand-alone  tool not requiring expert knowledge or it can be used in an advanced way to  support and complement formal verification.", "num_citations": "7\n", "authors": ["697"]}
{"title": "Verification of a Prolog Compiler: First Steps with KIV\n", "abstract": " This paper describes the rst steps of the formal veri cation of a Prolog compiler with the KIV system. We build upon the mathematical de nitions given by B orger and Rosenzweig in BR95]. There an operational semantics of Prolog is de ned using the formalism of Evolving Algebras, and then transformed in several systematic steps to the Warren Abstract Machine (WAM). To verify these transformation steps formally in KIV, a translation of deterministic Evolving Algebras to Dynamic Logic is de ned, which may also be of general interest. With this translation, correctness of transformation steps becomes a problem of program equivalence in Dynamic Logic. We de ne a proof technique for verifying such problems, which corresponds to the use of proof maps in Evolving Algebras. Although the transformation steps are small enough for a mathematical analysis, this is not su cient for a successful formal correctness proof. Such a proof requires to explicitly state a lot of facts, which were only implicitly assumed in the analysis. We will argue that these assumptions cannot be guessed in a rst proof attempt, but have to be lled in incrementally. We report on our experience with thisevolutionary'veri cation process for the rst transformation step, and the support KIV o ers to do such incremental correctness proofs.", "num_citations": "6\n", "authors": ["697"]}
{"title": "Practical aspects of automated deduction for program verification\n", "abstract": " Software is vital for modern society. It is used in many safety- or security-critical applications, where a high degree of correctness is desirable. Over the last years, technologies for the formal specification and verification of software\u2014using logic-based specification languages and automated deduction\u2014have matured and can be expected to complement and partly replace traditional software engineering methods in the future. Program verification is an increasingly important application area for automated deduction. The field has outgrown the area of academic case studies, and industry is showing serious interest. This article describes the aspects of automated deduction that are important for program verification in practise, and it gives an overview of the reasoning mechanisms, the methodology, and the architecture of modern program verification systems.", "num_citations": "4\n", "authors": ["697"]}
{"title": "Using KeY\n", "abstract": " Abstract                              This whole book is about the KeY approach and framework. This chapter now focuses on the KeY system, and that entirely from the user\u2019s perspective. Naturally, the graphical user interface (GUI) will play an important role here. However, the chapter is not all about that. Via the GUI, the system and the user communicate, and interactively manipulate, several artefacts of the framework, like formulae of the used logic, proofs within the used calculus, elements of the used specification languages, among others. Therefore, these artefacts are (in parts) very important when using the system. Even if all of them have their own chapter/section in this book, they will appear here as well, in a somewhat superficial manner, with pointers given to in-depth discussions in other parts.", "num_citations": "4\n", "authors": ["697"]}
{"title": "A basis for model computation in free data types\n", "abstract": " . Abstract data types, specied by some equality logic under the assumption of term generatedness, are calledfree', if terms, built only by constructors, are semantically unique. This paper presents a calculus, intended to search for models of free data type specications. A semantical view is discussed, where the uniqueness of constructor terms ishard wired'. This suggests an explicit reasoning about interpretations instead of performing real equality reasoning. The rules, which depend on signature, constructor denitions and axioms, are formulated as range restricted clauses. This allows toperform'the calculus simply by calling a model generation prover, in particular the MGTP system. This approach is abasis' only, because one of the core problems in model construction, the terminating detection of satisfying models, is not yet solved for the described frame. Perspectives in this issue are briey discussed against the background of using the method for disprovin...", "num_citations": "3\n", "authors": ["697"]}
{"title": "The Approach: Integrating Design and Formal Verification of Java Card Programs\n", "abstract": " This paper reports on the ongoing KeY project aimed at bridging the gap between (a) object-oriented software engineering methods and tools and (b) deductive verification for the development of JAVA CARD programs. In particular, we describe a Dynamic Logic for JAVA CARD and outline a sequent calculus for this logic that axiomatises JAVA CARD and is used in the verification component of the KeY system.", "num_citations": "3\n", "authors": ["697"]}
{"title": "The Key approach: integrating design and formal verification of Java Card programs\n", "abstract": " This paper reports on the ongoing KeY project aimed at bridging the gap between (a) object-oriented software engineering methods and tools and (b) deductive verification for the development of JAVA CARD programs. In particular, we describe a Dynamic Logic for JAVA CARD and outline a sequent calculus for this logic that axiomatises JAVA CARD and is used in the verification component of the KeY system.", "num_citations": "3\n", "authors": ["697"]}
{"title": "Proof transformations from search-oriented into interaction-oriented tableau calculi\n", "abstract": " Logic calculi, and Gentzen-type calculi in particular, can be categorised into two types: search-oriented and interaction-oriented calculi. Both these types have certain inherent characteristics stemming from the purpose for which they are designed. In this paper, we give a general characterisation of the two types and present two calculi that are typical representatives of their respective class. We introduce a method for transforming proofs in the search-oriented calculus into proofs in the interactionoriented calculus, and we demonstrate that the difficulties arising with devising such a transformation do not pertain to the specific calculi we have chosen as examples but are general. We also give examples for the application of our transformation procedure.", "num_citations": "3\n", "authors": ["697"]}
{"title": "Deduktive Fehlersuche in Abstrakten Datentypen\n", "abstract": " Zuallererst m\u00f6chte ich Herrn Prof. Dr. Reiner H\u00e4hnle Dank sagen f\u00fcr die unwahrscheinliche Unterst\u00fctzung und F\u00f6rderung, die er mir sowohl als Betreuer dieser Arbeit als auch in vielerlei anderer Hinsicht hat zuteil werden lassen. Seinem unerm\u00fcdlichen Einsatz, seiner Freude an wissenschaftlicher Arbeit, seinem Teamgeist und nicht zuletzt seinem Vertrauen verdanke ich sehr viel.Ich hatte zudem das Gl\u00fcck, mit Herrn Prof. Dr. Peter H. Schmitt und Herrn Prof. Dr. Wolfram Menzel zwei weitere F\u00f6rderer zu haben. Diese beiden haben es mir \u00fcberhaupt erst erm\u00f6glicht, am Institut f\u00fcr Logik, Komplexit\u00e4t und Deduktionssysteme zu arbeiten. Sie haben mich jederzeit aktiv unterst\u00fctzt und gro\u00dfen Wert auf eine intensive und beiderseitige Zusammenarbeit gelegt. Das dadurch entstehende Klima empfand ich als sehr anregend.", "num_citations": "2\n", "authors": ["697"]}
{"title": "Using the KeY Prover\n", "abstract": " This chapter is a self-contained introduction into the usage of the  KeY prover, a tool for proving formulas of a program logic called  Java Dynamic Logic. It does not assume the reader to have read any  other chapter of the book in advance. Here, we discuss the usage of  the KeY prover in isolation. For a tutorial on the most common  context of the prover, i.e., the KeY verification process, we refer  to the chapter `Formal Verification with KeY: A Tutorial'. The  present chapter takes entirely the user's perspective on the KeY  prover, and the GUI plays an important role. However, we do not only  introduce the various ways of using, and interacting with, the KeY  prover. Rather, the various visible artifacts the prover acts on, in  particular the logic and the taclet language, are introduced on the  side, on demand, and example driven, in a light-weight manner. This  chapter is meant to be read with the KeY system up\u00a0\u2026", "num_citations": "1\n", "authors": ["697"]}