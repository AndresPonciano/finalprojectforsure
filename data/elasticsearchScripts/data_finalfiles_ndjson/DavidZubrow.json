{"title": "Software quality and the capability maturity model\n", "abstract": " Engineering Institute (SEI) were busy putting together the set of ideas that was to become the Capability Maturity Model (CMM) for Software. 1 The CMM adopted the opposite of the quick-fix silver bullet philosophy. It was intended to be a coherent, ordered set of incremental improvements, all having experienced success in the field, packaged into a roadmap that showed how effective practices could be built on one another in a logical progression (see \u201cThe Capability Maturity Model for Software\u201d sidebar). Far from a quick fix, it was", "num_citations": "607\n", "authors": ["1993"]}
{"title": "Maturity questionnaire\n", "abstract": " This package contains a copy of the software process maturity questionnaire. It is intended for those interested in performing and learning about software process appraisals. This version differs in several important ways from its predecessor, A Method for Assessing the Software Capability of Contractors CMUSEI-87-TR-23. The most important difference is that this questionnaire is not an appraisal method itself rather, it is one component that is used in different appraisal methods.Descriptors:", "num_citations": "86\n", "authors": ["1993"]}
{"title": "Standardized testing from the administrative perspective\n", "abstract": " Recent debates over the nature of testing have generated more heat than light, partly because participants often sound as though they have never visited a school building or school district. All too often arguments on this topic tend to be framed in terms of the harm or good an abstract*'someone''does with test scores. We decided that one way to il luminate the issues surrounding stan dardized testing was to talk with school district personnel to learn firsthand what they think about and do with test scores. We talked with 58 administrators in 18 school systems in western Pennsylvania serving more than 124,000 students. Pub lic (urban and suburban), parochial, and private schools were represented in our sample. In every system we talked to the person in charge of standardized testing. We also interviewed other district office personnel who had the opportunity to use or work with tests and test scores, in cluding\u00a0\u2026", "num_citations": "73\n", "authors": ["1993"]}
{"title": "Moving on Up: Data and experience doing CMM-based process improvement\n", "abstract": " An analysis of Software Process Assessment results from 48 organizations undertaking 2 or more assessments is presented in this report. The analysis focuses on the time required to increase process maturity, as well as the most prevalent process issues faced by the 48 organizations. Results of the analysis are used to provide guidance to organizations embarking on a software process improvement effort.", "num_citations": "65\n", "authors": ["1993"]}
{"title": "How good is the software: a review of defect prediction techniques\n", "abstract": " Awareness of the value to project management and process improvement activities of analyzing defect data", "num_citations": "56\n", "authors": ["1993"]}
{"title": "Measures for software product lines\n", "abstract": " This technical note characterizes the status of measurement associated with the operation of a software product line, suggests a small set of measures to support its management, and provides guidance for those establishing measurement activities within a software product line. It is intended to help managers of software product lines develop a set of base measures for tracking those categories of needs most relevant to their organizations products, projects, and processes. The measures suggested here range from relatively mature to those whose general utility have yet to be validated. Therefore, an organization using this paper needs to assess its ability to generate the measures and the value they are likely to return to the organization. In most cases, an organization may wish to start with a subset of the measures described.Descriptors:", "num_citations": "40\n", "authors": ["1993"]}
{"title": "Performance information in school systems: Perspectives from organization theory\n", "abstract": " The nature of performance information is explored empirically through data describing administrator behaviors and preferences, and conceptually through a pure cybernetic model and a more organizationally-realistic administrative model. Implications from the latter model are derived for both school system administrators and school system critics.", "num_citations": "38\n", "authors": ["1993"]}
{"title": "Software process models and project performance\n", "abstract": " In this paper we review the progress in software process research and the role of process improvement in enhancing business outcomes of software projects. We first describe the process view of software development. Next, we review the literature on software process research and discuss some of the leading software process models. The business value of software process improvements and empirical evidence from the software industry are also discussed in this paper. We conclude with a discussion of current challenges in software process research and directions for future research.", "num_citations": "33\n", "authors": ["1993"]}
{"title": "Moving On Up: Data and Experience Doing CMM-Based Software Process Improvement.\n", "abstract": " An analysis of Software Process Assessment results from 48 organizations undertaking 2 or more assessments is presented in this report. The analysis focuses on the time required to increase process maturity, as well as the most prevalent process issues faced by the 48 organizations. Results of the analysis are used to provide guidance to organizations embarking on a software process improvement effort.Descriptors:", "num_citations": "26\n", "authors": ["1993"]}
{"title": "Analysis of architecture evaluation data\n", "abstract": " The output of 18 software architecture evaluations is analyzed. The goal of the analysis is to find patterns in the important quality attributes and risk themes identified in the evaluations. The major results are\u2022A categorization of risk themes.\u2022The observation that twice as many risk themes are risks of \u201comission\u201d as are risks of \u201ccommission\u201d.\u2022A failure to find a relationship between the business and mission goals of a system and the risk themes from an evaluation of that system.\u2022A failure to find a correlation between the domain of a system being evaluated and the important quality attributes for that system.\u2022A wide diversity of names used for various quality attributes.The results of this investigation have application to practitioners by suggesting activities on which developers should put greater focus. They also have application to researchers by suggesting further areas of investigation.", "num_citations": "23\n", "authors": ["1993"]}
{"title": "Quantifying uncertainty in early lifecycle cost estimation (QUELCE)\n", "abstract": " Difficulties with estimating the costs of developing new systems have been well documented, and are compounded by the fact that estimates are now prepared much earlier in the acquisition lifecycle, before there is concrete technical information available on the particular program to be developed. This report describes an innovative synthesis of analytical techniques into a cost estimation method that models and quantifies the uncertainties associated with early lifecycle cost estimation. The method described in this report synthesizes scenario building, Bayesian Belief Network BBN modeling and Monte Carlo simulation into an estimation method that quantifies uncertainties, allows subjective inputs, visually depicts influential relationships among program change drivers and outputs, and assists with the explicit description and documentation underlying an estimate. It uses scenario analysis and design structure matrix DSM techniques to limit the combinatorial effects of multiple interacting program change drivers to make modeling and analysis more tractable. Representing scenarios as BBNs enables sensitivity analysis, exploration of scenarios, and quantification of uncertainty. The methods link to existing cost estimation methods and tools to leverage their cost estimation relationships and calibration. As a result, cost estimates are embedded within clearly defined confidence intervals and explicitly associated with specific program scenarios or alternate futures.Descriptors:", "num_citations": "20\n", "authors": ["1993"]}
{"title": "Measuring software product quality: The ISO 25000 Series and CMMI\n", "abstract": " ObjectivesProvide status on a new Software Product Quality Measurement standard and its connection to CMMI", "num_citations": "20\n", "authors": ["1993"]}
{"title": "Prioritizing alerts from multiple static analysis tools, using classification models\n", "abstract": " Static analysis (SA) tools examine code for flaws without executing the code, and produce warnings (\"alerts\") about possible flaws. A human auditor then evaluates the validity of the purported code flaws. The effort required to manually audit all alerts and repair all confirmed code flaws is often too much for a project's budget and schedule. An alert triaging tool enables strategically prioritizing alerts for examination, and could use classifier confidence. We developed and tested classification models that predict if static analysis alerts are true or false positives, using a novel combination of multiple static analysis tools, features from the alerts, alert fusion, code base metrics, and archived audit determinations. We developed classifiers using a partition of the data, then evaluated the performance of the classifier using standard measurements, including specificity, sensitivity, and accuracy. Test results and overall data\u00a0\u2026", "num_citations": "16\n", "authors": ["1993"]}
{"title": "An investigation of techniques for detecting data anomalies in earned value management data\n", "abstract": " Organizations rely on valid data to make informed decisions. When data integrity is compromised, the veracity of the decision-making process is likewise threatened. Detecting data anomalies and defects is an important step in understanding and improving data quality. The study described in this report investigated statistical anomaly detection techniques for identifying potential errors associated with the accuracy of quantitative earned value management EVM data values reported by government contractors to the Department of Defense. This research demonstrated the effectiveness of various statistical techniques for discovering quantitative data anomalies. The following tests were found to be effective when used for EVM variables that represent cumulative values Grubbs test, Rosner test, box plot, autoregressive integrated moving average ARIMA, and the control chart for individuals. For variables related to contract values, the moving range control chart, moving range technique, ARIMA, and Tukey box plot were equally effective for identifying anomalies in the data. One or more of these techniques could be used to evaluate data at the point of entry to prevent data errors from being embedded and then propagated in downstream analyses. A number of recommendations regarding future work in this area are proposed in this report.Descriptors:", "num_citations": "16\n", "authors": ["1993"]}
{"title": "Software process automation: interviews, survey, and workshop results.\n", "abstract": " This report describes the results of a two-year study of experiences with the adoption and use of software process automation. The work was motivated by a desire to provide insights and guidelines to those planning to implement this technology. The focus of the study was primarily, but not exclusively, on end-user organizations. The study was conducted in three stages First, in-depth interviews were conducted to assess the state of the practice. Second, a survey questionnaire was distributed to a wider number of organizations to obtain more quantitative data. The populations in these two groups turned out to be quite different-a fact that we believe enriches the content of this report. Finally, a one-day workshop was held, the objective of which was to explore with practitioners why the gap between the theory and practice of software process automation is as large as it is. A previous report by Alan Christie, et al. Christie 96 documented the results of the in-depth interviews in detail. This report now summarizes the results of the interviews, and describes in more detail the questionnaire survey and the workshop. It also provides both insight for process automation tool developers and guidelines for adoption to process-automation end users.Descriptors:", "num_citations": "16\n", "authors": ["1993"]}
{"title": "Current trends in adoption of the CMMI/spl reg/Product Suite\n", "abstract": " This paper examines the current stage of adoption of the Capability Maturity Model Integration (CMMI) Product Suite. It is based on appraisal reports submitted to and processed by the Software Engineering Institute (SEI/sup SM/) as of July 10, 2003. Relevant appraisal data-including organization type, geographic distribution, and appraisal history-are used to describe CMMI adoption and use patterns. This paper also explains some characteristics of the appraisal process and obtained results.", "num_citations": "15\n", "authors": ["1993"]}
{"title": "The measurement and analysis process area in cmmi\n", "abstract": " In December, 2000, the CMMI Project released the Capability Maturity Model\u00ae-Integrated (CMMI SM) for Systems Engineering/Software Engineering, Version 1.02. A previous article in this newsletter described the CMMI. One new feature contained in this model is the Measurement and Analysis Process Area.\" The purpose of Measurement and Analysis is to develop and sustain a measurement capability that is used to support management information needs.\" This purpose for measurement is broader than what\u2019s mentioned in the Software CMM\u00ae(SW-CMM) model, which primarily addressed measurement and analysis via the practices within the Measurement and Analysis common feature of the model. The scope of the Measurement and Analysis common feature was noted as the\"\u2026 practices that are necessary to determine status related to the process. Measurements included in this common feature are used\u00a0\u2026", "num_citations": "11\n", "authors": ["1993"]}
{"title": "Software Process Automation: Experiences from the Trenches.\n", "abstract": " Software process automation is a new technology with significant promise. However practical experience in the field is still limited and there appears to be a variety of potential barriers to its use. The objective of this empirical study is to document current practical experience and to identify what works and what does not. Lessons learned from the study will be disseminated to help others who wish to implement the technology. This report documents results from the first phase of the study in which 14 in-depth interviews were conducted. Personnel interviewed were involved in projects in which process-centered environments were developed and adopted.Descriptors:", "num_citations": "11\n", "authors": ["1993"]}
{"title": "Justification of a Pattern for Detecting Intellectual Property Theft by Departing Insiders\n", "abstract": " This paper describes an analysis that justifies applying the pattern Increased Review for Intellectual Property IP Theft by Departing Insiders. The pattern helps organizations plan, prepare, and implement a strategy to mitigate the risk of insider theft of IP. The analysis shows that organizations can reduce their risk of insider theft of IP through increased review of departing insiders actions during a relatively small window of time prior to their departure. Preliminary research results show that approximately 70 of insider IP thieves can be caught by following the patterns recommendation of reviewing insiders actions for theft events during only the last two months of their employment. These results provide practical guidance for practitioners wishing to fine tune the application of the pattern for their organizations. Increased Review for IP Theft by Departing Insiders is part of the CERTregistered Insider Threat Centers evolving library of enterprise architectural patterns for mitigating the insider threat, based on the Centers collected data. The Centers larger goal is to foster greater organizational resilience to insider threat, using repeated application of patterns from the library.Descriptors:", "num_citations": "10\n", "authors": ["1993"]}
{"title": "Software quality requirements and evaluation, the ISO 25000 series\n", "abstract": " BackgroundThis presentation reviews the latest developments with the ISO 25000 SQuaRE series of standards. This series on Software Quality Requirements and Evaluation (SQuaRE) is an effort to harmonize ISO 9126 and ISO 14598. The information presented here is based on the current state of the standards/", "num_citations": "10\n", "authors": ["1993"]}
{"title": "Using capture-recapture models for the reinspection decision\n", "abstract": " Capture-recapture (CR) models have been proposed as an objective method for improving the effectiveness of software inspections. CR models were originally developed to estimate the size of animal populations. In software, they have been used to estimate the number of defects in an inspected artifact. This estimate can be another source of information for deciding whether the artifact requires a reinspection to improve the phase containment of defects. This article describes a research project that produced a decision model for the reinspection decision. The resulting decision model yielded significant improvement in determining whether an artifact should be reinspected.", "num_citations": "10\n", "authors": ["1993"]}
{"title": "Case Study: A Measurement Program for Product Lines\n", "abstract": " The Naval Undersea Warfare Center NUWC Division Newport Ranges, Engineering, and Analysis Department applied product line practices in the development of systems for the Navy test ranges it supports. To gauge the success of its product line effort, NUWC must be able to measure the effectiveness of the product line approach compared to more traditional development approaches. To do this, NUWC established a software measurement team to develop and monitor a measurement program. The team includes representatives from programs using the NUWC core asset base, RangeWare. Four projects are currently contributing to the measurement program. This report documents NUWCs approach for measurement by describing the Goal-Driven Software Measurement approach adopted by the test range product line effort and by providing early results of the measurement program.Descriptors:", "num_citations": "9\n", "authors": ["1993"]}
{"title": "Benchmarking software organizations\n", "abstract": " model (such as the Capability Maturity Model framework). Although many consider the assessment of organizational practices against a reference model to be a form of benchmarking, other special issues of IEEE Software recently covered that issue (\u201cProcess Maturity,\u201d July/Aug. 2000, and \u201cSoftware Estimation,\u201d Nov./Dec. 2000). We decided to focus on the two ideas historically recognized as benchmarking in other fields:\u25a0 comparing an organization\u2019s quantitative performance with its peers (typically using an industry database), and\u25a0 comparing the processes of cooperating organizations to identify and transfer \u201cbest practices.\u201d", "num_citations": "9\n", "authors": ["1993"]}
{"title": "Intergrating measurement with improvement: An action-oriented approach: Experience report\n", "abstract": " ABSTRACT In 1986, Science Applications International Corporation (SAIC) was tasked to design, develop, deploy, and maintain a health care system. Over the last ten years, extensive measurement data has been collected and analyzed. By setting goals in terms of a few key indicators, establishing baselines for those indicators, and measuring success in terms of the baseline, management easily monitors development trends and the impacts of process improvement activities. This paper describes the measurement program implemented within SAIC's health care software development organization, illustrates how the measurements are used to influence process improvement, and concludes with general observations and lessons learned.", "num_citations": "9\n", "authors": ["1993"]}
{"title": "Measures in Support of Evolutionary Acquisition\n", "abstract": " The intent of this paper is to identify what measures are necessary to aid an acquisition agency and a contractor when its decided that a program should follow an evolutionary acquisition strategy. Evolutionary acquisition is a strategy that develops and deploys a core capability with the intent to field additional capabilities as stakeholder needs, expectations, constraints, and interfaces are better understood.Descriptors:", "num_citations": "6\n", "authors": ["1993"]}
{"title": "Can you trust your data? establishing the need for a measurement and analysis infrastructure diagnostic\n", "abstract": " An organizations measurement and analysis infrastructure directly Impacts the quality of the decisions made by people at all organizational levels Ensuring information quality is a challenge for most organizations-partly because they might not be fully aware of their own data quality levels Without this information they cannot know the full business impact of poor or unknown data quality or determine how to begin improving their data This report describes common errors in measurement and analysis and the need for a criterion-based assessment method that will allow organizations to evaluate key characteristics of their measurement programs.Descriptors:", "num_citations": "4\n", "authors": ["1993"]}
{"title": "CMMI High Maturity Measurement and Analysis Workshop Report: March 2008\n", "abstract": " Organizations are increasingly looking for guidance on what it takes to implement Capability Maturity Model Integration CMMI high maturity practices and how to sustain their momentum for improvement. As high maturity organizations work to improve their use of measurement and analysis, they often look to examples of successful implementations for guidance. In response to the need for clarification and guidance on implementing measurement and analysis in the context of high maturity processes, members of the SEI s Software Engineering Measurement and Analysis SEMA initiative organized a workshop at the 2008 SEPG North America conference to bring leaders in the field together at a forum on the topic. Other workshops will be held as part of an ongoing series to allow high maturity organizations to share best practices and case studies.Descriptors:", "num_citations": "4\n", "authors": ["1993"]}
{"title": "Empirical Methods\n", "abstract": " /gray exch def/start exch def/rotval exch def/mode exch def findfont/infont exch def/printme exch def", "num_citations": "3\n", "authors": ["1993"]}
{"title": "Editors' Introduction: Should You Trust Your Data?\n", "abstract": " Today information is often taken at face value without much consideration for the quality of the data it's based on, but interest in data quality is growing. A recent report published by the SEI on the quality and use of data in the Department of Defense (DoD) identifies the increased focus on data quality within the DoD (Kasunic, Zubrow, and Harper 2011). The report also makes several recommendations for improvement that could also be applied commercially.", "num_citations": "2\n", "authors": ["1993"]}
{"title": "Issues and Opportunities for Improving the Quality and Use of Data in the Department of Defense\n", "abstract": " The Department of Defense DoD is becoming increasingly aware of the importance of data quality to its operations, leading to an interest in methods and techniques that can be used to determine and improve the quality of its data. The Office of the Secretary of Defense for Acquisition, Technology, and Logistics OSD ATL, Director, Defense Research Engineering DDRE sponsored a workshop to bring together leading researchers and practitioners to identify opportunities for research focused on data quality, data analysis, and data use. Seventeen papers were accepted for presentation during the workshop. During workshop discussions participants were asked to identify challenging areas that would address technology gaps and to discuss research ideas that would support future DoD policies and practices. The Software Engineering Institute formed three primary recommendations for areas of further research from the information produced at the workshop. These areas were integrating data from disparate sources, employing provenance analytics, and developing models, methods, and tools that support data quality by design.Descriptors:", "num_citations": "2\n", "authors": ["1993"]}
{"title": "System of Systems Integration Cost Driver Research\n", "abstract": " System of Systems Integration Cost Driver Research Page 1 Sponsored by the US Department of Defense \u00a9 2004 by Carnegie Mellon University page 1 Pittsburgh, PA 15213-3890 Carnegie Mellon Software Engineering Institute System of Systems Integration Cost Driver Research Dave Zubrow February 2004 Page 2 Report Documentation Page Form Approved OMB No. 0704-0188 Public reporting burden for the collection of information is estimated to average 1 hour per response, including the time for reviewing instructions, searching existing data sources, gathering and maintaining the data needed, and completing and reviewing the collection of information. Send comments regarding this burden estimate or any other aspect of this collection of information, including suggestions for reducing this burden, to Washington Headquarters Services, Directorate for Information Operations and Reports, 1215 Jefferson \u2026", "num_citations": "2\n", "authors": ["1993"]}
{"title": "CMMI Appraisal Results\n", "abstract": " CMMI Appraisal Results Page 1 \u00a9 2003 by Carnegie Mellon University Version 1 Page 1 Pittsburgh, PA 15213-3890 Sponsored by the US Department of Defense \u00a9 2003 by Carnegie Mellon University CMMI Appraisal Results SEPG 2003 February 25, 2003 Dave Zubrow Software Engineering Institute SM SCAMPI, SCAMPI Lead Appraiser, SEPG, and SEI are service marks of Carnegie Mellon University. \u00ae CMMI, Capability Maturity Model, and CMM are registered in the US Patent and Trademark Office by Carnegie Mellon University. Page 2 Report Documentation Page Form Approved OMB No. 0704-0188 Public reporting burden for the collection of information is estimated to average 1 hour per response, including the time for reviewing instructions, searching existing data sources, gathering and maintaining the data needed, and completing and reviewing the collection of information. Send comments regarding \u2026", "num_citations": "2\n", "authors": ["1993"]}
{"title": "Causal Models for Software Cost Prediction and Control (SCOPE)\n", "abstract": " Why Causal Learning Estimating and controlling program costs benefits from causal knowledge of program dynamics. Regression does not distinguish between correlation and causation. Causal knowledge is actionable knowledge. Causal discovery is becoming practical and is supported with innovative tools and algorithms.Descriptors:", "num_citations": "1\n", "authors": ["1993"]}
{"title": "Quantifying uncertainty for early life cycle cost estimates\n", "abstract": " Extensive cost overruns in major defense programs are common, and studies have identified poor cost estimation as a main contributor. Research and experience have identified several factors associated with poor cost estimates. These include the following 1 optimistic expectations about the programs scope and technology such that it can be delivered on schedule and within budget 2 the enormous amount of unknowns and uncertainty that exist when these estimates are made about large-scale, unprecedented systems that take years to develop and deploy and 3 the heavy reliance, of necessity, on expert judgment. In this paper, we describe a new, integrative approach for pre-Milestone A cost estimation called quantifying uncertainty in early life cycle cost estimation QUELCE. QUELCE synthesizes scenario building, Bayesian belief network modeling, and Monte Carlo simulation into an estimation method that quantifies uncertainties, allows subjective inputs, visually depicts influential relationships among change drivers and outputs, and assists with explicit description and documentation underlying an estimate. We use scenario analysis and dependency structure matrix techniques to limit the combinatorial effects of multiple interacting program change drivers to make modeling and analysis more tractable. Finally, we describe results and insights gained from applying the method retrospectively to a major defense program.Descriptors:", "num_citations": "1\n", "authors": ["1993"]}
{"title": "Programmatic and Constructive Interdependence: Emerging Insights and Predictive Indicators of Development Resource Demand\n", "abstract": " The challenges program managers encounter in attempting to deliver programs on time and on budget are well substantiated. A significant driver of the turbulence experienced by acquisition programs today is the transformation to joint capabilities. This report describes a series of ongoing research efforts, sponsored by the Office of the Secretary of Defense OSD, that investigated the role of interdependence in the acquisition of major defense acquisition programs. The overall goal of the research was to identify, quantify, and assess the degree of programmatic and constructive interdependence and to assess the effects of interdependence on program risk. A number of important findings and noteworthy insights were discovered as programs were examined in light of their interdependencies with other programs. The results indicate that an expanded definition of interdependencies along with the incorporation of network analysis tools may provide important insights into program performance in a joint capability arena.Descriptors:", "num_citations": "1\n", "authors": ["1993"]}
{"title": "A tutorial for building CMMI process performance models\n", "abstract": " THIS MATERIAL OF CARNEGIE MELLON UNIVERSITY AND ITS SOFTWARE ENGINEERING INSTITUTE IS FURNISHED ON AN \u201cAS-IS\" BASIS. CARNEGIE MELLON UNIVERSITY MAKES NO WARRANTIES OF ANY KIND, EITHER EXPRESSED OR IMPLIED, AS TO ANY MATTER INCLUDING, BUT NOT LIMITED TO, WARRANTY OF FITNESS FOR PURPOSE OR MERCHANTABILITY, EXCLUSIVITY, OR RESULTS O SS O U OS O C, C US, O SU S OBTAINED FROM USE OF THE MATERIAL. CARNEGIE MELLON UNIVERSITY DOES NOT MAKE ANY WARRANTY OF ANY KIND WITH RESPECT TO FREEDOM FROM PATENT, TRADEMARK, OR COPYRIGHT INFRINGEMENT.", "num_citations": "1\n", "authors": ["1993"]}
{"title": "Can You Trust Your Data? Measurement and Analysis Infrastructure Diagnosis\n", "abstract": " Poor estimation Ineffective process change instead of process improvement Improper architecture and design decisions driving up the lifecycle cost and reducing the useful life of the product Ineffective and inefficient testing causing issues with time to market, field quality and development costs Products that are painful and costly to use within real-life usage profiles", "num_citations": "1\n", "authors": ["1993"]}
{"title": "Acquisition pilot: Product line acquisition and measurement at nuwc\n", "abstract": " \u2022 NUWC has established measurement goals and indicator\u2022 Tracking effort data from Off-board Advanced System Stimulus (OASYS) project", "num_citations": "1\n", "authors": ["1993"]}
{"title": "Benchmarking Process Maturity\n", "abstract": " SEI, CMM Integration, and SCAMPI are service marksSM of Carnegie Mellon University. organizations that may or may not be relevant. In addition, averages do not reveal the variability that goes into their computation. So as a general guide, we would like to know the characteristics of the organizations that make up the reference benchmark and the variability in their performance.The process assessment data in this article come from CBA IPI assessments using the Software CMM V1. 1. These assessments were conducted by teams trained in the assessment method and led by an SEI-authorized assessor. The teams typically investigated four to six projects while including representatives from additional projects in group interviews. The interviews conducted during an assessment will involve project leaders, middle managers, and practitioners. Often team members will interview 40 or more representatives of an organization. The results reported to the", "num_citations": "1\n", "authors": ["1993"]}
{"title": "Framework Document: Model-Based Verification Pilot Study\n", "abstract": " This Pilot Study Framework document describes the processes, activities, artifacts, and deliverables associated with an Engineering Practice Investigation that applies Model-Based Verification MBV.Descriptors:", "num_citations": "1\n", "authors": ["1993"]}
{"title": "Measures for Software Product Lines: A White Paper for the Office of the Undersecretary of Defense, Science and Technology, Software Engineering\n", "abstract": " This paper is one of a series commissioned by the Department of the Undersecretary of Defense, Science and Technology DUSD ST that characterizes the status of measurement associated with a particular aspect of software engineering. The specific focus of this paper is measures for software product lines.Descriptors:", "num_citations": "1\n", "authors": ["1993"]}