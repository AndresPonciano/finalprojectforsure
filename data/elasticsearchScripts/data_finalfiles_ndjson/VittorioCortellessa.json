{"title": "Early reliability assessment of UML based software models\n", "abstract": " The ability to validate software systems early in the development lifecycle is becoming crucial. While early validation of functional requirements is supported by well known approaches, the validation of non-functional requirements, such as reliability, is not. Early assessment of non-functional requirements can be facilitated by automated transformation of software models into (mathematical) notations suitable for validation. These type of validation approaches are usually as\" transparent\" to the developers as possible. Consequently, most software developers find them user friendly and easy to adopt. In this paper we introduce a methodology that starts with the analysis of the UML model of software architecture followed by the bayesian framework for reliability prediction. We utilize three different types of UML diagrams: Use Case, Sequence and Deployment diagrams. They are annotated with reliability related\u00a0\u2026", "num_citations": "191\n", "authors": ["468"]}
{"title": "A bayesian approach to reliability prediction and assessment of component based systems\n", "abstract": " It is generally believed that component-based software development leads to improved application quality, maintainability and reliability. However most software reliability techniques model integrated systems. These models disregard system's internal structure, taking into account only the failure data and interactions with the environment. We propose a novel approach to reliability analysis of component-based systems. Reliability prediction algorithm allows system architects to analyze reliability of the system before it is built, taking into account component reliability estimates and their anticipated usage. Fully integrated with the UML, this step can guide the process of identifying critical components and analyze the effect of replacing them with the more/less reliable ones. Reliability assessment algorithm, applicable in the system test phase, utilizes these reliability predictions as prior probabilities. In the Bayesian\u00a0\u2026", "num_citations": "177\n", "authors": ["468"]}
{"title": "Model-based software performance analysis\n", "abstract": " Poor performance is one of the main quality-related shortcomings that cause software projects to fail. Thus, the need to address performance concerns early during the software development process is fully acknowledged, and there is a growing interest in the research and software industry communities towards techniques, methods and tools that permit to manage system performance concerns as an integral part of software engineering. Model-based software performance analysis introduces performance concerns in the scope of software modeling, thus allowing the developer to carry on performance analysis throughout the software lifecycle. With this book, Cortellessa, Di Marco and Inverardi provide the cross-knowledge that allows developers to tackle software performance issues from the very early phases of software development. They explain the basic concepts of performance analysis and describe the most representative methodologies used to annotate and transform software models into performance models. To this end, they go all the way from performance primers through software and performance modeling notations to the latest transformation-based methodologies. As a result, their book is a self-contained reference text on software performance engineering, from which different target groups will benefit: professional software engineers and graduate students in software engineering will learn both basic concepts of performance modeling and new methodologies; while performance specialists will find out how to investigate software performance model building.", "num_citations": "166\n", "authors": ["468"]}
{"title": "A modeling approach to analyze the impact of error propagation on reliability of component-based systems\n", "abstract": " We present a novel approach to the analysis of the reliability of a component-based system that takes into account an important architectural attribute, namely the error propagation probability. This is the probability that an error, arising somewhere in the system, propagates to other components, possibly up to the system output. As we show in the paper, this attribute may heavily affect decisions on crucial architectural choices. Nonetheless, it is often neglected in modeling the reliability of component-based systems. Our modeling approach provides a useful support to the reliability engineering of component-based systems, since it can be used to drive several significant tasks, such as: (i) placing error detection and recovery mechanisms, (ii) focusing the design, implementation and selection efforts on critical components, (iii) devising cost-effective testing strategies. We illustrate the approach on an ATM\u00a0\u2026", "num_citations": "164\n", "authors": ["468"]}
{"title": "An optimization framework for \u201cbuild-or-buy\u201d decisions in software architecture\n", "abstract": " Building a software architecture that meets functional requirements is a quite consolidated activity, whereas keeping high quality attributes is still an open challenge. In this paper we introduce an optimization framework that supports the decision whether to buy software components or to build them in-house upon designing a software architecture. We devise a non-linear cost/quality optimization model based on decision variables indicating the set of architectural components to buy and to build in order to minimize the software cost while keeping satisfactory values of quality attributes. From this point of view, our tool can be ideally embedded into a Cost Benefit Analysis Method to provide decision support to software architects. The novelty of our approach consists in building costs and quality attributes on a common set of decision variables related to software development. We start from a special case of the\u00a0\u2026", "num_citations": "111\n", "authors": ["468"]}
{"title": "Towards a UML profile for QoS: a contribution in the reliability domain\n", "abstract": " Non-functional attributes of software/hardware systems are aspects of interest to embed in modeling notations. In the last few years, extensions of UML in this direction have been proposed, and some of them have been recently adopted as final specifications, such as the UML Profile for Schedulability, Performance, and Time. In this paper we intend to further contribute to the integration of UML with non-functional aspects, and we devise a lightweight extension of UML (i.e., stereotypes, tagged values and constraints) to represent issues related to the reliability modeling of component-based systems. To a certain extent we lay on other profiles to make easier the embedding of such issues and to work toward a unifying UML profile for Quality of Service and Fault Tolerance. Our extensions mostly concern the fault forecasting task, which enables the specification of models describing the failure rates of components and\u00a0\u2026", "num_citations": "85\n", "authors": ["468"]}
{"title": "From UML models to software performance results: an SPE process based on XML interchange formats\n", "abstract": " The SPE process uses multiple performance assessment tools depending on the state of the software and the amount of performance data available. This paper describes two XML based interchange formats that facilitate using a variety of performance tools in a plug-and-play manner thus enabling the use of the tool best suited to the analysis. The Software Performance Model Interchange Format (S-PMIF) is a common representation that is used to exchange information between (UML-based) software design tools and software performance engineering tools. On the other hand, the performance model interchange format (PMIF 2.0) is a common representation for system performance model data that can be used to move models among system performance modeling tools that use a queueing network model paradigm. This paper first defines an XML based S-PMIF based on an updated SPE meta-model Then it\u00a0\u2026", "num_citations": "78\n", "authors": ["468"]}
{"title": "Reliability modeling and analysis of service-oriented architectures\n", "abstract": " Service selection and composition are central activities in service-oriented computing, and the prediction of the QoS attributes of a Service-Oriented Architecture (SOAs) plays a key role to appropriately drive these activities. Software composition driven by QoS criteria (e.g., optimization of performance, maximization of reliability) has been mostly studied in the Component-Based Software Engineering domain, whereas methodological approaches are not well established in the service-oriented area. Indeed, prediction methodologies for service-oriented systems should be supported by automated and efficient tools to remain compliant with the requirement that most of the activities connected with service discovery and composition must be performed automatically. Moreover, the adopted implementation should respect the autonomy and independence of each provider of the services we want to include in our\u00a0\u2026", "num_citations": "65\n", "authors": ["468"]}
{"title": "Automated selection of software components based on cost/reliability tradeoff\n", "abstract": " Functional criteria often drive the component selection in the assembly of a software system. Minimal distance strategies are frequently adopted to select the components that require minimal adaptation effort. This type of approach hides to developers the non-functional characteristics of components, although they may play a crucial role to meet the system specifications. In this paper we introduce the CODER framework, based on an optimization model, that supports \u201cbuild-or-buy\u201d decisions in selecting components. The selection criterion is based on cost minimization of the whole assembly subject to constraints on system reliability and delivery time. The CODER framework is composed by: an UML case tool, a model builder, and a model solver. The output of CODER indicates the components to buy and the ones to build, and the amount of testing to be performed on the latter in order to achieve the desired\u00a0\u2026", "num_citations": "64\n", "authors": ["468"]}
{"title": "A framework for automated generation of architectural feedback from software performance analysis\n", "abstract": " A rather complex task in the performance analysis of software architectures has always been the interpretation of the analysis results and the generation of feedback that may help developers to improve their architecture with alternative \u201dbetter performing\u201d solutions. This is due, on one side, to the fact that performance analysis results may be rather complex to interpret (e.g., they are often collections of different indices) and, on the other side, to the problem of coupling the \u201dright\u201d architectural alternatives to results, that are the alternatives that allow to improve the performance by resolving critical issues in the architecture. In this paper we propose a framework to interpret the performance analysis results and to propose alternatives to developers that improve their architectural designs. The interpretation of results is based on the ability to automatically recognize performance anti-patterns in the software\u00a0\u2026", "num_citations": "49\n", "authors": ["468"]}
{"title": "Automatic derivation of software performance models from case documents\n", "abstract": " Lifecycle validation of software performance (or prediction of the product ability to satisfy the user performance-requirements) is based on the automatic derivation of software performance models from CASE documents or rapid prototypes.This paper deals with the CASE document alternative. After a brief overview of existing automatic derivation methods, it introduces a method that unifies existing techniques that use CASE documents.The method is step-wise clear, can be used from the early phases of the software lifecycle, is distributed-software oriented, and can be easily incorporated into modern (e.g., UML-based) CASE tools.The method enables the software designer with no specific knowledge of performance theory to predict at design time the performance of various final product alternatives. The designer does only need to feed the CASE documents into the performance model generator.The paper carries\u00a0\u2026", "num_citations": "46\n", "authors": ["468"]}
{"title": "Integrating software models and platform models for performance analysis\n", "abstract": " System performance is a key factor to take into account throughout the software life cycle of modern computer systems, mostly due to their typical characteristics such as distributed deployment, code mobility, and platform heterogeneity. An open challenge in this direction is to integrate the performance validation as a transparent and efficient activity in the system development process. Several methodologies have been proposed to automate the transformation of software/hardware models into performance models. In this paper, we do not take a transformational approach; rather, we present a framework to integrate a software model with a platform model in order to build a performance model. Performance indices are obtained from simulation of the resulting performance model. Our framework provides a library of predefined resource models, model annotation and integration procedures, and simulation support\u00a0\u2026", "num_citations": "44\n", "authors": ["468"]}
{"title": "How far are we from the definition of a common software performance ontology?\n", "abstract": " The recent approaches to software performance modeling and validation share the idea of annotating software models with information related to performance (eg operational profile) and transforming the annotated model into a performance model (eg a Stochastic Petri Net). Up to date, no standard has been defined to represent the information related to performance in software artifacts, although clear advantages in tool interoperability and model transformations would stem from it. This paper is aimed at questioning whether a software performance ontology (ie a standard set of concepts and relations) is achievable or not. We consider three meta-models defined for software performance, that are the Schedulability, Performance and Time profile of UML, the Core Scenario Model and the Software Performance Engineering meta-model. We devise two approaches to the creation of an ontology:(i) bottom-up, that\u00a0\u2026", "num_citations": "42\n", "authors": ["468"]}
{"title": "Integrating performance and reliability analysis in a non-functional MDA framework\n", "abstract": " Integration of non-functional validation in Model-Driven Architecture is still far from being achieved, although it is ever more necessary in the development of modern software systems. In this paper we make a step ahead towards the adoption of such activity as a daily practice for software engineers all along the MDA process. We consider the Non-Functional MDA framework (NFMDA) that, beside the typical MDA model transformations for code generation, embeds new types of model transformations that allow the generation of quantitative models for non-functional analysis. We plug into the framework two methodologies, one for performance analysis and one for reliability assessment, and we illustrate the relationships between non-functional models and software models. For this aim, Computation Independent, Platform Independent and Platform Specific Models are also defined in the non-functional\u00a0\u2026", "num_citations": "37\n", "authors": ["468"]}
{"title": "A conceptual model for adaptable context-aware services\n", "abstract": " The rapid evolution of (Web) service technologies is leading services to play a central role in the software development process. The number of service-based applications is quickly increasing, and they are subject to continuous evolution to meet ever more demanding requirements, such as: adaptability to different types of devices, optimal exploitation of available resources to achieve a certain level of Quality of Service. In addition, Service Oriented Architectures are replacing Software Architectures as a main software model that allows to represent and validate functional and non-functional properties of the system. This paper content originates from the basic goal of the PLASTIC project, where we work to provide tools and methodologies to develop service-based applications that are adaptable to the context and able to offer the best tradeoff between offered QoS (from the platform) and required QoS (from users). The first step towards this goal consists in building a common dictionary. Here we propose a first version of the PLASTIC dictionary, that is a conceptual model that embeds three original aspects with respect to other existing service models:(i) relationships between components and services are well defined while keeping feasible the composability in both domains,(ii) context is defined and related to the other concepts of the model,(iii) QoS characteristics do not explicitly appear, but are scattered among several concepts. The latter two aspects induce adaptability to the context in the services built within our conceptual model.", "num_citations": "37\n", "authors": ["468"]}
{"title": "Software performance model-driven architecture\n", "abstract": " Model transformations in MDA mostly aim at stepping from a Platform Independent Model (PIM) to a Platform Specific Model (PSM) from a functional viewpoint. In order to develop high quality software products, non-functional attributes (such as performance) must be taken into account. In this paper we extend the canonical view of the MDA approach to embed additional types of models that allow to structure a Model Driven approach keeping into account performance issues. We define the relationships between MDA typical models and the newly introduced models, as well as relationships among the latter ones. In this extended framework new types of model-to-model transformations also need to be devised. We place an existing methodology for transforming software models into performance models within the scope of this framework.", "num_citations": "33\n", "authors": ["468"]}
{"title": "Non-functional modeling and validation in model-driven architecture\n", "abstract": " Software models are, in most cases, considered as functional abstractions of systems. They represent the backbone of transformational processes aimed at code generation. On the other end, modeling is a traditional activity in the field of non-functional validation of software/hardware systems, although non-functional models found on different notations (such as Petri Nets) and embed additional information (such as the operational profile) with respect to software models. In this paper we widen the scope of model-driven architecture by introducing a Non-Functional-MDA framework that, beside the typical model transformations for code generation, embeds new types of model transformations that allow to generate non-functional models. For an uniform integration of these practices, we define Platform Independent/Specific Models in the non-functional domain.", "num_citations": "30\n", "authors": ["468"]}
{"title": "Grain sensitive event scheduling in time warp parallel discrete event simulation\n", "abstract": " Several scheduling algorithms have been proposed to determine the next event to be executed on a processor in a time warp parallel discrete event simulation. However none of them is specifically designed for simulations where the execution time (or granularity) for different types of events has large variance. We present a grain sensitive scheduling algorithm which addresses this problem. In our solution, the scheduling decision depends on both timestamp and granularity values with the aim at giving higher priority to small grain events even if their timestamp is not the lowest one (i.e. the closest one to the commitment horizon of the simulation). This implicitly limits the optimism of the execution of large grain events that, if rolled back, would produce a large waste of CPU time. The algorithm is adaptive in that it relies on the dynamic recalculation of the length of a simulated time window within which the timestamp\u00a0\u2026", "num_citations": "28\n", "authors": ["468"]}
{"title": "Modeling resources in a UML-based simulative environment\n", "abstract": " The importance of early performance assessment grows as software systems increase in terms of size, logical distribution and interaction complexity. Lack of time on the side of software developers, as well as distance between software model notations and performance model representation do not help to build an integrated software process that takes into account, from the early phases of the lifecycle, nonfunctional requirements. We work towards filling this gap by extending the capabilities of a simulative environment developed for the UML notation. Our intent is to introduce new stereotypes representing performance related items, such as resource types and job dispatchers. They allow the software designers to homogeneously represent a software architecture integrated with a running platform as well as parameterized with the resource demand that the components require.", "num_citations": "25\n", "authors": ["468"]}
{"title": "MOSES: MOdeling Software and platform architEcture in UML 2 for Simulation-based performance analysis\n", "abstract": " Performance analysis at the architectural level has been a widely studied topic in the last few years. Automated solutions to this problem, such as the ones based on model transformations, would allow early detection of performance critical aspects in the software lifecycle. In this paper, building on top of our existing methodology [11] that aims at integrating software architectural models and platform models in the same notation (UML-RT), we present a new implementation based on the UML 2 metamodel that we call MOSES (MOdeling Software and platform architEcture in UML 2 for Simulation-based performance analysis). The goal of this paper is to provide a proof of concept that the UML 2 metamodel is rich enough to implement our approach that aims at modeling software and platform architecture within the same environment for sake of performance analysis. Finally we compare the results that we\u00a0\u2026", "num_citations": "24\n", "authors": ["468"]}
{"title": "Certifying adaptive flight control software\n", "abstract": " As aircraft designs become more complex, automation has become an important factor in improving safety and reliability. Automated flight control systems can respond intelligently to faults when it is impractical for a human to take control quickly. In recent years neural networks have been proposed for fault identification and accommodation purposes within flight control schemes because they are well suited to non-linear, multi-variable systems. Because neural networks learn to associate various control actions with particular input data patterns, they avoid the need to explicitly program all the relevant fault situations. A major issue in the use of adaptive fault-tolerant flight control systems is certification. Current practice relies heavily on testing as a means of performing certification. This has two shortcomings, the first being high cost. The second shortcoming of certification by testing is that it only provides a fairly limited guarantee. Certification based on testing exclusively is meaningless for new software technologies, such as adaptive controllers and neural networks which\u201d learn\u201d after deployment since the system tested in the lab is not the system that is being run in the field.In this paper, we formulate the research problems underlying the certification of adaptive systems. We also describe preliminary results of a certification case study, based on the methodology which combines formal methods and automated testing, and identify the areas of basic research needed to overcome the limitations observed in the proposed framework.", "num_citations": "24\n", "authors": ["468"]}
{"title": "Xprit: An xml-based tool to translate uml diagrams into execution graphs and queueing networks\n", "abstract": " Various methodologies exist to annotate software models with data related to performance, and to translate the annotated models into performance models. A relevant objective is now at hand in this direction, that is to make these methodologies acceptable from the software engineering community. We present here the XPRIT tool that allows to annotate UML diagrams and translate them into models ready to performance validation, that are execution graphs and queueing networks. The translation is based on an existing methodology (PRIMA-UML), and the output models represent the inputs to a software performance engineering approach.", "num_citations": "23\n", "authors": ["468"]}
{"title": "A framework for the integration of functional and non-functional analysis of software architectures\n", "abstract": " The separation of functional and non-functional analysis of software systems often prevents from considering design solutions that would be evident if an integrated analysis would be possible. Lack of analysis integration is in fact leading software developers to loose precious feedback that would improve the quality of the software product or, even better, would avoid late software inconsistencies with respect to functional or non-functional requirements. In this paper we introduce a framework for software analysis integration. The framework core is XML-based and consists of software models and formal relations among models. The relations help to automatically propagate the analysis feedback among software models. We specify how different analysis methodologies can be integrated in our framework. We also show how the Eclipse platform represents a natural implementation environment for such a framework.", "num_citations": "19\n", "authors": ["468"]}
{"title": "Performability modeling of mobile software systems\n", "abstract": " An increasing number of applications operate in heterogeneous computing environments, often with mobile components. Methodologies that help developers assess the ability of such applications to meet their performance requirements throughout the software life-cycle are needed. In particular, early in the design phases, analysis techniques are critical for ensuring the future system's behavior, evaluating and comparing design alternatives. A performability evaluation is the most appropriate means to assess the expected system's ability to perform, including the effects of component failures and repairs. This paper focuses on model-based analysis of performability of mobile software systems. We propose a general methodology that starts from design artifacts expressed in a UML-based notation. Inferred performability models are based on the stochastic activity networks notation. The viability of the proposed\u00a0\u2026", "num_citations": "17\n", "authors": ["468"]}
{"title": "On the processor scheduling problem in time warp synchronization\n", "abstract": " Time Warp is a synchronization mechanism for parallel/distributed simulation. It allows logical processes (LPs) to execute events without the guarantee of a causally consistent execution. Upon the detection of a causality violation, rollback procedures recover the state of the simulation to a correct value. When a rollback occurs there are two primary sources of performance loss: (1) CPU time must be spent for the execution of the rollback procedures and (2) waste of CPU time arises from the invalidation of event executions. In this paper we present a general framework for the problem of scheduling the next LP to be run on a processor in Time Warp simulations. The framework establishes a class of scheduling algorithms having the twofold aim to keep low the CPU time for the execution of the rollback procedures and also to guarantee low waste of time due to event executions invalidated by rollback. The combination\u00a0\u2026", "num_citations": "16\n", "authors": ["468"]}
{"title": "An architectural framework for analyzing tradeoffs between software security and performance\n", "abstract": " The increasing complexity of software systems entails large effort to jointly analyze their non-functional attributes in order to identify potential tradeoffs among them (e.g. increased availability can lead to performance degradation). In this paper we propose a framework for the architectural analysis of software performance degradation induced by security solutions. We introduce a library of UML models representing security mechanisms that can be composed with performance annotated UML application models for architecting security and performance critical systems. Composability of models allows to introduce different security solutions on the same software architecture, thus supporting software architects to find appropriate security solutions while meeting performance requirements. We report experimental results that validate our approach by comparing a model-based evaluation of a software\u00a0\u2026", "num_citations": "15\n", "authors": ["468"]}
{"title": "Using ATL for transformations in software performance engineering: a step ahead of java-based transformations?\n", "abstract": " Transformations of software models (such as UML diagrams) into non-functional models (such as Queueing Networks) have brought a real breakthrough to the entire field of non-functional software validation, because they allow to introduce automatism in the generation of a non-functional model from software artifacts. However, up today almost all the existing approaches are based on general purpose programming languages, such as Java. With the rapid evolution of model transformation languages, it is interesting to study how transformations in the software performance engineering domain may benefit from using constructs and tools of these languages. In this paper we present the results of our implementation, in ATLAS Transformation Language (ATL), of a transformation approach from UML models to Queueing Network models and, laying on a previous implementation of the same transformation in Java, we\u00a0\u2026", "num_citations": "15\n", "authors": ["468"]}
{"title": "A model-driven approach to catch performance antipatterns in ADL specifications\n", "abstract": " Context: While the performance analysis of a software architecture is a quite well-assessed task nowadays, the issue of interpreting the performance results for providing feedback to software architects is still very critical. Performance antipatterns represent effective instruments to tackle this issue, because they document common mistakes leading to performance problems as well as their solutions.Objective: Up today performance antipatterns have been only studied in the context of software modeling languages like UML, whereas in this manuscript our objective is to catch them in the context of ADL-based software architectures to investigate their effectiveness.Method: We have implemented a model-driven approach that allows the automatic detection of four performance antipatterns in \u00c6milia, that is a stochastic process algebraic ADL for performance-aware component-oriented modeling of software systems\u00a0\u2026", "num_citations": "14\n", "authors": ["468"]}
{"title": "Towards a library of composable models to estimate the performance of security solutions\n", "abstract": " Complex distributed dependable systems, such as web-based applications that contain sensitive data and are exposed to many users, have to meet different, and sometimes conflicting, non functional requirements, such as security and performance requirements. A typical example of this trade-off is the performance degradation introduced in a system by the raising of security solutions. Several proposals have been made to estimate the performance of security methodologies, but they are often grounded to existing standards such as IPsec and SSL.", "num_citations": "14\n", "authors": ["468"]}
{"title": "Path-based error propagation analysis in composition of software services\n", "abstract": " In Service-Oriented Architectures (SOA) composed services provide functionalities with certain non-functional properties that depend on the properties of the basic services. Models that represent dependencies among these properties are necessary to analyze non-functional properties of composed services. In this paper we focus on the reliability of a SOA. Most reliability models for software that is assembled from basic elements (e.g. objects, components or services) assume that the elements are independent, namely they do not take into account the dependencies that may exist between basic elements. We relax this assumption here and propose a reliability model for a SOA that embeds the \u201cerror propagation\u201d property. We present a path-based model that generates the possible execution paths within a SOA from a set of scenarios. The reliability of the whole system is then obtained as a combination of\u00a0\u2026", "num_citations": "14\n", "authors": ["468"]}
{"title": "Performance modeling and validation of a software system in a RT-UML-based simulative environment\n", "abstract": " The performance validation of software systems is becoming a crucial activity of the software development process. This is mostly due to the resource sharing and the remote deployment of software objects that may introduce critical delays in performance indices like the system response time. Hard and soft real-time systems are particularly affected from performance issues, therefore the ability to model and validate this attribute may become an extra value in software development environments. In this paper we introduce a framework to model performance aspects using the real-time object modeling (ROOM) notation. We devise a standard approach to represent hardware resources (such as CPUs and disks), to formulate resource requests of software objects, and to model the delays and the resource contentions that may arise from such requests. The integration of the software model and the resources is made\u00a0\u2026", "num_citations": "14\n", "authors": ["468"]}
{"title": "How can optimization models support the maintenance of component-based software?\n", "abstract": " The maintenance phase of software systems is ever more increasing its incidence, in terms of effort, to the whole software lifecycle. Therefore the introduction of automated techniques that can help software maintainers to take decision on the basis of quantitative evaluation would be a suitable phenomenon.Search-based techniques offer today a very promising view on the automation of searching processes in the software engineering domain. Component-based software is a very interesting paradigm to apply such type of techniques, for example for component selection. In this paper we introduce optimization techniques to manage the problem of failures at maintenance time. In particular,we introduce two approaches that provide maintenance actions to be taken in order to overcome system failures in case of monitored and non-monitored software systems.", "num_citations": "13\n", "authors": ["468"]}
{"title": "Three performance models at work: a software designer perspective\n", "abstract": " The validation of software performance since the very early phases of the lifecycle is a crucial issue in complex software system design. Nowadays in the software development practice, the percentage of time and effort allocated to this task is still too small to avoid performance bugs, which are late to discover and hard to fix. This is due both to the short time to market and to the special skills needed (and often lacking in the development team) to effectively accomplish early performance validation.Software architecture represents a system abstraction that may support the validation and the pre- dictive analysis of system performance. Different notations/languages are available for representing software architectures under a performance viewpoint. In this paper we focus on performance issues of software architectures and we analyze different performance model notations from a software designer perspective. Goal of\u00a0\u2026", "num_citations": "13\n", "authors": ["468"]}
{"title": "Software performance antipatterns: Modeling and analysis\n", "abstract": " The problem of capturing performance problems is critical in the software design, mostly because the results of performance analysis (i.e. mean values, variances, and probability distributions) are difficult to be interpreted for providing feedback to software designers. Support to the interpretation of performance analysis results that helps to fill the gap between numbers and design alternatives is still lacking. The aim of this chapter is to present the work that has been done in the last few years on filling such gap. The work is centered on software performance antipatterns, that are recurring solutions to common mistakes (i.e. bad practices) affecting performance. Such antipatterns can play a key role in the software performance domain, since they can be used in the investigation of performance problems as well as in the formulation of solutions in terms of design alternatives.", "num_citations": "12\n", "authors": ["468"]}
{"title": "On the adaptation of context-aware services\n", "abstract": " Ubiquitous networking empowered by Beyond 3G networking makes it possible for mobile users to access networked software services across heterogeneous infrastructures by resource-constrained devices. Heterogeneity and device limitedness creates serious problems for the development and deployment of mobile services that are able to run properly on the execution context and are able to ensures that users experience the \"best\" Quality of Service possible according to their needs and specific contexts of use. To face these problems the concept of adaptable service is increasingly emerging in the software community. In this paper we describe how CHAMELEON, a declarative framework for tailoring adaptable services, is used within the IST PLASTIC project whose goal is the rapid and easy development/deployment of self-adapting services for B3G networks.", "num_citations": "11\n", "authors": ["468"]}
{"title": "Performance antipatterns: State-of-art and future perspectives\n", "abstract": " The problem of capturing performance problems is critical in the software design, mostly because the results of performance analysis (i.e. mean values, variances, and probability distributions) are difficult to be interpreted for providing feedback to software designers. Support to the interpretation of performance analysis results that helps to fill the gap between numbers and design alternatives is still lacking. The aim of this talk is to present the work that has been done in the last few years on filling such gap. The work is centered on software performance antipatterns, that are recurring solutions to common mistakes (i.e. bad practices) affecting performance. Such antipatterns can play a key role in the software performance domain, since they can be used in the investigation of performance problems as well as in the formulation of solutions in terms of design alternatives.", "num_citations": "10\n", "authors": ["468"]}
{"title": "Performance-driven architectural refactoring through bidirectional model transformations\n", "abstract": " The generation of performance models from architectural models has been tackled with well-founded approaches in the last decade, whereas there is a clear lack of automation in the backward path that brings the analysis results back to the software architecture. It is common to iteratively modify a (generated) performance model until performance indices meet the requirements. However, propagating the performance model modifications back to the original architectural model is a complex problem. In this paper we make a first step in this direction, in that we use the JTL language for specifying a bidirectional model transformation between UML models and Queueing Networks, so working towards an automated round-trip process between software architectural models and performance models.", "num_citations": "10\n", "authors": ["468"]}
{"title": "A performance-based methodology to early evaluate the effectiveness of mobile software architectures\n", "abstract": " Modern programming languages and hardware technologies require (and effectively enable) ever more software to be distributed. Different paradigms (client\u2013server, mobility-based, etc.) can be adopted to design distributed software, and deciding the \u201cbest\u201d paradigm is a typical choice to be made in the very early software design phases. Several factors should drive this choice, that can also change depending on the software application domain. Within this framework, we focus on a class of attributes related to the performance, and the contribution of this paper is twofold: we extend an existing architecture description language (ADL) to model the physical and logical mobility of components; we introduce a methodology that, starting from a software architecture described using this extended notation, generates a performance model (namely a Markov decision process (MDP)) that allows the designer to evaluate the\u00a0\u2026", "num_citations": "10\n", "authors": ["468"]}
{"title": "Trade-off between sequential and time warp-based parallel simulation\n", "abstract": " Discrete event simulation is a methodology to study the behavior of complex systems. Its drawback is that, in order to get reliable results, simulations usually have to be run over a long stretch of time. This time requirement could decrease through the usage of parallel or distributed computing systems. In this paper, we analyze the Time Warp synchronization protocol for parallel discrete event simulation and present an analytical model evaluating the upper bound on the completion time of a Time Warp simulation. In our analysis, we consider the case of a simulation model with homogeneous logical processes, where \"homogeneous\" means they have the same average event routine time and the same state saving cost. Then we propose a methodology to determine when it is time-convenient to use a Time Warp synchronized simulation, instead of a sequential one, for a simulation model with features matching those\u00a0\u2026", "num_citations": "10\n", "authors": ["468"]}
{"title": "A Unified Approach to Model Non-Functional Properties of Mobile Context-Aware Software.\n", "abstract": " Modeling context-awareness is becoming a primary activity for software engineers that design applications for mobile devices. In fact, software applications running on such devices need to be aware of their context (that may rapidly change) to adapt their services and offer the best quality (intended as a combination of non-functional properties) in any context. Thus the need of instruments to manage mobility, context-awareness and non-functional characteristics is critical to build software systems in ubiquitous and mobile domain. In this paper we introduce a framework to uniformly model different types of mobility and context-awareness so that the modeling and analysis of non-functional properties of such systems can be supported in an integrated environment. To enable non-functional analysis, we devise the integration of non-functional parameters in the modeling framework. In particular, we present an UML implementation of our framework within the Magic-Draw modeling environment, with the support of existing UML profiles for modeling context-awareness and non-functional properties. We finally show an example of modeling and analysis of reliability in the eHealth domain.", "num_citations": "9\n", "authors": ["468"]}
{"title": "Modeling the Fault Tolerant Capability of a Flight Control System: An Exercise in SCR Specification\n", "abstract": " In life-critical and mission-critical applications, it is important to make provisions for a wide range of contingencies, by providing means for fault tolerance. In this paper, we discuss the specification of a flight control system that is fault tolerant with respect to sensor faults. Redundancy is provided by analytical relations that hold between sensor readings; depending on the conditions, this redundancy can be used to detect, identify and accommodate sensor faults.", "num_citations": "9\n", "authors": ["468"]}
{"title": "Rollback-based parallel discrete event simulation by using hybrid state saving\n", "abstract": " Optimistically synchronized parallel discrete event simulators must sometimes undo, by rolling back parts of the system state, the erroneous over optimistic computation deriving from the decentralized management of the event list. For this reason, an essential part of these simulators is the state saving mechanism. Three state saving mechanisms have been proposed in literature: copy, periodic and incremental state saving. In this paper we introduce a new state saving technique, that will be referred to as hybrid, which mixes the advantages of previous approaches. We also present experimental results obtained in a simulation environment which adopts hybrid state saving; such results quantify the bene ts, in terms of reduced simulation execution time, achievable by using our technique.", "num_citations": "9\n", "authors": ["468"]}
{"title": "From software architecture to analysis models and back: Model-driven refactoring aimed at availability improvement\n", "abstract": " ContextWith the ever-increasing evolution of software systems, their architecture is subject to frequent changes due to multiple reasons, such as new requirements. Appropriate architectural changes driven by non-functional requirements are particularly challenging to identify because they concern quantitative analyses that are usually carried out with specific languages and tools. A considerable number of approaches have been proposed in the last decades to derive non-functional analysis models from architectural ones. However, there is an evident lack of automation in the backward path that brings the analysis results back to the software architecture.ObjectiveIn this paper, we propose a model-driven approach to support designers in improving the availability of their software systems through refactoring actions.MethodThe proposed framework makes use of bidirectional model transformations to map UML\u00a0\u2026", "num_citations": "8\n", "authors": ["468"]}
{"title": "Modeling the performance of border inspections with electronic travel documents\n", "abstract": " Increased security risk in international travel has resulted in the creation of new programs to determine the admissibility of foreign travelers at official ports of entry within a country. Primary program goals are improving border security and, at the same time, facilitating the flow of legitimate travelers. Major program requirements include the adoption of machine readable travel documents (i.e., passports, visas, etc.), the use of biometric identifiers, and the interoperability among multiple information systems for travelersy identity verification and background checks. Performance analysis of a border inspection system early in its development life-cycle is essential to predict its ability to meet established performance goals, to identify key performance drivers and potential bottlenecks and to suggest possible design improvements. This paper presents our experience with performance evaluation of a hypothetical inspection\u00a0\u2026", "num_citations": "8\n", "authors": ["468"]}
{"title": "Role and impact of error propagation in software architecture reliability\n", "abstract": " We present a novel approach to the analysis of the reliability of a software architecture that takes into account an important architectural attribute, namely the error propagation probability. This is the probability that an error, arising somewhere in the architecture, propagates to other components, possibly up to the output. Although this attribute is often neglected in modeling the architecture reliability, it may heavily affect decisions on crucial architectural choices. With our approach, we are able to derive closed-form expressions for the overall system reliability and its sensitivity to variations in the reliability properties of each component (ie the probability of failure and the probability of error propagation). This latter result is useful to drive several significant tasks, such as: placing error detection and recovery mechanisms, focusing the design and implementation efforts on critical components, devising cost-effective testing strategies.", "num_citations": "8\n", "authors": ["468"]}
{"title": "A framework to model and analyze the performability of mobile software systems\n", "abstract": " The early validation of non-functional requirements of software systems is becoming a very stringent concern, especially in two domains: heterogeneous computing environments and interactive systems. In the former case the issue arises from the need of effectively exploiting the resources and capabilities that those environments may provide. In the latter case non-functional attributes (such as performance, reliability and availability) are peculiar for guaranteeing high levels of quality of services to users. Mobile software systems (eg web connected mobile phones) embrace both domains and therefore claim for accurate nonfunctional validation since the early phases of the software development process. This paper focuses on model based analysis of the performability of mobile software systems. We introduce a general framework that encompasses performance, dependability and mobility of software systems and\u00a0\u2026", "num_citations": "8\n", "authors": ["468"]}
{"title": "Availability-driven architectural change propagation through bidirectional model transformations between UML and petri net models\n", "abstract": " Software architecture is nowadays subject to frequent changes due to multiple reasons, such as evolution induced by new requirements. Architectural changes driven by non-functional requirements are particularly difficult to identify, because they attain quantitative analyses that are usually carried out with specific languages and tools. A considerable number of approaches, based on model transformations, have been proposed in the last decades to derive non-functional models from software architectural descriptions. However, there is a clear lack of automation in the backward path that brings the analysis results back to the software architecture. In this paper we address this problem in the context of software availability. We introduce a bidirectional model transformation between UML State Machines (SM), annotated with availability properties, and Generalized Stochastic Petri Nets (GSPN). Such transformation\u00a0\u2026", "num_citations": "7\n", "authors": ["468"]}
{"title": "Extending model transformations in the performance domain with a node modeling library\n", "abstract": " We introduce a new methodology that employs an architecture framework that can be used to automatically generate simulation models based on the UML model diagrams created by requirements engineers and software system architects. The framework takes advantage of a library of node models already specified by expert performance engineers. We envision that requirements engineers and architects will be able to generate optimized performance models using this approach by annotating UML deployment diagrams and sequence diagram models with performance requirements. In addition, they would be able to generate optimized simulation models by putting together existing simulation nodes.", "num_citations": "6\n", "authors": ["468"]}
{"title": "Formal Methods for Model-Driven Engineering: 12th International School on Formal Methods for the Design of Computer, Communication and Software Systems, SFM 2012, Bertinoro\u00a0\u2026\n", "abstract": " This volume presents a set of papers accompanying the lectures of the 12th International School on Formal Methods for the Design of Computer, Communication and Software Systems (SFM).This series of schools addresses the use of formal methods in computer science as a prominent approach to the rigorous design of the above-mentioned systems. The main aim of the SFM series is to offer a good spectrum of current research in foundations as well as applications of formal methods, which can be of help for graduate students and young researchers who intend to approach the field. SFM 2012 was devoted to model-driven engineering and covered several topics including modeling languages, model transformations, functional and performance modeling and analysis, and model evolution management. This volume comprises 11 articles. Selic\u2019s paper reviews how UML has changed over time and what new\u00a0\u2026", "num_citations": "5\n", "authors": ["468"]}
{"title": "TwoEagles: A Model Transformation Tool from Architectural Descriptions to Queueing Networks\n", "abstract": " We present the implementation of a methodology for the modeling, analysis, and comparison of software architectures based on their performance characteristics. The implementation is part of a software tool that is called TwoEagles, which extends the architecture-centric tool TwoTowers \u2013 based on the stochastic process algebraic description language \u00c6milia \u2013 and integrates it into Eclipse. The extension consists of a Java-coded plugin that we have called AEmilia_to_QN. This plugin transforms \u00c6milia descriptions into queueing network models expressed in the XML schema PMIF, which can then be rendered via the QN_Editor tool or analyzed by multiple queueing network solvers that can be invoked through the Weasel web service.", "num_citations": "5\n", "authors": ["468"]}
{"title": "An Architectural Framework for Analyzing Tradeoffs between Software Security and Performance-Extended results\n", "abstract": " The increasing complexity of software systems entails large effort to jointly analyze their non-functional attributes in order to identify potential tradeoffs among them (eg increased availability can lead to performance degradation). In this paper we propose a framework for the architectural analysis of software performance degradation induced by security solutions. We introduce a library of UML models representing security mechanisms that can be composed with performance annotated UML application models for architecting security and performance critical systems. Composability of models allows to introduce different security solutions on the same software architecture, thus supporting software architects to find appropriate security solutions while meeting performance requirements. We report experimental results that validate our approach by comparing a model-based evaluation of a software architecture for management of cultural assets with values observed on the real implementation of the system.", "num_citations": "5\n", "authors": ["468"]}
{"title": "Transformations of software models into performance models\n", "abstract": " It is widely recognized that in order to make performance validation an integrated activity along the software lifecycle, it is crucial to be supported from automated approaches. Easiness to annotate software models with performance parameters (e.g. the operational profile) and automated translations of the annotated models into ready-to-validate models are the key challenges in this direction. Several methodologies have been introduced in the last few years to address these challenges. The tutorial introduces the attendance to the main methodologies for annotating and transforming software models into performance models.", "num_citations": "5\n", "authors": ["468"]}
{"title": "Performance evaluation of mobility-based software architectures\n", "abstract": " Software architectures (SA) describe software systems at an early design stage, in terms of components and interactions among them; decisions made at this early stage can have a deep impact on the overall quality of the final software product, since they can affect several quality attributes, like reusability, performance, reliability. For this reason, it is important to develop methodologies to evaluate the impact of different architectural choices on these attributes, at the time these decisions are made [1, 5, 7, 12]. One of such decisions concerns the adoption of an architectural style, that determines the components type and patterns of interactions that can be used [2]. Several styles have been identified, motivated by trends in software design and technologies. In recent years, it has emerged the idea of explicitly taking into account the notion of components location, to deal conveniently with the fact that it is becoming\u00a0\u2026", "num_citations": "5\n", "authors": ["468"]}
{"title": "Analysis and Refactoring of Software Systems Using Performance Antipattern Profiles.\n", "abstract": " Refactoring is often needed to ensure that software systems meet their performance requirements in deployments with different operational profiles, or when these operational profiles are not fully known or change over time. This is a complex activity in which software engineers have to choose from numerous combinations of refactoring actions. Our paper introduces a novel approach that uses performance antipatterns and stochastic modelling to support this activity. The new approach computes the performance antipatterns present across the operational profile space of a software system under development, enabling engineers to identify operational profiles likely to be problematic for the analysed design, and supporting the selection of refactoring actions when performance requirements are violated for an operational profile region of interest. We demonstrate the application of our approach for a software system comprising a combination of internal (ie, in-house) components and external third-party services.", "num_citations": "3\n", "authors": ["468"]}
{"title": "Proactive model-based performance analysis and security tradeoffs in a complex system\n", "abstract": " Application domains in which early performance evaluation is needed are becoming more complex. In addition to traditional measures of complexity due, for example, to the number of components, their interactions, complicated control coordination and schemes, emerging applications may require adaptive response and reconfiguration the impact of externally observable (security) parameters. In this paper we introduce an approach for effective modeling and analysis of performance and security tradeoffs. The approach identifies a suitable allocation of resources that meet performance requirements, while maximizing measurable security effects. We demonstrate this approach through the analysis of performance sensitivity of a Border Inspection Management System (BIMS) with changing security mechanisms (e.g. biometric system parameters for passenger identification). The final result is a model-based\u00a0\u2026", "num_citations": "3\n", "authors": ["468"]}
{"title": "Software Performance Validation in UML-RT\n", "abstract": " System performance is a key factor to take into account throughout the software lifecycle of modern computer systems, mostly due to their typical characteristics such as distributed deployment, code mobility and platform heterogeneity. An open challenge in this direction is to integrate the performance validation as a transparent and efficient activity in the system development process. Several methodologies have been proposed to automate the transformation of software/hardware models into performance models. In this paper we do not take a transformational approach, rather we present a framework to integrate a software model with a platform model in order to build a performance model. Performance indices are obtained from simulation of the resulting performance model. Our framework provides: a library of pre-defined resource models, model annotation and integration procedures, and simulation support that make the performance analysis a much easier activity. We present the results obtained from two different industrial case studies that show the maturity and the stability of our approach.", "num_citations": "3\n", "authors": ["468"]}
{"title": "On the adequacy of UML-RT for performance validation of an sdh telecommunication system\n", "abstract": " This paper illustrates an industrial application of a performance validation methodology, which integrates software and resource models in a UML-RT development environment. The methodology is successfully applied on a synchronous digital hierarchy (SDH) telecommunication system modeled and simulated using the Rose Real Time toolset. The case study demonstrates the validity of the methodology, and it is an opportunity to refine the mechanisms of the methodology as well as to extend its scope. One of the key factors that the case study highlights is the concept of \"transparency\", i.e. the ability to apply a performance validation methodology without deeply modifying the software development process and environment.", "num_citations": "3\n", "authors": ["468"]}
{"title": "Comparing performance models from a software designer perspective\n", "abstract": " The validation of software performance since the very early phases of the lifecycle is a crucial issue in complex software systems. Nowadays in the software development practice, the percentage of time and effort allocated to this task is still too small to avoid performance bugs, which are late to discover and hard to fix. This is due both to the short time to market and to the special skills needed (and often lacking in the development team) to effectively accomplish early performance validation.Software architecture represents a system abstraction that may support the validation and the predictive analysis of system performance. Different models are available for representing software architectures under a performance viewpoint. Choosing the appropriate notation to model performance features is a quite hard task. In this paper we focus on performance issues and software architecture in order to discuss different\u00a0\u2026", "num_citations": "3\n", "authors": ["468"]}
{"title": "A checkpointing\u2013recovery scheme for Time Warp parallel simulation\n", "abstract": " This paper presents a checkpointing\u2013recovery scheme for Time Warp parallel simulation. The scheme relies on a checkpointing protocol, namely mixed state saving, embedding both sparse and incremental state saving modes, and on a state recovery procedure embedding both forward and backward recovery modes. This scheme is a generalization of many previous solutions, which can be obtained as particular instances of it by selecting appropriate values for the checkpointing protocol parameters. We also present two regulating algorithms to adaptively tune the checkpointing protocol parameters, in order to make the protocol reacting to variable rollback behavior. A synthetic benchmark in several different configurations has been used for evaluating and comparing our scheme with previous solutions. The obtained data show that our solution allows faster execution and, in addition, keeps quite low the amount\u00a0\u2026", "num_citations": "3\n", "authors": ["468"]}
{"title": "Aggressiveness/risk effects based scheduling in time warp\n", "abstract": " The time warp synchronization protocol for parallel discrete event simulation is characterized by aggressiveness and risk. The former property refers to greediness in the execution of unsafe events. The latter one refers to greediness in the notification of new events produced by aggressive event execution. Both these properties are potential sources for rollback occurrence/spreading. We present a scheduling algorithm for the selection of the next LP to be run on a processor which tends to keep low the joint impact of these two properties on the experienced amount of rollback. Reduction of negative effects of aggressiveness and risk is achieved by giving higher priority to the LPs whose next event has low probability to be undone due to rollback and has low fan-out, that is, notifies few new events. Our algorithm differs from most previous solutions in that they miss a direct control on the effects due to risk. These\u00a0\u2026", "num_citations": "3\n", "authors": ["468"]}
{"title": "A successful VISION: video-oriented UWB based intelligent ubiquitous sensing\n", "abstract": " This paper presents a project that has been recently funded by means of the ERC Starting Grant (http://erc.europa.eu/). The main goal of the project is to develop a new generarion of wireless sensor networks infrastructure to support innovative services for ubiquitous sensing and video. The work is in a very preliminary phase so the paper presents a general overview and the main challenges.", "num_citations": "2\n", "authors": ["468"]}
{"title": "What Is Software Performance?\n", "abstract": " The increasing complexity of software and its pervasiveness in everyday life has in the last years motivated growing interest for software analysis. This has mainly been directed to assess functional properties of the software systems (related to their structure and their behavior) and, in the case of safety critical systems, dependability properties. The quantitative behavior of a software system has gained relevance only recently with the advent of software performance analysis. This kind of analysis aims at assessing the quantitative behavior of a software system by comprehensively analyzing its structure and its behavior, from design to code. In this chapter we introduce the concepts and definitions that will be used throughout the entire book.", "num_citations": "2\n", "authors": ["468"]}
{"title": "Computer Performance Engineering: 7th European Performance Engineering Workshop, EPEW 2010, Bertinoro, Italy, September 23-24, 2010, Proceedings\n", "abstract": " This volume contains the proceedings of the 7th European Performance En-neering Workshop (EPEW 2010), held in Bertinoro, Italy, on September 23\u201324, 2010. The purpose of this workshop series is to gather academic and industrial researchers working on all aspects of performance engineering. This year the workshop was structured around three main areas: system and network p-formance engineering, software performance engineering, and the modeling and evaluation techniques supporting them. This edition of the workshop attracted 38 submissions, whose authors we wish to thank for their interest in EPEW 2010. After a careful review process during which every paper was refereed by at least three reviewers, the Program Committee selected 16 papers for presentation at the workshop. We warmly thank all the members of the ProgramCommittee and all the reviewersfor their fair and constructive comments and discussions. The workshop program was enriched by two keynote talks given by Marco Roccetti and Ralf Reussner. We conclude by expressing our gratitude to all the people who contributed to the organization of EPEW 2010, in particular the sta? of the University Residential Center of Bertinoro. We are also grateful to the EasyChair team for having allowed us to use their conference system and Springer for the continued editorial support of this workshop series.", "num_citations": "2\n", "authors": ["468"]}
{"title": "Transformations of UML Architectural Models into Performance Models based on ATLAS Transformation Language\n", "abstract": " Prior to the invention of electronic computers, data processing was performed using electromechanical devices called Unit Record Equipment, Electric Accounting Machine (EAM) or Tabulating Machine. All information for representing data was written on punched cards. Each punched column represented a single digit, letter or special character. Since it was not easy to write programs with these punched cards, their complexities were usually very simple.", "num_citations": "2\n", "authors": ["468"]}
{"title": "Relational characterizations of system fault tolerance\n", "abstract": " Fault tolerance is the ability of a system to continue delivering its services after faults have caused errors. We have argued, in the past, that complex and/or critical systems are best validated by a wide range of methods, including proving, testing, and fault tolerance; we have also argued that in order to use these methods in concert, we need to cast them in a common framework. In this paper, we present mathematical characterizations of fault tolerance properties, using a relational calculus.", "num_citations": "2\n", "authors": ["468"]}
{"title": "A UML-based Architectural Model for Timing and Performance Analyses of GSM Radio Subsystem\n", "abstract": " Global System for Mobile communication (GSM) is a widely accepted standard for digital cellular communication. It has become the mobile communication standard in more than 160 countries all over the globe. In this paper, we are interested in modeling the radio network part of a GSM system, in particular the Mobile Station (MS), using a UML-based notation. Our long-term research goal is to investigate issues related to timing and performance of the model in several operational scenarios. Our approach in both timing and performance analysis was introduced in former works, and was based on applying the proposed techniques on UML-based simulation models of systems\u2019 dynamic specifications. In this paper we propose a high-level architecture for the simulation model of the GSM Radio Subsystem, focusing on the Mobile Station. The paper discusses the main challenges faced in modeling this type of systems, in order to reach an adequate level of abstraction catering to the research objectives. The paper also highlights the problem areas where timing and performance analyses techniques are to be applied.", "num_citations": "2\n", "authors": ["468"]}
{"title": "Performance analysis of optimistic parallel simulations with limited rolled back events\n", "abstract": " Using the parallel simulation approach is not always the best choice. There are situations in which the sequential approach works better, in terms of simulation effectiveness.Indeed, the optimistic parallel simulation time consists of two basic components: the forward execution time, and the rollback mechanism time-overhead. It is convenient to parallelize a simulation until the latter component is not predominant with respect to the former one.The breakeven point depends on the nature of the model to simulate, on the characteristics of the simulation platform, and on the choice of tuning parameters such as the number of processors and the checkpoint interval.This paper deals with an evaluation of the performances of the sequential and parallel approach, in case the optimistic parallel method is used. An analytical model is introduced to study the sensitivity of the parallel simulation effectiveness to the forward event\u00a0\u2026", "num_citations": "2\n", "authors": ["468"]}
{"title": "Co-evolution of Metamodel and Generators: Higher-order Templating to the Rescue\n", "abstract": " ABSTRACT In Model-Driven Engineering, metamodels are the cornerstone entities underpinning modeling environments. Given one or more metamodels, a diversity of artefacts, including models, transformations, and code generators, are formally coupled with them. Like any other software, metamodels are prone to evolutionary pressure due to shifting business requirements. However, metamodel modifications might come at the price of jeopardizing the related artefacts that, in turn, must be adapted in order to remain valid. While a comprehensive corpus of research has shown that the co-evolution of metamodels and models can be effectively addressed with semi-automated techniques, the co-evolution of transformations and code generators still requires significant manual intervention. This paper proposes a novel technique to make template-based code generators resilient, to some extent, against metamodel evolution. A new template-based language, called hotello, is proposed for the specification of meta-templates, ie, higher-order model-to-text transformations. The approach has been implemented, and a demonstration of its capabilities on a case study in the IoT domain is discussed.", "num_citations": "1\n", "authors": ["468"]}
{"title": "Performance Modeling Notations\n", "abstract": " A major problem for stably embedding software performance modeling and analysis within the software lifecycle resides in the distance between notations for static and dynamic modeling of software (such as UML) and notations for modeling performance (such as Queueing Networks). In Chap.\u00a0               2                             we have introduced the major notations for software modeling, whereas in this chapter we introduce basic performance modeling notations. A question may arise at this point from readers that are not familiar with performance analysis: \u201cIf all the performance notations are able to provide the desired indices, then why using different notations for performance modeling?\u201d. The software performance community is still far from unifying languages and notations, although some recent efforts have been spent in the direction of building a performance ontology as a shared vocabulary of the domain\u00a0\u2026", "num_citations": "1\n", "authors": ["468"]}
{"title": "Software lifecycle and performance analysis\n", "abstract": " This chapter is aimed at illustrating performance modeling and analysis issues within the software lifecycle. After having introduced software and performance modeling notations, here the goal is to illustrate their role within the software development process. In Chap.               5                             we will describe in more details several approaches that, based on model transformations, can be used to implement the integration of software performance analysis and software development process. After briefly introducing the most common software lifecycle stages, we present our unifying view of software performance analysis as integrated within a software development process (i.e. the Q-Model).", "num_citations": "1\n", "authors": ["468"]}
{"title": "From software models to performance models\n", "abstract": " This chapter focuses on the transformational approaches from software system specifications to performance models. These transformations aim at filling the gap between the software development process and the performance analysis by generating performance model ready to be validated from the software models. Three approaches are discussed in detail presenting their foundations and their application to an e-commerce case study. Moreover, the chapter briefly reviews representatives of other transformational approaches present in the literature. All the presented approaches are discussed with respect to a set of relevant dimensions such as software specification, performance model, evaluation methods and level of automated support for performance prediction.", "num_citations": "1\n", "authors": ["468"]}
{"title": "A UML-based Architectural Model for Performance Analysis of Slotted ALOHA in GSM Radio Networks\n", "abstract": " In our research, we are interested in modeling the radio network part of the GSM system in order to apply in-house developed framework for timing and performance analyses. Our approach in both timing and performance analyses was introduced in former works, and is based on applying the proposed techniques on UML-based simulation models of systems\u2019 dynamic specifications. In former work, we introduced an UML Architectural model for the GSM case study. In this paper, we discuss the modeling of a resource contention situation in the GSM radio network, which is the Slotted-ALOHA Random Access by mobile stations. The model introduced here incorporates adjustment for propagation delay. However,* effects of Capture and fading are neglected.", "num_citations": "1\n", "authors": ["468"]}
{"title": "An analysis of the efficiency of optimistically synchronized parallel simulators\n", "abstract": " In optimistically synchronized parallel simulators logical processes execute events greedily and recovery from timestamp order violations is based on rollback. These type of simulators have shown the potential to exploit a high degree of parallelism; however, they may result ine cient due to possible unacceptable percentage of CPU time spent executing events that are rolled back (ie, non productive simulation work). The e ciency of an optimistically synchronized parallel simulation is, in general, highly unpredictable, depending on features of the simulation model and of the hardware/software architecture. Therefore, the question on being optimistic parallel simulation timeconvenient over sequential one is a hard problem to solve.In this paper we present an analysis of the e ciency for the case of simulations with a single logical process running on each processor, and under the assumption that only one non-executed event is stored in the event list of any logical process at a time. The analysis allows to predict e ciency values which are demonstrated, through simulation results of synthetic workloads, to be good approximations of the observed ones. Finally, we show how our theoretical results can be used for predicting upper bound values on the completion time of optimistically synchronized simulations.", "num_citations": "1\n", "authors": ["468"]}