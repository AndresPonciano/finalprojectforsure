{"title": "A view of software development environments based on activity theory\n", "abstract": " We view software development as a collaborative activity that is typically supported by a software development environment. Since these environments can significantly influence the collaborative nature of a software development project, it is important to analyze and evaluate their capabilities with respect to collaboration. In this paper, we present an analysis and evaluation of the collaborative capabilities of software development environments using an activity theory perspective.               The discipline of software engineering (SE) emerged to study and develop artifacts to mediate the collective development of large software systems. While many advances have been made in the past three decades of SE's existence, the historical origins of the discipline are present in that techniques and tools to support the collaborative aspects of large-scale software development are still lacking. One factor is a common\u00a0\u2026", "num_citations": "149\n", "authors": ["651"]}
{"title": "Integrating open hypermedia systems with the World Wide Web\n", "abstract": " Research on open hypermedia systems (OHSS) has been conducted since the late Eighties [10]. These systems employ a variety of techniques to provide hypermedia services to a diverse range of applications. The World Wide Web is the largest distributed hypermedia system in use and was developed largely independent of the research in OHSS. The popularity of the Web along with problems inherent in its design has motivated OHS researchers to integrate their systems with it. This research has primarily focused on enhancing the functionality of the Web via the services of an OHS. This paper presents three experiments exploring the integration of the Chimera OHS with the Web. While one of the experiments indeed describes work which enhances the Web, the other two investigate ways in which the Web can beneficially enhance an OHS. The paper concludes with a call for both communities to continue\u00a0\u2026", "num_citations": "147\n", "authors": ["651"]}
{"title": "Web-based development of complex information products\n", "abstract": " The World-Wide Web connects islands of information, along with the people seeking that information, from within corporate intranets and across the global Internet, easily and effectively. Sharing information without regard to physical location has prompted new forms of virtual business and social endeavors. A virtual enterprise is an organization unconstrained by geographic location, and a membership intersecting multiple traditional organizations. Virtual enterprises can be formed within large corporations (consisting of groups at distributed sites), as parts of business alliances or task forces [4], and even among individuals working independently of any corporate connection. Indeed, all that is needed to form a virtual enterprise is at least one common goal, a shared information space, a means of coordinating users\u2019 efforts, and people willing to share the work.The Web provides the minimum for setting up such\u00a0\u2026", "num_citations": "146\n", "authors": ["651"]}
{"title": "MySQL to NoSQL: data modeling challenges in supporting scalability\n", "abstract": " Software systems today seldom reside as isolated systems confined to generating and consuming their own data. Collecting, integrating and storing large amounts of data from disparate sources has become a need for many software engineers, as well as for scientists in research settings. This paper presents the lessons learned when transitioning a large-scale data collection infrastructure from a relational database to a hybrid persistence architecture that makes use of both relational and NoSQL technologies. Our examples are drawn from the software infrastructure we built to collect, store, and analyze vast numbers of status updates from the Twitter micro-blogging service in support of a large interdisciplinary group performing research in the area of crisis informatics. We present both the software architecture and data modeling challenges that we encountered during the transition as well as the benefits we gained\u00a0\u2026", "num_citations": "137\n", "authors": ["651"]}
{"title": "Chimera: hypermedia for heterogeneous software development enviroments\n", "abstract": " Emerging software development environments are characterized by heterogeneity: they are composed of diverse object stores, user interfaces, and tools. This paper presents an approach for providing hypermedia services in this heterogeneous setting. Central notions of the approach include the following: anchors are established with respect to interactive views of objects, rather than the objects themselves; composable, n-ary links can be established between anchors on different views of objects which may be stored in distinct object bases; viewers may be implemented in different programming languages; and, hypermedia services are provided to multiple, concurrently active, viewers. The paper describes the approach, supporting architecture, and lessons  learned. Related work in the areas of supporing heterogeneity and hypermedia data modeling is discussed. The system has been employed in a variety of\u00a0\u2026", "num_citations": "109\n", "authors": ["651"]}
{"title": "Design and implementation of a data analytics infrastructure in support of crisis informatics research (NIER track)\n", "abstract": " Crisis informatics is an emerging research area that studies how information and communication technology (ICT) is used in emergency response. An important branch of this area includes investigations of how members of the public make use of ICT to aid them during mass emergencies. Data collection and analytics during crisis events is a critical pre-requisite for performing such research, as the data generated during these events on social media networks are ephemeral and easily lost. We report on the current state of a crisis informatics data analytics infrastructure that we are developing in support of a broader, interdisciplinary research program. We also comment on the role that software engineering research plays in these increasingly common, highly-interdisciplinary research efforts.", "num_citations": "97\n", "authors": ["651"]}
{"title": "Addressing interoperability in open hypermedia: The design of the open hypermedia protocol\n", "abstract": " Early hypertext systems were monolithic and closed, but newer systems tend to be open, distributed, and support collaboration. While this development has resulted in increased openness and flexibility, integration or adaptation of various different tools (such as content editors, viewers, services, or even other link servers) has remained a tedious task. Many developers were implementing essentially similar components, simply for the benefit of having their own platform on which to experiment with hypertexts. The open hypermedia community is addressing this issue of interoperability between open hypermedia systems. The goal of this effort is to provide an open framework that can be used by application developers outside the community to construct more powerful hypermedia-aware applications. The design and evolution of this framework is presented along with the requirements that drove its development. The\u00a0\u2026", "num_citations": "94\n", "authors": ["651"]}
{"title": "Reconfiguration in the Enterprise JavaBean component model\n", "abstract": " Reconfiguration is the process of applying planned changes to the communication, interconnection, componentization, or functionality of a deployed system. It is a powerful tool for achieving a variety of desirable properties of large-scale, distributed systems, including evolvability, adaptability, survivability, and continuous availability. Current approaches to reconfiguration are inadequate: some allow one to describe a system\u2019s range of configurations for a relatively broad class of system architectures, but do not provide a mechanism for actually carrying out a reconfiguration; others provide a mechanism for carrying out certain kinds of limited reconfigurations, but assume a specialized system architecture in order to do so. This paper describes our attempt at devising a reconfiguration mechanism for use with the popular and widely available Enterprise JavaBean (EJB) component container model. We describe\u00a0\u2026", "num_citations": "74\n", "authors": ["651"]}
{"title": "A framework for mapping traceability relationships\n", "abstract": " Traceability relationships help stakeholders understand the many associations and dependencies that exist between software artifacts created during a software development project. Individual relationships between specific artifacts can be useful in understanding portions of the system. However, these explicit relationships are greatly outnumbered by the implicit relationships that exist between artifacts. This situation adds to the complexity of software development. Stakeholders need a way to understand all the relationships that exist in a software development project. We describe TraceM, a framework for automating the management of traceability relationships. A key contribution of TraceM is its ability to transform implicit relationships into explicit relationships by processing chains of traceability relationships. Thus, our framework has the potential to provide software developers with insight into the state of their software development projects.", "num_citations": "69\n", "authors": ["651"]}
{"title": "The impact of shift work on sleep quality among nurses\n", "abstract": " Background           Shift work is common among nurses, and it is known to be a workplace hazard as it may cause poor sleep quality, which can impact adversely on the health and safety of nurses and their patients.                             Aims           To explore factors that contribute to poor sleep quality in shift working nurses (SWNs) compared with non-shift working nurses (NSWNs) and to assess the awareness of support from occupational health.                             Methods           Cross-sectional study of nurses at a National Health Service (NHS) foundation trust, February to March 2016. Data were collected via an online questionnaire. Sleep quality was measured using the Pittsburgh Sleep Quality Index.                             Results           Eight hundred and eighty-eight nurses participated; the response rate was 34%. The prevalence of poor sleep quality was 78% (95% confidence interval [CI] 0.748\u20130.813) in the\u00a0\u2026", "num_citations": "59\n", "authors": ["651"]}
{"title": "Interoperability between hypermedia systems: The standardisation work of the OHSWG\n", "abstract": " The University of Aarhus University, DK Southampton, UK{bouvin, kgronbak, Tel:+ 44 1703 59 3669 pnuern,{hcd, dem97r, les}@ daimi. aau. dk sr}@ ecs. soton. ac. uk", "num_citations": "59\n", "authors": ["651"]}
{"title": "Embrace the challenges: Software engineering in a big data world\n", "abstract": " The design and development of data-intensive software systems -- systems that generate, collect, store, process, analyze, query, and visualize large sets of data -- is fraught with significant challenges both technical and social. Project EPIC has been designing and developing data-intensive systems in support of crisis informatics research since Fall 2009. Our experience working on Project EPIC has provided insight into these challenges. In this paper, we share our experience working in this design space and describe the choices we made in tackling these challenges and their attendant trade-offs. We highlight the lack of developer support tools for data-intensive systems, the importance of multidisciplinary teams, the use of highly-iterative life cycles, the need for deep understanding of the frameworks and technologies used in data intensive systems, how simple operations transform into significant challenges at\u00a0\u2026", "num_citations": "53\n", "authors": ["651"]}
{"title": "Chiron-1: A software architecture for user interface development, maintenance, and run-time support\n", "abstract": " The Chiron-1 user interface system demonstrates key techniques that enable a strict separation of an application from its user interface. These techniques include separating the control-flow aspects of the application and user interface: they are concurrent and may contain many threads. Chiron also separates windowing and look-and-feel issues from dialogue and abstract presentation decisions via mechanisms employing a client-server architecture. To separate application code from user interface code, user interface agents called artists are attached to instances of application abstract data types (ADTs). Operations on ADTs within the application implicitly trigger user interface activities within the artists. Multiple artists can be attached to ADTs, providing multiple views and alternative forms of access and manipulation by either a single user or by multiple users. Each artist and the application run in separate\u00a0\u2026", "num_citations": "53\n", "authors": ["651"]}
{"title": "Towards large-scale information integration\n", "abstract": " Software engineers confront many challenges during software development. One challenge is managing the relationships that exist between software artifacts. We refer to this task as information integration, since establishing a relationship between documents typically implies that an engineer must integrate information from each of the documents to perform a development task. In the past, we have applied open hypermedia techniques and technology to address this challenge. We now extend this work with the development of an information integration environment. We present the design of our environment along with details of its first prototype implementation. Furthermore, we describe our efforts to evaluate the utility of our approach. Our first experiment involves the discovery of keyword relationships between text-based software artifacts. Our second experiment examines the code of an open source project and\u00a0\u2026", "num_citations": "52\n", "authors": ["651"]}
{"title": "Design challenges/solutions for environments supporting the analysis of social media data in crisis informatics research\n", "abstract": " Crisis informatics investigates how society's pervasive access to technology is transforming how it responds to mass emergency events. To study this transformation, researchers require access to large sets of data that because of their volume and heterogeneous nature are difficult to collect and analyze. To address this concern, we have designed and implemented an environment - EPIC Analyze - that supports researchers with the collection and analysis of social media data. Our research has identified the types of components - such as NoSQL, MapReduce, caching, and search - needed to ensure that these services are reliable, scalable, extensible, and efficient. We describe the design challenges encountered - such as data modeling, time vs. Space tradeoffs, and the need for a useful and usable system - when building EPIC Analyze and discuss its scalability, performance, and functionality.", "num_citations": "40\n", "authors": ["651"]}
{"title": "Data scalability in open hypermedia systems\n", "abstract": " A key issue in hypermedia is scalability. A review of the hypermedia literature relevant to scalability is presented and related to the field of open hypermedia systems. The issues are grounded in the description of a development project that increased the scalability of the Chimera open hypermedia system two orders of magnitude. The project description includes the scenario that motivated the work, Chimera\u2019s architecture, the scalability issues encountcrcd and the techniques employed to address them. An important lesson of the work is that scalability impacts all levels of a system\u2019s architecture. This has significant ramifications with respect to open hypermedia systems since the highest layer of their architecture is composed of third-party applications typically outside the control of the open hypermedia system\u2019s developers.", "num_citations": "28\n", "authors": ["651"]}
{"title": "Templates and queries in contextual hypermedia\n", "abstract": " This paper presents a new definition of context for context-aware computing based on a model that relies on dynamic queries over structured objects. This new model enables developers to flexibly specify the relationship between context and context data for their context-aware applications. We discuss a framework, HyConSC, that implements this model and describe how it can be used to build new contextual hypermedia systems. Our framework aids the developer in the iterative development of contextual queries (via a dynamic query browser) and offers support for con-text matching, a key feature of contextual hypermedia. We have tested the framework with data and sensors taken from the HyCon contextual hypermedia system and are now migrating HyCon to this new framework.", "num_citations": "25\n", "authors": ["651"]}
{"title": "Metis: lightweight, flexible, and web-based workflow services for digital libraries\n", "abstract": " The Metis project is developing workflow technology designed for use in digital libraries by avoiding the assumptions made by traditional workflow systems. In particular, digital libraries have highly distributed sets of stakeholders who nevertheless must work together to perform shared activities. Hence, traditional assumptions that all members of a workflow belong to the same organization, work in the same fashion, or have access to similar computing platforms are invalid. The Metis approach makes use of event-based workflows to support the distributed nature of digital library workflow and employs techniques to make the resulting technology lightweight, flexible, and integrated with the Web. We describe the conceptual framework behind the Metis approach as well as a prototype which implements the framework. The prototype represents a \"proof-of-concept\" of the Metis framework and approach as we show how\u00a0\u2026", "num_citations": "25\n", "authors": ["651"]}
{"title": "Getting the query right: User interface design of analysis platforms for crisis research\n", "abstract": " Web-based data analysis environments are powerful platforms for exploring large data sets. To ensure that these environments meet the needs of analysts, a human-centered perspective is needed. Interfaces to these platforms should provide flexible search, support user-generated content, and enable collaboration. We report on our efforts to design and develop a web interface for a custom analytics platform\u2014EPIC Analyze\u2014which provides interactive search over large Twitter data sets collected during crisis events. We performed seven think-aloud sessions with researchers who regularly analyze crisis data sets and compiled their feedback. They identified a need for a \u201cbig picture\u201d view of an event, flexible exporting capabilities, and user-defined coding schemes. Adding these features allowed EPIC Analyze to meet the needs of these analysts and enable exploratory research on crisis data.", "num_citations": "22\n", "authors": ["651"]}
{"title": "A Framework for Managing Traceability Relationships between Requirements and Architectures.\n", "abstract": " Traceability helps stakeholders to understand the relationships that exist between software artifacts created during a software development project. For example, the evolution of the relationships between requirements and the components to which they are allocated can provide insight into the maintainability of a system. Unfortunately, due to the heterogeneous nature of these artifacts, creating, maintaining, and viewing these relationships is extremely difficult. We propose a new approach to traceability based on techniques from open hypermedia and information integration. Open hypermedia and information integration provide generic techniques for establishing, maintaining, and viewing relationships between software artifacts. Our approach allows the automated creation, maintenance, and viewing of traceability relationships in tools that software professionals are accustomed to using on a daily basis.", "num_citations": "22\n", "authors": ["651"]}
{"title": "Many views, many modes, many tools... one structure: Towards a non-disruptive integration of personal information\n", "abstract": " People yearn for more integration of their information. But tools meant to help often do the opposite-pulling people and their information in different directions. Fragmentation is potentially worsened as personal information moves onto the Web and into a myriad of special-purpose, mobile-enabled applications. How can tool developers innovate\" non-disruptively\" in ways that do not force people to re-organize or re-locate their information? This paper makes two arguments: 1. An integration of personal information is not likely to happen through some new release of a desktop operating system or via a Web-based\" super tool.\" 2. Instead, integration is best supported through the development of a standards-based infrastructure that makes provision for the shared manipulation of common structure by any number of tools, each in its own way. To illustrate this approach, the paper describes an XML-based schema\u00a0\u2026", "num_citations": "20\n", "authors": ["651"]}
{"title": "XLink and open hypermedia systems: a preliminary investigation\n", "abstract": " XLink is an emerging Internet standard designed to support the linking of XML documents. We present preliminary work on using XLink as an export format for the links of an open hypermedia system. Our work provides insights into XLink\u2019s suitability as a vehicle for extending the benefits of open hypermedia to the rapidly evolving world of XML.", "num_citations": "19\n", "authors": ["651"]}
{"title": "Structure and behavior awareness in themis\n", "abstract": " Structural computing provides techniques and tools to ease the task of developing application infrastructure; infrastructure that provides common services such as persistence, naming, distribution, navigational hypermedia, etc., over a set of application-specific or domain-specific structures. Within structural computing,\" structure\" refers to a combination of data together with relationships pertaining to that data. Structure servers support the specification and manipulation of structures. One important aspect of structural computing is the power and flexibility it provides application developers constructing new applications. A large part of this power is due to structural computing's ability to provide awareness services for both structure and behavior. We define this concept and describe the awareness services provided by the Themis structural computing environment. The utility of these services are demonstrated by\u00a0\u2026", "num_citations": "18\n", "authors": ["651"]}
{"title": "The theoretical basis of ACE, an Age Calculation Engine for cosmogenic nuclides\n", "abstract": " We present the theory behind ACE, an \u2018Age Calculation Engine\u2019 for cosmogenic nuclides. ACE is a theoretical development environment for cosmogenic nuclide dating, and contains novel features such as the ability to work with any cosmogenic nuclide, calibrate production rates from user-supplied calibration databases, and examine the sensitivity of computed sample ages to theoretical uncertainties. The default algorithms for calibration and dating in ACE are described so that users can interpret results within a scientific context. Sensitivities of the dating algorithms to assumptions regarding geomagnetic and atmospheric scaling, independently dated calibration databases, and secular variability are shown to identify key sources of uncertainty in the cosmogenic nuclide dating method.", "num_citations": "17\n", "authors": ["651"]}
{"title": "Supporting industrial hyperwebs: lessons in scalability\n", "abstract": " Open hypermedia is one approach to managing the relationships that exist in software development projects. A key technical issue in this endeavor is support for scalability. Our experience supporting scalability in open hypermedia has revealed several key insights including the notion of the transitivity of scalability, the need to consider issues of scale in moving from design to implementation, the need to apply multiple techniques in tandem, and the unexpected nontechnical issues that arise when scaling a system to meet the demands of industrial software engineering. These insights are grounded in observations of a development project that scaled an open hypermedia system, Chimera, two orders of magnitude to meet the demands of an industrial user.", "num_citations": "17\n", "authors": ["651"]}
{"title": "The extensibility mechanisms of the Chimera open hypermedia system\n", "abstract": " Open hypermedia system developers have many choices to make with respect to the extensibility mechanisms they include within their systems. The extensibility mechanisms of the Chimera open hypermedia system are presented to document the set of choices made for it. Chimera\u2019s extensibility mechanisms are based on a general technique that can be applied to many aspects of an open hypermedia system. For each choice, a particular issue is discussed and a set of alternatives for solving the issue is presented. Then, the choice made for Chimera, along with its supporting rationale, is presented using an extensibility analysis framework developed by Wiil.", "num_citations": "16\n", "authors": ["651"]}
{"title": "Supporting Project Awareness on the WWW with the iScent Framework\n", "abstract": " Supporting project awareness in the context of large-scale software development is difficult. One problem is identifying appropriate abstractions and techniques that support the insertion of project awareness mechanisms into a software development environment with minimal impact. An additional problem is scaling project awareness mechanisms to handle the demands of large software development projects. The Web is increasingly being used to support software engineering and, as such, becomes an additional target for project awareness mechanisms with its own unique challenges. To maintain awareness of information evolving on an Internet scale, and to address the problems and challenges mentioned above, we present a framework to support awareness and intersubjectivity among software team members through the use of automatically collected, hypermedia-enabled event trails. The concepts\u00a0\u2026", "num_citations": "16\n", "authors": ["651"]}
{"title": "Software engineering requirements for structural computing\n", "abstract": " In 1997, N\u00fcrnberg et al. argued for the formation of a new field of study in computer science called structural computing [7]. Structural computing asserts the primacy of structure over data. This is defined by N\u00fcrnberg et al. as follows:", "num_citations": "16\n", "authors": ["651"]}
{"title": "Unifying structure, behavior, and data with Themis types and templates\n", "abstract": " Structural computing evolved from work on open hypermedia to aid in the creation of software infrastructure. Open hypermedia had produced software that provided applications with access to hypermedia structures and services. The question was asked if these results could be generalized to create similar tools for other domains. Initial work focused on the development of structure servers that can create and manipulate domain-specific structures, but little work focused on allowing those structures to provide a rich set of behaviors. Indeed, this forced developers to place behaviors on the client rather than having behaviors live within a structure server. This paper presents research on the addition of a type system to the Themis structure server and how these types interact with Themis's template mechanism to provide a single interface that unifies structure, behavior, and data. This new mechanism lets behaviors live\u00a0\u2026", "num_citations": "15\n", "authors": ["651"]}
{"title": "Structural templates and transformations: the Themis structural computing environment\n", "abstract": " The field of structural computing is working to produce techniques and tools to ease the task of developing application infrastructure. This paper describes the Themis structural computing environment. Themis provides developers with a generic structure server and two key extension mechanisms that enable the rapid creation of tools for a variety of application domains. The two novel extension mechanisms enable support for structure templates and automated structure transformation. Each of these mechanisms is described in detail along with the interfaces and capabilities of the generic structure server. We evaluate the utility of Themis in supporting the migration of the InfiniTe information integration environment from an XML-based repository to the Themis structure server. The use of Themis has led to a significant reduction in the number of lines of code required to produce the InfiniTe prototype. In addition, the\u00a0\u2026", "num_citations": "15\n", "authors": ["651"]}
{"title": "ACE: Age Calculation Engine-A design environment for cosmogenic dating techniques\n", "abstract": " ACE (age calculation engine; previously called iCronus) is a design environment for analyzing data used in cosmogenic dating methods. It is supported by a software architecture designed with flexibility, scalability, security and safety in mind. These properties have allowed us to create an environment that directly supports the tasks that geoscientists perform as they work on developing new algorithms for cosmogenic dating, such as running calibrations, defining new experiments, and evaluating the impacts of scaling factors on the calculated ages of samples. Our goal is to provide geoscientists using cosmogenic dating methods with a flexible and powerful software infrastructure upon which to base their future research efforts. In this paper, we describe the design of the ACE system and compare it to existing cosmogenic dating software. We also discuss how our system has been evaluated and our plans for future\u00a0\u2026", "num_citations": "14\n", "authors": ["651"]}
{"title": "A vision for heart rate health through wearables\n", "abstract": " Wearable technology has great potential for helping members of the public monitor their health. We are interested in medical conditions that can be monitored using the sensors on wearable devices like the Apple Watch. We are interested in the insights that can be provided by the monitoring of a person's heart rate. We have conducted interviews with doctors to understand what can be learned about the health of an individual via their heart rate and how we can use that information to design applications that aid in monitoring these conditions. In this paper, we explore this design space and identify the applications we will develop to help users track these conditions in considerably less invasive ways than current methods.", "num_citations": "13\n", "authors": ["651"]}
{"title": "Incremental sorting for large dynamic data sets\n", "abstract": " In today's world of pervasive computing, it is straightforward for organizations to generate large amounts of data in support of a variety of business needs. For this reason, it is important to build tools that allow analysts to manage and investigate these data sets quickly and efficiently. One feature needed by these tools is the ability to sort large amounts of data along a number of dimensions to facilitate the search for useful information. In this paper, we describe a new method for incrementally sorting large, multi-dimensional, dynamic data sets. Our particular use case involves sorting large Twitter data sets but our technique can be applied more generally across a variety of data types. Our approach is evaluated with respect to its scalability and by comparing it to several alternatives. It is currently able to efficiently sort data sets consisting of tens of millions of tweets along a variety of dimensions even when the data set\u00a0\u2026", "num_citations": "13\n", "authors": ["651"]}
{"title": "Supporting software engineering with open hypermedia\n", "abstract": " One approach to supporting relationship management in software engineering is open hypermedia. A body of research has developed over the past two decades that has explored the effectiveness of this approach in supporting various software engineering tasks. This paper explores the underlying issues and discusses relevant work in this area. In addition, a small case study of the use of an open hypermedia system in an industrial context is presented.", "num_citations": "13\n", "authors": ["651"]}
{"title": "Event-based document sensing for insider threats\n", "abstract": " In this report we describe a uniquely decentralized event-based system for online and offline tracking, analysis, and control of electronic document transactions in order to detect suspected insider misuse of those documents. Our system is focused on the problem of tracking and analyzing user\u2019s actions with respect to documents. On the user side, the proposed system will support the placing of document sensors into a heterogeneous collection of document editors (eg, Microsoft Office) and browsers, including Web browsers. The system will provide a low entry barrier with respect to integrating new user-side tools. On the administrative side, the proposed system will support a dynamically changing set of online and offline analysis and control programs capable of providing such diverse capabilities as visualization, persistence, forensics, access control validation, and slicing of document access patterns based on, for example, user, or document, or transaction type, or time-line. The system as a whole will be portable, which we will demonstrate by providing integration of tools under both Linux and Windows.", "num_citations": "10\n", "authors": ["651"]}
{"title": "Open Hypermedia Systems and Structural Computing: 6th International Workshop, OHS-6 2nd International Workshop, SC-2 San Antonio, Texas, USA, May 30-June 3, 2000 Proceedings\n", "abstract": " This book constitutes the thoroughly refereed post-proceedings of the 6th International Workshop on Open Hypermedia Systems, OHS-6, and the 2nd International Workshop on Structural Computing, SC-2, held at the 11th ACM Conference on Hypertext and Hypermedia in San Antonio, Texas, USA in May/June 2000. The 19 revised full papers presented were carefully reviewed and selected for inclusion in the book. All current issues on open hypertext systems and structural computing are addressed.", "num_citations": "10\n", "authors": ["651"]}
{"title": "Investigating the relationship between violations of the law of demeter and software maintainability\n", "abstract": " We present DemeterCop\u2013a system for finding violations of the Law of Demeter in JavaTM code while investigating the correlation between these violations and software maintainability. We compare how fixing these violations affects the Maintainability Index\u2013hence the software maintainability\u2013and look into new ways of fixing these violations.", "num_citations": "10\n", "authors": ["651"]}
{"title": "Issues of data scalability in open hypermedia systems\n", "abstract": " One requirement placed on open hypermedia technology is the ability to support relationship management in large-scale information environments. We examine the issues of scalability encountered in supporting open hypermedia in a large-scale software development environment. The World Wide Web is discussed as an alternative approach to supporting relationship management in these environments and we identify reasons why open hypermedia is a superior approach. We also report on a research project where the Chimera open hypermedia system was used to support the relationship management needs of an industrial-scale development project of an aerospace organization. The results of this project supply insights to developers about the implications of supporting data scalability in open hypermedia systems. We conclude by evaluating the level of scalability achieved by our efforts and describe our\u00a0\u2026", "num_citations": "10\n", "authors": ["651"]}
{"title": "Using structural computing to support information integration\n", "abstract": " Software engineers face a dificult task in managing the many different types of relationships that exist between the documents of a software development project. We refer to this task as information integration, since establishinga relationship between two documents typically means that some part of the information in each document is semantically related. A key challenge in information integration is providing techniques and tools that manage and evolve these relationships over time. The structural computing domain provides a set of principles to derive new techniques and tools to help with these tasks of relationship management and evolution. We present a prototype information integration environment, InfiniTe, and describe how we are exploiting structural computing principles in the design of its infrastructure services.", "num_citations": "9\n", "authors": ["651"]}
{"title": "Using XML to support Information Integration\n", "abstract": " Software engineers face overwhelming information management tasks, such as performing requirements traceability between the artifacts of a software development project, or ensuring that these artifacts are consistent with one another over time. These tasks are hindered because software artifacts are created with a multitude of tools and are stored in a variety of data formats, and none (or few) of these tools were designed to interoperate or make it easy to share information. We describe an approach to information integration based on open hypermedia to address these problems and deliver powerful information management tools into the hands of software engineers. Although the work is preliminary, the existing prototypes make significant use of XML which enables a degree of flexibility and extensibility not normally found in prototype software tools. We reflect on these features and discuss our future plans for use of XML within the information integration environment.", "num_citations": "9\n", "authors": ["651"]}
{"title": "Batch to real-time: Incremental data collection & analytics platform\n", "abstract": " Real-time data collection and analytics is a desirable but challenging feature to provide in dataintensive software systems. To provide highly concurrent and efficient real-time analytics on streaming data at interactive speeds requires a welldesigned software architecture that makes use of a carefully selected set of software frameworks. In this paper, we report on the design and implementation of the Incremental Data Collection & Analytics Platform (IDCAP). The IDCAP provides incremental data collection and indexing in real-time of social media data; support for real-time analytics at interactive speeds; highly concurrent batch data processing supported by a novel data model; and a front-end web client that allows an analyst to manage IDCAP resources, to monitor incoming data in real-time, and to provide an interface that allows incremental queries to be performed on top of large Twitter datasets.", "num_citations": "8\n", "authors": ["651"]}
{"title": "Using open hypermedia to support information integration\n", "abstract": " The task of information integration challenges software engineers on a daily basis. Software artifacts, produced during software development, contain many implicit and explicit relationships whose sheer numbers quickly overwhelm a software team\u2019s ability to understand, manipulate, and evolve them. We are developing an information integration environment to aid software engineers in tackling this dificult task and are making use of open hypermedia techniques to enable critical characteristics of the environment, such as third-party tool integration, typed links, and a partitioned information space through the use of contexts, traditionally referred to as composites. We describe our prototype implementation of the information integration environment, focusing on how open hypermedia has either influenced the design of the environment, or contributed directly to its functional capabilities.", "num_citations": "8\n", "authors": ["651"]}
{"title": "Structural computing requirements for the transformation of structures and behaviors\n", "abstract": " The field of structural computing is a new paradigm of computation based on structure as opposed to data. Initial work in this area has suggested the need for the transformation of structures, especially when considering the interpretation of a structure from domain A within domain B. This work examines the need for formal mechanisms to specify both structures and the legal ways in which structures can be transformed from one structure to another. We motivate this discussion with an example from the domain of programming languages. In addition, we briefly present an example from the domain of genetic algorithms that suggests the need to consider transformations on behaviors as well. We conclude by enumerating the benefits to structural computing if such formalisms are developed and suggest possible first avenues of exploration.", "num_citations": "8\n", "authors": ["651"]}
{"title": "Integrating Infrastructure: enabling large-scale client integration\n", "abstract": " The open hypermedia community has addressed issues of client integration\u2014providing hypermedia services in thirdparty applications\u2014over the past decade. As a result, a set of models and techniques has emerged to guide developers in the task of integrating hypermedia services into their applications. We argue that the logical next step for the open hypermedia community is to develop techniques for integrating massive numbers of clients in tandem. Our approach consists of integrating existing infrastructure mechanisms that are already used by numerous applications. We believe that integrating an underlying infrastructure can provide a basic level of hypermedia functionality to client applications while reducing the level of effort required of application developers. We present issues encountered in performing client-integration-in-the-large, discuss an experimental prototype of a specific infrastructure integration\u00a0\u2026", "num_citations": "7\n", "authors": ["651"]}
{"title": "Engineering scalable distributed services for real-time big data analytics\n", "abstract": " There is high demand for tools that analyze large sets of streaming data in both industrial and academic settings. While existing work has examined a wide range of issues, we focus on query support. In particular, we focus on providing analysts flexibility with respect to the types of queries they can make on large data sets in real time as well as over historical data. We have designed and implemented a lightweight service-based framework-EPIC Real-Time-that manages a set of queries that can be applied to user-initiated data analysis events (such as studying tweets generated during a disaster). Our prototype combines stream processing and batch processing techniques inspired by the Lambda Architecture. We investigate a core set of query types that can answer a wide range of queries asked by analysts who study crisis events. In this paper, we present a prototype implementation of EPIC Real-Time which\u00a0\u2026", "num_citations": "6\n", "authors": ["651"]}
{"title": "Representing our information structures for research and for everyday use\n", "abstract": " We argue for a methodology and supporting infrastructure that promotes a cross-study investigation of information structure to advance the science of personal information management. Moreover, we observe that the infrastructure to support a methodology of scientific inquiry may have direct application to users as they struggle to manage their information. Research on information structure reaches towards a new age in information management wherein organizing information structures grow and change over time based on the internal needs of their owners and not the external demands of tools.", "num_citations": "6\n", "authors": ["651"]}
{"title": "Towards lightweight structural computing techniques with the smallsc framework\n", "abstract": " Since 1997 a significant amount of research has been conducted on the topic of structural computing, leading to the creation of several structural computing systems. Unfortunately, many of these systems require a considerable amount of infrastructure making it difficult for these systems to be used by anyone except their original developers. This situation has hindered the adoption of structural computing techniques by researchers outside of the structural computing field. This paper reports on an effort to create an extensible data model that embodies some of the lessons learned from structural computing research while also being packaged in such a way to enable its easy adoption. We report on how we have used this model in three separate systems and discuss ways in which the model can be enhanced in the future. The paper ends with a call to the structural computing community to form a working group that\u00a0\u2026", "num_citations": "6\n", "authors": ["651"]}
{"title": "Examining the Replication\u2014or Mutation\u2014Processes of Implementing a National Model for Engineering Mathematics Education at a New Site\n", "abstract": " This research paper investigates how a renowned national model for engineering mathematics education is adapted and adjusted for implementation within a new large public university site, and the consequences of these modifications for students, instructors, administrators, and institutions. By examining how elements of the original Wright State Model are replicated or mutated in the process of starting a pilot course, we illustrate not just the challenges inherent to creating a new course in a new place but also the ways seemingly neutral and benign objects (such as course numbers and course titles) are transformed and modified to suit local contexts. Further, we show what is lost and gained through the adaptation and conversion processes of moving an established course model from one institution to another. We argue that these negotiations and local compromises are worthy of detailed examination to understand more about the existing social organization of academic institutions in order to reveal structures that both limit and enable the success or failure of educational initiatives and innovations. This paper integrates ethnographic data, institutional artifacts, and student survey responses to demonstrate how the pilot course implementation is not a one-to-one replication of the original model; rather it is a mutation of how the course exists at Wright State. Viewing the course as a mutation enables a deeper analysis of the institutional processes required to instantiate a new educational initiative within existing systems, curricula, and infrastructures, with implications for engineering educators looking to make positive change within their home\u00a0\u2026", "num_citations": "5\n", "authors": ["651"]}
{"title": "Places of our own for digital information: building structures that work for individuals and small groups\n", "abstract": " Structuring items such as folders and tags bring many benefits. Indeed, the very act of structuring may help people to make sense of their information. But structures can also confine and clutter. Some structures are created and never used. Other structures are used differently by different members of a group or by the same person at different points in time. More serious, structures are often \u201clocked\u201d within specific tools. Using tools may mean the inconsistent duplication and maintenance of a structure many times over. Resulting problems of information fragmentation are made worse as personal information moves onto a variety of devices and into a \u201ccloud\u201d of web-based devices and services.We argue for a methodology and supporting infrastructure to promote a cross-study investigation of information structure. Moreover, we observe that the infrastructure to support a methodology of scientific inquiry may have direct application to users as they struggle to manage their information. Research on information structure reaches towards a new age in information management wherein organizing information structures grow and change over time based on the internal needs of their owners and not the external demands of tools..", "num_citations": "5\n", "authors": ["651"]}
{"title": "Providing decision support for cosmogenic isotope dating\n", "abstract": " Human experts in scientific fields routinely work with evidence that is noisy and untrustworthy, heuristics that are unproven, and possible conclusions that are contradictory. We present a deployed AI system, Calvin, for cosmogenic isotope dating, a domain that is fraught with these difficult issues. Calvin solves these problems using an argumentation framework and a system of confidence that uses two-dimensional vectors to express the quality of heuristics and the applicability of evidence. The arguments it produces are strikingly similar to published expert arguments. Calvin is in daily use by isotope dating experts.", "num_citations": "5\n", "authors": ["651"]}
{"title": "Client-Side Services for Open Hypermedia-Getting past the \u201cfoo\u201d\n", "abstract": " One important aspect of the work on the Open Hypermedia Protocol has been defining the set of services assumed to be available in the user\u2019s host environment. These services, collectively known as the client-side foo, have a variety of duties including process invocation, message routing, protocol conversion, user and client tracking, and providing the interface to a set of standard client-side tools. This paper attempts to collate all of the functionality that has been assigned to the client-side foo and then examine ways in which the functionality can be achieved in a platformindependent fashion.", "num_citations": "5\n", "authors": ["651"]}
{"title": "Extending user-interface toolkits with hypermedia functionality\n", "abstract": " This paper describes a technique for extending user interface toolkits with hypermedia functionality. The technique employs a separation-of-concerns approach which is incremental, reusable, and maintainable. The essence of the approach is to integrate a user interface toolkit with an open hypermedia system. The integration occurs through a set of integrated widgets and a hypermedia infrastructure. The infrastructure acts as a gateway between the toolkit and the open hypermedia system. The integrated widgets use the infrastructure to augment their behavior with hypermedia services. Applications constructed with the resulting toolkit contain hypermedia enabled widgets, automatically providing consistent cross application hypermedia services with little effort required by the application developer. The benefits of generalizing the technique to other services, such as groupware, are also discussed.", "num_citations": "5\n", "authors": ["651"]}
{"title": "Diaphragmatic paralysis in motor neurone disease: use of non-invasive investigative and therapeutic techniques.\n", "abstract": " Two cases of bilateral diaphragmatic weakness are described in which the condition was the presenting feature of motor neurone disease. Inspiratory muscle strength was assessed by a non-invasive technique involving measurements of pressures generated within the mouth. One patient with severe inspiratory muscle weakness is being treated with domiciliary nasal ventilation and has returned to a good-quality life. The other patient with less severe weakness has thus far required no ventilatory support.", "num_citations": "5\n", "authors": ["651"]}
{"title": "A comparison of two types of electrospun chitosan membranes and a collagen membrane in vivo\n", "abstract": " BackgroundElectrospun chitosan membranes subjected to post-spinning processes using either triethylamine/tert-butyloxycarbonyl (TEA/tBOC) or butyryl-anhydride (BA) modifications to maintain nanofiber structure have exhibited potential for use in guided bone regeneration applications. The aim of this study was to evaluate ability of the modified membranes to support healing of bone-grafted defects as compared to a commercial collagen membrane.MethodTEA/tBOC-treated and BA-treated chitosan membranes were characterized for fiber morphology by electron microscopy, residual trifluoroacetic acid by19F NMR and endotoxin level using an endotoxin quantitation kit (ThermoScientific, US). Chitosan membranes were cut into 12 mm diameter disks. An 8 mm calvarial defect was created in each of 48 male rats and then filled with Bio-Oss (Geistlich, US) bone graft. The grafted defects were covered with either\u00a0\u2026", "num_citations": "4\n", "authors": ["651"]}
{"title": "Scaling Up or Scale-making? Examining Sociocultural Factors in a New Model for Engineering Mathematics Education\n", "abstract": " Researchers have pointed to Wright State\u2019s Introductory Mathematics for Engineering Applications course as a model for undergraduate engineering education curricular reform. The work behind the Wright State Model (WSM) demonstrates that adoption of its introductory course can increase engineering student retention, motivation, and academic success (N. Klingbeil, Mercer, Rattan, Raymer, & Reynolds, 2006; N. Klingbeil & Bourne, 2013), and can remove \u201cthe first-year bottleneck\u201d associated with the traditional first-year calculus sequence (Ohland, Yuhasz, & Sill, 2004; N. Klingbeil & Bourne, 2013; Long, Abrams, Barclay, & Paulson, 2016). Klingbeil & Bourne (2013) point to the promise of the Wright State Model in engineering education reform, claiming that the model \u201cis designed to be readily adopted by any institution employing a traditional engineering curriculum\u2026 should it be sufficiently scaled\u2026 the Wright State approach has the potential to double the number of our nation\u2019s engineering graduates, while both maintaining their quality and increasing their diversity\u201d(p. 10, emphasis added). In our analysis, we reconsider the \u201cdiffusion\u201d notion of \u201cscaling\u201d as it is typically used in educational research (McDonald, Keesler, Kauffman, & Schneider, 2006), proposing instead that innovations and adaptations are better conceived in terms of what educational anthropologists have called \u201cscale-making\u201d(Nespor, 2004). According to this perspective, scale-making is an active process of forming connections between, on one hand, new practices such as the WSM course, and on the other hand, existing networks that operate at a broader\u00a0\u2026", "num_citations": "4\n", "authors": ["651"]}
{"title": "Forensic Reasoning and Paleoclimatology: Creating a System That Works\n", "abstract": " Human experts in many scientific fields routinely work with data that are heterogeneous, noisy, and/or uncertain, as well as with heuristics that are unproven and with possible conclusions that are contradictory. We present a deployed software system for cosmogenic isotope dating, a domain that is fraught with these difficult issues. This system, which is called ACE (\u201cage calculation engine\u201d), takes as inputs the nuclide densities in a set of rock samples from a landform. It answers the scientific question \u201cWhat geological processes could have produced this distribution of nuclide concentrations, and over what time scales?\u201d ACE employs an encoded knowledge base of the possible processes that may have acted on that landform in the past, complete with the mathematics of how those processes can affect samples, and it uses a workflow system to encode the computations associated with this scientific analysis. Flexibility and extensibility were critical issues in ACE\u2019s design to allow its scientist-users to modify and extend it after its developers were no longer involved. The success of this is evident; the system remains in active use to this day, several years after the development cycle ended, without a single request for help from the geoscientists to the computer science side of the team. The ACE project website has received over 17,000 hits since 2008, including 2500 over the last twelve months. The software (\u223c 20,000 lines of Python code) has been downloaded nearly 600 times as of April 2013, which is a significant number in a research community of a few hundred PI-level scientists.", "num_citations": "4\n", "authors": ["651"]}
{"title": "Arguing about radioisotope dating\n", "abstract": " We present a prototype of the AICronus system, an argumentation system that automates a challenging reasoning process used by experts in cosmogenic isotope dating. The architecture of the system is described and preliminary results are discussed.", "num_citations": "4\n", "authors": ["651"]}
{"title": "iCronus: a computational tool for cosmogenic nuclide dating\n", "abstract": " iCronus is a freely available tool to estimate landform ages using cosmogenic nuclide techniques. It is a Web application built on top of a platform independent scripting language, allowing it to be hosted on a wide range of computing platforms and accessed by users using standards-compliant Web browsers. The iCronus project intends to create a publicly accessible website that contains published samples, modules, and workflows that can be downloaded and used by other users of the iCronus prototype. This will facilitate a managed approach for the sharing of information between different research groups performing work on cosmogenic nuclide techniques. For a sample with assumed tectonic and erosional history the sensitivity of calculated age to these processes can be determined. A future version of iCronus will also incorporate effects due to an assumed climatic history. For a particular sample iCronus is\u00a0\u2026", "num_citations": "4\n", "authors": ["651"]}
{"title": "MatDL. org: The Materials Digital Library and the National Science Digital Library Program\n", "abstract": " The National Science Foundation's National Science Digital Library (NSDL) Program is a premier collective portal of authoritative scientific resources supporting education and research. With funding from NSF, the Materials Digital Library (MatDL) is a collaborative project being developed by the National Institute of Standards and Technology's Materials Science and Engineering Laboratory (NIST/MSEL), the Department of Materials Science and Engineering at the Massachusetts Institute of Technology (MIT), the Department of Chemical Engineering and the Department of Materials Science and Engineering at the University of Michigan (U-M), with Kent State University and University of Colorado at Boulder providing the materials science informatics and workflow technology backbone. As part of the NSDL program, MatDL aims to supports the interface of materials science information and its cognate disciplines\u00a0\u2026", "num_citations": "4\n", "authors": ["651"]}
{"title": "Pervasive hypermedia\n", "abstract": " The heterogeneity of modern computing environments contributes to the information overload experienced by users. Relationships within and between applications, documents, and processes are often implicit and must be managed and tracked by the user. Hypermedia has been put forth as one approach to organizing these relationships, making them explicit so they can be managed. One approach to providing environment-wide hypermedia services is through the use of open hypermedia systems (OHSs). OHSs are open with respect to the set of systems and information over which hypermedia services can be provided. This research area contrasts with the original approach to hypermedia services that involved developing monolithic systems with a closed set of supported data types (eg HyperCard). Given the existence of OHSs, another area of research is developing integration techniques such that\u00a0\u2026", "num_citations": "4\n", "authors": ["651"]}
{"title": "Oral Manifestations of Syphilis: a Review of the Clinical and Histopathologic Characteristics of a Reemerging Entity with Report of 19 New Cases\n", "abstract": " BackgroundSyphilis is a sexually-transmitted infectious disease caused by Treponema pallidum. Cases of primary and secondary syphilis are on the rise in the United States, with a 14.4% increase in new cases noted from 2017 to 2018 and an escalation of 71% between the years 2014 and 2018. Fulfilling its nickname of \u201cthe great imitator,\u201d oral manifestations of syphilis may mimic a variety of infectious, neoplastic, or immune-mediated processes, both clinically and histopathologically. This large spectrum of appearances can create a diagnostic challenge to the clinician and/or pathologist, leading to delay in diagnosis or misdiagnosis.MethodsA database of oral syphilis cases was created from archives at the University of Kentucky, University of Pittsburgh, LIJMC, Columbia University MC, and University of Tennessee. The age, sex, race, location, duration, and clinical description were recorded. Cases without\u00a0\u2026", "num_citations": "3\n", "authors": ["651"]}
{"title": "A metainformatical view of collections\n", "abstract": " Collections are implemented in many ways, depending on the purpose they serve and their implementation environment. We approach collections as entity containers and, from principles discovered through our structural computing work, we propose a metainformatical view of generalized collections, and a theoretical framework for discussing collection variations. Included in the framework is the idea of accessing generalized collection content through views, with support for multiple views per collection. The importance of associating semantics with both collections and the views of their content is noted, as are techniques for preserving those semantics. Set, bag, array, and relational table implementations are shown to fit into this framework. The paper closes with a summary of the advantages of our approach, along with a discussion of future and related work.", "num_citations": "3\n", "authors": ["651"]}
{"title": "iCRONUS meets CRONUS-Earth: improved calculations for cosmogenic dating methods\u2013from neutron intensity to previously ignored correction factors\n", "abstract": " Conclusion: In addition to latitude, longitude and altitude, whose effects on cosmogenic production rates have been worked out, the following environmental variables cause large (non-negligible) variations in cosmogenic production rates: eustatic sea-level changes, pressure, temperature and temperature lapse rate. Accounting for these variables improves the internal consistency of calibration data sets. Rigorous models and databases describing these effects are under construction, and will be presented in December.", "num_citations": "3\n", "authors": ["651"]}
{"title": "Software engineering and the cobbler\u2019s barefoot children, revisited\n", "abstract": " While the World-Wide-Web is demonstrably useful for a wide variety of tasks, in its current form it is not capable of supporting wide-area software development activities. This report describes the following areas for improvement and indicates key directions and approaches for their achievement:", "num_citations": "3\n", "authors": ["651"]}
{"title": "Intended and Unintended Consequences of Rapidly Expanding an Engineering Mathematics Intervention for Incoming First-Year Students\n", "abstract": " BackgroundBased on other implementations of the WSM model, Engineering Math was intended for firsttime, first-year engineering students with the goal of improving engineering persistence [4],[5]. In fall 2017 (Y1), one section of Engineering Math was piloted in the College of Engineering with a target course enrollment of 32; 22 students earned a grade in the course and one withdrew at the end of the term.", "num_citations": "2\n", "authors": ["651"]}
{"title": "Getting the query right for crisis informatics design issues for web-based analysis environments\n", "abstract": " Web-based data analysis environments are powerful platforms for exploring large data sets. To ensure that these environments meet the needs of analysts, a human-centered design perspective is needed. Interfaces to these platforms should provide exible search, support user-generated content, and enable collaboration. We report on our eorts to design and develop a web interface for a custom analytics platform| EPIC Analyze| which provides interactive search over large Twitter data sets collected during crisis events. We performed seven think-aloud sessions with researchers who regularly analyze crisis data sets and compiled their feedback. They identied a need for a\\big picture\" view of an event, exible querying capabilities, and user-dened coding schemes. Adding these features allowed EPIC Analyze to meet the needs of these analysts and enable exploratory research on crisis data. In performing this work, we identied an opportunity to migrate the software architecture of EPIC Analyze to one based on microservices. We report on the lessons learned in performing this migration and the impact it had on EPIC Analyze's capabilities. We also re ect on the benets a microservices approach can have on the design of data-intensive software systems like EPIC Analyze.", "num_citations": "2\n", "authors": ["651"]}
{"title": "Extending types to modelling problem-space entities\n", "abstract": " Structural computing has evolved from work on open hypermedia to aid in the construction of domain-specific software infrastructure and tools. Part of the premise of structural computing has been that by focusing on the abstraction of structure rather than on a concrete data layer, it should make it easier for developers to use appropriate levels of abstraction to build applications. By using the appropriate level of abstraction, the resulting systems can represent components in ways that closely reflect the problem space, instead of forcing the problem into an implementation-centric paradigm. Our previous work has concentrated on how to accomplish these ends through the abstraction of data\u2014this paper concentrates on the benefits of abstraction of type. As our concern is primarily with modelling the problem space in an application domain, we approach \u2018type\u2019 initially from a problem-space viewpoint, not from a\u00a0\u2026", "num_citations": "2\n", "authors": ["651"]}
{"title": "Configuration management culture as the kernel to success in Software Process Improvement efforts\n", "abstract": " For a Software Process Improvement (SPI) effort to succeed, its participants must have a sense of ownership. One practical technique for achieving that sense of ownership is to apply a meta-process based on the principals of configuration management (CM) to the SPI effort. This paper provides insight into issues of ownership surrounding actual SPI efforts and describes the use of a CM-based meta-process that successfully supported one of these efforts.", "num_citations": "2\n", "authors": ["651"]}
{"title": "Introduction to SC2\n", "abstract": " The hypermedia community has engaged in open hypermedia research for well over a decade. Open hypermedia is an approach to providing hypermedia services to multiple users over heterogeneous information managed by an open set of applications. However, the conceptual foundations of open hypermedia\u2014its underlying structures and behaviors\u2014have all focused on supporting one task: information navigation. While these structures are flexible enough to be applied to other domains, the mappings are often inefficient and unsatisfying. In fact, concurrent with open hypermedia research, several researchers were exploring domains such as spatial hypermedia and taxonomic hypermedia that required conceptual foundations markedly different from those used to support navigational hypermedia.", "num_citations": "2\n", "authors": ["651"]}
{"title": "ML-EPIC: Collection and Translation of Multilingual Social Media Data\n", "abstract": " Data-intensive systems are powerful platforms for collecting and exploring big data. Project EPIC (Empowering the Public with Information in Crisis) has been designing and developing data-intensive systems in support of crisis informatics research since Fall 2009. However, Project EPIC (https://epic. cs. colorado. edu/) has always focused on collecting and analyzing tweets written in English, which raises an interesting question: how do we collect and get insight into tweets from multiple languages during crisis events? We report on our efforts to design and develop a multilingual cloud-based analytical platform---ML-EPIC---which enhances Project EPIC's ability to perform crisis informatics research on global events. More generally, our research provides insight into tackling the challenges of big data in a multilingual context.", "num_citations": "1\n", "authors": ["651"]}
{"title": "Pre-Cancer and Cancer\n", "abstract": " Description: Actinic cheilitis is an irreversi le precancerous change of the lower lip vermillion. Adult males are the predominant demographic group affected and fair-skinned individuals or those who have an outdoor occupation are at greatest risk. Early changes include the development of lotchy\u01f0 pale areas and an indistinct margin etween the lip vermillion and skin. Rough\u01f0 scaly areas\u01f0 leukoplakia\u01f0 and ulceration may develop as the lesion progresses.Etiology: Chronic sun exposureTreatment: Patients should e encouraged to use lip sunscreens or road-rimmed hats to protect the lip from further damage when outdoors. Scaly\u01f0 ulcerated\u01f0 or indurated areas should e iopsied to evaluate for the possi ility of transformation to squamous cell carcinoma. Extensive involvement may require vermillionectomy\u01f0 a procedure where the entire lip vermillion is removed and the la ial mucosa is pulled forward.Prognosis: Good. Actinic cheilitis ehaves similarly to actinic keratosis of the skin. Over time\u01f0 a small proportion of lesions will undergo malignant transformation\u01f0 which is generally amena le to surgical excision.Differential diagnosis: Cheilocandidiasis\u01f0 lip chapping\u01f0 traumatic ulcer \u0169 OLFHQVHH, Q7HFK 7KLV LV DQ RSHQ DFFHVV DUWLFOH GLVWULEXWHG XQGHU WKH WHUPV RI WKH &UHDWLYH &RPPRQV $ WWULEXWLRQ/LFHQVH KWWS FUHDWLYHFRPPRQV RUJ OLFHQVHV E\\ZKLFK SHUPLWV XQUHVWULFWHG XVH GLVWULEXWLRQ DQG UHSURGXFWLRQ LQ DQ\\PHGLXP SURYLGHG WKH RULJLQDO ZRUN LV SURSHUO\\FLWHG", "num_citations": "1\n", "authors": ["651"]}
{"title": "Enabling Project Awareness and Intersubjectivity via Hypermedia-Enabled Event Trails; CU-CS-911-00\n", "abstract": " Supporting project awareness in the context of large-scale software development is difficult. One key problem is identifying appropriate abstractions and techniques for the insertion of project awareness mechanisms into a software development environment with minimal impact. An additional problem is scaling project awareness mechanisms to handle the demands of large-scale software development projects. We present a framework to support awareness and intersubjectivity among software team members through the use of automatically collected, hypermedia-enabled event trails. Event notification and open hypermedia concepts, techniques, and tools are used to support the framework in addressing the two problems identified above. A distinction of the framework is the presence of mechanisms that explicitly support intersubjectivity among team members, enabling a high degree of quality to the project awareness in the team.", "num_citations": "1\n", "authors": ["651"]}
{"title": "Biopsy Technique and Histopathological Diagnosis of Oral Squamous Cell Carcinoma of the Tongue-A Case Report\n", "abstract": " Introduction: Early detection and diagnosis of oral cancer can increase cure rates from up to 50% to 80% and also improves the quality of life by decreasing the extent of debilitating treatments. Tobacco smoking, alcohol, betel quid, immunocompromised states are some of the known risk factors of the disease. It is important to not only address the patient\u2019s chief complaint but to do a comprehensive oral examination to rule out suspicious lesions especially in patients presenting with known risk factors.Case Presentation: A 59-year old female patient presenting for treatment of periodontitis shows a non-scrapable red-white lesion with indurate borders on the lateral and ventral aspect of tongue undergoes biopsy for a histopathological diagnosis of well-differentiated oral squamous cell carcinoma.Conclusion: Oral cancer screening is necessary at routine dental appointments, particularly for smokers to provide early detection and appropriate management.", "num_citations": "1\n", "authors": ["651"]}
{"title": "Providing Automatic Support for Extra-Application Hypertext Functionality\n", "abstract": " This paper describes a technique to automatically provide extra-application hypertext functionality for client applications. After an introduction to the topic area, the paper discusses the key parts of the technique and outlines a design for implementing a proof-of-concept prototype. The paper concludes with a discussion of the technique's implications on the issues of extra-application hypertext functionality.", "num_citations": "1\n", "authors": ["651"]}