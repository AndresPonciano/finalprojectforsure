{"title": "Scalability, elasticity, and efficiency in cloud computing: A systematic literature review of definitions and metrics\n", "abstract": " Context: In cloud computing, there is a multitude of definitions and metrics for scalability, elasticity, and efficiency. However, stakeholders have little guidance for choosing fitting definitions and metrics for these quality properties, thus leading to potential misunderstandings. For example, cloud consumers and providers cannot negotiate reliable and quantitative service level objectives directly understood by each stakeholder. Objectives: Therefore, we examine existing definitions and metrics for these quality properties from the viewpoint of cloud consumers, cloud providers, and software architects with regard to commonly used concepts. Methods: We execute a systematic literature review (SLR), reproducibly collecting common concepts in definitions and metrics for scalability, elasticity, and efficiency. As quality selection criteria, we assess whether existing literature differentiates the three properties, exemplifies\u00a0\u2026", "num_citations": "112\n", "authors": ["1964"]}
{"title": "CloudStore\u2014towards scalability, elasticity, and efficiency benchmarking and analysis in Cloud computing\n", "abstract": " This paper describes CloudStore, an open source application that lends itself to analyzing key characteristics of Cloud computing platforms. Based on an earlier standard from transaction processing, it represents a simplified version of a typical e-commerce application\u2013an electronic book store. We detail how a deployment on a popular public cloud offering can be instrumented to gain insight into system characteristics such as capacity, scalability, elasticity and efficiency. Based on our insights, we create a CloudStore performance model, allowing to accurately predict such properties already at design time.", "num_citations": "44\n", "authors": ["1964"]}
{"title": "Modeling and extracting load intensity profiles\n", "abstract": " Today\u2019s system developers and operators face the challenge of creating software systems that make efficient use of dynamically allocated resources under highly variable and dynamic load profiles, while at the same time delivering reliable performance. Autonomic controllers, for example, an advanced autoscaling mechanism in a cloud computing context, can benefit from an abstracted load model as knowledge to reconfigure on time and precisely. Existing workload characterization approaches have limited support to capture variations in the interarrival times of incoming work units over time (i.e., a variable load profile). For example, industrial and scientific benchmarks support constant or stepwise increasing load, or interarrival times defined by statistical distributions or recorded traces. These options show shortcomings either in representative character of load variation patterns or in abstraction and flexibility of\u00a0\u2026", "num_citations": "42\n", "authors": ["1964"]}
{"title": "Engineering Scalable, Elastic, and Cost-Efficient Cloud Computing Applications: The CloudScale Method\n", "abstract": " This book provides an overview of the problems involved in engineering scalable, elastic, and cost-efficient cloud computing services and describes the CloudScale method\u2014a description of rescuing tools and the required steps to exploit these tools. It allows readers to analyze the scalability problem in detail and identify scalability anti-patterns and bottlenecks within an application. With the CloudScale method, software architects can analyze both existing and planned IT services.", "num_citations": "20\n", "authors": ["1964"]}
{"title": "Applying architectural templates for design-time scalability and elasticity analyses of saas applications\n", "abstract": " Software architects plan, model, and analyze architectures of large software like Software-as-a-Service (SaaS) applications. The scalability and elasticity of these applications is crucially impacted by architects' early decision for an architectural style. However, whether this decision fostered scalability and elasticity can currently only be tested with the final application deployed in the target cloud computing environment. This process leads to the high risk of unsatisfying scalability/elasticity and expensive re-implementations.", "num_citations": "17\n", "authors": ["1964"]}
{"title": "Approaching the Cloud: Using Palladio for Scalability, Elasticity, and Efficiency Analyses.\n", "abstract": " In cloud computing, software architects develop systems for virtually unlimited resources that cloud providers account on a pay-per-use basis. Elasticity management systems provision these resource autonomously to deal with changing workloads. Such changing workloads call for new objective metrics allowing architects to quantify quality properties like scalability, elasticity, and efficiency, eg, for software design analysis. However, analysis approaches such as Palladio so far did not support these novel metrics, thus rendering such analyzes inefficient. To tackle this problem, we (1) extended Palladio\u2019s simulation approach SimuLizar by additional metrics for scalability, elasticity, and efficiency and (2) integrated the Architectural Template language into Palladio allowing architects to model cloud computing environments efficiently. A novel analysis process guides software architects through these new capabilities. In this paper, we focus on illustrating this new process by analyzing a simple, self-adaptive system.", "num_citations": "15\n", "authors": ["1964"]}
{"title": "Efficiently conducting quality-of-service analyses by templating architectural knowledge\n", "abstract": " Previously, software architects were unable to effectively and efficiently apply reusable knowledge (eg, architectural styles and patterns) to architectural analyses. This work tackles this problem with a novel method to create and apply templates for reusable knowledge. These templates capture reusable knowledge formally and can efficiently be integrated in architectural analyses.", "num_citations": "12\n", "authors": ["1964"]}
{"title": "Architectural Templates: Engineering Scalable SaaS Applications Based on Architectural Styles.\n", "abstract": " Software architects plan, model, and analyze the high-level design of software systems. Today, these systems are often deployed in cloud computing environments as Software-as-a-Service (SaaS) applications. The scalability of these applications is crucially impacted by architects\u2019 early design decisions. Architects decide based on their experience and known architectural styles like a 3-tier architecture. In new application domains, however, architects lack the experience to determine whether their designs will result in scalable implementations. This lack leads to the high risk of unsatisfying scalability and expensive reimplementations.To tackle this problem, we propose initial ideas and concepts for architectural templates (ATs), defined as a language to formalize architectural styles on component models. This formalization allows to enrich styles by quality annotations and completions for model-driven quality analyses. As we focus on SaaS applications, we exemplify this idea by enriching ATs by scalability annotations and completions allowing architects to analyze their applications\u2019 scalability. To illustrate such an analysis, we introduce and use a toy example. Based on this example, we derive initial working packages describing how we plan to realize and validate ATs.", "num_citations": "12\n", "authors": ["1964"]}
{"title": "The architectural template method: templating architectural knowledge to efficiently conduct quality\u2010of\u2010service analyses\n", "abstract": " Software architects plan the realization of software systems by assessing design decisions on the basis of architectural models. Using these models as input, architectural analyses assess the impact of architects' decisions on quality\u2010of\u2010service properties. While the creation of suitable architectural models requires software architects to apply complex architectural knowledge, for example, in the form of established architectural styles and patterns, current architectural analyses lack support for directly reusing such knowledge. This lack points to an unused potential to make the work of software architects more effective and efficient. To use this potential, we introduce the architectural template (AT) method, an engineering method that makes design\u2010time analyses of quality\u2010of\u2010service properties of software systems more efficient. The AT method allows to quantify quality\u2010of\u2010service properties on the basis of reusable\u00a0\u2026", "num_citations": "10\n", "authors": ["1964"]}
{"title": "Parallelization, modeling, and performance prediction in the multi-/many core area: A systematic literature review\n", "abstract": " Context: Software developers face complex, connected, and large software projects. The development of such systems involves design decisions that directly impact the quality of the software. For an early decision making, software developers can use model-based prediction approaches for (non-)functional quality properties. Unfortunately, the accuracy of these approaches is challenged by newly introduced hardware features like multiple cores within a single CPU (multicores) and their dependence on shared memory and other shared resources. Objectives: Our goal is to understand whether and how existing model-based performance prediction approaches face this challenge. We plan to use gained insights as foundation for enriching existing prediction approaches with capabilities to predict systems running on multicores. Methods: We perform a Systematic Literature Review (SLR) to identify current model\u00a0\u2026", "num_citations": "10\n", "authors": ["1964"]}
{"title": "Performance prototyping with protocom in a virtualised environment: A case study\n", "abstract": " Performance prototyping is an often used technique to assess the performance of software architectures early in the development process without relying on models of the system under study. ProtoCom is a prototype generator for the PCM realised as model-2-text transformation for which no experience report in a larger, virtualised setting exists. In this paper, we report on four case studies performed with an improved version of ProtoCom and report on the results gained with respect to analysis accuracy and usability. Our results demonstrate that the new version is much easier to use than previous versions and that results gained in our virtualised execution environment help in early assessments of performance under realistic conditions.", "num_citations": "10\n", "authors": ["1964"]}
{"title": "Towards Integrating Java EE into ProtoCom.\n", "abstract": " A key concept of model-driven software development is the transformation of models into other models or source code. ProtoCom is such a transformation that generates a performance prototype from a Palladio Component Model (PCM) instance by means of a model-to-text transformation. The actual supported platform, on which the PCM instance is mapped, is Java SE. Even though related work suggests that multiple platforms should be supported, their concrete integration into ProtoCom is only conceptual. For instance, Java EE has been investigated as a possible target platform, however, ProtoCom lacks its integration as well as the consideration of the current Java EE standard. Therefore, we provide a novel conceptual mapping from PCM to Java EE, thus, allowing to implement a transformation that realizes the mapping. As basis for this implementation, we also provide an initial Java EE reference implementation of a simple example PCM model.", "num_citations": "6\n", "authors": ["1964"]}
{"title": "Using Java EE ProtoCom for SAP HANA Cloud.\n", "abstract": " Performance engineers analyze the performance of software architectures before their actual implementation to resolve performance bottlenecks in early development phases. Performance prototyping is such an approach where software architecture models are transformed to runnable performance prototypes that can provide analysis data for a specific target operation platform. This coupling to the operation platform comprises new challenges for performance prototyping in the context of cloud computing because a variety of different cloud platforms exists. Because the choice of platform impacts performance, this variety of platforms induces the need for prototype transformations that either support several platforms directly or that are easily extensible. However, current performance prototyping approaches are tied to only a small set of concrete platforms and lack an investigation of their extensibility for new platforms, thus rendering performance protoyping ineffective for cloud computing. To cope with this problem, we extended Palladio\u2019s performance prototyping approach ProtoCom by an additional target platform, namely the SAP HANA Cloud, and analyzed its extensibility during the extension process. In this tool paper, we focus on illustrating the capabilities of our extension of ProtoCom. For this illustration, we use a simple example system for which we create a ProtoCom performance prototype. We particularly run this prototype in the SAP HANA Cloud, thereby showing that our extension can efficiently be applied within a practical context.", "num_citations": "5\n", "authors": ["1964"]}
{"title": "Reuse and configuration for code generating architectural refinement transformations\n", "abstract": " The transformation of component-based architectures into object-oriented source code for different platforms is a common task in Model-Driven Software Development. Reusing parts that are common to all supported target-platforms for several model-to-text transformations is challenging. Existing approaches, like parameterized transformations and modularity concepts for transformations, make the reuse of transformations parts easier, but cannot be used to visualize design decisions that are common to all supported target-platforms. In this paper, we propose that platform-independent design decisions and their transformation results should be made explicit in an intermediate view. A single parameterized transformation should yield a common object-oriented model before individual transformations for specific platforms are executed. We argue that the additional view makes it possible to analyze decisions on how\u00a0\u2026", "num_citations": "5\n", "authors": ["1964"]}
{"title": "Using performance models for planning the redeployment to infrastructure-as-a-service environments: a case study\n", "abstract": " Context: Performance models allow software architects to conduct what-if analyses, e.g., to assess deployment scenarios regarding performance. While a typical scenario is the redeployment to Infrastructure-as-a-Service (IaaS) environments, there is currently no empirical evidence that architects can apply performance models in such scenarios for accurate performance analyses and how much effort is required. Objectives: Therefore, we explore the applicability of software performance engineering for planning the redeployment of existing software applications to IaaS environments. Methods: We conduct a case study in which we apply performance engineering to redeploy a realistic existing application to IaaS environments. We select an online book shop implementation (CloudStore) as existing application and engineer a corresponding Palladio performance model. Subsequently, we compare analysis results\u00a0\u2026", "num_citations": "4\n", "authors": ["1964"]}
{"title": "Security Modeling with Palladio\u2014Different Approaches\n", "abstract": " Security is never perfect, security deals with a lot of uncertainty, and security is complex. Nevertheless, security is one of the non-functional properties, that we, as software architects, have to consider. It is needed to include security in many trade-off decisions (usability, performance, costs, etc. versus security), to compare the security of different architectures, and to check whether legal constraints are meet. Thus it is demanded to include security modeling to approaches like Palladio.In this paper, we describe two approaches to model and analyze security using Palladio. The first approach is an external one and requires to adapt Palladio. The second approach is proposed by us and does not need to modify Palladio. Furthermore, we explain why we needed to develop a new approach based on a use case and its demanded pragmatism for the model.", "num_citations": "4\n", "authors": ["1964"]}
{"title": "Cloud computing applications\n", "abstract": " Cloud computing focuses on elasticity, i.e., providing constant quality of service independent of workload. For achieving elasticity, cloud computing applications utilize virtualized infrastructures, distributed platforms, and other software-as-a-service offerings. The surge of cloud computing applications responds to the ability of cloud computing environments to only pay for utilized resources while saving upfront costs (e.g., buying and setting up infrastructure) and allowing for dynamic allocation of resources even in public-private hybrid scenarios.This chapter investigates the shift from classical three-tier web applications to such elastic cloud computing applications. After characterizing web applications, we describe cloud computing characteristics and derive how web applications can exploit these characteristics.Our results motivate novel requirements that have to be engineered and modeled, as further\u00a0\u2026", "num_citations": "3\n", "authors": ["1964"]}
{"title": "The CloudScale Method for Managers\n", "abstract": " Having described the CloudScale method for engineering scalable cloud computing applications in the previous chapters, we explicitly address managers of software development processes in this chapter. It answers questions managers have in mind when considering the CloudScale method: Is it worth implementing the CloudScale method in my organization? What does it take? What are the benefits? What will be the costs? How should I get started? This chapter addresses all these questions and provides answers based on our own experience that we gained when introducing and applying the CloudScale method in practice. In the course of the chapter, we distinguish two types of managers: project managers, who are concerned with managing project teams that implement the business requirements, and technical managers, who manage the actual development efforts and take technical decisions\u00a0\u2026", "num_citations": "3\n", "authors": ["1964"]}
{"title": "Extensible Graphical Editors for Palladio\n", "abstract": " Palladio is an approach to design and performance prediction of software architectures. An important part of the Palladio\u2019s tooling\u2014the Palladio Bench\u2014are its graphical GMF-based editors. In contrast to rudimentary tree-based editors, they enable a more intuitive creation of models even for less experienced developers. However, the maintenance of the GMF-based editors has become cumbersome because the requirement arose to support an increasing amount of new language features.In this paper, we present the new generation of graphical editors for Palladio, which are based on the Sirius editor framework. Further, we present a concept of how to develop external extensions to the graphical language, which can be plugged into the new editors without the need to intrusively modify them.", "num_citations": "2\n", "authors": ["1964"]}
{"title": "Analyzing Cost-Efficiency of Cloud Computing Applications with SimuLizar\n", "abstract": " In cloud computing, software applications are potentially able to use only the computing resources that are minimally needed for performant operation. Because cloud providers provision such resources on a pay-per-use basis, software architects are interested in analyzing the operational costs that accrue for such applications, allowing architects to optimize for cost-efficiency. Current analysis approaches like Palladio focus on traditional performance metrics but lack support for cost-efficiency metrics. Therefore, software architects have to inaccurately estimate operational costs of their applications, potentially leading to economically unusable applications.To tackle this problem, we integrated cost metrics into SimuLizar, a Palladio extension for analyzing cloud computing applications. Our integration allows architects to attach prices to computing resources used by software applications. In a proof-of-concept evaluation with a simple book shop, we show that our integration allows architects to analyze costs with high accuracy.", "num_citations": "2\n", "authors": ["1964"]}
{"title": "Software architecture design assistants need controlled efficiency experiments: Lessons learned from a survey\n", "abstract": " Software architects use so-called software architecture design assistants to get tool-based, (semi-)automated support in engineering software systems. Compared to manual engineering, the main promise of such a support is that architects can create high-quality architectural designs more efficiently. Yet, current practice in evaluating whether this promise is kept is based on case studies conducted by the original authors of respective design assistants. The downside of such evaluations is that they are neither generalizable to thirdparty software architects nor can be used for quantitative efficiency comparisons between competing design assistants. To tackle this problem, we investigate how researchers can apply controlled experiments for evaluating the impact of software architecture design assistants on the efficiency of architects. For our investigation, we survey related controlled experiments. Based on this\u00a0\u2026", "num_citations": "2\n", "authors": ["1964"]}
{"title": "The Architectural Template Method: Design-Time Engineering of SaaS Applications\n", "abstract": " Typical requirements of SaaS applications target scalability, elasticity, and cost-efficiency. However, these quality properties lack an engineering method for software architects, allowing them to precisely and efficiently analyze these properties already at early design-time. To tackle this lack, we propose the architectural template (AT) method, an efficient design-time engineering method for analyzing scalability, elasticity, and efficiency properties of SaaS applications. Our method quantifies such properties based on reusable analysis templates of cloud computing environments. Architects only have to fill-in the parts specific to their SaaS application.", "num_citations": "2\n", "authors": ["1964"]}
{"title": "Reengineering of component-based software systems in the presence of design deficiencies\u2013an overview\n", "abstract": " In reengineering, up-to-date architecture models are important artifacts to get an overview of a system and to plan and execute the necessary reengineering activities. If such models do not exist, software architecture reconstruction (SAR) techniques can be used to recover them from the system\u2019s source code. However, design deficiencies like Interface Violations can influence the architecture reconstruction and thereby adulterate the recovered architecture. This is currently not addressed by SAR approaches. Archimetrix is an iterative reengineering process that was developed in a PhD thesis at the University of Paderborn [5]. It aims at detecting and removing design deficiencies which influence the architecture reconstruction and thereby enable the recovery of more accurate architecture models.", "num_citations": "2\n", "authors": ["1964"]}
{"title": "Why and How We Should Use Graphiti to Implement PCM Editors\u2217\n", "abstract": " For the Palladio Component Model (PCM), performance engineers use graphical editors for specifying and composing components as well as usage scenarios and deployment environments. These editors are created with the Graphical Modeling Framework (GMF). The fact that GMF editors are widely considered as difficult to maintain and to customize raises the question whether it makes sense to migrate to a more modern framework, namely Graphiti. Currently, related work does not evaluate the applicability of Graphiti for PCM editors. Therefore, we analyze the advantages and disadvantages of Graphiti and GMF in the context of Palladio. Based on our findings, we suggest to use Graphiti for the further development of PCM editors. Furthermore, we suggest how these editors can be implemented based on Graphiti. 1", "num_citations": "2\n", "authors": ["1964"]}
{"title": "Analysing evolution of work and load\n", "abstract": " Evolution of work and load is required for investigating elasticity and cost-efficiency of cloud computing applications as well as their underlying architecture. Existing modelling environments have fixed load and work, therefore rendering model-and-analyse approaches infeasible for such applications. This deficiency particularly leads to high risks that applications will violate their service level objectives. Therefore, this article describes how we can model and analyse the evolution of both work and load. We have created a corresponding meta model for usage evolution, and describe how we have integrated our meta model with Palladio, a common model-and-analyse environment. To model evolution we use the Descartes Load Intensity Model (DLIM). DLIM is coupled with the scenario model in the Palladio Component Model (PCM). We illustrate evolution of both work and load within Palladio simulations using a\u00a0\u2026", "num_citations": "1\n", "authors": ["1964"]}
{"title": "Measured Values Lost in Time-or How I rose from a User to a Developer of Palladio\n", "abstract": " I am working with software in academia for more than an decade and I had the \u201cMoment\u201d quite often. Palladio appeared just like an ordinary tool to solve my problem. Then, I changed a single parameter of my simulation\u2014some hours later we hunted for a bug in the depths of Palladio. Based on the open source development model of Palladio and a very elegant structure of the source code, we were able to find the root cause of the problem very fast. To start fixing the problem, we \u201cjust\u201d had to know when\u2014in simulation time\u2014a measurement of the SimuLizar simulator is valid. This paper summarizes our technical and philosophical discussions that ware needed to make Palladio deliver correct results and not to get lost in the depths of time and duration.", "num_citations": "1\n", "authors": ["1964"]}