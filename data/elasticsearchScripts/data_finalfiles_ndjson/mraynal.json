{"title": "Algorithms for mutual exclusion\n", "abstract": " This is a textbook on algorithms for mutual exclusion, which documents the development of the algorithms on that subject. By no means is it a catalogue or case book, for many of the presented algorithms are of more theoretical than practical interest today. Although it is only a compilation of published algorithms, it will be very valuable to have them all collected in a single book. The book can be used both by teachers and students, since it requires almost no additional background. Chapter 1 introduces us to the fundamental terms and problems: process, competition, cooperation, sharing, communication, protocol, etc. The next four chapters describe in logical sequence the protocols for mutual exclusion: first in the presence of a common memory (both software and hardware solutions), then in its absence (using local state variables and message communication). Real effort was made to present all algorithms in a\u00a0\u2026", "num_citations": "526\n", "authors": ["495"]}
{"title": "Logical time: Capturing causality in distributed systems\n", "abstract": " Causality is vital in distributed computations. Distributed systems can determine causality using logical clocks. Human beings use the concept of causality to plan, schedule, and execute an enterprise, or to determine a plan's feasibility. In daily life, we use global time to deduce causality from loosely synchronized clocks such as wrist watches and wall clocks. But in distributed computing systems, the rate of event occurrence is several magnitudes higher, and the event-execution time several magnitudes smaller. If the physical clocks in these systems are not synchronized precisely the causality relation between events cannot be captured accurately. However, distributed systems have no built-in physical time and can only approximate it. This article presents a general framework of a system of logical clocks in distributed systems and discusses three methods: scalar, vector and matrix, for implementing logical time in\u00a0\u2026", "num_citations": "383\n", "authors": ["495"]}
{"title": "Distributed algorithms for message-passing systems\n", "abstract": " La profusion des choses cachait la raret\u00e9 des id\u00e9es et l\u2019usure des croyances.[...] Retenir quelque chose du temps o\u00f9 l\u2019on ne sera plus.", "num_citations": "210\n", "authors": ["495"]}
{"title": "Concurrent programming: algorithms, principles, and foundations\n", "abstract": " This book is devoted to the most difficult part of concurrent programming, namely synchronization concepts, techniques and principles when the cooperating entities are asynchronous, communicate through a shared memory, and may experience failures. Synchronization is no longer a set of tricks but, due to research results in recent decades, it relies today on sane scientific foundations as explained in this book. In this book the author explains synchronization and the implementation of concurrent objects, presenting in a uniform and comprehensive way the major theoretical and practical results of the past 30 years. Among the key features of the book are a new look at lock-based synchronization (mutual exclusion, semaphores, monitors, path expressions); an introduction to the atomicity consistency criterion and its properties and a specific chapter on transactional memory; an introduction to mutex-freedom and associated progress conditions such as obstruction-freedom and wait-freedom; a presentation of Lamport's hierarchy of safe, regular and atomic registers and associated wait-free constructions; a description of numerous wait-free constructions of concurrent objects (queues, stacks, weak counters, snapshot objects, renaming objects, etc.); a presentation of the computability power of concurrent objects including the notions of universal construction, consensus number and the associated Herlihy's hierarchy; and a survey of failure detector-based constructions of consensus objects. The book is suitable for advanced undergraduate students and graduate students in computer science or computer engineering, graduate students in\u00a0\u2026", "num_citations": "206\n", "authors": ["495"]}
{"title": "The information structure of indulgent consensus\n", "abstract": " To solve consensus, distributed systems have to be equipped with oracles such as a failure detector, a leader capability, or a random number generator. For each oracle, various consensus algorithms have been devised. Some of these algorithms are indulgent toward their oracle in the sense that they never violate consensus safety, no matter how the underlying oracle behaves. We present a simple and generic indulgent consensus algorithm that can be instantiated with any specific oracle and be as efficient as any ad hoc consensus algorithm initially devised with that oracle in mind. The key to combining genericity and efficiency is to factor out the information structure of indulgent consensus executions within a new distributed abstraction, which we call \"Lambda\". Interestingly, identifying this information structure also promotes a fine-grained study of the inherent complexity of indulgent consensus. We show that\u00a0\u2026", "num_citations": "173\n", "authors": ["495"]}
{"title": "A simple taxonomy for distributed mutual exclusion algorithms\n", "abstract": " This short paper examines the two basic principles from which distributed mutual exclusion algorithms are designed : permission-based and token-based principles. This presentation is done in a pedagogical way and is illustrated by references to existing algorithms.", "num_citations": "172\n", "authors": ["495"]}
{"title": "An adaptive failure detection protocol\n", "abstract": " The detection of process failures is a crucial problem system designers have to cope with in order to build fault-tolerant distributed platforms. Unfortunately, it is impossible to distinguish with certainty a crashed process from a very slow process in a purely asynchronous distributed system. This prevents some problems from being solved in such systems. That is why failure detector oracles have been introduced to circumvent these impossibility results. The paper presents a relatively simple protocol that allows a process to \"monitor\" another process, and consequently to detect its crash. This protocol relies as much as possible on application messages to do this monitoring. Different from previous process crash detection protocols, it uses control messages only when no application message is sent by the monitoring process to the observed process. When the underlying system satisfies the partial synchrony\u00a0\u2026", "num_citations": "170\n", "authors": ["495"]}
{"title": "An adaptive causal ordering algorithm suited to mobile computing environments\n", "abstract": " Causal message ordering is required for several distributed applications. In order to preserve causal ordering, only direct dependency information between messages, with respect to the destination process(es), need be sent with each message. By eliminating other kinds of control information from the messages, the communication overheads can be significantly reduced. In this paper we present an algorithm that uses this knowledge to efficiently enforce causal ordering of messages. The proposed algorithm does not require any prior knowledge of the network topology or communication pattern. As computation proceeds, it acquires knowledge of the communication pattern and is capable of handling dynamically changing multicast communication groups, and minimizing the communication overheads. With regard to communication overheads, the algorithm is optimal for the broadcast communication case\u00a0\u2026", "num_citations": "133\n", "authors": ["495"]}
{"title": "A simple and fast asynchronous consensus protocol based on a weak failure detector\n", "abstract": " The Consensus problem is a fundamental paradigm for fault-tolerant asynchronous systems. It abstracts a family of problems known as Agreement (or Coordination) problems. Any solution to consensus can serve as a basic building block for solving such problems (e.g., atomic commitment or atomic broadcast). Solving consensus in an asynchronous system is not a trivial task: it has been proven (1985) by Fischer, Lynch and Paterson that there is no deterministic solution in asynchronous systems which are subject to even a single crash failure. To circumvent this impossibility result, Chandra and Toueg have introduced the concept of unreliable failure detectors (1991), and have studied how these failure detectors can be used to solve consensus in asynchronous systems with crash failures. This paper presents a new consensus protocol that uses a failure detector of the class $\\Diamond{\\cal S}$. Like\u00a0\u2026", "num_citations": "126\n", "authors": ["495"]}
{"title": "Timed consistency for shared distributed objects\n", "abstract": " Ordering and time are two different aspects of consistency of shared objects in a distributed system. One avoids conflicts between operations, the other addresses how quickly the effects of an operation are perceived by the rest of the system. Consistency models such as sequential consistency and causal consistency do not consider the particular time at which an operation is executed to establish a valid order among all the operations of a computation. Timed consistency models require that if a write operation is executed at time t, it must be visible to all nodes by time t+ A. Timed consistency generalizes several existing consistency criteria and it is well suited for interactive and collaborative applications, where the action of one user must be seen by others in a timely fashion.", "num_citations": "117\n", "authors": ["495"]}
{"title": "Communication and agreement abstractions for fault-tolerant asynchronous distributed systems\n", "abstract": " Understanding distributed computing is not an easy task. This is due to the many facets of uncertainty one  has to cope with and  master in  order to produce correct distributed software. Considering the  uncertainty  created by asynchrony  and process crash failures in the context of message-passing systems, the book  focuses  on  the main abstractions  that one has to understand and master  in order to be  able to  produce software with guaranteed properties.  These fundamental abstractions are communication abstractions that allow the processes to communicate consistently  (namely the register abstraction and the reliable broadcast abstraction),  and  the consensus agreement abstractions that allows them to cooperate  despite failures. As they give a precise meaning to the words  \"communicate\" and \"agree\" despite asynchrony and failures,  these abstractions allow distributed  programs to be designed with\u00a0\u2026", "num_citations": "116\n", "authors": ["495"]}
{"title": "A general framework to solve agreement problems\n", "abstract": " Agreement problems are among the most important problems designers of distributed systems have to cope with. A way to solve them is to first provide a solution to the Consensus problem and then to reduce each agreement problem to Consensus. This \"run-time customizing\" approach is particularly relevant when upper layer applications have to solve several distinct agreement problems. We investigate a \"compile-time customizing\" approach to automatically generate ad hoc agreement protocols. A general agreement framework, characterized by six \"versatility\" parameters, is defined. Appropriate instantiations of these parameters provide particular agreement protocols. This approach is particularly suited to generate efficient agreement protocols.", "num_citations": "109\n", "authors": ["495"]}
{"title": "A distributed solution to the k-out of-M resources allocation problem\n", "abstract": " We consider, in a distributed system, a set of M identical resources shared between n processes. Each of these resources can be used by at most one process at a given time (i.e. in mutual exclusion). In the k-out of-M resources allocation problem a process P                  i                can requestat once any number k                  i                of these M resources ; this process remains blocked until it has got a set of k                  i                resources. A distributed algorithm, which generalizes the Ricart-Agrawala's mutual exclusion algorithm, is given for this problem ; a variant reducing the number of messages is also proposed. Finally this solution is extended to solve the generalized resourcesallocation problem in which a process request can concern several instances of different types of resources, each type being represented by some number of identical resources.", "num_citations": "104\n", "authors": ["495"]}
{"title": "Synchronization and control of distributed systems and programs\n", "abstract": " The von Neumann model of computation has dominated the computer industry of the last decades in almost every respect, including performance, price, and availability. Still, more and more voices point to the many drawbacks of the model. Notions such as the von Neumann bottleneck are giving headaches both to the designers and manufacturers and to the users of computers. It is definitely time for a change. Some of the most promising models of computation for the future are distributed systems of the multiple-instruction-multiple-data (MIMD) type. Many efforts are being made to provide a theoretical basis for this model to aid in understanding the fundamentals of distributed computation, which in turn should facilitate the spread of distributed computation in the real world. This book presents the state of the art on the crucial subject of the synchronization of distributed systems. The many recent sources of\u00a0\u2026", "num_citations": "101\n", "authors": ["495"]}
{"title": "Fundamentals of distributed computing: A practical tour of vector clock systems\n", "abstract": " A vector clock system is a timestamping mechanism that tracks causality among events produced by a distributed computation. This paper is a practical introduction to vector clock systems. It reviews their fundamental protocols, properties and uses. The paper also discusses approximate vector clocks and dependency vectors. Concepts and mechanisms presented in this paper are of primary importance to distributed computing systems engineers. They will provide them with a solid background to better understand causality related distributed computing problems. Such an experience can be used to solve a given problem with the appropriate protocols.", "num_citations": "95\n", "authors": ["495"]}
{"title": "Consensus in synchronous systems: A concise guided tour\n", "abstract": " This paper considers consensus protocols for synchronous systems where processes can commit crash failures, omission failures or Byzantine failures. It presents and revisits consensus protocols coping with such failures in an increasing order of difficulty. The paper can be seen as a short tutorial whose aim is to make the reader familiar with synchrony assumptions, different definitions of the consensus problem, and a hierarchy of process failure models. An important concern of the paper lies in simplicity. In addition to the survey flavor of the paper, several results that are presented are new, among which the ones concerning the omission failure model.", "num_citations": "91\n", "authors": ["495"]}
{"title": "A speculation-friendly binary search tree\n", "abstract": " We introduce the first binary search tree algorithm designed for speculative executions. Prior to this work, tree structures were mainly designed for their pessimistic (non-speculative) accesses to have a bounded complexity. Researchers tried to evaluate transactional memory using such tree structures whose prominent example is the red-black tree library developed by Oracle Labs that is part of multiple benchmark distributions. Although well-engineered, such structures remain badly suited for speculative accesses, whose step complexity might raise dramatically with contention. We show that our speculation-friendly tree outperforms the existing transaction-based version of the AVL and the red-black trees. Its key novelty stems from the decoupling of update operations: they are split into one transaction that modifies the abstraction state and multiple ones that restructure its tree implementation in the background. In\u00a0\u2026", "num_citations": "90\n", "authors": ["495"]}
{"title": "Fault-tolerant agreement in synchronous message-passing systems\n", "abstract": " Understanding distributed computing is not an easy task. This is due to the many facets of uncertainty one has to cope with and master in  order to  produce correct distributed software. A previous book  Communication and Agreement Abstraction for Fault-tolerant Asynchronous Distributed Systems (published by Morgan & Claypool, 2010) was devoted to the problems created by crash failures in  asynchronous  message-passing systems.   The present book focuses on the way to cope with the uncertainty created  by process failures (crash, omission failures and Byzantine  behavior) in synchronous message-passing systems (i.e., systems whose progress is  governed by the passage of time). To that end, the book considers  fundamental  problems that distributed synchronous processes have to solve.  These fundamental problems concern agreement among processes (if processes  are unable to agree in one way\u00a0\u2026", "num_citations": "88\n", "authors": ["495"]}
{"title": "An efficient causal ordering algorithm for mobile computing environments\n", "abstract": " Causal message ordering is required for several distributed applications. In order to preserve causal ordering, only direct dependency information between messages with respect to the destination process(es) should be sent with each message. By eliminating other kinds of control information from the messages, the communication overheads can be significantly reduced. In this paper we present an algorithm that uses this knowledge to efficiently enforce causal ordering of messages. The proposed algorithm does not require any prior knowledge of the network or communication topology. As computation proceeds, it acquires knowledge of the logical communication topology and is capable of handling dynamically changing multicast communication groups. With regard to communication overheads, the algorithm is optimal for the broadcast communication case. Its energy efficiency and four bandwidth requirement\u00a0\u2026", "num_citations": "88\n", "authors": ["495"]}
{"title": "An adaptive protocol for implementing causally consistent distributed services\n", "abstract": " Distributed services that are accessed by widely distributed clients are becoming common place. Such services cannot be provided at the needed level of performance and availability without replicating the service at multiple nodes, and without allowing a relatively weak level of consistency among replicated copies of the state of a service. This paper explores causally consistent distributed services when multiple related services are replicated to meet performance and availability requirements. This consistency criterion is particularly well suited for some distributed services (e.g., cooperative document sharing), and it is attractive because of the efficient implementations allowed by it.", "num_citations": "84\n", "authors": ["495"]}
{"title": "Detecting atomic sequences of predicates in distributed computations\n", "abstract": " This paper deals with a class of unstable non-monotonic global predicates, called herein atomic sequences of predicates. Such global predicates are defined for distributed programs built with messagepassing communication only (no shared memory) and they describe global properties by causal com-position of local predicates augmented with atomicity constraints. These constraints specify forbidden properties, whose occurrence invalidate causal sequences. This paper defines formally these atomic sequences of predicates, proposes a distributed algorithm to detect their occurrences and gives a sketch of a proof of correctness of this algorithm.", "num_citations": "83\n", "authors": ["495"]}
{"title": "Networks and distributed computation: concepts, tools, and algorithms\n", "abstract": " This work, translated from French, is one of a series of computer systems books published by MIT Press. The translation is fluid and natural, and the book is well edited and clear. In the series foreword, the editors indicate that they are seeking a wide range of subjects that \u201cpermit deeper understandings of complex interrelationships and their effects on performance, reliability, and usefulness\u201d of computer systems. This particular work is devoted to problems related to communication among a set of distributed computing modules connected by some sort of network. Instead of rendering a tutorial on X. 21 or X. 25, the author presents increasingly complex communications situations in which messages are to be sent and received over the network to which the computers are attached. Attention is given to the flow of the control messages required to make certain that the communication has been successfully performed\u00a0\u2026", "num_citations": "80\n", "authors": ["495"]}
{"title": "Efficient distributed detection of conjunctions of local predicates\n", "abstract": " Global predicate detection is a fundamental problem in distributed systems and finds applications in many domains such as testing and debugging distributed programs. This paper presents an efficient distributed algorithm to detect conjunctive-form global predicates in distributed systems. The algorithm detects the first consistent global state that satisfies the predicate even if the predicate is unstable. Unlike previously proposed run-time predicate detection algorithms, our algorithm does not require the exchange of control messages during the normal computation. All the necessary information to detect predicates is piggybacked on computation messages of application programs. The algorithm is distributed because the predicate detection efforts as well as the necessary information are equally distributed among the processes. We prove the correctness of the algorithm and compare its performance with respect to\u00a0\u2026", "num_citations": "77\n", "authors": ["495"]}
{"title": "The renaming problem in shared memory systems: An introduction\n", "abstract": " Exploring the power of shared memory communication objects and models, and the limits of distributed computability are among the most exciting research areas of distributed computing. In that spirit, this paper focuses on a problem that has received considerable interest since its introduction in 1987, namely the renaming problem. It was the first non-trivial problem known to be solvable in an asynchronous distributed system despite process failures. Many algorithms for renaming and variants of renaming have been proposed, and sophisticated lower bounds have been proved, that have been a source of new ideas of general interest to distributed computing. It has consequently acquired a paradigm status in distributed fault-tolerant computing.In the renaming problem, processes start with unique initial names taken from a large name space, then deciding new names such that no two processes decide the same\u00a0\u2026", "num_citations": "76\n", "authors": ["495"]}
{"title": "DBFT: Efficient leaderless Byzantine consensus and its application to blockchains\n", "abstract": " This paper introduces a new leaderless Byzantine consensus called the Democratic Byzantine Fault Tolerance (DBFT) for blockchains. While most blockchain consensus protocols rely on a correct leader or coordinator to terminate, our algorithm can terminate even when its coordinator is faulty. The key idea is to allow processes to complete asynchronous rounds as soon as they receive a threshold of messages, instead of having to wait for a message from a coordinator that may be slow. The resulting decentralization is particularly appealing for blockchains for two reasons: (i) each node plays a similar role in the execution of the consensus, hence making the decision inherently \u201cdemocratic\u201d (ii) decentralization avoids bottlenecks by balancing the load, making the solution scalable. DBFT is deterministic, assumes partial synchrony, is resilience optimal, time optimal and does not need signatures. We first present a\u00a0\u2026", "num_citations": "73\n", "authors": ["495"]}
{"title": "A contention-friendly binary search tree\n", "abstract": " This paper proposes a new lock-based concurrent binary tree using a methodology for writing concurrent data structures. This methodology limits the high contention induced by today\u2019s multicore environments to come up with efficient alternatives to the most widely used search structures.               Data structures are generally constrained to guarantee a big-oh step complexity even in the presence of concurrency. By contrast our methodology guarantees the big-oh complexity only in the absence of contention and limits the contention when concurrency appears. The key concept lies in dividing update operations within an eager abstract access that returns rapidly for efficiency reason and a lazy structural adaptation that may be postponed to diminish contention. Our evaluation clearly shows that our lock-based tree is up to 2.2\u00d7 faster than the most recent lock-based tree algorithm we are aware of.", "num_citations": "73\n", "authors": ["495"]}
{"title": "Design and performance evaluation of efficient consensus protocols for mobile ad hoc networks\n", "abstract": " Designing protocols for solving the consensus problem faces new challenges in mobile computing environments. Among others, how we can achieve message efficiency for saving resource consumption has been the focus of research. In this paper, we present the HC protocol, a message efficient consensus protocol for MANETs. We consider the widely used system model where the hosts fail by crashes and the system is equipped with Chandra-Toueg's unreliable failure detectors. Unlike existing consensus protocols, the HC protocol uses a two-layer hierarchy based on clusters to achieve message efficiency. The messages from and to the hosts in the same cluster are merged so as to reduce the message cost. However, adding such a hierarchy is not trivial. Due to host movements and failures, the hierarchy changes from time to time and this may cause message loss. In designing HC, we also propose methods\u00a0\u2026", "num_citations": "72\n", "authors": ["495"]}
{"title": "An introduction to snapshot algorithms in distributed computing\n", "abstract": " Recording on-the-fly global states of distributed executions is an important paradigm when one is interested in analysing, testing, or verifying properties associated with these executions. Since Chandy and Lamports (1985) seminal paper on this topic, this problem is called the snapshot problem. Unfortunately, the lack of both a globally shared memory and a global clock in a distributed system, added to the fact that transfer delays in these systems are finite but unpredictable, makes this problem non-trivial. This paper first discusses issues which have to be addressed to compute distributed snapshots in a consistent way. Then several algorithms which determine on-the-fly such snapshots are presented for several types of networks (according to the properties of their communication channels, namely, FIFO, non-FIFO, and causal delivery).", "num_citations": "72\n", "authors": ["495"]}
{"title": "Deadlock models and a general algorithm for distributed deadlock detection\n", "abstract": " This paper deals with the problem of deadlock detection in asynchronous message passing systems in a system model that covers unspecified receptions and non-FIFO channels. It presents a hierarchy of deadlock models and deadlock detection problems. It abstracts deadlocks by a general deadlock model that has the same modeling power as the OR-AND model; however, it has much concise expressive power. An abstract general definition of deadlocks in distributed systems is presented that defines deadlocks independently of the underlying deadlock model. This formulation can be used to design a single distributed deadlock detection algorithm which uniformly addresses all deadlocks in the context of various request models such as AND, OR, AND-OR, and k-out-of-n requests. A simple generalized deadlock detection algorithm that uses a circulating token is presented to illustrate the concept. The algorithm\u00a0\u2026", "num_citations": "72\n", "authors": ["495"]}
{"title": "A distributed algorithm for mutual exclusion in an arbitrary network\n", "abstract": " A distributed algorithm for mutual exclusion is presented. No particular assumptions on the network topology are required, except connectivity; the communication graph may be arbitrary. The processes communicate by using messages only and there is no global controller. Furthermore, no process needs to know or learn the global network topology. In that sense, the algorithm is more general than the mutual exclusion algorithms which make use of an a priori knowledge of the network topology (for example either ring or complete network). A proof of the correctness of the algorithm is provided. The algorithm's complexity is examined by evaluating the number of messages required for the mutual exclusion protocol.", "num_citations": "71\n", "authors": ["495"]}
{"title": "Detection of stable properties in distributed applications\n", "abstract": " When evaluated to true, a stable property remains true forever. Such a stable property may characterize important states of a computation. This is the case of deadlocked or terminated computations. In this paper we expose a general algorithm for the distributed detection of stable properties in distributed applications or systems. This distributed algorithm deals with every stable property of a fairly general class: in this sense the algorithm is generic. This was achieved using a methodical approach, with a strong distinction between the computation and control activities in the problem. Moreover, the detection method used by the algorithm is based on an observational mechanism,", "num_citations": "71\n", "authors": ["495"]}
{"title": "Looking for a definition of dynamic distributed systems\n", "abstract": " This paper is a position paper on the nature of dynamic systems. While there is an agreement on the definition of what a static distributed system is, there is no agreed definition on what a dynamic distributed system is. This paper is a first step in that direction. To that end, it emphasizes two orthogonal dimensions that are present in any dynamic distributed system, namely the varying and possibly very large number of entities that currently define the system, and the fact that each of these entities knows only a few other entities (its neighbors) and possibly will never be able to know the whole system it is a member of. To illustrate the kind of issues one has to cope with in dynamic systems, the paper considers, as a \u201ccanonical\u201d problem, a simple data aggregation problem. It shows the type of dynamic systems in which that problem can be solved and the ones in which it cannot be solved. The aim of the paper is\u00a0\u2026", "num_citations": "70\n", "authors": ["495"]}
{"title": "Efficient \u0394-causal broadcasting\n", "abstract": " \\Delta-causal ordering is a communication abstraction designed for distributed applications whose messages (i) have to be delivered according to causal ordering and (ii) have a limited lifetime after which their data can no longer be used by the application. Example of such applications are: multimedia real-time collaborative applications and groupware real-time applications. For such applications, the broadcasting of information is of primary importance. In this paper, we propose a simple and efficient\\Delta-causal ordering protocol in the context of broadcast communication. By taking into account transitive dependencies on message sends, this algorithm gets a significant reduction in the control information piggybacked on application messages, compared to previous algorithms. Keywords: distributed computing, causal ordering, multimedia, real-time communication. 1 Introduction The notion of\\Delta-causal ordering was introduced in [Yav92], and later refined and formalized in [BMR95...", "num_citations": "69\n", "authors": ["495"]}
{"title": "On the fly testing of regular patterns in distributed computations\n", "abstract": " A class of properties of distributed computations is described and an algorithm which detects them is presented. This class of properties called regular patterns allows the user to specify an expected (or unwanted) behavior of a computation as sequences of relevant events (or as sequences of local predicates that must be successively verified). The sequences are defined by a finite state automaton (hence the name regular patterns) A computation verifies the property if and only if one of its causal paths matches a sequence.", "num_citations": "69\n", "authors": ["495"]}
{"title": "Fault-Tolerant Message-Passing Distributed Systems\n", "abstract": " La recherche du temps perdu passait par le Web.[...] La m\u00e9moire \u00e9tait devenue in\u00e9puisable, mais la profondeur du temps [...] avait disparu. On \u00e9tait dans un pr\u00e9sent infini.", "num_citations": "68\n", "authors": ["495"]}
{"title": "Anonymous publish/subscribe in p2p networks\n", "abstract": " One of the most important issues to deal with in peer-to-peer networks is how to disseminate information. In this paper, we use a completely new approach to solving the information dissemination problem. Our approach uses the publish/subscribe paradigm. The publish/subscribe method is the most inclusive strategy to establish communication between the information providers (publishers) and the information consumers (subscribers). We give a formal definition of publish/subscribe systems. We then use the publish/subscribe communication paradigm to design deterministic protocols (topic and content-based) for peer-to-peer networks. Our protocols are designed on top of an innovative information dissemination scheme, and can cope with the anonymity and mobility of both publishers and subscribers, weak-connectivity, and polarization, which are some of the characteristics of peer-to-peer networks. Moreover\u00a0\u2026", "num_citations": "68\n", "authors": ["495"]}
{"title": "Consistency issues in distributed checkpoints\n", "abstract": " A global checkpoint is a set of local checkpoints, one per process. The traditional consistency criterion for global checkpoints states that a global checkpoint is consistent if it does not include messages received and not sent. The paper investigates other consistency criteria, transitlessness, and strong consistency. A global checkpoint is transitless if it does not exhibit messages sent and not received. Transitlessness can be seen as a dual of traditional consistency. Strong consistency is the addition of transitlessness to traditional consistency. The main result of the paper is a statement of the necessary and sufficient condition answering the following question: \"given an arbitrary set of local checkpoints, can this set be extended to a global checkpoint that satisfies P\" (where P is traditional consistency, transitlessness, or strong consistency). From a practical point of view, this condition, when applied to transitlessness, is\u00a0\u2026", "num_citations": "67\n", "authors": ["495"]}
{"title": "About logical clocks for distributed systems\n", "abstract": " Memory space and processor time are basic resources when executing a program. But beside this implementation aspect (this time resource is necessary but does not belong to the program semantics), the concept of time presents a more fundamental facet in distributed systems namely causality relation between events. Put forward by Lamport in 1978, the logical nature of time is of primary importance when designing or analyzing distributed systems. This paper reviews three ways (linear time, vector time and matrix time) which have been proposed to capture causality between events of a distributed computation and which consequently allow to define logical time.", "num_citations": "66\n", "authors": ["495"]}
{"title": "Model-based control of networked systems\n", "abstract": " Feedback control of dynamical systems has benefited from recent development of sensing and actuation nodes with strong local computation capabilities and from the use of digital communication networks for system interconnections. With all these advancements, the detailed analysis of feedback control systems remains an important part of the complex networked control applications. System uncertainties have always been a central issue in control systems. It is critical to address uncertainty effects on the stability and performance of control systems when it is not possible to obtain continuous feedback measurements. Such is the case in Networked Control Systems (NCS) where the communication channel is of limited bandwidth and it is also shared by different subsystems.This book presents a specific framework, the Model-Based Networked Control Systems (MB-NCS) framework, for design and analysis of NCS\u00a0\u2026", "num_citations": "65\n", "authors": ["495"]}
{"title": "Signature-free asynchronous binary Byzantine consensus with t< n/3, O (n2) messages, and O (1) expected time\n", "abstract": " This article is on broadcast and agreement in asynchronous message-passing systems made up of n processes, and where up to t processes may have a Byzantine Behavior. Its first contribution is a powerful, yet simple, all-to-all broadcast communication abstraction suited to binary values. This abstraction, which copes with up to t < n/3 Byzantine processes, allows each process to broadcast a binary value, and obtain a set of values such that (1) no value broadcast only by Byzantine processes can belong to the set of a correct process, and (2) if the set obtained by a correct process contains a single value v, then the set obtained by any correct process contains v. The second contribution of this article is a new round-based asynchronous consensus algorithm that copes with up to t < n/3 Byzantine processes. This algorithm is based on the previous binary broadcast abstraction and a weak common coin. In addition to\u00a0\u2026", "num_citations": "64\n", "authors": ["495"]}
{"title": "Implementing a register in a dynamic distributed system\n", "abstract": " Providing distributed processes with concurrent objects is a fundamental service that has to be offered by any distributed system. The classical shared read/write register is one of the most basic ones. Several protocols have been proposed that build an atomic register on top of an asynchronous message-passing system prone to process crashes. In the same spirit, this paper addresses the implementation of a regular register (a weakened form of an atomic register) in an asynchronous dynamic message-passing system. The aim is here to cope with the net effect of the adversaries that are asynchrony and dynamicity (the fact that processes can enter and leave the system). The paper focuses on the class of dynamic systems the churn rate c of which is constant. It presents two protocols, one applicable to synchronous dynamic message passing systems, the other one to eventually synchronous dynamic systems. Both\u00a0\u2026", "num_citations": "61\n", "authors": ["495"]}
{"title": "The alpha of indulgent consensus\n", "abstract": " This paper presents a simple framework unifying a family of consensus algorithms that can tolerate process crash failures and asynchronous periods of the network, also called indulgent consensus algorithms. Key to the framework is a new abstraction we introduce here, called Alpha, and which precisely captures consensus safety. Implementations of Alpha in shared memory, storage area network, message passing and active disk systems are presented, leading to directly derived consensus algorithms suited to these communication media. The paper also considers the case where the number of processes is unknown and can be arbitrarily large.", "num_citations": "61\n", "authors": ["495"]}
{"title": "k-arbiter: A safe and general scheme for h-out of-k mutual exclusion\n", "abstract": " Mutual exclusion is a well-known problem that arises when multiple processes compete, in an uncoordinated way, for the acquisition of shared resources over a distributed system. In particular, k-mutual exclusion allows at most k processes to get one unit of the same resource simultaneously. These paradigms do not cover all the cases in which resource accesses must be serialized over a distributed system. There exist cases (e.g. the bandwidth of communication lines) where the amount of shared resource might differ from request to request (for example, audio and video communications). In this paper, we formalize this problem as the h-out of-k mutual exclusion problem, in which each request concerns some number h (1 \u2a7d h \u2a7d k) of units of shared resource and no unit is allocated to multiple processes at the same time. Former simple and k-mutual algorithms cannot be used to solve this problem. We present a\u00a0\u2026", "num_citations": "61\n", "authors": ["495"]}
{"title": "From crash fault-tolerance to arbitrary-fault tolerance: Towards a modular approach\n", "abstract": " Presents a generic methodology to transform a protocol which is resilient to process crashes into one that is resilient to arbitrary failures in the case where processes run the same text and regularly exchange messages (i.e. the case of round-based protocols). The methodology follows a modular approach, encapsulating the detection of arbitrary failures in specific modules. This can be the starting point for designing tools that allow automatic transformation. We show an application of this methodology to the case of consensus.", "num_citations": "56\n", "authors": ["495"]}
{"title": "An adaptive programming model for fault-tolerant distributed computing\n", "abstract": " The capability of dynamically adapting to distinct runtime conditions is an important issue when designing distributed systems where negotiated quality of service (QoS) cannot always be delivered between processes. Providing fault tolerance for such dynamic environments is a challenging task. Considering such a context, this paper proposes an adaptive programming model for fault-tolerant distributed computing, which provides upper-layer applications with process state information according to the current system synchrony (or QoS). The underlying system model is hybrid, composed by a synchronous part (where there are time bounds on processing speed and message delay) and an asynchronous part (where there is no time bound). However, such a composition can vary over time, and, in particular, the system may become totally asynchronous (e.g., when the underlying system QoS degrade) or totally\u00a0\u2026", "num_citations": "55\n", "authors": ["495"]}
{"title": "Virtual world consistency: A condition for STM systems (with a versatile protocol with invisible read operations)\n", "abstract": " The aim of a Software Transactional Memory (STM) is to discharge the programmers from the management of synchronization in multiprocess programs that access concurrent objects. To that end, an STM system provides the programmer with the concept of a transaction. The job of the programmer is to design each process the application is made up of as a sequence of transactions. A transaction is a piece of code that accesses concurrent objects, but contains no explicit synchronization statement. It is the job of the underlying STM system to provide the illusion that each transaction appears as being executed atomically. Of course, for efficiency, an STM system has to allow transactions to execute concurrently. Consequently, due to the underlying STM concurrency management, a transaction commits or aborts.This paper first presents a new STM consistency condition, called virtual world consistency. This\u00a0\u2026", "num_citations": "52\n", "authors": ["495"]}
{"title": "Atomic broadcast in asynchronous crash-recovery distributed systems\n", "abstract": " Atomic broadcast is a fundamental problem of distributed systems: it states that messages must be delivered in the same order to their destination processes. This paper describes a solution to this problem in asynchronous distributed systems in which processes can crash and recover. A consensus-based solution to atomic broadcast problem has been designed by Chandra and Toueg (1996) for asynchronous distributed systems where crashed processes do nor recover. Although our solution is based on different algorithmic principles, it follows the same approach: it transforms any consensus protocol suited to the crash-recovery model into an atomic broadcast protocol suited to the same model. We show that atomic broadcast can be implemented without requiring any additional log operations in excess of those required by the consensus. The paper also discusses how additional log operations can improve the\u00a0\u2026", "num_citations": "52\n", "authors": ["495"]}
{"title": "Consensus in Byzantine asynchronous systems\n", "abstract": " This paper presents a consensus protocol resilient to Byzantine failures. It uses signed and certified messages and is based on two underlying failure detection modules. The first is a muteness failure detection module of the class\u2662 M. The second is a reliable Byzantine behaviour detection module. More precisely, the first module detects processes that stop sending messages, while processes experiencing other non-correct behaviours (ie, Byzantine) are detected by the second module. The protocol is resilient to F faulty processes, F\u2a7d min (\u230a(n\u2212 1)/2\u230b, C)(where C is the maximum number of faulty processes that can be tolerated by the underlying certification service). The approach used to design the protocol is new. While usual Byzantine consensus protocols are based on failure detectors to detect processes that stop communicating, none of them use a module to detect their Byzantine behaviour (this detection is\u00a0\u2026", "num_citations": "51\n", "authors": ["495"]}
{"title": "No hot spot non-blocking skip list\n", "abstract": " This paper presents a new non-blocking skip list algorithm. The algorithm alleviates contention by localizing synchronization at the least contended part of the structure without altering consistency of the implemented abstraction. The key idea lies in decoupling a modification to the structure into two stages: an eager abstract modification that returns quickly and whose update affects only the bottom of the structure, and a lazy selective adaptation updating potentially the entire structure but executed continuously in the background. On SPECjbb as well as on micro-benchmarks, we compared the performance of our new non-blocking skip list against the performance of the JDK non-blocking skip list. The results indicate that our implementation can me more than twice as fast as the JDK skip list.", "num_citations": "50\n", "authors": ["495"]}
{"title": "Rollback-dependency trackability: Visible characterizations\n", "abstract": " When we consider an asynchronous distributed computation on which local checkpoints have been defined (namely, a communication and checkpoint pattern-in brief, CCP), two types of dependencies between its local checkpoints can be observed. The first type is due to causal sequences of messages that establish on-line trackable dependencies. The second type is due to noncausal sequences of messages (called Z-paths) that establish \u201chidden\u201d dependencies between local checkpoints (a dependency is \u201chidden\u201d if it can not be tracked online). The Rollback Dependency Trackability (RDT) property, defined by Y.-M. Wang, has been introduced to study CCPs. A CCP satisfies the RDT property if every pair of local checkpoints that are connected by a \u201chidden\u201d dependency are also connected by a causal sequence of messages. The RDT property has a great interest: CCPs that satisfy this property allow relatively\u00a0\u2026", "num_citations": "50\n", "authors": ["495"]}
{"title": "Eventual leader election with weak assumptions on initial knowledge, communication reliability, and synchrony\n", "abstract": " This report considers the eventual leader election problem in asynchronous message-passing systems where an arbitrary number  of processes can crash (, where  is the total number of processes). It considers weak assumptions both on the initial knowledge of the processes and on the network behavior. More precisely, initially, a process knows only its identity and the fact that the process identities are different and totally ordered (it knows neither  nor ). Two eventual leader election protocols and a lower bound are presented. The first protocol assumes that a process also knows the lower bound  on the number of processes that do not crash. This protocol requires the following behavioral properties from the underlying network: the graph made up of the correct processes and fair lossy links is strongly connected, and there is a correct process connected to  other correct processes (where  is the actual number of crashes in the considered run) through eventually timely paths (paths made up of correct processes and eventually timely links). This protocol is not communication-efficient in the sense that each correct process has to send messages forever. The second protocol is communication-efficient: after some time, only the final common leader has to send messages forever. This protocol does not require the processes to know , but requires stronger properties from the underlying network: each pair of correct processes has to be connected by fair lossy links (one in each direction), and there is a correct process whose output links to the rest of correct processes have to be eventually timely. The lower bound result shows that\u00a0\u2026", "num_citations": "49\n", "authors": ["495"]}
{"title": "Modeling software testing processes\n", "abstract": " The production of a high quality software product requires application of both defect prevention and defect detection techniques. A common defect detection strategy is to subject the product to several phases of testing such as unit, integration, and system. These testing phases consume significant project resources and cycle time. As software companies continue to search for ways for reducing cycle time and development costs while increasing quality, software testing processes emerge as a prime target for investigation. The paper proposes the utilization of system dynamics models for better understanding testing processes. Motivation for modeling testing processes is presented along with a an executable model of the unit test phase. Some sample model runs are described to illustrate the usefulness of the model.", "num_citations": "48\n", "authors": ["495"]}
{"title": "Sequential consistency in distributed systems\n", "abstract": " Recently, distributed shared memory (DSM) systems have received much attention because such an abstraction simplifies programming. It has been shown that many practical applications using DSMs require competing operations. We have aimed at unifying theory and implementations of protocols for sequential consistency, which provides competing operations. By adopting concepts from concurrency control, we developed theory for sequential consistency, called a sequentializability theory. This paper first presents the sequentializability theory, and then demonstrates the correctness of existing protocols using the theory. Finally, the paper presents a new protocol which requires significantly less communication than previously proposed protocols in systems which do not provide hardware atomic broadcasting facilities.", "num_citations": "47\n", "authors": ["495"]}
{"title": "Group membership failure detection: a simple protocol and its probabilistic analysis\n", "abstract": " A group membership failure (in short, a group failure) occurs when one of the group members crashes. A group failure detection protocol has to inform all the non-crashed members of the group that this group entity has crashed. Ideally, such a protocol should be live (if a process crashes, then the group failure has to be detected) and safe (if a group failure is claimed, then at least one process has crashed).", "num_citations": "46\n", "authors": ["495"]}
{"title": "Distributed slicing in dynamic systems\n", "abstract": " Peer to peer (P2P) systems are moving from application specific architectures to a generic service oriented design philosophy. This raises interesting problems in connection with providing useful P2P middleware services capable of dealing with resource assignment and management in a large-scale, heterogeneous and unreliable environment. The slicing service, has been proposed to allow for an automatic partitioning of P2P networks into groups (slices) that represent a controllable amount of some resource and that are also relatively homogeneous with respect to that resource. In this paper we propose two gossip-based algorithms to solve the distributed slicing problem. The first algorithm speeds up an existing algorithm sorting a set of uniform random numbers. The second algorithm statistically approximates the rank of nodes in the ordering. The scalability, efficiency and resilience to dynamics of both\u00a0\u2026", "num_citations": "44\n", "authors": ["495"]}
{"title": "Deadline-constrained causal order\n", "abstract": " A causal ordering protocol ensures that if two messages are causally related and have the same destination, they are delivered to the application in their sending order. Causal order strongly simplifies the development of distributed object oriented systems. To prevent causal order violation, either messages may be forced to wait for messages in their past, or late messages may have to be discarded. For a real time setting, the first approach is not suitable since when a message misses a deadline, all the messages that causally depend on it may also be forced to miss their deadlines. We propose a novel causal ordering abstraction that takes message deadlines into consideration. Two implementations are proposed in the context of multicast and broadcast communication that deliver as many messages as possible to the application. Examples of distributed soft real time applications that benefit from the use of a\u00a0\u2026", "num_citations": "44\n", "authors": ["495"]}
{"title": "From serializable to causal transactions for collaborative applications\n", "abstract": " Services in decentralized distributed systems can be implemented using shared distributed objects. When these objects are accessed concurrently, serializability (the traditional consistency criterion) can be used to define their execution behaviour. However, this consistency criterion has a major drawback because it imposes strong synchronization constraints on the execution of applications which cannot be met efficiently in decentralized systems. In this paper, we examine weaker consistency criteria for computations in which accesses to shared objects are grouped to form transactions. The guarantees provided by transactions (e.g. concurrency and failure atomicity) make them attractive when computations manipulate the state of long-lived objects. We explore two new criteria: causal consistency and causal serializability. These criteria turn out to be sufficient for a class of applications (e.g. collaborative\u00a0\u2026", "num_citations": "44\n", "authors": ["495"]}
{"title": "On the solvability of anonymous partial grids exploration by mobile robots\n", "abstract": " Given an arbitrary partial anonymous grid (a finite grid with possibly missing vertices or edges), this paper focuses on the exploration of such a grid by a set of mobile anonymous agents (called robots). Assuming that the robots can move synchronously, but cannot communicate with each other, the aim is to design an algorithm executed by each robot that allows, as many robots as possible (let k be this maximal number), to visit infinitely often all the vertices of the grid, in such a way that no vertex hosts more than one robot at a time, and each edge is traversed by at most one robot at a time.               The paper addresses this problem by considering a central parameter, denoted \u03c1, that captures the view of each robot. More precisely, it is assumed that each robot sees the part of the grid (and its current occupation by other robots, if any) centered at the vertex it currently occupies and delimited by the radius \u03c1\u00a0\u2026", "num_citations": "43\n", "authors": ["495"]}
{"title": "Optimal early stopping uniform consensus in synchronous systems with process omission failures\n", "abstract": " Consensus is a central problem of fault-tolerant distributed computing that, in the context of synchronous distributed systems, has received a lot of attention in the crash failure model and in the Byzantine failure model. This paper considers synchronous distributed systems made up of n processes, where up to t can commit failures by crashing or omitting to send or receive messages when they should (\" process omission\" failure model). It presents a protocol solving uniform consensus in such a context. This protocol has several noteworthy features. First, it is particularly simple. Then, it is optimal both in (1) the number of communication steps needed for processes to decide and stop, namely, min (f+ 2, t+ 1) where f is the actual number of faulty processes, and (2) the number of processes that can be faulty, namely t< n/2. Moreover,(3) it ensures that no process (be it correct or faulty) executes more than min (f+ 2, t+ 1\u00a0\u2026", "num_citations": "43\n", "authors": ["495"]}
{"title": "Atomic broadcast in asynchronous crash-recovery distributed systems and its use in quorum-based replication\n", "abstract": " Atomic broadcast is a fundamental problem of distributed systems: It states that messages must be delivered in the same order to their destination processes. This paper describes a solution to this problem in asynchronous distributed systems in which processes can crash and recover. A consensus-based solution to atomic broadcast problem has been designed by Chandra and Toueg for asynchronous distributed systems where crashed processes do not recover. We extend this approach: it transforms any consensus protocol suited to the crash-recovery model into an atomic broadcast protocol suited to the same model. We show that atomic broadcast can be implemented requiring few additional log operations in excess of those required by the consensus. The paper also discusses how additional log operations can improve the protocol in terms of faster recovery and better throughput. To illustrate the use of the\u00a0\u2026", "num_citations": "43\n", "authors": ["495"]}
{"title": "Rollback-dependency trackability: A minimal characterization and its protocol\n", "abstract": " Considering a checkpoint and communication pattern, the rollback-dependency trackability (RDT) property stipulates that there is no hidden dependency between local checkpoints. In other words, if there is a dependency between two checkpoints due to a noncausal sequence of messages (Z-path), then there exists a causal sequence of messages (C-path) that doubles the noncausal one and that establishes the same dependency. This paper introduces the notion of RDT-compliance. A property defined on Z-paths is RDT-compliant if the causal doubling of Z-paths having this property is sufficient to ensure RDT. Based on this notion, the paper provides examples of such properties. Moreover, these properties are visible, ie, they can be tested on the fly. One of these properties is shown to be minimal with respect to visible and RDT-compliant properties. In other words, this property defines a minimal visible set of Z\u00a0\u2026", "num_citations": "43\n", "authors": ["495"]}
{"title": "On classes of problems in asynchronous distributed systems with process crashes\n", "abstract": " This paper is on classes of problems encountered in asynchronous distributed systems in which processes can crash but links are reliable. The hardness of a problem is defined with respect to the difficulty to solve it despite failures: a problem is easy if it can be solved in presence of failures, otherwise it is hard. Three classes of problems are defined: F, NF and NFC. F is the class of easy problems, namely, those that can be solved in presence of failures (e.g., reliable broadcast). The class NF includes harder problems, namely, the ones that can be solved in a non-faulty system (e.g., consensus). The class NFC (NF-complete) is a subset of NF that includes the problems that are the most difficult to solve in presence of failures. It is shown that the terminating reliable broadcast problem, the non-blocking atomic commitment problem and the construction of a perfect failure detector (problem P) are equivalent problems\u00a0\u2026", "num_citations": "43\n", "authors": ["495"]}
{"title": "The k-simultaneous consensus problem\n", "abstract": " This paper introduces and investigates the k-simultaneous consensus task: each process participates at the same time in k independent consensus instances until it decides in any one of them. It is shown that the k-simultaneous consensus task is equivalent to the k-set agreement task in the wait-free read/write shared memory model, and furthermore k-simultaneous consensus possesses properties that k-set does not. In particular we show that the multivalued version and the binary version of the k-simultaneous consensus task are wait-free equivalent. These equivalences are independent of the number of processes. Interestingly, this provides us with a new characterization of the k-set agreement task that is based on the fundamental binary consensus problem.", "num_citations": "40\n", "authors": ["495"]}
{"title": "The iterated restricted immediate snapshot model\n", "abstract": " In the Iterated Immediate Snapshot model () the memory consists of a sequence of one-shot Immediate Snapshot () objects. Processes access the sequence of  objects, one-by-one, asynchronously, in a wait-free manner; any number of processes can crash. Its interest lies in the elegant recursive structure of its runs, hence of the ease to analyze it round by round. In a very interesting way, Borowsky and Gafni have shown that the  model and the read/write model are equivalent for the wait-free solvability of decision tasks.               This paper extends the benefits of the  model to partially synchronous systems. Given a shared memory model enriched with a failure detector, what is an equivalent  model? The paper shows that an elegant way of capturing the power of a failure detector and other partially synchronous systems in the  model is by restricting appropriately its set of runs, giving rise\u00a0\u2026", "num_citations": "40\n", "authors": ["495"]}
{"title": "Sequential consistency as lazy linearizability\n", "abstract": " This paper shows that actually sequential consistency is a form of \u201clazy\u201d atomic consistency. More precisely, it proposes a new particularly simple sequential consistency protocol that orders the conflicting operations on each object separately, and appropriately invalidates object copies to prevent consistency violation. When compared to invalidation-based protocols that ensure atomic consistency (such as Li-Hudak\u2019s protocol), the proposed protocol can be seen as using lazy invalidation. Hence, in addition to a new consistency protocol, the paper provides a new insight into the concepts and mechanisms that underlie consistency protocols: while atomic consistency is based on physical time and requires eager invalidation, sequential consistency is based on logical time and needs only lazy invalidation.", "num_citations": "39\n", "authors": ["495"]}
{"title": "Fault-tolerant leader election in mobile dynamic distributed systems\n", "abstract": " This paper addresses the leader election problem in dynamic distributed systems with mobile processes. To do so, it is assumed that the system alternates periods of good and bad behavior, in the line of the timed asynchronous model of Cristian and Fetzer. We extend the eventual leadership properties recently proposed by Larrea et al. for non-mobile dynamic systems, defining two new properties that take into account graph joins/fragmentations due to process mobility. We also propose a new leader election algorithm in a weak mobile dynamic distributed system model. Using a categorization framework, we compare our system model with a number of models proposed in the literature, showing that our leader election algorithm works in a model which is weaker than the rest.", "num_citations": "38\n", "authors": ["495"]}
{"title": "Test & set, adaptive renaming and set agreement: a guided visit to asynchronous computability\n", "abstract": " An important issue in fault-tolerant asynchronous computing is the respective power of an object type with respect to another object type. This question has received a lot of attention, mainly in the context of the consensus problem where a major advance has been the introduction of the consensus number notion that allows ranking the synchronization power of base object types (atomic registers, queues, test&set objects, compare&swap objects, etc.) with respect to the consensus problem. This has given rise to the well-known Herlihy's hierarchy. Due to its very definition, the consensus number notion is irrelevant for studying the respective power of object types that are too weak to solve consensus for an arbitrary number of processes (these objects are usually called subconsensus objects). Considering an asynchonous system made up of n processes prone to crash, this paper addresses the power of such object\u00a0\u2026", "num_citations": "38\n", "authors": ["495"]}
{"title": "In search of the holy grail: Looking for the weakest failure detector for wait-free set agreement\n", "abstract": " Asynchronous failure detector-based set agreement algorithms proposed so far assume that all the processes participate in the algorithm. This means that (at least) the processes that do not crash propose a value and consequently execute the algorithm. It follows that these algorithms can block forever (preventing the correct processes from terminating) when there are correct processes that do not participate in the algorithm. This paper investigates the wait-free set agreement problem, i.e., the case where the correct participating processes have to decide a value whatever the behavior of the other processes (i.e., the processes that crash and the processes that are correct but do not participate in the algorithm). The paper presents a wait-free set agreement algorithm. This algorithm is based on a leader failure detector class that takes into account the notion of participating processes. Interestingly, this\u00a0\u2026", "num_citations": "38\n", "authors": ["495"]}
{"title": "Fast, scalable synchronization with minimal hardware support\n", "abstract": " This paper concerns synchronization under read/write atomicity in shared memory multiprocessors. We present a new algorithm for N-process mutual exclusion that requires only read and write operations and that has 0 (log2 IV) time complexity, where \u201ctime\u201d is measured by counting remote memory references. The time complexity of this algorithm is better than that of all prior solutions to the mutual exclusion problem that are based upon atomic read and write instructions; in fact, the time complexity of most prior solutions is unbounded. Performance studies are presented that show that our mutual exclusion algorithm exhibits scalable performance under heavy contention. In the second part of the paper, we discuss two extensions of our mutual exclusion algorithm. In the first extension, we modify the algorithm so that in the absence of contention only 0 (1) memory references are required. In the second extension, the\u00a0\u2026", "num_citations": "37\n", "authors": ["495"]}
{"title": "Synchrony weakened by message adversaries vs asynchrony restricted by failure detectors\n", "abstract": " A message adversary is a daemon that suppresses messages in round-based message-passing synchronous systems in which no process crashes. A property imposed on a message adversary defines a subset of messages that cannot be eliminated by the adversary. It has recently been shown that when a message adversary is constrained by a property denoted TOUR (for tournament), the corresponding synchronous system and the asynchronous crash-prone read/write system have the same computability power for task solvability.", "num_citations": "36\n", "authors": ["495"]}
{"title": "How to find his way in the jungle of consistency criteria for distributed shared memories (or how to escape from Minos' labyrinth)\n", "abstract": " Surveys consistency criteria that have been proposed, and sometimes implemented, for distributed shared objects and memories. Linearizability, sequential consistency, hybrid consistency and causal consistency are particularly emphasized. These criteria are precisely analyzed and protocols that implement them are described. It is suggested that the hybrid consistency, introduced by Attiya and Friedman (1992), constitutes Ariadne's clue to understanding this jungle of consistency criteria.< >", "num_citations": "36\n", "authors": ["495"]}
{"title": "Power and limits of distributed computing shared memory models\n", "abstract": " What can and cannot be computed in a distributed system is a complex function of the system\u2019s communication model, timing model, and failure model. Considering a canonical distributed system model, where processes execute asynchronously, communicate by reading and writing shared memory, and fail by crashing, this paper surveys important results about computability, and explains the fundamental role that topology plays in the distributed computability theory. The paper also considers different types of additional assumptions that allow impossibility results to be circumvented. These assumptions are known under the names failure detectors and adversaries. Finally, it presents a powerful simulation technique (known under the name BG simulation), which allows to show that, from a computability point of view, t-resilience is not different from wait-freedom. When pieced together, the aim of all the concepts\u00a0\u2026", "num_citations": "35\n", "authors": ["495"]}
{"title": "Normality: A consistency condition for concurrent objects\n", "abstract": " This paper is focused on concurrent objects (objects shared by concurrent processes). It introduces a consistency condition called Normality whose definition is based only on local orders of operations as perceived by processes and by objects. First we consider the model in which each operation is on exactly one object. In this model we show that a history is linearizable iff it is normal. However, the definition of Normality is less constraining in the sense that there are strictly more legal sequential histories which are considered equivalent to the given history when Normality is used. We next consider a more general model where operations can span multiple objects. In this model we show that Normality is strictly weaker than Linearizability, i.e., history may be normal but not linearizable. As Normality refers only to local orders (process order and object order) it appears to be well-suited to objects supported by\u00a0\u2026", "num_citations": "35\n", "authors": ["495"]}
{"title": "Anonymous graph exploration without collision by mobile robots\n", "abstract": " Considering autonomous mobile robots moving on a finite anonymous graph, this paper focuses on the Constrained Perpetual Graph Exploration problem (CPGE). That problem requires each robot to perpetually visit all the vertices of the graph, in such a way that no vertex hosts more than one robot at a time, and each edge is traversed by at most one robot at a time. The paper states an upper bound k on the number of robots that can be placed in the graph while keeping CPGE solvability. To make the impossibility result as strong as possible (no more than k robots can be initially placed in the graph), this upper bound is established under a strong assumption, namely, there is an omniscient daemon that is able to coordinate the robots movements at each round of the synchronous system. Interestingly, this upper bound is related to the topology of the graph. More precisely, the paper associates with each graph a\u00a0\u2026", "num_citations": "34\n", "authors": ["495"]}
{"title": "Exploiting write semantics in implementing partially replicated causal objects\n", "abstract": " To support efficient access to objects that support cooperation between users, the objects need to be replicated at nodes where they are frequently accessed. Causal consistency is a consistency criterion particularly attractive for objects shared in cooperative applications. It is based on a causality relation on read and write operations issued by concurrent processes. It only requires that writes that depend on one another be perceived in their dependence order by all processes; so, two independent writes can be perceived in a distinct order by two different processes. In message-passing systems causal consistency is usually implemented by a protocol that ensures causal delivery of all messages. In this paper we develop a new protocol for causally consistent shared objects that exploits the write semantics that can be associated with update messages. This protocol allows early delivery of update messages and\u00a0\u2026", "num_citations": "34\n", "authors": ["495"]}
{"title": "Specifying concurrent problems: beyond linearizability and up to tasks\n", "abstract": " Tasks and objects are two predominant ways of specifying distributed problems. A task specifies for each set of processes (which may run concurrently) the valid outputs of the processes. An object specifies the outputs the object may produce when it is accessed sequentially. Each one requires its own implementation notion, to tell when an execution satisfies the specification. For objects linearizability is commonly used, while for tasks implementation notions are less explored.               Sequential specifications are very convenient, especially important is the locality property of linearizability, which states that linearizable objects compose for free into a linearizable object. However, most well-known tasks have no sequential specification. Also, tasks have no clear locality property.               The paper introduces the notion of interval-sequential object. The corresponding implementation notion of interval\u00a0\u2026", "num_citations": "33\n", "authors": ["495"]}
{"title": "Anonymous asynchronous systems: The case of failure detectors\n", "abstract": " Trivially, agreement problems such as consensus, that cannot be solved in non-anonymous asynchronous systems prone to process failures, cannot be solved either if the system is anonymous. The paper investigates failure detectors that allow processes to circumvent this impossibility. It has several contributions. It first presents four failure detectors (denoted AP, , A\u03a9 and A\u03a3) and show that they are the \u201cidentity-free\u201d counterparts of the two perfect failure detectors, eventual leader failure detectors and quorum failure detectors, respectively. A\u03a3 is new and showing that A\u03a3 and \u03a3 have the same computability power in a non-anonymous system is not trivial. The paper also shows that the notion of failure detector reduction is related to the computation model. Then, the paper presents and proves correct an uniform anonymous consensus algorithm based on the failure detector pair (A\u03a9,A\u03a3) (\u201cuniform\u201d means\u00a0\u2026", "num_citations": "31\n", "authors": ["495"]}
{"title": "Brief announcement: virtual world consistency: a new condition for stm systems\n", "abstract": " The concept of Software Transactional Memory (STM), originally proposed in [15], originates from the observation that programmers were missing something for the applications made up of concurrent processes that access shared data structures (base objects). Roughly speaking, the \u201conly\u201d tool they were proposed to solve their synchronization problems is a set of locks that allow the processes to prevent conflicting accesses to shared objects. But, due to the difficulty to manage them, locks are not a panacea. If a single lock controls a large set of data, it reduces drastically the parallelism, while many locks used to control fine grain data are difficult to master and error-prone. On another side, the recent advances in technology (eg, more particularly in multicore architectures) have given rise to a new momentum to practical and theoretical research in concurrency and synchronization that constitutes a large application\u00a0\u2026", "num_citations": "31\n", "authors": ["495"]}
{"title": "Eventual clusterer: A modular approach to designing hierarchical consensus protocols in manets\n", "abstract": " This paper proposes a modular approach to the design of hierarchical consensus protocols for the mobile ad hoc network with a static and known set of hosts. A two-layer hierarchy is imposed on the network by grouping mobile hosts into clusters, each with a clusterhead. The messages from and to the hosts in the same cluster are merged/unmerged by the clusterhead so as to reduce the message cost and improve the scalability. The proposed modular approach separates the concerns of clustering hosts from achieving consensus. A clustering function, called eventual clusterer (denoted as diamC), is designed for constructing and maintaining the two-layer hierarchy. Similar to unreliable failure detectors, diamC greatly facilitates the design of hierarchical protocols by providing the fault-tolerant clustering function transparently. We propose an implementation of diamC based on the failure detector diamS. Using\u00a0\u2026", "num_citations": "31\n", "authors": ["495"]}
{"title": "Small-world networks: From theoretical bounds to practical systems\n", "abstract": " In small-world networks, each peer is connected to its closest neighbors in the network topology, as well as to additional long-range contact(s), also called shortcut(s). In 2000, Kleinberg provided asymptotic lower bounds on routing performances and showed that greedy routing in an n-peer small-world network performs in  steps when the distance to shortcuts is chosen uniformly at random, and in \u0398(log2               n) when the distance to shortcuts is chosen according to a harmonic distribution in a d-dimensional mesh. Yet, we observe through experimental results that peer to peer gossip-based protocols achieving small-world topologies where shortcuts are randomly chosen, perform reasonably well in practice.             Kleinberg results are relevant for extremely large systems while systems considered in practice are usually of smaller size (they are typically made up of less than one million of peers). This\u00a0\u2026", "num_citations": "31\n", "authors": ["495"]}
{"title": "On-the-fly analysis of distributed computations\n", "abstract": " At some abstraction level a distributed computation can be modeled as a partial order on a set of observable events. This paper presents an analysis technique which can be superimposed on distributed computations to analyze the structure of control flows terminating at observable events. A general algorithm working on the longest control flows of distributed computations is introduced. Moreover it is shown how this algorithm can be simplified according to the position of observable events with respect to communication events.", "num_citations": "31\n", "authors": ["495"]}
{"title": "Inevitable global states: a concept to detect unstable properties of distributed computations in an observer independent way\n", "abstract": " When analyzing, testing or debugging a distributed program, an important question one has to answer is: \"Does this computation satisfy a given property?\". We are interested in this paper in answering such a question when the property is formulated as a general predicate on a global state of the computation, and more specifically when the property is unstable (i.e. once true the associated predicate is not guaranteed to remain true forever). Notions such as abstraction level with respect to predicate (user's level) and weak precedence between local states are first introduced. Then an abstraction called inevitable global state is defined, and a necessary and sufficient condition to detect such states is provided. With this abstraction a precise meaning is given to the previous question (independently of any particular perception one can have of the distributed computation). A detection algorithm for this question is finally\u00a0\u2026", "num_citations": "31\n", "authors": ["495"]}
{"title": "Anonymous asynchronous systems: the case of failure detectors\n", "abstract": " Due to the multiplicity of loci of control, a main issue distributed systems have to cope with lies in the uncertainty on the system state created by the adversaries that are asynchrony, failures, dynamicity, mobility, etc. Considering message-passing systems, this paper considers the uncertainty created by the net effect of asynchrony and process crash failures in systems where the processes are anonymous (i.e., processes have no identity and locally execute the same algorithm). Trivially, agreement problems such as consensus, that cannot be solved in non-anonymous asynchronous systems prone to process failures, cannot be solved either if the system is anonymous. The paper investigates failure detectors that allow processes to circumvent this impossibility. It has several contributions. It first presents four failure detectors (denoted AP, , A\u03a9, and A\u03a3) and show that they are the \u201cidentity-free\u201d counterparts\u00a0\u2026", "num_citations": "30\n", "authors": ["495"]}
{"title": "On asymmetric progress conditions\n", "abstract": " Wait-freedom and obstruction-freedom have received a lot of attention in the literature. These are symmetric progress conditions in the sense that they consider all processes as being\" equal\". Wait-freedom has allowed to rank the synchronization power of objects in presence of process failures, while (the weaker) obstruction-freedom allows for simpler and more efficient object implementations.", "num_citations": "30\n", "authors": ["495"]}
{"title": "Distributed agreement and its relation with error-correcting codes\n", "abstract": " The condition based approach identifies sets of input vectors, called conditions, for which it is possible to design a protocol solving a distributed problem despite process crashes. This paper investigates three related agreement problems, namely consensus, interactive consistency, and k-set agreement, in the context of the condition-based approach. In consensus, processes have to agree on one of the proposed values; in interactive consistency, they have to agree on the vector of proposed values; in k-set agreement, each process decides on one of the proposed values, and at most k different values can be decided on. For both consensus and interactive consistency, a direct correlation between these problems and error correcting codes is established. In particular, crash failures in distributed agreement problems correspond to erasure failures in error correcting codes, and Byzantine and value domain\u00a0\u2026", "num_citations": "30\n", "authors": ["495"]}
{"title": "A hierarchy of conditions for consensus solvability\n", "abstract": " In a previous paper we introduced the condition-based approach, consisting of identifying sets of input vectors, called conditions, for which there exists an asynchronous protocol solving consensus despite the occurrence of up to f process crashes, and characterized this set of conditions,@@@@ wk f. Here, we investigate@@@@ wk f from the complexity perspective, and show that this class consists of a hierarchy of classes of conditions,@@@@[d] f, where d, 0\u2a87 d\u2a87 f, is the degree of the condition, each one strictly contained in the previous one. The value f-d represents the \u201cdifficulty\u201d of the class@@@@[d] f: we present a generic condition-based protocol that can be instantiated with any C\u2208@@@@[d] f, and solve consensus with (2n+ 1)[log 2 ([(f-d)/2]+ 1)] shared memory read/write operations per process. For each d we present two natural conditions, C1 [d] f and C2 [d] f, that might be useful in practice, and we\u00a0\u2026", "num_citations": "29\n", "authors": ["495"]}
{"title": "A case study of agreement problems in distributed systems: non-blocking atomic commitment\n", "abstract": " The paper considers an agreement problem whose practical interest is well known, namely the Non-Blocking Atomic Commitment Problem. First, a generic protocol solving this problem is given and then instantiations of its generic statements are provided for both synchronous and asynchronous distributed systems. These instantiations use a few basic components: timeout mechanism and reliable multicast primitives for synchronous systems unreliable failure detectors and a solution to the consensus problem for asynchronous systems. So, the article can also be considered as an introduction to state of the art concepts and protocols for distributed fault tolerance.", "num_citations": "29\n", "authors": ["495"]}
{"title": "The price of anonymity: Optimal consensus despite asynchrony, crash, and anonymity\n", "abstract": " This article addresses the consensus problem in asynchronous systems prone to process crashes, where additionally the processes are anonymous (they cannot be distinguished one from the other: they have no name and execute the same code). To circumvent the three computational adversaries (asynchrony, failures, and anonymity) each process is provided with a failure detector of a class denoted \u03c8, that gives it an upper bound on the number of processes that are currently alive (in a nonanonymous system, the classes \u03c8 and P---the class of perfect failure detectors---are equivalent). The article first presents a simple \u03c8-based consensus algorithm where the processes decide in 2t + 1 asynchronous rounds (where t is an upper bound on the number of faulty processes). It then shows one of its main results, namely 2t + 1 is a lower bound for consensus in the anonymous systems equipped with \u03c8. The second\u00a0\u2026", "num_citations": "28\n", "authors": ["495"]}
{"title": "Primary component asynchronous group membership as an instance of a generic agreement framework\n", "abstract": " Group-based computing is becoming more and more popular when one has to design middleware able to support reliable distributed applications. This paradigm is made of two basic services, namely, a group membership service and a group communication service. More generally, a group is a set of processes cooperating to carry out a common task (e.g., copies of a replicated server, participants in a transaction or users in a CSCW-based application). Due to the desire of new processes to join the group, to the desire of a group member to leave it, or to process crashes, the composition of a group can evolve dynamically. The set of processes that currently implements the group is called the current view of the group. This paper addresses the specification and the implementation of a primary component group membership service. Primary component means that the specification imposes to have a single view at\u00a0\u2026", "num_citations": "28\n", "authors": ["495"]}
{"title": "Distributed computing with mobile robots: an introductory survey\n", "abstract": " This paper surveys the main characteristics of the distributed models proposed for robot networks and briefly presents the latest algorithmic achievements for tackling the agreement abstraction in both continuous and discrete spaces.", "num_citations": "27\n", "authors": ["495"]}
{"title": "The universe of symmetry breaking tasks\n", "abstract": " Processes in a concurrent system need to coordinate using a shared memory or a message-passing subsystem in order to solve agreement tasks such as, for example, consensus or set agreement. However, coordination is often needed to \u201cbreak the symmetry\u201d of processes that are initially in the same state, for example, to get exclusive access to a shared resource, to get distinct names or to elect a leader.               This paper introduces and studies the family of generalized symmetry breaking (GSB) tasks, that includes election, renaming and many other symmetry breaking tasks. Differently from agreement tasks, a GSB task is \u201cinputless\u201d, in the sense that processes do not propose values; the task only specifies the symmetry breaking requirement, independently of the system\u2019s initial state (where processes differ only on their identifiers). Among various results characterizing the family of GSB tasks, it is\u00a0\u2026", "num_citations": "27\n", "authors": ["495"]}
{"title": "Sequential consistency in distributed systems: Theory and implementation\n", "abstract": " Recently, distributed shared memory (DSM) systems have received much attention because such an abstraction simplifies programming. It has been shown that many practical applications using DSMs require competing operations. We have aimed at unifying theory and implementations of protocols for sequential consistency, which provides competing operations. The results are useful not only to clarify previously proposed implementations but also to develop new efficient implementations for consistency criteria which provide competing operations, such as sequential consistency, weak ordering (with sequential consistency for competing accesses), and release consistency (with sequential consistency for competing accesses). By adopting concepts from concurrency control, we have developed theory for sequential consistency, called a \\it sequentializability theory. This paper first presents the sequentializability theory, and then demonstrates the correctness of existing protocols using the theory. Finally, the paper presents new protocols which require significantly less communication than previously proposed protocols in systems which do not provide hardware atomic broadcasting facilities.", "num_citations": "27\n", "authors": ["495"]}
{"title": "A distributed algorithm to prevent mutual drift between n logical clocks\n", "abstract": " Numerous distributed algorithms, whose aim is to control a computation, are based on logical clocks. Each process is endowed with such a clock which behaves as a counter initialized to zero and strictly increasing [8]. Each time an event is produced by a process (eg, sending or receiving of a message), the clock of this process is incremented and the resulting value is used to stamp the event. So, the event is uniquely identified by this timestamp coupled with the process name (all the process names are supposed to be distinct). A priori, the logical speeds of the processes are independent (by logical speed we mean the growth of logical clocks). Any logical clock may drift with respect to the other clocks. Two attitudes are then possibly depending on the type of the distributed algorithm which uses these clocks: the value of a drifting clock may be corrected when it becomes too large with respect to the other clock\u00a0\u2026", "num_citations": "27\n", "authors": ["495"]}
{"title": "Syst\u00e8mes r\u00e9partis et r\u00e9seaux: concepts, outils et algorithmes\n", "abstract": " L'\u00e9volution conjointe de la technologie mat\u00e9rielle, des normes et standards, de la m\u00e9thodologie de conception et d'\u00e9criture du logiciel incitent de plus en plus \u00e0 consid\u00e9rer les applications comme un ensemble d'entit\u00e9s coop\u00e9rant \u00e0 la r\u00e9alisation d'un but commun D\u00e8s lors la ma\u00eetrise des syst\u00e8mes r\u00e9partis et des applications d\u00e9velopp\u00e9es sur les r\u00e9seaux de machines passe par la connaissance de concepts, d'outils, d'algorithmes et de m\u00e9thodes sp\u00e9cifiques Ce livre aborde ces diff\u00e9rents aspects du domaine de la r\u00e9partition Les outils de base sont introduits \u00e0 l'aide d'exemples issus des r\u00e9seaux et des syst\u00e8mes; les probl\u00e8mes d'apprentissage de r\u00e9seau et d'\u00e9tat global sont particuli\u00e8rement approfondis; des protocoles permettant de r\u00e9partir des contraintes de synchronisation sont pr\u00e9sent\u00e9s et au travers de nombreux algorithmes des \u00e9l\u00e9ments fondamentaux de la r\u00e9partition sont \u00e9tudi\u00e9s et analys\u00e9s dans le d\u00e9tail Il s'\u00a0\u2026", "num_citations": "27\n", "authors": ["495"]}
{"title": "Failure detectors in homonymous distributed systems (with an application to consensus)\n", "abstract": " This paper is on homonymous distributed systems where processes are prone to crash failures and have no initial knowledge of the system membership (\u201chomonymous\u201d means that several processes may have the same identifier). New classes of failure detectors suited to these systems are first defined. Among them, the classes H \u03a9 and H \u03a3 are introduced that are the homonymous counterparts of the classes \u03a9 and \u03a3, respectively.(Recall that the pair< \u03a9, \u03a3> defines the weakest failure detector to solve consensus.) Then, the paper shows how H \u03a9 and H \u03a3 can be implemented in homonymous systems without membership knowledge (under different synchrony requirements). Finally, two algorithms are presented that use these failure detectors to solve consensus in homonymous asynchronous systems where there is no initial knowledge of the membership. One algorithm solves consensus with< H \u03a9, H \u03a3>, while\u00a0\u2026", "num_citations": "26\n", "authors": ["495"]}
{"title": "Visiting gafni\u2019s reduction land: From the bg simulation to the extended bg simulation\n", "abstract": " The Borowsky-Gafni (BG) simulation algorithm is a powerful tool that allows a set of t\u2009+\u20091 asynchronous sequential processes to wait-free simulate (i.e., despite the crash of up to t of them) a large number n of processes under the assumption that at most t of these processes fail (i.e., the simulated algorithm is assumed to be t-resilient). The BG simulation has been used to prove solvability and unsolvability results for crash-prone asynchronous shared memory systems.               In its initial form, the BG simulation applies only to colorless decision tasks, i.e., tasks in which nothing prevents processes to decide the same value (e.g., consensus or k-set agreement tasks). Said in another way, it does not apply to decision problems such as renaming where no two processes are allowed to decide the same new name. Very recently (STOC 2009), Eli Gafni has presented an extended BG                  simulation\u00a0\u2026", "num_citations": "26\n", "authors": ["495"]}
{"title": "A leader election protocol for eventually synchronous shared memory systems\n", "abstract": " While protocols that elect an eventual common leader in asynchonous message-passing systems have been proposed, to our knowledge, no such protocol has been proposed for the shared memory communication model. This paper presents a leader election protocol suited to the shared memory model. In addition to its design simplicity, the proposed protocol has two noteworthy properties, namely, it does not use timers, and is optimal with respect to the number of processes that have to write forever the shared memory: a single process has to do it (namely, the leader that is eventually elected). Among the many possible uses of such a leader protocol, one is Lamport's Paxos protocol. Paxos is an asynchronous consensus algorithm that relies on an underlying eventual leader abstraction. As recently, several versions of Paxos have been designed for asynchronous shared memory systems (the shared memory\u00a0\u2026", "num_citations": "26\n", "authors": ["495"]}
{"title": "Early stopping in global data computation\n", "abstract": " The Global Data Computation problem consists of providing each process with the same vector (with one entry per process) such that each entry is filled by a value provided by the corresponding process. This paper presents a protocol that solves this problem in an asynchronous distributed system where processes can crash, but equipped with a perfect failure detector. This protocol requires that processes execute asynchronous computation rounds. The number of rounds is upper bounded by min(f+2, t+1, n), where n, t, and f represent the total number of processes, the maximum number of processes that can crash, and the number of processes that actually crash, respectively. This value is a lower bound for the number of rounds when t<n-1. To our knowledge, this protocol is the first to achieve this lower bound. Interestingly, this protocol meets the same lower bound as the one required in synchronous systems.", "num_citations": "26\n", "authors": ["495"]}
{"title": "Evaluating the condition-based approach to solve consensus\n", "abstract": " Several approaches have been proposed to circumvent the impossibility to solve consensus in asynchronous distributed systems prone to process crash failures. Among them, randomization, unreliable failure detectors, and leader oracles have been particularly investigated. Recently a new approach (called \u201ccondition-based\u201d) has been proposed. Let an input vector be a vector whose i-th entry contains the value proposed by process pi. The conditionbased approach consists in stating conditions on input vectors that make consensus solvable despite up to f process crashes. Several conditions have been proposed.(As an example, one of them requires that the greatest value in an input vector appears more than f times.) This paper presents an evaluation of the condition-based approach to solve consensus. It shows that this approach is particularly attractive and very efficient when the probability of process crashes is low (a common fact in practice). In these cases, the probability for the condition-based protocol to terminate is practically equal to 1.", "num_citations": "26\n", "authors": ["495"]}
{"title": "Anonymous obstruction-free ( n ,\u00a0 k )-set agreement with                                           n            -            k            +            1 atomic read/write registers\n", "abstract": " The k-set agreement problem is a generalization of the consensus problem. Namely, assuming that each process proposes a value, every non-faulty process must decide one of the proposed values, under the constraint that at most k different values are decided. This is a hard problem in the sense that it cannot be solved in a pure read/write asynchronous system, in which k or more processes may crash. One way to sidestep this impossibility result consists in weakening the termination property, requiring only that a process decides if it executes alone during a long enough period of time. This is the well-known obstruction-freedom progress condition. Consider a system of n anonymous asynchronous processes that communicate through atomic read/write registers, and such that any number of them may crash. This paper addresses and solves the challenging open problem of designing an obstruction-free k-set agreement\u00a0\u2026", "num_citations": "25\n", "authors": ["495"]}
{"title": "Signature-free asynchronous Byzantine systems: from multivalued to binary consensus with  t< n/3,  O (n 2) messages, and constant time\n", "abstract": " This paper presents a new algorithm that reduces multivalued consensus to binary consensus in an asynchronous message-passing system made up of n processes where up to t may commit Byzantine failures. This algorithm has the following noteworthy properties: it assumes  (and is consequently optimal from a resilience point of view), uses  messages, has a constant time complexity, and uses neither signatures nor additional computational power (such as random numbers, failure detectors, additional scheduling assumption, or additional synchrony assumption). The design of this reduction algorithm relies on two new all-to-all communication abstractions. The first one allows the non-faulty processes to reduce the number of proposed values to c, where c is a small constant. The second communication abstraction allows each non-faulty process to compute a set of (proposed) values satisfying the\u00a0\u2026", "num_citations": "25\n", "authors": ["495"]}
{"title": "The multiplicative power of consensus numbers\n", "abstract": " The Borowsky-Gafni (BG) simulation algorithm is a powerful reduction algorithm that shows that t-resilience of decision tasks can be fully characterized in terms of wait-freedom. Said in another way, the BG simulation shows that the crucial parameter is not the number n of processes but the upper bound t on the number of processes that are allowed to crash. The BG algorithm considers colorless decision tasks in the base read/write shared memory model.(Colorless means that if, process decides a value, any other process is allowed to decide the very same value.)", "num_citations": "25\n", "authors": ["495"]}
{"title": "Implementing a regular register in an eventually synchronous distributed system prone to continuous churn\n", "abstract": " Due to their capability to hide the complexity generated by the messages exchanged between processes, shared objects are one of the main abstractions provided to developers of distributed applications. Implementations of such objects, in modern distributed systems, have to take into account the fact that almost all services, implemented on top of distributed infrastructures, are no longer fully managed due to either their size or their maintenance cost. Therefore, these infrastructures exhibit several autonomic behaviors in order to, for example, tolerate failures and continuous arrival and departure of nodes (churn phenomenon). Among all the shared objects, the register object is a fundamental one. Several protocols have been proposed to build fault resilient registers on top of message-passing system, but, unfortunately, failures are not the only challenge in modern distributed systems and new issues arise in the\u00a0\u2026", "num_citations": "24\n", "authors": ["495"]}
{"title": "The price of anonymity: Optimal consensus despite asynchrony, crash and anonymity\n", "abstract": " This paper addresses the consensus problem in asynchronous systems prone to process crashes, where additionally the processes are anonymous (they cannot be distinguished one from the other: they have no name and execute the same code). To circumvent the three computational adversaries (asynchrony, failures and anonymity) each process is provided with a failure detector of a class denoted \u03c8, that gives it an upper bound on the number of processes that are currently alive (in a non-anonymous system, the classes \u03c8 and  -the class of perfect failure detectors- are equivalent).               The paper first presents a simple \u03c8-based consensus algorithm where the processes decide in 2t\u2009+\u20091 asynchronous rounds (where t is an upper bound on the number of faulty processes). It then shows one of its main results, namely, 2t\u2009+\u20091 is a lower bound for consensus in the anonymous systems equipped with \u03c8. The\u00a0\u2026", "num_citations": "24\n", "authors": ["495"]}
{"title": "Synchronization and Concurrency Measures for Distributed Computations.\n", "abstract": " Time and message complexities are measures commonly used to characterize distributed computations. However, these measures only address quantitative aspects of the computation. This paper presents several qualitative measures which quantify the degree of concurrency in a distributed computation by analyzing its synchronization constraints. We introduce two abstractions, called cone and cylinder, and de ne concurrency measures using these two abstractions. Then, we present simple ways to compute these measures; therefore, these measures can be easily incorporated into any system to analyze distributed executions.", "num_citations": "24\n", "authors": ["495"]}
{"title": "Parcours et apprentissage dans un r\u00e9seau de processus communicants\n", "abstract": " Les algorithmes distribu\u00e9s, qui constituent les composants de base des applications et des syst\u00e8mes r\u00e9partis, sont form\u00e9s d\u2019un r\u00e9seau de processus communicant par messages. Un grand nombre d\u2019entre eux, dont le r\u00f4le est de r\u00e9aliser une fonction de contr\u00f4le. n\u00e9cessitent la mise en \u0153uvre de parcours du r\u00e9seau par des messages ou l\u2019apprentissage par un processus donn\u00e9 d\u2019une information de nature globale. Cet article examine ces deux probl\u00e8mes.\u2018A partir de l\u2019analyse d\u2019un probl\u00e8me simple (la diffusion d\u2019une information) une technique g\u00e9n\u00e9rale visant \u00e0 r\u00e9duire le nombre de messages \u00e9chang\u00e9s est introduite. Le contr\u00f4le des transferts introduit est appliqu\u00e9 aux techniques de parcours canoniques de r\u00e9seau qui sont ensuite \u00e9tudi\u00e9es et \u00e0 un paradigme relatif \u00e0 l\u2019apprentissage d\u2019une connaissance globale par un processus donn\u00e9. La g\u00e9n\u00e9ralit\u00e9 du contr\u00f4le des transferts, des modes d\u2019exploration et de la\u00a0\u2026", "num_citations": "24\n", "authors": ["495"]}
{"title": "Towards a universal construction for transaction-based multiprocess programs\n", "abstract": " The aim of a Software Transactional Memory (STM) system is to discharge the programmer from the explicit management of synchronization issues. The programmer\u2019s job resides in the design of multiprocess programs in which processes are made up of transactions, each transaction being an atomic execution unit that accesses concurrent objects. The important point is that the programmer has to focus her/his efforts only on the parts of the code which have to be atomic execution units without worrying on the way how the corresponding synchronization has to be realized.Non-trivial STM systems allow transactions to execute concurrently and rely on the notion of commit/abort of a transaction in order to solve their conflicts on the objects they access simultaneously. In some cases, the management of aborted transactions is left to the programmer. In other cases, the underlying system scheduler is appropriately\u00a0\u2026", "num_citations": "23\n", "authors": ["495"]}
{"title": "Specifying and implementing an eventual leader service for dynamic systems\n", "abstract": " The election of an eventual leader in an asynchronous system prone to process crashes is an important problem of fault-tolerant distributed computing. This problem is known as the implementation of the failure detector \u03a9. Nearly all papers that propose algorithms implementing such an eventual leader service consider a static system. In contrast this paper considers a dynamic system, i.e. a system in which processes can join and leave. The paper has three main contributions. It first proposes a specification of \u03a9 suited to dynamic systems. Then, it presents and proves correct two algorithms implementing this specification. Finally, the paper discusses the notion of an eventual leader suited to dynamic systems. It introduces an additional property related to system stability. The design of an algorithm satisfying this last property remains an open challenging problem.", "num_citations": "23\n", "authors": ["495"]}
{"title": "Help when needed, but no more: efficient read/write partial snapshot\n", "abstract": " An atomic snapshot object is an object that can be concurrently accessed by asynchronous processes prone to crash. It is made of m components (base atomic registers) and is defined by two operations: an update operation that allows a process to atomically assign a new value to a component and a snapshot operation that atomically reads and returns the values of all the components. To cope with the net effect of concurrency, asynchrony and failures, the algorithm implementing the update operation has to help concurrent snapshot operations so that they always terminate. This paper is on partial snapshot objects. Such an object provides a snapshot operation that can take any subset of the components as input parameter, and atomically reads and returns the values of this subset of components. The paper has two contributions. The first is the introduction of two properties for partial snapshot object algorithms\u00a0\u2026", "num_citations": "23\n", "authors": ["495"]}
{"title": "A lock-based stm protocol that satisfies opacity and progressiveness\n", "abstract": " The aim of a software transactional memory (STM) system is to facilitate the delicate problem of low-level concurrency management, i.e. the design of programs made up of processes/threads that concurrently access shared objects. To that end, a STM system allows a programmer to write transactions accessing shared objects, without having to take care of the fact that these objects are concurrently accessed: the programmer is discharged from the delicate problem of concurrency management. Given a transaction, the STM system commits or aborts it. Ideally, it has to be efficient (this is measured by the number of transactions committed per time unit), while ensuring that as few transactions as possible are aborted. From a safety point of view (the one addressed in this paper), a STM system has to ensure that, whatever its fate (commit or abort), each transaction always operates on a consistent state\u00a0\u2026", "num_citations": "23\n", "authors": ["495"]}
{"title": "Two abstractions for implementing atomic objects in dynamic systems\n", "abstract": " Defining appropriate abstractions is one of the main challenges in computer science. This paper investigates two matching abstractions for implementing read/write objects in a dynamic server system prone to crash failures. The first abstraction concerns dynamic quorum systems. The second is a persistent reliable broadcast communication primitive. These two abstractions capture the essence of basic mechanisms allowing the implementation of atomic objects in a distributed system where servers can dynamically enter and leave the system (or crash). A read protocol and a write protocol based on these abstractions are described and proved correct. The properties defining these abstractions can be seen as requirements that are sufficient for implementing a dynamic storage service, while the feasibility conditions that are stated can be seen as necessary requirements. Instantiating the proposed\u00a0\u2026", "num_citations": "23\n", "authors": ["495"]}
{"title": "Local states in distributed computations: A few relations and formulas\n", "abstract": " If events produced by processes of a distributed computation are generally supposed to be instantaneous, it is not the case for local states generated by these events. Due to message exchanges and synchronization local states have some duration. This paper defines notions about local states such as weak precedence, strong precedence, weak concurrency and strong concurrency. Moreover a few formulas based on vector clocks, and consequently usable in an operational context, are introduced to decide about relations between local states. These relations and formulas can be used either to debug, test or analyze distributed programs (especially for global properties detection) or to define consistent checkpoints.", "num_citations": "23\n", "authors": ["495"]}
{"title": "On-the-fly replay: a practical paradigm and its implementation for distributed debugging\n", "abstract": " This paper presents a practical paradigm, called on-the-fly replay. This paradigm consists of running a distributed program twice at the same time: an original computation is running in a regular fashion, which also includes steps of making non-deterministic choices; this execution is driving a twin execution, whose non-deterministic choices do not have to be evaluated (since they are taken from the original computation). This paradigm has several interesting uses. Among them, distributed debugging is particularly noteworthy. The integration of this paradigm into a distributed debugging facility, called EREBUS, is described. This implementation was run on a distributed memory parallel machine (Intel Hypercube iPSC2) and experimental results are described, that demonstrate the advantage of this paradigm.< >", "num_citations": "22\n", "authors": ["495"]}
{"title": "Loo king for the Wea kest Failure Detector for k-Set Agreement in Message-Passing Systems: Is  the End of the Road?\n", "abstract": " In the k-set agreement problem, each process (in a set of n processes) proposes a value and has to decide a proposed value in such a way that at most k different values are decided. While this problem can easily be solved in asynchronous systems prone to t process crashes when k\u2009>\u2009t, it cannot be solved when k\u2009\u2264\u2009t. Since several years, the failure detector-based approach has been investigated to circumvent this impossibility. While the weakest failure detector class to solve the k-set agreement problem in read/write shared-memory systems has recently been discovered (PODC 2009), the situation is different in message-passing systems where the weakest failure detector classes are known only for the extreme cases k\u2009=\u20091 (consensus) and k\u2009=\u2009n\u2009\u2212\u20091 (set agreement). This paper introduces a candidate for the general case. It presents a new failure detector class, denoted , and shows  (the weakest class for k\u00a0\u2026", "num_citations": "21\n", "authors": ["495"]}
{"title": "From\u22c4 W to \u03a9: A simple bounded quiescent reliable broadcast-based transformation\n", "abstract": " Failure detectors in the class\u22c4 W ensure that every crashed process is eventually suspected by a correct process, and eventually there is a correct process that is never suspected. Failure detectors in the class \u03a9 ensure that eventually all the processes trust the same correct process. This paper presents a very simple and efficient algorithm that transforms any failure detector of the class\u22c4 W into a failure detector of the class \u03a9. The simplicity of the transformation is due to its modular design\u2014it is based on an underlying reliable broadcast facility. It is quiescent and requires each message to carry only one process identity, in addition to the control information appended to a message by the reliable broadcast mechanism (namely, a sequence number and the identity of its sender).", "num_citations": "21\n", "authors": ["495"]}
{"title": "Mastering agreement problems in distributed systems\n", "abstract": " Distributed systems are difficult to design and implement because of the unpredictability of message transfer delays and process speeds (asynchrony) and of failures. Consequently, systems designers have to compete with these difficulties intrinsically associated with distributed systems.", "num_citations": "21\n", "authors": ["495"]}
{"title": "Towards the construction of distributed detection programs, with an application to distributed termination\n", "abstract": " Methodological design of distributed programs is necessary if one is to master the complexity of parallelism. The class of control programs, whose purpose is to observe or detect properties of an underlying program, plays an important role in distributed computing. The detection of a property generally rests upon consistent evaluations of a predicate; such a predicate can be global, i.e. involve states of several processes and channels of the observed program. Unfortunately, in a distributed system, the consistency of an evaluation cannot be trivially obtained. This is a central problem in distributed evaluations. This paper addresses the problem of distributed evaluation, used as a basic tool for solution of general distributed detection problems. A new evaluation paradigm is put forward, and a general distributed detection program is designed, introducing the iterative scheme ofguarded waves sequence. The\u00a0\u2026", "num_citations": "21\n", "authors": ["495"]}
{"title": "On the road to the weakest failure detector for k-set agreement in message-passing systems\n", "abstract": " In the k-set agreement problem, each process (in a set of n processes) proposes a value and has to decide a proposed value in such a way that at most k different values are decided. While this problem can easily be solved in asynchronous systems prone to t process crashes when k> t, it cannot be solved when k\u2264 t. For several years, the failure-detector-based approach has been investigated to circumvent this impossibility. While the weakest failure detector class to solve the k-set agreement problem in read/write shared memory systems has recently been discovered (PODC 2009), the situation is different in message-passing systems where the weakest failure detector classes are known only for the extreme cases k= 1 (consensus) and k= n\u2212 1 (set agreement). This paper presents four contributions whose aim is to help pave the way to discover the weakest failure detector class for k-set agreement in message\u00a0\u2026", "num_citations": "20\n", "authors": ["495"]}
{"title": "Signature-free broadcast-based intrusion tolerance: never decide a Byzantine value\n", "abstract": " Providing application processes with strong agreement guarantees despite failures is a fundamental problem of fault-tolerant distributed computing. Correct processes have not to be \u201cpolluted\u201d by the erroneous behavior of faulty processes. This paper considers the consensus agreement problem in a setting where some processes can behave arbitrarily (Byzantine behavior). In such a context it is possible that Byzantine processes collude to direct the correct processes to decide on a \u201cbad\u201d value (a value proposed only by faulty processes).               The paper has several contributions. It presents a family of consensus algorithms in which no bad value is ever decided by correct processes. These processes always decide a value they have proposed (and this is always the case when they all propose the same value) or a default value . These algorithms are called intrusion-free consensus algorithms. To that\u00a0\u2026", "num_citations": "20\n", "authors": ["495"]}
{"title": "D2HT: the best of both worlds, Integrating RPS and DHT\n", "abstract": " Distributed Hash Tables (DHTs) and Random Peer Sampling (RPS) provide important and complementary services in the area of P2P overlay networks. DHTs achieve efficient lookup while RPS enables nodes to build and maintain connectivity in the presence of high churn. Clearly, many applications, e.g. in the area of search, would greatly benefit if both these services were available together at a reasonable cost. This paper integrates a structured P2P overlay and a Random Peer Sampling service through gossip protocols. This system called D2HT, leverages the small-world nature of DHTs and relies on two cohabiting gossip protocols maintaining the close and long-range links respectively. The long links are chosen according to a harmonic distribution, following the Kleinberg small-world model. This approach exhibits several benefits: (i) The resulting DHT is highly dynamic and self-stabilizing, changes are\u00a0\u2026", "num_citations": "20\n", "authors": ["495"]}
{"title": "A simple proof of the necessity of the failure detector \u03a3 to implement an atomic register in asynchronous message-passing systems\n", "abstract": " This paper presents a simple proof that shows that the quorum failure detector class (denoted \u03a3) is the weakest failure detector class required to implement an atomic read/write register in an asynchronous message-passing system prone to an arbitrary number of process crashes. This proof is based on a new reduction algorithm in which all the variables are bounded.", "num_citations": "20\n", "authors": ["495"]}
{"title": "From an asynchronous intermittent rotating star to an eventual leader\n", "abstract": " Considering an asynchronous system made up of n processes and where up to t of them can crash, finding the weakest assumption that such a system has to satisfy for a common leader to be eventually elected is one of the holy grail quests of fault-tolerant asynchronous computing. This paper is a step in that direction. It has two contributions. Considering a simple and general asynchronous system model where processes generate asynchronous pulses during which they send and receive messages, it first introduces an additional assumption that allows to elect an eventual leader in all the runs that satisfy that assumption. That assumption is captured by the notion of asynchronous intermittent rotating t-star. An x-star is made up of one process p (the center of the star) plus a sequence of sets of x processes (the successive points of the star), which satisfies some properties. Intuitively, the intermittent rotating t-star\u00a0\u2026", "num_citations": "20\n", "authors": ["495"]}
{"title": "An impossibility about failure detectors in the iterated immediate snapshot model\n", "abstract": " The Iterated Immediate Snapshot model (IIS) is an asynchronous computation model where processes communicate through a sequence of one-shot Immediate Snapshot (IS) objects. It is known that this model is equivalent to the usual asynchronous read/write shared memory model, for wait-free task solvability. Its interest lies in the fact that its runs are more structured and easier to analyze than the runs in the shared memory model. As the IIS model and the shared memory model are equivalent for wait-free task solvability, a natural question is the following: Are they still equivalent for wait-free task solvability, when they are enriched with the same failure detector? The paper shows that the answer to this question is \u201cno\u201d.", "num_citations": "20\n", "authors": ["495"]}
{"title": "From an intermittent rotating star to a leader\n", "abstract": " Considering an asynchronous system made up of n processes and where up to t of them can crash, finding the weakest assumptions that such a system has to satisfy for a common leader to be eventually elected is one of the holy grail quests of fault-tolerant asynchronous computing. This paper is a step in such a quest. It has two main contributions. First, it proposes an asynchronous system model, in which an eventual leader can be elected, that is weaker and more general than previous models. This model is captured by the notion of intermittent rotating t                      -star. An x-star is a set of x\u2009+\u20091 processes: a process p (the center of the star) plus a set of x processes (the points of the star). Intuitively, assuming logical times rn (round numbers), the intermittent rotating t                      -star assumption means that there are a process p, a subset of the round numbers rn, and associated sets Q(rn) such that each\u00a0\u2026", "num_citations": "20\n", "authors": ["495"]}
{"title": "Simultaneous consensus tasks: A tighter characterization of set-consensus\n", "abstract": " We address the problem of solving a task T=(T                         1,...T                                            m                 ) (called (m,1)-BG), in which a processor returns in an arbitrary one of m simultaneous consensus subtasks T                         1,...T                                            m                 . Processor p                                            i                  submits to T an input vector of proposals (prop                                                     i,1,...,prop                                                     i,m                         ), one entry per subtask, and outputs, from just one subtask \u2113, a pair (\u2113,\u00a0prop                                                     j,l                         ) for some j. All processors that output at \u2113 output the same proposal.               Let d be a bound on the number of distinct input vectors that may be submitted to T. For example, d=3 if Democrats always vote Democrats across the board, and similarly for Republicans and Libertarians. A wait-free algorithm that immaterial of the number of processors\u00a0\u2026", "num_citations": "20\n", "authors": ["495"]}
{"title": "Synchronous condition-based consensus\n", "abstract": " The condition-based approach studies restrictions on the inputs to a distributed problem, called conditions, that facilitate its solution. Previous work considered mostly the asynchronous model of computation. This paper studies conditions for consensus in a synchronous system where processes can fail by crashing. It describes a full classification of conditions for consensus, establishing a continuum between the asynchronous and synchronous models, with the following hierarchy $${\\cal S}_t^{[-t]}\\subset\\cdots\\subset {\\cal S}_t^{[0]}\\subset\\cdots\\subset {\\cal S}_t^{[t]}$$ where $${\\cal S}_t^{[t]}$$ includes all conditions (and in particular the trivial one made up of all possible input vectors). For a condition $$C \\in{\\cal S}_t^{[d]}$, $-t \\leq d \\leq t$$, we have:                                         For values of $$d \\leq 0$$ consensus is solvable in an asynchronous system with t failures, and we obtain the known hierarchy of\u00a0\u2026", "num_citations": "20\n", "authors": ["495"]}
{"title": "Shared state consistency for time-sensitive distributed applications\n", "abstract": " Distributed applications that share a dynamically changing state are increasingly being deployed in wide-area environments. Such applications must access the state in a consistent manner, but the consistency requirements vary significantly from other systems. For example, shared memory models, such as sequential consistency, focus on the ordering of operations, and the same level of consistency is provided to each process. In interactive distributed applications, the timeliness of updates becoming effective could be an extremely important consistency requirement, and it could be different across different users. We propose a system that provides both non-timed and time-sensitive read and write operations for dynamic shared state. For example, a timed read can be used by a process to read a recently written value, whereas a timed write can make a new value available to all readers within a certain amount of\u00a0\u2026", "num_citations": "20\n", "authors": ["495"]}
{"title": "Lifetime based consistency protocols for distributed objects\n", "abstract": " Techniques such as replication and caching of objects that implement distributed services lead to consistency problems that must be addressed. We explore new consistency protocols based on the notion of object value lifetimes. By keeping track of the lifetimes of the values stored in shared objects (i.e., the time interval that goes from the writing of a value until the latest time when this value is known to be valid), it is possible to check the mutual consistency of a set of related objects cached at a site. Initially, this technique is presented assuming the presence of physical clocks. Later, these clocks are replaced by vector clocks and then by plausible clocks. Lifetimes based on such clocks result in weaker consistency but do provide more efficient implementations.", "num_citations": "20\n", "authors": ["495"]}
{"title": "Debugging tool for distributed Estelle programs\n", "abstract": " This paper discusses design and implementation issues for a distributed debugger, called EREBUS, which fits in a programming environment for distributed programs written in Estelle, an ISO-normalized language. Problems pertaining to execution replays of distributed programs are discussed in detail, and performance of the prototype debugger is exhibited.", "num_citations": "20\n", "authors": ["495"]}
{"title": "A general method to define quorums\n", "abstract": " Composition, a general method for constructing quorum sets, coteries, and bicoteries, is discussed. It is shown that composition provides a natural method for constructing quorum structures in an arbitrary network or even in a collection of interconnected networks, and that the resulting structures, called composite structures, can be efficiently evaluated. In particular, an efficient method for determining if a given set contains a quorum of a composite structure is presented. If this method is used, it is not necessary to compute and store all of the quorums of the composite structure in advance.<>", "num_citations": "20\n", "authors": ["495"]}
{"title": "Structured specification of communicating systems\n", "abstract": " Specification methods for distributed systems is the underlying theme of this paper. A model of communicating processes with rendezvous interactions is assumed as a basis for the discussion. The possible interactions by a process, and the interconnection between several subprocesses within a process are specified using the concept of ports, which are specified separately. Step-wise refinement of process specifications and associated verification rules are considered. The step-wise refinement of port specifications and associated interactions is considered as well. After the presentation of an introductory example, the paper discusses the basic concepts of the specification method. They are then applied to more complex examples. The step-wise wefinement of ports and interactions is demonstrated by a hardware interface for which an abstract specification and a more detailed implementation is given. Proof rules\u00a0\u2026", "num_citations": "20\n", "authors": ["495"]}
{"title": "Unifying concurrent objects and distributed tasks: Interval-linearizability\n", "abstract": " Tasks and objects are two predominant ways of specifying distributed problems where processes should compute outputs based on their inputs. Roughly speaking, a task specifies, for each set of processes and each possible assignment of input values, their valid outputs. In contrast, an object is defined by a sequential specification. Also, an object can be invoked multiple times by each process, while a task is a one-shot problem. Each one requires its own implementation notion, stating when an execution satisfies the specification. For objects, linearizability is commonly used, while tasks implementation notions are less explored. The article introduces the notion of interval-sequential object, and the corresponding implementation notion of interval-linearizability, to encompass many problems that have no sequential specification as objects. It is shown that interval-sequential specifications are local, namely, one can\u00a0\u2026", "num_citations": "19\n", "authors": ["495"]}
{"title": "A simple broadcast algorithm for recurrent dynamic systems\n", "abstract": " This paper presents a simple broadcast algorithm suited to dynamic systems where links can repeatedly appear and disappear. The algorithm is proved correct and a simple improvement is introduced, that reduces the number and the size of control messages. As it extends in a simple way a classical network traversal algorithm to the dynamic context, the proposed algorithm has also pedagogical flavor.", "num_citations": "19\n", "authors": ["495"]}
{"title": "Renaming is weaker than set agreement but for perfect renaming: A map of sub-consensus tasks\n", "abstract": " In the wait-free shared memory model substantial attention has been devoted to understanding the relative power of sub-consensus tasks. Two important sub-consensus families of tasks have been identified: k-set agreement and M-renaming. When 2\u2009\u2264\u2009k\u2009\u2264\u2009n\u2009\u2212\u20091 and n\u2009\u2264\u2009M\u2009\u2264\u20092n\u2009\u2212\u20092, these tasks are more powerful than read/write registers, but not strong enough to solve consensus for two processes.             This paper studies the power of renaming with respect to set agreement. It shows that, in a system of n processes, n-renaming is strictly stronger than (n\u2009\u2212\u20091)-set agreement, but not stronger than (n\u2009\u2212\u20092)-set agreement. Furthermore, (n\u2009+\u20091)-renaming cannot solve even (n\u2009\u2212\u20091)-set agreement. As a consequence, there are cases where set agreement and renaming are incomparable when looking at their power to implement each other.", "num_citations": "19\n", "authors": ["495"]}
{"title": "Regular register: an implementation in a churn prone environment\n", "abstract": " Due to their capability to hide the complexity generated by the messages exchanged between processes, shared objects are one of the main abstractions provided to the developers of distributed applications. Among all the shared objects, the register object is fundamental. Several protocols have been proposed to build fault resilient registers on top of message-passing system, but, unfortunately, failure are not the only challenge in modern distributed systems. New issues arise from the dynamicity introduced in the system by the continuous arrival and departure of nodes (churn phenomenon). This paper addresses the construction of a single writer/multiple readers regular register in a distributed system affected by the continuous arrival/departure of participants. In particular, a general protocol implementing a regular register is proposed and feasibility conditions on the arrival and departure of the processes\u00a0\u2026", "num_citations": "19\n", "authors": ["495"]}
{"title": "A dual-token-based fault tolerant mutual exclusion algorithm for manets\n", "abstract": " Most existing mutual exclusion algorithms for mobile ad hoc networks (MANETs) adopt a token-based approach. In traditional wired networks, timeout-based mechanisms are commonly used to detect token losses. However, in MANETs, it is difficult to set a proper timeout value due to the network dynamics. In this paper, we propose a dual-token-based mutual exclusion algorithm, which can tolerate token losses without using timeout. Two tokens are concurrently circulated in the system to monitor each other by using sequence numbers. If one token is lost, the other token can detect the loss and regenerate a new token. Simulations have been carried out to evaluate the effectiveness and performance of the proposed algorithm in comparison with the timeout-based approach. The results show that the timeout-based algorithm may falsely claim the loss of a token, thus cannot guarantee the correctness of\u00a0\u2026", "num_citations": "19\n", "authors": ["495"]}
{"title": "A distributed implementation of sequential consistency with multi-object operations\n", "abstract": " Sequential consistency is a consistency criterion for concurrent objects stating that the execution of a multiprocess program is correct if it could have been produced by executing the program on a mono-processor system, preserving the order of the operations of each individual process. Several protocols implementing sequential consistency on top of asynchronous distributed systems have been proposed. They assume that the processes access the shared objects through basic read and write operations. We consider the case where the processes can invoke multiobject operations which can read or write several objects in a single operation atomically. It proposes a particularly simple protocol that guarantees sequentially consistent executions in such a context. The previous sequential consistency protocols, in addition to considering only unary operations, assume either full replication or a central manager\u00a0\u2026", "num_citations": "19\n", "authors": ["495"]}
{"title": "A generic framework for indulgent consensus\n", "abstract": " Consensus is a fundamental distributed agreement problem that has to be solved when one has to design or implement reliable applications. As consensus cannot be solved in pure asynchronous distributed systems, those systems have to be equipped with appropriate oracles to circumvent the impossibility. Several oracles (unreliable failure detector leader capability, random number generator) have been proposed, and consensus protocols based on such ad hoc oracles have been designed This paper presents a generic consensus framework that can be instantiated with any oracle, or combination of oracles, that satisfies a set of properties. This generic framework provides indulgent consensus protocols that are particularly simple and efficient both in well-behaved runs (i.e., when there are no failures), and in stable runs (i.e., when there is no failure during the execution although some processes can be initially\u00a0\u2026", "num_citations": "19\n", "authors": ["495"]}
{"title": "Consistent records in asynchronous computations\n", "abstract": " A global record (i.e. a set of local records, one for each process of an asynchronous computation) abstracts what is usually called global state, global checkpoint or global snapshot in particular problems. Consistent global records are important in many applications. This paper addresses the following question: \u201cGiven a set of local records, is it possible that these records belong to the same consistent global record?\u201d. This question has been answered by Netzer and Xu in the particular context of message passing systems. This paper extends their result to a very general asynchronous computational model that encompasses shared memory systems and various message passing systems (with reliable or unreliable and point-to-point or multicast or broadcast communications).", "num_citations": "19\n", "authors": ["495"]}
{"title": "Broadcast with time and causality constraints for multimedia applications\n", "abstract": " /spl Delta/-causal ordering is a communication abstraction designed for distributed applications whose messages (i) have to be delivered according to causal ordering and (ii) have a limited lifetime after which their data can no longer be used by the application. Example of such applications are: multimedia real-time collaborative applications and groupware real-time applications. For such applications, the broadcasting of information is of primary importance. In this paper we propose a simple and efficient /spl Delta/-causal ordering protocol in the context of broadcast communication. By taking into account transitive dependencies on message sends, this algorithm gets a significant reduction in the control information piggybacked on application messages, compared to previous algorithms.", "num_citations": "19\n", "authors": ["495"]}
{"title": "Expressing and detecting control flow properties of distributed computations\n", "abstract": " Properties of distributed computations can be either on their global states or on their control flows. This paper addresses control flow properties. It first presents a simple yet powerful logic for expressing general properties on control flows, seen as sequences of local states. Among other properties, we can express invariance, sequential properties (20 satisfy such a property a control flow must match a pattern described as a word on some alphabet) and non-sequential properties (these properties are on several control flows at the same time). A decentralized detection algorithm for properties described by this logic is then presented. This algorithm, surprisingly simple despite the power of the logic, observes the underlying distributed computation, does not alter its control flows and uses message tags to carry detection-related information.", "num_citations": "19\n", "authors": ["495"]}
{"title": "Stabilizing server-based storage in Byzantine asynchronous message-passing systems\n", "abstract": " A stabilizing Byzantine single-writer single-reader (SWSR) regular register, which stabilizes after the first invoked write operation, is first presented. Then, new/old ordering inversions are eliminated by the use of a (bounded) sequence number for writes, obtaining a practically stabilizing SWSR atomic register. A practically stabilizing Byzantine single-writer multi-reader (SWMR) atomic register is then obtained by using several copies of SWSR atomic registers. Finally, bounded time-stamps, with a time-stamp per writer, together with SWMR atomic registers, are used to construct a practically stabilizing Byzantine multi-writer multi-reader (MWMR) atomic register. In a system of n servers implementing an atomic register, and in addition to transient failures, the constructions tolerate t< n/8 Byzantine servers if communication is asynchronous, and t< n/3 Byzantine servers if it is synchronous. The noteworthy feature of the\u00a0\u2026", "num_citations": "18\n", "authors": ["495"]}
{"title": "A timing assumption and two t-resilient protocols for implementing an eventual leader service in asynchronous shared memory systems\n", "abstract": " This paper considers the problem of electing an eventual leader in an asynchronous shared memory system. While this problem has received a lot of attention in message-passing systems, very few solutions have been proposed for shared memory systems. As an eventual leader cannot be elected in a pure asynchronous system prone to process crashes, the paper first proposes to enrich the asynchronous system model with an additional assumption. That assumption (denoted AWB) is particularly weak. It is made up of two complementary parts. More precisely, it requires that, after some time, (1) there is a process whose write accesses to some shared variables be timely, and (2) the timers of (t\u2212f) other processes be asymptotically well-behaved (t denotes the maximal number of processes that may crash, and f the actual number of process crashes in a run). The asymptotically well-behaved timer notion is\u00a0\u2026", "num_citations": "18\n", "authors": ["495"]}
{"title": "Mobile Ad-hoc and sensor networks\n", "abstract": " The principal theme of MSN conferences is the development and deployment of protocols, algorithms, systems, and applications for mobile ad-hoc and wireless sensor networks.Following the success of MSN 2005 and MSN 2006, MSN 2007 provided a forum for researchers and practitioners working in related areas to exchange research results and share development experiences. MSN 2007 attracted 304 submissions. Each paper was reviewed by at least three members of the Program Committee (PC) and reviewers. The final program included 75 papers, which covered a range of different topics, including routing, network protocols, energy management, security, etc. The Organizing Committee would like to thank the Steering Committee members Xiaohua Jia, Sajal K. Das, Ivan Stojmenovic, and Jie Wu for their support and guidance in the conference organization. We would like to take this opportunity to thank\u00a0\u2026", "num_citations": "18\n", "authors": ["495"]}
{"title": "Characterizing and detecting the set of global states seen by all observers of a distributed computation\n", "abstract": " A consistent observation of a given distributed computation is a sequence of global states that could be produced by executing that computation on a monoprocessor system. Therefore a distributed execution generally accepts several consistent observations. This paper concentrates on what all these observations have in common. An abstraction called common global state is defined. A necessary and sufficient condition characterizing such states is given. A monitor-based algorithm that detects them is also presented and proved correct. Previous works on detection of unstable properties of distributed computations are revisited and explained with this abstraction. Moreover other uses of such particular states are sketched.", "num_citations": "18\n", "authors": ["495"]}
{"title": "An introduction to the analysis and debug of distributed computations\n", "abstract": " Distributed programs are much more difficult to design, understand and implement than sequential or parallel ones. This is mainly due to the uncertainty created by the asynchrony inherent to distributed machines. So appropriate concepts and tools have to be devised to help the programmer of distributed applications in his task. This paper is motivated by the practical problem called distributed debugging. It presents concepts and tools that help the programmer to analyze distributed executions. Two basic problems are addressed: replay of a distributed execution (how to reproduce an equivalent execution despite of asynchrony) and the detection of a stable or unstable property of a distributed execution. Concepts and tools presented are fundamental when designing an environment for distributed program development. This paper is essentially a survey presenting a state of the art in replay mechanisms and\u00a0\u2026", "num_citations": "18\n", "authors": ["495"]}
{"title": "Read invisibility, virtual world consistency and probabilistic permissiveness are compatible\n", "abstract": " The aim of a Software Transactional Memory (STM) is to discharge the programmers from the management of synchronization in multiprocess programs that access concurrent objects. To that end, an STM system provides the programmer with the concept of a transaction. The job of the programmer is to design each process the application is made up of as a sequence of transactions. A transaction is a piece of code that accesses concurrent objects, but contains no explicit synchronization statement. It is the job of the underlying STM system to provide the illusion that each transaction appears as being executed atomically. Of course, for efficiency, an STM system has to allow transactions to execute concurrently. Consequently, due to the underlying STM concurrency management, a transaction commits or aborts.               This paper studies the relation between two STM properties (read invisibility and\u00a0\u2026", "num_citations": "17\n", "authors": ["495"]}
{"title": "Help when needed, but no more: Efficient read/write partial snapshot\n", "abstract": " An atomic snapshot object is an object that can be concurrently accessed by asynchronous processes prone to crash. It is made of m components (base atomic registers) and is defined by two operations: an update operation that allows a process to atomically assign a new value to a component and a snapshot operation that atomically reads and returns the values of all the components. To cope with the net effect of concurrency, asynchrony and failures, the algorithm implementing the update operation has to help concurrent snapshot operations so that they always terminate.               This paper is on partial snapshot objects. Such an object provides a snapshot operation that can take any subset of the components as input parameter, and atomically reads and returns the values of this subset of components. The paper has two contributions. The first is the introduction of two properties for partial snapshot\u00a0\u2026", "num_citations": "17\n", "authors": ["495"]}
{"title": "A versatile STM protocol with invisible read operations that satisfies the virtual world consistency condition\n", "abstract": " The aim of a Software Transactional Memory (STM) is to discharge the programmers from the management of synchronization in multiprocess programs that access concurrent objects. To that end, a STM system provides the programmer with the concept of a transaction. The job of the programmer is to design each process the application is made up of as a sequence of transactions. A transaction is a piece of code that accesses concurrent objects, but contains no explicit synchronization statement. It is the job of the underlying STM system to provide the illusion that each transaction appears as being executed atomically. Of course, for efficiency, a STM system has to allow transactions to execute concurrently. Consequently, due to the underlying STM concurrency management, a transaction commits or aborts.               This paper first presents a new STM consistency condition, called virtual world consistency\u00a0\u2026", "num_citations": "17\n", "authors": ["495"]}
{"title": "On the consistency conditions of transactional memories\n", "abstract": " The aim of a Software Transactional Memory (STM) is to discharge the programmers from the management of synchronization in multiprocess programs that access concurrent objects. To that end, a STM system provides the programmer with the concept of a transaction: each sequential process is decomposed into transactions, where a transaction encapsulates a piece of sequential code accessing concurrent objects. A transaction contains no explicit synchronization statement and appears as if it has been executed atomically. Due to the underlying concurrency management, a transaction commits or aborts. Up to now, few papers focused on the definition of consistency conditions suited to STM systems. One of them has recently proposed the opacity consistency condition. Opacity involves all the transactions (i.e., the committed plus the aborted transactions). It requires that (1) until it aborts (if ever it does) a transaction sees a consistent global state of the concurrent objects, and (2) the execution is linearizable (i.e., it could have been produced by a sequential execution -of the same transactions- that respects the real time order on the non-concurrent transactions). This paper is on consistency conditions for transactional memories. It first presents a framework that allows defining a space of consistency conditions whose extreme endpoints are serializability and opacity. It then extracts from this framework a new consistency condition that we call virtual world consistency. This condition ensures that (1) each transaction (committed or aborted) reads values from a consistent global state, (2) the consistent global states read by committed transactions\u00a0\u2026", "num_citations": "17\n", "authors": ["495"]}
{"title": "The combined power of conditions and failure detectors to solve asynchronous set agreement\n", "abstract": " An approach to cope with the impossibility of solving agreement problems in asynchronous systems made up of n processes and prone to t process crashes is to use failure detectors. An orthogonal approach that has been used is to consider conditions that restrict the possible inputs to such a problem. This paper considers a system with both failure detectors and conditions. The aim is to identify the failure detector class that abstracts away the synchrony needed to solve k-set agreement for a given condition. Three main contributions are presented. The first is a new class of failure detectors denoted \u03a6 t y, 0\u2264 y\u2264 t. The processes can invoke a primitive query y (S) with a set of process ids S. Roughly speaking, query y (S) returns true only when all processes in S have crashed, provided ty<| S|\u2264 t. It is shown that the classic Chandra and Toueg's failure detectors are incomparable to the \u03a6 t y failure detectors. The\u00a0\u2026", "num_citations": "17\n", "authors": ["495"]}
{"title": "Efficient condition-based consensus\n", "abstract": " Efficient Condition-Based Consensus Page 1 Efficient Condition-Based Consensus in Asynchronous Distributed Systems Achour Mostefaoui, Sergio Rajsbaum Michel Raynal and Matthieu Roy mroy@irisa.fr Efficient Condition-Based Consensus \u2013 p.1/25 Page 2 Summary Computation model and the Consensus Problem The Condition-Based approach Definitions, A simple protocol. Efficient protocol for consensus A hierarchy of conditions, A tailored read/write primitive, A generic formula for defining conditions. Efficient Condition-Based Consensus \u2013 p.2/25 Page 3 Computation Model An a priori known set of processes \u00a1\u00a3 \u00a2\u00a5 \u00a4 \u00a1\u00a3 \u00a6\u00a5 \u00a4 \u00a7 \u00a7 \u00a7 \u00a4 \u00a1\u00a9 , Communication via Shared Memory (supposed to be reliable) Asynchronous Model of failures: Fail-stop. At most processes may crash, A correct process is a process that does not crash. Efficient Condition-Based Consensus \u2013 p.3/25 Page 4 The Consensus Problem : : Every -\u2026", "num_citations": "17\n", "authors": ["495"]}
{"title": "Trading off t-Resilience for Efficiency in Asynchronous Byzantine Reliable Broadcast\n", "abstract": " This paper presents a simple and efficient reliable broadcast algorithm for asynchronous message-passing systems made up of n processes, among which up to  may behave arbitrarily (Byzantine processes). This algorithm requires two communication steps and  messages. When compared to Bracha\u2019s algorithm, which is resilience optimal () and requires three communication steps and  messages, the proposed algorithm shows an interesting tradeoff between communication efficiency and t-resilience.", "num_citations": "16\n", "authors": ["495"]}
{"title": "Increasing the power of the iterated immediate snapshot model with failure detectors\n", "abstract": " The base distributed asynchronous read/write computation model is made up of n asynchronous processes which communicate by reading and writing atomic registers only. The distributed asynchronous iterated model is a more constrained model in which the processes execute an infinite number of rounds and communicate at each round with a new object called immediate snapshot object. Moreover, in both models up to n\u2009\u2212\u20091 processes may crash in an unexpected way. When considering computability issues, two main results are associated with the previous models. The first states that they are computationally equivalent for decision tasks. The second states that they are no longer equivalent when both are enriched with the same failure detector.             This paper shows how to capture failure detectors in each model so that both models become computationally equivalent. To that end it introduces\u00a0\u2026", "num_citations": "16\n", "authors": ["495"]}
{"title": "Electing an eventual leader in an asynchronous shared memory system\n", "abstract": " This paper considers the problem of electing an eventual leader in an asynchronous shared memory system. While this problem has received a lot of attention in message- passing systems, very few solutions have been proposed for shared memory systems. As an eventual leader cannot be elected in a pure asynchronous system prone to process crashes, the paper first proposes to enrich the asynchronous system model with an additional assumption. That assumption, denoted AWB, requires that after some time (1) there is a process whose write accesses to some shared variables are timely, and (2) the timers of the other processes are asymptotically well-behaved. The asymptotically well-behaved timer notion is a new notion that generalizes and weakens the traditional notion of timers whose durations are required to monotonically increase when the values they are set to increase. Then, the paper presents two\u00a0\u2026", "num_citations": "16\n", "authors": ["495"]}
{"title": "Synchronous set agreement: a concise guided tour (including a new algorithm and a list of open problems)\n", "abstract": " The k-set agreement problem is a paradigm of coordination problems encountered in distributed computing. The parameter k defines the coordination degree we are interested in. (The case k=1 corresponds to the well-known uniform consensus problem.) More precisely, the k-set agreement problem considers a system made up of n processes where each process proposes a value. It requires that each non-faulty process decides a value such that a decided value is a proposed value, and no more than k different values are decided. This paper visits the k-set agreement problem in synchronous systems where up to t processes can experience failures. Three failure models are explored: the crash failure model, the send omission failure model, and the general omission failure model. Lower bounds and protocols are presented for each model. Open problems for the general omission failure model are stated. This\u00a0\u2026", "num_citations": "16\n", "authors": ["495"]}
{"title": "Irreducibility and additivity of set agreement-oriented failure detector classes\n", "abstract": " Solving agreement problems (such as consensus and k-set agreement) in asynchronous distributed systems prone to process failures has been shown to be impossible. To circumvent this impossibility, distributed oracles (also called unreliable failure detectors) have been introduced. A failure detector provides information on failures, and a failure detector class is defined by a set of abstract properties that encapsulate (and hide) synchrony assumptions. Some failure detector classes have been shown to be the weakest to solve some agreement problems (eg, \u03a9 is the weakest class of failure detectors that allow solving the consensus problem in asynchronous systems where a majority of processes do not crash). This paper considers several failure detector classes and focuses on their additivity or their irreducibility. It mainly investigates two families of failure detector classes (denoted\u25ca S x and\u25ca \u03c6 y, 0\u2264 x, y\u2264 n\u00a0\u2026", "num_citations": "16\n", "authors": ["495"]}
{"title": "Efficient causality-tracking timestamping\n", "abstract": " Vector clocks are the appropriate mechanism used to track causality among the events produced by a distributed computation. Traditional implementations of vector clocks require application messages to piggyback a vector of n integers (where n is the number of processes). This paper investigates the tracking of the causality relation on a subset of events (namely, the events that are defined as \"relevant\" from the application point of view) in a context where communication channels are not required to be FIFO, and where there is no a priori information on the connectivity of the communication graph or the communication pattern. More specifically, the paper proposes a suite of simple and efficient implementations of vector clocks that address the reduction of the size of message timestamps, i.e., they do their best to have message timestamps whose size is less than n. The relevance of such a suite of protocols is\u00a0\u2026", "num_citations": "16\n", "authors": ["495"]}
{"title": "Revisiting simultaneous consensus with crash failures\n", "abstract": " This paper addresses the \u201cconsensus with simultaneous decision\u201d problem in a synchronous system prone to t process crashes. This problem requires that all the processes that do not crash decide on the same value (consensus), and that all decisions are made during the very same round (simultaneity). So, there is a double agreement, one on the decided value (data agreement) and one on the decision round (time agreement). This problem was first defined by Dwork and Moses who analyzed it and solved it using an analysis of the evolution of states of knowledge in a system with crash failures. The current paper presents a simple algorithm that optimally solves simultaneous consensus. Optimality means in this case that the simultaneous decision is taken in each and every run as soon as any protocol decides, given the same failure pattern and initial value. The design principle of this algorithm is simplicity, a\u00a0\u2026", "num_citations": "15\n", "authors": ["495"]}
{"title": "The committee decision problem\n", "abstract": " We introduce the (b,n)-Committee Decision Problem (CD) \u2013 a generalization of the consensus problem. While set agreement generalizes consensus in terms of the number of decisions allowed, the CD problem generalizes consensus in the sense of considering many instances of consensus and requiring a processor to decide in at least one instance. In more detail, in the CD problem each one of a set of n processes has a (possibly distinct) value to propose to each one of a set of b consensus problems, which we call committees. Yet a process has to decide a value for at least one of these committees, such that all processes deciding for the same committee decide the same value. We study the CD problem in the context of a wait-free distributed system and analyze it using a combination of distributed algorithmic and topological techniques, introducing a novel reduction technique.               We use the\u00a0\u2026", "num_citations": "15\n", "authors": ["495"]}
{"title": "Software replication in three-tiers architectures: is it a real challange?\n", "abstract": " This paper is a first attempt to study the problem of handling software replication in three tiers architectures. In particular a study based on synchronization and communication patterns imposed by replication is presented. We show how the complexity of the replication scheme is affected by the deterministic (or not) behavior of the members of the backtier We also give two generic synchronization and communication patterns used in two and three tiers replication. Well-known schemes such us active and passive replication are particular instances of these generic patterns.", "num_citations": "15\n", "authors": ["495"]}
{"title": "Direct dependency-based determination of consistent global checkpoints\n", "abstract": " Building consistent global checkpoints that contain a given set of local checkpoints has been usually handled by using transitive dependency tracking. This imply the usage of a vector of integers piggybacked on each message of the computation (the vector size being given by the number of processes). In this paper we address the problem to get consistent global checkpoints including a given subset of local checkpoints tracking just direct dependencies. In that case application messages are required to piggyback one integer. An algorithm is proposed that takes a set of local checkpoints as an input and returns the minimum consistent global checkpoint, if any, including that set. Otherwise it returns the first consistent global checkpoint that follows this subset. Among the applications of the algorithm there are rollback-recovery and global predicate detection. Index Terms: Asynchronous Systems, Checkpoint Consistency, Communication-Induced Checkpointing, Direct Dependency, Predicate Det...", "num_citations": "15\n", "authors": ["495"]}
{"title": "Non-blocking atomic commitment in distributed systems: A tutorial based on a generic protocol\n", "abstract": " Agreement problems allow a set of processes to agree on a common output value. These problems are of primary importance in distributed systems and difficult to solve in presence of failures. This paper is a tutorial on one of these problems whose practical interest is well known, namely the Non-Blocking Atomic Commitment Problem. This tutorial is based on an original generic protocol that solves the problem at an abstract level. Instantiations of generic statements are given for both synchronous and asynchronous distributed systems. It is shown that the main problem to ensure the 'non-blocking' property lies in failures detection. While failures can be safely detected in synchronous distributed systems, they can only be 'suspected' (maybe falsely) in asynchronous distributed systems. So, this tutorial also visits problems such as reliable communication, failures detection and consensus whose solution are used\u00a0\u2026", "num_citations": "15\n", "authors": ["495"]}
{"title": "Time in distributed system models and algorithms\n", "abstract": " This chapter gives an account of recent advances with regard to both the analysis and the use of time in distributed systems models and algorithms. We discuss timed models for distributed systems, timing failures and their detection, clock synchronisation and time services for large-scale settings, real-time causal delivery and temporal order, and protocols that in one way or the other take advantage from time.", "num_citations": "15\n", "authors": ["495"]}
{"title": "An adaptive architecture for causally consistent distributed services\n", "abstract": " This paper explores causally consistent distributed services when multiple related services are replicated to meet performance and availability requirements. This consistency criterion is particularly well suited for distributed services such as cooperative document sharing, and it is attractive because of the efficient implementations that are allowed by it. A new protocol for implementing causally consistent services is presented. It allows service instances to be created and deleted dynamically according to service access patterns in the distributed system. It also handles the case where different but related services are replicated independently. Another novel aspect of this protocol lies in its ability to use both push and pull mechanisms for disseminating updates to objects that encapsulate service state.", "num_citations": "15\n", "authors": ["495"]}
{"title": "Probabilistic analysis of a group failure detection protocol\n", "abstract": " A group membership failure (in short, a group failure) occurs when one of the group members crashes. A group failure detection protocol has to inform all the non-crashed members of the group that this group entity has crashed. Ideally, such a protocol should be live (if a process crashes, then the group failure has to be detected) and safe (if a group failure is claimed, then at least one process has crashed). Unreliable asynchronous distributed systems are characterized by the impossibility for a process to get an accurate view of the system state. Consequently, the design of a group failure detection protocol that is both safe and live is a problem that cannot be solved in all runs of an asynchronous distributed system. We analyse a group failure detection protocol whose design naturally ensures its liveness. We show that by tuning appropriately some of its duration-related parameters, the safety property can be\u00a0\u2026", "num_citations": "15\n", "authors": ["495"]}
{"title": "From serializable to causal transactions for collaborative applications\n", "abstract": " Serializability is the traditional consistency criterion when shared objects are accessed concurrently. Its main drawback lies in the strong synchronization constraints it imposes on execution of applications when they are run on distributed systems. In this paper we examine weake consistency criteria for computations in which accesses to shared objects are grouped to form transactions. In particular, we explore causal consistency and causal serializability for transaction based computations. These criteria turn out to be sufficient for a class of applications ( e.g., collaborative applications) and their implementation results in greater availability of data and improved performance. These criteria are formally defined and protocols implementing them are presented. We demonstrate that causal consistency allows both read and update transactions to be executed in a wait-free manner. Although write accesses in causal serializability require synchronization with other nodes, read accesses appearing in update transactions can be executed locally. This distinguishes causal serializability from serializability where synchronization is necessary for both read and write accesses of update transactions. Finally, fault-tolerance problems are addressed in the context of process crash failures.", "num_citations": "15\n", "authors": ["495"]}
{"title": "Distributed debugging techniques\n", "abstract": " Ce document pr\u00e9sente certains probl\u00e8mes fondamentaux auxquels un impl\u00e9mentcur est confront\u00e9 lors du d\u00e9veloppement de metteurs au point pour des programmes fonctionnant sur des machines r\u00e9parties. Les concepts classiques de la mise au point de programmes s\u00e9quentiels sont en effet insuf\ufb01sants. Apr\u00e8s avoir d\u00e9\ufb01ni l\u2019\u00e9tat d \u2018un programme principal, une \u00e9quivalence d\u2019ex\u00e9cution et le concept de reproductibilit\u00e9 d \u2018un comportement de programme nous pr\u00e9sentons quelques solutions simples \u00e0 ces probl\u00e8mes.", "num_citations": "15\n", "authors": ["495"]}
{"title": "Prime numbers as a tool to design distributed algorithms\n", "abstract": " Prime numbers are investigated as a tool to design distributed control algorithms. One of the major drawbacks in designing such algorithms lies in the inability for one or several processes (or even for an external observer) to catch instantaneously some part of the global state of the system. It is shown in this paper how, in some cases, prime numbers can be used to make distributed observations allowing to make consistent decisions. Two very different distributed algorithms are produced as an illustration of the proposed tool (a mutual exclusion and a termination detection algorithm).", "num_citations": "15\n", "authors": ["495"]}
{"title": "Distributed universal constructions: a guided tour\n", "abstract": " The notion of a universal construction is central in computing science: the wheel has not to be reinvented for each new problem. In the context of n-process asynchronous distributed systems, a universal construction is an algorithm that is able to build any object defined by a sequential specification despite the occurrence of up to (n \u2212 1) process crash failures. The aim of this paper is to present a guided tour of such universal constructions. Its spirit is not to be a catalog of the numerous constructions proposed so far, but a (as simple as possible) presentation of the basic concepts and mechanisms that constitute the basis these constructions rest on.", "num_citations": "14\n", "authors": ["495"]}
{"title": "Distributed universality\n", "abstract": " A notion of a universal construction suited to distributed computing has been introduced by Herlihy in his celebrated paper \u201cWait-free synchronization\u201d (ACM Trans Program Lang Syst 13(1):124\u2013149, 1991). A universal construction is an algorithm that can be used to wait-free implement any object defined by a sequential specification. Herlihy\u2019s paper shows that the basic system model, which supports only atomic read/write registers, has to be enriched with consensus objects to allow the design of universal constructions. The generalized notion of a k                          -universal construction has been recently introduced by Gafni and Guerraoui (Proceedings of 22nd international conference on concurrency theory (CONCUR\u201911), Springer LNCS 6901, pp\u00a017\u201327, 2011). A k-universal construction is an algorithm that can be used to simultaneously implement k objects (instead of just one object), with the guarantee that at least one of the k constructed\u00a0\u2026", "num_citations": "14\n", "authors": ["495"]}
{"title": "Generalized symmetry breaking tasks and nondeterminism in concurrent objects\n", "abstract": " Processes in a concurrent system need to coordinate using an underlying shared memory or a message-passing system in order to solve agreement tasks such as, for example, consensus or set agreement. However, coordination is often needed to break the symmetry of processes that are initially in the same state---for example, to get exclusive access to a shared resource, to get distinct names, or to elect a leader. This paper introduces and studies the family of generalized symmetry breaking (GSB) tasks, which includes election, renaming, and many other symmetry breaking tasks, and studies how nondeterminism properties of objects solving tasks affects the computability power of GSB tasks. The aim is to develop the understanding of symmetry breaking tasks and their relation with agreement tasks and to study nondeterminism properties of objects solving tasks and how these properties affect the computability power of\u00a0\u2026", "num_citations": "14\n", "authors": ["495"]}
{"title": "The eventual leadership in dynamic mobile networking environments\n", "abstract": " Eventual leadership has been identified as a basic building block to solve synchronization or coordination problems in distributed computing systems. However, it is a challenging task to implement the eventual leadership facility, especially in dynamic distributed systems, where the global system structure is unknown to the processes and can vary over time. This paper studies the implementation of a leadership facility in infrastructured mobile networks, where an unbounded set of mobile hosts arbitrarily move in the area covered by fixed mobile support stations. Mobile hosts can crash and suffer from disconnections. We develop an eventual leadership protocol based on a time-free approach. The mobile support stations exchange queries and responses on behalf of mobile hosts. With assumptions on the message exchange flow, a correct mobile host is eventually elected as the unique leader. Since no time\u00a0\u2026", "num_citations": "14\n", "authors": ["495"]}
{"title": "Timed quorum systems for large-scale and dynamic environments\n", "abstract": " This paper presents Timed Quorum System (TQS), a quorum system for large-scale and dynamic systems. TQS provides guarantees that two quorums, accessed at instances of time that are close together, intersect with high probability. We present an algorithm that implements TQS at its core and that provides operations that respect atomicity with high probability. This TQS implementation has quorums of size  and expected access time of  message delays, where n measures the size of the system and D is a required parameter to handle dynamism. This algorithm is shown to have complexity sub-linear in size and dynamism of the system, and hence to be scalable. It is also shown that for systems where operations are frequent enough, the system achieves the lower bound on quorum size for probabilistic quorums in static systems, and it is thus optimal in that sense.", "num_citations": "14\n", "authors": ["495"]}
{"title": "A hybrid and adaptive model for fault-tolerant distributed computing\n", "abstract": " The capability of dynamically adapting to distinct runtime conditions is an important issue when designing distributed systems where negotiated quality of service (QoS) cannot always be delivered between processes. Providing fault-tolerance for such dynamic environments is a challenging task. Considering such a context, this paper proposes an adaptive model for fault-tolerant distributed computing. This model encompasses both the synchronous model (where there are time bounds on processing speed and message delay) and the asynchronous model (where there is no time bound). To illustrate what can be done in this model and how to use it, the consensus problem is taken as a benchmark problem. An implementation of the model is also described. This implementation relies on a negotiated quality of service (QoS) for channels, that can be timely or untimely. Moreover, the QoS of a channel can be lost\u00a0\u2026", "num_citations": "14\n", "authors": ["495"]}
{"title": "-BASED CONSENSUS for ASYNCHRONOUS BYZANTINE SYSTEMS\n", "abstract": " This paper presents a consensus protocol for asynchronous distributed systems made up of n processes, where up to f<n/4 processes can behave arbitrarily (Byzantine processes). The protocol assumes that the underlying system is equipped with an unreliable failure detector of the class . The failure detectors of the class  ensure that (1) all mute processes are detected (a mute process is a process that, after some time, stops sending protocol messages), and (2) after some unknown but finite time, no correct process is suspected (mute processes are a subset of the Byzantine processes). The proposed protocol enjoys the following properties. It is based on the round coordinator paradigm and its design principle is particularly simple. Its message complexity is O(n2) per round. In addition to a round number, the message size is O(1), except for one message per round (sent by the round coordinator\u00a0\u2026", "num_citations": "14\n", "authors": ["495"]}
{"title": "Token-based sequential consistency\n", "abstract": " A concurrent object is an object that can be concurrently accessed by several processes. Sequential consistency is a consistency criterion for such objects. It informally states that a multiprocess program executes correctly if its results could have been produced by executing that program on a single processor system.(Sequential consistency is weaker than atomic consistency\u2013the usual consistency criterion--as it does not refer to real-time.) The paper proposes a new surprisingly simple protocol that ensures sequential consistency when the shared memory abstraction is supported by the local memories of nodes that can communicate only by exchanging messages through reliable channels. The protocol nicely combines in a simple way the use a token with cached values. It has the noteworthy property to never invalidate cached values, thereby providing fast read opera-tions (ie, a process has never to wait to get a correct value of a shared object). Additionally, The paper presents a simple token navigation protocol.", "num_citations": "14\n", "authors": ["495"]}
{"title": "Interval consistency of asynchronous distributed computations\n", "abstract": " An interval of a sequential process is a sequence of consecutive events of this process. The set of intervals defined on a distributed computation defines an abstraction of this distributed computation, and the traditional causality relation on events induces a relation on the set of intervals that we call I-precedence. An important question is then, \u201cIs the interval-based abstraction associated with a distributed computation consistent?\u201d To answer this question, this paper introduces a consistency criterion named interval consistency (IC). Intuitively, this criterion states that an interval-based abstraction of a distributed computation is consistent if its I-precedence relation does not contradict the sequentiality of each process. More formally, IC is defined as a property of a precedence graph. Interestingly, the IC criterion can be operationally characterized in terms of timestamps (whose values belong to a lattice). The paper uses\u00a0\u2026", "num_citations": "14\n", "authors": ["495"]}
{"title": "Shared global states in distributed computations\n", "abstract": " A consistent observation of a given distributed computation is a sequence of global states that could be produced by executing that computation on a monoprocessor system. Therefore a distributed execution generally accepts several consistent observations. This paper investigates global states shared by all such observations. A necessary and sufficient condition characterizing these states is first given. Then, an algorithm that computes shared global states is described.", "num_citations": "14\n", "authors": ["495"]}
{"title": "Erebus: A debugger for asynchronous distributed computing systems\n", "abstract": " This paper addresses the problem of debugging distributed programs executing on distributed memory parallel computers with message-passing interprocess communication. The main issues of debugging such programs are exposed. Principles for designing and implementing a debugger for programs specified in the Estelle language are presented. All the described solutions have been implemented in a distributed debugger called EREBUS.", "num_citations": "14\n", "authors": ["495"]}
{"title": "Synchronisation et contr\u00f4le des systemes et des programmes r\u00e9partis\n", "abstract": " Le PARALLELISME et la REPARTITION constituent deux concepts fondamentaux de la Science et de la Technologie Informatiques. D'une part, le domaine des applications fond\u00e9es sur l'utilisation de r\u00e9seaux et de syst\u00e8mes repartis ne cesse de s' \u00e9tendre; d'autre part la m\u00e9thodologie de conception et d'\u00e9criture du logiciel incite de plus en plus \u00e0 consid\u00e9rer une application comme un ensemble d'agents coop\u00e9rant a la r\u00e9alisation d'un but commun. Il importe d\u00e8s lors, si l'on veut ma\u00eetriser les applications de plus en plus complexes qui se pr\u00e9sentent, de conna\u00eetre et de MAITRISER LES FONDEMENTS du calcul et du contr\u00f4le parall\u00e8le et r\u00e9parti c'est-\u00e0-dire ce qu'il est convenu d'appeler les bases de l'algorithmique repartie.", "num_citations": "14\n", "authors": ["495"]}
{"title": "Implementing snapshot objects on top of crash-prone asynchronous message-passing systems\n", "abstract": " In asynchronous crash-prone read/write shared-memory systems there is the notion of a snapshot object, which simulates the behavior of an array of single-writer/multi-reader (SWMR) shared registers that can be read atomically. Processes in the system can access the object invoking (any number of times) two operations, denoted write() and snapshot(). A process invokes write() to update the value of its register in the array. When it invokes snapshot(), the process obtains the values of all registers, as if it read them simultaneously. It is known that a snapshot object can be implemented on top of SWMR registers, tolerating any number of process failures. Snapshot objects provide a level of abstraction higher than individual SWMR registers, and they simplify the design of applications. Building a snapshot object on an asynchronous crash-prone message-passing system has similar benefits. The object can be\u00a0\u2026", "num_citations": "13\n", "authors": ["495"]}
{"title": "Blockchain consensus\n", "abstract": " Blockchain, as originally coined in the seminal Bitcoin paper [13], is a promising technology to track ownerships of digital assets within a distributed ledger. This technology aims at allowing processes to agree on a series of consecutive blocks of transactions that may invoke contract functions to exchange these assets. While the first instances of these distributed ledgers were accessed by Internet users with no specific permissions, companies have since then successfully deployed other instances in a consortium context, restricting the task of deciding blocks to a set of n (among others) carefully selected institutions with appropriate permissions.For the distributed computing community, a blockchain may seem like the application of classical state machine replication [14], where processes can be Byzantine [12], to the cryptocurrency context. A major distinction between blockchain and state machine replication is, however, the relation between consecutive consensus instances. A blockchain requires each of its consensus instances to be explicitly related to the previous one. To be decided, a block proposed in consensus instance number x must embed the hash of the block decided at instance number (x\u2212 1). By contrast, the classical state machine replication simply concatenates consensus instances one after the other without relating the input of a consensus instance to the previous consensus instance: the result of a command may depend on the previous commands, but not the fact that it can be applied.", "num_citations": "13\n", "authors": ["495"]}
{"title": "A distributed leader election algorithm in crash-recovery and omissive systems\n", "abstract": " This paper presents a distributed leader election algorithm for crash-recovery and omission environments. Contrary to previous works, our algorithm tolerates the occurrence of crash-recoveries and message omissions to any process during some finite but unknown time, after which a majority of processes in the system remains up and does not omit messages.", "num_citations": "13\n", "authors": ["495"]}
{"title": "Parallel computing vs. distributed computing: a great confusion?(position paper)\n", "abstract": " This short position paper discusses the fact that, from a teaching point of view, parallelism and distributed computing are often confused, while, when looking at their deep nature, they address distinct fundamental issues. Hence, appropriate curricula should be separately designed for each of them. The \u201ceverything is in everything (and reciprocally)\u201d attitude does not seem to be a relevant approach to teach students the important concepts which characterize parallelism on the one side, and distributed computing on the other side.", "num_citations": "13\n", "authors": ["495"]}
{"title": "A hierarchical consensus protocol for mobile ad hoc networks\n", "abstract": " Mobile ad hoc networks (MANETs) raise new challenges in designing protocols for solving the consensus problem. Among the others, how to design message efficient protocols so as to save resource consumption, has been the focus of research. In this paper, we present the design of such an efficient consensus protocol. We consider the system model for MANETs with host crashes, but equipped with Chandra-Toueg's unreliable failure detectors of class /spl diams/P. At most f hosts can crash where f < n/2 (n is the total number of the hosts). The protocol adopts the coordinator rotation paradigm to achieve consensus. Unlike existing consensus protocols, the proposed protocol is based on a two-layer hierarchy with hosts associated with proxies. At least f + 1 hosts act as proxies and each host is associated with one proxy host. The messages from and/or to the local hosts of the same proxy are merged so as to\u00a0\u2026", "num_citations": "13\n", "authors": ["495"]}
{"title": "Quorum-based multi-invocation model for replicated objects\n", "abstract": " In distributed systems, resources like databases are abstracted to be objects in                 order to increase the interoperability. Objects are replicated to make a system more                 reliable and available. In object-based systems, methods are invoked in a nested                 manner, i.e. methods-named invokees are invoked in another method named invoker. How                 to invoke methods on multiple replicas in the nested manner is discussed here. In                 this paper, methods are invoked on a quorum number of replicas of objects. Suppose                 each instance of a method t on multiple replicas of an object x                 invokes a method u on replicas in a quorum of another object y.                 Here, the method u is redundantly invoked, i.e. the same method is invoked                 many times on some replicas of the object y. This is redundant invocation. If each                 instance of the invoker method t invokes a\u00a0\u2026", "num_citations": "13\n", "authors": ["495"]}
{"title": "Understanding how metadata and explanations can better support data warehousing and related decision support systems: an exploratory case study\n", "abstract": " Many businesses have made or are making significant investments in data warehouses (DWs) and marts that are designed to support a myriad of decision support systems (DSSs). Due to the newness of DWs and related DSSs, the nature of the decision support provided to DSS users and the importance of meta-data and explanations within that support have not been documented. An exploratory case study has been undertaken at two organizations that are using DWs to support a particular type of DW-DSS - customer relationship management (CRM) systems. CRM systems were selected as a representative DW-DSS due to the large number of system users and the various types of DSS tools that these systems typically encompass. The DSS decision performance model suggested by P. Todd and I. Benbasat (1991, 1992, 1993, 1994, 1999) has been employed as a framework for this exploration. Constructs from\u00a0\u2026", "num_citations": "13\n", "authors": ["495"]}
{"title": "Restricted failure detectors: Definition and reduction protocols\n", "abstract": " This paper investigates unreliable failure detectors with restricted properties, in the context of asynchronous distributed systems made up of n processes where at most f may crash.\u201cRestricted\u201d means that the completeness and the accuracy properties defining a failure detector class are not required to involve all the correct processes but only k and k\u2032 of them, respectively (k are involved in the completeness property, and k\u2032 in the accuracy property). These restricted properties define the classes R (k, k\u2032) and\u2662 R (k, k\u2032) of unreliable failure detectors. A reduction protocol that transforms a restricted failure detector into its non-restricted counterpart is presented. It is shown that the reduction requires k+k\u2032> n (to be safe) and max (k, k\u2032)\u2264 n\u2212 f (to be live). So, when these two conditions are satisfied, R (k, k\u2032) and\u2662 R (k, k\u2032) are equivalent to the Chandra\u2013Toueg's failure detector classes S and\u2662 S, respectively. This\u00a0\u2026", "num_citations": "13\n", "authors": ["495"]}
{"title": "Asynchronous protocols to meet real-time constraints: Is it really sensible? How to proceed?\n", "abstract": " This paper investigates the use of asynchronous protocols to design and build middleware whose aim is to provide run-time support for soft real-time applications. A simple and general framework is described. This framework allows to take into account timeliness constraints of upper layer applications, while using an asynchronous protocol at the underlying level. When a timeliness constraint is about to be violated, the application layer is informed and can take appropriate measures. The deadline period can then be extended if the constraint is soft enough; in the other case, a default value can be used as a result. This framework can be seen as a bridge from asynchronous systems to synchronous ones. The proposed approach is illustrated with the consensus problem. This approach is investigated in the ARGO system we are implementing. The target applications of the ARGO middleware are telecommunication\u00a0\u2026", "num_citations": "13\n", "authors": ["495"]}
{"title": "An optimistic protocol for a linearizable distributed shared memory system\n", "abstract": " Recently, distributed shared memory systems have received much attention because such an abstraction simplifies programming. In this paper, we present a simple protocol which implements the linearizability consistency criterion in a distributed shared memory system. Unlike previously implemented protocols, our protocol is based on an optimistic approach. The protocol eliminates the necessity of potentially expensive synchronization among processors for each write operation, but may require processes to rollback.", "num_citations": "13\n", "authors": ["495"]}
{"title": "From serializable to causal transactions\n", "abstract": " In a shared object model, a consistency criterion defines which is the value that must be returned to aprocess when it reads an object, and a protocol implementing a consistency criterion describes how processes have to be synchronized in order to ensure that they read correct values (Le., satisfy the consistency criterion). Serializability and the two phase locking protocol, mainly studied and used in the database field, are the best known examples of a consistency criterion and its associated implementation protocol. Traditional consistency criteria (namely, atomici~, seridizability and linearizability) require that all processes have the same sequential view of the computation. This view is formally defined as a total order on operations issued by processes and an execution is correct if any read of an object gets the last value previously written into this object (the words \u2018last\u2019and \u2018previously\u2019 refer to the total order of\u00a0\u2026", "num_citations": "13\n", "authors": ["495"]}
{"title": "Energy-efficient composite event detection in wireless sensor networks\n", "abstract": " Composite event detection is one of fundamental tasks for wireless sensor networks. In existing approaches, typically, a routing tree is used to enable information exchange among sensor nodes and collaborative detection of composite events. However, such a tree is not optimal in terms of energy efficiency, because the relations included in composite events have not been fully utilized. In this letter, we propose a new type of routing tree called event detection tree (EDT) to achieve energy-efficient composite event detection. EDT reduces the amount of data to be transmitted by aggregating data in to events, at the cost of an increased distance in the data transmission to achieve such aggregations. EDT achieves a tradeoff of them to minimize the overall energy consumption. Simulation results show that our approach outperforms existing approaches and yields energy savings of up to 20%.", "num_citations": "12\n", "authors": ["495"]}
{"title": "Predicate detection in asynchronous distributed systems: A probabilistic approach\n", "abstract": " In an asynchronous distributed system, a number of processes communicate with each other via message passing that has a finite but arbitrary long delay. There is no global clock in that system. Predicates, denoting the states of processes and their relations, are often used to specify the information of interest in such a system. Due to the lack of a global clock, the temporal relations between the states at different processes cannot be uniquely determined, but have multiple possible circumstances. Existing works of predicate detection are based on the definitely modality or the possibly modality, denoting that a predicate holds in all of the possible circumstances or in one of them, respectively. No information is provided about the probability that a predicate will hold, which hinders the taking of countermeasures for different situations. Moreover, the detection is based on single occurrence of a predicate, so the results\u00a0\u2026", "num_citations": "12\n", "authors": ["495"]}
{"title": "A liveness condition for concurrent objects: x\u2010wait\u2010freedom\n", "abstract": " The liveness of concurrent objects despite asynchrony and failures is a fundamental problem. To that end several progress conditions have been proposed. Wait\u2010freedom is the strongest of these conditions: it states that any object operation must terminate if the invoking process does not crash. Obstruction\u2010freedom is a weaker progress condition as it requires progress only when a process executes in isolation for a long enough period. This paper explores progress conditions in n\u2010process asynchronous read/write systems enriched with base objects with consensus number x, 1<x\u2264n(i.e. objects that wait\u2010free solve consensus in a set of x processes). It is easy to solve consensus in such a system if progress is required only when one of the x processes allowed to access the underlying consensus object invokes this object and does not crash. This paper proposes and investigates a stronger progress condition that\u00a0\u2026", "num_citations": "12\n", "authors": ["495"]}
{"title": "Eventual leader service in unreliable asynchronous systems: Why? how?\n", "abstract": " Providing processes with an eventual leader service is an important issue when one has to design and implement a middleware layer on top of a failure-prone asynchronous distributed system. This invited lecture investigates this problem. It first shows that such a service cannot be built if the underlying system is fully asynchronous. Then, the paper visits several additional behavioral assumptions that have been proposed in the literature to cope with this impossibility and presents corresponding eventual leader election protocols. This lecture can be seen as a guided tour of the eventual leader service problem, whose aim is to benefit researchers and system engineers working in distributed middleware built on top of asynchronous networks.", "num_citations": "12\n", "authors": ["495"]}
{"title": "A note on a simple equivalence between round-based synchronous and asynchronous models\n", "abstract": " This short paper characterizes a round-based synchronous (timely) computing model that is equivalent to the popular crash prone round-based asynchronous (time-free) distributed computing model. Equivalence means here that any problem that can be solved by a protocol in one model can be solved by the same protocol in the other model. The style of this note is voluntarily informal. Its aim is mainly pedagogical. Its ambition is to help better understand relations linking synchronous and asynchronous distributed computing systems, and the nature of failures that make them difficult to master.", "num_citations": "12\n", "authors": ["495"]}
{"title": "Building responsive TMR-based servers in presence of timing constraints\n", "abstract": " This paper is on the construction of a fault-tolerant and responsive server subsystem in an application context where the subsystem is accessed through an asynchronous network by a large number of clients. The server is made fault-tolerant by the triple modular redundancy (TMR) technique: at least two server processes behave correctly, while the third one can behave arbitrarily. An essential requirement for process replication is that the client inputs be delivered to server replicas for processing in an identical order. Moreover, in order to cope with process' memory requirement, a time bound constraint is imposed: no client input can stay in the local memory of server process more than /spl Sigma/ units of time. Based on known technologies, two assumptions are made: (1) the network delivers a given client input to any two server processes within a known bounded time (D), and (2), there is an Ordered Timed\u00a0\u2026", "num_citations": "12\n", "authors": ["495"]}
{"title": "Real-time dependable decisions in timed asynchronous distributed systems\n", "abstract": " Allowing a set of objects to make a consistent decision, according to the values they propose, is a fundamental problem of distributed systems. When the system is reliable and synchronous the problem is simple. In the context of unreliable asynchronous systems that have to meet real-time constraints, the problem is far from trivial. A negative result stipulates that it is impossible to design a consensus protocol even if only one object crashes. The author considers timed asynchronous systems. He first proposes a general definition for decision-with-deadlines problems and then designs a protocol that solves these problems in timed asynchronous systems. An object can vote a or b. In a \"good\" configuration (there are not too many crashes and messages are timely) objects will decide consistently A or B according to the number of votes a or b that they have received. A and B are incompatible decision values. If there\u00a0\u2026", "num_citations": "12\n", "authors": ["495"]}
{"title": "Computing particular snapshots in distributed systems\n", "abstract": " The focus of this work is on a particular class of unstable global states: the states with no in-transit message. A characterization of these states and their interest are given, along with the principles of their detection. As detecting these states requires a network traversal, choosing a particular implementation of this traversal gives one instance from a family of algorithms. The algorithm based on a virtual Hamiltonian cycle (a ring traversal) is presented and proved to be correct. The exposition of the principles and of the ring algorithm is done in an analytic way: algorithmic techniques are given separately (markers, message counting, network traversal) to lay down the snapshot definition properties.<>", "num_citations": "12\n", "authors": ["495"]}
{"title": "Algorithmes Distribu\u00e9s synchrones et syst\u00e8mes r\u00e9partis asynchrones: concepts, mises en \u0153uvre et exp\u00e9rimentations\n", "abstract": " R\u00e9sum\u00e9 La conception de certains algorithmes distribu\u00e9s et parall\u00e8les est fond\u00e9e sur le concept de synchronisme; ce concept suppose que le comportement de chaque processus est exprim\u00e9 en terme d\u2019une s\u00e9quence d\u2019\u00e9tapes, chaque \u00e9tape se d\u00e9roulant au m\u00eame instant pour tous les processus. Apr\u00e8s avoir precis\u00e9 les d\u00e9\ufb01nitions des mod\u00e8les synchrones et asynchrones dans les syst\u00e8mes distribu\u00e9s, nous \u00e9tudions l\u2019interpr\u00e9tation des algorithmes synchrones sur des syst\u00e8mes asynchrones. Dans cette \u00e9tude, deux typ de synchronismes sont d\u00e9\ufb01nis et leurs propri\u00e9t\u00e9s respectives sont capt\u00e9es par deux th\u00e9or\u00e8mes; certaines relations entre les concepts de synchronisme et les m\u00e9canismes d\u2019horloges logiques sont par ailleurs mises en \u00e9vidence. Nous examinons ensuite les probl\u00e8mes de synchronisation que posent la mise en \u0153uvre des synchroniseurs et certaines de leurs solutions. En\ufb01n, des r\u00e9sultats issus des\u00a0\u2026", "num_citations": "12\n", "authors": ["495"]}
{"title": "Depth-first traversal and virtual ring construction in distributed systems\n", "abstract": " De nombreux syst\u00e8mes et applications r\u00e9partis utilisent des algorithmes de contr\u00f4le d\u00e9centralis\u00e9 qui s' appuient sur l\u2019existence pr\u00e9alable d\u2019un anneau virtuel; une telle structure est g\u00e9n\u00e9ralement d\u00e9\ufb01nie statiquement et la d\u00e9finition du syst\u00e8me est alors li\u00e9e \u00e0 celle d\u2019un anneau particulier.Nous proposons ici des algorithmes distribu\u00e9s de construction d\u2019anneaux. On montre tout d\u2019abord comment les algorithmes distribu\u00e9s de parcours en profondeur de r\u00e9seaux (par le parcours s\u00e9quentiel qu\u2019ils en r\u00e9alisent) peuvent constituer les fondements algorithmiques pour la construction de telles structures. On pr\u00e9sente ensuite un algorithme de construction d\u2019anneau dont les complexit\u00e9s en temps et en messages sont \u00e9gales a 2 (n\u2014l), les messages \u00e9tant de taille 0 (n), o\u00f9 n est le nombre de sites. Un parcours des n liens de l\u2019anneau virtuel construit requiert 2 (n\u20141) messages. L'am\u00e9lioration propos\u00e9e ensuite permet de\u00a0\u2026", "num_citations": "12\n", "authors": ["495"]}
{"title": "Optimal memory-anonymous symmetric deadlock-free mutual exclusion\n", "abstract": " The notion of an anonymous shared memory, introduced by Taubenfeld in PODC 2017, considers that processes use different names for the same memory location. As an example, a location name A used by a process p and a location name B\u2260 A used by another process q can correspond to the very same memory location X, and similarly for the names B used by p and A used by q which may (or may not) correspond to the same memory location Y\u2260 X. In this context, the PODC paper presented a 2-process symmetric deadlock-free mutual exclusion (mutex) algorithm and a necessary condition on the size m of the anonymous memory for the existence of such an n-process algorithm. This condition states that m must be belongs to M (n){1} where M (n)={m:\u2200 \u2113:(1)< \u2113\u2264 n: gcd (\u2113, m)= 1). Symmetric means here that, process identities define a specific data type which allows a process to check only if two identities are\u00a0\u2026", "num_citations": "11\n", "authors": ["495"]}
{"title": "Anonymity in distributed read/write systems: an introductory survey\n", "abstract": " This paper is an algorithmic introduction to anonymity in asynchronous systems where processes communicate by reading and writing atomic read/write registers. Two types of anonymity are investigated: process-anonymity and memory-anonymity. Process-anonymity is when the processes cannot be distinguished the ones from the others (among other features, they do not have identifiers). Memory-anonymity is when the same memory locations can have different names at different processes (e.g., the location name A used by process  and the location name B used by another process  can correspond to the very same memory location X, and similarly for the names B at  and A at  which correspond to the same memory location ). The paper shows how algorithms can cope with the uncertainty created by these two types of anonymity. To this end, taking examples from the literature, it presents\u00a0\u2026", "num_citations": "11\n", "authors": ["495"]}
{"title": "Long-lived tasks\n", "abstract": " The predominant notion for specifying problems to study distributed computability are tasks. Notable examples of tasks are consensus, set agreement, renaming and commit-adopt. The theory of task solvability is well-developed using topology techniques and distributed simulations. However, concurrent computing problems are usually specified by objects. Tasks and objects differ in at least two ways. While a task is a one-shot problem, an object, such as a queue or a stack, typically can be invoked multiple times by each process. Also, a task, defined in terms of sets, specifies its responses when invoked by each set of processes concurrently, while an object, defined in terms of sequences, specifies the outputs the object may produce when it is accessed sequentially.                 In a previous paper we showed how tasks can be used to specify one-shot objects (where each process can invoke only one\u00a0\u2026", "num_citations": "11\n", "authors": ["495"]}
{"title": "An introductory tutorial to concurrency-related distributed recursion\n", "abstract": " Recursion is a fundamental concept of sequential computing that allows for the design of simple and elegant algorithms. Recursion is also used in both parallel or distributed computing to operate on data structures, mainly by exploiting data independence (independent data being processed concurrently). This paper is a short introduction to recursive algorithms that compute tasks in asynchronous distributed systems where communication is through atomic read/write registers, and any number of processes can commit crash failures. In such a context and differently from sequential and parallel recursion, the conceptual novelty lies in the fact that the aim of the recursion parameter is to allow each participating process to learn the number of processes that it sees as participating to the task computation.", "num_citations": "11\n", "authors": ["495"]}
{"title": "Coordination and Computation in distributed intelligent MEMS\n", "abstract": " Over the last decades, research on microelectromechanical systems (MEMS) has focused on the engineering process which has led to major advances. Future challenges will consist in adding embedded intelligence to MEMS systems to obtain distributed intelligent MEMS. One intrinsic characteristic of MEMS is their ability to be mass-produced. This, however, poses scalability problems because a significant number of MEMS can be placed in a small volume. Managing this scalability requires paradigm-shifts both in hardware and software parts. Furthermore, the need for actuated synchronization, programming, communication and mobility management raises new challenges in both control and programming. Finally, MEMS are prone to faulty behaviors as they are mechanical systems and they are issued from a batch fabrication process. A new programming paradigm which can meet these challenges is therefore\u00a0\u2026", "num_citations": "11\n", "authors": ["495"]}
{"title": "Provable STM Properties: Leveraging clock and locks to favor commit and early abort\n", "abstract": " The aim of a Software Transactional Memory (STM) is to discharge the programmers from the management of synchronization in multiprocess programs that access concurrent objects. To that end, a STM system provides the programmer with the concept of a transaction: each sequential process is decomposed into transactions, where a transaction encapsulates a piece of code accessing concurrent objects. A transaction contains no explicit synchronization statement and appears as if it has been executed atomically. Due to the underlying concurrency management, a transaction commits or aborts.               The major part of papers devoted to STM systems address mainly their efficiency. Differently, this paper focuses on an orthogonal issue, namely, the design and the statement of a safety property. The only safety property that is usually considered is a global property involving all the transactions (e.g\u00a0\u2026", "num_citations": "11\n", "authors": ["495"]}
{"title": "Stabilizing mobile philosophers\n", "abstract": " We present a self-stabilizing solution to a new version of the dining philosophers problem. We call this problem mobile philosophers problem because the philosophers can move around a logical ring formed out of a dynamic network.", "num_citations": "11\n", "authors": ["495"]}
{"title": "Uniform agreement despite process omission failures\n", "abstract": " A process fails by omission if it \"forgets\" to send or receive messages. Considering omission failures is crucial for distributed systems, as such failures model both crash failures and incorrect behavior of process input/output buffers (such as buffer overflow). So, designing protocols that cope not only with crash failures but also with omission failures is a real challenge as soon as one is interested in obtaining real-time dependable distributed systems. While the consensus problem has received a lot of attention in the crash failure model and in the Byzantine failure model, it has received less attention in the omission failure model. This paper presents a simple uniform consensus protocol for synchronous systems made up of n processes where up to t can commit crash or omission failures. This protocol requires t+1 communication steps. Interestingly, as this bound is tight for crash failures and those are included in\u00a0\u2026", "num_citations": "11\n", "authors": ["495"]}
{"title": "An optimal atomic broadcast protocol and an implementation framework\n", "abstract": " Atomic broadcast (where all processes deliver broadcast messages in the same order) is a very useful group communication primitive for building fault-tolerant distributed systems. This paper presents an atomic broadcast protocol that can be claimed to be optimal in terms of failure detection, resilience, and latency. The protocol requires only the weakest of the useful failure detectors for liveness, and permits up to (n-1)/2 processes to crash in a system of n processes; at most two communication steps and n broadcasts are needed in a run during which process crashes and failure-suspicions do not occur. We also introduce the notion of notifying broadcast which can reduce the message overhead further in 'nice' runs in which all processes are operational and communication delays do not exceed the bound assumed. If nice runs persist, the average message overhead is just one broadcast. That is, the protocol\u00a0\u2026", "num_citations": "11\n", "authors": ["495"]}
{"title": "Consensus based on strong failure detectors: A time and message-efficient protocol\n", "abstract": " The class of strong failure detectors (denoted   ) includes all failure detectors that suspect all crashed processes and that do not suspect some (a priori unknown) process that never crashes. So, a failure detector that belongs to    is intrinsically unreliable as it can arbitrarily suspect correct processes. Several   -based consensus protocols have been designed. Some of them systematically require n computation rounds (n being the number of processes), each round involving n 2 or n messages. Others allow early decision (i.e., the number of rounds depends on the maximal number of crashes when there are no erroneous suspicions) but require each round to involve n 2 messages.             This paper presents an early deciding   -based consensus protocol each round of which involves 3(n \u2212 1) messages. So, the proposed protocol is particularly time and message-efficient.", "num_citations": "11\n", "authors": ["495"]}
{"title": "Semantics of recovery lines for backward recovery in distributed systems\n", "abstract": " Cet article est consacr\u00e9 \u00e0 la d\u00e9finition des \u00e9tats de reprise dans le cadre des techniques de r\u00e9tablissement, utilis\u00e9es pour traiter les d\u00e9faillances dans les syst\u00e8mes distribu\u00e9s. On introduit un cadre g\u00e9n\u00e9ral permettant de consid\u00e9rer plusieurs s\u00e9mantiques \u010f\u00e9tats de reprise. Des notions clefs telles que celles de messages manquants ou messages orphelins sont d\u00e9finies avec pr\u00e9cision, et leur influence sur la d\u00e9finition de la coh\u00e9rence \u010fun \u00e9tat de reprise est soigneusement analys\u00e9e. Les outils de base, tels que les points de contr\u00f4le locaux, le stockage des messages (optimiste ou pessismiste) et la r\u00e9-ex\u00e9cution, sont introduits pour illustrer des algorithmes de reprise, coordonn\u00e9s ou non.", "num_citations": "11\n", "authors": ["495"]}
{"title": "Termination detection in a very general distributed computing model\n", "abstract": " Termination detection constitutes one of the basic problems of distributed computing, and many distributed algorithms have been proposed to solve it, but all these algorithms consider a very simple model for the underlying application programs: for processes of such programs, nondeterministic constructs are allowed, but each 'receive' statement (request) concerns only one message at a time. A more realistic and very general model of distributed computing is first presented, allowing a request to be atomic on several messages and to obey AND/OR/AND-OR/k-out-of-n/etc. request types. Within this framework, two definitions of termination are proposed and discussed. Then, accordingly, two distributed algorithms for detecting these terminations are presented and evaluated; they differ in the information they use and in the time they need to claim termination.< >", "num_citations": "11\n", "authors": ["495"]}
{"title": "Distributed termination detection: General model and algorithms\n", "abstract": " Termination detection constitutes one of the basic problems of distributed computing and many distributed algorithms have been proposed to solve it. These algorithms differ in the way they ensure consistency of the detection and in the assumptions they do concerning behaviour of channels (FIFO or not, bounded delay or asynchronous, etc.) But all these algorithms consider a very simple model for underlying application programs : for processes of such programs non-deterministic constructs are allowed but each receive statement (request) concerns only one message at a time. In this paper a more realistic and very general model of distributed computing is first presented. This model allows a request (receive statement) to be atomic on several messages and to obey and/or/and-or/k out of n/etc request types. These types are abstracted by the notion of an activation condition. Within this framework two definitions of termination are proposed and discussed. Then, accordingly, two distributed algorithms to detect these terminations are presented and evaluated, they differ in the information they use and in the time they need to claim termination.", "num_citations": "11\n", "authors": ["495"]}
{"title": "Parallel and distributed algorithms\n", "abstract": " Inria - Parallel and distributed algorithms Acc\u00e9der directement au contenu Acc\u00e9der directement \u00e0 la navigation Toggle navigation CCSD HAL HAL HALSHS TEL M\u00e9diHAL Liste des portails AUR\u00e9HAL API Data Documentation Episciences.org Episciences.org Revues Documentation Sciencesconf.org Support HAL-Inria Les publications, logiciels... des scientifiques Inria Accueil D\u00e9poser Consulter tout HAL par date de publication/r\u00e9daction par domaine par type de publication par collection arXiv les derniers d\u00e9p\u00f4ts Publications Inria Recherche Services HalTools : cr\u00e9er sa page web Haltools : export RAWEB X2Hal : import par lot Consulter les structures de recherche connues de HAL Documentation Aide en ligne de HAL V3 Derni\u00e8res \u00e9volutions de HAL V3 Documentation API HAL Ajouter des vignettes Aide en ligne Haltools Aide en ligne de X2hal OpenAccess Inria soutient la science ouverte hal-00857012, version ''\u2026", "num_citations": "11\n", "authors": ["495"]}
{"title": "Mastering concurrent computing through sequential thinking\n", "abstract": " A 50-year history of concurrency.", "num_citations": "10\n", "authors": ["495"]}
{"title": "Vertex coloring with communication constraints in synchronous broadcast networks\n", "abstract": " This paper considers distributed vertex-coloring in broadcast/receive networks suffering from conflicts and collisions. (A collision occurs when, during the same round, messages are sent to the same process by too many neighbors; a conflict occurs when a process and one of its neighbors broadcast during the same round.) More specifically, the paper focuses on multi-channel networks, in which a process may either broadcast a message to its neighbors or receive a message from at most \u03b3 of them. The paper first provides a new upper bound on the corresponding graph coloring problem (known as frugal coloring) in general graphs, proposes an exact bound for the problem in trees, and presents a deterministic, parallel, color-optimal, collision- and conflict-free distributed coloring algorithm for trees, and proves its correctness.", "num_citations": "10\n", "authors": ["495"]}
{"title": "From wait-free to arbitrary concurrent solo executions in colorless distributed computing\n", "abstract": " In an asynchronous distributed system where any number of processes may crash, a process may have to run solo, computing its local output without receiving any information from other processes. In the basic shared memory system where the processes communicate through atomic read/write registers, at most one process may run solo. This paper introduces the family of d-solo models, where d-processes may concurrently run solo, 1\u2264 d\u2264 n (the 1-solo model is the basic read/write model). The paper then studies distributed colorless computations in the d-solo models, where process ids are not used, either in task specifications or during computation. It presents a characterization of the colorless tasks that can be solved in each d-solo model. Colorless tasks include consensus, set agreement and many other previously studied tasks. It shows that colorless algorithms have limited computational power for solving\u00a0\u2026", "num_citations": "10\n", "authors": ["495"]}
{"title": "Fisheye consistency: Keeping data in synch in a georeplicated world\n", "abstract": " Over the last thirty years, numerous consistency conditions for replicated data have been proposed and implemented. Popular examples include linearizability (or atomicity), sequential consistency, causal consistency, and eventual consistency. These conditions are usually defined independently from the computing entities (nodes) that manipulate the replicated data; i.e., they do not take into account how computing entities might be linked to one another, or geographically distributed. To address this lack, as a first contribution, this paper introduces the notion of proximity graph between computing nodes. If two nodes are connected in this graph, their operations must satisfy a strong consistency condition, while the operations invoked by other nodes are allowed to satisfy a weaker condition. The second contribution exploits this graph to provide a generic approach to the hybridization of data consistency\u00a0\u2026", "num_citations": "10\n", "authors": ["495"]}
{"title": "A generalized mutual exclusion problem and its algorithm\n", "abstract": " Mutual exclusion (ME) is a fundamental problem for resource allocation in distributed systems, It is concerned with how the various processes access shared resources in a mutually exclusive way. Besides the classic ME problem, several variant problems have been proposed and studied. In this paper, drawing inspiration from the scenario of controlling autonomous vehicles at intersections, we have defined a new ME problem, called Local Group Mutual Exclusion (LGME), w here mutual exclusion is necessary only among the processes requesting overlap but not the same set of resources. In comparison with other variant problems of ME, LGME is more general but also more challenging. To solve the LGME problem, we propose a novel notion called strong coterie, which can handle the complex process relationship in LGME. Based on strong coterie, we have designed an ME algorithm, which can handle concurrent CS execution and message asynchrony. The correctness of our algorithm is rigorously proved.", "num_citations": "10\n", "authors": ["495"]}
{"title": "Consensus in anonymous distributed systems: Is there a weakest failure detector?\n", "abstract": " This paper is on failure detectors to solve the consensus problem in asynchronous systems made up of anonymous processes prone to crash and connected by asynchronous reliable channels. Anonymity means that any two processes cannot be distinguished one from the other: they have no name and execute the same code. The paper has several contributions. It first introduces two new classes of failures detectors, denoted AP and A\u03a9, and presents an AP-based algorithm and an A\u03a9-based algorithm that solve the consensus problem despite the three computational adversaries that are asynchrony, failures and anonymity. Then, the paper shows that, in crash-prone non-anonymous systems, (a) AP and the class of perfect failure detectors (denoted P) are equivalent, and (b) A\u03a9 and the class of eventual leader failure detectors (denoted \u03a9) are also equivalent. Finally, the paper addresses the question of the\u00a0\u2026", "num_citations": "10\n", "authors": ["495"]}
{"title": "Software transactional memories: An approach for multicore programming\n", "abstract": " The recent advance of multicore architectures and the deployment of multiprocessors as the mainstream computing platforms have given rise to a new concurrent programming impetus. Software transactional memories (STM) are one of the most promising approach to take up this challenge. The aim of a STM system is to discharge the application programmer from the management of synchronization when he/she has to write multiprocess programs. His/her task is to decompose his/her program in a set of sequential tasks that access shared objects, and to decompose each task in atomic units of computation. The management of the required synchronization is ensured by the associated STM system. This paper presents two STM systems, and a formal proof for the second one. Such a proof -that is not trivial- is one of the very first proofs of a STM system. In that sense, this paper strives to contribute to the\u00a0\u2026", "num_citations": "10\n", "authors": ["495"]}
{"title": "Synchronization is coming back, but is it the same?\n", "abstract": " This invited talk surveys notions related to synchronization in presence of asynchrony and failures. To the author knowledge, there is currently no textbook in which these notions are pieced together, unified, and presented in a homogeneous way. This talk (that pretends to be neither exhaustive, nor objective) is only a first endeavor in that direction. The notions that are presented and discussed are listed in the keyword list.", "num_citations": "10\n", "authors": ["495"]}
{"title": "Early-stopping k-set agreement in synchronous systems prone to any number of process crashes\n", "abstract": " The k-set agreement problem is a generalization of the consensus problem: each process proposes a value, and each non-faulty process has to decide a value such that a decided value is a proposed value, and no more than k different values are decided.             This paper presents a surprisingly simple protocol that solves the k-set agreement problem in synchronous systems prone to up to t<n processes can crash (where n is the total number of processes). The proposed protocol is the first early stopping k-set agreement protocol that does not impose a constraint on t. It allows the processes to decide and stop by min  rounds where f is the number of actual crashes (0\u2264 f \u2264 t). In addition to its conceptual simplicity, the protocol has an additional noteworthy feature, namely, it is particularly efficient in common case scenarios. This comes from the fact that it is based on a mechanism that allows\u00a0\u2026", "num_citations": "10\n", "authors": ["495"]}
{"title": "Consistent checkpointing for transaction systems\n", "abstract": " Whether it is for audit or for recovery purposes, data checkpointing is an important problem of transaction systems. Actually, transactions establish dependence relations on data checkpoints taken by data object managers. So, given an arbitrary set of data checkpoints (including at least a single data checkpoint from a data manager, and at most a data checkpoint from each data manager), an important question is the following one: \u2018Can these data checkpoints be members of a same consistent global checkpoint?\u2019 This paper answers this question by providing a necessary and sufficient condition suited to transaction systems. Moreover, to show its usefulness, two non-intrusive data checkpointing protocols are designed from this condition.", "num_citations": "10\n", "authors": ["495"]}
{"title": "Tracking causality in distributed systems: a suite of efficient protocols\n", "abstract": " Vector clocks are the appropriate mechanism to track causality among the events produced by a distributed computation. Traditional implementations of vector clocks require application messages to piggyback a vector of n integers (where n is the number of processes). This paper considers the tracking of the causality relation on a subset of events (namely, the events that are defined as \u201crelevant\u201d from the application point of view). It first proposes simple and efficient implementations of vector clocks where the size of message timestamps can be less than n, in a context where communication channels are not required to be FIFO, and where there is no a priori information on the connectivity of the communication graph or the communication pattern. Then, it presents a protocol that provides a correct timestamping of the relevant events in presence of the following constraint: a message timestamp can piggyback at most b event identifiers (where b is a predefined constant, 1\u2264 b\u2264 n). To ensure this constraint, processes can be forced to produce additional \u201cnull\u201d relevant events. Finally, the paper presents and proves correct a protocol that tracks (on-thefly and without the help of an external observer) the immediate predecessors of each relevant event.", "num_citations": "10\n", "authors": ["495"]}
{"title": "Revisiting the non-blocking atomic commitment problem in distributed systems\n", "abstract": " Agreement problems allow a set of processes to agree on a common output value. These problems are of primary importance in distributed systems and di cult to solve in presence of failures. This paper considers one of these problems whose practical interest is well known, namely the Non-Blocking Atomic Commitment Problem. First, a generic protocol solving this problem is given and then instantiations of its generic statements are provided for both synchronous and asynchronous distributed systems. These instantiations use timeout mechanism, reliable multicast primitives and unreliable failure detectors as basic components. Incidentally, this paper can also be considered as an introduction to state-of-the-art concepts and mechanisms of distributed fault tolerance.", "num_citations": "10\n", "authors": ["495"]}
{"title": "An implementation of global flush primitives using counters\n", "abstract": " We present an implementation of Global-Flush Primitives using counters. This implementation costs comparable to the most lightweight implementation of causal ordering. Thus, at a comparable cost, the presented implementation enriches functionality compared to causal ordering; as Global-Flush Primitives permit making an assertion about messages sent in the past of sending m, in the future of sending m, about both, or neither, where the past and the future of an event is defined using the relation \"happened before.\" Using Global-Flush, a message can be sent to any subset of processes specified as a parameter.", "num_citations": "10\n", "authors": ["495"]}
{"title": "Specification and verification of behavioral patterns in distributed computations\n", "abstract": " The ability to specify and verify dynamic properties of computations is essential for ascertaining the dependability of distributed systems engaged in critical applications. In this paper, we consider properties that can be encoded as general Boolean predicates over global system states. We introduce two global predicate classes called simple sequences and interval-constrained sequences for specifying desirable states in some causality-preserving order along with intervening undesired states. Our formalism is simpler than more traditional proposals and permits concise and intuitive expression of many interesting system properties. Algorithms are given for verifying formulas belonging to these predicate classes in an on-line and observer-independent manner during distributed computations. We illustrate the utility of our results by applying them to examples drawn from program testing, debugging and\u00a0\u2026", "num_citations": "10\n", "authors": ["495"]}
{"title": "A characterization of a particular class of distributed snapshots\n", "abstract": " Computing consistent snapshots is a major problem in distributed systems and computations. A snapshot is made of the computing nodes states and of the network channels contents (ie the messages in transit taken at a given time). A subset of the states that a computation may reach can be defined by a stability predicate P. If P is true for some state S then it is also true for every state reachable from S. Several algorithms detecting the occurrence of stability properties are known. In this paper we focus on a particular class of instable global states: the states with no in transit message. A characterization of these states and their interest are given, then algorithmic techniques are exposed (markers, message counting, network traversal) to lay down the snapshot definition properties.", "num_citations": "10\n", "authors": ["495"]}
{"title": "A necessary condition for byzantine k-set agreement\n", "abstract": " This short paper presents a necessary condition for Byzantine k-set agreement in (synchronous or asynchronous) message-passing systems and asynchronous shared memory systems where the processes communicate through atomic single-writer multi-reader registers. It gives a proof, which is particularly simple, that k-set agreement cannot be solved t-resiliently in an n-process system when n\u2264 2 t+ t k. This bound is tight for the case k= 1 (Byzantine consensus) in synchronous message-passing systems.", "num_citations": "9\n", "authors": ["495"]}
{"title": "Read/write shared memory abstraction on top of asynchronous byzantine message-passing systems\n", "abstract": " This paper is on the construction and use of a shared memory abstraction on top of an asynchronous message-passing system in which up to t processes may commit Byzantine failures. This abstraction consists of arrays of n single-writer/multi-reader atomic registers, where n is the number of processes. These registers enable Byzantine tolerance by recording the whole history of values written to each one of them. A distributed algorithm building such a shared memory abstraction is first presented. This algorithm assumes t< n/3, which is shown to be a necessary and sufficient condition for such a construction. Hence, the algorithm is resilient-optimal. Then the paper presents distributed objects built on top of this read/write shared memory abstraction, which cope with Byzantine processes. As illustrated by these objects, the proposed shared memory abstraction is motivated by the fact that, for a lot of problems\u00a0\u2026", "num_citations": "9\n", "authors": ["495"]}
{"title": "Computing in the presence of concurrent solo executions\n", "abstract": " In a wait-free model any number of processes may crash. A process runs solo when it computes its local output without receiving any information from other processes, either because they crashed or they are too slow. While in wait-free shared-memory models at most one process may run solo in an execution, any number of processes may have to run solo in an asynchronous wait-free message-passing model.               This paper is on the computability power of models in which several processes may concurrently run solo. It first introduces a family of round-based wait-free models, called the d-solo models, 1\u2009\u2264\u2009d\u2009\u2264\u2009n, where up to d processes may run solo. The paper gives then a characterization of the colorless tasks that can be solved in each d-solo model. It also introduces the (d,\u03b5)-solo approximate agreement task, which generalizes \u03b5-approximate agreement, and proves that (d,\u03b5)-solo\u00a0\u2026", "num_citations": "9\n", "authors": ["495"]}
{"title": "From the happened-before relation to the causal ordered set abstraction\n", "abstract": " Several works in distributed systems have been designed based on the Happened-Before Relation (HBR). Most of these works intend to be efficient in their implementation by identifying and ensuring dependency constraints among single events. Even when the minimal causal dependencies among events have been clearly identified, the evolution of systems, which may involve a high number of processes and a high volume of transmitted data, calls for the need to design even more efficient approaches. This paper proposes the Causal Ordered Set Abstraction (CAOS) where the causally related events are arranged in sets that are strictly causally ordered. As for single events, CAOS establishes that any pair of resultant sets can be, and can only be, causally or concurrently related. We claim that our ordered set abstraction can be used to design more efficient algorithms based on the HBR principle. This assertion\u00a0\u2026", "num_citations": "9\n", "authors": ["495"]}
{"title": "From unreliable objects to reliable objects: the case of atomic registers and consensus\n", "abstract": " A concurrent object is an object that can be concurrently accessed by several processes. It has been shown by Maurice Herlihy that any concurrent object O defined by a sequential specification can be wait-free implemented from reliable atomic registers (shared variables) and consensus objects. Wait-free means that any invocation of an operation of the object O issued by a non-faulty process does terminate, whatever the behavior of the other processes (e.g., despite the fact they are very slow or even have crashed).               So, an important issue consists in providing reliable atomic registers and reliable consensus objects despite the failures experienced by the base objects from which these atomic registers and consensus objects are built. This paper considers self-implementations, i.e., the case where a reliable atomic register (resp., consensus object) is built from unreliable atomic registers (resp\u00a0\u2026", "num_citations": "9\n", "authors": ["495"]}
{"title": "On the Respective Power of/spl Lozenge/P and/spl Lozenge/S to Solve One-Shot Agreement Problems\n", "abstract": " Unreliable failure detectors are abstract devices that, when added to asynchronous distributed systems, enable solving distributed computing problems (e.g., consensus) that otherwise would be impossible to solve in these systems. This paper focuses on two classes of failure detectors defined by Chandra and Toueg, namely, the classes denoted diamP (eventually perfect) and diamS (eventually strong). Both classes include failure detectors that eventually detect permanently all process crashes, but while the failure detectors of diamP eventually make no erroneous suspicions, the failure detectors of diamS are only required to eventually not suspect a single correct process. Informally, in a one-shot agreement problem, a new problem instance is created each time the processes propose new values to be decided on (e.g., consensus is one-shot). In such a context, this paper addresses the following question related\u00a0\u2026", "num_citations": "9\n", "authors": ["495"]}
{"title": "Failure detectors as schedulers (an algorithmically-reasoned characterization)\n", "abstract": " This paper presents a new approach to study unreliable failure detectors. It uses the \\emph{iterated immediate snapshot model} (IIS) to capture the precise amount of synchrony achievable by a failure detector. The IIS model is a round-based model consisting of one-shot objects that provide processes with a single operation to atomically write and snapshot the shared memory. In a wait-free asynchronous manner, processes access a predefined sequence of one-shot immediate snapshot objects. This model is equivalent (for wait-free task solvability) to the usual read/write shared memory model, but its runs are more structured and easier to analyze. It has already been instrumental in other works. The paper studies three known failure detector classes $\\{\\Diamond {\\cal S}_x\\}_{1\\leq x\\leq n}$, , and $\\{\\Diamond {\\psi}^y\\}_{1\\leq y\\leq n}$, via the IIS model ( or  are parameters that specify the scope of the corresponding failure detector class). It identifies restrictions of the IIS model that characterize the power of each of these classes. These restrictions are captured as additional properties that the underlying immediate snapshot objects have to satisfy, in essence, obtaining a subset of IIS runs. For each failure detector class , it is shown that the basic read/write model enriched with  and a restricted IIS model have the same computational power for wait-free solvable tasks. Immediate applications of these results are new lower bound proofs for -set agreement in asynchronous systems enriched with a failure detector of each one of these classes. The proofs are simple, using novel distributed simulations, and shed light both to the IIS\u00a0\u2026", "num_citations": "9\n", "authors": ["495"]}
{"title": "Ordering vs Timeliness: Two Facets of Consistency?\n", "abstract": " Distributed applications are characterized by the fact that the processes they are made up of execute on possibly geographically dispersed nodes. An important problem the underlying distributed system has to solve lies in maintaining the consistency of the state that is shared by such processes. Unfortunately, the non-instantaneity of message transmissions and failure occurrences make this fundamental task far from being trivial. Of course, this difficulty depends on the type of consistency required by the application. Distributed programming models based on shared variables have been advocated by many researchers. Basically, a consistency criterion states which value has to be returned when a process reads a variable of the shared state. We think that there are two basic axes that help characterize consistency criteria: ordering and timeliness. The ordering axis defines the possible orders in which\u00a0\u2026", "num_citations": "9\n", "authors": ["495"]}
{"title": "Quiescent uniform reliable broadcast as an introduction to failure detector oracles\n", "abstract": " This paper is a short and informal introduction to failure detector oracles for asynchronous distributed systems prone to process crashes and fair lossy channels. A distributed coordination problem (the implementation of Uniform Reliable Broadcast with a quiescent protocol) is used as a paradigm to visit two types of such oracles. One of them is a \u201cguessing\u201d oracle in the sense that it provides a process with information that the processes could only approximate if they had to compute it. The other is a \u201chiding\u201d oracle in the sense that it allows to isolate and encapsulate the part of a protocol that has not the required behavioral properties. A quiescent uniform reliable broadcast protocol is described. The guessing oracle is used to ensure the \u201cuniformity\u201d requirement stated in the problem specification. The hiding oracle is used to ensure the additional \u201cquiescence\u201d property that the protocol behavior has to satisfy.", "num_citations": "9\n", "authors": ["495"]}
{"title": "Time, clocks and temporal order\n", "abstract": " Reposit\u00f3rio da Universidade de Lisboa: Time, clocks and temporal order Skip navigation P\u00e1gina principal Percorrer Comunidades & Colec\u00e7\u00f5es Percorrer Itens por: Data de publica\u00e7\u00e3o Autor Orientador T\u00edtulo Assunto Tipo de Documento Tipo de Acesso \u00cdndice de Autoridade Idioma portugu\u00eas english Entrar \u00c1rea Pessoal Servi\u00e7o de alertas Editar conta Reposit\u00f3rio da Universidade de Lisboa logo 1.Reposit\u00f3rio da Universidade de Lisboa 2.Comunidades & Colec\u00e7\u00f5es 3.Faculdade de Ci\u00eancias (FC) 4.Departamento de Inform\u00e1tica / Department of Informatics (FC-DI) 5.Lasige - Large-Scale Informatics Systems Laboratory (FC-DI-Lasige) 6.FC-DI-Lasige - Articles in International Journals Utilize este identificador para referenciar este registo: http://hdl.handle.net/10451/14432 T\u00edtulo: Time, clocks and temporal order Autor: P. Ver\u00edssimo M. Raynal Editor: S. Krakowiak SK Shrivastava Palavras-chave: Computer Science Data: \u2026", "num_citations": "9\n", "authors": ["495"]}
{"title": "Fault-tolerant distributed systems: a modular approach to the non-blocking atomic commitment problem\n", "abstract": " Agreement problems allow a set of processes to agree on a common output value. These problems are of primary importance in distributed systems and difficult to solve in presence of failures. This paper considers one of these problems whose practical interest is well known, namely the Non-Blocking Atomic Commitment Problem. First, a generic protocol solving this problem is given and then instantiations of its generic statements are provided for both synchronous and asynchronous distributed systems. These instantiations use timeout mechanism, reliable multicast primitives and unreliable failure detectors as basic components. Incidentally, this paper can also be considered as an introduction to state-of-the-art concepts and mechanisms of distributed fault tolerance.", "num_citations": "9\n", "authors": ["495"]}
{"title": "Causal deliveries in unreliable networks with real-time delivery constraints\n", "abstract": " Causal order states that for any process the order in which it is delivered messages cannot violate the \\em happened-before relation of the corresponding sendings. The aim of this communication abstraction is to cope with the asynchrony of communication channels in distributed systems. This abstraction has been defined for distributed systems without real-time delivery constraints. In this paper we extend this abstraction to cope with unreliable communication networks with real-time delivery constraints: messages have a lifetime, $\\Dter which their contentsaiai can no longer be used, moreover some of them can be lost. This new abstraction, called $\\Dal order, requires to delivers s as much messages as possible within their lifetime in such a way that these deliveries respect causal order. A simple efficient implementation is proposed. Examples of distributed multimedia real-time applications, in which scheduling messages deliveries respecting $\\Dal order is a crucial point for the quality ofarar the service, are given.", "num_citations": "9\n", "authors": ["495"]}
{"title": "Assigning distinct identities to sites on an anonymous distributed system\n", "abstract": " A distributed algorithm that assigns distinct and ordered identities to the sites of a connect anonymous distributed system is presented. The basis for this algorithm is the sequential distributed traversal scheme, the sequential aspect of which ensures that all sites are systematically visited in mutual exclusion. Such an algorithm allows the definition of sites to be independent of particular of initial values (as far as identities are concerned).< >", "num_citations": "9\n", "authors": ["495"]}
{"title": "Specification of properties is required to verify distributed algorithms\n", "abstract": " Specification of properties is required to verify distributed algorithms - OpenGrey fra | eng OpenGrey Open System for Information on Grey literature in Europe Home Search Subjects Partners Export Help Search XML To cite or link to this reference: http://hdl.handle.net/10068/59299 Title : Specification of properties is required to verify distributed algorithms De la necessite de specifier des proprietes pour la verification des algorithmes distribues Authors : Jard, Claude ; Raynal, Michel ; Corporate author : Institut National de Recherche en Informatique et en Automatique (INRIA), 35 - Rennes (France) ; Centre National de la Recherche Scientifique (CNRS), 35 - Rennes (France). Inst. de Recherche en Informatique et Systemes Aleatoires (IRISA). ; Institut National des Sciences Appliquees de Rennes (INSA), 35 (France). Inst. de Recherche en Informatique et Systemes Aleatoires (IRISA) ; Publication year : 1986 : French ; '\u2026", "num_citations": "9\n", "authors": ["495"]}
{"title": "Types in a mixed language system\n", "abstract": " As a support for writing software, a comprehensive set of problem oriented languages appears preferable to any so-called universal language, as soon as static checking is sufficient to ensure type correctness of the mixed language program. We lay the basis for a mixed language system where this requirement is fulfilled. The general outline of the system is first sketched. Detailed consideration is then given to our basic constructs for establishing communication between languages, namely \u201cstandard\u201d types and \u201cforeign\u201d types. \u201cAbstract\u201d types, such as defined in CLU, are finally shown to be a particular class of \u201cforeign\u201d types.", "num_citations": "9\n", "authors": ["495"]}
{"title": "Simple and efficient reliable broadcast in the presence of byzantine processes\n", "abstract": " This paper presents a surprisingly simple and efficient reliable broadcast algorithm for asynchronous message-passing systems made up of  processes, among which up to  may behave arbitrarily (Byzantine processes). This algorithm requires two communication steps and  messages. (The best algorithm known so far requires three communication steps and  messages.)", "num_citations": "8\n", "authors": ["495"]}
{"title": "Bio-economic modeling of wine grape protection strategies for environmental policy assessment\n", "abstract": " This research had two objectives. The first was to model the behaviour of wine producers, and the second was to assess the effectiveness of policies designed to reduce pesticide use in viticulture. We modeled the decisions of producers aiming to maximize their expected income while subject to a number of constraints and phytosanitary risks. We also examined the impacts of different protection strategies targeting downy mildew, the main grape disease in European Atlantic vineyards. The Vineyard model for Environmental Policy Analysis (VINEPA) model is a multi-periodic stochastic programming model based on panel data of about one hundred representative winegrowing farms from the Farm Accountancy Data Network in the Bordeaux region. The response of vines to fungicide treatments against downy mildew was simulated through the downy mildew potential system, an epidemiologic model initially\u00a0\u2026", "num_citations": "8\n", "authors": ["495"]}
{"title": "What can be computed in a distributed system?\n", "abstract": " Not only the world is distributed, but more and more applications are distributed. Hence, a fundamental question is the following one: What can be computed in a distributed system? The answer to this question depends on the environment in which evolves the considered distributed system, i.e., on the assumptions the system relies on. This environment is very often left implicit and nearly always not formulated in terms of precise underlying requirements. In the extreme case where the environment is such that there is no synchrony assumption and the computing entities may commit failures, many problems become impossible to solve (in these cases, a network of Turing machines where some machines may crash, is less powerful than a single reliable Turing machine). Given a distributed computing problem, it is consequently important to know the weakest assumptions (lower bounds) that give the limits\u00a0\u2026", "num_citations": "8\n", "authors": ["495"]}
{"title": "Brief announcement: a contention-friendly, non-blocking skip list\n", "abstract": " A skip list is a probabilistic data structure to store and retrieve in-memory data in an efficient way. In short, it is a linked structure that diminishes the linear big-oh complexity of a linked list with elements having additional shortcuts pointing towards other elements located further in the list [7]. These shortcuts allow operations to complete in O(logn) steps in expectation. The drawback of employing shortcuts is however to require additional maintenance each time some data is stored or discarded.", "num_citations": "8\n", "authors": ["495"]}
{"title": "Read invisibility, virtual world consistency and permissiveness are compatible\n", "abstract": " The aim of a Software Transactional Memory (STM) is to discharge the programmers from the management of synchronization in multiprocess programs that access concurrent objects. To that end, a STM system provides the programmer with the concept of a transaction. The job of the programmer is to design each process the application is made up of as a sequence of transactions. A transaction is a piece of code that accesses concurrent objects, but contains no explicit synchronization statement. It is the job of the underlying STM system to provide the illusion that each transaction appears as being executed atomically. Of course, for efficiency, a STM system has to allow transactions to execute concurrently. Consequently, due to the underlying STM concurrency management, a transaction commits or aborts. This paper studies the relation between two STM properties (read invisibility and permissiveness) and two consistency conditions for STM systems, namely, opacity and virtual world consistency. Both conditions ensures that any transaction (be it a committed or an aborted transaction) reads values from a consistent global state, a noteworthy property if one wants to prevents abnormal behavior from concurrent transactions that behave correctly when executed alone. A read operation issued by a transaction is invisible if it does not entail shared memory modifications. This is an important property that favors efficiency and privacy. An STM system is permissive with respect to a consistency condition if it accepts every history that satisfies the condition. This is a crucial property as a permissive STM system never aborts a transaction \u201cfor free\u201d. The\u00a0\u2026", "num_citations": "8\n", "authors": ["495"]}
{"title": "Failure detectors to solve asynchronous k-set agreement: a glimpse of recent results\n", "abstract": " In the k-set agreement problem, each process proposes a value and has to decide a value in such a way that a decided value is a proposed value and at most k different values are decided. This problem can easily be solved in synchronous systems or in asynchronous systems prone to t process crashes when t < k. In contrast, it has been shown that k-set agreement cannot be solved in asynchronous systems when k < t. Hence, since several years, the failure detector-based approach has been investigated to circumvent this impossibility. This approach consists in enriching the underlying asynchronous system with an additional module per process that provides it with information on failures. Hence, without becoming synchronous, the enriched system is no longer fully asynchronous. This paper surveys this approach in both asynchronous shared memory systems and asynchronous message passing systems. It presents and discusses recent results and associated k-set agreement algorithms.", "num_citations": "8\n", "authors": ["495"]}
{"title": "On adaptive renaming under eventually limited contention\n", "abstract": " The adaptive M-renaming problem consists in designing an algorithm that allows a set of p\u2009\u2264\u2009n participating asynchronous processes (where n is the total number of processes) not known in advance to acquire pair-wise different new names in a name space whose size M depends on p (and not on n). Adaptive (2p\u2009\u2212\u20091)-renaming algorithms for read/write shared memory systems have been designed. These algorithms, which are optimal with respect to the value of M, consider the wait-freedom progress condition, which means that any correct participant has to acquire a new name whatever the behavior of the other processes (that can be very slow or even crashed).               This paper addresses the design of an adaptive M-renaming algorithm when considering the k-obstruction-freedom progress condition. This condition, that is weaker than wait-freedom, requires that every correct participating process\u00a0\u2026", "num_citations": "8\n", "authors": ["495"]}
{"title": "Locks considered harmful: a look at non-traditional synchronization\n", "abstract": " This paper considers the implementation of concurrent objects in systems prone to asynchrony and process failures. It first shows that lock-based solutions have drawbacks that can make them redhibitory for systems deployed in very demanding environments, such as embedded systems. Then, considering the adaptive renaming problem as a paradigm of coordination and synchronization problems, the paper investigates wait-free implementations of an adaptive renaming object (wait-free means that these implementations do not rest on locks or waiting loops). This problem consists in assigning new distinct names (to the subset of processes that want to acquire a new name) in such a way that the new name space be as small as possible.               The best that can be done in asynchronous systems prone to process crashes, and where the processes communicate only through read/write atomic registers\u00a0\u2026", "num_citations": "8\n", "authors": ["495"]}
{"title": "On modeling fault tolerance of gossip-based reliable multicast protocols\n", "abstract": " Gossiping has been widely used for disseminating data in large scale networks. Existing works have mainly focused on the design of gossip-based protocols but few have been reported on developing models for analyzing the fault tolerance property of these protocols. In this paper, we propose a general gossiping algorithm and develop a mathematical model based on generalized random graphs for evaluating the reliability of gossiping, i.e., to what extent gossip-based protocols can tolerate node failures, yet guarantee the specified message delivery. We analytically derive the maximum ratio of failed nodes that can be tolerated without reducing the required degree of reliability. We also investigate the impact of the parameters, namely the fanout distribution and the non failed member ratio, on the protocol reliability. Simulations have been carried out to validate the effectiveness of our analytic model in terms of the\u00a0\u2026", "num_citations": "8\n", "authors": ["495"]}
{"title": "Tracking immediate predecessors in distributed computations\n", "abstract": " A distributed computation is usually modeled as a partially ordered set of relevant events (the relevant events are a subset of the primitive events produced by the computation). An important causality-related distributed computing problem, that we call the Immediate Predecessors Tracking (IPT) problem, consists in associating with each relevant event, on the fly and without using additional control messages, the set of relevant events that are its immediate predecessors in the partial order. So, IPT is the on-the-fly computation of the transitive reduction (ie, Hasse diagram) of the causality relation defined by a distributed computation. This paper addresses the IPT problem: it presents a family of protocols that provides each relevant event with a timestamp that exactly identifies its immediate predecessors. The family is defined by a general condition that allows application messages to piggyback control information whose\u00a0\u2026", "num_citations": "8\n", "authors": ["495"]}
{"title": "Illustrating the use of vector clocks in property detection: An example and a counter-example\n", "abstract": " Logical (scalar, vector or matrix) clocks are a powerful mechanism used by a lot of distributed algorithms. This paper is on vector clocks: it surveys their main features and is particularly focused on their power and their limitation. In that sense, this paper complements [5, 6] and may be seen as a critical and practical introduction to vector clocks.               The paper is divided into four main sections. Section 2 introduces a model for distributed executions. Section 3 describes vector clocks and their basic properties. Vector clocks are a simple mechanism that allows processes to track causality between the events they produce. Then, Section 4 and Section 5 study two problems related to causality. The first problem consists in detecting a conjunction of stable local predicates. The second problem consists in recognizing the occurrence of a very simple event pattern. It is shown that simple vector clocks are\u00a0\u2026", "num_citations": "8\n", "authors": ["495"]}
{"title": "Efficient distributed detection of conjunctions of local predicates\n", "abstract": " Global predicate detection is a fundamental problem in distributed systems and finds applications in many domains such as testing and debugging distributed programs. This paper presents two efficient distributed algorithms to detect conjunctive form global predicates in distributed systems. The algorithms detect the first consistent global state that satisfies the predicate even if the predicate is unstable. The algorithms are based on complementary approaches and are dual of each other. The algorithms are distributed because the predicate detection efforts as well as the necessary information is equally distributed among the processes. We prove the correctness of the algorithms and compare their performance with those of the existing predicate detection algorithms. The proposed algorithms compare very favorably with the existing algorithms in terms of the number of messages exchanged for predicate detection.", "num_citations": "8\n", "authors": ["495"]}
{"title": "An efficient implementation of sequentially consistent distributed shared memories\n", "abstract": " Recently, distributed shared memory systems have received much attention because such an abstraction simplifies programming. In this paper, we present a data consistency protocol for a distributed system which implements sequentially consistent memories. The protocol is aimed at an environment where no special support for atomic broadcast exists. As compared to previously proposed protocols, our protocol eliminates the need of atomic broadcast and significantly reduces the amount of information flow among the processors. This is realized by maintaining state information and capturing causal relations among read and write operations.", "num_citations": "8\n", "authors": ["495"]}
{"title": "Communication efficient distributed shared memories\n", "abstract": " Recently distributed shared memory (DSM) systems have received much attention because such an abstraction simplifies programming. An important class of DSM implementations is one which uses cache memories to improve efficiency. In this paper, we present a cache-consistency protocol which uses considerably less communication as compared to previously proposed protocols. This is realized by maintaining state information and capturing causal relations among read and write operations. We prove that the protocol satisfies a formulation of sequential consistency. We also present several modifications to the protocol and compare the classes of execution histories captured by these protocols and several previously.proposed protocols.", "num_citations": "8\n", "authors": ["495"]}
{"title": "Virtual ring construction in parallel distributed systems\n", "abstract": " Many distributed systems and applications use decentralized control algorithms lying on a predefined virtual ring. Such a structure is usually statically defined, and is thus inherent to the system definition. Ring construction distributed algorithms are proposed. First, distributed depth-first traversal algorithms are shown to be an algorithmic basis for the construction of such a structure. Then, a ring construction algorithm is presented; its time and message complexities are equal to 2 (n\u2212 1) with O (n) size of messages, where n is the number of processes. A ring traversal requires 2 (n\u2212 1) messages. This algorithm is then improved: it allows building of a virtual ring whose traversal requires p messages, where n\u2264 p\u2264 2 (n\u2212 1).", "num_citations": "8\n", "authors": ["495"]}
{"title": "A distributed algorithm for mutual exclusion in an arbitrary network\n", "abstract": " Un algorithme distribu\u00e9 offrant. un service d'exclusion mutuelle dans un r\u00e9seau est pr\u00e9sent\u00e9. Aucune hypoth\u00e8se particuli\u00e8re n'est Faite sur le graphe qui mod\u00e9lise le r\u00e9seau si ce n\u2019est sa connexit\u00e9; celui-ci peut donc \u00eatre quel-conque. L'algorithme est distribu\u00e9 non seulement par les outils qu'il utilise [communication de messages) et l\u2019absence d'un processus qui jouerait le r\u00f4le d'un contr\u00f4leur central mais surtout par le fait qu'un site donn\u00e9 n'a jamais besoin de conna\u00eetre la structure globale du r\u00e9seau. Il est donc en ce sens plus g\u00e9n\u00e9ral que les algorithmes d'exclusion mutuelle distribu\u00e9s qui supposent d'une part un maille-ge complet ou un anneau et d'autre part la connaissance a priori de cette structure par les divers sites. L\u2019algorithme est prouv\u00e9 correct et sa complexit\u00e9 analys\u00e9e [en terme du nombre de messages n\u00e9cessaires \u00e0 la r\u00e9alisation d'une exclusion]. x", "num_citations": "8\n", "authors": ["495"]}
{"title": "Self-stabilizing uniform reliable broadcast\n", "abstract": " We study a well-known communication abstraction called Uniform Reliable Broadcast (URB). URB is central in the design and implementation of fault-tolerant distributed systems, as many non-trivial fault-tolerant distributed applications require communication with provable guarantees on message deliveries. Our study focuses on fault-tolerant implementations for time-free message-passing systems that are prone to node-failures. Moreover, we aim at the design of an even more robust communication abstraction. We do so through the lenses of self-stabilization\u2014a very strong notion of fault-tolerance. In addition to node and communication failures, self-stabilizing algorithms can recover after the occurrence of arbitrary transient faults; these faults represent any violation of the assumptions according to which the system was designed to operate (as long as the algorithm code stays intact). We propose the first self-stabilizing URB\u00a0\u2026", "num_citations": "7\n", "authors": ["495"]}
{"title": "Collisions are preferred: Rfid-based stocktaking with a high missing rate\n", "abstract": " RFID-based stocktaking uses RFID technology to verify the presence of objects in a region e.g., a warehouse or a library, compared with an inventory list. The existing approaches for this purpose assume that the number of missing tags is small. This is not true in some cases. For example, for a handheld RFID reader, only the objects in a larger region (e.g., the warehouse) rather than in its interrogation region can be known as the inventory list, and hence many tags in the list are regarded as missing. The missing objects significantly increase the time required for stocktaking. In this paper, we propose an algorithm called CLS (Coarse-grained inventory list based stocktaking) to solve this problem. CLS enables multiple missing objects to hash to a single time slot and thus verifies them together. CLS also improves the existing approaches by utilizing more kinds of RFID collisions and reducing approximately one-fourth\u00a0\u2026", "num_citations": "7\n", "authors": ["495"]}
{"title": "A fast contention-friendly binary search tree\n", "abstract": " This paper presents a fast concurrent binary search tree algorithm. To achieve high performance under contention, the algorithm divides update operations within an eager abstract access that returns rapidly for efficiency reason and a lazy structural adaptation that may be postponed to diminish contention. To achieve high performance under read-only workloads, it features a rebalancing mechanism and guarantees that read-only operations searching for an element execute lock-free. We evaluate the contention-friendly binary search tree using Synchrobench, a benchmark suite to compare synchronization techniques. More specifically, we compare its performance against five state-of-the-art binary search trees that use locks, transactions or compare-and-swap for synchronization on Intel Xeon, AMD Opteron and Oracle SPARC. Our results show that our tree is more efficient than other trees and double the\u00a0\u2026", "num_citations": "7\n", "authors": ["495"]}
{"title": "Eventual leader election despite crash-recovery and omission failures\n", "abstract": " In this work we consider the problem of leader election, abstraction used by many distributed services to select a unique process for coordinating actions. We propose an eventual leader election algorithm for partially synchronous systems prone to concurrent crash-recovery and omission failures where any process may suffer failures forever as long as a majority of processes meet some weak connectivity and reliability conditions.", "num_citations": "7\n", "authors": ["495"]}
{"title": "Trust-aware peer sampling: Performance and privacy tradeoffs\n", "abstract": " The ability to identify people that share one\u2019s own interests is one of the most interesting promises of the Web 2.0 driving user-centric applications such as recommendation systems or collaborative marketplaces. To be truly useful, however, information about other users also needs to be associated with some notion of trust. Consider a user wishing to sell a concert ticket. Not only must she find someone who is interested in the concert, but she must also make sure she can trust this person to pay for it.This paper addresses the need for trust in user-centric applications by proposing two novel distributed protocols that combine interest-based connections between users with explicit links obtained from social networks \u00e0-la Facebook. Both protocols build trusted multi-hop paths between users in an explicit social network supporting the creation of semantic overlays backed up by social trust. The first protocol, TAPS2\u00a0\u2026", "num_citations": "7\n", "authors": ["495"]}
{"title": "Simultaneous consensus vs set agreement: a message-passing-sensitive hierarchy of agreement problems\n", "abstract": " This paper investigates the relation linking the s-simultaneous consensus problem and the k-set agreement problem in wait-free message-passing systems. To this end, it first defines the (s,k)-SSA problem which captures jointly both problems: each process proposes a value, executes s simultaneous instances of a k-set agreement algorithm, and has to decide a value so that no more than sk different values are decided. The paper introduces then a new failure detector class denoted Z                                                     s,k                         , which is made up of two components, one focused on the \u201cshared memory object\u201d that allows the processes to cooperate, and the other focused on the liveness of (s,k)-SSA algorithms. A novelty of this failure detector lies in the fact that the definition of its two components are intimately related. Then, the paper presents a Z                                                     s,k                         -based\u00a0\u2026", "num_citations": "7\n", "authors": ["495"]}
{"title": "On the implementation of concurrent objects\n", "abstract": " The implementation of objects shared by concurrent processes, with provable safety and liveness guarantees, is a fundamental issue of concurrent programming in shared memory systems. It is now largely accepted that linearizability (or atomicity) is an appropriate consistency condition for concurrent objects. On the liveness side, progress conditions (mainly absence of deadlock or the stronger absence of starvation) have been stated and investigated for a long time and are now well-mastered. The situation is different in asynchronous shared memory systems prone to process failures.               This paper visits three progress conditions suited to concurrent objects in presence of failures, namely obstruction-freedom, non-blocking and wait-freedom. To that end, the paper also visits appropriate computation models and paradigm problems to illustrate this family of progress conditions. The paper has\u00a0\u2026", "num_citations": "7\n", "authors": ["495"]}
{"title": "Distributed Computing\n", "abstract": " DISC, the International Symposium on DIStributed Computing, is an international forum on the theory, design, analysis, implementation and application of distributed systems and networks. DISC is organized in cooperation with the European Association for Theoretical Computer Science (EATCS). This volume contains the papers presented at DISC 2010, the 24th International Symposium on Distributed Computing, held on September 13\u201315, 2010 in Cambridge, Massachusetts. The volume also includes the citation for the 2010 Edsger W. Dijkstra Prize in Distributed Computing, jointly sponsored by DISC and PODC (the ACM Symposium on Principles of Distributed Computing), which was presented at PODC 2010 in Zurich to Tushar D. Chandra, Vassos Hadzilacos, and Sam Toueg for their work on failure detectors. There were 135 papers submitted to the symposium (in addition there were 14 abstract-only\u00a0\u2026", "num_citations": "7\n", "authors": ["495"]}
{"title": "Shared Memory Synchronization in Presence of Failures: An Exercise-Based Introduction for the Sophomore\n", "abstract": " In the recent past, lots of papers have addressed synchronization in asynchronous shared memory systems prone to process crashes. Unfortunately, to date, nearly all these results have appeared only in theory-oriented journals and conferences, very few being presented and studied in textbooks. This aim of this paper is to give a flavor of a few of these fundamental results. To that end, it considers three problems and presents solutions proposed to solve them, emphasizing the basic concepts and techniques these solutions rely on. These problems have been selected because they address distinct facets of synchronization in presence of failures. So, the spirit of this introductory paper is mainly pedagogical (with an algorithmic taste).", "num_citations": "7\n", "authors": ["495"]}
{"title": "Decision optimal early-stopping k-set agreement in synchronous systems prone to send omission failures\n", "abstract": " The k-set agreement problem is a generalization of the consensus problem: each process proposes a value, and each non-faulty process has to decide a value such that a decided value is a proposed value, and no more than k different values are decided. This paper focuses on the k-set agreement problem in the context of synchronous systems where up to t < n processes can experience crash or send omission failures (n being the total number of processes). The paper presents a k-set agreement protocol for this failure model (the first to our knowledge) which has two main outstanding features. (1) It provides the following early deciding and stopping property: no process decides or halts after the round min(/spl lfloor/f/k/spl rfloor/ + 2, /spl lfloor/t/k/spl rfloor/ + 1) where f is the number of actual crashes (0 /spl les/ f /spl les/ t). (2) It is decision-optimal. This new optimality criterion, suited to the omission failure model\u00a0\u2026", "num_citations": "7\n", "authors": ["495"]}
{"title": "An efficient causal ordering algorithm for mobile computing environments\n", "abstract": " Causal message ordering is required for several distributed applications. In order to preserve causal ordering, only direct dependency information between messages, with respect to the destination process(es), should be sent with each message. By eliminating other kinds of control information from the messages, the communication overheads can be significantly reduced. In this paper we present an algorithm that uses this knowledge to efficiently enforce causal ordering of messages. The proposed algorithm does not require any prior knowledge of the network or communication topology. As computation proceeds, it acquires knowledge of the logical communication topology and is capable of handling dynamically changing multicast communication groups. With regard to communication overheads, the algorithm is optimal for the broadcast communication case. Its energy efficiency and low bandwidth requirement make it suitable for mobile computing systems. We present a strategy that employs the algorithm for causally ordered multicasting of messages in mobile computing environments.", "num_citations": "7\n", "authors": ["495"]}
{"title": "Money Transfer Made Simple: a Specification, a Generic Algorithm, and its Proof\n", "abstract": " It has recently been shown that, contrarily to a common belief, money transfer in the presence of faulty (Byzantine) processes does not require strong agreement such as consensus. This article goes one step further: namely, it first proposes a non-sequential specification of the money-transfer object, and then presents a generic algorithm based on a simple FIFO order between each pair of processes that implements it. The genericity dimension lies in the underlying reliable broadcast abstraction which must be suited to the appropriate failure model. Interestingly, whatever the failure model, the money transfer algorithm only requires adding a single sequence number to its messages as control information. Moreover, as a side effect of the proposed algorithm, it follows that money transfer is a weaker problem than the construction of a safe/regular/atomic read/write register in the asynchronous message-passing crash-prone model.", "num_citations": "6\n", "authors": ["495"]}
{"title": "Byzantine-tolerant set-constrained delivery broadcast\n", "abstract": " Set-Constrained Delivery Broadcast (SCD-broadcast), recently introduced at ICDCN 2018, is a high-level communication abstraction that captures ordering properties not between individual messages but between sets of messages. More precisely, it allows processes to broadcast messages and deliver sets of messages, under the constraint that if a process delivers a set containing a message m before a set containing a message m, then no other process delivers first a set containing m and later a set containing m. It has been shown that SCD-broadcast and read/write registers are computationally equivalent, and an algorithm implementing SCD-broadcast is known in the context of asynchronous message passing systems prone to crash failures. This paper introduces a Byzantine-tolerant SCD-broadcast algorithm, which we call BSCD-broadcast. Our proposed algorithm assumes an underlying basic Byzantine-tolerant reliable broadcast abstraction. We first introduce an intermediary communication primitive, Byzantine FIFO broadcast (BFIFO-broadcast), which we then use as a primitive in our final BSCD-broadcast algorithm. Unlike the original SCD-broadcast algorithm that is tolerant to up to t< n/2 crashing processes, and unlike the underlying Byzantine reliable broadcast primitive that is tolerant to up to t< n/3 Byzantine processes, our BSCD-broadcast algorithm is tolerant to up to t< n/4 Byzantine processes. As an illustration of the high abstraction power provided by the BSCD-broadcast primitive, we show that it can be used to implement a Byzantine-tolerant read/write snapshot object in an extremely simple way.", "num_citations": "6\n", "authors": ["495"]}
{"title": "Distributed computing pearls\n", "abstract": " Computers and computer networks are one of the most incredible inventions of the 20th century, having an ever-expanding role in our daily lives by enabling complex human activities in areas such as entertainment, education, and commerce. One of the most challenging problems in computer science for the 21st century is to improve the design of distributed systems where computing devices have to work together as a team to achieve common goals. In this book, I have tried to gently introduce the general reader to some of the most fundamental issues and classical results of computer science underlying the design of algorithms for distributed systems, so that the reader can get a feel of the nature of this exciting and fascinating  field called distributed computing. The book will appeal to the educated layperson and requires no computer-related background. I strongly suspect that also most computer-knowledgeable\u00a0\u2026", "num_citations": "6\n", "authors": ["495"]}
{"title": "Agent-based broadcast protocols for wireless heterogeneous node networks\n", "abstract": " Abstract Internet of Things (IoT) is a wireless network composed of a variety of heterogeneous objects such as Connected Wearable Devices (sensors, smartwatches, smartphones, PDAs...), Connected Cars, Connected Homes,... etc. These things use generally wireless communication to interact and cooperate with each other to reach common goals. IoT (T, n) is a network of things composed of T things with n items (packets) distributed randomly on it. The aim of the permutation routing is to route to each thing, its items, so it can accomplish its task. In this paper, we propose two agent-based broadcast protocols for mobile IoT, using a limited number of communication channels. The main idea is to partition the things into groups where an agent in each group manages a group of things. This partitioning is based on the memory capacities for these heterogeneous nodes. The first protocol uses a few communication\u00a0\u2026", "num_citations": "6\n", "authors": ["495"]}
{"title": "Early decision and stopping in synchronous consensus: a predicate-based guided tour\n", "abstract": " Consensus is the most basic agreement problem encountered in fault-tolerant distributed computing: each process proposes a value and non-faulty processes must agree on the same value, which has to be one of the proposed values. While this problem is impossible to solve in asynchronous systems prone to process crash failures, it can be solved in synchronous (round-based) systems where all but one process might crash in any execution. It is well-known that $$(t+1)$$ rounds are necessary and sufficient in the worst case execution scenario for the processes to decide and stop executing, where $$t < n$$ is a system parameter denoting the maximum number of allowed process crashes and n denotes the number of processes in the system.                          Early decision and stopping considers the case where $$f<t$$ processes actually crash, f not being known by processes. It has been shown that\u00a0\u2026", "num_citations": "6\n", "authors": ["495"]}
{"title": "Implementing snapshot objects on top of crash-prone asynchronous message-passing systems\n", "abstract": " Distributed snapshots, as introduced by Chandy and Lamport in the context of asynchronous failure-free message-passing distributed systems, are consistent global states in which the observed distributed application might have passed through. It appears that two such distributed snapshots cannot necessarily be compared (in the sense of determining which one of them is the \u201cfirst\u201d). Differently, snapshots introduced in asynchronous crash-prone read/write distributed systems are totally ordered, which greatly simplify their use by upper layer applications.                 In order to benefit from shared memory snapshot objects, it is possible to simulate a read/write shared memory on top of an asynchronous crash-prone message-passing system, and build then snapshot objects on top of it. This algorithm stacking is costly in both time and messages. To circumvent this drawback, this paper presents algorithms\u00a0\u2026", "num_citations": "6\n", "authors": ["495"]}
{"title": "Optimal Collision/Conflict-Free Distance-2 Coloring in Wireless Synchronous Broadcast/Receive Tree Networks\n", "abstract": " This article is on message-passing systems where communication is (a) synchronous and (b) based on the \u201cbroadcast/receive\u201d pair of communication operations. \u201cSynchronous\u201d means that time is discrete and appears as a sequence of time slots (or rounds) such that each message is received in the very same round in which it is sent. \u201cBroadcast/receive\u201d means that during a round a process can either broadcast a message to its neighbors or receive a message from one of them. In such a communication model, no two neighbors of the same process, nor a process and any of its neighbors, must be allowed to broadcast during the same time slot (thereby preventing message collisions in the first case, and message conflicts in the second case). From a graph theory point of view, the allocation of slots to processes is known as the distance-2 coloring problem: a color must be associated with each process (defining the\u00a0\u2026", "num_citations": "6\n", "authors": ["495"]}
{"title": "Implementing set objects in dynamic distributed systems\n", "abstract": " This paper considers a set object, i.e., a shared object allowing users (processes) to add and remove elements to the set, as well as taking consistent snapshots of its content. Specifically, we show that there not exists any protocol implementing a set object, using finite memory, when the underlying distributed system is eventually synchronous and affected by continuous arrivals and departures of processes (phenomenon also known as churn). Then, we analyze the relationship between system model assumptions and object specification in order to design protocols implementing the set object using finite memory. Along one direction (strengthening the system model), we propose a protocol implementing the set object in synchronous distributed systems and, along the other direction (weakening the object specification), we introduce the notion of a k-bounded set object proposing a protocol working on an\u00a0\u2026", "num_citations": "6\n", "authors": ["495"]}
{"title": "A communication-efficient leader election algorithm in partially synchronous systems prone to crash-recovery and omission failures\n", "abstract": " Leader election is a key service for many dependable distributed systems. It eases the consistent management of replicas in current highly available computing scenarios. This paper presents a new leader election algorithm for crash-recovery and omission environments, in order to support fault-tolerant agreement protocols, eg, Paxos. As a novelty with respect to previous works, our algorithm tolerates the occurrence of both crash-recoveries and message omissions to any process during some finite but unknown time, assuming that eventually a majority of processes in the system remains up forever and stops omitting messages among them. Also, the proposed algorithm does not rely on stable storage and is communication-efficient, ie, eventually each process of the well-connected majority communicates only with the elected leader.", "num_citations": "6\n", "authors": ["495"]}
{"title": "Brief Announcement: Anonymous Obstruction-free (n, k)-Set Agreement with n\u2013k+ 1 Atomic Read/Write Registers\n", "abstract": " This paper presents an obstruction-free solution to the (n, k)-set agreement problem in an asynchronous anonymous read/write system using solely (n\u2212 k+ 1) registers. We then extend this algorithm into (i) a space-optimal solution for the repeated version of (n, k)-set agreement, and (ii) an x-obstruction-free solution using (n\u2212 k+ x) atomic registers (with 1\u2264 x\u2264 k< n).", "num_citations": "6\n", "authors": ["495"]}
{"title": "Fair synchronization in the presence of process crashes and its weakest failure detector\n", "abstract": " A non-blocking implementation of a concurrent object is an implementation that does not prevent concurrent accesses to the internal representation of the object, while guaranteeing the deadlock-freedom progress condition without using locks. Considering a failure free context, G. Taubenfeld has introduced (DISC 2013) a simple modular approach, captured under a new problem called the it fair synchronization problem, to transform a non-blocking implementation into a starvation-free implementation satisfying a strong fairness requirement. This paper extends this approach in several directions. It first generalizes the fair synchronization problem to read/write asynchronous systems where any number of processes may crash. Then, it introduces a new failure detector and uses it to solve the fair synchronization problem when processes may crash. This failure detector, denoted QP (Quasi Perfect), is very close to, but\u00a0\u2026", "num_citations": "6\n", "authors": ["495"]}
{"title": "Computability in distributed computing: a tutorial\n", "abstract": " What can and cannot be computed in a distributed system is a complex function of the system's communication model, timing model, and failure model. This tutorial surveys some important results about computability in the canonical distributed system model, where processes execute asynchronously, they communicate by reading and writing shared memory, and they fail by crashing. It explains the fundamental role that topology plays in the distributed computability theory.", "num_citations": "6\n", "authors": ["495"]}
{"title": "Eventual leader election with weak assumptions on initial knowledge, communication reliability, and synchrony\n", "abstract": " his paper considers the eventual leader election problem in asynchronous message-passing systems where an arbitrary number t of processes can crash (t < n, where n is the total number of processes). It considers weak assumptions both on the initial knowledge of the processes and on the network behavior. More precisely, initially, a process knows only its identity and the fact that the process identities are different and totally ordered (it knows neither n nor t). Two eventual leader election protocols and a lower bound are presented. The first protocol assumes that a process also knows a lower bound \u03b1 on the number of processes that do not crash. This protocol requires the following behavioral properties from the underlying network: the graph made up of the correct processes and fair lossy links is strongly connected, and there is a correct process connected to (n \u2212 f) \u2212 \u03b1 other correct processes (where f is\u00a0\u2026", "num_citations": "6\n", "authors": ["495"]}
{"title": "Early consensus in message-passing systems enriched with a perfect failure detector and its application in the theta model\n", "abstract": " While lots of consensus algorithms have been proposed for crash-prone asynchronous message-passing systems enriched with a failure detector of the class \u03a9 (the class of eventual leader failure detectors), very few algorithms have been proposed for systems enriched with a failure detector of the class P (the class of perfect failure detectors). Moreover, (to the best of our knowledge) the early decision and stopping notion has not been investigated in such systems. This paper presents an early-deciding/stopping P-based consensus algorithm. A process that does not crash decides (and stops) in at most min(f+2, t+1) rounds, where t is the maximum number of processes that may crash, and f the actual number of crashes (0\u2264 f\u2264 t). Differently from what occurs in a synchronous system, a perfect failure detector notifies failures asynchronously. This makes the design of an early deciding (and stopping) algorithm not\u00a0\u2026", "num_citations": "6\n", "authors": ["495"]}
{"title": "Using asynchrony and zero degradation to speed up indulgent consensus protocols\n", "abstract": " Existing consensus protocols suffer from slowdowns caused by the failures of processes and the mistakes made by the underlying oracles. In this paper, we propose two novel techniques to circumvent such slowdowns in failure-detector-based consensus protocols. The first technique guarantees the Round-Zero-Degradation (RZD) property (an extension of the Zero-Degradation property) in order to avoid the slowdown caused by a failed coordinator process. The second technique, named \u201cLook-Ahead\u201d, helps speed up the execution of the consensus protocol by making use of the messages delivered before their receivers enter the corresponding phases or rounds. The first technique is effective only when the underlying failure detector makes no or few mistakes, while the second technique always works well regardless of the performance of the failure detector. Moreover, Look-Ahead is a general technique and\u00a0\u2026", "num_citations": "6\n", "authors": ["495"]}
{"title": "The notion of a timed register and its application to indulgent synchronization\n", "abstract": " A new type of shared object, called timed register, is proposed and used to design indulgent timing-based algorithms. A timed register generalizes the notion of an atomic register as follows: if a process invokes two consecutive operations on the same timed register which are a read followed by a write, then the write operation is executed only if it is invoked at most d time units after the read operation, where d is defined as part of the read operation. In this context, a timing-based algorithm is an algorithm whose correctness relies on the existence of a bound \u0394 such that any pair of consecutive constrained read and write operations issued by the same process on the same timed register are separated by at most \u0394 time units. An indulgent algorithm is an algorithm that always guarantees the safety properties, and ensures the liveness property as soon as the timing assumptions are satisfied. The usefulness of this new\u00a0\u2026", "num_citations": "6\n", "authors": ["495"]}
{"title": "Distributed slicing in dynamic systems\n", "abstract": " Peer to peer (P2P) systems are moving from application specific architectures to a generic service oriented design philosophy. This raises interesting problems in connection with providing useful P2P middleware services that are capable of dealing with resource assignment and management in a large-scale, heterogeneous and unreliable environment. One such service, the slicing service, has been proposed to allow for an automatic partitioning of P2P networks into groups (slices) that represent a controllable amount of some resource and that are also relatively homogeneous with respect to that resource, in the face of churn and other failures. In this report we propose two algorithms to solve the distributed slicing problem. The first algorithm improves upon an existing algorithm that is based on gossip-based sorting of a set of uniform random numbers. We speed up convergence via a heuristic for gossip peer selection. The second algorithm is based on a different approach: statistical approximation of the rank of nodes in the ordering. The scalability, efficiency and resilience to dynamics of both algorithms relies on their gossip-based models. We present theoretical and experimental results to prove the viability of these algorithms.", "num_citations": "6\n", "authors": ["495"]}
{"title": "Consensus-based management of distributed and replicated data\n", "abstract": " Atomic Broadcast and Atomic Commitment are fundamental problems that have to be solved when managing distributed/replicated data. This short note aims at showing that solutions to these problems can benefit from results associated with the Consensus problem. Such an approach helps gain a better insight into distributed/replicated data management problems.More precisely, this note addresses one of the most important issues one is faced to when designing distributed/replicated data management protocols, namely, their Non-Blocking property. This property stipulates that the crash of nodes participating in a protocol must not prevent the non-crashed nodes from terminating the protocol execution. Results from the Consensus study allow to know the minimal assumptions a system must satisfy in order its distributed/replicated data management protocols be non-blocking despite process crash and asynchrony.", "num_citations": "6\n", "authors": ["495"]}
{"title": "Static and dynamic adaptation of transactional consistency\n", "abstract": " Consistency criteria adopted for the management of persistent replicated objects in a distributed system define the degree of concurrency allowed among operations accessing objects. Several notions of consistency are known from the literature; among them are causal consistency, causal serializability, and serializability. We propose a generalizing algorithm for concurrency control in a transaction system that exhibits a clean separation between policy and mechanism. A consistency criterion selected is manifested as a set of rules forming the policy. The mechanism however, remains unchanged regardless of the currently used policy. It implements causally consistent message delivery and uses tokens and quorums of tokens to enforce access operation ordering according to the specified consistency criterion. An example of an application exploiting the advantages of dynamically switching among various\u00a0\u2026", "num_citations": "6\n", "authors": ["495"]}
{"title": "A general scheme for token and tree based distributed mutual exclusion algorithms\n", "abstract": " In a distributed context, mutual exclusion algorithms can be divided into two families according to their underlying algorithmic principles: those which are permission-based and those which are token-based. Within the latter family a lot of algorithms use a rooted tree structure to move the requests and the unique token. This paper presents a very general information structure (and the associated generic algorithm) for token-and treebased mutual exclusion algorithms. This general structure does not only cover, as particular cases, several known algorithms but also allows to design new algorithms well suited to topology requirements.", "num_citations": "6\n", "authors": ["495"]}
{"title": "Towards the construction of distributed detection programs, with an application to distributed termination\n", "abstract": " Methodological design of distributed programs is of major concern to master paral lelism. Due to their role in distributed systems, the class of observation or detection programs, whose aim is to observe or detect properties of an observed program, is very important. The detection of a property generally rests upon consistent evaluations of a predicate; such a predicate can be global, ie involve states of several processes \ufb01x and channels of the observed program. Unfortunately, in a distributed system, the consistency of an evaluation cannot be trivially obtained. This is a Cl:.| tral problem in distributed evaluations. This paper addresses the problem of distributed evaluation, used as a basic tool (or solution of general distributed detection problems. A new evaluation paradigm is put forward,'and a gtneral distributed detection program is designed, introducing the iterative scheme of guarded waves sequence. The case of\u00a0\u2026", "num_citations": "6\n", "authors": ["495"]}
{"title": "About logical clocks for distributed systems\n", "abstract": " Mcmory spacc and processor timc arc basic rcsourccs whcn exccuting a program. But bcsidc this implcmcntation aspect (Lhis lime rcsourccis ncccssary but docs not bchang to thc programuscn1antics) thc concept of timc prescnts a more fundamcntal lacet in distributcd systcms namcly causality relation bctwccn cvcnts. Put forward by Lamport in 1978, the logical nature of timc is of primary importance whcn designing or analyzing distributcd systcms. This papcr revicws thrcc ways (lima; Lime, vector lime and matrix timc) which have bccn proposed to capture causa\ufb01ty bclwccn cvcnts of a dish\ufb01butcd computation and which conscqucntly allow to dc\ufb01nc logical timc. I (cy words: distributh systcms, causality, log\u00eecal lime, happcncd bcforc, lincar timc, vcct0r lime, matr\u00eex lime.", "num_citations": "6\n", "authors": ["495"]}
{"title": "Self-stabilizing set-constrained delivery broadcast\n", "abstract": " Fault-tolerant distributed applications require communication abstractions with provable guarantees on message deliveries. For example, Set-Constrained Delivery Broadcast (SCD-broadcast) is a communication abstraction for broadcasting messages in a manner that, if a process delivers a set of messages that includes m and later delivers a set of messages that includes m , no process delivers first a set of messages that includes m\u2032 and later a set of messages that includes m.Imbs et al. proposed this communication abstraction and its first implementation. They have demonstrated that SCD-broadcast has the computational power of read/write registers and allows for an easy building of distributed objects such as snapshot objects and consistent counters. Imbs et al. focused on fault-tolerant implementations for asynchronous message-passing systems that are prone to process crashes. This paper aims to design an\u00a0\u2026", "num_citations": "5\n", "authors": ["495"]}
{"title": "Mutual exclusion in fully anonymous shared memory systems\n", "abstract": " Process anonymity has been studied for a long time. Memory anonymity is more recent. In an anonymous memory system, there is no a priori agreement among the processes on the names of the shared registers. As an example, a shared register named A by a process p and a shared register named B by another process q may correspond to the very same register X, while the same name C may correspond to different register names for the processes p and q, and this remains unknown to the processes. This article introduces the full anonymous model, namely a model in which both the processes and the registers are anonymous. A fundamental question is then \u201cis this model meaningful?\u201d, which can be translated as \u201ccan non-trivial fundamental problems be solved in such a very weak computing model?\u201d This article answers this question positively. More precisely, it presents a deadlock-free mutual exclusion\u00a0\u2026", "num_citations": "5\n", "authors": ["495"]}
{"title": "Providing Collision-Free and Conflict-Free Communication in General Synchronous Broadcast/Receive Networks\n", "abstract": " This work considers the problem of communication in dense and large scale wireless networks composed of resourcelimited nodes. In this kind of networks, a massive amount of data is becoming increasingly available, and consequently implementing protocols achieving error-free communication channels constitutes an important challenge. Indeed, in this kind of networks, the prevention of message conflicts and message collisions is a crucial issue. In terms of graph theory, solving this issue amounts to solve the distance-2 coloring problem in an arbitrary graph. The paper presents a distributed algorithm providing the processes with such a coloring. This algorithm is itself collision-free and conflict-free. It is particularly suited to wireless networks composed of nodes with communication or local memory constraints.", "num_citations": "5\n", "authors": ["495"]}
{"title": "t-Resilient Immediate Snapshot Is Impossible\n", "abstract": " An immediate snapshot object is a high level communication object, built on top of a read/write distributed system in which all except one processes may crash. It allows each process to write a value and obtains a set of pairs (process id, value) such that, despite process crashes and asynchrony, the sets obtained by the processes satisfy noteworthy inclusion properties.                 Considering an n-process model in which up\u00a0to t processes are allowed to crash (t-crash system model), this paper is on the construction of t-resilient immediate snapshot objects. In the t-crash system model, a process can obtain values from at least  processes, and, consequently, t-immediate snapshot is assumed to have the properties of the basic -resilient immediate snapshot plus the additional property stating that each process obtains values from at least  processes. The main result of the paper is the following. While there is a\u00a0\u2026", "num_citations": "5\n", "authors": ["495"]}
{"title": "Distributed universality\n", "abstract": " A notion of a universal construction suited to distributed computing has been introduced by M. Herlihy in his celebrated paper \u201cWait-free synchronization\u201d (ACM TOPLAS, 1991). A universal construction is an algorithm that can be used to wait-free implement any object defined by a sequential specification. Herlihy\u2019s paper shows that the basic system model, which supports only atomic read/write registers, has to be enriched with consensus objects to allow the design of universal constructions. The generalized notion of a k-universal construction has been recently introduced by Gafni and Guerraoui (CONCUR, 2011). A k-universal construction is an algorithm that can be used to simultaneously implement k objects (instead of just one object), with the guarantee that at least one of the k constructed objects progresses forever. While Herlihy\u2019s universal construction relies on atomic registers and consensus\u00a0\u2026", "num_citations": "5\n", "authors": ["495"]}
{"title": "Communication and agreement abstractions in the presence of Byzantine processes\n", "abstract": " Byzantine process is a process that --intentionally or not-- behaves arbitrarily (Byzantine failures include crash and omission failures). Considering message-passing systems, this paper presents communication and agreement abstractions that allow non-faulty processes to correctly cooperate, despite the uncertainty created by the net effect of asynchrony and Byzantine failures. The world is distributed. Consequently more and more applications are distributed, and the ''no Byzantine failure'' assumption is no longer reasonable. Hence, due to both the development of clouds and security requirements, such abstractions are becoming more and more important. The aim of this paper is to be a simple and homogeneous introduction to (a) communication and agreement abstractions, and (b) algorithms that implement these abstractions, in the context of asynchronous distributed message-passing systems where an a priori unknown subset of processes may exhibit Byzantine failures. To that end the paper presents existing abstractions and algorithms, and new ones. In this sense the paper has a mixed ''pedagogical/survey/research'' flavor.", "num_citations": "5\n", "authors": ["495"]}
{"title": "The weakest failure detector to implement a register in asynchronous systems with hybrid communication\n", "abstract": " This paper introduces an asynchronous crash-prone hybrid system model. The system is hybrid in the way the processes can communicate. On the one side, a process can send messages to any other process. On another side, the processes are partitioned into clusters and each cluster has its own read/write shared memory. In addition to the model, a main contribution of the paper concerns the implementation of an atomic register in this system model. More precisely, a new failure detector (denoted M \u03a3) is introduced and it is shown that, when considering the information on failures needed to implement a register, this failure detector is the weakest. To that end, the paper presents an M \u03a3-based algorithm that builds a register in the considered hybrid system model and shows that it is possible to extract M \u03a3 from any failure detector-based algorithm that implements a register in this model. The paper also (a) shows\u00a0\u2026", "num_citations": "5\n", "authors": ["495"]}
{"title": "A contention-friendly methodology for search structures\n", "abstract": " In this paper, a new methodology for writing concurrent data structures is proposed. This methodology limits the high contention induced by today's mutlicore environments to come up with efficient alternatives to most widely used search structures, including skip lists, binary search trees and hash tables. Data structures are generally constrained to guarantee a big-oh step complexity even in the presence of concurrency. By contrast our methodology guarantees the big-oh complexity only in the absence of contention and limits the contention when concurrency appears. The key concept lies in dividing update operations within an eager abstract access that returns rapidly for efficiency reason and a lazy structural adaptation that may be postponed to diminish contention. We illustrate our methodology with three contention-friendly data structures: a lock based skip list and binary search tree, and a lock-free hash table. Our evaluation clearly shows that our contention-friendly data structures are more efficient than their non-contention-friendly counterparts. In particular, our lockbased skip list is up to 1:3 faster than the Java concurrent skip list, our lock-based tree is up to 2:2 faster than the most recent concurrent tree algorithm we are aware of, and our lock-free hash table outperforms by up to 1:2 the Java concurrent hash table. We also present contention-friendly versions of the skip list and binary search tree using transactional memory. Even though our transaction-based data structures are substantially slower than our lock-based ones, they inherit compositionality from transactional memory and outperform their non-contention-friendly counterparts by\u00a0\u2026", "num_citations": "5\n", "authors": ["495"]}
{"title": "Software transactional memories: an approach for multicore programming\n", "abstract": " The recent advance of multicore architectures and the deployment of multiprocessors as the mainstream computing platforms have given rise to a new concurrent programming impetus. Software transactional memories (STM) are one of the most promising approaches to take up this challenge. The aim of a STM system is to discharge the application programmer from the management of synchronization when he/she has to write multiprocess programs. His/her task is to decompose his/her program into a set of sequential tasks that access shared objects, and to decompose each task in atomic units of computation. The management of the required synchronization is ensured by the associated STM system. This paper presents two existing STM systems, and a new one based on time-window mechanism. The paper, which focuses mainly on STM principles, has an introductory and survey flavor.", "num_citations": "5\n", "authors": ["495"]}
{"title": "A simple snapshot algorithm for multicore systems\n", "abstract": " An atomic snapshot object is an object that can be concurrently accessed by n asynchronous processes prone to crash. It is made of m components (base atomic registers) and is defined by two operations: an update operation that allows a process to atomically assign a new value to a component and a snapshot operation that atomically reads and returns the values of all the components. To cope with the net effect of concurrency, asynchrony and failures, the algorithm implementing the update operation has to help concurrent snapshot operations in order they can always terminate. This paper presents a new and particularly simple construction of a snapshot object. This construction relies on a new principle, that we call \"write first, help later\" strategy. This strategy directs an update operation first to write its value and only then computes an helping snapshot value that can be used by a snapshot operation in order\u00a0\u2026", "num_citations": "5\n", "authors": ["495"]}
{"title": "Personalized top-k processing: from centralized to decentralized systems\n", "abstract": " The Web 2.0 revolution has transformed the Internet from a read-only infrastructure to an active read-write platform. The rapid increasing amount user-generated content in collaborative tagging systems provides a huge source of information. Yet, performing effective search becomes more challenging, especially when we seek the most appropriate items that match a potentially ambiguous query. Personalization is appealing in this context as it limits the search for the items within a small network of participants with similar interests. However, centralized solutions for this personalization do not scale given the large amount of information that needs to be maintained on a user basis, especially given the dynamic nature of the systems where users continuously change their profiles by tagging new items. In this regard, this thesis deals with the efficiency and scalability of personalized query processing, from centralized to decentralized systems, around two axes: (i) the off-line personalization that relies on users' past tagging behaviors and (ii) the on-line personalization that relies on both the past behaviors and the current query. We first present the algorithm P3K, which decentralizes a state-of-the-art approach and achieves off-line personalized top-k processing in peer-to-peer systems. Then we present P4Q, an extension of P3K that enhances the system performance in terms of storage, bandwidth and robustness. Both P3K and P4Q rely on gossip-based protocols to capture the implicit similarity between users and associate each user with a set of social acquaintances to process the query. Analytical and experimental evaluations convey their\u00a0\u2026", "num_citations": "5\n", "authors": ["495"]}
{"title": "A Methodological Construction of an Efficient Sequentially Consistent Distributed Shared Memory\n", "abstract": " The paper proposes a simple protocol that ensures sequential consistency. The protocol assumes that the shared memory abstraction is supported by the local memories of nodes that can communicate only by exchanging messages through reliable channels. Unlike other sequential consistency protocols, the one proposed here does not rely on a strong synchronization mechanism, such as an atomic broadcast primitive or a central node managing a copy of every shared object. From a methodological point of view, the protocol is built incrementally starting from the very definition of sequential consistency. It has the noteworthy property that a process that issues a write operation never has to wait for other processes. Depending on the current local state, most read operations issued also have the same property.", "num_citations": "5\n", "authors": ["495"]}
{"title": "Value-based sequential consistency for set objects in dynamic distributed systems\n", "abstract": " This paper introduces a shared object, namely a set object that allows processes to add and remove values as well as take a snapshot of its content. A new consistency condition suited to such an object is introduced. This condition, named value-based sequential consistency, is weaker than linearizability. The paper also addresses the construction of a set object in a synchronous anonymous distributed system where participants can continuously join and leave the system. Interestingly, the protocol is proved correct under the assumption that some constraint on the churn is satisfied. This shows that the notion of \u201cprovably correct software\u201d can be applied to dynamic systems.", "num_citations": "5\n", "authors": ["495"]}
{"title": "The x-wait-freedom progress condition\n", "abstract": " The liveness of concurrent objects despite asynchrony and failures is a fundamental problem. To that end several progress conditions have been proposed. Wait-freedom is the strongest of these conditions: it states that any object operation must terminate if the invoking process does not crash. Obstruction-freedom is a weaker progress condition as it requires progress only when a process executes in isolation for a long enough period.               This paper explores progress conditions in n-process asynchronous read/write systems enriched with base objects with consensus number x, 1\u2009<\u2009x\u2009\u2264\u2009n (i.e., objects that wait-free solve consensus in a set of x processes). It is easy to solve consensus in such a system if progress is required only when one of the x processes allowed to access the underlying consensus object invokes this object and does not crash. This paper proposes and investigates a stronger\u00a0\u2026", "num_citations": "5\n", "authors": ["495"]}
{"title": "Conditions for set agreement with an application to synchronous systems\n", "abstract": " The k-set agreement problem is a generalization of the consensus problem: considering a system made up of n processes where each process proposes a value, each non-faulty process has to decide a value such that a decided value is a proposed value, and no more than k different values are decided. While this problem cannot be solved in an asynchronous system prone to t process crashes when t \u2265 k, it can always be solved in a synchronous system;  is then a lower bound on the number of rounds (consecutive communication steps) for the non-faulty processes to decide. The condition-based approach has been introduced in the consensus context. Its aim was to both circumvent the consensus impossibility in asynchronous systems, and allow for more efficient consensus algorithms in synchronous systems. This paper addresses the condition-based approach in the context of the k-set\u00a0\u2026", "num_citations": "5\n", "authors": ["495"]}
{"title": "A lock-based protocol for software transactional memory\n", "abstract": " The aim of a software transactional memory (STM) system is to facilitate the design of concurrent programs, i.e., programs made up of processes (or threads) that concurrently access shared objects. To that end, a STM system allows a programmer to write transactions accessing shared objects, without having to take care of the fact that these objects are concurrently accessed: the programmer is discharged from the delicate problem of concurrency management. Given a transaction, the STM system commits or aborts it. Ideally, it has to be efficient (this is measured by the number of transactions processed per time unit), while ensuring that as few transactions as possible are aborted. From a safety point of view (the one addressed in this paper), a STM system has to ensure that, whatever its fate (commit or abort), each transaction always operates on a consistent state. STM systems have recently received a great attention. Among the proposed solutions, lock-based systems and clock-based systems have been particularly investigated. This paper presents a new lock-based STM system designed from simple basic principles. Its main features are the following: it (1) does not require the shared memory to manage several versions of each object, (2) uses neither timestamps, nor version numbers, (3) aborts a transaction only when it conflicts (with some other live transaction), (4) never aborts a write only transaction, (5) employs only bounded control variables, and (6) has no centralized contention point.", "num_citations": "5\n", "authors": ["495"]}
{"title": "Failure detectors are schedulers\n", "abstract": " Categories and Subject Descriptors C. 2.4 [Computer-Communication Network]: Distributed Systems-distributed applications, network operating systems; D. 4.1 [Operating Systems] Process Managementconcurrency, multiprocessing, synchronization; D. 4.5 [Operating Systems] Reliability-fault-tolerance; F. 1.1 [Computation by Abstract Devices]: Models of Computation-Computability theory", "num_citations": "5\n", "authors": ["495"]}
{"title": "A methodological construction of an efficient sequential consistency protocol\n", "abstract": " A concurrent object is an object that can be concurrently accessed by several processes. Sequential consistency is a consistency criterion for such objects. Informally, it states that a multiprocess program executes correctly if its results could have been produced by executing that program on a single processor system. (Sequential consistency is weaker than atomic consistency -the usual consistency criterion- as it does not refer to real-time.) The paper proposes a simple protocol that ensures sequential consistency when the shared memory abstraction is supported by the local memories of nodes that can communicate only by exchanging messages through reliable channels. Differently from other sequential consistency protocols, the proposed protocol does not rely on a strong synchronization mechanism such as an atomic broadcast primitive or a central node managing a copy of every shared object. From a\u00a0\u2026", "num_citations": "5\n", "authors": ["495"]}
{"title": "Elastic vector time\n", "abstract": " In recent years there has been an increasing demand to build \"soft\" real-time applications on top of asynchronous distributed systems. Designing and implementing such applications is a non-trivial task and application designers are often faced with the need to circumvent impossibility results. In this paper we discuss how to ensure that actions are executed in the correct order even in the face of failures. We propose a novel time base and a new synchronization mechanism for the design of distributed \"soft\" real-time applications. We demonstrate (1) how this time base can be used to enforce an externally consistent ordering, and (2) how it permits to circumvent impossibility results by sketching how to solve the leader election and perfect failure detection problem.", "num_citations": "5\n", "authors": ["495"]}
{"title": "Error correcting codes: A future direction to solve distributed agreement problems\n", "abstract": " \u2022 Consenso\u2022 Impossibilidade e Solu\u00e7\u00f5es\u2022 Aproxima\u00e7\u00e3o baseada em condi\u00e7\u00f5es\u2022 Acordo Distribu\u00eddo e C\u00f3digos de correc\u00e7\u00e3o de erros", "num_citations": "5\n", "authors": ["495"]}
{"title": "Time and message-efficient S-based consensus (brief announcement)\n", "abstract": " The class of strong failure detectors (denoted S) includes all failure detectors that suspect all crashed processes and that do not suspect some (a priori unknown) process that never crashes. So, a failure detector that belongs to S is intrinsically unreliable as it can arbitrarily suspect correct processes.", "num_citations": "5\n", "authors": ["495"]}
{"title": "Computing global functions in asynchronous distributed systems prone to process crashes\n", "abstract": " Global data is a vector with one entry per process. Each entry must be filled with an appropriate value provided by the corresponding process. Several distributed computing problems amount to compute a function on global data. This paper proposes a protocol to solve such problems in the context of asynchronous distributed systems where processes may fail by crashing. The main problem that has to be solved lies in computing the global data and in providing each non-crashed process with a copy of it, despite the possible crash of some processes. To be consistent, the global data must contain (at least) all the values provided by the processes that do not crash. This defines the global data computation (GDC) problem. To solve this problem, processes execute a sequence of asynchronous rounds during which they construct (in a decentralized way) the value of the global data, and eventually each process gets a\u00a0\u2026", "num_citations": "5\n", "authors": ["495"]}
{"title": "Distributed database checkpointing\n", "abstract": " Data checkpointing is an important problem of distributed database systems. Actually, transactions establish dependence relations on data checkpoints taken by data object managers. So, given an arbitrary set of data checkpoints (including at least a single data checkpoint from a data manager, and at most a data checkpoint from each data manager), an important question is the following one: \u201cCan these data checkpoints be members of a same consistent global checkpoint?\u201d. This paper answers this question andp roposes a non-intrusive data checkpointing protocol.", "num_citations": "5\n", "authors": ["495"]}
{"title": "A practical building block for solving agreement problems in asynchronous distributed systems\n", "abstract": " Providing processes with the same view of a global state or allowing them to take consistent decisions, despite asynchrony and failure occurrences, are fundamental problems encountered in distributed systems. These problems are called agreement problems. Non blocking atomic commitment and definition of a single delivery order for broadcast messages are examples of such problems. We define a paradigm (called Single Global View) that encompasses various practical agreement problems. The interest of this paradigm lies in its practicability: each process starts with an initial value, and all these values are pieced together in such a way that, despite process crashes and asynchrony, all correct processes are delivered the same set of values (namely, the Single Global View). The power of this paradigm is the same as that of the consensus problem defined by theoreticians. Instantiations of the paradigm, which\u00a0\u2026", "num_citations": "5\n", "authors": ["495"]}
{"title": "About state recording in asynchronous computations\n", "abstract": " The global record notion is of primary importance, in asynchronous parallel or distributed systems. Informally, a local record is a local state selected by a process and a global record is a set of local records, one from each process of the system. Such a global record is said to be consistent if it has been passed through, or if it could have been passed through, by the current computation. The purpose of this paper is to provide an answer to the following question:\u201a\u00c4\u00f9given a subset of local records, can these local records belong to a consistent global record of the computation?\u201a\u00c4\u00f9. Such a question has been answered in the particular context of reliable point-to-point message passing systems [2]. Here, this result is extended in two directions: first, we consider a very general computational model that encompasses shared memory, reliable point-to-point communication, multicast communication and unreliable communication systems. Second, we introduce a formal frame based on the notion of record interval and on a precedence relation defined on them. Within this general model and formal frame, a necessary and sufficient condition that answers the previous question is stated and proved. Further, a corollary of this condition suggests a strategy on how to build algorithms forcing processes to select local records in order that no previously selected local record be useless (useless local records cannot belong to any consistent global records). Due to space limitations, we only give the main notations and statement. The complete development of these ideas can be found in [1](also available by e-mail to helary@ irisa. fr).", "num_citations": "5\n", "authors": ["495"]}
{"title": "Mutually consistent recording in asynchronous computations\n", "abstract": " : A global record (ie a set of local records, one for each process of an asynchronous computation) abstracts what is usually called global state, global checkpoint or global snapshot in particular problems. This paper concentrates on consistency of global records. First, a general model of asynchronous computations, including the classical shared memory model and several message passing models, is introduced. Then, under this general model, a necessary and sufficient condition, stating whether an arbitrary set of local records can be included in some consistent global record, is proved. Finally, it is shown that, when a simple strategy (derived as a consequence of the previous theorem) is followed by each process of an asynchronous computation, then all local records taken by processes belong to consistent global records. Such a result can be used to design efficient snapshoting or checkpointing algorithms in asynchronous computations. Key-words: Distributed systems, asynchronous co...", "num_citations": "5\n", "authors": ["495"]}
{"title": "When all the observers of a distributed computation do agree\n", "abstract": " A consistent observation of a distributed computation can be seen as a sequence of states and events that might have been produced by executing this computation on a monoprocessor. So a distributed execution generally accepts a lot of consistent observations. This paper concentrates on what all these observations have in common. An abstraction called inevitable global state is de ned. A necessary and su cient condition characterizing such states is given and a monitorbased algorithm that detects them is also presented. Possible uses of such states are sketched.", "num_citations": "5\n", "authors": ["495"]}
{"title": "Distributed evaluation: a tool for constructing distributed detection programs\n", "abstract": " Methodological design of distributed programs is of major concern to master parallelism. Due to their role in distributed systems, the class of observation or detection programs, whose aim is to observe or detect properties of an observed program, is very important. The detection of a property generally rests upon consistent evaluations of a predicate; such a predicate can be global, i.e. involve states of several processes and channels of the observed program. Unfortunately, in a distributed system, the consistency of an evaluation cannot be trivially obtained. This is a central problem in distributed evaluations. This paper addresses the problem of distributed evaluation, as a basic tool for the design of a general distributed detection program.", "num_citations": "5\n", "authors": ["495"]}
{"title": "A distributed kernel for virtual time driven applications\n", "abstract": " The advent of distributed memory parallel machines turns the design and implementation of dedicated environments feasible for distributed applications. This paper addresses such a realization by presenting a distributed kernel, called FLORIA, whose aim is to provide a virtual time environment for application programs (distributed discrete event simulation is the most known of the applications based on such a virtual time-the so called simulation time-and consequently constitutes the paradigm of this class). This paper presents basic features of the virtual time concept and then describes the time-related aspects of the implementation of a distributed kernel dedicated to virtual time driven applications.<>", "num_citations": "5\n", "authors": ["495"]}
{"title": "Order notions and atomic multicast in distributed systems: a short survey\n", "abstract": " The understanding of precedence relations between events and the definition of high-level communication primitives are two main issues in the architecture and software engineering of distributed systems and distributed kernels. The author studies different mechanisms that allow timestamping of events produced by distributed executions. Their relative properties are analyzed in depth and some of their possible uses are exhibited. Communication primitives which could be offered by a distributed kernel are discussed. A list and an assessment of such primitive are given. Essentially, the author presents a survey of timestamping mechanisms and communication primitives for the purpose of building an abstract distributed machine that is easier to use than the underlying one.< >", "num_citations": "5\n", "authors": ["495"]}
{"title": "Distributed Algorithms: Their Nature & The Problems Encountered\n", "abstract": " The field of distributed applications is growing more and more. This spectacular increase in the use. of computer science as a preferred tool in ever more diverse areas is essentially the result in both theoretical and practical aspects of this discipline. In fact the results of evolutions in hardware technology (especially local area networks), in norms and standards,(OSi/lSO), in methodology for designing and writing software give the researcher or the engineer more and more tools to conduct his project.A head point of these diverse evolutions is the following one; they considerer applications and operating systems as composed of a set of entities cooperating to a common goal (the one to which the application or the system is devoted). Mastering and correct design of distributed systems and of applications developped oft networks of machines need consequently specific concepts, tools, and algorithms, that is to say the computer science field now called distributed algorithmice.", "num_citations": "5\n", "authors": ["495"]}
{"title": "The notion of universality in crash-prone asynchronous message-passing systems: a tutorial\n", "abstract": " The notion of a universal construction is central in computing science and technology: general solutions make life easier and the wheel has not to be reinvented each time a new problem appears. In the context of message-passing asynchronous distributed systems made up of n processes, where some of them may commit crash failures, a universal construction is an algorithm that is able to build any object defined by a sequential specification despite the adversary effect resulting from the combination of asynchrony and process crashes. The aim of this tutorial is to introduce the reader to the notion of a distributed universal construction (and universal objects these constructions rely on), and more precisely, explain what can be done, what cannot be done, and which assumptions on the environment are necessary in order objects with provably reliability properties can be built. Its aim is be a guided tour providing\u00a0\u2026", "num_citations": "4\n", "authors": ["495"]}
{"title": "Anonymous read/write memory: Leader election and de-anonymization\n", "abstract": " Anonymity has mostly been studied in the context where processes have no identity. A new notion of anonymity was recently introduced at PODC 2017, namely, this notion considers that the processes have distinct identities but disagree on the names of the read/write registers that define the shared memory. As an example, a register named A by a process p and a shared register named B by another process q may correspond to the very same register X, while the same name C may correspond to different registers for p and q.                 Recently, a memory-anonymous deadlock-free mutual exclusion algorithm has been proposed by some of the authors. This article addresses two different problems, namely election and memory de-anonymization. Election consists of electing a single process as a leader that is known by every process. Considering the shared memory as an array of atomic read/write registers , memory de-anonymization consists\u00a0\u2026", "num_citations": "4\n", "authors": ["495"]}
{"title": "Mutex-based de-anonymization of an anonymous read/write memory\n", "abstract": " Anonymous shared memory is a memory in which processes use different names for the same shared read/write register. As an example, a shared register named A by a process p and a shared register named B by another process q can correspond to the very same register X, and similarly for the names B at p and A at q which can correspond to the same register . Hence, there is a permanent disagreement on the register names among the processes. This new notion of anonymity was recently introduced by G. Taubenfeld (PODC 2017), who presented several memory-anonymous algorithms and impossibility results.                 This paper introduces a new problem, that consists in \u201cde-anonymizing\u201d an anonymous shared memory. To this end, it presents an algorithm that, starting with a shared memory made up of m anonymous read/write atomic registers (i.e., there is no a priori agreement on their\u00a0\u2026", "num_citations": "4\n", "authors": ["495"]}
{"title": "Making local algorithms wait-free: the case of ring coloring\n", "abstract": " When considering distributed computing, reliable message-passing synchronous systems on the one side, and asynchronous failure-prone shared-memory systems on the other side, remain two quite independently studied ends of the reliability/asynchrony spectrum. The concept of locality of a computation is central to the first one, while the concept of wait-freedom is central to the second one. The paper proposes a new DECOUPLED model in an attempt to reconcile these two worlds. It consists of a synchronous and reliable communication graph of nnodes, and on top a set of asynchronous crash-prone processes, each attached to a communication node. To illustrate the DECOUPLED model, the paper presents an asynchronous 3-coloring algorithm for the processes of a ring. From the processes point of view, the algorithm is wait-free. From a locality point of view, each process uses information only from\u00a0\u2026", "num_citations": "4\n", "authors": ["495"]}
{"title": "Are Byzantine Failures Really Different from Crash Failures?\n", "abstract": " When considering n-process asynchronous systems, where up\u00a0to t processes can fail, and communication is by read/write registers or reliable message-passing, are (from a computability point of view) Byzantine failures \u201cdifferent\u201d from crash failures? This is the question addressed in this paper, which shows that the answer is \u201cno\u201d for systems where .               To this end, the paper presents a new distributed simulation whose core is an extended BG simulation suited to asynchronous message-passing systems. More precisely, assuming , it describes a signature-free algorithm that simulates a system of  processes where up\u00a0to t may crash, on top of a basic system of n processes where up\u00a0to t may be Byzantine. In addition to extending (in a modular and direct way) the basic BG simulation to Byzantine message-passing systems this simulation also allows crash-tolerant algorithms\u00a0\u2026", "num_citations": "4\n", "authors": ["495"]}
{"title": "A look at basics of distributed computing\n", "abstract": " This tutorial presents concepts and basics of distributed computing which are important (at least from the author's point of view!), and should be known and mastered by Master students, researchers, and engineers. Those include: (a) a characterization of distributed computing (which is too much often confused with parallel computing); (b) the notion of a synchronous system and its associated notions of a local algorithm and message adversaries; (c) the notion of an asynchronous shared memory system and its associated notions of universality and progress conditions; and (d) the notion of an asynchronous messagepassing system with its associated broadcast and agreement abstractions, its impossibility results, and approaches to circumvent them. Hence, the tutorial can be seen as a guided tour to key elements that constitute basics of distributed computing.", "num_citations": "4\n", "authors": ["495"]}
{"title": "Efficient broadcast protocol for the internet of things\n", "abstract": " Internet of Things (IoT) is a network composed of a variety of heterogeneous things and objects such as Connected Wearable Devices (sensors, MEMS, microrobots, PDA, ...), Connected Cars, Connected Homes, Connected Cities, and the Industrial Internet. These things use generally wireless communication to interact and cooperate with each other to reach common services and goals. IoT(T, n) is a wireless network of things composed of T things with n items (information) distributed on it. The aim of the permutation routing is to route to each thing, its items, so it can accomplish its task. In this paper, we present an agent-based broadcast protocol for mobile Internet of Things that uses few communication channels. The main idea is to partition things into groups according to the number of channels. In each group, an agent manages a set of things. This new protocol performs efficiently with respect to the number of\u00a0\u2026", "num_citations": "4\n", "authors": ["495"]}
{"title": "Reliable shared memory abstraction on top of asynchronous byzantine message-passing systems\n", "abstract": " This paper is on the construction and the use of a shared memory abstraction on top of an asynchronous message-passing system in which up to t processes may commit Byzantine failures. This abstraction consists of arrays of n single-writer/multi-reader atomic registers, where n is the number of processes. Differently from usual atomic registers which record a single value, each of these atomic registers records the whole history of values written to it. A distributed algorithm building such a shared memory abstraction it first presented. This algorithm assumes t\u2009<\u2009n/3, which is shown to be a necessary and sufficient condition for such a construction. Hence, the algorithm is resilient-optimal. Then the paper presents distributed algorithms built on top of this shared memory abstraction, which cope with up to t Byzantine processes. The simplicity of these algorithms constitutes a strong motivation for such a shared\u00a0\u2026", "num_citations": "4\n", "authors": ["495"]}
{"title": "A Generalized Mutual Exclusion Problem and Its Algorithm\n", "abstract": " Mutual exclusion (ME) is a fundamental problem for resource allocation in distributed systems, It is concerned with how the various processes access shared resources in a mutually exclusive way. Besides the classic ME problem, several variant problems have been proposed and studied. In this paper, drawing inspiration from the scenario of controlling autonomous vehicles at intersections, we have defined a new ME problem, called Local Group Mutual Exclusion (LGME), w here mutual exclusion is necessary only among the processes requesting overlap but not the same set of resources. In comparison with other variant problems of ME, LGME is more general but also more challenging. To solve the LGME problem, we propose a novel notion called strong coterie, which can handle the complex process relationship in LGME. Based on strong coterie, we have designed an ME algorithm, which can handle\u00a0\u2026", "num_citations": "4\n", "authors": ["495"]}
{"title": "Agreement via symmetry breaking: on the structure of weak subconsensus tasks\n", "abstract": " This paper is on the relative power and the relations linking two important synchronization problems in n-process wait-free shared memory models, namely, set agreement and renaming, which are two of the most studied subconsensus tasks. Since the 2006 seminal paper of Gafni, Rajsbaum and Herlihy, it is known that some renaming instances are strictly weaker than set agreement. Indeed, it was later on shown that not even (n + 1)-renaming (the strongest task in the renaming family, after perfect n-renaming) can implement (n - 1)-set agreement (the weakest non-trivial task in the set agreement family). These and other results seem to imply that renaming and, more generally, the tasks called generalized symmetry breaking tasks (GSB) are weaker than agreement tasks. This paper shows that this is not the case, namely, it shows that there is a large family of GSB tasks that are more powerful than (n - 1)-set\u00a0\u2026", "num_citations": "4\n", "authors": ["495"]}
{"title": "The mutual exclusion problem\n", "abstract": " This chapter introduces definitions related to process synchronization and focuses then on the mutual exclusion problem, which is one of the most important synchronization problems. It also defines progress conditions associated with mutual exclusion, namely deadlock-freedom and starvation-freedom.", "num_citations": "4\n", "authors": ["495"]}
{"title": "Adaptation en ligne de m\u00e9canismes de tol\u00e9rance aux fautes par une approche \u00e0 composants ouverts\n", "abstract": " L'adaptation en-ligne du logiciel de tol\u00e9rance aux fautes permet de renforce la s\u00fbret\u00e9 de fonctionnement du syst\u00e8me et prenant en compte son environnement. L'adaptation n\u00e9cessite de nouvelles techniques de conception. Ces travaux visent \u00e0 comprendre et ma\u00eetriser l'impact des modifications du logiciel de tol\u00e9rance aux fautes en op\u00e9ration sur les fonctionnalit\u00e9s du syst\u00e8me, pour en ma\u00eetriser les effets de bords. L'approche propos\u00e9e introduit une architecture r\u00e9flexive \u00e0 composants et une mod\u00e9lisation du logiciel. Un mod\u00e8le structurel du logiciel permet de calculer et appliquer les modifications du contenu du logiciel. Un mod\u00e8le comportemental d\u00e9crit les observations attendues en fonctionnement. Il permet de d\u00e9terminer les \u00e9tats permettant d'appliquer les modifications, d'amener et de maintenir le syst\u00e8me dans ces \u00e9tats. Ces travaux montrent que, gr\u00e2ce aux capacit\u00e9s de manipulation et de contr\u00f4le en ligne du logiciel, la modification des m\u00e9canismes de tol\u00e9rance aux fautes peut \u00eatre r\u00e9alis\u00e9e en ligne de mani\u00e8re ma\u00eetris\u00e9e.", "num_citations": "4\n", "authors": ["495"]}
{"title": "No double discount: Condition-based simultaneity yields limited gain\n", "abstract": " Assuming that each process proposes a value, the consensus problem requires the non-faulty processes to agree on the same value that, moreover, must be one of the proposed values. Solutions to the consensus problem in synchronous systems are based on the round-based model, namely, the processes progress in synchronous rounds. The well-known worst-case lower bound for consensus in the synchronous setting is t+ 1 rounds, where t is an a priori bound on the number of failures. Simultaneous consensus is a variant of consensus in which the non-faulty processes are required to decide in the exact same round, in addition to the deciding on the same value. Dwork and Moses showed that, in a synchronous system prone to t process crashes, the earliest round at which a common decision can be simultaneously obtained is (t+ 1)\u2212 W where t is a bound on the number of faulty processes and W is a non\u00a0\u2026", "num_citations": "4\n", "authors": ["495"]}
{"title": "Modularity: a first class concept to address distributed systems\n", "abstract": " Decomposing distributed systems into modules, each with a precise interface and a functional implementation independent specification, is highly effective both from a software engineering point of view and for theoretical purposes. The usefulness of this approach has been demonstrated in the past in several areas of distributed computing. Yet, despite its attractiveness, so far work on peer to peer systems failed to do so. This paper argues in favor of this approach and advocates such a decomposition for peer to peer systems. This allows designers to understand and explain both what a system does and how it does it.", "num_citations": "4\n", "authors": ["495"]}
{"title": "A timing assumption and a t-resilient protocol for implementing an eventual leader service in asynchronous shared memory systems\n", "abstract": " While electing an eventual common leader, despite process crashes, in a shared memory system where the processes communicate only by reading and writing shared registers is possible when the processes progress synchronously, this problem becomes impossible to solve as soon as the processes can progress in a fully asynchronous way. So, an important problem consists in finding additional behavioral assumptions that are, at the same time, \"as weak as possible\" (in order they are practically always satisfied), and \"strong enough\" in order to allow implementing an eventual leader service despite the net effect of asynchrony and failures. This paper focuses on this dilemma. More explicitly, it investigates a timing assumption that allows implementing an eventual leader in presence of partial asynchrony and process crashes. The proposed timing assumptions are particularly weak. They are the following: after\u00a0\u2026", "num_citations": "4\n", "authors": ["495"]}
{"title": "A Universal Construction for Concurrent Objects\n", "abstract": " A concurrent object is an object that can be concurrently accessed by several processes. A wait-free implementation of an object is such that any operation issued by a non-faulty process terminates in a finite number of its own steps, whatever the behavior of the other processes (that can be very slow or even have crashed). An object type is universal if objects of that type, together with atomic registers, allows implementing any concurrent object defined by a sequential specification. A universal construction is a wait-free algorithm, based only on atomic registers and universal objects, that, given any sequential object type T, provides the processes with a wait-free concurrent object of the type T. In a famous paper (titled \"Wait-free synchronization\") Herlihy has shown that consensus objects are universal, and has presented a consensus-based universal construction. We present here a new universal construction. That\u00a0\u2026", "num_citations": "4\n", "authors": ["495"]}
{"title": "Mixed consistency model: Meeting data sharing needs of heterogeneous users\n", "abstract": " Heterogeneous users usually have different requirements as far as consistency of shared data is concerned. This paper proposes and investigates a mixed consistency model to meet this heterogeneity challenge in large scale distributed systems that support shared objects. This model allows combining strong (sequential) consistency and weak (causal) consistency. The paper defines the model, motivates it and proposes a protocol implementing it", "num_citations": "4\n", "authors": ["495"]}
{"title": "Merging atomic consistency and sequential consistency\n", "abstract": " Merging atomic consistency and sequential consistency - OpenGrey fra | eng OpenGrey Open System for Information on Grey literature in Europe Home Search Subjects Partners Export Help Search XML To cite or link to this reference: http://hdl.handle.net/10068/41025 Title : Merging atomic consistency and sequential consistency Authors : Raynal, Michel ; Roy, Matthieu ; Tutu, Ciprian ; Corporate author : Institut National de Recherche en Informatique et en Automatique (INRIA), 35 - Rennes (France). Inst. de Recherche en Informatique et Systemes Aleatoires (IRISA) ; Institut National des Sciences Appliquees de Rennes (INSA), 35 (France). Inst . de Recherche en Informatique et Systemes Aleatoires (IRISA) ; Rennes-1 Univ., 35 (France). Inst. de Recherche en Informatique et Systemes Aleatoires (IRISA) ; Centre National de la Recherche Scientifique (CNRS), 35 - Rennes (France). Inst . de Recherche en et (IRISA) ; \u2026", "num_citations": "4\n", "authors": ["495"]}
{"title": "A short introduction to failure detectors for asynchronous distributed systems\n", "abstract": " Since the rst version of Chandra and Toueg's seminal paper titled\\Unreliable failure detectors for reliable distributed systems\" in 1991, the failure detector concept has been extensively studied and investigated. This is not at all surprising as failure detection is pervasive in the design, the analysis and the implementation of a lot of fault-tolerant distributed algorithms that constitute the core of distributed system middleware.The literature on this topic is mostly technical and appears mainly in theoretically inclined journals and conferences. The aim of this article is to o er an introductory survey to the failure detector concept for readers who are not familiar with it and want to quickly understand its aim, its basic principles, its power and limitations. To attain this goal, the paper rst describes the motivations that underlie the concept, and then surveys several distributed computing problems showing how they can be solved with the help of an appropriate failure detector. So, the paper presents motivations, concepts, problems, de nitions, and algorithms. It does not contain proofs. It is aimed at people who want to understand basics of failure detectors.", "num_citations": "4\n", "authors": ["495"]}
{"title": "Looking for a common view for mobile worlds\n", "abstract": " This paper considers central issues of distributed computing in a mobile environment. Its aim is to light on the first brick of a common view for mobile systems. We pool together mobile systems and analyze them from different angles including architecture and computability aspects. We show that mobile systems (i.e., cellular systems, ad hoc networks, peer-to-peer systems, virtual reality systems or cooperative robotics) are basically confronted with the same problems, hence it is useless to maintain the actual \"misleading\" barriers. Due to important similarities between the different mobile systems we claim that the next logical step in building a common view is to design a model which conceptually should unify them by providing an abstract description of the parameters which distinguish these systems from classic distributed systems. Moreover, in the new model, the fundamental problems of distributed computing (i.e\u00a0\u2026", "num_citations": "4\n", "authors": ["495"]}
{"title": "Nested invocation protocol for object-based systems\n", "abstract": " We discuss how to invoke a method on multiple object replicas in a quorum-based way. Suppose each instance of a method t on replicas of an object x invokes another method u on replicas in a quorum of an object y. Here, the method u is redundantly invoked multiple times on some replicas of the object y. If each instance of the method t issues a method u to its own quorum, more number of replicas are manipulated than the quorum number This is quorum expansion. We discuss a protocol to invoke methods on replicas in a nested manner without the redundant invocation and quorum expansion. We evaluate the protocol on how many replicas are manipulated and requests are issued.", "num_citations": "4\n", "authors": ["495"]}
{"title": "A note on the determination of the immediate predecessors in a distributed computation\n", "abstract": " A distributed computation can be modeled as a partially ordered set (poset) of relevant events (the relevant events are the subset  of the primitive events that are meaningful for an observer). This  short note presents a general protocol that, when superimposed on  a distributed computation, provides each relevant event with a  timestamp that identifies exactly its immediate predecessors in the poset. This determination is done on the fly and without using  additional control messages. So, the proposed protocol provides an  on the fly computation of the Hasse diagram (transitive reduction)  of the event graph produced by a distributed computation. The  protocol is particularly simple and efficient. It is based on a  general condition that allows application messages to piggyback  control information whose size can be smaller than n (the  number of processes). Interestingly, when one is not interested  in tracking the\u00a0\u2026", "num_citations": "4\n", "authors": ["495"]}
{"title": "Real-time based strong consistency for distributed objects\n", "abstract": " Ordering and time are two different aspects of consistency of shared objects in a distributed system. One avoids conflicts between operations, the other addresses how quickly the effects of an operation are perceived by the rest of the system. Consistency models such as sequential consistency [26] and causal consistency [3] do not consider the particular time at which an operation is executed to establish a valid order among all the operations of a computation. A timed consistency model addresses how quickly the effects of an operation are perceived by the rest of the system, by requiring that if a write operation is executed at time t, it must be visible to the entire distributed system by time t + Delta. Timed consistency generalizes several existing consistency criteria and it is well suited for interactive and collaborative applications, where the action of one user must be seen by others in a timely fashion.", "num_citations": "4\n", "authors": ["495"]}
{"title": "A failure detection protocol based on a lazy approach\n", "abstract": " The detection of process failures is a crucial problem system designers have to cope with in order to build fault-tolerant distributed platforms. Unfortunately, it is impossible to distinguish with certainty a crashed process from a very slow process in a purely asynchronous distributed system. This prevents some problems to be solved in such systems. That is why failure detector oracles have been introduced to circumvent these impossibility results. This paper presents a relatively simple protocol that allows a process to\\monitor\" another process, and consequently to detect its crash. This protocol enjoys the nice property to rely as much as possible on application messages to do this monitoring. Di erently from previous process crash detection protocols, it uses control messages only when no application messages is sent by the monitoring process to the observed process. This protocol has noteworthy features. When the underlying system satis es the partial synchrony assumption, it actually implements an eventually perfect failure detector (ie, a failure detector of the class usually denoted 3P). Moreover, if the upper layer application terminates correctly when the failure detector it uses belongs to 3P, then, when run with the proposed protocol, it also terminates correctly. These properties make the protocol attractive: it is inexpensive, implementable, and powerful. The paper also describes performance measurements of an implementation of the protocol.", "num_citations": "4\n", "authors": ["495"]}
{"title": "Primary component asynchronous group membership as an instance of a generic agreement framework\n", "abstract": " Group-based computing is becoming more and more popular when one has to design a middleware able to support reliable distributed applications. This paradigm is made of two basic services, namely, a group membership service and a group communication service. A group is a set of processes that cooperate in carrying out a common task. Due to the desire of new processes to join the group, to the desire of a group member to leave it, or to process crashes, the composition of a group can evolve dynamically. The set of processes that currently implements the group is called the current view of the group. This paper addresses the specification and the implementation of a primary component group membership service. \u00abPrimary component\u00bb means that the specification imposes to have a single view at any time. The paper first proposes a specification for the problem. Then it presents a protocol that implements that specification in asynchronous distributed systems equipped with failure detectors. This primary component group membership protocol is obtained as an appropriate instantiation of a general agreement framework.", "num_citations": "4\n", "authors": ["495"]}
{"title": "A Sliding Round Window S-based Consensus Protocol\n", "abstract": " A failure detector of the class 3S eventually suspects every crashed process, and guarantees that there is a correct process that, after some time, is no longer suspected. Several protocols have been proposed to solve the consensus problem in asynchronous distributed systems (prone to process crash failures) equipped with a failure detector 2 3S. These protocols are based on the rotating coordinator paradigm: processes proceed in asynchronous rounds, each round being coordinated by a predetermined process. All these protocols share a common design feature, namely, a process can be involved in a single round at a time. This paper presents an original 3S-based consensus protocol that also uses the rotating coordinator paradigm, but allows each process to be simultaneously involved in several rounds. The rounds in which a process is simultaneously involved de ne its\" sliding round window\". This approach has several advantages. Among them, there is the achievement of an e cient protocol, and a better understanding of the synchronization required by 3S-based consensus protocols that use the rotating coordinator paradigm.", "num_citations": "4\n", "authors": ["495"]}
{"title": "Crit\u00e8res de coh\u00e9rence pour donn\u00e9es partag\u00e9es \u00e0 support r\u00e9parti\n", "abstract": " Une memoire partagee construite sur un systeme reparti constitue une memoire virtuelle partagee (mvp). Si beaucoup de protocoles implantant une memoire virtuelle partagee dans des contextes varies ont ete proposes, aucun ensemble de definitions homogenes n'a ete donne pour les nombreuses semantiques (ou criteres de coherence) offertes par ces implantations. Dans cette these, nous donnons un ensemble de definitions pour les coherences atomique, sequentielle, causale, pram et objet. Ces definitions sont fondees sur un modele unique: un calcul reparti est defini comme un ordre partiel sur l'ensemble des operations de lecture et d'ecriture effectuees par les processus et un critere de coherence est defini comme une contrainte sur cet ordre partiel. Une telle approche fournit une classification simple des criteres de coherence (i. E., une hierarchie de niveaux de contraintes). L'implantation d'une memoire partagee sur un systeme reparti ou les sites communiquent physiquement par passage de messages est simplifiee par l'utilisation de protocoles de communication de groupe. Differents niveaux de synchronisation ont ete implantes (diffusion atomique, causale) en relation a differents criteres de coherence (sequentielle, causale). Par ailleurs, nous avons etudie la tolerance aux defaillances dans la communication de groupe; principalement, en utilisant le concept de suspecteur de defaillances pour resoudre le protocole de consensus, brique de base dans les systemes repartis.", "num_citations": "4\n", "authors": ["495"]}
{"title": "Static and dynamic adaptation of transactional consistency\n", "abstract": " Consistency criteria adopted for the management of persistent replicated objects in a distributed system define the degree of concurrency allowed among operations accessing objects. Several notions of consistency are known from the literature, among them are causal consistency, causal serializability, and serializability. In this paper, we propose a generalizing algorithm for concurrency control in a transaction system that exhibits a clean separation between policy and mechanism. A consistency criterion selected is manifested as a set of rules forming the policy. The mechanism, however, remains unchanged regardless of the currently used policy. The mechanism implements causally consistent message delivery and uses tokens and quorums of tokens to enforce access operation ordering according to the specified consistency criterion. Since a policy is implemented as a set of rules, switching on-the-fly from one consistency criterion to another one can easily be done whenever changes in access patterns or cost/availability requirements suggest a modification. An example of an application exploiting the advantages of switching among various consistency criteria concludes the paper.", "num_citations": "4\n", "authors": ["495"]}
{"title": "Definition and implementation of a flexible communication primitive for distributed programming\n", "abstract": " Distributed programming has to face problems due to asynchronism of underlying communication networks. If for some applications the only use of FIFO channels eliminates the undesired effets due to asynchronism, this is generally not sufficient. Total or causal order of deliveries of messages have been proposed to overcome such problems but in some cases these orders impose a too strong property that can reduce the potential parallelism of the application. This paper proposes a flexible broadcast primitive that attaches a type (ordinary or causal) to each message, these types impose constraints on messages deliveries. In that way the programmer is able to exploit the potential parallelism of this application in order to get an efficient program.", "num_citations": "4\n", "authors": ["495"]}
{"title": "Elements for a course on the design of distributed algorithms\n", "abstract": " Sequential algorithms design and operating system principles have always been fundamental courses in any computer science curriculum. Protocols are now a well established discipline, and parallelism and concurrency issues are becoming more and more popular in academic courses. Along these guidelines distributed algorithms have now emerged as a proper topic of computer science; studying them demands some prerequisite on algorithms, parallelism and protocols but they cannot themselves be reduced to these three domains.In this paper we present elements for a course on the design of distributed algorithms performing common operating system services. The fundamental aspects of this course lie in teaching the students that no global state can be instantaneously caught because of the asynchronism of the processes and message transmission delays. We state basis problems addressed during the\u00a0\u2026", "num_citations": "4\n", "authors": ["495"]}
{"title": "Communication E cient Distributed Shared Memories\n", "abstract": " Recently, distributed shared memory (DSM) systems have received much attention because such an abstraction simpli es programming. An important class of DSM implementations is one which uses cache memories to improve e ciency. In this paper, we present a cache-consistency protocol which uses considerably less communication as compared to previously proposed protocols. This is realized by maintaining state information and capturing causal relations among read and write operations. We prove that the protocol satis es a formulation of sequential consistency. We also present several modi cations to the protocol and compare the classes of execution histories captured by these protocols and several previously proposed protocols.", "num_citations": "4\n", "authors": ["495"]}
{"title": "Simulation r\u00e9partie: sch\u00e9mas d'ex\u00e9cution pour un mod\u00e8le \u00e0 processus\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "4\n", "authors": ["495"]}
{"title": "Distributed Algorithms: 3rd International Workshop, Nice, France, September 26-28, 1989. Proceedings\n", "abstract": " This book includes the papers presented at the Third International Workshop on Distributed Algorithms organized at La Colle-sur-Loup, near Nice, France, September 26-28, 1989 which followed the first two successful international workshops in Ottawa (1985) and Amsterdam (1987). This workshop provided a forum for researchers and others interested in distributed algorithms on communication networks, graphs, and decentralized systems. The aim was to present recent research results, explore directions for future research, and identify common fundamental techniques that serve as building blocks in many distributed algorithms. Papers describe original results in all areas of distributed algorithms and their applications, including: distributed combinatorial algorithms, distributed graph algorithms, distributed algorithms for control and communication, distributed database techniques, distributed algorithms for decentralized systems, fail-safe and fault-tolerant distributed algorithms, distributed optimization algorithms, routing algorithms, design of network protocols, algorithms for transaction management, composition of distributed algorithms, and analysis of distributed algorithms.", "num_citations": "4\n", "authors": ["495"]}
{"title": "Un sch\u00e9ma abstrait d'it\u00e9ration r\u00e9partie\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "4\n", "authors": ["495"]}
{"title": "Traversal and learning in a network of communicating processes.\n", "abstract": " Developments in distributed systems are being increasingly influenced by user pressure and progress in hardware. Users are expecting more in the way of availability of services, in the event of hardware or software breakdown, and in terms of better performance. Distributed algorithms are made up of a network of processes communicating by exchanging messages. Many of them, whose role is to implement a control function, require the implementation of network traversal by messages, or have to allow a given process to obtain overall information distributed throughout the network. This article examines both these issues. The authors introduce a general technique which they call transfer control and which sets out to reduce the number of messages exchanged. Apart from their originality, the value of the traversal and learning models obtained lies in their generality and their efficiency. Application examples are\u00a0\u2026", "num_citations": "4\n", "authors": ["495"]}
{"title": "Calcul distribu\u00e9 d'un extremum et du routage associ\u00e9 dans un r\u00e9seau quelconque\n", "abstract": " Deux algorithmes distribu\u00e9s r\u00e9alisant une \u00e9lection dans un syst\u00e8me distribu\u00e9 sont pr\u00e9sent\u00e9s. Leur originalit\u00e9 r\u00e9side dans les hypoth\u00e8ses qu\u2019ils in\u00e9cessitent et les techniques qu\u2019ils utilisent. Aucune hypoth\u00e8se particuli\u00e8re n\u2019est faite sur le graphe qui mod\u00e9lise le r\u00e9seau si ce n'est sa connexit\u00e9; de plus aucun des processus n\u2019a besoin de connaitre ni la structure globale du r\u00e9seau ni m\u00eame sa taille. Les algorithmes sont donc en ce sens enti\u00e8rement distriHb\u00e9s, et se distinguent fondamentalement des algorithmes qui s\u2019 appuient sur une topologie particuli\u00e8re connue de tous (tel qu\u2019un anneau ou un maillage complet par exemple).'Fond\u00e9e sur un m\u00eame principe: l\u2019extinction selective de messages, les algorithmes propos\u00e9s g\u00e9n\u00e9ralisent au contexte distribu\u00e9 les strat\u00e9gies de recherche s\u00e9quentielle en profondeur et en largeur d\u2019abord; des techniques et des outils sp\u00e9cialement adapt\u00e9s sont introduits \u00e0 cette fin.", "num_citations": "4\n", "authors": ["495"]}
{"title": "D\u00e9tecter la perte de jetons et les r\u00e9g\u00e9n\u00e9rer sur une structure en anneau\n", "abstract": " De nombreux syst\u00e8mes distribu\u00e9s utilisent des structures en'anneau sur lesquelles circulent des messages sp\u00e9claux (les jetons) r\u00e9alisant'le contr\u00f4le des applications. La fiabilit\u00e9 des algorithmes de contr0ie dlstribu\u00e9 n\u00e9cessite alors de savoir d\u00e9tecter la perte des jetons et. si tel est le cas. de les reg\u00e9n\u00e9rer. C\u2019est a ce probl\u00e8me qu'est consacr\u00e9 ce rapport. Un nouvel algorithme bas\u00e9 sur I'ekistence de plusieurs| etons qui d\u00e9tectent mutuellement leurs pertes respectives est pr\u00e9sent\u00e9. Son orlglnalit\u00e9 est. contrairement aux algorithmes\" classiques\", de n'utiliser ni horloge de garde. ni lden'til\u00e9 des sites qui constituent le syst\u00e8me distribu\u00e9: il est fond\u00e9 sur le principe des compteurs monotones croissants'Abstract: Numerous distributed systems use ring strdctures with special messages (tokens) to control applications. In order to have reliable distributed I controi algorithms, it is necessary to detect the loss of the tokens and if\u00a0\u2026", "num_citations": "4\n", "authors": ["495"]}
{"title": "Self-Stabilizing Indulgent Zero-degrading Binary Consensus\n", "abstract": " Guerraoui proposed an indulgent solution for the binary consensus problem. Namely, he showed that an arbitrary behavior of the failure detector never violates safety requirements even if it compromises liveness. Consensus implementations are often used in a repeated manner. Dutta and Guerraoui proposed a zero-degrading solution, ie, during system runs in which the failure detector behaves perfectly, a node failure during one consensus instance has no impact on the performance of future instances.", "num_citations": "3\n", "authors": ["495"]}
{"title": "Atomic Appends in Asynchronous Byzantine Distributed Ledgers\n", "abstract": " The following topics are dealt with: security of data; formal specification; safety-critical software; risk analysis; fault tolerant computing; genetic algorithms; finite state machines; automata theory; distributed processing; program diagnostics.", "num_citations": "3\n", "authors": ["495"]}
{"title": "Fully anonymous consensus and set agreement algorithms\n", "abstract": " Process anonymity has been studied for a long time. Memory anonymity is more recent. In an anonymous memory system, there is no a priori agreement among the processes on the names of the shared registers they access. As an example, a shared register named A by a process p and a shared register named B by another process q may correspond to the very same register X, while the same name C may correspond to different shared registers for the processes p and q. This article focuses on solving the consensus and set agreement problems in the fully anonymous model, namely a model in which both the processes and the registers are anonymous. It is shown that consensus, and its weak version called set agreement, can be solved despite full anonymity, in the presence of any number of process crashes. As far as we know, this is the first time where non-trivial concurrency-related problems are\u00a0\u2026", "num_citations": "3\n", "authors": ["495"]}
{"title": "An Informal visit to the wonderful land of consensus numbers and beyond\n", "abstract": " Since its introduction by M. Herlihy in 1991, consensus number has be-come a central notion to capture and understand the agreement and synchro-nization power of objects in the presence of asynchrony and any number of process crashes. This notion has now become fundamental in shared mem-ory systems, when one is interested in the design of universal constructions for high level objects defined by a sequential specification.", "num_citations": "3\n", "authors": ["495"]}
{"title": "One for all and all for one: Scalable consensus in a hybrid communication model\n", "abstract": " This paper addresses consensus in an asynchronous model where the processes are partitioned into clusters. Inside each cluster, processes can communicate through a shared memory, which favors efficiency. Moreover, any pair of processes can also communicate through a message-passing communication system, which favors scalability. In such a \u201chybrid communication\u201d context, the paper presents two simple binary consensus algorithms (one based on local coins, the other one based on a common coin). These algorithms are straightforward extensions of existing message-passing randomized round-based consensus algorithms. At each round, the processes of each cluster first agree on the same value (using an underlying shared memory consensus algorithm), and then use a message-passing algorithm to converge on the same decided value. The algorithms are such that, if all except one processes of a\u00a0\u2026", "num_citations": "3\n", "authors": ["495"]}
{"title": "On the weakest failure detector for read/write-based mutual exclusion\n", "abstract": " Failure detectors are devices (objects) that provides the processes with information on failures. They were introduced to enrich asynchronous systems so that it becomes possible to solve problems (or implement concurrent objects) that are otherwise impossible to solve in pure asynchronous systems where processes are prone to crash failures. The most famous failure detector (which is called \u201ceventual leader\u201d and denoted $$\\varOmega $$) is the weakest failure detector which allows consensus to be solved in n-process asynchronous systems where up\u00a0to $$t=n-1$$ processes may crash in the read/write communication model, and up\u00a0to $$t<n/2$$ processes may crash in the message-passing communication model.             When looking at the mutual exclusion problem (or equivalently the construction of a lock object), while the weakest failure detectors are known for both asynchronous message-passing\u00a0\u2026", "num_citations": "3\n", "authors": ["495"]}
{"title": "Set agreement and renaming in the presence of contention-related crash failures\n", "abstract": " A new notion of process failure explicitly related to contention has recently been introduced by one of the authors (NETYS 2018). More precisely, given a predefined contention threshold , this notion considers the executions in which process crashes are restricted to occur only when process contention is smaller than or equal to . If crashes occur after contention bypassed , there are no correctness guarantees (e.g., termination is not guaranteed). It was shown that, when , consensus can be solved in an n-process asynchronous read/write system despite the crash of one process, thereby circumventing the well-known FLP impossibility result. Furthermore, it was shown that when  and , k-set agreement can be solved despite the crash of  processes.               This paper considers two types of process crash failures: \u201c-constrained\u201d crash failures (as previously defined), and classical crash failures (that we call \u201cany time\u00a0\u2026", "num_citations": "3\n", "authors": ["495"]}
{"title": "On additivity in transformation languages\n", "abstract": " Some areas in computer science are characterized by a shared base structure for data artifacts (e.g., list, table, tree, graph, model), and dedicated languages for transforming this structure. We observe that in several of these languages it is possible to identify a clear correspondence between some elements in the transformation code and the output they generate. Conversely given an element in an output artifact it is often possible to immediately trace the transformation parts that are responsible for its creation. In this paper we formalize this intuitive concept by defining a property that characterizes several transformation languages in different domains. We name this property additivity: for a given fixed input, the addition or removal of program elements results in a corresponding addition or removal of parts of the output. We provide a formal definition for additivity and argue that additivity enhances modularity and\u00a0\u2026", "num_citations": "3\n", "authors": ["495"]}
{"title": "Which Broadcast Abstraction Captures -Set Agreement?\n", "abstract": " It is well-known that consensus (one-set agreement) and total order broadcast are equivalent in asynchronous systems prone to process crash failures. Considering wait-free systems, this article addresses and answers the following question: which is the communication abstraction that \"captures\" -set agreement? To this end, it introduces a new broadcast communication abstraction, called -BO-Broadcast, which restricts the disagreement on the local deliveries of the messages that have been broadcast (-BO-Broadcast boils down to total order broadcast). Hence, in this context,  is not a special number, but only the first integer in an increasing integer sequence. This establishes a new \"correspondence\" between distributed agreement problems and communication abstractions, which enriches our understanding of the relations linking fundamental issues of fault-tolerant distributed computing.", "num_citations": "3\n", "authors": ["495"]}
{"title": "Vertex coloring with communication and local memory constraints in synchronous broadcast networks\n", "abstract": " This paper considers the broadcast/receive communication model in which message collisions and message conflicts can occur because processes share frequency bands. (A collision occurs when, during the same round, messages are sent to the same process by too many neighbors. A conflict occurs when a process and one of its neighbors broadcast during the same round.) More precisely, the paper considers the case where, during a round, a process may either broadcast a message to its neighbors or receive a message from at most m of them. This captures communication-related constraints or a local memory constraint stating that, whatever the number of neighbors of a process, its local memory allows it to receive and store at most m messages during each round. The paper defines first the corresponding generic vertex multi-coloring problem (a vertex can have several colors). It focuses then on tree\u00a0\u2026", "num_citations": "3\n", "authors": ["495"]}
{"title": "Optimal collision/conflict-free distance-2 coloring in synchronous broadcast/receive tree networks\n", "abstract": " This article is on message-passing systems where communication is (a) synchronous and (b) based on the \"broadcast/receive\" pair of communication operations. \"Synchronous\" means that time is discrete and appears as a sequence of time slots (or rounds) such that each message is received in the very same round in which it is sent. \"Broadcast/receive\" means that during a round a process can either broadcast a message to its neighbors or receive a message from one of them. In such a communication model, no two neighbors of the same process, nor a process and any of its neighbors, must be allowed to broadcast during the same time slot (thereby preventing message collisions in the first case, and message conflicts in the second case). From a graph theory point of view, the allocation of slots to processes is know as the distance-2 coloring problem: a color must be associated with each process (defining the time slots in which it will be allowed to broadcast) in such a way that any two processes at distance at most 2 obtain different colors, while the total number of colors is \"as small as possible\". The paper presents a parallel message-passing distance-2 coloring algorithm suited to trees, whose roots are dynamically defined. This algorithm, which is itself collision-free and conflict-free, uses  colors where  is the maximal degree of the graph (hence the algorithm is color-optimal). It does not require all processes to have different initial identities, and its time complexity is , where d is the depth of the tree. As far as we know, this is the first distributed distance-2 coloring algorithm designed for the broadcast/receive round-based\u00a0\u2026", "num_citations": "3\n", "authors": ["495"]}
{"title": "Concurrent systems: hybrid object implementations and abortable objects\n", "abstract": " As they allow processes to communicate and synchronize, concurrent objects are, de facto, the most important objects of concurrent programming. This paper presents and illustrates two important notions associated with concurrent objects. The first one, which is related to their implementation, is the notion of a hybrid implementation. The second one, which is related to their definition, is the notion of an abortable object.", "num_citations": "3\n", "authors": ["495"]}
{"title": "Simple deadlock detection for the and-communication model\n", "abstract": " The advent of multicore architectures is a good incentive to revisit base synchronization mechanisms. Among them, the AND communication model is particularly attractive. This communication model provides the processes with a receive operation denoted receive (DS) where DS is a dynamically defined set of processes (DS stands for \"dependency set\"). The receive operation blocks the invoking process until it has received a message from each process appearing in the dynamically defined set DS. When this occurs, the invoking process consumes these messages and continues its execution. While it simplifies concurrent programming, this high-level communication operation is deadlock-prone. This paper presents a very simple algorithm which allows to detect on the fly communication deadlock in the AND communication model.", "num_citations": "3\n", "authors": ["495"]}
{"title": "Logical Time in Distributed Systems\n", "abstract": " Aim\u2022 Build a logical time in order to be able to associate a consistent date with events, ie, e\u2212\u2192 f\u21d2 date (e)< date (f)", "num_citations": "3\n", "authors": ["495"]}
{"title": "Distributed termination detection\n", "abstract": " This chapter is on the detection of the termination of a distributed computation. This problem was posed and solved for the first time in the early 1980s independently by E.W. Dijkstra and C.S. Scholten (1980) and N. Francez (1980). This is a non-trivial problem. While, in sequential computing, the termination of the only process indicates that the computation has terminated, this is no longer true in distributed computing. Even if we were able to observe simultaneously all the processes, observing all of them passive could not allow us to conclude that the distributed execution has terminated. This is because some messages can still be in transit, which will reactivate their destination processes when they arrive, and these re-activations will, in turn, entail the sending of new messages, etc.             This chapter presents several models of asynchronous computations and observation/detection algorithms suited to\u00a0\u2026", "num_citations": "3\n", "authors": ["495"]}
{"title": "From a store-collect object and \u2126 to efficient asynchronous consensus\n", "abstract": " This paper presents an efficient algorithm that build a consensus object. This algorithm is based on an \u03a9 failure detector (to obtain consensus liveness) and a store-collect object (to maintain its safety). A store-collect object provides the processes with two operations, a store operation which allows the invoking process to deposit a new value while discarding the previous value it has deposited and a collect operation that returns to the invoking process a set of pairs (i, val) where val is the last value deposited by the process p                                    i                 . A store-collect object has no sequential specification.               While store-collect objects have been used as base objects to design wait-free constructions of more sophisticated objects (such as snapshot or renaming objects), as far as we know, they have not been explicitly used to built consensus objects. The proposed store-collect-based algorithm, which\u00a0\u2026", "num_citations": "3\n", "authors": ["495"]}
{"title": "A contention-friendly, non-blocking skip list\n", "abstract": " This paper presents a new non-blocking skip list algorithm. The algorithm alleviates contention by localizing synchronization at the least contended part of the structure without altering consistency of the implemented abstraction. The key idea lies in decoupling a modification to the structure into two stages: an eager abstract modification that returns quickly and whose update affects only the bottom of the structure, and a lazy selective adaptation updating potentially the entire structure but executed continuously in the background. As non-blocking skip lists are becoming appealing alternatives to latch-based trees in modern main-memory databases, we integrated it into a main-memory database benchmark, SPECjbb. On SPECjbb as well as on micro-benchmarks, we compared the performance of our new non-blocking skip list against the performance of the JDK non-blocking skip list. Results indicate that our implementation is up to 2:5 faster than the JDK skip list.", "num_citations": "3\n", "authors": ["495"]}
{"title": "A theory-oriented introduction to wait-free synchronization based on the adaptive renaming problem\n", "abstract": " The recent deployment of multiprocessors (such as multicores) as the mainstream computing platform has given rise to a new concurrent programming impetus. In such a context it becomes extremely important to be able to design shared objects that can cope with the net effect of asynchrony and process crashes. This paper is a theory-oriented introduction to wait-free synchronization for such systems. It uses the adaptive renaming problem as a paradigm to explain the difficulties and subtleties of synchronization in presence of process crashes. Renaming is one of the most famous coordination problems studied in distributed computability. It consists in assigning new names to processes in such a way that no two processes obtain the same new name and the new name space be as small as possible. The paper visits the problem by presenting three solutions. This paper, that has a strong survey/short tutorial flavor\u00a0\u2026", "num_citations": "3\n", "authors": ["495"]}
{"title": "Small-World Networks: Is there a mismatch between theory and practice?\n", "abstract": " In small-world networks, each peer is connected to its closest neighbors in the network topology, as well as to additional long-range contact(s), also called shortcut(s). In 2000, Kleinberg showed that greedy routing in a  peer small-world network, performs in  steps when the distance to shortcuts is chosen uniformly at random, and in  when the distance to shortcuts is chosen according to a harmonic distribution in a -dimensional mesh. Yet, we observe through experimental results that peer to peer gossip-based protocols achieving small-world topologies where shortcuts are randomly chosen, perform well in practice. The motivation of this paper is to explore this mismatch and attempt to reconcile theory and practice in the context of small-world overlay networks. More precisely, based on the observation that, despite the fact that the routing complexity of gossip-based small-world overlay networks is not polylogarithmic (as proved by Kleinberg), this type of networks ultimately provide reasonable results in practice. This leads us to think that the asymptotic big  complexity alone might not always be sufficient to assess the practicality of a system. The paper consequently proposes a refined routing complexity measure for small-world networks. Simulation results confirm that random selection of shortcuts can achieve ``practical'' systems. Then, given that Kleinberg proved that the distribution of shortcuts has a strong impact on the routing complexity, arises the question of leveraging this result to improve upon current gossip-based protocols. We show that it is possible to design gossip-based protocols providing a good approximation of\u00a0\u2026", "num_citations": "3\n", "authors": ["495"]}
{"title": "Fault-Tolerant techniques for concurrent objects\n", "abstract": " Devising wait-free resilient implementations of concurrent objects from fault-prone base objects is a fundamental challenge of computer science. Wait-free means that any process that invokes an operation eventually receives a reply after executing a finite number of its own steps, even if other processes are arbitrarily slow or even failed. Resilience means that the implementation of the concurrent object behaves correctly despite the failure of up to t base objects (t being a threshold parameter a priori defined). The tutorial surveys different techniques to build wait-free resilient implementations of concurrent objects. Three complementary classes of techniques are presented: (1) fault-tolerance \u201cby replication\u201d, (2) fault-tolerance \u201cby diversity\u201d, and (3) fault-tolerance \u201cby oracle\u201d, respectively. The first is the well-known redundancy technique and its applicability depends on the kinds of faults that the objects can\u00a0\u2026", "num_citations": "3\n", "authors": ["495"]}
{"title": "Wait-free computing: an introductory lecture\n", "abstract": " This paper is a short introduction to wait-free computing. \u201cWait-free\u201d means that the progress of a process depends only on it, regardless of the other processes (that can progress slowly or even crash). To illustrate wait-free computing, the paper considers the design of two concurrent objects, namely, a renaming object and a snapshot object. A renaming object allows the processes to acquire new names from a smaller name space despite possible process crashes. A snapshot object provides the processes with an array-like data structure (with one entry per process) offering two operations. The write operation allows a process to update its own entry. The snapshot operation allows a process to read all the entries in such a way that the reading of the whole array appears as it is was an atomic operation. A renaming protocol by Moir and Anderson and a snapshot protocol by Afek et al. are used to illustrate the beauty\u00a0\u2026", "num_citations": "3\n", "authors": ["495"]}
{"title": "The Notion of Veto Number and the Respective Power of $\\Diamond {\\cal P} $ and $\\Diamond {\\cal S} $ to Solve One-Shot Agreement Problems\n", "abstract": " Unreliable failure detectors are abstract devices that, when added to asynchronous distributed systems, allow to solve distributed computing problems (e.g., Consensus) that otherwise would be impossible to solve in these systems. This paper focuses on two classes of failure detectors defined by Chandra and Toueg, namely, the classes denoted $\\Diamond {\\cal P}$ (eventually perfect) and $\\Diamond {\\cal S}$ (eventually strong). Both classes include failure detectors that eventually detect permanently all process crashes, but while the failure detectors of $\\Diamond {\\cal P}$ eventually make no erroneous suspicions, the failure detectors of $\\Diamond {\\cal S}$ are only required to eventually not suspect a single correct process.             In such a context, this paper addresses the following question related to the comparative power of these classes, namely: \u201cAre there one-shot agreement problems that can be\u00a0\u2026", "num_citations": "3\n", "authors": ["495"]}
{"title": "Wait-free objects for real-time systems?\n", "abstract": " The aim of this position paper is to promote the use of wait-free implementations for real-time shared objects. Such implementations allow the nonfaulty processes to progress despite the fact the other processes are slow, fast or have crashed. This is a noteworthy property for shared real-time objects. To assess its claim, the paper considers wait-free implementations of three objects: a renaming object, an efficient store/collect object, and a consensus object. On an other side, the paper can also be seen as an introductory survey, to wait-free protocols.", "num_citations": "3\n", "authors": ["495"]}
{"title": "Approximate real-time clocks for scheduled events\n", "abstract": " This paper presents a simple protocol that provides application processes with an approximate real-time notion. This time notion is very versatile. At one extreme, it behaves at least as virtual time (being thereby consistent with causality). At the other extreme, it behaves as real-time. More precisely, with respect to approximate real-time all scheduled events are always executed at their scheduled time. If local computations took no time, approximate real-time would always be real-time. The system facilitates the rescheduling of events to bring real-time and approximate time closer together if local computations take too much time. A time-slotted leader election protocol using the proposed approximate time notion is described.", "num_citations": "3\n", "authors": ["495"]}
{"title": "Building TMR-based reliable servers despite bounded input lifetimes\n", "abstract": " This paper comes from practical considerations [5]. It considers a client-server system made up of an arbitrary large number of clients that access a single server. To access the server, a client issues an input request and possibly waits for an answer. Then, the server processes the client input and sends back the result (if any) to the client.", "num_citations": "3\n", "authors": ["495"]}
{"title": "Consensus based on strong failure detectors: Time and message-efficient protocols\n", "abstract": " The class of strong failure detectors (denoted S) includes all failure detectors that suspect all crashed processes and that do not suspect some (a priori unknown) process that never crashes. So, a failure detector that belongs to S is intrinsically unreliable as it can arbitrarily suspect correct processes. Several S-based consensus protocols have been designed. Some of them systematically require n computation rounds (n being the number of processes), each round involving n2 or n messages. Others allow early decision (i.e., the number of rounds depends on the maximal number of crashes when there are no erroneous suspicions) but require each round to involve n2 messages. This paper presents an early deciding S-based consensus protocol each round of which involves 3(n-1) messages. So, the proposed protocol is particularly time and message-efficient. Moreover, it can easily be generalized to reduce the number of rounds at the price of an increase in the number of messages per round.", "num_citations": "3\n", "authors": ["495"]}
{"title": "Rollback-dependency trackability: an optimal characterization and its protocol\n", "abstract": " Considering a checkpoint and communication pattern, the Rollback Dependency Trackability (RDT) property stipulates that there is no hidden dependency between local checkpoints. In other words, if there is a dependency between two checkpoints due to a non-causal sequence of messages, then there must exist a causal sequence of messages that\\doubles\" the non-causal one and that establishes the same dependency.This paper provides a minimal characterization of the RDT property. This characterization de nes the smallest set of non-causal sequences of messages that have to be doubled in order to ensure the RDT property. Then, we consider the family of communication-induced checkpointing protocols that ensure on-the-y the RDT property. Assuming processes take local checkpoints independently (called basic checkpoints), protocols of this family direct them to take on-the-y additional local checkpoints (called forced checkpoints) in order that the resulting checkpoint and communication pattern satis es the RDT property. A new protocol belonging to that family is presented and it is shown that this protocol is optimal in terms of the number of forced checkpoints and in terms of the size of data structures it requires. The protocol attains this goal by a subtle tracking of causal dependencies on already taken checkpoints; this tracking is then used to prevent the occurrence of hidden dependencies. Finally a set of non-optimal protocols are derived from the optimal one. These derivations show a tradeo between the size of the control information required by a protocol and the number of forced checkpoints it takes. It is interesting to note that\u00a0\u2026", "num_citations": "3\n", "authors": ["495"]}
{"title": "Distributed Algorithms: 9th International Workshop, WDAG'95, Le Mont-Saint-Michel, France, September 13-15, 1995. Proceedings\n", "abstract": " This book constitutes the proceedings of the 9th International Workshop on Distributed Algorithms, WDAG'95, held in Le Mont-Saint-Michel, France in September 1995. Besides four invited contributions, 18 full revised research papers are presented, selected from a total of 48 submissions during a careful refereeing process. The papers document the progress achieved in the area since the predecessor workshop (LNCS 857); they are organized in sections on asynchronous systems, networks, shared memory, Byzantine failures, self-stabilization, and detection of properties.", "num_citations": "3\n", "authors": ["495"]}
{"title": "Deadlocks in distributed systems: request models and definitions\n", "abstract": " The paper addresses the problem of deadlock detection in asynchronous distributed systems for system model that covers unspecified receptions and non-FIFO channels. It presents a hierarchy of deadlock models considered till now, and then abstracts away their differences to define a single, general deadlock model. This general model is used to introduce abstract formulation of basic deadlock detection problems, and to specify distributed algorithm which uniformly addresses deadlock detection problem for various request models. Finally, in this context, termination detection problem is also considered.", "num_citations": "3\n", "authors": ["495"]}
{"title": "A graph-based characterization of communications modes in distributed executions\n", "abstract": " The main problem of asynchronous distributed systems is to master the uncertainty created by the asynchrony of communication networks and by the possibility of failures. This uncertainty arises to the user as the impossibility in getting instantaneously a global state of his application, or in knowing exactly which components of the system have failed. He can only get a previous consistent state of the application [5] or can only suspect failures of some components [3, 4]. To cope with failures in asynchronous systems Chandra and Toueg proposed the concept of failure detector [4]; such an entity allows groups of processes (or nodes) to eventually agree on a set of\" suspected processes\". The problem is that if a process is suspected to be failed (because it really failed or it reacts too slowly to queries), it should be suspected by all the processes of the group. It is shown in [4] how this concept can be used to solve distributed problems such as consensus and atomic broadcast. To cope with the asynchrony of communication channels basic communication modes have been defined: rendez-vous (sometimes called synchronous), logically instantaneous, causally ordered and First-in-First-out (FIFO) are the most known and used. Rendez-vous [7] is a communication mode that defines at the same physical time a communication and a (strong) synchronization: both the sender and the receiver of a message have to synchronize in order that the communication be realized (it is as if the communication took place through a buffer of size 0). A weakening of rendez-vous gives the logical instantaneous communication mode [15], it requires only that\u00a0\u2026", "num_citations": "3\n", "authors": ["495"]}
{"title": "On Granularity of Events in Distributed Computations.\n", "abstract": " This paper deals with event granularity within the distributed application context. Several ways of clustering basic events into high-level events are addressed. Properties of these event structures are investigated and their relationships to some distributed programming constructions are exposed.", "num_citations": "3\n", "authors": ["495"]}
{"title": "How to find his way in the jungle of consistency criteria for distributed objects memories (or how to escape from minos' labyrinth)\n", "abstract": " This paper surveys consistency criteria that have been proposed and sometimes implemented, for shared distributed objects and memories. Linearizability, sequential consistency, hybrid consistency and causal consistency are particularly emphasized, some protocols implementing these criteria are described. It is suggested that the hybrid consistency frame, introduced by Attiya and Friedman, constitutes the Ariadne's clew to undestand this jungle of consistency criteria.", "num_citations": "3\n", "authors": ["495"]}
{"title": "Sequence-based global predicates for distributed computations: definitions and detection algorithms\n", "abstract": " We consider the problem of detecting sequences of predicates defined over global states of distributed computation. We introduce two new global predicate classes called simple sequences and interval-constrained sequences that define causally-ordered sets of desirable states along with intervening forbidden states. Our formalism is more general than former proposals and permits concise and intuitive expression of many interesting system properties. Algorithms are given for verifying formulas belonging to these predicate classes in an on-line and observer-independent manner during distributed computations. We illustrate the utility of our results by applying them to examples drawn from programs testing, debugging and dynamic reconfiguration in distributed systems.", "num_citations": "3\n", "authors": ["495"]}
{"title": "Implementation and evaluation of distributed synchronization on a distributed memory parallel machine\n", "abstract": " Advent of distributed memory parallel machines make possible to study and analyze distributed algorithms in a real context. In this paper we are interested in a paradigm of distributed computing : the implementation of (binary and multiway) rendez-vous. This problem actually includes two subproblems encountered in several synchronization problems : how to realize a coordination (of the processes involved in the rendez-vous) and how to ensure some exclusion (between conflicting rendez-vous sharing some processes). Several algorithms implementing rendez-vous are presented. Implementations of these protocols on an hypercube are analyzed and compared according to a certain number of parameters ; an efficiency ratio is introduced in order to make these comparisons easier. In addition to the results exhibited, this paper suggests a way to conduct such experiments.", "num_citations": "3\n", "authors": ["495"]}
{"title": "Vers la construction raisonn\u00e9e d'algorithmes r\u00e9partis: le cas de la terminaison\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "3\n", "authors": ["495"]}
{"title": "A general method to define quorums\n", "abstract": " Un certain nombre de protocoles utilises dans les systemes repartis sont fondes sur 1 utilisation de quorums (c'est par exemple le cas pour assurer la coherence mutuelle des donnees dans les bases de donnees reparties ou pour resister aux defaillances dans les systemes d exploitation repartis). Les methodes traditionnelles utilisent des mecanismes de votes pour implementer les quorums. Plusieurs auteurs ont propose d autres methodes (fondees sur des structurations logiques des sites en arbre ou en grille) afin d en ameliorer les performances.Dans cet article une methode tres generale est presentee pour definir des quorums; elle est accompagnee d une procedure efficace permettant de decider si un ensemble donne contient un quorum. Il est montre que cette methode, appelee composition, bien qu'extremement simple, est plus generale que les autres. Il est egalement montre que cette methode de\u00a0\u2026", "num_citations": "3\n", "authors": ["495"]}
{"title": "The asymptotic local approach to change detection and model validation\n", "abstract": " On pr\u00e9sente une approche syst\u00e9matique pour la conception d \u2018algorithmes de d\u00e9tection de changements et de validation de mod\u00e8les pour les syst\u00e8mes dynamiques. On montre comment associer \u00e0 tout algorithme d'identification des proc\u00e9dures de d\u00e9\u2014tection de changements et de validation de mod\u00e8les qui sont optimales asymptotique\u2014ment en un certain sens. les fondements de notre m\u00e9thode s' appuient sur l'approche asymptotique locale des Statisticiens, et notre m\u00e9thode g\u00e9n\u00e9ralise cette approche.ABSTRACI \u2018We present a systematic approach for the design of change detection and model validation algorithms for dynamical systems. We show how to associate to any'identi\ufb01cation algorithm a change detection and a model validation procedures, whicb are optimal in some asymptotic meaning. The foundations of our method go back to the \u201casymptotic local\" approach in Statistics, and our method\u00a0\u2026", "num_citations": "3\n", "authors": ["495"]}
{"title": "An experience in implementing abstract data types\n", "abstract": " The abstract data type concept appears to be a useful software structuring tool. A project, called \u2018Syst\u00e8me d'Objets Conserv\u00e9s\u2019, which was developed at the University of Rennes, (France), gave some experience in implementing this concept. The possibility of including abstract data type into a pre\u2010existing compiler is demonstrated, and desirable properties of the host language are exhibited. Provision of external procedures and data makes some type checking extensions necessary: these features increase software reliability.", "num_citations": "3\n", "authors": ["495"]}
{"title": "Les parcours distribu\u00e9s de r\u00e9seaux: un outil pour la conception de protocoles\n", "abstract": " Un certain nombre de protocoles et d\u2019algorithmes distribu\u00e9s rencontr\u00e9s dans les systemes r\u00e9partis reposent sur un m\u00eame fondement algorithmique: les parcours de r\u00e9seau. On examine ici un tel parcours: le parcours dit s\u00e9quentiel. Celui-ci est illustr\u00e9a l\u2019aide d\u2019une de ses utilisations possibles: l\u2019attribution d\u2019identit\u00e9s distinctes aux sites d\u2019un systeme r\u00e9parti anonyme;(un tel algorithme rend la d\u00e9finition des sites ind\u00e9pendante de valeurs initiales particulieres, du point de vue des identit\u00e9s). En plus du r\u00e9sultat apport\u00e9, l\u2019algorithme obtenu est int\u00e9ressant par sa construction m\u00eame: la structure de contr\u00f4le de base qu\u2019est le parcours de r\u00e9seau (qui permet d\u2019effectuer une visite\u2013ayant certaines propri\u00e9t\u00e9s\u2013de tous les sites) est d\u2019abord d\u00e9gag\u00e9e puis des actions permettant de r\u00e9aliser le calcul voulu sont greff\u00e9es sur ce parcours. Cette approche m\u00e9thodique est la cons\u00e9quence directe de la technique de parcours employ\u00e9e et peut \u00eatre utilis\u00e9e pour r\u00e9soudre d\u2019autres problemes.", "num_citations": "3\n", "authors": ["495"]}
{"title": "Byzantine-tolerant causal broadcast\n", "abstract": " Causal broadcast is a communication abstraction built on top of point-to-point send/receive networks that ensures that any two messages whose broadcasts are causally related (as captured by Lamport's \u201chappened before\u201d relation) are delivered in their sending order. Several causal broadcast algorithms have been designed for failure-free and crash-prone asynchronous message-passing systems.This article first gives a formal definition of a causal broadcast abstraction in the presence of Byzantine processes, in the form of two equivalent characterizations, and then presents a simple causal broadcast algorithm that implements it. The main difficulty in the design and the proof of this algorithm comes from the very nature of Byzantine faults: Byzantine processes may have arbitrary behavior, and the algorithm must ensure that correct processes (i) maintain a coherent view of causality and (ii) are never prevented\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "An eventually perfect failure detector for networks of arbitrary topology connected with ADD channels using time-to-live values\n", "abstract": " We present an implementation of an eventually perfect failure detector in an arbitrarily connected, partitionable network. We assume ADD channels: for each one there exist constants , , not known to the processes, such that for every  consecutive messages sent in one direction, at least one is delivered within time . The best previous implementation used messages of bounded size, but exponential in , the number of nodes. The main contribution of this paper is a novel use of time-to-live values in the design of failure detectors, obtaining a flexible implementation that uses messages of size .", "num_citations": "2\n", "authors": ["495"]}
{"title": "Bee\u2019s Strategy Against  Byzantines Replacing Byzantine Participants\n", "abstract": " Schemes for the identification and replacement of two-faced Byzantine processes are presented. The detection is based on the comparison of the (blackbox) decision result of a Byzantine consensus on input consisting of the inputs of each of the processes, in a system containing n processes $$p_1,\\dots , p_n$$. Process $$p_i$$ that received a gossiped message from $$p_j$$ with the input of another process $$p_k$$, that differs from $$p_k$$\u2019s input value as received from $$p_k$$ by $$p_i$$, reports on $$p_k$$ and $$p_j$$ being two-faced. If enough processes (where enough means at least $$t+1$$, $$t<n$$ is a threshold on the number of Byzantine participants) report on the same participant $$p_j$$ to be two-faced, participant $$p_j$$ is replaced. If less than the required $$t+1$$ processes threshold report on a participant $$p_j$$, both the reporting processes and the reported process are\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "A pleasant stroll through the land of distributed machines, computation, and universality\n", "abstract": " Not only the world is distributed, but more and more applications are distributed. Hence, a fundamental question is the following one: What can be computed in a distributed system? The answer to this question depends on the environment in which evolves the considered distributed system, i.e., on the assumptions the system relies on. This environment is very often left implicit and nearly always not formulated in terms of precise underlying requirements. In the extreme case where the environment is such that there is no synchrony assumption and the computing entities may commit failures, some problems become impossible to solve. Given a distributed computing problem, it is consequently important to know the weakest assumptions (lower bounds) that give the limits beyond which the considered distributed problem cannot be solved. This paper is a short introduction to this kind of issues. It is made up of\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "Time-efficient RFID-based stocktaking with a coarse-grained inventory list\n", "abstract": " RFID-based stocktaking uses RFID technology to verify the presence of objects in a region e.g., a warehouse or a library. The existing approaches for this purpose assume that an inventory list of objects in the interrogation region of an RFID reader is known. This is not true in some cases. For example, for a handheld RFID reader, only the objects in a larger region (e.g., the warehouse) rather than in its interrogation region can be known. The additional objects significantly increase the time required for stocktaking. In this paper, we propose a time-efficient stocktaking algorithm called CLS (Coarse-grained inventory list based stocktaking) to solve this problem. We transform the problem to a missing tag identification problem with a large missing rate. CLS enables multiple missing objects to hash to a single time slot and thus verifies them together. CLS also improves the existing approaches by utilizing more kinds of\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "Modular randomized byzantine k-set agreement in asynchronous message-passing systems\n", "abstract": " k-Set agreement is a central problem of fault-tolerant distributed computing. Considering a set of n processes, where up to t may commit failures, let us assume that each process proposes a value. The problem consists in defining an algorithm such that each non-faulty process decides a value, at most k different values are decided, and the decided values satisfy some context-depending validity condition. Synchronous message-passing algorithms solving k-set agreement have been proposed for different failure models (mainly process crashes, and process Byzantine failures). Differently, k-set agreement cannot be solved in failure-prone asynchronous message-passing systems when t\u2265 k. To circumvent this impossibility an asynchronous system must be enriched with additional computational power.", "num_citations": "2\n", "authors": ["495"]}
{"title": "Distributed slicing in dynamic systems\n", "abstract": " Peer to peer (P2P) systems have moved from application specific architectures to a generic service oriented design philosophy. This raised interesting problems in connection with providing useful P2P middleware services capable of dealing with resource assignment and management in a large-scale, heterogeneous and unreliable environment. The slicing problem consists of partitioning a P2P network into     groups (slices) of a given portion of the network nodes that share similar resource values. As the network is large and dynamic this partitioning is continuously updated without any node knowing the network size. In this paper, we propose the first algorithm to solve the slicing problem. We introduce the metric of slice disorder and show that the existing ordering algorithm cannot nullify this disorder. We propose a new algorithm that speeds up the existing ordering algorithm but that suffers from the same\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "Special issue on distributed computing and networking\n", "abstract": " Special Issue on Distributed Computing and Networking | Theoretical Computer Science ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Theoretical Computer Science Periodical Home Latest Issue Archive Authors Affiliations Award Winners More HomeBrowse by TitlePeriodicalsTheoretical Computer ScienceVol. , No. PBSpecial Issue on Distributed Computing and Networking research-article Special Issue on Distributed Computing and Networking Share on Authors: Michel Raynal Institut Universitaire de France, IRISA, Universit\u00e9 de Rennes, Campus de Beaulieu, Rennes, France Institut Universitaire de France, IRISA, Universit\u00e9 de Rennes, Campus de Beaulieu, Rennes, France View Profile , Franck , \u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "Cliff-edge consensus: agreeing on the precipice\n", "abstract": " This paper presents a new form of consensus that allows nodes to agree locally on the extent of crashed regions in networks of arbitrary size. One key property of our algorithm is that it shows local complexity, i.e. its cost is independent of the size of the complete system, and only depends on the shape and extent of the crashed region to be agreed upon. In this paper, we motivate the need for such an algorithm, formally define this new consensus problem, propose a fault-tolerant solution, and prove its correctness.", "num_citations": "2\n", "authors": ["495"]}
{"title": "Distributed Resource Allocation\n", "abstract": " This chapter is on resource allocation in distributed systems. It first considers the case where there are M instances of the same resource, and a process may request several instances of it. The corresponding resource allocation problem is called k-out-of-M problem (where k, 1\u2264k\u2264M, stands for the\u2014dynamically defined\u2014number of instances requested by a process). Then, the chapter addresses the case where there are several resources, each with a single or several instances.             The multiplicity of resources may generate deadlocks if resources are arbitrarily allocated to processes. Hence, the chapter visits deadlock prevention techniques suited to resource allocation. It also introduces the notion of a conflict graph among processes. Such a graph is a conceptual tool, which captures the possible conflicts among processes, when each resource can be accessed by a subset of processes. Finally, the\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "Asynchronous Distributed Checkpointing\n", "abstract": " This chapter is devoted to checkpointing in asynchronous message-passing systems. It first presents the notions of local and global checkpoints and a theorem stating a necessary and sufficient condition for a set of local checkpoints to belong to the same consistent global checkpoint.             Then, the chapter considers two consistency conditions, which can be associated with a distributed computation enriched with local checkpoints (the corresponding execution is called a communication and checkpoint pattern). The first consistency condition (called z-cycle-freedom) ensures that any local checkpoint, which has been taken by a process, belongs to a consistent global checkpoint. The second consistency condition (called rollback-dependency trackability) is stronger. It states that a consistent global checkpoint can be associated on the fly with each local checkpoint (i.e., without additional communication\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "STM systems: Enforcing strong isolation between transactions and non-transactional code\n", "abstract": " Transactional memory (TM) systems implement the concept of an atomic execution unit called transaction in order to discharge programmers from explicit synchronization management. But when shared data is atomically accessed by both transaction and non-transactional code, a TM system must provide strong isolation in order to overcome consistency problems. Strong isolation enforces ordering between non-transactional operations and transactions and preserves the atomicity of a transaction even with respect to non-transactional code. This paper presents a TM algorithm that implements strong isolation with the following features: (a) concurrency control of non-transactional operations is not based on locks and is particularly efficient, and (b) any non-transactional read or write operation always terminates (there is no notion of commit/abort associated with them).", "num_citations": "2\n", "authors": ["495"]}
{"title": "Leader Election: from higham-przytycka's algorithm to a gracefully degrading algorithm\n", "abstract": " The leader election problem consists in selecting a process (called leader) in a group of processes. Several leader election algorithms have been proposed in the past for ring networks, tree networks, fully connected networks or regular networks (such as tori and hypercubes). As far as ring networks are concerned, it has been shown that the number of messages that processes have to exchange to elect a leader is \u03a9(n log n). The algorithm proposed by Higham and Przytycka is the best leader algorithm known so far for ring networks in terms of message complexity, which is 1.271 n log n + O(n). This algorithm uses round numbers and assumes that all processes start with the same round number. More precisely, when round numbers are not initially equal, the algorithm has runs that do not terminate. This paper presents an algorithm, based on Higham-Przytycka's technique, which allows processes to start with\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "No double discount: Condition-based simultaneity yields limited gain\n", "abstract": " We consider the consensus problem in synchronous message-passing distributed systems. A celebrated result states that every protocol that is guaranteed to tolerate up to t crash failures has a worst-case execution in which some process does not decide before the end of t+ 1 rounds. A variant of the problem in which the set of input vectors is restricted is called condition-based consensus. In this setting, Most\u00e9faoui, Rajsbaum and Raynal defined a natural degree of restriction called the condition of the set of input vectors that a protocol is assumed to handle. The condition is a natural number d\u2a7d t, with a larger condition implying a smaller set of input values. Moreover, they showed that condition-d consensus can be solved in t+ 1\u2212 d rounds in the worst case. Dwork and Moses considered simultaneous consensus, a variant of (unconditional) consensus in which all correct processes must decide in the same round\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "Trying to Unify the LL/SC Synchronization Primitive and the Notion of a Timed Register\n", "abstract": " The aim of this short paper is to show that both the LL/SC (Linked Load/Store Conditional) synchronization primitive and the notion of a Timed register can be seen as two instances of a general abstract synchronization object type that we called a predicate-based read/write synchronization object. More precisely, LL/SC corresponds to its time-free instance while a timed register corresponds to its timed instance. It follows that the notion of a predicate-based read/write synchronization object constitutes a unifying notion that allows for a deeper insight into synchronization objects proposed for multicore architectures.", "num_citations": "2\n", "authors": ["495"]}
{"title": "A survey on some recent advances in shared memory models\n", "abstract": " Due to the advent of multicore machines, shared memory distributed computing models taking into account asynchrony and process crashes are becoming more and more important. This paper visits models for these systems and analyses their properties from a computability point of view. Among them, the base snapshot model and the iterated model are particularly investigated. The paper visits also several approaches that have been proposed to model failures (mainly the wait-free model and the adversary model) and gives also a look at the BG simulation. The aim of this survey is to help the reader to better understand the power and limits of distributed computing shared memory models.", "num_citations": "2\n", "authors": ["495"]}
{"title": "Eventual Leader election with weak assumptions on initial knowledge, communication reliability and synchrony.\n", "abstract": " This paper considers the eventual leader election problem in asynchronous message-passing systems where an arbitrary number t of processes can crash (t < n, where n is the total number of processes). It considers weak assumptions both on the initial knowledge of the processes and on the network behavior. More precisely, initially, a process knows only its identity and the fact that the process identities are different and totally ordered (it knows neither n nor t). Two eventual leader election protocols and a lower bound are presented. The first protocol assumes that a process also knows a lower bound \u03b1 on the number of processes that do not crash. This protocol requires the following behavioral properties from the underlying network: the graph made up of the correct processes and fair lossy links is strongly connected, and there is a correct process connected to (n \u2212 f) \u2212 \u03b1 other correct processes (where f is the\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "Principles of Distributed Systems: 13th International Conference, OPODIS 2009, N\u00eemes, France, December 15-18, 2009. Proceedings\n", "abstract": " This book constitutes the refereed proceedings of the 13th International Conference on Principles of Distributed Systems, OPODIS 2009, held in Nimes, France, in December 2009. The 23 full papers and 4 short papers presented were carefully reviewed and selected from 72 submissions. The papers are organized in topical sections on distributed scheduling, distributed robotics, fault and failure detection, wireless and social networks, synchronization, storage systems, distributed agreement, and distributed algorithms.", "num_citations": "2\n", "authors": ["495"]}
{"title": "Joining a Distributed Shared Memory Computation in a Dynamic Distributed System\n", "abstract": " This paper is on the implementation of high level communication abstractions in dynamic systems (i.e., systems where the entities can enter and leave arbitrarily). Two abstractions are investigated, namely the read/write register and add/remove/get set data structure. The paper studies the join protocol that a process has to execute when it enters the system, in order to obtain a consistent copy of the (register or set) object despite the uncertainty created by the net effect of concurrency and dynamicity. It presents two join protocols, one for each abstraction, with provable guarantees.", "num_citations": "2\n", "authors": ["495"]}
{"title": "A note on atomicity: Boosting Test&Set to solve consensus\n", "abstract": " This short note shows how a simple extension of object types with consensus number 2 boosts them to an infinite consensus number. This extension is a simple embedding of a shared memory write within the base operation defining the corresponding type with consensus number 2. The style of this note is voluntarily informal.", "num_citations": "2\n", "authors": ["495"]}
{"title": "Narrowing power vs. efficiency in synchronous set agreement\n", "abstract": " The k-set agreement problem is a generalization of the uniform consensus problem: each process proposes a value, and each non-faulty process has to decide a value such that a decided value is a proposed value, and at most k different values are decided. It has been shown that any algorithm that solves the k-set agreement problem in synchronous systems that can suffer up to t crash failures requires  rounds in the worst case. It has also been shown that it is possible to design early deciding algorithms where no process decides and halts after  rounds, where f is the number of actual crashes in a run (0\u2009\u2264\u2009f\u2009\u2264\u2009t).                 This paper explores a new direction to solve the k-set agreement problem in a synchronous system. It considers that the system is enriched with base objects (denoted [m,\u2113]_SA objects) that allow solving the \u2113-set agreement problem in a set of m processes (m\u2009<\u2009n). The\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "The eventual clusterer oracle and its application to consensus in MANETs\n", "abstract": " This paper studies the design of hierarchical consensus protocols for mobile ad hoc networks. A two-layer hierarchy is imposed on the mobile hosts by grouping them into clusters, each with a clusterhead. The messages from and to the hosts in the same cluster are merged/unmerged by the clusterhead so as to reduce the message cost and improve the scalability. We adopt a modular method in the design, separating clustering from achieving consensus using the clusters. The clustering function, named eventual clusterer (denoted as diamC), is designed to construct a cluster-based hierarchy over the mobile hosts in the network. Since diamC provides the fault tolerant clustering function transparently, it can be used as a new oracle (i.e. an abstract tool to provide some kind of information about the state of the system) for the design of hierarchical consensus protocols. Based on diamC, we design a new consensus\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "A simple protocol offering both atomic consistent read operations and sequentially consistent read operations\n", "abstract": " A concurrent object is an object that can be concurrently accessed by several processes. Two well-known consistency criteria for such objects are atomic consistency (also called linearizability) and sequential consistency. Both criteria require that all the operations on the concurrent objects can be totally ordered in such a way that each read operation obtains the last value written into the corresponding object. They differ in the meaning of the word \"last\" that refers to physical time for atomic consistency, and to logical time for sequential consistency. This paper investigates the merging of these consistency criteria in a multiprocess program. The proposed combination offers two read operations to the processes, namely, an atomic read operation and a sequentially consistent read operation. While the first provides a process with the last \"physical\" value of an object, the second provides it with a value that is\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "The Power and Limit of Synchronization for Synchronous Agreement\n", "abstract": " This paper is on the use of additional synchronization messages in round-based message-passing synchronous systems. It first presents a synchronous computation model allowing a process to send such messages. The difference with respect to the traditional round-based synchronous model lies in the sending phase, where a process can first send a data message to each other process, and then, without a break, a synchronization message (their sendings can be pipelined). To illustrate and motivate the model, the paper presents a uniform consensus algorithm suited to this model. This algorithm, based on the rotating coordinator paradigm, allows the processes to decide in at most f+ 1 rounds where f is the actual number of processes that crash in the corresponding run.(This improves the f+ 2 lower bound of the traditional synchronous model.) In addition to its efficiency, the algorithm enjoys another first class property, namely, design simplicity. The paper focuses also on lower bound results, and shows that any uniform consensus algorithm designed for the proposed model, requires at least f+ 1 rounds in the worst case. The proposed algorithm is consequently optimal.", "num_citations": "2\n", "authors": ["495"]}
{"title": "On the benefits of the functional modular approach to distributed data management systems\n", "abstract": " Decomposing distributed data management systems into modules, each with a precise interface and a functional implementation-independent specification, is highly effective both from a software engineering point of view and for theoretical purposes. The usefulness of this approach has been demonstrated in the past in several areas of distributed computing. Yet, despite its attractiveness, so far work on peer-to-peer systems failed to do so. This paper argues in favor of this approach and presents the first attempt at such a decomposition for peer-ro-peer systems.", "num_citations": "2\n", "authors": ["495"]}
{"title": "An introduction to the renaming problem\n", "abstract": " The aim of this paper is to provide a brief introduction to the renaming problem for unfamiliar readers. In the renaming problem the processes have to acquire new names from a small bounded space despite possible process crashes and asynchrony. The problem is first introduced. Then two solutions are presented. One considers the shared memory model, while the second considers the message-passing model.", "num_citations": "2\n", "authors": ["495"]}
{"title": "Quorum-based replication in asynchronous crash-recovery distributed systems\n", "abstract": " This paper describes a solution to the replica management problem in asynchronous distributed systems in which processes can crash and recover. Our solution is based on an Atomic Broadcast primitive which, in turn, is based on an underlying Consensus algorithm. The proposed technique makes a bridge between established results on Weighted Voting and recent results on the Consensus problem.", "num_citations": "2\n", "authors": ["495"]}
{"title": "Logical Instantaneity and Causal Order: Two \u201cFirst Class\u201d Communication Modes for Parallel Computing\n", "abstract": " This paper focuses on two communication modes, namely Logically Instantaneity (li) and Causal Order (co). These communica-tion modes address two different levels of quality of service in message delivery. li means that it is possible to timestamp communication events with integers in such a way that (1) timestamps increase within each process and (2) the sending and the delivery events associated with each message have the same timestamp. So, there is a logical time frame in which for each message, the send event and the corresponding delivery events occur simultaneously. co means that when a process delivers a message m, its delivery occurs in a context where the receiving process knows all the causal past of m. Actually, Li is a property strictly stronger than co. The paper explores these noteworthy communication modes. Their main interest lies in the fact that they deeply simplify the design of\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "Logically Instantaneous communication on top of distributed memory parallel machines\n", "abstract": " Communication is Logically Instantaneous (LI) if it is possi- ble to timestamp communication events with integers in such a way that (1) timestamps increase within each process and (2) the sending and the delivery events associated with each message have the same times- tamp. So, there is a logical time frame in which for each message, the send event and the corresponding delivery events occur simultaneously. li is stronger than Causally Ordered (CO) communication, but weaker than Rendezvous (RDV) communication. This paper explores Logically Instantaneous communication and provides a simple and efficient pro- tocol that implements LI on top of asynchronous distributed systems. LI is attractive as it includes CO and provides more concurrency than RDV. Moreover it allows to adopt the following approach: first design a distributed application assuming Rendezvous communication, and then run\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "Consensus in byzantine asynchronous systems\n", "abstract": " This paper studies the consensus problem in byzantine asynchronous distributed systems. In such systems, a process may stop communicating with other processes or may behave arbitrarily (e.g., execute a statement more than once, corrupt the value of a local variable or misevaluate a local predicate). A consensus protocol resilient to such failures is proposed. It uses signed and certified messages and is based on two underlying failure detection modules. The first is an unreliable failure detector module. The second is a reliable arbitrary behavior detection module. More precisely, the first module detects processes that stop sending messages, while processes experiencing other arbitrary behaviors are detected by the second module. The protocol is resilient to F faulty processes, where F is less than half of the total number of processes and less than an upper bound C (where C is the maximum number of faulty processes that can be tolerated by the underlying certification service). The approach used to design the protocol is new. While usual byzantine consensus protocols are based on unreliable failure detectors to detect processes that stop communicating, none of them use a module to detect their arbitrary behavior (this detection is not isolated from the protocol and makes it difficult to understand and prove correct). In addition to this modular approach and to a new consensus protocol for byzantine systems, the paper presents a finite state automaton-based implementation of the arbitrary behavior detection module. Finally, the modular approach followed in this paper can be used to solve other problems in byzantine systems.", "num_citations": "2\n", "authors": ["495"]}
{"title": "A necessary and sufficient condition for transforming limited accuracy failure detectors\n", "abstract": " Unreliable failure detectors are oracles that give information about process failures. Chandra and Toueg were first to study such failure detectors for distributed systems, and they identified a number that enabled the solution of the Consensus problem in asynchronous distributed systems. This paper focuses on two of these, denoted S (strong) and 3S (eventually strong). The characteristics of a given unreliable failure detector are usually described by its completeness and accuracy properties. Completeness is a requirement on the actual detection of failures, while accuracy limits the mistakes a failure detector can make. Let the scope of the accuracy property of an unreliable failure detector be the minimum number (k) of processes that may not erroneously suspect a correct process to have crashed. Usual failure detectors implicitly consider a scope equal to n (the total number of processes). Accuracy properties with limited scope give rise to the classes of failure detectors that we call Sk and 3Sk.", "num_citations": "2\n", "authors": ["495"]}
{"title": "A probabilistic analysis of the consensus problem\n", "abstract": " A probabilistic analysis of the consensus problem - OpenGrey fra | eng OpenGrey Open System for Information on Grey literature in Europe Home Search Subjects Partners Export Help Search XML To cite or link to this reference: http://hdl.handle.net/10068/39958 Title : A probabilistic analysis of the consensus problem Authors : Fromentin, Eddy ; Tronel, Frederic ; Corporate author : Centre National de la Recherche Scientifique (CNRS), 35 - Rennes (France). Inst. de Recherche en Informatique et Systemes Aleatoires (IRISA) ; Rennes-1 Univ., 35 (France). Inst. de Recherche en Informatique et Systemes Aleatoires (IRISA) ; Institut National des Sciences Appliquees de Rennes (INSA), 35 (France). Inst. de Recherche en Informatique et Systemes Aleatoires (IRISA) ; Institut National de Recherche en Informatique et en Automatique (INRIA), 35 - Rennes (France). Inst. de Recherche en Informatique et Systemes (IRISA) ; : '\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "Points de contr\u00f4le coh\u00e9rents dans les systemes r\u00e9partis: concepts et protocoles\n", "abstract": " D eterminer des points de contr^ ole globaux coh erents est une t^ ache importante qui trouve des applications tant dans le domaine de la tol erance aux d efaillances (points de reprise) que dans la d etection de propri et es des ex ecutions r eparties (coupes coh erentes). Dans cet article on s' int eresse a de telles d eterminations dans le cadre des syst emes r epartis asynchrones. L'article d ebute par une pr esentation de la th eorie des Z-chemins de Netzer et Xu. L'existence d'un tel chemin entre deux points de contr^ ole locaux r ev ele une d ependance qui leur interdit d'appartenir a un m^ eme point de contr^ ole global coh erent. Deux familles de protocoles de d etermination de points de contr^ ole globaux coh erents sont ensuite etudi ees. Ceux de la premi ere famille pr eviennent la formation de Z-cycles et garantissent ainsi l'appartenance de tout point de contr^ ole local a au moins un point de contr^ ole global coh erent.(De tels protocoles sont plus particuli erement int eressants pour de nir des points de reprise a partir desquels un calcul peut^ etre relanc e apr es d efaillance.) Les protocoles de la deuxi eme famille garantissent une propri et e plus forte, a savoir l'absence de d ependance cach ee entre tout couple de points de reprise locaux.(Ces protocoles-l a sont plus particuli erement int eressants pour la d etection de propri et es.) Cet article o re ainsi un etat de l'art (1) sur di erentes notions de coh erence associ ees a l'abstraction d'une ex ecution r epartie que constitue un ensemble de points de contr^ ole, et (2) sur des protocoles qui permettent de de nir de telles abstractions coh erentes.", "num_citations": "2\n", "authors": ["495"]}
{"title": "Efficient \u0394-causal broadcasting for multimedia applications\n", "abstract": " A-causal ordering communication mode [1, 3] has been defined in order to reduce the asynchrony of communication channels in distributed systems with the following characteristics:(i) messages can be lost and (ii) messages have a lifetime, A, after which their data can no longer be used. A-ca\u201d usal order strives to deliver as many messages as possible before their deadlines in such a way that these deliveries respect causal order. In the context of broadcast communication, the A-causal ordering abstraction matches the requirements of an important class of multimedia applications, namely exchange of real-time audio and video information over a communication network. This flow of information must preserve the causal dependency even though part of the information can be lost, or can be discarded when it violates the timing constraints imposed by a real-time interaction.The Lifetime of a Message. In multimedia\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "D\u00e9terminer un \u00e9tat global dans un syst\u00e8me r\u00e9parti\n", "abstract": " Le calcul d\u2019un \u00e9tat global r\u00e9parti est l\u2019un des paradigmes des probl\u00e8mes de contr\u00f4le des messages entre processus r\u00e9partis. Apr\u00e8s avoir expos\u00e9 le probl\u00e8me, cet article analyse et pr\u00e9sente plusieurs solutions. Celles-ci se distinguent les unes des autres par les hypoth\u00e8ses qu\u2019elles font sur les canaux de communication et les messages de contr\u00f4le utilis\u00e9s. En plus de son caract\u00e8re synth\u00e9tique sur le calcul d\u2019un \u00e9tat global r\u00e9parti, cet article constitue une illustration des hypoth\u00e8ses et difficult\u00e9s propres au contexte r\u00e9parti.", "num_citations": "2\n", "authors": ["495"]}
{"title": "Inevitable global states: a concept to detect properties of distributed computations\n", "abstract": " When analyzing, testing or debugging a distributed program, an important question one has to answer is:\" Does this computation satisfy a given property?\". We are interested in this paper in answering such a question when the property is formulated as a general predicate on a global state of the computation, and more specifically when the property is unstable (ie once true the associated predicate is not guaranteed to remain true forever). Notions such as abstraction level with respect to a predicate (user's level) and weak precedence between local states are first introduced. Then an abstraction called inevitable global state is defined, and a necessary and sufficient condition to detect such states is provided. With this abstraction a precise meaning is given to the previous question (independently of any particular perception one can have of the distributed computation). A detection algorithm for this question is finally presented.", "num_citations": "2\n", "authors": ["495"]}
{"title": "Conception et realisation d'un noyau de systeme reparti pour la simulation parallele\n", "abstract": " Le but de cette these est d'etudier certaines techniques de distribution de simulations a evenements discrets et leur mise en uvre sur des machines paralleles de type mimd a memoire repartie, et de preciser leur situation dans le contexte general de l'algorithmique repartie, en etablissant des rapports entre ces techniques et d'autres methodes connues de synchronisation. Nous avons construit un prototype de noyau de systeme reparti, appele floria, pour l'execution de simulations a evenements discrets. Ce prototype rend possible l'experimentation in natura des techniques de synchronisation etudiees. Il nous a aussi permis de mener une reflexion approfondie sur les services necessaires a la mise en uvre de simulations reparties, et leur consequence sur la structure interne d'un noyau de systeme dedie a ce type d'application. La structure que nous proposons pour ce noyau est completement modulaire, et permet d'isoler ses fonctionnalites dans leurs aspects lies a la distribution, la synchronisation et l'evolution du programme de simulation. Une evaluation quantitative de notre noyau est presentee, visant a presenter les gains obtenus par la parallelisation et a etudier l'impact des diverses caracteristiques des modeles sur les performances du simulateur", "num_citations": "2\n", "authors": ["495"]}
{"title": "Protocoles simples pour \u013eimpl\u00e9mentation r\u00e9partie des s\u00e9maphores\n", "abstract": " \u013dutilisation croissante des machines parall\u00e8les \u00e0 m\u00e9moire r\u00e9partie constitue un terrain de pr\u00e9dilection relativement nouveau pour les concepteurs de syst\u00e8mes r\u00e9partis, le paradigme classique r\u00e9seau (local) + messages y \u00e9tant souvent remplac\u00e9 par celui de la m\u00e9moire virtuelle r\u00e9partie. Dans cette nouvelle probl\u00e9matique (qui consiste en fait \u00e0 mettre en \u0153uvre sur ces nouvelles architectures des concepts fondamentaux des syst\u00e8mes centralis\u00e9s) on examine ici la mise en \u0153uvre r\u00e9partie \u010fun des m\u00e9canismes de base pour la synchronisation: le s\u00e9maphore. Plusieurs protocoles sont propos\u00e9s; ils sont tous construits \u00e0 partir de \u013einvariant fondamental associ\u00e9 au concept de s\u00e9maphore. Ces protocoles, joints \u00e0 un m\u00e9canisme de m\u00e9moire virtuelle r\u00e9partie, peuvent ainsi permettre une programmation classique de ce type de machines parall\u00e8les.", "num_citations": "2\n", "authors": ["495"]}
{"title": "R\u00e9\u00e9x\u00e9cution et analyse de la dynamique des programmes r\u00e9partis\n", "abstract": " L'objectif de cette these est de proposer un ensemble coherent d'outils permettant d'analyser le comportement d'une application repartie au cours d'une execution. Nous nous interessons tout d'abord au probleme de l'observation. Dans l'approche adoptee, le comportement de l'application observee est modelise sous la forme d'un ensemble partiellement ordonne d'etats locaux. Une adequation entre l'analyse effectuee et l'ensemble des etats locaux pris en compte est obtenue en choisissant un niveau d'observation adapte. La definition d'une relation de dependance entre les etats locaux selectionnes permet d'expliquer le deroulement du calcul effectue en fonction des interactions entre processus qui se manifestent lors des echanges de messages. Dans une seconde partie, nous abordons le probleme de la reproduction d'un comportement prealablement observe. Dans le cas particulier ou l'application est specifiee dans un langage proche du langage estelle, un mecanisme de reexecution post mortem et un mecanisme de reexecution au vol sont etudies, implementes et compares. La derniere partie est consacree a la presentation d'outils d'analyse permettant de visualiser le deroulement du calcul, de detecter des proprietes et d'effectuer des mesures de performances. Une nouvelle classe de proprietes instables appelees sequences atomiques de predicats locaux et un algorithme original permettant de detecter au vol ces proprietes sont proposes. Le probleme de l'arret du programme suite a la detection d'un point d'arret est egalement traite. Un outil de deverminage de programme estelle, appele erebus, a ete developpe dans le cadre de\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "Synchronization and concurrency measures for distributed computations\n", "abstract": " Time and message complexities are the usual measures used to characterize distributed computations. llowever. these measures only address quantitative aspects of the computation. Very little work has been devoted to defining more qualitative measures. such as the parallelism and the con-currency inherent in such computations.This paper presents some qualitative measures from a synchronization point of view. These measures are based on the set of events that. participate in the production of a given event (or of the whole computation). Such an approach allows us to precisely characterize the synchIonization constraints inherent within a distributed computation, without being bothered by the perturbations caused by a given iinplententation. First, we introduce two abstractions, called cone and cylinder, associated with an event. and a whole distributed computation. respectively. Then, the proposed\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "Un sch\u00e9ma (abstrait) d'it\u00e9ration r\u00e9partie. Application au calcul des chemins de valeurs minimales\n", "abstract": " La d\u00e9\ufb01nition de structures de contr\u00f4le aptes \u00e0 exprimer les algorithmes distribu\u00e9s est un probl\u00e8me central de l\u2019algorithmique r\u00e9partie. On examine ici l\u2019une de ces structures: l\u2019it\u00e9ration r\u00e9partie. Apr\u00e8s en avoir distingu\u00e9 deux formes aux propri\u00e9t\u00e9s diff\u00e9rentes, appel\u00e9es respectivement train de vagues et s\u00e9quence de phases, on s\u2019 int\u00e9resse plus particuli\u00e8rement au sch\u00e9ma abstrait que constitue la vague, sur lequel est b\u00e2tie la premi\u00e8re des deux formes d\u2019it\u00e9ration r\u00e9partie. Ce sch\u00e9ma est d\u00e9\ufb01ni \u00e0 la mani\u00e8re d\u2019un type abstrait, c\u2019est-\u00e0\u2014dire par les op\u00e9rations de contr\u00f4le qu\u2019il offre \u00e0 l\u2019utilisateur et les propri\u00e9t\u00e9s qui leur sont associ\u00e9es, ind\u00e9pendamment d\u2019une mise en \u0153uvre particuli\u00e8re. Deux exemples de mise en \u0153uvre sont ensuite propos\u00e9s; elles s\u2019 appuient respectivement sur les topologies de contr\u00f4le que sont l\u2019anneau virtuel et l\u2019arborescence couvrante. On montre ensuite comment un tel sch\u00e9ma d'it\u00e9ration r\u00e9partie\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "Controlling information transfers in distributed algorithms: application to deadlock detection\n", "abstract": " A distributed algorithm is made of a finite set of communicating sequential processes exchanging messages [13]. Such a system is fundamentally characterized by the lack of a global state which could be instantaneously cast by a process (11). Furthermore, a given process initially has access but to local information (or knowledge) and the implementation of a distributed computation involves protocols to gain information from the other processes.", "num_citations": "2\n", "authors": ["495"]}
{"title": "De la n\u00e9cessit\u00e9 de sp\u00e9cifier des propri\u00e9t\u00e9s pour la verification des algorithmes distribu\u00e9s\n", "abstract": " cet article argumente la th\u00e8se suivante: la v\u00e9rification d'un algorithme distribu\u00e9 s' effectue par l'analyse d'un mod\u00e8le de celui-ci. Raisonner uniquement \u00e0 l \u2018int\u00e9rieur du mod\u00e8le et s' assurer de sa coh\u00e9rence ne suffit pas en g\u00e9n\u00e9ral. On a besoin d'un m\u00e9ta-langage de sp\u00e9cification pour d\u00e9crire les propri\u00e9t\u00e9s attendues du mod\u00e8le, qui d\u00e9pendent de l \u2018algorithme.Ce fait, bien qu'admis par plusieurs sp\u00e9cialistes du domaine de la v\u00e9rification, n'est pas reconnu par tous. Notre but est de le pr\u00e9senter de fa\u00e7on p\u00e9dagogique \u00e0 l'aide d'un exemple simple. L'article fournit, en m\u00eame temps, une introduction \u00e0 la v\u00e9rification des algorithmes distribu\u00e9s.", "num_citations": "2\n", "authors": ["495"]}
{"title": "Un algorithme d'exclusion mutuelle pour une structure logique en anneau\n", "abstract": " Nous pr\u00e9sentons un nouvel algorithme d \u2018exclusion mutuelle pour un ensemble de processus connect\u00e9s selon une structure d'anneau virtuel. Cet algorithme bas\u00e9 sur des variables d \u2018\u00e9tats se diff\u00e9rencie de celui propos\u00e9 par DIJKSTRA (C. ACM. 74) par le fait qu\u2019il ne pr\u00e9sente pas de processus jouant un r\u00f4le privil\u00e9gi\u00e9: le protocole d \u2018entr\u00e9e et de sortie de section critique est le m\u00eame pour tous. Outre cette propri\u00e9t\u00e9, l \u2018algorithme en poss\u00e8de deux autres: il ne n\u00e9cessite que des variables de taille born\u00e9e et r\u00e9siste aux pannes des processus plac\u00e9s sur l \u2018anneau.ABS \u2018I \u2018RACI \u2018.-A new mutual exclusion algorithm designed for a set of processes connected along a virtual ring is presented.'I \u2018his algorithm is based on state variables' and differs \u2018\u201cfrom the Dijkstra's one (Comm. ACM 74) by'not having a tagged process playing a special part: entry and exit protocols are identical for all the processes. Moreover the algorithm\u00a0\u2026", "num_citations": "2\n", "authors": ["495"]}
{"title": "Une Expression de la Synchronisation pour les Types Abstraits\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "2\n", "authors": ["495"]}
{"title": "Byzantine-Tolerant Reliable Broadcast in the Presence of Silent Churn\n", "abstract": " This paper introduces a new reliable broadcast communication abstraction suited to n-process asynchronous message-passing systems in which up\u00a0to t processes may behave arbitrarily (Byzantine processes) and where (due to transient disconnections or message losses) up\u00a0to d correct processes may not receive a message broadcast by a correct (i.e., not Byzantine) process. Then the paper presents and proves correct an algorithm implementing such a communication abstraction where the system parameters n, t, and d are such that .", "num_citations": "1\n", "authors": ["495"]}
{"title": "On the Versatility of Bracha\u2019s Byzantine Reliable Broadcast Algorithm\n", "abstract": " G. Bracha presented in 1987 a simple and efficient reliable broadcast algorithm for -process asynchronous message-passing systems, which tolerates up to  Byzantine processes. Following an idea recently introduced by Hirt, Kastrato and Liu-Zhang (OPODIS 2020), instead of considering the upper bound on the number of Byzantine processes , the present short article considers two types of Byzantine behavior: the ones that can prevent the safety property from being satisfied, and the ones that can prevent the liveness property from being satisfied (a Byzantine process can exhibit only one or both types of failures). This Byzantine differentiated failure model is captured by two associated upper bounds denoted  (for safety) and  for liveness). The article shows that only the threshold values used in the predicates of Bracha\u2019s algorithm must be modified to obtain an algorithm that works with this\u00a0\u2026", "num_citations": "1\n", "authors": ["495"]}
{"title": "From incomplete to complete networks in asynchronous Byzantine systems\n", "abstract": " This paper presents a simple broadcast operation suited to n-process asynchronous message-passing systems in which (i) up to t processes may commit Byzantine faults, and (2), while the underlying communication network is connected (any pair of processes is connected by a path), not all the pairs of processes are directly connected by a communication channel. The algorithm proposed to implement this operation assumes (i) and (ii)-vertex connectivity of the underlying network (each pair of processes is connected by at least disjoint paths), requirements which are shown to be necessary. When considering incomplete networks, this abstraction can be used as the first level of a software stack on top of which, without any modifications, Byzantine-tolerant broadcast and agreement abstractions designed for fully connected networks can directly be used. The paper has also a short survey flavor\u00a0\u2026", "num_citations": "1\n", "authors": ["495"]}
{"title": "Self-stabilizing Multivalued Consensus in Asynchronous Crash-prone Systems\n", "abstract": " The problem of multivalued consensus is fundamental in the area of fault-tolerant distributed computing since it abstracts a very broad set of agreement problems in which processes have to uniformly decide on a specific value v in V, where |V| >1. Existing solutions (that tolerate process failures) reduce the multivalued consensus problem to the one of binary consensus, e.g., Mostefaoui-Raynal-Tronel and Zhang-Chen. Our study aims at the design of an even more reliable solution. We do so through the lenses of self-stabilization -- a very strong notion of fault-tolerance. In addition to node and communication failures, self-stabilizing algorithms can recover after the occurrence of arbitrary transient-faults; these faults represent any violation of the assumptions according to which the system was designed to operate (as long as the algorithm code stays intact). This work proposes the first (to the best of our knowledge) self-stabilizing algorithm for multivalued consensus for asynchronous message-passing systems prone to process failures and arbitrary transient-faults. Our solution is also the first (to the best of our knowledge) to support wait-freedom. Moreover, using piggybacking techniques, our solution can invoke n binary consensus objects concurrently. Thus, the proposed self-stabilizing wait-free solution can terminate using fewer resources than earlier non-self-stabilizing solutions by Mostefaoui, Raynal, and Tronel, which uses an unbounded number of binary consensus objects, or Zhang and Chen, which is not wait-free.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Loosely-self-stabilizing Byzantine-tolerant Binary Consensus for Signature-free Message-passing Systems\n", "abstract": " At PODC 2014, A. Most\\'efaoui, H. Moumen, and M. Raynal presented a new and simple randomized signature-free binary consensus algorithm (denoted here MMR) that copes with the net effect of asynchrony Byzantine behaviors. Assuming message scheduling is fair and independent from random numbers MMR is optimal in several respects: it deals with up to t Byzantine processes where t < n/3 and n is the number of processes, O(n\\^2) messages and O(1) expected time. The present article presents a non-trivial extension of MMR to an even more fault-prone context, namely, in addition to Byzantine processes, it considers also that the system can experience transient failures. To this end it considers self-stabilization techniques to cope with communication failures and arbitrary transient faults (such faults represent any violation of the assumptions according to which the system was designed to operate). The proposed algorithm is the first loosely-self-stabilizing Byzantine fault-tolerant binary consensus algorithm suited to asynchronous message-passing systems. This is achieved via an instructive transformation of MMR to a self-stabilizing solution that can violate safety requirements with probability Pr= O(1/(2\\^M)), where M is a predefined constant that can be set to any positive integer at the cost of 3 M n + log M bits of local memory. In addition to making MMR resilient to transient faults, the obtained self-stabilizing algorithm preserves its properties of optimal resilience and termination, (i.e., t < n/3, and O(1) expected time). Furthermore, it only requires a bounded amount of memory.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Byzantine-tolerant Distributed Grow-only Sets: Specification and Applications\n", "abstract": " In order to formalize Distributed Ledger Technologies and their interconnections, a recent line of research work has formulated the notion of Distributed Ledger Object (DLO), which is a concurrent object that maintains a totally ordered sequence of records, abstracting blockchains and distributed ledgers. Through DLO, the Atomic Appends problem, intended as the need of a primitive able to append multiple records to distinct ledgers in an atomic way, is studied as a basic interconnection problem among ledgers. In this work, we propose the Distributed Grow-only Set object (DSO), which instead of maintaining a sequence of records, as in a DLO, maintains a set of records in an immutable way: only Add and Get operations are provided. This object is inspired by the Grow-only Set (G-Set) data type which is part of the Conflict-free Replicated Data Types. We formally specify the object and we provide a consensus-free Byzantine-tolerant implementation that guarantees eventual consistency. We then use our Byzantine-tolerant DSO (BDSO) implementation to provide consensus-free algorithmic solutions to the Atomic Appends and Atomic Adds (the analogous problem of atomic appends applied on G-Sets) problems, as well as to construct consensus-free Single-Writer BDLOs. We believe that the BDSO has applications beyond the above-mentioned problems.", "num_citations": "1\n", "authors": ["495"]}
{"title": "k-Immediate Snapshot and x-Set Agreement: How Are They Related?\n", "abstract": " An immediate snapshot object is a high level communication object, built on top of a read/write distributed system in which all except one processes may crash. This object provides the processes with a single operation, denoted , which allows the invoking process to write a value and obtain a set of pairs process id, value satisfying some set containment properties, that represent a snapshot of the values written to the object, occurring immediately after the write step.               Considering an n-process model in which up\u00a0to t processes may crash, this paper introduces first the k-resilient immediate snapshot object, which is a natural generalization of the basic immediate snapshot (which corresponds to the case ). In addition to the set containment properties of the basic immediate snapshot, a k-resilient immediate snapshot object requires that each set returned to a process contains at least  pairs\u00a0\u2026", "num_citations": "1\n", "authors": ["495"]}
{"title": "From Bezout's Identity to Space-Optimal Election in Anonymous Memory Systems\n", "abstract": " An anonymous shared memory REG can be seen as an array of atomic registers such that there is no a priori agreement among the processes on the names of the registers. As an example a very same physical register can be known as REG [x] by a process p and as REG [y](where y\u2260 x) by another process q. Moreover, the register known as REG [a] by a process p and the register known as REG [b] by a process q can be the same physical register. It is assumed that each process has a unique identifier that can only be compared for equality. This article is on solving the d-election problem, in which it is required to elect at least one and at most d leaders, in such an anonymous shared memory system. We notice that the 1-election problem is the familiar leader election problem. Let n be the number of processes and m the size of the anonymous memory (number of atomic registers). The article shows that the\u00a0\u2026", "num_citations": "1\n", "authors": ["495"]}
{"title": "60 Years of Mastering Concurrent Computing through Sequential Thinking\n", "abstract": " Modern computing systems are highly concurrent. Threads run concurrently in shared-memory multi-core systems, and programs run in different servers communicating by sending messages to each other. Concurrent programming is hard because it requires to cope with many possible, unpredictable behaviors of the processes, and the communication media. The article argues that right from the start in 1960's, the main way of dealing with concurrency has been by reduction to sequential reasoning. It traces this history, and illustrates it through several examples, from early ideas based on mutual exclusion (which was initially introduced to access shared physical resources), passing through consensus and concurrent objects (which are immaterial data), until today distributed ledgers. A discussion is also presented, which addresses the limits that this approach encounters, related to fault-tolerance, performance\u00a0\u2026", "num_citations": "1\n", "authors": ["495"]}
{"title": "Relaxed Queues and Stacks from Read/Write Operations\n", "abstract": " Considering asynchronous shared memory systems in which any number of processes may crash, this work identifies and formally defines relaxations of queues and stacks that can be non-blocking or wait-free while being implemented using only read/write operations. Set-linearizability and Interval-linearizability are used to specify the relaxations formally, and precisely identify the subset of executions which preserve the original sequential behavior. The relaxations allow for an item to be returned more than once by different operations, but only in case of concurrency; we call such a property multiplicity. The stack implementation is wait-free, while the queue implementation is non-blocking. Interval-linearizability is used to describe a queue with multiplicity, with the additional relaxation that a dequeue operation can return weak-empty, which means that the queue might be empty. We present a read/write wait-free interval-linearizable algorithm of a concurrent queue. As far as we know, this work is the first that provides formalizations of the notions of multiplicity and weak-emptiness, which can be implemented on top of read/write registers only.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Brief announcement: fully anonymous shared memory algorithms\n", "abstract": " Process anonymity has been studied for a long time. Memory anonymity is more recent. In an anonymous memory system, there is no a priori agreement among the processes on the names of the shared registers they access. This article introduces the fully anonymous model, namely a model in which both the processes and the memory are anonymous. It is shown that fundamental problems such as mutual exclusion, consensus, and its weak version called set agreement, can be solved despite full anonymity, the first in a failure-free system, the others in the presence of any number of process crashes.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Fully anonymous shared memory algorithms\n", "abstract": " Process anonymity has been studied for a long time. Memory anonymity is more recent. In an anonymous memory system, there is no a priori agreement among the processes on the names of the shared registers they access. This article introduces the fully anonymous model, namely a model in which both the processes and the memory are anonymous. It is shown that fundamental problems such as mutual exclusion, consensus, and its weak version called set agreement, can be solved despite full anonymity, the first in a failure-free system, the others in the presence of any number of process crashes.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Participant-Restricted Consensus in Asynchronous Crash-Prone Read/Write Systems and Its Weakest Failure Detector\n", "abstract": " A failure detector is a device (object) that provides the processes with information on failures. Failure detectors were introduced to enrich asynchronous systems so that it becomes possible to solve problems (or implement concurrent objects) that are otherwise impossible to solve in pure asynchronous systems where processes are prone to crash failures. The most famous failure detector (which is called \u201ceventual leader\u201d and denoted ) is the weakest failure detector which allows consensus to be solved in n-process asynchronous systems where up\u00a0to  processes may crash in the read/write communication model, and up\u00a0to  processes may crash in the message-passing communication model. In these models, all correct processes are supposed to participate in a consensus instance and in particular the eventual leader.                 This paper considers the case where some subset of processes that do not crash\u00a0\u2026", "num_citations": "1\n", "authors": ["495"]}
{"title": "Pannes de processus li\u00e9es \u00e0 la contention\n", "abstract": " Cet article est un r\u00e9sum\u00e9 \u00e9tendu de [DRT18] dans lequel nous nous int\u00e9ressons \u00e0 un nouveau type de pannes de processus d\u00e9fini r\u00e9cemment par l'un des auteurs [Tau18] : les pannes \u03bb-contraintes. Cette nouvelle notion est explicitement li\u00e9e \u00e0 la contention. En effet, elle ne consid\u00e8re que les ex\u00e9cutions dans lesquelles les pannes de processus se produisent lorsque la contention est plus petite o\u00f9 \u00e9gale \u00e0 un seuil \u03bb donn\u00e9. Si des pannes se produisent lorsque la contention a d\u00e9pass\u00e9 ce seuil \u03bb, aucune propri\u00e9t\u00e9 de correction (comme par exemple la terminaison) n'est garantie. [Tau18] montre que, lorsque \u03bb = n \u2212 1, il est possible de r\u00e9soudre le probl\u00e8me du consensus dans un syst\u00e8me asynchrone \u00e0 registres atomiques de n processus m\u00eame si un processus tombe en panne, outrepassant ainsi le r\u00e9sultat d'impossibilit\u00e9 FLP. Nous proposons ici des algorithmes pour les probl\u00e8mes de k-accord et de renommage qui tol\u00e8rent \u00e0 la fois des pannes de processus \"classiques\" et des pannes \u03bb-contraintes.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Mastering concurrent computing through sequential thinking: a half-century evolution\n", "abstract": " Concurrency, the art of doing many things at the same time is slowly becoming a science. It is very difficult to master, yet it arises all over modern computing systems, both when the communication medium is shared memory and when it is by message passing. Concurrent programming is hard because it requires to cope with many possible, unpredictable behaviors of communicating processes interacting with each other. Right from the start in the 1960s, the main way of dealing with concurrency has been by reduction to sequential reasoning. We trace this history, and illustrate it through several examples, from early ideas based on mutual exclusion, passing through consensus and concurrent objects, until today ledgers and blockchains. We conclude with a discussion on the limits that this approach encounters, related to fault-tolerance, performance, and inherently concurrent problems.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Consensus and interactive consistency in synchronous systems prone to process crash failures\n", "abstract": " This first chapter on agreement in synchronous systems focuses on the consensus and interactive consistency (also called vector consensus) agreement abstractions. It first defines these abstractions, and presents algorithms that build them in the presence of any number of process crashes in the system model CSMPn,t  .", "num_citations": "1\n", "authors": ["495"]}
{"title": "Reliable broadcast in the presence of Byzantine processes\n", "abstract": " This chapter presents two broadcast communication abstractions suited to the asynchronous systems prone to process Byzantine failures (basic model BAMPn,t   appropriately enriched). The first of these broadcast abstractions is called no-duplicity broadcast, while the second one is the classic non-uniform reliable broadcast adapted to Byzantine failures. (Let us notice that, as a Byzantine process may behave arbitrarily, it is meaningless to force a correct process to deliver a message only because it was delivered by a Byzantine process.) An algorithm implementing no-duplicity broadcast, and two algorithms implementing Byzantine reliable broadcast are presented.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Atomic Read/Write Registers in the Presence of Byzantine Processes\n", "abstract": " Theorem 18 (stated and proved in Section 5.4) has shown that t < n/2 is an upper bound on the resilience parameter t to build atomic read/write registers in the asynchronous crash process model CAMPn,t  . Section 6.3 and Section 6.4 then presented an incremental construction of Single-Writer Multi-Reader (SWMR) and Multi-Writer Multi-Reader (MW-MR) atomic registers.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Wait-freedom and Locality are not Incompatible (with Distributed Ring Coloring as an Example)\n", "abstract": " In the world of message-passing distributed computing, reliable synchronous systems and asyn-chronous failure-prone systems lie at the two ends of the reliability/asynchrony spectrum. The concept of locality of a computation is central to the first one, while the concept of wait-freedom is central to the second one. This paper is an attempt to reconcile these two extreme worlds, and benefit from both of them. To this end, it first proposes a new distributed computing model, where (differently from the two previous ones) processing and communication are decoupled. The communication component (made up of n nodes) is considered as reliable and synchronous, while the processing component (composed of n processes, each attached to a communication node) is asyn-chronous and any number of its processes may suffer crash failures. To illustrate the benefit of this model, the paper presents an asynchronous algorithm that, assuming a ring communication component , colors the processes with at most three colors. From a process crash failure point of view, this algorithm is wait-free. From a locality point of view, each process needs information only from processes at distance O(log * n) from it. This local wait-free algorithm is made up of a communication phase followed by a purely local simulation (by each process) of an extended version of Cole and Vishkin's vertex coloring algorithm (this extension does not require the processes to start simultaneously). This new communication/processing decoupled model seems to offer a promising approach for distributed computing.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Asynchronous Byzantine Systems: From Multivalued to Binary Consensus with t< n/3, O (n\u00b2) Messages, O (1) Time, and no Signature\n", "abstract": " This paper presents a new algorithm that reduces multivalued consensus to binary consensus in an asyn-chronous message-passing system made up of n processes where up to t may commit Byzantine failures. This algorithm has the following noteworthy properties: it assumes t < n/3 (and is consequently optimal from a resilience point of view), uses O(n\u00b2) messages, has a constant time complexity, and does not use signatures. The design of this reduction algorithm relies on two new all-to-all communication abstractions. The first one allows the non-faulty processes to reduce the number of proposed values to c, where c is a small constant. The second communication abstraction allows each non-faulty process to compute a set of (proposed) values such that, if the set of a non-faulty process contains a single value, then this value belongs to the set of any non-faulty process. Both communication abstractions have an O(n\u00b2) message complexity and a constant time complexity. The reduction of multivalued Byzantine consensus to binary Byzantine consensus is then a simple sequential use of these communication abstractions. To the best of our knowledge, this is the first asynchronous message-passing algorithm that reduces multivalued consensus to binary consensus with O(n\u00b2) messages and constant time complexity (measured with the longest causal chain of messages) in the presence of up to t < n/3 Byzantine processes, and without using cryptography techniques. Moreover, this reduction algorithm tolerates message reordering by Byzantine processes.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Minimal synchrony for asynchronous Byzantine consensus\n", "abstract": " Solving the consensus problem requires in one way or another that the underlying system satisfies some synchrony assumption. Considering an asynchronous message-passing system of n processes where (a) up to t < n/3 may commit Byzantine failures, and (b) each pair of processes is connected by two uni-directional channels (with possibly different timing properties), this paper investigates the synchrony assumption required to solve consensus, and presents a signature-free consensus algorithm whose synchrony requirement is the existence of a process that is an eventual t+1bisource. Such a process p is a correct process that eventually has (a) timely input channels from t correct processes and (b) timely output channels to t correct processes (these input and output channels can connect p to different subsets of processes). As this synchrony condition was shown to be necessary and sufficient in the stronger asynchronous system model (a) enriched with message authentication, and (b) where the channels are bidirectional and have the same timing properties in both directions, it follows that it is also necessary and sufficient in the weaker system model considered in the paper. In addition to the fact that it closes a long-lasting problem related to Byzantine agreement, a noteworthy feature of the proposed algorithm lies in its design simplicity, which is a first-class property.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Fisheye consistency: Keeping data in synch in a georeplicated world\n", "abstract": " Over the last thirty years, numerous consistency conditions for replicated data have been proposed and implemented. Popular examples of such conditions include linearizability (or atomicity), sequential consistency, causal consistency, and eventual consistency. These consistency conditions are usually defined independently from the computing entities (nodes) that manipulate the replicated data; i.e., they do not take into account how computing entities might be linked to one another, or geographically distributed. To address this lack, as a first contribution, this paper introduces the notion of proximity graph between computing nodes. If two nodes are connected in this graph, their operations must satisfy a strong consistency condition, while the operations invoked by other nodes are allowed to satisfy a weaker condition. The second contribution is the use of such a graph to provide a generic approach to the hybridization of data consistency conditions into the same system. We illustrate this approach on sequential consistency and causal consistency, and present a model in which all data operations are causally consistent, while operations by neighboring processes in the proximity graph are sequentially consistent. The third contribution of the paper is the design and the proof of a distributed algorithm based on this proximity graph, which combines sequential consistency and causal consistency (the resulting condition is called fisheye consistency). In doing so the paper not only extends the domain of consistency conditions, but provides a generic provably correct solution of direct relevance to modern georeplicated systems.", "num_citations": "1\n", "authors": ["495"]}
{"title": "An exercise in concurrency: From non-blocking objects to fair objects\n", "abstract": " Inria - An Exercise in Concurrency: From Non-blocking Objects to Fair Objects Acc\u00e9der directement au contenu Acc\u00e9der directement \u00e0 la navigation Toggle navigation CCSD HAL HAL HALSHS TEL M\u00e9diHAL Liste des portails AUR\u00e9HAL API Data Documentation Episciences.org Episciences.org Revues Documentation Sciencesconf.org Support HAL-Inria Les publications, logiciels... des scientifiques Inria Accueil D\u00e9poser Consulter tout HAL par date de publication/r\u00e9daction par domaine par type de publication par collection arXiv les derniers d\u00e9p\u00f4ts Publications Inria Recherche Services HalTools : cr\u00e9er sa page web Haltools : export RAWEB X2Hal : import par lot Consulter les structures de recherche connues de HAL Documentation Aide en ligne de HAL V3 Derni\u00e8res \u00e9volutions de HAL V3 Documentation API HAL Ajouter des vignettes Aide en ligne Haltools Aide en ligne de X2hal OpenAccess Inria soutient la hal'\u2026", "num_citations": "1\n", "authors": ["495"]}
{"title": "Distributed universality: contention-awareness, wait-freedom, object Progress, and other properties\n", "abstract": " A notion of a universal construction suited to distributed computing has been introduced by M. Herlihy in his celebrated paper \"Wait-free synchronization\" (ACM TOPLAS, 1991). A universal construction is an algorithm that can be used to wait-free implement any object defined by a sequential specification. Herlihy's paper shows that the basic system model, which supports only atomic read/write registers, has to be enriched with consensus objects to allow the design of universal constructions. The generalized notion of a k-universal construction has been recently introduced by Gafni and Guerraoui (CONCUR, 2011). A k-universal construction is an algorithm that can be used to simultaneously implement k objects (instead of just one object), with the guarantee that at least one of the k constructed objects progresses forever. While Herlihy's universal construction relies on atomic registers and consensus objects, a k-universal construction relies on atomic registers and k-simultaneous consensus objects (which are wait-free equivalent to k-set agreement objects in the read/write system model). This paper significantly extends the universality results introduced by Herlihy and Gafni-Guerraoui. In particular, we present a k-universal construction which satisfies the following five desired properties, which are not satisfied by the previous k-universal construction: (1) among the k objects that are constructed, at least l objects (and not just one) are guaranteed to progress forever; (2) the progress condition for processes is wait-freedom, which means that each correct process executes an infinite number of operations on each object that progresses forever; (3) if\u00a0\u2026", "num_citations": "1\n", "authors": ["495"]}
{"title": "Distributed deadlock detection\n", "abstract": " This chapter addresses the deadlock detection problem. After having introduced the AND deadlock model and the OR deadlock model, it presents distributed algorithms that detect their occurrence. Let us recall that the property \u201cthere is a deadlock\u201d is a stable property (once deadlocked, a set of processes remain deadlocked until an external agent\u2014the underlying system\u2014resolves it). Hence, as seen in Sect.\u00a0                 6.5                                , algorithms computing global states of a computation can be used to detect deadlocks. Differently, the algorithms presented in this chapter are specific to deadlock detection. For simplicity, they all assume FIFO channels.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Leader Election Algorithms\n", "abstract": " This chapter is on the leader election problem. Electing a leader consists for the processes of a distributed system in selecting one of them. Usually, once elected, the leader process is required to play a special role for coordination or control purposes.             Leader election is a form of symmetry breaking in a distributed system. After showing that no leader can be elected in anonymous regular networks (such as rings), this chapter presents several leader election algorithms with a special focus on non-anonymous ring networks.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Solving Mutual Exclusion\n", "abstract": " This chapter is on the implementation of mutual exclusion locks. As announced at the end of the previous chapter, it presents three distinct families of algorithms that solve the mutual exclusion problem. The first is the family of algorithms which are based on atomic read/write registers only. The second is the family of algorithms which are based on specialized hardware operations (which are atomic and stronger than atomic read/write operations). The third is the family of algorithms which are based on read/write registers which are weaker than atomic registers. Each algorithm is first explained and then proved correct. Other properties such as time complexity and space complexity of mutual exclusion algorithms are also discussed.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Safe, Regular, and Atomic Read/Write Registers\n", "abstract": " For self-containment, this chapter starts with a short presentation of the notions of safe, regular, and atomic read/write registers (which were introduced in Chap.\u00a02). It then presents simple wait-free implementations of \u201chigh-level\u201d registers from \u201clow-level\u201d registers. The notions of \u201chigh-level\u201d and \u201clow-level\u201d used here are not related to the computability power but to the abstraction level. This is because, as we will see in the next two chapters, while a regular register is easier to use than a safe register and an atomic register is easier to use than a regular register, they are all computationally equivalent; i.e., any of them can be built wait-free from any other without enriching the underlying system with additional computational power.             The proofs of the theorems stated in this chapter use the definitions and terminology introduced in Chap.\u00a04.", "num_citations": "1\n", "authors": ["495"]}
{"title": "When and How Process Groups Can Be Used to Reduce the Renaming Space\n", "abstract": " Considering the M-renaming problem and process groups, this paper investigates the following question: Is there a relation between the number of groups and the size of the new name space M? This question can be rephrased as follows: Can the initial partitioning of the processes into m groups allows the size of the renaming space M to be reduced, and if yes, how much?             This paper answers the previous questions. Let n denote the number of processes. Assuming that the processes are initially partitioned into m\u2009=\u2009n\u2009\u2212\u2009\u2113 non-empty groups, such that each process knows only its identity and its group number, the paper first presents a wait-free M-renaming algorithm whose size of the new name space is M\u2009=\u2009n\u2009+\u20092\u2113\u2009\u2212\u20091. For  (i.e. ), we have M\u2009<\u20092n\u2009\u2212\u20091, which shows that, when the number of groups is greater than , groups allow to circumvent the renaming lower bound in read\u00a0\u2026", "num_citations": "1\n", "authors": ["495"]}
{"title": "A Simple Asynchronous Shared Memory Consensus Algorithm Based on Omega and Closing Sets\n", "abstract": " This paper is on the design of a consensus object in the context of asynchronous shared memory systems where any number of process can suffer a crash failure. These systems are becoming more and more important with the advent of multicore architectures. To circumvent the impossibility of implementing a consensus object in such a context, the paper considers that the base read/write system model is enriched with an eventual leader failure detector (traditionally denoted \u03a9). This failure detector can easily be used to ensure that all the invocations of the consensus object issued by processes that do not crash eventually terminate(wait-freedom termination property). Hence, when one has to implement a consensus object in such an enriched system model, the main issue consists in designing an object (from base atomic read/write registers) on which the implementation can rely to ensure that no two different\u00a0\u2026", "num_citations": "1\n", "authors": ["495"]}
{"title": "Power and limits of distributed computing shared memory models\n", "abstract": " Due to the advent of multicore machines, shared memory distributed computing models taking into account asynchrony and process crashes are becoming more and more important. This paper visits some of the models for these systems, and analyses their properties from a computability point of view. Among them, the snapshot model and the iterated model are particularly investigated. The paper visits also several approaches that have been proposed to model crash failures. Among them, the wait-free case where any number of processes can crash is fundamental. The paper also considers models where up to t processes can crash, and where the crashes are not independent. The aim of this survey is to help the reader to better understand recent advances on what is known about the power and limits of distributed computing shared memory models and their underlying mathematics.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Enriching the reduction map of sub-consensus tasks\n", "abstract": " Understanding the relative computability power of tasks, in the presence of asynchrony and failures, is a central concern of distributed computing theory. In the wait-free case, where the system consists of n processes and any of them can fail by crashing, substantial attention has been devoted to understanding the relative power of the subconsensus family of tasks, which are too weak to solve consensus for two processes. The first major results showed that set agreement and renaming (except for some particular values of n) cannot be solved wait-free in read/write memory. Then it was proved that renaming is strictly weaker than set agreement (when n is odd). This paper considers a natural family of subconsensus tasks that includes set agreement, renaming and other generalized symmetry breaking (GSB) tasks. It extends previous results, and proves various new results about when there is a reduction and when not, among these tasks. Among other results, the paper shows that there are incomparable subconsensus tasks.", "num_citations": "1\n", "authors": ["495"]}
{"title": "The 2010 Edsger W. Dijkstra prize in distributed computing\n", "abstract": " The ACM-EATCS Edsger W. Dijkstra Prize in Distributed Computing was created to acknowledge outstanding papers on the principles of distributed computing whose significance and impact on the theory or practice of distributed computing have been evident for at least a decade.", "num_citations": "1\n", "authors": ["495"]}
{"title": "From anarchy to geometric structuring: the power of virtual coordinates\n", "abstract": " This note define self-structuring in a large-scale networked system as the ability of the participating entities to collaboratively impose a geometric structure to the network. This refers to assigning virtual coordinates to participating entities and to dividing the entities in several partitions, in such a way that each entity knows to which partition it belongs.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Persistance de noyau dans les syst\u00e8mes dynamiques \u00e0 grande \u00e9chelle\n", "abstract": " La plupart des syst\u00e8mes distribu\u00e9s modernes sont \u00e0 la fois grande \u00e9chelle et dynamiques. Malgr\u00e9 l'av\u00e8nement de tels syst\u00e8mes, aucune des solutions que nous avons rencontr\u00e9es ne permet de maintenir la persistance des donn\u00e9es. Cet article se focalise sur la portion des noeuds que quelqu'un doit contacter et la fr\u00e9quence avec laquelle il doit le faire, en fonction du va-et-vient du syst\u00e8me, afin d'assurer, avec une probabilit\u00e9 fix\u00e9e, la persistance des donn\u00e9es. Plus pr\u00e9cis\u00e9ment, cet article met en relation le nombre d'\u00e9l\u00e9ments \u00e0 contacter et la fr\u00e9quence de contact, prouve ce r\u00e9sultat et analyse cette information \u00e0 grande \u00e9chelle.", "num_citations": "1\n", "authors": ["495"]}
{"title": "From static distributed systems to dynamic systems: an approach for a first step\n", "abstract": " A noteworthy advance in distributed computing is due to the recent development of peer-to-peer systems. These systems are essentially dynamic in the sense that no process can get a global knowledge on the system structure. They mainly allow processes to look up for data that can be dynamically added/suppressed in a permanently evolving set of nodes. Although protocols have been developed for such dynamic systems, to our knowledge, up to date no computation model for dynamic systems has been proposed. Nevertheless, there is a strong demand for the definition of such models as soon as one wants to develop provably correct protocols suited to dynamic systems. The talk will present an approach aiming at defining an appropriate model for (a class of) dynamic systems. That dynamic model is defined by (1) a parameter (an integer denoted alpah) and (2) two basic communication abstractions (query\u00a0\u2026", "num_citations": "1\n", "authors": ["495"]}
{"title": "Modularity: A first class concept to address distributed systems\n", "abstract": " Decomposing distributed systems into modules, each with a precise interface and a functional implementation-independent specification, is highly effective both from a software engineering point of view and for theoretical purposes. The usefulness of this approach has been demonstrated in the past in several areas of distributed computing. Yet, despite its attractiveness, so far work on peer-to-peer systems failed to do so. This paper argues in favor of this approach and advocates such a decomposition for peer-to-peer systems.", "num_citations": "1\n", "authors": ["495"]}
{"title": "The Committee Decision Problem\n", "abstract": " We introduce the (b,n)-Committee Decision Problem (CD) - a generalization of the consensus problem. While set agreement generalizes consensus in terms of the number of decisions allowed, the CD problem generalizes consensus in the sense of considering many instances of consensus and requiring a processor to decide in at least one instance. In more detail, in the CD problem each one of a set of n processes has a (possibly distinct) value to propose to each one of a set of b consensus problems, which we call committees. Yet a process has to such that all processes deciding for the same committee decide the same value. We study the CD problem in the context of a wait-free distributed system and analyze it using a combination of distributed algorithmic and topological techniques, introducing a novel reduction technique. We use the reduction technique to obtain the following results. We show that the (2,3)-CD problem is equivalent to the musical benches problem of Gafni and Rajsbaum (DISC 2005), and both are equivalent to (2,3)-set agreement, closing an open question left there. Thus, all three problems are wait-free unsolvable in a read/write shared memory system, and they are all solvable if the system is enriched with objects capable of solving (2,3)-set agreement. While the previous proof of the impossibility of musical benches was based on the Borsuk-Ulam (BU) Theorem, it now relies on Sperner's Lemma, opening intriguing questions about the relation between BU and distributed computing tasks. // Ce rapport pr\u00e9sente un probl\u00e8me de prise de d\u00e9cisionsmultiples (qui g\u00e9n\u00e9ralise le probl\u00e8me du consensus) et \u00e9tudie sa\u00a0\u2026", "num_citations": "1\n", "authors": ["495"]}
{"title": "A QoS-based adaptive model for fault-tolerant distributed computing\n", "abstract": " The capability of dynamically adapting to distinct run-time conditions is an important issue when designing distributed systems where negotiated quality of service (QoS) cannot always be delivered between processes. Providing fault-tolerance for such dynamic environments is a challenging task. Considering such a context, this paper proposes an adaptive model for fault-tolerant distributed computing. This model encompasses both the synchronous model (where there are time bounds on processing speed and message delay) and the asynchronous model (where there is no time bound). To illustrate what can be done in this model and how to use it, the consensus problem is taken as a benchmark problem. An implementation of the model is also described. This implementation relies on a negotiated quality of service (QoS) for channels, that can be timely or untimely. Moreover, the QoS of a channel can be lost during the execution (ie, it can be dynamically modified from timely to untimely), thereby adding uncertainty into the system.", "num_citations": "1\n", "authors": ["495"]}
{"title": "The renaming problem as an introduction to structures for wait-free computing\n", "abstract": " The aim of this introductory survey paper is twofold: to be an introduction to wait-free computing and present the renaming problem. \u201cWait-free\u201d means that the progress of a process depends only on it, regardless of the other processes (that can progress slowly or even crash). It is shown that the design of wait-free algorithms rests on the definition and the use of appropriate data/control structures. To illustrate such structures, the paper considers the renaming problem where the processes have to acquire new names from a small bounded space despite possible process crashes. Two renaming algorithms are presented. The first is a protocol due to Moir and Anderson; it is based on a grid of splitters. The second is due to Attiya and Fouren; it is based on a network of reflectors. It appears that splitters and reflectors are basic data/control structures that permit to define switching networks well-suited to wait-free\u00a0\u2026", "num_citations": "1\n", "authors": ["495"]}
{"title": "Towards a Formal Model for View Maintenance in Data Warehouses\n", "abstract": " Existing protocols A Formal Definition of the Problem Formal Definition of Data Objects Abstract Definition of View Management The Protocol", "num_citations": "1\n", "authors": ["495"]}
{"title": "Early stopping in global data computation\n", "abstract": " The Global Data Computation problem consists in providing each process with the same vector (with one entry per process) such that each entry is lled by a value provided by the corresponding process. This paper presents a protocol that solves this problem in an asynchronous distributed system where processes can crash, but equipped with a perfect failure detector. This protocol requires that processes execute asynchronous computation rounds. The number of rounds is upper bounded by min (f+ 2; t+ 1; n), where n, t and f represent the total number of processes, the maximum number of processes that can crash, and the number of processes that actually crash, respectively. It appears that this value is a lower bound for the number of rounds when t< n 1. Interestingly, this protocol meets the same lower bound as the one required in synchronous systems.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Quiescent uniform reliable broadcast as an introductory survey to failure detector oracles\n", "abstract": " This paper is a short and informal introduction to failure detector oracles for asynchronous distributed systems prone to process crashes and fair lossy channels. A distributed coordination problem (namely, the implementation of Uniform Reliable Broadcast with a quiescent protocol) is used as a paradigm to visit two types of such oracles. One of them is a\\guessing\" oracle in the sense that it provides a process with information that the processes could only approximate if they had to compute it. The other is a\\hiding\" oracle in the sense that it allows to isolate and encapsulate the part of a protocol that has not the required behavioral properties. A quiescent uniform reliable broadcast protocol is described. The guessing oracle is used to ensure the\\uniformity\" requirement stated in the problem speci cation. The\\hiding\" oracle is used to ensure the\\quiescence\" property required for the protocol behavior.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Consistent Data Checkpoints in Distributed Database Systems: a Formal Approach\n", "abstract": " Whether it is for audit or for recovery purposes, data checkpointing is an important problem of distributed database systems. Actually, transactions establish dependence relations on data checkpoints taken by data object managers. So, given an arbitrary set of data checkpoints (including at least a single data checkpoint from a data manager, and at most a data checkpoint from each data manager), an important question is the following one:\u201cCan these data checkpoints be members of a same consistent global checkpoint?\u201d. This paper answers this question by providing a necessary and sufficient condition suited for database systems. Moreover, to show the usefulness of this condition, two non-intrusive data checkpointing protocols are derived from this condition. It is also interesting to note that this paper, by exhibiting \u201ccorrespondences\u201d, establishes a bridge between the data object/transaction model and the process/message-passing model.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Fast asynchronous consensus based on a Weak failure detector\n", "abstract": " The Consensus problem is a fundamental paradigm for fault-tolerant asynchronous systems. It abstracts a family of problems known as Agreement (or Coordination) problems. Any solution to consensus can serve as a basic building block to solve such problems (eg, atomic commitment or atomic broadcast).Solving consensus in an asynchronous system is not a trivial task: it has been proven (1985) by Fischer, Lynch and Paterson that there is no deterministic solution in asynchronous systems that are subject to even a single crash failure. To circumvent this impossibility result, Chandra and Toueg have introduced the concept of unreliable failure detectors (1991), and have studied how these failure detectors can be used to solve consensus in asynchronous systems with crash failures. In this paper, we present a new consensus protocol that uses a failure detector of the class 3S. As previous protocols, our protocol is based on the rotating coordinator paradigm and proceeds in asynchronous rounds. Its design originality lies in (1) the use of a voting mechanism combined with a simple nite state automaton that manages the behavior of each process during each round, and in (2) the possibility for a process to change its mind during a round. This new protocol is more e cient than previous consensus protocols that use the same type of failure detectors. It is particularly e cient when, whether there are failures or not, the underlying failure detector makes few mistakes.", "num_citations": "1\n", "authors": ["495"]}
{"title": "D\u00e9tection de propri\u00e9t\u00e9s instables dans les ex\u00e9cutions r\u00e9parties, application \u00e0 la mise au point des programmes r\u00e9partis\n", "abstract": " Notre incapacite a prouver formellement la correction des programmes repartis rend incontournable les outils de validation de programmes repartis. Dans cette these, nous etudions le probleme de la detection de proprietes instables, les proprietes stables n'etant que de peu d'interet dans le contexte de la mise au point des programmes repartis. Nous definissons d'abord un cadre formel pour la specification et la detection de proprietes d'une execution repartie. Duquel cadre, nous nous servons pour construire et implementer des algorithmes de detection de proprietes comportementales sur les flots de controle. Il s' agit d'une instanciation du probleme de la reconnaissance d'un langage sur un graphe dirige acyclique etiquete. Nous montrons comment instancier notre algorithme generique afin de detecter des proprietes comportementales sur l'ensemble des flots de controle du graphe des etats locaux. Aussi, nous avons defini une logique qui permet de specifier et de detecter une large classe de proprietes comportementales. Une implementation des algorithmes elabores a ete realisee au sein du prototype de devermineur erebus et une etude comparative des resultats obtenus est donnee. Enfin, nous montrons comment specifier des proprietes comportementales sur l'ensemble des sequences d'etats globaux. Les comportements specifies et detectes sont alors les plus larges possibles mais ont un cout important. Nous etudions alors comment detecter des proprietes a moindre cout et notamment comment detecter des etats globaux qui soient atteints quelle que soit l'observation qu'il est possible de construire", "num_citations": "1\n", "authors": ["495"]}
{"title": "A general definition of deadlocks for distributed systems\n", "abstract": " This paper is about the definition of deadlocks in asynchronous messages communication systems. The considered system model covers unspecified receptions, not FIFO channels, and general resource (message) requests including, among others, AND, OR, AND-OR and k-out-of-n requests.< >", "num_citations": "1\n", "authors": ["495"]}
{"title": "k-Arbiter: A safe and general Scheme for h-out of-k mutual exclusion problems\n", "abstract": " Mutual exclusion is a well-known problem that arise when multiple processes compete, in an uncoordinated way, for the acquisition of shared resources over a distributed system. In particular, k-mutual exclusion allows at most k processes to get one unit of the same resource simultaneously. These paradigms do not cover all the cases in which resource accesses must be serialized over a distributed system. There exist cases (e.g. the bandwidth of communication lines) where the amount of shared resource might differ from request to request (for example, audio and video communications). In this paper, we formalize this problem as the {h-out of-k mutual exclusion problem}, in which each request concerns some number h  of units of shared resource and no unit is allocated to multiple processes at the same time. We present a general scheme for a {\\em quorum-based h-out of-k mutual exclusion algorithm} that relies on a collection of quorums called {\\em -arbiter}. Several examples of -arbiters are discussed, two particular classes of k-arbiters are investigated and a metric to evaluate the resiliency with respect to failures of k-arbiters is also given.", "num_citations": "1\n", "authors": ["495"]}
{"title": "R\u00e9-ex\u00e9cution et analyse de calculs r\u00e9partis\n", "abstract": " La mise au point (debugging) de programmes r epartis est une activit e d elicate et di cile. Elle s' apparente a la fois a la mise au point des programmes s equentiels (que l'on r e-ex ecute pour trouver des erreurs et traquer les comportements incorrects) et au test de protocoles (qui mettent en jeu des entit es communiquant par messages).On examine ici deux points fondamentaux de la mise au point des programmes r epartis. Le premier concerne les techniques de r e-ex ecution dont le but est d'obtenir, pour un programme donn e, des ex ecutions r eparties identiques a une ex ecution initiale. Le second point abord e est la d etection de pr edicats globaux (stables ou instables) dans les ex ecutions r eparties (un pr edicat sur un etat global servant a d ecrire une propri et e souhait ee ou non du calcul). En plus des techniques pr esent ees pour r esoudre les probl emes pos es, cet article peut^ etre vu comme une introduction a des concepts de base des syst emes r epartis (pris au sens distributed computing systems).", "num_citations": "1\n", "authors": ["495"]}
{"title": "Evaluation des performances d'un noyau de simulation r\u00e9partie\n", "abstract": " L'utilisation du temps physique comme r\u00e9f\u00e9rence pour la synchronisation des processus d'une application r\u00e9partie peut \u00eatre \u00e9tendue \u00e0 une notion logique de temps : le temps virtuel. Dans un tel contexte, il existe une horloge virtuelle globale \u00e0 l'ensemble des processus dont l'\u00e9volution est cadenc\u00e9e par des r\u00e8gles propres \u00e0 l'application et non par un ph\u00e9nomene physique ext\u00e9rieur. Cette horloge permet d'organiser le calcul, de contr\u00f4ler son \u00e9volution, de dater des \u00e9v\u00e8nements, etc. Cet article pr\u00e9sente l'impl\u00e9mentation et l'\u00e9valuation d'un noyau de syst\u00e8me r\u00e9partie appele Floria et r\u00e9alis\u00e9 \u00e0 l'IRISA ; ce noyau permet d'utiliser la notion de temps virtuel dans une application. Dans un premier temps, le noyau et son interface sont pr\u00e9sent\u00e9s, et les principaux choix de mise en oeuvre sont discut\u00e9s. Ensuite, quelques exemples d'utilisation du noyau sont donn\u00e9s. Finalement, les r\u00e9sultats des exp\u00e9riences effectu\u00e9es pour \u00e9valuer les performances du prototype construit sont pr\u00e9sent\u00e9s et analys\u00e9s.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Implementation and evaluation of distributed synchronization on a distributed memory parallel machine\n", "abstract": " Advenl (ii'di> lrilniled llll\u2019lllUl')\u2018parailel nmchines make possible 10 slndy and analyze dislrilmicd algoritlnns in a real context. In Lhis paper we are interested in a pnrndigm of Lii5Ll'il) llh\u2014P (i computing: t. lie implement. at. ion of (binary and iiiiili. iway) rendez-vous. TiliS problem actuaHy includes two subproblems eneountered in several synchroni7. ation problems: how L0 realize a coordination (of the processes involved in the rendez-vous) and how in ensure some exclusion (beiween con\ufb02iciing rendeavous sharing some processes). Several algorillnns iniplmnenl ing rendez-vous are presented. lmplementat. ions 0f Lhese|> rol-ocols on un li_\\'percube are nualyzed and compared according to a certain number of parmneters; un ef\ufb01ciency ratio is introduced in order lo makc llmse comparisons easier. In addition L0 the resnits exhibited. this paper suggests ai\\'; i)\u2018l ()('0ndlu'l sneh e.\\| wriinents.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Simulation r\u00e9partie de syst\u00e8mes \u00e0 \u00e9v\u00e9nements discrets\n", "abstract": " La simulation r\u00e9partie \u00e0 \u00e9v\u00e9nements discrets est un sujet int\u00e9ressant \u00e0 la fois du point de vue de l'algorithmique r\u00e9partie, car on y retrouve un certain nombre de probl\u00e8mes-type, et du point de vue de l'exp\u00e9rimentation en vraie grandeur de programmes parall\u00e8les, car tout gain de temps peut \u00eatre d\u00e9terminant pour la viabilit\u00e9 de certaines simulations. On examine dans ce rapport d'une part la mod\u00e9lisation des syst\u00e8mes \u00e0 \u00e9v\u00e9nements discrets dans un contexte de r\u00e9partition (mod\u00e8le \u00e0 base de processus et de messages), et d'autre part les probl\u00e8mes pos\u00e9s par la mise en oeuvre de simulateurs r\u00e9partis. Un simulateur est un interpr\u00e9teur de temps virtuel (le temps de la simulation). R\u00e9aliser un simulateur r\u00e9parti consiste donc \u00e0 d\u00e9finir un sch\u00e9ma d'ex\u00e9cution distribu\u00e9 qui assure la progression du temps virtuel (vivacit\u00e9) en respectant les relations de causalit\u00e9 du syst\u00e8me simul\u00e9 (suret\u00e9). Une pr\u00e9sentation des principaux\u00a0\u2026", "num_citations": "1\n", "authors": ["495"]}
{"title": "Simulation r\u00e9partie de syst\u00e8mes \u00e0 \u00e9v\u00e8nements discrets. Partie 1: mod\u00e9lisation et sch\u00e9mas d'ex\u00e9cution\n", "abstract": " La simulation r\u00e9partie \u00e0 \u00e9v\u00e9nements discrets est un sujet int\u00e9ressant \u00e0 la fois du point de vue de l'algorithmique r\u00e9partie, car on y retrouve un certain nombre de probl\u00e8mes-type, et du point de vue de l'exp\u00e9rimentation en vraie grandeur de programmes parall\u00e8les, car tout gain de temps peut \u00eatre d\u00e9terminant pour la viabilit\u00e9 de certaines simulations. On examine dans ce rapport d'une part la mod\u00e9lisation des syst\u00e8mes \u00e0 \u00e9v\u00e9nements discrets dans un contexte de r\u00e9partition (mod\u00e8le \u00e0 base de processus et de messages), et d'autre part les probl\u00e8mes pos\u00e9s par la mise en oeuvre de simulateurs r\u00e9partis. Un simulateur est un interpr\u00e9teur de temps virtuel (le temps de la simulation). R\u00e9aliser un simulateur r\u00e9parti consiste donc \u00e0 d\u00e9finir un sch\u00e9ma d'ex\u00e9cution distribu\u00e9 qui assure la progression du temps virtuel (vivacit\u00e9) en respectant les relations de causalit\u00e9 du syst\u00e8me simul\u00e9 (suret\u00e9). Une pr\u00e9sentation des principaux\u00a0\u2026", "num_citations": "1\n", "authors": ["495"]}
{"title": "La radioth\u00e9rapie avant amputation du rectum pour cancer: 100 observations\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "1\n", "authors": ["495"]}
{"title": "Construction m\u00e9thodique d'un algorithme r\u00e9parti de d\u00e9tection de la terminaison\n", "abstract": " _ bre de m\u00e9thodes, de structures de contr\u00f4le et de m\u00e9canismes d\u2019abstraction propres au contexte r\u00e9parti. Apr\u00e8s avoir pr\u00e9sent\u00e9 l\u2019un des paradigmes de l\u2019observation r\u00e9partie: la d\u00e9tection de la terminaison, cet article en propose une solution fond\u00e9e sur une d\u00e9rivation m\u00e9thodique. Cette solution repose sur la d\u00e9\ufb01nition d\u2019une structure de contr\u00f4le r\u00e9partie abstraite (c\u2019est \u00e0, dire in\u2014d\u00e9pendante d\u2019une mise en \u0153uvre donn\u00e9e), appel\u00e9e train de vagues, permettant de r\u00e9aliser des it\u00e9rations distribu\u00e9e. Quelques exemples de mises en \u0153uvre sont propos\u00e9s. Les outils et la m\u00e9thode utilis\u00e9s peuvent \u00eatre exploit\u00e9s pour r\u00e9soudre diff\u00e9rents probl\u00e8mes de nature distribu\u00e9e.", "num_citations": "1\n", "authors": ["495"]}
{"title": "General and efficient decentralized consensus protocols\n", "abstract": " In this article we are interested in computing a function or a predicate whose arguments are distributed on the nodes (or processors) of a network. When the computation is finished two cases may occur according to the application. The result is either known by each node or distributed on each node. Furthermore during the computation all the nodes have the same behaviour (there is no privileged node). We shall call the distributed algorithms which achieve such computations \"consensus protocols\".             A general and efficient consensus protocol is presented here. It is based on the concepts of phases and filterings. This algorithm can be applied to many problems, for example to compute a minimum routing table for the nodes of the network or to find the maximum of the identities of the nodes (election). If we denote by D the diameter of the network and by m the number of channels (communication links\u00a0\u2026", "num_citations": "1\n", "authors": ["495"]}
{"title": "Calcul r\u00e9parti d'un extr\u00e9mum et du routage associ\u00e9 dans un r\u00e9seau quelconque\n", "abstract": " 16. JM Helary, A. Maddi et M. Raynal, Calcul distribu\u00e9 d'un extr\u00eamum et du routage associ\u00e9 dans un r\u00e9seau quelconque, Rapport de recherche INRIA, n 516, avril 1986, 36 p. A para\u00eetre dans Computer journal 1988.", "num_citations": "1\n", "authors": ["495"]}
{"title": "Conception et r\u00e9alisation d'une machine-langage de haut niveau adapt\u00e9e \u00e0 l'\u00e9criture de syst\u00e8mes\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "1\n", "authors": ["495"]}
{"title": "On the Respective Power of \u041eP and \u041eS to Solve One-Shot Agreement Problems\n", "abstract": " Unreliable failure detectors are abstract devices that, when added to asynchronous distributed systems, allow to solve distributed computing problems (eg Consensus) that otherwise would be impossible to solve in these systems. This paper focuses on two classes of failure detectors defined by Chandra and Toueg, namely, the classes denoted \u041eP (eventually perfect) and \u041eS (eventually strong). Both classes include failure detectors that eventually detect permanently all process crashes, but while the failure detectors of \u041eP eventually make no erroneous suspicions, the failure detectors of \u041eS are only required to eventually not suspect a single correct process. In such a context, this paper addresses the following question related to the comparative power of these classes, namely:\u201cAre there one-shot agreement problems that can be solved in asynchronous distributed systems with reliable links but prone to process crash failures augmented with \u041eP, but cannot be solved when those systems are augmented with \u041eS?\u201d Surprisingly, the paper shows that the answer to this question is \u201cno\u201d. An important consequence of this result is that \u041eP cannot be the weakest class of failure detectors that allows to solve one-shot agreement problems in unreliable asynchronous distributed systems. These results are then extended to the case of more severe failure modes.", "num_citations": "1\n", "authors": ["495"]}