{"title": "Handbook of satisfiability\n", "abstract": " \u201cSatisfiability (SAT) related topics have attracted researchers from various disciplines: logic, applied areas such as planning, scheduling, operations research and combinatorial optimization, but also theoretical issues on the theme of complexity and much more, they all are connected through SAT. My personal interest in SAT stems from actual solving: The increase in power of modern SAT solvers over the past 15 years has been phenomenal. It has become the key enabling technology in automated verification of both computer hardware and software. Bounded Model Checking (BMC) of computer hardware is now probably the most widely used model checking technique. The counterexamples that it finds are just satisfying instances of a Boolean formula obtained by unwinding to some fixed depth a sequential circuit and its specification in linear temporal logic. Extending model checking to software verification is a much more difficult problem on the frontier of current research. One promising approach for languages like C with finite word-length integers is to use the same idea as in BMC but with a decision procedure for the theory of bit-vectors instead of SAT. All decision procedures for bit-vectors that I am familiar with ultimately make use of a fast SAT solver to handle complex formulas. Decision procedures for more complicated theories, like linear real and integer arithmetic, are also used in program verification. Most of them use powerful SAT solvers in an essential way. Clearly, efficient SAT solving is a key technology for 21st century computer science. I expect this collection of papers on all theoretical and practical aspects of SAT solving will\u00a0\u2026", "num_citations": "2099\n", "authors": ["1025"]}
{"title": "PicoSAT essentials\n", "abstract": " In this article we describe and evaluate optimized compact data structures for watching literals. Experiments with our SAT solver PicoSAT show that this low-level optimization not only saves memory, but also turns out to speed up the SAT solver considerably. We also discuss how to store proof traces compactly in memory and further unique features of PicoSAT including an aggressive restart schedule.", "num_citations": "597\n", "authors": ["1025"]}
{"title": "Boolector: An efficient SMT solver for bit-vectors and arrays\n", "abstract": " Satisfiability Modulo Theories (SMT) is the problem of deciding satisfiability of a logical formula, expressed in a combination of first-order theories. We present the architecture and selected features of Boolector, which is an efficient SMT solver for the quantifier-free theories of bit-vectors and arrays. It uses term rewriting, bit-blasting to handle bit-vectors, and lemmas on demand for arrays.", "num_citations": "484\n", "authors": ["1025"]}
{"title": "Resolve and expand\n", "abstract": " We present a novel expansion based decision procedure for quantified boolean formulas (QBF) in conjunctive normal form (CNF). The basic idea is to resolve existentially quantified variables and eliminate universal variables by expansion. This process is continued until the formula becomes propositional and can be solved by any SAT solver. On structured problems our implementation quantor is competitive with state-of-the-art QBF solvers based on DPLL. It is orders of magnitude faster on certain hard to solve instances.", "num_citations": "341\n", "authors": ["1025"]}
{"title": "Lingeling, plingeling and treengeling entering the sat competition 2013\n", "abstract": " This paper serves as solver description for our SAT solver Lingeling and its two parallel variants Treengeling and Plingeling entering the SAT Competition 2013. We only list important differences to the version of these solvers used in the SAT Challenge 2012. For further information we refer to the solver description [1] of the SAT Challenge 2012 or source code.", "num_citations": "262\n", "authors": ["1025"]}
{"title": "Lingeling, plingeling, picosat and precosat at sat race 2010\n", "abstract": " This note serves as system description for our SAT solvers that entered the SAT Race 2010 affiliated to the SAT conference 2010.", "num_citations": "208\n", "authors": ["1025"]}
{"title": "Linear encodings of bounded LTL model checking\n", "abstract": " We consider the problem of bounded model checking (BMC) for linear temporal logic (LTL). We present several efficient encodings that have size linear in the bound. Furthermore, we show how the encodings can be extended to LTL with past operators (PLTL). The generalised encoding is still of linear size, but cannot detect minimal length counterexamples. By using the virtual unrolling technique minimal length counterexamples can be captured, however, the size of the encoding is quadratic in the specification. We also extend virtual unrolling to Buchi automata, enabling them to accept minimal length counterexamples. Our BMC encodings can be made incremental in order to benefit from incremental SAT technology. With fairly small modifications the incremental encoding can be further enhanced with a termination check, allowing us to prove properties with BMC. Experiments clearly show that our new encodings improve performance of BMC considerably, particularly in the case of the incremental encoding, and that they are very competitive for finding bugs. An analysis of the liveness-to-safety transformation reveals many similarities to the BMC encodings in this paper. Using the liveness-to-safety translation with BDD-based invariant checking results in an efficient method to find shortest counterexamples that complements the BMC-based approach.", "num_citations": "200\n", "authors": ["1025"]}
{"title": "Bounded Model Checking.\n", "abstract": " Besides Equivalence Checking [KK97, KPKG02] the most important industrial application of SAT is currently Bounded Model Checking (BMC)[BCCZ99]. Both techniques are used for formal hardware verification in the context of electronic design automation (EDA), but have successfully been applied to many other domains as well. In this chapter, we focus on BMC. In practice, BMC is mainly used for falsification resp. testing, which is concerned with violations of temporal properties. However, the original paper on BMC [BCCZ99] already discussed extensions that can prove properties. A considerable part of this chapter discusses these complete extensions, which are often called \u201cunbounded\u201d model checking techniques, even though they are build upon the same principles as plain BMC.Two further related applications, in which BMC becomes more and more important, are automatic test case generation for closing coverage holes, and disproving redundancy in designs. Most of the techniques discussed in this chapter transfer to this more general setting as well, even though our focus is on property verification resp. falsification.", "num_citations": "189\n", "authors": ["1025"]}
{"title": "DepQBF: A dependency-aware QBF solver\n", "abstract": " We present DepQBF 0.1, a new search-based solver for quantified boolean formulae (QBF). It integrates compact dependency graphs to overcome the restrictions imposed by linear quantifier prefixes of QBFs in prenex conjunctive normal form (PCNF). DepQBF 0.1 was placed first in the main track of QBFEVAL\u201910 in a score-based ranking. We provide a general system overview and describe selected orthogonal features such as restarts and removal of learnt constraints.", "num_citations": "172\n", "authors": ["1025"]}
{"title": "Adaptive restart strategies for conflict driven SAT solvers\n", "abstract": " As the SAT competition has shown, frequent restarts improve the speed of SAT solvers tremendously, particularly on satisfiable industrial instances. This paper presents a novel adaptive technique that measures the agility of the search process dynamically, which in turn is used to control the restart frequency. Experiments demonstrate, that this new dynamic restart strategy improves speed of our SAT solver PicoSAT on crafted instances considerably and on industrial instances slightly.", "num_citations": "147\n", "authors": ["1025"]}
{"title": "Boolector 2.0\n", "abstract": " In this paper, we discuss the most important changes and new features introduced with version 2.0 of our SMT solver Boolector, which placed first in the QF_BV and QF_ABV tracks of the SMT competition 2014. We further outline some features and techniques that were not yet described in the context of Boolector.", "num_citations": "141\n", "authors": ["1025"]}
{"title": "Minimizing learned clauses\n", "abstract": " Minimizing learned clauses is an effective technique to reduce memory usage and also speed up solving time. It has been implemented in MiniSat since 2005 and is now adopted by most modern SAT solvers in academia, even though it has not been described in the literature properly yet. With this paper we intend to close this gap and also provide a thorough experimental analysis of it\u2019s effectiveness for the first time.", "num_citations": "136\n", "authors": ["1025"]}
{"title": "Cadical, lingeling, plingeling, treengeling and yalsat entering the sat competition 2018\n", "abstract": " This note documents the versions of our SAT solvers submitted to the SAT Competition 2018, which are CADICAL, LINGELING, its two parallel variants TREENGELING and PLIN-GELING, and our local search solver YALSAT.", "num_citations": "125\n", "authors": ["1025"]}
{"title": "Simple bounded LTL model checking\n", "abstract": " We present a new and very simple translation of the bounded model checking problem which is linear both in the size of the formula and the length of the bound. The resulting CNF-formula has a linear number of variables and clauses.", "num_citations": "110\n", "authors": ["1025"]}
{"title": "Yet another local search solver and lingeling and friends entering the SAT competition 2014\n", "abstract": " This paper serves as solver description for the SAT solvers Lingeling and its two parallel variants Treengeling and Plingeling, as well as for our new local search solver YalSAT entering the Competition 2014. For Lingeling and its variants we only list important differences to earlier version of these solvers as used in the SAT Competition 2013. For further information we refer to the solver description [1] of the SAT Competition 2013 or source code.", "num_citations": "98\n", "authors": ["1025"]}
{"title": "Fuzzing and delta-debugging SMT solvers\n", "abstract": " SMT solvers are widely used as core engines in many applications. Therefore, robustness and correctness are essential criteria. Current testing techniques used by developers of SMT solvers do not satisfy the high demand for correct and robust solvers, as our testing experiments show. To improve this situation, we propose to complement traditional testing techniques with grammar-based blackbox fuzz testing, combined with delta-debugging. We demonstrate the effectiveness of our approach and report on critical bugs and incorrect results which we found in current state-of-the-art SMT solvers for bit-vectors and arrays.", "num_citations": "98\n", "authors": ["1025"]}
{"title": "Compressing BMC encodings with QBF\n", "abstract": " Symbolic model checking is PSPACE complete. Since QBF is the standard PSPACE complete problem, it is most natural to encode symbolic model checking problems as QBF formulas and then use QBF decision procedures to solve them. We discuss alternative encodings for unbounded and bounded safety checking into SAT and QBF. One contribution is a linear encoding of simple path constraints, which usually are necessary to make k-induction complete. Our experimental results show that indeed a large reduction in the size of the generated formulas can be obtained. However, current QBF solvers seem not to be able to take advantage of these compact formulations. Despite these mostly negative results the availability of these benchmarks will help improve the state of the art of QBF solvers and make QBF based symbolic model checking a viable alternative.", "num_citations": "91\n", "authors": ["1025"]}
{"title": "Clause elimination procedures for CNF formulas\n", "abstract": " We develop and analyze clause elimination procedures, a specific family of simplification techniques for conjunctive normal form (CNF) formulas. Extending known procedures such as tautology, subsumption, and blocked clause elimination, we introduce novel elimination procedures based on hidden and asymmetric variants of these techniques. We analyze the resulting nine (including five new) clause elimination procedures from various perspectives: size reduction, BCP-preservance, confluence, and logical equivalence. For the variants not preserving logical equivalence, we show how to reconstruct solutions to original CNFs from satisfying assignments to simplified CNFs. We also identify a clause elimination procedure that does a transitive reduction of the binary implication graph underlying any CNF formula purely on the CNF level.", "num_citations": "90\n", "authors": ["1025"]}
{"title": "Automated testing and debugging of SAT and QBF solvers\n", "abstract": " Robustness and correctness are essential criteria for SAT and QBF solvers. We develop automated testing and debugging techniques designed and optimized for SAT and QBF solver development. Our fuzz testing techniques are able to find critical solver defects that lead to crashes, invalid satisfying assignments and incorrect satisfiability results. Moreover, we show that sequential and concurrent delta debugging techniques are highly effective in minimizing failure-inducing inputs.", "num_citations": "90\n", "authors": ["1025"]}
{"title": "Evaluating CDCL variable scoring schemes\n", "abstract": " The VSIDS (variable state independent decaying sum) decision heuristic invented in the context of the CDCL (conflict-driven clause learning) SAT solver Chaff, is considered crucial for achieving high efficiency of modern SAT solvers on application benchmarks. This paper proposes ACIDS (average conflict-index decision score), a variant of VSIDS. The ACIDS heuristics is compared to the original implementation of VSIDS, its popular modern implementation EVSIDS (exponential VSIDS), the VMTF (variable move-to-front) scheme, and other related decision heuristics. They all share the important principle to select those variables as decisions, which recently participated in conflicts. The main goal of the paper is to provide an empirical evaluation to serve as a starting point for trying to understand the reason for the efficiency of these decision heuristics. In our experiments, it turns out that EVSIDS, VMTF\u00a0\u2026", "num_citations": "86\n", "authors": ["1025"]}
{"title": "Efficient reduction of finite state model checking to reachability analysis\n", "abstract": " Two types of temporal properties are usually distinguished: safety and liveness. Recently we have shown how to verify liveness properties of finite state systems using safety checking. In this article we extend the translation scheme to typical combinations of temporal operators. We discuss optimizations that limit the overhead of our translation. Using the notions of predicated diameter and radius we obtain revised bounds for our translation scheme. These notions also give a tight bound on the minimal completeness bound for simple liveness properties. Experimental results show the feasibility of the approach for complex examples. For one example, even an exponential speedup can be observed.", "num_citations": "83\n", "authors": ["1025"]}
{"title": "Splatz, lingeling, plingeling, treengeling, yalsat entering the sat competition 2016\n", "abstract": " This paper serves as solver description for our new SAT solver Splatz and further documents the versions of our other solvers submitted to the SAT Competition 2016, which are Lingeling, its two parallel variants Treengeling and Plingeling, and our local search solver YalSAT.", "num_citations": "66\n", "authors": ["1025"]}
{"title": "Lemmas on demand for the extensional theory of arrays\n", "abstract": " The quantifier-free extensional theory of arrays T A plays an important role in hardware and software verification. In this article we present a novel decision procedure that refines formula abstractions with lemmas on demand. We consider the case where T A is combined with a decidable quantifier-free first-order theory T B. Unlike traditional lazy SMT approaches, where lemmas are added on the boolean abstraction layer, our decision procedure adds lemmas in T B. We discuss our decision procedure in detail. In particular, we prove soundness and completeness, and discuss complexity. We present our decision procedure in a generic context and provide implementation details and optimizations, in particular for bit-vectors. Finally, we report on experiments and discuss related work.", "num_citations": "66\n", "authors": ["1025"]}
{"title": "Nenofex: Expanding NNF for QBF solving\n", "abstract": " The topic of this paper is Nenofex, a solver for quantified boolean formulae (QBF) in negation normal form (NNF), which relies on expansion as the core technique for eliminating variables. In contrast to eliminating existentially quantified variables by resolution on CNF, which causes the formula size to increase quadratically in the worst case, expansion on NNF is involved with only a linear increase of the formula size. This property motivates the use of NNF instead of CNF combined with expansion. In Nenofex, a formula in NNF is represented as a tree with structural restrictions in order to keep its size small and distances from nodes to the root short. Expansions of variables are scheduled based on estimated expansion cost. The variable with the smallest estimated cost is expanded first. In order to remove redundancy from the formula, limited versions of two approaches from the domain of circuit optimization\u00a0\u2026", "num_citations": "66\n", "authors": ["1025"]}
{"title": "SAT and ATPG: Boolean engines for formal hardware verification\n", "abstract": " In this survey, we outline basic SAT-and ATPG-procedures as well as their applications in formal hardware verification. We attempt to give the reader a trace trough literature and provide a basic orientation concerning the problem formulations and known approaches in this active field of research.", "num_citations": "66\n", "authors": ["1025"]}
{"title": "Integrating dependency schemes in search-based QBF solvers\n", "abstract": " Many search-based QBF solvers implementing the DPLL algorithm for QBF (QDPLL) process formulae in prenex conjunctive normal form (PCNF). The quantifier prefix of PCNFs often results in strong variable dependencies which can influence solver performance negatively. A common approach to overcome this problem is to reconstruct quantifier structure e.g.\u00a0by quantifier trees. Dependency schemes are a generalization of quantifier trees in the sense that more general dependency graphs can be obtained. So far, dependency graphs have not been applied in QBF solving. In this work we consider the problem of efficiently integrating dependency graphs in QDPLL. Thereby we generalize related work on integrating quantifier trees. By analyzing the core parts of QDPLL, we report on modifications necessary to profit from general dependency graphs. In comprehensive experiments we show that QDPLL\u00a0\u2026", "num_citations": "64\n", "authors": ["1025"]}
{"title": "AIGER 1.9 and beyond\n", "abstract": " This is a short note on the differences between AIGER format version 20071012 and the new versions starting with version 1.9.To ease the transition, the new 1.9 series of AIGER is intended to be syntactically downward compatible with the previous format, but contains already all the new features of the upcoming AIGER version 2.0 format. The future AIGER 2.0 version will not be syntactically downward compatible, because it uses a new binary encoding. However, at least initially, it will not have new features. For the HWMCC\u201911 competition we will accept tools that work on the old format or with the new 1.9 series formats. However, for the new track with multiple properties and particularly for the liveness track only the new 1.9 series format is supported.", "num_citations": "62\n", "authors": ["1025"]}
{"title": "P {re, i} coSAT@ SC\u201909\n", "abstract": " In this note we describe the new features of PicoSAT version 913 as it was submitted to the SAT competition 2009. It also contains a description of our new solver PrecoSAT version 236, which tightly integrates various preprocessing techniques into a PicoSAT like core engine.", "num_citations": "61\n", "authors": ["1025"]}
{"title": "Shortest counterexamples for symbolic model checking of LTL with past\n", "abstract": " Shorter counterexamples are typically easier to understand. The length of a counterexample, as reported by a model checker, depends on both the algorithm used for state space exploration and the way the property is encoded. We provide necessary and sufficient criteria for a B\u00fcchi automaton to accept shortest counterexamples. We prove that B\u00fcchi automata constructed using the approach of Clarke, Grumberg, and Hamaguchi accept shortest counterexamples of future time LTL formulae, while an automaton generated with the algorithm of Gerth et al.\u00a0(GPVW) may lead to unnecessary long counterexamples. Optimality is lost in the first case as soon as past time operators are included. Adapting a recently proposed encoding for bounded model checking of LTL with past, we construct a B\u00fcchi automaton that accepts shortest counterexamples for full LTL. We use our method of translating liveness into\u00a0\u2026", "num_citations": "61\n", "authors": ["1025"]}
{"title": "Simple is better: Efficient bounded model checking for past LTL\n", "abstract": " We consider the problem of bounded model checking for linear temporal logic with past operators (PLTL). PLTL is more attractive as a specification language than linear temporal logic without past operators (LTL) since many specifications are easier to express in PLTL . Although PLTL is not more expressive than LTL, it is exponentially more succinct. Our contribution is a new more efficient encoding of the bounded model checking problem for PLTL based on our previously presented encoding for LTL . The new encoding is linear in the bound. We have implemented the encoding in the NuSMV\u00a02.1 model checking tool and compare it against the encoding in NuSMV by Benedetti and Cimatti. The experimental results show that our encoding performs significantly better than this previously used encoding.", "num_citations": "60\n", "authors": ["1025"]}
{"title": "The AIGER And-Inverter Graph (AIG) Format Version 20071012\n", "abstract": " This report describes the AIG file format as used by the AIGER library. The purpose of this report is not only to motivate and document the format, but also to allow independent implementations of writers and readers by giving precise and unambiguous definitions.", "num_citations": "59\n", "authors": ["1025"]}
{"title": "Managing SAT inconsistencies with HUMUS\n", "abstract": " In Product Line Engineering, as in any other modeling domain, designers and end users are prone to making inconsistent assumptions (errors) because of complexity and lack of system knowledge. We previously envisioned a way of allowing inconsistencies during product configuration and in this paper we present a solution on how to realize this vision. We introduce HUMUS (High-level Union of Minimal Unsatisfiable Sets), which enables correct reasoning in product line engineering (encoded in SAT) despite the presence of errors. We focus mainly on tolerating inconsistencies during product configuration, to make it possible to resolve inconsistencies later without misguiding the human user along the way. We also provide a discussion of other applications in product line engineering and beyond. The main advantage of using HUMUS is, that it is possible to isolate erroneous parts of a product line model such\u00a0\u2026", "num_citations": "57\n", "authors": ["1025"]}
{"title": "Lingeling Essentials, A Tutorial on Design and Implementation Aspects of the the SAT Solver Lingeling.\n", "abstract": " One of the design principles of the state-of-the-art SAT solver Lingeling is to use as compact data structures as possible. These reduce memory usage, increase cache efficiency and thus improve runtime, particularly, when using multiple solver instances on multi-core machines, as in our parallel portfolio solver Plingeling and our cube and conquer solver Treengeling. The scheduler of a dozen inprocessing algorithms is an important aspect of Lingeling as well. In this talk we explain these design and implementation aspects of Lingeling and discuss new direction of solver design.", "num_citations": "54\n", "authors": ["1025"]}
{"title": "Liveness checking as safety checking for infinite state spaces\n", "abstract": " In previous work we have developed a syntactic reduction of repeated reachability to reachability for finite state systems. This may lead to simpler and more uniform proofs for model checking of liveness properties, help to find shortest counterexamples, and overcome limitations of closed-source model-checking tools. In this paper we show that a similar reduction can be applied to a number of infinite state systems, namely, (\u03c9\u2212)regular model checking, push-down systems, and timed automata.", "num_citations": "54\n", "authors": ["1025"]}
{"title": "Detecting cardinality constraints in CNF\n", "abstract": " We present novel approaches to detect cardinality constraints expressed in CNF. The first approach is based on a syntactic analysis of specific data structures used in SAT solvers to represent binary and ternary clauses, whereas the second approach is based on a semantic analysis by unit propagation. The syntactic approach computes an approximation of the cardinality constraints AtMost-1 and AtMost-2 constraints very fast, whereas the semantic approach has the property to be generic, i.e. it can detect cardinality constraints AtMost-k for any k, at a higher computation cost. Our experimental results suggest that both approaches are efficient at recovering AtMost-1 and AtMost-2 cardinality constraints.", "num_citations": "53\n", "authors": ["1025"]}
{"title": "Lingeling and friends entering the SAT Challenge 2012\n", "abstract": " Compared to the version submitted to the SAT competition 2011 and described in [1], we removed complicated algorithms and features, which did not really have any observable impact on the run-time for those benchmarks we tried. In particular, various versions of distillation inprocessors were removed. Regarding inprocessing [4], there are two new probing variants. One is called simple probing and tries to learn hyper binary resolutions eagerly. The other variant is based on tree-based look-ahead, which is a simplified version of the implementation in March [2]. These two techniques are complemented by gaussian elimination and a new congruence closure algorithm, which both use extracted gates to generate and propagate equivalences.We also switched to one merged inprocessing phase, called simplification, where all inprocessors run one after each other, instead of allowing each inprocessor to be scheduled and interleaved with search individually. Furthermore, for most inprocessors we have now a way to save the part of the formula on which the inprocessor did not run until completion (actually currently only \u201cuntried variables\u201d). In the next simplification phase, the algorithm can be resumed on that part, such that eventually we achieve the same effect as really running the various algorithms until completion. Previously we used randomization to achieve a similar effect. This technique also allowed us to remove certain limits, such as the maximum number of occurrences or the maximum resolvent size in variable elimination. We moved to an inner-outer scheme for the size of kept learned clauses, also called reduce schedule. The inner\u00a0\u2026", "num_citations": "52\n", "authors": ["1025"]}
{"title": "Btor2 , BtorMC and Boolector\u00a03.0\n", "abstract": " We describe Btor2, a word-level model checking format for capturing models of hardware and potentially software in a bit-precise manner. This simple, line-based and easy to parse format can be seen as a sorted extension of the word-level format Btor. It uses design principles from the bit-level format Aiger and follows semantics of the Smt-Lib logics of bit-vectors with arrays. This intermediate format can be used in various verification flows and is perfectly suited to establish a word-level model checking competition. It is supported by our new open source model checker BtorMC, which is built on top of version 3.0 of our SMT solver Boolector. We further provide new word-level benchmarks on which these open source tools are evaluated.", "num_citations": "49\n", "authors": ["1025"]}
{"title": "\u03bccke\u2014efficient \u03bc-calculus model checking\n", "abstract": " In this paper we present an overview of the verification tool \u03bccke. It is an implementation of a BDD-based \u03bc-calculus model checker and uses several optimization techniques that are lifted from special purpose model checkers to the \u03bc-calculus. This gives the user more expressibility without loosing efficiency.", "num_citations": "48\n", "authors": ["1025"]}
{"title": "Column-wise verification of multipliers using computer algebra\n", "abstract": " Verifying arithmetic circuits, and most prominently multipliers, is an important problem but in practice still requires substantial manual effort. Recent work tries to solve this issue using techniques from computer algebra. The most effective approach uses polynomial reasoning over pseudo boolean polynomials. In this paper we give a rigorous formalization of this approach and present a new column-wise verification technique for the correctness of gate-level multipliers which does not require the reduction of a full word-level specification. We formally prove soundness and completeness of our technique, making use of our precise formalization. Our experiments show that simple multipliers can be verified efficiently by using off-the-shelf computer algebra tools, while more complex and optimized multipliers require more sophisticated techniques. Further, our paper independently confirms the effectiveness of previous\u00a0\u2026", "num_citations": "47\n", "authors": ["1025"]}
{"title": "Fixed-Parameter Tractability.\n", "abstract": " The propositional satisfiability problem (SAT) is famous for being the first problem shown to be NP-complete\u2014we cannot expect to find a polynomial-time algorithm for SAT. However, over the last decade, SAT-solvers have become amazingly successful in solving formulas with thousands of variables that encode problems arising from various application areas. Theoretical performance guarantees, however, are far from explaining this empirically observed efficiency. Actually, theorists believe that the trivial 2n time bound for solving SAT instances with n variables cannot be significantly improved, say to 2o (n)(see the end of Section 13.2). This enormous discrepancy between theoretical performance guarantees and the empirically observed performance of SAT solvers can be explained by the presence of a certain \u201chidden structure\u201d in instances that come from applications. This hidden structure greatly facilitates the propagation and simplification mechanisms of SAT solvers. Thus, for deriving theoretical performance guarantees that are closer to the actual performance of solvers one needs to take this hidden structure of instances into account. The literature contains several suggestions for making the vague term of a hidden structure explicit. For example, the hidden structure can be considered as the \u201ctree-likeness\u201d or \u201cHorn-likeness\u201d of the instance (below we will discuss how these notions can be made precise). All such concepts have in common that one associates with a CNF formula F a non-negative integer k= \u03c0 (F); the smaller the integer, the more structured the instance under a certain perspective. We call such a mapping \u03c0 a satisfiability\u00a0\u2026", "num_citations": "47\n", "authors": ["1025"]}
{"title": "Evaluating CDCL restart schemes\n", "abstract": " Modern CDCL (conflict-driven clause learning) SAT solvers are used for many practical applications. One of the key ingredients of state-of-the-art CDCL solvers are efficient restart schemes. The main contribution of this work is an extensive empirical evaluation of various restart strategies. We show that optimal static restart intervals are not only correlated with the satisfiability status of a certain instance, but also with the more specific problem class of the given benchmark. We further compare uniform restart intervals with the performance of non-uniform restart schemes, such as Luby restarts. Finally, we revisit the dynamic restart strategy used in Glucose and propose a new variant thereof, which is based on the concept of exponential moving averages. The resulting implementation in Lingeling improves state-of-the-art performance in SAT solving.", "num_citations": "46\n", "authors": ["1025"]}
{"title": "Factoring out assumptions to speed up MUS extraction\n", "abstract": " In earlier work on a limited form of extended resolution for CDCL based SAT solving, new literals were introduced to factor out parts of learned clauses. The main goal was to shorten clauses, reduce proof size and memory usage and thus speed up propagation and conflict analysis. Even though some reduction was achieved, the effectiveness of this technique was rather modest for generic SAT solving. In this paper we show that factoring out literals is particularly useful for incremental SAT solving, based on assumptions. This is the most common approach for incremental SAT solving and was pioneered by the authors of MINISAT. Our first contribution is to focus on factoring out only assumptions, and actually all eagerly. This enables the use of compact dedicated data structures, and naturally suggests a new form of clause minimization, our second contribution. As last main contribution, we propose to use\u00a0\u2026", "num_citations": "45\n", "authors": ["1025"]}
{"title": "On the Complexity of Fixed-Size Bit-Vector Logics with Binary Encoded Bit-Width.\n", "abstract": " On the Complexity of Fixed-Size Bit-Vector Logics with Binary Encoded Bit-Width Page 1 1 On the Complexity of Fixed-Size Bit-Vector Logics with Binary Encoded Bit-Width Gergely Kov\u00e1sznai, Andreas Fr\u00f6hlich, Armin Biere Institute for Formal Models and Verification Johannes Kepler University, Linz, Austria http://fmv.jku.at SMT 2012 June 30 - July 1, 2012 Manchester, UK Gergely Kov\u00e1sznai, Andreas Fr\u00f6hlich, Armin Biere Complexity of Bit-Vector Logics with Binary Encoded Bit-Width Page 2 2 Motivation How the encoding of the bit-widths affects the complexity of satisfiability checking for BV logics? In practice logarithmic (eg binary, decimal, hexadecimal) encoding is used (in contrast with unary encoding) Example in SMT2 (set-logic QF_BV) (declare-fun x () (_ BitVec 1000000)) (declare-fun y () (_ BitVec 1000000)) (assert (distinct (bvadd xy) (bvadd yx))) Using Boolector: 103 MB in AIGER format; 1 GB in DIMACS \u2026", "num_citations": "44\n", "authors": ["1025"]}
{"title": "Complexity of fixed-size bit-vector logics\n", "abstract": " Bit-precise reasoning is important for many practical applications of Satisfiability Modulo Theories (SMT). In recent years, efficient approaches for solving fixed-size bit-vector formulas have been developed. From the theoretical point of view, only few results on the complexity of fixed-size bit-vector logics have been published. Some of these results only hold if unary encoding on the bit-width of bit-vectors is used. In our previous work (Kov\u00e1sznai et al. 2012), we have already shown that binary encoding adds more expressiveness to various fixed-size bit-vector logics with and without quantification. In a follow-up work (Fr\u00f6hlich et al. 2013), we then gave additional complexity results for several fragments of the quantifier-free case. In this paper, we revisit our complexity results from (Fr\u00f6hlich et al. 2013; Kov\u00e1sznai et al. 2012) and go into more detail when specifying the underlying logics and presenting the\u00a0\u2026", "num_citations": "43\n", "authors": ["1025"]}
{"title": "iDQ: Instantiation-Based DQBF Solving.\n", "abstract": " iDQ: Instantiation-Based DQBF Solving Page 1 iDQ: Instantiation-Based DQBF Solving Andreas Fr\u00f6hlich1, Gergely Kov\u00e1sznai2, Armin Biere1, Helmut Veith2 1 Johannes Kepler University, Linz 2 Vienna University of Technology, Vienna http://fmv.jku.at http://forsyte.at POS 2014 July 13, 2014 Vienna, Austria Andreas Fr\u00f6hlich, Gergely Kov\u00e1sznai, Armin Biere, Helmut Veith iDQ: Instantiation-Based DQBF Solving Page 2 What is DQBF? DQBF = Dependency Quantified Boolean Formulas \u2200u1, u2, u3 \u2203e(u1, u3), f (u2) . (u2 \u2228 u3 \u2228 e) \u2227 (u1 \u2228 u2 \u2228 e \u2228 f ) Generalization of QBF Variable dependencies can be explicitly given Higher complexity: QBF \u2013 PSpace-complete DQBF \u2013 NExpTime-complete Andreas Fr\u00f6hlich, Gergely Kov\u00e1sznai, Armin Biere, Helmut Veith iDQ: Instantiation-Based DQBF Solving Page 3 Applications for DQBF Partial-information 2-player games [Peterson, Reif. Multiple-person alternation. \u2026", "num_citations": "41\n", "authors": ["1025"]}
{"title": "Lingeling and Friends at the SAT Competition 2011\n", "abstract": " This note serves as system description for our solvers submitted to the various tracks of the SAT Competition 2011 affiliated to the SAT conference 2011.", "num_citations": "41\n", "authors": ["1025"]}
{"title": "Local two-level and-inverter graph minimization without blowup\n", "abstract": " And-Inverter Graphs (AIGs) are an efficient and scalable representation for boolean formulas and circuits. We present a maximal set of rules for local two-level optimization of AIGs. This set consists of rules which can be applied before node creation greedily without affecting structural sharing negatively. We implemented these techniques in the AIG library of our tool SMV2QBF and report on experimental results in the context of SAT based model checking.", "num_citations": "40\n", "authors": ["1025"]}
{"title": "A DPLL algorithm for solving DQBF\n", "abstract": " A DPLL Algorithm for Solving DQBF Page 1 A DPLL Algorithm for Solving DQBF Andreas Fr\u00f6hlich, Gergely Kov\u00e1sznai, Armin Biere Institute for Formal Models and Verification, Johannes Kepler University, Linz, Austria June 16, 2012 Andreas Fr\u00f6hlich, Gergely Kov\u00e1sznai, Armin Biere A DPLL Algorithm for Solving DQBF Page 2 What is DQBF? DQBF = Dependency Quantified Boolean Formulas Boolean formulas with Henkin quantifiers, ie dependencies are ... ... specified explicitely ... partially ordered Example: Vu1,u29e1(u1),e2(u2).\u03c6 Deciding DQBF is NEXPTIME-complete Andreas Fr\u00f6hlich, Gergely Kov\u00e1sznai, Armin Biere A DPLL Algorithm for Solving DQBF Page 3 Motivation Algorithm for solving NEXPTIME-problems (eg satisfiability of formulas in EPR or SMT: BV UF) Profit from efficient techniques developed for SAT/QBF So far there is no algorithm for DQBF Andreas Fr\u00f6hlich, Gergely Kov\u00e1sznai, Armin Biere A \u2026", "num_citations": "38\n", "authors": ["1025"]}
{"title": "Hardware model checking competition 2017\n", "abstract": " The Hardware Model Checking Competition (HWMCC) 2017 affiliated to the International Conference on Formal Methods in Computer Aided Design (FMCAD) in 2017 in Vienna was the 9th competitive event for hardware model checkers we organized. After HWMCC'15 affiliated with FMCAD'15 in Austin, the competition took a break in 2016.", "num_citations": "37\n", "authors": ["1025"]}
{"title": "Stochastic local search for satisfiability modulo theories\n", "abstract": " Satisfiability Modulo Theories (SMT) is essential for many practical applications, eg, in hard-and software verification, and increasingly also in other scientific areas like computational biology. A large number of applications in these areas benefit from bit-precise reasoning over finite-domain variables. Current approaches in this area translate a formula over bit-vectors to an equisatisfiable propositional formula, which is then given to a SAT solver. In this paper, we present a novel stochastic local search (SLS) algorithm to solve SMT problems, especially those in the theory of bit-vectors, directly on the theory level. We explain how several successful techniques used in modern SLS solvers for SAT can be lifted to the SMT level. Experimental results show that our approach can compete with state-of-the-art bit-vector solvers on many practical instances and, sometimes, outperform existing solvers. This offers interesting possibilities in combining our approach with existing techniques, and, moreover, new insights into the importance of exploiting problem structure in SLS solvers for SAT. Our approach is modular and, therefore, extensible to support other theories, potentially allowing SLS to become part of the more general SMT framework.", "num_citations": "36\n", "authors": ["1025"]}
{"title": "BTOR: bit-precise modelling of word-level problems for model checking\n", "abstract": " This is a proposal for a bit-precise word-level format, called BTOR. It is easy to parse and has precise semantics. In its basic form it allows to model SMT problems over the quantifier-free theory of bit-vectors in combination with one-dimensional arrays. Our main contribution is a sequential extension that can be used to capture model checking problems on the word-level. We present two case studies where BTOR is used as sequential format. Finally, we report on experimental results for the model checking extension of our SMT solver Boolector.", "num_citations": "36\n", "authors": ["1025"]}
{"title": "Effective bit-width and under-approximation\n", "abstract": " Recently, it has been proposed to use approximation techniques in the context of decision procedures for the quantifier-free theory of fixed-size bit-vectors. We discuss existing and novel variants of under-approximation techniques. Under-approximations produce smaller models and may reduce solving time significantly. We propose a new technique that allows early termination of an under-approximation refinement loop, although the original formula is unsatisfiable. Moreover, we show how over-approximation and under-approximation techniques can be combined. Finally, we evaluate the effectiveness of our approach on array and bit-vector benchmarks of the SMT library.", "num_citations": "31\n", "authors": ["1025"]}
{"title": "The auspicious couple: Symbolic execution and WCET analysis\n", "abstract": " We have recently shown that symbolic execution together with the implicit path enumeration technique can successfully be applied in the Worst-Case Execution Time (WCET) analysis of programs. Symbolic execution offers a precise framework for program analysis and tracks complex program properties by analyzing single program paths in isolation. This path-wise program exploration of symbolic execution is, however, computationally expensive, which often prevents full symbolic analysis of larger applications: the number of paths in a program increases exponentially with the number of conditionals, a situation denoted as the path explosion problem. Therefore, for applying symbolic execution in the timing analysis of programs, we propose to use WCET analysis as a guidance for symbolic execution in order to avoid full symbolic coverage of the program. By focusing only on paths or program fragments that are relevant for WCET analysis, we keep the computational costs of symbolic execution low. Our WCET analysis also profits from the precise results derived via symbolic execution. In this article we describe how use-cases of symbolic execution are materialized in the r-TuBound toolchain and present new applications of WCET-guided symbolic execution for WCET analysis. The new applications of selective symbolic execution are based on reducing the effort of symbolic analysis by focusing only on relevant program fragments. By using partial symbolic program coverage obtained by selective symbolic execution, we improve the WCET analysis and keep the effort for symbolic execution low.", "num_citations": "30\n", "authors": ["1025"]}
{"title": "Verifying large multipliers by combining SAT and computer algebra\n", "abstract": " We combine SAT and computer algebra to substantially improve the most effective approach for automatically verifying integer multipliers. In our approach complex final stage adders are detected and replaced by simple adders. These simplified multipliers are verified by computer algebra techniques and correctness of the replacement step by SAT solvers. Our new dedicated reduction engine relies on a Gr\u00f6bner basis theory for coefficient rings which in contrast to previous work no longer are required to be fields. Modular reasoning allows us to verify not only large unsigned and signed multipliers much more efficiently but also truncated multipliers. We are further able to generate and check proofs an order of magnitude faster than in our previous work, relative to verification time, while other competing approaches do not provide certificates.", "num_citations": "29\n", "authors": ["1025"]}
{"title": "Hardware model checking competition 2014: an analysis and comparison of model checkers and benchmarks\n", "abstract": " Model checkers and sequential equivalence checkers have become essential tools for the semiconductor industry in recent years. The Hardware Model Checking Competition (HWMCC) was founded in 2006 with the purpose of intensifying research interest in these technologies, and establishing more of a science behind them. For example, the competition provided a standardized benchmark format, a challenging and diverse set of industrially-relevant public benchmarks, and, as a consequence, a significant motivation for additional research to advance the state-of-the-art in model checkers for these verification problems. This paper provides a historical perspective, and an analysis of the tools and benchmarks submitted to the competition. It also presents a detailed analysis of the results collected in the 2014 edition of the contest, showing relations among tools, and among tools and benchmarks. It finally\u00a0\u2026", "num_citations": "29\n", "authors": ["1025"]}
{"title": "Counterexample-guided model synthesis\n", "abstract": " In this paper we present a new approach for solving quantified formulas in Satisfiability Modulo Theories (SMT), with a particular focus on the theory of fixed-size bit-vectors. We combine counterexample-guided quantifier instantiation with a syntax-guided synthesis approach, which allows us to synthesize both Skolem functions and terms for quantifier instantiations. Our approach employs two ground theory solvers to reason about quantified formulas. It neither relies on quantifier specific simplifications nor heuristic quantifier instantiation techniques, which makes it a simple yet effective approach for solving quantified formulas. We implemented our approach in our SMT solver Boolector and show in our experiments that our techniques are competitive compared to the state-of-the-art in solving quantified bit-vectors.", "num_citations": "28\n", "authors": ["1025"]}
{"title": "Failed literal detection for QBF\n", "abstract": " Failed literal detection (FL) in SAT is a powerful approach for preprocessing. The basic idea is to assign a variable as assumption. If boolean constraint propagation (BCP) yields an empty clause then the negated assumption is necessary for satisfiability. Whereas FL is common in SAT, it cannot easily be applied to QBF due to universal quantification. We present two approaches for FL to preprocess prenex CNFs. The first one is based on abstraction where certain universal variables are treated as existentially quantified. Second we combine QBF-specific BCP (QBCP) in FL with Q-resolution to validate assignments learnt by FL. Finally we compare these two approaches to a third common approach based on SAT. It turns out that the three approaches are incomparable. Experimental evaluation demonstrates that FL for QBF can improve the performance of search- and elimination-based QBF solvers.", "num_citations": "28\n", "authors": ["1025"]}
{"title": "The evolution from Limmat to Nanosat\n", "abstract": " In this technical report we summarize the evolution of SAT solvers implemented at the formal methods group at ETH Z\u00a8urich. We start with LIMMAT and COMPSAT, which both took part in the SAT\u201903 SAT solver competition. From the more ambitious design of FUNEX we reach the minimal implementation of NANOSAT. We close the discussion with an overview on how our QBF solver QUANTOR can be used as a preprocessor for SAT. We highlight differences to similar implementations, emphasizing new ideas. No detailed experimental comparison is provided, since the main purpose of this technical report is to give a reference point for the SAT\u201904 SAT solver competition.", "num_citations": "28\n", "authors": ["1025"]}
{"title": "Effiziente Modellpr\u00fcfung des \u00b5-Kalk\u00fcls mit bin\u00e4ren Entscheidungsdiagrammen.\n", "abstract": " Diese Randbedingungen werden formalisiert und es wird gezeigt, wie verschiedene Randbedingungen kombiniert werden k\u00f6nnen. So erh\u00e4lt man einen weitestgehend automatischen Allokationsalgorithmus f\u00fcr den Modellpr\u00fcfer \u00b5cke. In vergleichbaren Systemen/Rauzy, 1995, Enders et al., 1993/mu\u00df der Benutzer die Allokationen per Hand angeben und verliert einen gro\u00dfen Teil des Komforts gegen\u00fcber Spezialmodellpr\u00fcfer wie dem SMV/McMillan, 1993a/, bei dem gute Allokationen, was die Substitutionen betrifft, f\u00fcr die verwendete eingeschr\u00e4nkte Eingabesprache fest gew\u00e4hlt werden k\u00f6nnen.", "num_citations": "26\n", "authors": ["1025"]}
{"title": "Analysis of Portfolio-Style Parallel SAT Solving on Current Multi-Core Architectures.\n", "abstract": " Effectively parallelizing SAT solving is an open and important issue. The current stateof-the-art is based on parallel portfolios. This technique relies on running multiple solvers on the same instance in parallel. As soon as one instance finishes, the entire run stops. Several successful systems even use Plain Parallel Portfolio (PPP), where the individual solvers do not exchange any information. This paper contains a thorough experimental evaluation of PPP, which shows that PPP can improve wall-clock runtime. This improvement is due to the fact that memory access is still local and the memory system can hide the latency of memory access, respectively. In particular, there does not seem as much cache congestion as one might imagine. We further present some limits on the scalability of PPP and finally give one argument why PPP solvers are a good fit for todays multi-core architectures.", "num_citations": "24\n", "authors": ["1025"]}
{"title": "JVM independent replay in Java\n", "abstract": " Deterministic replay can help to understand the cause of a failing execution of a multi-threaded program. Stepwise browsing of a counterexample serves the same purpose in the context of static and dynamic checking. In this paper we present a tool for deterministic replay of a multi-threaded execution of a Java program. The replay engine is independent of a specific JVM. We also suggest a language to describe thread schedules. Such schedules can be produced either directly by a tool or virtual machine or can, given some additional information, be extracted from a bytecode trace. Thus, off-the-shelf debuggers can be used for both, cyclic debugging of multi-threaded Java programs, and for browsing of concurrent execution traces produced by many checking tools. Experimental results show that correct replay can be performed with acceptable overhead across a number of virtual machines. Plug-ins have been\u00a0\u2026", "num_citations": "24\n", "authors": ["1025"]}
{"title": "HW accelerated ultra wide band MAC protocol using SDL and SystemC\n", "abstract": " In This work we present a novel method for designing and validating a HW accelerated MAC controller for ultra wide band systems. Guaranteed response time and low power consumption are the two main drivers for the proposed HW/SW partitioning. We propose to use the SDL formalism in a way that facilitates the refinement verification of the SDL model against its derived SystemC implementation.", "num_citations": "24\n", "authors": ["1025"]}
{"title": "Incremental inprocessing in SAT solving\n", "abstract": " Incremental SAT is about solving a sequence of related SAT problems efficiently. It makes use of already learned information to avoid repeating redundant work. Also preprocessing and inprocessing are considered to be crucial. Our calculus uses the most general redundancy property and extends existing inprocessing rules to incremental SAT solving. It allows to automatically reverse earlier simplification steps, which are inconsistent with literals in new incrementally added clauses. Our approach to incremental SAT solving not only simplifies the use of inprocessing but also substantially improves solving time.", "num_citations": "22\n", "authors": ["1025"]}
{"title": "Improving and extending the algebraic approach for verifying gate-level multipliers\n", "abstract": " The currently most effective approach for verifying gate-level multipliers uses Computer Algebra. It reduces a word-level multiplier specification by a Grobner basis derived from a gate-level implementation. This reduction produces zero if and only if the circuit is a multiplier. We improve this approach by extracting full- and half-adder constraints to reduce the Grobner basis, which speeds up computation substantially. Refactoring the specification in terms of partial products instead of inputs yields further improvements. As a third contribution we extend these algebraic techniques to verify the equivalence of bit-level multipliers without using a word-level specification.", "num_citations": "22\n", "authors": ["1025"]}
{"title": "Model-based API testing for SMT solvers\n", "abstract": " Verification back ends such as SMT solvers are typically highly complex pieces of software with performance, correctness and robustness as key requirements. Full verification of SMT solvers, however, is difficult due to their complex nature and still an open question. Grammar-based black-box input fuzzing proved to be effective to uncover bugs in SMT solvers but is entirely input-based and restricted to a certain input language. State-of-theart SMT solvers, however, usually provide a rich API, which often introduces additional functionality not supported by the input language. Previous work showed that applying model-based API fuzzing to SAT solvers is more effective than input fuzzing. In this paper, we introduce a model-based API testing framework for our SMT solver Boolector. Our experimental results show that model-based API fuzzing in combination with delta debugging techniques is effective for testing SMT solvers.", "num_citations": "22\n", "authors": ["1025"]}
{"title": "PicoSAT\n", "abstract": " CiNii \u8ad6\u6587 - PicoSAT CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587 \u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 PicoSAT BIERE Armin \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 BIERE Armin \u53ce\u9332\u520a\u884c\u7269 http://fmv.jku.at/picosat/ http://fmv.jku.at/picosat/ \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 \u8ad6\u7406\u95a2\u6570\u306e\u5145\u8db3\u4e0d\u53ef\u80fd\u6027\u306b\u6ce8\u76ee\u3057\u305f\u8ad6\u7406\u56de\u8def\u30c7\u30d0\u30c3\u30b0\u624b\u6cd5\u306e\u691c\u8a0e \u674e \u5728\u57ce , \u677e\u672c \u525b\u53f2 , \u85e4\u7530 \u660c\u5b8f \u96fb\u5b50\u60c5\u5831\u901a\u4fe1\u5b66\u4f1a\u6280\u8853\u7814\u7a76\u5831\u544a. CPSY, \u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30b7\u30b9\u30c6\u30e0 111(461), 25-30, 2012-02-24 \u53c2\u8003\u6587\u732e9\u4ef6 Tweet \u5404\u7a2e\u30b3\u30fc\u30c9 NII\u8ad6\u6587ID(NAID) 20000920030 \u8cc7\u6599\u7a2e\u5225 \u305d\u306e\u4ed6 \u30c7\u30fc\u30bf\u63d0\u4f9b\u5143 CJP\u5f15\u7528 \u66f8\u304d\u51fa\u3057 RefWorks\u306b\u66f8\u304d\u51fa\u3057 EndNote\u306b\u66f8\u304d\u51fa\u3057 Mendeley\u306b\u66f8\u304d\u51fa\u3057 Refer/BiblX\u3067 \u8868\u793a RIS\u3067\u8868\u793a BibTeX\u3067\u8868\u793a TSV\u3067\u8868\u793a \u554f\u984c\u306e\u6307\u6458 \u30da\u30fc\u30b8\u30c8\u30c3\u30d7\u3078 \u30b9\u30de\u30fc\u30c8\u30d5\u30a9\u30f3\u7248 | PC\u7248 \u2026", "num_citations": "22\n", "authors": ["1025"]}
{"title": "Reconstructing solutions after blocked clause elimination\n", "abstract": " Preprocessing has proven important in enabling efficient Boolean satisfiability (SAT) solving. For many real application scenarios of SAT it is important to be able to extract a full satisfying assignment for original SAT instances from a satisfying assignment for the instances after preprocessing. We show how such full solutions can be efficiently reconstructed from solutions to the conjunctive normal form (CNF) formulas resulting from applying a combination of various CNF preprocessing techniques implemented in the PrecoSAT solver\u2014especially, blocked clause elimination combined with SatElite-style variable elimination and equivalence reasoning.", "num_citations": "20\n", "authors": ["1025"]}
{"title": "A compact representation for syntactic dependencies in QBFs\n", "abstract": " Different quantifier types in Quantified Boolean Formulae (QBF) introduce variable dependencies which have to be taken into consideration when deciding satisfiability of a QBF. In this work, we focus on dependencies based on syntactically connected variables. We generalize our previous ideas for efficiently representing dependency sets of universal variables to existential ones. We obtain a dependency graph which is applicable to arbitrary QBF solvers. The core part of our work is the formulation and correctness proof of a static and compact, tree-shaped connection relation over equivalence classes of existential variables. In practice, this relation is constructed once from a given QBF and allows to share connection information among all variables. We report on practical aspects and demonstrate the effectiveness of our approach in experiments on structured formulae from QBF competitions. Further, we\u00a0\u2026", "num_citations": "19\n", "authors": ["1025"]}
{"title": "Consistency checking of all different constraints over bit-vectors within a SAT solver\n", "abstract": " This paper shows how all different constraints (ADCs) over bit-vectors can be handled within a SAT solver. It also contains encouraging experimental results in applying this technique to encode simple path constraints in bounded model checking. Finally, we present a new compact encoding of equalities and inequalities over bit-vectors in CNF.", "num_citations": "19\n", "authors": ["1025"]}
{"title": "Propagation based local search for bit-precise reasoning\n", "abstract": " Many applications of computer-aided verification require bit-precise reasoning as provided by satisfiability modulo theories (SMT) solvers for the theory of quantifier-free fixed-size bit-vectors. The current state-of-the-art in solving bit-vector formulas in SMT relies on bit-blasting, where a given formula is eagerly translated into propositional logic (SAT) and handed to an underlying SAT solver. Bit-blasting is efficient in practice, but may not scale if the input size can not be reduced sufficiently during preprocessing. A recent score-based local search approach lifts stochastic local search from the bit-level (SAT) to the word-level (SMT) without bit-blasting and proved to be quite effective on hard satisfiable instances, particularly in the context of symbolic execution. However, it still relies on brute-force randomization and restarts to achieve completeness. Guided by a completeness proof, we simplified, extended and\u00a0\u2026", "num_citations": "18\n", "authors": ["1025"]}
{"title": "Backing backtracking\n", "abstract": " Non-chronological backtracking was considered an important and necessary feature of conflict-driven clause learning\u00a0(CDCL). However, a SAT\u00a0solver combining CDCL with chronological backtracking succeeded in the main track of the SAT Competition\u00a02018. In that solver, multiple invariants considered crucial for\u00a0CDCL were violated. In particular, decision levels of literals on the trail were not necessarily increasing anymore. The corresponding paper presented at SAT 2018 described the algorithm and provided empirical evidence of its correctness, but a formalization and proofs were missing. Our contribution is to fill this gap. We further generalize the approach, discuss implementation details, and empirically confirm its effectiveness in an independent implementation.", "num_citations": "17\n", "authors": ["1025"]}
{"title": "Collection of combinational arithmetic miters submitted to the SAT Competition 2016\n", "abstract": " In this short note we present a collection of benchmarks submitted to the SAT Competition 2016. Most of them stem from other sources, some crafted ones are new, but all present equivalence checking problems (miters) for arithmetic circuits, such as multipliers.", "num_citations": "17\n", "authors": ["1025"]}
{"title": "Improving local search for bit-vector logics in SMT with path propagation\n", "abstract": " \u2022 State-of-the-art: Bit-Blasting\u25e6 eager reduction to propositional logic (SAT)\u2212\u2192 offline SAT solver integration\u25e6 efficient in practice\u25e6 relies heavily on rewriting and other simplification techniques\u2212\u2192 does not scale if input size can not be reduced sufficiently", "num_citations": "17\n", "authors": ["1025"]}
{"title": "Improving implementation of SLS solvers for SAT and new heuristics for k-SAT with long clauses\n", "abstract": " Stochastic Local Search (SLS) solvers are considered one of the best solving technique for randomly generated problems and more recently also have shown great promise for several types of hard combinatorial problems. Within this work, we provide a thorough analysis of different implementation variants of SLS solvers on random and on hard combinatorial problems. By analyzing existing SLS implementations, we are able to discover new improvements inspired by CDCL solvers, which can speed up the search of all types of SLS solvers. Further, our analysis reveals that the multilevel break values of variables can be easily computed and used within the decision heuristic. By augmenting the probSAT solver with the new heuristic, we are able to reach new state-of-the-art performance on several types of SAT problems, especially on those with long clauses. We further provide a detailed analysis of the\u00a0\u2026", "num_citations": "17\n", "authors": ["1025"]}
{"title": "More on the complexity of quantifier-free fixed-size bit-vector logics with binary encoding\n", "abstract": " Bit-precise reasoning is important for many practical applications of Satisfiability Modulo Theories (SMT). In recent years, efficient approaches for solving fixed-size bit-vector formulas have been developed. From the theoretical point of view, only few results on the complexity of fixed-size bit-vector logics have been published. Most of these results only hold if unary encoding on the bit-width of bit-vectors is used.               In previous work\u00a0[1], we showed that binary encoding adds more expressiveness to bit-vector logics, e.g.\u00a0it makes fixed-size bit-vector logic without uninterpreted functions nor quantification $\\hbox{\\sc NExpTime}$-complete.               In this paper, we look at the quantifier-free case again and propose two new results. While it is enough to consider logics with bitwise operations, equality, and shift by constant to derive $\\hbox{\\sc NExpTime}$-completeness, we show that the logic becomes $\\hbox\u00a0\u2026", "num_citations": "17\n", "authors": ["1025"]}
{"title": "Digitaltechnik-eine praxisnahe Einf\u00fchrung\n", "abstract": " Dieses Einf\u00fchrungswerk in die Digitaltechnik wurde speziell f\u00fcr Bachelorstudenten entwickelt. Es enth\u00e4lt viele auf den Anf\u00e4nger zugeschnittene praktische Anwendungen. Folgende Aspekte sind einmalig: Tool-orientierter Ansatz-Verwendung der Hardwarebeschreibungssprache Verilog-Einf\u00fchrung in systematische Methoden zur Fehlersuche-Geringe Anforderungen an die mathematischen Vorkenntnisse-Ein vereinfachter X86 IA32-Prozessor als Anwendungsbeispiel Die vorgestellten Beispiele werden mit Hilfe von Tools wie XILINX ISE und MentorGraphics ModelSim in echte Schaltungen umgesetzt. Diese Tools werden auch im industriellen Alltag eingesetzt. Im Internet werden weitere \u00dcbungen, realisierte Beispiele sowie Animationen angeboten. F\u00fcr Dozenten stehen Folien zum Abrufen bereit.", "num_citations": "17\n", "authors": ["1025"]}
{"title": "Picosat version 535\n", "abstract": " Our SAT solver PicoSAT is an attempt to optimize low-level performance of BooleForce, which shares many of its key features with MiniSAT version 1.14. In this short note we describe the features of PicoSAT version 535, which is the version that was submitted to the SAT 2007 SAT Solver Competition.", "num_citations": "17\n", "authors": ["1025"]}
{"title": "A comparison of strategies for tolerating inconsistencies during decision-making\n", "abstract": " Tolerating inconsistencies is well accepted in design modeling because it is often neither obvious how to fix an inconsistency nor important to do so right away. However, there are technical reasons why inconsistencies are not tolerated in many areas of software engineering. The most obvious being that common reasoning engines are rendered (partially) useless in the presence of inconsistencies. This paper investigates automated strategies for tolerating inconsistencies during decision-making in product line engineering, based on isolating parts from reasoning that cause inconsistencies. We compare trade offs concerning incorrect and incomplete reasoning and demonstrate that it is even possible to fully eliminate incorrect reasoning in the presence of inconsistencies at the expense of marginally less complete reasoning. Our evaluation is based on seven medium-to-large size software product line case studies\u00a0\u2026", "num_citations": "16\n", "authors": ["1025"]}
{"title": "Preprocessing and Inprocessing Techniques in SAT.\n", "abstract": " Preprocessing and Inprocessing Techniques in SAT Page 1 Preprocessing and Inprocessing Techniques in SAT Armin Biere Institute for Formal Models and Verification Johannes Kepler University Linz, Austria joint work with Marijn Heule and Matti Jarvisalo WorKer\u201911 3rd Workshop on Kernelization TU Vienna, Austria Friday, September 2, 2011 Page 2 Dress Code as Satisfiability Problem 1/48 \u2022 propositional logic: \u2013 variables tie shirt \u2013 negation \u00ac (not) \u2013 disjunction \u2228 disjunction (or) \u2013 conjunction \u2227 conjunction (and) \u2022 three conditions / clauses: \u2013 clearly one should not wear a tie without a shirt \u00actie\u2228shirt \u2013 not wearing a tie nor a shirt is impolite tie\u2228shirt \u2013 wearing a tie and a shirt is overkill \u00ac(tie\u2227shirt) \u2261 \u00actie\u2228\u00acshirt \u2022 is the formula (\u00actie\u2228shirt)\u2227(tie\u2228shirt)\u2227(\u00actie\u2228\u00acshirt) satisfiable? Preprocessing and Inprocessing Techniques in SAT Armin Biere \u2013 FMV \u2013 JKU Linz Page 3 0 200 400 600 800 1000 1200 0 20 40 60 \u2026", "num_citations": "16\n", "authors": ["1025"]}
{"title": "Precise and complete propagation based local search for satisfiability modulo theories\n", "abstract": " Satisfiability Modulo Theories (SMT) is essential for many applications in computer-aided verification. A recent SMT solving approach based on stochastic local search for the theory of quantifier-free fixed-size bit-vectors proved to be quite effective on hard satisfiable instances, particularly in the context of symbolic execution. However, it still relies on brute-force randomization and restarts to achieve completeness. In this paper we simplify, extend, and formalize the propagation-based variant of this approach. We introduce a notion of essential inputs to lift the well-known concept of controlling inputs from the bit-level to the word-level, which allows to prune search. Guided by a formal completeness proof for our propagation-based variant we obtain a clean, simple and more precise algorithm, which yields a substantial gain in performance, as shown in our experimental evaluation.", "num_citations": "15\n", "authors": ["1025"]}
{"title": "ddSMT: a delta debugger for the SMT-LIB v2 format\n", "abstract": " ddSMT: A Delta Debugger for the SMT-LIB v2 Format Page 1 ddSMT: A Delta Debugger for the SMT-LIB v2 Format Aina Niemetz and Armin Biere Institute for Formal Models and Verification (FMV) Johannes Kepler University, Linz, Austria http://fmv.jku.at/ SMT Workshop 2013 July 8 - 9, 2013 Helsinki, Finland Page 2 Motivation Why delta debugging? 1 (set-logic UFNIA) 2 (declare-sort sort1 0) 3 (declare-fun x () sort1) 4 (declare-fun y () sort1) 5 (assert (= xy )) 6 (push 1) 7 (define-sort sort2 () Bool) 8 (declare-fun x () sort2) 9 (declare-fun y () sort2) 10 (assert (and (as x Bool) (as y Bool))) 11 (assert (! (not (as x Bool)) :named z)) 12 (assert z) 13 (pop 1) 14 (assert (forall ((z Int)) (exists ((zz Int)) (= z zz)))) 15 (check-sat) 16 (get-value ((let ((x 1) (y 1)) (= xy)))) 17 (exit) 1 ( set \u2212 logic UFNIA ) 2 ( get\u2212value ( false )) 3 ( exit ) Page 3 Motivation Why delta debugging? 1 (set-logic UFNIA) 2 (declare-sort sort1 0) 3 (declare-fun x () sort1) \u2026", "num_citations": "15\n", "authors": ["1025"]}
{"title": "Verifying the IEEE 1394 firewire tree identify protocol with SMV\n", "abstract": " This case study contains a formal verification of the IEEE 1394 FireWire tree identify protocol. Crucial properties of finite models of the protocol have been validated with state-of-the-art symbolic model checkers. Various optimisation techniques were applied to verify concrete and generic configurations.", "num_citations": "15\n", "authors": ["1025"]}
{"title": "Turbo-charging Lemmas on demand with don't care reasoning\n", "abstract": " Lemmas on demand is an abstraction/refinement technique for procedures deciding Satisfiability Modulo Theories (SMT), which iteratively refines full candidate models of the formula abstraction until convergence. In this paper, we introduce a dual propagation-based technique for optimizing lemmas on demand by extracting partial candidate models via don't care reasoning on full candidate models. Further, we compare our approach to a justification-based approach similar to techniques employed in the context of model checking. We implemented both optimizations in our SMT solver Boolector and provide an extensive experimental evaluation, which shows that by enhancing lemmas on demand with don't care reasoning, the number of lemmas generated, and consequently the solver runtime, is reduced considerably.", "num_citations": "14\n", "authors": ["1025"]}
{"title": "Lemmas on demand for lambdas\n", "abstract": " We generalize the lemmas on demand decision procedure for array logic as implemented in Boolector to handle non-recursive and non-extensional lambda terms. We focus on the implementation aspects of our new approach and discuss the involved algorithms and optimizations in more detail. Further, we show how arrays, array operations and SMT-LIB v2 macros are represented as lambda terms and lazily handled with lemmas on demand. We provide experimental results that demonstrate the effect of native lambda support within an SMT solver and give an outlook on future work.", "num_citations": "14\n", "authors": ["1025"]}
{"title": "Incremental Column-wise verification of arithmetic circuits using computer algebra\n", "abstract": " Verifying arithmetic circuits and most prominently multiplier circuits is an important problem which in practice still requires substantial manual effort. The currently most effective approach uses polynomial reasoning over pseudo boolean polynomials. In this approach a word-level specification is reduced by a Gr\u00f6bner basis which is implied by the gate-level representation of the circuit. This reduction returns zero if and only if the circuit is correct. We give a rigorous formalization of this approach including soundness and completeness arguments. Furthermore we present a novel incremental column-wise technique to verify gate-level multipliers. This approach is further improved by extracting full- and half-adder constraints in the circuit which allows to rewrite and reduce the Gr\u00f6bner basis. We also present a new technical theorem which allows to rewrite local parts of the Gr\u00f6bner basis. Optimizing the Gr\u00f6bner\u00a0\u2026", "num_citations": "13\n", "authors": ["1025"]}
{"title": "Implicit hitting set algorithms for maximum satisfiability modulo theories\n", "abstract": " Solving optimization problems with SAT has a long tradition in the form of MaxSAT, which maximizes the weight of satisfied clauses in a propositional formula. The extension to maximum satisfiability modulo theories (MaxSMT) is less mature but allows problems to be formulated in a higher-level language closer to actual applications. In this paper we describe a new approach for solving MaxSMT based on lifting one of the currently most successful approaches for MaxSAT, the implicit hitting set approach, from the propositional level to SMT. We also provide a unifying view of how optimization, propositional reasoning, and theory reasoning can be combined in a MaxSMT solver. This leads to a generic framework that can be instantiated in different ways, subsuming existing work and supporting new approaches. Experiments with two instantiations clearly show the benefit of our generic framework.", "num_citations": "13\n", "authors": ["1025"]}
{"title": "Experimenting with SAT solvers in Vampire\n", "abstract": " Recently, a new reasoning framework, called AVATAR, integrating first-order theorem proving with SAT solving has been proposed. In this paper, we experimentally analyze the behavior of various SAT solvers within first-order proving. For doing so, we first integrate the Lingeling SAT solver within the first-order theorem prover Vampire and compare the behavior of such an integration with Vampire using a less efficient SAT solver. Interestingly, our experiments on first-order problems show that using the best SAT solvers within AVATAR does not always give best performance. There are some problems that could be solved only by using a less efficient SAT solver than Lingeling. However, the integration of Lingeling with Vampire turned out to be the best when it came to solving most of the hard problems.", "num_citations": "12\n", "authors": ["1025"]}
{"title": "Efficiently solving bit-vector problems using model checkers\n", "abstract": " STP Boolector MathSAT5 Z3 IImc-BDD-bw NuSMV-bw IImc-BDD-fw IImc NuSMV Blimc Tip-BMC Aigbmc Tip solved 147 146 127 123 192 189 185 172 170 147 130 99 93 sat 23 32 13 23 32 29 32 32 27 9 31 21 17 unsat 124 114 114 100 160 160 153 140 143 138 99 78 76 time 206 190 310 171 12 30 79 132 148 233 266 295 496 space 1063 805 587 2180 8 24 9 74 38 95 1142 2073 6", "num_citations": "12\n", "authors": ["1025"]}
{"title": "Lazy hyper binary resolution\n", "abstract": " \u2022 learn binary clauses lazily or on-the-fly\u2013in BCP\u2013during preprocessing with failed literal probing\u2013or during search\u2022 whenever a large clause (a1\u2228\u00b7\u00b7\u00b7\u2228 am\u2228 c) with m\u2265 2 becomes a reason for c\u2013for the partial assignment \u03c3 we have \u03c3 (ai)= 0 and \u03c3 (c)= 1\u2013check whether there is a literal d which dominates all ai\u2013in the implication graph restricted to binary clauses\u2022 learn (d\u2228 c) if such a dominator exists", "num_citations": "12\n", "authors": ["1025"]}
{"title": "C32sat: Checking c expressions\n", "abstract": " C32SAT is a tool for checking C expressions. It can check whether a given C expression can be satisfied, is tautological, or always defined according to the ISO C99 standard. C32SAT can be used to detect nonportable expressions where program behavior depends on the compiler. Our contribution consists of C32SAT\u2019s functional representation and the way it handles undefined values. Under-approximation is used as optimization.", "num_citations": "12\n", "authors": ["1025"]}
{"title": "Tutorial on model checking: Modelling and verification in computer science\n", "abstract": " This paper serves as background material for an invited tutorial on model checking given at the Third International Conference on Algebraic Biology (AB 2008). The intended audience of the tutorial were researchers in natural science, particularly life science, but this paper may also serve as a light-weight introduction into model checking techniques in general.", "num_citations": "11\n", "authors": ["1025"]}
{"title": "A practical polynomial calculus for arithmetic circuit verification\n", "abstract": " A Practical Polynomial Calculus for Arithmetic Circuit Verification Page 1 A PRACTICAL POLYNOMIAL CALCULUS FOR ARITHMETIC CIRCUIT VERIFICATION Daniela Ritirc, Armin Biere and Manuel Kauers Johannes Kepler University Linz, Austria SC-Square Workshop 2018 July 11, 2018 Oxford, United Kingdom Page 2 Motivation Multiplier a1b1 a0b1 a1b0 a0b0 g1 g2 g3 g4 s0 s1 s2 s3 Polynomials B = { x \u2212 a0 \u2217 b0, y \u2212 a1 \u2217 b1, s0 \u2212 x \u2217 y, ... } Verification = 0 = 0 Specification 2n\u22121 \u2211 i=0 2isi\u2212 ( n\u22121 \u2211 i=0 2iai)( n\u22121 \u2211 i=0 2ibi) Correct? Problem: Verification might not be error free Goal: Validate result of verification process \u25a0 Generate machine-checkable proofs \u25a0 Check by independent proof checkers Contribution: \u25a0 Proof format based on polynomial calculus \u25a0 Independent proof checker \u25a0 Validate previous verification results Page 3 Related Work \u25a0 Reasoning with polynomial equations \u25a1 D. Kapur. Using \u2026", "num_citations": "10\n", "authors": ["1025"]}
{"title": "On the complexity of symbolic verification and decision problems in bit-vector logic\n", "abstract": " We study the complexity of decision problems encoded in bit-vector logic. This class of problems includes word-level model checking, i.e., the reachability problem for transition systems encoded by bit-vector formulas. Our main result is a generic theorem which determines the complexity of a bit-vector encoded problem from the complexity of the problem in explicit encoding. In particular, NL-completeness of graph reachability directly implies PSpace-completeness and ExpSpace-completeness for word-level model checking with unary and binary arity encoding, respectively. In general, problems complete for a complexity class C are shown to be complete for an exponentially harder complexity class than C when represented by bit-vector formulas with unary encoded scalars, and further complete for a double exponentially harder complexity class than C with binary encoded scalars. We also show that multi\u00a0\u2026", "num_citations": "10\n", "authors": ["1025"]}
{"title": "Efficiently representing existential dependency sets for expansion-based QBF solvers\n", "abstract": " Given a quantified boolean formula (QBF) in prenex conjunctive normal form (PCNF), we consider the problem of identifying variable dependencies. In related work, a formal definition of dependencies has been suggested based on quantifier prefix reordering: two variables are independent if swapping them in the prefix does not change satisfiability of the formula. Instead of the general case, we focus on the sets of depending existential variables for all universal variables. This is relevant particularly for expansion-based QBF solvers. We present an approach for efficiently computing existential dependency sets by means of a directed connection relation over variables and demonstrate how this relation can be compactly represented as a tree using a union-find data structure. Experimental results show the effectiveness of our approach.", "num_citations": "10\n", "authors": ["1025"]}
{"title": "SDL versus C equivalence checking\n", "abstract": " We present a tool that automatically checks the existence of a bisimulation relation between an SDL specification and the corresponding auto-generated C code. The tool has been used to verify part of the C implementation of a WiFi Medium Access Controller (IEEE 802.11) that has been derived from its original SDL specification using the Telelogic CAdvanced Code Generator.", "num_citations": "10\n", "authors": ["1025"]}
{"title": "Dualizing projected model counting\n", "abstract": " In many recent applications of model counting not all variables are relevant for a specific problem. For instance redundant variables are added during formula transformation. In projected model counting these redundant variables are ignored by projecting models onto relevant variables. Inspired by dual propagation which has its origin in solving quantified Boolean formulae and jointly works on both the original formula and its negation, we present a novel calculus for dual projected model counting. It allows to capture existing techniques such as blocking clauses, chronological as well as non-chronological backtracking, but also introduces new concepts including discounting and dual conflict analysis to obtain partial models. Experiments demonstrate the benefit of our approach.", "num_citations": "8\n", "authors": ["1025"]}
{"title": "bv2epr: A Tool for Polynomially Translating Quantifier-Free Bit-Vector Formulas into EPR\n", "abstract": " Bit-precise reasoning is essential in many applications of Satisfiability Modulo Theories (SMT). In recent years, efficient approaches for solving fixed-size bit-vector formulas have been developed. Most of these approaches rely on bit-blasting. In [1], we argued that bit-blasting is not polynomial in general, and then showed that solving quantifier-free bit-vector formulas (QF_BV) is NExpTime-complete. In this paper, we present a tool based on a new polynomial translation from QF_BV into Effectively Propositional Logic (EPR). This allows us to solve QF_BV problems using EPR solvers and avoids the exponential growth that comes with bit-blasting. Additionally, our tool allows us to easily generate new challenging benchmarks for EPR solvers.", "num_citations": "8\n", "authors": ["1025"]}
{"title": "SAT, computer algebra, multipliers\n", "abstract": " Verifying multiplier circuits is an important problem which in practice still requires substantial manual effort. The currently most effective approach uses polynomial reasoning. However parts of a multiplier, ie, complex final stage adders are hard to verify using computer algebra. In our approach we combine SAT and computer algebra to substantially improve automated verification of integer multipliers. In this paper we focus on the implementation details of our new dedicated reduction engine, which not only allows fully automated adder substitution, but also employs polynomial reduction efficiently. Our tool is furthermore able to generate proof certificates in the practical algebraic calculus and we also investigate the size of these proofs for one specific multiplier architecture.", "num_citations": "7\n", "authors": ["1025"]}
{"title": "Lingeling and friends entering the SAT Race 2015\n", "abstract": " This is a solver description for our SAT solvers Lingeling, Treengeling and Plingeling entering the SAT Race 2015. We only focus on the difference to their 2014 versions. For further information we refer to previous solver descriptions [1],[2],[3], our POS\u201914 talk [4] and of course the source code.", "num_citations": "7\n", "authors": ["1025"]}
{"title": "Theory and Practice of SAT Solving (Dagstuhl Seminar 15171)\n", "abstract": " This report documents the program and the outcomes of Dagstuhl Seminar 15171\" Theory and Practice of SAT Solving\". The purpose of this workshop was to explore one of the most significant problems in all of computer science, namely that of computing whether formulas in propositional logic are satisfiable or not. This problem is believed to be intractable in general (by the theory of NP-completeness). However, the last two decades have seen dramatic developments in algorithmic techniques, and today so-called SAT solvers are routinely and successfully used to solve large-scale real-world instances in a wide range of application areas. A surprising aspect of this development is that the best current SAT solvers are still to a large extent based on methods from the early 1960s, which can often handle formulas with millions of variables but may also get hopelessly stuck on formulas with just a few hundred variables. The fundamental question of when SAT solvers perform well or badly, and what underlying mathematical properties of the formulas influence SAT solver performance, remains very poorly understood. Another intriguing aspect is that much stronger mathematical methods of reasoning about propositional logic formulas are known today, in particular methods based on algebra and geometry, and these methods would seem to have great potential based on theoretical studies. However, attempts at harnessing the power of such methods have conspicuously failed to deliver any significant improvements in practical performance. This workshop gathered leading researchers in applied and theoretical areas of SAT and computational\u00a0\u2026", "num_citations": "7\n", "authors": ["1025"]}
{"title": "Combining local and global model checking\n", "abstract": " The verification process of reactive systems in local model checking [1,7] and in explicit state model checking is[13,15] on-the-fly. Therefore only those states of a system have to be traversed that are necessary to prove a property. In addition, if the property does not hold, than often only a small subset of the state space has to be traversed to produce a counterexample. Global model checking [6,23] and, in particular, symbolic model checking [4,22] can utilize compact representations of the state space, e.g. BDDs [3], to handle much larger designs than what is possible with local and explicit model checking. We present a new model checking algorithm for LTL that combines both approaches. In essence, it is a generalization of the tableau construction of [1] that enables the use of BDDs but still is on-the-fly.", "num_citations": "7\n", "authors": ["1025"]}
{"title": "Verifying sequential behavior with model checking\n", "abstract": " The design of state-of-the-art digital circuits often involves interacting state machines with very complex control flow. As consequence functional verification of sequential designs is becoming a major bottleneck in the design process. Model checking techniques, the topic of this tutorial, promise to speed up verification time by checking high level temporal properties. Model checking is best used in early design phases where it may help to catch fundamental design flaws and errors as early as possible.", "num_citations": "7\n", "authors": ["1025"]}
{"title": "A simple verification of the Tree Identify Protocol with SMV\n", "abstract": " 4 ResultsThe specification has been verified for a number of topologies with synchronous execution. Both deterministic and non-deterministic configurations are used. For each configuration, Table 4 lists the number of reachable states as calculated by SMV, the number of bytes allocated, and the user time. Most configurations are easily verified. The verification of the last configuration has been interrupted after 12 hours without results.", "num_citations": "7\n", "authors": ["1025"]}
{"title": "Two flavors of DRAT\n", "abstract": " DRAT proofs have become the de facto standard for certifying SAT solvers\u2019 results. State-of-the-art DRAT checkers are able to efficiently establish the unsatisfiability of a formula. However, DRAT checking requires unit propagation, and so it is computationally non-trivial. Due to design decisions in the development of early DRAT checkers, the class of proofs accepted by state-of-the-art DRAT checkers differs from the class of proofs accepted by the original definition. In this paper, we formalize the operational definition of DRAT proofs, and discuss practical implications of this difference for generating as well as checking DRAT proofs. We also show that these theoretical differences have the potential to affect whether some proofs generated in practice by SAT solvers are correct or not.", "num_citations": "6\n", "authors": ["1025"]}
{"title": "Deep bound hardware model checking instances, quadratic propagations benchmarks and reencoded factorization problems submitted to the SAT competition 2017\n", "abstract": " In this benchmark description we describe our three set of benchmarks submitted to the SAT Competition 2016. The first contains bounded model checking problems from the deep bound track of the hardware model checking competition. The second crafted set of benchmarks has the sole purpose to show that the standard watch list implementation has a quadratic corner case. As third set of benchmarks we submitted factoring problems of products of medium sized primes, which seem to be hard for standard SAT solvers, but become trivial if the solution is reencoded back into the CNF by flipping literals appropriately.", "num_citations": "6\n", "authors": ["1025"]}
{"title": "Two pigeons per hole problem\n", "abstract": " In the newest version of our SAT solver Lingeling we included a simple algorithm for solving large trivially encoded pigeon hole problems. The algorithm is based on cardinality reasoning. More information about the algorithm can be found in our solver description [1]. One phase of the algorithm consists of extracting at-mostone constraints, which we extended to extract at-most-two constraints too. This extension allowed us to solve the following simple extension of the pigeon hole problem. Given h holes, we ask whether it possible to fit n= 2\u00b7 h+ 1 pigeons into these holes, where each hole can fit at most two pigeons. We submitted a C program gentph. c as benchmark generator, which takes the number of holes as one argument. For each hole there is an at-most-two constraint over n pigeons, which is encoded with (n3)= n\u00b7(n\u2212 1)\u00b7(n\u2212 2)/6 clauses of length 3. In addition, for each pigeon there is a clause of length n requiring that the pigeon is at least in one hole. For h= 6 holes the problem becomes difficult for standard CDCL solvers. Glucose 2.1 needs 420 seconds, while Lingeling 587f needs 970 seconds, both on an Intel i7-3930K CPU running at 3.20 GHz. Lingeling as submitted to this year\u2019s competition, but without cardinality reasoning needs 291 seconds. More holes seem to be out of reach. With cardinality constraint reasoning this problem is trivial and can be solved for up to 20 holes instantly. We list the sizes of these new benchmarks in Table I. Compared to the well-known original pigeon hole benchmarks, with sizes listed in Table II, we observed that the benchmarks become more difficult for a smaller number of variables. REFERENCES\u00a0\u2026", "num_citations": "6\n", "authors": ["1025"]}
{"title": "A history of Satisfiability\n", "abstract": " Interest in Satisfiability is expanding for a variety of reasons, not in the least because nowadays more problems are being solved faster by SAT solvers than other means. This is probably because Satisfiability stands at the crossroads of logic, graph theory, computer science, computer engineering, and operations research. Thus, many problems originating in one of these fields typically have multiple translations to Satisfiability and there exist many mathematical tools available to the SAT solver to assist in solving them with improved performance. Because of the strong links to so many fields, especially logic, the history of Satisfiability can best be understood as it unfolds with respect to its logic roots. Thus, in addition to time-lining events specific to Satisfiability, the chapter follows the presence of Satisfiability in logic as it was developed to model human thought and scientific reasoning through its use in computer design and now as modeling tool for solving a variety of practical problems. In order to succeed in this, we must introduce many ideas that have arisen during numerous attempts to reason with logic and this requires some terminology and perspective that has developed over the past two millennia. It is the purpose of this preface to prepare the reader with this information so as to make the remainder of the chapter more understandable and enlightening.Logic is about validity and consistency. The two ideas are interdefinable if we make use of negation (\u00ac): the argument from p1,..., pn to q is valid if and only if the set {p1,..., pn,\u00ac q} is inconsistent. Thus, validity and consistency are really two ways of looking at the same thing and each may be\u00a0\u2026", "num_citations": "6\n", "authors": ["1025"]}
{"title": "Challenges in verifying arithmetic circuits using computer algebra\n", "abstract": " Verifying arithmetic circuits is an important problem which still requires considerable manual effort. For instance multipliers are considered difficult to verify. The currently most effective approach for arithmetic circuit verification uses computer algebra. In this approach the circuit is modeled as a set of pseudo-boolean polynomials and it is checked if the given word-level specification is implied by the circuit polynomials. For this purpose the theory of Gr\u00f6bner bases is used. In this paper we give a summary of two recent papers on this work. We reword the theory and illustrate the results of these papers by examples. We also present a new technical theorem which allows to rewrite local parts of the Gr\u00f6bner basis. Rewriting the Gr\u00f6bner basis has tremendous effect on computation time.", "num_citations": "5\n", "authors": ["1025"]}
{"title": "Boolector at the SMT Competition 2016\n", "abstract": " This paper serves as solver description for our SMT solver Boolector, entering the SMT Competition 2016 in two different configurations. We only list important differences to earlier version of Boolector in the SMT Competition 2015.", "num_citations": "5\n", "authors": ["1025"]}
{"title": "Better lemmas with lambda extraction\n", "abstract": " In Satisfiability Modulo Theories (SMT), the theory of arrays provides operations to access and modify an array at a given index, e.g., read and write. However, common operations to modify multiple indices at once, e.g., memset or memcpy of the standard C library, are not supported. We describe algorithms to identify and extract array patterns representing such operations, including memset and memcpy.We represent these patterns in our SMT solver Boolector by means of compact and succinct lambda terms, which yields better lemmas and increases overall performance. We describe how extraction and merging of lambda terms affects lemma generation, and provide an extensive experimental evaluation of the presented techniques. It shows a considerable improvement in terms of solver performance, particularly on instances from symbolic execution.", "num_citations": "5\n", "authors": ["1025"]}
{"title": "SAT Solving with GPU Accelerated Inprocessing.\n", "abstract": " Since 2013, the leading SAT solvers in the SAT competition all use inprocessing, which unlike preprocessing, interleaves search with simplifications. However, applying inprocessing frequently can still be a bottle neck, ie, for hard or large formulas. In this work, we introduce the first attempt to parallelize inprocessing on GPU architectures. As memory is a scarce resource in GPUs, we present new space-efficient data structures and devise a data-parallel garbage collector. It runs in parallel on the GPU to reduce memory consumption and improves memory access locality. Our new parallel variable elimination algorithm is twice as fast as previous work. In experiments our new solver PARAFROST solves many benchmarks faster on the GPU than its sequential counterparts.", "num_citations": "4\n", "authors": ["1025"]}
{"title": "Preprocessing in SAT solving\n", "abstract": " Preprocessing has become a key component of the Boolean satisfiability (SAT) solving workflow. In practice, preprocessing is situated between the encoding phase and the solving phase, with the aim of decreasing the total solving time by applying efficient simplification techniques on SAT instances to speed up the search subsequently performed by a SAT solver. In this chapter, we overview key preprocessing techniques proposed in the literature. While the main focus is on techniques applicable to formulas in conjunctive normal form (CNF), we also selectively cover main ideas for preprocessing structural and higher-level SAT instance representations.", "num_citations": "4\n", "authors": ["1025"]}
{"title": "Distributed cube and conquer with Paracooba\n", "abstract": " Cube and conquer is currently the most effective approach to solve hard combinatorial problems in parallel. It organizes the search in two phases. First, a look-ahead solver splits the problem into many sub-problems, called cubes, which are then solved in parallel by incremental CDCL solvers. In this tool paper we present the first fully integrated and automatic distributed cube-and-conquer solver Paracooba targeting cluster and cloud computing. Previous work was limited to multi-core parallelism or relied on manual orchestration of the solving process. Our approach uses one master per problem to initialize the solving process and automatically discovers and releases compute nodes through elastic resource usage. Multiple problems can be solved in parallel on shared compute nodes, controlled by a custom peer-to-peer based load-balancing protocol. Experiments show the scalability of our approach.", "num_citations": "4\n", "authors": ["1025"]}
{"title": "From DRUP to PAC and back\n", "abstract": " Currently the most efficient automatic approach to verify gate-level multipliers combines SAT solving and computer algebra. In order to increase confidence in the verification, proof certificates are generated. However, due to different solving techniques, these certificates require two different proof formats, namely DRUP and PAC. A combined proof has so far been missing. Correctness of this approach can thus only be trusted up to the correctness of compositional reasoning. In this paper we show how to generate a single proof in one proof format, which then allows to certify correctness using one simple proof checker. We further investigate empirically the effect on proof generation and checking time as well as on proof size. It turns out that PAC proofs are much more compact and faster to check.", "num_citations": "4\n", "authors": ["1025"]}
{"title": "Combining Conflict-Driven Clause Learning and Chronological Backtracking for Propositional Model Counting.\n", "abstract": " In propositional model counting, also named# SAT, the search space needs to be explored exhaustively, in contrast to SAT, where the task is to determine whether a propositional formula is satisfiable. While state-of-the-art SAT solvers are based on nonchronological backtracking, it has also been shown that backtracking chronologically does not significantly degrade solver performance. Hence investigating the combination of chronological backtracking with conflict-driven clause learning (CDCL) for# SAT seems evident. We present a calculus for# SAT combining chronological backtracking with CDCL and provide a formal proof of its correctness.", "num_citations": "4\n", "authors": ["1025"]}
{"title": "An Abstract Dual Propositional Model Counter.\n", "abstract": " Various real-world problems can be formulated as the task of counting the models of a propositional formula. This problem, also called# SAT, is therefore of practical relevance. We present a formal framework describing a novel approach based on considering the formula in question together with its negation. This method enables us to close search branches earlier. We formalize a non-dual variant and argue that our framework is sound.", "num_citations": "4\n", "authors": ["1025"]}
{"title": "Weaknesses of CDCL solvers\n", "abstract": " Summary Variable Scoring Schemes Evaluating CDCL Variable Scoring Schemes 10/45 s old score s new score variable score s after i conflicts bumped not-bumped", "num_citations": "4\n", "authors": ["1025"]}
{"title": "SmacC: A Retargetable Symbolic Execution Engine\n", "abstract": " SmacC is a symbolic execution engine for C programs. It can be used for program verification, bounded model checking and generating SMT benchmarks. More recently we also successfully applied SmacC for high-level timing analysis of programs to infer exact loop bounds and safe over-approximations. SmacC uses the logic for bit-vectors with arrays to construct a bit-precise memory-model of a program for path-wise exploration.", "num_citations": "4\n", "authors": ["1025"]}
{"title": "Theory and Applications of Satisfiability Testing-SAT 2006: 9th International Conference, Seattle, WA, USA, August 12-15, 2006, Proceedings\n", "abstract": " This volume contains the papers presented at the 9th International Conference on Theory and Applications of Satisfiability Testing (SAT 2006). The International Conference on Theory and Applications of Satisfiability Testing is the primary annual meeting for researchers studying the propositional satisfiability problem (SAT). SAT 2006 was part of FLoC 2006, the fourth Federated Logic Conference, which hosted, in addition to SAT, LICS, RTA, CAV, ICLP and IJCAR. SAT 2005 was held in St. Andrews, Scotland, and SAT 2004 in Vancouver, BC, Canada. This time SAT featured the SAT Race in spirit of the SAT Competitions, the first competitive QBF Evaluation, an Evaluation of Pseudo-Boolean Solvers and the Workshop on Satisfiability Solvers and Program Verification (SSPV).Many hard combinatorial problems can be formulated as Boolean Satisfiability (SAT) problems. In fact, given the tremendous advances in\u00a0\u2026", "num_citations": "4\n", "authors": ["1025"]}
{"title": "A case study on different modelling approaches based on model checking: verifying numerous versions of the alternating bit protocol with SMV\n", "abstract": " Recently, outstanding results have been achieved in the formal verication of concurrent systems by model checking techniques. In this paper we report our experience with SMV, a symbolic model veri er, applied to a communication protocol, the alternating bit protocol. We investigated di erent approaches of modeling the alternating bit protocol in SMV. We describe the problems encountered because of the restrictions of SMV. As a consequence, we call for a more general language for model checking, which both overcomes these disadvantages of SMV and enhances the possibility of optimizations, and more speci c input languages on top of it, easing the application of model checking for the end user.", "num_citations": "4\n", "authors": ["1025"]}
{"title": "AMulet 2.0 for Verifying Multiplier Circuits.\n", "abstract": " AMulet 2.0 for Verifying Multiplier Circuits [2ex] Page 1 AMULET 2.0 FOR VERIFYING MULTIPLIER CIRCUITS Daniela Kaufmann and Armin Biere daniela.kaufmann@jku.at Johannes Kepler University Linz, Austria TACAS 2021 online March 31, 2021 Page 2 Bugs in hardware are expensive! Circuit verification prevents issues like the famous Pentium FDIV bug. Multiplier verification Given: Gate-level integer multiplier for fixed bit-width. Input format: AND-Inverter Graph Question: For all possible ai, bi \u2208 B : (2a1 + a0) \u2217 (2b1 + b0) = 8s3 + 4s2 + 2s1 + s0? 2 a[0] 4 b[0] 6 a[1] 8 b[1] 10 12 14 16 18 20 22 24 26 28 s[0] s[1] s[2] s[3] 1 Page 3 Formal Verification Techniques Satisfiability Checking (SAT) \u25a0 SAT 2016 Competition [Bie16] \u25a0 Exponential run-time of solvers Theorem Proving \u25a0 Used in industry \u25a0 Past: Requires manual effort \u25a0 2020: Progress in ACL2 [TSH20] Decision Diagrams \u25a0 First technique to detect \u2026", "num_citations": "3\n", "authors": ["1025"]}
{"title": "Hardware Model Checking Competition 2020\n", "abstract": " in\u2264 31 sort bitvec 1 2 sort bitvec 3 3 zero 2 4 state 2 cnt 5 init 2 4 3 6 input 2 in 7 add 2 4 6 8 next 2 4 7 9 constd 2 7 10 eq 1 4 9 11 bad 10 12 constd 2 3 13 ulte 1 6 12 14 constraint 13 sat b0# 0@ 0 0 011 in@ 0@ 10 010 in@ 1@ 20 010 in@ 2@ 30 000 in@ 3", "num_citations": "3\n", "authors": ["1025"]}
{"title": "Challenges in bit-precise reasoning\n", "abstract": " Summary form only given. Bit-precise reasoning (BPR) precisely captures the semantics of systems down to each individual bit and thus is essential to many verification and synthesis tasks for both hardware and software systems. As an instance of Satisfiabiliy Modulo Theories (SMT), BPR is in essence about word-level decision procedures for the theory of bit-vectors. In practice, quantiers and other theory extensions, such as reasoning about arrays, are important too. In the first part of the tutorial we gave a brief overview on basic techniques for bit-precise reasoning and then covered more recent theoretical results, including complexity classification results. We discussed challenges in developping an efficient SMT solver for bit-vectors, like our award winning SMT solver Boolector, and in particular presented examples, for which current techniques fail. Finally, we reviewed the state-of-the-art in word-level model\u00a0\u2026", "num_citations": "3\n", "authors": ["1025"]}
{"title": "Am\u00e9liorer SAT dans le cadre incr\u00e9mental.\n", "abstract": " Les avanc\u00e9es spectaculaires obtenues dans le cadre de la r\u00e9solution pratique du probl\u00e8me SAT ont rejailli bien au del\u00e0 de ses fronti\u00e8res. Ainsi, \u00e0 l\u2019heure actuelle, de nombreux probl\u00e8mes dont la classe de complexit\u00e9 est sup\u00e9rieure \u00e0 NP peuvent \u00eatre trait\u00e9s de mani\u00e8re pratique en se reposant directement ou indirectement sur l\u2019utilisation de solveurs SAT. Dans un grand nombre de cas, la r\u00e9solution de ces probl\u00e8mes consiste \u00e0 appeler un solveur SAT sur plusieurs instances analogues. Ce type de r\u00e9solution, appel\u00e9 r\u00e9solution incr\u00e9mentale de SAT, est en passe de devenir l\u2019\u00e9tat de l\u2019art dans bien des domaines. Il devient donc important de prendre en compte ce nouveau mode op\u00e9ratoire lors de la conception des nouveaux d\u00e9monstrateurs SAT. Dans cet article, nous proposons d\u2019am\u00e9liorer le d\u00e9monstrateur SAT Glucose afin d\u2019en faire un d\u00e9monstrateur incr\u00e9mental efficace dans ce cadre pr\u00e9cis. Pour cela, nous \u00e9tendons la notion de qualit\u00e9 de clauses apprises dans le cas de d\u00e9monstrateur incr\u00e9mental bas\u00e9 sur l\u2019utilisation intensive d\u2019hypoth\u00e8ses. Afin de valider exp\u00e9rimentalement notre contribution, nous avons \u00e9tudi\u00e9 ses performances sur une utilisation importante et typique des d\u00e9monstrateurs SAT incr\u00e9mentaux: la recherche de noyaux minimaux inconsistants. Nous pensons que ces am\u00e9liorations peuvent directement b\u00e9n\u00e9ficier \u00e0 la plupart des autres applications bas\u00e9es sur les d\u00e9monstrateurs SAT incr\u00e9mentaux.ABSTRACT. The spectacular progresses obtained in the practical solving of SAT problems had a number of important impacts beyond its own frontiers. For instance, a number of recent applications explicitly rely on a new use of\u00a0\u2026", "num_citations": "3\n", "authors": ["1025"]}
{"title": "Cube-and-Conquer approach for SAT solving on grids\n", "abstract": " Our goal is to develop techniques for using distributed computing resources to efficiently solve instances of the propositional satisfiability problem (SAT). We claim that computational grids provide a distributed computing environment suitable for SAT solving. In this paper we apply the Cube and Conquer approach to SAT solving on grids and present our parallel SAT solver CCGrid (Cube and Conquer on Grid) on computational grid infrastructure. Our solver consists of two major components. The master application runs march_cc, which applies a lookahead SAT solver, in order to partition the input SAT instance into work units distributed on the grid. The client application executes an iLingeling instance, which is a multi-threaded CDCL SAT solver. We use BOINC middleware, which is part of the SZTAKI Desktop Grid package and supports the Distributed Computing Application Programming Interface (DC-API). Our preliminary results suggest that our approach can gain significant speedup and shows a potential for future investigation and development.", "num_citations": "3\n", "authors": ["1025"]}
{"title": "Quantifier-free bit-vector formulas with binary encoding: Benchmark description\n", "abstract": " This document describes several sets of benchmarks corresponding to quantifier-free bit-vector formulas. A generation script first creates all benchmarks in SMT2 format and then uses Boolector to generate CNF instances in DIMACS format by bit-blasting.", "num_citations": "3\n", "authors": ["1025"]}
{"title": "Sat, smt and applications\n", "abstract": " SAT solving has gained tremendous interest. On the practical side there have been considerable performance improvements, due to new highly efficient algorithms, new heuristics, and optimized data structures. There are new applications and reformulations of important classical problems, mainly in the context of formal methods, where SAT solving is also applied successfully in an industrial setting. These applications range from equivalence checking, configuration, over model checking to test case generation. SAT is becoming one of the most important core technology in all these areas. Many applications actually use Satisfiability Modulo Theory (SMT), which can be seen as an extension of SAT solving. SMT has it roots in automated theorem proving. But it heavily relies on SAT technology. We discuss some key technologies in practical SAT solving, e.g.\u00a0how to write a fast solver, some aspects in lifting\u00a0\u2026", "num_citations": "3\n", "authors": ["1025"]}
{"title": "Boolector 0.4\n", "abstract": " Boolector 0.4 SMT-COMP\u201908, Tool Presentation Page 1 Boolector 0.4 Robert Brummayer and Armin Biere Institute for Formal Models and Verification Johannes Kepler University Linz, Austria SMT-COMP\u201908, Tool Presentation Princeton, New Jersey, USA July 8th, 2008 Page 2 Boole + Vector = Boolector R. Brummayer, FMV, JKU Linz 1/3 \u2022 SMT solver \u2022 Theories \u2013 QF BV \u2013 QF AUFBV \u2022 Model Checker for safety properties \u2013 Sequential and synchronous circuits with registers and memories \u2013 BTOR Page 3 Implementation and Algorithms (1/2) R. Brummayer, FMV, JKU Linz 2/3 \u2022 C \u2022 Term-level rewriting \u2013 Bounded rewriting \u2013 Substitution of variables \u2013 Substitution of slices on bit-vector variables \u2013 Normalization of bvadd and bvmul on demand \u2013 Local two level rewriting \u2013 Linear equation solver Page 4 Implementation and Algorithms (2/2) R. Brummayer, FMV, JKU Linz 3/3 \u2022 And-Inverter Graph Synthesis \u2013 Each \u2026", "num_citations": "3\n", "authors": ["1025"]}
{"title": "Nullstellensatz-proofs for multiplier verification\n", "abstract": " Automated reasoning techniques based on computer algebra are an essential ingredient in formal verification of gate-level multiplier circuits. Generating and independently checking proof certificates helps to validate the verification results. Two algebraic proof systems, Nullstellensatz and polynomial calculus, are well-known in proof complexity. The practical application of the polynomial calculus has been studied recently. However, producing and checking Nullstellensatz certificates for multiplier verification has not been considered so far. In this paper we show how Nullstellensatz proofs can be generated as a by-product of multiplier verification and present our Nullstellensatz proof checker Nuss-Checker. Additionally, we prove quadratic upper bounds on the proof size for simple array multipliers.", "num_citations": "2\n", "authors": ["1025"]}
{"title": "Covered clauses are not propagation redundant\n", "abstract": " Propositional proof systems based on recently-developed redundancy properties admit short refutations for many formulas traditionally considered hard. Redundancy properties are also used by procedures which simplify formulas in conjunctive normal form by removing redundant clauses. Revisiting the covered clause elimination procedure, we prove the correctness of an explicit algorithm for identifying covered clauses, as it has previously only been implicitly described. While other elimination procedures produce redundancy witnesses for compactly reconstructing solutions to the original formula, we prove that witnesses for covered clauses are hard to compute. Further, we show that not all covered clauses are propagation redundant, the most general, polynomially-verifiable standard redundancy property. Finally, we close a gap in the literature by demonstrating the complexity of clause redundancy itself.", "num_citations": "2\n", "authors": ["1025"]}
{"title": "Chasing target phases\n", "abstract": " We discuss and evaluate the idea of target phases introduced first in CaDiCaL in 2019 and also ported to our latest SAT solver Kissat. Target phases provide a heuristic to choose the value assigned to decision variables. This technique is an extension of phase saving. It extends promising assignments derived by the solver towards full models. Combined with alternatively applying series of Glucose-style and Luby-style restarts, the technique is particularly effective on satisfiable instances.", "num_citations": "2\n", "authors": ["1025"]}
{"title": "Duplex encoding of staircase at-most-one constraints for the antibandwidth problem\n", "abstract": " Decision and optimization problems can be tackled with different techniques, such as Mixed Integer Programming, Constraint Programming or SAT solving. An important ingredient in the success of each of these approaches is the exploitation of common constraint structures with specialized (re-)formulations, encodings or other techniques. In this paper we present a new linear SAT encoding using binary decision diagrams over multiple variable orders as intermediate representation of a special form of constraints denoted as staircase at-most-one-constraints. The use of these constraints is motivated by recent work on the antibandwidth problem, where an iterative solution procedure using feasibility-mixed integer programs based on such constraints was most effective. In a computational study we compare the effectiveness of our new encoding against traditional SAT-encodings for staircase at-most-one\u00a0\u2026", "num_citations": "1\n", "authors": ["1025"]}
{"title": "Tools and Algorithms for the Construction and Analysis of Systems: 26th International Conference, TACAS 2020, Held as Part of the European Joint Conferences on Theory and\u00a0\u2026\n", "abstract": " This open access two-volume set constitutes the proceedings of the 26th International Conference on Tools and Algorithms for the Construction and Analysis of Systems, TACAS 2020, which took place in Dublin, Ireland, in April 2020, and was held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2020. The total of 60 regular papers presented in these volumes was carefully reviewed and selected from 155 submissions. The papers are organized in topical sections as follows: Part I: Program verification; SAT and SMT; Timed and Dynamical Systems; Verifying Concurrent Systems; Probabilistic Systems; Model Checking and Reachability; and Timed and Probabilistic Systems. Part II: Bisimulation; Verification and Efficiency; Logic and Proof; Tools and Case Studies; Games and Automata; and SV-COMP 2020.", "num_citations": "1\n", "authors": ["1025"]}
{"title": "Certifying Hardware Model Checking Results\n", "abstract": " Model checking is used widely as a formal verification technique for safety-critical systems. Certifying the correctness of model checking results helps increasing confidence in the verification procedure. This can be achieved by additional book-keeping inside existing model checkers. Based on this, we extended an existing BDD-based model checker as well as an IC3-based incremental inductive model checker, to generate certificates during the model checking procedure. We also introduce a proof checker which provides a standardised way to validate certificates generated from model checkers in conjunction with a SAT solver. The main goal is to establish a certification process for the hardware model checking competition.", "num_citations": "1\n", "authors": ["1025"]}
{"title": "Package \u2018BoolNet\u2019\n", "abstract": " Synchronous Boolean networks These networks consist of a set of Boolean variables (genes) X and a set of transition functions, one for each variable. These transition functions map an input from the set X to a Boolean value. A state is a vector of values for each of the variables in X. Then, the next state of the network is calculated by applying all transition functions to the state.Asynchronous Boolean networks Asynchronous networks have the same structure as synchronous Boolean networks. Yet, the next state of the network is calculating by choosing only one of the transition functions at random and updating the corresponding Boolean variable (gene). This corresponds to the assumption that in a genetic network, gene expression levels are likely to change at different points of time.", "num_citations": "1\n", "authors": ["1025"]}
{"title": "Revisiting Decision Diagrams for SAT\n", "abstract": " Symbolic variants of clause distribution using decision diagrams to eliminate variables in SAT were shown to perform well on hard combinatorial instances. In this paper we revisit both existing ZDD and BDD variants of this approach. We further investigate different heuristics for selecting the next variable to eliminate. Our implementation makes further use of parallel features of the open source BDD library Sylvan.", "num_citations": "1\n", "authors": ["1025"]}
{"title": "Hardware and Software: Verification and Testing: 8th International Haifa Verification Conference, HVC 2012, Haifa, Israel, November 6-8, 2012. Revised Selected Papers\n", "abstract": " This book constitutes the thoroughly refereed proceedings of the 8th International Haifa Verification Conference, HVC 2012, held in Haifa, Israel in November 2012. The 18 revised full papers presented together with 3 poster presentations were carefully reviewed and selected from 36 submissions. They focus on the future directions of testing and verification for hardware, software, and complex hybrid systems.", "num_citations": "1\n", "authors": ["1025"]}
{"title": "Boolector Entering the SMT Competition 2012\n", "abstract": " extended by Armin Biere. Boolector supports the SMT-Lib input format version 1 and 2 for the logics QF BV and QF ABV. The current version has been further simplified, compared to last year, by removing for instance domain abstraction. The SAT solver Lin-geling continues to be the default back-end. Boolector still supports PicoSAT and now also MiniSAT. Support for PrecoSAT has been removed. New features include usage of the \u201cclone\u201d functionality of Lingeling and a top-level boolean skeleton simplifier. Boolector is expected to perform substantially better than last year, particularly in the plain bit-vector category QF BV, due to better integration with Lingeling. It also has new incremental features, but those have not been integrated with the SMT-Lib 2 parser yet. Boolector has also been improved for very large instances. The submitted competition version of Boolector is currently only available as binary. We will publish the source code of an updated version after the com-petition, which as before will use a GPL license.", "num_citations": "1\n", "authors": ["1025"]}
{"title": "PicoSAT and PicoAigerSAT entering the SAT-Race 2008\n", "abstract": " This note describes features of those version of PicoSAT and PicoAigerSAT, that entered the SAT-Race 2008 affilliated to the SAT\u20192008 conference in Guangzhou, China.", "num_citations": "1\n", "authors": ["1025"]}
{"title": "Combining Symbolic Model Checking with Uninterpreted Functions for\n", "abstract": " We present a new approach to the verification of hardware systems with data dependencies using temporal logic symbolic model checking. As a benchmark we take Tomasulo's algorithm (10) for out-of-order instruction scheduling. Our approach is similar to the idea of uninterpreted function symbols (4). We use symbolic values and instructions instead of concrete ones. This allows us to show the correctness of the machine independently of the actual instruction set architecture and the implementation of the functional units. Instead of using first order terms as in [4], we represent symbolic values with a new compact encoding. In addition, we apply some other reduction techniques to the model. This significantly reduces the state space and allows the use of highly efficient symbolic model checkers like SMV instead of special decision procedures. The correct-ness of the method has been proven formally with the PVS theorem prover.", "num_citations": "1\n", "authors": ["1025"]}
{"title": "Translating CSP to SMV and then to SAT for the CSP\u201905 competition\n", "abstract": " The CSP table file format used by the CSP\u201905 competition allows a straightforward translation into the input format of the SMV model checker. For bounded model checking many translators of SMV models into CNF exist. This allows the application of SAT solvers to these CSP problems.", "num_citations": "1\n", "authors": ["1025"]}