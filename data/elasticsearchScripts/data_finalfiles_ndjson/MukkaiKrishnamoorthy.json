{"title": "Finding communities by clustering a graph into overlapping subgraphs.\n", "abstract": " We present a new approach to the problem of finding communities: a community is a subset of actors who induce a locally optimal subgraph with respect to a density function defined on subsets of actors. Two different subsets with significant overlap can both be locally optimal, and in this way we may obtain overlapping communities. We design, implement, and test two novel efficient algorithms, RaRe and IS, which find communities according to our definition. These algorithms are shown to work effectively on both synthetic and real-world graphs, and also are shown to outperform a well-known k-neighborhood heuristic.", "num_citations": "268\n", "authors": ["899"]}
{"title": "A random walk method for alleviating the sparsity problem in collaborative filtering\n", "abstract": " Collaborative Filtering is one of the most widely used approaches in recommendation systems which predicts user preferences by learning past user-item relationships. In recent years, item-oriented collaborative filtering methods came into prominence as they are more scalable compared to user-oriented methods. Item-oriented methods discover item-item relationships from the training data and use these relations to compute predictions. In this paper, we propose a novel item-oriented algorithm, Random Walk Recommender, that first infers transition probabilities between items based on their similarities and models finite length random walks on the item space to compute predictions. This method is especially useful when training data is less than plentiful, namely when typical similarity measures fail to capture actual relationships between items. Aside from the proposed prediction algorithm, the final transition\u00a0\u2026", "num_citations": "257\n", "authors": ["899"]}
{"title": "Syntactic segmentation and labeling of digitized pages from technical journals\n", "abstract": " A method for extracting alternating horizontal and vertical projection profiles are from nested sub-blocks of scanned page images of technical documents is discussed. The thresholded profile strings are parsed using the compiler utilities Lex and Yacc. The significant document components are demarcated and identified by the recursive application of block grammars. Backtracking for error recovery and branch and bound for maximum-area labeling are implemented with Unix Shell programs. Results of the segmentation and labeling process are stored in a labeled x-y tree. It is shown that families of technical documents that share the same layout conventions can be readily analyzed. Results from experiments in which more than 20 types of document entities were identified in sample pages from two journals are presented.< >", "num_citations": "249\n", "authors": ["899"]}
{"title": "Fault diameter of interconnection networks\n", "abstract": " We introduce the concept of fault diameter of interconnection networks. The motivation is to estimate the degradation of performance under maximally fault conditions. We derive fault diameter of specific classes of commonly used interconnection networks and various types of product graphs.", "num_citations": "242\n", "authors": ["899"]}
{"title": "Modeling and multiway analysis of chatroom tensors\n", "abstract": " This work identifies the limitations of n-way data analysis techniques in multidimensional stream data, such as Internet chatroom communications data, and establishes a link between data collection and performance of these techniques. Its contributions are twofold. First, it extends data analysis to multiple dimensions by constructing n-way data arrays known as high order tensors. Chatroom tensors are generated by a simulator which collects and models actual communication data. The accuracy of the model is determined by the Kolmogorov-Smirnov goodness-of-fit test which compares the simulation data with the observed (real) data. Second, a detailed computational comparison is performed to test several data analysis techniques including svd [1], and multiway techniques including Tucker1, Tucker3 [2], and Parafac [3].", "num_citations": "173\n", "authors": ["899"]}
{"title": "A mechanizable induction principle for equational specifications\n", "abstract": " Automating proofs of properties of functions defined on inductively constructed data structures is important in many computer science and artificial intelligence applications, in particular in program verification and specification systems. A new induction principle based on a constructor model of a data structure is developed. This principle along with a given function definition as a set of equations is used to construct automatically an induction scheme suitable for proving inductive properties of the function. The proposed induction principle thus gives different induction schema for different function definitions, just as Boyer and Moore's prover does. A novel feature of this approach is that it can also be used for proving properties by induction for data structures such as integers, finite sets, whose values cannot be freely constructed, i.e., constructors for such data structures are related to each other. This method has\u00a0\u2026", "num_citations": "166\n", "authors": ["899"]}
{"title": "Algorithms for generating fundamental cycles in a graph\n", "abstract": " The following problem is considered: Given an undirected, connected graph G, find a spanning tree in G such that the sum of the lengths of the fundamental cycles (with respect to this tree) is minimum. This problem, besides being interesting in its own right, is useful in a variety of situations It is shown that this problem is NP-complete. A number of polynomial-time, heuristic algorithms which yield\" good\" suboptimal solutions are presented and their performances are discussed. Finally, it is shown that for regular graphs of order n the expected value of the total length of a minimum fundamentalcycle set does not exceed O (n2).", "num_citations": "160\n", "authors": ["899"]}
{"title": "Graph theoretic and spectral analysis of Enron email data\n", "abstract": " Analysis of social networks to identify communities and model their evolution has been an active area of recent research. This paper analyzes the Enron email data set to discover structures within the organization. The analysis is based on constructing an email graph and studying its properties with both graph theoretical and spectral analysis techniques. The graph theoretical analysis includes the computation of several graph metrics such as degree distribution, average distance ratio, clustering coefficient and compactness over the email graph. The spectral analysis shows that the email adjacency matrix has a rank-2 approximation. It is shown that preprocessing of data has significant impact on the results, thus a standard form is needed for establishing a benchmark data.", "num_citations": "148\n", "authors": ["899"]}
{"title": "An NP-hard problem in bipartite graphs\n", "abstract": " Checking for Hamiltonian circuit in bipartite graphs is shown to be NP-hard.", "num_citations": "108\n", "authors": ["899"]}
{"title": "Node-deletion NP-complete problems\n", "abstract": " The entire class of node-deletion problems can be stated as follows: Given a graph G, find the minimum number of nodes to be deleted so that the remaining subgraph g satisfies a specified property . For each , a distinct node-deletion problem arises. The various deletion problems considered here are for the following properties: each component of g is (i) null, (ii) complete, (iii) a tree, (iv) nonseparable, (v) planar, (vi) acyclic, (vii) bipartite, (viii) transitive, (ix) Hamiltonian, (x) outerplanar, (xi) degree-constrained, (xii) line invertible, (xiii) without cycles of a specified length, (xiv) with a singleton K-basis, (xv) transitively orientable, (xvi) chordal, and (xvii) interval. In this paper, these 17 different node-deletion problems are shown to be NP-complete. A unified approach is taken for the transformations employed in the proofs.", "num_citations": "106\n", "authors": ["899"]}
{"title": "Parallel algorithms for matrix normal forms\n", "abstract": " Here we offer a new randomized parallel algorithm that determines the Smith normal form of a matrix with entries being univariate polynomials with coefficients in an arbitrary field. The algorithm has two important advantages over our previous one: the multipliers relating the Smith form to the input matrix are computed, and the algorithm is probabilistic of Las Vegas type, i.e., always finds the correct answer. The Smith form algorithm is also a good sequential algorithm. Our algorithm reduces the problem of Smith form computation to two Hermite form computations. Thus the Smith form problem has complexity asymptotically that of the Hermite form problem. We also construct fast parallel algorithms for Jordan normal form and testing similarity of matrices. Both the similarity and non-similarity problems are in the complexity class RNC for the usual coefficient fields, i.e., they can be probabilistically decided in\u00a0\u2026", "num_citations": "100\n", "authors": ["899"]}
{"title": "Exact and approximate solutions for the gate matrix layout problem\n", "abstract": " We consider the gate matrix layout problem for VLSI circuits, which is known to be NP-complete. We present an efficient algorithm for determining whether two tracks suffice. For the general problem of minimizing the number of tracks (and, hence, the area) needed, we design an attractive dynamic programming formulation to guarantee optimality. We also investigate the performance of fast heuristic algorithms published in the literature and demonstrate that there exist families of problem instances for which the ratio of the number of tracks required by these heuristics to the optimal value is unbounded. Moreover, we show that this result holds for any on-line layout algorithm. We additionally prove that, unless P = NP, no polynomial-time layout algorithm can ensure that the number of tracks it requires never exceeds k plus the optimum, for any constant k.", "num_citations": "100\n", "authors": ["899"]}
{"title": "On the harmonious coloring of graphs\n", "abstract": " In this report we define a new coloring of graphs, namely harmonious coloring of graphs, which arises as an extension of harmonious and graceful numbering of graphs. We show that the harmonious coloring problem for general graphs is NP-complete.", "num_citations": "100\n", "authors": ["899"]}
{"title": "Fast parallel computation of Hermite and Smith forms of polynomial matrices\n", "abstract": " Boolean circuits of polynomial size and polylogarithmic depth are given for computing the Hermite and Smith normal forms of polynomial matrices over finite fields and the field of rational numbers.  The circuits for the Smith normal form computation are probabilistic ones and also determine very efficient sequential algorithms. Furthermore, we give a polynomial-time deterministic sequential algorithm for the Smith  normal form over the rationals. The Smith normal form algorithms are applied to the rational canonical form  of matrices over finite fields and the field of rational numbers.", "num_citations": "99\n", "authors": ["899"]}
{"title": "LOGML: Log markup language for web usage mining\n", "abstract": " Web Usage Mining refers to the discovery of interesting information from user navigational behavior as stored in web access logs. While extracting simple information from web logs is easy, mining complex structural information is very challenging. Data cleaning and preparation constitute a very significant effort before mining can even be applied. We propose two new XML applications, XGMML and LOGML to help us in this task. XGMML is a graph description language and LOGML is a web-log report description language. We generate a web graph in XGMML format for a web site using the web robot of the WWWPal system. We generate web-log reports in LOGML format for a web site from web log files and the web graph. We further illustrate the usefulness of LOGML in web usage mining; we show the simplicity with which mining algorithms (for extracting increasingly complex frequent patterns) can be\u00a0\u2026", "num_citations": "92\n", "authors": ["899"]}
{"title": "Web usage mining\u2014Languages and algorithms\n", "abstract": " Web Usage Mining deals with the discovery of interesting information from user navigational patterns from web logs. While extracting simple information from web logs is easy, mining complex structural information is very challenging. Data cleaning and preparation constitute a very significant effort before mining can even be applied. We propose two new XML applications, XGMML and LOGML to help us in this task. XGMML is a graph description language and LOGML is a web-log report description language. We generate a web graph in XGMML format for a web site and generate web-log reports in LOGML format for a web site from web log files and the web graph. We show the simplicity with which mining algorithms can be specified and implemented efficiently using our two XML applications.", "num_citations": "80\n", "authors": ["899"]}
{"title": "Model-based analysis of printed tables\n", "abstract": " We discuss our system of model-based analysis of printed tables. The goal of our system is to extract and associate parts of a table's image into related segments. For example, we can locate columns, rows, column and table headings of a table's image. The location of these segments are based on features of the table image and on a model of the table. This is a stepwise, top-down approach to table image analysis; thus, for example, the body of the table is located before rows or columns, or individual table cells. The algorithms we discuss involve the stepwise analysis of the image and the grouping of these segments into larger structures (columns, rows, etc.).", "num_citations": "74\n", "authors": ["899"]}
{"title": "Computer-implemented interactive, virtual bookshelf system and method\n", "abstract": " A computer-implemented method and system for realizing an interactive, virtual bookshelf representing physical books and digitally stored books of the user. Using a search query, the Web is searched using search metadata to identify a desired book. Library metadata corresponding to the physical books and digitally stored books of the user is then searched using the search metadata to determine whether the desired book is present in the virtual on-line bookshelf. Results indicative of whether the desired book is present on the virtual on-line bookshelf can be displayed.", "num_citations": "66\n", "authors": ["899"]}
{"title": "Two complementary techniques for digitized document analysis\n", "abstract": " Two complementary methods are proposed for characterizing the spatial structure of digitized technical documents and labelling various logical components without using optical character recognition. The top-down method segments and labels the page image simultaneously using publication-specific information in the form of a page-grammar. The bottom-up method naively segments the document into rectangles that contain individual connected components, combines blocks using knowledge about generic layout objects, and identifies logical objects using publication-specific knowledge. Both methods are based on the XY tree representation of a page image. The procedures are demonstrated on scanned and synthesized bit-maps of the title pages of technical articles.", "num_citations": "63\n", "authors": ["899"]}
{"title": "Complexity of the minimum\u2010dummy\u2010activities problem in a PERT network\n", "abstract": " Any complex project consists of a number of activities which are carried out in some specified precedence order. One of the factors that is considered is in minimizing the project completior, time. The computation of the optimum project completion time is proportional to the number of edges, including dummy activities. In the past, many algorithms were proposed to yield minimum number of dummy activities required to satisfy the given precedence relation. In this paper we transform the node\u2010cover problem in graphs of degree at most 3 to the minimum\u2010dummy\u2010activities problem. Using this transformation we show that the minimum\u2010dummy\u2010activities problem in a PERT network is NP\u2010complete. The significance of this result is that it is worthwhile in developing a polynomial time heuristic algorithm for solving the dummy activities problem.", "num_citations": "62\n", "authors": ["899"]}
{"title": "On recursive path ordering\n", "abstract": " The \u2018Recursive Path Ordering\u2019 (RPO) scheme of Dershowitz is a powerful way of extending a partial order on a set of function symbols to a well-founded partial order on their set of terms. We prove that, given a pair of terms, the problem of deciding whether they can be made RPO-comparable, by choosing a partial order on their function symbols, is NP-complete.", "num_citations": "52\n", "authors": ["899"]}
{"title": "Fractal simulations of African design in pre-college computing education\n", "abstract": " This article describes the use of fractal simulations of African design in a high school computing class. Fractal patterns---repetitions of shape at multiple scales---are a common feature in many aspects of African design. In African architecture we often see circular houses grouped in circular complexes, or rectangular houses in rectangular complexes. Typically the accompanying ceremonies, cosmologies, and other traditions make use of scaling and recursion in their conceptual models. African scaling designs include textiles, sculpture, adornment, and other forms; in many cases there are explicit geometric algorithms and other formal aspects (e.g., pseudorandom number generation in divination systems) embedded in the associated indigenous knowledge system. Thus African fractals provide a strong counter to stereotypes of African culture as primitive or simplistic. Following this fieldwork, we developed a Web\u00a0\u2026", "num_citations": "46\n", "authors": ["899"]}
{"title": "N-tuple features for OCR revisited\n", "abstract": " N-tuple features for optical character recognition have received only scattered attention since the 1960s. Our main purpose is to show that advances in computer technology and computer science compel renewed interest. N-tuple features are useful for printed character classification because they indicate the presence or absence of a given rigid configuration of n black and white pixels in a pattern. Desirable n-tuples fit each pattern of a specified (positive) training set of characters in at least p different shift positions, and fail to fit each pattern of a specified (negative) training set by at least n-q pixels in each shift position. We prove that the problem of finding a distinguishing n-tuple is NP-complete, by examining a natural subproblem with binary strings called the missing configuration problem. The NP-completeness result notwithstanding, distinguishing n-tuples are found automatically in a few seconds on\u00a0\u2026", "num_citations": "40\n", "authors": ["899"]}
{"title": "Cake-cutting is not a piece of cake\n", "abstract": " Fair cake-cutting is the division of a cake or resource among N users so that each user is content. Users may value a given piece of cake differently, and information about how a user values different parts of the cake can only be obtained by requesting users to \u201ccut\u201d pieces of the cake into specified ratios. One of the most interesting open questions is to determine the minimum number of cuts required to divide the cake fairly. It is known that O(N logN) cuts suffices, however, it is not known whether one can do better.               We show that sorting can be reduced to cake-cutting: any algorithm that performs fair cake-division can sort. For a general class of cake-cutting algorithms, which we call linearly-labeled, we obtain an \u03a9(N logN) lower bound on their computational complexity. All the known cake-cutting algorithms fit into this general class, which leads us to conjecture that every cake-cutting algorithm is\u00a0\u2026", "num_citations": "39\n", "authors": ["899"]}
{"title": "Clusterability detection and initial seed selection in large datasets\n", "abstract": " The need for a preliminary assessment of the clustering tendency or clusterability of massive data sets is known. A good clusterability detection method should serve to in uence a decision as to whether to cluster at all, as well as provide useful seed input to a chosen clustering algorithm. We present a framework for the de nition of the clusterability of a data set from a distance-based perspective. We discuss a graphbased system for detecting clusterability and generating seed information including an estimate of the value of k {the number of clusters in the data set, an input parameter to many distance-based clustering methods. The output of our method is tunable to accommodate a wide variety of clustering methods. We have conducted a number of experiments using our methodology with stock market data and with the well-known BIRCH data sets, in two as well as higher dimensions. Based on our experiments and results we nd that our methodology can serve as the basis for much future work in this area. We report our results and discuss promising future directions.", "num_citations": "32\n", "authors": ["899"]}
{"title": "Data extraction from web tables: The devil is in the details\n", "abstract": " We present a method based on header paths for efficient and complete extraction of labeled data from tables meant for humans. Although many table configurations yield to the proposed syntactic analysis, some require access to semantic knowledge. Clicking on one or two critical cells per table, through a simple interface, is sufficient to resolve most of these problem tables. Header paths, a purely syntactic representation of visual tables, can be transformed (\"factored\") into existing representations of structured data such as category trees, relational tables, and RDF triples. From a random sample of 200 web tables from ten large statistical web sites, we generated 376 relational tables and 34,110 subject-predicate-object RDF triples.", "num_citations": "31\n", "authors": ["899"]}
{"title": "Converting heterogeneous statistical tables on the web to searchable databases\n", "abstract": " Much of the world\u2019s quantitative data reside in scattered web tables. For a meaningful role in Big Data analytics, the facts reported in these tables must be brought into a uniform framework. Based on a formalization of header-indexed tables, we proffer an algorithmic solution to end-to-end table processing for a large class of human-readable tables. The proposed algorithms transform header-indexed tables to a category table format that maps easily to a variety of industry-standard data stores for query processing. The algorithms segment table regions based on the unique indexing of the data region by header paths, classify table cells, and factor header category structures of two-dimensional as well as the less common multidimensional tables. Experimental evaluations substantiate the algorithmic approach to processing heterogeneous tables. As demonstrable results, the algorithms generate queryable\u00a0\u2026", "num_citations": "29\n", "authors": ["899"]}
{"title": "An O (| T| 3) algorithm for testing the Church-Rosser property of Thue systems\n", "abstract": " We give an O(|T|3) algorithm for testing the Church-Rosser property of Thue systems using the linear string-matching algorithm by Knuth, Morris and Pratt (1977). This improves the earlier bound of O(|T|6) given by Book and O'Dunlaing (1981). The proposed algorithm uses a reduction algorithm for finding a normal form of a string which is based on building a trie for matching a finite set of patterns, as proposed by Aho and Corasick (1975).", "num_citations": "28\n", "authors": ["899"]}
{"title": "Comparative study of a genetic fuzzy c-means algorithm and a validity guided fuzzy c-means algorithm for locating clusters in noisy data\n", "abstract": " The partitioning of data into clusters is an important problem with many applications. Typically, one locates partitions using an iterative fuzzy c-means algorithm of one form or another. Unfortunately, the results of these techniques depend on the cluster center initialization because their search is based on hill climbing methods. Recently, there has been much investigation into the use of genetic algorithms to partition data into fuzzy clusters. Genetic algorithms are less sensitive to initial conditions due to the stochastic nature of their search. In this paper we compare the two techniques when locating fuzzy clusters embedded in noisy data and discuss the advantages and disadvantages of both methods.", "num_citations": "27\n", "authors": ["899"]}
{"title": "A tool for internet chatroom surveillance\n", "abstract": " Internet chatrooms are common means of interaction and communications, and they carry valuable information about formal or ad-hoc formation of groups with diverse objectives. This work presents a fully automated surveillance system for data collection and analysis in Internet chatrooms. The system has two components: First, it has an eavesdropping tool which collects statistics on individual (chatter) and chatroom behavior. This data can be used to profile a chatroom and its chatters. Second, it has a computational discovery algorithm based on Singular Value Decomposition (SVD) to locate hidden communities and communication patterns within a chatroom. The eavesdropping tool is used for fine tuning the SVD-based discovery algorithm which can be deployed in real-time and requires no semantic information processing. The evaluation of the system on real data shows that (i) statistical properties of\u00a0\u2026", "num_citations": "26\n", "authors": ["899"]}
{"title": "Culturally Situated Design Tools: Generative justice as a foundation for STEM diversity\n", "abstract": " The \u201cpipeline\u201d model of STEM education conceives of underrepresentation by race, gender and class in terms of leaks that fail to deliver students to their destination in the science and technology workforce. But that model fails to consider the role of STEM in producing underrepresentation. This can only be solved by moving from the extractive approach of the pipeline model to a generative model in which the value produced by STEM students cycles back to their own communities. We report on our experience creating and evaluating Culturally Situated Design Tools. Using a framework of \u201cgenerative justice\u201d, we contrast the cyclic social damage, which reproduces underrepresentation with the potential for STEM education as a niche in the technosocial ecosystem that can address underrepresentation and causal factors.", "num_citations": "22\n", "authors": ["899"]}
{"title": "Studying e-mail graphs for intelligence monitoring and analysis in the absence of semantic information\n", "abstract": " This work describes a methodology that can be used to identify structure and communication patterns within an organization based on e-mail data. The first step of the method is the construction of an e-mail graph; we then experimentally show that the adjacency matrix of the graph is well approximated by a low-rank matrix. The low-rank property indicates that Principal Component Analysis techniques may be used to remove the noise and extract the structural information (e.g. user communities, communication patterns, etc.). Furthermore, it is shown that the e-mail graph degree distribution (both with respect to indegrees and outdegrees) follows power laws; we also demonstrate that there exists a giant component connecting 70% of the nodes.", "num_citations": "20\n", "authors": ["899"]}
{"title": "An approximation algorithm to the file allocation problem in computer networks\n", "abstract": " In this paper, we are going to examine the problem of optimal file allocation In arbitrary computer networks This problem has been shown to be NP-complete[CHAHD76, ESWAR74] Several authors TCHU69, CASEY72, CHAND76, MAHMD76] have stud3ed this problem using analytical, heurlstlc and lmear-Integer programmlng methods But these techniques only tend to demonstrate their relative efficiencies in fIndIng solutions to known problems and for small values of the number of nodes In the network They did not provide any mathematical analysis of the worst case sltuatlon of their techniques Hence, they falled to establish bounds on the devlatlon of their solutions In terms of exact solutions for problems with no known optimal solutlons They also did not establish the time and space complexltles of their algorithms This has motivated us to develop a polynomial appro,;'at: on algorithm which guarantees a\u00a0\u2026", "num_citations": "20\n", "authors": ["899"]}
{"title": "Algorithmic detection of computer generated text\n", "abstract": " Computer generated academic papers have been used to expose a lack of thorough human review at several computer science conferences. We assess the problem of classifying such documents. After identifying and evaluating several quantifiable features of academic papers, we apply methods from machine learning to build a binary classifier. In tests with two hundred papers, the resulting classifier correctly labeled papers either as human written or as computer generated with no false classifications of computer generated papers as human and a 2% false classification rate for human papers as computer generated. We believe generalizations of these features are applicable to similar classification problems. While most current text-based spam detection techniques focus on the keyword-based classification of email messages, a new generation of unsolicited computer-generated advertisements masquerade as legitimate postings in online groups, message boards and social news sites. Our results show that taking the formatting and contextual clues offered by these environments into account may be of central importance when selecting features with which to identify such unwanted postings.", "num_citations": "19\n", "authors": ["899"]}
{"title": "Analysis and taxonomy of column header categories for web tables\n", "abstract": " We describe a component of a document analysis system for constructing ontologies for domain-specific web tables imported into Excel. This component automates extraction of the Wang Notation for the column header of a table. Using column-header specific rules for XY cutting we convert the geometric structure of the column header to a linear string denoting cell attributes and directions of cuts. The string representation is parsed by a context-free grammar and the parse tree is further processed to produce an abstract data-type representation (the Wang notation tree) of each column category. Experiments were carried out to evaluate this scheme on the original and edited column headers of Excel tables drawn from a collection of 200 used in our earlier work. The transformed headers were obtained by editing the original column headers to conform to the format targeted by our grammar. Forty-four original\u00a0\u2026", "num_citations": "19\n", "authors": ["899"]}
{"title": "Interactive graph drawing on the world wide web\n", "abstract": " We discuss a system for performing interactive graph drawing on the World Wide Web (WWW), implemented in the Java programming language. The system allows for highly interactive experimentation in graph drawing, supporting direct user interaction and parameter adjustment during the embedding process. The use of Java and the WWW in its implementation makes the system globally available, both for interactive use and for integration into other systems, regardless of computer platform details. We present the design, implementation and use of the system, as well as some experimental results.", "num_citations": "19\n", "authors": ["899"]}
{"title": "Enumerating all cycles of a planar graph\n", "abstract": " We present a new and elegant cycle vector space algorithm that runs in O(n2.\u03b1) steps and needs O:lpar;nn) space for enumerating all simple cycles of a planar graph with n vertices, where \u03b1 is the total number of simple cycles in the graph Unlike backtrack algorithms, cycle vector space algorithms for this problem are suitable for parallelization. A parallel version of this algorithm alone with a parallel version of Syslo's O(n.\u03b1) step algorithm for the same problem are on an exclusive-read, exclusive-write parallel RAM model with p processors. The results of an implementation of our parallel algorithm on a meshconnected SIMD computer are also presented.", "num_citations": "19\n", "authors": ["899"]}
{"title": "Factoring web tables\n", "abstract": " Automatic interpretation of web tables can enable database-like semantic search over the plethora of information stored in tables on the web. Our table interpretation method presented here converts the two-dimensional hierarchy of table headers, which provides a visual means of assimilating complex data, into a set of strings that is more amenable to algorithmic analysis of table structure. We show that Header Paths, a new purely syntactic representation of visual tables, can be readily transformed (\u201cfactored\u201d) into several existing representations of structured data, including category trees and relational tables. Detailed examination of over 100 tables reveals what table features require further work.", "num_citations": "18\n", "authors": ["899"]}
{"title": "Musical puzzle toy\n", "abstract": " A cube shaped toy has a button and a rotary switch on each of the cube's six sides. For each of the cube's six faces, there is an associated set of four tones. Pushing the button on a selected face causes the toy to play the tones associated with that face. In particular, if each face is divided into four quadrants, there is one\" quadrant-tone\" associated with each quadrant. The toy has just six distinct tones, and when the toy is first turned on, or restarted, all four tones for each face are identical. Whenever one of the rotary switches is turned, the quadrant-tones of the associated face are rotated, and the quadrant-tones for the neighboring faces are also\" rotated\", generating a new set of tone patterns for each of the five affected faces. By listening to the tones for each face and rotating the rotary switches, the user can move the quadrant-tones until all four tones for each face are identical.", "num_citations": "17\n", "authors": ["899"]}
{"title": "An Internet measure of the value of citations\n", "abstract": " A new method for computing the value of citations is introduced and compared with the PageRank algorithm for author ranking. In our proposed approach, the value of each publication is expressed in CENTs (sCientific currENcy Tokens). The publication\u2019s value is then divided by the number of citations made by that publication to yield a value for each citation. As citations are the acknowledgements of the work by authors other than oneself (indicating that it has been useful), self-citations count as zero in acknowledged citation value. Circular citations, a generalized type of self-citation, are considered to have a reduced acknowledged citation value. Finally, we propose a modification of the h-index to define it as the largest integer such that the i-th publication (on the list of publications sorted by their value in CENTs) is worth more than i CENTs. This new index, termed the i-index or i2 in short, appears to be a more\u00a0\u2026", "num_citations": "15\n", "authors": ["899"]}
{"title": "Interactive conversion of web tables\n", "abstract": " Two hundred web tables from ten sites were imported into Excel. The tables were edited as needed, then converted into layout independent Wang Notation using the Table Abstraction Tool (TAT). The output generated by TAT consists of XML files to be used for constructing narrow-domain ontologies. On an average each table required 104 seconds for editing. Augmentations like aggregates, footnotes, table titles, captions, units and notes were also extracted in an average time of 93 seconds. Every user intervention was logged and audited. The logged interactions were analyzed to determine the relative influence of factors like table size, number of categories and various types of augmentations on the processing time. The analysis suggests which aspects of interactive table processing can be automated in the near term, and how much time such automation would save. The correlation coefficient between\u00a0\u2026", "num_citations": "14\n", "authors": ["899"]}
{"title": "Hardness results for cake cutting\n", "abstract": " Fair cake-cutting is the division of a cake or resource among N users so that each user is content. Users may value a given piece of cake differently, and information about how a user values different parts of the cake can only be obtained by requesting users to\" cut\" pieces of the cake into specified ratios. Many", "num_citations": "14\n", "authors": ["899"]}
{"title": "Document recognition: an attribute grammar approach\n", "abstract": " A formulation of a hierarchical page decomposition technique for technical journal pages using attribute grammars is presented. In this approach, block-grammars are recursively applied until a page is classified into its most significant sub-blocks. While a grammar devised for each block depends on its logical function, it is possible to formulate a generic description for all block grammars using attribute grammars. This attribute grammar formulation forms a generic framework on which this syntactic approach is based, while the attributes themselves are derived from publication-specific knowledge. The attribute extraction process and the formulation itself are covered in this paper. We discuss an application of attribute grammars to a document analysis problem, the extraction of logical, relational information from the image of tables.", "num_citations": "14\n", "authors": ["899"]}
{"title": "Program tools for algorithm animation\n", "abstract": " This paper proposes graphics primitives for constructing programs for algorithm animation. Our experiments show that these primitives can reduce program development time. Future directions of the current research is also discussed.", "num_citations": "14\n", "authors": ["899"]}
{"title": "Fast parallel algorithms for similarity of matrices\n", "abstract": " A linear operator on an n-dimensional vector space over a field F can be defined by how it acts on each vector of a given basis (u 1,..., u,) for the space. This action gives rise to an n by n matrix A= Iai, Jll< t, 16~ 1 1 ai,, Ef, such that o~,~ u,+. a\u2019+ Oi, n U, is the image of vi under that linear operator. Clearly, A not only depends on the operator itself but also on the choire of basis. If we pass to a different basis, the representative matrix B corresponding to the same linear operator is similar to A, that is there exists a nonsingular matrix TEF n\u2019n such that B= TAT-I. The fundamental problem with similarity is to construct a new basis such that B is as close to diagonal as possible. since then much information about the linear operator becomes apparent. One \u201calmost\u201d diagonal matrix similar to A is the Jordan normal form of A. Another basic question is, of course. whether two matrices over a field are similar, that is whether the\u00a0\u2026", "num_citations": "14\n", "authors": ["899"]}
{"title": "A hybrid model for disease spread and an application to the SARS pandemic\n", "abstract": " Pandemics can cause immense disruption and damage to communities and societies. Thus far, modeling of pandemics has focused on either large-scale difference equation models like the SIR and the SEIR models, or detailed micro-level simulations, which are harder to apply at a global scale. This paper introduces a hybrid model for pandemics considering both global and local spread of infections. We hypothesize that the spread of an infectious disease between regions is significantly influenced by global traffic patterns and the spread within a region is influenced by local conditions. Thus we model the spread of pandemics considering the connections between regions for the global spread of infection and population density based on the SEIR model for the local spread of infection. We validate our hybrid model by carrying out a simulation study for the spread of SARS pandemic of 2002-2003 using available data on population, population density, and traffic networks between different regions. While it is well-known that international relationships and global traffic patterns significantly influence the spread of pandemics, our results show that integrating these factors into relatively simple models can greatly improve the results of modeling disease spread.", "num_citations": "13\n", "authors": ["899"]}
{"title": "Efficient multiway radix search trees\n", "abstract": " We present a new scheme for building static search trees, using multiway radix search. We apply this method to the problem of code generation for switch statements in imperative languages. For sparse case sets, the method has an advantage over existing methods, empirically requiring fewer than three branches for the average search. We give timing results that show that in practice our method runs faster than other methods on large sparse case sets.", "num_citations": "13\n", "authors": ["899"]}
{"title": "Exploring network scaling through variations on optimal channel networks\n", "abstract": " Metabolic allometry, a common pattern in nature, is a close to 3/4-power scaling law between metabolic rate and body mass in organisms, across and within species. An analogous relationship between metabolic rate and water volume in river networks has also been observed. Optimal channel networks (OCNs), at local optima, accurately model many scaling properties of river systems, including metabolic allometry. OCNs are embedded in 2D space; this work extends the model to three dimensions. In this paper we compare characteristics of 3D OCNs with 2D OCNs and with organic metabolic networks, studying the scaling behaviors of area, length, volume, and energy. We find that the 3D OCN has predictable characteristics analogous to those of the 2D version, as well as scaling properties similar to metabolic networks in biological organisms.", "num_citations": "12\n", "authors": ["899"]}
{"title": "From tessellations to table interpretation\n", "abstract": " The extraction of the relations of nested table headers to content cells is automated with a view to constructing narrow domain ontologies of semi-structured web data. A taxonomy of tessellations for displaying tabular data is developed. X-Y tessellations that can be obtained by a divide-and-conquer method are asymptotically only an infinitesimal fraction of all partitions of a rectangle into rectangles. Admissible tessellations are the even smaller subset of all partitions that correspond to the structures of published tables and that contain only rectangles produced by successive guillotine cuts. Many of these can be processed automatically. Their structures can be conveniently represented by X-Y trees, which facilitate relating hierarchical row and column headings to content cells. A formal grammar is proposed for characterizing the X-Y trees of layout-equivalent admissible tessellations. Algorithms are\u00a0\u2026", "num_citations": "11\n", "authors": ["899"]}
{"title": "Architecting a search engine for the semantic web\n", "abstract": " Since its emergence in the early 1990s, the World Wide Web has rapidly evolved into a global information space of incomparable size. Keyword-based search engines such as Google\u2122 index as many webpages as possible for the benefit of human users. Sophisticated as such search engines have become, they are still often unable to bridge the gap between HTML and the human. Tim Berners-Lee envisions the Semantic Web as the web of machineinterpretable information that complements the existing World Wide Web, providing an automated means for machines to truly traverse the Web on behalf of their human counterparts. A cornerstone application of the emerging Semantic Web is the search engine that is capable of tying components of the Semantic Web together into a traversable landscape. This paper describes both an architecture for and a prototype of a Semantic Web Search Engine (SWSE) using Jena that provides more sophisticated searching with more exacting results. To compare keyword-based search via Google with semantics-based search via the SWSE prototype, we utilize the Google CruciVerbalist (GCV), a system we developed that attempts to solve crossword puzzles via a generic search interface.", "num_citations": "11\n", "authors": ["899"]}
{"title": "Cycle vector space algorithms for enumerating all cycles of a planar graph\n", "abstract": " We present a new and elegant cycle vector space algorithm that runs in O (n 2\\Delta ff) steps and needs O (n) space for enumerating all the cycles of a planar graph with n vertices, where ff is the total number of simple cycles in the graph. Unlike backtrack algorithms, cycle vector space algorithms for this problem are suitable for parallelization. A parallel version of this algorithm along with a parallel version of Syslo's O (n\\Delta ff) step algorithm for the same problem are given on an exclusiveread, exclusive-write parallel RAM model with p processors. The results of an implementation of our parallel algorithm on a mesh-connected SIMD computer are also presented. Keywords: enumerating all cycles, cycle basis, planar graphs, EREW PRAM algorithm, meshconnected SIMD computer. 1 Introduction A graph G=(V; E) is a collection of objects, represented by a set of vertices V and relations among them, represented by a set of edges E. A graph G is said to be planar if there exists so...", "num_citations": "11\n", "authors": ["899"]}
{"title": "Toeplitz networks and their properties\n", "abstract": " Toeplitz networks are investigated as a source of interconnection networks. These networks possess many desirable properties including low diameter and high connectivity. Further, their diversity allows the generation of new networks with some specific parameters. Theorems are proved that can be used to analyze these graphs with respect to diameter, connectivity, fault tolerance, etc. A number of examples are included.< >", "num_citations": "11\n", "authors": ["899"]}
{"title": "Mr. Smith goes to Las Vegas: Randomized parallel computation of the Smith normal form of polynomial matrices\n", "abstract": " We have provided a parallel solution for the well-known Smith normal form problem. Our method employs randomization as a tool to remove the iterations along the main diagonal in the classical sequential algorithms, and as such might be useful in similar settings, as well as may speed the sequential methods themselves.", "num_citations": "11\n", "authors": ["899"]}
{"title": "Worst-case choice for the stable marriage problem\n", "abstract": " We present a worst-case choice for the stable marriage problem which takes the maximum number of stages for Gale and Shapely's algorithm (1962). We also analyze a coroutine solution recently suggested by Allison (1983) as well as a parallel algorithm for this problem.", "num_citations": "11\n", "authors": ["899"]}
{"title": "Semantic inference for pharmacokinetic drug-drug interactions\n", "abstract": " Drug-drug interaction (DDI) study is an important aspect of therapy management and drug efficacy. DDI study investigates how drugs interact with each other and determine whether these interactions may lead to dire effects or nullify the therapeutic effects of each other. In this paper we model metabolic pathways of drugs that include the reaction effects between drugs and the related enzymes. By modeling the reaction effects, our model captures the degree of the effects of the interacting drugs. We introduce a novel methodology that combines semantics, ontology to model the concepts and interactions, and Answer Set Programming for temporal reasoning. We illustrate our method by inferring the effects of DDI among three drugs clozapine, olanzapine and fluvoxamine.", "num_citations": "10\n", "authors": ["899"]}
{"title": "Comparing keyword search to semantic search: a case study in solving crossword puzzles using the Google\u2122 API\n", "abstract": " Keyword\u2010based search engines such as Google\u2122 index Web pages for human consumption. Sophisticated as such engines have become, surveys indicate almost 25% of Web searchers are unable to find useful results in the first set of URLs returned (Technology Review, March 2004). The lack of machine\u2010interpretable information on the Web limits software agents from matching human searches to desirable results. Tim Berners\u2010Lee, inventor of the Web, has architected the Semantic Web in which machine\u2010interpretable information provides an automated means to traversing the Web. A necessary cornerstone application is the search engine capable of bringing the Semantic Web together into a searchable landscape. We implemented a Semantic Web Search Engine (SWSE) that performs semantic search, providing predictable and accurate results to queries. To compare keyword search to semantic search\u00a0\u2026", "num_citations": "10\n", "authors": ["899"]}
{"title": "Coloring procedures for finite element computation on shared-memory parallel computers.\n", "abstract": " We consider solution procedures for linear elliptic partial differential systems on shared-memory parallel computers. With mesh generation and adaptive mesh refinement utilizing an underlying quadtree structure for data management, we show that terminal nodes of the quadtree can be colored so as to separate contiguous spatial regions that may be processed in parallel without conflict. The quadtree coloring algorithm has a linear time complexity and uses a maximum of six colors. While parallel performance of the quadtree coloring procedure is reasonable for piecewise linear finite element solutions, it degrades rapidly when higher-degree approximations are used. A coloring procedure to separate contiguous element edges provides superior performance when higher-degree piecewise hierarchical approximations are involved and hence should be useful for hp-refinement.", "num_citations": "10\n", "authors": ["899"]}
{"title": "A parallel algorithm for the monadic unification problem\n", "abstract": " The monadic unification problem is introduced. AnO(log2 n) parallel algorithm to solve this problem is given and shown to be correct.", "num_citations": "10\n", "authors": ["899"]}
{"title": "Clusterability detection and cluster initialization\n", "abstract": " The need for a preliminary assessment of the clustering tendency or clusterability of massive data sets is known. A good clusterability detection method should serve to influence a decision as to whether to cluster at all, as well as provide useful seed input to a chosen clustering algorithm. We present a framework for the definition of the clusterability of a data set from a distance-based perspective. We discuss a graph-based system for detecting clusterability and generating seed information including an estimate of the value of k\u2013the number of clusters in the data set, an input parameter to many distancebased clustering methods. The output of our method is tunable to accommodate a wide variety of clustering methods.We have conducted a number of experiments using our methodology with stock market data and with the well-known BIRCH data sets, in two as well as higher dimensions. Based on our experiments and results we find that our methodology can serve as the basis for much future work in this area. We report our results and discuss promising future directions.", "num_citations": "9\n", "authors": ["899"]}
{"title": "Algorithms of placing recovery points\n", "abstract": " In this paper we study the complexity of placing recovery points in computer programs, so that the roll-back time is minimized. The roll-back time corresponds to the recomputation time involved from the previous correct point. Here we give O(n2) time algorithms for placing recovery points when the underlying program model is either a path tree or a rooted tree. We also show that the problem is NP-complete when the underlying program model is a directed graph.", "num_citations": "9\n", "authors": ["899"]}
{"title": "Towards a theory of packages\n", "abstract": " A model for packages is introduced, along with operations for their manipulation. The model is based on the unifying principle that programs should be represented by trees, and packages by substitutions on trees. Operations are defined on packages, that allow the construction of any package from a collection of basic packages. A programming environment, based on this model, would allow manipulations and operations that are not possible in current languages. Information hiding and encapsulation are automatically supported by the model. A typing mechanism is presented, which allows polymorphic types. The typing does not affect the typeless aspect of the model.", "num_citations": "9\n", "authors": ["899"]}
{"title": "Quantitative Metrics for Generative Justice: Graphing the value of diversity\n", "abstract": " Scholarship utilizing the Generative Justice framework has focused primarily on qualitative data collection and analysis for its insights. This paper introduces a quantitative data measurement, contributory diversity, which can be used to enhance the analysis of ethical dimensions of value production under the Generative Justice lens. It is well known that the identity of contributors\u2014gender, ethnicity, and other categories\u2014is a key issue for social justice in general. Using the example of Open Source Software communities, we note that that typical diversity measures, focusing exclusively on workforce demographics, can fail to fully illuminate issues in value generation. Using Shannon\u2019s entropy measure, we offer an alternative metric which combines the traditional assessment of demographics with a measure http://dx. doi. org/10.5209/rev_TEKN. 2016. v13. n2. 52838 ISSN: 1549 2230", "num_citations": "8\n", "authors": ["899"]}
{"title": "Clustering header categories extracted from web tables\n", "abstract": " Revealing related content among heterogeneous web tables is part of our long term objective of formulating queries over multiple sources of information. Two hundred HTML tables from institutional web sites are segmented and each table cell is classified according to the fundamental indexing property of row and column headers. The categories that correspond to the multi-dimensional data cube view of a table are extracted by factoring the (often multi-row/column) headers. To reveal commonalities between tables from diverse sources, the Jaccard distances between pairs of category headers (and also table titles) are computed. We show how about one third of our heterogeneous collection can be clustered into a dozen groups that exhibit table-title and header similarities that can be exploited for queries.", "num_citations": "8\n", "authors": ["899"]}
{"title": "A nonparametric classifier for unsegmented text\n", "abstract": " Symbolic Indirect Correlation (SIC) is a new classification method for unsegmented patterns. SIC requires two levels of comparisons. First, the feature sequences from an unknown query signal and a known multi-pattern reference signal are matched. Then, the order of the matched features is compared with the order of matches between every lexicon symbol-string and the reference string in the lexical domain. The query is classified according to the best matching lexicon string in the second comparison. Accuracy increases as classified feature-and-symbol strings are added to the reference string.", "num_citations": "8\n", "authors": ["899"]}
{"title": "A multiple-resolution method for edge-centric data clustering\n", "abstract": " Recent works in spatial data clustering view the input data set in terms of inter-point edge lengths rather than the points themselves. Cluster detection in such a system is a matter of finding connected paths of edges whose weight is no greater than some user input threshold or cutoff value. The SMTIN algorithm [9] is one such system that uses Delaunay triangulation to compute the set of nearest neighbor edges quickly and efficiently. Experiments demonstrate a substantial performance and accuracy improvement using SMTIN in comparison to other clustering systems.", "num_citations": "8\n", "authors": ["899"]}
{"title": "GraphPack: Design and features\n", "abstract": " We present several elegant methods used in GraphPack, an educational package, for three dimensional embedding of graphs, as well as a two dimensional layout method, namely barycentric embedding. After that, a program for automatic recognition of graphs is introduced. In addition, we show how graphs in GraphPack format can be exported into Xfig format. Finally, we describe the client/server capabilities of GraphPack designed for providing communication with other tools and application programs written in C and C++.", "num_citations": "8\n", "authors": ["899"]}
{"title": "A syntactic approach to document segmentation\n", "abstract": " A document image is a bit-map produced by raster-digitizing (scanning) a printed page. It can contain fields of text, equations, tables and figures. This article describes a method to identify the spatial structure of a document image and label various components without using optical character recognition. The segmentation and labeling is done simultaneously using publication specific information. This domain-dependent knowledge is in the form of a page-grammar and is used to describe the relationship between various entity classes or blocks. Lexical and syntax analysis tools such as Lex and Yacc are used to label the segments. A simulated document title page is used to illustrate this approach.", "num_citations": "8\n", "authors": ["899"]}
{"title": "Categorization of blogs through similarity analysis\n", "abstract": " We describe a new model for evaluating similarities among a large number of web logs, and compare several algorithms using the model. Possible uses of this include isolating and tracking like-minded networks for surveillance and improved categorization. Our model consists of similarity analysis combined with clustering. Experimental results show that our algorithm is able to separate blogs into categories, consistently achieving over 90% success rate.", "num_citations": "7\n", "authors": ["899"]}
{"title": "Solving Crossword Puzzles via the Google API.\n", "abstract": " The Google\u2122 API enables software agents to query and use search results from the large collections of data available via the ever-popular Google search engine. Web searches using Google are exposed to over 4 billion pages, many of which are cached within Google. While the Google API may be used to produce customized user interfaces to Google, the API also provides direct programmatic access to the subset of the Web covered by Google. In this paper, we present a fresh approach to solving crossword puzzles by making use of the Google API. Our system, the Google CruciVerbalist (GCV), reads XML-encoded crossword puzzles, derives answers to clues via the Google API, and uses a refined depth-first search algorithm to populate the crossword grid. GCV has successfully solved smaller puzzles, especially ones containing pop-culture and fill-in-the-blank types of clues. Based on this ongoing work, limitations of current search technologies are identified. To overcome these limitations, we look ahead to semantic queries via the emerging Semantic Web, including techniques using RDF that augment the Google search engine with semantic information, enabling semantically rich queries beyond the current capabilities of Google.", "num_citations": "7\n", "authors": ["899"]}
{"title": "Logml-xml language for web usage mining\n", "abstract": " ABSTRACT\u00a2\u00a1\u00a4\u00a3\u00a6\u00a5 \u00a7 \u00a9\u00a3 \u00a7 \u00a1\u00a6\u00a1!#\"% $'& () 10 23 0\u00a1\u00a9 45 $76989\"% $ A@ B $76989\"% $'CD E 5\u00a1 GF\u00a6 HI&D \u00a7 \u00a9 0\u00a4\u00a5\u00a1 G\u00a3 \u00a7 \u00a5 P# Q\u00a6\u00a1 G RS\u00a5 CT\u00a3 UPCD \u00a7 \u00a9 V &T 10 23) 0\u00a9\u00a1\u00a9@ W X\u00a1 Y 0\u00a9\u00a1 G\u00a6\u00a1\u00a5) P\u00a1 ab\u00a1 GFUH &D \u00a7 0c\u00a5\u00a1\u00a3 \u00a7 \u00a5 P\u00a4 CD d $76989\"% $ f eg \u00a7 \u00a5 h\u00a4) P\u00a4 eg \u00a7 \u00a5\u00a2 b\u00a1 GF'CiP\u00a1 eg\u00a5 \u00a7 hp b\u00a1 GF &D \u00a7 0r q1&T\u00a1) 3Qs Pt1\u00a1 5\u00a1 GFd 0\u00a5)\u00a3 1tu@ w vx s Pt1CD\u00a3 1\u00a3\u00a1\u00a5 y4 5\u00a1 eg2\u00a6\u00a5 Pt1\u00a1 S\u00a5 CD&D&D21 P\u00a5P\u00a1% Pt1\u00a1 2\u00a6\u00a1 e 2\u00a6 &D 1\u00a1 G \u00a7 ) e Pt1CD#\"% $)\u00a3 1\u00a3 1&DCDRy PCT \u00a7 s CiPts 5\u00a1 GF Q1) Ph CD 1CD\u00a6 0r\u00a1 S 1) h\u00a3 1&D\u00a1\u00a9@ X\u00a1\u00a3\u00a6\u00a5 \u00a7 C (QU\u00a1) h\u00a3 1&D\u00a1 V\u00a5\u00a1 G 21&iP G4 1 h\u00a1 G&i eg\u00a5\u00a1 y 21\u00a1 P\u00a3 3 PP\u00a1\u00a5 1 W \u00a7 eA 21\u00a1\u00a5 CT E b\u00a1 F CiP\u00a1\u00a9 4 CiPt \u00a7 \u00a9 2U\u00a5 5\u00a1 GF% 2\u00a6 0\u00a9\u00a1 ah CD 1CD\u00a6 0E &D0 \u00a7 \u00a5 CiPt1h%@", "num_citations": "7\n", "authors": ["899"]}
{"title": "Triangle graphs\n", "abstract": " We introduce a new class of planar graphs called triangle graphs. First, we present a formal way of constructing and characterizing triangle graphs, and then show that they characterize the adjacencies of arbitrary triangulations and they are three-colorable for a certain subclass of triangulations. Subsequently, we discuss an application of triangle graphs to the parallel finite element solution of elliptic partial differential equations on triangulated domains.", "num_citations": "7\n", "authors": ["899"]}
{"title": "Automatic source-code parallelization using HICOR objects\n", "abstract": " We show that by using an intermediate representation, which supports a formalized interface on which to construct parallelization tools, the mapping of the representation onto parallel architectures can be performed quickly and efficiently. An intermediate representation called HICOR (Hierarchical Intermediate Code Object Representation) is shown to facilitate the exploitation of parallel operations by providing an abstraction layer for performing high-level intermediate code analysis, scheduling, and code generation. An object-oriented design approach has been employed in the development of HICOR and associated tools. Source language constructs are transformed into specialized object classes. Inheritance properties provided by the object-oriented paradigm are utilized to provide a common interface to each object in the HICOR representation. It is this interface that provides the needed consistency\u00a0\u2026", "num_citations": "7\n", "authors": ["899"]}
{"title": "Congrats: a system for converting graphics to sound\n", "abstract": " In this paper, we describe our prototype implementation of the CONGRATS system rst implemented at the Indian Institute of Technology, Bombay,(IITB) for his Masters project by one of the authors of this paper, TV Raman. The prototype we have built here is only a small subset of the actual system, and is meant more to show what can be done using sound and elucidate the concepts involved. When complete it will provide a whole new range of educational aids for the visually impaired, and thereby open up subjects that have till now remained inaccessible.", "num_citations": "7\n", "authors": ["899"]}
{"title": "Analysis of yelp reviews\n", "abstract": " In the era of Big Data and Social Computing, the role of customer reviews and ratings can be instrumental in predicting the success and sustainability of businesses. In this paper, we show that, despite the apparent subjectivity of user ratings, there are also external, or objective factors which help to determine the outcome of a business's reviews. The current model for social business review sites, such as Yelp, allows data (reviews, ratings) to be compiled concurrently, which introduces a bias to participants (Yelp Users). Our work examines Yelp Reviews for businesses in and around college towns. We demonstrate that an Observer Effect causes data to behave cyclically: rising and falling as momentum (quantified in user ratings) shifts for businesses.", "num_citations": "6\n", "authors": ["899"]}
{"title": "FCLUST: a visualization tool for fuzzy clustering\n", "abstract": " Emerging technologies on the World Wide Web promise to make program, algorithm and concept simulations universally accessible. Simulations involving animation and visualization have a tremendous benefit when applied to various algorithms. We present a simulation tool for experimenting with concepts in fuzzy clustering that has proved useful in visualizing the results and demonstrating the computation method of the algorithms. This is especially advantageous in a classroom or laboratory setting where students may become more comfortable with the mechanics of fuzzy clustering through personal discovery and online experimentation.", "num_citations": "6\n", "authors": ["899"]}
{"title": "A Java simulation tool for fuzzy clustering\n", "abstract": " Emerging technologies on the World Wide Web promise to make program, algorithm and concept simulations universally accessible, and Java appears to be the best technology available. Simulations involving animation and visualization have a tremendous benefit when applied to various algorithms. We present a simulation tool for experimenting with concepts in fuzzy clustering that has proved useful in visualizing the results and demonstrating the computation method of the algorithms. This is an asset when working with people unfamiliar with the mechanics of fuzzy clustering, such as non\u2010computer scientists or students. This system was integral in the development of an algorithm capable of locating an unknown number of clusters embedded in background noise. \u00a9 1997 John Wiley & Sons, Ltd.", "num_citations": "6\n", "authors": ["899"]}
{"title": "Hamiltonian cycle problem for triangle graphs\n", "abstract": " We show that the Hamiltonian cycle problem is NP-complete for a class of planar graphs named triangle graphs that are closely related to inner-triangulated graphs. We present a lineartime heuristic algorithm that finds a solution at most one-third longer than the optimum solution and use it to obtain a fast rendering algorithm on triangular meshes in computer graphics. Keywords: Planar graph, inner-triangulated graph, triangle graph, NP-complete, heuristic algorithm, rendering triangular meshes. 1 Introduction. The Hamiltonian cycle problem (HC) is that of determining whether or not a given graph contains a cycle that passes through every vertex exactly once and has numerous applications in different areas [3, 9, 10, 11]. HC is NP-complete for various classes of graphs including perfect graphs, planar bipartite graphs, grid graphs and 3-connected planar graphs but a polynomial time algorithm was presented for 4-connected planar graphs by Chiba and Nishizeki [5]. Garey, Johnson, and T...", "num_citations": "6\n", "authors": ["899"]}
{"title": "Improvements to GraphPack: A system to manipulate graphs and digraphs\n", "abstract": " This paper describes the improvements that we have carried out on GraphPack. the system that we have developed here. These improvements are specifically four fold. We have incorporated GraphPack to communicate with other systems: specifically. Mathernatica. Maple. Mat lab and Set Player. Further, we have incorporated commands to perform graph algorithms on MasPar. a SIMD machine. A lot of display routines are added for different embeddings of graphs. We also incorporated a 3D display of graphs. including rotation and swapping of vertices to get a better embedding. Finally, the language LiLa and the interpreter has been enhanced so as to write application programs easier.", "num_citations": "6\n", "authors": ["899"]}
{"title": "Critical path method: a review\n", "abstract": " PURCHASING PAPER COPIES AND MICROFICHE PROVIDES FASTER, MORE EFFICIENT SERVICE ON DOCUMENT REQUESTS. THE PREPAID COUPON IS A TABULATING CARD WITH A FACE VALUE OF THE PURCHASE PRICE OF A CLEARINGHOUSE DOCUMENT ($3.00 PAPER COPY OR 65 CENTS MICROFI CHE). IT IS YOUR METHOD OF PAYMENT, ORDER FORM, SHIPPING LABEL, AND RECEIPT OF SALE.", "num_citations": "6\n", "authors": ["899"]}
{"title": "Simulating the spread of influenza pandemic of 2009 considering international traffic\n", "abstract": " Pandemics have the potential to cause immense disruption and damage to communities and societies. In this paper, we model the influenza pandemic of 2009. We propose a hybrid model to determine how the pandemic spreads through the world. The model considers both SEIR-based model for local areas and the network model for global connection between countries referring to data on international travelers. Our interest is to reproduce the situation using the data of the early stage of the pandemic and to predict the future transition by extending the simulation cycle. Our simulation result predicts the second peak of the pandemic in the real world by considering the factors of tendency of seasonal influenza and people\u2019s reaction against the infection. Without considering these factors, the simulation does not predict the second peak of the pandemic in the real world. We conclude that the seasonal tendency and\u00a0\u2026", "num_citations": "5\n", "authors": ["899"]}
{"title": "Virtual design studio: Facilitating online learning and communication between US and Kenyan participants\n", "abstract": " This chapter analyzes the way in which existing instructional and communication technologies can bridge geographic, digital, and cultural divides and facilitate collaboration on an international scale. It highlights some existing Web-based technologies for distance learning and synchronous and asynchronous communication; and it explores their limitations in terms of collaboration between first-and third-world participants. Three disciplinary perspectives\u2014those of visual communication, anthropology, and computer science\u2014are presented at times in dialogue with each other. The synthesis of these three perspectives offers technical communicators an interdisciplinary understanding of important intercultural and technical issues involved in international online learning and health-related communication.In the summer of 2003, three multidisciplinary educators and one graduate student conducted a collaborative design workshop with laypeople in Kenya in a rural community resource center. In a participatory manner, a local group of bilingual (English/Luo) Kenyans designed HIV/AIDS prevention and awareness posters for their community. Simultaneously, by way of a virtual design studio (VDS) constructed out of existing communication technologies (eg, e-mail, online chat rooms, collaborative-learning software), the educators situated in front of their computer screens in Troy, New York, indirectly observed and participated in the Kenyans\u2019 design process. Understanding the intercultural communication and technical issues of international collaborations of this kind is the next frontier for the technical communication discipline as it broadens to\u00a0\u2026", "num_citations": "5\n", "authors": ["899"]}
{"title": "Describing Structure and Semantics of Graphs Using an RDF Vocabulary.\n", "abstract": " The RDF Graph Modeling Language (RGML) is a W3C RDF vocabulary to describe graph structures, including semantic information associated with a graph. Viewing general graphs as Web resources, RGML defines graph, node, and edge as RDF classes and attributes of graphs (such as label and weight) as RDF properties. Some of these RDF properties establish relationships between graph, node, and edge instances. RDF Statements about graph elements involve subjects, predicates and objects. Subjects and predicates are RDF Resources, while objects are either RDF Resources or RDF Literals. RGML uses the XML Schema datatypes for RDF Literals. RGML can be easily combined with other RDF vocabularies, for example, to add Dublin Core properties. RGML is very useful for describing webgraphs (the structure of a web site), web collections, and sitemaps.", "num_citations": "5\n", "authors": ["899"]}
{"title": "Coloring quadtrees\n", "abstract": " Consider solving linear elliptic partial differential systems on shared-memory parallel computers; with mesh generation and adaptive mesh refinement utilizing an underlying quadtree structure for data management, the terminal nodes of the quadtree can be colored so as to separate contiguous spatial regions that may be processed in parallel without conflict. The quadtree coloring algorithm given in [2, 4] has a linear time complexity and uses a maximum of six colors. However, it is restricted to those quadtrees which correspond to quadrilateral meshes with at most one-level difference across quadrant edges. In this paper, we present a linear eight-color algorithm that works for any quadtree by first six-coloring it and then removing coloring conflicts introduced by level differences with a fourth color pair in a consistent manner.", "num_citations": "5\n", "authors": ["899"]}
{"title": "Temporal analysis of literary and programming prose\n", "abstract": " Literary works reference a variety of globally shared themes including well-known people, events, and time periods. It is particularly interesting to locate patterns that are either invariant across time or exhibit a characteristic change across time, as they could imply something important about society that those works record. This paper suggests the use of Google n-gram viewer as a fast prototyping method for examining time-based properties over a rich sample of literary prose. Using this method, we find that some repeating periods of time, like Sunday, are referenced disproportionally, allowing us to pose questions such as why a day like Thursday is so unpopular. Furthermore, by treating software as a work of prose, we can apply a similar analysis to open-source software repositories and explore time-based relations in commit logs. Doing a simple statistical analysis on a few temporal keywords in the log records, we reinforce and weaken a few beliefs on how college students approach open source software. Finally, we help readers working on their own temporal analysis by comparing the fundamental differences between literary works and code repositories, and suggest blog or wiki as recently-emerging works.", "num_citations": "4\n", "authors": ["899"]}
{"title": "Influence of the Cold War upon influenza pandemic of 1957-1958\n", "abstract": " Influenza Pandemic of 1957-1958, also called Asian Flu Pandemic, was one of the most widespread pandemics in history. In this paper, we model the pandemic, considering the effect of the Cold War. There were some restrictions between Western and Eastern nations due to the Cold War during the pandemic. We expect that such restrictions influenced the spread of the pandemic. We propose a hybrid model to determine how the pandemic spread through the world. The model combines the SEIR-based model for local areas and the network model for global connection between countries. First, we reproduce the situation in 19 countries. Then, we run another experiment to find the influence of the war in the spread of the pandemic, simulation considering international relationships in different years. The simulation results show that the impact of the pandemic in each country was much influenced by international\u00a0\u2026", "num_citations": "4\n", "authors": ["899"]}
{"title": "Differential routing of MCMs-CIF: The ideal bifurcation medium\n", "abstract": " Recently published findings indicate that full differential routing of both VLSI chips and MCMs may be necessary to preserve noise margins in high performance systems. The optimal differential routing technique relies on routing signal pairs as logical nets and bifurcating the results to achieve a physical realization. Based on our research, CIF (Caltech. Interchange Format) has emerged as the ideal medium for the bifurcation process associated with differential routing of MCMs. Since MCMs have not as yet fully come of age, many of their design variables are under constrained. One of the greatest strengths of our finding is CIF's ability to handle the design uncertainty associated with current MCM system development, where both package and chip specification are typically in a tremendous state of flux throughout the engineering design cycle.< >", "num_citations": "4\n", "authors": ["899"]}
{"title": "Wiring pitch integrates MCM design domains\n", "abstract": " MCM designs require independent analysis in loosely coupled but interrelated design regimes. This paper proposes wiring pitch as the unifying thread in a real time iterative design environment that facilitates analysis in all pertinent domains. Actual system results demonstrate the strengths of the technique.< >", "num_citations": "4\n", "authors": ["899"]}
{"title": "Fibonacci networks\n", "abstract": " Several Interconnection networks have been proposed in literature for interconnecting computing elements. The interconnection network usually forms a regular pattern, which is exploited by the algorithms running on the network. Some of the commercially available networks are the hypercube, mesh, etc., which are highly regular. The advantage of using such regular networks is that the algorithms written for one network can be extended with minimal effort to larger versions of the same network. However, networks like the hypercube, mesh, etc, have one significant disadvantage; they do not scale in increments of one. A hypercube scales in exponents of two, and a mesh scales in order of n or k, in an n x k mesh.A tree is the cheapest interconnection network but has unacceptably poor communication and fault-tolerant properties. On the other hand, the complete graph Kn is highly reliable but is extremely expensive\u00a0\u2026", "num_citations": "4\n", "authors": ["899"]}
{"title": "A GUI for Parallel Code Generation\n", "abstract": " Developing applications for parallel architectures is a very complicated and arduous task even for expert programmers. There are several issues that must be considered, i.e., the number of CPU\u2019s available, vector processing capabilities, shared memory issues, process communications, and process synchronization, to name a few. Software developers have been trained to view the solution to a selected problem as a sequence of dependent steps or transitions which are applied to some input in an effort to produce the desired results. This approach to problem solving has been enforced by the traditional languages of C, Pascal, and Fortran. In this paper we describe the Interactive Visualization Tool (IVT) developed for the HICOR interactive parallelizing compiler. In particular, the IVT allows users to interactively manipulate a graphical representation of the program to be parallelized. Parameters describing\u00a0\u2026", "num_citations": "4\n", "authors": ["899"]}
{"title": "Concurrent Programming in Turbo Pascal\n", "abstract": " Concurrent programming in Turbo Pascal | BYTE ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search BYTE Periodical Home Latest Issue Archive Authors Affiliations Award Winners More HomeBrowse by TitlePeriodicalsBYTEVol. , No. Concurrent programming in Turbo Pascal article Concurrent programming in Turbo Pascal Share on Authors: Mukkai S Krishnamoorthy profile image Mukkai S. Krishnamoorthy View Profile , Snorri Agnarsson profile image Snorri Agnarsson View Profile Authors Info & Affiliations Publication: BYTEApril 1987 2citation 0 Downloads Metrics Total Citations2 Total Downloads0 Last 12 Months0 Last 6 weeks0 Get Citation Alerts New Citation Alert added! This alert has been \u2026", "num_citations": "4\n", "authors": ["899"]}
{"title": "ASHE (a simple HTML editor)-xhtml\n", "abstract": " This document is a description of a HTML (HyperText Markup Language) Editor (ASHE). HTML is the markup language used in the World Wide Web project and the NCSA Mosaic networked information browser. This editor does not cover HTML entirely but this tool will help you to create full HTML documents in no time.The name of this editor is ASHE (A Simple HTML Editor) and it is written in C and Motif OSF Windows. The visual interface is based on the XMosaic Visual interface since the purpose of this editor is to write HTML documents that can be browsed by Mosaic.", "num_citations": "3\n", "authors": ["899"]}
{"title": "An object-oriented intermediate code representation for the development of parallelization tools\n", "abstract": " We show that by developing an intermediate representation, which supports a formalized interface on which to construct parallelization tools, the mapping of the representation onto parallel architectures can be performed quickly and e ciently. A exible intermediate representation called HICOR (Hierarchical Intermediate Code Object Representation) is presented. HICOR is shown to facilitate the exploitation of parallel operations by providing an abstraction layer for performing both parallel transformations and code generation. An object oriented design approach has been employed in the development of HICOR. Source language constructs are transformed into specialized object classes. Inheritance properties provided by the object oriented paradigm are utilized to provide a common interface to each object in the HICOR representation. It is this interface that provides the needed consistency and exibility in which to construct tools for parallel compiler development that has since been lacking. In particular, we present a tool to perform Hierarchical Dependency Analysis. This tool allows program dependencies to be calculated on various grain sizes including: module, function, block, and instruction-level. This approach di ers from current methods in that explicit ow graph construction is not necessary. We have implemented a prototype system in C++ which incorporates the methodology described. The target architectures include a Sun 630 MP/4, Sequent Balance 21, and Stardent Titan. The construction of a high-level exible intermediate representation will provide a strong foundation for future work, eventually leading to a standardized interface in\u00a0\u2026", "num_citations": "3\n", "authors": ["899"]}
{"title": "Generalizations of line graphs and applications\n", "abstract": " Only loopless, undirected, finite graphs without multiple edges will be considered here. The more-orless standard graph terminology used here can be found in mos: text books on graph theory, eg [1, 5]. We denote a graph G=(V, E) w\u2019here V is the set of vertices, and E, the set of edges of G. An ever1 (oddjfactor fof G is a non-null spanning subgraph of G, such that the degree of every vertex in fis even (odd). A perfect matchbg in a graph G is a spanning subgraph in which the degree of every vertex is one. A line graph (or an edge graph j H of a given graph G is a graph in which each vertex corresponds to a distinct edge of G, and two vertices in H are adjacent if and only if the corresponding edges in C are incident to a common vertex. Graph G is referred to as an@ verse line graph (or root graph) of H. Following Harary and Nash-Williams [B] we denote H= L (G) and G= K\u2019(H).(The fact that the inverse line graph of a\u00a0\u2026", "num_citations": "3\n", "authors": ["899"]}
{"title": "Evolving graph representation and visualization\n", "abstract": " The study of evolution of networks has received increased interest with the recent discovery that many real-world networks possess many things in common, in particular the manner of evolution of such networks. By adding a dimension of time to graph analysis, evolving graphs present opportunities and challenges to extract valuable information. This paper introduces the Evolving Graph Markup Language (EGML), an XML application for representing evolving graphs and related results. Along with EGML, a software tool is provided for the study of evolving graphs. New evolving graph drawing techniques based on the force-directed graph layout algorithm are also explored. Our evolving graph techniques reduce vertex movements between graph instances, so that an evolving graph can be viewed with smooth transitions", "num_citations": "2\n", "authors": ["899"]}
{"title": "A Design of Complementary Community Currencies for Education.\n", "abstract": " This paper proposes a design for complementary community currencies for education communities to boost cooperation of the more advanced students with the less advanced ones. Its design follows two goals: motivating students to learn by doing extra homework (effort) and share knowledge with younger students (tutoring), and shifting the role of teachers towards a more supervisory, tutoring and dynamic tasks. The hypothesis, following a Brazilian example, is that colleges may accept as payment for their tuitions not only conventional legal currencies, but also educational complementary currencies. The traditional grants policies based on personal effort will be paid with bunnies, and modern community tutoring effort will be paid with knowls. The bunnies and knowls will be obtained as a reward of doing homework and providing help for homework, respectively, and as an expected result, students will have more solid knowledge background at all levels resulting from their boosted personal and community effort.", "num_citations": "2\n", "authors": ["899"]}
{"title": "Condorcet winner probabilities-a statistical perspective\n", "abstract": " A Condorcet voting scheme chooses a winning candidate as one who defeats all others in pairwise majority rule. We provide a review which includes the rigorous mathematical treatment for calculating the limiting probability of a Condorcet winner for any number of candidates and value of  odd or even and with arbitrary ran k order probabilities, when the voters are independent. We provide a compact and complete Table for the limiting probability of a Condorcet winner with three candidates and arbitrary rank order probabilities. We present a simple proof of a result of May to show the limiting probability of a Condorcet winner tends to zero as the number of candidates tends to infinity. We show for the first time that the limiting probability of a Condorcet winner for any given number of candidates  is monotone decreasing in  for the equally likely case. This, in turn, settles the conjectures of Kelly and Buckley and Westen for the case . We prove the validity of Gillett's conjecture on the minimum value of the probability of a Condorcet winner for  and any . We generalize this result for any  and  and obtain the minimum solution and the minimum probability of a Condorcet winner.", "num_citations": "2\n", "authors": ["899"]}
{"title": "Digital Library Portal using Semantic Tools in WWWPal\n", "abstract": " The WWWPal system and associated languages and tools (such as LOGML, XGMML, webbot and the graph browser) have been developed to perform syntactic analysis of web sites. In this paper, using WWWPal and semantic analysis tools (such as RGML, clustering and the graph browser) we construct digital library portals. We describe a method of obtaining the portal.", "num_citations": "2\n", "authors": ["899"]}
{"title": "Optimal differential routing based on finite state machine theory\n", "abstract": " Noise margins in high speed digital systems continue to erode. Full differential signal routing provides a mechanism for deferring these effects. This paper proposes a three stage routing process for solving the adjacent placement routing problem of differential signal pairs, and proves that it is optimal. The process views differential pairs as logical nets; routes the logical nets; then bifurcates the result to achieve a physical realization. Finite state machine theory provides the critical theoretical underpinning and formal proof of correctness necessary for linear time bifurcation. Regular expressions map the theoretical solution to an appropriate implementation strategy that employs feature vectors for net recognition.", "num_citations": "2\n", "authors": ["899"]}
{"title": "Chip pad migration is a key component to high performance MCM design\n", "abstract": " As Multichip Modules (MCMs) evolve from niche solutions to necessary ingredients of high performance computing systems, this change must be reflected in the associated CAD tools for MCM system design. Given the transmission velocities of modern thin film substrates, conventional design techniques where chips are developed in isolation from the substrate fall short of producing optimal solutions. Critical to the success of these tools is the ability to influence chip pad placement. Our research indicates that an integrated chip/MCM codesign environment should be established. MCM CAD tools must provide advice for and accommodate an interactive pad migration facility, where chip designers are provided recommended signal pad locations that contribute to the optimization of the overall system.", "num_citations": "2\n", "authors": ["899"]}
{"title": "Table Image Understanding\n", "abstract": " We are developing a system to perform table image understanding. The recognition problem is to locate and characterize the cells of a table in a two-dimensional black and white document image. More meaning is implicit in the geometric location of the image regions (cells) of a table than in most other document types. Ideally, we wish to develop a strategy for extracting the underlying relational information from the image given its visual clues such as ruling lines, space separations, etc. Various strategies of achieving this physical to logical mapping of table information are presented.", "num_citations": "2\n", "authors": ["899"]}
{"title": "Lucid and efficient case analysis\n", "abstract": " This paper describes a new scheme for building static search trees, using multiway radix search trees. We present this method for code generation of switch statements in imperative languages. We show that, for sparse case sets, the method produces faster code on average than existing methods, requiring O (1) time with a small constant for the average search. We then apply this method to the problem of code generation for generic functions in object-oriented languages, and nd that its use improves clarity as well as e ciency.", "num_citations": "2\n", "authors": ["899"]}
{"title": "The Stable Marriage Problem: Structure and Algorithms (Dan Gusfield and Robert W. Irving)\n", "abstract": " The book consists of two parts. Part pro-vides an introduction to the Simulation An-nealing algorithm, its convergence properties (Chapters 2 and 3), empirical analysis ofpolynomial-time cooling schedules (Chapter 4) and illustrates the practical use of Simulated An-nealing for a number of combinatorial opti-mization problems. Neither the theory of convergence nor the analysis of polynomial time cooling schedules are treated in depth. Instead, the authors\u2019 intention was to provide an easyto-read treatment of the fundamental facts to-gether with a large number of references for further reading (the bibliography has of more than 200 entries and seems to contain everything relevant in the context of Simulated An-nealing).The main concern ofthe present book is to investigate the use of Simulated Annealing for designing and analyzing so-called Boltzmann Machines (Part II). Roughly, a Boltzmann Machine is a neural\u00a0\u2026", "num_citations": "2\n", "authors": ["899"]}
{"title": "An object-based parallel programming assistant\n", "abstract": " Programmers of sequential and parallel computers share the objective of developing fast, reliable programs as efficiently as possible. Already, considerable effort has been made to develop tools and techniques for sequential computers. Several approaches have been devised to meet the parallel programming challenge. Sequential languages have been adapted for parallel computers; new parallel languages designed; and tools developed which aid the programmer in detecting parallel code. A parallel programming assistant can aid the user in several ways: it can carry out tasks that are simple but mundane to the user, it can make comprehension easier for the user by summarizing program information; and it can cooperate with the user in doing a complex task, thus combining its own knowledge   with that of the user's. We have developed a parallel programming assistant [1] which supports object-based\u00a0\u2026", "num_citations": "2\n", "authors": ["899"]}
{"title": "The Church-Rosser property and special Thue systems\n", "abstract": " In an earlier paper we gave an O(|T|3) algorithm for testing the Church-Rosser property of Thue systems, where |T| is the total size of the Thue system. Here we improve that bound to O(\u03ba|T|), where \u03ba is the number of rules in T, in the case when the Thue system is special, i.e., when all its rule are of the form (\u03be, \u03bb) where \u03bb is the empty string. Also obtained are several results on special Thue systems which may be of independent interest.", "num_citations": "2\n", "authors": ["899"]}
{"title": "A note on\" Some simplified NP-complete graph problems\"\n", "abstract": " The directed Hamiltonian circuit problem with node-degree bounded by 3-out, 3-in has been shown to be NP. complete [I]. This implies that the directed Hamiltonian circuit with node-degree bounded by 3-out, 1-in or 1-out, 3-in is NP-complete by the following construction~", "num_citations": "2\n", "authors": ["899"]}
{"title": "Tree graphs and tree numbers\n", "abstract": " The concept of the tree graph of a given connected graph was first introduced and studied by Cummins [2]. Further properties of tree graphs were explored in [1], [6]-[10]. In this correspondence, some additional properties of tree graphs are brought out. A related concept of tree numbers is introduced and explored.", "num_citations": "2\n", "authors": ["899"]}
{"title": "Interactive Complexity: Software Metrics from an Ecosystem Perspective\n", "abstract": " With even the most trivial of applications now being written on top of millions of lines code of libraries, API's, and programming languages, much of the complexity that used to exist when designing software has been abstracted away to allow programmers to focus on primarily business logic. With each application relying so heavily on the ecosystem it was designed to run in, whether that is limited to a local system or includes dependencies on machines connected by networks, measuring the complexity of these systems can no longer be done simply by observing the code internal to the application; we also need to account for its external interactions. This is especially important when considering issues of security, which becomes more vital as our healthcare, financial, and automobiles rely on complicated software systems. We propose Interactive Complexity, which provide a quantitative measure of how intertwined parts of the system are. Some of the most well-known software complexity metrics out there are the metrics in the CK-metric suite; these metrics are designed for use in measuring object oriented systems, but we believe they can be adapted to help measure the interaction of software systems. Our experimental results show strong correlations between the number of bugs fixed in a release and the value of some of these metrics in systems of sufficient scale.", "num_citations": "1\n", "authors": ["899"]}
{"title": "TECHNIQUES FOR COMPUTER-ASSISTED GRADING IN COMPUTER SCIENCE CURRICULA\n", "abstract": " As more curricula integrate computational thinking, designing assessments that are compatible with both student engagement and educator efficacy becomes more urgent. In this paper we discuss the potential role of complexity metrics as an aide to assessing student comprehension. In this first stage of the research, we examined the relationship between manually assigned scores and computer generated scores. While the sample size was too small for statistical results, the positive correlation suggests that this is a plausible research direction.", "num_citations": "1\n", "authors": ["899"]}
{"title": "Simulating the spread of pandemics with different origins considering international traffic\n", "abstract": " Pandemics have the potential to cause immense disruption and damage to communities and societies. In this paper, we propose a hybrid model to determine how the pandemic spread through the world. The model combines the SEIR-based model for local areas and the network model for global connection between countries. We simulate the potential pandemic with different origins and find how the difference of the origin of a pandemic influences the impact in the world. We investigate the travelers network which is derived from real data, and simulate 65 countries, and see how the pandemic spread through the world from different 14 countries as origins of pandemic. We compare the difference in terms of the impact in countries and the impact in the world. As a result, the impact in the world increases when pandemic originates from the United States, India, and China.", "num_citations": "1\n", "authors": ["899"]}
{"title": "Observation of network structure in Amazon.com\n", "abstract": " Amazon.com is among the largest bookstores on the Internet. It provides the sales rank of each book. Our hypothesis is as follows: if a book has low sales rank (i.e., it is well-sold), the related book also has a low sales rank. In the small world principle, if a network is connected, any two nodes are connected with relatively small number of links. If this hypothesis is true, any book can link to a bestseller book with small number of distance by linking some related books. In this paper, we design an algorithm to ascertain our hypothesis, and analyze the network structure of Amazon.com.", "num_citations": "1\n", "authors": ["899"]}
{"title": "From isothetic tessellations to web tables\n", "abstract": " The properties of idealized tables are examined with a view to creating a taxonomy of tessellations suitable for displaying tabular data. XY tessellations that can be obtained by a divide-and-conquer method are asymptotically only an infinitesimal fraction of all partitions of a rectangle into rectangles. Admissible tessellations are the even smaller subset of all partitions that can be produced by successive guillotine cuts and that also correspond to the structures of published tables. Many of these, layout-equivalent admissible tables, can be processed automatically. Their structures can be conveniently represented by XY trees, which facilitate relating hierarchical row and column headings to content cells. A formal grammar is proposed for characterizing the XY trees of layout-equivalent admissible tessellations. Algorithms are presented for transforming a tessellation into an XY tree and for extracting multidimensional\u00a0\u2026", "num_citations": "1\n", "authors": ["899"]}
{"title": "A study of the Sudoku graph family\n", "abstract": " This paper describes the properties of a family of Sudoku graphs, defined from valid solutions to Sudoku puzzles. We also analyze backtracking algorithms with hard instances of the problem. Finally, we describe some codes that can be generated from Sudoku solutions.", "num_citations": "1\n", "authors": ["899"]}
{"title": "Consideration of fluctuation and factors in election with a simulation model\n", "abstract": " In elections, a voter changes his/her opinion and the voting result in a society fluctuates. There are many factors that determine the fluctuation and such factors reflect the characteristics of the society. In the US Presidential Election, each state approves a party, usually either Republican or Democrat, based on the voting result, but the percentage of the approval changes at every election. Our interest is to determine whether the fluctuation of percentage of approval for a party in a state has a relationship with the state's characteristic. In this paper, we propose a simple model to simulate an election with four types of agents, determine how these agents' characteristics influence the fluctuation of the voting result, and compare the result with historical data. Finally, we conclude how such factors relate to the fluctuation of the election results in the society.", "num_citations": "1\n", "authors": ["899"]}
{"title": "Real-Time Monitoring and Alerting of Web Usage\n", "abstract": " Web usage mining is an active research area for its uses in web site maintenance and for the potential economical impact. In the past, research has focused on off-line statistical analysis, learning the user behavior and on identifying most frequently visited structures. In this paper, we propose and study on-line monitoring of web usage. We devise efficient real-time algorithms for identifying most visited sites and site-paths. We further provide advance warning when there is a potential denial of service attack. In our system named W3 live, we have implemented algorithms and event warnings using LOGML and the graph library of the WWWPal [2] suite. Finally, we analyze the performance of our system.", "num_citations": "1\n", "authors": ["899"]}
{"title": "Using rules to specify classification strategies in the credit card industry\n", "abstract": " Classifying accounts is a critical part of efficiently servicing credit cards. The use of rules enables natural specification of classification strategies. A problem we call the Rule Coverage Problem (RCP) arrises when rules are employed for specifying a classification strategy, and we develop and compare three approaches for solving this problem.", "num_citations": "1\n", "authors": ["899"]}
{"title": "Input/Output Pad Placement Problem\n", "abstract": " We propose efficient heuristics for placing input/output (I/O) pads around the VLSI chip boundary. The heuristics are based on the circuit connectivity and do not require the placement of cells. This is useful for cell placement methods that require the knowledge of I/O pad placement. Using these heuristics, several pad placement candidates can be generated as input to cell placement algorithms.", "num_citations": "1\n", "authors": ["899"]}
{"title": "Iterative Networks and their Properties\n", "abstract": " We introduce three new families of undirected graphs as a basis for interconnection networks. The three families are based on Fibonacci graphs, Relatively-prime graphs, and", "num_citations": "1\n", "authors": ["899"]}
{"title": "Protenv: a programming environment for protocol development\n", "abstract": " The design and functionality of Protenv, a programming environment for protocol development, is described. Protenv runs under X windows and allows the user to develop protocols using Petri nets and Estelle. The combination of Petri nets and Estelle provides a precise protocol specification as well as a powerful way for graphical visualization and verification of protocols. The use of Protenv to specify, analyze, and implement the manufacturing message specification (MMS) is also discussed.<>", "num_citations": "1\n", "authors": ["899"]}
{"title": "Formal specification of syntax directed editor\n", "abstract": " Formal specification of syntax directed editor | Proceedings of the second conference on Software development tools, techniques, and alternatives ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleProceedingsProceedings of the second conference on Software development tools, techniques, and alternativesFormal specification of syntax directed editor Article Formal specification of syntax directed editor Share on Authors: Ebba Thora Hvannberg profile image Ebba Hvannberg View Profile , Mukkai S Krishnamoorthy profile image Mukkai S. Krishnamoorthy View Profile Authors Info & Affiliations Publication: Proceedings of the second \u2026", "num_citations": "1\n", "authors": ["899"]}
{"title": "An algebraic implementation of packages\n", "abstract": " An implementation of packages is described. The implementation is based on viewing packages as substitutions. Using a few operations on packages it is possible to build any package, from a small collection of basic packages. Generic packages can be built, that can be used as building blocks for new packages. The packages defined by the model lend themselves well to algebraic manipulation.", "num_citations": "1\n", "authors": ["899"]}
{"title": "The generalized towers of Hanoi\n", "abstract": " Kenersl. lLm4 tomz'of HanmL pz, oblen: 11.8 to t\u00a2 sn. ste: the tout. oct n~ m'to me ot the o~, vNsnt pop: in tho: lblgt Imsi. ble lo4al iron.~ tclJm~ e~ lm b~ bern~ seuam~ m~ lolvedL aul m d,, mneo4 Web~ u~~ mb~~ 8\u00a2 n~~~~ t~ l Imtb~~ ob 1941.~ am ot the ll. Ku8~ m therein us pt~~ l~ md~ K~ nFW~~ m4.,= v). mere~ J. 8 the mmbor of emr~ t peKs~ n tbo mmbors~~: l.=~ t~).=~~,=.,.,,, w J,,~ rt~. oJ. oat= adw~~ tz~ nov..~~ r ll4e c~ bov~\u00a2~\u00a3~ rv,,. pt~-c~ pressionj Ol~ er/k~ n~ e", "num_citations": "1\n", "authors": ["899"]}