{"title": "A survey of software testing practices in Canada\n", "abstract": " Software testing is an important activity in the software development life-cycle. In an earlier study in 2009, we reported the results of a regional survey of software testing practices among practitioners in the Canadian province of Alberta. To get a larger nationwide view on this topic (across Canada), we conducted a newer survey with a revised list of questions in 2010. Compared to our previous Alberta-wide survey (53 software practitioners), the nation-wide survey had larger number of participants (246 practitioners). We report the survey design, execution and results in this article. The survey results reveal important and interesting findings about software testing practices in Canada. Whenever possible, we also compare the results of this survey to other similar studies, such as the ones conducted in the US, Sweden and Australia, and also two previous Alberta-wide surveys, including our 2009 survey. The results of\u00a0\u2026", "num_citations": "160\n", "authors": ["183"]}
{"title": "Graphical user interface (GUI) testing: a systematic mapping\n", "abstract": " ContextGUI testing is system testing of a software that has a graphical-user interface (GUI) front-end. Because system testing entails that the entire software system, including the user interface, be tested as a whole, during GUI testing, test cases\u2014modeled as sequences of user input events\u2014are developed and executed on the software by exercising the GUI\u2019s widgets (e.g., text boxes and clickable buttons). More than 230 articles have appeared in the area of GUI testing since 1991.ObjectiveIn this paper, we study this existing body of knowledge using a systematic mapping (SM).MethodThe SM is conducted using the guidelines proposed by Petersen et al. We pose three sets of research questions. We define selection and exclusion criteria. From the initial pool of 230 articles, published in years 1991\u20132011, our final pool consisted of 136 articles. We systematically develop a classification scheme and map the\u00a0\u2026", "num_citations": "155\n", "authors": ["183"]}
{"title": "When and what to automate in software testing? A multi-vocal literature review\n", "abstract": " ContextMany organizations see software test automation as a solution to decrease testing costs and to reduce cycle time in software development. However, establishment of automated testing may fail if test automation is not applied in the right time, right context and with the appropriate approach.ObjectiveThe decisions on when and what to automate is important since wrong decisions can lead to disappointments and major wrong expenditures (resources and efforts). To support decision making on when and what to automate, researchers and practitioners have proposed various guidelines, heuristics and factors since the early days of test automation technologies. As the number of such sources has increased, it is important to systematically categorize the current state-of-the-art and -practice, and to provide a synthesized overview.MethodTo achieve the above objective, we have performed a Multivocal Literature\u00a0\u2026", "num_citations": "153\n", "authors": ["183"]}
{"title": "Web application testing: A systematic literature review\n", "abstract": " ContextThe web has had a significant impact on all aspects of our society. As our society relies more and more on the web, the dependability of web applications has become increasingly important. To make these applications more dependable, for the past decade researchers have proposed various techniques for testing web-based software applications. Our literature search for related studies retrieved 193 papers in the area of web application testing, which have appeared between 2000 and 2013.ObjectiveAs this research area matures and the number of related papers increases, it is important to systematically identify, analyze, and classify the publications and provide an overview of the trends and empirical evidence in this specialized field.MethodsWe systematically review the body of knowledge related to functional testing of web application through a systematic literature review (SLR) study. This SLR is a\u00a0\u2026", "num_citations": "106\n", "authors": ["183"]}
{"title": "A systematic literature review of literature reviews in software testing\n", "abstract": " ContextAny newcomer or industrial practitioner is likely to experience difficulties in digesting large volumes of knowledge in software testing. In an ideal world, all knowledge used in industry, education and research should be based on high-quality evidence. Since no decision should be made based on a single study, secondary studies become essential in presenting the evidence. According to our search, over 101 secondary studies have been published in the area of software testing since 1994. With this high number of secondary studies, it is important to conduct a review in this area to provide an overview of the research landscape in this area.ObjectiveThe goal of this study is to systematically map (classify) the secondary studies in software testing. We propose that tertiary studies can serve as summarizing indexes which facilitate finding the most relevant information from secondary studies and thus supporting\u00a0\u2026", "num_citations": "99\n", "authors": ["183"]}
{"title": "Citations, research topics and active countries in software engineering: A bibliometrics study\n", "abstract": " Context: An enormous number of papers (more than 70,000) have been published in the area of Software Engineering (SE) since its inception in 1968. To better characterize and understand this massive research literature, there is a need for comprehensive bibliometrics assessments in this vibrant field.Objective: The objective of this study is to utilize automated citation and topic analysis to characterize the software engineering research literature over the years. While a few bibliometrics studies have appeared in the field of SE, this article aims to be the most comprehensive bibliometrics assessments in this vibrant field.Method: To achieve the above objective, we report in this paper a bibliometrics study with data collected from Scopus database consisting of over 70,000 articles. For thematic analysis, we used topic modeling to automatically generate the most probable topic distributions given the data.Results: We\u00a0\u2026", "num_citations": "84\n", "authors": ["183"]}
{"title": "Smells in software test code: A survey of knowledge in industry and academia\n", "abstract": " As a type of anti-pattern, test smells are defined as poorly designed tests and their presence may negatively affect the quality of test suites and production code. Test smells are the subject of active discussions among practitioners and researchers, and various guidelines to handle smells are constantly offered for smell prevention, smell detection, and smell correction. Since there is a vast grey literature as well as a large body of research studies in this domain, it is not practical for practitioners and researchers to locate and synthesize such a large literature. Motivated by the above need and to find out what we, as the community, know about smells in test code, we conducted a \u2018multivocal\u2019 literature mapping (classification) on both the scientific literature and also practitioners\u2019 grey literature. By surveying all the sources on test smells in both industry (120 sources) and academia (46 sources), 166 sources in total, our\u00a0\u2026", "num_citations": "79\n", "authors": ["183"]}
{"title": "A replicated survey of software testing practices in the Canadian province of Alberta: What has changed from 2004 to 2009?\n", "abstract": " Software organizations have typically de-emphasized the importance of software testing. In an earlier study in 2004, our colleagues reported the results of an Alberta-wide regional survey of software testing techniques in practice. Five years after that first study, the authors felt it is time to replicate the survey and analyze what has changed and what not from 2004 to 2009. This study was conducted during the summer of 2009 by surveying software organizations in the Canadian province of Alberta. The survey results reveal important and interesting findings about software testing practices in Alberta, and point out what has changed from 2004 to 2009 and what not. Note that although our study is conducted in the province of Alberta, we have compared the results to few international similar studies, such as the ones conducted in the US, Turkey, Hong Kong and Australia, The study should thus be of interest to all testing\u00a0\u2026", "num_citations": "64\n", "authors": ["183"]}
{"title": "Test automation: not just for test execution\n", "abstract": " To work more efficiently and effectively, test engineers must be aware of various automated-testing strategies and tools that assist test activities other than test execution. However, automation doesn't come for free, so it must be carefully implemented.", "num_citations": "55\n", "authors": ["183"]}
{"title": "Highly-cited papers in software engineering: The top-100\n", "abstract": " ContextAccording to the search reported in this paper, as of this writing (May 2015), a very large number of papers (more than 70,000) have been published in the area of Software Engineering (SE) since its inception in 1968. Citations are crucial in any research area to position the work and to build on the work of others. Identification and characterization of highly-cited papers are common and are regularly reported in various disciplines.ObjectiveThe objective of this study is to identify the papers in the area of SE that have influenced others the most as measured by citation count. Studying highly-cited SE papers helps researchers to see the type of approaches and research methods presented and applied in such papers, so as to be able to learn from them to write higher quality papers which will likely receive high citations.MethodTo achieve the above objective, we conducted a study, comprised of five research\u00a0\u2026", "num_citations": "54\n", "authors": ["183"]}
{"title": "A bibliometric analysis of the Turkish software engineering research community\n", "abstract": " This paper presents a bibliometric analysis of the Turkish software engineering (SE) community (researchers and institutions). The bibliometric analysis has been conducted based on the number of papers published in the software-engineering-related venues and indexed in the Scopus academic search engine until year 2014. According to the bibliometric analysis, the top-ranked institution is Middle East Technical University, and the top-ranked scholar is Ay\u015fe Ba\u015far Bener (formerly with Bo\u011fazi\u00e7i University and now with Ryerson University in Canada). The analysis reveals other important findings and presents a set of implications for the Turkish SE community and stakeholders (e.g., funding agencies and decision makers) such as the followings: (1) Turkey produces only about 0.49\u00a0% of the world-wide SE knowledge, as measured by the number of papers in Scopus, which is very negligible unfortunately\u00a0\u2026", "num_citations": "50\n", "authors": ["183"]}
{"title": "Applying peer reviews in software engineering education: An experiment and lessons learned\n", "abstract": " Based on the demonstrated value of peer reviews in the engineering industry, numerous industry experts have listed it at the top of the list of desirable development practices. Experience has shown that problems (defects) are eliminated earlier if a development process incorporates peer reviews and that these reviews are as effective as or even more effective than testing. It is therefore important for engineering students to peer review each other's work during design projects. However, surprisingly, few engineering courses in universities and colleges include peer-review activities in their design projects. The author thus decided to incorporate peer reviews in the design project of a senior software engineering course in two offerings of the course. The purpose of this article is to present the experimental findings, lessons learned, possible challenges, and recommendations that may be used to promote learning and\u00a0\u2026", "num_citations": "48\n", "authors": ["183"]}
{"title": "What industry wants from academia in software testing? Hearing practitioners\u2019 opinions\n", "abstract": " The level of industry-academia collaboration (IAC) in software engineering in general and in software testing in particular is quite low. Many researchers and practitioners are not collaborating with the\" other side\" to solve industrial problems. To shed light on the above issue and to characterize precisely what industry wants from academia in software testing, we solicited practitioners' opinions on their challenges in different testing activities and also the particularly relevant topics that they want the research community to work on. This short paper aims to draw the community's attention to the important issue of strengthening IAC with the hope of more IAC in software testing in the areas of most importance to the industry.", "num_citations": "46\n", "authors": ["183"]}
{"title": "Choosing the right test automation tool: a grey literature review of practitioner sources\n", "abstract": " Background: Choosing the right software test automation tool is not trivial, and recent industrial surveys indicate lack of right tools as the main obstacle to test automation. Aim: In this paper, we study how practitioners tackle the problem of choosing the right test automation tool. Method: We synthesize the\" voice\" of the practitioners with a grey literature review originating from 53 different companies. The industry experts behind the sources had roles such as\" Software Test Automation Architect\", and\" Principal Software Engineer\". Results: Common consensus about the important criteria exists but those are not applied systematically. We summarize the scattered steps from individual sources by presenting a comprehensive process for tool evaluation with 12 steps and a total of 14 different criteria for choosing the right tool. Conclusions: The practitioners tend to have general interest in and be influenced by related grey\u00a0\u2026", "num_citations": "44\n", "authors": ["183"]}
{"title": "Developing, verifying and maintaining high-quality automated test scripts\n", "abstract": " With the increasing importance, size, and complexity of automated test suites, the need exists for suitable methods and tools to develop, assess the quality of, and maintain test code (scripts) in parallel with regular production (application) code. A recent review paper called this subarea of software testing software test code engineering (STCE). This article summarizes STCE tools, techniques, and guidelines. It also presents specific quantitative examples in this area based on experience in projects and raises important issues practitioners and researchers must address to further advance this field.", "num_citations": "43\n", "authors": ["183"]}
{"title": "Environmental crisis in Lake Urmia, Iran: A systematic review of causes, negative consequences and possible solutions\n", "abstract": " Lake Urmia, located in NW of Iran, is the third largest salt-water lake on earth. Due to poor water management and construction of 48+ dams, more than 70% of the lake surface areas has already dried up. As a result, the retrieval of the lake shore has left a salt deposit behind and exposed to wind. Studies have predicted that salt storms from the dried lake will have serious impacts on the lives of 76 million people living around the lake. We are undertaking a systematic literature review in this article on a pool of 36 papers carefully selected from the literature, which have studied the Lake Urmia crisis in recent years. The systematic review synthesizes the evidence and insights reported in the existing body of knowledge in this area. This article is aimed to raise awareness and capture the attention of international organizations, NGOs and activists in the international arena and neighbouring countries. We hope that this review article would increase awareness for this major international environmental crisis in making and alert environmental and governmental decision makers in the countries around the lake.", "num_citations": "43\n", "authors": ["183"]}
{"title": "Industry\u2013academia collaborations in software testing: Experience and success stories from Canada and Turkey\n", "abstract": " Collaboration between industry and academia supports improvement and innovation in industry and helps to ensure industrial relevance in academic research. However, many researchers and practitioners believe that the level of joint industry\u2013academia collaborations (IAC) in software engineering (SE) is still relatively very low, compared to the amount of activity in each of the two communities. The goal of the empirical study reported in this paper is to characterize a set of collaborative industry\u2013academia R&D projects in the area of software testing conducted by the authors (based in Canada and Turkey) with respect to a set of challenges, patterns and anti-patterns identified by a recent Systematic Literature Review study, with the aim of contributing to the body of evidence in the area of IAC, for the benefit of SE researchers and practitioners in conducting successful IAC projects in software testing and in\u00a0\u2026", "num_citations": "42\n", "authors": ["183"]}
{"title": "A search-based approach for cost-effective software test automation decision support and an industrial case study\n", "abstract": " Test automation is a widely-used approach to reduce the cost of manual software testing. However, if it is not planned or conducted properly, automated testing would not necessarily be more cost effective than manual testing. Deciding what parts of a given System Under Test (SUT) should be tested in an automated fashion and what parts should remain manual is a frequently-asked and challenging question for practitioner testers. In this study, we propose a search-based approach for deciding what parts of a given SUT should be tested automatically to gain the highest Return On Investment (ROI). This work is the first systematic approach for this problem, and significance of our approach is that it considers automation in the entire testing process (i.e., from test-case design, to test scripting, to test execution, and test-result evaluation). The proposed approach has been applied in an industrial setting in the context of\u00a0\u2026", "num_citations": "41\n", "authors": ["183"]}
{"title": "A tester-assisted methodology for test redundancy detection\n", "abstract": " Test redundancy detection reduces test maintenance costs  and also ensures the integrity of test suites. One of the most widely used approaches for this purpose is based on coverage information. In a recent work, we have shown that although this information can be useful in detecting redundant tests, it may suffer from large number of false-positive errors, that is, a test case being identified as redundant while it is really not. In this paper, we propose a semiautomated methodology to derive a reduced test suite from a given test suite, while keeping the fault detection effectiveness unchanged. To evaluate the methodology, we apply the mutation analysis technique to measure the fault detection effectiveness of the reduced test suite of a real Java project. The results confirm that the proposed manual interactive inspection process leads to a reduced test suite with the same fault detection ability as the original test suite.", "num_citations": "36\n", "authors": ["183"]}
{"title": "A genetic algorithm-based stress test requirements generator tool and its empirical evaluation\n", "abstract": " Genetic algorithms (GAs) have been applied previously to UML-driven stress test requirements generation with the aim of increasing chances of discovering faults relating to network traffic in distributed real-time systems. However, since evolutionary algorithms are heuristic, their performance can vary across multiple executions, which may affect robustness and scalability. To address this, we present the design and technical detail of a UML-driven, GA-based stress test requirements generation tool, together with its empirical analysis. The main goal is to analyze and improve the applicability, efficiency, and effectiveness and also to validate the design choices of the GA used in the tool. Findings of the empirical evaluation reveal that the tool is robust and reasonably scalable when it is executed on large-scale experimental design models. The study also reveals the main bottlenecks and limitations of the tools, e.g\u00a0\u2026", "num_citations": "35\n", "authors": ["183"]}
{"title": "Empirical analysis of a genetic algorithm-based stress test technique\n", "abstract": " Evolutionary testing denotes the use of evolutionary algorithms, eg, Genetic Algorithms (GAs), to support various test automation tasks. Since evolutionary algorithms are heuristics, their performance and output efficiency can vary across multiple runs. Therefore, there is a strong need to empirically investigate the capacity of evolutionary test techniques to achieve the desired objectives (eg, generate stress test cases) and their scalability in terms of the complexity of the System Under Test (SUT), the inputs, and the control parameters of the search algorithms. In a previous work, we presented a GA-based UML-driven, stress test technique aimed at increasing chances of discovering faults related to network traffic in distributed real-time software. This paper reports a carefully-designed empirical study which was conducted to analyze and improve the applicability, efficiency and effectiveness of the above GA-based\u00a0\u2026", "num_citations": "30\n", "authors": ["183"]}
{"title": "Selecting the right topics for industry-academia collaborations in software testing: an experience report\n", "abstract": " The global software industry and the Software Engineering (SE) academia are two large communities. However, unfortunately, the level of joint industry-academia collaborations (IAC) in SE is still relatively very low, compared to the amount of activity in each of the two communities. Selecting the right topic for a new IAC has been reported to be challenging and often a deal-maker or-breaker for the start of IACs. Motivated by the above need, the goal of this paper is to propose experience-based guidelines from our 10+ software testing IACs in the past several years in Canada and Turkey to effectively and efficiently select right topics for IACs in software testing (also easily generalizable to other areas of SE), for the benefit of SE researchers and practitioners in starting new IACs. The experience and evidence supporting the guidelines in this paper are drawn from the authors' past projects and also seven on-going\u00a0\u2026", "num_citations": "28\n", "authors": ["183"]}
{"title": "Test redundancy measurement based on coverage information: Evaluations and lessons learned\n", "abstract": " Measurement and detection of redundancy in test suites attempt to achieve test minimization which in turn can help reduce test maintenance costs, and to also ensure the integrity of test cases. Test suite reduction based on coverage information has been discussed in many previous works. However, the applications of such techniques on real test suites and realistic measurements of redundancy have not yet been experimented thoroughly. To address such a need, we formulate in this paper two experimental metrics for coverage-based measurement of test redundancy in the context of JUnit test suites. We then evaluate the approach by measuring the redundancy of four real Java projects. The automated measures are compared with manual redundancy decisions (performed through an inspection by a tester). The results and lessons learned are interesting and somewhat surprising in that besides they show\u00a0\u2026", "num_citations": "28\n", "authors": ["183"]}
{"title": "Multi-objective regression test selection in practice: An empirical study in the defense software industry\n", "abstract": " ContextExecuting an entire regression test-suite after every code change is often costly in large software projects. To cope with this challenge, researchers have proposed various regression test-selection techniques.ObjectiveThis paper was motivated by a real industrial need to improve regression-testing practices in the context of a safety-critical industrial software in the defence domain in Turkey. To address our objective, we set up and conducted an \u201caction-research\u201d collaborative project between industry and academia.MethodAfter a careful literature review, we selected a conceptual multi-objective regression-test selection framework (called MORTO) and adopted it to our industrial context by developing a custom-built genetic algorithm (GA) based on that conceptual framework. GA is able to provide full coverage of the affected (changed) requirements while considering multiple cost and benefit factors of\u00a0\u2026", "num_citations": "26\n", "authors": ["183"]}
{"title": "Quantity versus impact of software engineering papers: a quantitative study\n", "abstract": " According to the data from the Scopus publication database, as analyzed in several recent studies, more than 70,000 papers have been published in the area of Software Engineering (SE) since late 1960\u2019s. According to our recent work, 43% of those papers have received no citations at all. Since citations are the most commonly used metric for measuring research (academic) impact, these figures raise questions (doubts) about the (non-existing) impact of such a large set of papers. It is a reality that typical academic reward systems encourage researchers to publish more papers and do not place a major emphasis on research impact. To shed light on the issue of volume (quantity) versus citation-based impact of SE research papers, we conduct and report in this paper a quantitative bibliometrics assessment in four aspects: (1) quantity versus impact of different paper types (e.g., conference versus journal\u00a0\u2026", "num_citations": "26\n", "authors": ["183"]}
{"title": "A bibliometric/geographic assessment of 40 years of software engineering research (1969-2009)\n", "abstract": " Bibliometric rankings are quite common in the field of software engineering. For example, there are a series of ranking repeated every year which identify the top researchers and institutions at the international level in the field. There are also other studies to determine the most cited articles in software engineering journals, the most popular research topics in this area, or identify the top researchers and institutions in regional levels. However, there exists no existing bibliometric quantitative analysis of publications in the area of software engineering (SE), including relative and absolute growth in the number of all SE publications as well as an analysis among countries. This is the main goal and motivation of this article. Besides, this study intends to provide an overall quantitative trend of the software engineering papers, and compare that trend to research output in other areas of science.         The bibliometric study\u00a0\u2026", "num_citations": "26\n", "authors": ["183"]}
{"title": "Development of scientific software: a systematic mapping, bibliometrics study and a paper repository\n", "abstract": " Scientific and engineering research is heavily dependent on effective development and use of software artifacts. Many of these artifacts are produced by the scientists themselves, rather than by trained software engineers. To address the challenges in this area, a research community often referred to as \"Development of Scientific Software\" has emerged in the last few decades. As this research area has matured, there has been a sharp increase in the number of papers and results made available, and it has thus become important to summarize and provide an overview about those studies. Through a systematic mapping and bibliometrics study, we have reviewed 130 papers in this area. We present the results of our study in this paper. Also we have made the mapping data available on an online repository which is planned to be updated on a regular basis. The results of our study seem to suggest that many\u00a0\u2026", "num_citations": "26\n", "authors": ["183"]}
{"title": "A bibliometric assessment of Canadian software engineering scholars and institutions (1996-2006)\n", "abstract": " This paper summarizes a ranking of Canadian researchers and institutions in the field of software engineering from 1996 to 2006, based on two metrics: impact factors, and h-index. The ranking is going to be an ongoing, annual event to identify the top 50 scholars and top 50 institutions over a 10-year period in Canada. The rankings are calculated based on the impact factor and h-index of papers published in top 12 selected software engineering journals and conferences. The top-ranked institution is Carleton University, and the top-ranked scholars (by each of the two metrics) are Lionel Briand (formerly with Carleton University) and Gail Murphy from UBC.", "num_citations": "26\n", "authors": ["183"]}
{"title": "Traffic-aware stress testing of distributed real-time systems based on UML models in the presence of time uncertainty\n", "abstract": " In a previous work, we reported and experimented with a stress testing methodology to detect network traffic- related real-time (RT) faults in distributed real-time systems (DRTSs) based on the design UML models. The stress methodology, referred to as time-shifting stress test methodology (TSSTM), aimed at increasing chances of discovering RT faults originating from network traffic overloads in DRTSs. The TSSTM uses the UML 2.0 model of a system under test (SUT), augmented with timing information, and is based on an analysis of the control flow in UML sequence diagrams. In order to devise deterministic test requirements (from time point of view) that yield the maximum stress test scenario in terms of network traffic in a SUT, the TSSTM methodology requires that the timing information of messages in sequence diagrams is available and as precise as possible. In reality, however, the timing information of\u00a0\u2026", "num_citations": "26\n", "authors": ["183"]}
{"title": "When to automate software testing? A decision\u2010support approach based on process simulation\n", "abstract": " Software test processes are complex and costly. To reduce testing effort without compromising effectiveness and product quality, automation of test activities has been adopted as a popular approach in software industry. However, because test automation usually requires substantial upfront investments, automation is not always more cost\u2010effective than manual testing. To support decision\u2010makers in finding the optimal degree of test automation in a given project, we recently proposed a process simulation model using the System Dynamics modeling technique and used the simulation model in the context of a case study with a software company in Calgary, Canada. With the help of the simulation model, we were able to evaluate the performance of test processes with varying degrees of automation of test activities and help testers choose the most optimal cases. The goal of the earlier study was to investigate how\u00a0\u2026", "num_citations": "21\n", "authors": ["183"]}
{"title": "An MILP-based formulation for minimizing pumping energy costs of oil pipelines: beneficial to both the environment and pipeline companies\n", "abstract": " Optimal scheduling of pumps operation in fluid distribution networks (e.g., oil or water) is an important optimization problem. This is due to the fact that the dollar cost and also global carbon footprints of such a major transportation are in mega scales. For example, one of our industrial partners, a Canadian oil pipeline operator, spent more than $18.11 million dollars in 2008 for pumping costs. According to our calculations, this would lead to up to 182,460 tons of CO2 emissions annually. Therefore, even slight improvements in operation of a pipeline system can lead to considerable savings in costs and also reducing carbon footprints emitted to the environment (by introducing air pollutions needed to generate those huge amounts of electricity). In this paper, a methodology for determining optimal pump operation schedule for a fluid distribution pipeline system with multi-tariff electricity supply is presented. The\u00a0\u2026", "num_citations": "21\n", "authors": ["183"]}
{"title": "Tecrevis: a tool for test coverage and test redundancy visualization\n", "abstract": " This tool paper presents the feature set, graphical user interface and also the implementation details of a test coverage and test redundancy visualization tool, called TeCReVis. The tool is an Eclipse plug-in and supports JUnit test suites helping testers in analyzing the coverage information more effectively in a visual way compared to traditional text-based coverage tools.", "num_citations": "21\n", "authors": ["183"]}
{"title": "Evidence-based insights about issue management processes: an exploratory study\n", "abstract": " Issue (e.g., defect) repositories usually contain rich information that can be used to mine evidence about team dynamics, issue management processes, and other aspects of software development. The exploratory case study reported in this paper uses quantitative issue tracking data of three open-source projects to derive insights into how issues emerge and are handled in open-source projects. The mined information provides empirical evidence for a few beliefs in the software engineering and process communities. For example, depending on their specific context factors, projects show different degrees of responsiveness to the occurrence of defects. Software engineers can use techniques similar to those presented in this paper to mine the issue repositories of their in-house development projects. This may serve to better characterize their issue management processes, to perform self-assessment and\u00a0\u2026", "num_citations": "21\n", "authors": ["183"]}
{"title": "Incorporating real-world industrial testing projects in software testing courses: Opportunities, challenges, and lessons learned\n", "abstract": " In order to effectively teach software engineering students how to solve real-world problems, if possible, students should have the chance of working with and testing \u201creal-world\u201d industrial software systems during their courses. In a previous article, we presented a comprehensive software-testing lab exercise repository in which real software systems and test tools were incorporated to give students the chance of learning industry-standard tools (such as JUnit and IBM Rational Functional Tester). As the next step in our on-going efforts to improve the learning experience of students in testing courses, we have incorporated \u201creal-world\u201d industrial testing projects in a graduate-level software testing course in the past three years (2008-2010). The experience and the outcomes of these industrial-caliber projects have been very satisfying to the stakeholders. We report in this article some details about those projects and\u00a0\u2026", "num_citations": "20\n", "authors": ["183"]}
{"title": "An open modern software testing laboratory courseware\n", "abstract": " In order to effectively teach software testing students how to test real-world software, the software tools, exercises, and lab projects chosen by testing educators should be practical and realistic. However, there are not many publicly-available realistic testing courseware for software testing educators to adapt and customize. Even for the existing testing lab exercises developed and/or used by the educators, there are various drawbacks, e.g.: (1) They are not usually kept up-to-date with the most recent testing tools and technologies, e.g., JUnit, (2) They are not built based on realistic/real-world Systems Under Test (SUTs), but rather use \u00bftoy\u00bf examples (SUTs). The above needs were the main motives for the author and his team at the University of Calgary to modernize the lab exercises of an undergraduate software testing course. This paper presents the designed lab courseware, and the experiences learned from\u00a0\u2026", "num_citations": "20\n", "authors": ["183"]}
{"title": "Introducing automated environment configuration testing in an industrial setting\n", "abstract": " This paper presents an automated environment configuration testing strategy developed as part of an action research project to deal with issues of staging environment instability in a large organization. We demonstrate how a suite of automated environment configuration tests provided an unobtrusive way to verify the hospitability of staging environments, decreased the time wasted on manual troubleshooting of environmental issues, and consolidated software configuration management information. The test strategy was also greatly welcomed by upper-level management and is now being expanded to other parts of the organization.", "num_citations": "19\n", "authors": ["183"]}
{"title": "Introducing automated GUI testing and observing its benefits: An industrial case study in the context of law-practice management software\n", "abstract": " Motivated by a real-world industrial need in the context of a large IT solutions company based in Turkey, the authors and their colleagues developed and introduced automated test suites for GUI testing of two large-scale law-practice management software (comprising of 414 and 105 KLOC). We report in this paper our experience in developing and introducing a set of large automated test suites (more than 50 KLOC in total), using best practices in state-of-the art and -practice, and to report its observed benefits by conducting cost-benefit analysis in the specific industrial context. The project was conducted based on the principles of case-study and \"action research\" in which the real industrial needs drove the research. Among the best practices that we used are the followings: (1) the page-object test pattern, (2) modularity in test code, (3) creating test-specific libraries, and (4) using systematic guidelines to decide\u00a0\u2026", "num_citations": "17\n", "authors": ["183"]}
{"title": "Classification and trend analysis of UML books (1997\u20132009)\n", "abstract": " Technical books of each subject area denote the level of maturity and knowledge demand in that area. According to the Google Books database, about 208 Unified Modeling Language (UML) books have been published from its inception in 1997 until 2009. While various book reviews are frequently published in various sources (e.g., IEEE Software Bookshelf), there are no studies to classify UML books into meaningful categories. Such a classification can help researchers in the area to identify trends and also reveal the level of activity in each sub-area of UML. The statistical survey reported in this article intends to be a first step in classification and trend analysis of the UML books published from 1997 to 2009. The study also sheds light on the quantity of books published in different focus areas (e.g., UML\u2019s core concepts, patterns, tool support, Object Constraint Language and Model-Driven Architecture\u00a0\u2026", "num_citations": "16\n", "authors": ["183"]}
{"title": "Tool support for automated traceability of test/code artifacts in embedded software systems\n", "abstract": " Development, testing and maintenance of software for embedded systems is a complex task. Analysis of the traceability between different software artifacts (e.g., source code, test code and requirements) is an enabling capability for better development, testing and maintenance of software systems. However, there is a general lack of tool support for automating traceability analysis for embedded systems. We demonstrate in this paper how to extend an existing unit test and test coverage framework to produce a hard-ware assisted tool framework capable of automatically deriving and visualizing traceability links between source code and test code artifacts. To demonstrate the applicability and usefulness of the framework, we report the application of the framework on realistic embedded software for vehicle gear transmission control built and deployed on the Analog Devices Blackfin \u00ae ADSP-5XX family of DSP\u00a0\u2026", "num_citations": "16\n", "authors": ["183"]}
{"title": "Test cost-effectiveness and defect density: a case study on the android platform\n", "abstract": " The Android operating system is one of the most popular open-source platforms in the mobile operating system market. It had a worldwide smart-phone market share of 68% at the second quarter of 2012. However, there has been little research on test coverage and test cost-effectiveness in this platform. The goal of this case study reported in this paper is to assess test coverage, fault detection effectiveness, test cost-effectiveness, and defect density in code-base of version 2.1 of the Android platform. We raise and address five research questions (RQs) in this study. Among our results are: (1) in contrary to what one would expect, for packages with larger coverage values (meaning more rigorous testing), it is not necessarily true that less defects have been reported by the users after release. Also, it is not necessarily true that components with low coverage have more defects; (2) we re-confirm (replicate) the existence\u00a0\u2026", "num_citations": "15\n", "authors": ["183"]}
{"title": "Video game development in a rush: A survey of the global Game-Jam participants\n", "abstract": " Video game development is a complex endeavor, often involving complex software, large organizations, and aggressive release deadlines. Several studies have reported that periods of \u201ccrunch time\u201d are prevalent in the video game industry, but there are few studies on the effects of time pressure. We conducted a survey with participants of the Global Game Jam (GGJ), a 48-h hackathon. Based on 198 responses, the results suggest the following: iterative brainstorming is the most popular method for conceptualizing initial requirements; continuous integration, minimum viable product, scope management, version control, and stand-up meetings are frequently applied development practices; regular communication, internal playtesting, and dynamic and proactive planning are the most common quality assurance activities; and familiarity with agile development has a weak correlation with perception of success in the\u00a0\u2026", "num_citations": "14\n", "authors": ["183"]}
{"title": "Citation and topic analysis of the ESEM papers\n", "abstract": " Context: The pool of papers published in ESEM. Objective: To utilize citation analysis and automated topic analysis to characterize the SE research literature over the years focusing on those papers published in ESEM. Method: We collected data from Scopus database consisting of 513 ESEM papers. For thematic analysis, we used topic modeling to automatically generate the most probable topic distributions given the data. Results: Nearly 42% of the papers have not been cited at all but the effect seems to wear off as time passes. Using text mining of article titles and abstracts, we found that currently the most popular research topics in the ESEM community are: systematic reviews, testing, defects, cost estimation, and team work. Conclusions: While this study analyzes the paper pool of the ESEM symposium, the approach can easily be applied to any other sub-set of SE papers to conduct large scale studies. Due to\u00a0\u2026", "num_citations": "14\n", "authors": ["183"]}
{"title": "Investigating the success factors of opensource software projects across their lifetime\n", "abstract": " It is important to develop measures of success for Open-Source Software (OSS) projects across their lifetime. For example, having such measures would be useful for OSS project managers and other stakeholders in evaluating and assessing their projects. In some cases, OSS projects are sponsored by third parties, so measures are useful for sponsors to understand the return on their investment. Such measures will also help in different decision-making tasks, eg, allocating more resources or enhancing the development process if the success of a project is decreasing. Being the first of its kind, the focus of this work is on identifying factors that investigate and evaluate the performance and success of four systematically-sampled OSS projects by analyzing their history of project data across their lifetimes. A systematic case study is conducted in which measurements reveal the likeliness of the following observations about the four OSS projects, eg,(1) poor issue-handling performance of an OSS team may deteriorate its other success measures (eg, number of downloads),(2) bug opening and closing efforts usually occur together in time in more successful projects, and (3) any single success measure should not be viewed as the final word on success.", "num_citations": "14\n", "authors": ["183"]}
{"title": "NLP-assisted software testing: A systematic mapping\n", "abstract": " ContextTo reduce manual effort of extracting test cases from natural-language requirements, many approaches based on Natural Language Processing (NLP) have been proposed in the literature. Given the large amount of approaches in this area, and since many practitioners are eager to utilize such techniques, it is important to synthesize and provide an overview of the state-of-the-art in this area.ObjectiveOur objective is to summarize the state-of-the-art in NLP-assisted software testing which could benefit practitioners to potentially utilize those NLP-based techniques. Moreover, this can benefit researchers in providing an overview of the research landscape.MethodTo address the above need, we conducted a survey in the form of a systematic literature mapping (classification). After compiling an initial pool of 95 papers, we conducted a systematic voting, and our final pool included 67 technical papers\u00a0\u2026", "num_citations": "13\n", "authors": ["183"]}
{"title": "Practical relevance of software engineering research: Synthesizing the community\u2019s voice\n", "abstract": " Software engineering (SE) research should be relevant to industrial practice. There have been regular discussions in the SE community on this issue since the 1980\u2019s, led by pioneers such as Robert Glass. As we recently passed the milestone of \u201c50 years of software engineering\u201d, some recent positive efforts have been made in this direction, e.g., establishing \u201cindustrial\u201d tracks in several SE conferences. However, many researchers and practitioners believe that we, as a community, are still struggling with research relevance and utility. The goal of this paper is to synthesize the evidence and experience-based opinions shared on this topic so far in the SE community, and to encourage the community to further reflect and act on the research relevance. For this purpose, we have conducted a Multi-vocal Literature Review (MLR) of 54 systematically-selected sources (papers and non peer-reviewed articles). Instead of\u00a0\u2026", "num_citations": "13\n", "authors": ["183"]}
{"title": "Automated testing of simulation software in the aviation industry: An experience report\n", "abstract": " To develop high-quality software systems, software testing is a critical phase of any software development process. However, software testing is expensive and makes up about half of the development cost of an average software project [1]. According to a 2013 study [1], the global cost of finding and removing defects from software rose to $312 billion worldwide annually as of 2013.Different steps of software testing can be conducted manually or automated. In manual testing, the tester takes over the role of an end-user executing the software under test (SUT) to verify its behavior and find any possible defects. However, in automated testing, using certain test tools (eg, the JUnit test framework), test-code scripts are developed and executed without human testers\u2019 intervention to test the behavior of the SUT. If it is planned and implemented properly [2], automated testing could provide various benefits over manual testing, eg, repeatability and reducing testing effort and costs. However, if not implemented properly, automated testing could lead to extra cost and effort and might be even less effective than manual testing in detecting faults [3].", "num_citations": "13\n", "authors": ["183"]}
{"title": "Visual testing of graphical user interfaces: an exploratory study towards systematic definitions and approaches\n", "abstract": " Graphical User Interface (GUI) testing literature emphasizes testing a system's functionality through its GUI, rather than testing visual aspects of the GUI itself. In this paper we introduce the notion of visual testing as a subset of GUI testing. To explore visual testing, we have conducted a study of defects in four open source systems. We found that visual defects represent between 16% and 33% of reported defects in those systems. Two categories of visual defects are identified with six subcategories within each of them. Other findings are also reported that are aimed at motivating the importance and the need for systematically conducting visual testing among researchers and practitioners.", "num_citations": "13\n", "authors": ["183"]}
{"title": "Iranians in Canada: A statistical analysis\n", "abstract": " This paper presents a statistical analysis on the demographic, social educational and occupational issues of the Iranian-Canadian community. The main sources of data for the paper are the Government of Canada\u2019s 2001 census statistics and an online webbased survey conducted by the author from the Iranian-Canadian community. Other sources were the author\u2019s personal experiences and findings during his study and life in Canada during the last four years and also information provided by his friends and colleagues. Demographic features of the Iranian-Canadians such as population, gender, immigration status and period, age groups, marital status and marriage are investigated and compared to other typical Canadians. Other topics such as education, employment factors, income levels, ties with the home country (Iran), interest in and preservation of the home culture, identity in Canada, following issues related to Iran are also addressed. We also give a short discussion on the intra-social relations in the Iranian community in Canada. A brief overview on some of the related works, done specifically on the Iranians living in Canada, is also presented. The author hopes this analysis dispels the illusion held by Iranians prior to their immigration to foreign countries and Canada in particular. He further hopes that the analysis helps the decision makers and also Iranians associations, groups and societies both in Iran and in Canada to better analyze and solve the social, cultural, and psychological issues of the Iranian-Canadian community.", "num_citations": "13\n", "authors": ["183"]}
{"title": "On adequacy of assertions in automated test suites: An empirical investigation\n", "abstract": " An integral part of test case is the verification phase (also called `test oracle'), which verifies program's state, output or behavior. In automated testing, the verification phase is often implemented using test assertions which are usually developed manually by testers. More precisely, assertions are used for checking the unit or the system's behavior (or output) which is reflected by the changes in the data fields of the class under test, or the output of the function under test. Originated from human (testers') error, test suites are prone to having inadequate assertions. The paper reports an empirical study on the Inadequate-Assertion (IA) problem in the context of automated test suites developed for open-source projects. In this study, test suites of three active open-source projects have been chosen. To investigate IA problem occurrence among the sampled test suites, we performed mutation analysis and coverage analysis\u00a0\u2026", "num_citations": "11\n", "authors": ["183"]}
{"title": "Analysis of network traffic in ad-hoc networks based on DSDV protocol with emphasis on mobility and communication patterns\n", "abstract": " An ad-hoc network is a collection of mobile nodes dynamically forming a temporary network without the use of any existing network infrastructure or centralized administration. Because of the limited communication range among mobile nodes in ad-hoc networks, several network hops may be needed to deliver a packet from one node to another one in the wireless network. In recent years, a variety of different routing protocols addressing multi-hop ad-hoc networks have been presented, and their performance issues are discussed and some comparisons are made among them. However, no works have been reported on such analysis with emphasis on mobility and communication patterns of the mobile nodes. We are aiming to do such an analysis through simulations in this work. Our simulations are based on ad-hoc networks using DSDV protocol and are done using NS (Network Simulator) tool. We give a\u00a0\u2026", "num_citations": "10\n", "authors": ["183"]}
{"title": "Successful engagement of practitioners and software engineering researchers: Evidence from 26 international industry-academia collaborative projects\n", "abstract": " There has been a push to increase the practical relevance and impact of software engineering research. Although many practitioners and researchers agree that this change is desirable, thus far, only a few concrete actions have been taken by the community. In this article, we present our experiences with a large number of collaborative research projects that have had a practical (industrial) impact.", "num_citations": "9\n", "authors": ["183"]}
{"title": "Usage, usefulness and quality of defect reports: an industrial case study\n", "abstract": " In the context of an industry-academia collaboration in the scope of test process improvement, there was a need to assess the usage, usefulness and quality of defect reports. The objective was to assess the extent to which each field of a defect report (eg, product name, version number) is read/used by developers, ensuring that efforts spent into writing those fields are worthwhile, and also to pinpoint improvement areas in defect reports to increase developers' effectiveness in fixing defects. To address those needs, we conducted a questionnaire survey which gathered input from 38 software developers in the context of a large Turkish software and systems company providing global solutions in the areas of defense and IT. Analysis of survey results helped us to determine the usage and usefulness of various defect report fields and also to pinpoint the necessary improvement areas in defect reports, out of which an\u00a0\u2026", "num_citations": "9\n", "authors": ["183"]}
{"title": "Designing cyber-physical systems with aDSL: A domain-specific language and tool support\n", "abstract": " A Cyber-Physical System (CPS) comprises the integration of computation, software, networking, and physical processes. Consequently, CPS models extend traditional embedded system models with an increased support for hybrid and heterogeneous models, networking, time synchronization, and especially interoperability. To assist engineers in designing CPSs, we have developed aDSL, a Domain-Specific Language (DSL) that comes with fully-automated tool support and is tailored to interoperability of CPS. The aDSL tool support includes: (i) interactive model description with input validation; (ii) the computation of possible operation modes of subsystems and parts; and, (iii) checking the adherence to requirements for various design alternatives and finding the Pareto optimal designs given these requirements. Moreover, aDSL generates intuitive visualizations throughout the toolchain which help design\u00a0\u2026", "num_citations": "8\n", "authors": ["183"]}
{"title": "UML-driven software performance engineering: a systematic mapping and trend analysis\n", "abstract": " Performance is critical to the success of every software system. As a sub-area of software engineering, Software Performance Engineering (SPE) is a systematic and quantitative discipline to construct software systems that meet performance objectives. A family of SPE approaches that has become popular in the last decade is SPE based on models developed using the Unified Modeling Language (UML), referred to as UML-Driven Software Performance Engineering (UML-SPE). This particular research area has emerged and grown since late 1990s when the UML was proposed. More than 100 papers have been published so far in this area. As this research area matures and the number of related papers increases, it is important to systematically summarize and categorize the current state-of-the-art and to provide an overview of the trends in this specialized field. The authors systematically map the body of\u00a0\u2026", "num_citations": "8\n", "authors": ["183"]}
{"title": "IssuePlayer: An extensible framework for visual assessment of issue management in software development projects\n", "abstract": " This article presents a software visualization framework which can help project managers and team leaders in overseeing issues and their management in software development. To automate the framework, a dashboard tool called IssuePlayer is developed. The tool is used to study the trends in which different types of issues (e.g., bugs, support requests) are submitted, handled and piled up in software projects and use that information to identify process symptoms, e.g., the times when the code maintenance team is not responsive enough. The interactive nature of the tool enables identification of the team members who have not been as active as they were expected to be in such cases. The user can play, pause, rewind and forward the issue management histories using the tool. The tool is empirically evaluated by two industrial partners in North America and Europe. The survey and qualitative feedback support the\u00a0\u2026", "num_citations": "8\n", "authors": ["183"]}
{"title": "Experience and challenges with UML-driven performance engineering of a Distributed Real-Time System\n", "abstract": " ContextPerformance-related failures of Distributed and Real-Time Software Systems (DRTS\u2019s) can be very costly, e.g., explosion of a nuclear reactor. We reported in a previous work a stress testing methodology to detect performance-related Real-Time (RT) faults in DRTS\u2019s based on the design UML model of a System Under Test (SUT). The stress methodology aimed at increasing the chances of RT failures (violations in RT constraints).ObjectiveAfter stress testing a SUT and finding RT faults, an important immediate question is how to fix (debug) those RT faults and prevent the same RT violations in the future and after deployment. If appropriate solutions to this challenge cannot be found, stress testing and its findings (detection of RT faults) will be of no or little use to the quality assurance goals of the development team.MethodTo move towards systematically solving performance-related problems causing RT\u00a0\u2026", "num_citations": "8\n", "authors": ["183"]}
{"title": "Mining user reviews of COVID contact-tracing apps: An exploratory analysis of nine European apps\n", "abstract": " Context: More than 50 countries have developed COVID contact-tracing apps to limit the spread of coronavirus. However, many experts and scientists cast doubt on the effectiveness of those apps. For each app, a large number of reviews have been entered by end-users in app stores. Objective: Our goal is to gain insights into the user reviews of those apps, and to find out the main problems that users have reported. Our focus is to assess the \"software in society\" aspects of the apps, based on user reviews. Method: We selected nine European national apps for our analysis and used a commercial app-review analytics tool to extract and mine the user reviews. For all the apps combined, our dataset includes 39,425 user reviews. Results: Results show that users are generally dissatisfied with the nine apps under study, except the Scottish (\"Protect Scotland\") app. Some of the major issues that users have complained about are high battery drainage and doubts on whether apps are really working. Conclusion: Our results show that more work is needed by the stakeholders behind the apps (e.g., app developers, decision-makers, public health experts) to improve the public adoption, software quality and public perception of these apps.", "num_citations": "7\n", "authors": ["183"]}
{"title": "Fault\u2010driven stress testing of distributed real\u2010time software based on UML models\n", "abstract": " In a previous article, a stress testing methodology was reported to detect network traffic\u2010related Real\u2010Time (RT) faults in distributed RT systems based on the design UML model of a System Under Test (SUT). The stress methodology, referred to as Test LOcation\u2010driven Stress Testing (TLOST), aimed at increasing the chances of RT failures (violations in RT constraints) associated with a given stress test location (an network or a node under test). As demonstrated and experimented in this article, although TLOST is useful in stress testing different test locations (nodes and network, it does not guarantee to target (test) all RT constraints in an SUT. This is because the durations of message sequences bounded by some RT constraints might never be exercised (covered) by TLOST. A complementary stress test methodology is proposed in this article, which guarantees to target (cover) all RT constraints in an SUT and\u00a0\u2026", "num_citations": "7\n", "authors": ["183"]}
{"title": "A tool for automated inspection of software design documents and its empirical evaluation in an aviation industry setting\n", "abstract": " While software inspection is an effective activity to detect defects early in the software development lifecycle, it is an effort-intensive and error-prone activity. Motivated by a real need in the context of the Turkish Aerospace Industries Inc. (TAI), a tool named AutoInspect was developed to (semi-) automate the inspection of software design documents and, as a result, to increase the efficiency and effectiveness of the inspection process. We present in this paper the features of the tool, its development details and its initial evaluation for inspecting the design documents of three real systems in the company. The results of the initial case-study reveal that the tool is indeed able to increase the inspections efficiency and effectiveness. In terms of efficiency, inspection engineers who used AutoInspect performed 41-50% more efficiently, for the three design documents under study, compared to the case when the tool was not\u00a0\u2026", "num_citations": "6\n", "authors": ["183"]}
{"title": "A bibliometrics analysis of Canadian electrical and computer engineering institutions based on IEEE journal publications (1996-2006)\n", "abstract": " A bibliometrics analysis of Canadian electrical and computer engineering institutions based on IEEE journal publications (1996-2006) \u2014 Queen's University Belfast Skip to main navigation Skip to search Skip to main content Queen's University Belfast Logo Help & FAQ Home Profiles Organisations Research output Projects Impact Datasets Activities Prizes Press / Media Student theses Facilities Search by expertise, name or affiliation A bibliometrics analysis of Canadian electrical and computer engineering institutions based on IEEE journal publications (1996-2006) Vahid Garousi, Tan Varma School of Electronics, Electrical Engineering and Computer Science Research output: Contribution to journal \u203a Article \u203a peer-review Overview Original language English Journal Computer and Information Science Publication status Published - 28 May 2012 Cite this APA Author BIBTEX Harvard Standard RIS Vancouver Garousi'\u2026", "num_citations": "6\n", "authors": ["183"]}
{"title": "Experience in developing a robot control software\n", "abstract": " This article presents an experience report in using the UML-driven development process to develop an object-oriented control software for a Sony AIBO robot. The entire project was a great learning experience for all the team members and we found the methodologies we used very effective in helping us design and develop a high-quality control system. We also feel that other software developers and practitioners, especially those developing robotic and embedded control software, would benefit from the experience and observations reported in this article.", "num_citations": "6\n", "authors": ["183"]}
{"title": "An empirical evaluation to study benefits of visual versus textual test coverage information\n", "abstract": " The code coverage tools (e.g., CodeCover for Java) and the textual coverage information (e.g., only metric values) they produce are very useful for testers. However with increasing size and complexity of code bases of both systems under test and also their automated test suites (e.g., based on JUnit), there is a need for visualization techniques to enable testers to analyze code coverage in higher levels of abstraction. To address the above need, we recently proposed a test coverage visualization tool. To assess the usability, effectiveness and usefulness of this tool in unit testing and test maintenance tasks, we have conducted a controlled experiment, the results of which show that the tool can benefit testers more compared to textual coverage information.", "num_citations": "6\n", "authors": ["183"]}
{"title": "UML model-driven detection of performance bottlenecks in concurrent real-time software\n", "abstract": " A UML-driven technique for detection of performance bottlenecks in concurrent real-time systems is presented. The approach is based on comprehensive analysis of control flow in two types of UML 2.x behavioral models: sequence diagrams and interaction overview diagrams. The technique takes an input the runtime durations of tasks and uses the Program Evaluation and Review Technique (PERT) to pinpoint performance bottlenecks in UML-based control flow information of a concurrent real-time system. Since design UML models are usually developed and are available already for most object-oriented systems, the technique prevents the need to construct specific-purpose performance models such as Layered Queuing Networks. Application of the technique on an example control software system demonstrates the applicability and effectiveness of the technique in pinpointing performance bottlenecks.", "num_citations": "6\n", "authors": ["183"]}
{"title": "Engineering control software systems: A multi-disciplinary challenge\n", "abstract": " Advancement of computer, software, telecommunication and internet technologies during the last twenty years has fundamentally shifted the focus of the expertise in control-systems engineering (CSE) industry. It is evident that building high-quality modern control systems requires a multi-disciplinary effort as a single engineer simply cannot be an expert in all the related areas, e.g., software/computer engineering, computer science and information systems. As an experience and evidence report, this article reports on the challenges in CSE based on the authors' experience and presents observations and potential recommendations for multi-disciplinary nature of CSE. It is hoped that the article would bring awareness to the community and would be useful for the industrial practitioners and researchers working in this area in building stronger multi-disciplinary CSE teams and, ultimately, in building higher-quality\u00a0\u2026", "num_citations": "4\n", "authors": ["183"]}
{"title": "Iterative stress-test performance engineering of distributed real-time systems\n", "abstract": " Performance failures of software systems are usually very costly, eg, they can result in damaged customer relations, lost productivity for users, lost revenue, cost and time overruns due to performance tuning or redesign, and missed market windows. This article presents an iterative performance engineering process for Distributed Real-Time Systems (DRTS) based on test results from applying our previous stress test methodology. The process, referred to as Iterative Stress-Test Performance Engineering (ISTPE), is iteratively applied to a System Under Test (SUT) until stress test results reveal that there are still scenarios in which one or more of Real-Time (RT) constraints are violated. In such scenarios, our ISTPE process provides developers with different choices of performance tuning guidelines to prevent RT faults, eg, redesigning the system architecture, increasing resource capacities (eg, network bandwidth), or\u00a0\u2026", "num_citations": "4\n", "authors": ["183"]}
{"title": "Grey literature versus academic literature in software engineering: A call for epistemological analysis\n", "abstract": " To learn about novel software engineering (SE) trends, where do you refer to? In order to document and disseminate their experience / knowledge, many SE practitioners prepare technical materials and share them online as blog posts, white papers and videos. Such materials are often called \u201cgrey literature\u201d because they are not formally peer reviewed. By contrast, SE researchers write technical papers that are peer-reviewed and published as academic literature. We observe that, in general, these two communities mostly read literature that is only written by and published within their respective communities. This situation has led to a form of \u201cknowledge divide\u201d between the two communities that, we believe, hurts both communities. By characterizing and contrasting the two types of literature, grey and academic, we discuss how each literature can complement the other and can lead to a richer and more integrated\u00a0\u2026", "num_citations": "3\n", "authors": ["183"]}
{"title": "Multi-objective optimization of both pumping energy and maintenance costs in oil pipeline networks using genetic algorithms\n", "abstract": " This paper proposes an optimization model for the pipeline operation problem using a dual-objective nondominated sorting genetic algorithm (NSGA-II). One and foremost objective is to minimize pumping energy costs. The second objective is to recognize the pipeline operators\u2019 concern on pumps maintenance costs by reducing the number of times pumps are turned on and off. This is commonly believed as a main source of wear and tear on the pumps. The formulation of the problem is presented in detail and the model is tested on a hypothetical case study (which is based on consultation with two industrial partners). The output results are promising since they would give operators a better understanding of different optimal scenarios on a \u201cPareto front\u201d. Operators can visually assess several alternatives, and analyse the cost-effectiveness of each scenario in terms of both objective functions.", "num_citations": "3\n", "authors": ["183"]}
{"title": "Towards design and architectural evaluation of product variants: A case study on an open source software system\n", "abstract": " Evolving a software system demands a careful balance between equally important but often conflicting views of customers and system architecture. This paper proposes a method to address evolution of a software system into a product line containing specialized product variants for specific markets while aligning the two views. The proposed method COPE+ iteratively explores the solutions space to generate product variants for the two views independently. It uses density based clustering to identify market segments. Impact of the proposed features on the existing product\u2019s architecture is heuristically determined. Behaviors of the promising variants are then compared with that of the existing system through extended mqsimulation on statechart representations. This determines the degree of similarity between existing system and proposed product variants. Finally, human experts evaluate the suggested products. COPE+ is applied to jEdit, a popular open source editor. Results indicate usefulness of the proposed method in bringing together the diversified views of customers and architecture.", "num_citations": "3\n", "authors": ["183"]}
{"title": "A domain-specific language framework for farm management information systems in precision agriculture\n", "abstract": " Farm management information system (FMIS) is an important element of precision agriculture to support the decision making process in the agricultural business. Developing FMIS is not trivial and requires the proper design and implementation models for supporting the understandability, enhancing communication and analysis of the design decisions, and the communication among stakeholders. To cope with these challenges, a Domain-specific language (DSL) framework for the design and development of precision-agriculture FMISs is proposed and evaluated. The DSL framework is developed based on a domain-driven design approach in which a feature diagram is provided that represents the common and variant features of the precision agriculture domain. The key requirements for the DSL framework are discussed, the scope of the DSL is defined, and the set of DSLs for supporting FMISs is\u00a0\u2026", "num_citations": "2\n", "authors": ["183"]}
{"title": "Test Maturity Model integration (TMMi): Trends of worldwide test maturity and certifications\n", "abstract": " Test Maturity Model integration (TMMi) is a popular model for maturity assessment and capability improvement of software testing practices in industry. Originally inspired by the Capability Maturity Model Integration (CMMI), and managed by the TMMi Foundation, the TMMi specification provides detailed guidelines for assessing and improving testing capabilities of teams and organizations. We present in this paper a status report about TMMi, motivations for and benefits of using TMMi, and how companies have been ranked in each of its process areas.", "num_citations": "2\n", "authors": ["183"]}
{"title": "Visualization, monitoring and control techniques for use in Scrum software development: An Analytic-Hierarchy-Process approach\n", "abstract": " Scrum is the most widely used agile development framework that guides the development process with its ability to create customer-valued software artifacts iteratively and incrementally, whilst seeking best practices to provide continuous measurement during production. However, measuring success in Scrum can be a challenging endeavor. In particular, it is hard to select the best fitting agile metrics during consecutive Scrum sprints. The goal of this industrial case study was to utilize a systematic selection process for identifying the appropriate scrum metrics tools addon component within the TB\u0130TAK SAGE software development group. Moreover, the distribution of software developers\u2019 preferences of process metrics were analyzed according to their characteristic features and defense industry structure, and are presented using various distribution charts. Finally, alternatives to the software development\u00a0\u2026", "num_citations": "2\n", "authors": ["183"]}
{"title": "Transitioning from manual to automated software regression testing: Experience from the banking domain\n", "abstract": " Regression testing is needed when a software or the environment hosting that software changes. Motivated by a real-world industrial need in the context of a large financial (banking) corporation in Turkey, the authors and their colleagues developed and introduced an automated regression testing infrastructure for automated testing of one of the main mobile applications of the company. Before this project, regression testing was conducted manually which incurred a lot of costs and was by nature subjective. We report in this paper our experience in \"transitioning\" from manual to automated regression testing, and in developing and introducing a set of large automated test suites (more than 16 KLOC in total), using best practices in state-of-the art and -practice, and to report its observed benefits by conducting cost-benefit analysis. The project was conducted based on the principles of case-study and \"action research\"\u00a0\u2026", "num_citations": "2\n", "authors": ["183"]}
{"title": "Calibrating a customizable system dynamics simulation model of generic software development processes\n", "abstract": " GENSIM 2.0 is a customizable system dynamics simulation model of generic software development processes which takes as input the specifics of software development projects (eg size of the code document, headcount of the developer team and their skills) and generates as output a broad range of distinct variables (eg software product quality, total project effort) of interest to different users of the model. This technical report is dedicated to elaborate on current calibration of GENSIM 2.0, its calibration parameters and the source from which they can be potentially calibrated.", "num_citations": "2\n", "authors": ["183"]}
{"title": "A quantitative framework for predicting resource usage and load in real-time systems based on UML models\n", "abstract": " This paper presents a quantitative framework for predicting resource usage and load in Real-Time Systems (RTS). The prediction is based on an analysis of UML 2.0 sequence diagrams, augmented with timing information, to extract timed-control flow information. It is aimed at improving the predictability of a RTS by offering a systematic approach to predict system behavior in each time instant during its execution. Since behavioral models such as sequence diagrams are available in earlier design phases of the software life cycle, the framework enables resource analysis at a stage when design decisions are still easy to change. We use network traffic as an example resource to illustrate the approach. Usage and load analysis of other resources (such as CPU, memory and database) can be performed in a similar fashion. A case study illustrates the feasibility of the approach.", "num_citations": "2\n", "authors": ["183"]}
{"title": "Test automation with the Gauge framework: Experience and best practices\n", "abstract": " While Behavior-driven development (BDD) tools such as Cucumber are powerful tools for automated testing, they have certain limitations. For example, they often enforce strict syntax for test cases, like the \u201cGiven-When-Then\u201d format, which may not always be easy to write for a given test case. A new test automation framework named Gauge (                   gauge.org                                    ) addresses that limitation since it does not prescribe the BDD testing process with a strict syntax. In Gauge, writing a test case is as easy as writing down the flow of test cases in several itemized sentences in a natural language, like English.                 In the context of Testinium (                   testinium.com                                    ), a large software testing company which provides software testing services, tools and solutions to a large number of clients, we have actively used the Gauge framework since 2018 to develop large automated\u00a0\u2026", "num_citations": "1\n", "authors": ["183"]}
{"title": "Yazilim hatalarinin atanmasi: Bir sistematik literat\u00fcr haritalamasi\n", "abstract": " Managing the assignment of bug report to related team or related developer is challenging and time consuming issue in large-scale software projects. In order to reduce the assignment time and to increase success of right decision making automated bug assignment approaches presented. To support automated decision making on bug assignment, researchers and practitioners propound various methods, tools and processes. Number of academic and technical sources have increased and this has brought the need to systematically categorize the current studies and practices and to provide an overview. In order to give an overview of current studies, we performed a systematic mapping study in the area of bug assignment. We searched the academic literature using several search engines (eg, Scopus, and Google Scholar). The SM and its results are based on 93 primary studies, which were published sources like conferences (45), journals (24), symposiums (12), workshops (4) and theses (3) and others (5). As a result, approximately 46% of the primary syudies are emprical studies, and 40% used Bayesian statistics as machine learning method.", "num_citations": "1\n", "authors": ["183"]}
{"title": "Data visualization\n", "abstract": " \u201cThe ability to take data\u2013to be able to understand it, to process it, to extract value from it, to visualize it, to communicate it's going to be a hugely important skill in the next decades, not only at the professional level but even at the educational level for elementary school kids, for high school kids, for college kids. Because now we really do have essentially free and ubiquitous data.\u201d\u2013Hal Varian", "num_citations": "1\n", "authors": ["183"]}
{"title": "Choosing the right testing tools and systems under test (SUTs) for practical exercises in testing education\n", "abstract": " In order to effectively teach software testing students how to solve real-world problems, the practical testing tools, exercises, projects and assignments chosen by testing educators should be realistic.In the context of software testing education, the above need implies the use of realistic and relevant Systems Under Test (SUT), and making use of realistic commercial testing tools. Otherwise, the skills that students learn in those courses will not enable them to be ready to test large-scale industrial software systems.", "num_citations": "1\n", "authors": ["183"]}
{"title": "A formalism for arrival time analysis of real-time tasks based on UML models\n", "abstract": " One of the important and effort-consuming aspects in the development of real-time (RT) systems is the analysis of RT job arrival times, i.e., finding the time instant(s) or time interval(s) when tasks are allowed to start. The analysis of arrival times becomes complex when the number of RT tasks under analysis grows and also when RT tasks have different arrival patterns, e.g., periodic. We present in this paper an automatable UML-based arrival time analysis formalism for RT systems. To show the applicability and effectiveness of our formalism, an example arrival time analysis using the formalism is presented.", "num_citations": "1\n", "authors": ["183"]}
{"title": "An experiment to study the magnitude of weak test redundancy in agile projects\n", "abstract": " Following test driven development implies that new test cases are added to the test suite or existing test cases are modified whenever production code is changed during development and maintenance. New or modified test cases might overlap with existing tests, ie they might be redundant. Redundant tests increase test execution time without increasing the confidence in the system under test. In traditional testing, there are various test set reduction techniques. They consider test case coverage criteria like statement or path coverage, fault detection effectiveness or combination of them. This report presents and approach for measuring the magnitude of test redundancy by considering a combination of statement, branch and method coverage. We then apply our approach to the unit tests for some project which are known to have been developed by Agile processes like FitNesse, Tomcat and JUnit.", "num_citations": "1\n", "authors": ["183"]}
{"title": "Fault-driven stress testing of distributed real-time systems based on UML models\n", "abstract": " In a previous work, we reported and experimented with a stress testing methodology to detect network traffic-related Real-Time (RT) faults in Distributed Real-Time Systems based on the design UML model of a System Under Test (SUT). The stress methodology, referred to as Test LOcation-driven Stress Testing (TLOST), aimed at increasing the chances of violations in RT constraints associated with a given stress test location (a network or a node under test). As we demonstrate and experiment in this article, although useful to stress different test location-, but TLOST does not guarantee to target (test) all RT constraints in a SUT. This is because the durations of message sequences bounded by some RT constraints might never be exercised by TLOST. To address the above limitation of TLOST in not being able to target all possible RT faults in a SUT, we propose in this work an extended stress test methodology, referred to as Real-Time FAult-driven Stress Testing (RTFAST), which guarantees to target (test) all RT constraints in a SUT and detect their potential RT faults. Using a case study, we show that RTFAST is capable of targeting (and possibly revealing) the RT faults not detected by our previous methodology (TLOST).", "num_citations": "1\n", "authors": ["183"]}
{"title": "Using genetic algorithms to prioritize real-time stress test locations based on fault criticalities\n", "abstract": " In a previous contribution [1], we reported and experimented with a stress testing technique to detect Real-Time (RT) faults in Distributed Real-Time Systems (DRTSs) based on the design UML model of a System Under Test (SUT). For stress testing processes to be cost effective, especially in systems with numerous RT constraints and/or when test resources (eg, time, budget) are limited, software testers should prioritize test locations (a network or a node under stress test) such that more critical RT faults are revealed earlier in a stress testing process. More criticality of a RT fault in this context means for example more serious (eg, life-threatening) consequences if a constraint is violated. To order stress test locations in a more cost effective manner, ie, to find the most cost effective test orders in a SUT, one should be able to first measure the cost effectiveness of stress test locations and test orders. To achieve the\u00a0\u2026", "num_citations": "1\n", "authors": ["183"]}