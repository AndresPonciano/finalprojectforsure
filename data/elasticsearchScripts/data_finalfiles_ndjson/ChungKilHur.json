{"title": "Biorthogonality, step-indexing and compiler correctness\n", "abstract": " We define logical relations between the denotational semantics of a simply typed functional language with recursion and the operational behaviour of low-level programs in a variant SECD machine. The relations, which are defined using biorthogonality and stepindexing, capture what it means for a piece of low-level code to implement a mathematical, domain-theoretic function and are used to prove correctness of a simple compiler. The results have been formalized in the Coq proof assistant.", "num_citations": "125\n", "authors": ["698"]}
{"title": "A Kripke logical relation between ML and assembly\n", "abstract": " There has recently been great progress in proving the correctness of compilers for increasingly realistic languages with increasingly realistic runtime systems. Most work on this problem has focused on proving the correctness of a particular compiler, leaving open the question of how to verify the correctness of assembly code that is hand-optimized or linked together from the output of multiple compilers. This has led Benton and other researchers to propose more abstract, compositional notions of when a low-level program correctly realizes a high-level one. However, the state of the art in so-called\" compositional compiler correctness\" has only considered relatively simple high-level and low-level languages.", "num_citations": "97\n", "authors": ["698"]}
{"title": "Strongly typed term representations in Coq\n", "abstract": " There are two approaches to formalizing the syntax of typed object languages in a proof assistant or programming language. The extrinsic approach is to first define a type that encodes untyped object expressions and then make a separate definition of typing judgements over the untyped terms. The intrinsic approach is to make a single definition that captures well-typed object expressions, so ill-typed expressions cannot even be expressed. Intrinsic encodings are attractive and naturally enforce the requirement that metalanguage operations on object expressions, such as substitution, respect object types. The price is that the metalanguage types of intrinsic encodings and operations involve non-trivial dependency, adding significant complexity. This paper describes intrinsic-style formalizations of both simply-typed and polymorphic languages, and basic syntactic operations thereon, in the Coq proof\u00a0\u2026", "num_citations": "91\n", "authors": ["698"]}
{"title": "Pilsner: A compositionally verified compiler for a higher-order imperative language\n", "abstract": " Compiler verification is essential for the construction of fully verified software, but most prior work (such as CompCert) has focused on verifying whole-program compilers. To support separate compilation and to enable linking of results from different verified compilers, it is important to develop a compositional notion of compiler correctness that is modular (preserved under linking), transitive (supports multi-pass compilation), and flexible (applicable to compilers that use different intermediate languages or employ non-standard program transformations). In this paper, building on prior work of Hur et al., we develop a novel approach to compositional compiler verification based on parametric inter-language simulations (PILS). PILS are modular: they enable compiler verification in a manner that supports separate compilation. PILS are transitive: we use them to verify Pilsner, a simple (but non-trivial) multi-pass optimizing\u00a0\u2026", "num_citations": "86\n", "authors": ["698"]}
{"title": "The marriage of bisimulations and Kripke logical relations\n", "abstract": " There has been great progress in recent years on developing effective techniques for reasoning about program equivalence in ML-like languages---that is, languages that combine features like higher-order functions, recursive types, abstract types, and general mutable references. Two of the most prominent types of techniques to have emerged are *bisimulations* and *Kripke logical relations (KLRs)*. While both approaches are powerful, their complementary advantages have led us and other researchers to wonder whether there is an essential tradeoff between them. Furthermore, both approaches seem to suffer from fundamental limitations if one is interested in scaling them to inter-language reasoning. In this paper, we propose *relation transition systems (RTSs)*, which marry together some of the most appealing aspects of KLRs and bisimulations. In particular, RTSs show how bisimulations' support for\u00a0\u2026", "num_citations": "80\n", "authors": ["698"]}
{"title": "Interaction trees: representing recursive and impure programs in Coq\n", "abstract": " Interaction trees (ITrees) are a general-purpose data structure for representing the behaviors of recursive programs that interact with their environments. A coinductive variant of \u201cfree monads,\u201d ITrees are built out of uninterpreted events and their continuations. They support compositional construction of interpreters from event handlers, which give meaning to events by defining their semantics as monadic actions. ITrees are expressive enough to represent impure and potentially nonterminating, mutually recursive computations, while admitting a rich equational theory of equivalence up to weak bisimulation. In contrast to other approaches such as relationally specified operational semantics, ITrees are executable via code extraction, making them suitable for debugging, testing, and implementing software artifacts that are amenable to formal verification.  We have implemented ITrees and their associated theory as a\u00a0\u2026", "num_citations": "58\n", "authors": ["698"]}
{"title": "A formal C memory model supporting integer-pointer casts\n", "abstract": " The ISO C standard does not specify the semantics of many valid programs that use non-portable idioms such as integer-pointer casts. Recent efforts at formal definitions and verified implementation of the C language inherit this feature. By adopting high-level abstract memory models, they validate common optimizations. On the other hand, this prevents reasoning about much low-level code relying on the behavior of common implementations, where formal verification has many applications. We present the first formal memory model that allows many common optimizations and fully supports operations on the representation of pointers. All arithmetic operations are well-defined for pointers that have been cast to integers. Crucially, our model is also simple to understand and program with. All our results are fully formalized in Coq.", "num_citations": "57\n", "authors": ["698"]}
{"title": "Second-order equational logic\n", "abstract": " We extend universal algebra and its equational logic from first to second order as follows.                                                                        1                                             We consider second-order equational presentations as specified by identities between second-order terms, with both variables and parameterised metavariables over signatures of variable-binding operators.                                                                                1                                             We develop an algebraic model theory for second-order equational presentations, generalising the semantics of (first-order) algebraic theories and of (untyped and simply-typed) lambda\u00a0calculi.                                                                                1                                             We introduce a deductive system, Second-Order Equational Logic, for reasoning about the equality of second-order terms. Our development is novel in that this equational logic is synthesised from the model theory\u00a0\u2026", "num_citations": "56\n", "authors": ["698"]}
{"title": "Lightweight verification of separate compilation\n", "abstract": " Major compiler verification efforts, such as the CompCert project, have traditionally simplified the verification problem by restricting attention to the correctness of whole-program compilation, leaving open the question of how to verify the correctness of separate compilation. Recently, a number of sophisticated techniques have been proposed for proving more flexible, compositional notions of compiler correctness, but these approaches tend to be quite heavyweight compared to the simple\" closed simulations\" used in verifying whole-program compilation. Applying such techniques to a compiler like CompCert, as Stewart et al. have done, involves major changes and extensions to its original verification. In this paper, we show that if we aim somewhat lower---to prove correctness of separate compilation, but only for a* single* compiler---we can drastically simplify the proof effort. Toward this end, we develop several\u00a0\u2026", "num_citations": "53\n", "authors": ["698"]}
{"title": "On the construction of free algebras for equational systems\n", "abstract": " The purpose of this paper is threefold: to present a general abstract, yet practical, notion of equational system; to investigate and develop the finitary and transfinite construction of free algebras for equational systems; and to illustrate the use of equational systems as needed in modern applications.", "num_citations": "34\n", "authors": ["698"]}
{"title": "Term equational systems and logics\n", "abstract": " We introduce an abstract general notion of system of equations between terms, called Term Equational System, and develop a sound logical deduction system, called Term Equational Logic, for equational reasoning. Further, we give an analysis of algebraic free constructions that together with an internal completeness result may be used to synthesise complete equational logics. Indeed, as an application, we synthesise a sound and complete nominal equational logic, called Synthetic Nominal Equational Logic, based on the category of Nominal Sets.", "num_citations": "32\n", "authors": ["698"]}
{"title": "Realizability and compositional compiler correctness for a polymorphic language\n", "abstract": " As the title suggests, this paper will describe a (mechanized) proof that a particular compiler is correct. The real subject, however, is how to define a good specification of when a low-level code fragment should be said to \u2018correspond to\u2019a phrase in a high-level language.A straightforward compiler correctness theorem says that for every closed, ground type source program P, the result C (P) of running compiler C on P is a target program whose observable behaviour (termination, final result, IO behaviour)\u2018matches\u2019 that of C. Proving such a theorem involves a strengthened induction hypothesis, relating open source phrases of higher types to target code (and values). This richer relation, typically some kind of (bi) simulation, is often essentially the simplest extension of the function C itself that suffices to establish the \u2018big\u2019theorem about complete programs, which are, after all, the only ones we can run according to the semantics of our source language. But the \u2018closed\u2019systems we really run are not the result of a single compilation: they are composed by linking code from many places, including libraries, the operating system, the runtime system and foreign functions, which may be compiled with different compilers and written in many languages, including \u2018cleverly\u2019handcrafted machine code. To reason modularly about all these components, we need a clean specification of the interface between compiled code and its environment, a job for which a naive induction hypothesis is inappropriate. The kind of specification we want should constrain only the observable behaviour of code, rather than intensional details of just how it executes, and make no\u00a0\u2026", "num_citations": "30\n", "authors": ["698"]}
{"title": "Promising-ARM/RISC-V: a simpler and faster operational concurrency model\n", "abstract": " For ARMv8 and RISC-V, there are concurrency models in two styles, extensionally equivalent: axiomatic models, expressing the concurrency semantics in terms of global properties of complete executions; and operational models, that compute incrementally. The latter are in an abstract microarchitectural style: they execute each instruction in multiple steps, out-of-order and with explicit branch speculation. This similarity to hardware implementations has been important in developing the models and in establishing confidence, but involves complexity that, for programming and model-checking, one would prefer to avoid.", "num_citations": "26\n", "authors": ["698"]}
{"title": "Equational Systems and Free Constructions (Extended Abstract)\n", "abstract": " The purpose of this paper is threefold: to present a general abstract, yet practical, notion of equational system; to investigate and develop a theory of free constructions for such equational systems; and to illustrate the use of equational systems as needed in modern applications, specifically to the theory of substitution in the presence of variable binding and to models of name-passing process calculi.", "num_citations": "24\n", "authors": ["698"]}
{"title": "Promising 2.0: global optimizations in relaxed memory concurrency\n", "abstract": " For more than fifteen years, researchers have tried to support global optimizations in a usable semantics for a concurrent programming language, yet this task has been proven to be very difficult because of (1) the infamous \u201cout of thin air\u201d problem, and (2) the subtle interaction between global and thread-local optimizations.", "num_citations": "19\n", "authors": ["698"]}
{"title": "A logical step forward in parametric bisimulations\n", "abstract": " In the last several years, a number of effective methods have been developed for reasoning about program equivalence in higher-order imperative languages like ML. Most recently, we proposed parametric bisimulations (PBs), which fruitfully synthesize the direct coinductive style of bisimulations with the flexible invariants on local state afforded by Kripke logical relations, and which furthermore support transitive composition of equivalence proofs. However, the PB model of our previous work suffered from two limitations. First, it failed to validate the eta law for function values, which is important for our intended application of compiler certification. Second, it was not clear how to scale the method to reason about control effects.In this paper, we propose stuttering parametric bisimulations (SPBs), a variant of PBs that addresses their aforementioned limitations. Interestingly, despite the fact that the eta law and control effects seem like unrelated issues, our solutions to both problems hinge on the same technical device, namely the use of a \u201clogical\u201d reduction semantics that permits finite but unbounded stuttering in between physical steps. This technique is closely related to the key idea in well-founded and stuttering bisimulations, adapted here for the first time to reasoning about open, higher-order programs. We present SPBs\u2014along with meta-theoretic results and example applications\u2014for a language with recursive types and first-class continuations. Following our previous account of PBs, we can easily extend SPBs to handle abstract types and general mutable references as well (see the appendix for details). All our results have been fully\u00a0\u2026", "num_citations": "16\n", "authors": ["698"]}
{"title": "CompCertM: CompCert with C-assembly linking and lightweight modular verification\n", "abstract": " Supporting multi-language linking such as linking C and handwritten assembly modules in the verified compiler CompCert requires a more compositional verification technique than that used in CompCert just supporting separate compilation. The two extensions, CompCertX and Compositional CompCert, supporting multi-language linking take different approaches. The former simplifies the problem by imposing restrictions that the source modules should have no mutual dependence and be verified against certain well-behaved specifications. On the other hand, the latter develops a new verification technique that directly solves the problem but at the expense of significantly increasing the verification cost.   In this paper, we develop a novel lightweight verification technique, called RUSC (Refinement Under Self-related Contexts), and demonstrate how RUSC can solve the problem without any restrictions but still\u00a0\u2026", "num_citations": "12\n", "authors": ["698"]}
{"title": "Separation logic in the presence of garbage collection\n", "abstract": " Separation logic has proven to be a highly effective tool for the verification of heap-manipulating programs. However, it has been applied almost exclusively in language settings where either memory is managed manually or the issue of memory management is ignored altogether. In this paper, we present a variant of separation logic, GCSL, for reasoning about low-level programs that interface to a garbage collector. In contrast to prior work by Calcagno et al., our model of GCSL (1) permits reasoning about programs that use internal pointers and address arithmetic, (2) supports logical variables that range over pointers, and (3) validates the \"frame\" rule, as well as a standard interpretation of separation-logic assertions, without requiring any restrictions on existentially-quantified formulae. Essential to our approach is the technique (due originally to McCreight et al.) of distinguishing between \"logical\" and \"physical\"\u00a0\u2026", "num_citations": "12\n", "authors": ["698"]}
{"title": "Categorical equational systems: algebraic models and equational reasoning\n", "abstract": " We introduce two abstract notions of equational algebraic system, called Equational System (ES) and Term Equational System (TES), in order to achieve sufficient expressivity as needed in modern applications in computer science. These generalize the classical concept of (enriched) algebraic theory of Kelly and Power [1993]. We also develop a theory for constructing free algebras for ESs and a theory of equational reasoning for TESs. In Part I, we introduce the general abstract, yet practical, concept of equational system and develop finitary and transfinitary conditions under which we give an explicit construction of free algebras for ESs. This free construction extends the well-known construction of free algebras for \u03c9-cocontinuous endofunctors to an equational setting, capturing the intuition that free algebras consist of freely constructed terms quotiented by given equations and congruence rules. We further show the monadicity and cocompleteness of categories of algebras for ESs under the finitary and transfinitary conditions. To illustrate the expressivity of equational systems, we exhibit various examples including two modern applications, the \u03a3-monoids of Fiore et al.[1999] and the \u03c0-algebras of Stark [2005].In Part II, we introduce the more concrete notion of term equational system, which is obtained by specializing the concept of equational system, but remains more general than that of enriched algebraic theory. We first develop a sound logical deduction system, called Term Equational Logic (TEL), for equational reasoning about algebras of TESs. Then, to pursue a complete logic, we give an internal completeness result, from which together\u00a0\u2026", "num_citations": "11\n", "authors": ["698"]}
{"title": "The transitive composability of relation transition systems\n", "abstract": " 1.1 Syntax l\u2208 Loc x\u2208 Var \u03b1\u2208 TyVar \u03c3\u2208 Typ::= \u03b1| unit| int| bool| \u03c31\u00d7 \u03c32| \u03c31+ \u03c32| \u03c31\u2192 \u03c32| \u00b5\u03b1. \u03c3|\u2200 \u03b1. \u03c3|\u2203 \u03b1. \u03c3| ref \u03c3 v\u2208 Val::= x|\u2329\u232a| n| tt| ff|\u2329 v1, v2\u232a| inj1 v| inj2 v| roll v| fix f (x). e| \u039b. e| pack v| l e\u2208 Exp::= v| if e0 then e1 else e2|\u2329 e1, e2\u232a| e. 1| e. 2| inj1 e| inj2 e|(case e of inj1 x\u21d2 e1| inj2 x\u21d2 e2)| roll e| unroll e| e1 e2| e []| pack e| unpack e1 as x in e2| ref e|! e| e1:= e2| e1== e2K\u2208 Cont::=\u2022| if K then e1 else e2|\u2329 K, e\u232a|\u2329 v, K\u232a| K. 1| K. 2| inj1 K| inj2 K| case K of [inji x\u21d2 ei]| roll K| unroll K| K e| v K| K []| pack K| unpack K as x in e| ref K|! K| K:= e| v:= K| K== e| v== K", "num_citations": "7\n", "authors": ["698"]}
{"title": "Heq: A Coq library for heterogeneous equality\n", "abstract": " We give an introduction to the library Heq, which provides a set of tactics to manipulate heterogeneous equality and explicit coercion, such as rewriting of heterogeneous equality and elimination and relocation of explicit coercions.", "num_citations": "7\n", "authors": ["698"]}
{"title": "An equational theory for weak bisimulation via generalized parameterized coinduction\n", "abstract": " Coinductive reasoning about infinitary structures such as streams is widely applicable. However, practical frameworks for developing coinductive proofs and finding reasoning principles that help structure such proofs remain a challenge, especially in the context of machine-checked formalization.", "num_citations": "6\n", "authors": ["698"]}
{"title": "Step-indexing: The good, the bad and the ugly\n", "abstract": " Over the last decade, step-indices have been widely used for the construction of operationally-based logical relations in the presence of various kinds of recursion. We first give an argument that step-indices, or something like them, seem to be required for defining realizability relations between high-level source languages and low-level targets, in the case that the low-level allows egregiously intensional operations such as reflection or comparison of code pointers. We then show how, much to our annoyance, step-indices also seem to prevent us from exploiting such operations as aggressively as we would like in proving program transformations.", "num_citations": "6\n", "authors": ["698"]}
{"title": "AliveInLean: a verified LLVM peephole optimization verifier\n", "abstract": " Ensuring that compiler optimizations are correct is important for the reliability of the entire software ecosystem, since all software is compiled. Alive\u00a0[12] is a tool for verifying LLVM\u2019s peephole optimizations. Since Alive was released, it has helped compiler developers proactively find dozens of bugs in LLVM, avoiding potentially hazardous miscompilations. Despite having verified many LLVM optimizations so far, Alive is itself not verified, which has led to at least once declaring an optimization correct when it was not.                 We introduce AliveInLean, a formally verified peephole optimization verifier for LLVM. As the name suggests, AliveInLean is a reengineered version of Alive developed in the Lean theorem prover\u00a0[14]. Assuming that the proof obligations are correctly discharged by an SMT solver, AliveInLean gives the same level of correctness guarantees as state-of-the-art formal frameworks such as\u00a0\u2026", "num_citations": "4\n", "authors": ["698"]}
{"title": "Parametric bisimulations: A logical step forward\n", "abstract": " 1.1. 2 Dynamics v\u2208 Val::= x| n|\u2329 v1, v2\u232a| inl v| inr v| fixf (x). e| roll v| cont K e\u2208 Exp::= v| e1\u2299 e2| ifz e0 then e1 else e2|\u2329 e1, e2\u232a| e. 1| e. 2| inl e| inr e|(caseeof inlx\u21d2 e1| inr x\u21d2 e2)| e1 e2| roll e| unroll e| callcc (x. e)| throw e1 to e2| isolate e K\u2208 Cont::=\u2022| K\u2299 e| v\u2299 K| ifz K then e1 else e2|\u2329 K, e\u232a|\u2329 v, K\u232a| K. 1| K. 2| inl K| inr K|(caseK of inlx\u21d2 e1| inr x\u21d2 e2)| K e| v K| roll K| unroll K| throw K to e| throw v to K| isolate K e\u21a9\u2192 e", "num_citations": "4\n", "authors": ["698"]}
{"title": "Modular data-race-freedom guarantees in the promising semantics\n", "abstract": " Local data-race-freedom guarantees, ensuring strong semantics for locations accessed by non-racy instructions, provide a fruitful methodology for modular reasoning in relaxed memory concurrency. We observe that standard compiler optimizations are in inherent conflict with such guarantees in general fully-relaxed memory models. Nevertheless, for a certain strengthening of the promising model by Lee et al. that only excludes relaxed RMW-store reorderings, we establish multiple useful local data-racefreedom guarantees that enhance the programmability aspect of the model. We also demonstrate that the performance price of forbidding these reorderings is insignificant. To the best of our knowledge, these results are the first to identify a model that includes the standard concurrency constructs, supports the efficient mapping of relaxed reads and writes to plain hardware loads and stores, and yet validates several\u00a0\u2026", "num_citations": "3\n", "authors": ["698"]}
{"title": "On the mathematical synthesis of equational logics\n", "abstract": " We provide a mathematical theory and methodology for synthesising equational logics from algebraic metatheories. We illustrate our methodology by means of two applications: a rational reconstruction of Birkhoff's Equational Logic and a new equational logic for reasoning about algebraic structure with name-binding operators.", "num_citations": "3\n", "authors": ["698"]}
{"title": "Spousal transmission of hepatitis C virus\n", "abstract": " BACKGROUND/AIMSParenteral exposure, such as transfusion, drug abuse, needle stick injury, tatooing, hemodialysis and transplantation, is well documented as the major route of transmission. But about half of hepatitis C virus (HCV) carriers have no previous history of parenteral infection. Therefore, other possible routes of the spread should be evaluated. The possibility of intrafomilial transmission of HCV was considered to be low as compared to that of hepatitis B virus (HBV), but recent publications from Japan and Europe elicit the interest in intrafamilial transrmission, especially in spousal transmission. The aim of this study is to investigate the possibility of spousal transmission of HCV.METHODSWe analyzed clinical features, serum transaminase and anti-HCV in 56 spouses who got married to anti-HCV positive patients. The mean age in index cases was 44.7 years, 45.6 in male and 43.2 in female and that of spouses was 42.4 yenrs, 45.7 in male and 40.7 in female. The mean duration of marriage was 20, 0 years, distributed from 1 to 50. Index cases included 8 asymptomatic carriers, 44 chronic hepatitis, 3 liver cirrhosis and 1 hepatoma. Four of those had previous history of blood transfusion.RESULTSAmong 56 spouses, anti-HCV was detected in 9 cases representing 16.1%. Four of those were clinically asymptomatic carriers and remaining 5 had chronic hepatitis. The mean age in index cases of anti-HCV positive spouses was 56 years old and was older than that of anti-HCV negative spouses 42.6 (P< 0.01). The mean duration of marriage in index cases of anti-HCV positive spouses was 30, 9 years and was longer than that of anti-HCV\u00a0\u2026", "num_citations": "2\n", "authors": ["698"]}
{"title": "An SMT Encoding of LLVM\u2019s Memory Model for Bounded Translation Validation\n", "abstract": " Several automatic verification tools have been recently developed to verify subsets of LLVM\u2019s optimizations. However, none of these tools has robust support to verify memory optimizations. In this paper, we present the first SMT encoding of LLVM\u2019s memory model that 1) is sufficiently precise to validate all of LLVM\u2019s intraprocedural memory optimizations, and 2) enables bounded translation validation of programs with up to hundreds of thousands of lines of code. We implemented our new encoding in Alive2, a bounded translation validation tool, and used it to uncover 21 new bugs in LLVM memory optimizations, 10 of which have been already fixed. We also found several inconsistencies in LLVM IR\u2019s official specification document (LangRef) and fixed LLVM\u2019s code and the document so they are in agreement.", "num_citations": "1\n", "authors": ["698"]}
{"title": "An Equational Theory for Weak Bisimulation via Generalized Parameterized Coinduction\n", "abstract": " Coinductive reasoning about infinitary structures such as streams is widely applicable. However, practical frameworks for developing coinductive proofs and finding reasoning principles that help structure such proofs remain a challenge, especially in the context of machine-checked formalization. This paper gives a novel presentation of an equational theory for reasoning about structures up to weak bisimulation. The theory is both compositional, making it suitable for defining general-purpose lemmas, and also incremental, meaning that the bisimulation can be created interactively. To prove the theory\u2019s soundness, this paper also introduces generalized parameterized coinduction, which addresses expressivity problems of earlier works and provides a practical framework for coinductive reasoning. The paper presents the resulting equational theory for streams, but the technique applies to other structures too. All of the results in this paper have been proved in Coq, and the generalized parameterized coinduction framework is available as a Coq library.", "num_citations": "1\n", "authors": ["698"]}
{"title": "Mathematical Synthesis of Equational Deduction Systems.\n", "abstract": " Mathematical Synthesis of Equational Deduction Systems Marcelo Fiore Page 1 Mathematical Synthesis of Equational Deduction Systems Marcelo Fiore Computer Laboratory University of Cambridge TLCA 2009 3.VII.2009 /1 Page 2 Context concrete theories meta-theories /2 Page 3 Context concrete theories '' meta-theories Calculi features: For: higher-order, formalisation, linearity, reasoning, sharing, computation, graphics, translation, type dependency, . . . ... /2-a Page 4 Context concrete theories '' meta-theories gg h Calculi features: For: higher-order, formalisation, linearity, reasoning, sharing, computation, graphics, translation, type dependency, . . . ... /2-b Page 5 Context concrete theories '' meta-theories gg h Calculi features: For: higher-order, formalisation, linearity, reasoning, sharing, computation, graphics, translation, type dependency, . . . ... Programme [1] mathematical models /2-c Page 6 Context concrete \u2026", "num_citations": "1\n", "authors": ["698"]}