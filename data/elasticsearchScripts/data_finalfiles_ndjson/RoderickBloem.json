{"title": "Synthesis of reactive (1) designs\n", "abstract": " We address the problem of automatically synthesizing digital designs from linear-time specifications. We consider various classes of specifications that can be synthesized with effort quadratic in the number of states of the reactive system, where we measure effort in symbolic steps. The synthesis algorithm is based on a novel type of game called General Reactivity of rank 1 (gr (1)), with a winning condition of the form (\u25a1\u25ca p 1\u2227\u22ef\u2227\u25a1\u25ca p m)\u2192(\u25a1\u25ca q 1\u2227\u22ef\u2227\u25a1\u25ca q n), where each p i and q i is a Boolean combination of atomic propositions. We show symbolic algorithms to solve this game, to build a winning strategy and several ways to optimize the winning strategy and to extract a system from it. We also show how to use gr (1) games to solve the synthesis of ltl specifications in many interesting cases. As empirical evidence to the generality and efficiency of our approach we include a significant case study. We describe\u00a0\u2026", "num_citations": "403\n", "authors": ["1630"]}
{"title": "Safe reinforcement learning via shielding\n", "abstract": " Reinforcement learning algorithms discover policies that maximize reward, but do not necessarily guarantee safety during learning or execution phases. We introduce a new approach to learn optimal policies while enforcing properties expressed in temporal logic. To this end, given the temporal logic specification that is to be obeyed by the learning system, we propose to synthesize a reactive system called a shield. The shield monitors the actions from the learner and corrects them only if the chosen action causes a violation of the specification. We discuss which requirements a shield must meet to preserve the convergence guarantees of the learner. Finally, we demonstrate the versatility of our approach on several challenging reinforcement learning scenarios.", "num_citations": "282\n", "authors": ["1630"]}
{"title": "Program repair as a game\n", "abstract": " We present a conservative method to automatically fix faults in a finite state program by considering the repair problem as a game. The game consists of the product of a modified version of the program and an automaton representing the LTL specification. Every winning finite state strategy for the game corresponds to a repair. The opposite does not hold, but we show conditions under which the existence of a winning strategy is guaranteed. A finite state strategy corresponds to a repair that adds variables to the program, which we argue is undesirable. To avoid extra state, we need a memoryless strategy. We show that the problem of finding a memoryless strategy is NP-complete and present a heuristic. We have implemented the approach symbolically and present initial evidence of its usefulness.", "num_citations": "251\n", "authors": ["1630"]}
{"title": "Better quality in synthesis through quantitative objectives\n", "abstract": " Most specification languages express only qualitative constraints. However, among two implementations that satisfy a given specification, one may be preferred to another. For example, if a specification asks that every request is followed by a response, one may prefer an implementation that generates responses quickly but does not generate unnecessary responses. We use quantitative properties to measure the \u201cgoodness\u201d of an implementation. Using games with corresponding quantitative objectives, we can synthesize \u201coptimal\u201d implementations, which are preferred among the set of possible implementations that satisfy a given specification.               In particular, we show how automata with lexicographic mean-payoff conditions can be used to express many interesting quantitative properties for reactive systems. In this framework, the synthesis of optimal implementations requires the solution of\u00a0\u2026", "num_citations": "229\n", "authors": ["1630"]}
{"title": "Optimizations for LTL synthesis\n", "abstract": " We present an approach to automatic synthesis of specifications given in linear time logic. The approach is based on a translation through universal co-Buchi tree automata and alternating weak tree automata (O. Kupferman and M. Vardi, 2005). By careful optimization of all intermediate automata, we achieve a major improvement in performance. We present several optimization techniques for alternating tree automata, including a game-based approximation to language emptiness and a simulation-based optimization. Furthermore, we use an incremental algorithm to compute the emptiness of nondeterministic Buchi tree automata. All our optimizations are computed in time polynomial in the size of the automaton on which they are computed. We have applied our implementation to several examples and show a significant improvement over the straightforward implementation. Although our examples are still small\u00a0\u2026", "num_citations": "188\n", "authors": ["1630"]}
{"title": "Specify, compile, run: Hardware from PSL\n", "abstract": " We propose to use a formal specification language as a high-level hardware description language. Formal languages allow for compact, unambiguous representations and yield designs that are correct by construction. The idea of automatic synthesis from specifications is old, but used to be completely impractical. Recently, great strides towards efficient synthesis from specifications have been made. In this paper we extend these recent methods to generate compact circuits and we show their practicality by synthesizing a generalized buffer and an arbiter for ARM's AMBA AHB bus from specifications given in PSL. These are the first industrial examples that have been synthesized automatically from their specifications.", "num_citations": "148\n", "authors": ["1630"]}
{"title": "Automatic hardware synthesis from specifications: A case study\n", "abstract": " We propose to use a formal specification language as a high-level hardware description language. Formal languages allow for compact, unambiguous representations and yield designs that are correct by construction. The idea of automatic synthesis from specifications is old, but used to be completely impractical. Recently, great strides towards efficient synthesis from specifications have been made. In this paper we extend these recent methods to generate compact circuits and we show their practicality by synthesizing an arbiter for ARM's AMBA AHB bus and a generalized buffer from specifications given in PSL. These are the first industrial examples that have been synthesized automatically from their specifications", "num_citations": "142\n", "authors": ["1630"]}
{"title": "Anzu: A tool for property synthesis\n", "abstract": " We present the tool Anzu. Anzu takes a formal specification of a design and generates a functionally correct system if one exists. The specification is given as a set of linear temporal logic (LTL) formulas belonging to the class of generalized reactivity of rank 1. Such formulas cover the majority of the formulas used in practice. Anzu is an implementation of the symbolic reactive(1) approach to synthesis by Piterman, Pnueli, and Sa\u2019ar. If the specification is realizable                 Anzu provides the user with a Verilog module that represents a correct finite-state system.", "num_citations": "125\n", "authors": ["1630"]}
{"title": "Decidability of parameterized verification\n", "abstract": " While the classic model checking problem is to decide whether a finite      system satisfies a specification, the goal of parameterized model      checking is to decide, given finite systems M(n)      parameterized by n \u2208 \u2115, whether, for all n \u2208 \u2115, the system M(n) satisfies a specification. In this book we consider the important case of M(n) being a      concurrent system, where the number of replicated processes      depends on the parameter n but each process is independent      of n. Examples are cache coherence protocols,  networks of finite-state      agents, and systems that solve mutual exclusion or scheduling      problems. Further examples are abstractions      of systems, where the processes of the original systems actually      depend on the parameter.  The literature in this area has studied a wealth of computational      models based on a variety of synchronization and communication      primitives, including token\u00a0\u2026", "num_citations": "121\n", "authors": ["1630"]}
{"title": "Automatic fault localization for property checking\n", "abstract": " We present an efficient fully automatic approach to fault localization for safety properties stated in linear temporal logic. We view the failure as a contradiction between the specification and the actual behavior and look for components that explain this discrepancy. We find these components by solving the satisfiability of a propositional Boolean formula. We show how to construct this formula and how to extend it so that we find exactly those components that can be used to repair the circuit for a given set of counterexamples. Furthermore, we discuss how to efficiently solve the formula by using the proper decision heuristics and simulation-based preprocessing. We demonstrate the quality and efficiency of our approach by experimental results.", "num_citations": "105\n", "authors": ["1630"]}
{"title": "Finding and fixing faults\n", "abstract": " We present a method for combined fault localization and correction for sequential systems. We assume that the specification is given in linear-time temporal logic and state the localization and correction problem as a game that is won if there is a correction that is valid for all possible inputs. For invariants, our method guarantees that a correction is found if one exists. The set of fault models we consider is very general: components can be replaced by arbitrary new functions. We compare our approach to model based diagnosis and show that it is more precise. We present experimental data that supports the applicability of our approach, obtained from a symbolic implementation of the algorithm in the Vis model checker.", "num_citations": "90\n", "authors": ["1630"]}
{"title": "A comparison of tree transductions defined by monadic second order logic and by attribute grammars\n", "abstract": " Two well-known formalisms for the specification and computation of tree transductions are compared: the mso graph transducer and the attributed tree transducer with look-ahead, respectively. The mso graph transducer, restricted to trees, uses monadic second order logic to define the output tree in terms of the input tree. The attributed tree transducer is an attribute grammar in which all attributes are trees; it is preceded by a look-ahead phase in which all attributes have finitely many values. The main result is that these formalisms are equivalent, ie, that the attributed tree transducer with look-ahead is an appropriate implementation model for the tree transductions that are specifiable in mso logic. This result holds for mso graph transducers that produce trees with shared subtrees. If no sharing is allowed, the attributed tree transducer satisfies the single use restriction.", "num_citations": "89\n", "authors": ["1630"]}
{"title": "Using unsatisfiable cores to debug multiple design errors\n", "abstract": " Due to the increasing complexity of today's circuits a high degree of automation in the design process is mandatory. The detection of faults and design errors is supported quite well using simulation or formal verification. But locating the fault site is typically a time consuming manual task. Techniques to automate debugging and diagnosis have been proposed. Approaches based on Boolean Satisfiability (SAT) have been demonstrated to be very effective. In this work debugging on the gate level is considered. Unsatisfiable cores contained in a SAT instance for debugging are used (1) to determine all suspects, and (2) to speed-up the debugging process. In comparison to standard SAT-based debugging, the experimental results show a significant speed-up for debugging multiple faults.", "num_citations": "86\n", "authors": ["1630"]}
{"title": "Automated fault localization for C programs\n", "abstract": " If a program does not fulfill a given specification, a model checker delivers a counterexample, a run which demonstrates the wrong behavior. Even with a counterexample, locating the actual fault in the source code is often a difficult task for the verification engineer.We present an automatic approach for fault localization in C programs. The method is based on model checking and reports only components that can be changed such that the difference between actual and intended behavior of the example is removed. To identify these components, we use the bounded model checker CBMC on an instrumented version of the program. We present experimental data that supports the applicability of our approach.", "num_citations": "85\n", "authors": ["1630"]}
{"title": "Formal verification of masked hardware implementations in the presence of glitches\n", "abstract": " Masking provides a high level of resistance against side-channel analysis. However, in practice there are many possible pitfalls when masking schemes are applied, and implementation flaws are easily overlooked. Over the recent years, the formal verification of masked software implementations has made substantial progress. In contrast to software implementations, hardware implementations are inherently susceptible to glitches. Therefore, the same methods tailored for software implementations are not readily applicable.                 In this work, we introduce a method to formally verify the security of masked hardware implementations that takes glitches into account. Our approach does not require any intermediate modeling steps of the targeted implementation. The verification is performed directly on the circuit\u2019s netlist in the probing model with glitches and covers also higher-order flaws. For this purpose\u00a0\u2026", "num_citations": "62\n", "authors": ["1630"]}
{"title": "Parameterized synthesis\n", "abstract": " We study the synthesis problem for distributed architectures with a parametric number of finite-state components. Parameterized specifications arise naturally in a synthesis setting, but thus far it was unclear how to detect realizability and how to perform synthesis in a parameterized setting. Using a classical result from verification, we show that for a class of specifications in indexed LTL\\X, parameterized synthesis in token ring networks is equivalent to distributed synthesis in a network consisting of a few copies of a single process. Adapting a well-known result from distributed synthesis, we show that the latter problem is undecidable. We describe a semi-decision procedure for the parameterized synthesis problem in token rings, based on bounded synthesis. We extend the approach to parameterized synthesis in token-passing networks with arbitrary topologies, and show applicability on a simple case study. Finally, we sketch a general framework for parameterized synthesis based on cutoffs and other parameterized verification techniques.", "num_citations": "61\n", "authors": ["1630"]}
{"title": "Finding and fixing faults\n", "abstract": " Knowing that a program has a bug is good, knowing its location is better, but a fix is best. We present a method to automatically locate and correct faults in a finite state system, either at the gate level or at the source level. We assume that the specification is given in Linear Temporal Logic, and state the correction problem as a game, in which the protagonist selects a faulty component and suggests alternative behavior. The basic approach is complete but as complex as synthesis. It also suffers from problems of readability: the correction may add state and logic to the system. We present two heuristics. The first avoids the doubly exponential blowup associated with synthesis by using nondeterministic automata. The second heuristic finds a memoryless strategy, which we show is an NP-complete problem. A memoryless strategy corresponds to a simple, local correction that does not add any state. The drawback of the\u00a0\u2026", "num_citations": "59\n", "authors": ["1630"]}
{"title": "Fault localization and correction with QBF\n", "abstract": " In this paper, we study the use of QBF solvers for fault localization and correction of sequential circuits. Given a violated specification, we compute whether the circuit can be repaired by evaluating a sequence of quantified Boolean formulas. If a repair exists, it can be extracted from a certificate for another quantified Boolean formula. Because it only finds components when a repair is possible, this approach is more precise than a satisfiability-based approach that we have developed earlier. We demonstrate this in an experimental evaluation.", "num_citations": "53\n", "authors": ["1630"]}
{"title": "Graph games and reactive synthesis\n", "abstract": " Graph-based games are an important tool in computer science. They have applications in synthesis, verification, refinement, and far beyond. We review graph-based games with objectives on infinite plays. We give definitions and algorithms to solve the games and to give a winning strategy. The objectives we consider are mostly Boolean, but we also look at quantitative graph-based games and their objectives. Synthesis aims to turn temporal logic specifications into correct reactive systems. We explain the reduction of synthesis to graph-based games (or equivalently tree automata) using synthesis of LTL specifications as an example. We treat the classical approach that uses determinization of parity automata and more modern approaches.", "num_citations": "47\n", "authors": ["1630"]}
{"title": "Robustness in the presence of liveness\n", "abstract": " Systems ought to behave reasonably even in circumstances that are not anticipated in their specifications. We propose a definition of robustness for liveness specifications which prescribes, for any number of environment assumptions that are violated, a minimal number of system guarantees that must still be fulfilled. This notion of robustness can be formulated and realized using a Generalized Reactivity formula. We present an algorithm for synthesizing robust systems from such formulas. For the important special case of Generalized Reactivity formulas of rank 1, our algorithm improves the complexity of [PPS06] for large specifications with a small number of assumptions and guarantees.", "num_citations": "44\n", "authors": ["1630"]}
{"title": "The 4th reactive synthesis competition (SYNTCOMP 2017): Benchmarks, participants & results\n", "abstract": " We report on the fourth reactive synthesis competition (SYNTCOMP 2017). We introduce two new benchmark classes that have been added to the SYNTCOMP library, and briefly describe the benchmark selection, evaluation scheme and the experimental setup of SYNTCOMP 2017. We present the participants of SYNTCOMP 2017, with a focus on changes with respect to the previous years and on the two completely new tools that have entered the competition. Finally, we present and analyze the results of our experimental evaluation, including a ranking of tools with respect to quantity and quality of solutions.", "num_citations": "43\n", "authors": ["1630"]}
{"title": "Shielded decision-making in MDPs\n", "abstract": " A prominent problem in artificial intelligence and machine learning is the safe exploration of an environment. In particular, reinforcement learning is a wellknown technique to determine optimal policies for complicated dynamic systems, but suffers from the fact that such policies may induce harmful behavior. We present the concept of a shield that forces decision-making to provably adhere to safety requirements with high probability. Our method exploits the inherent uncertainties in scenarios given by Markov decision processes. We present a method to compute probabilities of decision making regarding temporal logic constraints. We use that information to realize a shield that\u2014when applied to a reinforcement learning algorithm\u2014ensures (near-) optimal behavior both for the safety constraints and for the actual learning objective. In our experiments, we show on the arcade game PAC-MAN that the learning efficiency increases as the learning needs orders of magnitude fewer episodes. We show tradeoffs between sufficient progress in exploration of the environment and ensuring strict safety.", "num_citations": "39\n", "authors": ["1630"]}
{"title": "PARTY parameterized synthesis of token rings\n", "abstract": " Synthesis is the process of automatically constructing an implementation from a specification. In parameterized synthesis, we construct a single process such that the distributed system consisting of an arbitratry number of copies of the process satisfies a parameterized specification. In this paper, we present Party, a tool for parameterized synthesis from specifications in indexed linear temporal logic. Our approach extends SMT-based bounded synthesis, a flexible method for distributed synthesis, to parameterized specifications. In the current version, Party can be used to solve the parameterized synthesis problem for token-ring architectures. The tool can also synthesize monolithic systems, for which we provide a comparison to other state-of-the-art synthesis tools.", "num_citations": "38\n", "authors": ["1630"]}
{"title": "Characterization of properties and relations de ned in monadic second order logic on the nodes of trees\n", "abstract": " A formula from monadic second order (mso) logic with one free variable can be used to de ne a property of the nodes of a tree. Similarly, an mso formula with two free variables can be used to de ne a binary relation between the nodes of a tree. It is proved that a node relation is mso de nable i it can be computed by a nite-state tree-walking automaton, provided the automaton can test mso de nable properties of the nodes of the tree; if the relation is a function, the automaton is deterministic. It is also proved that a node property is mso de nable i it can be computed by an attribute grammar of which all attributes have nitely many values. mso de nable node properties are computable in linear time, mso de nable node relations in quadratic time, and mso de nable node functions in linear time.", "num_citations": "29\n", "authors": ["1630"]}
{"title": "Towards efficient parameterized synthesis\n", "abstract": " Parameterized synthesis was recently proposed as a way to circumvent the poor scalability of current synthesis tools. The method uses cut-off results in token rings to reduce the problem to bounded distributed synthesis, and thus ultimately to a sequence of SMT problems. This solves the problem of scalability in the size of the architecture, but experiments show that the size of the specification is still a major issue. In this paper we propose several optimizations of the approach. First, we tailor the SMT encoding to systems with isomorphic processes and token-ring architecture. Second, we extend the cut-off results for token rings and refine the reduction, using modularity and abstraction techniques. Some of our optimizations also apply to isomorphic or distributed synthesis in arbitrary architectures. To evaluate these optimizations, we developed the first completely automatic implementation of parameterized\u00a0\u2026", "num_citations": "27\n", "authors": ["1630"]}
{"title": "Fault localization using a model checker\n", "abstract": " If a program does not fulfill its specification, a model checker can deliver a counterexample. However, although such a counterexample shows how the specification can be violated, it typically comprises large parts of the program and gives little information about which of the visited statements is responsible for the error. In this article, we show that model checkers can also be used to perform model\u2010based diagnosis and thus fault localization. The approach leads to significantly more precise diagnoses than the state\u2010of\u2010the\u2010art and typically rules out 90\u201399% of the code as possible fault locations. The approach is general and can be applied to any system that is amenable to model checking (with respect to language and complexity). To demonstrate the applicability and high precision of our approach, we present implementations for C programs using two different model checking tools and show experimental\u00a0\u2026", "num_citations": "27\n", "authors": ["1630"]}
{"title": "Synthesis of self-stabilising and byzantine-resilient distributed systems\n", "abstract": " Fault-tolerant distributed algorithms play an increasingly important role in many applications, and their correct and efficient implementation is notoriously difficult. We present an automatic approach to synthesise provably correct fault-tolerant distributed algorithms from formal specifications in linear-time temporal logic. The supported system model covers synchronous reactive systems with finite local state, while the failure model includes strong self-stabilisation as well as Byzantine failures. The synthesis approach for a fixed-size network of processes is complete for realisable specifications, and can optimise the solution for small implementations and short stabilisation time. To solve the bounded synthesis problem with Byzantine failures more efficiently, we design an incremental, CEGIS-like loop. Finally, we define two classes of problems for which our synthesis algorithm obtains solutions that are not only\u00a0\u2026", "num_citations": "26\n", "authors": ["1630"]}
{"title": "Generic low-latency masking in hardware\n", "abstract": " In this work, we introduce a generalized concept for low-latency masking that is applicable to any implementation and protection order, and (in its most extreme form) does not require on-the-fly randomness. The main idea of our approach is to avoid collisions of shared variables in nonlinear circuit parts and to skip the share compression. We show the feasibility of our approach on a full implementation of a one-round unrolled Ascon variant and on an AES S-box case study. Additionally, we discuss possible trade-offs to make our approach interesting for practical implementations. As a result, we obtain a first-order masked AES S-box that is calculated in a single clock cycle with rather high implementation costs (60.7 kGE), and a two-cycle variant with much less implementation costs (6.7 kGE). The side-channel resistance of our Ascon S-box designs up to order three are then verified using the formal analysis tool of [BGI+ 18]. Furthermore, we introduce a taint checking based verification approach that works specifically for our low-latency approach and allows us to verify large circuits like our low-latency AES S-box design in reasonable time.", "num_citations": "24\n", "authors": ["1630"]}
{"title": "Synthesis of distributed algorithms with parameterized threshold guards\n", "abstract": " Fault-tolerant distributed algorithms are notoriously hard to get right. In this paper we introduce an automated method that helps in that process: the designer provides specifications (the problem to be solved) and a sketch of a distributed algorithm that keeps arithmetic details unspecified. Our tool then automatically fills the missing parts. Fault-tolerant distributed algorithms are typically parameterized, that is, they are designed to work for any number n of processes and any number t of faults, provided some resilience condition holds; eg, n> 3t. In this paper we automatically synthesize distributed algorithms that work for all parameter values that satisfy the resilience condition. We focus on threshold-guarded distributed algorithms, where actions are taken only if a sufficiently large number of messages is received, eg, more than t or n/2. Both expressions can be derived by choosing the right values for the coefficients a, b, and c, in the sketch of a threshold a\u00b7 n+ b\u00b7 t+ c. Our method takes as input a sketch of an asynchronous threshold-based fault-tolerant distributed algorithm\u2014where the guards are missing exact coefficients\u2014and then iteratively picks the values for the coefficients. Our approach combines recent progress in parameterized model checking of distributed algo-rithms with counterexample-guided synthesis. Besides theoretical results on termination of the synthesis procedure, we experimentally evaluate our method and show that it can synthesize sev-eral distributed algorithms from the literature, eg, Byzantine reliable broadcast and Byzantine one-step consensus. In addition, for several new variations of safety and liveness specifications\u00a0\u2026", "num_citations": "22\n", "authors": ["1630"]}
{"title": "Dependability for the Internet of Things\u2014from dependable networking in harsh environments to a holistic view on dependability\n", "abstract": " Internet of Things (IoT) applications in several domains such as surveillance of civil infrastructure, smart grids, and smart healthcare are of utmost importance for our society and require dependable performance. Guaranteeing that application-specific dependability requirements are met is however still an open research challenge. The IoT indeed exposes highly resource-constrained computing devices to harsh environmental conditions (e.g., heat, mechanical shock, electromagnetic radiation) and physical attacks. Unfortunately, traditional methods to withstand these threats heavily rely on redundancy, a concept that is incompatible with the resource constraints of common IoT devices.               In this article, we illustrate our efforts in providing methods and tools to predict, guarantee, and raise the level of dependability of the IoT. We first outline our contributions in the area of dependable wireless networking\u00a0\u2026", "num_citations": "21\n", "authors": ["1630"]}
{"title": "Automatic fault localization for property checking\n", "abstract": " We present an efficient, fully automatic approach to fault localization for safety properties stated in linear temporal logic. We view the failure as a contradiction between the specification and the actual behavior and look for components that explain this discrepancy. We find these components by solving the satisfiability of a propositional Boolean formula. We show how to construct this formula and how to extend it so that we find exactly those components that can be used to repair the circuit for a given set of counterexamples. Furthermore, we discuss how to efficiently solve the formula by using the proper decision heuristics and simulation based preprocessing. We demonstrate the quality and efficiency of our approach by experimental results.", "num_citations": "21\n", "authors": ["1630"]}
{"title": "Run-time optimization for learned controllers through quantitative games\n", "abstract": " A controller is a device that interacts with a plant. At each time point, it reads the plant\u2019s state and issues commands with the goal that the plant operates optimally. Constructing optimal controllers is a fundamental and challenging problem. Machine learning techniques have recently been successfully applied to train controllers, yet they have limitations. Learned controllers are monolithic and hard to reason about. In particular, it is difficult to add features without retraining, to guarantee any level of performance, and to achieve acceptable performance when encountering untrained scenarios. These limitations can be addressed by deploying quantitative run-time shields that serve as a proxy for the controller. At each time point, the shield reads the command issued by the controller and may choose to alter it before passing it on to the plant. We show how optimal shields that interfere as little as possible while\u00a0\u2026", "num_citations": "19\n", "authors": ["1630"]}
{"title": "Parameterized synthesis case study: AMBA AHB (extended version)\n", "abstract": " We revisit the AMBA AHB case study that has been used as a benchmark for several reactive syn- thesis tools. Synthesizing AMBA AHB implementations that can serve a large number of masters is still a difficult problem. We demonstrate how to use parameterized synthesis in token rings to obtain an implementation for a component that serves a single master, and can be arranged in a ring of arbitrarily many components. We describe new tricks -- property decompositional synthesis, and direct encoding of simple GR(1) -- that together with previously described optimizations allowed us to synthesize the model with 14 states in 30 minutes.", "num_citations": "19\n", "authors": ["1630"]}
{"title": "Bounded synthesis of register transducers\n", "abstract": " Reactive synthesis aims at automatic construction of systems from their behavioural specifications. The research mostly focuses on synthesis of systems dealing with Boolean signals. But real-life systems are often described using bit-vectors, integers, etc. Bit-blasting would make such systems unreadable, hit synthesis scalability, and is not possible for infinite data-domains. One step closer to real-life systems are register transducers\u00a0[10]: they can store data-input into registers and later output the content of a register, but they do not directly depend on the data-input, only on its comparison with the registers. Previously\u00a0[5] it was proven that synthesis of register transducers from register automata is undecidable, but there the authors considered transducers equipped with the unbounded queue of registers. First, we prove the problem becomes decidable if bound the number of registers in transducers, by\u00a0\u2026", "num_citations": "18\n", "authors": ["1630"]}
{"title": "Synthesizing multiple boolean functions using interpolation on a single proof\n", "abstract": " It is often difficult to correctly implement a Boolean controller for a complex system, especially when concurrency is involved. Yet, it may be easy to formally specify a controller. For instance, for a pipelined processor it suffices to state that the visible behavior of the pipelined system should be identical to a non-pipelined reference system (Burch-Dill paradigm). We present a novel procedure to efficiently synthesize multiple Boolean control signals from a specification given as a quantified first-order formula (with a specific quantifier structure). Our approach uses uninterpreted functions to abstract details of the design. We construct an unsatisfiable SMT formula from the given specification. Then, from just one proof of unsatisfiability, we use a variant of Craig interpolation to compute multiple coordinated interpolants that implement the Boolean control signals. Our method avoids iterative learning and back-substitution of\u00a0\u2026", "num_citations": "18\n", "authors": ["1630"]}
{"title": "Open implication\n", "abstract": " We argue that the usual trace-based notions of implication and equivalence for linear temporal logics are too strong and should be complemented by the weaker notions of open implication and open equivalence. Although open implication is harder to compute, it can be used to advantage both in model checking and in synthesis. We study the difference between trace-based equivalence and open equivalence and describe an algorithm to compute open implication of Linear Temporal Logic formulas with an asymptotically optimal complexity. We also show how to compute open implication while avoiding Safra\u2019s construction. We have implemented an open-implication solver for Generalized Reactivity(1) specifications. In a case study, we show that open equivalence can be used to justify the use of an alternative specification that allows us to synthesize much smaller systems in far less time.", "num_citations": "18\n", "authors": ["1630"]}
{"title": "Monadic second order logic and node relations on graphs and trees\n", "abstract": " A formula from monadic second-order (MSO) logic can be used to specify a binary relation on the set of nodes of a tree. It is proved that, equivalently, such a relation can be computed by a finite-state tree-walking automaton, provided the automaton can test MSO properties of the nodes of the tree. For graphs, if a binary relation on the nodes of a graph can be computed by a finite-state graph-walking automaton, then it can be specified by an MSO formula, but, in general, not vice versa.", "num_citations": "18\n", "authors": ["1630"]}
{"title": "Safe reinforcement learning using probabilistic shields\n", "abstract": " This paper concerns the efficient construction of a safety shield for reinforcement learning. We specifically target scenarios that incorporate uncertainty and use Markov decision processes (MDPs) as the underlying model to capture such problems. Reinforcement learning (RL) is a machine learning technique that can determine near-optimal policies in MDPs that may be unknown before exploring the model. However, during exploration, RL is prone to induce behavior that is undesirable or not allowed in safety-or mission-critical contexts. We introduce the concept of a probabilistic shield that enables RL decision-making to adhere to safety constraints with high probability. We employ formal verification to efficiently compute the probabilities of critical decisions within a safety-relevant fragment of the MDP. These results help to realize a shield that, when applied to an RL algorithm, restricts the agent from taking unsafe actions, while optimizing the performance objective. We discuss tradeoffs between sufficient progress in the exploration of the environment and ensuring safety. In our experiments, we demonstrate on the arcade game PAC-MAN and on a case study involving service robots that the learning efficiency increases as the learning needs orders of magnitude fewer episodes.", "num_citations": "17\n", "authors": ["1630"]}
{"title": "Diagnosis is repair\n", "abstract": " We argue that for sequential circuits, fault localization and repair are one and the same problem. We assume that a specification is given in linear temporal logic and we solve the diagnosis and repair problem for finite-state programs using games. Our approach is sound and it is complete if the specification is an invariant. In contrast to known approaches, the repair we find is valid for all possible input sequences, not just for one given test case. We show the applicability of our approach, which has a complexity comparable to that of model checking, on a set of examples.", "num_citations": "17\n", "authors": ["1630"]}
{"title": "Towards a secure scrum process for agile web application development\n", "abstract": " Agile development such as Scrum and Extreme Programming deliver software in short iterations for quick response to rapid business requirement and market changes. However, established secure software development methodologies are mostly based on linear models such as waterfall and V-model, making them unsuitable for direct application in an agile environment. This paper presents a proposal for integrating security activities into Scrum process for developing secure Web applications. We identify gaps in existing approaches to secure agile development and analyze established security engineering activities. We then adapt these activities and orchestrate them into Scrum development process to achieve both security and agility. Our proposal is evaluated by a Scrum team developing commercial JAVA EE applications in an opinion survey.", "num_citations": "16\n", "authors": ["1630"]}
{"title": "Test case generation from mutants using model checking techniques\n", "abstract": " Mutation testing is a powerful testing technique: a program is seeded with artificial faults and tested. Undetected faults can be used to improve the test bench. The problem of automatically generating test cases from undetected faults is typically not addressed by existing mutation testing systems. We propose a symbolic procedure, namely Sym BMC, for the generation of test cases from a given program using Bounded Model Checking (BMC) techniques. The Sym BMC procedure determines a test bench, that detects all seeded faults affecting the semantics of the program, with respect to a given unrolling bound. We have built a prototype tool that uses a Satisfiability Modulo Theories (SMT) solver to generate test cases and we show initial results for ANSI-C benchmark programs.", "num_citations": "15\n", "authors": ["1630"]}
{"title": "Coco: Co-design and co-verification of masked software implementations on CPUs\n", "abstract": " The protection of cryptographic implementations against power analysis attacks is of critical importance for many applications in embedded systems. The typical approach of protecting against these attacks is to implement algorithmic countermeasures, like masking. However, implementing these countermeasures in a secure and correct manner is challenging. Masking schemes require the independent processing of secret shares, which is a property that is often violated by CPU microarchitectures in practice. In order to write leakage-free code, the typical approach in practice is to iteratively explore instruction sequences and to empirically verify whether there is leakage caused by the hardware for this instruction sequence or not. Clearly, this approach is neither efficient, nor does it lead to rigorous security statements.", "num_citations": "14\n", "authors": ["1630"]}
{"title": "Automatic testing through planning\n", "abstract": " We describe a strategy to automatically test software built using pre-and postconditions. The strategy searches for valid routine calls: calls for which the preconditions are satisfied. If such calls fail (because the postcondition or another check is violated), we have found a bug. The testing strategy automatically builds a model of the software under test. The model is an abstract version of the semantics given by the pre-and postconditions. We use planning and learning to find a sequence of instructions that constructs the arguments to a valid routine call. The strategy is fully automatic and can be used to find bugs without intervention of the user. The generated test cases complement the unit tests that a designer may write by hand. We also illustrate the use of our experimental implementation on a non-trivial example.", "num_citations": "12\n", "authors": ["1630"]}
{"title": "Synthesis of minimum-cost shields for multi-agent systems\n", "abstract": " In this paper, we propose a general approach to derive runtime enforcement implementations for multiagent systems, called shields, from temporal logical specifications. Each agent of the multi-agent system is monitored, and if needed corrected, by the shield, such that a global specification is always satisfied. The different ways of how a shield can interfere with each agent in the system in case of an error introduces the need for quantitative objectives. This work is the first to discuss the shield synthesis problem with quantitative objectives. We provide several cost functions that are utilized in the multi-agent setting and provide methods for the synthesis of cost-optimal shields and fair shields, under the given assumptions on the multi-agent system. We demonstrate the applicability of our approach via a detailed case study on UAV mission planning for warehouse logistics and simulating the shielded multi-agent\u00a0\u2026", "num_citations": "11\n", "authors": ["1630"]}
{"title": "Generalized reactivity (1) synthesis without a monolithic strategy\n", "abstract": " We present a new approach to synthesizing systems from Generalized Reactivity(1) specifications. Our method does not require a monolithic strategy, which can be prohibitively large. Instead, our approach constructs a circuit directly from the iterates of the fixpoint computation that computes the winning region. We build the overall system by combining these circuit parts. Our approach has generally lower memory requirements than previous GR(1) synthesis approaches, and is also faster. In addition to that, the circuits we build are eager, in the sense that they typically fulfill system guarantees faster than the circuits obtained with previous approaches, as experiments show.", "num_citations": "10\n", "authors": ["1630"]}
{"title": "Shield synthesis for reinforcement learning\n", "abstract": " Reinforcement learning algorithms discover policies that maximize reward. However, these policies generally do not adhere to safety, leaving safety in reinforcement learning (and in artificial intelligence in general) an open research problem. Shield synthesis is a formal approach to synthesize a correct-by-construction reactive system called a shield that enforces safety properties of a running system while interfering with its operation as little as possible. A shield attached to a learning agent guarantees safety during learning and execution phases. In this paper we summarize three types of shields that are synthesized from different specification languages, and discuss their applicability to reinforcement learning. First, we discuss deterministic shields that enforce specifications expressed as linear temporal logic specifications. Second, we discuss the synthesis of probabilistic shields from specifications in probabilistic\u00a0\u2026", "num_citations": "9\n", "authors": ["1630"]}
{"title": "Search Techniques and Automata for Symbolic Model Checking\n", "abstract": " Model checking addresses correctness of finite-state systems by formal methods. It automatically either proves the user-defined properties of the system correct, or refutes them. The algorithms involve searching very large graphs and are memory and time intensive. In our application, we use BDD-based symbolic methods that consider sets of nodes at a time", "num_citations": "9\n", "authors": ["1630"]}
{"title": "Approximations for fixpoint computations in symbolic model checking\n", "abstract": " We review the techniques for over-and underapproximation used in symbolic model checking and their applications to the efficient computation of fixpoints.", "num_citations": "8\n", "authors": ["1630"]}
{"title": "The reactive synthesis competition: Syntcomp 2016 and beyond\n", "abstract": " We report on the design of the third reactive synthesis competition (SYNTCOMP 2016), including a major extension of the competition to specifications in full linear temporal logic. We give a brief overview of the synthesis problem as considered in SYNTCOMP, and present the rules of the competition in 2016, as well as the ideas behind our design choices. Furthermore, we evaluate the recent changes to the competition based on the experiences with SYNTCOMP 2016. Finally, we give an outlook on further changes and extensions of the competition that are planned for the future.", "num_citations": "7\n", "authors": ["1630"]}
{"title": "Reduction of resolution refutations and interpolants via subsumption\n", "abstract": " Propositional resolution proofs and interpolants derived from them are widely used in automated verification and circuit synthesis. There is a broad consensus that \u201csmall is beautiful\u201d\u2014small proofs and interpolants lead to concise abstractions in verification and compact designs in synthesis.Contemporary proof reduction techniques either minimise the proof during construction, or perform a post-hoc transformation of a given resolution proof. We focus on the latter class and present a subsumption-based proof reduction algorithm that extends existing singlepass analyses and relies on a meet-over-all-paths analysis to identify redundant resolution steps and clauses.We show that smaller refutations do not necessarily entail smaller interpolants, and use labelled interpolation systems to generalise our reduction approach to interpolants. Experimental results support the theoretical claims.", "num_citations": "6\n", "authors": ["1630"]}
{"title": "Controller synthesis for pipelined circuits using uninterpreted functions\n", "abstract": " We present a novel abstraction-based approach to controller synthesis based on the use of a logic with uninter-preted functions, arrays, equality, and limited quantification. Extending the Burch-Dill paradigm for the verification of pipelined processors, we show how to use this logic to synthesize the Boolean control of a pipelined circuit, using a sequential version as the specification. Thus, we tackle the main difficulty in constructing concurrent systems, that of constructing a control that prevents conflicts due to concurrency. At the same time, we avoid the complexity of the datapath, taking advantage of the fact that it must mirror the operations in the sequential variant. We start with the controller's specification, an equivalence criterion written in a fragment of second-order logic, stating that for all possible inputs/states, there exist Boolean control values such that the outcome is correct. We show how to decide such\u00a0\u2026", "num_citations": "6\n", "authors": ["1630"]}
{"title": "Game-based and simulation-based improvements for LTL synthesis\n", "abstract": " Game-based and Simulation-based Improvements for LTL Synthesis Page 1 Graz University of Technology Professor Horst Cerjak, 19.12.2005 1 Barbara Jobstmann Seattle, Aug 21st Improvements for LTL Synthesis Game-based and Simulation-based Improvements for LTL Synthesis Barbara Jobstmann Roderick Bloem Graz University of Technology, Austria August 21st, 2006 Page 2 Graz University of Technology Professor Horst Cerjak, 19.12.2005 2 Barbara Jobstmann Seattle, Aug 21st Improvements for LTL Synthesis Motivation \u25cf Synthesis from specification fascinating \u25cf Correct by construction - no verification \u25cf You say what, it tells how! \u25cf Goes back to Church (1962) \u25cf What has changed since then? Page 3 Graz University of Technology Professor Horst Cerjak, 19.12.2005 3 Barbara Jobstmann Seattle, Aug 21st Improvements for LTL Synthesis Outline \u25cf Introduction \u25cf Safraless Approach \u25cf Steps and \u2026", "num_citations": "6\n", "authors": ["1630"]}
{"title": "Case study: Automatic test case generation for a secure cache implementation\n", "abstract": " While many approaches for automatic test case generation have been proposed over the years, it is often difficult to predict which of them may work well on concrete problems. In this paper, we therefore present a case study in automatic, model-based test case generation: We implemented several graph-based methods that compute test cases with a model checker using trap properties, and evaluate these methods on a Secure Block Device implementation. We compare the number of generated test cases, the required generation time and the achieved code coverage. Our conclusions are twofold: First, automatic test case generation is feasible and beneficial for this case study, and even found a real bug in the implementation. Second, simple coverage methods on the model may already yield test suites of sufficient quality.", "num_citations": "5\n", "authors": ["1630"]}
{"title": "Formal analysis of a TPM-based secrets distribution and storage scheme\n", "abstract": " Trusted computing introduces the Trusted Platform Module (TPM) as a root of trust on an otherwise untrusted computer. The TPM can be used to restrict the use of cryptographic keys to trusted states, i.e., to situations in which the computer runs trusted software. This allows for the distribution of intellectual property or secrets to a remote party with a reasonable security that such secrets will not be obtained by a malicious or compromised client. We model a specific protocol for the distribution of secrets proposed by Sevine et al. A formal analysis using the NuSMV model checker shows that the protocol allows an intruder to give the client an arbitrary secret, without the client noticing. We propose an alternative that prevents this scenario.", "num_citations": "5\n", "authors": ["1630"]}
{"title": "The 5th reactive synthesis competition\u2014SYNTCOMP 2018\n", "abstract": " AIGER-based Safety Track of SYNTCOMP\u2022 synthesis problem defined by AIGER circuit A, with controllable (C) and uncontrollable (U) inputs, and single output error\u2022 solution of synthesis problem is an AIG that includes original AIG A, and adds control structure B for inputs C such that resulting system never raises error", "num_citations": "4\n", "authors": ["1630"]}
{"title": "CTL* synthesis via LTL synthesis\n", "abstract": " We reduce synthesis for CTL* properties to synthesis for LTL. In the context of model checking this is impossible - CTL* is more expressive than LTL. Yet, in synthesis we have knowledge of the system structure and we can add new outputs. These outputs can be used to encode witnesses of the satisfaction of CTL* subformulas directly into the system. This way, we construct an LTL formula, over old and new outputs and original inputs, which is realisable if, and only if, the original CTL* formula is realisable. The CTL*-via-LTL synthesis approach preserves the problem complexity, although it might increase the minimal system size. We implemented the reduction, and evaluated the CTL*-via-LTL synthesiser on several examples.", "num_citations": "4\n", "authors": ["1630"]}
{"title": "Reactive synthesis\n", "abstract": " Summary form only given. Synthesis is the question of how to construct a correct system from a specification. In recent years, synthesis has made major steps from a theoretists dream towards a practical design tool. While synthesis from a language like LTL has very high complexity, synthesis can be quite practical when we are willing to compromise on the specification formalism. Similarly, we can take a pragmatic approach to synthesize small distributed systems, a problem that is in general undecidable.", "num_citations": "4\n", "authors": ["1630"]}
{"title": "Specification-centered robustness\n", "abstract": " In addition to being correct, a system should be robust, that is, it should behave reasonably even after receiving unexpected inputs. In this paper, we summarize two formal notions of robustness that we have introduced previously for reactive systems. One of the notions is based on assigning costs for failures on a user-provided notion of incorrect transitions in a specification. Here, we define a system to be robust if a finite number of incorrect inputs does not lead to an infinite number of incorrect outputs. We also give a more refined notion of robustness that aims to minimize the ratio of output failures to input failures. The second notion is aimed at liveness. In contrast to the previous notion, it has no concept of recovery from an error. Instead, it compares the ratio of the number of liveness constraints that the system violates to the number of liveness constraints that the environment violates.", "num_citations": "4\n", "authors": ["1630"]}
{"title": "Adaptive shielding under uncertainty\n", "abstract": " This paper targets control problems that exhibit specific safety and performance requirements. In particular, the aim is to ensure that an agent, operating under uncertainty, will at runtime strictly adhere to such requirements. Previous works create so-called shields that correct an existing controller for the agent if it is about to take unbearable safety risks. However, so far, shields do not consider that an environment may not be fully known in advance and may evolve for complex control and learning tasks. We propose a new method for the efficient computation of a shield that is adaptive to a changing environment. In particular, we base our method on problems that are sufficiently captured by potentially infinite Markov decision processes (MDP) and quantitative specifications such as mean payoff objectives. The shield is independent of the controller, which may, for instance, take the form of a high-performing\u00a0\u2026", "num_citations": "3\n", "authors": ["1630"]}
{"title": "Online Shielding for Stochastic Systems\n", "abstract": " We propose a method to develop trustworthy reinforcement learning systems. To ensure safety especially during exploration, we automatically synthesize a correct-by-construction runtime enforcer, called a shield, that blocks all actions of the agent that are unsafe with respect to a temporal logic specification. Our main contribution is a new synthesis algorithm for computing the shield online. Existing offline shielding approaches compute exhaustively the safety of all states-action combinations ahead-of-time, resulting in huge computation times, large memory consumption, and significant delays at runtime due to the look-ups in huge databases. The intuition behind online shielding is to compute at runtime the set of all states that could be reached in the near future. For each of these states, the safety of all available actions is analysed and used for shielding as soon as one of the considered states is reached. Our\u00a0\u2026", "num_citations": "3\n", "authors": ["1630"]}
{"title": "Learning Mealy Machines with One Timer.\n", "abstract": " We present Mealy machines with a single timer (MM1Ts), a class of models that is both sufficiently expressive to describe the realtime behavior of many realistic applications, and can be learned efficiently. We show how learning algorithms for MM1Ts can be obtained via a reduction to the problem of learning Mealy machines. We describe an implementation of an MM1T learner on top of LearnLib, and compare its performance with recent algorithms proposed by Aichernig et al. and An et al. on several realistic benchmarks.", "num_citations": "3\n", "authors": ["1630"]}
{"title": "It's Time to Play Safe: Shield Synthesis for Timed Systems\n", "abstract": " Erroneous behaviour in safety critical real-time systems may inflict serious consequences. In this paper, we show how to synthesize timed shields from timed safety properties given as timed automata. A timed shield enforces the safety of a running system while interfering with the system as little as possible. We present timed post-shields and timed pre-shields. A timed pre-shield is placed before the system and provides a set of safe outputs. This set restricts the choices of the system. A timed post-shield is implemented after the system. It monitors the system and corrects the system's output only if necessary. We further extend the timed post-shield construction to provide a guarantee on the recovery phase, i.e., the time between a specification violation and the point at which full control can be handed back to the system. In our experimental results, we use timed post-shields to ensure the safety in a reinforcement learning setting for controlling a platoon of cars, during the learning and execution phase, and study the effect.", "num_citations": "3\n", "authors": ["1630"]}
{"title": "Small faults grow up-verification of error masking robustness in arithmetically encoded programs\n", "abstract": " The increasing prevalence of soft errors and security concerns due to recent attacks like rowhammer have caused increased interest in the robustness of software against bit flips.               Arithmetic codes can be used as a protection mechanism to detect small errors injected in the program\u2019s data. However, the accumulation of propagated errors can increase the number of bits flips in a variable - possibly up\u00a0to an undetectable level.               The effect of error masking can occur: An error weight exceeds the limitations of the code and a new, valid, but incorrect code word is formed. Masked errors are undetectable, and it is crucial to check variables for bit flips before error masking can occur.               In this paper, we develop a theory of provably robust arithmetic programs. We focus on the interaction of bit flips that can happen at different locations in the program and the propagation and possible masking of\u00a0\u2026", "num_citations": "3\n", "authors": ["1630"]}
{"title": "Safe Reinforcement Learning via Probabilistic Shields\n", "abstract": " This paper targets the efficient construction of a safety shield for decision making in scenarios that incorporate uncertainty. Markov decision processes (MDPs) are prominent models to capture such planning problems. Reinforcement learning (RL) is a machine learning technique to determine near-optimal policies in MDPs that may be unknown prior to exploring the model. However, during exploration, RL is prone to induce behavior that is undesirable or not allowed in safety- or mission-critical contexts. We introduce the concept of a probabilistic shield that enables decision-making to adhere to safety constraints with high probability. In a separation of concerns, we employ formal verification to efficiently compute the probabilities of critical decisions within a safety-relevant fragment of the MDP. We use these results to realize a shield that is applied to an RL algorithm which then optimizes the actual performance objective. We discuss tradeoffs between sufficient progress in exploration of the environment and ensuring safety. In our experiments, we demonstrate on the arcade game PAC-MAN and on a case study involving service robots that the learning efficiency increases as the learning needs orders of magnitude fewer episodes.", "num_citations": "3\n", "authors": ["1630"]}
{"title": "Sharing independence & relabeling: efficient formal verification of higher-order masking\n", "abstract": " The efficient verification of the security of masked hardware implementations is an important issue that hinders the development and deployment of randomness-efficient masking techniques. At EUROCRYPT 2018, Bloem et al.[6] introduced the first practical formal tool to prove the side-channel resilience of masked circuits in the probing model with glitches. Most recently Barthe et al.[2] introduced a more efficient formal tool that builds upon the findings of Bloem et al. for modeling the effects of glitches. While Barthe et al.'s approach greatly improves the first-order verification performance, it shows that higher-order verification in the probing model with glitches is still enormously time-consuming for larger circuits like a second-order AES S-box, for instance. Furthermore, the results of Barthe et al. underline the discrepancy between state-of-the-art formal security notions that allow for faster verification of circuits. Namely the strong non-interference (SNI) notion, and existing masked hardware implementations that are secure in the probing model with glitches. In this work, we extend and improve the formal approaches of Bloem et al. and Barthe et al. on manifold levels. We first introduce a so-called sharing independence notion which helps to reason about the independence of shared variables. We then show how to use this notion to test for the independence of input and output sharings of a module which allows speeding up the formal verification of circuits that do not fulfill the SNI notion. With this extension, we are for the time able to verify the security of a second-order masked DOM AES S-box which takes about 3 seconds, and up to a fifth-order\u00a0\u2026", "num_citations": "3\n", "authors": ["1630"]}
{"title": "Bounded Synthesis for Streett, Rabin, and \n", "abstract": " SMT-based bounded synthesis uses an SMT solver to synthesize systems from LTL properties by going through co-B\u00fcchi automata. In this paper, we show how to extend the ranking functions used in Bounded Synthesis, and thus the bounded synthesis approach, to B\u00fcchi, Parity, Rabin, and Streett conditions. We show that we can handle both existential and universal properties this way, and therefore, that we can extend Bounded Synthesis to . Thus, we obtain the first Safraless synthesis approach and the first synthesis tool for (conjunctions of) the acceptance conditions mentioned above, and for .", "num_citations": "3\n", "authors": ["1630"]}
{"title": "Debugging Design Errors by Using Unsatisfiable Cores.\n", "abstract": " Due to the increasing complexity of today\u2019s circuits a high degree of automation in the design process is mandatory. The detection of faults and design errors is supported quite well using simulation or formal verification. But locating the fault site is typically a time consuming manual task. Techniques to automate debugging and diagnosis have been proposed. Approaches based on Boolean Satisfiability (SAT) have been demonstrated to be very effective. In this work debugging on the gate level is considered. Unsatisfiable cores contained in a SAT instance for debugging are used (1) to determine all suspects, and (2) to speed-up the debugging process. In comparison to standard SAT-based debugging, the experimental results show a significant speed-up for debugging multiple faults.", "num_citations": "3\n", "authors": ["1630"]}
{"title": "Attribute Grammars and Monadic Second Order Logic\n", "abstract": " It is shown that formulas in monadic second order logic (mso) with one free variable can be mimicked by attribute grammars with a designated boolean attribute and vice versa. We prove that mso formulas with two free variables have the same power in de ning binary relations on nodes of a tree as regular path languages have. For graphs in general, mso formulas turn out to be stronger. We also compare path languages against the routing languages of Klarlund and Schwartzbach. We compute the complexity of evaluating mso formulas with free variables, especially in the case where there is a dependency between free variables of the formula.", "num_citations": "3\n", "authors": ["1630"]}
{"title": "Efficient information-flow verification under speculative execution\n", "abstract": " We study the formal verification of information-flow properties in the presence of speculative execution and side-channels. First, we present a formal model of speculative execution semantics. This model can be parameterized by the depth of speculative execution and is amenable to a range of verification techniques. Second, we introduce a novel notion of information leakage under speculation, which is parameterized by the information that is available to an attacker through side-channels. Finally, we present one verification technique that uses our formalism and can be used to detect information leaks under speculation through cache side-channels, and can decide whether these are only possible under speculative execution. We implemented an instance of this verification technique that combines taint analysis and safety model checking. We evaluated this approach on a range of examples that have been\u00a0\u2026", "num_citations": "2\n", "authors": ["1630"]}
{"title": "Reactive synthesis modulo theories using abstraction refinement\n", "abstract": " Reactive synthesis builds a system from a specification given as a temporal logic formula. Traditionally, reactive synthesis is defined for systems with Boolean input and output variables. Recently, new theories and techniques have been proposed to extend reactive synthesis to data domains, which are required for more sophisticated programs. In particular, Temporal stream logic(TSL) (Finkbeiner et al. 2019) extends LTL with state variables, updates, and uninterpreted functions and was created for use in synthesis. We present a synthesis procedure for TSL(T), an extension of TSL with theories. Synthesis is performed using a counter-example guided synthesis loop and an LTL synthesis procedure. Our method translates TSL(T) specifications to LTL and extracts a system if synthesis is successful. Otherwise, it analyzes the counterstrategy for inconsistencies with the theory. If the counterstrategy is theory-consistent, it proves that the specification is unrealizable. Otherwise, we add temporal assumptions and Boolean predicates to the TSL(T) specification and start the next iteration of the the loop. We show that the synthesis problem for TSL (T) is undecidable. Nevertheless our method can successfully synthesize or show unrealizability of several non-Boolean examples.", "num_citations": "1\n", "authors": ["1630"]}
{"title": "Proving SIFA protection of masked redundant circuits\n", "abstract": " Implementation attacks like side-channel and fault attacks pose a considerable threat to cryptographic devices that are physically accessible by an attacker. As a consequence, devices like smart cards implement corresponding countermeasures like redundant computation and masking. Recently, statistically ineffective fault attacks (SIFA) were shown to be able to circumvent these classical countermeasure techniques. We present a new approach for verifying the SIFA protection of arbitrary masked implementations in both hardware and software. The proposed method uses Boolean dependency analysis, factorization, and known properties of masked computations to show whether the fault detection mechanism of redundant masked circuits can leak information about the processed secret values. We implemented this new method in a tool called Danira, which can show the SIFA resistance of cryptographic implementations like AES S-Boxes within minutes.", "num_citations": "1\n", "authors": ["1630"]}
{"title": "Placement of Runtime Checks to Counteract Fault Injections\n", "abstract": " Bitflips form an increasingly serious problem for the correctness and security of software and hardware, whether they occur inadvertently as soft errors or on purpose as fault injections. Error Detection Codes add redundancy and make it possible to check for faults during runtime, making systems more resilient to bitflips. Codes require data integrity to be checked regularly. Such checks need to be used sparingly, because they cause runtime overhead.                 In this paper, we show how to use static verification to minimize the number of runtime checks in encoded programs. We focus on loops, because this is where it is important to avoid unnecessary checks. We introduce three types of abstractions to decide correctness: depending on (i) whether we keep track of errors precisely or of their Hamming weights, (ii) how we check whether faults can still be detected, and (iii) whether we keep track of the data or\u00a0\u2026", "num_citations": "1\n", "authors": ["1630"]}
{"title": "QBF Solving by Counterexample-guided Expansion\n", "abstract": " We introduce a novel generalization of Counterexample-Guided Inductive Synthesis (CEGIS) and instantiate it to yield a novel, competitive algorithm for solving Quantified Boolean Formulas (QBF). Current QBF solvers based on counterexample-guided expansion use a recursive approach which scales poorly with the number of quantifier alternations. Our generalization of CEGIS removes the need for this recursive approach, and we instantiate it to yield a simple and efficient algorithm for QBF solving. Lastly, this research is supported by a competitive, though straightforward, implementation of the algorithm, making it possible to study the practical impact of our algorithm design decisions, along with various optimizations.", "num_citations": "1\n", "authors": ["1630"]}
{"title": "Security concepts for a distributed architecture for activity logging and analysis\n", "abstract": " We describe security concepts for a distributed architecture for activity logging and analysis. The described system collects user and usage data from multiple devices (PC and mobile). Such data is used to create open learner models for reflection on and improvement of time management. Additionally, such data is the basis for adaptation of notification mechanisms. We propose concepts for secure local storage of collected data, network communication and user authentication, and secure data storage and processing on the server side. We only touch partially on security concepts for client services and applications. The proposed concept is thus applicable for all systems with distributed activity logging and server-based analysis components.", "num_citations": "1\n", "authors": ["1630"]}
{"title": "Better quality in synthesis through quantitative objectives\n", "abstract": " Most specification languages express only qualitative constraints. However, among two implementations that satisfy a given specification, one may be preferred to another. For example, if a specification asks that every request is followed by a response, one may prefer an implementation that generates responses quickly but does not generate unnecessary responses. We use quantitative properties to measure the \"goodness\" of an implementation. Using games with corresponding quantitative objectives, we can synthesize \"optimal\" implementations, which are preferred among the set of possible implementations that satisfy a given specification. In particular, we show how automata with lexicographic mean-payoff conditions can be used to express many interesting quantitative properties for reactive systems. In this framework, the synthesis of optimal implementations requires the solution of lexicographic mean\u00a0\u2026", "num_citations": "1\n", "authors": ["1630"]}
{"title": "Repair of Boolean programs using games\n", "abstract": " We show how to find and fix faults in Boolean programs by extending the program to a game. In the game, the protagonist can choose which statement is incorrect and how to repair it. If she can do this successfully using a memoryless strategy, we have found a fault plus a correction. We discuss how this technique can be used to fix faults in programs written in a language like C, by using the Boolean programs that are produced as abstractions in approaches such as SLAM and MAGIC.", "num_citations": "1\n", "authors": ["1630"]}