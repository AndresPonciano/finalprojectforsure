{"title": "The art and science of software release planning\n", "abstract": " Incremental development provides customers with parts of a system early, so they receive both a sense of value and an opportunity to provide feedback early in the process. Each system release is thus a collection of features that the customer values. Furthermore, each release serves to fix defects detected in former product variants. Release planning (RP) addresses decisions related to selecting and assigning features to create a sequence of consecutive product releases that satisfies important technical, resource, budget, and risk constraints.", "num_citations": "344\n", "authors": ["171"]}
{"title": "The cognitive process of decision making\n", "abstract": " Decision making is one of the basic cognitive processes of human behaviors by which a preferred option or a course of actions is chosen from among a set of alternatives based on certain criteria. Decision theories are widely applied in many disciplines encompassing cognitive informatics, computer science, management science, economics, sociology, psychology, political science, and statistics. A number of decision strategies have been proposed from different angles and applica-tion domains such as the maximum expected utility and Bayesian method. However, there is still a lack of a fundamental and mathematical decision model and a rigorous cognitive process for decision making. This article presents a fundamental cognitive decision making process and its mathematical model, which is described as a sequence of Cartesian-product based selections. A rigorous description of the decision process in real\u00a0\u2026", "num_citations": "324\n", "authors": ["171"]}
{"title": "On spanning tree problems with multiple objectives\n", "abstract": " We investigate two versions of multiple objective minimum spanning tree problems defined on a network with vectorial weights. First, we want to minimize the maximum ofQ linear objective functions taken over the set of all spanning trees (max-linear spanning tree problem, ML-ST). Secondly, we look for efficient spanning trees (multi-criteria spanning tree problem, MC-ST).               Problem ML-ST is shown to be NP-complete. An exact algorithm which is based on ranking is presented. The procedure can also be used as an approximation scheme. For solving the bicriterion MC-ST, which in the worst case may have an exponential number of efficient trees, a two-phase procedure is presented. Based on the computation of extremal efficient spanning trees we use neighbourhood search to determine a sequence of solutions with the property that the distance between two consecutive solutions is less than a\u00a0\u2026", "num_citations": "209\n", "authors": ["171"]}
{"title": "A flexible method for software effort estimation by analogy\n", "abstract": " Effort estimation by analogy uses information from former similar projects to predict the effort for a new project. Existing analogy-based methods are limited by their inability to handle non-quantitative data and missing values. The accuracy of predictions needs improvement as well. In this paper, we propose a new flexible method called AQUA that is able to overcome the limitations of former methods. AQUA combines ideas from two known analogy-based estimation techniques: case-based reasoning and collaborative filtering. The method is applicable to predict effort related to any object at the requirement, feature, or project levels. Which are the main contributions of AQUA when compared to other methods? First, AQUA supports non-quantitative data by defining similarity measures for different data types. Second, it is able to tolerate missing values. Third, the results from an explorative study in this paper\u00a0\u2026", "num_citations": "184\n", "authors": ["171"]}
{"title": "Product release planning: methods, tools and applications\n", "abstract": " Business success hinges on successfully creating products with the right features. You must correctly analyze the needs of the customer and match these needs with your resources to not only produce a product and but also deliver it in a timely manner. An in-depth understanding of systematic release planning can put you on this path. Authored by ren", "num_citations": "153\n", "authors": ["171"]}
{"title": "Hybrid intelligence in software release planning\n", "abstract": " There is a growing recognition that an incremental approach to software development is often more suitable and less risky than the traditional waterfall approach. Delivering software in an incremental fashion suggests better customer satisfaction and reduces many of the risks associated with delivering large software projects. In this paper, we consider the problem of deciding which requirements should be assigned to which release. The proposed hybrid approach called EVOLVE* improves existing methods for release planning by combining the strength of mathematical models with the subtleness of experts\u2019 knowledge and judgment. It makes use of different computationally intelligent techniques such as evolutionary computing and principles of multi-criteria decision aid. This is combined with appropriate involvement of human intelligence. EVOLVE* consists of three main phases called modeling, exploration\u00a0\u2026", "num_citations": "146\n", "authors": ["171"]}
{"title": "Supporting software release planning decisions for evolving systems\n", "abstract": " Large-scale software systems constantly change during system evolution for feature enhancement. Most of the features originate from diverse stakeholders that require their needs to be met despite resource and risk constraints. In such large systems, the number of features requested during the different releases of the system typically exceeds the available resources. Release planning involves decision making about what new features or changes to implement during which release of the software. Existing release planning techniques are not targeted at evolving systems; in this case, knowledge about existing software product is core to making meaningful release decisions. In this paper, we describe ten key technical and nontechnical aspects impacting release planning. Based on these aspects, we evaluate seven existing release planning methods. We have also proposed a new release planning framework that\u00a0\u2026", "num_citations": "126\n", "authors": ["171"]}
{"title": "Software engineering decision support\u2013a new paradigm for learning software organizations\n", "abstract": " Software development and evolution is characterized by multiple objectives and constraints, by a huge amount of uncertainty, incomplete information and changing problem parameters. Success of software development very much depends on providing the right knowledge at the right time, at the right place, and for the appropriate person. Experience factory and organizational learning approaches are increasingly used to improve software development practices.               The paradigm of Software Engineering Decision Support (SEDS) goes beyond the concept of reusing models, knowledge or experience. For more focused problem domain, emphasis is on providing methodology for generation, evaluation, prioritization and selection of solution alternatives. Typically, modelling, measurement, empirical and simulation-type investigations are combined with intelligent methods of analysis and reasoning to\u00a0\u2026", "num_citations": "121\n", "authors": ["171"]}
{"title": "Bi-objective release planning for evolving software systems\n", "abstract": " The release planning (RP) problem can be investigated from two dimensions--what to release and when to release. We investigate the\" what\" to release decision in terms of which new features or change requests should be assigned and implemented in which releases of a software system. RP for evolving systems is challenging, because the new features might require changes to the existing system. A major drawback of existing RP methods is that, they do not consider the existing systems in making RP decisions. In this paper, we present a technique to detect coupling between features based on relatedness of the components that would implement the features. The components implementing the features are derived from change impact analysis. We integrate the results from feature coupling into a RP strategy that encourages the assignment of highly coupled features in the same release. This helps to avoid\u00a0\u2026", "num_citations": "119\n", "authors": ["171"]}
{"title": "Release planning\n", "abstract": " A method of software release planning. The method comprises the steps of assigning stakeholder priorities to a set of requirements for software; explicitly defining a set of constraints on the requirements; and operating on the stakeholder priorities with algorithms using a computer, subject to the constraints, to generate at least one release plan solution. Priorities are balanced between priorities of multiple stakeholders, and between the impact of various release plan solutions on project time, overall benefit, and quality of the software. A set of near optimal and maximally distinct solutions is generated.", "num_citations": "95\n", "authors": ["171"]}
{"title": "Intelligent support for selection of COTS products\n", "abstract": " Intelligent Decision Support is considered in unstructured decision situations characterized by one or more of the following factors: complexity, uncertainty, multiple groups with a stake in the decision outcome (multiple stakeholders), a large amount of information (especially company data), and/or rapid change in information. Support here means to provide access to information that would otherwise be unavailable or difficult to obtain; to facilitate generation and evaluation of solution alternatives, and to prioritize alternatives by using explicit models that provide structure for particular decisions.               Integration of commercial off the shelf (COTS) products as elements of larger systems is a promising new paradigm. In this paper, we focus on the selection of COTS products. This is characterized as a problem with a high degree of inherent uncertainty, incompleteness of information, dynamic changes and\u00a0\u2026", "num_citations": "90\n", "authors": ["171"]}
{"title": "Analysis of attribute weighting heuristics for analogy-based software effort estimation method AQUA+\n", "abstract": " Estimation by analogy (EBA) predicts effort for a new project by aggregating effort information of similar projects from a given historical data set. Existing research results have shown that a careful selection and weighting of attributes may improve the performance of the estimation methods. This paper continues along that research line and considers weighting of attributes in order to improve the estimation accuracy. More specifically, the impact of weighting (and selection) of attributes is studied as extensions to our former EBA method AQUA, which has shown promising results and also allows estimation in the case of data sets that have non-quantitative attributes and missing values. The new resulting method is called AQUA+. For attribute weighting, a qualitative analysis pre-step using rough set analysis (RSA) is performed. RSA is a proven machine learning technique for classification of objects. We\u00a0\u2026", "num_citations": "87\n", "authors": ["171"]}
{"title": "Release Practices for Mobile Apps--What do Users and Developers Think?\n", "abstract": " Large software organizations such as Facebook or Netflix, who otherwise make daily or even hourly releases of their web applications using continuous delivery, have had to invest heavily into a customized release strategy for their mobile apps, because the vetting process of app stores introduces lag and uncertainty into the release process. Amidst these large, resourceful organizations, it is unknown how the average mobile app developer organizes her app's releases, even though an incorrect strategy might bring a premature app update to the market that drives away customers towards the heavy market competition. To understand the common release strategies used for mobile apps, the rationale behind them and their perceived impact on users, we performed two surveys with users and developers. We found that half of the developers have a clear strategy for their mobile app releases, since especially the\u00a0\u2026", "num_citations": "81\n", "authors": ["171"]}
{"title": "Formal description of the cognitive process of decision making\n", "abstract": " Decision making is one of the basic cognitive processes of human behaviors by which a preferred option or a course of actions is chosen from among a set of alternatives based on certain criteria. Decision theories are widely applied in a number of disciplines encompassing cognitive science, computer science, management science, economics, sociology, psychology, political science, and statistics. The studies on decision making can be categorized into two classes: descriptive and normative theories. A number of decision strategies have been proposed from different angles and application domains such as the maximum expected utility and Bayesian method. However, there is still a lack of a fundamental and mathematical decision model and a rigorous cognitive process for decision making. This paper presents a decision making process on the basis of the layered reference model of the brain (LRMB). The\u00a0\u2026", "num_citations": "66\n", "authors": ["171"]}
{"title": "Optimized resource allocation for software release planning\n", "abstract": " Release planning for incremental software development assigns features to releases such that technical, resource, risk and budget constraints are met. Planning of software releases and allocation of resources cannot be handled in isolation. A feature can be offered as part of a release only if all its necessary tasks are done before the given release date. We assume a given pool of human resources with different degrees of productivity to perform different types of tasks. To address the inherent difficulty of this process, we propose a two-phased optimization approach that combines the strength of two existing solution methods. The industrial applicability of the approach is primarily directed towards mature organizations having systematic development and measurement processes in place. The expected practical benefit of the planning method is to provide release plan solutions that achieve a better overall business\u00a0\u2026", "num_citations": "62\n", "authors": ["171"]}
{"title": "Software release planning\n", "abstract": " Incremental software development replaces monolithic-type development by offering a series of releases with additive functionality. To create optimal value under existing project constraints, the question is what should be done when? Release planning is giving the answer. It determines proper priorities and assigns features to releases. Comprehensive stakeholder involvement ensures a high degree of applicability of the results. The formal procedure of release planning is able to consider different criteria (urgency, importance) and to bring them together in a balanced way. Release planning is based on (estimates of) the implementation effort. In addition, constraints related to risk, individual resources necessary to implement the proposed features, money, or technological dependencies can be easily adopted into the release planning approach presented in this article. Releases are known to be new versions of\u00a0\u2026", "num_citations": "62\n", "authors": ["171"]}
{"title": "Algorithmic aspects of flows in networks\n", "abstract": " FEt moi... sifavait sucommenten rcvenir, One service mathematics has rendered the jen'yseraispointall,: human race. It hasput rommon senseback JulesVerne whereit belongs, on the topmost shelf next tothedustycanisterlabelled'discardednon Theseriesis divergent; thereforewemaybe sense'. ahletodosomethingwithit. EricT. Bell O. Heaviside Mathematicsisatoolforthought. Ahighlynecessarytoolinaworldwherebothfeedbackandnon linearitiesabound. Similarly, allkindsofpartsofmathematicsserveastoolsforotherpartsandfor othersciences. Applyinga simplerewritingrule to thequoteon theright aboveonefinds suchstatementsas:'One service topology hasrenderedmathematicalphysics...';'Oneservicelogichasrenderedcom puterscience...';'Oneservicecategorytheoryhasrenderedmathematics...'. Allarguablytrue. And allstatementsobtainablethiswayformpartoftheraisond'etreofthisseries. This series, Mathematics and Its Applications, started in 1977. Now that over one hundred volumeshaveappeareditseemsopportunetoreexamineitsscope. AtthetimeIwrote\" Growing specialization and diversification have brought a host of monographs and textbooks on increasingly specialized topics. However, the'tree'of knowledge of mathematics and related fields does not grow only by puttingforth new branches. It also happens, quiteoften in fact, that branches which were thought to becompletely disparatearesuddenly seento berelated. Further, thekindandlevelofsophistication of mathematics applied in various sciences has changed drastically in recent years: measure theory is used (non-trivially) in regionaland theoretical economics; algebraic geometryinteractswithphysics\u00a0\u2026", "num_citations": "60\n", "authors": ["171"]}
{"title": "Software release planning for evolving systems\n", "abstract": " Release planning is a crucial step in incremental software development. It addresses the issues involved with assigning features to sequence of releases of a system such that the most important technical, resource, risk and budget constraints are met. These problems are difficult to solve for even mid-sized systems. The issues become even more challenging in evolving systems where we need to consider the characteristics of the existing system, as the existing components of the system have their own history and status in terms of size, complexity, health, criticality, and understandability.               In this paper, we present the foundations for handling release planning for evolving systems in a rigorous manner. Based on a formalized problem description, we present a new solution approach for release planning of evolving systems called S-EVOLVE*. From analyzing and comparing different characteristics of\u00a0\u2026", "num_citations": "60\n", "authors": ["171"]}
{"title": "Complexity results for multicriterial and parametric network flows using a pathological graph of Zadeh\n", "abstract": " For two classes of network flow problems a worst-case analysis is given depending on the number of vertices of a pathological graph of Zadeh. Firstly, an exponential number of breakpoints in the optimal value function of the maximal flow problem in generalized networks with parametric capacities is demonstrated. Secondly, it is shown that the bicriterial min-cost flow has, in the worst case. an exponential number of efficient extreme point solutions in the objective space.", "num_citations": "60\n", "authors": ["171"]}
{"title": "A systematic approach for solving the wicked problem of software release planning\n", "abstract": " Release planning is known to be a cognitively and computationally difficult problem. Different kinds of uncertainties make it hard to formulate and solve the problem. Our solution approach called EVOLVE+ mitigates these difficulties by (i) an evolutionary problem solving method combining rigorous solution methods to solve the actual formalization of the problem combined with the interactive involvement of the human experts in this process, (ii) provision of a portfolio of diversified and qualified solutions at each iteration of the solution process, and (iii) the application of a multi-criteria decision aid method (ELECTRE IS) to assist the selection of the final solution from a set of qualified solutions. At the final stage of the process, an outranking relation is established among the qualified candidate solutions to address existing soft constraints or objectives. A case study is provided to illustrate and initially evaluate\u00a0\u2026", "num_citations": "57\n", "authors": ["171"]}
{"title": "\u03b5-optimality for bicriteria programs and its application to minimum cost flows\n", "abstract": " A subsetS\u2282X of feasible solutions of a multicriteria optimization problem is called \u03b5-optimal w.r.t. a vector-valued functionf:X\u2192Y   \u211d                   K                  if for allx\u2208X there is a solutionz x\u2208S so thatf k(z x)\u2264(1+\u03b5)f k (x) for allk=1,...,K. For a given accuracy \u03b5>0, a pseudopolynomial approximation algorithm for bicriteria linear programming using the lower and upper approximation of the optimal value function is given. Numerical results for the bicriteria minimum cost flow problem on NETGEN-generated examples are presented.", "num_citations": "54\n", "authors": ["171"]}
{"title": "Software engineering decision support\u2013Methodology and applications\n", "abstract": " The quality of life in our 21 st century society heavily depends on products and services that are enabled, supported, and strengthened by software systems. The future vision of life is a society where communal interactions and access to personal knowledge and services are enabled, supported and strengthened by computing that is available in practically every conceivable environment. The next step of the internet and the mobile revolution requires software solutions with extreme demands on their quality and predictability. Software contributes to an increasingly larger share of the costs of computer systems. While software is of paramount importance for market success in all high-tech and service domains, software engineering practice does not yet live up to this challenge and requires tremendous improvement efforts. We have been struggling with a status of immaturity in software development already for a long time. New methods, tools and techniques have been developed. However, we are still confronted with the situation that software does not satisfy expected quality, cost and time requirements. Software development is far from being in a controlled and predictable mode. Often, it is too much crafting, and too little engineering. What is needed is a set of empirically based guidelines to support", "num_citations": "51\n", "authors": ["171"]}
{"title": "Learning software organizations\n", "abstract": " A Learning Software Organization (LSO) is an organization that learns within the domain of software development, evolution and application. In the context of LSO, knowledge management and learning approaches are complementary views on knowledge handling processes. Learning is based on knowledge and experiences related to the different processes, products, tools, techniques and methods applied to the software development process. The overall objective of an LSO is to improve software processes and products according to the strategic goals of the organization. Knowledge is considered a crucial resource of each organization and, therefore, needs to be managed carefully. The knowledge management literature usually deals with the mechanisms of knowledge handling, while learning approaches address the process how to gain knowledge. This can be done on an individual, group, or\u00a0\u2026", "num_citations": "51\n", "authors": ["171"]}
{"title": "Who should take this task? Dynamic decision support for crowd workers\n", "abstract": " Context: The success of crowdsourced software development (CSD) depends on a large crowd of trustworthy software workers who are registering and submitting for their interested tasks in exchange of financial gains. Preliminary analysis on software worker behaviors reveals an alarming task-quitting rate of 82.9%.Goal: The objective of this study is to empirically investigate worker decision factors and provide better decision support in order to improve the success and efficiency of CSD.Method: We propose a novel problem formulation, DCW-DS, and an analytics-based decision support methodology to guide workers in acceptance of offered development tasks. DCS-DS is evaluated using more than one year's real-world data from TopCoder, the leading CSD platform.Results: Applying Random Forest based machine learning with dynamic updates, we can predict a worker as being a likely quitter with 99\u00a0\u2026", "num_citations": "50\n", "authors": ["171"]}
{"title": "Intelligent support for software release planning\n", "abstract": " One of the most prominent issues involved in incremental software development is to decide upon the most appropriate software release plans taking into account all explicit and implicit objectives and constraints. Such decisions have become even more complicated in the presence of large number of stakeholders such as different groups of users, managers, or developers. However, early involvement of customers and understanding of their real needs is one of the core success factors of software business [16].               This paper introduces a six step process model for release planning. It is inspired by the Quality Improvement Paradigm [2], as release planning is a learning and improvement process as well. Emphasis is on proposing the tool support implementing this process. The use of the intelligent decision support tool ReleasePlannerTM is presented by comparing a baseline scenario reflecting\u00a0\u2026", "num_citations": "48\n", "authors": ["171"]}
{"title": "Release planning process improvement\u2014an industrial case study\n", "abstract": " Planning of software releases is accomplished by the assignment of requirements to the releases, where effort, finance, and risk constraints are considered in order to determine strategic release plans. Planning and re\u2010planning of releases has an impact on time\u2010to\u2010market, customer satisfaction, and stability of the development process. This article presents an industrial case study of the release planning process improvement as performed at Trema Laboratories, Inc. The baseline situation is compared against the improvement gained from the introduction of a more systematic process defined by a decision support tool called ReleasePlanner, and an accompanying methodology. The new process was designed and implemented as part of a trial project performed at Trema. The article describes the main findings of this trial. The study shows that the process improvement introduced has added significant value to\u00a0\u2026", "num_citations": "47\n", "authors": ["171"]}
{"title": "Requirements engineering visualization: a systematic literature review\n", "abstract": " Requirements Engineering (RE) is a decision-centric activity which is highly data-intensive. The results of this process are known to have key impact on the results of the project. As known from the experience in other fields and disciplines, visualization can potentially provide more insights into data, information and knowledge studied. While research in the area of information visualization and its application to software engineering has rapidly increased over the last decade, there is only a limited amount of studies addressing the usage and impact of visualization techniques for RE activities. In this paper, we report on the results of a Systematic Literature Review (SLR) related to RE visualization. Extending the established SLR process by the usage of grounded theory for the encoding of papers, we synthesize 18 usage patterns. Even though there are punctual applications, there is a clear deficit on a holistic\u00a0\u2026", "num_citations": "45\n", "authors": ["171"]}
{"title": "Optimized staffing for product releases and its application at Chartwell Technology\n", "abstract": " Release planning for incremental software development assigns features to releases such that technical, resource, risk and budget constraints are met. Each feature offers a piece of functionality. A feature can be offered as part of a release only if all its necessary tasks are done before the given release date. These tasks require different skills. Staffing for product releases as considered in this paper is the process of assigning human resources from a given pool of developers who might have varying levels of skill to perform different tasks. In addition to that, we consider time windows of absence of the developers. The primary goal of staffing is to provide product releases of best quality where quality means offering the most attractive features to customers in a timely manner. We call the problem STAFF\u2010PRO. The problem is known to be NP\u2010complete. Consequently, we have to be satisfied with solutions that are\u00a0\u2026", "num_citations": "44\n", "authors": ["171"]}
{"title": "A comparative study of attribute weighting heuristics for effort estimation by analogy\n", "abstract": " Five heuristics for attribute weighting in analogy-based effort estimation are evaluated in this paper. The baseline heuristic involves using all attributes with equal weights. We propose four additional heuristics that use rough set analysis for attribute weighting. These five heuristics are evaluated over five data sets related to software projects. Three of the data sets are publicly available, hence allowing comparison with other methods. The results indicate that three of the rough set analysis based heuristics perform better than the equal weights heuristic. This evaluation is based on an integrated measure of accuracy.", "num_citations": "44\n", "authors": ["171"]}
{"title": "A formal knowledge representation system (FKRS) for the intelligent knowledge base of a cognitive learning engine\n", "abstract": " It is recognized that the generic form of machine learning is a knowledge acquisition and manipulation process mimicking the brain. Therefore, knowledge representation as a dynamic concept network is centric in the design and implementation of the intelligent knowledge base of a Cognitive Learning Engine (CLE). This paper presents a Formal Knowledge Representation System (FKRS) for autonomous concept formation and manipulation based on concept algebra. The Object-Attribute-Relation (OAR) model for knowledge representation is adopted in the design of FKRS. The conceptual model, architectural model, and behavioral models of the FKRS system is formally designed and specified in Real-Time Process Algebra (RTPA). The FKRS system is implemented in Java as a core component towards the development of the CLE and other knowledge-based systems in cognitive computing and computational\u00a0\u2026", "num_citations": "43\n", "authors": ["171"]}
{"title": "App store mining is not enough for app improvement\n", "abstract": " The rise in popularity of mobile devices has led to a parallel growth in the size of the app store market, intriguing several research studies and commercial platforms on mining app stores. App store reviews are used to analyze different aspects of app development and evolution. However, app users\u2019 feedback does not only exist on the app store. In fact, despite the large quantity of posts that are made daily on social media, the importance and value that these discussions provide remain mostly unused in the context of mobile app development. In this paper, we study how Twitter can provide complementary information to support mobile app development. By analyzing a total of 30,793 apps over a period of six weeks, we found strong correlations between the number of reviews and tweets for most apps. Moreover, through applying machine learning classifiers, topic modeling and subsequent crowd-sourcing\u00a0\u2026", "num_citations": "42\n", "authors": ["171"]}
{"title": "A hybrid approach to analyze empirical software engineering data and its application to predict module fault-proneness in maintenance\n", "abstract": " Knowledge discovery from software engineering measurement data is essential in deriving the right conclusions from experiments. Various data analysis techniques may provide data analysts with different and complementary insights into the studied phenomena. In this paper, two data analysis techniques \u2013 Rough Sets (RSs) and Logistic Regression (LR) are compared, from both the theoretical and the experimental point of view. In particular, the empirical study was performed as a part of the ESPRIT/ESSI project CEMP on a real-life maintenance project, the DATATRIEVE\u2122 project carried out at Digital Engineering Italy. We have applied both techniques to the same data set. The goal of the experimental study was to predict module fault-proneness and to determine the major factors affecting software reliability in the application context. The results obtained with either analysis technique are discussed and\u00a0\u2026", "num_citations": "42\n", "authors": ["171"]}
{"title": "Bi-objective genetic search for release planning in support of themes\n", "abstract": " Release planning is a mandatory part of incremental and iterative software development. For the decision about which features should be implemented next, the values of features need to be balanced with the effort and readiness of their implementation. Traditional planning looks at the sum of the values of individual and potentially isolated features. As an alternative idea, a theme is a meta-functionality which integrates a number of individual features under a joint umbrella. That way, possible value synergies from offering features in conjunction (theme-related) can be utilized.               In this paper, we model theme-based release planning as a bi-objective (search-based) optimization problem. Each solution of this optimization problem balances the preference between individual and theme-based planning objectives. We apply a two-stage solution approach. In Phase 1, the existing Non-dominated Sorting\u00a0\u2026", "num_citations": "38\n", "authors": ["171"]}
{"title": "Lightweight replanning of software product releases\n", "abstract": " Well defined product features are the essence of good product management. High quality features lead to successful software products, both functionally and financially. One of the crucial processes in software product management is release planning where features are assigned to releases. Volatile features, resources and stakeholder preferences have been recognized as factors that decrease release quality. In this paper, we propose a lightweight replanning process model where old features are compared with newly added ones using the Analytical Hierarchy Process (AHP). Then, a greedy replan algorithm is applied to select the most promising features to accommodate changing market driven product demands.", "num_citations": "36\n", "authors": ["171"]}
{"title": "Information needs for integration decisions in the release process of large-scale parallel development\n", "abstract": " Version control branching allows an organization to parallelize its development efforts. Releasing a software system developed in this manner requires release managers, and other project stakeholders, to make decisions about how to integrate the branched work. This group decision-making process becomes very complex in the case of large-scale parallel development. To better understand the information needs of release managers in this context, we conducted an interview study at a large software company. Our analysis of the interviews provides a view into how release managers make integration decisions, organized around ten key factors. Based on these factors, we discuss specific information needs for release managers and how the needs can be met in future work.", "num_citations": "35\n", "authors": ["171"]}
{"title": "Decision support analysis for software effort estimation by analogy\n", "abstract": " Effort estimation by analogy (EBA) is an established method for software effort estimation. For this paper, we understand EBA as a meta-method which needs to be instantiated and customized at different stages and decision points regarding a specific context. Some example decision problems are related to the selection of the similarity measures, the selection of analogs for adaptation or the weighting and selection of attributes. This paper proposes a decision-centric process model for EBA by generalizing the existing EBA methods. Typical decision-making problems are identified at different stages of the process as part of the model. Some existing solution alternatives of the decision-making problems are then studied. The results of the decision support analysis can be used for better understanding of EBA related techniques and for providing guidelines for implementation and customization of general EBA. An\u00a0\u2026", "num_citations": "34\n", "authors": ["171"]}
{"title": "Leveraging crowdsourcing for team elasticity: an empirical evaluation at TopCoder\n", "abstract": " There is an emergent trend in software development projects that mini-tasks can be crowdsourced to achieve rapid development and delivery. For software managers requesting crowdsourcing services, it is beneficial to be able to evaluate and assure the availability and performance of trustable workers on their tasks. However, existing rating systems are facing challenges such as providing limited information regarding worker's abilities as well as potential threats from workers' gaming or cheating the systems. To develop better understanding of worker performance in software crowdsourcing, this paper reports an empirical study at TopCoder, one of the primary software crowdsourcing platforms. We aim at investigating the following questions: How diverse are crowd workers in terms of skill and experience? How fast do crowd workers respond to a task call? How reliable are crowd workers in submitting tasks? And\u00a0\u2026", "num_citations": "31\n", "authors": ["171"]}
{"title": "Decision support for value-based software release planning\n", "abstract": " Incremental software development replaces monolithic-type development by offering a series of releases with additive functionality. To create optimal value under existing project constraints, the question is what should be done when? Release planning (RP) provides the answer by assigning features to a sequence of releases in the most beneficial way within the resources available.           In this chapter, we extend the existing hybrid intelligence-based release planning method called EVOLVE* to accommodate financial value in the form of net present value estimates of proposed features. This extension enables us to perform financial value-based software release planning. The new approach called F-EVOLVE* is illustrated by an example. The results show that the F-EVOLVE* model may be used to decide which features to produce and when based on their financial contributions. Specifically, F-EVOLVE\u00a0\u2026", "num_citations": "31\n", "authors": ["171"]}
{"title": "Using real options to manage technical debt in requirements engineering\n", "abstract": " Despite the importance of Requirements Engineering (RE) for the success of software products, most of the requirements decisions such as requirements specification and prioritization are still ad hoc and depend upon the managers' preferences and the trade-offs they make. The Technical Debt (TD) metaphor looks into the trade-offs between short term and long-term goals in software development projects that may lead to increased cost in the future. This problem is mainly due to the lack of a systematic and well-defined approach to manage the high level of uncertainty in requirements decisions. In this paper, we propose to apply the real options thinking to develop a quantitative method for managing requirements decisions under uncertainty and, more specifically for managing requirements debt in software development projects. A real option is a right without an obligation to make a specific future decision\u00a0\u2026", "num_citations": "29\n", "authors": ["171"]}
{"title": "Rough set-based data analysis in goal-oriented software measurement\n", "abstract": " The analysis of software engineering data is often concerned with the treatment of incomplete knowledge, the management of inconsistent pieces of information and the manipulation of various data representation levels. Existing techniques of data analysis are mainly based on quite strong assumptions (some knowledge about dependencies, probability distributions, and a large number of experiments), are unable to derive conclusions from incomplete knowledge, or cannot manage inconsistent pieces of information. A rough set is a collection of objects which, in general, cannot be precisely characterized in terms of the values of the set of attributes, while a lower and an upper approximation of the collection can do so. Rough sets have been successfully applied for data analysis in different areas. In this paper, the approach is applied to the analysis of software engineering data resulting from goal-oriented\u00a0\u2026", "num_citations": "29\n", "authors": ["171"]}
{"title": "A formal knowledge representation system for the cognitive learning engine\n", "abstract": " Knowledge representation is one of the central problems in the design and implementation of a cognitive learning engine (CLE). A formal knowledge representation system (FKRS) is developed for autonomous concept formation based on concept algebra. The object-attribute-relation (OAR) model for knowledge representation is adopted in the design of FKRS. The conceptual model, architectural model, and behavioral models of the FKRS system is formally designed and specified in real-time process algebra (RTPA). The FKRS system is implemented in Java as a major component towards the development of the CLE and other knowledge-based systems in cognitive computing and computational intelligence.", "num_citations": "28\n", "authors": ["171"]}
{"title": "Rigorous support for flexible planning of product releases-a stakeholder-centric approach and its initial evaluation\n", "abstract": " This paper addresses the problem of product release planning in iterative product development. We propose a method which combines decision, process, and tool support. The method, which is called SCERP, facilitates the active involvement of stakeholders in the different stages of the planning process. SCERP is flexible in the number of stakeholders involved, in the number of releases, in the number and definition of planning criteria, and in the selection of the best plan out of a set of optimized alternatives. A proof-of-concept of the method is given by a case study of release planning for a tool called Agilefant, which is developed with a process partially based on Scrum. The benefits of the method as demonstrated by the case study are: (i) better decisions by the product manager by relying on more objective information, (ii) more transparency of release decisions, and (iii) efficient tool support accompanying the\u00a0\u2026", "num_citations": "28\n", "authors": ["171"]}
{"title": "Impact analysis of missing values on the prediction accuracy of analogy-based software effort estimation method AQUA\n", "abstract": " Effort estimation by analogy (EBA) is often confronted with missing values. Our former analogy- based method AUQA is able to tolerate missing values in the data set, but it is unclear how the percentage of missing values impacts the prediction accuracy and if there is an upper bound for how big this percentage might become in order to guarantee the applicability of AQUA. This paper investigates these questions through an impact analysis. The impact analysis is conducted for seven data sets being of different size and having different initial percentages of missing values. The major results are that (i) we confirm the intuition that the more missing values, the poorer the prediction accuracy of AQUA; (ii) there is a quadratic dependency between the prediction accuracy and the percentage of missing values; and (Hi) the upper limit of missing values for the applicability of AQUA is determined as 40%. These results are\u00a0\u2026", "num_citations": "28\n", "authors": ["171"]}
{"title": "Decision support in requirements engineering\n", "abstract": " Decisions are increasingly understood as the crystallization points of the software development process. Despite the abundance of the requirements engineering (RE) processes, little attention has been given to providing appropriate support for making RE decisions. In this chapter we analyze current research related to RE decision making. We study how and when decisions are made in RE and the underlying methodology. Our focus is not to provide solution approaches for particular decision problems in RE, but to discuss strategies for improving research and practice in the RE decision making process. We have performed an extensive analysis of related research. Our findings show the difficulties in RE decision making and the deficits of current research. We position decision support at the appropriate approach to handle incompleteness and uncertainty of information as is mostly the case in RE. Based\u00a0\u2026", "num_citations": "28\n", "authors": ["171"]}
{"title": "The science and practice of software release planning\n", "abstract": " Software release planning plays a crucial role that affects the success of software engineering project management (SEPM). Release planning (RP) determines which customer gets which features at which moment. In the 2002 Standish Group report, it was observed that mismatching customer satisfaction with the functionality of delivered software is still one of the main reasons that many software projects fail to achieve their stated objectives. Despite the importance of RP, our study reveals that current industry practices are mainly based on informal procedures. Most of the existing RP approaches are not based on comprehensive involvement of stakeholders, and do not give enough attention to resources and other constraints influencing RP decisions.This article provides guidelines for RP and lessons learned in performing RP. We give overview of existing RP techniques and describe a case study using an intelligent decision support tool called ReleasePlannerTM. We present industry experience to describe the added value in terms of the quality of plans, the ability to better react to changing customer demands, the ease of performing planning and replanning more efficiently, and the ability to make proposed decisions more transparent.", "num_citations": "27\n", "authors": ["171"]}
{"title": "Crowdsourced exploration of mobile app features: A case study of the fort mcmurray wildfire\n", "abstract": " The ubiquity of mobile devices has led to unprecedented growth in not only the usage of apps, but also their capacity to meet people's needs. Smart phones take on a heightened role in emergency situations, as they may suddenly be among their owner's only possessions and resources. The 2016 wildfire in Fort McMurray, Canada, intrigued us to study the functionality of the existing apps by analyzing social media information. We investigated a method to suggest features that are useful for emergency apps. Our proposed method called MAPFEAT, combines various machine learning techniques to analyze tweets in conjunction with crowdsourcing and guides an extended search in app stores to find currently missing features in emergency apps based on the needs stated in social media. MAPFEAT is evaluated by a real-world case study of the Fort McMurray wildfire, where we analyzed 69,680 unique tweets\u00a0\u2026", "num_citations": "26\n", "authors": ["171"]}
{"title": "App store mining is not enough\n", "abstract": " App store reviews are currently the main source of information for analyzing different aspects of app development and evolution. However, app users' feedback do not only occur on the app store. In fact, a large quantity of posts about apps are made daily on social media. In this paper, we study how Twitter can provide complementary information to support mobile app development. By analysing a total of 70 apps over a period of six weeks, we show that 22.4% more feature requests and 12.89% more bug reports could be found on Twitter.", "num_citations": "26\n", "authors": ["171"]}
{"title": "A bibliometric/geographic assessment of 40 years of software engineering research (1969\u20132009)\n", "abstract": " Bibliometric rankings are quite common in the field of software engineering. For example, there are a series of ranking repeated every year which identify the top researchers and institutions at the international level in the field. There are also other studies to determine the most cited articles in software engineering journals, the most popular research topics in this area, or identify the top researchers and institutions in regional levels. However, there exists no existing bibliometric quantitative analysis of publications in the area of software engineering (SE), including relative and absolute growth in the number of all SE publications as well as an analysis among countries. This is the main goal and motivation of this article. Besides, this study intends to provide an overall quantitative trend of the software engineering papers, and compare that trend to research output in other areas of science.         The bibliometric study\u00a0\u2026", "num_citations": "26\n", "authors": ["171"]}
{"title": "Towards comprehensive release planning for software product lines\n", "abstract": " Release Planning (RP) plays an important role for the success of incremental product development. Proper planning includes consideration of stakeholder preferences, resources and their capacities, as well as product and business objectives. The complexity of this process is getting even larger when looking for releases of software product lines (SPL). SPL is considered as a viable and important software development paradigm allowing companies under certain conditions to realize order-of-magnitude improvements in time to market, cost, productivity, quality, and other business drivers. In this paper, we present ongoing research in the process to develop a comprehensive and formalized model for planning and optimizing releases for SPL. We have identified key issues that are unique to RP of SPL. Some of them are highlighted by an example modified from literature for illustrative purposes.", "num_citations": "26\n", "authors": ["171"]}
{"title": "Strategic release planning and evaluation of operational feasibility\n", "abstract": " Strategic planning (or road-mapping) of software releases addresses the assignment of requirements to releases on a strategic level. Effort, finance and risk constraints are considered to determine strategic release plans. The goal is to find an optimal balance between competing stakeholder priorities and bottleneck resources. However, strategic planning has to be supplemented by more fine-grained operational planning as typically performed in project management. The paper describes mechanisms by which to reduce the complexity of strategic and operational planning to a series of data and formulae that objectively represent input from all stakeholders and can easily reported, analyzed and manipulated. The capability provides improved planning and re-planning in a dynamic business environment, including the ability to validate strategic plans against operational limitations and revise as necessary. For\u00a0\u2026", "num_citations": "26\n", "authors": ["171"]}
{"title": "Characterization of all optimal solutions and parametric maximal mows in networks\n", "abstract": " In the paper two extensions of the classical max-flow problem are considered. At first, an approach to solve the case of parametric are capacities is presented. And secondly, a constructive description for the set of all optimal solutions of the max-flow problem is given.", "num_citations": "25\n", "authors": ["171"]}
{"title": "Analytical product release planning\n", "abstract": " As part of any incremental and iterative development, release planning is the process of assigning features to upcoming releases (or iterations) such that the overall product evolution is optimized. Analytical product release planning refers to the application of analytical methods in this process, thereby utilizing the diversity of data available from internal and external sources of information. In this chapter, information needs for release planning are outlined and a taxonomy of release planning problems is given. The paradigm of Open Innovation is introduced as a new way to elicit and gain access to relevant data related to product objectives, features and their dependencies, customers and changing priorities, as well as product values and market trends. Analytical Open Innovation (AOI) is the integration of Open Innovation with (a portfolio of) analytical methods which could be used in different problems of a semi\u00a0\u2026", "num_citations": "24\n", "authors": ["171"]}
{"title": "Ad hoc versus systematic planning of software releases\u2013a three-staged experiment\n", "abstract": " Release planning addresses the process of deciding which requirement of an evolving software system should be assigned to which release. We study two fundamentally different software release planning approaches: (i) ad hoc planning and (ii) systematic planning. Ad hoc planning is mainly based on human intuition, experience and communication. Systematic planning, based on formalization, assumes a quantitative description of the problem, and application of optimization algorithms for its solution.               We have performed a controlled experiment intended to investigate hypotheses related to confidence, understanding, and trust related to the two approaches. The stated hypotheses were based on an explorative pre-study and prior industrial release planning projects. Although limited in scope and size, the experiment provided interesting insight into the performance of the stated approaches\u00a0\u2026", "num_citations": "24\n", "authors": ["171"]}
{"title": "An Explanation Oriented Dialogue Approach for Solving Wicked Planning Problems.\n", "abstract": " In this paper we discuss support for solving complex \u201cwicked\u201d planning problems by dialogues and explanations. Wicked problems are essentially imprecisely formulated problems, ie those that do not have a clear goal, well defined methods, and are subject to personal opinions of involved stakeholders that may be changeable. The method contains the following steps:(1) Reducing the complexity of the problem by the selecting a specific concern;(2) Obtaining a user defined ideal plan, called a prototype;(3) Comparing the actually generated plan and the prototype by a similarity measure. This will be aided by an explanation oriented dialogue. A major problem for the explanation is that we need to explain the result of an optimization procedure which excludes classical parsing oriented methods. The approach is generic and was instantiated in release planning, investment, and urban planning. We have simplified the original problems significantly in order to illustrate the principal approach.", "num_citations": "24\n", "authors": ["171"]}
{"title": "No improvement without feedback: Experiences from goal-oriented measurement at schlumberger\n", "abstract": " Schlumberger is an international technology oriented company and started its company wide software process improvement program in 1989. This industrial experience paper describes how goal-oriented measurement was established and which role feedback sessions played as a critical success factor within this process.             By feedback sessions we mean well-organized, structured meetings between the project team and the measurement team. Main objective is to review the data collected so far and to analyze and interpret it. The interpretations derived are fed back both into the software development process and into the measurement process. Thus, feedback sessions serve multiple purposes: they maintain motivation and momentum in the measurement program, they ensure that the interpretations derived from the collected data are correct, and they allow the identification of small-scale changes\u00a0\u2026", "num_citations": "23\n", "authors": ["171"]}
{"title": "Which version should be released to app store?\n", "abstract": " Background: Several mobile app releases do not find their way to the end users. Our analysis of 11,514 releases across 917 open source mobile apps revealed that 44.3% of releases created in GitHub never shipped to the app store (market). Aims: We introduce \"marketability\" of open source mobile apps as a new release decision problem. Considering app stores as a complex system with unknown treatments, we evaluate performance of predictive models and analogical reasoning for marketability decisions. Method: We performed a survey with 22 release engineers to identify the importance of marketability release decision. We compared different classifiers to predict release marketability. For guiding the transition of not successfully marketable releases into successful ones, we used analogical reasoning. We evaluated our results both internally (over time) and externally (by developers). Results: Random\u00a0\u2026", "num_citations": "22\n", "authors": ["171"]}
{"title": "Software effort estimation by analogy using attribute selection based on rough set analysis\n", "abstract": " Estimation by analogy (EBA) predicts effort for a new project by learning from the performance of former projects. This is done by aggregating effort information of similar projects from a given historical data set that contains projects, or objects in general, and attributes describing the objects. While this has been successful in general, existing research results have shown that a carefully selected subset, as well as weighting, of the attributes may improve the performance of the estimation methods.         In order to improve the estimation accuracy of our former proposed EBA method AQUA, which supports data sets that have non-quantitative and missing values, an attribute weighting method using rough set analysis is proposed in this paper. AQUA is thus extended to AQUA+ by incorporating the proposed attribute weighting and selection method. Better prediction accuracy was obtained by AQUA+ compared to AQUA\u00a0\u2026", "num_citations": "22\n", "authors": ["171"]}
{"title": "A family of empirical studies to compare informal and optimization-based planning of software releases\n", "abstract": " Replication of experiments, or performing a series of related studies, aims at attaining a higher level of validity of results. This paper reports on a series of empirical studies devoted to comparing informal release planning with two variants of optimization-based release planning. Two research questions were studied: How does optimization-based release planning compare with informal planning in terms of (i) time to generate release plans, and the feasibility and quality of those plans, and (ii) understanding and confidence of generated solutions and trust in the release planning process. For the family of empirical studies, the paper presents two types of results related to (i) the two research questions to compare the release planning techniques, and (ii) the evolution and lessons learned while conducting the studies.", "num_citations": "21\n", "authors": ["171"]}
{"title": "What are practitioners asking about requirements engineering? an exploratory analysis of social q&a sites\n", "abstract": " Requirements Engineering (RE) and all its underlying activities, such as requirements identification, evolution, validation, communication, and management, are still the key factors in successful product development. Therefore, proper implementation of this process is necessary to obtain a quality product. A better understanding of the most challenging RE-related topics for practitioners will greatly help to identify the areas of RE that may require extra attention by researchers and project managers. However, there has been very little experimental work towards identifying a practitioner's needs on the implementation and understanding of RE activities and tasks. Therefore, in this paper, we use data from popular social Q&A sites (i.e. Stack Overflow, Programmers Stack Exchange, Project Management Stack Exchange, and Quora), and analyze 4,553 questions and answers to examine what requirements engineers'\u00a0\u2026", "num_citations": "19\n", "authors": ["171"]}
{"title": "Stratos: Using visualization to support decisions in strategic software release planning\n", "abstract": " Software is typically developed incrementally and released in stages. Planning these releases involves deciding which features of the system should be implemented for each release. This is a complex planning process involving numerous trade-offs-constraints and factors that often make decisions difficult. Since the success of a product depends on this plan, it is important to understand the trade-offs between different release plans in order to make an informed choice. We present STRATOS, a tool that simultaneously visualizes several software release plans. The visualization shows several attributes about each plan that are important to planners. Multiple plans are shown in a single layout to help planners find and understand the trade-offs between alternative plans. We evaluated our tool via a qualitative study and found that STRATOS enables a range of decision-making processes, helping participants decide\u00a0\u2026", "num_citations": "19\n", "authors": ["171"]}
{"title": "Bi-criteria genetic search for adding new features into an existing product line\n", "abstract": " Software product line evolution involves decisions like finding which products are better candidates for realizing new feature requests. In this paper, we propose a solution for finding trade-off evolution alternatives for products while balancing between overall value and product integrity. The purpose of this study is to support product managers with feature selection for an existing product line. For this purpose, first, the feature model of the product line is encoded into a single binary encoding. Then we employ a bi-criteria genetic search algorithm, NSGA-II, to find the possible alternatives with different value and product integrity. From the proposed set of trade-off alternatives, the product line manager can select the solutions that best fit with the concerns of their preference. The implementation has been initially evaluated by two product line configurations.", "num_citations": "19\n", "authors": ["171"]}
{"title": "The vision: Requirements engineering in society\n", "abstract": " Industry and society are facing radical changes due to fast growing digital technologies and its ubiquity. Products and services will increasingly augment and integrate the real world with the digital world. This digital transformation has reached all business areas. Companies and consumers expect to obtain innovation, market penetration, cost reductions and more flexibility. The relationship between RE and society is bi-directional. In this talk, we discuss the evolving role of RE by referring to a quarter century of impressive research. We discuss the increasing scope and responsibility of our discipline, serving as the bridge between the general public and technical teams and providing a response to the dramatic changes in our society.", "num_citations": "17\n", "authors": ["171"]}
{"title": "When-to-release decisions in consideration of technical debt\n", "abstract": " Shortening release duration is essential in creating competitive products in iterative software development. However, short-term expedients (e.g., code compromises, delayed change requests, etc.) can have long term effects on the maintenance of the software. There are multifaceted factors that influenced the effective management of technical debt in organizations. In this position paper, we propose a formulation of technical debt in the context of (software) product releases, specifically when-to-release decisions. The potential competitive advantage through faster delivery needs to be balanced against the delivery of the overall business values and the potentially incurred technical debt. Pro-active analysis of the estimated impact of various release scenarios is expected to provide insights and essential inputs for actual decision-making process. This paper also evaluates a real-world case study.", "num_citations": "17\n", "authors": ["171"]}
{"title": "Theme-based product release planning: An analytical approach\n", "abstract": " Release planning is part of iterative software development and strongly impacts the success of a product by providing a roadmap for future releases. As such, it is of key importance for lean and agile organizations. Often features are highly dependent on each other and the value of a release is influenced by a set of bundled features constituting a theme. This paper addresses the topic of theme-based release planning. Themes might be defined, manually, upfront or as the result of computer-based analysis. In this paper, we propose an analytical approach to detect themes from a given set of feature dependencies. On top of an existing release planning methodology called EVOLVE II, our approach applies clustering performed on a feature dependency graph. The release plans generated from such an approach are a balance between two goals: (i) considering the values of individual features, (ii) detecting and\u00a0\u2026", "num_citations": "17\n", "authors": ["171"]}
{"title": "A systematic literature review of the personnel assignment problem\n", "abstract": " Context: Personnel assignment (PA) is an important problem in industry. In general it is about assigning the right people to the right tasks. Operations research plays a big role in solving such problems. Objective: In this paper, we study the personnel assignment problem (PAP) and the proposed solutions to solve it. In addition to that, we aim to identify promising future works from the study results.Methods: We take a systematic approach towards studying the literature of the PAP. A general systematic review method, which has been recently used by a number of researchers in the field of software engineering, was modified and deployed in this study.Results: The analysis results reveal potential solution approaches, the trends in application of existing solution methods, and some potential future research areas. The review process is based on our variation of an existing literature review method. This variation is also presented in the paper. Conclusions: Although a concern in industry, PAP has not been widely studied when compared to other similar fields of research. It has been mainly studied in operations research and in the context of military personnel assignments. It seems that artificial intelligence and machine learning still have a good potential to contribute to this field of research in different applications. Application of PAP in software engineering (SE) is an open area of research. For instance, it looks promising for developer or bug assignments in software development projects.", "num_citations": "17\n", "authors": ["171"]}
{"title": "A hybrid release planning method and its empirical justification\n", "abstract": " Background: The use of Constraint Programming (CP) has been proposed by Regnell and Kuchcinski to model and solve the Release Planning Problem. However, they did not empirically demonstrate the advantages and disadvantages of CP over existing release planning methods. Aims: The aims of this paper are (1) to perform a comparative analysis between CP and ReleasePlanner (RP), an existing release planning tool, and (2) to suggest a hybrid approach combining the strengths of each individual method. Method: (1) An empirical evaluation was performed, evaluating the efficiency and effectiveness of the individual methods to justify their hybrid usage. (2) A proof of concept for a hybrid release planning method is introduced, and a real-world dataset including more than 600 features was solved using the hybrid method to provide evidence of its effectiveness. Results: (1) Use of RP was found to be more\u00a0\u2026", "num_citations": "17\n", "authors": ["171"]}
{"title": "Defect prediction using case-based reasoning: An attribute weighting technique based upon sensitivity analysis in neural networks\n", "abstract": " Software defect prediction is an acknowledged approach used to achieve better product quality and to better utilize resources needed for that purpose. One known method for predicting the number of defects is to apply case-based reasoning (CBR). In this paper, different attribute weighting techniques for CBR-based defect prediction are analyzed. One of the weighting techniques used in this work, Sensitivity Analysis based on Neural Networks (SANN), is based on sensitivity analysis of the impact of attributes as part of neural network analysis. Neural networks are applicable when there are non-linear and complicated relationships among the attributes. Since weighting plays a key role in the CBR model, using an efficient weight calculation method can change the results. The results of SANN are compared with applying uniform weights and weights gained from Multiple Linear Regression (MLR).         Evaluation of\u00a0\u2026", "num_citations": "17\n", "authors": ["171"]}
{"title": "An open innovation approach in support of product release decisions\n", "abstract": " Release decisions are of pivotal importance for product success in incremental and iterative software development. In this paper, the wickedness of these decisions is approached by a collective problem solving process. The paradigm of Open Innovations is emphasizing the range of opportunities available to get access to distributed knowledge and information. In particular, we apply (i) Analytical Open Innovation for information gathering and (ii) Morphological Analysis (MA) for problem structuring. The proposed decision support methodology is illustrated by a comprehensive case study. In the context of OTT service delivery, planning of both features and their different functionality levels is studied. From the broad involvement of stakeholders in the whole formulation, structuring and solution process, a higher validity and customer value of the developed products is demonstrated. Without performing MA, the\u00a0\u2026", "num_citations": "16\n", "authors": ["171"]}
{"title": "RELREA-An Analytical Approach for Evaluating Release Readiness.\n", "abstract": " As part of incremental and iterative software development, decisions about \u201cIs the software product ready to be released at some given release date?\u201d have to be made at the end of each release, sprint or iteration. While this decision is critically important, so far it is largely done either informally or in a simplistic manner, relying on a small set of isolated metrics. In this paper, we present an analytical approach combining the goal-oriented definition of the most relevant readiness metrics with their individual evaluation and their subsequent analytical integration into an aggregated evaluation measure. The applicability of the proposed approach called RELREA is demonstrated for an ongoing public project hosted on GitHub, a web-based hosting service for software development projects. Initial evidence shows that the method is supportive in evaluating release readiness at any point of the development cycle, making\u00a0\u2026", "num_citations": "16\n", "authors": ["171"]}
{"title": "Kontinuierliche Qualit\u00e4tsverbesserung in der Software-Entwicklung: Erfahrungen bei der Allianz Lebensversicherungs-AG\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "16\n", "authors": ["171"]}
{"title": "Failure prediction in crowdsourced software development\n", "abstract": " Background: Despite the increasingly reported benefits of software crowdsourcing, one of the major practical concerns is the limited visibility and control over task progress. Aim: This paper reports an empirical study to develop a framework for failure prediction in software crowdsourcing. Method: This process begins with identifying 13 influencing factors in software crowdsourcing failures, across four categories including task characteristics, technology popularity, competition network, and workers reliability. Presenting an algorithm to construct worker competition network and extract its network metrics features. The proposed framework was evaluated on 4,872 software crowdsourcing tasks, extracted from TopCoder platform, using five machine learners, compared with in-house TopCoder predictor. Results: 1) Workers reliability, links in the description, number of registered workers, number of required technologies\u00a0\u2026", "num_citations": "15\n", "authors": ["171"]}
{"title": "Optimized functionality for super mobile apps\n", "abstract": " Functionality of software products often does not match user needs and expectations. The closed set-up of systems and information is replaced by wide access to data of users and competitor products. This shift offers completely new opportunities to approach requirements elicitation and subsequent planning of software functionality. This is, in particular true for app store markets. App stores are markets for many small sized software products which provide an open platform for users to provide feedback on using apps. Moreover, the functionality and status of similar software products can be retrieved. While this is a competitive risk, it is at the same time an opportunity.In this paper, we envision a new release planning approach that leverages the new opportunities for decision making. We propose a new model using bi-criterion integer programming. We make suggestions for optimized super app functionality that are\u00a0\u2026", "num_citations": "15\n", "authors": ["171"]}
{"title": "Analysis of marketed versus not-marketed mobile app releases\n", "abstract": " Market and user characteristics of mobile apps make their release managements different from proprietary software products and web services. Despite the wealth of information regarding users' feedback of an app, an in-depth analysis of app releases is difficult due to the inconsistency and uncertainty of the information. To better understand and potentially improve app release processes, we analyze major, minor and patch releases for releases following semantic versioning. In particular, we were interested in finding out the difference between marketed and not-marketed releases. Our results show that, in general, major, minor and patch releases have significant differences in the release cycle duration, nature and change velocity. We also observed that there is a significant difference between marketed and non-marketed mobile app releases in terms of cycle duration, nature and the extent of changes, and the\u00a0\u2026", "num_citations": "15\n", "authors": ["171"]}
{"title": "Analytics for Software Project Management--Where are We and Where do We Go?\n", "abstract": " Software project management is a decision intensive process. Success or failure of the project is highly dependent on these decisions. Analytical techniques and tools can support project managers throughout the software project life cycle by increasing the predictability and chance of success in these projects. In this paper, we report the results of a systematic mapping study within which we investigate the usage of different types of analytics for software project management. We analyze the accessibility of the data as well as the degree of validation reported in the 115 studies selected for final analysis. This resulted in a picture of the status quo (Where are we?) of analytics in software project management. From comparing this status quo with the results of an industrial survey on the industrial needs of different types of analysis, we propose an agenda on future work (Where do we go?).", "num_citations": "15\n", "authors": ["171"]}
{"title": "Software engineering decision support\n", "abstract": " Developing software involves making hundreds, even thousands, of decisions. Decisions in the context of software systems are hard to make, as the information available is incomplete, uncertain and dynamically changing. Even worse, these decisions are often impacted by conflicting objectives, restricting constraints and stakeholder preferences.", "num_citations": "15\n", "authors": ["171"]}
{"title": "Intelligent decision support for road mapping a technology transfer case study with seimens corporate technology\n", "abstract": " In this paper, we describe a technology transfer case study with Siemens Corporate Technology, Systems and Engineering in Munich, Germany in which intelligent decision support was provided for road mapping of the services provided by this unit. The challenge was to provide roadmaps for optimal success in order to achieve maximum market competitiveness and customer satisfaction while simultaneously balancing the resources, business rules, risks, constraints and priorities of different stakeholders and customers around the world. The paper thus describes how ReleasePlanner, a cutting edge technology based on hybrid intelligence developed by the Laboratory for Software Engineering Decision Support at the University of Calgary was used to provide decision support. The technology transfer process and its impact at Siemens are reported.", "num_citations": "15\n", "authors": ["171"]}
{"title": "Effective customer relationship management at ATB financial: a case study on industry-academia collaboration in data analytics\n", "abstract": " Data analytics serve as a means to detect trends and patterns from organizational data repositories. The variety and dynamism of data and analysis approaches create a wide range of opportunities for collaboration between academia and industry. Successful collaboration projects create win-win scenarios with tangible benefits for both sides. This paper reports about an ongoing project between ATB Financial and the Laboratory for Software Engineering Decision Support (SEDS) at The University of Calgary. The key content of the project was to leverage the benefits of data analytics for efficient and effective customer relationship management (CRM). More precisely, the objective was to find analytic solutions that allow us to predict the complexity of an opportunity and to connect it with the right team member in order to increase efficiency and create value for ATB\u2019s customers. We report the results and\u00a0\u2026", "num_citations": "14\n", "authors": ["171"]}
{"title": "Software release planning\n", "abstract": " One of the most critical activities in software product development is the decisional process that assigns features to subsequent releases under technical, resource, risk, and budget constraints. This decision-centric process is referred to as software release planning (SRP).This briefing will expose a state of the art on SRP. A survey of the most relevant approaches will be presented. Emphasis will be made on their applicability (concerning e.g. type of development process - being more predictive versus more adaptive, type of system - commercial, open source product or mobile app), tool support and degree of validation in industry. One of these approaches, EVOLVE, will be analysed in detail.", "num_citations": "14\n", "authors": ["171"]}
{"title": "Release planning under fuzzy effort constraints\n", "abstract": " A software release is a collection of new and/or changed features that form a new product. Release planning is a very complex problem including different stakeholder perspectives, competing objectives and different types of constraints. Most of the information is usually uncertain. Under such circumstances, the use of crisp values is only an approximation of reality. We propose an approach improving existing methods for release planning by handling the uncertainty of data using fuzzy logic. Concretely, we consider fuzziness with respect to the effort estimates, effort capacity constraints and the different objectives related to cost, benefit and quality. The satisfaction of traditional constraints on effort is performed using a fuzzy system to obtain an overall satisfaction level of a solution. This is considered to be an essential support for the actual decision-making. All the proposed concepts and the complete approach are\u00a0\u2026", "num_citations": "14\n", "authors": ["171"]}
{"title": "Asymmetric release planning: Compromising satisfaction against dissatisfaction\n", "abstract": " Maximizing satisfaction from offering features as part of the upcoming release(s) is different from minimizing dissatisfaction gained from not offering features. This asymmetric behavior has never been utilized for product release planning. We study Asymmetric Release Planning (ARP) by accommodating asymmetric feature evaluation. We formulated and solved ARP as a bi-criteria optimization problem. In its essence, it is the search for optimized trade-offs between maximum stakeholder satisfaction and minimum dissatisfaction. Different techniques including a continuous variant of Kano analysis are available to predict the impact on satisfaction and dissatisfaction with a product release from offering or not offering a feature. As a proof of concept,we validated the proposed solution approach called Satisfaction-Dissatisfaction Optimizer (SDO) via a real-world case study project. From running three replications with\u00a0\u2026", "num_citations": "13\n", "authors": ["171"]}
{"title": "Learn or earn?-intelligent task recommendation for competitive crowdsourced software development\n", "abstract": " Background: Competitive crowdsourced development encourages online software developers to register for tasks offered on the crowdsourcing platform and implement them in a competitive mode. As a large number of tasks are uploaded daily, the scenery of competition is changing continuously. Without appropriate decision support, online developers often make task decisions in an ad hoc and intuitive manner. Aims: To provide dynamic decision support for crowd developers to select the task that fit best to their personal learning versus earning objectives, taking into account the actual competitiveness situation. Method: We propose a recommendation system called EX2 (\" EX-Square\") that combines both explorative (\" learn\") and exploitative (\" earn\") search for tasks, based on a systematic analysis of workers preference patterns, technologies hotness, and the projection of winning chances. The implemented prototype allows dynamic recommendations that reflect task updates and competition dynamics at any given time. Results: Based on evaluation from 4007 tasks monitored over a period of 2 years, we show that EX2 can explore and adjust task recommendations corresponding to context changes, and individual learning preferences of workers. A survey was also conducted with 14 actual crowd workers, showing that intelligent decision support from EX2 is considered useful and valuable. Conclusions: With support from EX2, workers benefit from the tool from getting customized recommendations, and the platform provider gets a higher chance to better cover the breadth of technology needs in case recommendations are taken.", "num_citations": "13\n", "authors": ["171"]}
{"title": "Analytical open innovation for value-optimized service portfolio planning\n", "abstract": " Service portfolio planning is the process of designing collections of services and deciding on their provision. The problem is highly information and decision centric. In this paper, we present a solution approach called Analytical Open Innovation (AOI). Open innovation facilitates comprehensive crowdsourcing and social media information analysis. In our proposed approach (AOI), open innovation is utilized for the elicitation of service needs, the definition of quality provision levels for each of the services, and detection of service dependencies and cost and value synergies. As the result of a rigorous optimization process, diversified and resource-optimized service portfolios are created. As a proof of concept, the proposed approach is illustrated via a case study project using Over the Top TV (OTT) services to be offered at different levels of quality over four quarters of a year.", "num_citations": "13\n", "authors": ["171"]}
{"title": "Two machine-learning techniques for mining solutions of the ReleasePlanner\u2122 decision support system\n", "abstract": " Decision support systems (DSSs) perform complex computations to provide suggestions regarding decision-making and problem solving. Quite often, the DSS solutions are not fully accepted by users because DSSs work as a black box so that the users cannot fully understand where the results came from and how they were derived. Explanations of the generated DSSs solutions are expected to mitigate this situation.In this paper, two machine-learning techniques, called rough set analysis (RSA) and dependency network analysis (DNA), are proposed for mining DSS solutions. The mining results are provided to the users as explanations for those solutions. Two parts of research results are described. First, a framework applying RSA and DNA for generating explanations for DSS solutions is presented. This framework is generic and applicable to many other DSSs. Second, as a proof-of-concept, the applications of\u00a0\u2026", "num_citations": "13\n", "authors": ["171"]}
{"title": "Analyzing an industrial strategic release planning process\u2013a case study at Roche diagnostics\n", "abstract": " [Context and motivation] Strategic release planning (SRP) for a globally used information system is a challenging task. Changes to requirements on different abstraction levels are arriving continuously and have an impact on long-term selected features. [Question/problem] The major question is how to successfully do SRP to create competitive advantage. [Principal ideas/results] An exploratory case study in an industrial context was conducted (1) to get a deeper understanding of the as-is SRP process in practice, (2) to evaluate the suitability of a to-be SRP process, introducing the EVOLVE II method and corresponding ReleasePlanner tool and (3) to gather additional requirements for the to-be SRP process, with respect to feature generation and feature selection. [Contribution] In this paper we describe the case study and present lessons learned to improve and customize a SRP process in\u00a0\u2026", "num_citations": "13\n", "authors": ["171"]}
{"title": "Task interruptions in requirements engineering: reality versus perceptions!\n", "abstract": " Task switching and interruptions are a daily reality in software development projects: developers switch between Requirements Engineering (RE), coding, testing, daily meetings, and other tasks. Task switching may increase productivity through increased information flow and effective time management. However, it might also cause a cognitive load to reorient the primary task, which accounts for the decrease in developers' productivity and increases in errors. This cognitive load is even greater in cases of cognitively demanding tasks as the ones typical for RE activities. In this paper, to compare the reality of task switching in RE with the perception of developers, we conducted two studies: (i) a case study analysis on 5,076 recorded tasks of 19 developers and (ii) a survey of 25 developers. The results of our retrospective analysis show that in ALL of the cases that the disruptiveness of RE interruptions is statistically\u00a0\u2026", "num_citations": "12\n", "authors": ["171"]}
{"title": "Evolutionary robust optimization for software product line scoping: An explorative study\n", "abstract": " Background: Software product line (SPL) scoping is an important phase when planning for product line adoption. An SPL scope specifies: (1) the extent of the domain supported by the product line, (2) portfolio of products in the product line and (3) list of assets to be developed for reuse across the family of products.Issue: SPL scope planning is usually based on estimates about the state of the market and the engineering capabilities of the development team. One challenge with these estimates is that there are inaccuracies due to uncertainty in the environment or accuracy of measurement. This may result in issues ranging from suboptimal plans to infeasible plans.Objective: To address the above, we propose to include uncertainty as part of the SPL scoping model. Plans developed in consideration of uncertainty would be more robust against possible fluctuations in estimates.Approach: In this paper, a method to\u00a0\u2026", "num_citations": "12\n", "authors": ["171"]}
{"title": "DEVis: A tool for visualizing software document evolution\n", "abstract": " During the software development process many technical documents are produced. Such documents and their evolution history contain rich information about the development process. Analyzing these document changes may reveal regularities and anomalies which are helpful to understand the software system and its development process. In this paper, we propose DEVis, an interactive visualization tool to visualize the software documentation evolution and aid the tasks of analyzing software development process. We initially evaluated our tool using the knowledge task-based framework and discuss the challenging aspects and lessons learned during the development of DEVis.", "num_citations": "12\n", "authors": ["171"]}
{"title": "When-to-release decisions for features with time-dependent value functions\n", "abstract": " Release planning is of key importance for incremental software product development. With the increasing size and complexity of software products, as well as with the growing demands for transparency and objectivity of decision-making, intuition alone is no longer sufficient for release planning. EVOLVE+ is a systematic method for release planning, which combines the strengths of formalization and computational efficiency with the expertise of the human experts. From a given set of candidate features, the most attractive ones are selected and assigned to a sequence of releases. In this paper, we consider three extensions to the current systematic planning approach EVOLVE+: (a) value functions describing the estimated value of the feature are continuous functions of time, (b) the actual release dates are no longer fixed but can be varied in some pre-defined interval. As a consequence, the available\u00a0\u2026", "num_citations": "12\n", "authors": ["171"]}
{"title": "Measurable software quality improvement through innovative software inspection technologies at allianz life assurance\n", "abstract": " The development of high quality software satisfying cost, schedule, and resource requirements is an essential prerequisite for improved competitiveness of life insurance companies. One major difficulty to master this challenge is the inevitability of defects in software products. Since defects are known to be significantly more expensive if detected in later development phases or testing, companies in this marketplace must use cost-effective technologies to detect defects early on in the development process. A particular promising one is software inspection.This paper describes the ESPRIT/ESSI Process Improvement Experiment\" High Quality of Software Products by Early Use of Innovative Reading Techniques (HYPER)\". The core of this project has been the transfer of innovative software inspection technologies to the Allianz EURO conversion projects. The innovation in the area of software inspection is based on a systematic reading technique, that is, Perspective-based reading (PBR), that tells inspection participants what to look for and-more important-how to scrutinise a software artefact for defects. Although numerous controlled experiments have shown the PBR technique to be particularly cost-effective, few results have been reported on its use in the context of development projects.", "num_citations": "12\n", "authors": ["171"]}
{"title": "Experience Factory-based professional education and training\n", "abstract": " Professional education and training plays a crucial role for successful transfer of innovative software engineering technologies and for achieving long-term strategic goals of an organization. We describe how empirically validated knowledge related to methods, tools, and techniques is organized and maintained in an organizational unit called Experience Factory. Emphasis of the paper is to describe how the knowledge and experience available from the Experience Factory is integrated into professional education and training courses and programs. We apply the fundamental quality improvement paradigm to describe the different steps how to perform courses and programs as part of organizational learning. Finally, the approach is illustrated by technology related experiences from the Fraunhofer Institute for Experimental Software Engineering. The infrastructure technology under investigation is goal-oriented\u00a0\u2026", "num_citations": "12\n", "authors": ["171"]}
{"title": "Software Engineering Decision Support and Empirical Investigations\u2013A Proposed Marriage\n", "abstract": " Do you conduct empirical investigations without realizing how they contribute to decision-making? Decisions are the driving engines behind any kind of development. This is also true for all stages of software development and evolution. Decisions can be related to resources and software technologies (subsuming methods, tools, and techniques). Decision-Making in Software Engineering is extremely challenging because of a dynamically changing environment, conflicting (stakeholder) objectives and constraints, and a high degree of uncertainty and vagueness of the information that is available. Decisions related to the \u2018How\u2019?\u2018How good\u2019?\u2018When\u2019?\u2018Why\u2019? and \u2018Where\u2019? questions in the use of Software technologies is too often still based on simplistic rules of thumb. What is needed is a sound methodology and with links to validated models and experience.Empirical Software Engineering is relying on or derived from observations or experiments. It is oriented towards making decisions about Software Engineering technologies. The paradigm of Software Engineering Decision Support (SEDS) goes beyond the concept of just reusing models, knowledge or experience. For a more focused problem domain, emphasis is on providing a methodology for pro-active generation, evaluation, prioritization and selection of solution alternatives. However, the results of this process can only be as good as the underlying models and experience. This is exactly the main purpose of Empirical Software Engineering: to incrementally establish a body of empirically validated knowledge about existing or new phenomena.", "num_citations": "11\n", "authors": ["171"]}
{"title": "Releasing sooner or later: An optimization approach and its case study evaluation\n", "abstract": " Decisions about the release date need to balance between the degree of readiness (quality) of the product and the potential competitive advantage and added value of (early) delivery. Based on an existing optimization approach for solving the maximum value release planning problem for a fixed release time, we provide a re-optimization approach for which includes local and global re-planning exchange operations to determine the outcome of varying the release dates. The proposed method determines a set of trade-off solutions related to (i) the value of the features implemented, (ii) their estimated quality, and (iii) the release time. The approach is evaluated by a real-world case study taken from an ongoing project which is to develop the new main release 2.0 for the release planning decision support platform ReleasePlanner\u2122 v1.6.", "num_citations": "10\n", "authors": ["171"]}
{"title": "The how? when? and what? for the process of re-planning for product releases\n", "abstract": " Volatility of features and dynamic change in stakeholders\u2019 needs often requires re-planning of an existing release plan to accommodate changes. H2W is a re-planning method that answers the questions of how, when, and what to re-plan of an existing product release strategy. For HOW, a greedy heuristic based on prioritization of candidate features is applied. A value-based re-planning approach is proposed for the WHEN question. For WHAT, a trade-off analysis between the degree of change related to the originally announced release plan and the improvement achievable by replacing existing features with more attractive ones is suggested. At each of the re-planning iterations, H2W either provides a new improved plan or states that an improvement does not exist. As a proof-of-concept, a case study is conducted.", "num_citations": "10\n", "authors": ["171"]}
{"title": "The PROFES Improvement Methodology\u2013Enabling Technologies and Methodology Design\n", "abstract": " Software process improvement methodologies do not typically address product issues explicitly and integration of different technologies is often weak. In the European project PROFES an integrated, product-focused software process improvement methodology has been developed. This paper gives an overview of the methodology and explains its enabling technologies. Emphasis is on how the PROFES improvement methodology was created, what was the design rationale, and how the methodology was implemented.", "num_citations": "10\n", "authors": ["171"]}
{"title": "Parametric maximal flows in generalized networks\u2013complexity and algorithms\n", "abstract": " The problem of determining parametric maximal flows in networks with gains is considered. A worst-case analysis with respect to the number of breakpoints in the optimal objective value function is performed for both parametric flows leaving the source and parametric capacities of the arcs. The result is an exponential growth of the number of breakpoints depending on the number of vertices in the underlying graph. From there, the idea of a horizontal approximation algorithm developed from Hamachee and Foulds [5] is extended to generalized flows. In each iteration the horizontal approach makes an improvement which is a piecewise linear function of the whole parameter interval. This process can be applied up to optimality", "num_citations": "10\n", "authors": ["171"]}
{"title": "Predicting the vector impact of change-an industrial case study at brightsquid\n", "abstract": " Background: Understanding and controlling the impact of change decides about the success or failure of evolving products. The problem magnifies for start-ups operating with limited resources. Their usual focus is on Minimum Viable Product (MVP's) providing specialized functionality, thus have little expense available for handling changes. Aims: Change Impact Analysis (CIA) refers to the identification of source code files impacted when implementing a change request. We extend this question to predict not only affected files, but also the effort needed for implementing the change, and the duration necessary for that. Method: This study evaluates the performance of three textual similarity techniques for CIA based on Bag of words in combination with either topic modeling or file coupling. Results: The approaches are applied on data from two industrial projects. The data comes as part of an industrial collaboration\u00a0\u2026", "num_citations": "9\n", "authors": ["171"]}
{"title": "A prototype tool supporting when-to-release decisions in iterative development\n", "abstract": " Shortening release cycles is one of the key elements for achieving highly competitive product releases. However, decisions about when-to-release are inherently complex: The potential competitive advantage through faster delivery needs to be balanced against the degree of readiness of the product (overall quality) and the added value through new and revised features. Pro-active analysis of the estimated impact of running through various release scenarios is expected to provide insights and essential inputs for the actual decision-making.When-to-release decisions are largely re-actively using existing release planning tools such as IBM Focal Point, Ontime (for Scrum-based development) or ReleasePlanner. In this paper, the authors propose a plugin tool that analyzes the impact of varying the release date. More precisely, we proactively investigate the trade-off relationship between the total amount of implemented functionality and the predicted quality achieved from the related effort investment. As a result, the product managers are empowered to see the projected impact of releasing earlier (or later) in terms of reduced (or added) functionality and/or quality. As a proof-of-concept, we provide some preliminary results on the usage of the tool.", "num_citations": "9\n", "authors": ["171"]}
{"title": "Evaluation of optimized staffing for feature development and bug fixing\n", "abstract": " Skill level and productivity varies substantially between developers. In current staffing practices, however, developers are largely treated as the same. In this paper, an empirical analysis of the tow formulations of assignment of developers to tasks and bug fixing activities is studied. Two related problems are considered:", "num_citations": "9\n", "authors": ["171"]}
{"title": "ReleasePlanner-Planning new Releases for Software Maintenance and Evolution.\n", "abstract": " ReleasePlanner\u00ae(www. releaseplanner. com) is a webbased decision support system based on the principles of hybrid intelligence. By bringing computational intelligence together with the capabilities of human experts, it enables intelligent planning, prioritizing and road-mapping decisions. To support challenges related to software maintenance, the tool is used for prioritization and planning of software releases as the systems evolve with requirements. With dynamic market environment and the changing needs of customers and considering constraints related to cost, quality and time it becomes increasingly important to plan which features to have in the immediate next release, which ones to have in the subsequent releases after that or which ones to post pone for future to have the maximum benefit and customer satisfaction. Continuous evolution is what is typically happening with the software systems and more and more systems are being delivered incrementally to the market. The ReleasePlanner\u00ae tool is thus used to provide intelligent support for software maintenance when requirements keep evolving. The tool assigns requirements to releases such that most important technical, resource, risk and budget constraints are met. The tool models the uncertainties involved with parameters such as different stakeholder perspectives, competing objectives, business rules and different types of constraints and generates plans which are maximally diversified and optimized to give best possible solutions based on the problem parameters modeled. In this paper we would introduce the architecture of the tool and discuss the key features of the tool.", "num_citations": "9\n", "authors": ["171"]}
{"title": "Uncertainty handling in tabular-based requirements using rough sets\n", "abstract": " Software requirements management is an essential process to better understand, identify, derive, control and improve system requirements. Typically, requirements are unclear at the beginning and evolve over time. Uncertainties usually produce conflicts among requirements. Rough set analysis (RSA) is a promising technique of granular computing. The emphasis of this paper is on formally defining three software requirements uncertainty problems and on applying RSA to solve these problems. A systematic approach called MATARS was developed for that purpose. We use a modification of a real world software requirements specification (SRS) benchmark example to illustrate main concepts and ideas of the approach.", "num_citations": "9\n", "authors": ["171"]}
{"title": "New approaches to the identification of dependencies between requirements\n", "abstract": " There is a high demand for intelligent decision support systems which assist stakeholders in requirements engineering tasks. Examples of such tasks are the elicitation of requirements, release planning, and the identification of requirement-dependencies. In particular, the detection of dependencies between requirements is a major challenge for stakeholders. In this paper, we present two content-based recommendation approaches which automatically detect and recommend such dependencies. The first approach identifies potential dependencies between requirements which are defined on a textual level by exploiting document classification techniques (based on Linear SVM, Naive Bayes, Random Forest, and k-Nearest Neighbors). This approach uses two different feature types (TF-IDF features vs. probabilistic features). The second recommendation approach is based on Latent Semantic Analysis and defines\u00a0\u2026", "num_citations": "8\n", "authors": ["171"]}
{"title": "Hybrid Labels Are the New Measure!\n", "abstract": " Developing minimum viable products (MVPs) is critical for start-up companies to hit the market fast with an accepted level of performance. The US Food and Drug Administration mandates additional nonfunctional requirements in healthcare systems, meaning that the MVP should provide the best availability, privacy, and security. This critical demand is motivating companies to further rely on analytics to optimize the development process. In a collaborative project with Brightsquid, the authors provided a decision-support system based on analogical reasoning to assist in effort estimation, scoping, and assignment of change requests. This experience report proposes a new metric, change request labels, for better prediction. Using different methods for textual-similarity analysis, the authors found that the combination of machine-learning techniques with experts' manually added labels has the highest prediction\u00a0\u2026", "num_citations": "8\n", "authors": ["171"]}
{"title": "Release readiness classification: An explorative case study\n", "abstract": " Context: To survive in a highly competitive software market, product managers are striving for frequent, incremental releases in ever shorter cycles. Release decisions are characterized by high complexity and have a high impact on project success. Under such conditions, using the experience from past releases could help product managers to take more informed decisions.", "num_citations": "8\n", "authors": ["171"]}
{"title": "A hybrid machine learning method and its application in municipal waste prediction\n", "abstract": " Prediction methods combining clustering and classification techniques have the potential of creating more accurate results than the individual techniques, particularly for large datasets. In this paper, a hybrid prediction method is proposed from combining weighted k-means clustering and linear regression. Weighted k-means is used to cluster the dataset. Then, linear regression is performed on each cluster to build the final predictors. The proposed method has been applied to the problem of municipal waste prediction and evaluated with a dataset including 63,000 records. The results showed that it outperforms the single application of linear regression and k-means clustering in terms of prediction accuracy and robustness. The prediction model is integrated into a decision support system for strategic and operational planning of waste and recycling services at the City of Calgary in Canada. The potential\u00a0\u2026", "num_citations": "8\n", "authors": ["171"]}
{"title": "Decision support for software release planning using e-assistants\n", "abstract": " The problem of assigning most appropriate requirements to a series of releases of a software system is difficult to solve due to uncertainty from several sources, for example, the preferences of different stakeholders. We present a solution to this problem by providing a flexible release planning procedure using a solution generation engine, ReleasePlanner\u00ae, and so-called e-assistants. In our iterated e-release planning process, e-assistants present to their human stakeholders solutions to variants of the problem instance. By selecting the best suited solutions, the stakeholders allow the e-assistants to elicit more and more their implicit preferences. To guarantee termination, in each round the assignment of some requirements to releases is fixed, based on analysing concordance and non-discordance of assignments between the preferred candidate solutions.", "num_citations": "8\n", "authors": ["171"]}
{"title": "Requirements dependency extraction by integrating active learning with ontology-based retrieval\n", "abstract": " Context: Incomplete or incorrect detection of requirement dependencies has proven to result in reduced release quality and substantial rework. Additionally, the extraction of dependencies is challenging since requirements are mostly documented in natural language, which makes it a cognitively difficult task. Moreover, with ever-changing and new requirements, a manual analysis process must be repeated, which imposes extra hardship even for domain experts.Objective: The three main objectives of this research are: 1) Proposing a new dependency extraction method using a variant of Active Learning (AL). 2) Evaluating this AL and Ontology-based Retrieval (OBR) as baseline methods for dependency extraction on the two industrial data sets. 3) Analyzing the value gained from integrating these diverse approaches to form two hybrid methods.Method: Building on the general AL, ensemble and semi-supervised\u00a0\u2026", "num_citations": "7\n", "authors": ["171"]}
{"title": "More insight from being more focused: analysis of clustered market apps\n", "abstract": " The increasing attraction of mobile apps has inspired researchers to analyze apps from different perspectives. As any software product, apps have different attributes such as size, content maturity, rating, category or number of downloads. Current research studies mostly consider sampling across all apps. This often results in comparisons of apps being quite different in nature and category (games compared with weather and calendar apps), also being different in size and complexity. Similar to proprietary software and web-based services, more specific results can be expected from looking at more homogeneous samples as they can be received as a result of applying clustering.", "num_citations": "7\n", "authors": ["171"]}
{"title": "What counts is decisions, not numbers\u2014Toward an analytics design sheet\n", "abstract": " Decision-making is the process of determining a course of action to achieve a goal, and fulfill given constraints. The variety of product release decisions (What features to release next? When to release them? Focus on functionality versus quality of features?) is just one example of the wide spectrum of decisions that have to be made during the different stages of the software life-cycle. Some of these decisions are related to operational questions (who should fix this bug?), others are more strategic decisions in nature (outsourcing which parts of development? Migration to another platform?). In all these cases, one wants to select best feasible alternative based on some evaluation criteria. All these decisions are made by humans. However, the difference is in how much the human decision makers can rely on insight gained from analytics, and how much of it is just based on intuition. We propose the analytics design\u00a0\u2026", "num_citations": "7\n", "authors": ["171"]}
{"title": "Trade-off service portfolio planning\u2013a case study on mining the Android app market\n", "abstract": " Service portfolio planning is the process of designing collections of services and deciding on their provision. The problem is highly information intensive, and most of the information required is hard to gather. In this paper, we present a solution approach based on the paradigm of Analytical Open Innovation (AOI). Open innovation is a cheap and low risk problem solving approach which relies on knowledge exchange with outside of company as a competitive advantage. Different forms of open innovation; crowd source, open source and outsource; facilitate the provider and consumer interactions and brings higher customer value. In our proposed AOI approach, open innovation is utilized for elicitation of services from web data, crowdsourcing the service value from potential customers and for the estimation of service implementation effort. For service evaluation, we apply the Kano theory of product development and customer satisfaction. Based on that and as the result from an optimization process, resource-optimized service portfolios are created that constitute trade-offs in balancing between gained value and effort needed. As a proof of concept, the proposed approach is illustrated via a case study project for the composition of Over the Top TV (OTT) services. The atomic services from 241 qualified apps were analyzed from the android app market. We demonstrate that the proposed approach is able to generate optimized trade-off solutions, composing better apps at each capacity level and achieving better customer satisfaction. The level of improvement in customer satisfaction varies between 16.5% and 95.3%.", "num_citations": "7\n", "authors": ["171"]}
{"title": "Monitoring bottlenecks in achieving release readiness: a retrospective case study across ten OSS projects\n", "abstract": " Context: Not releasing software on time can cause substantial loss in revenue. Continuous awareness of the product release status is required. Release readiness is a time-dependent attribute of the status of the product release, which aggregates the degree of satisfaction of a portfolio of release process and product measures.Goal: At different stages of a release cycle, the goal is to understand frequencies and pattern of occurrence of factors affecting project success by restricting the status of release readiness (called bottlenecks).Method: As a form of explorative case study research, we analyzed ten open source software (OSS) projects taken from the GitHub repository. As a retrospective study covering a period of 28 weeks, we monitored eight release readiness attributes and identified their impact on release readiness over time across the ten projects.Results: Feature completion rate, Bug fixing rate, and\u00a0\u2026", "num_citations": "7\n", "authors": ["171"]}
{"title": "Multi-criteria decision analysis for customization of estimation by analogy method aqua+\n", "abstract": " The quality of results from a predictor model depends on the proper customization of the parameters of the model. For Estimation by Analogy (EBA), the impact of the parameter\" Attribute weighting technique\" has been shown by several authors. The decision problem\" Which attribute weighting technique is preferable for EBA in which situation?\" is considered in this paper from the perspective of multi-criteria decision analysis (MCDA). The empirical results are given for the EBA method AQUA+.", "num_citations": "7\n", "authors": ["171"]}
{"title": "Kosten/Nutzen-Analyse von GQM-basiertem Messen und Bewerten\u2014Eine replizierte Fallstudie\n", "abstract": " Empirische Untersuchungen erlauben es, die Wirksamkeit des Einsatzes neuer Technologien, Methoden und Werkzeuge im kommerziellen Umfeld abzusch\u00e4tzen. Im Mittelpunkt dieses Beitrags stehen der Einsatz und die experimentelle Evaluierung der Kosten/Nutzen-Relation des Goal/Question/Metric (GQM)-An-satzes zur Beschreibung, Bewertung, Kontrolle sowie zur systematischen Verbesserung eines breiten Spektrums von Qualit\u00e4tszielen im gesamten Proze\u00df der Software-Entwicklung. Dazu werden die Ergebnisse einer replizierten Fallstudie mit Software-Organisationen aus drei Unternehmen (Robert Bosch GmbH, DEC Italy, Schlumberger RPS (Niederlande)) vorgestellt, die innerhalb des ESPRIT/ESSI Projekts Customized Establishment of Measurement Programs (CEMP) erarbeitet wurden. Dabei wurde GQM in Verbindung mit unternehmensspezifischen Software-Qualit\u00e4tsaspekten der Zuverl\u00e4ssigkeit\u00a0\u2026", "num_citations": "7\n", "authors": ["171"]}
{"title": "Knowledge discovery from software engineering measurement data: a comparative study of two analysis techniques\n", "abstract": " You have located a publication of the Fraunhofer Gesellschaft. To conduct a more concise search, please access the Fraunhofer-Publica, a bibliographic database of Fraunhofer publications dating from 1980 to present, or the Fraunhofer-ePrints which contains electronic fulltext documents of the Fraunhofer Gesellschaft.", "num_citations": "7\n", "authors": ["171"]}
{"title": "Data-driven elicitation and optimization of dependencies between requirements\n", "abstract": " Requirement dependencies affect many activities in the software development life cycle such as design, implementation, testing, release planning and change management. They are the basis for various software development decisions. However, requirements dependencies extraction is not only error-prone but also a cognitively and computationally complex problem that consumes substantial efforts, since most of the requirements are documented in natural language. This paper proposes a novel approach to extracts requirements dependencies utilizing natural-language processing (NLP) and weakly supervised learning (WSL) in two stages. In the first stage, binary dependencies (basic dependencies:dependent/independent) are identified, which are further analyzed to detect the type of the dependency in the second stage. An initial evaluation of this approach on the PURE data set - European Rail Traffic\u00a0\u2026", "num_citations": "6\n", "authors": ["171"]}
{"title": "Decision support for increasing the efficiency of crowdsourced software development\n", "abstract": " Crowdsourced software development (CSD) offers a series of specified tasks to a large crowd of trustworthy software workers. Topcoder is a leading platform to manage the whole process of CSD. While increasingly accepted as a realistic option for software development, preliminary analysis on Topcoder's software crowd worker behaviors reveals an alarming task-quitting rate of 82.9%. In addition, a substantial number of tasks do not receive any successful submission. In this paper, we report about a methodology to improve the efficiency of CSD. We apply massive data analytics and machine leaning to (i) perform comparative analysis on alternative technique analysis to predict likelihood of winners and quitters for each task, (ii) significantly reduce the amount of non-succeeding development effort in registered but inappropriate tasks, (iii) identify and rank the most qualified registered workers for each task, and (iv) provide reliable prediction of tasks risky to get any successful submission. Our results and analysis show that Random Forest (RF) based predictive technique performs best among the alternative techniques studied. Applying RF, the tasks recommended to workers can reduce the amount of non-succeeding development effort to a great extent. On average, over a period of 30 days, the savings are 3.5 and 4.6 person-days per registered tasks for experienced resp. unexperienced workers. For the task-related recommendations of workers, we can accurately recommend at least 1 actual winner in the top ranked workers, particularly 94.07% of the time among the top-2 recommended workers for each task. Finally, we can predict, with\u00a0\u2026", "num_citations": "6\n", "authors": ["171"]}
{"title": "Applying data analytics towards optimized issue management: An industrial case study\n", "abstract": " This document describes our experience of applying data analytics at Plexina, a leading IT company working in the healthcare domain. The main goal of the project was to identify factors currently affecting issue management and to make analytics based suggestions for optimizing the process. Various statistical and machine learning techniques were applied on a data set extracted from six releases of Plexina, containing more than 666 issues. Statistical techniques successfully identified the various factors that leads to estimation inaccuracy related to issues as well as identified the hidden relationships existing among various variables. The employed predictive analytic models was also successful to some extent, in predicting effort estimation related inaccuracy associated with the issues. The insights provided by the entire data analytics study can be of great help to product managers or the developers to make\u00a0\u2026", "num_citations": "6\n", "authors": ["171"]}
{"title": "Value-based portfolio scoping: An industrial case study\n", "abstract": " Customization is considered as a promising way for better satisfying diversity of customer needs. In organizations short of resources, it is a frequent challenge to get balance between development and customization workload in order to ensure product success as well as customer satisfaction. In this paper, we proposed a value-based product portfolio scoping approach to determine optimal product scale for planning software product line adoption. The approach blends existing methods in domain analysis, requirements clustering, and valuation theory. An industrial case study is presented to demonstrate the application of the approach and its effectiveness.", "num_citations": "6\n", "authors": ["171"]}
{"title": "Simulation-based decision support for bringing a project back on track: The case of RUP-based software construction\n", "abstract": " RUP-based development has proven successful in various contexts. The iterative and phased development approach provides a framework for how to develop software efficiently and effectively. Yet, there are plenty of occasions that the projects go off-track in terms of the key parameters of the project such as quality, functionality, cost, and schedule. The challenge for the software project manager is to bring the project back on track. Simulation, in general, and system dynamics based simulation in particular, is established as a method to pro-actively evaluate possible scenarios and decisions. The main contribution of this paper is a method called SIM-DASH; it combines three established techniques for providing decision support to the software project manager in the context of RUP-based development. SIM-DASH consists of (i) a system dynamics modeling and simulation component for RUP-based construction, (ii\u00a0\u2026", "num_citations": "6\n", "authors": ["171"]}
{"title": "Resource allocation and activity scheduling: bug fixing perspective\n", "abstract": " The problem of resource allocation and activity scheduling deals with a set of activities competing for reusable resource. The main objective is to find a feasible schedule to specify which activities are selected for execution and when they are scheduled so that maximum profit can be gained. A successful scheduling requires assigning right personnel for the right task which has been a great challenge in the software industry. For optimal resource allocation decision makers require both activities and workforce related information. This sort of information largely depends on software project estimation. Most commonly used estimation techniques are regression, analogy, expert judgment, work break-down, function point, classification and regression trees, simulation, neural network, theory, Bayesian and combination of these techniques. Researchers have done lots of work on estimation and numerous models and\u00a0\u2026", "num_citations": "6\n", "authors": ["171"]}
{"title": "Does explanation improve the acceptance of decision support for product release planning?\n", "abstract": " Objective: Decision support provided to users is often lack of acceptance. One of the reasons is a deficit in understanding where the suggestions come from and how they come. This essentially is not a technical problem, but a technology adoption problem. This situation was also analyzed as a result of former empirical studies conducted on ReleasePlanner TM , a decision support tool for planning product releases. To overcome this situation, three machine learning techniques have been applied to mine the tool's solutions, and the mining results are presented to the tool users as explanations. This paper presents the evaluation on the generated explanations as a means to improve the user acceptance of the tool. Method: A three-stage controlled experiment was designed and carried out with a group of ten graduate students at the University of Calgary and another group of five project managers from the IT\u00a0\u2026", "num_citations": "6\n", "authors": ["171"]}
{"title": "A two-staged survey on release readiness\n", "abstract": " Deciding about the content and readiness when shipping a new product release can have a strong impact on the success (or failure) of the product. Having formerly analyzed the state-of-the art in this area, the objective for this paper was to better understand the process and rationale of real-world release decisions and to what extent research on release readiness is aligned with industrial needs. We designed two rounds of surveys with focus on the current (Survey-A) and the desired (Survey-B) process of how to make release readiness decisions. We received 49 and 40 valid responses for Survey-A and Survey-B, respectively.", "num_citations": "5\n", "authors": ["171"]}
{"title": "Understanding task interruptions in service oriented software development projects: an exploratory study\n", "abstract": " The Service-Oriented Software Development (SOSD) approach is a common software development paradigm. Previous qualitative and quantitative studies looked at the main reasons for the delay in software development so as to help project's stakeholders to take appropriate actions for improvement in their planning. In SOSD projects, due to the high level of user involvement in new service and product development, service providers need to make dynamic trade-offs to address their clients' demands. In this paper, we look at interruptions and their impact on tasks duration. We used text classification, Natural Language Processing (NLP), and quantitative time series analysis techniques to analyze 7, 770 development tasks of five real SOSD projects at Arcurve Inc. Our results show that fixing an issue, addressing changes, and adding new features are the most frequently perceived causes of {interruption} in SOSD\u00a0\u2026", "num_citations": "5\n", "authors": ["171"]}
{"title": "Understanding the impact of technical debt in coding and testing: An exploratory case study\n", "abstract": " Technical Debt (TD) refers to the long-term consequences of shortcuts taken during different phases of software development life cycle. Lack of attention to monitoring and managing testing and development debt can contribute to unexpectedly large cost overruns and severe quality issues in software development projects. This paper describes a case study conducted with an industry partner to explore the impact of TD in coding and testing. By conducting (i) a semi-structured interview, and (ii) a quantitative survey, we found that (1) the status of TD is largely project-independent,(2) we could not reject that there is no significant difference between the percentage of existing TD and the required time for reducing this TD in testing and development teams,(3) there is a statistically significant difference between the perceived influence of reducing TD on productivity increase in testing and development teams,(4) team\u00a0\u2026", "num_citations": "5\n", "authors": ["171"]}
{"title": "Value-risk trade-off analysis for iteration planning in extreme programming\n", "abstract": " Selection of the right user stories and planning their implementation for the next iteration is critical for success of extreme Programming (XP). Success here is measured by the total business value generated from all user stories implemented within time. The business value of an iteration is composed by the value of the individual user stories selected and additional value created from themes of user stories. In this paper, a method combining advanced search and risk analysis is proposed to support decision-making for the \"best\" set of user stories. The advanced search technique combines genetic search with subsequent application of the hill climbing technique. The top candidate solutions are further analyzed pro-actively in terms of their risk to be implementable in-time with the available effort. As a proof-of-concept, the applicability of the proposed method is applied for the planning of one iteration in a case study\u00a0\u2026", "num_citations": "5\n", "authors": ["171"]}
{"title": "Customization support for CBR-based defect prediction\n", "abstract": " Background: The prediction performance of a case-based reasoning (CBR) model is influenced by the combination of the following parameters:(i) similarity function,(ii) number of nearest neighbor cases,(iii) weighting technique used for attributes, and (iv) solution algorithm. Each combination of the above parameters is considered as an instantiation of the general CBR-based prediction method. The selection of an instantiation for a new data set with specific characteristics (such as size, defect density and language) is called customization of the general CBR method.Aims: For the purpose of defect prediction, we approach the question which combinations of parameters works best at which situation. Three more specific questions were studied:", "num_citations": "5\n", "authors": ["171"]}
{"title": "Balancing value and modifiability when planning for the next release\n", "abstract": " Planning the next release in software release planning addresses the problem of assigning features to the next release such that technical, resource, risk, and budget constraints are met. This paper studies the planning for the next release of an evolving system from a bi-criteria perspective. We introduce a method called NRP-trade-off to adjust baseline release plans for more modifiability by replacing lower value features with features having a higher modifiability. For that purpose, we include a new approach for feature modeling and assessing modifiability by applying object-oriented design metrics to the feature domain. We also briefly introduce a case study.", "num_citations": "5\n", "authors": ["171"]}
{"title": "Strategic planning of enterprise application integration\n", "abstract": " The integration of enterprise applications is an emerging paradigm of software development. It extends the integration of Components-of-the shelf (COTS) products by bringing together complete applications, processes, repositories and technologies. However, this process is far from being fully understood or even controlled.In this paper, we propose a novel and innovative approach for release planning called ReleasePlannerTM as a means to perform strategic planning of enterprise application integration (EAI). It is intended to serve as an early guidance of how to conduct EAI which has to be supplemented later by more detailed operational planning. The release planning technology is based on an evolutionary approach for assigning features to releases. For varying degree of stakeholder importance, well balanced plans are generated satisfying most relevant technological, resource and risk constraints.", "num_citations": "5\n", "authors": ["171"]}
{"title": "Panel: shortages of qualified software engineering faculty and practitioners: challenges in breaking the cycle\n", "abstract": " One of the most serious issues facing the software engineering education community is the lack of qualified tenure-track (full-time) faculty to teach software engineering courses, particularly at the undergraduate level. Similarly, one of the most serious issues facing the software industry is the lack of qualified junior and senior software engineers. This shortage cycle has existed for some time, and if it is not addressed properly will only worsen, thereby affecting the software engineering field in a more general way than it has already. The objective of this panel is to put a number of suggestions for improvement into discussion and debate in order to evaluate their potential and viability.", "num_citations": "5\n", "authors": ["171"]}
{"title": "Knowledge discovery from software engineering data: Rough set analysis and its interaction with goal-oriented measurement\n", "abstract": " Knowledge discovery from software engineering measurement data is an essential prerequisite for software quality improvement. Software measurement is increasingly recognized as a device to better understand, monitor, predict, and improve software development and maintenance projects. The paper describes the interaction between goal-oriented measurement and rough set based analysis in the context of experimental software engineering. The gained experiences are based on the application of rough set analysis in practical problems of software engineering.", "num_citations": "5\n", "authors": ["171"]}
{"title": "A comparative study of two techniques for analyzing software measurement data\n", "abstract": " Careful analysis of Software Engineering measurement data is essential in deriving the right conclusions from performed experiments. Different data analysis techniques may provide data analysts with different and complementary insights into the studied phenomena. In this paper, two data analysis techniques-Rough Sets and Logistic Regression-are compared, from both the theoretical and the experimental points of view. In particular, the empirical study was performed as part of the ESPRIT/ESSI project CEMP on a real-life maintenance project, the DATATRIEVE project carried out at Digital Engineering Italy. The two data analysis techniques are different in nature: Logistic Regression uses a statistical approach, while the Rough Sets analysis technique does not. We have applied both techniques to the same data set. The goal of the experimental study was to determine the major factors affecting reliability and reusability in the application context. Results obtained with either analysis technique are discussed and compared, to identify commonalities and differences between the two techniques. Finally, both analysis techniques are evaluated with respect to their weaknesses and strengths.", "num_citations": "5\n", "authors": ["171"]}
{"title": "Essmart way to manage user requests\n", "abstract": " Quality and market acceptance of software products is strongly influenced by responsiveness to user requests. Once a request is received from a customer, decisions need to be made if the request should be escalated to the development team. Once escalated, the ticket must be formulated as a development task and be assigned to a developer. To make the process more efficient and reduce the time between receiving and escalating the user request, we aim to automate of the complete user request management process. We propose a holistic method called ESSMArT. The methods performs text summarization, predicts ticket escalation, creates the title and content of the ticket used by developers, and assigns the ticket to an available developer. We internally evaluated the method by 4,114 user tickets from Brightsquid and their secure health care communication plat- form Secure-Mail. We also perform an external evaluation on the usefulness of the approach. We found that supervised learning based on context specific data performs best for extractive summarization. For predicting escalation of tickets, Random Forest trained on a combination of conversation and extractive summarization is best with highest precision (of 0.9) and recall (of 0.55). From external evaluation we found that ESSMArT provides suggestions that are 71% aligned with human ones. Applying the prototype implementation to 315 user requests resulted in an average time reduction of 9.2 minutes per request. ESSMArT helps to make ticket management faster and with reduced effort for human experts. ESSMArT can help Brightsquid to (i) minimize the impact of staff turnover\u00a0\u2026", "num_citations": "4\n", "authors": ["171"]}
{"title": "Analysis of software service usage in healthcare communication services\n", "abstract": " In digital health communication domain, the software is usually offered as a service (SaaS) which mandates attracting customers' satisfaction within each use of service. We report a case study in this domain which provides secure web based mail services that establish a secure bridge between patients and medical personnel. In this context, we explore service usage to guide value prediction for existing and prospective customers. Understanding the behavior of clients can help optimize services by providing them to users based on past usage trends or patterns. Therefore, service usage analysis in digital health products can pave the road for efficient communications and feature utilization in software in the health-care market.", "num_citations": "4\n", "authors": ["171"]}
{"title": "A search based approach towards robust optimization in software product line scoping\n", "abstract": " Software product line (SPL) scoping is important for planning upfront investment. One challenge with scoping comes from inaccuracies in estimated parameters and uncertainty in environment. In this paper, a method to incorporate uncertainty in SPL scoping optimization and its application to generate robust solutions is proposed. We model scoping optimization as a multi-objective problem with profit and stability as heuristics. To evaluate our proposal, a number of experiments are conducted. Analysis of results show that both performance stability and feasibility stability were improved providing the product line manager enhanced decision-making support.", "num_citations": "4\n", "authors": ["171"]}
{"title": "Decision support for capacitated arc routing for providing municipal waste and recycling services\n", "abstract": " This paper describes the design, development and initial evaluation of a decision support system (DSS) for capacitated arc routing. The research was motivated from a collaboration project with The City of Calgary business unit for Waste & Recycling Services (WRS). Their services cover residential waste collection for 306,000 residential homes. Intelligent decision support was needed to address the increasing business complexity and the need for higher efficiency and transparency of decision-making processes. The proposed routing is incorporating seasonal trends of waste creation. The seasonal changes are between 10.000 (low) to 25000 (peak) tons per month for the whole city. Different arc routings apply for different amounts of waste. A prototype DSS was developed with several components including one for prediction of waste amounts and one for arc routing of trucks. The paper describes the\u00a0\u2026", "num_citations": "4\n", "authors": ["171"]}
{"title": "Integrating project and system knowledge management\n", "abstract": " Software engineering is a knowledge-intensive task. Many different kinds of knowledge are created, eg, system knowledge such as requirements, design or code, and project knowledge such as project plans and work items. In this chapter, we study two kinds of project knowledge: work items and decisions. Work items represent the short-term project knowledge documenting what should or has been done by whom and when. This is very important for the project manager. Decisions represent the long-term project knowledge, that is, what should be known and kept in mind for future development in order to be consistent with the past. This is very important for project and maintenance staff. These kinds of knowledge can be implicit or explicit. Work items are typically managed explicitly in issue trackers, while decisions are mostly hidden in informal notes or in the artifacts, which result from the decisions. Rationale\u00a0\u2026", "num_citations": "4\n", "authors": ["171"]}
{"title": "Balancing Business and Technical Objectives for Supporting Software Evolution\n", "abstract": " Context: Successful software systems continuously evolve to accommodate feature requests of a diverse customer-base. At some point during this evolution, the variety of customer needs and increased system complexity suggests the consideration of a software product line (SPL).Aim: The goal of this research is to support the decision maker facing the enhancement of an evolving software system (ESS) by determining the most appropriate product line design (out of a given set of candidate SPL portfolios) to minimize the technical risk and maximize the business value.Method: The proposed method called OPTESS is aimed at finding an evolution plan for the ESS which optimizes both the given technical and business objectives. Business analysis using a value-based pricing mechanism is applied to a set of initially proposed SPL portfolios (for enhancing the ESS) such that profit is maximized. Technical analysis is applied to the same initially proposed SPL portfolios to minimize the risk of failure of ESS due to implementation of new features. Business and technical analyses improve the performance of solutions for their respective objectives by modifying the feature sets of candidate SPL portfolios. OPTESS helps the decision maker select a plan for enhancement of an ESS by performing trade-off analysis between economic and technical objectives.Results: The method was initially evaluated through a case study for a set of 9 new candidate features to be added to an open source text editing system called jEdit. OPTESS helped the decision maker to identify 3 non-dominated solutions judged to be the best contenders for addition when\u00a0\u2026", "num_citations": "4\n", "authors": ["171"]}
{"title": "Software release planning with time-dependent value functions and flexible release dates\n", "abstract": " SOFTWARE RELEASE PLANNING WITH TIME-DEPENDENT VALUE FUNCTIONS AND FLEXIBLE RELEASE DATES Jim Mc Elroy & Guenther Ruhe University of Calgary Laboratory for Software Engineering Decision Support 2500 University Dr. NW, Calgary, AB T2N1N4 Canada {mcelroy, ruhe}@cpsc.ucalgary.ca ABSTRACT Release planning is of key importance for incremental software product development. In conjunction with the value and the effort needed to implement features, decisions need to be made as to which features are offered in which releases. The value of features can vary over time depending on market conditions, competition, contractual constraints, and other concerns. Release dates and the specific features placed in releases need to be determined in a way that maximizes the overall value related to the investments made. The main contributions of the paper are (i) the formula- tion of value--[\u2026", "num_citations": "4\n", "authors": ["171"]}
{"title": "Web-based decision support for software release planning\n", "abstract": " Web technology and Web Services represent a great opportunity for improving knowledge and experience exchange. In this paper, the focus is on intelligent decision support for software release planning. We first characterize the problem of software release planning, and then review Web technology and Webfbased Decision Support Systems. By deriving some major requirements on Webfbased decision support for release planning, we then put forward a suggestion for an architectural design. We discuss the first steps of its realization and future directions of its realfworld application.", "num_citations": "4\n", "authors": ["171"]}
{"title": "Methodological contributions to professional education and training\n", "abstract": " Professional education and training plays a crucial role for successful transfer of innovative software engineering technologies and for achieving long-term strategic goals of an organization. We describe how empirically validated knowledge related to methods, tools and techniques is organized and maintained in an organizational unit called Experience Factory. The emphasis is on describing how the knowledge and experience available from the Experience Factory is integrated into professional education and training courses and programs. The Web-based training approach is focusing on computer supported collaborative learning. We apply the fundamental quality improvement paradigm to describe the different steps for how to perform and develop courses and programs by applying principles of systematic product and process management.", "num_citations": "4\n", "authors": ["171"]}
{"title": "How to Make Sense of Empirical Software Engineering Data: An Integrated Approach\n", "abstract": " You have located a publication of the Fraunhofer Gesellschaft. To conduct a more concise search, please access the Fraunhofer-Publica, a bibliographic database of Fraunhofer publications dating from 1980 to present, or the Fraunhofer-ePrints which contains electronic fulltext documents of the Fraunhofer Gesellschaft.", "num_citations": "4\n", "authors": ["171"]}
{"title": "A case study of evaluating configuration management practices with goal-oriented measurement\n", "abstract": " The paper describes the application of goal-oriented measurement for evaluating configuration management practices at Societa Interbancaria per l'Automazione (SIA). SIA is in charge of running, developing, and maintaining the National Interbank Network of Italy. The results of a CMM-based process assessment indicated that configuration management (CM) practice was one of the most premising areas for improvement. A project was initiated aimed at establishing an improved CM process supported by state-of-the-art tools and incorporating sound practices. It was decided to apply the new process to one of the most important products of SIA, which deals with the development of a new generation of networking software. Goal-oriented measurement following the goal/question/metric (GQM) approach was applied to monitor the establishment of the CM process. The paper describes the establishment and\u00a0\u2026", "num_citations": "4\n", "authors": ["171"]}
{"title": "CrowdSim: A Hybrid Simulation Model for Failure Prediction in Crowdsourced Software Development\n", "abstract": " A typical crowdsourcing software development(CSD) marketplace consists of a list of software tasks as service demands and a pool of freelancer developers as service suppliers. Highly dynamic and competitive CSD market places may result in task failure due to unforeseen risks, such as increased competition over shared worker supply, or uncertainty associated with workers' experience and skills, and so on. To improve CSD effectiveness, it is essential to better understand and plan with respect to dynamic worker characteristics and risks associated with CSD processes. In this paper, we present a hybrid simulation model, CrowdSim, to forecast crowdsourcing task failure risk in competitive CSD platforms. CrowdSim is composed of three layered components: the macro-level reflects the overall crowdsourcing platform based on system dynamics,the meso-level represents the task life cycle based on discrete event simulation, and the micro-level models the crowd workers' decision-making processes based on agent-based simulation. CrowdSim is evaluated through three CSD decision scenarios to demonstrate its effectiveness, using a real-world historical dataset and the results demonstrate CrowdSim's potential in empowering crowdsourcing managers to explore crowdsourcing outcomes with respect to different task scheduling options.", "num_citations": "3\n", "authors": ["171"]}
{"title": "Beyond accuracy: Roi-driven data analytics of empirical data\n", "abstract": " Background: The unprecedented access to data has rendered a remarkable opportunity to analyze, understand, and optimize the investigation approaches in almost all the areas of (Empirical) Software Engineering. However, data analytics is time and effort consuming, thus, expensive, and not automatically valuable.Objective: This vision paper demonstrates that it is crucial to consider Return-on-Investment (ROI) when performing Data Analytics. Decisions on\" How much analytics is needed\"? are hard to answer. ROI could guide for decision support on the What?, How?, and How Much? analytics for a given problem.Method: The proposed conceptual framework is validated through two empirical studies that focus on requirements dependencies extraction in the Mozilla Firefox project. The two case studies are (i) Evaluation of fine-tuned BERT against Naive Bayes and Random Forest machine learners for binary\u00a0\u2026", "num_citations": "3\n", "authors": ["171"]}
{"title": "A recommendation system for emergency mobile applications using context attributes: Remac\n", "abstract": " The extensive use of mobile devices had led to tremendous growth in not only the usage of different apps but also their capability to help people in moments of crisis. There are different emergency mobile apps published in the app markets; these apps can be of enormous assistance to victims as they can provide valuable information and guidance at the opportune moments. However, app store reviews, ratings, and relevant studies have revealed that users are often averse to using these apps or their different features. This draws our attention to the need for recognizing essential features and including them in the emergency apps to increase their usability. Our proposed recommendation system called REMAC combines different machine learning techniques to analyze the context characteristics of different organizations and suggest unique features that can be included in their emergency apps. REMAC is built by\u00a0\u2026", "num_citations": "3\n", "authors": ["171"]}
{"title": "A Visual Narrative Path from Switching to Resuming a Requirements Engineering Task\n", "abstract": " Requirements Engineering (RE) is closely tied to other development activities and is at the heart and foundation of every software development process. This makes RE the most data and communication intensive activity compared to other development tasks. The highly demanding communication makes task switching and interruptions inevitable in RE activities. While task switching often allows us to perform tasks effectively, it imposes a cognitive load and can be detrimental to the primary task, particularly in complex tasks as the ones typical for RE activities. Visualization mechanisms enhanced with analytical methods and interaction techniques help software developers obtain a better cognitive understanding of the complexity of RE decisions, leading to timelier and higher quality decisions. In this paper, we propose to apply interactive visual analytics techniques for managing requirements decisions from various\u00a0\u2026", "num_citations": "3\n", "authors": ["171"]}
{"title": "Sensitivity analysis for weak constraint generation\n", "abstract": " In this paper we consider multi-constraint planning problems with limited and incomplete knowledge. We assume an optimization algorithm and a situation where not all existing knowledge can be formulated as constraints. As a result, one wants to change the plan in a way that weak constraints are relaxed. This can be done by changing some input constraints and obtaining a new input to the optimizer. We present a method for estimating the impact of such changes. The methods for sensitivity analysis are simulation and clustering. The main application domain and area for experiments is strategic release planning. A prototype simulator tool, RPSim, was developed to illustrate the applicability of sensitivity analysis. As a proof-of-concept, a sample release planning project with thirty features and three stakeholders is used to illustrate the approach.", "num_citations": "3\n", "authors": ["171"]}
{"title": "Comparative Analysis of Three Techniques for Predictions in Time Series Having Repetitive Patterns.\n", "abstract": " Modelling nonlinear patterns is possible through using regression (curve fitting) methods. However, they can be modelled by linear regression (LR) methods, too. This kind of modelling is usually used to depict and study trends and it is not used for prediction purposes. Our goal is to study the applicability and accuracy of piecewise linear regression in predicting a target variable in different time spans (where a pattern is being repeated).Using moving average, we identified the split points and then tested our approach on a real world case study. The dataset of the amount of recycling material in Blue Carts in Calgary (including more than 31,000 records) was taken as a case study for evaluating the performance of the proposed approach. Root mean square error (RMSE) and Spearman rho were used to evaluate and prove the applicability of this prediction approach and evaluate its performance. A comparison between the performances of Support Vector Machine (SVM), Neural Networks (NN), and the proposed LR-based prediction approach is also presented. The results show that the proposed approach works very well for such prediction purposes. It outperforms SVM and is a powerful competitor for NN.", "num_citations": "3\n", "authors": ["171"]}
{"title": "Towards Design and Architectural Evaluation of Product Variants: A Case Study on an Open Source Software System.\n", "abstract": " Evolving a software system demands a careful balance between equally important but often conflicting views of customers and system architecture. This paper proposes a method to address evolution of a software system into a product line containing specialized product variants for specific markets while aligning the two views. The proposed method COPE+ iteratively explores the solutions space to generate product variants for the two views independently. It uses density based clustering to identify market segments. Impact of the proposed features on the existing product\u2019s architecture is heuristically determined. Behaviors of the promising variants are then compared with that of the existing system through extended mqsimulation on statechart representations. This determines the degree of similarity between existing system and proposed product variants. Finally, human experts evaluate the suggested products. COPE+ is applied to jEdit, a popular open source editor. Results indicate usefulness of the proposed method in bringing together the diversified views of customers and architecture.", "num_citations": "3\n", "authors": ["171"]}
{"title": "Identification of question types and answer types for an explanation component in software release planning\n", "abstract": " Acceptance of decision support offered by software systems is largely determined by the degree of acceptance and understanding of system results from the users. The generation of explanations helps the user of the software systems to better understand and utilize system outputs. Explanations can be generated and conveyed through dialogues. One way to achieve dialogues is to use question types and answer types. This paper presents an overview of the identification of question types and answer types for an explanation component called EXPLAIN-RP that provides decision support for software release planning.", "num_citations": "3\n", "authors": ["171"]}
{"title": "Finding the k bicriterial foremost edges in planar flow networks\n", "abstract": " 1. Introduction. The paper examines an optimization problem in a planar unoriented network, with two weights given on its edges: capacity and reliability. Upon a given natural number k it is required to find those k edges, the removal of which reduces the network to a new one of the minimum possible capacity and minimum reliability of the minimum cut. These k edges are called bicriterial foremost edges. The applications of this problem lie in that it is possible to know in advance what the consequences will be if some of the network elements cease to function (eg fault, switching-off, destruction, etc.). Similar problems dealing with the so-called vitality of the networks have been examined elsewhere 2, 5-8, 11].2. Formulation of the Problem. Let G (N, E) be a finite, connected, unoriented, planar graph without loops and with set of nodes N and set of edges E={(1,..., em}. s and I are two nodes called source and sink, respectively. Each edge e, is presented by the", "num_citations": "3\n", "authors": ["171"]}
{"title": "Optimization in Software Engineering: A pragmatic approach\n", "abstract": " Empirical software engineering is concerned with the design and analysis of empirical studies that include software products, processes, and resources. Optimization is a form of data analytics in support of human decision-making. Optimization methods are aimed to find best decision alternatives. Empirical studies serve both as a model and as data input for optimization. In addition, the complexity of the models used for optimization triggers further studies on explaining and validating the results in real-world scenarios. The goal of this chapter is to give an overview of the as-is and of the to-be usage of optimization in software engineering. The emphasis is on a pragmatic use of optimization, and not so much on describing the most recent algorithmic innovations and tool developments. The usage of optimization covers a wide range of questions from different types of software engineering problems along the whole\u00a0\u2026", "num_citations": "2\n", "authors": ["171"]}
{"title": "Zielorientiertes Messen und Bewerten zur Software-Qualit\u00e4tsverbesserung-Eine Kosten/Nutzen-Analyse\n", "abstract": " Empirische Untersuchungen erlauben es, die Wirksamkeit des Einsatzes neuer Technologien, Methoden und Werkzeuge im kommerziellen Umfeld abzusch\u00e4tzen. Im Mittelpunkt dieses Beitrags steht die Erl\u00e4uterung des Einsatzes und die Darstellung der experimentellen Evaluierung der Kosten/Nutzen-Relation des Goal/Question/Metric (GQM)-Ansatzes zur Beschreibung, Bewertung, Kontrolle sowie zur systematischen Verbesserung von Qualit\u00e4tszielen in der Software-Entwicklung. Dazu werden die Ergebnisse einer replizierten Fallstudie mit Software-Organisationen aus drei Unternehmen gezeigt, die im ESPRIT/ESSI-Projekt CEMP erarbeitet wurden.", "num_citations": "2\n", "authors": ["171"]}
{"title": "Predictions in Time Series with Repeated Patterns, Using Piecewise Linear Regression\n", "abstract": " Modelling nonlinear patterns is possible through using regression (curve fitting) methods. However, they can be modelled by linear regression (LR) methods, too. This kind of modelling is usually used to depict and study trends and it is not used for prediction purposes. Our goal is to study the applicability and accuracy of piecewise linear regression in predicting a target variable in different time spans (where a pattern is being repeated).Using Moving Average, we identified the split points and then tested our approach on a real world case study. The dataset of the amount of recycling material in Blue Carts in Calgary (including more than 31,000 records) was taken as a case study for evaluating the performance of the proposed approach. Root mean square error (RMSE) and Spearman rho were used to evaluate and prove the applicability of this prediction approach and evaluate its performance. A comparison between the performances of Support Vector Machine (SVM), Artificial Neural Networks (ANN), and the proposed LR-based prediction approach is also presented. The results show that the proposed approach works very well for such prediction purposes. It outperforms SVM and is a powerful competitor for ANN.", "num_citations": "2\n", "authors": ["171"]}
{"title": "How to Address Modifiability Concerns in the Process of Planning for the Next Release\u2013A Trade-off Method and its Initial Evaluation\n", "abstract": " Planning the next release in the context of software release planning addresses the problem of assigning features to the next release so that technical, resource, risk, and budget constraints are met. However, inevitable changes in stakeholders\u2019 needs might require modifications in already implemented features. Accommodating these changes is a non-trivial task as many features have dependencies with other features. Thus, this paper studies the planning for the next release of an evolving system. We introduce a method to adjust baseline release plans for more modifiability by systematically replacing lower value features with features having a higher degree of modifiability and which therefore are expected to increase the overall system modifiability. Our method includes a new approach for feature modeling and assessing the degree of modifiability of systems by applying object-oriented design metrics to the feature domain. As a proof-of-concept, a case study is conducted.", "num_citations": "2\n", "authors": ["171"]}
{"title": "Decision Support for Resource-centric Software Release Planning.\n", "abstract": " Release planning for incremental software development assigns features to releases such that most important technical, resource, risk and budget constraints are met. Most organizations perform release planning in an ad-hoc manner, ignoring proper consideration of resources. The result of this process is the consideration of plans that are likely to fail or at least have to be updated several times in the course of their realization. This paper addresses better integration of the resource management aspects into the decision-making process. For that purpose, it studies scenario-driven analysis of bottleneck resource situations in order to support the process of finding solutions accommodating possible future changes. A hypothetical case study is undertaken to illustrate the approach and to show the added value from a decision-making perspective.", "num_citations": "2\n", "authors": ["171"]}
{"title": "Art and science of system release planning\n", "abstract": " Informed and qualified decisions are key factors for project failure or success. The idea of decision support always arises when timely decisions must be made in unstructured or semi-structured problem domains, where multiple stakeholders are involved, and when the information available is uncertain. Release planning (RP) addresses decisions related to the selection and assignment of features to a sequence of consecutive product releases such that the most important technical, resource, budget, and risk constraints are met. Release planning is an important and integral part of any type of incremental product development. The objective of this tutorial is to describe and position the \u2018art and science\u2019 of software release planning. The \u201cart of release planning\u201d refers to relying on human intuition, communication, and capabilities to negotiate between conflicting objectives and constraints. The \u201cscience of\u00a0\u2026", "num_citations": "2\n", "authors": ["171"]}
{"title": "Experience Package from the ESSI Process Improvement Experiment HYPER\n", "abstract": " The development of high quality software satisfying cost, schedule, and resource requirements is an essential prerequisite for improved competitiveness of life insurance companies. One major difficulty to master this challenge is the inevitability of defects in software products. Since defects are known to be significantly more expensive if detected in later development phases or testing, companies in this marketplace must use cost-effective technologies to detect defects early on in the development process. A particular promising one is software inspection. This report describes the results of the ESPRIT/ESSI Process Improvement Experiment\" High Quality of Software Products by Early Use of Innovative Reading Techniques (HYPER)\". The core of this project has been the transfer of innovative software inspection technologies to the Allianz EURO conversion projects. The innovation in the area of software inspection\u00a0\u2026", "num_citations": "2\n", "authors": ["171"]}
{"title": "Das Fraunhofer Institut f\u00fcr Experimentelles Software Engineering\n", "abstract": " Die Herstellung von Software ist ein nicht wiederholbarer und wesentlich von Menschen getragener Entwicklungsproze\u00df. Es gibt keine universelle Standard-Technologie, die in allen Situationen anwendbar ist. Vielmehr mu\u00df davon ausgegangen werden, da\u00df aus dem Potential verf\u00fcgbarer Technologien sorgf\u00e4ltig ausgew\u00e4hlt und dabei jeweils eine Anpassung an die Umgebungscharakteristika erfolgen mu\u00df. Der vom Fh IESE praktizierte experimentelle Ansatz hat das Ziel, auf der Basis von gezielten Experimenten die St\u00e4rken und Schw\u00e4chen der jeweiligen Technologien auf der Basis von quantitativen und qualitativen Analysen herauszufinden und zu beschreiben. Auf diesem Wege werden Technologie-Pakete aufgebaut, in denen inkrementell das empirisch gewonnene Wissen und die Erfahrung zur Wiederverwendung in nachfolgenden Projekten bereitgestellt wird. Im Detail verl\u00e4uft der Proze\u00df des\u00a0\u2026", "num_citations": "2\n", "authors": ["171"]}
{"title": "Systematic improvement of software engineering processes\n", "abstract": " Systematic improvement of software engineering processes needs to be based on empirical investigation and organisational learning. Explicit description and focused management of information and experience are crucial for the success of software projects and improvement programmes. Appropriate methods and procedures are needed as well as a suitable organisational and technical infrastructure.             This paper presents the PERFECT Improvement Approach (PIA) that was developed in ESPRIT project PERFECT. It builds on the Quality Improvement Paradigm (QIP)/Experience Factory (EF) approach that represents an adoption of Total Quality Management to the software engineering discipline.             The elements of PIA are introduced. Focus is put on its methodological aspects. The role of information and experience in systematic improvement programmes is described. It is illustrated using an\u00a0\u2026", "num_citations": "2\n", "authors": ["171"]}
{"title": "Analyse von GQM-Pl\u00e4nen auf Grundlage von Rough Sets\n", "abstract": " Mit dieser Arbeit endet ein weiterer Lebensabschnitt f\u00fcr mich. Deshalb m\u00f6chte ich die Gelegenheit nutzen mich bei einigen Personen zu bedanken, durch die diese Arbeit erst m\u00f6glich wurde oder die zum Entstehen der Arbeit beigetragen haben.", "num_citations": "2\n", "authors": ["171"]}
{"title": "Decision Support System for Cost-benefit Analysis in Service Provision.\n", "abstract": " Cost-benefit analysis is an approach to relate effort and cost of an activity to the resulting benefit. In this paper a novel decision support system for cost-benefit analysis in the context of service provision is proposed. Four decision support scenarios are investigated:(i) analyzing the impact of the services on cost and benefit,(ii) sensitivity analysis for the system variables,(iii) goal-seek analysis, and (iv) analyzing the impact of the services on operational resources. The key engine of the analysis approach is a Bayesian Belief Network (BBN). The BBN incorporates the key incoming, control and outgoing service parameters as well as their probabilistic relationships. In the sense of a hierarchical system, the variation of some of the parameters is guided by the results of optimizing operational resources being some of the BBN parameters. We\u2019ve evaluated the framework in a case study with the City of Calgary\u2019s Waste and Recycling Services. The results showed that using such a DSS facilitates the decision making process and improves the overall cost-benefit ratio.", "num_citations": "1\n", "authors": ["171"]}
{"title": "A Hybrid Method for Scenario-based Effort Re-allocation in Software Projects\n", "abstract": " A HYBRID METHOD FOR SCENARIO-BASED EFFORT RE-ALLOCATION IN SOFTWARE PROJECTS Emadoddin Livani1 , \u0141ukasz Radli\u0144ski2 , Elham Paikari1 , G\u00fcnther Ruhe1,3 1 Department of Electrical and Computer Engineering, University of Calgary, Canada 2 Institute of Information Technology in Management, University of Szczecin, Poland 3 Department of Computer Science, University of Calgary, Canada elivani@ucalgary.ca, lukrad@uoo.univ.szczecin.pl, epaikari@ucalgary.ca, ruhe@ucalgary.ca ABSTRACT Effort re-allocation among software development stages potentially leads to changes in the scope and quality of delivered software and in total effort. The goal of this paper is to develop a framework for prioritizing effort re- allocation scenarios against a set of criteria according to one\u2019s preferences. This framework is a hybrid of Bayesian network (BN), which reflects a development process, and Process \u2026", "num_citations": "1\n", "authors": ["171"]}
{"title": "Software Release Planning Incorporating Technological Change\u2013The Case of Considering Software Inspections\n", "abstract": " Release planning is a cognitively and computationally complex task. It assigns features to different releases considering technological, business objectives and constraints. Current planning techniques ignore the impact of technological changes. However, these changes are more the rule than the exception.Our proposed approach considers the impact of technological change. Our model measures this impact in the revised effort needed to perform development activities. While scope of technological change might potentially be very broad, we focused on introducing software inspections, a technique empirically proven to increase software development effectiveness. In this paper,(i) a theoretical method of quantitatively incorporating technology change impact into existing release planning model is discussed.;(ii) a solution method using EVOVLE II is proposed; and (iii) results of an illustrative case study using an\u00a0\u2026", "num_citations": "1\n", "authors": ["171"]}
{"title": "Empirical Evaluation of the Impact of Assignment of Developers to Tasks in Iterative Development\n", "abstract": " A software development team consists of developers with varying expertise and levels of productivity. With reported productivity variation of up to 1: 20, the quality of assignment of developers to tasks is assumed to have strong impact on project performance.In this paper, four empirical research questions related to the assignment of developers to tasks in iterative development are studied. As part of that, baseline ad hoc assignment is compared with two optimized strategies applying genetic algorithms and greedy optimization. Estimation of (relative) productivity of developers is done by applying the Analytical Hierarchy Process AHP.", "num_citations": "1\n", "authors": ["171"]}
{"title": "Evaluating the Modifiability of Software Architectural Designs\n", "abstract": " In this chapter, we propose an architectural design evaluation technique called EBEAM (Expert\u2010Based Evaluation of Architecture for Modifiability) that assists experts in articulating their knowledge of architectural designs and expressing the knowledge in measurable terms. EBEAM supports the evaluation of different architectural design versions for modifiability. In addition, EBEAM supports relative comparison between these design versions and the target design. We develop EBEAM as a generalized technique that is reusable for evaluating other architectural design attributes, apart from modifiability. We discuss EBEAM in detail and report on two case studies that investigate its applicability, and one study that validates the results of the evaluations made using EBEAM.", "num_citations": "1\n", "authors": ["171"]}
{"title": "Decision Support for Software Release Planning-Methods, Tools, and Practical Experience\n", "abstract": " Decision Support for Software Release Planning - Methods, Tools, and Practical Experience Page 1 N tG ti I t t 1 1 NASA SEW-29 Decision Support for Software Release Planning Methods, Tools, and Practical Experience Guenther Ruhe Omolade Saliu Pankaj Bhawnani Joseph Momoh An Ngo-The University of Calgary Laboratory for Software Engineering Decision Support 2 NASA SEW-29 A. Methodology Software engineering decision support paradigm Release planning solution approaches Art & science of release planning EVOLVE* Strategic versus operational planning B. Tool & Case Study Tool Overview - ReleasePlannerTM Case study problem conceptualization & formulation Modeling & exploration Scenario-playing (consolidation) C. Impact Analysis D. Summary & Outlook Extension of applicability Future research Table of Content Page 2 N tG ti I t t 2 3 NASA SEW-29 Laboratory for Software Decision of (\u2026", "num_citations": "1\n", "authors": ["171"]}
{"title": "Introduction and Motivation\n", "abstract": " Introduction and Motivation | Proceedings of the 11th International Conference on Software Engineering and Knowledge Engineering, Learning Software Organizations, Methodology and Applications ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleProceedingsSEKE '99Introduction and Motivation ARTICLE Introduction and Motivation Share on Authors: Guenther H Ruhe profile image G\u00fcnther Ruhe View Profile , Frank Bomarius profile image Frank Bomarius View Profile Authors Info & Affiliations Publication: SEKE '99: Proceedings of the 11th International Conference on Software Engineering and Knowledge Engineering, Learning , 1'\u2026", "num_citations": "1\n", "authors": ["171"]}
{"title": "Goal-oriented learning in experimental software engineering by using rough sets\n", "abstract": " Rough set theory is a foundation for a series of analysis methods which has been successfully applied in many real-life problems of various areas. Main focus of the approach is to explain experimental data by establishing cause-e ect relationships. We have applied the approach in the context of experimental software engineering to support analysis and interpretation of measurement data within interactive feedback sessions. Measurement was performed following the Goal/Question/Metric-approach. As a case study, we report experiences from a project at Allianz Lebensversicherungs-AG devoted to better understanding of and subsequent improvement of exibility in software development. Experiences are reported from both application and methodological point of view.", "num_citations": "1\n", "authors": ["171"]}
{"title": "Solution of Network Flow Problems with Additional Constraints\n", "abstract": " The achieved success in solving pure or generalized network flow problems has caused the question to investigate more general linear programs with embedded network structure. The objective is to transform as much as possible of the efficiency of the basic flow routines to the solution algorithm for the more general case. Due to Glover & Klingman (1981), most large-scale LP-problems involving production scheduling, physical distribution, facility location, or personal assignment contain a large embedded network component, sometimes consisting of several smaller embedded networks. The general linear constraints arise, for example, from economies of scale, capacity restrictions on modes of transportation, limitations on shared resources, or from combining the outputs of subdivisions to meet overall demands.", "num_citations": "1\n", "authors": ["171"]}
{"title": "Solution of a class of interval scheduling problems using network flows\n", "abstract": " We consider a generalization of the Fixed Job Scheduling Problem, where jobs with fixed start and finish time and from different job classes must be assigned in a non-preemptive way to a given set of machines from different machine classes. For each machine class a set of job classes is given which specifies the jobs that may be processed by the machines in the machine class.             The problem is to find a subset of the jobs of maximum total value that can be assigned to the given set of machines. This problem is known to be NP-Hard as soon as there are at least 2 non-trivial machine classes. We give a formulation of this problem using network flows which allows good algorithmic treatment. More specific, we present a solution method based on surrogate constraints and parametric flows for a minimum cost flow problem with simple additional constraints and integrality demand. The method is illustrated\u00a0\u2026", "num_citations": "1\n", "authors": ["171"]}
{"title": "Shifting to Goal-Oriented Measurement in Industrial Environments. Experiences of Schlumberger\n", "abstract": " You have located a publication of the Fraunhofer Gesellschaft. To conduct a more concise search, please access the Fraunhofer-Publica, a bibliographic database of Fraunhofer publications dating from 1980 to present, or the Fraunhofer-ePrints which contains electronic fulltext documents of the Fraunhofer Gesellschaft.", "num_citations": "1\n", "authors": ["171"]}
{"title": "A Dialogue Approach for Solving Wicked Planning Problems\n", "abstract": " Although wicked problems don\u2019t have a precise definition, they have several characteristics [Rittel, Webber 1984]:", "num_citations": "1\n", "authors": ["171"]}