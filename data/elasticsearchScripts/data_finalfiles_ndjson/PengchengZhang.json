{"title": "Interpretable spatio-temporal attention LSTM model for flood forecasting\n", "abstract": " Modeling interpretable artificial intelligence (AI) for flood forecasting represents a serious challenge: both accuracy and interpretability are indispensable. Because of the uncertainty and nonlinearity of flood, existing hydrological solutions always achieve low prediction robustness while machine learning (ML) approaches neglect the physical interpretability of models. In this paper, we focus on the need for flood forecasting and propose an interpretable Spatio-Temporal Attention Long Short Term Memory model (STA-LSTM) based on LSTM and attention mechanism. We use dynamic attention mechanism and LSTM to build model, Max-Min method to normalize data, variable control method to select hyperparameters, and Adam algorithm to train the model. Emphasis is placed on the visualization and interpretation of attention weights. Experiment results on three small and medium basins in China suggest that the\u00a0\u2026", "num_citations": "44\n", "authors": ["1657"]}
{"title": "Efficient alignment between event logs and process models\n", "abstract": " The aligning of event logs with process models is of great significance for process mining to enable conformance checking, process enhancement, performance analysis, and trace repairing. Since process models are increasingly complex and event logs may deviate from process models by exhibiting redundant, missing, and dislocated events, it is challenging to determine the optimal alignment for each event sequence in the log, as this problem is NP-hard. Existing approaches utilize the cost-based A* algorithm to address this problem. However, scalability is often not considered, which is especially important when dealing with industrial-sized problems. In this paper, by taking advantage of the structural and behavioral features of process models, we present an efficient approach which leverages effective heuristics and trace replaying to significantly reduce the overall search space for seeking the optimal\u00a0\u2026", "num_citations": "34\n", "authors": ["1657"]}
{"title": "Short-term rainfall forecasting using multi-layer perceptron\n", "abstract": " Rainfall forecasting is crucial in the field of meteorology and hydrology. However, existing solutions always achieve low prediction accuracy for short-term rainfall forecasting. Atmospheric forecasting models perform worse in many conditions. Machine learning approaches neglect the influences of physical factors in upstream or downstream regions, which make forecasting accuracy fluctuate in different areas. To improve the overall forecasting accuracy for short-term rainfall, this paper proposes a novel solution called Dynamic Regional Combined short-term rainfall Forecasting approach (DRCF) using Multi-layer Perceptron (MLP). First, Principal Component Analysis (PCA) is used to reduce the dimension of thirteen physical factors, which serves as the input of MLP. Second, a greedy algorithm is applied to determine the structure of MLP. The surrounding sites are perceived based on the forecasting site. Finally, to\u00a0\u2026", "num_citations": "27\n", "authors": ["1657"]}
{"title": "RBF-MLMR: A multi-label metamorphic relation prediction approach using RBF neural network\n", "abstract": " Metamorphic testing has been successfully used in many different fields to solve the test oracle problem. However, how to find a set of appropriate metamorphic relations for metamorphic testing remains a complicated and tedious task. Recently some machine learning approaches have been proposed to predict metamorphic relations. These approaches predicting single label metamorphic relation can alleviate this problem to some extent. However, many applications involve multi-group metamorphic relations, and these approaches are clearly inefficient. To address this problem, in this paper we propose a Multi-Label Metamorphic Relations prediction approach based on an improved radial basis function (RBF) neural network named RBF-MLMR. First, RBF-MLMR uses state-of-the-art soot analysis tool to generate control flow graph and corresponds labels from the source codes of programs. Second, the\u00a0\u2026", "num_citations": "26\n", "authors": ["1657"]}
{"title": "A deep-learning based precipitation forecasting approach using multiple environmental factors\n", "abstract": " Precise precipitation forecasting can better reflect the changing trend of climate and also provide timely and efficient environmental information for management decision, as well as prevent the occurrence of floods or droughts. In the era of big data, this paper proposes a novel approach for precipitation forecasting based on deep belief nets, called DBNPF (Deep Belief Network for Precipitation Forecast). Through simulating neural connecting structure of human brain, Gaussian kernel function for data conversion, and back-propagation network for fine-tuning the entire network, the features of the data in the original space are mapped into the new feature space with semantic feature through the dimensionality reduction. The proposed approach can not only learn the hierarchical representation of raw data using a highly generalized way, fully mining the information hidden in the original data, but also make a more\u00a0\u2026", "num_citations": "19\n", "authors": ["1657"]}
{"title": "Urban street cleanliness assessment using mobile edge computing and deep learning\n", "abstract": " During the process of smart city construction, city managers always spend a lot of energy and money for cleaning street garbage due to the random appearances of street garbage. Consequently, visual street cleanliness assessment is particularly important. However, the existing assessment approaches have some clear disadvantages, such as the collection of street garbage information is not automated and street cleanliness information is not real-time. To address these disadvantages, this paper proposes a novel urban street cleanliness assessment approach using mobile edge computing and deep learning. First, the high-resolution cameras installed on vehicles collect the street images. Mobile edge servers are used to store and extract street image information temporarily. Second, these processed street data is transmitted to the cloud data center for analysis through city networks. At the same time, Faster\u00a0\u2026", "num_citations": "17\n", "authors": ["1657"]}
{"title": "IgS-wBSRM: A time-aware Web Service QoS monitoring approach in dynamic environments\n", "abstract": " ContextQuality of Service(QoS) is an important criterion to measure the quality of third-party web services. However, it is always affected by different environmental factors. Consequently, how to monitor web service QoS timely and accurately in dynamic environments is an important problem.ObjectiveOur article aims to design a novel Web service QoS monitoring approach which can be used in dynamic environments.MethodTo achieve the above objective, we propose a novel weighted na\u00efve Bayesian runtime monitoring approach based on information gain theory and sliding window mechanism, called IgS-wBSRM. IgS-wBSRM initializes the weights of different environmental factors according to training samples collected. Then, according to information entropy and information gain theory, IgS-wBSRM reads the sample data flow in sequence, and calculates the information gain of each environmental impact factor\u00a0\u2026", "num_citations": "17\n", "authors": ["1657"]}
{"title": "A survey on quality assurance techniques for big data applications\n", "abstract": " With the rapid advance of big data and cloud computing, building high quality big data systems in different application fields has gradually became a popular research topic in academia and industry as well as government agencies. However, more quality problems lead to application errors. Although the current research work has discussed how to ensure the quality of big data applications from several aspects, there is no systematic discussion on how to ensure the quality of large data applications. Therefore, a systematic study on big data application quality assurance is very necessary and critical. This paper focuses on the survey of quality assurance techniques of big data applications, and it introduces big data properties and quality attributes. It mainly discusses the key approaches to ensure the quality of big data applications and they are testing, model-driven architecture (MDA), monitoring, fault tolerance\u00a0\u2026", "num_citations": "17\n", "authors": ["1657"]}
{"title": "Heuristic recovery of missing events in process logs\n", "abstract": " Event logs are of paramount significance for process mining and complex event processing. Yet, the quality of event logs remains a serious problem. Missing events of logs are usually caused by omitting manual recording, system failures, and hybrid storage of executions of different processes. It has been proved that the problem of minimum recovery based on a priori process specification is NP-hard. State-of-the-art approach is still lacking in efficiency because of the large search space. To address this issue, in this paper, we leverage the technique of process decomposition and present heuristics to efficiently prune the unqualified sub-processes that fail to generate the minimum recovery. We employ real-world processes and their incomplete sequences to evaluate our heuristic approach. The experimental results demonstrate that our approach achieves high accuracy as the state-of-the-art approach does, but it\u00a0\u2026", "num_citations": "14\n", "authors": ["1657"]}
{"title": "A novel QoS prediction approach for cloud service based on bayesian networks model\n", "abstract": " Considered as the next generation computing model, cloud computing plays an important role in scientific and commercial computing and draws wide attention from both academia and industry. In the dynamic, complex and changeable cloud computing environment, Quality Of Service (QoS) is an important basis for the selection of different cloud services. Therefore, the prediction of cloud services QoS can help users to choose the most suitable service at hand. The software and hardware and resources of three-layer structure for cloud computing will impact on cloud services QoS, but existing QoS prediction approaches are not consider the three-layer structure on the influence of thecloud service QoS. The CPU usage, physical memory usage andthe number of processes of infrastructure layer have definitely influenced QoS. In order to address this limitation, in the paper, a Bayesian network model of QoS\u00a0\u2026", "num_citations": "13\n", "authors": ["1657"]}
{"title": "Hydrological big data prediction based on similarity search and improved BP neural network\n", "abstract": " Large amount of hydrological data set is a kind of big data, which has much hidden and potentially useful knowledge. Hydrological prediction is important for the state flood control and drought relief. How to forecast accurately and timely with hydrological big data becomes a big challenge. There are some forecasting techniques used widely. However, they are limited by their adaptability, the data volume and the data feature. The most important problems are the high time consumption, low accuracy and bad adaptability of prediction. In this paper, a new forecasting approach based on an integration of two tasks of data mining is put forward. This approach which is called S LMDBP combines similarity search and Levenberg-Marquardt(LM) algorithm improved Double-hidden layer Back Propagation(BP) neural network. A specialized data pretreatment including three parts is applied to process the hydrological data\u00a0\u2026", "num_citations": "13\n", "authors": ["1657"]}
{"title": "Multivariate time series similarity searching\n", "abstract": " Multivariate time series (MTS) datasets are very common in various financial, multimedia, and hydrological fields. In this paper, a dimension-combination method is proposed to search similar sequences for MTS. Firstly, the similarity of single-dimension series is calculated; then the overall similarity of the MTS is obtained by synthesizing each of the single-dimension similarity based on weighted BORDA voting method. The dimension-combination method could use the existing similarity searching method. Several experiments, which used the classification accuracy as a measure, were performed on six datasets from the UCI KDD Archive to validate the method. The results show the advantage of the approach compared to the traditional similarity measures, such as Euclidean distance (ED), cynamic time warping (DTW), point distribution (PD), PCA similarity factor                           , and extended Frobenius norm (Eros), for MTS datasets in some ways. Our experiments also demonstrate that no measure can fit all datasets, and the proposed measure is a choice for similarity searches.", "num_citations": "13\n", "authors": ["1657"]}
{"title": "Bayesian probabilistic monitor: A new and efficient probabilistic monitoring approach based on bayesian statistics\n", "abstract": " Modern software systems deal with increasing dependability requirements which specify non-functional aspect of a system correct operation. Usually, probabilistic properties are used to formulate dependability requirements like performance, reliability, safety, and availability. Probabilistic monitoring techniques, as an important assurance measure, has drawn more and more interest. Despite currently several approaches has been proposed to monitor probabilistic properties, it still lacks of a general and efficient monitoring approach for monitoring probabilistic properties. This paper puts forward a novel probabilistic monitoring approach based on Bayesian statistics, called Bayesian Probabilistic Monitor (BaProMon). By calculating Bayesian Factor, the approach can check whether the runtime information can provide sufficient evidences to support the null or alternative hypothesis. We give the corresponding\u00a0\u2026", "num_citations": "13\n", "authors": ["1657"]}
{"title": "Model based verification of dynamically evolvable service oriented systems\n", "abstract": " Dynamic evolution is highly desirable for service oriented systems in open environments. For the evolution to be trusted, it is crucial to keep the process consistent with the specification. In this paper, we study two kinds of evolution scenarios and propose a novel verification approach based on hierarchical timed automata to model check the underlying consistency with the specification. It examines the procedures before, during and after the evolution process, respectively and can support the direct modeling of temporal aspects, as well as the hierarchical decomposition of software structures. Probabilities are introduced to model the uncertainty characterized in open environments and thus can support the verification of parameter-level evolution. We present a flattening algorithm to facilitate automated verification using the mainstream timed automata based model checker\u2013UPPAAL (integrated with\u00a0\u2026", "num_citations": "12\n", "authors": ["1657"]}
{"title": "A novel QoS monitoring approach sensitive to environmental factors\n", "abstract": " The quality of service-oriented system relies heavily on the third-party service. Such reliance would result in many uncertainties, in consideration of the complex and changeable network environment. Hence, effective runtime monitoring technique is required by service-oriented system. Several monitoring approaches have been proposed. However, all of these approaches do not consider the influences of environmental factors such as the position of server and users, and the load at runtime. Ignoring these influences, which exist among monitoring process, may cause wrong monitoring results. In order to solve this problem, this paper proposes a novel QoS monitoring approach sensitive to environmental factors called wBSRM (weighted Bayesian Runtime Monitoring) based on weighted naive Bayesian and TF-IDF (Term Frequency-Inverse Document Frequency). The proposed approach measures influence of\u00a0\u2026", "num_citations": "11\n", "authors": ["1657"]}
{"title": "A novel QoS prediction approach for cloud services using Bayesian network model\n", "abstract": " Cloud computing is the next generation computing model, which has a significant position in the field of scientific and business computing. By predicting cloud service's QoS in next period, it is helpful for end users to choose the most suitable cloud service that meets their needs. The underlying hardware/software resources of cloud architecture may have a certain influence on cloud service QoS. However, existing cloud service QoS prediction approaches do not take this influence into account. As these effects are real during the process of cloud service QoS prediction, ignoring the impact of these effects may create a big gap between the prediction results and the actual results. Therefore, in this paper interactive information is first used to describe the correlation between the hardware/software resources and the QoS attributes of the cloud service. Then, a Bayesian network model is established to predict cloud QoS\u00a0\u2026", "num_citations": "10\n", "authors": ["1657"]}
{"title": "A web service qos forecasting approach based on multivariate time series\n", "abstract": " In order to accurately forecast Quality of Service (QoS) of different Web Services, this paper proposes a novel QoS forecasting approach called MulA-LMRBF (Multi-step fore-casting with Advertisement and Levenberg-Marquardt improved Radial Basis Function) based on multivariate time series. Considering the correlation among different QoS attributes, we use phase-space reconstruction to map historical multivariate QoS data into a dynamic system, use Average Dimension (AD) to estimate the embedding dimension and delay time of reconstructed phase space. We also add the short-term QoS advertisement data of service provider to form a more comprehensive data set. Then, RBF (Radial Basis Function) neural network improved by the Levenberg-Marquardt (LM) algorithm is used to update the weight of the neural network dynamically, which improves the forecasting accuracy and realizes the dynamic\u00a0\u2026", "num_citations": "10\n", "authors": ["1657"]}
{"title": "A framework for self-healing service compositions in cloud computing environments\n", "abstract": " Cloud computing is an emerging computing paradigm that users can request on-demand computing services through networks and cloud computing platforms anytime and anywhere. Some distinguishing characteristics of cloud computing are elasticity, scalability, hardware virtualization, fast service configuration, etc. In cloud computing environments, three kinds of services can be provided, including Infrastructure as a Service (IaaS), Platform as a Service (PaaS) and Software as a Service (SaaS). These cloud services can be composed into a value-added service to satisfy the dynamic needs of Internet users. This paper proposes a self-healing framework for service composition in cloud environments.", "num_citations": "10\n", "authors": ["1657"]}
{"title": "Data quality in big data processing: Issues, solutions and open problems\n", "abstract": " With the rapid development of social networks, Internet of things, Cloud computing as well as other technologies, big data age is arriving. The increasing number of data has brought great value to the public and enterprises. Meanwhile how to manage and use big data better has become the focus of all walks of life. The 4V characteristics of big data have brought a lot of issues to the big data processing. The key to big data processing is to solve data quality issue, and to ensure data quality is a prerequisite for the successful application of big data technique. In this paper, we use recommendation systems and prediction systems as typical big data applications, and try to find out the data quality issues during data collection, data preprocessing, data storage and data analysis stages of big data processing. According to the elaboration and analysis of the proposed issues, the corresponding solutions are also put\u00a0\u2026", "num_citations": "9\n", "authors": ["1657"]}
{"title": "A framework and dataset for bugs in ethereum smart contracts\n", "abstract": " Ethereum is the largest blockchain platform that supports smart contracts. Users deploy smart contracts by publishing the smart contract\u2019s bytecode to the blockchain. Since the data in the blockchain cannot be modified, even if these contracts contain bugs, it is not possible to patch deployed smart contracts with code updates. Moreover, there is currently neither a comprehensive classification framework for Ethereum smart contract bugs, nor detailed criteria for detecting bugs in smart contracts, making it difficult for developers to fully understand the negative effects of bugs and design new approaches to detect bugs. In this paper, to fill the gap, we first collect as many smart contract bugs as possible from multiple sources and divide these bugs into 9 categories by extending the IEEE Standard Classification for Software Anomalies. Then, we design the criteria for detecting each kind of bugs, and construct a dataset of\u00a0\u2026", "num_citations": "8\n", "authors": ["1657"]}
{"title": "SolidityCheck: Quickly detecting smart contract problems through regular expressions\n", "abstract": " As a blockchain platform that has developed vigorously in recent years, Ethereum is different from Bitcoin in that it introduces smart contracts into blockchain.Solidity is one of the most mature and widely used smart contract programming language,which is used to write smart contracts and deploy them on blockchain. However, once the data in the blockchain is written, it cannot be modified. Ethereum smart contract is stored in the block chain, which makes the smart contract can no longer repair the code problems such as re-entrancy vulnerabilities or integer overflow problems. Currently, there still lacks of an efficient and effective approach for detecting these problems in Solidity. In this paper, we first classify all the possible problems in Solidity, then propose a smart contract problem detection approach for Solidity, namely SolidityCheck. The approach uses regular expressions to define the characteristics of problematic statements and uses regular matching and program instrumentation to prevent or detect problems. Finally, a large number of experiments is performed to show that SolidityCheck is superior to existing approaches.", "num_citations": "8\n", "authors": ["1657"]}
{"title": "LA-LMRBF: online and long-term web service QoS forecasting\n", "abstract": " We propose a Long-term Quality of Service (QoS) forecasting approach using Advertisement and Levenberg-Marquardt improved Radial Basis Function (LA-LMRBF) \u2013 a novel online QoS forecasting approach. LA-LMRBF aims to accurately predict QoS attributes of Web services in the form of multivariate time series via three stages. First, the phase space reconstruction theory is employed to restore multi-dimensional and nonlinear relations among the multivariate QoS attributes. Second, short-term QoS advertisement data is incorporated to enable long-term QoS forecasting. Finally, an optimized Radial Basis Function (RBF) neural network is constructed to forecast long-term multivariate QoS values, where the Affinity Propagation clustering algorithm is used to determine the number of hidden nodes and the Levenberg-Marquardt (LM) algorithm is utilized to dynamically update some parameters of the RBF neural\u00a0\u2026", "num_citations": "8\n", "authors": ["1657"]}
{"title": "Web services property sequence chart monitor: a tool chain for monitoring BPEL-based web service composition with scenario-based specifications\n", "abstract": " Web service composition is a new paradigm to develop distributed and reactive software-intensive systems. Owing to the autonomous nature of basic services, the validation of composite service must be extended from design-time to run-time. Here, the authors describe a novel tool chain called web services property sequence chart monitor to monitor temporal, timing and probabilistic properties in composite service based on scenario-based property specifications called property sequence chart, timed property sequence chart and probabilistic timed property sequence chart, respectively. The tool chain provides a completely graphical front-end that eliminates the need to deal with any particular textual and logical formalism. Furthermore, the framework and implementation detail of the tool chain are also presented. Finally, the feasibility and usability of the tool have been validated by the case studies and\u00a0\u2026", "num_citations": "8\n", "authors": ["1657"]}
{"title": "Adf-ga: Data flow criterion based test case generation for ethereum smart contracts\n", "abstract": " Testing is an important technique to improve the quality of Ethereum smart contract programs. However, current work on testing smart contract only focus on static problems of smart contract programs. A data flow oriented test case generation approach for dynamic testing of smart contract programs is still missing. To address this problem, this paper proposes a novel test case generation approach, called ADF-GA (All-uses Data Flow criterion based test case generation using Genetic Algorithm), for Solidity based Ethereum smart contract programs. ADF-GA aims to efficiently generate a valid set of test cases via three stages. First, the corresponding program control flow graph is constructed from the source codes. Second, the generated control flow graph is analyzed to obtain the variable information in the Solidity programs, locate the require statements, and also get the definition-use pairs to be tested. Finally, a\u00a0\u2026", "num_citations": "7\n", "authors": ["1657"]}
{"title": "A novel approach for QoS prediction based on Bayesian combinational model\n", "abstract": " As an important factor in evaluating service, QoS (Quality of Service) has drawn more and more concerns with the rapid increasing of Web services. However, due to the great volatility of services in Mobile Internet environments, such as internet of vehicles, Web services often do not work as announced and thus cause unacceptable problems. QoS prediction can avoid failure before it takes place, which is considered a more effective way to assure quality. However, Current QoS prediction approaches neither consider the highly dynamic of Web services, nor maintain good prediction performance all the time. Consequently we propose a novel Bayesian combinational model to predict QoS by continuously adjusting credit values of the basic models so as to keep good prediction accuracy. QoS attributes such as response time, throughput and reliability are used to validate the proposed model. Experimental results\u00a0\u2026", "num_citations": "7\n", "authors": ["1657"]}
{"title": "A combinational QoS-prediction approach based on RBF neural network\n", "abstract": " Quality of Service (QoS) is considered as an important factor to determine the success of a Web Service. Currently, many QoS prediction approaches focus on time series models. However, these approaches only consider linear and nonlinear time series. Analysis of real QoS datasets shows that they are characterized by other behaviors. Incomplete characteristics analysis of existing prediction approaches will result in wrong prediction results. Furthermore, the collected QoS values may miss some data, which will also impact the prediction accuracy. RBF (Radial Basis Function) neural network model can manage the complex linear and nonlinear relationship, with great flexibility and adaptability. Therefore, we propose a novel combinational prediction approach for QoS based on RBF, which chooses the optimal model from the established linear or nonlinear prediction model, and dynamic gray prediction model\u00a0\u2026", "num_citations": "6\n", "authors": ["1657"]}
{"title": "Hydrological Time Series Anomaly Mining based on Symbolization and Distance Measure\n", "abstract": " Large amount of hydrological data set is a kind of big data, which has much hidden and potentially useful knowledge. It is necessary to extract these knowledge from hydrological data set, which can provide more valuable hydrological information and be useful for future hydrological forecasting. Data mining based on time series is widely used currently. There are some techniques based on time series to extract anomaly. However, most of these techniques cannot suit big unstable data such as hydrological big data set. Some important problems are high fitting error after dimension reduction and low accuracy of mining results. In this work we propose a new idea to solve the problem of hydrological anomaly mining based on time series. The idea combines time series symbolization with distance measure. It proposes Feature Points Symbolic Aggregate Approximation (FP SAX) to improve the selection of feature\u00a0\u2026", "num_citations": "6\n", "authors": ["1657"]}
{"title": "Predicting failures in dynamic composite services with proactive monitoring technique\n", "abstract": " Web service composition is a new paradigm to develop distributed and reactive software-intensive systems. Predicting and preventing failures of dynamic composite services is an important and challenge problem due to the dynamically evolving attribute. In previous work, we propose CASSANDRA, a novel proactive monitoring technique with the ability to predict and prevent the potential failures happening in dynamic evolvable system. In this paper, we concretize the approach into web service composition field. By combining runtime information and design-time specification of basic services, the approach can analyse future -step models ahead of the current service execution states. Then, this model can be used to check with a set of desired properties represented by property sequence chart. Initial experiments on an online medicine case study validates our approach and shows encouraging results.", "num_citations": "5\n", "authors": ["1657"]}
{"title": "Surface and high-altitude combined rainfall forecasting using convolutional neural network\n", "abstract": " Rainfall forecasting can guide human production and life. However, the existing methods usually have a poor prediction accuracy in short-term rainfall forecasting. Machine learning methods ignore the influence of the geographical characteristics of the rainfall area. The regional characteristics of surface and high-altitude make the prediction accuracy always fluctuate in different regions. To improve the prediction accuracy of short-term rainfall forecasting, a surface and high-Altitude Combined Rainfall Forecasting model (ACRF) is proposed. First, the weighted k-means clustering method is used to select the meteorological data of the surrounding stations related to the target station. Second, the high-altitude shear value of the target station is calculated by using the meteorological factors of the surrounding stations. Third, the principal component analysis method is used to reduce dimensions of the high-altitude\u00a0\u2026", "num_citations": "4\n", "authors": ["1657"]}
{"title": "Smartclean: Smart city street cleanliness system using multi-level assessment model\n", "abstract": " Advancements in mobile, cloud computing and other techniques have made the world even smaller and connected like never before. It has become a challenge and an opportunity for cities to leverage these growing technologies to solve real city administration problems. Cities are in the transformation to become state-of-the-art smart cities using these technologies. This paper is about the automation of street cleanliness assessment in near real-time. It answers the question of how can we assess the status of streets in a more efficient and effective way. To address the problem, this paper proposes a multi-level assessment system on how the cleanliness status of streets is collected using mobile stations. They are connected via city network, analyzed in the cloud and presented to city administrators online or on mobile. The real case studies show the usability and feasibility of our system. This also gives opportunities\u00a0\u2026", "num_citations": "4\n", "authors": ["1657"]}
{"title": "Sky-MCSP-R: an efficient graph-based Web service composition approach\n", "abstract": " Aiming at optimizing Web service composition which satisfies user's multiple QoS constraints, an efficient graph-based Web service composition approach, named Skyline improved Multi Constraint Shortest Path-Relax (Sky-MCSP-R), is proposed. Firstly, the approach selects Skyline services from candidate service spaces, thus it can construct the model of Web service composition directly on these high quality candidate services, reducing the whole number of nodes of the model. Secondly, the approach uses MCSP-K algorithm which uses over constraint mechanism to compose basic services, and reduces the constraint intensity so to make algorithm MCSP-K produce as many feasible solutions as possible. Thirdly, the approach uses Relax algorithm to optimize the solutions. Experimental results show that the approach improves the efficiency of Web service composition and keeps a high optimization rate\u00a0\u2026", "num_citations": "4\n", "authors": ["1657"]}
{"title": "Mobility and Dependence-aware QoS Monitoring in Mobile Edge Computing\n", "abstract": " Mobile edge computing is a new computing paradigm that performs computing on the edge of a network. Services may be unavailable or do not satisfy the needs of users due to changing edge environments. Quality of service (QoS) is commonly employed as a critical means to indicate qualitative status of services. It is particularly important to monitor QoS of the services timely and effectively in the mobile edge environment. However, user mobility and dependencies among QoS values often cause the monitoring results to deviate from the real results. Existing QoS monitoring approaches have not taken into account these problems. To address them, this paper proposes ghBSRM-MEC, a novel mobility and dependence-aware QoS monitoring approach. This approach assumes that the QoS attribute values of edge servers obey Gaussian distribution. It constructs a parent property for each property, thus reducing the\u00a0\u2026", "num_citations": "3\n", "authors": ["1657"]}
{"title": "Neural Network Based Test Case Generation for Data-Flow Oriented Testing\n", "abstract": " Data-flow oriented testing plays an important role in software quality assurance. Many researches applied genetic algorithm to automatically generating test cases. However, each test case needs the run of program so as to compute its fitness value in most researches, which costs a lot. This paper proposes a neural network based approach for all-uses criterion oriented test case generation. The DU-pairs that need to be tested are calculated firstly. Then BP neural network is trained to simulate the fitness function. Finally, genetic algorithm is used to generate test cases where fitness value of each test case is evaluated with the trained neural network.", "num_citations": "3\n", "authors": ["1657"]}
{"title": "Condition-guided adversarial generative testing for deep learning systems\n", "abstract": " Over the past decade, Deep Neural Networks (DNNs) have achieved remarkable progress. However, the quality of such kind of systems is far from perfect. Software test is one of the most effective techniques for finding bugs in DNNs. Test case generation is the key factors of the success of software test. Existing test case generation approaches for DNNs always generate a large number of test cases, most of which do not meet the test requirements or the actual situation. In this paper, we propose CAGTest, a condition-guided adversarial generative testing tool for other DNNs to generate their test inputs to find potential defects. In general, CAGTest can generate test cases conditionally, which is not only efficient, but also does not produce a large number of invalid test cases and reduces the scale of test cases.", "num_citations": "3\n", "authors": ["1657"]}
{"title": "FunkR-pDAE: Personalized Project Recommendation Using Deep Learning\n", "abstract": " In open source communities, developers always need to spend plenty of time and energy on discovering specific projects from massive open source projects. Consequently, the study of personalized project recommendation for developers has important theoretical and practical significance. However, existing recommendation approaches have clear limitations, such as ignoring developers' operating behavior, social relationships and practical skills, and are very inefficient for large amounts of data. To address these limitations, this paper proposes FunkR-pDAE (Funk singular value decomposition Recommendation using pearson correlation coefficient and Deep Auto-Encoders), a novel personalized project recommendation approach using a deep learning model. FunkR-pDAE first extracts data related to developers and open source projects from open source communities, which build a developer-open source\u00a0\u2026", "num_citations": "3\n", "authors": ["1657"]}
{"title": "Automatic generation of predictive monitors from scenario-based specifications\n", "abstract": " ContextUnpredictability and uncertainty about future evolutions of both the system and its environment may easily compromise the behavior of the system. The subsequent software failures can have serious consequences. When dealing with open environments, run-time monitoring is one of the most promising techniques to detect software failures. Several monitoring approaches have been proposed in the last years; however, they suffer from two main limitations. First, they provide limited information to be exploited at run-time for early detecting and managing situations that most probably will lead to failures. Second, they mainly rely on logic-based specifications, whose intrinsic complexity may hamper the use of these monitoring approaches in industrial contexts.ObjectiveIn order to address these two limitations, this paper proposes a novel approach, called PREDIMO (PREDIctive MOnitoring). The approach starts\u00a0\u2026", "num_citations": "3\n", "authors": ["1657"]}
{"title": "A deep belief network based precipitation forecast approach using multiple environmental factors\n", "abstract": " Precise precipitation forecast can better reflect the changing trend of climate, provide timely and efficient environmental information for management decision, as well as help people to make preparations for the incoming floods or droughts. However, existing approaches have limited ability to forecast future precipitation in different regions. In order to addess the problem, this paper proposes a big data based approach for precipitation forecasting based on deep belief nets, called DBNPF (Deep Belief Network for Precipitation Forecast). The proposed approach can not only learn the hierarchical representation of raw data using a highly generalized way, but also make a more accurate description of the rule underlying different kind of environmental factors. A set of dedicated experiments with hydrological multivariate time series from four typical areas of China is conducted to validate the feasibility and robustness of\u00a0\u2026", "num_citations": "3\n", "authors": ["1657"]}
{"title": "Model checking WS-BPEL with universal modal sequence diagrams\n", "abstract": " Analyzing the composite service by manual is rather difficult and time-consuming. In the paper, we propose an approach to automatically verify the correctness of composite services by model checking based on a novel property specification universal Modal Sequence Diagrams(uMSDs). Because uMSDs can find a well-balance between simplicity of use and expressive power, the temporal properties of the composite service can be specified by uMSDs in an easy and intuitive way. Based on the formal syntax and semantics of uMSDs, a novel model checking approach is proposed to verify whether the model of WS-BPEL specification satisfies the properties represented by uMSDs. Finally, a series of experiments show the approach can effectively detect the logical errors in an On-the-Job Assistant case study.", "num_citations": "3\n", "authors": ["1657"]}
{"title": "CAGFuzz: Coverage-Guided Adversarial Generative Fuzzing Testing of Deep Learning Systems\n", "abstract": " Deep Learning systems (DL) based on Deep Neural Networks (DNNs) are more and more used in various aspects of our life, including unmanned vehicles, speech processing, and robotics. However, due to the limited dataset and the dependence on manual labeling data, DNNs often fail to detect their erroneous behaviors, which may lead to serious problems. Several approaches have been proposed to enhance the input examples for testing DL systems. However, they have the following limitations. First, they design and generate adversarial examples from the perspective of model, which may cause low generalization ability when they are applied to other models. Second, they only use surface feature constraints to judge the difference between the adversarial example generated and the original example. The deep feature constraints, which contain high-level semantic information, such as image object category and scene semantics are completely neglected. To address these two problems, in this paper, we propose CAGFuzz, a Coverage-guided Adversarial Generative Fuzzing testing approach, which generates adversarial examples for a targeted DNN to discover its potential defects. First, we train an adversarial case generator (AEG) from the perspective of general data set. Second, we extract the depth features of the original and adversarial examples, and constrain the adversarial examples by cosine similarity to ensure that the semantic information of adversarial examples remains unchanged. Finally, we retrain effective adversarial examples to improve neuron testing coverage rate. Based on several popular data sets, we design a set\u00a0\u2026", "num_citations": "2\n", "authors": ["1657"]}
{"title": "M-BSRM: Multivariate bayesian runtime QoS monitoring using point mutual information\n", "abstract": " Quality of Service (QoS) is well acknowledged as a decisive means for ascertaining the performance of third-party Web services. QoS has high uncertainty in complex and dynamic network environments. QoS monitoring is considered as one of the most effective techniques to detect QoS violations at runtime. However, existing QoS monitoring approaches only consider single QoS attribute and do not provide a promising solution for comprehensively monitoring multivariate QoS attributes. To overcome this problem, a novel QoS monitoring approach, named M-BSRM (Multivariate BayeSian Runtime Monitoring), is proposed. First, M-BSRM adopts the point mutual information theory to initialize the weights of different environmental impact factors and solves the problem of uneven distribution between classes brought by traditional algorithms. Second, each single QoS attribute is integrated with user preference using\u00a0\u2026", "num_citations": "2\n", "authors": ["1657"]}
{"title": "\u57fa\u4e8e\u7070\u5ea6\u56fe\u7eb9\u7406\u6307\u7eb9\u7684\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\n", "abstract": " \u6458 \u8981 \u968f\u7740\u5b89\u5353\u6076\u610f\u8f6f\u4ef6\u6570\u91cf\u7684\u5feb\u901f\u589e\u957f, \u4f20\u7edf\u7684\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4e0e\u5206\u7c7b\u673a\u5236\u5b58\u5728\u68c0\u6d4b\u7387\u4f4e, \u8bad\u7ec3\u6a21\u578b\u590d\u6742\u5ea6\u9ad8\u7b49\u95ee\u9898. \u4e3a\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898, \u7ed3\u5408\u56fe\u50cf\u7eb9\u7406\u7279\u5f81\u63d0\u53d6\u6280\u672f\u548c\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668, \u63d0\u51fa\u57fa\u4e8e\u7070\u5ea6\u56fe\u7eb9\u7406\u7279\u5f81\u7684\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u65b9\u6cd5. \u8be5\u65b9\u6cd5\u9996\u5148\u5c06\u6076\u610f\u8f6f\u4ef6\u6837\u672c\u751f\u6210\u7070\u5ea6\u56fe, \u8bbe\u8ba1\u5e76\u96c6\u6210\u4e86\u5305\u542b GIST \u548c Tamura \u7279\u5f81\u63d0\u53d6\u7b97\u6cd5\u5728\u5185\u7684 4 \u79cd\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5; \u7136\u540e\u5c06\u6240\u5f97\u7eb9\u7406\u7279\u5f81\u96c6\u5408\u4f5c\u4e3a\u6e90\u6570\u636e, \u57fa\u4e8e Caffe \u9ad8\u6027\u80fd\u5904\u7406\u67b6\u6784\u6784\u9020\u4e86 5 \u79cd\u5206\u7c7b\u5b66\u4e60\u6a21\u578b, \u6700\u7ec8\u5b9e\u73b0\u5bf9\u6076\u610f\u8f6f\u4ef6\u7684\u68c0\u6d4b\u548c\u5206\u7c7b. \u5b9e\u9a8c\u7ed3\u679c\u8868\u660e, \u57fa\u4e8e\u56fe\u50cf\u7eb9\u7406\u7279\u5f81\u7684\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u5177\u6709\u8f83\u9ad8\u7684\u51c6\u786e\u7387, \u4e14 Caffe \u67b6\u6784\u80fd\u6709\u6548\u7f29\u77ed\u5b66\u4e60\u65f6\u95f4, \u964d\u4f4e\u590d\u6742\u5ea6.", "num_citations": "2\n", "authors": ["1657"]}
{"title": "Android-srv: scenario-based runtime verification of android applications\n", "abstract": " With the wide-spread usage of Android systems, Android applications have become the target of mobile malwares. Therefore, an effective verification approach for Android applications is essential. Runtime verification based on monitors is one of the most promising techniques to check the software\u2019s behaviors. Currently, there are a number of monitoring approaches for Android applications. However, these approaches mainly have two limitations. First, there is no effective mechanism to reduce the load on Android applications caused by monitors. Second, these approaches mainly rely on logic-based specifications, which are complex and not intuitive for being used in practice. In order to address these two limitations, this paper proposes a scenario-based runtime verification approach for Android applications (called Android-SRV). The approach concentrates on providing a dynamic and usable solution for\u00a0\u2026", "num_citations": "2\n", "authors": ["1657"]}
{"title": "\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u7f51\u7edc\u7684\u591a\u73af\u5883\u56e0\u7d20\u964d\u6c34\u91cf\u9884\u62a5\u6a21\u578b\n", "abstract": " \u6458 \u8981 \u4e3a\u4e86\u66f4\u597d\u5730\u53cd\u6620\u533a\u57df\u964d\u6c34\u7684\u53d8\u5316\u8d8b\u52bf, \u5f00\u5c55\u533a\u57df\u964d\u6c34\u91cf\u9884\u62a5\u663e\u5f97\u5c24\u4e3a\u91cd\u8981. \u5728\u6d41\u57df\u4fe1\u606f\u65f6\u4ee3\u5b58\u5728\u4e30\u5bcc\u5927\u6570\u636e\u7684\u60c5\u51b5\u4e0b, \u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e DBN (DeepBeliefNets) \u6df1\u5ea6\u7f51\u7edc\u964d\u6c34\u91cf\u9884\u62a5\u6a21\u578b\u7684\u65b0\u65b9\u6848. \u8be5\u65b9\u6848\u901a\u8fc7\u6a21\u62df\u5927\u8111\u795e\u7ecf\u5143\u7684\u591a\u5c42\u7ed3\u6784, \u5e76\u4f7f\u7528\u53cd\u5411\u4f20\u64ad\u7f51\u7edc\u5bf9\u6574\u4e2a\u7f51\u7edc\u8fdb\u884c\u5fae\u8c03. \u6a21\u578b\u4f7f\u7528\u4e86\u4e0e\u6bcf\u65e5\u964d\u6c34\u91cf\u606f\u606f\u76f8\u5173\u7684\u4e03\u79cd\u73af\u5883\u56e0\u7d20\u4f5c\u4e3a\u8f93\u5165\u5411\u91cf, \u672a\u6765 24 \u5c0f\u65f6\u964d\u6c34\u4f5c\u4e3a\u8f93\u51fa\u5411\u91cf, \u901a\u8fc7\u5728\u8d35\u5dde\u9075\u4e49\u5730\u533a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027, \u5e76\u4e0e\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5b9e\u9a8c, \u7ed3\u679c\u8868\u660e\u6a21\u578b\u5177\u6709\u66f4\u597d\u7684\u9884\u6d4b\u6548\u679c.", "num_citations": "2\n", "authors": ["1657"]}
{"title": "On Building a Big Data Analysis System for California Drought\n", "abstract": " Water scarcity is one of the serious problems that California is facing today. Water scarcity leads to doughtiness when not properly addressed. In the recent years, California faces a serious drought problem. This provides a strong demand in building a real-time system to support water resources analysis, drought modeling and prediction. Existing models and approaches lack of desirable accuracy in predicting and analyzing California Drought. This paper proposes a big data based approach to support California Drought analysis and prediction based on diverse data sets, including climate sensor and satellite data, weather data, and drought condition and water usage reports. The paper reports an implemented system supporting big data analytics for California Drought. It uses a proposed California Drought Index and presents big data analytics results based on existing big data models and algorithms, as well as\u00a0\u2026", "num_citations": "2\n", "authors": ["1657"]}
{"title": "Effa: A ProM plugin for recovering event logs\n", "abstract": " While event logs generated by business processes play an increasingly significant role in business analysis, the quality of data remains a serious problem. Automatic recovery of dirty event logs is desirable and thus receives more attention. However, existing methods only focus on missing event recovery, or fall short of efficiency. To this end, we present Effa, a ProM plugin, to automatically recover event logs in the light of process specifications. Based on advanced heuristics including process decomposition and trace replaying to search the minimum recovery, Effa achieves a balance between repairing accuracy and efficiency.", "num_citations": "2\n", "authors": ["1657"]}
{"title": "An Automatic Recovery Mechanism for Cloud Service Composition\n", "abstract": " Cloud computing, with characteristics of large scale computation, data storage, visualization, high expansibility and elasticity, provides a powerful computing paradigm. Cloud services can be rapidly composed to form on-demand composite service for accomplishing the users' requirements. However, the uncertainty of cloud services has impacted on the correctness and reliability of the composite services. Especially, for unanticipated hardware and software failures, it is very difficult to assure the quality of the composite services. In the complex cloud computing environments, recovery of the composite services from these failures is a challenging issue. The paper first presents a unified fault taxonomy in the three layers of cloud computing and analyze the causes of the faults. The authors then propose a hierarchical recovery mechanism including five different recovery algorithms for various kinds of failures. Finally\u00a0\u2026", "num_citations": "2\n", "authors": ["1657"]}
{"title": "Hierarchical timed automata based verification of dynamic evolution process in open environments\n", "abstract": " The paper proposes a novel approach based on the hierarchical timed automata to verify the consistency of dynamic evolution process. Different from traditional approaches, it investigates the problem from the behavioral perspective and examines the procedures before, during and after the evolution process. Furthermore, our approach can support the direct modeling of temporal aspects, as well as the hierarchical structures. A flattening algorithm is presented to facilitate the automated verification using the mainstream timed automata based model checker--UPPAAL. A motivating example is discussed and demonstrates the feasibility of our approach.", "num_citations": "2\n", "authors": ["1657"]}
{"title": "Self-Healing Event Logs\n", "abstract": " Event logs of process-aware information systems play an increasingly critical role in today's enterprises because they are the basis for a number of business intelligence applications such as complex event processing, provenance analysis, performance analysis, and process mining. However, due to incorrect manual recording, system errors, and resource constraints, event logs inevitably contain noise in the form of deviating event sequences with redundant, missing, or dislocated events. To repair event logs, existing approaches rely on predefined process specifications to obtain a minimum recovery for each deviating event sequence. However, process specifications are typically unavailable in practice, rendering existing approaches inapplicable. In this scenario, can event logs be self-healing? To address this problem, we propose an approach that leverages compliant event sequences to repair deviating\u00a0\u2026", "num_citations": "1\n", "authors": ["1657"]}
{"title": "AHWCI: A Prototype Tool for Identifying High-Level Workflow Changes\n", "abstract": " Identifying a minimum sequence of high-level workflowchanges is required in many application scenarios suchas workflow retrieval, comparison, and merging, etc. However, this problem has been proved to be NP-hard. In this paper, we utilize an A* like algorithm and a set of pruning rules to address this problem. The performance evaluation demonstrates the advantages of our approach over the state-of-the-art approach.", "num_citations": "1\n", "authors": ["1657"]}
{"title": "\u4e00\u79cd\u73af\u5883\u56e0\u7d20\u654f\u611f\u7684 Web Service QoS \u76d1\u63a7\u65b9\u6cd5\n", "abstract": " \u9762\u5411\u670d\u52a1\u7cfb\u7edf\u7684\u6267\u884c\u80fd\u529b\u4f9d\u8d56\u7b2c\u4e09\u65b9\u63d0\u4f9b\u7684\u670d\u52a1, \u5728\u590d\u6742\u591a\u53d8\u7684\u7f51\u7edc\u73af\u5883\u4e2d, \u8fd9\u79cd\u4f9d\u8d56\u4f1a\u5e26\u6765\u670d\u52a1\u8d28\u91cf (QoS) \u7684\u4e0d\u786e\u5b9a\u6027. \u800c QoS \u662f\u8861\u91cf\u7b2c\u4e09\u65b9\u670d\u52a1\u8d28\u91cf\u7684\u91cd\u8981\u6807\u51c6, \u56e0\u6b64, \u6709\u6548\u76d1\u63a7 QoS \u662f\u5bf9 Web \u670d\u52a1\u5b9e\u73b0\u8d28\u91cf\u63a7\u5236\u7684\u5fc5\u8981\u8fc7\u7a0b. \u73b0\u6709\u76d1\u63a7\u65b9\u6cd5\u90fd\u672a\u8003\u8651\u73af\u5883\u56e0\u7d20\u7684\u5f71\u54cd, \u6bd4\u5982\u670d\u52a1\u5668\u4f4d\u7f6e, \u7528\u6237\u4f7f\u7528\u670d\u52a1\u7684\u4f4d\u7f6e\u548c\u4f7f\u7528\u65f6\u95f4\u6bb5\u8d1f\u8f7d\u7b49, \u800c\u8fd9\u4e9b\u5f71\u54cd\u5728\u5b9e\u9645\u76d1\u63a7\u4e2d\u662f\u5b58\u5728\u7684, \u5ffd\u7565\u73af\u5883\u56e0\u7d20\u4f1a\u5bfc\u81f4\u76d1\u63a7\u7ed3\u679c\u4e0e\u5b9e\u9645\u7ed3\u679c\u6709\u6096. \u9488\u5bf9\u8fd9\u4e00\u95ee\u9898, \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a0\u6743\u6734\u7d20\u8d1d\u53f6\u65af\u7b97\u6cd5 wBSRM (weightednaive Bayes running monitoring) \u7684 Web Service QoS \u76d1\u63a7\u65b9\u6cd5. \u53d7\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u65b9\u6cd5\u7684\u542f\u53d1, \u901a\u8fc7 TF-IDF (term frequency-inverse document frequency) \u7b97\u6cd5\u8ba1\u7b97\u73af\u5883\u56e0\u7d20\u7684\u5f71\u54cd, \u901a\u8fc7\u5bf9\u90e8\u5206\u6837\u672c\u8fdb\u884c\u5b66\u4e60, \u6784\u5efa\u52a0\u6743\u6734\u7d20\u8d1d\u53f6\u65af\u5206\u7c7b\u5668. \u5c06\u76d1\u63a7\u7ed3\u679c\u5206\u7c7b, \u6ee1\u8db3 QoS \u6807\u51c6\u4e3a c0, \u4e0d\u6ee1\u8db3 QoS \u6807\u51c6\u4e3a c1, \u76d1\u63a7\u65f6\u8c03\u7528\u5206\u7c7b\u5668\u5f97\u5230 c0 \u548c c1 \u7684\u540e\u9a8c\u6982\u7387\u4e4b\u6bd4, \u5bf9\u6bd4\u503c\u8fdb\u884c\u5206\u6790, \u53ef\u5f97\u76d1\u63a7\u7ed3\u679c\u6ee1\u8db3 QoS \u5c5e\u6027\u6807\u51c6, \u4e0d\u6ee1\u8db3 QoS \u5c5e\u6027\u6807\u51c6\u548c\u4e0d\u80fd\u5224\u65ad\u8fd9 3 \u79cd\u60c5\u51b5. \u5728\u7f51\u7edc\u5f00\u6e90\u6570\u636e\u4ee5\u53ca\u968f\u673a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e: \u5229\u7528 TF-IDF \u7b97\u6cd5\u80fd\u591f\u51c6\u786e\u5730\u4f30\u7b97\u73af\u5883\u56e0\u5b50\u6743\u503c, \u901a\u8fc7\u52a0\u6743\u6734\u7d20\u8d1d\u53f6\u65af\u5206\u7c7b\u5668, \u80fd\u591f\u66f4\u597d\u5730\u76d1\u63a7 QoS, \u6548\u7387\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5.", "num_citations": "1\n", "authors": ["1657"]}
{"title": "\u57fa\u4e8e\u5f84\u5411\u57fa\u795e\u7ecf\u7f51\u7edc\u7684 Web Service QoS\u5c5e\u6027\u503c\u7ec4\u5408\u9884\u6d4b\u65b9\u6cd5\n", "abstract": " \u4e3a\u6b63\u786e\u9884\u6d4bWebService\u7684\u670d\u52a1\u8d28\u91cf(Quality of Service,QoS),\u5e2e\u52a9\u7528\u6237\u9009\u62e9\u7b26\u5408\u670d\u52a1\u8d28\u91cf\u9700\u6c42\u7684Web Service,\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5f84\u5411\u57fa\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u670d\u52a1\u8d28\u91cf\u7ec4\u5408\u9884\u6d4b\u65b9\u6cd5.\u9996\u5148\u4f7f\u7528\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u5bf9\u6570\u636e\u96c6\u5efa\u7acb\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u9884\u6d4b\u6a21\u578b,\u5e76\u9009\u62e9\u6700\u4f18\u6a21\u578b,\u540c\u65f6\u6839\u636e\u6570\u636e\u7279\u70b9\u5efa\u7acb\u4e0d\u540c\u6ed1\u52a8\u7a97\u53e3\u7684\u7070\u8272\u7b49\u7ef4\u65b0\u606f\u6a21\u578b,\u518d\u5c06\u4e0a\u8ff02\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c\u4f5c\u4e3a\u8f93\u5165\u6e90\u4f20\u9012\u7ed9\u5f84\u5411\u57fa\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u6a21\u578b,\u8fdb\u884c\u9884\u6d4b.\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e,\u8be5\u65b9\u6cd5\u4e0e\u5df2\u6709\u65b9\u6cd5\u76f8\u6bd4\u8f83,\u5728\u9884\u6d4b\u7cbe\u5ea6\u65b9\u9762\u6709\u4e00\u5b9a\u7a0b\u5ea6\u7684\u63d0\u9ad8.", "num_citations": "1\n", "authors": ["1657"]}
{"title": "Game-based monitors for a scenario-based specification in open environments\n", "abstract": " In open environments, unsafe run-time changes of systems and environments may compromise the correct execution of the entire systems and make the software systems do not meet the original specifications, which may eventually lead to the occurrence of software failures. Runtime monitor which is a lightweight formal dynamic verification technology has become the basic means of detecting software failures in open environments. For scenario-based specification property sequence charts, this paper defines the multi-valued monitoring semantics from the perspective of game theory: satisfied, infinitely controllable, the system is finitely controllable, the system is emergency controllable, the environment is finitely controllable, the environment is emergency controllable, violated. Through the multi-valued semantics definition, the monitor can detect failures as early as possible and also provide sufficient information to help the system to take measures for failure prevention and recovery. Finally, the property sequence chart used in RailCab case study shows its extensive application prospect.", "num_citations": "1\n", "authors": ["1657"]}