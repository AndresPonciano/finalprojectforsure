{"title": "ImageNet large scale visual recognition challenge\n", "abstract": " The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5\u00a0years of the challenge, and propose future directions and improvements.", "num_citations": "28636\n", "authors": ["1164"]}
{"title": "Visual genome: Connecting language and vision using crowdsourced dense image annotations\n", "abstract": " Despite progress in perceptual tasks such as image classification, computers still perform poorly on cognitive tasks such as image description and question answering. Cognition is core to tasks that involve not just recognizing, but reasoning about our visual world. However, models used to tackle the rich content in images for cognitive tasks are still being trained using the same datasets designed for perceptual tasks. To achieve success at cognitive tasks, models need to understand the interactions and relationships between objects in an image. When asked \u201cWhat vehicle is the person riding?\u201d, computers will need to identify the objects in an image as well as the relationships riding(man, carriage) and pulling(horse, carriage) to answer correctly that \u201cthe person is riding a horse-drawn carriage.\u201d In this paper, we present the Visual Genome dataset to enable the modeling of such relationships. We collect dense\u00a0\u2026", "num_citations": "2678\n", "authors": ["1164"]}
{"title": "Visual relationship detection with language priors\n", "abstract": " Visual relationships capture a wide variety of interactions between pairs of objects in images (e.g. \u201cman riding bicycle\u201d and \u201cman pushing bicycle\u201d). Consequently, the set of possible relationships is extremely large and it is difficult to obtain sufficient training examples for all possible relationships. Because of this limitation, previous work on visual relationship detection has concentrated on predicting only a handful of relationships. Though most relationships are infrequent, their objects (e.g. \u201cman\u201d and \u201cbicycle\u201d) and predicates (e.g. \u201criding\u201d and \u201cpushing\u201d) independently occur more frequently. We propose a model that uses this insight to train visual models for objects and predicates individually and later combines them together to predict multiple relationships per image. We improve on prior work by leveraging language priors from semantic word embeddings to finetune the likelihood of a predicted\u00a0\u2026", "num_citations": "774\n", "authors": ["1164"]}
{"title": "Twitinfo: aggregating and visualizing microblogs for event exploration\n", "abstract": " Microblogs are a tremendous repository of user-generated content about world events. However, for people trying to understand events by querying services like Twitter, a chronological log of posts makes it very difficult to get a detailed understanding of an event. In this paper, we present TwitInfo, a system for visualizing and summarizing events on Twitter. TwitInfo allows users to browse a large collection of tweets using a timeline-based display that highlights peaks of high tweet activity. A novel streaming algorithm automatically discovers these peaks and labels them meaningfully using text from the tweets. Users can drill down to subevents, and explore further via geolocation, sentiment, and popular URLs. We contribute a recall-normalized aggregate sentiment visualization to produce more honest sentiment overviews. An evaluation of the system revealed that users were able to reconstruct meaningful\u00a0\u2026", "num_citations": "755\n", "authors": ["1164"]}
{"title": "Image retrieval using scene graphs\n", "abstract": " This paper develops a novel framework for semantic image retrieval based on the notion of a scene graph. Our scene graphs represent objects (\" man\",\" boat\"), attributes of objects (\" boat is white\") and relationships between objects (\" man standing on boat\"). We use these scene graphs as queries to retrieve semantically related images. To this end, we design a conditional random field model that reasons about possible groundings of scene graphs to test images. The likelihoods of these groundings are used as ranking scores for retrieval. We introduce a novel dataset of 5,000 human-generated scene graphs grounded to images and use this dataset to evaluate our method for image retrieval. In particular, we evaluate retrieval using full scene graphs and small scene subgraphs, and show that our method outperforms retrieval methods that use only objects or low-level image features. In addition, we show that our full model can be used to improve object localization compared to baseline methods.", "num_citations": "719\n", "authors": ["1164"]}
{"title": "Visual7w: Grounded question answering in images\n", "abstract": " We have seen great progress in basic perceptual tasks such as object recognition and detection. However, AI models still fail to match humans in high-level vision tasks due to the lack of capacities for deeper reasoning. Recently the new task of visual question answering (QA) has been proposed to evaluate a model's capacity for deep image understanding. Previous works have established a loose, global association between QA sentences and images. However, many questions and answers, in practice, relate to local regions in the images. We establish a semantic link between textual descriptions and image regions by object-level grounding. It enables a new type of QA with visual answers, in addition to textual answers used in previous work. We study the visual QA tasks in a grounded setting with a large collection of 7W multiple-choice QA pairs. Furthermore, we evaluate human performance and several baseline models on the QA tasks. Finally, we propose a novel LSTM model with spatial attention to tackle the 7W QA tasks.", "num_citations": "662\n", "authors": ["1164"]}
{"title": "Quantifying the invisible audience in social networks\n", "abstract": " When you share content in an online social network, who is listening? Users have scarce information about who actually sees their content, making their audience seem invisible and difficult to estimate. However, understanding this invisible audience can impact both science and design, since perceived audiences influence content production and self-presentation online. In this paper, we combine survey and large-scale log data to examine how well users' perceptions of their audience match their actual audience on Facebook. We find that social media users consistently underestimate their audience size for their posts, guessing that their audience is just 27% of its true size. Qualitative coding of survey responses reveals folk theories that attempt to reverse-engineer audience size using feedback and friend count, though none of these approaches are particularly accurate. We analyze audience logs for 222,000\u00a0\u2026", "num_citations": "447\n", "authors": ["1164"]}
{"title": "4chan and /b/: An Analysis of Anonymity and Ephemerality in a Large Online Community\n", "abstract": " We present two studies of online ephemerality and anonymity based on the popular discussion board/b/at 4chan. org: a website with over 7 million users that plays an influential role in Internet culture. Although researchers and practitioners often assume that user identity and data permanence are central tools in the design of online communities, we explore how/b/succeeds despite being almost entirely anonymous and extremely ephemeral. We begin by describing/b/and performing a content analysis that suggests the community is dominated by playful exchanges of images and links. Our first study uses a large dataset of more than five million posts to quantify ephemerality in/b/. We find that most threads spend just five seconds on the first page and less than five minutes on the site before expiring. Our second study is an analysis of identity signals on 4chan, finding that over 90% of posts are made by fully anonymous users, with other identity signals adopted and discarded at will. We describe alternative mechanisms that/b/participants use to establish status and frame their interactions.", "num_citations": "423\n", "authors": ["1164"]}
{"title": "Anyone can become a troll: Causes of trolling behavior in online discussions\n", "abstract": " In online communities, antisocial behavior such as trolling disrupts constructive discussion. While prior work suggests that trolling behavior is confined to a vocal and antisocial minority, we demonstrate that ordinary people can engage in such behavior as well. We propose two primary trigger mechanisms: the individual's mood, and the surrounding context of a discussion (eg, exposure to prior trolling behavior). Through an experiment simulating an online discussion, we find that both negative mood and seeing troll posts by others significantly increases the probability of a user trolling, and together double this probability. To support and extend these results, we study how these same mechanisms play out in the wild via a data-driven, longitudinal analysis of a large online news discussion community. This analysis exposes temporal mood effects, and explores long range patterns of repeated exposure to trolling. A\u00a0\u2026", "num_citations": "391\n", "authors": ["1164"]}
{"title": "Crowds in two seconds: Enabling realtime crowd-powered interfaces\n", "abstract": " Interactive systems must respond to user input within seconds. Therefore, to create realtime crowd-powered interfaces, we need to dramatically lower crowd latency. In this paper, we introduce the use of synchronous crowds for on-demand, realtime crowdsourcing. With synchronous crowds, systems can dynamically adapt tasks by leveraging the fact that workers are present at the same time. We develop techniques that recruit synchronous crowds in two seconds and use them to execute complex search tasks in ten seconds. The first technique, the retainer model, pays workers a small wage to wait and respond quickly when asked. We offer empirically derived guidelines for a retainer system that is low-cost and produces on-demand crowds in two seconds. Our second technique, rapid refinement, observes early signs of agreement in synchronous crowds and dynamically narrows the search space to focus on\u00a0\u2026", "num_citations": "388\n", "authors": ["1164"]}
{"title": "Reflective physical prototyping through integrated design, test, and analysis\n", "abstract": " Prototyping is the pivotal activity that structures innovation, collaboration, and creativity in design. Prototypes embody design hypotheses and enable designers to test them. Framin design as a thinking-by-doing activity foregrounds iteration as a central concern. This paper presents d. tools, a toolkit that embodies an iterative-design-centered approach to prototyping information appliances. This work offers contributions in three areas. First, d. tools introduces a statechart-based visual design tool that provides a low threshold for early-stage prototyping, extensible through code for higher-fidelity prototypes. Second, our research introduces three important types of hardware extensibility-at the hardware-to-PC interface, the intra-hardware communication level, and the circuit level. Third, d. tools integrates design, test, and analysis of information appliances. We have evaluated d. tools through three studies: a laboratory\u00a0\u2026", "num_citations": "383\n", "authors": ["1164"]}
{"title": "Empath: Understanding topic signals in large-scale text\n", "abstract": " Human language is colored by a broad range of topics, but existing text analysis tools only focus on a small number of them. We present Empath, a tool that can generate and validate new lexical categories on demand from a small set of seed terms (like\" bleed\" and\" punch\" to generate the category violence). Empath draws connotations between words and phrases by deep learning a neural embedding across more than 1.8 billion words of modern fiction. Given a small set of seed words that characterize a category, Empath uses its neural embedding to discover new related terms, then validates the category with a crowd-powered filter. Empath also analyzes text across 200 built-in, pre-validated categories we have generated from common topics in our web dataset, like neglect, government, and social media. We show that Empath's data-driven, human validated categories are highly correlated (r= 0.906) with\u00a0\u2026", "num_citations": "295\n", "authors": ["1164"]}
{"title": "We are dynamo: Overcoming stalling and friction in collective action for crowd workers\n", "abstract": " By lowering the costs of communication, the web promises to enable distributed collectives to act around shared issues. However, many collective action efforts never succeed: while the web's affordances make it easy to gather, these same decentralizing characteristics impede any focus towards action. In this paper, we study challenges to collective action efforts through the lens of online labor by engaging with Amazon Mechanical Turk workers. Through a year of ethnographic fieldwork, we sought to understand online workers' unique barriers to collective action. We then created Dynamo, a platform to support the Mechanical Turk community in forming publics around issues and then mobilizing. We found that collective action publics tread a precariously narrow path between the twin perils of stalling and friction, balancing with each step between losing momentum and flaring into acrimony. However, specially\u00a0\u2026", "num_citations": "269\n", "authors": ["1164"]}
{"title": "Expert crowdsourcing with flash teams\n", "abstract": " We introduce flash teams, a framework for dynamically assembling and managing paid experts from the crowd. Flash teams advance a vision of expert crowd work that accomplishes complex, interdependent goals such as engineering and design. These teams consist of sequences of linked modular tasks and handoffs that can be computationally managed. Interactive systems reason about and manipulate these teams' structures: for example, flash teams can be recombined to form larger organizations and authored automatically in response to a user's request. Flash teams can also hire more people elastically in reaction to task needs, and pipeline intermediate output to accelerate completion times. To enable flash teams, we present Foundry, an end-user authoring platform and runtime manager. Foundry allows users to author modular tasks, then manages teams through handoffs of intermediate work. We\u00a0\u2026", "num_citations": "237\n", "authors": ["1164"]}
{"title": "Handbook of collective intelligence\n", "abstract": " Experts describe the latest research in a rapidly growing multidisciplinary field, the study of groups of individuals acting collectively in ways that seem intelligent. Intelligence does not arise only in individual brains; it also arises in groups of individuals. This is collective intelligence: groups of individuals acting collectively in ways that seem intelligent. In recent years, a new kind of collective intelligence has emerged: interconnected groups of people and computers, collectively doing intelligent things. Today these groups are engaged in tasks that range from writing software to predicting the results of presidential elections. This volume reports on the latest research in the study of collective intelligence, laying out a shared set of research challenges from a variety of disciplinary and methodological perspectives. Taken together, these essays\u2014by leading researchers from such fields as computer science, biology, economics, and psychology\u2014lay the foundation for a new multidisciplinary field. Each essay describes the work on collective intelligence in a particular discipline\u2014for example, economics and the study of markets; biology and research on emergent behavior in ant colonies; human-computer interaction and artificial intelligence; and cognitive psychology and the \u201cwisdom of crowds\u201d effect. Other areas in social science covered include social psychology, organizational theory, law, and communications. Contributors Eytan Adar, Ishani Aggarwal, Yochai Benkler, Michael S. Bernstein, Jeffrey P. Bigham, Jonathan Bragg, Deborah M. Gordon, Benjamin Mako Hill, Christopher H. Lin, Andrew W. Lo, Thomas W. Malone, Mausam, Brent Miller, Aaron\u00a0\u2026", "num_citations": "233\n", "authors": ["1164"]}
{"title": "PeerStudio: rapid peer feedback emphasizes revision and improves performance\n", "abstract": " Rapid feedback is a core component of mastery learning, but feedback on open-ended work requires days or weeks in most classes today. This paper introduces PeerStudio, an assessment platform that leverages the large number of students' peers in online classes to enable rapid feedback on in-progress work. Students submit their draft, give rubric-based feedback on two peers' drafts, and then receive peer feedback. Students can integrate the feedback and repeat this process as often as they desire. In MOOC deployments, the median student received feedback in just twenty minutes. Rapid feedback on in-progress work improves course outcomes: in a controlled experiment, students' final grades improved when feedback was delivered quickly, but not if delayed by 24 hours. More than 3,600 students have used PeerStudio in eight classes, both massive and in-person. This research demonstrates how large\u00a0\u2026", "num_citations": "189\n", "authors": ["1164"]}
{"title": "Designing and deploying online field experiments\n", "abstract": " Online experiments are widely used to compare specific design alternatives, but they can also be used to produce generalizable knowledge and inform strategic decision making. Doing so often requires sophisticated experimental designs, iterative refinement, and careful logging and analysis. Few tools exist that support these needs. We thus introduce a language for online field experiments called PlanOut. PlanOut separates experimental design from application code, allowing the experimenter to concisely describe experimental designs, whether common\" A/B tests\" and factorial designs, or more complex designs involving conditional logic or multiple experimental units. These latter designs are often useful for understanding causal mechanisms involved in user behaviors. We demonstrate how experiments from the literature can be implemented in PlanOut, and describe two large field experiments conducted on\u00a0\u2026", "num_citations": "187\n", "authors": ["1164"]}
{"title": "Information scraps: How and why information eludes our personal information management tools\n", "abstract": " In this article we investigate information scraps\u2014personal information where content has been scribbled on Post-it notes, scrawled on the corners of sheets of paper, stuck in our pockets, sent in email messages to ourselves, and stashed in miscellaneous digital text files. Information scraps encode information ranging from ideas and sketches to notes, reminders, shipment tracking numbers, driving directions, and even poetry. Although information scraps are ubiquitous, we have much still to learn about these loose forms of information practice. Why do we keep information scraps outside of our traditional PIM applications? What role do information scraps play in our overall information practice? How might PIM applications be better designed to accommodate and support information scraps' creation, manipulation and retrieval? We pursued these questions by studying the information scrap practices of 27 knowledge\u00a0\u2026", "num_citations": "160\n", "authors": ["1164"]}
{"title": "Who gives a tweet? Evaluating microblog content value\n", "abstract": " While microblog readers have a wide variety of reactions to the content they see, studies have tended to focus on extremes such as retweeting and unfollowing. To understand the broad continuum of reactions in-between, which are typically not shared publicly, we designed a website that collected the first large corpus of follower ratings on Twitter updates. Using our dataset of over 43,000 voluntary ratings, we find that nearly 36% of the rated tweets are worth reading, 25% are not, and 39% are middling. These results suggest that users tolerate a large amount of less-desired content in their feeds. We find that users value information sharing and random thoughts above me-oriented or presence updates. We also offer insight into evolving social norms, such as lack of context and misuse of@ mentions and hashtags. We discuss implications for emerging practice and tool design.", "num_citations": "155\n", "authors": ["1164"]}
{"title": "Scalable multi-label annotation\n", "abstract": " We study strategies for scalable multi-label annotation, or for efficiently acquiring multiple labels from humans for a collection of items. We propose an algorithm that exploits correlation, hierarchy, and sparsity of the label distribution. A case study of labeling 200 objects using 20,000 images demonstrates the effectiveness of our approach. The algorithm results in up to 6x reduction in human computation time compared to the naive method of querying a human annotator for the presence of every object in every image.", "num_citations": "147\n", "authors": ["1164"]}
{"title": "Flash organizations: Crowdsourcing complex work by structuring crowds as organizations\n", "abstract": " This paper introduces flash organizations: crowds structured like organizations to achieve complex and open-ended goals. Microtask workflows, the dominant crowdsourcing structures today, only enable goals that are so simple and modular that their path can be entirely pre-defined. We present a system that organizes crowd workers into computationally-represented structures inspired by those used in organizations-roles, teams, and hierarchies-which support emergent and adaptive coordination toward open-ended goals. Our system introduces two technical contributions: 1) encoding the crowd's division of labor into de-individualized roles, much as movie crews or disaster response teams use roles to support coordination between on-demand workers who have not worked together before; and 2) reconfiguring these structures through a model inspired by version control, enabling continuous adaptation of the\u00a0\u2026", "num_citations": "144\n", "authors": ["1164"]}
{"title": "Flock: Hybrid crowd-machine learning classifiers\n", "abstract": " We present hybrid crowd-machine learning classifiers: classification models that start with a written description of a learning goal, use the crowd to suggest predictive features and label data, and then weigh these features using machine learning to produce models that are accurate and use human-understandable features. These hybrid classifiers enable fast prototyping of machine learning models that can improve on both algorithm performance and human judgment, and accomplish tasks where automated feature extraction is not yet feasible. Flock, an interactive machine learning platform, instantiates this approach. To generate informative features, Flock asks the crowd to compare paired examples, an approach inspired by analogical encoding. The crowd's efforts can be focused on specific subsets of the input space where machine-extracted features are not predictive, or instead used to partition the input\u00a0\u2026", "num_citations": "143\n", "authors": ["1164"]}
{"title": "Break it down: A comparison of macro-and microtasks\n", "abstract": " A large, seemingly overwhelming task can sometimes be transformed into a set of smaller, more manageable microtasks that can each be accomplished independently. For example, it may be hard to subjectively rank a large set of photographs, but easy to sort them in spare moments by making many pairwise comparisons. In crowdsourcing systems, microtasking enables unskilled workers with limited commitment to work together to complete tasks they would not be able to do individually. We explore the costs and benefits of decomposing macrotasks into microtasks for three task categories: arithmetic, sorting, and transcription. We find that breaking these tasks into microtasks results in longer overall task completion times, but higher quality outcomes and a better experience that may be more resilient to interruptions. These results suggest that microtasks can help people complete high quality work in interruption\u00a0\u2026", "num_citations": "141\n", "authors": ["1164"]}
{"title": "Twitch crowdsourcing: crowd contributions in short bursts of time\n", "abstract": " To lower the threshold to participation in crowdsourcing, we present twitch crowdsourcing: crowdsourcing via quick contributions that can be completed in one or two seconds. We introduce Twitch, a mobile phone application that asks users to make a micro-contribution each time they unlock their phone. Twitch takes advantage of the common habit of turning to the mobile phone in spare moments. Twitch crowdsourcing activities span goals such as authoring a census of local human activity, rating stock photos, and extracting structured data from Wikipedia pages. We report a field deployment of Twitch where 82 users made 11,240 crowdsourcing contributions as they used their phone in the course of everyday life. The median Twitch activity took just 1.6 seconds, incurring no statistically distinguishable costs to unlock speed or cognitive load compared to a standard slide-to-unlock interface.", "num_citations": "124\n", "authors": ["1164"]}
{"title": "Enhancing directed content sharing on the web\n", "abstract": " To find interesting, personally relevant web content, people rely on friends and colleagues to pass links along as they encounter them. In this paper, we study and augment link-sharing via e-mail, the most popular means of sharing web content today. Armed with survey data indicating that active sharers of novel web content are often those that actively seek it out, we developed FeedMe, a plug-in for Google Reader that makes directed sharing of content a more salient part of the user experience. FeedMe recommends friends who may be interested in seeing content that the user is viewing, provides information on what the recipient has seen and how many emails they have received recently, and gives recipients the opportunity to provide lightweight feedback when they appreciate shared content. FeedMe introduces a novel design space within mixed-initiative social recommenders: friends who know the user\u00a0\u2026", "num_citations": "120\n", "authors": ["1164"]}
{"title": "Learning perceptual kernels for visualization design\n", "abstract": " Visualization design can benefit from careful consideration of perception, as different assignments of visual encoding variables such as color, shape and size affect how viewers interpret data. In this work, we introduce perceptual kernels: distance matrices derived from aggregate perceptual judgments. Perceptual kernels represent perceptual differences between and within visual variables in a reusable form that is directly applicable to visualization evaluation and automated design. We report results from crowd-sourced experiments to estimate kernels for color, shape, size and combinations thereof. We analyze kernels estimated using five different judgment types-including Likert ratings among pairs, ordinal triplet comparisons, and manual spatial arrangement-and compare them to existing perceptual models. We derive recommendations for collecting perceptual similarities, and then demonstrate how the\u00a0\u2026", "num_citations": "117\n", "authors": ["1164"]}
{"title": "Direct answers for search queries in the long tail\n", "abstract": " Web search engines now offer more than ranked results. Queries on topics like weather, definitions, and movies may return inline results called answers that can resolve a searcher's information need without any additional interaction. Despite the usefulness of answers, they are limited to popular needs because each answer type is manually authored. To extend the reach of answers to thousands of new information needs, we introduce Tail Answers: a large collection of direct answers that are unpopular individually, but together address a large proportion of search traffic. These answers cover long-tail needs such as the average body temperature for a dog, substitutes for molasses, and the keyboard shortcut for a right-click. We introduce a combination of search log mining and paid crowdsourcing techniques to create Tail Answers. A user study with 361 participants suggests that Tail Answers significantly improved\u00a0\u2026", "num_citations": "116\n", "authors": ["1164"]}
{"title": "Talkabout: Making distance matter with small groups in massive classes\n", "abstract": " Massive online classes are global and diverse. How can we harness this diversity to improve engagement and learning? Currently, though enrollments are high, students' interactions with each other are minimal: most are alone together. This isolation is particularly disappointing given that a global community is a major draw of online classes. This paper illustrates the potential of leveraging geographic diversity in massive online classes. We connect students from around the world through small-group video discussions. Our peer discussion system, Talkabout, has connected over 5,000 students in fourteen online classes. Three studies with 2,670 students from two classes found that globally diverse discussions boost student performance and engagement: the more geographically diverse the discussion group, the better the students performed on later quizzes. Through this work, we challenge the view that online\u00a0\u2026", "num_citations": "114\n", "authors": ["1164"]}
{"title": "Ensemble: exploring complementary strengths of leaders and crowds in creative collaboration\n", "abstract": " In story writing, the diverse perspectives of the crowd could support an author's search for the perfect character, setting, or plot. However, structuring crowd collaboration is challenging. Too little structure leads to unfocused, sprawling narratives, and too much structure stifles creativity. Motivated by the idea that individual creative leaders and the crowd have complementary creative strengths, we present an approach where a leader directs the high-level vision for a story and articulates creative constraints for the crowd. This approach is embodied in Ensemble, a novel collaborative story-writing platform. In a month-long short story competition, over one hundred volunteer users on the web started over fifty short stories using Ensemble. Leaders used the platform to direct collaborator work by establishing creative goals, and collaborators contributed meaningful, high-level ideas to stories through specific suggestions\u00a0\u2026", "num_citations": "102\n", "authors": ["1164"]}
{"title": "Personalization via friendsourcing\n", "abstract": " When information is known only to friends in a social network, traditional crowdsourcing mechanisms struggle to motivate a large enough user population and to ensure accuracy of the collected information. We thus introduce friendsourcing, a form of crowdsourcing aimed at collecting accurate information available only to a small, socially-connected group of individuals. Our approach to friendsourcing is to design socially enjoyable interactions that produce the desired information as a side effect. We focus our analysis around Collabio, a novel social tagging game that we developed to encourage friends to tag one another within an online social network. Collabio encourages friends, family, and colleagues to generate useful information about each other. We describe the design space of incentives in social tagging games and evaluate our choices by a combination of usage log analysis and survey data. Data\u00a0\u2026", "num_citations": "101\n", "authors": ["1164"]}
{"title": "Examining crowd work and gig work through the historical lens of piecework\n", "abstract": " The internet is empowering the rise of crowd work, gig work, and other forms of on-demand labor. A large and growing body of scholarship has attempted to predict the socio-technical outcomes of this shift, especially addressing three questions: 1) What are the complexity limits of on-demand work?, 2) How far can work be decomposed into smaller microtasks?, and 3) What will work and the place of work look like for workers? In this paper, we look to the historical scholarship on piecework\u2014a similar trend of work decomposition, distribution, and payment that was popular at the turn of the 20th century\u2014to understand how these questions might play out with modern on-demand work. We identify the mechanisms that enabled and limited piecework historically, and identify whether on-demand work faces the same pitfalls or might differentiate itself. This approach introduces theoretical grounding that can help address\u00a0\u2026", "num_citations": "95\n", "authors": ["1164"]}
{"title": "Apparition: Crowdsourced user interfaces that come to life as you sketch them\n", "abstract": " Prototyping allows designers to quickly iterate and gather feedback, but the time it takes to create even a Wizard-of-Oz prototype reduces the utility of the process. In this paper, we introduce crowdsourcing techniques and tools for prototyping interactive systems in the time it takes to describe the idea. Our Apparition system uses paid microtask crowds to make even hard-to-automate functions work immediately, allowing more fluid prototyping of interfaces that contain interactive elements and complex behaviors. As users sketch their interface and describe it aloud in natural language, crowd workers and sketch recognition algorithms translate the input into user interface elements, add animations, and provide Wizard-of-Oz functionality. We discuss how design teams can use our approach to reflect on prototypes or begin user studies within seconds, and how, over time, Apparition prototypes can become fully\u00a0\u2026", "num_citations": "95\n", "authors": ["1164"]}
{"title": "Iris: A conversational agent for complex tasks\n", "abstract": " Today, most conversational agents are limited to simple tasks supported by standalone commands, such as getting directions or scheduling an appointment. To support more complex tasks, agents must be able to generalize from and combine the commands they already understand. This paper presents a new approach to designing conversational agents inspired by linguistic theory, where agents can execute complex requests interactively by combining commands through nested conversations. We demonstrate this approach in Iris, an agent that can perform open-ended data science tasks such as lexical analysis and predictive modeling. To power Iris, we have created a domain-specific language that transforms Python functions into combinable automata and regulates their combinations through a type system. Running a user study to examine the strengths and limitations of our approach, we find that data\u00a0\u2026", "num_citations": "89\n", "authors": ["1164"]}
{"title": "Collabio: a game for annotating people within social networks\n", "abstract": " We present Collabio, a social tagging game within an online social network that encourages friends to tag one another. Collabio's approach of incentivizing members of the social network to generate information about each other produces personalizing information about its users. We report usage log analysis, survey data, and a rating exercise demonstrating that Collabio tags are accurate and augment information that could have been scraped online.", "num_citations": "85\n", "authors": ["1164"]}
{"title": "Embracing error to enable rapid crowdsourcing\n", "abstract": " Microtask crowdsourcing has enabled dataset advances in social science and machine learning, but existing crowdsourcing schemes are too expensive to scale up with the expanding volume of data. To scale and widen the applicability of crowdsourcing, we present a technique that produces extremely rapid judgments for binary and categorical labels. Rather than punishing all errors, which causes workers to proceed slowly and deliberately, our technique speeds up workers' judgments to the point where errors are acceptable and even expected. We demonstrate that it is possible to rectify these errors by randomizing task order and modeling response latency. We evaluate our technique on a breadth of common labeling tasks such as image verification, word similarity, sentiment analysis and topic classification. Where prior work typically achieves a 0.25 x to 1x speedup over fixed majority vote, our approach often\u00a0\u2026", "num_citations": "78\n", "authors": ["1164"]}
{"title": "Human-computer interaction and collective intelligence\n", "abstract": " The field of Human\u2013Computer Interaction (HCI) works to understand and to design interactions between people and machines. Increasingly, human collectives are using technology to gather together and coordinate. This mediation occurs through volunteer and interest-based communities on the Web, through paid online marketplaces, and through mobile devices.The lessons of HCI can therefore be brought to bear on different aspects of collective intelligence. On the one hand, the people in the collective (the crowd) will contribute only if there are proper incentives and if the interface guides them in usable and meaningful ways. On the other, those interested in leveraging the collective need usable ways of coordinating, making sense of, and extracting value from the collective work that is being done, often on their behalf. Ultimately, collective intelligence involves the co-design of technical infrastructure and human\u2013human interaction: a socio-technical system. In crowdsourcing, we might differentiate between two broad classes of users: requesters and crowd members. The requesters are the individuals (or the group) for whom work is done or who take responsibility for aggregating the work done by the collective. The crowd member (or crowd worker) is one of many people who contribute. Although we often use the word \u201cworker,\u201d crowd workers do not have to be (and often aren\u2019t) contributing as part of what we might consider standard work. They may or may be paid, they may work only for short periods of time or spend days contributing to a project they care about, and they may work in such a way that each individual\u2019s contribution may be\u00a0\u2026", "num_citations": "78\n", "authors": ["1164"]}
{"title": "Street-level algorithms: A theory at the gaps between policy and decisions\n", "abstract": " Errors and biases are earning algorithms increasingly malignant reputations in society. A central challenge is that algorithms must bridge the gap between high-level policy and on-the-ground decisions, making inferences in novel situations where the policy or training data do not readily apply. In this paper, we draw on the theory of street-level bureaucracies, how human bureaucrats such as police and judges interpret policy to make on-the-ground decisions. We present by analogy a theory of street-level algorithms, the algorithms that bridge the gaps between policy and decisions about people in a socio-technical system. We argue that unlike street-level bureaucrats, who reflexively refine their decision criteria as they reason through a novel situation, street-level algorithms at best refine their criteria only after the decision is made. This loop-and-a-half delay results in illogical decisions when handling new or\u00a0\u2026", "num_citations": "75\n", "authors": ["1164"]}
{"title": "Atelier: Repurposing Expert Crowdsourcing Tasks as Micro-internships\n", "abstract": " Expert crowdsourcing marketplaces have untapped potential to empower workers' career and skill development. Currently, many workers cannot afford to invest the time and sacrifice the earnings required to learn a new skill, and a lack of experience makes it difficult to get job offers even if they do. In this paper, we seek to lower the threshold to skill development by repurposing existing tasks on the marketplace as mentored, paid, real-world work experiences, which we refer to as micro-internships. We instantiate this idea in Atelier, a micro-internship platform that connects crowd interns with crowd mentors. Atelier guides mentor-intern pairs to break down expert crowdsourcing tasks into milestones, review intermediate output, and problem-solve together. We conducted a field experiment comparing Atelier's mentorship model to a non-mentored alternative on a real-world programming crowdsourcing task, finding\u00a0\u2026", "num_citations": "74\n", "authors": ["1164"]}
{"title": "Mechanical novel: Crowdsourcing complex work through reflection and revision\n", "abstract": " Crowdsourcing systems accomplish large tasks with scale and speed by breaking work down into independent parts. However, many types of complex creative work, such as fiction writing, have remained out of reach for crowds because work is tightly interdependent: changing one part of a story may trigger changes to the overall plot and vice versa. Taking inspiration from how expert authors write, we propose a technique for achieving interdependent complex goals with crowds. With this technique, the crowd loops between reflection, to select a high-level goal, and revision, to decompose that goal into low-level, actionable tasks. We embody this approach in Mechanical Novel, a system that crowdsources short fiction stories on Amazon Mechanical Turk. In a field experiment, Mechanical Novel resulted in higher-quality stories than an iterative crowdsourcing workflow. Our findings suggest that orienting crowd work\u00a0\u2026", "num_citations": "70\n", "authors": ["1164"]}
{"title": "Measuring crowdsourcing effort with error-time curves\n", "abstract": " Crowdsourcing systems lack effective measures of the effort required to complete each task. Without knowing how much time workers need to execute a task well, requesters struggle to accurately structure and price their work. Objective measures of effort could better help workers identify tasks that are worth their time. We propose a data-driven effort metric, ETA (error-time area), that can be used to determine a task's fair price. It empirically models the relationship between time and error rate by manipulating the time that workers have to complete a task. ETA reports the area under the error-time curve as a continuous metric of worker effort. The curve's 10th percentile is also interpretable as the minimum time most workers require to complete the task without error, which can be used to price the task. We validate the ETA metric on ten common crowdsourcing tasks, including tagging, transcription, and search, and find\u00a0\u2026", "num_citations": "70\n", "authors": ["1164"]}
{"title": "Referring relationships\n", "abstract": " Images are not simply sets of objects: each image represents a web of interconnected relationships. These relationships between entities carry semantic meaning and help a viewer differentiate between instances of an entity. For example, in an image of a soccer match, there may be multiple persons present, but each participates in different relationships: one is kicking the ball, and the other is guarding the goal. In this paper, we formulate the task of utilizing these\" referring relationships\" to disambiguate between entities of the same category. We introduce an iterative model that localizes the two entities in the referring relationship, conditioned on one another. We formulate the cyclic condition between the entities in a relationship by modelling predicates that connect the entities as shifts in attention from one entity to another. We demonstrate that our model can not only outperform existing approaches on three datasets---CLEVR, VRD and Visual Genome---but also that it produces visually meaningful predicate shifts, as an instance of interpretable neural networks. Finally, we show that by modelling predicates as attention shifts, we can even localize entities in the absence of their category, allowing our model to find completely unseen categories.", "num_citations": "66\n", "authors": ["1164"]}
{"title": "No workflow can ever be enough: How crowdsourcing workflows constrain complex work\n", "abstract": " The dominant crowdsourcing infrastructure today is the workflow, which decomposes goals into small independent tasks. However, complex goals such as design and engineering have remained stubbornly difficult to achieve with crowdsourcing workflows. Is this due to a lack of imagination, or a more fundamental limit? This paper explores this question through in-depth case studies of 22 workers across six workflow-based crowd teams, each pursuing a complex and interdependent web development goal. We used an inductive mixed method approach to analyze behavior trace data, chat logs, survey responses and work artifacts to understand how workers enacted and adapted the crowdsourcing workflows. Our results indicate that workflows served as useful coordination artifacts, but in many cases critically inhibited crowd workers from pursuing real-time adaptations to their work plans. However, the CSCW and\u00a0\u2026", "num_citations": "64\n", "authors": ["1164"]}
{"title": "On the opportunities and risks of foundation models\n", "abstract": " AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.", "num_citations": "63\n", "authors": ["1164"]}
{"title": "Scaling short-answer grading by combining peer assessment with algorithmic scoring\n", "abstract": " Peer assessment helps students reflect and exposes them to different ideas. It scales assessment and allows large online classes to use open-ended assignments. However, it requires students to spend significant time grading. How can we lower this grading burden while maintaining quality? This paper integrates peer and machine grading to preserve the robustness of peer assessment and lower grading burden. In the identify-verify pattern, a grading algorithm first predicts a student grade and estimates confidence, which is used to estimate the number of peer raters required. Peers then identify key features of the answer using a rubric. Finally, other peers verify whether these feature labels were accurately applied. This pattern adjusts the number of peers that evaluate an answer based on algorithmic confidence and peer agreement. We evaluated this pattern with 1370 students in a large, online design class\u00a0\u2026", "num_citations": "59\n", "authors": ["1164"]}
{"title": "Scene graph prediction with limited labels\n", "abstract": " Visual knowledge bases such as Visual Genome power numerous applications in computer vision, including visual question answering and captioning, but suffer from sparse, incomplete relationships. All scene graph models to date are limited to training on a small set of visual relationships that have thousands of training labels each. Hiring human annotators is expensive, and using textual knowledge base completion methods are incompatible with visual data. In this paper, we introduce a semi-supervised method that assigns probabilistic relationship labels to a large number of unlabeled images using few labeled examples. We analyze visual relationships to suggest two types of image-agnostic features that are used to generate noisy heuristics, whose outputs are aggregated using a factor graph-based generative model. With as few as 10 labeled examples per relationship, the generative model creates enough training data to train any existing state-of-the-art scene graph model. We demonstrate that our method outperforms all baseline approaches on scene graph prediction by5. 16 recall@ 100 for PREDCLS. In our limited label setting, we define a complexity metric for relationships that serves as an indicator (R^ 2= 0.778) for conditions under which our method succeeds over transfer learning, the de-facto approach for training with limited labels.", "num_citations": "54\n", "authors": ["1164"]}
{"title": "Huddler: Convening Stable and Familiar Crowd Teams Despite Unpredictable Availability\n", "abstract": " Distributed, parallel crowd workers can accomplish simple tasks through workflows, but teams of collaborating crowd workers are necessary for complex goals. Unfortunately, a fundamental condition for effective teams--familiarity with other members--stands in contrast to crowd work's flexible, on-demand nature. We enable effective crowd teams with Huddler, a system for workers to assemble familiar teams even under unpredictable availability and strict time constraints. Huddler utilizes a dynamic programming algorithm to optimize for highly familiar teammates when individual availability is unknown. We first present a field experiment that demonstrates the value of familiarity for crowd teams: familiar crowd teams doubled the performance of ad-hoc (unfamiliar) teams on a collaborative task. We then report a two-week field deployment wherein Huddler enabled crowd workers to convene highly familiar teams in 18\u00a0\u2026", "num_citations": "52\n", "authors": ["1164"]}
{"title": "Structure and messaging techniques for online peer learning systems that increase stickiness\n", "abstract": " When students work with peers, they learn more actively, build richer knowledge structures, and connect material to their lives. However, not every peer learning experience online sees successful adoption. This paper articulates and addresses three adoption challenges for global-scale peer learning. First, peer interactions struggle to bootstrap critical mass. However, class incentives can signal importance and spur initial usage. Second, online classes have limited peer visibility and awareness, so students often feel alone even when surrounded by peers. We find that highlighting interdependence and strengthening norms can mitigate this issue. Third, teachers can readily access\" big\" aggregate data but not\" thick\" contextual data that helps build intuitions, so software should guide teachers' scaffolding of peer interactions. We illustrate these challenges through studying 8,500 students' usage of two peer learning\u00a0\u2026", "num_citations": "52\n", "authors": ["1164"]}
{"title": "Fair work: Crowd work minimum wage with one line of code\n", "abstract": " Accurate task pricing in microtask marketplaces requires substantial effort via trial and error, contributing to a pattern of worker underpayment. In response, we introduce Fair Work, enabling requesters to automatically pay their workers minimum wage by adding a one-line script tag to their task HTML on Amazon Mechanical Turk. Fair Work automatically surveys workers to find out how long the task takes, then aggregates those self-reports and auto-bonuses workers up to a minimum wage if needed. Evaluations demonstrate that the system estimates payments more accurately than requesters and that worker time surveys are close to behaviorally observed time measurements. With this work, we aim to lower the threshold for pro-social work practices in microtask marketplaces.", "num_citations": "51\n", "authors": ["1164"]}
{"title": "Shirtless and Dangerous: Quantifying Linguistic Signals of Gender Bias in an Online Fiction Writing Community\n", "abstract": " Imagine a princess asleep in a castle, waiting for her prince to slay the dragon and rescue her. Tales like the famous Sleeping Beauty clearly divide up gender roles. But what about more modern stories, borne of a generation increasingly aware of social constructs like sexism and racism? Do these stories tend to reinforce gender stereotypes, or counter them? In this paper, we present a technique that combines natural language processing with a crowdsourced lexicon of stereotypes to capture gender biases in fiction. We apply this technique across 1.8 billion words of fiction from the Wattpad online writing community, investigating gender representation in stories, how male and female characters behave and are described, and how authors' use of gender stereotypes is associated with the community's ratings. We find that male over-representation and traditional gender stereotypes (eg, dominant men and submissive women) are common throughout nearly every genre in our corpus. However, only some of these stereotypes, like sexual or violent men, are associated with highly rated stories. Finally, despite women often being the target of negative stereotypes, female authors are equally likely to write such stereotypes as men.", "num_citations": "51\n", "authors": ["1164"]}
{"title": "Note to self: examining personal information keeping in a lightweight note-taking tool\n", "abstract": " This paper describes a longitudinal field experiment in personal note-taking that examines how people capture and use information in short textual notes. Study participants used our tool, a simple browser-based textual note-taking utility, to capture personal information over the course of ten days. We examined the information they kept in notes using the tool, how this information was expressed, and aspects of note creation, editing, deletion, and search. We found that notes were recorded extremely quickly and tersely, combined information of multiple types, and were rarely revised or deleted. The results of the study demonstrate the need for a tool such as ours to support the rapid capture and retrieval of short notes-to-self, and afford insights into how users' actual note-keeping tendencies could be used to better support their needs in future PIM tools.", "num_citations": "50\n", "authors": ["1164"]}
{"title": "Hype: A benchmark for human eye perceptual evaluation of generative models\n", "abstract": " Generative models often use human evaluations to measure the perceived quality of their outputs. Automated metrics are noisy indirect proxies, because they rely on heuristics or pretrained embeddings. However, up until now, direct human evaluation strategies have been ad-hoc, neither standardized nor validated. Our work establishes a gold standard human benchmark for generative realism. We construct Human eYe Perceptual Evaluation (HYPE) a human benchmark that is (1) grounded in psychophysics research in perception,(2) reliable across different sets of randomly sampled outputs from a model,(3) able to produce separable model performances, and (4) efficient in cost and time. We introduce two variants: one that measures visual perception under adaptive time constraints to determine the threshold at which a model's outputs appear real (eg  ms), and the other a less expensive variant that measures human error rate on fake and real images sans time constraints. We test HYPE across six state-of-the-art generative adversarial networks and two sampling techniques on conditional and unconditional image generation using four datasets: CelebA, FFHQ, CIFAR-10, and ImageNet. We find that HYPE can track model improvements across training epochs, and we confirm via bootstrap sampling that HYPE rankings are consistent and replicable.", "num_citations": "49\n", "authors": ["1164"]}
{"title": "Daemo: A self-governed crowdsourcing marketplace\n", "abstract": " Crowdsourcing marketplaces provide opportunities for autonomous and collaborative professional work as well as social engagement. However, in these marketplaces, workers feel disrespected due to unreasonable rejections and low payments, whereas requesters do not trust the results they receive. The lack of trust and uneven distribution of power among workers and requesters have raised serious concerns about sustainability of these marketplaces. To address the challenges of trust and power, this paper introduces Daemo, a self-governed crowdsourcing marketplace. We propose a prototype task to improve the work quality and open-governance model to achieve equitable representation. We envisage Daemo will enable workers to build sustainable careers and provide requesters with timely, quality labor for their businesses.", "num_citations": "46\n", "authors": ["1164"]}
{"title": "d. tools: Visually prototyping physical UIs through statecharts\n", "abstract": " Processor enabled products, each with its own user interface, have pervaded everyday life. To facilitate interaction design exploration for novel devices, we have developed d. tools, a design tool for prototyping the bits and the atoms of physical user interfaces in concert. It enables designers without specialized engineering or programming knowledge to quickly build functional interactive prototypes. d. tools offers a visual authoring environment that allows for drag-and-drop specification of interaction models for tangible user interfaces in a matter of minutes.", "num_citations": "46\n", "authors": ["1164"]}
{"title": "Crowd guilds: Worker-led reputation and feedback on crowdsourcing platforms\n", "abstract": " Crowd workers are distributed and decentralized. While decentralization is designed to utilize independent judgment to promote high-quality results, it paradoxically undercuts behaviors and institutions that are critical to high-quality work. Reputation is one central example: crowdsourcing systems depend on reputation scores from decentralized workers and requesters, but these scores are notoriously inflated and uninformative. In this paper, we draw inspiration from historical worker guilds (eg, in the silk trade) to design and implement crowd guilds: centralized groups of crowd workers who collectively certify each other's quality through double-blind peer assessment. A two-week field experiment compared crowd guilds to a traditional decentralized crowd work model. Crowd guilds produced reputation signals more strongly correlated with ground-truth worker quality than signals available on current crowd working\u00a0\u2026", "num_citations": "45\n", "authors": ["1164"]}
{"title": "Boomerang: Rebounding the consequences of reputation feedback on crowdsourcing platforms\n", "abstract": " Paid crowdsourcing platforms suffer from low-quality work and unfair rejections, but paradoxically, most workers and requesters have high reputation scores. These inflated scores, which make high-quality work and workers difficult to find, stem from social pressure to avoid giving negative feedback. We introduce Boomerang, a reputation system for crowdsourcing platforms that elicits more accurate feedback by rebounding the consequences of feedback directly back onto the person who gave it. With Boomerang, requesters find that their highly-rated workers gain earliest access to their future tasks, and workers find tasks from their highly-rated requesters at the top of their task feed. Field experiments verify that Boomerang causes both workers and requesters to provide feedback that is more closely aligned with their private opinions. Inspired by a game-theoretic notion of incentive-compatibility, Boomerang opens\u00a0\u2026", "num_citations": "45\n", "authors": ["1164"]}
{"title": "Anyone can become a troll\n", "abstract": " \" Fail at life. Go bomb yourself.\" Comments such as this one, found attached to a CNN article about how women perceive themselves, are prevalent today across the Internet, whether the location is Facebook, Reddit, or a news Web site. Such commenting behavior can range from profanity and name-calling to personal attacks, sexual harassment, or hate speech. A recent Pew Internet Survey found that 4 out of 10 people online have been harassed on the Internet, with far more having witnessed such behavior. Trolling has become so rampant that several Web sites have even resorted to completely removing comments. Many believe that trolling is solely done by a small, vocal minority of sociopathic individuals. This belief has been reinforced not only in the media, but also in past research on trolling, which focused on interviewing these individuals. Some studies even showed that trolls have predisposing personal\u00a0\u2026", "num_citations": "44\n", "authors": ["1164"]}
{"title": "EmailValet: Managing email overload through private, accountable crowdsourcing\n", "abstract": " This paper introduces privacy and accountability techniques for crowd-powered systems. We focus on email task management: tasks are an implicit part of every inbox, but the overwhelming volume of incoming email can bury important requests. We present EmailValet, an email client that recruits remote assistants from an expert crowdsourcing marketplace. By annotating each email with its implicit tasks, EmailValet's assistants create a task list that is automatically populated from emails in the user's inbox. The system is an example of a valet approach to crowdsourcing, which aims for parsimony and transparency in access con-trol for the crowd. To maintain privacy, users specify rules that define a sliding-window subset of their inbox that they are willing to share with assistants. To support accountability, EmailValet displays the actions that the assistant has taken on each email. In a weeklong field study, participants\u00a0\u2026", "num_citations": "44\n", "authors": ["1164"]}
{"title": "Information maximizing visual question generation\n", "abstract": " Though image-to-sequence generation models have become overwhelmingly popular in human-computer communications, they suffer from strongly favoring safe generic questions (\" What is in this picture?\"). Generating uninformative but relevant questions is not sufficient or useful. We argue that a good question is one that has a tightly focused purpose---one that is aimed at expecting a specific type of response. We build a model that maximizes mutual information between the image, the expected answer and the generated question. To overcome the non-differentiability of discrete natural language tokens, we introduce a variational continuous latent space onto which the expected answers project. We regularize this latent space with a second latent space that ensures clustering of similar answers. Even when we don't know the expected answer, this second latent space can generate goal-driven questions specifically aimed at extracting objects (\" what is the person throwing\"), attributes,(\" What kind of shirt is the person wearing?\"), color (\" what color is the frisbee?\"), material (\" What material is the frisbee?\"), etc. We quantitatively show that our model is able to retain information about an expected answer category, resulting in more diverse, goal-driven questions. We launch our model on a set of real world images and extract previously unseen visual concepts.", "num_citations": "43\n", "authors": ["1164"]}
{"title": "Emergent, crowd-scale programming practice in the IDE\n", "abstract": " While emergent behaviors are uncodified across many domains such as programming and writing, interfaces need explicit rules to support users. We hypothesize that by codifying emergent programming behavior, software engineering interfaces can support a far broader set of developer needs. To explore this idea, we built Codex, a knowledge base that records common practice for the Ruby programming language by indexing over three million lines of popular code. Codex enables new data-driven interfaces for programming systems: statistical linting, identifying code that is unlikely to occur in practice and may constitute a bug; pattern annotation, automatically discovering common programming idioms and annotating them with metadata using expert crowdsourcing; and library generation, constructing a utility package that encapsulates and reflects emergent software practice. We evaluate these applications to\u00a0\u2026", "num_citations": "43\n", "authors": ["1164"]}
{"title": "Visual genome: Connecting language and vision using crowdsourced dense image annotations. 2016\n", "abstract": " Despite progress in perceptual tasks such as image classification, computers still perform poorly on cognitive tasks such as image description and question answering. Cognition is core to tasks that involve not just recognizing, but reasoning about our visual world. However, models used to tackle the rich content in images for cognitive tasks are still being trained using the same datasets designed for perceptual tasks. To achieve success at cognitive tasks, models need to understand the interactions and relationships between objects in an", "num_citations": "43\n", "authors": ["1164"]}
{"title": "Catalyst: triggering collective action with thresholds\n", "abstract": " The web is a catalyst for drawing people together around shared goals, but many groups never reach critical mass. It can thus be risky to commit time or effort to a goal: participants show up only to discover that nobody else did, and organizers devote significant effort to causes that never get off the ground. Crowdfunding has lessened some of this risk by only calling in donations when an effort reaches a collective monetary goal. However, it leaves unsolved the harder problem of mobilizing effort, time and participation. We generalize the concept into activation thresholds, commitments that are conditioned on others' participation. With activation thresholds, supporters only need to show up for an event if enough other people commit as well. Catalyst is a platform that introduces activation thresholds for on-demand events. For more complex coordination needs, Catalyst also provides thresholds based on time or role\u00a0\u2026", "num_citations": "38\n", "authors": ["1164"]}
{"title": "A glimpse far into the future: Understanding long-term crowd worker quality\n", "abstract": " Microtask crowdsourcing is increasingly critical to the creation of extremely large datasets. As a result, crowd workers spend weeks or months repeating the exact same tasks, making it necessary to understand their behavior over these long periods of time. We utilize three large, longitudinal datasets of nine million annotations collected from Amazon Mechanical Turk to examine claims that workers fatigue or satisfice over these long periods, producing lower quality work. We find that, contrary to these claims, workers are extremely stable in their quality over the entire period. To understand whether workers set their quality based on the task's requirements for acceptance, we then perform an experiment where we vary the required quality for a large crowdsourcing task. Workers did not adjust their quality based on the acceptance threshold: workers who were above the threshold continued working at their usual quality\u00a0\u2026", "num_citations": "37\n", "authors": ["1164"]}
{"title": "In search of the dream team: Temporally constrained multi-armed bandits for identifying effective team structures\n", "abstract": " Team structures---roles, norms, and interaction patterns---define how teams work. HCI researchers have theorized ideal team structures and built systems nudging teams towards them, such as those increasing turn-taking, deliberation, and knowledge distribution. However, organizational behavior research argues against the existence of universally ideal structures. Teams are diverse and excel under different structures: while one team might flourish under hierarchical leadership and a critical culture, another will flounder. In this paper, we present DreamTeam: a system that explores a large space of possible team structures to identify effective structures for each team based on observable feedback. To avoid overwhelming teams with too many changes, DreamTeam introduces multi-armed bandits with temporal constraints: an algorithm that manages the timing of exploration--exploitation trade-offs across multiple\u00a0\u2026", "num_citations": "36\n", "authors": ["1164"]}
{"title": "Mosaic: designing online creative communities for sharing works-in-progress\n", "abstract": " Online creative communities allow creators to share their work with a large audience, maximizing opportunities to showcase their work and connect with fans and peers. However, sharing in-progress work can be technically and socially challenging in environments designed for sharing completed pieces. We propose an online creative community where sharing process, rather than showcasing outcomes, is the main method of sharing creative work. Based on this, we present Mosaic---an online community where illustrators share work-in-progress snapshots showing how an artwork was completed from start to finish. In an online deployment and observational study, artists used Mosaic as a vehicle for reflecting on how they can improve their own creative process, developed a social norm of detailed feedback, and became less apprehensive of sharing early versions of artwork. Through Mosaic, we argue that\u00a0\u2026", "num_citations": "36\n", "authors": ["1164"]}
{"title": "Motif: Supporting novice creativity through expert patterns\n", "abstract": " Creating personal narratives helps people build meaning around their experiences. However, novices lack the knowledge and experience to create stories with strong narrative structure. Current storytelling tools often structure novice work through templates, enforcing a linear creative process that asks novices for materials they may not have. In this paper, we propose scaffolding creative work using storytelling patterns extracted from stories created by experts. Patterns are modular sets of related camera shots that expert videographers commonly use to achieve a specific narrative function. After identifying a set of patterns from high-quality storytelling videos, we created Motif, a mobile video storytelling application that allows users to construct video stories by combining these patterns. By making existing solutions used by experts available to novices, we encourage capturing shots with story structure and narrative\u00a0\u2026", "num_citations": "36\n", "authors": ["1164"]}
{"title": "Crowd-powered systems\n", "abstract": " Crowd-powered systems combine computation with human intelligence, drawn from large groups of people connecting and coordinating online. These hybrid systems enable applications and experiences that neither crowds nor computation could support alone.               Unfortunately, crowd work is error-prone and slow, making it difficult to incorporate crowds as first-order building blocks in software. We introduce computational techniques that decompose complex tasks into simpler, verifiable steps to improve quality, and optimize work to return results in seconds. Using these techniques, we prototype a set of interactive crowd-powered systems. The first, Soylent, is a word processor that uses paid micro-contributions to aid writing tasks such as text shortening and proofreading. Using Soylent is like having access to an entire editorial staff as you write. The second system, Adrenaline, is a camera that uses\u00a0\u2026", "num_citations": "36\n", "authors": ["1164"]}
{"title": "Visual relationships as functions: Enabling few-shot scene graph prediction\n", "abstract": " Scene graph prediction--classifying the set of objects and predicates in a visual scene--requires substantial training data. The long-tailed distribution of relationships can be an obstacle for such approaches, however, as they can only be trained on the small set of predicates that carry sufficient labels. We introduce the first scene graph prediction model that supports few-shot learning of predicates, enabling scene graph approaches to generalize to a set of new predicates. First, we introduce a new model of predicates as functions that operate on object features or image locations. Next, we define a scene graph model where these functions are trained as message passing protocols within a new graph convolution framework. We train the framework with a frequently occurring set of predicates and show that our approach outperforms those that use the same amount of supervision by 1.78 at recall@ 50 and performs on par with other scene graph models. Next, we extract object representations generated by the trained predicate functions to train few-shot predicate classifiers on rare predicates with as few as 1 labeled example. When compared to strong baselines like transfer learning from existing state-of-the-art representations, we show improved 5-shot performance by 4.16 recall@ 1. Finally, we show that our predicate functions generate interpretable visualizations, enabling the first interpretable scene graph model.", "num_citations": "34\n", "authors": ["1164"]}
{"title": "Hive: Collective design through network rotation\n", "abstract": " Collectives gather online around challenges they face, but frequently fail to envision shared outcomes to act on together. Prior work has developed systems for improving collective ideation and design by exposing people to each others' ideas and encouraging them to intermix those ideas. However, organizational behavior research has demonstrated that intermixing ideas does not result in meaningful engagement with those ideas. In this paper, we introduce a new class of collective design system that intermixes people instead of ideas: instead of receiving mere exposure to others' ideas, participants engage deeply with other members of the collective who represent those ideas, increasing engagement and influence. We thus present Hive: a system that organizes a collective into small teams, then intermixes people by rotating team membership over time. At a technical level, Hive must balance two competing\u00a0\u2026", "num_citations": "33\n", "authors": ["1164"]}
{"title": "Augur: Mining human behaviors from fiction to power interactive systems\n", "abstract": " From smart homes that prepare coffee when we wake, to phones that know not to interrupt us during important conversations, our collective visions of HCI imagine a future in which computers understand a broad range of human behaviors. Today our systems fall short of these visions, however, because this range of behaviors is too large for designers or programmers to capture manually. In this paper, we instead demonstrate it is possible to mine a broad knowledge base of human behavior by analyzing more than one billion words of modern fiction. Our resulting knowledge base, Augur, trains vector models that can predict many thousands of user activities from surrounding objects in modern contexts: for example, whether a user may be eating food, meeting with a friend, or taking a selfie. Augur uses these predictions to identify actions that people commonly take on objects in the world and estimate a user's future\u00a0\u2026", "num_citations": "33\n", "authors": ["1164"]}
{"title": "Pay it backward: Per-task payments on crowdsourcing platforms reduce productivity\n", "abstract": " Paid crowdsourcing marketplaces have gained popularity by using piecework, or payment for each microtask, to incentivize workers. This norm has remained relatively unchallenged. In this paper, we ask: is the pay-per-task method the right one? We draw on behavioral economic research to examine whether payment in bulk after every ten tasks, saving money via coupons instead of earning money, or material goods rather than money will increase the number of completed tasks. We perform a twenty-day, between-subjects field experiment (N= 300) on a mobile crowdsourcing application and measure how often workers responded to a task notification to fill out a short survey under each incentive condition. Task completion rates increased when paying in bulk after ten tasks: doing so increased the odds of a response by 1.4 x, translating into 8% more tasks through that single intervention. Payment with coupons\u00a0\u2026", "num_citations": "33\n", "authors": ["1164"]}
{"title": "Context trees: Crowdsourcing global understanding from local views\n", "abstract": " Crowdsourcing struggles when workers must see all of the pieces of input to make an accurate judgment. For example, to find the most important scenes in a novel or movie, each worker must spend hours consuming the entire plot to acquire a global understanding and then apply that understanding to each local scene. To enable the crowdsourcing of large-scale goals with only local views, we introduce context trees, a crowdsourcing workflow for creating global summaries of a large input. Context trees recursively combine elements through written summaries to form a tree. Workers can then ground their local decisions by applying those summaries back down to the leaf nodes. In the case of scale ratings such as scene importance, we introduce a weighting process that percolates ratings downwards through the tree so that important nodes in unimportant branches are not overweighted. When using context trees to rate the importance of scenes in a 4000-word story and a 100-minute movie, workers\u2019 ratings are nearly as accurate as those who saw the entire input, and much improved over the traditional approach of splitting the input into independent segments. To explore whether context trees enable crowdsourcing to undertake new classes of goals, we also crowdsource the solution to a large hierarchical puzzle of 462,000 interlocking pieces.", "num_citations": "33\n", "authors": ["1164"]}
{"title": "Taskpos\u00e9: exploring fluid boundaries in an associative window visualization\n", "abstract": " Window management research has aimed to leverage users' tasks to organize the growing number of open windows in a useful manner. This research has largely assumed task classifications to be binary--either a window is in a task, or not--and context-independent. We suggest that the continual evolution of tasks can invalidate this approach and instead propose a fuzzy association model in which windows are related to one another by varying degrees. Task groupings are an emergent property of our approach. To support the association model, we introduce the WindowRank algorithm and its use in determining window association. We then describe Taskpos\u00e9, a prototype window switch visualization embodying these ideas, and report on a week-long user study of the system.", "num_citations": "33\n", "authors": ["1164"]}
{"title": "Talkabout: small-group discussions in massive global classes\n", "abstract": " In the physical classroom, peer interactions motivate students and expand their perspective. We suggest that synchronous peer interaction can benefit massive online courses as well. Talkabout organizes students into video discussion groups and allows instructors to determine group composition and discussion content. Using Talkabout, students pick a discussion time that suits their schedule. The system groups the students into small video discussions based on instructor preferences such as gender or geographic balance. To date, 2,474 students in five massive online courses have used Talkabout to discuss topics ranging from prejudice to organizational theory. Talkabout discussions are diverse: in one course, the median six-person discussion group had students from four different countries. Students enjoyed discussing in these diverse groups: the average student participated for 66 minutes, twice the course\u00a0\u2026", "num_citations": "30\n", "authors": ["1164"]}
{"title": "Gui---phooey! the case for text input\n", "abstract": " Information cannot be found if it is not recorded. Existing rich graphical application approaches interfere with user input in many ways, forcing complex interactions to enter simple information, requiring complex cognition to decide where the data should be stored, and limiting the kind of information that can be entered to what can fit into specific applications' data models. Freeform text entry suffers from none of these limitations but produces data that is hard to retrieve or visualize. We describe the design and implementation of Jourknow, a system that aims to bridge these two modalities, supporting lightweight text entry and weightless context capture that produces enough structure to support rich interactive presentation and retrieval of the arbitrary information entered.", "num_citations": "30\n", "authors": ["1164"]}
{"title": "Rotating online behavior change interventions increases effectiveness but also increases attrition\n", "abstract": " Behavior change systems help people manage their time online and achieve many other goals. These systems typically consist of a single static intervention, such as a timer or site blocker, to persuade users to behave in ways consistent with their stated goals. However, static interventions decline in effectiveness over time as users begin to ignore them. In this paper, we compare the effectiveness of static interventions to a rotation strategy, where users experience different interventions over time. We built and deployed a browser extension called HabitLab, which features many interventions that the user can enable across social media and other web sites to control their time spent browsing. We ran three in-the-wild field experiments on HabitLab to compare static interventions to rotated interventions. We found that rotating between interventions increased effectiveness as measured by time on site, but also\u00a0\u2026", "num_citations": "28\n", "authors": ["1164"]}
{"title": "Better when it was smaller? community content and behavior after massive growth\n", "abstract": " Online communities have a love-hate relationship with membership growth: new members bring fresh perspectives, but old-timers worry that growth interrupts the community\u2019s social dynamic and lowers content quality. To arbitrate these two theories, we analyze over 45 million comments from 10 Reddit subcommunities following an exogenous shock when each subcommunity was added to the default set for all Reddit users. Capitalizing on these natural experiments, we test for changes to the content vote patterns, linguistic patterns, and community network patterns before and after being defaulted. Results support a narrative that the communities remain high-quality and similar to their previous selves even post-growth. There is a temporary dip in upvote scores right after the communities were defaulted, but the communities quickly recover to pre-default or even higher levels. Likewise, complaints about low-quality posts do not rise in frequency after getting defaulted. Strong moderation also helps keep upvotes common and complaint levels low. Communities\u2019 language use does not become more like the rest of Reddit after getting defaulted. However, growth does have some impact on attention: community members cluster their activity around a smaller proportion of posts after the community is defaulted.", "num_citations": "27\n", "authors": ["1164"]}
{"title": "Crowd-scale interactive formal reasoning and analytics\n", "abstract": " Large online courses often assign problems that are easy to grade because they have a fixed set of solutions (such as multiple choice), but grading and guiding students is more difficult in problem domains that have an unbounded number of correct answers. One such domain is derivations: sequences of logical steps commonly used in assignments for technical, mathematical and scientific subjects. We present DeduceIt, a system for creating, grading, and analyzing derivation assignments in any formal domain. DeduceIt supports assignments in any logical formalism, provides students with incremental feedback, and aggregates student paths through each proof to produce instructor analytics. DeduceIt benefits from checking thousands of derivations on the web: it introduces a proof cache, a novel data structure which leverages a crowd of students to decrease the cost of checking derivations and providing real\u00a0\u2026", "num_citations": "23\n", "authors": ["1164"]}
{"title": "d. tools: Integrated prototyping for physical interaction design\n", "abstract": " Figure 1. d. tools enables designers to rapidly prototype the circuits and code of information appliances using pictures and parts.Designers tasked with imagining future information appliances currently employ separate tools for rapidly prototyping the form (the atoms) and the interaction model (the bits) because integrated prototyping of bits and atoms requires resources and knowledge outside the reach of design generalists. Based on interviews with product designers, we created d. tools, a system enabling non-programmers to prototype the bits and the atoms of physical user interfaces in concert. d. tools lowers the threshold to prototyping functional physical interfaces through plug-and-play hardware that is closely coupled with a visual authoring environment. We evaluated the d. tools use threshold through a first-use study with thirteen participants; the study showed that the tool is accessible and encourages reflective design practice. We tested the d. tools range of design support by recreating existing research and commercial devices; this demonstrated that the visual language was sufficiently expressive for existing and emerging real-world designs.", "num_citations": "22\n", "authors": ["1164"]}
{"title": "Crowd research: Open and scalable university laboratories\n", "abstract": " Research experiences today are limited to a privileged few at select universities. Providing open access to research experiences would enable global upward mobility and increased diversity in the scientific workforce. How can we coordinate a crowd of diverse volunteers on open-ended research? How could a PI have enough visibility into each person's contributions to recommend them for further study? We present Crowd Research, a crowdsourcing technique that coordinates open-ended research through an iterative cycle of open contribution, synchronous collaboration, and peer assessment. To aid upward mobility and recognize contributions in publications, we introduce a decentralized credit system: participants allocate credits to each other, which a graph centrality algorithm translates into a collectively-created author order. Over 1,500 people from 62 countries have participated, 74% from institutions with\u00a0\u2026", "num_citations": "21\n", "authors": ["1164"]}
{"title": "Conceptual metaphors impact perceptions of human-ai collaboration\n", "abstract": " With the emergence of conversational artificial intelligence (AI) agents, it is important to understand the mechanisms that influence users' experiences of these agents. In this paper, we study one of the most common tools in the designer's toolkit: conceptual metaphors. Metaphors can present an agent as akin to a wry teenager, a toddler, or an experienced butler. How might a choice of metaphor influence our experience of the AI agent? Sampling a set of metaphors along the dimensions of warmth and competence---defined by psychological theories as the primary axes of variation for human social perception---we perform a study  where we manipulate the metaphor, but not the behavior, of a Wizard-of-Oz conversational agent. Following the experience, participants are surveyed about their intention to use the agent, their desire to cooperate with the agent, and the agent's usability. Contrary to the current\u00a0\u2026", "num_citations": "20\n", "authors": ["1164"]}
{"title": "Micro-volunteering: helping the helpers in development\n", "abstract": " Finding and retaining volunteers is a challenge for most of the NGOs (non-government-organizations) or non-profit organizations worldwide. Quite often, volunteers have a desire to help but are hesitant in making time commitments due to busy lives or demanding schedules. Micro-volunteering or crowdsourced volunteering has taken off in the last few years where a task is divided into fragments and accomplished collectively by the crowd. Individuals are only required to work on small chunks of tasks during their bits of short free times during the day. This panel brings in an interesting mix of researchers from the crowdsourcing/development space and social entrepreneurs to discuss the pros and cons of micro-volunteering for non-profits and identify the missing blocks in enabling us to replicate this concept in developing regions worldwide.", "num_citations": "20\n", "authors": ["1164"]}
{"title": "PolicyKit: building governance in online communities\n", "abstract": " The software behind online community platforms encodes a governance model that represents a strikingly narrow set of governance possibilities focused on moderators and administrators. When online communities desire other forms of government, such as ones that take many members? opinions into account or that distribute power in non-trivial ways, communities must resort to laborious manual effort. In this paper, we present PolicyKit, a software infrastructure that empowers online community members to concisely author a wide range of governance procedures and automatically carry out those procedures on their home platforms. We draw on political science theory to encode community governance into policies, or short imperative functions that specify a procedure for determining whether a user-initiated action can execute. Actions that can be governed by policies encompass everyday activities such as\u00a0\u2026", "num_citations": "18\n", "authors": ["1164"]}
{"title": "Productivity decomposed: Getting big things done with little microtasks\n", "abstract": " It is difficult to accomplish meaningful goals with limited time and attentional resources. However, recent research has shown that concrete plans with actionable steps allow people to complete tasks better and faster. With advances in techniques that can decompose larger tasks into smaller units, we envision that a transformation from larger tasks to smaller microtasks will impact when and how people perform complex information work, enabling efficient and easy completion of tasks that currently seem challenging. In this workshop, we bring together researchers in task decomposition, completion, and sourcing. We will pursue a broad understanding of the challenges in creating, allocating, and scheduling microtasks, as well as how accomplishing these microtasks can contribute towards productivity. The goal is to discuss how intersections of research across these areas can pave the path for future research in this\u00a0\u2026", "num_citations": "18\n", "authors": ["1164"]}
{"title": "The disagreement deconvolution: Bringing machine learning performance metrics in line with reality\n", "abstract": " Machine learning classifiers for human-facing tasks such as comment toxicity and misinformation often score highly on metrics such as ROC AUC but are received poorly in practice. Why this gap? Today, metrics such as ROC AUC, precision, and recall are used to measure technical performance; however, human-computer interaction observes that evaluation of human-facing systems should account for people\u2019s reactions to the system. In this paper, we introduce a transformation that more closely aligns machine learning classification metrics with the values and methods of user-facing performance measures. The disagreement deconvolution takes in any multi-annotator (eg, crowdsourced) dataset, disentangles stable opinions from noise by estimating intra-annotator consistency, and compares each test set prediction to the individual stable opinions from each annotator. Applying the disagreement deconvolution\u00a0\u2026", "num_citations": "17\n", "authors": ["1164"]}
{"title": "Did it have to end this way? Understanding the consistency of team fracture\n", "abstract": " Was a problematic team always doomed to frustration, or could it have ended another way? In this paper, we study the consistency of team fracture: a loss of team viability so severe that the team no longer wants to work together. Understanding whether team fracture is driven by the membership of the team, or by how their collaboration unfolded, motivates the design of interventions that either identify compatible teammates or ensure effective early interactions. We introduce an online experiment that reconvenes the same team without members realizing that they have worked together before, enabling us to temporarily erase previous team dynamics. Participants in our study completed a series of tasks across multiple teams, including one reconvened team, and privately blacklisted any teams that they would not want to work with again. We identify fractured teams as those blacklisted by half the members. We find\u00a0\u2026", "num_citations": "17\n", "authors": ["1164"]}
{"title": "PingPong++ community customization in games and entertainment\n", "abstract": " In this paper, we introduce PingPong++, an augmented ping pong table that applies Do-It-Yourself (DIY) and community contribution principles to the world of physical sports and play. PingPong++ includes an API for creating new visualizations, easily recreateable hardware, an end-user interface for those without programming experience, and a crowd data API for replaying and remixing past games. We discuss a range of contribution domains for PingPong++ and share the design, usage, feedback, and lessons for each domain. We then reflect on our process and outline a design space for community-contributed sports.", "num_citations": "16\n", "authors": ["1164"]}
{"title": "HYPE: Human-eYe Perceptual Evaluation of Generative Models\n", "abstract": " Generative models often use human evaluations to determine and justify progress. Unfortunately, existing human evaluation methods are ad-hoc: there is currently no standardized, validated evaluation that:(1) measures perceptual fidelity,(2) is reliable,(3) separates models into clear rank order, and (4) ensures high-quality measurement without intractable cost. In response, we construct Human-eYe Perceptual Evaluation (HYPE), a human metric that is (1) grounded in psychophysics research in perception,(2) reliable across different sets of randomly sampled outputs from a model,(3) results in separable model performances, and (4) efficient in cost and time. We introduce two methods. The first, HYPE-Time, measures visual perception under adaptive time constraints to determine the minimum length of time (eg, 250ms) that model output such as a generated face needs to be visible for people to distinguish it as real or fake. The second, HYPE-Infinity, measures human error rate on fake and real images with no time constraints, maintaining stability and drastically reducing time and cost. We test HYPE across four state-of-the-art generative adversarial networks (GANs) on unconditional image generation using two datasets, the popular CelebA and the newer higher-resolution FFHQ, and two sampling techniques of model outputs. By simulating HYPE's evaluation multiple times, we demonstrate consistent ranking of different models, identifying StyleGAN with truncation trick sampling (27.6% HYPE-Infinity deception rate, with roughly one quarter of images being misclassified by humans) as superior to StyleGAN without truncation (19.0%) on FFHQ.", "num_citations": "15\n", "authors": ["1164"]}
{"title": "The daemo crowdsourcing marketplace\n", "abstract": " The success of crowdsourcing markets is dependent on a strong foundation of trust between workers and requesters. In current marketplaces, workers and requesters are often unable to trust each other's quality, and their mental models of tasks are misaligned due to ambiguous instructions or confusing edge cases. This breakdown of trust typically arises from (1) flawed reputation systems which do not accurately reflect worker and requester quality, and from (2) poorly designed tasks. In this demo, we present how Boomerang and Prototype Tasks, the fundamental building blocks of the Daemo crowdsourcing marketplace, help restore trust between workers and requesters. Daemo's Boomerang reputation system incentivizes alignment between opinion and ratings by determining the likelihood that workers and requesters will work together in the future based on how they rate each other. Daemo's Prototype tasks\u00a0\u2026", "num_citations": "13\n", "authors": ["1164"]}
{"title": "Meta: Enabling programming languages to learn from the crowd\n", "abstract": " Collectively authored programming resources such as Q&A sites and open-source libraries provide a limited window into how programs are constructed, debugged, and run. To address these limitations, we introduce Meta: a language extension for Python that allows programmers to share functions and track how they are used by a crowd of other programmers. Meta functions are shareable via URL and instrumented to record runtime data. Combining thousands of Meta functions with their collective runtime data, we demonstrate tools including an optimizer that replaces your function with a more efficient version written by someone else, an auto-patcher that saves your program from crashing by finding equivalent functions in the community, and a proactive linter that warns you when a function fails elsewhere in the community. We find that professional programmers are able to use Meta for complex tasks (creating\u00a0\u2026", "num_citations": "13\n", "authors": ["1164"]}
{"title": "Designing creativity support tools for failure\n", "abstract": " Creative tools today strive to amplify our ability to create high-quality work. However, experiencing failure is also an important part of mastering creative skills. While experts have developed strategies for engaging in risky experiments and learning from mistakes, novices lack the experience and mindset needed to use failures as opportunities for growth. Current tools intimidate the unsure novice, as they are designed around showcasing success or critiquing finished work, rather than providing safe spaces for experimentation. To better support experiences of failure for novices, we instead propose flipping the value of failure in creativity tools from something to avoid to something to pursue actively. To do this, we develop a taxonomy of creative activities that people engage in when they aim to succeed. We then invert this taxonomy to derive a new set of creative activities where deliberate failure can provide a path\u00a0\u2026", "num_citations": "12\n", "authors": ["1164"]}
{"title": "Crowd-powered interfaces\n", "abstract": " We investigate crowd-powered interfaces: interfaces that embed human activity to support high-level conceptual activities such as writing, editing and question-answering. For example, a crowd-ppowered interface using paid crowd workers can compute a series of textual cuts and edits to a paragraph, then provide the user with an interface to condense his or her writing. We map out the design space of interfaces that depend on outsourced, friendsourced, and data mined resources, and report on designs for each of these. We discuss technical and motivational challenges inherent in human-powered interfaces.", "num_citations": "11\n", "authors": ["1164"]}
{"title": "Management of personal information scraps\n", "abstract": " We introduce research on information scraps. short, self-contained personal notes that fall outside of traditional filing schemes. We report on a preliminary study of information scraps. nature and outline plans for the next phase of our user study. Based on ongoing study results, we describe our designs and prototypes for information scrap capture and access tools.", "num_citations": "11\n", "authors": ["1164"]}
{"title": "Diamond\u2019s edge: from notebook to table and back again\n", "abstract": " We discuss the interaction benefits derived from combining the collaborative nature of touch-sensitive tabletop interfaces with the paper affordances and personal space of digital pen and paper. The pen may be used as fluid input to create and transform content within the public table space, and the table\u2019s top-down projection as a method to augment the physical paper with properties of digital output. Finally, we introduce Diamond\u2019s Edge, a design brainstorming tool which incorporates the interaction techniques described.", "num_citations": "11\n", "authors": ["1164"]}
{"title": "Deep Bayesian active learning for multiple correct outputs\n", "abstract": " Typical active learning strategies are designed for tasks, such as classification, with the assumption that the output space is mutually exclusive. The assumption that these tasks always have exactly one correct answer has resulted in the creation of numerous uncertainty-based measurements, such as entropy and least confidence, which operate over a model's outputs. Unfortunately, many real-world vision tasks, like visual question answering and image captioning, have multiple correct answers, causing these measurements to overestimate uncertainty and sometimes perform worse than a random sampling baseline. In this paper, we propose a new paradigm that estimates uncertainty in the model's internal hidden space instead of the model's output space. We specifically study a manifestation of this problem for visual question answer generation (VQA), where the aim is not to classify the correct answer but to produce a natural language answer, given an image and a question. Our method overcomes the paraphrastic nature of language. It requires a semantic space that structures the model's output concepts and that enables the usage of techniques like dropout-based Bayesian uncertainty. We build a visual-semantic space that embeds paraphrases close together for any existing VQA model. We empirically show state-of-art active learning results on the task of VQA on two datasets, being 5 times more cost-efficient on Visual Genome and 3 times more cost-efficient on VQA 2.0.", "num_citations": "10\n", "authors": ["1164"]}
{"title": "Conservation of Procrastination: Do Productivity Interventions Save Time or Just Redistribute It?\n", "abstract": " Productivity behavior change systems help us reduce our time on unproductive activities. However, is that time actually saved, or is it just redirected to other unproductive activities? We report an experiment using HabitLab, a behavior change browser extension and phone application, that manipulated the frequency of interventions on a focal goal and measured the effects on time spent on other applications and platforms. We find that, when intervention frequency increases on the focal goal, time spent on other applications is held constant or even reduced. Likewise, we find that time is not redistributed across platforms from browser to mobile phone or vice versa. These results suggest that any conservation of procrastination effect is minimal, and that behavior change designers may target individual productivity goals without causing substantial negative second-order effects.", "num_citations": "10\n", "authors": ["1164"]}
{"title": "My team will go on: Differentiating high and low viability teams through team interaction\n", "abstract": " Understanding team viability --- a team's capacity for sustained and future success --- is essential for building effective teams. In this study, we aggregate features drawn from the organizational behavior literature to train a viability classification model over a dataset of 669 10-minute text conversations of online teams. We train classifiers to identify teams at the top decile (most viable teams), 50th percentile (above a median split), and bottom decile (least viable teams), then characterize the attributes of teams at each of these viability levels. We find that a lasso regression model achieves an accuracy of .74--.92 AUC ROC under different thresholds of classifying viability scores. From these models, we identify the use of exclusive language such as 'but' and 'except', and the use of second person pronouns, as the most predictive features for detecting the most viable teams, suggesting that active engagement with others'\u00a0\u2026", "num_citations": "9\n", "authors": ["1164"]}
{"title": "Sloppy programming\n", "abstract": " Publisher SummaryThe essence of sloppy programming is that the user should be able to enter something simple and natural, such as a few keywords, and the computer should try everything within its power to interpret and make sense of this input. This chapter discusses several prototypes that implement sloppy programming, translating sloppy commands directly into executable code. It also describes the algorithms used in these prototypes, exposes their limitations, and proposes directions for future work. The techniques described in this discussion still just scratch the surface of a domain with great potential: translating sloppy commands into executable code. It has described potential benefits to end users and expert programmers alike, as well as advocated a continued need for textual command interfaces. A number of prototypes are discussed exploring this technology and what one can learn from them\u00a0\u2026", "num_citations": "9\n", "authors": ["1164"]}
{"title": "Esr: Ethics and society review of artificial intelligence research\n", "abstract": " Artificial intelligence (AI) research is routinely criticized for its real and potential impacts on society, and we lack adequate institutional responses to this criticism and to the responsibility that it reflects. AI research often falls outside the purview of existing feedback mechanisms such as the Institutional Review Board (IRB), which are designed to evaluate harms to human subjects rather than harms to human society. In response, we have developed the Ethics and Society Review board (ESR), a feedback panel that works with researchers to mitigate negative ethical and societal aspects of AI research. The ESR's main insight is to serve as a requirement for funding: researchers cannot receive grant funding from a major AI funding program at our university until the researchers complete the ESR process for the proposal. In this article, we describe the ESR as we have designed and run it over its first year across 41 proposals. We analyze aggregate ESR feedback on these proposals, finding that the panel most commonly identifies issues of harms to minority groups, inclusion of diverse stakeholders in the research plan, dual use, and representation in data. Surveys and interviews of researchers who interacted with the ESR found that 58% felt that it had influenced the design of their research project, 100% are willing to continue submitting future projects to the ESR, and that they sought additional scaffolding for reasoning through ethics and society issues.", "num_citations": "8\n", "authors": ["1164"]}
{"title": "The Cancer in Young People in Canada surveillance system\n", "abstract": " Although childhood cancer remains the leading cause of disease-related deaths among children younger than 14 years of age, it is relatively rare. 1, 2 Each year, an average of 910 children are diagnosed with cancer in Canada, and 139 children die of the disease. 3 Cancers in children differ biologically from those usually found in adults. 4, 5 The majority of cancers in adults are carcinomas of the epithelial tissues that line organs such as the breast, lung, colon and prostate. In children, carcinomas are rare and childhood tumours are more likely to be embryonic or hematopoietic in origin. 5 Leukemias, lymphomas and central nervous system cancers represent the largest diagnostic groups. 5 Compared to cancers in adults, cancers in children have shorter latency periods and are generally more aggressive, invasive and advanced at diagnosis. 5Despite the high ranking of cancer as a cause of death in children\u00a0\u2026", "num_citations": "8\n", "authors": ["1164"]}
{"title": "Simplifying knowledge creation and access for end-users on the SW\n", "abstract": " In this position paper, we argue that improved mechanisms for knowledge acquisition and access on the semantic web (SW) will be necessary before it will be adopted widely by end-users. In particular, we propose an investigation surrounding improved languages for knowledge exchange, better UI mechanisms for interaction, and potential help from user modeling to enable accurate, efficient, SW knowledge modeling for everyone.", "num_citations": "8\n", "authors": ["1164"]}
{"title": "Parallel worlds: Repeated initializations of the same team to improve team viability\n", "abstract": " A team's early interactions are influential: small behaviors cascade, driving the team either toward successful collaboration or toward fracture. Would a team be more viable if it could undo initial interactional missteps and try again? We introduce a technique that supports online and remote teams in creating multiple parallel worlds: the same team meets many times, led to believe that each convening is with a new team due to pseudonym masking while actual membership remains static. Afterward, the team moves forward with the parallel world with the highest viability by using the same pseudonyms and conversation history from that instance. In two experiments, we find that this technique improves team viability: teams that are reconvened from the highest-viability parallel world are significantly more viable than the same group meeting in a new parallel world. Our work suggests parallel worlds can help teams start\u00a0\u2026", "num_citations": "7\n", "authors": ["1164"]}
{"title": "Ai-based request augmentation to increase crowdsourcing participation\n", "abstract": " To support the massive data requirements of modern supervised machine learning (ML) algorithms, crowdsourcing systems match volunteer contributors to appropriate tasks. Such systems learn what types of tasks contributors are interested to complete. In this paper, instead of focusing on what to ask, we focus on learning how to ask: how to make relevant and interesting requests to encourage crowdsourcing participation. We introduce a new technique that augments questions with ML-based request strategies drawn from social psychology. We also introduce a contextual bandit algorithm to select which strategy to apply for a given task and contributor. We deploy our approach to collect volunteer data from Instagram for the task of visual question answering (VQA), an important task in computer vision and natural language processing that has enabled numerous human-computer interaction applications. For example, when encountering a user\u2019s Instagram post that contains the ornate Trevi Fountain in Rome, our approach learns to augment its original raw question \u201cWhere is this place?\u201d with image-relevant compliments such as \u201cWhat a great statue!\u201d or with travel-relevant justifications such as \u201cI would like to visit this place\u201d, increasing the user\u2019s likelihood of answering the question and thus providing a label. We deploy our agent on Instagram to ask questions about social media images, finding that the response rate improves from 15.8% with unaugmented questions to 30.54% with baseline rule-based strategies and to 58.1% with ML-based strategies.", "num_citations": "7\n", "authors": ["1164"]}
{"title": "Prototype tasks: improving crowdsourcing results through rapid, iterative task design\n", "abstract": " Low-quality results have been a long-standing problem on microtask crowdsourcing platforms, driving away requesters and justifying low wages for workers. To date, workers have been blamed for low-quality results: they are said to make as little effort as possible, do not pay attention to detail, and lack expertise. In this paper, we hypothesize that requesters may also be responsible for low-quality work: they launch unclear task designs that confuse even earnest workers, under-specify edge cases, and neglect to include examples. We introduce prototype tasks, a crowdsourcing strategy requiring all new task designs to launch a small number of sample tasks. Workers attempt these tasks and leave feedback, enabling the re- quester to iterate on the design before publishing it. We report a field experiment in which tasks that underwent prototype task iteration produced higher-quality work results than the original task designs. With this research, we suggest that a simple and rapid iteration cycle can improve crowd work, and we provide empirical evidence that requester \"quality\" directly impacts result quality.", "num_citations": "6\n", "authors": ["1164"]}
{"title": "Lexicons on Demand: Neural Word Embeddings for Large-Scale Text Analysis.\n", "abstract": " Human language is colored by a broad range of topics, but existing text analysis tools only focus on a small number of them. We present Empath, a tool that can generate and validate new lexical categories on demand from a small set of seed terms (like \u201cbleed\u201d and \u201cpunch\u201d to generate the category violence). Empath draws connotations between words and phrases by learning a neural embedding across billions of words on the web. Given a small set of seed words that characterize a category, Empath uses its neural embedding to discover new related terms, then validates the category with a crowd-powered filter. Empath also analyzes text across 200 built-in, pre-validated categories we have generated such as neglect, government, and social media. We show that Empath\u2019s data-driven, human validated categories are highly correlated (r= 0.906) with similar categories in LIWC.", "num_citations": "6\n", "authors": ["1164"]}
{"title": "Dynamo: Designing interactive technology to support social movements in digital labor\n", "abstract": " These Turkers were primarily located in America and Canada. We learned that Turkers have built whole online communities that are resources for education and socialization. However, launching collective efforts within these communities have proven much more difficult. While scholars have raised doubts about how effective digital media can be in creating social change--arguing that on the ground activism can not be substituted with online-only social interactions--they have not considered labor markets that solely function online. What can\" on the ground activism\u201d mean for these workers?As researchers we collaborated with workers of AMT to explore possibilities of digital media facilitated collective action. We built Dynamo, a system that supports workers to pitch ideas, gather to discuss them, define collective goals, and act on them. We started by speaking with workers about existing forms of activism and the\u00a0\u2026", "num_citations": "6\n", "authors": ["1164"]}
{"title": "Wicked problems and gnarly results: Reflecting on design and evaluation methods for idiosyncratic personal information management tasks\n", "abstract": " This paper is a case study of an artifact design and evaluation process; it is a reflection on how right thinking about design methods may at times result in sub-optimal results. Our goal has been to assess our decision making processthroughout the design and evaluation stages for a software prototype in order to consider where design methodology may need to be tuned to be more sensitive to the domain of practice, in this case software evaluation in personal information management. In particular, we reflect on design methods around (1) scale of prototype, (2) prototyping and design process, (3) study design, and (4) study population.", "num_citations": "6\n", "authors": ["1164"]}
{"title": "Ink: Increasing worker agency to reduce friction in hiring crowd workers\n", "abstract": " The web affords connections by which end-users can receive paid, expert help\u2014such as programming, design, and writing\u2014to reach their goals. While a number of online marketplaces have emerged to facilitate such connections, most end-users do not approach a market to hire an expert when faced with a challenge. To reduce friction in hiring from peer-to-peer expert crowd work markets, we propose Ink, a system that crowd workers can use to showcase their services by embedding tasks inside web tutorials\u2014a common destination for users with information needs. Workers have agency to define and manage tasks, through which users can request their help to review or execute each step of the tutorial, for example, to give feedback on a paper outline, perform a statistical analysis, or host a practice programming interview. In a public deployment, over 25,000 pageviews led 168 tutorial readers to pay crowd\u00a0\u2026", "num_citations": "5\n", "authors": ["1164"]}
{"title": "The web is flat: The inflation of uncommon experiences online\n", "abstract": " People populate the web with content relevant to their lives, content that millions of others rely on for information and guidance. However, the web is not a perfect rep-resentation of lived experience: some topics appear in greater proportion online than their true incidence in our population, while others are deflated. This paper presents a large scale data collection study of this phenomenon. We collect webpages about 21 topics of interest capturing roughly 200,000 webpages, and then compare each topic's popularity to representative national surveys as ground truth. We find that rare experiences are inflated on the web (by a median of 7x), while common experiences are deflated (by a median of 0.7 x). We call this phenomenon novelty bias.", "num_citations": "5\n", "authors": ["1164"]}
{"title": "Designing scalable and sustainable peer interactions online\n", "abstract": " When students work with peers, they learn more actively, build richer knowledge structures, and connect material to their lives. However, not every peer learning experience online sees successful adoption. This chapter first introduces PeerStudio, an assessment platform that leverages the large number of students\u2019 peers in online classes to enable rapid feedback on in-progress work. Students submit their draft, give rubric-based feedback on two peers\u2019 drafts, and then receive peer feedback. Students can integrate the feedback and repeat this process as often as they desire. PeerStudio demonstrates how rapid feedback on in-progress work improves course outcomes. We then articulate and address three adoption and implementation challenges for peer learning platforms such as PeerStudio. First, peer interactions struggle to bootstrap critical mass. However, class incentives can signal importance and\u00a0\u2026", "num_citations": "5\n", "authors": ["1164"]}
{"title": "Structured handoffs in expert crowdsourcing improve communication and work output\n", "abstract": " Expert crowdsourcing allows specialized, remote teams to complete projects, often large and involving multiple stages. Its execution is complicated due to communication difficulties between remote workers. This paper investigates whether structured handoff methods, from one worker to the next, improve final product quality by helping the workers understand the input of their tasks and reduce overall integration cost. We investigate this question through 1) a\" live\" handoff method where the next worker shadows the former via screen sharing technology and 2) a\" recorded\" handoff, where workers summarize work done for the next, via a screen capture and narration. We confirm the need for a handoff process. We conclude that structured handoffs result in higher quality work, improved satisfaction (especially for workers with creative tasks), improved communication of non-obvious instructions, and increased\u00a0\u2026", "num_citations": "5\n", "authors": ["1164"]}
{"title": "Apps with Benefits: Using Benefits and Burdens to Predict Mobile App Usage\n", "abstract": " How do mobile apps keep users coming back? Suh et al. proposed that the level of burden placed on a user has a negative effect on user retention. They developed the User Burden Scale, and showed that computing systems still in use had lower burdens than those that were abandoned. What is not captured is how the added benefits a system provides increases user retention. We hypothesize that both benefits and burdens of a mobile app predict usage. To show this, we design and validate a User Benefit Scale to complement the User Burden Scale, for the evaluation of benefits of mobile apps. Our scale consists of four constructs: if an app is 1) useful and informational, 2) enjoyable and enables pursuit of interests, 3) enables social interaction, and 4) has good usability and visual/interaction design. We administered the benefit and burden scales to 347 participants. Our results suggest that benefit is more\u00a0\u2026", "num_citations": "4\n", "authors": ["1164"]}
{"title": "Anyone can become a troll: Analysis and simulation of online discussion sections show circumstances that can cause civil commentators to engage in aggressive behavior\n", "abstract": " \" Fail at life. Go bomb yourself.\" Comments such as this one, found attached to a CNN article about how women perceive themselves, are prevalent today across the internet, whether the location is Facebook, Reddit, or a news website. Such commenting behavior can range from profanity and name calling to personal attacks, sexual harassment, or hate speech.A recent Pew Internet Survey found that 4 out of 10 people online have been harassed on the internet, with far more having witnessed such behavior. Trolling has become so rampant that several websites have even resorted to completely removing comments.", "num_citations": "4\n", "authors": ["1164"]}
{"title": "Crowdsourcing the research process\n", "abstract": " Research is a high skill and resource intensive activity, both in time and effort, and often follows an ad hoc process. In a research process, its often unclear what ingredients; or what recipe or process, which if repeated produces a publishable paper. Meanwhile, experienced researchers with novel ideas are constrained with limited time and funding resources; and motivated students with exceptional skill-sets lack direction or research mentor. In this proposal, I introduce a research direction which explores the possibility of expert crowdsourcing the research process, by connecting mentor with student crowd. The process would allow mentors to systematically use operators such as split, merge, remove or add on project ideas, code or students to manage research process and crowd. The process would include series of research phases like, brainstorming, paper-pencil prototyping, development and user-evaluation to produce publishable results. Encouraged by prior pilot experiment findings, my doctoral research examines the possibility of crowdsourcing the research process using operators along the research phase, while solving resource and opportunity constraints among mentor and crowd.", "num_citations": "4\n", "authors": ["1164"]}
{"title": "Can Online Juries Make Consistent, Repeatable Decisions?\n", "abstract": " A jury of one\u2019s peers is a prominent way to adjudicate disputes and is increasingly used in participatory governance online. The fairness of this approach rests on the assumption that juries are consistent: that the same jury would hand down similar judgments to similar cases. However, prior literature suggests that social influence would instead cause early interactions to cascade into different judgments for similar cases. In this paper, we report an online experiment that changes participants\u2019 pseudonyms as they appear to collaborators, temporarily masking a jury\u2019s awareness that they have deliberated together before. This technique allows us to measure consistency by reconvening the same jury on similar cases. Counter to expectation, juries are equally consistent as individuals, a result that is \u201cgood for democracy.\u201d But this consistency arises in part due to group polarization, as consensus develops by hardening\u00a0\u2026", "num_citations": "3\n", "authors": ["1164"]}
{"title": "Establishing an evaluation metric to quantify climate change image realism\n", "abstract": " With success on controlled tasks, deep generative models are being increasingly applied to humanitarian applications (Nie et al 2017 Int. Conf. on Medical Image Computing and Computer-Assisted Intervention (Berlin: Springer) pp 417\u201325, Yanardag et al 2017 Deep Empathy). In this paper, we focus on the evaluation of a conditional generative model that illustrates the consequences of climate change-induced flooding to encourage public interest and awareness on the issue. Because metrics for comparing the realism of different modes in a conditional generative model do not exist, we propose several automated and human-based methods for evaluation. To do this, we adapt several existing metrics and assess the automated metrics against gold standard human evaluation. We find that using Fr\u00e9chet Inception Distance with embeddings from an intermediary Inception-v3 layer that precedes the auxiliary\u00a0\u2026", "num_citations": "3\n", "authors": ["1164"]}
{"title": "Myriadhub: Efficiently scaling personalized email conversations with valet crowdsourcing\n", "abstract": " Email has scaled our ability to communicate with large groups, but has not equivalently scaled our ability to listen and respond. For example, emailing many people for feedback requires either impersonal surveys or manual effort to hold many similar conversations. To scale personalized conversations, we introduce techniques that exploit similarities across conversations to recycle relevant parts of previous conversations. These techniques reduce the authoring burden, save senders' time, and maintain recipient engagement through personalized responses. We introduce MyriadHub, a mail client where users start conversations and then crowd workers extract underlying conversational patterns and rules to accelerate responses to future similar emails. In a within-subjects experiment comparing MyriadHub to existing mass email techniques, senders spent significantly less time planning events with MyriadHub. In a\u00a0\u2026", "num_citations": "3\n", "authors": ["1164"]}
{"title": "Founder Center: Enabling Access to Collective Social Capital\n", "abstract": " Social costs and limited reach inhibit our use of social capital to solicit help. However, individuals are not the only holders of social capital: groups also possess reputations and social capital, and are often prepared to vouch for their own members. In this paper, we design methods for mobilizing this collective social capital in sociotechnical systems, enabling an individual to ask a trusted group whether it is willing to invest its reputation in doing them a favor. We instantiate this concept with Founder Center, a web platform in which members of a local entrepreneurship accelerator ask the accelerator community to collectively make them introductions to potential funders. In a field experiment, enabling access to collective social capital in this community nearly doubled the odds of members making a social capital request. Requests fulfilled utilizing collective social capital were at least as effective as ones utilizing\u00a0\u2026", "num_citations": "3\n", "authors": ["1164"]}
{"title": "Connecting stories and pedagogy increases participant engagement in discussions\n", "abstract": " Student discussions over video in massive classes allow students to explore course content, share personal experiences and get feedback on their ideas. However, such discussions frequently turn into casual conversations without focusing on the curriculum and the learning objectives. This short paper explores whether students can achieve multiple learning objectives by solving challenges collaboratively during discussions. We introducethink-pair-share'technique for video discussions. Our pilot results, drawn from a Coursera class, suggest that participants prefer to exchange information with their peers using personal stories and connecting stories with curriculum increases participant engagement.", "num_citations": "3\n", "authors": ["1164"]}
{"title": "collaboration with\n", "abstract": " CiteSeerX \u2014 collaboration with: Documents Authors Tables Log in Sign up MetaCart DMCA Donate CiteSeerX logo Documents: Advanced Search Include Citations Authors: Advanced Search Include Citations Tables: DMCA collaboration with: Cached Download as a PDF Download Links [eprints.ecs.soton.ac.uk] [kurtluther.com] [eprints.soton.ac.uk] Save to List Add to Collection Correct Errors Monitor Changes by Paul Andr\u00e9 , Alan Dix , Paul Andr\u00e9 , Michael Bernstein , Kurt Luther Summary Citations Active Bibliography Co-citation Clustered Documents Version History Share Facebook Twitter Reddit Bibsonomy OpenURL Abstract The Healthii project is a collaboration with: mc schraefel Electronics & Computer Science Keyphrases healthii project schraefel electronics computer science Powered by: Apache Solr About CiteSeerX Submit and Index Documents Privacy Policy Help Data Source Contact Us Developed \u2026", "num_citations": "3\n", "authors": ["1164"]}
{"title": "Not Now, Ask Later: Users Weaken Their Behavior Change Regimen Over Time, But Expect To Re-Strengthen It Imminently\n", "abstract": " How effectively do we adhere to nudges and interventions that help us control our online browsing habits? If we have a temporary lapse and disable the behavior change system, do we later resume our adherence, or has the dam broken? In this paper, we investigate these questions through log analyses of 8,000+ users on HabitLab, a behavior change platform that helps users reduce their time online. We find that, while users typically begin with high-challenge interventions, over time they allow themselves to slip into easier and easier interventions. Despite this, many still expect to return to the harder interventions imminently: they repeatedly choose to be asked to change difficulty again on the next visit, declining to have the system save their preference for easy interventions.", "num_citations": "2\n", "authors": ["1164"]}
{"title": "Crowd Research: Open and Scalable University Laboratories\n", "abstract": " Research experiences today are limited to a privileged few at select universities. Providing open access to research experiences would enable global upward mobility and increased diversity in the scientific workforce. How can we coordinate a crowd of diverse volunteers on open-ended research? How could a PI have enough visibility into each person\u2019s contributions to recommend them for further study? We present Crowd Research, a crowdsourcing technique that coordinates open-ended research through an iterative cycle of open contribution, synchronous collaboration, and peer assessment. To aid upward mobility and recognize contributions in publications, we introduce a decentralized credit system: participants allocate credits to each other, which a graph centrality algorithm translates into a collectively-created author order. Over 1500 people from 62 countries have participated, 74% from institutions with\u00a0\u2026", "num_citations": "2\n", "authors": ["1164"]}
{"title": "Text mining emergent human behaviors for interactive systems\n", "abstract": " People engage with thousands of situations, activities, and objects on a daily basis. Hand-coding this knowledge into interactive systems is prohibitively labor-intensive, but fiction captures a vast number of human lives in moment to moment detail. In this paper, we bootstrap a knowledge graph of human activities by text mining a large dataset of modern fiction on the web. Our knowledge graph, Augur, describes human actions over time as conditioned by nearby locations, people, and objects. Applications can use this graph to react to human behavior in a data-driven way. We demonstrate an Augur-enhanced video game world in which non-player characters follow realistic patterns of behavior, interact with their environment and each other, and respond to the user's behavior.", "num_citations": "2\n", "authors": ["1164"]}
{"title": "HCI Human-Computer Interaction and Collective Intelligence\n", "abstract": " Human-computer interaction (HCI) works to understand and to design interactions between people and machines. Increasingly, human collectives are using technology to gather together and coordinate. This mediation occurs through volunteer and interest-based communities on the web, through paid online marketplaces, and through mobile", "num_citations": "2\n", "authors": ["1164"]}
{"title": "Enabling Expert Crowdsourcing with Flash Teams\n", "abstract": " Crowdsourcing enables individuals to come together quickly and complete projects that would be virtually impossible for a single individual to accomplish at the same scale [1, 2]. To date, the dominant paradigm has been to combine many paid non-expert opinions, for example from Amazon Mechanical Turk, to match the performance of a single expert [2, 4]. However, this 1 paradigm is plateauing in complexity: many creative, open-ended or highly complex tasks remain largely unsolved because they require significant expertise that cannot be designed into the system [3, 5]. Our objective is to drive crowdsourcing research past this complexity boundary by introducing expert teams as core elements of crowdsourcing systems and developing modular computational techniques to guide these teams.", "num_citations": "2\n", "authors": ["1164"]}
{"title": "Designing for Schadenfreude (or, how to express well-being and see if you\u02bcre boring people)\n", "abstract": " This position paper presents two studies of content not normally expressed in status updates\u2014well-being and status feedback\u2014and considers how they may be processed, valued and used for potential quality-of-life benefits in terms of personal and social reflection and awareness.  Do I Tweet Good? (poor grammar intentional) is a site investigating more nuanced forms of status feedback than current microblogging sites allow, towards understanding self-identity, reflection, and online perception.  Healthii is a tool for sharing physical and emotional well-being via status updates, investigating concepts of self-reflection and social awareness.  Together, these projects consider furthering the value of microblogging on two fronts: 1) refining the online personal/social networking experience, and 2) using the status update for enhancing the personal/social experience in the offline world, and considering how to leverage that online/offline split. We offer results from two different methods of study and target groups\u2014one co-workers in an academic setting, the other followers on Twitter\u2014to consider how microblogging can become more than just a communication medium if it facilitates these types of reflective practice.", "num_citations": "2\n", "authors": ["1164"]}
{"title": "Collabio: A Game for Annotating People within Social Networks. UIST'09\n", "abstract": " We present Collabio, a social tagging game within an online social network that encourages friends to tag one another. Collabio\u2019s approach of incentivizing members of the social network to generate information about each other produces personalizing information about its users. We report usage log analysis, survey data, and a rating exercise demonstrating that Collabio tags are accurate and augment information that could have been scraped online. ACM Classification Keywords: H5. 2. Information Interfaces:", "num_citations": "2\n", "authors": ["1164"]}
{"title": "AtomsMasher: Personal Reactive Automation for the Web\n", "abstract": " The rise of \"Web 2.0\" has seen an explosion of web sites for the social sharing of personal information. To enable users to make valuable use of the rich yet fragmented sea of public, social, and personal information, data mashups emerged to provide a means for combining and filtering such information into coherent feeds and visualizations. In this paper we present AtomsMasher (AM), a new framework which extends data mashups into the realm of context-aware reactive behaviors. Reactive scripts in AM can be made to trigger automatically in response to changes in its world model derived from multiple web-based data feeds. By exposing a simple state-model abstraction and query language abstractions of data derived from heterogeneous web feeds through a simulation-based interactive script debugging environment, AM greatly simplifies the process of creating such automation in a way that is flexible, predictable, scalable and within the reach of everyday Web programmers.", "num_citations": "2\n", "authors": ["1164"]}
{"title": "Evolution and evaluation of an information scrap manager\n", "abstract": " The Jourknow project addresses the question of freeform notes known as information scraps. We are focused on unifying the user\u2019s PIM tools, providing lightweight input and enabling support for uncommon types of personal information. In this position paper we describe our current directions and lessons learned from work on the Jourknow system. We have redesigned our lightweight input language for capture of arbitrary data types and developed a mobile phone client. We report on feedback from a weeklong user study, generating design recommendations for systems like Jourknow. Our study identified the importance of supporting common PIM data in addition to uncommon information types, of providing a mobile solution for capture and retrieval of notes, and of integrating with current user tools and practice. With respect to evaluation, we reflect on the large scale of personal information needed to evaluate our tools. Author Keywords Personal information management, lightweight input, information scraps", "num_citations": "2\n", "authors": ["1164"]}
{"title": "Research Methods I\n", "abstract": " This class is a foundation course for the scientific study of psychology. Throughout the term, you will learn how to test scientific hypotheses, design experiments, evaluate research conclusions, and conduct your own research studies. In many psychology courses, you learn what human behavior is or why it occurs, but this class is much more important, for it teaches how to study human behavior and arrive at those conclusions, and how to think like a psychologist. The material we will cover in this course will provide you with the ability to design research studies, conduct proper analyses to test the predictions of a study, and to critically infer what conclusions can be made based on the design and analyses of a study. In addition, this course will teach you how to evaluate the validity of others\u2019 research, which if not properly understood, can often be misleading. Science is often concerned with the pursuit of truth, and in the study of psychology, it is this course that teaches you the correct way to pursue it.", "num_citations": "2\n", "authors": ["1164"]}
{"title": "Understanding the Representation and Representativeness of Age in AI Data Sets\n", "abstract": " A diverse representation of different demographic groups in AI training data sets is important in ensuring that the models will work for a large range of users. To this end, recent efforts in AI fairness and inclusion have advocated for creating AI data sets that are well-balanced across race, gender, socioeconomic status, and disability status. In this paper, we contribute to this line of work by focusing on the representation of age by asking whether older adults are represented proportionally to the population at large in AI data sets. We examine publicly-available information about 92 face data sets to understand how they codify age as a case study to investigate how the subjects' ages are recorded and whether older generations are represented. We find that older adults are very under-represented; five data sets in the study that explicitly documented the closed age intervals of their subjects included older adults (defined\u00a0\u2026", "num_citations": "1\n", "authors": ["1164"]}
{"title": "Can we just start over again? Resetting remote team dynamics\n", "abstract": " Interactions defining teamwork today are heavily influenced by constraints and expectations found in in-person teams, however, remote collaboration provides the opportunity to try new ways to make teams work. One foundation of teamwork is persistent identity\u2014we are who we were last time we worked together. Breaking with the expectation of in-person teams, we present a system that affords discontinuous identity using two-way pseudonym masking\u2014enabling teams with new behaviors to arise from the same group of individuals. With this scaffold, a novel family of experiments, comparing the same group across multiple fresh starts, are possible. Further, interventions that involve choosing between versions of the same team are unlocked. We present an overview of experiments and interventions leveraging this system, and propose methods for its broader use in organizations enacting the future of work.", "num_citations": "1\n", "authors": ["1164"]}
{"title": "Eevee: Transforming Images by Bridging High-level Goals and Low-level Edit Operations\n", "abstract": " There is a significant gap between the high-level, semantic manner in which we reason about image edits and the low-level, pixel-oriented way in which we execute these edits. While existing image-editing tools provide a great deal of flexibility for professionals, they can be disorienting to novice editors because of the gap between a user's goals and the unfamiliar operations needed to actualize them. We present Eevee, an image-editing system that empowers users to transform images by specifying intents in terms of high-level themes. Based on a provided theme and an understanding of the objects and relationships in the original image, we introduce an optimization function that balances semantic plausibility, visual plausibility, and theme relevance to surface possible image edits. A formative evaluation finds that we are able to guide users to meet their goals while helping them to explore novel, creative ideas\u00a0\u2026", "num_citations": "1\n", "authors": ["1164"]}
{"title": "Engagement Learning: Expanding Visual Knowledge by Engaging Online Participants\n", "abstract": " Most artificial intelligence (AI) systems to date have focused entirely on performance, and rarely if at all on their social interactions with people and how to balance the AIs' goals against their human collaborators'. Learning quickly from interactions with people poses both social challenges and is unresolved technically. In this paper, we introduce engagement learning: a training approach that learns to trade off what the AI needs---the knowledge value of a label to the AI---against what people are interested to engage with---the engagement value of the label. We realize our goal with ELIA (Engagement Learning Interaction Agent), a conversational AI agent who's goal is to learn new facts about the visual world by asking engaging questions of people about the photos they upload to social media. Our current deployment of ELIA on Instagram receives a response rate of 26%.", "num_citations": "1\n", "authors": ["1164"]}
{"title": "Shared autonomy for an interactive AI system\n", "abstract": " Across many domains, interactive systems either make decisions for us autonomously or yield decision-making authority to us and play a supporting role. However, many settings, such as those in education or the workplace, benefit from sharing this autonomy between the user and the system, and thus from a system that adapts to them over time. In this paper, we pursue two primary research questions:(1) How do we design interfaces to share autonomy between the user and the system?(2) How does shared autonomy alter a user\" s perception of a system? We present SharedKeys, an interactive shared autonomy system for piano instruction that plays different video segments of a piece for students to emulate and practice. Underlying our approach to shared autonomy is a mixed-observability Markov decision process that estimates a user\" s desired autonomy level based on her performance and attentiveness\u00a0\u2026", "num_citations": "1\n", "authors": ["1164"]}
{"title": "Designing A Constitution for a Self-Governing Crowdsourcing Marketplace\n", "abstract": " Paid crowdsourcing platforms such as Upwork and Amazon Mechanical Turk must jointly serve workers, requesters, and platform owners. However, design and governance decisions tend to be made only by the owners, and in the business interests of the requesters, so the many stakeholders\u2019 issues often remain unaddressed. In response to the resulting frustration and power imbalances, platform users created external tools for communication and platform monitoring [Irani and Silberman 2013], as grassroots alternatives to an improved platform design [LaPlante et al. 2016]. Similar solutions emerged in most paid crowdsourcing platforms [Yin et al. 2016], despite top down controls (eg,[Amazon 2014; Upwork 2016; Vakharia and Lease 2013]). This trend of asymmetric governance undermines the anticipated future of paid crowdsourcing [Kittur et al. 2013]. In contrast to the top-down governance structures that paid crowdsourcing platforms currently use, we explored a bottom-up approach: open source governance [Rushkoff 2003]. We describe a crowdsourcing platform where constituents have full access to governing documents and participate in writing legislation through an iterative community process akin to how open source software is developed [O\u2019Mahony and Ferraro 2007]. Open source governance has been used in online communities such as Jupyter [Jupyter 2015], and in physical communities such as in Iceland [Landemore 2015]. Crowdsourced democratic deliberation [Aitamurto and Landemore 2016] offers an effective bridging of these approaches into a mechanism driven by participant stakeholders. We introduce the Daemo\u00a0\u2026", "num_citations": "1\n", "authors": ["1164"]}
{"title": "Trust, sustainability, and political innovation: A new reality for our future\n", "abstract": " Jay was a Federalist and the above quotation reminds us of two fundamental aspects of US history and of whom we strive to be: that we come together in good faith to meet challenges and solve problems, whatever they may be; and that our founders were innovators working at the cutting edge of governance innovation. Their ideas for effective governance were housed within a visionary framework embracing life, liberty, and the pursuit of happiness, and equality before the law. As a whole, this laid down the foundation for institutions with the potential to embrace the bold idea of representing both \u201cthe people\u201d and the changing landscapes of public context that inevitably arise. As governance innovation, it was a beginning.Jay described as central to the framers\u2019 success an atmosphere of trust and goodwill in which people, despite having conflicting opinions, came together and solved the problem of governing\u00a0\u2026", "num_citations": "1\n", "authors": ["1164"]}
{"title": "Human computation and crowdsourcing\n", "abstract": " In 1937, Alan Turing formalized the notion of computation by introducing the Turing machine, thus laying the theoretical foundations of modern computer science. Turing also introduced a stronger computational model: a Turing machine with an oracle. In addition to performing computations itself, such a machine is able to ask the oracle questions and immediately receive correct answers, even if these questions are too hard for the machine itself to compute. Depending on the oracle\u2019s capabilities, a Turing machine with an oracle therefore could be much stronger than the machine on its own. The oracle itself is an unspecified entity,\u201capart from saying that it cannot be a machine\u201d(from Turing\u2019s 1939 work,", "num_citations": "1\n", "authors": ["1164"]}
{"title": "The war against spam: and more\n", "abstract": " http://cacm.acm.org/blogs/blog-cacmThe Communications Web site, http://cacm.acm.org, features more than a dozen bloggers in the BLOG@CACM community. In each issue of Communications, we'll publish selected posts or excerpts.twitterFollow us on Twitter at http://twitter.com/blogCACMGreg Linden asks if spammers have been defeated; Michael Bernstein discusses Clay Shirky's keynote speech at CSCW 2010; and Erika S. Poole writes about how the digital world can help parents cope with the death of a child.", "num_citations": "1\n", "authors": ["1164"]}
{"title": "Taskpos\u00e9: A Dynamic Task-Based Window Management Aid\n", "abstract": " The window manager, a program which helps users organize and access their computers\u2019 open windows, is central to many aspects of computer work. Research in window managers has recently aimed to leverage users\u2019 tasks to organize the growing number of open windows in a useful manner. This research has assumed task classifications to be binary\u2013a window is in a task, or not\u2013and contextindependent. However, our fieldwork and background theory suggest that neither is necessarily the case. Instead, we focus on association as an organizational scheme\u2013windows can associate with tasks to varying degrees. We then introduce Taskpos\u00e9, a prototype system that capitalizes on this idea through a fullscreen graphical interface, and report on a weeklong user study. Finally, we comment on future directions for the prototype.", "num_citations": "1\n", "authors": ["1164"]}
{"title": "AtomsMasher: PeRSSonalized Information Delivery and Management on the Web\n", "abstract": " Over the past two years, social networking sites have fostered a new kind of data publication: personal feeds about schedule, location, music playing, activity and so on. While these feeds have been mainly used at face value as status reports for human readership, we present AtomsMasher, a tool that uses these feeds as a computer's context to inform automatic actions: an update of a current location query, compared with a calendar entry's meeting location and time can trigger an automatic\" I'm late; I'm on the way\" to necessary parties. This light-weight (though surprisingly complex) automation frees us from manually updating multiple sources; likewise the information context can privilege the presentation of other sources: if the news is not about a band i listen to, don't show me upcoming gigs. To deliver this utility however, we have needed to address two key challenges: operationalizing data sources with little original structure and providing interaction approaches to support non-specialists defining rules for these sources' interaction. The contribution of this work is the demonstration that a simple property/value extension to RSS feeds enables a new kind of interaction with information: even non-specialist users can define precise rules to take control of or successfully delegate the handling of the high volume of both personal and public information we produce and must process.", "num_citations": "1\n", "authors": ["1164"]}
{"title": "Comparing the Perceived Legitimacy of Content Moderation Processes: Contractors, Algorithms, Expert Panels, and Digital Juries\n", "abstract": " While research continues to investigate and improve the accuracy, fairness, and normative appropriateness of content moderation processes on large social media platforms, even the best process cannot be effective if users reject its authority as illegitimate. We present a survey experiment comparing the perceived institutional legitimacy of four popular content moderation processes. We conducted a within-subjects experiment in which we showed US Facebook users moderation decisions and randomized the description of whether those decisions were made by paid contractors, algorithms, expert panels, or juries of users. Prior work suggests that juries will have the highest perceived legitimacy due to the benefits of judicial independence and democratic representation. However, expert panels had greater perceived legitimacy than algorithms or juries. Moreover, outcome alignment - agreement with the decision - played a larger role than process in determining perceived legitimacy. These results suggest benefits to incorporating expert oversight in content moderation and underscore that any process will face legitimacy challenges derived from disagreement about outcomes.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Jury Learning: Integrating Dissenting Voices into Machine Learning Models\n", "abstract": " Whose labels should a machine learning (ML) algorithm learn to emulate? For ML tasks ranging from online comment toxicity to misinformation detection to medical diagnosis, different groups in society may have irreconcilable disagreements about ground truth labels. Supervised ML today resolves these label disagreements implicitly using majority vote, which overrides minority groups' labels. We introduce jury learning, a supervised ML approach that resolves these disagreements explicitly through the metaphor of a jury: defining which people or groups, in what proportion, determine the classifier's prediction. For example, a jury learning model for online toxicity might centrally feature women and Black jurors, who are commonly targets of online harassment. To enable jury learning, we contribute a deep learning architecture that models every annotator in a dataset, samples from annotators' models to populate the jury, then runs inference to classify. Our architecture enables juries that dynamically adapt their composition, explore counterfactuals, and visualize dissent.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "A\" Distance Matters\" Paradox: Facilitating Intra-Team Collaboration Can Harm Inter-Team Collaboration\n", "abstract": " By identifying the socio-technical conditions required for teams to work effectively remotely, the Distance Matters framework has been influential in CSCW since its introduction in 2000. Advances in collaboration technology and practices have since brought teams increasingly closer to achieving these conditions. This paper presents a ten-month ethnography in a remote organization, where we observed that despite exhibiting excellent remote collaboration, teams paradoxically struggled to collaborate across team boundaries. We extend the Distance Matters framework to account for inter-team collaboration, arguing that challenges analogous to those in the original intra-team framework -- common ground, collaboration readiness, collaboration technology readiness, and coupling of work -- persist but are actualized differently at the inter-team scale. Finally, we identify a fundamental tension between the intra- and inter-team layers: the collaboration technology and practices that help individual teams thrive (e.g., adopting customized collaboration software) can also prompt collaboration challenges in the inter-team layer, and conversely the technology and practices that facilitate inter-team collaboration (e.g., strong centralized IT organizations) can harm practices at the intra-team layer. The addition of the inter-team layer to the Distance Matters framework opens new opportunities for CSCW, where balancing the tension between team and organizational collaboration needs will be a critical technological, operational, and organizational challenge for remote work in the coming decades.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Ethics and society review: Ethics reflection as a precondition to research funding\n", "abstract": " Researchers in areas as diverse as computer science and political science must increasingly navigate the possible risks of their research to society. However, the history of medical experiments on vulnerable individuals influenced many research ethics reviews to focus exclusively on risks to human subjects rather than risks to human society. We describe an Ethics and Society Review board (ESR), which fills this moral gap by facilitating ethical and societal reflection as a requirement to access grant funding: Researchers cannot receive grant funding from participating programs until the researchers complete the ESR process for their proposal. Researchers author an initial statement describing their proposed research\u2019s risks to society, subgroups within society, and globally and commit to mitigation strategies for these risks. An interdisciplinary faculty panel iterates with the researchers to refine these risks and\u00a0\u2026", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Crowdsourcing County-Level Data on Early COVID-19 Policy Interventions in the United States: Technical Report\n", "abstract": " Beginning in April 2020, we gathered partial county-level data on non-pharmaceutical interventions (NPIs) implemented in response to the COVID-19 pandemic in the United States, using both volunteer and paid crowdsourcing. In this report, we document the data collection process and summarize our results, to increase the utility of our open data and inform the design of future rapid crowdsourcing data collection efforts.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Visual Intelligence through Human Interaction\n", "abstract": " Over the last decade, Computer Vision, the branch of Artificial Intelligence aimed at understanding the visual world, has evolved from simply recognizing objects in images to describing pictures, answering questions about images, aiding robots maneuver around physical spaces, and even generating novel visual content. As these tasks and applications have modernized, so too has the reliance on more data, either for model training or for evaluation. In this chapter, we demonstrate that novel interaction strategies can enable new forms of data collection and evaluation for Computer Vision. First, we present a crowdsourcing interface for speeding up paid data collection by an order of magnitude, feeding the data-hungry nature of modern vision models. Second, we explore a method to increase volunteer contributions using automated social interventions. Third, we develop a system to ensure human\u00a0\u2026", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Drawventure: Teaching Design Sketching Through Gameplay\n", "abstract": " How can we make design sketching a more engaging, bite-sized practice in our daily schedules? Learning design sketching typically involves repeated practice of fundamentals. This approach can be discouraging and demotivating. We want to enable more self-directed learning and thereby democratize the design sketching education. In this project, we paper-prototyped and user-tested an application called Drawventure that reframes sketching lessons as micro-challenges, where player sketches become objects that populate an increasingly engaging toy world.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "New Perspectives on Hierarchical Roles in Groups and Organizations: Beyond High Rank vs Low Rank\n", "abstract": " Research on hierarchy has exploded in recent years. In this work, management scholars have largely focused on high- and low- rank roles within a hierarchy and how high and low rank can drive individual, group, and organizational processes and outcomes. However, recent work has begun to move beyond the study of traditional high- versus low- rank roles in hierarchies to instead consider other consequential hierarchical roles in groups and organizations. In this symposium, we highlight this emerging area of research on alternative perspectives on hierarchical roles, bringing together a set of five cutting-edge papers. These papers all offer new perspectives on the roles of different hierarchical ranks, including developing theory on the role of various high-ranking members in alliances (first paper), unpacking the consequences of a common yet overlooked rank: the second-in-command rank (second paper\u00a0\u2026", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Not Now, Ask Later: Users Weaken Their Behavior Change Regimen Over Time, But Expect To Re-Strengthen It Imminently (Supplementary Materials)\n", "abstract": " 1.2 Results Median times of Facebook session lengths in the presence of each intervention are shown in Figure 1. Interventions where session lengths are the shortest are be the most effective at reducing time on Facebook. We see that all interventions are more effective than no intervention, and that the most effective intervention is closing the tab automatically after 60 seconds. Note that the \u201cclose tab after 60 seconds\u201d intervention includes an \u201cadd time\u201d button, hence why time spent on Facebook in its presence can exceed 60 seconds.We asked three independent raters (HabitLab users who had been using it for over a month) to rate their perceived difficulty level of each intervention as either easy, medium, or hard. We opted for a 3-level difficulty categorization, as our studies ask users to choose difficulty levels and we did not want to overwhelm them with too many choices. We took the intervention\u2019s difficulty to be the median of its ratings. Our raters\u2019 intervention difficulty ratings are shown in Table 1. To investigate whether interventions perceived as more difficult by our raters are also more effective, we group the samples according to the raters\u2019 intervention difficulty. Median times of Facebook session lengths in the presence of each intervention difficulty are shown in Figure 2. The most time is spent when there was no intervention (median of 199 seconds per session), followed by easy (185 seconds), medium (161 seconds), and hard (135 seconds) interventions, as shown in Figure 2. There is a significant effect of difficulty on effectiveness according to a Kruskal-Wallis H test", "num_citations": "0\n", "authors": ["1164"]}
{"title": "UIST+ CSCW: A Celebration of Systems Research in Collaborative and Social Computing\n", "abstract": " This joint panel between UIST and CSCW brings together leading researchers at the intersection of the conferences-systems researchers in collaborative and social computing-to engage in a discussion and retrospective. Pairs of panelists will represent each decade since the founding of the conferences, sharing a brief retrospective that surveys the most influential papers of that decade, the zeitgeist of the problems that were popular that decade and why, and what each decade's work has to say to the decades that came before and after. The panel is intended as a space to celebrate advances in the field, and reflect on the burdens and opportunities that it faces ahead.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Understanding Undergraduate Course Consideration\n", "abstract": " Elective curriculums require undergraduates to choose from a large roster of courses for enrollment each term. It has proven difficult to characterize this fateful choice process as it remains largely unobserved. Using digital trace data to observe this process at scale at a private research university, together with qualitative student interviews, we provide a novel empirical study of course consideration as part of the course selection process. Clickstream logs from a course exploration platform used by most undergraduates at the case university reveal that students consider on average nine courses for enrollment for their first fall term (< 2% of available courses) and these courses predict which academic major students declare two years later. Twenty-nine interviews confirm that students experience consideration as complex and reveal variation in consideration strategy that may influence how consideration unfolds. Consideration presents a promising site for intervention in problems of equity, career funneling and college completion.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Learning Predicates as Functions to Enable Few-shot Scene Graph Prediction\n", "abstract": " Scene graph prediction --- classifying the set of objects and predicates in a visual scene --- requires substantial training data. However, most predicates only occur a handful of times making them difficult to learn. We introduce the first scene graph prediction model that supports few-shot learning of predicates. Existing scene graph generation models represent objects using pretrained object detectors or word embeddings that capture semantic object information at the cost of encoding information about which relationships they afford. So, these object representations are unable to generalize to new few-shot relationships. We introduce a framework that induces object representations that are structured according to their visual relationships. Unlike past methods, our framework embeds objects that afford similar relationships closer together. This property allows our model to perform well in the few-shot setting. For example, applying the 'riding' predicate transformation to 'person' modifies the representation towards objects like 'skateboard' and 'horse' that enable riding. We generate object representations by learning predicates trained as message passing functions within a new graph convolution framework. The object representations are used to build few-shot predicate classifiers for rare predicates with as few as 1 labeled example. We achieve a 5-shot performance of 22.70 recall@50, a 3.7 increase when compared to strong transfer learning baselines.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "This list excludes newspaper and equivalent articles cited in the text. Ackroyd, Stephen and Paul Thompson. Organizational Misbehaviour. London: Sage, 1999. ACTRAV Bureau for\u00a0\u2026\n", "abstract": " Bibliography Page 1 341 Bibliography This list excludes newspaper and equivalent articles cited in the text. Ackroyd, Stephen and Paul Thompson. Organizational Misbehaviour. London: Sage, 1999. ACTRAV Bureau for Workers\u2019 Activities. Just Transition towards Environmentally Sustainable Economies and Societies for All. Geneva: International Labour Organization, ILO ACTRAV Policy Brief, 2018. Addo, Michael K. \u2018Symposium: Human Rights Perspectives of Corporate Groups\u2019. Connecticut Law Review 37 (2005): 667\u201389. Albarr\u00e1n, Daniel Gallardo. A Composite Perspective on British Living Standards during the Industrial Revolution. Groningen, NL: Groningen Growth and Development Centre, University of Groningen, 2016. Alcorso, Caroline. The Effects of Enterprise Bargaining on Employees from NESB. Report to DIR for 1995 Enterprise Bargaining Report. Canberra: Department of Industrial Relations, 1996. \u2026", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Prototype Tasks: Improving Crowdsourcing Results through Rapid, Iterative Task Design\n", "abstract": " Low-quality results have been a long-standing problem on microtask crowdsourcing platforms, driving away requesters and justifying low wages for workers. To date, workers have been blamed for low-quality results: they are said to make as little effort as possible, do not pay attention to detail, and lack expertise. In this paper, we hypothesize that requesters may also be responsible for low-quality work: they launch unclear task designs that confuse even earnest workers, under-specify edge cases, and neglect to include examples. We introduce prototype tasks, a crowdsourcing strategy requiring all new task designs to launch a small number of sample tasks. Workers attempt these tasks and leave feedback, enabling the requester to iterate on the design before publishing it. We report a field experiment in which tasks that underwent prototype task iteration produced higher-quality work results than the original task designs. With this research, we suggest that a simple and rapid iteration cycle can improve crowd work, and we provide empirical evidence that requester \u201cquality\u201d directly impacts result quality.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "SentenceRacer: A Game with a Purpose for Image Sentence Annotation\n", "abstract": " Recently datasets that contain sentence descriptions of images have enabled models that can automatically generate image captions. However, collecting these datasets are still very expensive. Here, we present SentenceRacer, an online game that gathers and verifies descriptions of images at no cost. Similar to the game hangman, players compete to uncover words in a sentence that ultimately describes an image. SentenceRacer both generates and verifies that the sentences are accurate descriptions. We show that SentenceRacer generates annotations of higher quality than those generated on Amazon Mechanical Turk (AMT).", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Health Promotion and Chronic Disease Prevention in Canada\n", "abstract": " Vol 35, No 4, June 2015 - Health Promotion and Chronic Disease Prevention in Canada: Research, Policy and Practice - Canada.ca Skip to main content Skip to \"About government\" Language selection Fran\u00e7ais fr Government of Canada / Gouvernement du Canada Search Search Canada.ca Search Menu Main Menu Jobs and the workplace Immigration and citizenship Travel and tourism Business and industry Benefits Health Taxes Environment and natural resources National security and defence Culture, history and sport Policing, justice and emergencies Transport and infrastructure Canada and the world Money and finances Science and innovation You are here: 1.Canada.ca 2.Public Health Agency of Canada 3.Public Health Agency of Canada reports and publications 4.Health Promotion and Chronic Disease Prevention in Canada: Research, Policy and Practice Vol 35, No 4, June 2015 - Health Promotion \u2026", "num_citations": "0\n", "authors": ["1164"]}
{"title": "2014 Index IEEE Transactions on Visualization and Computer Graphics Vol. 20\n", "abstract": " This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the co-authors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under the primary entry in the Author Index.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "HCOMP-13 Organization\n", "abstract": " HCOMP-13 Organization Page 1 Conference Cochairs Bj\u00f6rn Hartmann (University of California, Berkeley, USA) Eric Horvitz (Microsoft Research, USA) Works in Progress and Demonstration Chair Jeffrey P. Bigham (Carnegie Mellon University, USA) Workshop and Tutorials Chair Aditya G. Parameswaran (Stanford University, USA) Sponsorship Chair Michael Kearns (University of Pennsylvania, USA) Program Committee Paul Bennett (Microsoft Research, USA) Michael Bernstein (Stanford University, USA) Yiling Chen (Harvard University, USA) Ed H. Chi (Google, USA) Lydia B. Chilton (University of Washington, USA) Janis L. Dickinson (Cornell University, USA) Mike Franklin (University of California, Berkeley, USA) Krzysztof Gajos (Harvard University, USA) Hector Garcia-Molina (Stanford University, USA) Jeffrey Heer (University of Washington, USA) Haym Hirsh (Rutgers University, USA) Panos Ipeirotis (New York \u2026", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Who gives a tweet? Evaluating microblog content gives us an insight into what makes a valuable academic tweet\n", "abstract": " Taking first steps in the Twitterverse can be a nerve-wrecking experience with new users unsure what thoughts to tweet to the world. Here, Paul Andr\u00e9, Michael Bernstein and Kurt Luther attempt to fill the void and give some insights into what makes interesting and valuable microblog content.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Predicting Content Quality From User Behavior\n", "abstract": " Whether it is a video blog about a new product, a posting about meeting an old high school fling or a shared document in the cloud, users create, contribute, and disseminate an astonishing amount of valuable information. User-contributed videos and discussion on YouTube alone are expected to produce over one billion dollars of revenue in 20121. However, not all content is created equal. Some is genuinely good, created with care and concern. Other content is assembled in a hurry, and may be of limited value to others. Some is even written in bad faith in an attempt to mislead. For example, the New York Times recently exposed the booming business of generating fraudulent Amazon product reviews for pay2. As more and more people generate content, this problem will only be exacerbated as the amount of content outstrips the human capacity to filter out the chaff. While existing approaches can readily identify\u00a0\u2026", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Profile Armando Solar-Lezama Programming machines to program bits\n", "abstract": " DOI: 10.1145/1836543.1836556 It\u2019s the rare programmer who doesn\u2019t get frustrated by her own code. Bugs are tough to pinpoint, race conditions produce unpredictable results, and performance tweaks means rewiring large blocks of code. For most programmers, these situations are just a fact of life. Others are a bit more introspective, recognizing when they tend to make the same errors over and over. And a select few of those intend to do something about it. Professor Armando Solar-Lezama is one of them. Solar-Lezama is a programming systems researcher at the Massachussets Institute of Technology\u2019s Computer Science and Artificial Intelligence Lab (CSAIL), and a recent Ph. D. graduate from University of California-Berkeley. If he gets his way, you will be programming more complex systems with less hassle. His modus operandi is to use automation and reasoning to support difficult programming problems\u00a0\u2026", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Profile John Resig Origins of the JavaScript ninja\n", "abstract": " Resig created jQuery in 2006 to make his own web development easier. Since then, the open-source JavaScript library has spiraled into one of the most popular web front-end resource in use today. It\u2019s fast, simple, extensible, and provides a conceptually consistent wrapper around the spaghetti of mutually incompatible APIs that constitute today\u2019s JavaScript programming environment. Resig\u2019s itch that led to jQuery began while he was a student at Rochester Institute of Technology (RIT).\u201cIt was incredibly frustrating to try and build a front-end application that would just work,\u201d he says. He began making life easier for himself by writing two independent pieces of software: a CSS class selector and an animation library. Those two projects meged together to become the first release of jQuery. Resig then turned his attention to crossbrowser compatibility, and the project flew onward and upward from there. Most\u00a0\u2026", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Simplifying knowledge acquisition from end-users on the semantic web\n", "abstract": " In this position paper, we argue that improved mechanisms for knowledge acquisition on the semantic web (SW) will be necessary before it will be adopted widely by end-users. In particular, we propose an investigation surrounding improved languages for knowledge exchange, better UI mechanisms for interaction, and potential help from user modeling to enable accurate, efficient, SW knowledge modeling for everyone. Copyright is held by the author/owner(s).", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Understanding and Supporting Directed Content Sharing on the Web\n", "abstract": " To find interesting, personally relevant web content, we often rely on friends and colleagues to pass links along as they encounter them. In this paper, we study and augment link-sharing via e-mail, the most popular means of sharing web content today. Armed with survey data indicating that active sharers of novel web content are often those that actively seek it out, we present FeedMe, a plug-in for Google Reader that makes directed sharing of content a more salient part of the user experience. Our survey research indicates that sharing is moderated by concern about relevancy to the recipient, a desire to send only novel content to the recipient, and the effort required to share. FeedMe allays these concerns by recommending friends who may be interested in seeing the content, providing information on what the recipient has seen and how many emails they have received recently, and giving recipients the opportunity to provide lightweight feedback when they appreciate shared content. FeedMe introduces a novel design space for mixed-initiative social recommenders: friends who know the user voluntarily vet the material on the user\u00e2  s behalf. We present a two week field experiment (N=60) demonstrating that FeedMe\u00e2  s recommendations and social awareness features made it easier and more enjoyable to share content that recipients appreciated and would not have found otherwise.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "CHIstory\n", "abstract": " How might the world view human-computer interaction a century from now? In this video, set one hundred years in the future, we playfully re-envision the early history of HCI. As the video opens, the Great Usability Cataclysm of 2068 has erased all previous knowledge of HCI. The world has been plunged into an age of darkness where terror, fear, and poor usability reign. Unearthing fragments of previously lost archival footage, a disembodied HCI historian (Jonathan Grudin) introduces a first attempt to reconstruct the history of our field. Pioneering systems like NLS and Sketchpad are reviewed alongside more recent work from CHI and related conferences. The results may surprise and perplex as much as they entertain, but most of all, we hope they inspire reflection on the past and future of our field.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Information Scraps: Understanding and Design\n", "abstract": " In this thesis I investigate information scraps\u2013personal information whose content has been scribbled on Post-it notes, scrawled on the corners of sheets of paper, stuck in our pockets, sent in e-mail messages to ourselves, and stashed into miscellaneous digital text files. Information scraps encode information ranging from ideas and sketches to notes, reminders, shipment tracking numbers, driving directions, and even poetry.I proceed by performing an in-depth ethnographic investigation of the nature and use of information scraps, and by designing and building two research systems designed for information scrap management. The first system, Jourknow, lowers the capture barrier for unstructured notes and structured information such as calendar items and to-dos, captures contextual information surrounding note creation such as location, documents viewed, and people corresponded with, and manages uncommon user-generated personal information such as restaurant reviews or this week\u2019s shopping list. The follow-up system, Pinky, further explores the lightweight capture space by providing a command line interface that is tolerant to re-ordering and GUI affordances for quick and accurate entry. Reflecting on these tools\u2019 successes and failures, I characterize the design process challenges inherent in designing and building information scrap tools.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "The Editorial Office would like to thank the following referees for their support reviewing articles during the year of 2008.\n", "abstract": " Acknowledgement to reviewers 2008 Page 1 ACKNOWLEDGEMENT Acknowledgement to reviewers 2008 \u00a9 Am Soc Emergency Radiol 2008 Olu Adesanya Zohair Al aseri Andrew Allmendinger Chiara Andreoli Kelli Andresen Sander Anten Javier Arnaiz Joseph Aulino Laura Avery Nafi Aygun Dominic Barron Goetz Benndorf Lorin Benneker D Lee Bennett Mark Bernstein Ronald Bilow Jeffrey Bisker Christopher Blackmore Alexis Boscak Eric Bourekas Zulkif Bozgeyik Joshua Broder Olga Brook Liem Bui-Mansfield Marc Camacho Claudio Cancelli Gianpaolo Carrafiello Emanuele Casciani German Castrillon Orlando Catalano Alan Chalmers Joseph Chen Hyeon Je Cho Jonathan Chung Filip Claus Maria Chiara Colaiacomo Bret Coughlin Nikos Courcoutsakis Chris Cousens Carmel Cronin David Dang Francesco Danza Ketan Davae Gulen Demirpolat Peter Doris Arockia Doss Ana Echenique Shigeru Ehara \u2026", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Databasket: Coherent Shared Data for the Web\n", "abstract": " Web applications have put significant effort into personalization services to improve the user experience. The current personalization model suffers from two major drawbacks: each site has access to a very limited subset of information about the user, and the users themselves have little or no control about what data is maintained and how it is kept private. Users thus repeat personalizing rituals across a number of sites, specifying their names, email and shipping addresses, and interests; and web sites often make poor predictions, recommending items when inappropriate or the wrong items altogether. Web sites occasionally see privacy gaffes such as America Online\u2019s in 2006, sharing personal data on the Web and exposing their users to fraud and identity theft.In this paper we propose a user-controlled central database of personal information called Databasket (Figure 1) as a potential reinvention of web personalization. We place the data locally on the user\u2019s computer, ensuring that the user him-or herself has primary control over how the data is shared. We provide a Javascript API for web sites to query over a range of this data once the user has granted permission, thus allowing web sites access to customize using broader, more up-to-date data. To control data access, we have designed an interface drawing on research in usable privacy and security to keep the user (arguably the most vulnerable link) aware and in control.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Personal Information Management, Personal Information Retrieval?\n", "abstract": " Traditional information retrieval has focused on the task of finding information or documents in a largely unknown space such as the Web or a library collection. In this paper we propose that the space of Personal Information Management (PIM) holds a great number of problems and untapped potential for research at the intersection of HCI and IR. In this position paper we focus on the problem of information scraps, or unstructured notes and thoughts, as a particularly interesting space for future research in HCI and IR.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Reflective Physical Prototyping through Integrated Design, Test, and Analysis\n", "abstract": " Prototyping is the pivotal activity that structures innova-tion, collaboration, and creativity in design. Prototypes embody design hypotheses and enable designers to test them. Framing design as a thinking-by-doing activity foregrounds iteration as a central concern. This paper presents d. tools, a toolkit that embodies an iterative-design-centered approach to prototyping information appliances. This work offers contributions in three areas. First, d. tools introduces a statechart-based visual design tool that provides a low threshold for early-stage prototyping, extensible through code for higher-fidelity prototypes. Second, our research introduces three important types of hardware extensibility\u2013at the hardware-to-PC interface, the intra-hardware communication level, and the circuit level. Third, d. tools integrates design, test, and analysis of information appli-ances. We have evaluated d. tools through three studies: a laboratory study with thirteen participants; rebuilding pro-totypes of existing and emerging devices, and by observing seven student teams who built prototypes with d. tools. ACM Classification: H. 5.2.[Information Interfaces]: User", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Interviewees and Correspondents\n", "abstract": " The following persons generously described the methods they have found useful in continuing their medical education after formal training. Most were interviewed by telephone or in person, whereas some returned written statements in response to specific questions, and others answered questionnaires distributed at courses conducted by the University of Southern California School of Medicine. The list includes world-renowned academicians, solo and group practitioners, and some spouses. The pages containing quotations from interviewees are shown next to their names. All those listed made significant contributions, but since some concepts were mentioned by many different physicians, it was not possible to quote everyone directly.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Professor Stuart W. Churchill on his 80th birthday\n", "abstract": " \ud654\ud559\uacf5\ud559\uc18c\uc7ac\uc5f0\uad6c\uc815\ubcf4\uc13c\ud130(CHERIC) | \uc5f0\uad6c\uc815\ubcf4 | \ubb38\ud5ccDB | \ud559\uc220\uc9c0 \uac80\uc0c9 \ud654\ud559\uacf5\ud559\uc18c\uc7ac\uc5f0\uad6c\uc815\ubcf4 \uc13c\ud130 \ud648 \ub85c\uadf8\uc778 \ub85c\uadf8\uc544\uc6c3 \uc5f0\ub77d\ucc98 \uc0ac\uc774\ud2b8\ub9f5 \uc13c\ud130 \uc13c\ud130\uc18c\uac1c \ud68c\uc6d0\uac00\uc785/\uc815\ubcf4\uc218\uc815 \ub274\uc2a4 \uacf5\uc9c0\uc0ac\ud56d \uc5f0\uad6c \ub3d9\ud5a5 \uc6b0\uc218\uc5f0\uad6c\uc790\uc18c\uac1c \ucde8\uc5c5\uc815\ubcf4 \uc5f0\uad6c\uc815\ubcf4 \ubb38\ud5ccDB KDB Compound Search \uc804\ubb38\uc5f0\uad6c\uc815\ubcf4 \ub3d9\uc601\uc0c1 \uc2ec\ud3ec\uc9c0\uc6c0 \uc790\ub8cc \uc5f0\uad6c\uc131\uacfc\ubcf4\uace0\uc11c \uc800\ub110\uc815\ubcf4 \ub17c\ubb38 \uc791\uc131\ubc95 \ucc38\uace0\ubb38\ud5ccDB \ubd84\uc11d\uae30\uae30DB \ud654\ud559\uacf5\uc815DB PSPDB \uc5f0\uad6c\uc790\uc9c0\uc2dd\uc9c0\ub3c4 \uc0c1\ud0dc\ub3c4\uc815\ubcf4 \uad50\uc721\uc815\ubcf4 \uc0ac\uc774\ubc84\uac15\uc758-\ud559\ubd80 \uc0ac\uc774\ubc84\uac15\uc758-\ub300\ud559\uc6d0 \uc2e4\ubb34\uac15\uc88c \uac15\uc758 \uc790\ub8cc \ub9c1\ud06c \uad50\uc721\uc790\ub8cc \ub9c1\ud06c \uc0ac\uc774\ubc84\uc2e4\ud5d8\uc2e4 \ubb3c\uc131\uce21\uc815\uc2e4\ud5d8 \ub9e4\ub274\uc5bc \ucee4\ubba4\ub2c8\ud2f0 \uacf5\ud559\ud3ec\ub7fc \uce74\ud398 \uc2e0\uc9c4\uc5f0\uad6c\uc790 \uc778\ud130\ubdf0 \ub9ac\uc18c\uc2a4 \ud2b9\ud5c8\uc815\ubcf4 \uc220\uc5b4DB \uad00\ub828\ubc95\ub839 \uc790\uaca9\uc99d\uc815\ubcf4 \uc131\uacfc\uc18c\uac1c\uc11c \uc5f0\uad6c\ubcf4\uace0\uc11c \ubb38\ud5ccDB \ud559\uc220\uc9c0 \uac80\uc0c9 \ud559\uc220\ub300\ud68c \ubc1c\ud45c\ub17c\ubb38\uc9d1 \ucd5c\uc2e0 \uad6d\ub0b4 \uc800\ub110 \ucd5c\uc2e0 \ub9ac\ubdf0\ud398\uc774\ud37c KDB Periodic Table of Elements Unit Conversion Universal Constants Pure Component Properties Binary Vapor-Liquid Equil. Data Calculation Modules Research Articles Citing KDB Compound Search \uc804\ubb38\uc5f0\uad6c\uc815\ubcf4 \u2026", "num_citations": "0\n", "authors": ["1164"]}
{"title": "PolicyKit\n", "abstract": " Amy X. Zhang axz@cs.uw.edu Grant Hugh ghugh@stanford.edu Michael Bernstein msb@cs.stanford.edu University of Washing Page 1 Amy X. Zhang axz@cs.uw.edu Grant Hugh ghugh@stanford.edu Michael Bernstein msb@cs.stanford.edu University of Washington Stanford University PolicyKit Building Governance in Online Communities 1,2 2 2 2 1 Page 2 Consider all the tools you use to participate in online communities today. Page 3 When it comes to the governance model that these tools provide to communities, they all share a strikingly similar pattern: Admins Mods Regular Users Page 4 These tools describe governance using a permissions model. So when a user wants to do something, the tool just checks what permissions they have before they can do it. User A would like to do Action X Action X Action Y Action Z User A User B check their permissions Action X is approved Page 5 And in order to modify \u2026", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Design Tools\n", "abstract": " MICHAEL BERNSTEIN CS 376 Page 1 Design Tools MICHAEL BERNSTEIN CS 376 Page 2 Design tools should... [Hartmann, PhD thesis \u201909] \u00b7 Decrease UI construction time \u00b7 Isolate designers from implementation details \u00b7 Enable designers to explore an interface technology previously reserved to engineers or other technology experts 2 Page 3 Goal: facilitate rapid iteration [Hartmann, PhD thesis \u201909] \u00b7 Prototypes enable exploration and iteration around concrete artifacts \u00b7 The more fluid the prototyping process is, the more you can learn before you sink time into engineering 3 Page 4 Early stage design Page 5 What tools do designers use? [Myers et al., VLHCC \u201908] \u00b7 Survey of 259 interaction designers Page 6 SILK: Sketching Interfaces Like Krazy [Landay, CHI \u201996] \u00b7 Combine the fluidity of paper-based sketching with the interactivity of tools \u00b7 Technique: sketch recognition of basic UI components 6 Page 7 DENIM: \u2026", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Research Analysis\n", "abstract": " MICHAEL BERNSTEIN CS 376 Page 1 Research Analysis MICHAEL BERNSTEIN CS 376 Page 2 Last time \u00b7 What is a statistical test? \u00b7 Chi-square \u00b7 t-test \u00b7 Paired t-test 2 Page 3 Today \u00b7 ANOVA \u00b7 Posthoc tests \u00b7 Two-way ANOVA \u00b7 Repeated measures ANOVA 3 Page 4 Recall: hypothesis testing Page 5 Anatomy of a statistical test \u00b7 If your change had no effect, what would the world look like? \u00b7 This is known as the null hypothesis 5 No difference in means No slope in relationship Page 6 Anatomy of a statistical test \u00b7 Given the difference you observed, how likely is it to have occurred by chance? 6 Probability of seeing a mean difference at least this large, by chance, is 0.012 Probability of seeing a slope at least this large, by chance, is 0.012 Page 7 Errors 7 Difference exists? Difference detected? True positive Type 1 error publish false findings Type 2 error get more data? True negative Y N Y N Page 8 Errors 8 Page 9 p-\u2026", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Supporting Big Tasks through Microtasks\n", "abstract": " Untitled Page 1 Page 2 Supporting Big Tasks through Microtasks Chair: Andres Monroy-Hernandez (Microsoft Research) Presentations: \u2022 Jaime Teevan (Microsoft Research) \u2022 Jeff Bigham (Carnegie Mellon University) \u2022 Michael Bernstein (Stanford University) Discussion (build from The Future of Work: Societal Challenges) Page 3 Page 4 Page 5 Page 6 Page 7 mi\u00b7cro\u00b7pro\u00b7duc\u00b7tiv\u00b7i\u00b7ty /\u02c8m\u012bkr\u014d pr\u014d\u02ccd\u0259k\u02c8tiv\u0259t\u0113/ noun The transformation of large productivity tasks into a set of smaller microtasks that can be completed individually in short bursts of time with limited context. Page 8 Key Aspects of Microproductivity Task Structure \u2013 Break tasks into microtasks \u2022 State of art: Examples of many complex tasks can be broken down \u2022 Emerging: Workflow creation, composition, reuse; context maintenance Task Completion \u2013 Make it easy to complete microtasks \u2022 State of art: Microtasks easier, especially during mobile micromoments \u2022 \u2026", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Why We Protest| Anonymous Activism Forum\n", "abstract": " We present two studies of online ephemerality and anonymity based on the popular discussion board/b/at 4chan. org: a website with over 7 million users that plays an influential role in Internet culture. Although researchers and practitioners often assume that user identity and data permanence are central tools in the design of online communities, we explore how/b/succeeds despite being almost entirely anonymous and extremely ephemeral. We begin by describing/b/and performing a content analysis that suggests the community is dominated by playful exchanges of images and links. Our first study uses a large dataset of more than five million posts to quantify ephemerality in/b/. We find that most threads spend just five seconds on the first page and less than five minutes on the site before expiring. Our second study is an analysis of identity signals on 4chan, finding that over 90% of posts are made by fully anonymous users, with other identity signals adopted and discarded at will. We describe alternative mechanisms that/b/participants use to establish status and frame their interactions.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "InformationScraps: HowandWhyInformationEludesour PersonalInformationManagement Tools\n", "abstract": " In this paper we investigate information scraps\u2013a class of personal information whose content is scribbled on Post-it notes, scrawled on corners of sheets of paper, buried in the bodies of e-mail messages sent to ourselves, and typed haphazardly into text files. Information scraps hold our ideas, sketches, notes, reminders, driving directions, and even our poetry. We here introduce a line of PIM research on information scraps, defining them to be the body of personal information held outside of its natural home. Although information scraps are all but ubiquitous, we have much still to learn about these loose forms of information capture. Why are they so often kept outside of our traditional PIM locations and instead in small, freeform tools? Why must we sometimes circumvent our traditional PIM applications to hold on to our scraps, such as by e-mailing ourselves? What are information scraps' role in the larger space of personal information management, and what do they uniquely offer that we find so appealing? If these disorganized bits truly indicate the limits of our PIM tools, how might we begin to build better tools? We have pursued these questions by undertaking a study of 27 knowledge workers. In our findings we describe information scraps from several angles: their content, their location, and their lifecycle. We identify common roles that information scraps play: temporary storage, archiving, work-in-progress, reminding, and handling of unusual data. We present a set of design considerations that we have derived from the analysis of our study results. We conclude with our work on an application platform, Jourknow, to translate our results into a\u00a0\u2026", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Rapport d\u2019\u00e9tape Le syst\u00e8me de surveillance Cancer chez les jeunes au Canada\n", "abstract": " M\u00eame si le cancer infantile demeure la principale cause de d\u00e9ces li\u00e9 ala maladie chez les enfants de moins de 14 ans, il est relativement rare1, 2. Chaque ann\u00e9e au Canada, environ 910 enfants recoivent un diagnostic de cancer et 139 meurent de la maladie3. Sur le plan biologique, les cancers infantiles different de ceux habituellement observ\u00e9s chez les adultes4, 5. Chez ces derniers, la majorit\u00e9 des cancers sont des carcinomes du tissu \u00e9pith\u00e9lial qui tapisse les organes comme le sein, le poumon, le colon et la prostate. Chez les enfants, les carcinomes sont rares, et les tumeurs p\u00e9diatriques sont le plus souvent d\u2019origine embryonnaire ou h\u00e9matopo\u0131\u00e9tique5. Les groupes de diagnostic les plus nombreux sont ceux de la leuc\u00e9mie, du lymphome et des cancers du systeme nerveux central5. Comparativement aux cancers chez les adultes, les cancers chez les enfants ont des p\u00e9riodes de latence plus courte et sont g\u00e9n\u00e9ralement plus agressifs, envahissants et avanc\u00e9s au moment du diagnostic5.Malgr\u00e9 le rang \u00e9lev\u00e9 qu\u2019occupe le cancer comme cause de d\u00e9ces chez les enfants, le taux de survie s\u2019 est grandement am\u00e9lior\u00e9 au cours des vingt dernieres ann\u00e9es, de sorte que les enfants survivent au cancer plus que jamais auparavant6. Toutefois, plus de 60% des survivants d\u2019un cancer infantile sont confront\u00e9s aux effets secondaires physiques et psychologiques along terme de la maladie et de son traitement, et presque 30% d\u2019entre eux \u00e9prouvent des effets tardifs graves ou potentiellement", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Why We Protest| Activism Forum\n", "abstract": " We present two studies of online ephemerality and anonymity based on the popular discussion board/b/at 4chan. org: a website with over 7 million users that plays an influential role in Internet culture. Although researchers and practitioners often assume that user identity and data permanence are central tools in the design of online communities, we explore how/b/succeeds despite being almost entirely anonymous and extremely ephemeral. We begin by describing/b/and performing a content analysis that suggests the community is dominated by playful exchanges of images and links. Our first study uses a large dataset of more than five million posts to quantify ephemerality in/b/. We find that most threads spend just five seconds on the first page and less than five minutes on the site before expiring. Our second study is an analysis of identity signals on 4chan, finding that over 90% of posts are made by fully\u00a0\u2026", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Heads in the Cloud: Challenges and Opportunities in Human Computation\n", "abstract": " Crowd computing is rapidly becoming an essential part of the landscape of modern computing. Crowd computing encompasses the interaction among large numbers of people facilitated by software systems and increasingly ubiquitous networking technology. Crowds are powering intellectual enterprises (Wikipedia), real-time information media (Twitter), prediction markets (Intrade), and online labor markets (Amazon Mechanical Turk). One way to think about crowd computing is as the human analogue to cloud computing. Where the cloud provides access to elastic, highly available computation and storage resources out in the network, the crowd represents access to elastic, highly-available human resources, such as human perception and intelligence. Crowd computing offers the potential to build systems that combine the strengths of software with the intelligence and common sense of human beings.The particular variant of crowd computing considered in this article is human computation, which we define as using software to orchestrate a process of small contributions from a crowd to solve a problem that can\u2019t be solved by software alone. Human computation was first popularized by Games With a Purpose (GWAP), in which the computation is a side effect of a fun game [8]. For example, the ESP Game asks two players to guess words associated with an image, scoring points when their words agree (which makes the game fun), but also generating useful labels to index the image for searching (which makes it human computation).", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Examining Personal Information Management in a Lightweight Note-Taking Tool\n", "abstract": " This paper describes a longitudinal field experiment in personal note-taking that examines how people capture and use information in short textual notes. Study participants used our tool, a simple browser-based textual note-taking utility, to capture personal information over the course of ten days. We examined the information they kept in notes using the tool, how this information was expressed, and aspects of note creation, editing, deletion, and search. We found that notes were recorded extremely quickly and tersely, combined information of multiple types, and were rarely revised or deleted. The results of the study not only demonstrated the need for a tool such as ours to support the rapid capture and retrieval of short notes-to-self, but also provided evidence of how users' actual note-keeping tendencies could be used to better support their needs in future PIM tools.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Diamond\u2019s Edge: From Paper to Table and Back Again\n", "abstract": " We discuss the interaction benefits derived from combining the collaborative nature of touch-sensitive tabletop interfaces with the paper affordances and personal space of digital pen and paper. The pen may be used as fluid input to create and transform content within the public table space, and the table\u2019s top-down projection as a method to augment the physical paper with properties of digital output. Finally, we introduce Diamond\u2019s Edge, a design brainstorming tool which incorporates the interaction techniques described.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Stanford University HCI Group Computer Science Department Stanford, CA 94305-9035, USA {bjoern, srk}@ cs. stanford. edu\n", "abstract": " Prototyping tomorrow\u2019s computing technologies\u2014which transcend the desktop PC\u2014poses a unique challenge for designers. Prototyping tools should offer a high-level approach that generates working results quickly. d. tools is a design tool for prototyping the bits and the atoms of physical user interfaces in concert. It enables designers without specialized engineering or programming knowledge to quickly build functional interactive prototypes. d. tools offers a visual authoring environment that allows for drag-and-drop specification of interaction models for tangible user interfaces in a matter of minutes.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Communications-Efficient Multithreading on Wide-Area Networks\n", "abstract": " This paper shows how to run multithreaded programs on a DRAM (Distributed Random Access Memory) parallel computer and demonstrates that such programs can run efficiently on a collection of machines distributed across thousands of miles over the internet. Suppose we have a fully strict multithreaded program has work \u0430\u0432\u0431 and critical-path length \u0430\u0434\u0433, and we have a \u0435 processor DRAM machine with \u0436 an upper bound to the cost of routing any permutation. This paper presents a deterministic conservative DRAM scheduling algorithm that runs in time \u0437\u0439 \u0436 \u0435\"!# \u0438\u0430\u0431% $ \u0435& \u0430\u0433!! and a randomized conservative DRAM scheduling algorithm that runs in time \u0430\u0431'$ \u0435 () \u0437\u0439 \u04360 1 2 \u0435\"! \u0430\u0433!. We have modified the Cilk multithreaded runtime system to use our randomized conservative DRAM scheduler. Surprisingly the modified system, called TreeCilk, often achieves a performance improvement when one 2000-mile-away machine is added to a tightly-bound cluster of machines.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Taskpos\u00e9: Exploring Fluid Boundaries in a Task-Based Window Manager\n", "abstract": " Window managers assist users in navigating their computing workspaces by providing an organizational and access mechanism for their open windows. Window manager research has aimed to leverage users\u2019 tasks to organize the growing number of open windows in a useful manner. This research has assumed task classifications to be binary\u2014a window is in a task, or not\u2014and context-independent. We suggest that tasks\u2019 continual evolution can invalidate this approach and introduce association between artifacts as an alternative organizational scheme. Association relates windows to one another at varying degrees; task-relatedness is an emergent property of association. We describe Taskpos\u00e9, our implementation of an associative window manager, and report on a week-long user study of the system.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "Information Scraps: Eluding our Personal Information Management Tools\n", "abstract": " Despite the number of personal information management tools available today, a striking amount of our data remains out of their reach: the content is instead scribbled on Post-it notes, scrawled on corners of sheets of paper, buried inside the bodies of e-mail messages sent to ourselves, and typed haphazardly into text files. This scattered data contains our great ideas, sketches, notes, reminders, driving directions, and even our poetry.We refer to these pieces of personal information as information scraps. The term conjures up several images: notes that are written on a scrap of paper, or that have been separated from the rest of our personal information collections. Information scraps can be to-dos, notes to yourself (Lin et al., 2004), passwords, song lyrics, or a variety of other information. In this paper, we investigate the existence, use, and composition of information scraps via our own focused study of the information scrap.", "num_citations": "0\n", "authors": ["1164"]}
{"title": "The Trouble With Systems Research in Social Computing\n", "abstract": " Social computing has led to an explosion of research in understanding users, and has the potential to similarly revolutionize systems research. However, the number of papers designing and building new sociotechnical systems has not kept pace. In this paper we analyze the reasons for this disparity, ranging from misaligned methodological incentives, evaluation expectations and research relevance compared to industry. We suggest improvements for the community to consider and evolve so that we can chart the future of our field.", "num_citations": "0\n", "authors": ["1164"]}