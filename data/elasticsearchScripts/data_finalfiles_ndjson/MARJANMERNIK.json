{"title": "Self-adapting control parameters in differential evolution: A comparative study on numerical benchmark problems\n", "abstract": " We describe an efficient technique for adapting control parameter settings associated with differential evolution (DE). The DE algorithm has been used in many practical cases and has demonstrated good convergence properties. It has only a few control parameters, which are kept fixed throughout the entire evolutionary process. However, it is not an easy task to properly set control parameters in DE. We present an algorithm-a new version of the DE algorithm-for obtaining self-adaptive control parameter settings that show good performance on numerical benchmark problems. The results show that our algorithm with self-adaptive control parameter settings is better than, or at least comparable to, the standard DE algorithm and evolutionary algorithms from literature when considering the quality of the solutions obtained", "num_citations": "3106\n", "authors": ["153"]}
{"title": "When and how to develop domain-specific languages\n", "abstract": " Domain-specific languages (DSLs) are languages tailored to a specific application domain. They offer substantial gains in expressiveness and ease of use compared with general-purpose programming languages in their domain of application. DSL development is hard, requiring both domain knowledge and language development expertise. Few people have both. Not surprisingly, the decision to develop a DSL is often postponed indefinitely, if considered at all, and most DSLs never get beyond the application library stage.Although many articles have been written on the development of particular DSLs, there is very limited literature on DSL development methodologies and many questions remain regarding when and how to develop a DSL. To aid the DSL developer, we identify patterns in the decision, analysis, design, and implementation phases of DSL development. Our patterns improve and extend earlier\u00a0\u2026", "num_citations": "2480\n", "authors": ["153"]}
{"title": "Exploration and exploitation in evolutionary algorithms: A survey\n", "abstract": " \u201cExploration and exploitation are the two cornerstones of problem solving by search.\u201d For more than a decade, Eiben and Schippers' advocacy for balancing between these two antagonistic cornerstones still greatly influences the research directions of evolutionary algorithms (EAs) [1998]. This article revisits nearly 100 existing works and surveys how such works have answered the advocacy. The article introduces a fresh treatment that classifies and discusses existing work within three rational aspects: (1) what and how EA components contribute to exploration and exploitation; (2) when and how exploration and exploitation are controlled; and (3) how balance between exploration and exploitation is achieved. With a more comprehensive and systematic understanding of exploration and exploitation, more research in this direction may be motivated and refined.", "num_citations": "1011\n", "authors": ["153"]}
{"title": "On clarifying misconceptions when comparing variants of the artificial bee colony algorithm by offering a new implementation\n", "abstract": " Artificial Bee Colony (ABC) is a Swarm Intelligence algorithm that has obtained meta-heuristic researchers\u2019 attention and favor over recent years. It comprises good balance between exploitation (employed bee phase and onlooker bee phase) and exploration (scout bee phase). As nowadays, more researchers are using ABC and its variants as a control group to perform comparisons, it is crucial that comparisons with other algorithms are fair. This paper points to some misapprehensions when comparing meta-heuristic algorithms based on iterations (generations or cycles) with special emphasis on ABC. We hope that through our findings this paper can be treated as a beacon to remind researchers to learn from these mistakes.", "num_citations": "229\n", "authors": ["153"]}
{"title": "Replication and comparison of computational experiments in applied evolutionary computing: common pitfalls and guidelines to avoid them\n", "abstract": " Replicating and comparing computational experiments in applied evolutionary computing may sound like a trivial task. Unfortunately, it is not so. Namely, many papers do not document experimental settings in sufficient detail, and hence replication of experiments is almost impossible. Additionally, some work fails to satisfy the thumb rules for Experimentation throughout all disciplines, such that all experiments should be conducted and compared under the same or stricter conditions. Also, because of the stochastic properties inherent in evolutionary algorithms (EAs), experimental results should always be rich enough with respect to Statistics. Moreover, the comparisons conducted should be based on suitable performance measures and show the statistical significance of one approach over others. Otherwise, the derived conclusions may fail to have scientific merits. The primary objective of this paper is to offer some\u00a0\u2026", "num_citations": "135\n", "authors": ["153"]}
{"title": "LISA: An interactive environment for programming language development\n", "abstract": " The LISA system is an interactive environment for programming language development. From the formal language specifications of a particular programming language LISA produces a language specific environment that includes editors (a language-knowledgable editor and a structured editor), a compiler/interpreter and other graphic tools. The LISA is a set of related tools such as scanner generators, parser generators, compiler generators, graphic tools, editors and conversion tools, which are integrated by well-designed interfaces.", "num_citations": "115\n", "authors": ["153"]}
{"title": "A chess rating system for evolutionary algorithms: A new method for the comparison and ranking of evolutionary algorithms\n", "abstract": " The Null Hypothesis Significance Testing (NHST) is of utmost importance for comparing evolutionary algorithms as the performance of one algorithm over another can be scientifically proven. However, NHST is often misused, improperly applied and misinterpreted. In order to avoid the pitfalls of NHST usage this paper proposes a new method, a Chess Rating System for Evolutionary Algorithms (CRS4EAs) for the comparison and ranking of evolutionary algorithms. A computational experiment in CRS4EAs is conducted in the form of a tournament where the evolutionary algorithms are treated as chess players and a comparison between the solutions of two algorithms on the objective function is treated as one game outcome. The rating system used in CRS4EAs was inspired by the Glicko-2 rating system, based on the Bradley\u2013Terry model for dynamic pairwise comparisons, where each algorithm is represented by\u00a0\u2026", "num_citations": "103\n", "authors": ["153"]}
{"title": "Automatic generation of language-based tools using the LISA system\n", "abstract": " Many tools have been constructed using different formal methods to process various parts of a language specification (e.g. scanner generators, parser generators and compiler generators). The automatic generation of a complete compiler was the primary goal of such systems, but researchers recognised the possibility that many other language-based tools could be generated from formal language specifications. Such tools can be generated automatically whenever they can be described by a generic fixed part that traverses the appropriate data structures generated by a specific variable part, which can be systematically derivable from the language specifications. The paper identifies generic and specific parts for various language-based tools. Several language-based tools are presented in the paper, which are automatically generated using an attribute grammar-based compiler generator called LISA. The\u00a0\u2026", "num_citations": "102\n", "authors": ["153"]}
{"title": "An educational tool for teaching compiler construction\n", "abstract": " Compiler construction is a well-developed discipline since there is a long tradition of producing compilers supported by practical underlying theory and a large selection of textbooks. In the compiler construction course, students learn how to write a compiler by hand and how to generate a compiler using tools like lex and yacc. However, these tools usually have little or no didactical value. In this paper, the software tool LISA is described. It facilitates learning and conceptual understanding of compiler construction in an efficient, direct, and long-lasting way. The authors' experience in using the tool shows the following didactical benefits: support for constructive learning, stimulation of exploratory and active learning, support for different learning styles and learning speed, increased motivation for learning, and better understanding of concepts.", "num_citations": "79\n", "authors": ["153"]}
{"title": "A parameter control method of evolutionary algorithms using exploration and exploitation measures with a practical application for fitting Sovova's mass transfer model\n", "abstract": " Exploration and exploitation are omnipresent terms in evolutionary computation community that have been broadly utilized to explain how evolutionary algorithms perform search. However, only recently exploration and exploitation measures were presented in a quantitative way enabling to measure amounts of exploration and exploitation. To move a step further, this paper introduces a parameter control approach that utilizes such measures as feedback to adaptively control evolution processes. The paper shows that with new exploration and exploitation measures, the evolution process generates relatively well results in terms of fitness and/or convergence rate when applying to a practical chemical engineering problem of fitting Sovova's model. We also conducted an objective statistical analysis using Bonferroni\u2013Dunn test and sensitivity analysis on the experimental results. The statistical analysis results again\u00a0\u2026", "num_citations": "77\n", "authors": ["153"]}
{"title": "Grammar\u2010driven generation of domain\u2010specific language debuggers\n", "abstract": " Domain\u2010specific languages (DSLs) assist a software developer (or end\u2010user) in writing a program using idioms that are similar to the abstractions found in a specific problem domain. Tool support for DSLs is lacking when compared with the capabilities provided for standard general\u2010purpose languages (GPLs), such as Java and C++. For example, support for debugging a program written in a DSL is often non\u2010existent. The lack of a debugger at the proper abstraction level limits an end\u2010user's ability to discover and locate faults in a DSL program. This paper describes a grammar\u2010driven technique to build a debugging tool generation framework from existing DSL grammars. The DSL grammars are used to generate the hooks needed to interface with a supporting infrastructure constructed for an integrated development environment that assists in debugging a program written in a DSL. The contribution represents a\u00a0\u2026", "num_citations": "77\n", "authors": ["153"]}
{"title": "Decision trees based on automatic learning and their use in cardiology\n", "abstract": " Computerized information systems, especially decision support systems, have become an increasingly important role in medical applications, particularly in those where important decision must be made effectively and reliably. But the possibility of using computers in medical decision making is limited by many difficulties, including the complexity of conventional computer languages, methodologies and tools. Thus a conceptual simple decision making model with the possibility of automating learning should be used. In this paper we introduce a cardiological knowledge-based system based on the decision tree approach supporting the mitral valve prolapse determination. Prolapse is defined as the displacement of a bodily part from its normal position. The term mitral valve prolaps (PMV), therefore, implies that the mitral leaflets are displaced relative to some structure, generally taken to be the mitral annulus\u00a0\u2026", "num_citations": "76\n", "authors": ["153"]}
{"title": "MARS: A metamodel recovery system using grammar inference\n", "abstract": " Domain-specific modeling (DSM) assists subject matter experts in describing the essential characteristics of a problem in their domain. When a metamodel is lost, repositories of domain models can become orphaned from their defining metamodel. Within the purview of model-driven engineering, the ability to recover the design knowledge in a repository of legacy models is needed.In this paper we describe MARS, a semi-automatic grammar-centric system that leverages grammar inference techniques to solve the metamodel recovery problem. The paper also contains an applicative case study, as well as experimental results from the recovery of several metamodels in diverse domains.", "num_citations": "72\n", "authors": ["153"]}
{"title": "Incremental programming language development\n", "abstract": " One of the well-known properties of software systems is that they are subject to changes. Incremental software development enables making such program changes in a non-destructive manner. In the area of programming language definition the language designer/implementer wants to include new language features incrementally as the programming language evolves. In the paper our approach to incremental programming language development is presented. The proposed approach has been successfully used in the development of real programming languages, which confirms feasibility in practice.", "num_citations": "71\n", "authors": ["153"]}
{"title": "Analysis of exploration and exploitation in evolutionary algorithms by ancestry trees\n", "abstract": " This paper introduces an ancestry tree-based approach for exploration and exploitation analysis. The approach introduces a data structure to record the evolution history of a population and a number of exploration and exploitation metrics. Such an approach not only provides insight of how and when the exploration and exploitation influence an evolution process, but also how the genetic structure of an individual is affected. It can be used to better understand inner working of an evolutionary algorithm or in evolutionary algorithm designing phase to develop suitable variation operators with good balance between exploration and exploitation. The approach is applied to the multi-objective 0/1 knapsack problem.", "num_citations": "70\n", "authors": ["153"]}
{"title": "Is a comparison of results meaningful from the inexact replications of computational experiments?\n", "abstract": " The main objective of this paper is to correct the unreasonable and inaccurate criticism to our previous experiments using Teaching\u2013Learning-Based Optimization algorithm and to quantify the amount of error that may arise due to incorrect counting of fitness evaluations. It is shown that inexact experiment replication should be avoided in comparisons between meta-heuristic algorithms whenever possible. Otherwise, an inexact replication and margin of error should be explicitly reported.", "num_citations": "66\n", "authors": ["153"]}
{"title": "Parameter tuning with Chess Rating System (CRS-Tuning) for meta-heuristic algorithms\n", "abstract": " Meta-heuristic algorithms should be compared using the best parameter values for all the involved algorithms. However, this is often unrealised despite the existence of several parameter tuning approaches. In order to further popularise tuning, this paper introduces a new tuning method CRS-Tuning that is based on meta-evolution and our novel method for comparing and ranking evolutionary algorithms Chess Rating System for Evolutionary Algorithms (CRS4EAs). The utility or performance a parameter configuration achieves in comparison with other configurations is based on its rating, rating deviation, and rating interval. During each iteration significantly worse configurations are removed and new configurations are formed through crossover and mutation. The proposed tuning method was empirically compared to two well-known tuning methods F-Race and Revac through extensive experimentation where the\u00a0\u2026", "num_citations": "60\n", "authors": ["153"]}
{"title": "An object-oriented approach to language compositions for software language engineering\n", "abstract": " In this paper, it is shown that inheritance, a core concept from object-oriented programming, is a possible solution for realizing composition of computer languages. Language composability is a property of language descriptions, which can be further classified into informal (language syntax and semantics are hard-coded in compiler/interpreter) and formal language descriptions (syntax and semantics are formally specified with one of several formal methods for language definition). However, language composition is much easier to achieve with declarative formal language descriptions into which the notion of inheritance is introduced. Multiple attribute grammar inheritance, as implemented in the language implementation system LISA, can assist in realizing all of the different types of language compositions identified in Erdweg et al. (2012). Different examples are given throughout the paper using an easy to\u00a0\u2026", "num_citations": "57\n", "authors": ["153"]}
{"title": "To explore or to exploit: An entropy-driven approach for evolutionary algorithms\n", "abstract": " An evolutionary algorithm is an optimization process comprising two important aspects: exploration discovers potential offspring in new search regions; and exploitation utilizes promising solutions already identified. Intelligent balance between these two aspects may drive the search process towards better fitness results and/or faster convergence rates. Yet, how and when to control the balance perceptively have not yet been comprehensively addressed. This paper introduces an entropy-driven approach for evolutionary algorithms. Five kinds of entropy to express diversity are presented; and the balance between exploration and exploitation is adaptively controlled by one kind of entropy and mutation rate in a metaprogramming fashion. The experimental results of the benchmark functions show that the entropy-driven approach achieves explicit balance between exploration and exploitation and hence obtains even\u00a0\u2026", "num_citations": "57\n", "authors": ["153"]}
{"title": "Multiple attribute grammar inheritance\n", "abstract": " The language design process should be supported by modularity and abstraction in a manner that allows incremental changes as easily as possible. To at least partially fullfil this ambitious goal a new object-oriented attribute grammar specication language which supports multiple attribute grammar inheritance is introduced. Multiple attribute grammar inheritance is a structural organization of attribute grammars where the attribute grammar inherits the specifications from ancestor attribute grammars, may add new specifications or may override some specifications from ancestor specifications. With the proposed approach a language designer has the chance to design incrementally a language or reuse some fragments from other programming language specifications. The multiple attribute grammar inheritance is first introduced using an example, and thereafter by a formal model. The proposed approach is successfully implemented in the compiler/interpreter generator tool LISA ver. 2.0.", "num_citations": "54\n", "authors": ["153"]}
{"title": "Compiler/interpreter generator system LISA\n", "abstract": " The paper describes the LISA system which is a generic interactive environment for programming language development. From the formal language specifications of a particular programming language, LISA produces a language specific environment that includes a language-knowledgeable editor, a compiler/interpreter and other graphic tools. The paper focuses on design decisions, implementation issues and tool integration in the system LISA. The main reasons for developing a new compiler/interpreter generator system were: support for incremental language development, support for language design in a visual manner and the portability of the system and the generated environment. LISA is a set of related tools such as scanner generators, parser generators, compiler generators, graphic tools, editor and conversion tools, which are integrated by well designed interfaces. Therefore, it has the advantages of a\u00a0\u2026", "num_citations": "50\n", "authors": ["153"]}
{"title": "Program comprehension for domain-specific languages\n", "abstract": " In the past, we have been looking for program comprehension tools that are able to interconnect operational and behavioral views, aiming at aiding the software analyst to relate problem and program domains in order to reach a full understanding of software systems. In this paper we are concerned with Program Comprehension issues applied to Domain Specific Languages (DSLs). We are now willing to understand how techniques and tools for the comprehension of traditional programming languages fit in the understanding of DSLs. Being the language tailored for the description of problems in a specific domain, we believe that specific visualizations (at a higher abstraction level, closer to the problem level) could and should be defined to enhance the comprehension of the descriptions in that particular domain. .", "num_citations": "49\n", "authors": ["153"]}
{"title": "Weaving a debugging aspect into domain-specific language grammars\n", "abstract": " A common trend in programming language specification is to generate various tools (eg, compiler, editor, profiler, and debugger) from a grammar. In such a generative approach, it is desirable to have the definition of a programming language be modularized according to specific concerns specified in the grammar. However, it is often the case that the corresponding properties of the generated tools are scattered and tangled across the language specification. In this paper, separation of concerns within a programming language specification is demonstrated by considering debugging support within a domain-specific language (DSL). The paper first describes the use of AspectJ to weave the debugging semantics into the code created by a parser generator. The paper outlines several situations when the use of AspectJ is infeasible at separating language specification properties. To accommodate such situations, a\u00a0\u2026", "num_citations": "49\n", "authors": ["153"]}
{"title": "Context-free grammar induction using genetic programming\n", "abstract": " While grammar inference is used in areas like natural language acquisition, syntactic pattern recognition, etc., its application to the programming language problem domain has been limited. We propose a new application area for grammar induction which intends to make domain-specific language development easier and finds a second application in renovation tools for legacy systems. The genetic programming approach is used for grammatical inference. Our earlier work used grammar-specific heuristic operators in tandem with non-random construction of the initial grammar population and succeeded in inducing small grammars.", "num_citations": "43\n", "authors": ["153"]}
{"title": "Can a parser be generated from examples?\n", "abstract": " One of the open problems in the area of domain-specific languages is how to make domain-specific language development easier for domain experts not versed in a programming language design. Possible approaches are to build a domain-specific language from parameterized building blocks or by language (grammar) induction. This paper uses an evolutionary approach to grammar induction. Grammar-specific genetic operators for crossover and mutation are proposed to achieve this task. Suitability of the approach is shown by small experiments where underlying grammars are successfully genetically obtained and parsers are than automatically generated.", "num_citations": "42\n", "authors": ["153"]}
{"title": "Implementation of multiple attribute grammar inheritance in the tool LISA\n", "abstract": " Multiple attribute grammar inheritance is a structural organization of attribute grammars where the attribute grammar inherits the specifications from ancestor attribute grammars, may add new specifications or may override some specifications from ancestor specifications. In the paper the implementation of multiple attribute grammar inheritance is described. The proposed approach is successfully implemented in the compiler/interpreter generator tool LISA ver. 2.0.", "num_citations": "41\n", "authors": ["153"]}
{"title": "A hybrid evolutionary algorithm for tuning a cloth-simulation model\n", "abstract": " Textile simulation models are notorious for being difficult to tune. The physically based derivations of energy functions, as mostly used for mapping the characteristics of real-world textiles on to simulation models, are labour-intensive and not guarantee satisfactory results. The extremely complex behaviour of textiles requires additional adjustment over a wide-range of parameters in order to achieve realistic real-life behaviour of the model. Furthermore, such derivations might not even be possible when dealing with mass-spring particle system-based models. Since there is no explicit correlation between the physical characteristics of textiles and the stiffnesses of springs that control a model\u2019s behaviour, this remains an unresolved issue. This paper proposes a hybrid evolutionary algorithm (EA), in order to solve this problem. The initial parameters of the model are written in individual\u2019s genes, where the number of\u00a0\u2026", "num_citations": "39\n", "authors": ["153"]}
{"title": "Automatic generation of language-based tools\n", "abstract": " Many tools can be automatically derived from formal language definitions, such as compilers/interpreters, editors, analyzers, visualizers/animators, etc. Some examples of language-based tools generated automatically by the LISA system are described in the paper. In addition the specification of an algorithm animator and program visualizer, Alma, generated from an extended LISA input-grammar is discussed; LISA principles and code are reused in Alma implementation.", "num_citations": "38\n", "authors": ["153"]}
{"title": "LISA: A tool for automatic language implementation\n", "abstract": " In the paper a tool for automatic language implementation is described. From formal language definition LISA1 produces efficient interpreters or compilers in C++. For lexical and syntax analysis well known formal methods: regular expressions and BNF are used. Semantics of the defined language is described with attribute grammars. LISA is a part of the ongoing effort to build an environment that supports experimentation in automatic language implementation for educational and industrial purposes.", "num_citations": "38\n", "authors": ["153"]}
{"title": "Design and implementation of domain-specific language easytime\n", "abstract": " Measuring time in mass sporting competitions is, typically, performed with a timing system that consists of a measuring technology and a computer system. The first is dedicated to tracking events that are triggered by competitors and registered by measuring devices (primarily based on RFID technology). The latter enables the processing of these events. In this paper, the processing of events is performed by an agent that is controlled by the domain-specific language, EasyTime. EasyTime improves the flexibility of the timing system because it supports the measuring of time in various sporting competitions, their quick adaptation to the demands of new sporting competitions and a reduction in the number of measuring devices. Essentially, we are focused on the development of a domain specific language. In practice, we made two case studies of using EasyTime by measuring time in two different sporting\u00a0\u2026", "num_citations": "37\n", "authors": ["153"]}
{"title": "The impact of quality indicators on the rating of multi-objective evolutionary algorithms\n", "abstract": " Evaluating and comparing multi-objective optimizers is an important issue. But, when doing a comparison, it has to be noted that the results can be influenced highly by the selected Quality Indicator. Therefore, the impact of individual Quality Indicators on the ranking of Multi-objective Optimizers in the proposed method must be analyzed beforehand. In this paper the comparison of several different Quality Indicators with a method called Chess Rating System for Evolutionary Algorithms (CRS4EAs) was conducted in order to get a better insight on their characteristics and how they affect the ranking of Multi-objective Evolutionary Algorithms (MOEAs). Although it is expected that Quality Indicators with the same optimization goals would yield a similar ranking of MOEAs, it has been shown that results can be contradictory and significantly different. Consequently, revealing that claims about the superiority of one MOEA\u00a0\u2026", "num_citations": "36\n", "authors": ["153"]}
{"title": "Extracting grammar from programs: evolutionary approach\n", "abstract": " The paper discusses context-free grammar (CFG) inference using genetic-programming with application to inducing grammars from programs written in simple domain-specific languages. Grammar-specific heuristic operators and non-random construction of the initial population are proposed to achieve this task. Suitability of the approach is shown by small examples where the underlying CFG's are successfully inferred.", "num_citations": "36\n", "authors": ["153"]}
{"title": "Extracting grammar from programs: brute force approach\n", "abstract": " Extracting grammar from programs attracts researchers from several fields such as software engineering, pattern recognition, computational linguistic and natural language acquisition. So far, only regular grammar induction has been successful, while purposeful context-free grammar induction is still elusive. We discuss the search space of context-free grammar induction and propose the Brute Force approach to the problem which, along with its various enhancements, can be further used in collaboration with the Evolutionary approach, as described in the accompanying paper.", "num_citations": "35\n", "authors": ["153"]}
{"title": "On the influence of the number of algorithms, problems, and independent runs in the comparison of evolutionary algorithms\n", "abstract": " When conducting a comparison between multiple algorithms on multiple optimisation problems it is expected that the number of algorithms, problems and even the number of independent runs will affect the final conclusions. Our question in this research was to what extent do these three factors affect the conclusions of standard Null Hypothesis Significance Testing (NHST) and the conclusions of our novel method for comparison and ranking the Chess Rating System for Evolutionary Algorithms (CRS4EAs). An extensive experiment was conducted and the results were gathered and saved of k\u00a0=\u00a016 algorithms on N\u00a0=\u00a040 optimisation problems over n\u00a0=\u00a0100 runs. These results were then analysed in a way that shows how these three values affect the final results, how they affect ranking and which values provide unreliable results. The influence of the number of algorithms was examined for values k\u00a0=\u00a0{4, 8, 12, 16\u00a0\u2026", "num_citations": "34\n", "authors": ["153"]}
{"title": "Domain-specific software engineering\n", "abstract": " This paper projects that an important future direction in software engineering is domain-specific software engineering (DSE). From requirements specification to design, and then implementation, a tighter coupling between the description of a software system with its application domain has the potential to improve both the correctness and reliability of the software system, and also lead to greater opportunities for software automation. In this position paper, we explore the impact of this emerging paradigm on requirements specification, design modeling, and implementation, as well as challenge areas benefiting from the new paradigm.", "num_citations": "34\n", "authors": ["153"]}
{"title": "Formal and Practical Aspects of Domain-Specific Languages: Recent Developments: Recent Developments\n", "abstract": " Computer languages are a programmer s basic tool and they play an essential role in computer science in which they specify computations which need to be performed as well as intended behavior of a system. Domain-Specific Language (DSL) is a particular computer programming language used to address a particular problem domain, representation technique, and solution technique. Formal and Practical Aspects of Domain-Specific Languages: Recent Developments is a collection of academic works containing current research on all aspects of domain-specific language. This book is a comprehensive overview in the computer language field and aims to be essential for scholars and practitioners in the software engineering fields by providing new results and answers to open problems in DSL research.", "num_citations": "31\n", "authors": ["153"]}
{"title": "A memetic grammar inference algorithm for language learning\n", "abstract": " An unsupervised incremental algorithm for grammar inference and its application to domain-specific language development are described. Grammatical inference is the process of learning a grammar from the set of positive and optionally negative sentences. Learning general context-free grammars is still considered a hard problem in machine learning and is not completely solved yet. The main contribution of the paper is a newly developed memetic algorithm, which is a population-based evolutionary algorithm enhanced with local search and a generalization process. The learning process is incremental since a new grammar is obtained from the current grammar and false negative samples, which are not parsed by the current grammar. Despite being incremental, the learning process is not sensitive to the order of samples. All important parts of this algorithm are explained and discussed. Finally, a case study of\u00a0\u2026", "num_citations": "31\n", "authors": ["153"]}
{"title": "AspectLISA: An aspect-oriented compiler construction system based on attribute grammars\n", "abstract": " The use of object-oriented techniques and concepts, like encapsulation and inheritance, greatly improves language specifications towards better modularity, reusability and extensibility. Additional improvements can be achieved with aspect-oriented techniques since semantic aspects also crosscut many language constructs. Indeed, aspect-oriented constructs have been already added to some language specifications. The LISA compiler construction system follows an object-oriented approach and has already implemented mechanisms for inheritance, modularity and extensibility. Adding aspects to LISA will lead to more reusable language specifications. In the paper, aspect-oriented attribute grammars are introduced, and the underlying ideas are incorporated into AspectLISA, an aspect-oriented compiler generator based on attribute grammars.", "num_citations": "31\n", "authors": ["153"]}
{"title": "Domain-specific aspect languages for modularising crosscutting concerns in grammars\n", "abstract": " The emergence of crosscutting concerns can be observed in various representations of software artefacts (e.g. source code, models, requirements and language grammars). Although much of the focus of aspect-oriented programming has been on aspect languages that augment the descriptive power of general-purpose programming languages, there is also a need for domain-specific aspect languages that address particular crosscutting concerns found in software representations other than traditional source code. This study discusses the issues involved in the design and implementation of domain-specific aspect languages that are focused within the domain of language specification. Specifically, the study outlines the challenges and issues faced while designing two separate aspect languages that assist in modularising crosscutting concerns in grammars.", "num_citations": "30\n", "authors": ["153"]}
{"title": "CUDACL: A tool for CUDA and OpenCL programmers\n", "abstract": " Graphical Processing Unit (GPU) programming languages are used extensively for general-purpose computations. However, GPU programming languages are at a level of abstraction suitable only for use by expert parallel programmers. This paper presents a new approach through which `C' or Java programmers can access these languages without having to focus on the technical or language-specific details. A prototype of the approach, named CUDACL, is introduced through which a programmer can specify one or more parallel blocks in a file and execute in a GPU. CUDACL also helps the programmer to make CUDA or OpenCL kernel calls inside an existing program. Two scenarios have been successfully implemented to assess the usability and potential of the tool. The tool was created based on a detailed analysis of the CUDA and OpenCL programs. Our evaluation of CUDACL compared to other similar\u00a0\u2026", "num_citations": "28\n", "authors": ["153"]}
{"title": "Graph 3-coloring with a hybrid self-adaptive evolutionary algorithm\n", "abstract": " This paper proposes a hybrid self-adaptive evolutionary algorithm for graph coloring that is hybridized with the following novel elements: heuristic genotype-phenotype mapping, a swap local search heuristic, and a neutral survivor selection operator. This algorithm was compared with the evolutionary algorithm with the SAW method of Eiben et al., the Tabucol algorithm of Hertz and de Werra, and the hybrid evolutionary algorithm of Galinier and Hao. The performance of these algorithms were tested on a test suite consisting of randomly generated 3-colorable graphs of various structural features, such as graph size, type, edge density, and variability in sizes of color classes. Furthermore, the test graphs were generated including the phase transition where the graphs are hard to color. The purpose of the extensive experimental work was threefold: to investigate the behavior of the tested algorithms in the\u00a0\u2026", "num_citations": "25\n", "authors": ["153"]}
{"title": "Unit testing for domain-specific languages\n", "abstract": " Domain-specific languages (DSLs) offer several advantages by providing idioms that are similar to the abstractions found in a specific problem domain. However, a challenge is that tool support for DSLs is lacking when compared to the capabilities offered in general-purpose languages (GPLs), such as Java and C++. For example, support for unit testing a DSL program is absent and debuggers for DSLs are rare. This limits the ability of a developer to discover the existence of software errors and to locate them in a DSL program. Currently, software developers using a DSL are generally forced to test and debug their DSL programs using available GPL tools, rather than tools that are informed by the domain abstractions at the DSL level. This reduces the utility of DSL adoption and minimizes the benefits of working with higher abstractions, which can bring into question the suitability of using DSLs in the\u00a0\u2026", "num_citations": "25\n", "authors": ["153"]}
{"title": "A hybrid self-adaptive evolutionary algorithm for marker optimization in the clothing industry\n", "abstract": " The task of marker optimization in clothing production is to eliminate pieces from a work order using an optimal sequence of markers and plies, where the work order is given as a matrix of colors by sizes, markers are vectors of sizes to be laid-out and cut together, and the number of plies determines how many pieces are eliminated from the work order each time. Although the optimality of a marker sequence can be determined in several ways, we consider minimum preparation cost as a key objective in clothing production. The traditional algorithms and the simple evolutionary algorithms used in marker optimization today have relied on minimizing the number of markers, which only indirectly reduces production costs. In this paper we propose a hybrid self-adaptive evolutionary algorithm (HSA-EA) for marker optimization that improves the results of the previous algorithms and successfully deals with the objective of\u00a0\u2026", "num_citations": "23\n", "authors": ["153"]}
{"title": "A metaevolutionary approach in searching of the best combination of crossover operators for the TSP\n", "abstract": " In the paper the metaevolutionary approach in searching of the best combination of crossover operators for traveling salesman problem is described. Since different crossover operators preserve different useful properties the combination of operators may out-perform single operator. Rather than randomly search for best combination of crossover operators the metaevolutionary approach is used. Preliminary results confirm this hypothesis.", "num_citations": "23\n", "authors": ["153"]}
{"title": "Entropy-driven parameter control for evolutionary algorithms\n", "abstract": " Barrett R. Bryant Department of Computer and Information Sciences University of Alabama at Birmingham Birmingham, AL 35294, USA bryant@ cis. uab. edu, http://www. cis. uab. edu/bryant", "num_citations": "22\n", "authors": ["153"]}
{"title": "Inferring context-free grammars for domain-specific languages\n", "abstract": " In the area of programming languages, context-free grammars (CFGs) are of special importance since almost all programming languages employ CFG's in their design. Recent approaches to CFG induction are not able to infer context-free grammars for general-purpose programming languages. In this paper it is shown that syntax of a small domain-specific language can be inferred from positive and negative programs provided by domain experts. In our work we are using the genetic programming approach in grammatical inference. Grammar-specific heuristic operators and nonrandom construction of the initial population are proposed to achieve this task. Suitability of the approach is shown by examples where underlying context-free grammars are successfully inferred.", "num_citations": "22\n", "authors": ["153"]}
{"title": "AspectCOOL: An experiment in design and implementation of aspect-oriented language\n", "abstract": " Aspect-oriented programming (AOP) is a promising technique helping programmers to easily reason about, develop and maintain programs. AOP improves reusability since components with a clearly defined functionality, which is not tangled with different aspects, are much easier to reuse. In order to explore different AOP concepts a general-purpose aspect-oriented language AspectCOOL has been designed and implemented. Among the different concepts, which we explored, the most important is the separate compilation of aspect and component code. Using this concept aspects can be applied on already compiled components, which improves their reusability.", "num_citations": "22\n", "authors": ["153"]}
{"title": "A reusable object-oriented approach to formal specifications of programming languages\n", "abstract": " . Formal methods for describing programming language semantics are an excellent tool for programming language design and development. However, they are not widely used since they are not modular, extensible and reusable. In the paper a new modular, extensible and reusable approach for specifying programming languages with attribute grammars is presented. The concepts of object-oriented programming, ie templates, multiple inheritance, and object-oriented implementation of semantic domains, are integrated with attribute grammars. With the proposed approach a language designer has the chance to design incrementally a language or reuse some fragments from other programming language specifications. The proposed approach has been implemented in our compiler generator tool LISA ver. 2.0. MOTS-CLES: KEY WORDS: language specifications, reusability, extensibility, attribute grammars, compiler generators 2 Document num\u00e9rique. Vol. 1-n 1/1997 1 Introduction Compiler construction is often...", "num_citations": "22\n", "authors": ["153"]}
{"title": "Domain-specific languages: A systematic mapping study\n", "abstract": " Domain-specific languages (DSLs) assist a software developer (or end-user) in writing a program using idioms that are similar to the abstractions found in a specific problem domain. Indeed, the enhanced software productivity and reliability benefits that have been reported from DSL usage are hard to ignore and DSLs are flourishing. However, tool support for DSLs is lacking when compared to the capabilities provided for standard General-Purpose Languages (GPLs). For example, support for unit testing of a DSL program, as well as DSL debuggers, are rare. A Systematic Mapping Study (SMS) has been performed to better understand the DSL research field, identify research trends, and any possible open issues. In this talk I will first introduce DSLs by discussing when and how to develop DSLs, then results from SMS will be presented along with open DSL problems such as lacking tool support for DSLs\u00a0\u2026", "num_citations": "21\n", "authors": ["153"]}
{"title": "Parameter control in evolutionary algorithms by domain-specific scripting language PPCEA\n", "abstract": " Abstract Programmable Parameter Control for Evolutionary Algorithms (PPCEA), a domainspecific scripting language, solves the problems of control parameter settings in a programmable fashion. It keeps the evolutionary algorithm simple and lifts the problems of control parameter settings into a higher abstraction layer by using metaprogramming. From our experiments, PPCEA outperforms the trial-anderror approach and performs the adaptable, reusable and controllable solutions of control parameter settings for evolutionary algorithms in parameter tuning, deterministic, and adaptive aspects.", "num_citations": "20\n", "authors": ["153"]}
{"title": "Abstract syntax driven language development: Defining language semantics through aspects\n", "abstract": " The paper presents an approach for defining a computer language driven by a language's abstract syntax. The whole process of language specification including abstract syntax, concrete syntax and semantics definition is explained. Particular emphasis is put on language semantics definition and two approaches are introduced in detail--via annotations and aspects. For this purpose, as the main example used throughout the paper, the DESK language has been selected. A simple approach to semantics definition through semantic methods in the language model is presented. The paper continues with more advanced semantics definition through aspects. As a proof of concept, a short description of the YAJCo experimental research parser generator is given.", "num_citations": "19\n", "authors": ["153"]}
{"title": "Grammar inference algorithms and applications in software engineering\n", "abstract": " Many problems exist whose solutions take the form of patterns that may be expressed using grammars (e.g., speech recognition, text processing, genetic sequencing). Construction of these grammars is usually carried out by computer scientists working with domain experts. In the case when there is a lack of domain experts, grammar inference can be applied. In this paper, two grammar inference algorithms are briefly described and their application to software engineering is presented.", "num_citations": "19\n", "authors": ["153"]}
{"title": "A technique for non-invasive application-level checkpointing\n", "abstract": " One of the key elements required for writing self-healing applications for distributed and dynamic computing environments is checkpointing. Checkpointing is a mechanism by which an application is made resilient to failures by storing its state periodically to the disk. The main goal of this research is to enable non-invasive reengineering of existing applications to insert Application-Level Checkpointing (ALC) mechanism. The Domain-Specific Language (DSL) developed in this research serves as a perfect means towards this end and is used for obtaining the ALC-specifications from the end-users. These specifications are used for generating and inserting the actual checkpointing code into the existing application. The performance of the application having the generated checkpointing code is comparable to the performance of the application in which the checkpointing code was inserted manually. With slight\u00a0\u2026", "num_citations": "18\n", "authors": ["153"]}
{"title": "Verification of DSMLs using graph transformation: a case study with Alloy\n", "abstract": " Domain-Specific Modeling Languages (DSMLs) enable domain experts to participate in software development tasks and to specify their own programs using domain abstractions. Many Model-Driven Engineering (MDE) platforms primarily concentrate on structural aspects of DSMLs and only provide techniques to define abstract and concrete syntax. Only a few platforms provide built-in support for specification of behavioral semantics and verification tasks. In this paper, we focus on how to specify the behavioral semantics of a DSML by a sequence of graph transformation rules. We also discuss how to transform a DSML specification into Alloy, a model checking tool. These transformations demonstrate that DSML models specified in a visual notation can be verified by means of existing model checking tools.", "num_citations": "18\n", "authors": ["153"]}
{"title": "An unsupervised incremental learning algorithm for domain-specific language development\n", "abstract": " While grammar inference (or grammar induction) has found extensive application in the areas of robotics, computational biology, and speech recognition, its application to problems in programming language and software engineering domains has been limited. We have found a new application area for grammar inference which intends to make domain-specific language development easier for domain experts not well versed in programming language design, and finds a second application in construction of renovation tools for legacy software systems. As a continuation of our previous efforts to infer context-free grammars (CFGs) for domain-specific languages which previously involved a genetic-programming based CFG inference system, we discuss extensions to the inference capabilities of GenInc, an incremental learning algorithm for inferring CFGs. We show that these extensions enable GenInc to infer more\u00a0\u2026", "num_citations": "18\n", "authors": ["153"]}
{"title": "On the importance of the artificial bee colony control parameter \u2018Limit\n", "abstract": " Artificial Bee Colony (ABC) is a successful meta-heuristic algorithm that has been greatly utilised by researchers. Through our practical experience of ABC, we have noticed that the recommended formula \u2018limit\u2019= ne* D may not be the best choice for different problems. In this work, a set of experiments using horizontal and vertical approaches has been designed and executed with the aim of observing the effect of \u2018limit\u2019on ABC. The results have been statistical analysed using Null Hypothesis Significance Testing (NHST) as well as the Chess Rating System for Evolutionary Algorithms (CRS4EAs), which is a novel approach for comparing meta-heuristic algorithms. It is shown that the recommended formula is not the best setting for different problems and approaches. Hence, the control parameter \u2018limit\u2019should be tuned or controlled. The other important result of this study is to show that CRS4EAs is comparable but also shows benefits over NHST.", "num_citations": "17\n", "authors": ["153"]}
{"title": "Converting metamodels to graph grammars: doing without advanced graph grammar features\n", "abstract": " In this paper, we present a method to convert a metamodel in the form of a UML class diagram into a context-sensitive graph grammar whose language comprises precisely the set of model graphs (UML object diagrams) that conform to the input metamodel. Compared to other approaches that deal with the same problem, we use a graph grammar formalism that does not employ any advanced graph grammar features, such as application conditions, precedence rules, and production schemes. Specifically, we use Rekers and Sch\u00fcrr\u2019s Layered Graph Grammars, which may be regarded as a pure generalization of standard context-sensitive string grammars. We show that elementary grammatical features, i.e., grammar labels and context-sensitive graph rewrite rules, suffice to represent metamodels with arbitrary multiplicities and inheritance. Inspired by attribute string grammars, we also propose a graph\u00a0\u2026", "num_citations": "17\n", "authors": ["153"]}
{"title": "Embedding DSLs into GPLs: a grammatical inference approach\n", "abstract": " Embedding of Domain-Specific Languages (DSLs) into General-Purpose Languages (GPLs) is oftenused to express domain-specific problems using the domain\u2019s natural syntax inside GPL programs. It speeds up thedevelopment process, programs are more self-explanatory and repeating tasks are easier to handle. End-users ordomain experts know what the desired language syntax would look like, but do not know how to write a grammar andlanguage processing tools. Grammatical inference can be used for grammar extraction from input examples. Amemetic algorithm for grammatical inference, named MAGIc, was implemented to extract grammar from DSLexamples. In this work MAGIc is extended with embedding the inferred DSL into existing GPL grammar. Additionally, negative examples were also incorporated into the inference process. From the results it can be concludedthat MAGIc is successful for DSL embedding and that the inference process is improved with use of negativeexamples.", "num_citations": "17\n", "authors": ["153"]}
{"title": "Is My DSL a Modeling or Programming Language?\n", "abstract": " It is often difficult to discern the differences between programming and modeling languages. As an example, the term \"domain-specific language\" has been used almost interchangeably in academia and industry to represent both programming and modeling languages, which has caused subtle misconceptions. The borders between a modeling and programming language are somewhat vague and not defined crisply. This paper discusses the similarities and differences between modeling and programming languages, and offers some suggestions on how to better differentiate such languages. A list of criteria is presented for language classification, but it is suggested that a set of the criteria be used, rather than a single criterion. Several example domain-specific languages are used as case studies to motivate the discussion.", "num_citations": "17\n", "authors": ["153"]}
{"title": "A two-dimensional separation of concerns for compiler construction\n", "abstract": " During language evolution, compiler construction is usually performed along two dimensions: defining new abstract syntax tree (AST) classes, or adding new operations. In order to facilitate such changes, two software design patterns (ie, the inheritance pattern and the visitor pattern) are widely used to help modularize the language constructs. However, as each design pattern is only suitable for one dimension of extension, neither of these two patterns can independently fulfill the evolution needs during the compiler construction process. In this paper, we analyze two dimensions of concerns in compiler construction and develop a paradigm allowing compiler evolution across these two dimensions using both object-orientation and aspect-orientation. Moreover, this approach provides an ability to perform pattern transformation based on pluggable aspects. A simple implementation of an expression language and its\u00a0\u2026", "num_citations": "17\n", "authors": ["153"]}
{"title": "Improving grammar inference by a memetic algorithm\n", "abstract": " A memetic algorithm, a novel approach for solving NP-hard problems, has been applied in this paper for grammatical inference in the field of domain-specific languages (DSLs). DSLs are often designed by domain experts who have no knowledge about the syntax and semantics of programming languages. However, they are able to write sample programs to accomplish their goals and illustrate the features of their language. Grammatical inference is a technique to infer a context-free grammar from a set of positive (and negative) samples. This paper shows that grammatical inference may assist domain experts and software language engineers in developing DSLs by automatically producing a grammar, which describes a set of sample DSL programs. A memetic-algorithm-based tool is developed, which greatly improves results and robustness of the inference process.", "num_citations": "16\n", "authors": ["153"]}
{"title": "A comparison between different chess rating systems for ranking evolutionary algorithms\n", "abstract": " Chess Rating System for Evolutionary algorithms (CRS4EAs) is a novel method for comparing evolutionary algorithms which evaluates and ranks algorithms regarding the formula from the Glicko-2 chess rating system. It was empirically shown that CRS4EAs can be compared to the standard method for comparing algorithms - null hypothesis significance testing. The following paper examines the applications of chess rating systems beyond Glicko-2. The results of 15 evolutionary algorithms on 20 minimisation problems obtained using the Glicko-2 system were empirically compared to the Elo rating system, Chessmetrics rating system, and German Evaluation Number (DWZ). The results of the experiment showed that Glicko-2 is the most appropriate choice for evaluating and ranking evolutionary algorithms. Whilst other three systems' benefits were mainly the simple formulae, the ratings in Glicko-2 are proven to be\u00a0\u2026", "num_citations": "15\n", "authors": ["153"]}
{"title": "Component-based LR parsing\n", "abstract": " A language implementation with proper compositionality enables a compiler developer to divide-and-conquer the complexity of building a large language by constructing a set of smaller languages. Ideally, these small language implementations should be independent of each other such that they can be designed, implemented and debugged individually, and later be reused in different applications (e.g., building domain-specific languages). However, the language composition offered by several existing parser generators resides at the grammar level, which means all the grammar modules need to be composed together and all corresponding ambiguities have to be resolved before generating a single parser for the language. This produces tight coupling between grammar modules, which harms information hiding and affects independent development of language features. To address this problem, we have\u00a0\u2026", "num_citations": "15\n", "authors": ["153"]}
{"title": "Long term memory assistance for evolutionary algorithms\n", "abstract": " Short term memory that records the current population has been an inherent component of Evolutionary Algorithms (EAs). As hardware technologies advance currently, inexpensive memory with massive capacities could become a performance boost to EAs. This paper introduces a Long Term Memory Assistance (LTMA) that records the entire search history of an evolutionary process. With LTMA, individuals already visited (ie, duplicate solutions) do not need to be re-evaluated, and thus, resources originally designated to fitness evaluations could be reallocated to continue search space exploration or exploitation. Three sets of experiments were conducted to prove the superiority of LTMA. In the first experiment, it was shown that LTMA recorded at least 50% more duplicate individuals than a short term memory. In the second experiment, ABC and jDElscop were applied to the CEC-2015 benchmark functions. By avoiding fitness re-evaluation, LTMA improved execution time of the most time consuming problems F 03 and F 05 between 7% and 28% and 7% and 16%, respectively. In the third experiment, a hard real-world problem for determining soil models\u2019 parameters, LTMA improved execution time between 26% and 69%. Finally, LTMA was implemented under a generalized and extendable open source system, called EARS. Any EA researcher could apply LTMA to a variety of optimization problems and evolutionary algorithms, either existing or new ones, in a uniform way. View Full-Text", "num_citations": "14\n", "authors": ["153"]}
{"title": "Raising the level of abstraction for developing message passing applications\n", "abstract": " Message Passing Interface (MPI) is the most popular standard for writing portable and scalable parallel applications for distributed memory architectures. Writing efficient parallel applications using MPI is a complex task, mainly due to the extra burden on programmers to explicitly handle all the complexities of message-passing (viz., inter-process communication, data distribution, load-balancing, and synchronization). The main goal of our research is to raise the level of abstraction of explicit parallelization using MPI such that the effort involved in developing parallel applications is significantly reduced in terms of the reduction in the amount of code written manually while avoiding intrusive changes to existing sequential programs. In this research, generative programming tools and techniques are combined with a domain-specific language, Hi-PaL (High-Level Parallelization Language), for automating the\u00a0\u2026", "num_citations": "14\n", "authors": ["153"]}
{"title": "Graph grammar induction as a parser-controlled heuristic search process\n", "abstract": " A graph grammar is a generative description of a graph language (a possibly infinite set of graphs). In this paper, we present a novel algorithm for inducing a graph grammar from a given set of \u2018positive\u2019 and \u2018negative\u2019 graphs. The algorithm is guaranteed to produce a grammar that can generate all of the positive and none of the negative input graphs. Driven by a heuristic specific-to-general search process, the algorithm tries to find a small grammar that generalizes beyond the positive input set. During the search, the algorithm employs a graph grammar parser to eliminate the candidate grammars that can generate at least one negative input graph. We validate our method by inducing grammars for chemical structural formulas and flowcharts and thereby show its potential applicability to chemical engineering and visual programming.", "num_citations": "14\n", "authors": ["153"]}
{"title": "Improving the graph grammar parser of Rekers and Schurr\n", "abstract": " Graph grammars and graph grammar parsers are to visual languages what string grammars and parsers are to textual languages. A graph grammar specifies a set of valid graphs and can thus be used to formalise the syntax of a visual language. A graph grammar parser is a tool for recognising valid programs in such a formally defined visual language. A parser for context-sensitive graph grammars, which have proved to be suitable for formalising real-world visual languages, was developed by Rekers and Sch\u00fcrr. We propose three improvements of this parser. One of them enlarges the class of parsable graph grammars, while the other two increase the parser\u0308s computational efficiency. Experimental results show that for some (meaningful) graph grammars, our improvements can enhance the parser\u0308s performance by orders of magnitude. The proposed improvements will hopefully increase both the parser\u0308s\u00a0\u2026", "num_citations": "14\n", "authors": ["153"]}
{"title": "Learning context-free grammars using an evolutionary approach\n", "abstract": " Machine learning of grammars finds many applications in syntactic pattern recognition, computational biology, natural language acquisition, etc. In this paper a new application of grammatical inference is suggested. Development of domain-specific languages is a hard problem for domain experts not versed in programming language design. We believe that syntax of a small domain-specific language can be inferred from positive and negative programs provided by domain experts. In our work we are the using genetic programming approach in grammatical inference. Grammar-specific heuristic operators and non-random construction of the initial population are proposed to achieve this task. Suitability of the approach is shown by small examples where underlying context-free grammars are successfully inferred.", "num_citations": "14\n", "authors": ["153"]}
{"title": "Applications of grammatical inference in software engineering: domain specific language development\n", "abstract": " In this chapter, application of grammatical inference to facilitate development of domain-specific languages (DSLs) is presented. Grammatical inference techniques have been applied to infer DSL grammar from DSL programs. Such a scenario would be feasible when domain experts can provide complete DSL programs or excerpts of such programs. The results of grammatical inference, namely the inferred grammar, can be directly used to generate the DSL parser or be further examined by a software language engineer with the aim to further enhance the design of the language. To achieve this goal we developed a memetic algorithm which enables incremental grammar inference. It is a population based evolutionary algorithm enhanced with local search and a generalization phase. Some examples of DSLs from which grammars have been successfully inferred from positive samples are presented.", "num_citations": "13\n", "authors": ["153"]}
{"title": "Model-driven engineering and its introduction with metamodeling tools\n", "abstract": " This article discusses the opportunities that are offered by the paradigm shift form code-centric software engineering to Model-Driven Engineering (MDE) and one of the problems that hinder this shift. To enable MDE in practice sophisticated software tools have to be developed and employed. This paper presents and compares the available ways for developing such software tools and argues that the most reasonable of them is the development with metamodeling tools. Based on this finding we identified a pretentious question that is relevant to practitioners:\u201cWhich metamodeling tool should be procured?\u201d The main contribution of this paper is the answer to this question that is given for a real-life project, which dealt with the procurement of a metamodeling tool.", "num_citations": "13\n", "authors": ["153"]}
{"title": "Separation of concerns in compiler development using aspect-orientation\n", "abstract": " A major difficulty in compiler development regards the proper modularization of concerns among the various compiler phases. The traditional object-oriented development paradigm has difficulty in providing an optimal solution towards modularizing the analysis phases of compiler development, because implementation of each phase often crosscuts the class hierarchy defined by language syntax constructs. Object-oriented design patterns, such as the Visitor pattern, also cannot solve the crosscutting problem adequately because an object is not a natural representation of a collection of operations. This paper demonstrates the benefits of applying aspect-oriented programming languages (eg, AspectJ) and principles to compiler design and implementation. The experience result shows that the various language constructs in AspectJ (eg, inter-type declaration, pointcut-advice model, static aspect members and\u00a0\u2026", "num_citations": "13\n", "authors": ["153"]}
{"title": "Testing domain-specific languages in Eclipse\n", "abstract": " Domain-specific languages (DSLs) use idioms that are closer to the abstractions found in a specific problem domain. Tool support for testing and debugging DSLs is lacking when compared to the capabilities provided for standard general purpose languages (GPLs). In fact, support for debugging and testing a program written in a DSL is often nonexistent. A common approach for implementing DSLs is to create a pre-processor that translates the DSL source into an object-oriented GPL, such as Java or C++. A DSL grammar serves as the primary artifact for defining DSLs from a higher level of abstraction. This demonstration is focused on a grammar-driven technique to build a testing tool from existing DSL grammars. The DSL grammars are used to generate the hooks needed to interface with a supporting infrastructure written for Eclipse that assists in testing and debugging a program written in a DSL. This\u00a0\u2026", "num_citations": "13\n", "authors": ["153"]}
{"title": "Design and implementation of simple object description language\n", "abstract": " In the paper a design and implementation of Simple Object Description Language SODL for automatic interface creation are presented. First, problem domain\u2013developing network applications and reasons for developing new domain-specific language are described. Since the cross network method calls slow down performance of our applications the solution was Tier to Tier Object Transport (TTOT). However, with this approach the network application development time has been increased. To enhance our productivity a new domain-specific SODL language has been designed. Syntax and semantics of SODL language are formally defined in an incremental way by special kind of attribute grammars that allows extensions and modifications in an easy way. From formal specifications SODL compiler is automatically generated using compiler/interpreter generator tool LISA. Finally, the benefits of our approach have\u00a0\u2026", "num_citations": "13\n", "authors": ["153"]}
{"title": "Metamodel recovery from multi-tiered domains using extended MARS\n", "abstract": " With the rapid development of model-driven engineering (MDE), domain-specific modeling has become a widely used software development technique. In MDE, metamodels represent a schema definition of the syntax and static semantics to which an instance model conforms (i.e., a model conforms to its metamodel in a similar manner to how a program conforms to a grammar). However, in order to address new feature requests of the domain and language, the metamodel often undergoes frequent evolution that may result in the inability of users to load and view previous model instances. MARS is a metamodel recovery system to address the problems of metamodel evolution. This paper presents our extensions to MARS to infer models for multi-tiered domains. A new XSLT translator has been developed to generate a domain-specific language (DSL) called MRL (model representation language) for the XML\u00a0\u2026", "num_citations": "12\n", "authors": ["153"]}
{"title": "A domain-specific language for application-level checkpointing\n", "abstract": " Checkpointing is one of the key requirements for writing fault-tolerant and flexible applications for dynamic and distributed environments like the Grid. Certain patterns are observed in the implementation of the application-level Checkpointing and Restart (CaR) mechanism across myriad of applications. These patterns indicate that a higher level of abstraction can be used to isolate the observed commonalities and variations in the CaR mechanism. This research paper describes an approach for the design and development of a Domain-Specific Language (DSL) for abstracting the application-level CaR mechanism. The specifications written in the DSL are used for semi-automatically generating the application-specific code for the CaR mechanism. This DSL not only provides a high-level of abstraction but also promotes code reuse, code correctness and non-invasive reengineering of legacy applications to\u00a0\u2026", "num_citations": "12\n", "authors": ["153"]}
{"title": "Domain-specific languages in perspective\n", "abstract": " Domain-Specific Languages in Perspective Page 1 Domain-Specific Languages in Perspective Jan Heering Centrum voor Wiskunde en Informatica Amsterdam www.cwi.nl/~jan Joint work with Marjan Mernik (University of Maribor, Slovenia) and Tony Sloane (Macquarie University, Sydney) April 26, 2007 MoDSE Colloquium Delft University of Technology Page 2 Agenda \u25cf General properties and examples \u25cf Opportunities \u2013 Software factories \u2013 Multicore \u25cf Two kinds of application domain? \u25cf DSLs vs. APIs \u25cf DSL development \u25cf Outlook and challenges Page 3 General properties DSLs \u25cf Notations and constructs tailored to domain \u25cf Notations very important Use accepted textual/graphical notations if any \u25cf Expressivity gain \u25cf Productivity gain \u25cf Reduced maintenance effort \u25cf Larger group of software developers Domain experts, end-users Page 4 General properties (cont.) Renewed interest 4GL and other (-\u2026", "num_citations": "12\n", "authors": ["153"]}
{"title": "Domain-specific languages for software engineering\n", "abstract": " We will not try to give a definition of what constitutes an application domain and what does not. Some people consider Cobol to be a DSL for business applications, while others would argue this is pushing the notion of application domain too far. Leaving matters of definition aside, it is natural to think of DSLs in terms of a gradual scale with very specialized DSLs such as HTML on the left and general purpose programming languages such as C++ on the right. On this scale, Cobol would be somewhere between HTML and C++, but much closer to the latter. In combination with an application library, any general purpose programming language can act as a DSL, so why were DSLs developed in the first place? Simply because they can offer domain-specificity in better ways:", "num_citations": "12\n", "authors": ["153"]}
{"title": "Optimization of markers in clothing industry\n", "abstract": " The optimization of markers is one of the most important preparatory steps for production in the clothing industry. It determines the sizes of clothes to be laid and cut together. Markers are built on a work order basis. The work order is a matrix of sizes by colors that have to be covered by markers in an optimal way. The optimal way can be defined in a number of ways: it can be the minimum number of markers to accomplish the work order, or the least time for fulfilling the work order, or the minimal amount of cloth used. In this article, the problem of marker optimization is treated formally. The problem is transformed into the 0/1 knapsack problem and solved using evolutionary algorithms. The results obtained on ten real-world work orders show an important improvement over the previously best known solutions.", "num_citations": "11\n", "authors": ["153"]}
{"title": "Automatic implementation of programming languages using object oriented approach\n", "abstract": " We present our implementation of a tool for automatic language implementation. From formal language definition, Language Implementation System based on Attribute Grammars (LISA) produces an interpreter or a compiler for the defined language. We describe the development of the tool. It is one of the first such tools developed using the object oriented technology and is coded in the C+ + programming language.", "num_citations": "11\n", "authors": ["153"]}
{"title": "PROMIS: a software metrics tool generator\n", "abstract": " The application of measurement technology in software engineering was not recognised enough in last decades, but recent trends show that software metrics are becoming more and more important. Indeed the development and use of adequate measurement of software and its design process are essential to the production of cost-effective and quality software. Actually, software metrics are not only significant as analysis instruments, but regarding the present iterative software design paradigms, they are likewise becoming powerful synthesis mechanisms. The main objective of this paper is to show that modern software tools and especially compiler-compilers, metric life cycle model and fractal metrics can improve the situation and make the development and use of software metrics more efficient and effective.", "num_citations": "11\n", "authors": ["153"]}
{"title": "Searching for soil models\u2019 parameters using metaheuristics\n", "abstract": " Grounding systems are an important part of protection systems which protect people and devices in case of defects in electro energetic systems or lightning strikes. The Finite Element Method (FEM) is often used for proper dimensioning of the grounding systems. Often data about the soil in the surroundings of the grounding system are obtained using measurements. Soil parameters can be determined using analytical soil models, and the determination of the soil models\u2019 parameters, which are based on the measured data, is an optimization problem. In this paper, different soil models are tested on different measured data and compared with each other. Different metaheuristics are used and tested for the determination of soil parameters: A Genetic Algorithm, Differential Evolution with two different strategies, Teaching-Learning Based Optimization, Artificial Bee Colony and Dynamic Optimization using Self-Adaptive\u00a0\u2026", "num_citations": "10\n", "authors": ["153"]}
{"title": "Towards building a forensics aware language for secure logging\n", "abstract": " Trustworthy system logs and application logs are crucial for digital    forensics. Researchers have proposed different security mechanisms to ensure    the integrity and confidentiality of logs. However, applying current secure    logging schemes on heterogeneous formats of logs is tedious. Here, we propose    Forensics Aware Language (FAL), a domain-specific language (DSL) through    which we can apply a secure logging mechanism on any format of logs. Using    FAL, we can define log structure, which represents the format of logs and    ensures the security properties of a chosen secure logging scheme. This log    structure can later be used by FAL to serve two purposes: it can be used to    store system logs securely and it will help application developers for secure    application logging by generating the required source code.", "num_citations": "10\n", "authors": ["153"]}
{"title": "FAL: A forensics aware language for secure logging\n", "abstract": " Trustworthy system logs and application logs are crucial for digital forensics. Researchers have proposed different security mechanisms to ensure the integrity and confidentiality of logs. However, applying current secure logging schemes on heterogeneous formats of logs is tedious. Here, we propose FAL, a domain-specific language (DSL) through which we can apply a secure logging mechanism on any format of logs. Using FAL, we can define log structure, which represents the format of logs and ensures the security properties of a chosen secure logging scheme. This log structure can be later used by FAL to serve two purposes: it can be used to store system logs securely, and it will help application developers for secure application logging by generating required source code.", "num_citations": "10\n", "authors": ["153"]}
{"title": "Raising the Level of Abstraction of GPU-programming.\n", "abstract": " General-purpose computing on GPUs (graphics processing units) has received much attention lately due to the benefits of stream processing to exploit limitations of parallel processing. However, programming GPUs has several challenges with respect to the amount of effort spent in combining the kernel functional code of an application with the parallel concerns offered by APIs from various GPUs. This paper introduces our approach for raising the level of abstaction for programming GPUs. We have implemented an abstract API that can be used with the Compute Unified Device Architecture (CUDA) and the Open Compute Language (OpenCL) frameworks, so that the mechanical steps involved in writing the GPU code are abstracted in separate modules. The approach involves static code analysis and generative programming techniques for automatically generating the host code required for CUDA and OpenCL frameworks from minimal specifications provided by the programmers. The generated code resembles the hand-written code with comparable performance.", "num_citations": "10\n", "authors": ["153"]}
{"title": "Experimental aspect-oriented language-AspectCOOL\n", "abstract": " Aspect-oriented programming (AOP) is a programming technique for modularizing concerns that crosscut the basic functionality of programs. In AOP, aspect languages are used to describe properties, which crosscut basic functionality, in a clean and a modular way. AOP is currently supported mostly by aspect weavers, which require a source code for both components and aspects in order to create the final program. In this paper we have presented our approach to aspect weaving in order to achieve separate compilation. This approach to aspect weaving is used in the languages COOL and AspectCOOL, which are also presented in the paper. With this approach it is possible to apply aspects on already compiled components.", "num_citations": "10\n", "authors": ["153"]}
{"title": "Determination of a hysteresis model parameters with the use of different evolutionary methods for an innovative hysteresis model\n", "abstract": " For precise modeling of electromagnetic devices, we have to model material hysteresis. A Genetic Algorithm, Differential Evolution with three different strategies, teaching\u2013learning-based optimization and Artificial Bee Colony, were used for testing seven different modified mathematical expressions, and the best combination of mathematical expression and solving method was used for hysteresis modeling. The parameters of the hysteresis model were determined based on the measured major hysteresis loop and first-order reversal curves. The model offers a simple determination of the magnetization procedure in the areas between measured curves, with the only correction of two parameters based on only two known points in the magnetization process. It was tested on two very different magnetic materials, and results show good agreement between the measured and calculated curves. The calculated curves between the measured curves have correct shapes. The main difference between our model and other models is that, in our model, each measured curve, major and reversal, is described with different parameters. The magnetization process between measured curves is described according to the nearest measured curve, and this ensures the best fit for each measured curve. In other models, there is mainly only one curve, a major hysteresis or magnetization curve, used for the determination of the parameters, and all other curves are then dependent on this curve. Results confirm that the evolutionary optimization method offers a reliable procedure for precise determination of the parameters. View Full-Text", "num_citations": "9\n", "authors": ["153"]}
{"title": "Implementation of EasyTime formal semantics using a LISA compiler generator\n", "abstract": " A manual measuring time tool in mass sporting competitions would not be imaginable nowadays, because many modern disciplines, such as IRONMAN, last a long-time and, therefore, demand additional reliability. Moreover, automatic timing-devices based on RFID technology, have become cheaper. However, these devices cannot operate as stand-alone because they need a computer measuring system that is capable of processing incoming events, encoding the results, assigning them to the correct competitor, sorting the results according to the achieved times, and then providing a printout of the results. This article presents the domain-specific language EasyTime, which enables the controlling of an agent by writing the events within a database. It focuses, in particular, on the implementation of EasyTime with a LISA tool that enables the automatic construction of compilers from language specifications, using Attribute Grammars.", "num_citations": "9\n", "authors": ["153"]}
{"title": "Application of metamodel inference with large-scale metamodels\n", "abstract": " Application of Metamodel Inference with Large-Scale Metamodels +Advanced Search Home About Journal Aims and Scopes Journal Indexing Copyrights Contact Us Editorial Board Current Former Guidelines For Authors For Reviewers Content News Top papers E-mail Alert Publication Ethics Old Version Home > Archive>Volume 6, Issue 2, 2012 >201-231 PDF HTML XML Export Cite reminder Application of Metamodel Inference with Large-Scale Metamodels DOI: Author: Affiliation: Clc Number: Fund Project: Article | Figures | Metrics | Reference | Related | Cited by | Materials | Comments Abstract: In software engineering, new technologies and methodologies have been developed with the aim of simplifying the software development process and improving software productivity. Model-driven engineering is considered as one potential alternative to the classical code-based approach to software development. A in -\u2026", "num_citations": "9\n", "authors": ["153"]}
{"title": "Implementation of the domain-specific language EasyTime using a LISA compiler generator\n", "abstract": " A manually time-measuring tool in mass sporting competitions cannot be imagined nowadays because many modern disciplines, such as IronMan, take a long time and, therefore, demand additional reliability. Moreover, automatic timing devices, based on RFID technology, have become cheaper. However, these devices cannot operate stand-alone because they need a computer measuring system that is capable of processing the incoming events, encoding the results, assigning them to the correct competitor, sorting the results according to the achieved times, and then providing a printout of the results. In this article, the domain-specific language EasyTime is presented, which enables the controlling of an agent by writing the events in a database. In particular, we are focused on the implementation of EasyTime with a LISA tool that enables the automatic construction of compilers from language specifications using\u00a0\u2026", "num_citations": "9\n", "authors": ["153"]}
{"title": "Entropy-driven exploration and exploitation in evolutionary algorithms\n", "abstract": " Every evolutionary algorithm needs to address two important facets: exploration and exploitation of a search space. Evolutionary search must combine exploration of the new regions of the space with exploitation of the potential solutions already identified. The necessity of balancing exploration with exploitation needs to be intelligent. This paper introduces an entropy-driven exploration and exploitation approach for evolutionary algorithms. Entropy represents the amount of disorder of the population, where an increase in entropy represents an increase in diversity. New kinds of entropy to express diversity and to control the entropy-driven approach are discussed.", "num_citations": "9\n", "authors": ["153"]}
{"title": "A grammar-based approach to class diagram validation\n", "abstract": " The UML has grown in popularity as the standard modeling language for describing software applications. However, UML lacks the formalism of a rigid semantics, which can lead to ambiguities in understanding the specifications. We propose a grammar-based approach to validating class diagrams and illustrate this technique using a simple case-study. Our technique involves converting UML representations into an equivalent grammar form, and then using existing language transformation and development tools to assist in the validation process. A string comparison metric is also used which provides feedback, allowing the user to modify the original class diagram according to the functionality desired.", "num_citations": "9\n", "authors": ["153"]}
{"title": "The template and multiple inheritance approach into attribute grammars\n", "abstract": " Formal methods for describing programming language semantics, such as attribute grammars, operational semantics and denotational semantics, are not widely used since they are not modular, extensible and reusable. A novel modular, extensible and reusable approach for specifying programming languages with attribute grammars is presented. The concepts from object oriented programming, i.e. templates and multiple inheritance, have been integrated with attribute grammers. A template in attribute grammar is an abstraction of a semantic rule parameterized with attribute occurrences. On the other hand, the whole attribute grammar is a subject of multiple inheritance and specialization. With the proposed approach, a language designer has the chance to design incrementally a language or reuse some fragments from other programming language specifications. Templates and multiple inheritance have been\u00a0\u2026", "num_citations": "9\n", "authors": ["153"]}
{"title": "ROSE: decision trees, automatic learning and their applications in cardiac medicine.\n", "abstract": " Computerized information systems, especially decision support systems, have acquired an increasingly important role in medical applications, particularly in those where important decisions must be made effectively and reliably. But the possibility of using computers in medical decision making is limited by many difficulties, including the complexity of conventional computer languages, methodologies, and tools. Thus a conceptual simple decision making model with the possibility of automating learning should be used. In this paper, we introduce a cardiological knowledge-based system based on the decision tree approach supporting the mitral valve prolapse determination. Prolapse is defined as the displacement of a bodily part from its normal position. The term mitral valve prolapse (PMV), therefore, implies that the mitral leaflets are displaced relative to some structure, generally taken to be the mitral annulus. The implications of the PMV are: disturbed normal laminar blood flow, turbulence of the blood flow, injury of the chordae tendinae, the possibility of thrombus's composition, bacterial endocarditis, and, finally, hemodynamic changes defined as mitral insufficiency and mitral regurgitation. Uncertainty persists about how it should be diagnosed and about its clinical importance. It is our deep belief that the echocardiography enables properly trained expert armed with proper criteria to evaluate PMV almost 100%. But, unfortunately, there are some problems concerned with the use of echocardiography. With this in mind, we have decided to start a research project aimed at finding new criteria and enabling the general practitioner to evaluate the\u00a0\u2026", "num_citations": "9\n", "authors": ["153"]}
{"title": "Hybridization of evolutionary algorithms\n", "abstract": " Evolutionary algorithms are good general problem solver but suffer from a lack of domain specific knowledge. However, the problem specific knowledge can be added to evolutionary algorithms by hybridizing. Interestingly, all the elements of the evolutionary algorithms can be hybridized. In this chapter, the hybridization of the three elements of the evolutionary algorithms is discussed: the objective function, the survivor selection operator and the parameter settings. As an objective function, the existing heuristic function that construct the solution of the problem in traditional way is used. However, this function is embedded into the evolutionary algorithm that serves as a generator of new solutions. In addition, the objective function is improved by local search heuristics. The new neutral selection operator has been developed that is capable to deal with neutral solutions, i.e. solutions that have the different representation but expose the equal values of objective function. The aim of this operator is to directs the evolutionary search into a new undiscovered regions of the search space. To avoid of wrong setting of parameters that control the behavior of the evolutionary algorithm, the self-adaptation is used. Finally, such hybrid self-adaptive evolutionary algorithm is applied to the two real-world NP-hard problems: the graph 3-coloring and the optimization of markers in the clothing industry. Extensive experiments shown that these hybridization improves the results of the evolutionary algorithms a lot. Furthermore, the impact of the particular hybridizations is analyzed in details as well.", "num_citations": "8\n", "authors": ["153"]}
{"title": "A clustering entropy-driven approach for exploring and exploiting noisy functions\n", "abstract": " Linear, Gaussian, fitness proportional, clustering, and Rosca entropies are succinct measures of diversity that have been applied to balance exploration and exploitation in evolutionary algorithms. In previous studies, an entropy-driven approach using linear entropy explicitly balances and/or searches optimal solutions for the selected unimodal and multimodal functions excluding noisy functions. This paper investigates the reasons for such an exception and introduces a clustering entropy-driven approach to solve the problem. Such an approach provides a coarse-grained diversity measure that filters the noise of functions, varies cluster size and categorizes individuals at the genotype level. The experimental results show that the clustering entropy-driven approach further improves the searching results of noisy functions by one more degree.", "num_citations": "8\n", "authors": ["153"]}
{"title": "Incrementally Inferring Context-Free Grammars for Domain-Specific Languages.\n", "abstract": " Grammatical inference (or grammar inference) has been applied to various problems in areas such as computational biology, and speech and pattern recognition but its application to the programming language problem domain has been limited. We propose a new application area for grammar inference which intends to make domain-specific language development easier and finds a second application in renovation tools for legacy software systems. We discuss the improvements made to our core incremental approach to inferring context-free grammars. The approach affords a number of advancements over our previous geneticprogramming based inference system. We discuss the beam search heuristic for improved searching in the solution space of all grammars, the Minimum Description Length heuristic to direct the search towards simpler grammars, and the right-hand-side subset constructor operator.", "num_citations": "8\n", "authors": ["153"]}
{"title": "Grammar-driven generation of domain-specific language testing tools\n", "abstract": " Domain-specific languages (DSLs) assist an end-user in writing a software program using idioms that are closer to the abstractions found in a specific problem domain. Language tool support for DSLs is lacking when compared to the capabilities provided for standard object-oriented general purpose languages (GPLs). For example, support for debugging and testing a program written in a DSL is often nonexistent. This poster abstract introduces an investigation into a grammar-driven technique to build a framework to generate DSL testing tools (eg, debugger and test engine). This research demonstrates the feasibility and applicability of using information derived from DSL grammars and existing software components to support end-user debugging and testing in a domain friendly environment.", "num_citations": "8\n", "authors": ["153"]}
{"title": "Two-level evolutionary algorithm for discovering relations between nodes\u2019 features in a complex network\n", "abstract": " Complex network theory offers an efficient mathematical framework for modelling natural phenomena. However, these studies focus mainly on the topological characteristics of networks, while the actual reasons behind the networks\u2019 formation remain overlooked. This paper proposes a new approach to complex network analysis. By searching for the optimal functional definition of the network's edge set, it allows an examination of the influences of the physical properties of the nodes on the network's structure and behaviour (i.e. changes of the network's structure when the physical properties of nodes change). A two-level evolutionary algorithm is proposed for this purpose, whereby the search for a suitable function form is achieved at the first level, while the second level is used for optimal function fitting. In this way, not only the features with the largest influences are identified, but also the intensities of their\u00a0\u2026", "num_citations": "7\n", "authors": ["153"]}
{"title": "Ranking multi-objective evolutionary algorithms using a chess rating system with quality indicator ensemble\n", "abstract": " Evolutionary Algorithms have been applied successfully for solving real-world multi-objective problems which explains the influx of newly proposed Multi-Objective Evolutionary Algorithms (MOEAs). In order to determine their performance, comparison with existing algorithms must be conducted. However, conducting a comparison is not a trivial task. Benchmark functions must be selected and the results have to be analyzed using a statistical method. In addition, the results of MOEAs can be evaluated with different Quality Indicators (QIs), which aggravates the comparison additionally. In this paper, we present a chess rating system which was adapted for ranking MOEAs with a Quality Indicator ensemble. The ensemble ensures that different aspects of quality are evaluated of the resulting approximation sets. The chess rating system is compared with an existing method which uses a double-elimination tournament\u00a0\u2026", "num_citations": "7\n", "authors": ["153"]}
{"title": "Analysis of VEGA and SPEA2 using exploration and exploitation measures\n", "abstract": " This paper presents the analysis and comparison between Vector Evaluated Genetic Algorithm (VEGA) and Strength Pareto Evolutionary Algorithm 2 (SPEA2) using the recently introduced exploration and exploitation measures. The experimental results show that the inner workings of both multiobjective algorithms can be observed and explained in a refined way in terms of exploration and exploitation.", "num_citations": "7\n", "authors": ["153"]}
{"title": "Memetic grammatical inference approach for DSL embedding\n", "abstract": " Domain-specific languages (DSLs) are often designed by domain experts who have no knowledge about the syntax and semantics of programming languages. However, they are able to write sample programs to accomplish their goals and illustrate the features of their language. Grammatical inference is a technique for inferring a context-free grammar (CFG) from a set of positive (and negative) samples. This paper presents an improved memetic algorithm for grammatical inference that may assist domain experts and software language engineers in developing DSLs by automatically producing a grammar which describes a set of sample DSL programs. Our approach uses local search technique with improved generalization step and mutation operator. Negative samples are also introduced to overcome overgeneralization problem. The algorithm was tested on several DSLs and a case study of embedding a DSL\u00a0\u2026", "num_citations": "7\n", "authors": ["153"]}
{"title": "Adaptive and evolvable software systems: techniques, tools, and applications\n", "abstract": " A longstanding goal of software developers is to construct programs that are easily modified and extended. One example is the ideal that each change in a design decision would require only modifications to one module of a program. As demands for software increase, future requirements will necessitate new strategies for software development tools and techniques which better support adaptation and evolution. Software's ability to adapt is actually partitioned among two stages: modifiability during development, and adaptation during execution. The first type of adaptation is concerned with design-time, or compile - time, techniques that permit the modification of the structure and function of a software representation in order to address changing stakeholder requirements. The first session of this mini-track contains papers that address this form of adaptation. Katrina Falkner et al., introduce work on separating policy\u00a0\u2026", "num_citations": "7\n", "authors": ["153"]}
{"title": "From grammar inference to semantic inference\u2014An evolutionary approach\n", "abstract": " This paper describes a research work on Semantic Inference, which can be regarded as an extension of Grammar Inference. The main task of Grammar Inference is to induce a grammatical structure from a set of positive samples (programs), which can sometimes also be accompanied by a set of negative samples. Successfully applying Grammar Inference can result only in identifying the correct syntax of a language. With the Semantic Inference a further step is realised, namely, towards inducing language semantics. When syntax and semantics can be inferred, a complete compiler/interpreter can be generated solely from samples. In this work Evolutionary Computation was employed to explore and exploit the enormous search space that appears in Semantic Inference. For the purpose of this research work the tool LISA. SI has been developed on the top of the compiler/interpreter generator tool LISA. The first results are encouraging, since we were able to infer the semantics only from samples and their associated meanings for several simple languages, including the Robot language. View Full-Text", "num_citations": "6\n", "authors": ["153"]}
{"title": "Hybrid evolutionary algorithm for the b-chromatic number\n", "abstract": " The b-chromatic number of a graph  is a maximum integer  for which there exists a proper -coloring with the additional property that each color class contains a vertex that is adjacent to one of the vertices within each color class. In contrast to many theoretical results discovered over the last decade and a half there are no computer running experiments on  in the literature. This work presents a hybrid evolutionary algorithm for graph b-coloring. Its performance has been tested on some instances of regular graphs where their b-chromatic number is theoretically known in advance, as well as by comparing with a brute force algorithm solving the regular graphs up to 12 vertices. In addition, the algorithm has been tested on some larger graphs taken from a DIMACS challenge benchmark that also proved to be challenging for the algorithms searching for the classical chromatic number .", "num_citations": "6\n", "authors": ["153"]}
{"title": "PPCea: a domain-specific language for programmable parameter control in evolutionary algorithms\n", "abstract": " An Evolutionary Algorithm (EA) is a meta-heuristic and stochastic optimization search process that mimics Darwinian evolution theory and Mendel's Genetics. Each process facilitates (a) population (s) evolve into fittest and/or convergence by setting parameters of selection, mutation, crossover, population resizing, and/or many other variant operators. However, due to two primary identified factors, EAs are still a challenging research topic:(1) Value choices/ranges for parameters (ie, parameter settings) will greatly influence the evolution performance of a search process in terms of fittest and/or convergence; and (2) Parameter settings that are good for one fitness function do not guarantee the same evolution performance of another fitness function. Namely, parameter settings are function-specific. Different functions may have various characteristics that request specific attention. In order to better organize and overcome the parameter setting problem, Eiben et al. have classified parameter settings into parameter tuning and parameter control (Eiben et al., 1999): Parameter tuning determines parameter values before a search process begins while parameter control changes parameter values during a search process. More specifically, parameter control adjusts parameters on-the-fly using three different approaches:(1) Deterministic approach alters parameters based on certain pre-determined rules or formulae;(2) Adaptive approach strategically adjusts parameter values based on the feedbacks of a search process. Such feedbacks could be fitness, diversity, distance, among others; and (3) Self-adaptive approach encodes parameters to be adapted\u00a0\u2026", "num_citations": "6\n", "authors": ["153"]}
{"title": "Domain-specific languages as key tools for ULSSIS engineering\n", "abstract": " We briefly discuss the potential of domain-specific languages and domain-specific modeling languages for ULSSIS engineering, some of the scaling challenges involved, and the possibilities for raising expressiveness beyond current levels.", "num_citations": "6\n", "authors": ["153"]}
{"title": "Model transformations require formal semantics\n", "abstract": " Despite the increasing interest in model-driven engineering, there are many open issues that need to be addressed to advance the technology and promote its adoption. This position paper outlines several current limitations of model transformation, with a specific emphasis on model optimization. A primary shortcoming that can be found in many model transformation approaches and tools is the lack of formal semantics to define the meaning of a modeling abstraction. This inadequacy is the source of many problems surrounding the practice of model engineering.", "num_citations": "6\n", "authors": ["153"]}
{"title": "VisualLISA: A visual interface for an attribute grammar based compiler-compiler\n", "abstract": " The research work that we discuss in this position paper, is concerned with the implementation of a visual front-end for LISA tool in order to make easier and more attractive the work of writing an attribute grammar for a new language. LISA (Language Implementation System based on Attribute grammars) is a compiler-compiler, or a system that generates automatically a compiler/interpreter from a formal language specification based on attribute grammars. The main idea is to design a visual language to draw derivation rules in conjunction with the associated semantic rules and to develop a visual compiler to transform that graphical representation into LISA notation.", "num_citations": "6\n", "authors": ["153"]}
{"title": "Specifying languages using aspect-oriented approach: AspectLISA\n", "abstract": " Object-oriented techniques and concepts have been successfully used in language specification and formalization. They greatly improve modularity, reusability and extensibility. In spite of using OO paradigms in language specification, some semantic aspects still crosscut many language constructs. Improvements can be achieved with aspect-oriented techniques. The paper describes AspectLISA tool wich uses aspect-oriented approach for language specification (aspect-oriented attribute grammars). An example will be worked out in order to illustrate the approach. We will show how to identify an aspect, specify it in the concrete AspectLisa syntax, and how to gather parts in order to develop a complete language processor.", "num_citations": "6\n", "authors": ["153"]}
{"title": "Evolutionary search for optimal combinations of markers in clothing manufacturing\n", "abstract": " Optimizing combinations of placements of parts, known as markers, is an important preparatory step in order-based industrial production of clothes. Given a work order in the form of a matrix of pieces in size numbers and designs, the task is to find a list of combinations of size numbers to complete the work order. The outcome of this step influences the number of cut out pieces, the amount of material used in the production phase, and the speed of the work order processing. The optimization task is demanding since a number of factors affect production costs and several conflicting criteria can be involved in marker assessment. We consider minimum number of markers per work order as an optimization criterion and transform the problem into the knapsack problem which is then solved with several variants of an evolutionary algorithm. Numerical experiments are performed on real problem instances from industrial\u00a0\u2026", "num_citations": "6\n", "authors": ["153"]}
{"title": "Object-oriented language specifications: Current status and future trends\n", "abstract": " It is a well-known fact that programming language definitions are hard to be efficiently modularized. Moreover, new programming languages are hard to build simply by incorporating different language components due to complex interactions among different language features. This is true for general-propose programming languages, as well as domainspecific languages. Here, object-oriented techniques and concepts, like encapsulation and inheritance, have much to offer and improve language specification languages towards better modularity, reusability and extensibility. In this position paper our view and experience with object-oriented specification languages are given.", "num_citations": "6\n", "authors": ["153"]}
{"title": "Domain-specific languages for software engineering\n", "abstract": " Domain-specific languages [1, 2, 3] are programming languages for solving problems in a particular domain and provide built-in abstractions and notations for that domain. Domain-specific languages are usually small, more declarative than imperative, less expressive and more attractive than general-purpose languages because of easier programming, systematic reuse, better productivity, reliability, maintainability, and flexibility. However, the benefits of domain-specific languages are not for free. The cost of domain-specific language design, development and maintenance has to be taken into account. Without an appropriate methodology and tools these costs can be higher than savings obtained by the later use of domain-specific languages. Advantages of the formal definitions of general-purpose languages should be exploited, taking into consideration the special nature of domain-specific languages. To be productive, the development of these languages has to be based on highlevel automated tools [4].The purpose of this mini-track is to bring together an international audience of researchers and practitioners actively involved in the development of domain-specific languages that support the software engineering process. It covers a wide range of domain-specific languages applied in different software engineering problems. Some topics of interest for this mini-track are:\u2022 design and implementation of domain-specific languages,", "num_citations": "6\n", "authors": ["153"]}
{"title": "A high-level framework for parallelizing legacy applications for multiple platforms\n", "abstract": " The tremendous growth and diversification in the area of computer architectures has contributed towards an upsurge in the number of parallel programing paradigms, languages, and environments. However, it is often difficult for domain-experts to develop expertise in multiple programming paradigms and languages in order to write performance-oriented parallel applications. Several active research projects aim at reducing the burden on programmers by raising the level of abstraction of parallel programming. However, a majority of such research projects either entail manual invasive reengineering of existing code to insert new directives for parallelization or force conformance to specific interfaces. Some systems require that the programmers rewrite their entire application in a new parallel programing language or a domain-specific language. Moreover, only a few research projects are addressing the need of a\u00a0\u2026", "num_citations": "5\n", "authors": ["153"]}
{"title": "Tools and techniques for non-invasive explicit parallelization\n", "abstract": " This paper presents an overview of our experiments in integrating modern software engineering tools and techniques with the process of developing parallel applications for distributed memory architectures. The main goal was to determine the methods that have the potential of reducing the complexities associated with explicit parallelization. We experimented with template metaprogramming, aspect-oriented programming, program transformation engine, and a domain-specific language called Hi-PaL. The pros and cons of using each technique for explicit parallelization are presented in this paper. Our experiments demonstrate that through a combination of modern software engineering tools and techniques, the effort involved in explicit parallelization can be reduced by 90\u00a0% without any significant loss in performance.", "num_citations": "5\n", "authors": ["153"]}
{"title": "Parameter control of EAs using exploration and exploitation measures: Preliminary results\n", "abstract": " This paper introduces a parameter control approach that utilizes recently introduced exploration and exploitation measures as feedback to adaptively control evolution processes. Schwefel\u2019s Problem 2.22 and Shekel\u2019s Foxholes Function are selected as benchmark functions to show the competence and usefulness of the measures. The paper shows that with new exploration and exploitation measures, the evolution processes generate relatively well results in terms of fitness and/or convergence rate.", "num_citations": "5\n", "authors": ["153"]}
{"title": "Fitting Sovova's mass transfer model using an evolutionary algorithm and differential evolution\n", "abstract": " In chemical engineering, reliable models are necessary to reduce the cost of process design. An evolutionary algorithm with resizable population was used to estimate coefficients of Sovova's mass transfer model and was compared with a global optimiser found in the literature and commonly used differential evolution algorithm. Comparison of the evolutionary algorithm to the global optimisation technique proved that the evolutionary algorithm is more robust, efficient, and significantly better than the global optimiser in regards to the deviation of the model from experimental data. It is also shown that the proposed evolutionary algorithm performed better than differential evolution algorithm.", "num_citations": "5\n", "authors": ["153"]}
{"title": "Developing scientific applications using generative programming\n", "abstract": " Scientific applications usually involve large number of distributed and dynamic resources and huge datasets. A mechanism like checkpointing is essential to make these applications resilient to failures. Using checkpointing as an example, this paper presents an approach for integrating the latest software engineering techniques with the development of scientific software. Generative programming is used in this research to achieve the goals of non-intrusive reengineering of existing applications to insert the checkpointing mechanism and to decouple the checkpointing-specifications from its actual implementation. The end-user specifies the checkpointing details at a higher level of abstraction, using which the necessary code is generated and woven into the application. The lessons learned and the implementation approach presented in this paper can be applied to the development of scientific applications in\u00a0\u2026", "num_citations": "5\n", "authors": ["153"]}
{"title": "A tool for compiler construction based on aspect-oriented specifications\n", "abstract": " Aspect-oriented programming (AOP) provides a way to modularize crosscutting concerns. Crosscuting concerns can be found in various representations of software artifacts and in different steps of software life cycle (e.g., source code, models, requirements, language grammars). This paper provides an introduction to the AspectLISA tool and its aspect-oriented specification language for programming language definition and compiler construction. AspectLISA is a mature, well-tested system for automatically generating compilers, interpreters, and other language related tools from formal incremental and reusable aspect-oriented attribute grammar-based specifications. In the paper we discuss about the issues involved in the design and implementation of domain-specific aspect language for compiler construction, as well as some benefits of aspect-oriented specifications.", "num_citations": "5\n", "authors": ["153"]}
{"title": "A metaevolutionary approach for the traveling salesman problem\n", "abstract": " The metaevolutionary approach used in searching for the best combination of crossover operators for the traveling salesman problem is described. Since different crossover operators preserve different useful properties, the combination of operators may out-perform a single operator. Rather than randomly search for the best combination of crossover operators, the metaevolutionary approach is used. Preliminary results confirm this hypothesis.", "num_citations": "5\n", "authors": ["153"]}
{"title": "Incremental language design\n", "abstract": " Formal methods for describing programming language semantics are not widely used since they are not modular, extensible and reusable. In the paper, a new extensible and reusable approach for specifying programming languages with attribute grammars is presented. The concepts from object-oriented programming, templates and multiple inheritance, are integrated with attribute grammars. A template in attribute grammar is an abstraction of a semantic rule parameterised with attribute occurrences. Conversely, the whole attribute grammar is a subject of multiple inheritance and specialisation. With the proposed approach a language designer has the opportunity to design incrementally a language or reuse some fragments from other programming language specifications. Templates and multiple inheritance have been implemented in the compiler generator tool LISA version 2.0.", "num_citations": "5\n", "authors": ["153"]}
{"title": "Reusability of formal specifications in programming language description\n", "abstract": " Compiler construction is often mentioned as one of the few really systematically managed disciplines. There is a long tradition of producing compilers, underlying theories are well understood and there exist many application generators which automatically produce compilers or interpreters from programming language specifications. In spite of this, currently used formal methods for programming language description are not modular, extensible and reusable. Since programming language design is an iterative process, designers need partial descriptions that can easily be extended and modified. In the paper our approach to reusable semantic specifications is described. The concept of semantic specification reuse for programming language design is a promising field of study which should contribute to better modularity, clarity, reusability and a general use of formal methods. In addition, experience gained in reusability of programming language specifications can also be applied to...", "num_citations": "5\n", "authors": ["153"]}
{"title": "Reverse language engineering: Program analysis and language inference\n", "abstract": " Abstraction is one of the most important concepts in computer science. This paper presents approach for analysis of abstraction based on program samples. Developed tool for analysis of Haskell programs from syntactic point of view is presented. Derivation trees of programs provided by the tool are used in presented approach for measurement of formal abstraction effect. We propose a method for automatised raise of abstraction level based on recognition of patterns in programs code. Language learning or grammatical inference is a technique for inferring a context-free grammar from a set of positive and/or negative samples. In this paper we also present a memetic algorithm for grammatical inference, called MAGIc. MAGIc is demonstrated on small part of Haskell language, data type declaration. MAGIc is able to infer correct context-free grammar from positive samples only.", "num_citations": "4\n", "authors": ["153"]}
{"title": "Refining high performance Fortran code from programming model dependencies\n", "abstract": " For next generation applications, programmers will be required to adapt to a new style of programming to utilize the parallelism in the processors available to them. Even with new advances, parallel programming still requires skill beyond that possessed by an average programmer. This is primarily due to the architecture-specific details in the domain. In this", "num_citations": "4\n", "authors": ["153"]}
{"title": "A SOA Approach for Domain-Specific Language Implementation\n", "abstract": " Although there have been many benefits of Domain-Specific Languages (DSLs) reported from both academia and industry, implementation of DSLs continue to face challenges with respect to frequent evolution of both syntax and semantics. Techniques for implementing DSLs also lack interoperable capabilities among base languages and limited tool support. Such challenges result in increasing DSL development cost and constrain DSL adoption opportunities. This paper introduces a Service-Oriented Architecture (SOA) approach to address such problems. The approach utilizes WSDL to perform lexical and syntax analysis. Web services are used to define the semantics of a DSL, and WS-BPEL is then used to specify a DSL program. We present two case studies representing different DSL categories to show the feasibility of SOA-based DSL implementation. The case studies demonstrate the potential for easing\u00a0\u2026", "num_citations": "4\n", "authors": ["153"]}
{"title": "Automatic generation of model traversals from metamodel definitions\n", "abstract": " Developing software from models is a growing practice and there exist many model-based tools (eg, model editors, model interpreters) for supporting model-driven engineering. Even though these tools facilitate the automation of software engineering tasks and activities, such tools are typically engineered manually. In this paper, a simple technique is described that enables automatic generation of model traversals. Semantic rules can be inserted into a traversal algorithm to provide meaning to the modeling language. The combination of automated traversal generation with attached semantic rules can generate a model interpreter that can translate a model into some other representation.", "num_citations": "4\n", "authors": ["153"]}
{"title": "Domain-specific languages\n", "abstract": " A programming language is a notation for expressing computations (algorithms) in both machine and human readable form. Appropriate programming languages and tools may drastically reduce the cost of building new applications as well as maintaining existing ones. In this regard, a domain-specific language (DSL), which is a language that provides constructs and notations tailored toward a particular application domain, is no exception. Usually, domainspecific languages are small, more declarative than imperative, and more attractive than general-purpose languages for their particular application domain because of:\u2022 easier program understanding, writing, and reasoning,\u2022 enhanced productivity, reliability, reusability, maintainability,\u2022 easier verification,\u2022 reduced semantic distance between the problem and the program.Despite the fact that domain-specific languages have been developed from the beginning\u00a0\u2026", "num_citations": "4\n", "authors": ["153"]}
{"title": "Language development in a visual manner\n", "abstract": " Programming language design and implementation are still one of the challenges of computer science. Programmers use a variety of languages in their daily work, and new languages appear frequently. With formal methods for programming language description, a language designer has the chance to automatically generate a compiler or an interpreter. Unfortunately, compiler generators nowadays use linear textual specifications, which are less suitable then visual presentations. In this paper, a language development in a visual manner is described.", "num_citations": "4\n", "authors": ["153"]}
{"title": "IMCL Language and its Implementation on the Personal Computer\n", "abstract": " The use of traditional industrial controllers has been a common practice for successfully controlling processes in industrial plants for a long time. However, these old-fashioned controllers (Figure 1) are unfortunately inflexible and much too slow and unreliable for critical applications, and not \"user friendly.\" Still worse, programming them is tedious, lengthy and difficult. LSI and VLSI technology with their 16- and 32-bit processors has permitted a new approach to the design and use of industrial controllers (Figure 2). The shift from MAD (Manually Aided Design) to CAD has been the most important result of this shift to date. But finally, newly emerging concepts of parallel computing, applicative languages and non-yon Neumann architecture have awakened our hopes of employing the computer to liberate the human (Figure 3).", "num_citations": "4\n", "authors": ["153"]}
{"title": "Aspect-Oriented Attribute Grammars\n", "abstract": " Despite the efforts of several researchers modularization, reusability and extensibility remain a problem within the area of language specification. Attribute Grammars (AGs) present a well-known formal approach for defining programming languages. This paper presents a new approach to language specification which increases the level of attribute grammars modularity and reusability and decreases developers\u2019 effort for specifying a new language. The paper introduces Aspect-Oriented Attribute Grammars (AOAGs) which extend the original notion of attribute grammars with features known from Aspect-Oriented Programming (AOP). Ill. 4, bibl. 16 (in English; abstracts in English and Lithuanian).", "num_citations": "3\n", "authors": ["153"]}
{"title": "Use of Genetic Algorithm for Fitting Sovova's Mass Transfer Model.\n", "abstract": " A genetic algorithm with resizable population has been applied to the estimation of parameters for Sovova\u2019s mass transfer model. The comparison of results between a genetic algorithm and a global optimizer from the literature shows that a genetic algorithm performs as good as or better than a global optimizer on a given set of problems. Other benefits of the genetic algorithm, for mass transfer modeling, are simplicity, robustness and efficiency.", "num_citations": "3\n", "authors": ["153"]}
{"title": "MARS: Metamodel Recovery from Multi-tiered Models Using Grammar Inference\n", "abstract": " In model-driven engineering, metamodels may get lost over time resulting in the inability to load and view existing model instances. MARS is a system that recovers metamodels from model instances using grammar inference. This paper discusses advances in MARS that improve accuracy and scalability.", "num_citations": "3\n", "authors": ["153"]}
{"title": "Implementation of Programming Languages Syntax and Semantics\n", "abstract": " Unlike natural languages, programming languages are strictly stylized entities created to facilitate human communication with computers. In order to make programming languages recognizable by computers, one of the key challenges is to describe and implement language syntax and semantics such that the program can be translated into machine-readable code. This process is normally considered as the front-end of a compiler, which is mainly related to the programming language, but not the target machine. This article will address the most important aspects in building a compiler front-end; that is, syntax and semantic analysis, including related theories, technologies and tools, as well as existing problems and future trends. As the main focus, formal syntax and semantic specifications will be discussed in detail. The article provides the reader with a high-level overview of the language implementation process\u00a0\u2026", "num_citations": "3\n", "authors": ["153"]}
{"title": "Ugla\u0161evanje parametrov rotacijskega gozda in klasifikatorjev v paketu Weka z genetskim algoritmom\n", "abstract": " A classifier is as useful as accurately it can learn from data and predict right decisions from new data. Many classifiers have control parameters that are usually set to default values. Because the data obtained from different domains are often very different, the accuracy of a classifier can vary substantially and may not be optimal at all. We realize that the classifier parameter values have important impact on the classifier accuracy and that appropriate parameter values are not equal for different datasets. To tune the classifier parameters, we have implemented a genetic algorithm coupled with the Weka data mining package, and experimentally tuned the parameters of decision tree and rotation forest classifiers on several datasets.", "num_citations": "3\n", "authors": ["153"]}
{"title": "Web service for designing and implementing formal languages\n", "abstract": " An intelligent Web service and its interface for designing and implementing formal languages are described in the paper. The paper describes also background tools LISA and GIE used in the Web service and some basics of their usage. Three language design approaches are presented. Firstly, from scratch using LISA specifications, secondly using stored specifications from other developers, and thirdly with a set of positive and negative example strings/programs. Advanced user interface with shared and documented repository of solutions make Web service suitable for beginners as well as compiler experts. Web service has been designed in a way which makes it suitable for integration in standalone applications", "num_citations": "3\n", "authors": ["153"]}
{"title": "Pattern transformation for two-dimensional separation of concerns\n", "abstract": " Design patterns are utilized in software development to decouple individual concerns, so that a change in a design decision is isolated to one location of the code base. However, multidimensional concerns exist in software development and therefore no single design pattern offers a panacea toward addressing problems of change evolution. By analyzing the matrix of concerns during the software development process and utilizing transferable aspect-orientation and object-orientation, a pattern transformation based two-dimensional separation of concerns is described, which integrates the benefits derived from the Inheritance pattern and several GoF patterns. An example implementation is shown using Java and AspectJ.", "num_citations": "3\n", "authors": ["153"]}
{"title": "Prolog and automatic language implementation systems\n", "abstract": " In the paper the use of Prolog, their benefits and drawbacks in automatic language implementation systems are presented. Various formal methods such as attribute grammars, operational semantics and denotational semantics are briefly described and implemented in Prolog. The advantages of Prolog basically stem from the use of unification and nondeterminism, and the price paid for the advantages are slower execution times. Various Prolog implementation of formal semantics method show that Prolog is viable tool for programming language development, design and prototyping.", "num_citations": "3\n", "authors": ["153"]}
{"title": "Object-Oriented Pattern-Based Language Implementation\n", "abstract": " Formal methods are often used for programming language description as they can specify syntax and semantics precisely and unambiguously. However, their popularity is offset by the poor reusability and extendibility when applied to non-toy programming language design. One cause of this problem is that classical formal methods lack modularity. Meanwhile there are always needs for informal constructs for semantic analysis, and there is no simple and precise way to specify informal constructs by formal specification, which makes the formal specification too complicated to understand. To address the aforementioned problems with modern software engineering technology, we conbine object-oriented Two-Level Grammar with Java to modularize language components and apply design patterns to achieve the modularity and implement the informal constructs in a proper way.", "num_citations": "3\n", "authors": ["153"]}
{"title": "A novel direct measure of exploration and exploitation based on attraction basins\n", "abstract": " Exploration, the process of visiting a new region in a search space, and exploitation, the process of searching in the neighborhood of previously visited regions, are two centerpieces of any metaheuristic algorithm. It is a common belief that good results can be obtained only if there is a good balance between exploration and exploitation. Hence, there is an urgent need to control the balance between exploration and exploitation in a direct manner. But, currently, direct measures of exploration and exploitation are almost non-existent, and researchers rely on indirect measures of exploration and exploitation, such as diversity, entropy, and fitness improvements. To remedy this situation, in this paper, a novel direct measure of exploration and exploitation is proposed that is based on attraction basins\u2014parts of a search space where each part has its own point called an attractor, to which neighboring points tend to evolve\u00a0\u2026", "num_citations": "2\n", "authors": ["153"]}
{"title": "Special issue on quality in model-driven engineering\n", "abstract": " Model-driven engineering (MDE) refers to a range of approaches where models play a core role in software development. Modeling promotes reasoning at a higher level of abstraction, therefore reducing complexity of software development, while hiding the unnecessary low level details at appropriate stages, and promoting communication among the several stakeholders in the development process. MDE initiatives make claims of increased quality and productivity by separating business and application logic from underlying platform technology, transforming models to other models and automating code generation. However, while quality assurance is a well-known topic in traditional software engineering, less is known on how to assess quality across the MDE lifecycle. We should understand not only how to measure the quality of the MDE process (and determine whether it is better than other approaches), but\u00a0\u2026", "num_citations": "2\n", "authors": ["153"]}
{"title": "Special issue on the Programming Languages track at the 28th ACM Symposium on Applied Computing\n", "abstract": " Special issue on the Programming Languages track at the 28th ACM Symposium on Applied Computing \u00d7 Close The Infona portal uses cookies, ie strings of text saved by a browser on the user's device. The portal can access those files and use them to remember the user's data, such as their chosen settings (screen view, interface language, etc.), or their login data. By using the Infona portal the user accepts automatic saving and using this information for portal operation purposes. More information on the subject can be found in the Privacy Policy and Terms of Service. By closing this window the user confirms that they have read the information on cookie usage, and they accept the privacy policy and the way cookies are used by the portal. You can change the cookie settings in your browser. I accept Polski English Login or register account remember me Password recovery INFONA - science communication portal \u00d7 , \u2026", "num_citations": "2\n", "authors": ["153"]}
{"title": "Natural language processing resources: Using semantic web technologies\n", "abstract": " Natural language processing relies heavily on resources. Most common usage scenarios include using the resources for automated lexical tagging or named entity recognition. Also manually annotated language resources are used for benchmarking of new automated approaches. To allow any processing on a large scale and considering the complexity of natural language (words can have multiple meanings within the same general context) the resources have to be quite large. In this paper we focus on lexical resources in ontology form.", "num_citations": "2\n", "authors": ["153"]}
{"title": "Introducing domain-specific language implementation using web service-oriented technologies\n", "abstract": " Several advantages have been documented that suggest Domain-Specific Languages (DSLs) have the potential to improve productivity, reliability, maintainability and portability in some specialized domains. However, several key challenges still remain. In particular, the extension and evolution of both DSL syntax and semantics still suffer due to the limitations related to the current state-of-the-art implementation techniques. Such techniques also lack interoperable capabilities among base languages and limited tool support. As changes of domain concepts are omnipresent and more base languages may support DSL implementation, the aforementioned limitations may be no longer tolerable, and hence a new implementation technique to DSL development is desired. This paper implements six DSL case studies (representing imperative, declarative and hybrid categories) to validate the feasibility of utilizing Service\u00a0\u2026", "num_citations": "2\n", "authors": ["153"]}
{"title": "Improving the graph grammar parser of Rekers and Schurr\n", "abstract": " Graph grammars and graph grammar parsers are to visual languages what string grammars and parsers are to textual languages. A graph grammar specifies a set of valid graphs and can thus be used to formalise the syntax of a visual language. A graph grammar parser is a tool for recognising valid programs in such a formally defined visual language. A parser for context-sensitive graph grammars, which have proved to be suitable for formalising real-world visual languages, was developed by Rekers and Schu\u0308rr. We propose three improvements of this parser. One of them enlarges the class of parsable graph grammars, while the other two increase the parser\u0308s computational efficiency. Experimental results show that for some (meaningful) graph grammars, our improvements can enhance the parser\u0308s performance by orders of magnitude. The proposed improvements will hopefully increase both the parser\u0308s applicability and the interest in visual language parsing in general.", "num_citations": "2\n", "authors": ["153"]}
{"title": "Can domain-specific languages be implemented by service-oriented architecture?\n", "abstract": " Although there have been many benefits of Domain-Specific Languages (DSLs) reported from both academia and industry, the need to evolve a DSL definition in the presence of limited tool support results in several challenges that increase DSL development cost and constrain DSL adoption opportunities. As a new approach to address such limitations, this paper introduces a Service-Oriented Architecture (SOA) technique to implement an existing imperative DSL. The approach utilizes WSDL to perform lexical analysis and assist with syntax analysis. The paper also explores how WS-BPEL can be used to define a DSL grammar. Web services have potential to define the semantics of a DSL. The advantages that SOA offers in DSL implementation are realized through SOA's characteristics of interoperability, loose coupling, and technology-neutral implementation.", "num_citations": "2\n", "authors": ["153"]}
{"title": "Using a Program Transformation Engine to Infer Types in a Metamodel Recovery System\n", "abstract": " Domain-Specific Modeling (DSM) allows domain experts to concentrate on the essential characteristics of a problem space without being overwhelmed by the complexities that may occur in the solution space. DSM is focused on the creation of a metamodel for a specific domain, from which instances pertaining to specific configurations of that domain can be constructed. However, as the metamodel undergoes evolutionary changes, repositories of instance models (also called domain models) can become orphaned from their defining metamodel. Within the context of model-driven engineering (MDE), we have developed the Metamodel Recovery System (MARS) which addresses the problem of \u201cmetamodel drift\u201d and recovers the design knowledge in a repository of legacy models. MARS is a semi-automatic system that uses grammar inference techniques to recover a metamodel by mining instance models. In addition to the instance models, there are other artifacts that can be investigated in the modeling repository. In this paper we describe an extension to MARS in the form of a type inference capability that is accomplished by the use of a program transformation engine that mines the model compiler code and recovers the type information of fields (or attributes) of metamodel entities.", "num_citations": "2\n", "authors": ["153"]}
{"title": "Gpk: A java based genetic programming kernel\n", "abstract": " A Java based genetic programming kernel (GPK) is described. Its main features are ease of use, portability, and robustness, which were achieved by strongly using the Java reflection mechanism. This unique characteristic of our GPK distinguishes it from other similar frameworks. GPK was successfully used in our research work as well in the teaching process.", "num_citations": "2\n", "authors": ["153"]}
{"title": "Using flocks for solving numerical optimization problems\n", "abstract": " The paper deals with an alternative numerical approach to optimum searching, which is similar to the particle swarm optimizer. The proposed approach uses aggregate motion of creatures in the artificial life based on flocks. Creatures have the social tendency to stick together, and to perform lifelike emergent behaviour, which is based on a few simple, local rules. They differ from most other artificial life flocking (Boids-type) implementations by being attracted by creatures that \"sit\" on the best found result. Their emergent behaviour produces effective search in the space of all possible solutions. Evolution Strategies, which are often used for solving this kind of problems, were used to compare the quality of searches.", "num_citations": "2\n", "authors": ["153"]}
{"title": "Graph grammar induction\n", "abstract": " We propose a novel approach to the graph grammar induction problem, the goal of which is to find a concise graph grammar whose language (the set of graphs which can be generated using the grammar's productions, i.e., graph substitution rules) contains all of the given \u201cpositive\u201d graphs and none of the given \u201cnegative\u201d graphs. Most of the existing induction methods learn graph grammars from positive examples alone, performing an iterative specific-to-general search procedure in which candidate productions for the grammar being induced are created from repeated subgraphs in the input graph set. Our approach, by contrast, couples the induction process with a graph grammar parser, thus inducing grammars from both positive and negative graphs. In addition to a graph grammar generalization operator akin to those found in the majority of existing approaches, we employ a novel generalization technique\u00a0\u2026", "num_citations": "1\n", "authors": ["153"]}
{"title": "Simpleconcepts: Support for constraints on generic types in c++\n", "abstract": " Generic programming plays an essential role in C++ software through the use of templates. However, both the creation and use of template libraries is hindered by the fact that the language does not allow programmers to specify constraints on generic types. To date, no proposal to update the language to provide concepts has survived the committee process. Until that time comes, as a form of early support, this paper introduces SimpleConcepts, an extension to C++11 that provides support for concepts, sets of constraints on generic types. SimpleConcepts features are parsed according to an island grammar and source-to-source translation is used to lower concepts to pure C++11 code.", "num_citations": "1\n", "authors": ["153"]}
{"title": "A Domain-Specific Language for High-Level Parallelization\n", "abstract": " There are several ongoing research efforts in the High Performance Computing (HPC) domain that are employing Domain-Specific Languages (DSLs) as the means of augmenting end-user productivity. A discussion on some of the research efforts that can positively impact the end-user productivity without negatively impacting the application performance is presented in this chapter. An overview of the process of developing a DSL for specifying parallel computations, called High-Level Parallelization Language (Hi-PaL), is presented along with the metrics for measuring its impact. A discussion on the future directions in which the DSL-based approaches can be applied in the HPC domain is also included.", "num_citations": "1\n", "authors": ["153"]}
{"title": "Grammar inference technology applications in software engineering\n", "abstract": " While Grammar Inference (GI) has been successfully applied to many diverse domains such as speech recognition and robotics, its application to software engineering has been limited, despite wide use of context-free grammars in software systems. This paper reports current developments and future directions in the applicability of GI to software engineering, where GI is seen to offer innovative solutions to the problems of inference of domain-specific language (DSL) specifications from example DSL programs and recovery of metamodels from instance models.", "num_citations": "1\n", "authors": ["153"]}
{"title": "Robot Learning of Domain Specific Knowledge from Natural Language Sources\n", "abstract": " The belief that problem solving systems would require only processing power was proven false. Actually almost the opposite is true: for even the smallest problems vast amounts of knowledge are necessary. So the key to systems that would aid humans or even replace them in some areas is knowledge. Humans use texts written in natural language as one of the primary knowledge sources. Natural language is by definition ambiguous and therefore less appropriate for machine learning. For machine processing and use the knowledge must be in a formal; machine readable format. Research in recent years has focused on knowledge acquisition and formalization from natural language sources (documents, web pages). The process requires several research areas in order to function and is highly complex. The necessary steps usually are: natural language processing (transformation to plain text, syntactic and semantic analysis), knowledge extraction, knowledge formalization and knowledge representation. The same is valid for learning of domain specific knowledge although the very first activity is the domain definition. These are the areas that this chapter focuses on; the approaches, methodologies and techniques for learning from natural language sources. Since this topic covers multiple research areas and every area is extensive, we have chosen to segment this chapter into five content segments (excluding introduction, conclusion and references). In the second segment we will define the term domain and provide the reader with an overview of domain engineering (domain analysis, domain design and domain implementation). The third\u00a0\u2026", "num_citations": "1\n", "authors": ["153"]}
{"title": "GenInc: An Incremental Context-Free Grammar Learning Algorithm for Domain-Specific Language Development.\n", "abstract": " While grammar inference (or grammar induction) has found extensive application in the areas of robotics, computational biology, speech and pattern recognition, its application to problems in programming language and software engineering domains has been limited. We have found a new application area for grammar inference which intends to make domainspecific language development easier for domain experts not well versed in programming language design, and finds a second application in construction of renovation tools for legacy software systems. As a continuation of our previous efforts to infer context-free grammars (CFGs) for domain-specific languages which previously involved a genetic-programming based CFG inference system, we discuss improvements made to an incremental learning algorithm, called GenInc, for inferring context-free grammars with a core focus on facilitating domain-specific language development. We elaborate on the enhancements made to GenInc in the form of new operators, and conclude by discussing the results of applying GenInc to domain-specific languages.", "num_citations": "1\n", "authors": ["153"]}
{"title": "Automatic generation of language-based tools\n", "abstract": " Conference name ETAPS 2002: European joint conference on theory and practice of software. Satellite workshop (Grenoble 2002-04-13)= Workshop on language descriptions, tools and applications (2; Grenoble 2002-04-13)", "num_citations": "1\n", "authors": ["153"]}
{"title": "Controlling industrial processes with a dataflow industrial controller: A way to achieve better performances\n", "abstract": " An application of the macro dataflow computer architecture in controlling industrial processes is described in this paper. The DFCL \u2014 a relatively low level data-flow language and a complier, which transforms programs written in this language into program graphs with different levels of granularity are presented first. A suitable macro data-flow industrial controller (IC) model architecture, which was theoretically studied and simulated is described next. The inputs in the simulation are: an fined grained dataflow graph, a number of processors, a communication delay times and execution times for simple nodes. The outputs are: a waiting tokens profile, a parallelism profile, a waiting nodes profile in queue, the program graph with optimal grain size and scheduling strategy for nodes of the program graph. The above research work was done simultaneously with the development of a real, but conventional IC so that many\u00a0\u2026", "num_citations": "1\n", "authors": ["153"]}