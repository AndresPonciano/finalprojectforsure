{"title": "Prototyping in industrial software projects-bridging the gap between theory and practice\n", "abstract": " Prototyping, a method and technique frequently used in many engineering disciplines, has been adopted as a technique in software engineering to improve the calculation of new projects involving risks. However, there has so far been a lack of documented experience with the use of prototyping in industrial software production. The paper tries to close this gap. First, we introduce central prototyping concepts and terminology. We also present five industrial software projects in which explicit use was made of prototyping. Based on our analysis of these projects we present the resulting conclusions: prototyping means more than rapidly developing user interfaces; prototyping is a central part of a development strategy; prototyping means end user involvement; finding the right mixture of prototypes improves the development process.< >", "num_citations": "157\n", "authors": ["1248"]}
{"title": "Towards definitions for release engineering and DevOps\n", "abstract": " Delivering software fast, reliable, and predictable is essential for software development organizations. Yet, they often struggle to implement proper approaches and practices like release engineering and DevOps. One reason is the lack of consistent definitions for both of these terms, making it difficult to grasp the meaning and adding further confusion. To the best of our knowledge, there are no uniform definitions for both terms, and thus, many inadequate or even wrong interpretations exist. Consequently, these terms are often confused, misinterpreted, or used as synonyms. In this paper, we propose definitions for release engineering and DevOps to tell both apart.", "num_citations": "145\n", "authors": ["1248"]}
{"title": "Deficiencies in feature models\n", "abstract": " Software product lines are characterized through common and variable parts. Modeling variability is one of the most important tasks during the analysis phase. Domain analysis and requirements elicitation bring up a huge amount of requirements and dependencies between product characteristics. Feature modeling is one approach to deal with complexity in expressing several requirements in features and structure them hierarchically in feature diagrams. Unfortunately these feature models become very complex as well. Therefore it is necessary to develop and maintain feature models very carefully with respect to redundancy and consistency. As feature models are not only used for domain modeling, but for product derivation in product line development as well, inconsistent feature models will limit the chance to build consistent product configurations. Hence, it must be defined, what is meant by consistency and redundancy in the context of feature models. Experiences show that an adequate tool support is needed to manage the feature models and to support automatic detection of redundancies and inconsistent models and product derivations. Our research group has developed a prototype of a requirements engineering tool that supports feature modeling and provides automatic consistency checks.", "num_citations": "141\n", "authors": ["1248"]}
{"title": "Modeling variability by UML use case diagrams\n", "abstract": " Software Product Lines are characterized through common and variable parts. Modeling variability is one of the most important tasks during the analysis phase. In order to guarantee that domain experts and developers understand each other variability has to be modeled explicitly. In this paper we present and examine the different types of variability. We analyze and assess UML Use Case diagrams in detail with respect to their capability to express variability, with the result, that they only provide poor assistance. Consequently we introduce an enhancement of the Use Case meta-model to overcome this deficiency by integrating new modeling elements that allow to express the identified types of variability.", "num_citations": "123\n", "authors": ["1248"]}
{"title": "Requiline: A requirements engineering tool for software product lines\n", "abstract": " Software Product Lines are characterized through common and variable parts. Modeling variability is one of the most important tasks during the analysis phase. Domain analysis and requirements elicitation will bring up a huge amount of requirements and dependencies between product characteristics. Feature modeling is one approach to deal with complexity in expressing several requirements in features and structure them hierarchically in feature diagrams. Unfortunately the requirements and feature models become very complex as well. An adequate tool support is needed to manage the feature models and to support the linkage to requirements. Our research group has developed a prototype of a requirements engineering tool that supports the requirements engineering process for software product lines.", "num_citations": "122\n", "authors": ["1248"]}
{"title": "User interface prototyping-concepts, tools, and experience\n", "abstract": " In recent years the development of highly interactive software systems with graphical user interfaces has become increasingly common. The acceptance of such a system depends to a large degree on the quality of its user interface. Prototyping is an excellent means for generating ideas about how a user interface can be designed, and it helps to evaluate the quality of a solution at an early stage. We present the basic concepts behind user interface prototyping, a classification of tools supporting it and a case study of nine major industrial projects. Based on our analysis of these projects we present the following conclusions: prototyping is used more consciously than in recent years. No project applied a traditional life-cycle approach, which is one of the reasons why most of them were successful. Prototypes are increasingly used as a vehicle for developing and demonstrating visions of innovative systems.", "num_citations": "118\n", "authors": ["1248"]}
{"title": "Studien-Arbeiten: ein Leitfaden zur Vorbereitung, Durchf\u00fchrung und Betreuung von Studien-, Diplom-und Doktorarbeiten am Beispiel Informatik. 2\n", "abstract": " Dieser Leitfaden ist als Skriptum des Kolloquiums \"Wissenschaftliches Arbeiten\" entstanden. Das Kolloquium wird auf Anregung der Fachschaft Informatik seit 1990 an der Universit\u00e4t Stuttgart regelm\u00e4\u00dfig abgehalten. Dieser Schrift liegen die Erfahrungen in dieser Fakult\u00e4t zugrunde, und so stammen auch die Beispiele aus diesem Gebiet. Aber die Unterschiede gegen\u00fcber anderen technischen Disziplinen sind marginal, so da\u00df sich auch Studierende benachbarter F\u00e4cher, vor allem der Ingenieur- und der Naturwissenschaften, beim Lesen nicht fremd f\u00fchlen werden.", "num_citations": "58\n", "authors": ["1248"]}
{"title": "Prototyping in industriellen Software-Projekten-Erfahrungen und Analysen\n", "abstract": " Prototyping in industriellen Software-Projekten - Erfahrungen und Analysen - Digitale Bibliothek - Gesellschaft f\u00fcr Informatik eV GI Logo GI Logo Anmelden Digitale Bibliothek Gesamter Bestand Bereiche & Sammlungen Titel Autor Erscheinungsdatum Schlagwort Diese Sammlung Titel Autor Erscheinungsdatum Schlagwort Toggle navigation Digital Bibliothek der Gesellschaft f\u00fcr Informatik eV GI-DL English Deutsch Deutsch English Deutsch Dokumentanzeige Startseite Informatik Spektrum Band 15 (1992) Band 15 - Heft 2 (April 1992) Dokumentanzeige Startseite Informatik Spektrum Band 15 (1992) Band 15 - Heft 2 (April 1992) Dokumentanzeige Prototyping in industriellen Software-Projekten - Erfahrungen und Analysen Autor(en): Kiebach, Antoinette [DBLP] ; Lichter, Horst [DBLP] ; Schneider-Hufschmidt, Matthias [DBLP] ; Z\u00fcllighoven, Heinz [DBLP] Vollst\u00e4ndige Referenz BibTeX Kiebach, A., Lichter, H., Schneider-\u2026", "num_citations": "49\n", "authors": ["1248"]}
{"title": "Determining the variation degree of feature models\n", "abstract": " When developing a product line the knowledge about the variation de gree is of vital importance for development, maintenance and evolution of a prod uct line. In this paper we focus on the variation degree of product line feature models, considering different types of variability and dependency relationships between features.", "num_citations": "43\n", "authors": ["1248"]}
{"title": "Towards the Integration of UML-and textual Use Case Modeling.\n", "abstract": " In this paper, we present a metamodel for textual use case descriptions, structurally conforming to the UML, to specify the behavior of use cases in a flow-oriented manner. While being primarily targeted at supporting requirements engineers in creating consistent use case models, the metamodel defines a textual representation of use case behavior that is easily understandable for readers, who are unaware of the underlying metamodel. Hence, the known benefits of natural language use case descriptions are preserved. Being formalized, consistency between UML-based use case representations and their textual descriptions can be automatically ensured. With NaUTiluS we present an extensible, Eclipse-based toolkit, which offers integrated UML use case modeling support, as well as editing capabilities for their textual descriptions.", "num_citations": "38\n", "authors": ["1248"]}
{"title": "Experience on a microservice-based reference architecture for measurement systems\n", "abstract": " In our former work we proposed a micro service-based reference architecture for Enterprise Measurement Infrastructures (EMI) which received encouraging feedback. The reference architecture supports the systematic development of measurement systems. This paper provides deeper insight into the application of the reference architecture by presenting the results of two field studies after an examination of the most important requirements that drove the development of the reference architecture. The two selected field studies were conducted with large cooperation partners from industry and research and addressed real problems. Using our reference architecture, development process, and requirements gathering techniques we were able to successfully build the EMIs presented in this paper. These results further ease the application of micro service inside our reference architecture and support practitioners with\u00a0\u2026", "num_citations": "30\n", "authors": ["1248"]}
{"title": "Model driven development challenges in the automation domain\n", "abstract": " Model driven development has evolved to a mature methodology and technology usable for some industrial settings. Within the automation domain it is an upcoming approach. This paper addresses challenges present in the automation domain when it comes to the usage of model driven development. Quality, life cycle, legacy systems, mental approach and safety challenges are briefly discussed.", "num_citations": "28\n", "authors": ["1248"]}
{"title": "Studien-Arbeiten\n", "abstract": " Dieser Schrift liegen die Erfahrungen in der Fakult\u00e4t Informatik zugrunde, und so stammen auch die Beispiele aus diesem Gebiet. Aber die Unterschiede gegen\u00fcber anderen technischen Disziplinen sind marginal, so da\u00df sich auch Studierende benachbarter F\u00e4cher, vor allem der Ingenieur-und der Naturwissenschaften, beim Lesen nicht fremd f\u00fchlen werden.", "num_citations": "22\n", "authors": ["1248"]}
{"title": "Code smells in infrastructure as code\n", "abstract": " Ensuring high quality in software systems is a wellknown and big challenge. Infrastructure as Code (IaC) gathered increasing popularity in recent years, but there is only little research done in terms of quality of this code. Like with programming languages we find a high diversity of languages and technologies. Existing research introduced code smells from traditional software engineering to the popular provisioning tool Puppet, which uses IaC to specify the desired state of environments. Results show that code smells are an adequate method to assess the quality of Puppet code. In this paper we extend the existing research by first applying code the IaC smells to an other technology and investigate if similar results can be achieved. We applied the code smells in two case studies to open and closed source IaC code repositories. The presented results indicate that IaC smells are present in other tools and\u00a0\u2026", "num_citations": "20\n", "authors": ["1248"]}
{"title": "A framework for model recommenders requirements, architecture and tool support\n", "abstract": " Content-assist systems and code completion are nicely accessible in integrated development environments (IDEs). Using multiple data sources and performing sophisticated completion in several editors is quite common. However, no such supporting system exists for modeling environments, e.g., a completion mechanism in class diagrams is only existent for textual items like names, if at all. We designed a framework to bolster model recommendation research and present the requirements, concepts, architecture, and the realization below. Last of which is easily extendable and adaptable to either new data recommendation strategies or new environments like editors. As additional tool support, we provide a simulation environment, which ease development as well as implementing recommendation algorithm. Accordingly, researchers get all the conceptual groundwork and a realized infrastructure that ease the\u00a0\u2026", "num_citations": "16\n", "authors": ["1248"]}
{"title": "On designing recommenders for graphical domain modeling environments\n", "abstract": " Recommender systems for source code artifacts are newly emerging and are now successfully supporting programmers. Their underlying knowledge bases, recommender algorithms, and user interfaces are well studied. Integrated into the development environment, they do a fairly good job in reducing complexity and development time.", "num_citations": "15\n", "authors": ["1248"]}
{"title": "Model recommenders for command-enabled editors\n", "abstract": " Content assist systems and code completion are nicely accessible in integrated development environments (IDEs). Using multiple data sources and performing sophisticated completion in several editors is quite common. However, no such supporting system exists for modeling environments, eg, a completion mechanism in class diagrams is only existent for textual items like names, if at all. We designed a framework to bolster model recommendation research and briefly present the architecture and the realization in this paper. Both are easily extendable via hot spots by new data recommendation strategies or by completely new environments like editors. As additional tool support for extending this framework, we provide a dashboard, which eases initial development for new extensions. Accordingly, researchers get all the conceptual groundwork and an implemented infrastructure explained in a tutorial manner that eases the initial burden to get recommendations going for modeling environments. These could produce recommendations from various sets of data, eg, example models, patterns, best practices, or template enhanced models.", "num_citations": "15\n", "authors": ["1248"]}
{"title": "SPIALS: A light-weight software process improvement self-assessment tool\n", "abstract": " In this paper we propose a tool-based approach called CMMIbySCRUM to improve CMMI-based processes with Agile technique such as Scrum. This model was designed to be especially useful for VSEs/SMEs. If VSEs/SMEs are aware of the current capability status of their software processes and have a improvement guideline based on their quality targets, they might be able to substantially improve their processes. To support organizations on their way to better processes, we present the design of a generic tool (SPIALS: Software Process Improvement Adaptive Learning System) applicable to measure up organizations' process capability status. VSEs/SMEs can use the tool to perform a self-assessment thus reducing the complex appraisal process. The measurement represents trend of practices which VSEs/SMEs should implement or avoid. The presented tool-based assessment strategy is based on Standard\u00a0\u2026", "num_citations": "15\n", "authors": ["1248"]}
{"title": "Evaluating process quality in GNOME based on change request data\n", "abstract": " The lifecycle of defects reports and enhancement requests collected in the Bugzilla database of the GNOME project provides valuable information on the evolution of the change request process and for the assessment of process quality in the GNOME sub projects. We present a quality model for the analysis of quality characteristics that is based on evaluating metrics on the Bugzilla database, and illustrate it with a comparative evaluation for 25 of the largest products within GNOME.", "num_citations": "15\n", "authors": ["1248"]}
{"title": "A cost-based approach to software product line management\n", "abstract": " The evolution of a software product line requires different product management practices compared to a single product since the diverging requirements of different customers must be coordinated to preserve the common product line architecture. Allowing too much variability leads to substantial follow-up costs during the lifecycle. This paper describes the challenges of product management for an evolving software product line. A costing approach is proposed to enable more transparency on the costs of variability, support sound decisions on the appropriate amount of variability and gain control on the development process.", "num_citations": "15\n", "authors": ["1248"]}
{"title": "From UML to ANSI-C-An Eclipse-Based Code Generation Framework\n", "abstract": " Model-driven engineering has recently gained broad acceptance in the field of embedded and real-time soft-ware systems. While larger embedded and real-time systems, developed eg in aerospace, telecommunication, or automotive industry, are quite well supported by model-driven engineering approaches based on the UML, small embedded and real-time systems, as they can for example be found in the industrial automation industry, are still handled a bit novercal. A major reason for this is that the code generation facilities, being offered by most of the UML modeling tools on the market, do indeed support C/C++ code generation in all its particu-lars, but neglect the generation of plain ANSI-C code. However, this would be needed for small embedded and real-time systems, which have special characteristics in terms of hard time and space constraints. Therefore we developed a framework, which allows to generate ANSI conformant C code from UML models. It is built on top of Eclipse technology, so that it can be integrated easily with available UML modeling tools. Because flexibility and customizability are important requirements, the generation process consists of a model-to-model transformation between the UML source model and an intermediate ANSI-C model, as well as a final model-to-text generation from the intermediate ANSI-C model into C code files. This approach has several advantages compared to a direct code generation strategy.", "num_citations": "14\n", "authors": ["1248"]}
{"title": "Towards the definition of enterprise architecture debts\n", "abstract": " In the software development industry, Technical Debt is regarded as a critical issue in terms of the negative consequences such as increased software development cost, low product quality, decreased maintainability, and slowed progress to the long-term success of developing software. However, despite the vast research contributions in Technical Debt management for software engineering, the idea of Technical Debt fails to provide a holistic consideration to include both IT and business aspects. Further, implementing an enterprise architecture (EA) project might not always be a success due to uncertainty and unavailability of resources. Therefore, we relate the consequences of EA implementation failure with a new metaphor \u2013Enterprise Architecture Debt (EA Debt). We anticipate that the accumulation of EA Debt will negatively influence EA quality, and expose the business to risk.", "num_citations": "13\n", "authors": ["1248"]}
{"title": "QMetric-a metric tool suite for the evaluation of software process data\n", "abstract": " Configuration and change request management systems offer valuable information for the assessment of process quality characteristics. The definition of appropriate metrics that address the information needs of an organization is an intricate task. We present the QMetric tool suite which provides a general infrastructure for specifying metrics, relating them to organization-specific quality models, and automatic evaluation based on empirical comparison data.", "num_citations": "13\n", "authors": ["1248"]}
{"title": "Defizite im Software-Projektmanagement-Erfahrungen aus einer industriellen Studie\n", "abstract": " Software-Entwicklungsprojekte erfolgreich durchzuf\u00fchren, ist eine schwierige Aufgabe. Neben technischen Problemen m\u00fcssen vielf\u00e4ltige organisatorische Probleme gemeistert werden. Ein wesentliches Instrument dabei ist das Projektmanagement. In diesem Beitrag berichten wir \u00fcber zwei von uns durchgef\u00fchrte Studien, deren Ziel es war, den Stand der Praxis im Bereich Projektmanagement zu beleuchten. In Abschnitt 2 stellen wir die durchgef\u00fchrten Studien vor. Abschnitt 3 bildet den Schwerpunkt unseres Beitrags. Er beschreibt die zentralen Ergebnisse, die wir erzielen konnten, indem die identifizierten Schwachstellen und Defizite des Projektmanagements herausgearbeitet werden. In Abschnitt 4 fassen wir diese zusammen und geben Hinweise f\u00fcr ein effektives und effizientes Projektmanagement.", "num_citations": "13\n", "authors": ["1248"]}
{"title": "Engineering model recommender foundations\n", "abstract": " Reuse has been widely carried out successfully, but not with models in Model Driven Engineering. Reasons seem manifold and conceptual issues and poor tool support are among them. A closer look at the tools available shows that models are often held in repositories which merely exceed versioning and indexing support. But model reuse requires mature approaches and tool support to become successful. We created a solid conceptual foundation and found recommendations as one solution, which in turn need appropriate data. We engineer these data subsequently and explain our design rationales. In a nutshell, we create a knowledge library comprising of elements which are connected on generic, semantic, and syntactic level. This knowledge library forms an enhanced knowledge graph enabling chain recommendations.", "num_citations": "12\n", "authors": ["1248"]}
{"title": "BugzillaMetrics: an adaptable tool for evaluating metric specifications on change requests\n", "abstract": " To manage the evolution of software processes and products, it is essential to evaluate their current state and how it evolved. This information can be obtained by analyzing the data available in change request management (CRM) systems like Bugzilla.", "num_citations": "12\n", "authors": ["1248"]}
{"title": "Designing a next-generation continuous software delivery system: concepts and architecture\n", "abstract": " Continuous Integration and Continuous Delivery are established practices in modern agile software development. The DevOps movement adapted theses practices and places the deployment pipeline at its heart as one of the main requirements to automate the software development process and to deliver and operate software in a more robust way with higher quality. Over the time a lot of systems and tools has been developed to implement the deployment pipeline and to support continuous delivery. But software development is complex, its process even more and due to the individual organization of software vendors no real all-in-one solution for CD exists. Literature identified a lot of challenges when adopting CD and DevOps in an organization. This paper presents a conceptual model and fundamental design decisions for a new generation of software delivery systems tackling some of these issues. Our\u00a0\u2026", "num_citations": "11\n", "authors": ["1248"]}
{"title": "Combinatorial testing with constraints for negative test cases\n", "abstract": " Constraint handling is an important extension of combinatorial testing to exclude irrelevant combinations which could otherwise lead to the input masking effect. A special handling of invalid values is also important because of potential input masking. Unfortunately, existing CT approaches only consider invalid values explicitly. Invalid value combinations are equally important but only indirectly supported . Therefore, we present a concept that allows to specify invalid value combinations as logical expressions to generate negative test cases.", "num_citations": "11\n", "authors": ["1248"]}
{"title": "Tool support for user-defined quality assessment models\n", "abstract": " Quality assessment based on software metrics is generally founded on an implicitly or explicitly given quality model, that defines how measurement values are aggregated. The quality model itself is often buried in the supporting tools, which limits adaptability and understandability of the quality model.In this paper we introduce a generic meta-model for quality assessment models that support metric-based quality evaluations. Furthermore we present a corresponding tool for the definition of quality models by the user, and their automatic evaluation based on underlying third-party metric tools.", "num_citations": "11\n", "authors": ["1248"]}
{"title": "Prototyping in industrial software projects:: Experiences and assessment\n", "abstract": " Presents five case studies of industrial software projectsspecifically involving prototyping. Designates projects ranging from 240person\u2010years to two person\u2010years involving large industrial corporationsto small/medium software manufacturers. Analyses the benefits andlimitations of prototyping. Concludes that prototyping is conducive tothe quality of the product and the development process, particularlywhen used in conjunction with an evolutionary development strategy andwhen all parties are aware of the benefits and limitations.", "num_citations": "11\n", "authors": ["1248"]}
{"title": "A framework for automated combinatorial test generation, execution, and fault characterization\n", "abstract": " Fault characterization is an important part of combinatorial testing, enabling it to automatically narrow down failed test inputs to specific failure-inducing combinations. As most current fault characterization algorithms adaptively generate more test inputs based on previous test execution results, a framework that integrates modelling, generation, execution, and fault characterization is necessary. Until now, no such framework exists, resulting in much manual work needed to identify failureinducing combinations.We therefore introduce COFFEe, which is a framework for completely automatic combinatorial testing and fault characterization. In this paper, we derive an architecture for the framework and present coffee4j, a Java implementation of COFFEe that integrates the JUnit5 test framework.", "num_citations": "10\n", "authors": ["1248"]}
{"title": "Towards an integration of multiple process improvement reference models based on automated concept extraction\n", "abstract": " A variety of process improvement reference models (IRM) such as CMMI, COBIT or ITIL support IT organizations. These reference models cover different domains (e.g. IT development, IT Services or IT Governance) but also share some similarities. There are organizations that address multiple domains and want to use different IRMs. As IRMs are described in different structures and are using different terminologies, we propose a tool based approach to extract IRMs\u2019 concepts and to normalize the terminologies. Our solution enables to semi-automatically build an integrated database of IRMs\u2019 concepts based on common meta-models and on a common terminology.", "num_citations": "10\n", "authors": ["1248"]}
{"title": "Simulating software projects\u2014an approach for teaching project management\n", "abstract": " In this paper, the results of two industrial case studies on software project management are presented. These case studies revealed key problem areas in software project management and also proved that there is a serious lack in training of software project managers. To reduce these deficiencies, we suggest a new approach for teaching project management: simulating software projects. The simulation is based on models of software development processes that can be executed. We present a new simulation model, the QA model. The development of that model was strongly guided by the results of the case study. We show in detail how simulation models can be bolstered by specific industrial data to provide the highest possible benefit to simulation model users.", "num_citations": "10\n", "authors": ["1248"]}
{"title": "Run-time monitoring-based evaluation and communication integrity validation of software architectures\n", "abstract": " Architecture descriptions greatly contribute to the understanding, evaluation and evolution of software but despite this, up-to-date software architecture views are rarely available. Typically only initial descriptions of the static view are created but during the development and evolution process the software drifts away from its description. Methods and corresponding tool support for reconstructing and evaluating the current architecture views have been developed and proposed, but they usually address the reconstruction of static and dynamic views separately. Especially the dynamic views are usually bloated with low-level information (e.g., Object interactions) making the understanding and evaluation of the behavior very intricate. To overcome this, we presented ARAMIS, a general architecture for building tool-based approaches that support the architecture-centric evolution and evaluation of software systems with a\u00a0\u2026", "num_citations": "9\n", "authors": ["1248"]}
{"title": "Run-time monitoring and real-time visualization of software architectures\n", "abstract": " Software architecture stands at the backbone of any software system. An up-to-date description of the architecture greatly contributes to its understanding, evaluation and evolution. Despite its importance, the architecture is typically described only in the preliminary development phases and later becomes subject of continuous degradation. Therefore, methods and corresponding tool support for reconstructing the current views of a system's architecture have been developed and proposed. Current state of the art addresses the reconstruction of static and dynamic views separately. The reconstruction is typically conducted post-mortem using heavy weight infrastructures. We have conceptually defined and built a light-weight run-time monitoring infrastructure that produces meaningful real-time visualizations of object-level interactions. We consider that the possibility to observe the behavior of a system in real-time\u00a0\u2026", "num_citations": "9\n", "authors": ["1248"]}
{"title": "Processes and practices for quality scientific software projects\n", "abstract": " Nowadays modern software development processes are well established and are one of the mayor success factors for software projects. However, many software projects in scientific organisations have serious quality issues since they lack a feasable development process. In this paper we discuss a feature based development process for scientific software projects that addresses the specific characteristics of scientific software. Moreover, we introduce a set of best practices for the infrastructure and management of such projects.", "num_citations": "9\n", "authors": ["1248"]}
{"title": "Comparison of process quality characteristics based on change request data\n", "abstract": " The evaluation of metrics on data available in change request management (CRM) systems offers valuable information for the assessment of process quality characteristics. The definition of appropriate metrics that consider the underlying change request workflow and address the information needs of an organization is an intricate task.               Furthermore CRM systems usually provide only a number of predefined metrics with limited adaptability. The tool BugzillaMetrics offers a more flexible approach that simplifies defining and adjusting new metrics. However a systematic approach for deriving an appropriate metric in a target-oriented way is needed. This paper describes a corresponding procedure on how to develop and validate metrics on CRM data applicable for the comparison of process quality characteristics.", "num_citations": "9\n", "authors": ["1248"]}
{"title": "Vergleich von Ansatzen zur Feature Modellierung bei der Softwareproduktlinienentwicklung\n", "abstract": " Zusammenfassung Die Feature Modellierung ist ein oft verwendeter Ansatz, um Variabilit\u00e4ten und Gemeinsamkeiten der Produkte einer Produktlinie zu modellieren. Die einzelnen Ans\u00e4tze, die die Feature-Modellierung nutzen, unterscheiden sich jedoch h\u00e4ufig in der Zielsetzung und Vorgehensweise bei der Modellierung. In diesem Artikel wird versucht, die verschiedenen Ans\u00e4tze zur Feature-Modellierung einander gegen\u00fcberzustellen und ihre Gemeinsamkeiten und Unterschiede zu vergleichen und zu bewerten. Hierbei wird insbesondere betrachtet, welche Vorgehensweise gew\u00e4hlt werden muss und welche Eingaben vorliegen m\u00fcssen, damit die Ergebnisse der Feature-Modellierung in den nachgelagerten Entwicklungsschritten als Eingabe weiterverwendet werden k\u00f6nnen.", "num_citations": "9\n", "authors": ["1248"]}
{"title": "A UML variant for modeling system searchability\n", "abstract": " Internet search engines today are facing problems in keeping upw ith the pace of web growth. Two facts are responsible: bandwidth bottlenecks due to central indexing; deep web (or invisible web) contents that are inaccessible for search engines. Powerful and flexibly extensible object-oriented frameworks are available that assist in the implementation of distributed search infrastructures, thus addressing the first problem. In order to address the second problem, searchability has to be designed into the online applications constituting the deep web, and integrations to the distributed search infrastructures have to be implemented. A model-driven approach to software construction can be used to specify an application\u2019s searchability. This paper presents an extension to the UML that can be used to specify an application\u2019s searchability in an efficient way. The resulting models can be used to generate large\u00a0\u2026", "num_citations": "9\n", "authors": ["1248"]}
{"title": "A probabilistic enterprise architecture model evolution\n", "abstract": " Enterprise Architecture (EA) is a widely accepted means to ease the alignment of IS projects with enterprise-wide objectives. One central artifact of EA are EA models, which provide a holistic view on the organization and support EA's stakeholder to create added value. As EA collects its data from different sources, the data can be contradictory. This work contributes to existing research by proposing a novel approach to deal with contradictory data without solving the thereby caused conflicts. In order to achieve this objective, we refine the Predictive, Probabilistic Architecture Modeling Framework (P 2 AMF) introduced by Johnson et al., which already incorporates a way to represent uncertainty regarding the existence of modelled entities. To make our technique usable, we generalize P 2 AMF from its UML/OCL notation to a graph presentation in order to apply it to EA models notated in arbitrary notations like\u00a0\u2026", "num_citations": "8\n", "authors": ["1248"]}
{"title": "The aramis workbench for monitoring, analysis and visualization of architectures based on run-time interactions\n", "abstract": " Up-to-date software architecture models dramatically ease the understanding and meaningful evolution of a software system. Unfortunately they are rarely available. Mostly the static view of the architecture is modeled and only stipulations are made regarding how architecture units should communicate. However, a software system tends to evolve independently from its description. This results in violations of the previously stipulated communication rules. A plethora of tools to recover up-to-date architecture models have been proposed, but little emphasis has been put on analyzing and validating the run-time interactions on various abstraction levels defined in the static view of the architecture. In our previous work we have presented ARAMIS-a conceptual infrastructure for the analysis and monitoring of data extracted during run-time-and some first evaluations thereof. This paper presents the current state of the\u00a0\u2026", "num_citations": "8\n", "authors": ["1248"]}
{"title": "Evolution of object oriented coupling metrics: a sampling of 25 years of research\n", "abstract": " Coupling is one of the most important properties that affect the quality of the design and implementation of a software system. In the context of object oriented software development, coupling metrics and their impact on quality attributes have been investigated for a quarter of a century. In this work we review and critically analyze the developments in this domain by considering 26 of the most influential research papers addressing object oriented coupling. Our analysis reveals that a very strong theoretical background has been already developed but unfortunately without a clear impact on the industry practices and software analysis tooling. Even more, recent developments fail to address this problem and seem to even contribute to increasing this gap. We argue that the direction of current research should be shifted towards systematizing and evaluating existing results rather than exploring new applicability domains\u00a0\u2026", "num_citations": "8\n", "authors": ["1248"]}
{"title": "Towards a Technical Debt Management Framework based on Cost-Benefit Analysis\n", "abstract": " Technical debt (TD) is a metaphor of bad software design or immature artifacts of a software system. The metaphor has been quite intensively researched especially on how to identify the TD symptoms,(eg, system deficiencies or architecture violations) explicitly. Although the TD identification is quite important in the TD management process, a systematic management of TD and how to reduce it should also be considered important in each release of the development project. Otherwise, the software becomes more and more unmaintainable. In this paper, we introduce a framework to manage and reduce the TD of software systems. As it is based on quantification and a costbenefit analysis, it is called Cost-Benefit based Technical Debt Management (CoBeTDM). CoBeTDM defines explicit phases focusing on the most important aspects of TD management: identification, monitoring, and prioritization. Overall, CoBeTDM should support managers to take the right decisions regarding the software evolution and the reduction of the collected TD at the right time.", "num_citations": "8\n", "authors": ["1248"]}
{"title": "Towards a maintainable federalist enterprise measurement infrastructure\n", "abstract": " Large scale measurement systems are hard to build and to maintain. In this paper we propose an architecture blueprint for a federalist Enterprise Measurement Infrastructure (EMI) which helps to address these typical weaknesses of centralistic measurement systems. The EMI is based on the ideas of Service Oriented Measurements. We combined these with modern ideas from the area of Enterprise Application Integration and extended the ISO 15939 data flow to allow a more flexible and elegant solution. The current prototypes of EMI implementations and field studies prove the benefits of the architecture blueprint over existing solutions. We strongly belief that the EMI can help to build better, extendible, and maintainable measurement systems which are integrated and aligned with modern business needs.", "num_citations": "8\n", "authors": ["1248"]}
{"title": "Efficient adoption and assessment of multiple process improvement reference models\n", "abstract": " A variety of reference models such as CMMI, COBIT or ITIL support IT organizations to improve their processes. These process improvement reference models (IRMs) cover different domains such as IT development, IT Services or IT Governance but also share some similarities. As there are organizations that address multiple domains and need to coordinate their processes in their improvement we present MoSaIC, an approach to support organizations to efficiently adopt and conform to multiple IRMs. Our solution realizes a semantic integration of IRMs based on common meta-models. The resulting IRM integration model enables organizations to efficiently implement and asses multiple IRMs and to benefit from synergy effects.", "num_citations": "8\n", "authors": ["1248"]}
{"title": "Combinatorial robustness testing with negative test cases\n", "abstract": " Error-handling is an important means to improve the robustness of a system and testing error-handling is crucial to ensure its correctness. In this paper, we argue that error-handling leads to input masking which requires special treatment in for combinatorial testing. Therefore, we propose an extension to combinatorial testing including a robustness fault model and robustness combination strategy. We also provide an evaluation which compares its efficiency to normal combinatorial testing.", "num_citations": "7\n", "authors": ["1248"]}
{"title": "Changes in requirements engineering after migrating to the software as a service model\n", "abstract": " Service-oriented architectures are widely considered to be the determining trend in software engineering. Vendors of software products want to benefit by migrating to cloud environments. However, when transforming an existing software system from the Software as a Product model to the Software as a Service model the software engineering process changes. While the process in general has been researched sufficiently, very low effort has been put into understanding the impact on requirements elicitation. This paper investigates the necessary changes in the requirements engineering process and provides a systematic approach for a successful transformation. Furthermore, it discusses the new benefits in requirements elicitation that are inherent in a cloud environment. The paper then discusses the identified problems and developed solutions with regards to deduced guidelines and best practices. We conclude that the requirements engineering process profits from a systematic transformation when migrating a traditional software product to the Software as a Service model.", "num_citations": "7\n", "authors": ["1248"]}
{"title": "Systematic architectural decision management, a process-based approach\n", "abstract": " The documentation of architecture and design decisions lies at the backbone of building a comprehensive architectural knowledge basis within a company. As a consequence, a plethora of supporting frameworks has been lately proposed by the research community. The existing frameworks focus on capturing the rationale that lies behind a certain decision, but less on sustaining the collaborative process that architects employ when making decisions. In this paper, we propose an innovative architectural decision making process that sustains the collaboration of architects, the timely notification of involved stakeholders, the inclusion of feedback cycles to improve the overall quality of the architecting process and a tag-based traceability system that leverages informal learning. The analysis of the current state of the practice in the industry has been conducted within various workshops and interviews with our industry\u00a0\u2026", "num_citations": "7\n", "authors": ["1248"]}
{"title": "Smart integration of process improvement reference models based on an automated comparison approach\n", "abstract": " A variety of reference models such as CMMI, COBIT or ITIL supports IT organizations to improve their processes. Although these process improvement reference models (IRMs) cover different domains, they also share some similarities. There are organizations that address multiple domains under the guidance of different IRMs. As IRMs overlap in some processes and have inter-dependencies, we developed an approach to integrate multiple IRMs. This enables organizations to efficiently adopt and assess multiple IRMs by automatically identifying IRM similarities and their dependencies. In this paper, we give an overview of this approach and particularly focus on its evaluation.", "num_citations": "7\n", "authors": ["1248"]}
{"title": "Model-based software architecture evolution and evaluation\n", "abstract": " The architecture of software systems should be well documented and up to date. Knowledge about the software architecture of a software system enables reasoning regarding the software's qualities such as modifiability, extensibility, security, etc. However, very often the architecture is only described during the initial phases of a software project and then undergoes progressive degradation. A degenerated architecture description cannot be used for reasoning regarding the qualities of the software, even if it possibly conveys the required functionality. This paper proposes an approach for a continuous model-based monitoring and semi-automatic evaluation of software architectures, meant to support the architecture-based evolution of software systems at various abstraction levels.", "num_citations": "7\n", "authors": ["1248"]}
{"title": "A model based integration approach for reference models\n", "abstract": " A variety of reference models (RMs) such as CMMI, COBIT or ITIL support IT organizations to improve their processes. As these RMs cover different domains and also share some similarities, organizations may benefit from the adoption of multiple RMs. However, organizations need a systematic support to select and efficiently implement RMs. We present the MoSaIC approach for a semantic RM integration based on common meta-models to help organizations in understanding and adopting the considered RMs.", "num_citations": "7\n", "authors": ["1248"]}
{"title": "Einsatz und Nutzen von Use Cases-Ergebnisse einer empirischen Untersuchung\n", "abstract": " Abb. 1: Use Case Projekte der letzten f\u00fcnf Jahre92% der Teilnehmer gaben an, in diesem Zeitraum an mindestens einem solchen Projekt beteiligt gewesen zu sein. 59% der Teilnehmer waren an drei oder mehr Use Case Projekten beteiligt und 28% haben sogar Erfahrungen in sechs oder mehr dieser Projekte. Von allen Teilnehmern w\u00e4hlten 84% als Bezugsprojekt ein Use Case Projekt.", "num_citations": "7\n", "authors": ["1248"]}
{"title": "vis-A-vis: An Object-Oriented Aplication Framework for Graphical Design-Tools.\n", "abstract": " Many engineering disciplines use graphical notations with defined semantic meaning, such as Petri nets, or structure charts. The diagrams drawn in these notations represent semantic models upon which applicationspecific operations may be performed. To handle this type of notations and their semantic models comfortably, a graphical editor can support them. As there are many different graphical notations in every discipline, reuse of general editor functionality should be supported and encouraged to save tool building effort. vis-A-vis is an object-oriented framework serving this purpose. However, instead of laying the burden of properly composing those classes on the tool builders shoulders, vis-A-vis also contains a backbone architecture. In this paper we motivate the construction of vis-A-vis by listing the essential requirements that we had set out for a framework supporting in tool building. The scope of vis-A-vis based tools is defined, and a short survey of the main concepts of vis-A-vis is given. An example of a System Dynamics graphical notation editor which was built within vis-A-vis illustrates these concepts and shows how little effort a tool builder has to spend to implement an editor.", "num_citations": "7\n", "authors": ["1248"]}
{"title": "A Case Study on Robustness Fault Characteristics for Combinatorial Testing-Results and Challenges.\n", "abstract": " Combinatorial testing is a well-known black-box testing approach. Empirical studies suggest the effectiveness of combinatorial coverage criteria. So far, the research focuses on positive test scenarios. But, robustness is an important characteristic of software systems and testing negative scenarios is crucial. Combinatorial strategies are extended to generate invalid test inputs but the effectiveness of negative test scenarios is yet unclear. Therefore, we conduct a case study and analyze 434 failures reported as bugs of an financial enterprise application. As a result, 51 robustness failures are identified including failures triggered by invalid value combinations and failures triggered by interactions of valid and invalid values. Based on the findings, four challenges for combinatorial robustness testing are derived.", "num_citations": "6\n", "authors": ["1248"]}
{"title": "Behavior-based architecture reconstruction and conformance checking\n", "abstract": " The reconstruction of software architectures and the evaluation of architecture conformance of software systems is a long-studied research topic. Although up-to-date architecture descriptions are necessary to understand and evolve systems, they are rarely available. Consequently, many software architecture reconstruction approaches and tools have been proposed. Despite this, software architects still do not extensively employ these tools and suffer from negative effects when relying only on outdated descriptions. In this paper we present ARAMIS, an approach and associated toolbox that aims to support the behavior-based reconstruction of up-to-date architecture descriptions based on the correction of possibly outdated prescriptive ones. Additionally, ARAMIS addresses the so-called meta-model incompatibility problem by allowing architects to use their own architecture description language instead of the one\u00a0\u2026", "num_citations": "6\n", "authors": ["1248"]}
{"title": "Rapid prototyping in der use-case-zentrierten Anforderungsanalyse\n", "abstract": " Die Anforderungsanalyse ist einer der zentralen Erfolgsfaktoren bei der Durchf\u00fchrung von Softwareentwicklungsprojekten. Zur Analyse der Anforderungen an interaktive Informationssysteme hat sich in den letzten Jahrzehnten die Use-Case-zentrierte Analyse etabliert. Hierbei bildet ein Use-Case-Modell das zentrale Artefakt des gesamten Anforderungsentwicklungsprozesses. Alle anderen Anforderungsartefakte werden mit diesem Use-Case-Modell verbunden. Verschiedene Studien zeigen, dass Prototyping deutlich zur Verbesserung der Ergebnisse von Anforderungsanalysen beitragen kann. Die fr\u00fche Verf\u00fcgbarkeit eines ausf\u00fchrbaren Modells des Zielsystems vereinfacht die Kommunikation aller Projektbeteiligten und die Validierung von Anforderungen. Au\u00dferdem verbessert Prototyping die Gebrauchsqualit\u00e4ten der Software und reduziert Akzeptanzprobleme. Dennoch werden die Potentiale von\u00a0\u2026", "num_citations": "6\n", "authors": ["1248"]}
{"title": "Automated comparison of process improvement reference models based on similarity metrics\n", "abstract": " A variety of reference models such as CMMI, COBIT or ITIL supports IT organizations to improve their processes. Although these process improvement reference models (IRM) cover different domains they also share some similarities. There are organizations that address multiple domains and want to take the guidance of different IRMs. As IRMs overlap in some processes, we present an approach to compare parts of IRMs (the IRMs' procedures) that is based on a common IRM integration model and on similarity metrics. Our approach enables organizations to efficiently adopt and assess multiple IRMs by automatically identifying similarities and specific details of the different IRMs.", "num_citations": "6\n", "authors": ["1248"]}
{"title": "Software Processes in an Agile World\n", "abstract": " In this paper we relate classical software process models to new agile development processes and software process improvement. We argue that there is no single process model that always fits and that organizations have to re-use the best out of classical and agile processes. Furthermore we question \u201cclassical\u201d software process improvement because it is often done isolated from people and technology issues. Finally, we present ten propositions about software process models and software process improvement.", "num_citations": "6\n", "authors": ["1248"]}
{"title": "Towards an enterprise architecture model evolution\n", "abstract": " One central aim of Enterprise Architecture (EA) is to keep the EA model up-to-date to provide recent information to its stakeholders. Based on EA information, projects develop their results, called solutions, which possibly affect the EA model. As the interaction between projects and EA is not always coordinated, wrong decisions can be taken and, consequently, solutions can be developed that do not conform to the EA. Therefore, we propose an enterprise architecture roundtrip process that guides the coordinated and project-driven distributed evolution of an EA model.", "num_citations": "5\n", "authors": ["1248"]}
{"title": "Staged evolution with quality gates for model libraries\n", "abstract": " Model evolution is widely considered as a subject under research. Despite its role in research, common purpose concepts, approaches, solutions, and methodologies are missing. Limiting the scope to model libraries makes model evolution and related quality concerns manageable, as we show below. In this paper, we put forward our quality staged model evolution theory for model libraries. It is founded on evolution graphs, which offer a structure for model evolution in model libraries through evolution steps. These evolution steps eventually form a sequence, which can be partitioned into stages by quality gates. Each quality gate is defined by a lightweight quality model and respective characteristics fostering reusability.", "num_citations": "5\n", "authors": ["1248"]}
{"title": "History and Lessons Learnt from a Metrics Program at a CMMI Level 3 Company\n", "abstract": " Metrics and especially metric-based monitoring dashboards provide valuable information and insights for managers in software development organizations. However, implementing and launching a company wide metrics program is very hard and time consuming. This paper describes the history and our experience with the development of a metrics program at Generali Deutschland Informatik Services, a CMMI level 3 certified company. We also provide important lessons learned alongside a list of consolidated best practices for the implementation and maintenance of a large metrics and dashboard program. We believe that both are useful for every practitioner and researcher in this field and help to build better and more sustainable metrics and dashboard development processes and infrastructures.", "num_citations": "5\n", "authors": ["1248"]}
{"title": "Metric based comparison of reference models based on similarity\n", "abstract": " A variety of reference models such as CMMI, CobiT or ITIL support IT organizations to improve their processes. Although these reference models (RM) cover different domains they also share some similarities. There are organizations that address multiple domains and want to use different RMs. As RMs may overlap in some processes, we present an approach to compare RMs\u2019 procedures which is based on a common RM integration model and on similarity metrics. Our approach enables organizations to better understand RMs by identifying commonalities and specific details of the different RMs in order to avoid redundant improvement measures.", "num_citations": "5\n", "authors": ["1248"]}
{"title": "MeDUSA-MethoD for Uml2-based Design of Embedded Software Applications\n", "abstract": " MeDUSA (Method for UML2-based Design of Embedded Software Applications) is a model-driven software design method targeting the domain of small embedded systems, especially field devices.Being Use Case-driven, MeDUSA systematically covers the software development lifecycle from the early requirements up to the late detailed design modelling. Models are successivly developed and employed throughout all activities. By enforcing an object-based rather than an object-oriented design, a smooth transition of the resulting detailed design model towards an implementation in a procedural programming language is facilitated. This is essential, as procedural programming languages as the C language are still state-of-the-art in the regarded domain. By leading to a component-based architectural design, MeDUSA explicitly addresses the reuse of components, something that is the prerequisite for the application of the method in a product-line setting. This has gained significant importance to the industrial practice in the last years.", "num_citations": "5\n", "authors": ["1248"]}
{"title": "Erfahrungen bei der systematischen Entwicklung kleiner eingebetteter Systeme mit der COMET-Methode\n", "abstract": " Der Einsatz objektorientierter Entwicklungsmethoden im Bereich eingebetteter Systeme ist zwar seit einigen Jahren Gegenstand intensiver Forschung ([SGW94][SR98][Do01])\u2013man betrachte nur die Anstrengungen, die die OMG in diesem Zusammenhang bei der Verabschiedung ihres UML-2.0 Standards unternimmt\u2013nach wie vor liegen aber nur wenige Erfahrungen \u00fcber deren Einsatz aus der industriellen Praxis vor.In diesem Beitrag pr\u00e4sentieren und diskutieren wir Erfahrungen, die wir bei der Entwicklung kleiner eingebetteter Echtzeitsysteme im ABB-Konzern mit der objektorientierten Entwicklungsmethode COMET [Go00] gewonnen haben. Die Entwicklung solcher eingebetteter Systeme wird massiv durch Ressourcenbeschr\u00e4nkungen bez\u00fcglich Speicherplatz (\u00fcblicherweise haben solche Systeme zwischen 0, 5-64 KByte RAM und 32-256 KByte ROM), Stromverbrauch und Rechenzeit beeinflusst, die sich durch die speziellen Einsatzgebiete im industriellen Umfeld ergeben.", "num_citations": "5\n", "authors": ["1248"]}
{"title": "Erfahrungen mit einem Workshop-Seminar im Software-Engineering-Unterricht.\n", "abstract": " Seminare sind eine bew\u00e4hrte Lehrform in allen Studieng\u00e4ngen. Um die Mitarbeit und den Lerneffekt der Studierenden in Seminaren zu Themen des Software Engineering zu erh\u00f6hen, f\u00fchrte das Lehr-und Forschungsgebiet Softwarekonstruktion der RWTH Aachen zusammen mit dem Softwarehaus sd&m K\u00f6ln ein Workshop-Seminar durch. Die Lehrveranstaltung gliederte sich in zwei Teile: Im ersten Teil bearbeiteten die Studierenden ein inhaltliches Thema. Der zweite Teil war ein zweit\u00e4giger Workshop, bei dem die Studierenden in Gruppen realit\u00e4tsnahe Problemstellungen bearbeiten und pr\u00e4sentieren mussten. Die mit dieser Lehrform erzielten Ergebnisse waren durchweg positiv.", "num_citations": "5\n", "authors": ["1248"]}
{"title": "Repairing over-constrained models for combinatorial robustness testing\n", "abstract": " Testing negative scenarios is important to evaluate robustness of software systems. Error-handling can terminate the system before all values are evaluated and faults can remain undetected. Therefore, extensions for combinatorial testing separate generation of positive and negative scenarios. Unfortunately, it is easy to create over-constrained models. Certain values or value combinations are prevented from appearing in the test suite and remain untested. In this paper, we define over-constrained models and present a technique to identify and repair them.", "num_citations": "4\n", "authors": ["1248"]}
{"title": "Towards Data-driven Continuous Compliance Testing.\n", "abstract": " Recent studies show that security vulnerabilities are caused by neglecting best-practices for the configuration of software and the underlying infrastructure. Due to the rising complexity of software systems and the accelerated speed of software releases using mechanisms like continuous delivery the problem gets even more challenging. Existing processes and methods are not adequate to cope with these challenges. This paper proposes an approach for continuous compliance testing. Using well-known methods from software testing, this approach enables an organization to define, organize, and execute compliance tests in a structured and reusable way. We focus in our approach onto integrating a software-centric point of view for modeling compliance requirements. By embedding our approach into a deployment pipeline automated continuous compliance testing can be realized.", "num_citations": "4\n", "authors": ["1248"]}
{"title": "Continuous integration processes for modern client-side web applications\n", "abstract": " Continuous Integration (CI) is very useful for applications that involve many files and multiple developers. Unfortunately, not all types of applications can easily apply this approach. Apparently, CI does not gain a lot of attention with Modern Client-Side Web Application (MCSWA) because it requires complicated testing, i.e. the running environments are browsers. There is no compiler or error warning when a developer writes bad code and the build behavior in the usual CI practice is different from the build process in MCSWA. If the integration process is done manually by an integration expert, unexpected errors are found not only while integrating but also when performing manual tests to verify it. Moreover, it is problematic and elaborate if a developer needs to test the features by clicking around with repeated user-interaction in different browsers; especially, he might create human errors or miss some steps. This\u00a0\u2026", "num_citations": "4\n", "authors": ["1248"]}
{"title": "Optimizing enterprise architectures using linear integer programming techniques\n", "abstract": " Within this paper, we present a technique to optimize the relations between two adjacent layers of Enterprise Architectures (EA). Therefore, we suggest to interpret the constraints between these two layers as triangles, where a needed capability of an upper layer element is realized by a lower layer element. This eases the communication of the optimization model e.g. to the management. Moreover, we propose a mapping between the elements of our technique to the widely accepted ArchiMate notation to enable the application of our technique in existing organizations.", "num_citations": "4\n", "authors": ["1248"]}
{"title": "Staged model evolution and proactive quality guidance for model libraries\n", "abstract": " A variety of modeling approaches, including model-driven development, consider model reuse as one of their cornerstones, but lack support for model reuse. This may be due to the available model repositories that barely exceed support for enhanced versioning or collaborative work and disregard model evolution. We believe that current model evolution approaches do not consider reuse sufficiently and that model repositories for reuse purposes should act as model libraries. This requires new functionality, because models for reuse  need to achieve and maintain high quality. Moreover, quality assessment and assurance, which are tasks often considered tedious, need to be as simple as putting away or maintaining artifacts for reuse. In this study, we propose an approach for model evolution in UML model libraries that differs from general model evolution, since it is aimless and triggered by new external\u00a0\u2026", "num_citations": "4\n", "authors": ["1248"]}
{"title": "Proactive quality guidance for model evolution in model libraries\n", "abstract": " Model evolution in model libraries differs from general model evolution. It limits the scope to the manageable and allows to develop clear concepts, approaches, solutions, and methodologies. Looking at model quality in evolving model libraries, we focus on quality concerns related to reusability. In this paper, we put forward our proactive quality guidance approach for model evolution in model libraries. It uses an editing-time assessment linked to a lightweight quality model, corresponding metrics, and simplified reviews. All of which help to guide model evolution by means of quality gates fostering model reusability.", "num_citations": "4\n", "authors": ["1248"]}
{"title": "A Model-based Narrative use Case Simulation Environment.\n", "abstract": " Since their introduction use cases are one of the most widespread used techniques to specify functional requirements. Because low quality use cases often cause serious problems in later phases of the development process the simulation of use cases may be an important technique to assure the quality of use case descriptions. In this paper we present a model based use case simulation environment for narrative use cases. At first we motivate core requirements of a simulation environment and an underlying execution model. Moreover we describe our model based simulation approach and present some first experiences.", "num_citations": "4\n", "authors": ["1248"]}
{"title": "Evaluating Process Quality based on Change Request Data\u2013An Empirical Study of the Eclipse Project\n", "abstract": " The information routinely collected in change request management systems contains valuable information for monitoring of the process quality. However this data is currently utilized in a very limited way. This paper presents an empirical study of the process quality in the product portfolio of the Eclipse project. It is based on a systematic approach for the evaluation of process quality characteristics using change request data. Results of the study offer insights into the development process of Eclipse. Moreover the study allows assessing applicability and limitations of the proposed approach for the evaluation of process quality.", "num_citations": "4\n", "authors": ["1248"]}
{"title": "UML2-basierte Architekturmodellierung kleiner eingebetteter Systeme Erfahrungen einer Feldstudie.\n", "abstract": " Um die neuen Modellierungsm\u00f6glichkeiten zu erproben, wurde im Rahmen einer Kooperation zwischen dem ABB Forschungszentrum Ladenburg und dem Lehr-und Forschungsgebiet Software-Konstruktion der RWTH Aachen eine Studie durchgef\u00fchrt, mit dem Ziel, die Software-Architekturen kleiner eingebetteter Systeme mit Hilfe der UML2 zu modellieren. Dabei konzentrierten wir uns in erster Linie auf die neu eingef\u00fchrten Kompositionsstrukturdiagramme, die wir exemplarisch an der Modellierung der Software-Architektur von Feldger\u00e4ten erprobten. Die dabei erzielten Ergebnisse pr\u00e4sentieren und bewerten wir in diesem Beitrag. Zuvor werden wir jedoch kurz auf die Besonderheiten der in unserer Studie betrachteten Systeme eingehen, damit unsere Modellierungsentscheidungen und das in diesem Beitrag durchgehend verwendete Beispiel besser nachvollzogen werden k\u00f6nnen.", "num_citations": "4\n", "authors": ["1248"]}
{"title": "Modellierung von variabilit\u00e4t mit uml use cases\n", "abstract": " Die Entwicklung einer Software-Produktlinie stellt hohe Anspr\u00fcche an den gesamten Softwareprozess, insbesondere auch an das Requirements Engineering. Clements und Northrop definieren eine Produktlinie1 wie folgt [Cle01]:\u201cA software product line is a set of software-intensive systems sharing a common, managed set of features that satisfy the specific needs of a particular market segment or mission\u201d. Eine Produktlinie besteht demnach aus einer Menge von Produkten, die auf Basis einer Plattform entwickelt werden, die die gemeinsamen Eigenschaften aller Produkte realisiert. Die einzelnen Produkte unterscheiden sich bei einer Reihe von Eigenschaften, dadurch dass diese gar nicht oder unterschiedlich ausgepr\u00e4gt sind. Die Identifikation und Modellierung von gemeinsamen und variablen Eigenschaften ist eine essentielle Aufgabe, weil diese kommuniziert und abgestimmt werden m\u00fcssen und die Entwicklung einer Produktlinie ma\u00dfgeblich beeinflussen.", "num_citations": "4\n", "authors": ["1248"]}
{"title": "Towards the identification of process anti-patterns in enterprise architecture models\n", "abstract": " IT processes constitute the backbone of an integrated enterprise architecture (EA). The model thereof sustains the development and management of the EA. Nevertheless, the quality of such models tends to degrade over time due to, eg improper modeling practices or ineffective evaluation. In this regard, the knowledge of relevant modeling anti-patterns can help identify, mitigate, and prevent the occurrence of sub-optimal or adverse constructs in the model. In the field of business process modeling (BPM), a plethora of BPM anti-patterns has been defined and compiled in various taxonomies. However, these BPM anti-patterns mostly focus on technical issues, which thus are applicable for evaluating workflows but not EA-level processes. We strongly argue that the concept of process anti-pattern in EA domain can facilitate EA analyses on process-related issues. To address this gap, this paper presents a catalogue of 18 EA process modeling anti-patterns, which we derived from the existing BPM anti-patterns. Our result should serve as food for thought and motivation for future research in this context.", "num_citations": "3\n", "authors": ["1248"]}
{"title": "Behavior-based architecture conformance checking\n", "abstract": " Architekturkonformit\u00e4ts\u00fcberpr\u00fcfung ist wichtig, um die unvermeidliche Abweichung zwischen der vorgesehenen Architekturbeschreibung und der eigentlich implementierten Architektur eines Softwaresystems zu kontrollieren. In den letzten Jahren wurden einige Ans\u00e4tze f\u00fcr eine statischbasierte Architekturkonformit\u00e4ts\u00fcberpr\u00fcfung vorgeschlagen. Diese haben jedoch erhebliche Nachteile, insbesondere dann, wenn damit moderne, technologisch heterogene und verteilte Systeme analysiert werden sollen. Eine Pr\u00fcfung der Architekturkonformit\u00e4t solcher Systeme kann h\u00e4ufig nicht mit statisch-basierten Verfahren durchgef\u00fchrt werden, da diese nicht immer feststellen k\u00f6nnen, ob sich ein System so verh\u00e4lt, wie dies vorgesehen ist. In dieser Arbeit stellen wir ARAMIS vor, einen verhaltensbasierten Ansatz zur Pr\u00fcfung der Architekturkonformit\u00e4t, der dieses Problem l\u00f6st.", "num_citations": "3\n", "authors": ["1248"]}
{"title": "Distributed enterprise architecture evolution\u2013a roundtrip approach\n", "abstract": " One central aim of EAM is to keep the EA up-to-date to provide recent information and models to EAM\u2019s clients. Based on EA information projects develop their results, called solutions, which possibly affect the EA. As the interaction between projects and EAM is not always coordinated systematically, wrong decisions can be taken and, consequently, solution variants are developed that do not conform to the EA. Therefore, we aim to develop in a stepwise manner a tool supported enterprise architecture roundtrip approach that guides the coordinated and project-driven distributed evolution of an EA. Our approach is based on change sets provided by the projects that are integrated into the EA to keep it up-to-date.", "num_citations": "3\n", "authors": ["1248"]}
{"title": "Adapting heterogeneous ADLs for software architecture reconstruction tools\n", "abstract": " Architecture reconstruction tools were proposed to enable the extraction of descriptive architecture models based on prescriptive input models. A limitation of these tools is that they employ specific meta-models to which the input prescriptive models must adhere. These are often incompatible with the languages or notations that architects use in practice, leading to substantial effort to overcome terminology differences, to transform possibly already existing prescriptive models in toolcompatible ones and interpreting the results. To alleviate this problem we propose to leverage model engineering techniques in order to enable heterogeneous prescriptive and descriptive models as input and output artifacts of reconstruction tools. We exemplify our proposal by extending the Architecture Analysis and Monitoring Infrastructure (ARAMIS)-an approach developed within our previous work for the reconstruction and evolution of software architectures with a strong focus on the behavior view.", "num_citations": "3\n", "authors": ["1248"]}
{"title": "On the influence of release engineering on software reputation\n", "abstract": " A successful release engineering should allow for a fast and controlled release process. Consequently, shipping features earlier than competitors or avert damages more quickly might be beneficial for a software\u2019s reputation.In this paper, we investigated the influence of release engineering on the user\u2019s perception of software. To this end, we analyzed the release engineering practices and market shares of web browsers. We found indications that a reasonable application of release engineering is beneficial for the software\u2019s reputation. However, flaws in the implementation, as well as an inadequate communication of introduced changes, effects the reputation negatively.", "num_citations": "3\n", "authors": ["1248"]}
{"title": "Design and evaluation of a CMMI conformant light-weight project management approach\n", "abstract": " CMMI is one of the well-known and accepted maturity models that many software organizations have implemented for its quality processes which are expected to bring a good quality for their software products. However, traditional software process models become too heavy-weight to be deployed. The aim of this paper is to design an Light-Weight Project Management (LWPM) approach to implement the CMMI by mapping between CMMI goals and Agile-Scrum based on defined artifacts and to indicate the differences in applying LWPM and the traditional Waterfall model. The approach focuses on the Project Management category which composes Project Planning, Project Monitoring and Control and Integrated Project Management. In order to compare both models, the authors collected relevant data by using questionnaire and Software Process Improvement Adaptive Learning System.", "num_citations": "3\n", "authors": ["1248"]}
{"title": "Towards a Systematic Metric Based Approach to Evaluate SCAMPI Appraisals\n", "abstract": " CMMI SCAMPI based appraisals are used worldwide to assess the process quality of organizations. In this paper we introduce a metric-based approach to assess and improve CMMI SCAMPI appraisals. To have a sound basis we at first present an appraisal meta model which defines all types of appraisal elements and their relationships. This meta model can be instantiated to get a concrete SCAMPI appraisal process, offering a precise roadmap for conducting appraisals. Based on the meta model two appraisal quality metrics are defined to systematically assess appraisal activities as well as phases and to support the improvement of appraisals. We describe the definition of these metrics in detail and give some metric interpretation guidelines.", "num_citations": "3\n", "authors": ["1248"]}
{"title": "Medusa-a model-based construction method for embedded and real-time software\n", "abstract": " While engineering of embedded & real-time systems has moved much into the focus of the research community, being strongly promoted by those prominent application areas as the automotive, aerospace & defense, or telecommunications industry, small embedded & real-time systems, as they can be found in somehow marginal application areas as the industrial automation, are still treated a bit stepmotherly. In particular, profound methodical support for the software development of such small devices is almost unavailable. With MeDUSA we especially target the domain of such small embedded & real-time systems, and explicitly address the very special technological, economical, and organizational constraints that have to be faced in such marginal application areas.", "num_citations": "3\n", "authors": ["1248"]}
{"title": "Improving software quality by static program analysis\n", "abstract": " This paper presents the results and conclusions obtained during a process improvement project of ABB Energy Information Systems, Germany. This project was executed in the context of ABB Energy Information Systems software process improvement activities. It was launched in order to collect experience in the usage of systematic static program analysis. We first give a brief overview on software development at ABB Energy Information Systems. Then we list the objectives of the project. After having given a short overview on the technique of static program analysis, we present in the main part of the paper our experience and conclusions. We do this by formulating and discussing nine major theses. \u00a9 1997 John Wiley & Sons Ltd", "num_citations": "3\n", "authors": ["1248"]}
{"title": "Assessing industrial prototyping projects\n", "abstract": " This paper presents the results of case studies of industrial software projects in which explicit use was made of prototyping. Our major concern was to analyze the experience gained in the projects with the use of prototyping, and in particular to juxtapose these findings and the claims made for prototyping. On the basis of this analysis, we have attempted to set out what we consider to be the benefits, but also the limitations of prototyping.", "num_citations": "3\n", "authors": ["1248"]}
{"title": "A lightweight collaborative approach for teaching software project labs with industry partners.\n", "abstract": " Software project labs are an important part of computer science education. In 2014, we started to run labs together with industry partners to implement further learning objectives. In this article, we present these learning objectives and our organizational approach to realize a joint lightweight teaching with an industry partner. Furthermore, we report on our experiences with this approach, including the students\u2019 point of view. Finally, we discuss what we adapted to conduct our software project lab online during the Covid-19 pandemic.", "num_citations": "2\n", "authors": ["1248"]}
{"title": "A Framework for Managing Enterprise Architecture Debts-Outline and Research Directions.\n", "abstract": " Even though enterprise architecture management (EAM) offers a wide range of methods and tools for aligning business with IT, an architect\u2019s work is challenged by reality. The evolution of enterprise architecture (EA) and given constraints (eg legacy systems and processes) lead to debts which may complicate and hinder opportunities; however, the management of such debts has not been considered in EAM research. This paper presents a framework for strategically managing EA-debt-related issues and propose open questions as well as future research directions in this field.", "num_citations": "2\n", "authors": ["1248"]}
{"title": "An experiment to compare combinatorial testing in the presence of invalid values\n", "abstract": " Robustness is an important property of software that should be thoroughly tested. Combinatorial testing (CT) is an effective black-box test approach. When using it for robustness testing, input masking can prevent faults from being detected. However, the impact is not yet clear. Therefore, we conducted a controlled experiment to understand how input masking affects the fault detection effectiveness of CT and how effective CT is in the presence of error-handling and invalid values.", "num_citations": "2\n", "authors": ["1248"]}
{"title": "Semi-automatic repair of over-constrained models for combinatorial robustness testing\n", "abstract": " Combinatorial robustness testing is an approach to generate separate test inputs for positive and negative test scenarios. The test model is enriched with semantic information to distinguish valid from invalid values and value combinations. Unfortunately, it is easy to create over-constrained models and invalid values or invalid value combinations do not appear in the final test suite. In this paper, we extend previous work on manual repair and develop a technique to semi-automatically repair over-constrained models. The technique is evaluated with benchmark models and the results indicate a small computational overhead.", "num_citations": "2\n", "authors": ["1248"]}
{"title": "Prioritization of EA Debts Facilitating Portfolio Theory\n", "abstract": " Implementing an enterprise architecture (EA) project might not always be a success due to uncertainty and unavailability of resources. Hitherto, we have proposed a new metaphor\u2013Enterprise Architecture Debt (EAD)\u2013, which makes bad habits within EAs explicit. We anticipate that the accumulation of EAD will negatively influence EA quality, also expose the business into risk.Recognizing the importance of business-IT alignment in enterprise architecture context, this paper proposes an application of portfolio-based thinking and utility theory for EAD prioritization. For proof-of-concept purpose, we develop synthetic data using coarse-grained estimates to demonstrate the application of the proposed portfolio-based approach which helps to determine the optimum selection of EAD to be resolved. The results show that our approach can help EA practitioners and management to reason their EA investment decisions based on the EAD concept, with adjustable enterprises risk tolerance level.", "num_citations": "2\n", "authors": ["1248"]}
{"title": "Developing a Semantic Mapping between TOGAF and BSI-IT-Grundschutz\n", "abstract": " Enterprise Architecture Frameworks (EAFs) are being employed vastly within various organizations in recent years. Moreover, due to the high prevalence of information technology in the enterprises, Information Security (IS) was incorporated into the EAFs. Therefore, it gradually became important for the EAFs to conform to the IS standards such as the ISO and the BSI series. In this paper, we present a mapping of such an EAF, called The Open Group Architecture Framework (TOGAF), to an IS standard, BSI-IT-Grundschutz. Following this, we explain how a real-world Enterprise Architecture (EA) model (developed using TOGAF) of a renowned German company was mapped to BSI-IT-Grundschutz. This not only allows the various IS safeguards defined within BSI-IT-Grundschutz to be adapted to TOGAF and the EA model but more importantly, it allows the reuse of identified components of the TOGAF and the EA model, while mapping it to BSI-IT-Grundschutz using an automated tool in future.", "num_citations": "2\n", "authors": ["1248"]}
{"title": "Static and Dynamic Architecture Conformance Checking: A Systematic, Case Study-Based Analysis on Tradeoffs and Synergies.\n", "abstract": " In order to uncover architectural drift, a plethora of architecture conformance checking tools has been proposed that mainly leverage two approaches: they extract architectural knowledge based on either source code artifacts (static approach) or run-time behavior (dynamic approach). Although both approaches have been evaluated separately, no up-to-date analysis of their relative strengths and weaknesses, nor realworld comparative case studies of the two were published. In this paper we address this issue by presenting the results of a direct comparison of both approaches. We first identify and compare their strengths and weaknesses on a theoretical level. We then evaluate these results against our experiences gained in a large-scale industrial case study. As a result, we argue that the approaches cannot substitute each other as they differ in many key aspects. Hence, we crystallize guidelines regarding how to combine these such that their strengths are emphasized while weaknesses mitigated.", "num_citations": "2\n", "authors": ["1248"]}
{"title": "Model-based evaluation and simulation of software architecture evolution\n", "abstract": " The software architecture description is often the reasoning basis for important design decisions. Nevertheless, during the evolution of a system, the software architecture tends to deviate from its description which gradually approaches obsolescence. Software architecture reconstruction tools can be employed to retrieve up-to-date descriptions, however reconstruction by itself is never a purpose. The reconstructed architecture description should, eg, support the architects to identify the best evolution variant with respect to a set of quality characteristics of interest. The state of the art approaches address reconstruction and evolution simulation in separation. To simulate changes, the current state of the system must be first manually modeled. In our previous work, we presented ARAMIS, an approach to support the reconstruction and evaluation of software architecture with a strong emphasis on software behavior. In this paper, we propose the extension of our approach for enabling the simulation of design decisions on the recovered architecture description. To reduce complexity and support a more focused analysis, we allow to specify and apply viewpoints, views, and perspectives on the recovered description and its evolution simulations.", "num_citations": "2\n", "authors": ["1248"]}
{"title": "Towards an Architecture Quality Index for the Behavior of Software Systems\n", "abstract": " Software architecture lies at the backbone of any software system and its choice directly influences important non-functional characteristics such as maintainability, extensibility, etc. Up-to-date software architecture descriptions should be at any time available to support the analysis and evaluation of the current state of the architecture. However the current state of the art lacks both methodologies and tools for ensuring availability of architecture descriptions and fails to offer objective means for evaluating software architectures. Currently, no generally accepted method for comparing software from an architecture point of view exists. In this paper, we present our current results towards creating a so-called architecture quality index that includes a bidirectional architecture quality model as well as a quality benchmark created for the context of the ARAMIS research project. The proposed architecture quality index aims to\u00a0\u2026", "num_citations": "2\n", "authors": ["1248"]}
{"title": "Towards Systematic Reuse of Metric Specifications\n", "abstract": " This paper presents a novel approach for reusing metrics. Contrasting a lot of work related to this issue, the authors are focusing on reusing metric specifications. By introducing reusability concepts such as genericity and variation points to metric specification, they enable the creation of reusable ones. On the other hand, this allows deriving project specific concrete metrics based on reusable metric specifications. Early experience from the industry cooperation is promising and indicates less stress and effort for the metric users.", "num_citations": "2\n", "authors": ["1248"]}
{"title": "Metrik-basierte Auswertung von Software-Entwicklungsarchiven zur Prozessbewertung\n", "abstract": " Softwareentwicklung als Expedition ist eine gebr\u00e4uchliche Metapher. Dieses Bildnis l\u00e4sst sich auch auf eine Forschungsarbeit \u00fcbertragen. Genauso wie eine Expedition verfolgt eine Forschungsarbeit ein Ziel. Sie verl\u00e4uft in verschiedenen Etappen, und gelegentlich ist es notwendig bei Problemen zu verweilen. Die Reiseroute l\u00e4sst sich nicht vollst\u00e4ndig planen, da ein neues Territorium betreten wird. Die Planung muss an die vor Ort anzutreffenden Verh\u00e4ltnisse angepasst werden. An dieser Stelle m\u00f6chte ich allen danken, die zum Gelingen dieser Expedition beigetragen haben.", "num_citations": "2\n", "authors": ["1248"]}
{"title": "Process assessment by evaluating configuration and change request management systems\n", "abstract": " This paper presents an approach for assessing process qualities based on evaluating metrics on change request and configuration management systems. It is based on user-defined quality models to enable quality evaluations customized to the information needs of an organization. Further on the concept of declarative metric specifications is introduced, which enables a precise definition of metrics on an appropriate abstraction level. With the corresponding tool support given in the QMetric tool suite, this concept simplifies development and validation of the metrics needed for quality evaluations.", "num_citations": "2\n", "authors": ["1248"]}
{"title": "Model Based Construction of Embedded & Real-time Software: A Methodology for Small Devices\n", "abstract": " While model-based software engineering-due to its increased abstraction and its advantages in terms of traceability and analyzability-seems to be the adequate means to deal with the increased complexity of software that one faces today, it does not seem to have penetrated all domains yet, in particular not the one of small embedded & realtime systems. Seeing this problem caused by the fact that current model-based approaches do not pay sufficient attention to the rather special technical, organizational, and economical constraints in the respective domain, this work presents an approach that explicitly takes these constraints into account.MeDUSA, a model-based software construction method for small embedded & realtime systems, is a principal item of the presented solution. To face the strong technical constraints it was especially designed as an instance-driven method, not incorporating any object-oriented concepts, but forcing a class-based design that can be seamlessly transferred into a procedural implementation, which is still state-of-the-art in the regarded domain. To guarantee such a seamless transition MeDUSA was furthermore designed to be a software construction rather than a mere design method, explicitly also addressing the implementation activities, and especially the transition from detailed design into source code. Being organized around the use case concept, the method excels at being very systematic and-inter alia by facilitating a continuous real-time analysis-also at being especially aware about the stringent real-time constraints that have to be faced in the domain of embedded & real-time systems.", "num_citations": "2\n", "authors": ["1248"]}
{"title": "Software process improvement at ABB-common issues and lessons learnt\n", "abstract": " The growing importance of software for products as well as processes has been recognised in several ABB companies. As a result they started initiatives to improve their software development. Unlike other improvement programmes in industry, ABB\u2018s software process improvement initiatives are not part of company-wide, globally controlled programme. They rather evolved locally in different ABB companies, coached and co-ordinated by ABB Corporate Research.This paper summarises the experiences gained in the various process improvement activities. Firstly it describes how ABB\u2018s software process improvement initiatives relate to similar ones in other companies, and how the foci of the improvement measures evolved over time. Secondly, we present the current status of the improvement initiatives, pointing out the role of ESSI funded process improvement experiments in this context. In the main part we\u00a0\u2026", "num_citations": "2\n", "authors": ["1248"]}
{"title": "A case study on software project management in industry\u2013experiences and conclusions\n", "abstract": " In this paper we present and discuss the findings of two case studies on software project management in industrial software development projects and the conclusions drawn from it. These studies were motivated to improve software project management capabilities. First, we describe how these studies were organized and performed. In the main part we present our findings and conclusions showing that there are strong deficits in project management quality. Based on these findings we briefly describe the structure of an improvement program aiming to remove or reduce those deficits.", "num_citations": "2\n", "authors": ["1248"]}
{"title": "vis-A-vis: Ein objekt-orientiertes Application Framework f\u00fcr grafische Entwurfswerkzeuge\n", "abstract": " Viele Ingenieurwissenschaften verwenden graphische Notationen mit wohldefinierter Semantik, wie Petri-Netze oder Blockschaltbilder. Diagramme, die mit Hilfe dieser Notationen erstellt werden, repr\u00e4sentieren semantische Modelle, auf denen anwendungsspezifische Operationen ausgef\u00fchrt werden k\u00f6nnen. Um diese Art von Notationen und ihre semantischen Modelle komfortabel handhaben zu k\u00f6nnen, empfiehlt es sich, sie durch einen grafischen Editor zu unterst\u00fctzen. Dabei sollte allgemeine Editor-Funktionalit\u00e4t nicht f\u00fcr jede einzelne Notation neu implementiert, sondern wiederverwendet werden, um Editoren mit geringem Aufwand erstellen zu k\u00f6nnen.               vis-A-vis ist ein objekt-orientiertes Application Framework, das diesem Zweck dient. In diesem Beitrag geben wir die wichtigsten Anforderungen an, die wir bei der Konstruktion von vis-A-vis beachtet haben. Der Anwendungsbereich von vis-A\u00a0\u2026", "num_citations": "2\n", "authors": ["1248"]}
{"title": "Use Case Modeling for Embedded Software Systems-Deficiencies & Workarounds\n", "abstract": " While applying use case modeling in the domain of embedded software systems, we observed some weaknesses, related to the very special characteristics of embedded software, discriminating it from those large-scale industrial applications, use case modeling was initially developed for and where this technique still has its greatest acceptance. In this paper we discuss some of the most severe deficiencies we observed, namely the lack of modeling capabilities to deal with timing and concurrency constraints, as well as difficulties to handle stacked interfaces, an aspect embedded software systems often have to face.", "num_citations": "2\n", "authors": ["1248"]}
{"title": "A Comparison Infrastructure for Fault Characterization Algorithms\n", "abstract": " Fault characterization is an important part of combinatorial testing which enables the automatic identification of failure-inducing combinations. Up until now, many different algorithms are proposed to compute failure-inducing combinations. However, the only comparisons between different algorithms are done by the algorithms authors themselves who only evaluate few algorithms at a time which complicates comparisons. Therefore, we present a concept and a reference implementation of a comparison infrastructure that allows to evaluate fault characterization algorithms in a comparable manner. In addition, we report on the results of a preliminary comparison using the comparison infrastructure.", "num_citations": "1\n", "authors": ["1248"]}
{"title": "Qualitative Comparison of Enterprise Architecture Model Maintenance Processes\n", "abstract": " Enterprise Architecture (EA) is no end in itself but has to provide central, important, and up-to-date information of the organization to its clients. So far, different researchers have elaborated on processes to ensure a (semi-)automated EA model maintenance. For practitioners this raises the question how the processes can be compared to each other. To answer this question, we identified a set of five quality criteria and asked EA researcher and practitioners to rate those for three processes.", "num_citations": "1\n", "authors": ["1248"]}
{"title": "Optimierung von Unternehmensarchitekturen unter Ber\u00fccksichtigung von Transitionskosten\n", "abstract": " Unternehmensarchitekturen, die sich \u00fcblicherweise von der Gesch\u00e4ftsschicht \u00fcber die Anwendungsschicht bis zur Infrastrukturschicht erstrecken, bieten eine M\u00f6glichkeit, die Gesch\u00e4ftsstrategie innerhalb der IT umzusetzen. Um dies erreichen zu k\u00f6nnen, werden Unternehmensarchitekturen kontinuierlich gepflegt. Dazu geh\u00f6rt unter anderem, dass unn\u00f6tige Elemente aus der Unternehmensarchitektur entfernt werden und diese somit optimiert wird.               In einem vorangegangenen Artikel haben wir bereits untersucht, wie auf Basis der Repr\u00e4sentation einer Unternehmensarchitektur als Graph eine Optimierung ermittelt werden kann. Dieser Ansatz unterscheidet allerdings nicht, ob die Elemente dem Ist-Zustand zuzurechnen sind oder ihr Einsatz bisher nur geplant ist. Dementsprechend werden auch die notwendigen Transitionskosten, um vom Ist-Zustand zum optimalen Zustand zu gelangen, nicht\u00a0\u2026", "num_citations": "1\n", "authors": ["1248"]}
{"title": "A Meta-Model for Maturity Model classification\n", "abstract": " Maturity Models are a common approach to measure and improve a company\u2019s process capabilities. Although Maturity Models share a common structure, numerous Maturity and Assessment Models have been developed, in fact so many that it requires a lot of effort for scholars and practitioners to choose an adequate one for their business and situation. This paper proposes a Meta-Model that represents this common structure of such models and their attributes. Based on that Meta-Model these models are classified, such that choosing an appropriate model becomes easier. For a better understanding of the common structure an overview of the history of Maturity Models is given and how they evolved. By analyzing different models criteria for grouping will be identified. Based on those findings a Meta-Model is created and finally applied to some models, to give an example on how this Meta-Model can be used to categorize Maturity Models.", "num_citations": "1\n", "authors": ["1248"]}
{"title": "On Adequate Behavior-based Architecture Conformance Checks\n", "abstract": " Architecture conformance checks are important to control the inevitable drift between the prescriptive and descriptive architectures of a software system during its evolution. To this end, behavior-based architecture conformance checks should be employed in addition to static ones. But behavior-based analyses suffer from an important shortcoming: their results depend on the adequateness of the monitored behavior. Our claim is that a behavior-based architecture conformance check is adequate if (1) the architectural rules relevant from a behavior viewpoint are expressible and can be checked against and (2) the set of captured scenarios are relevant for exhibiting the overall behavior of the system. First, using ARAMIS, our approach to behavior-based architecture reconstruction and conformance checking, we exemplify how conformance rules can be expressed. Then, we propose a metric to investigate the\u00a0\u2026", "num_citations": "1\n", "authors": ["1248"]}
{"title": "Studienarbeiten: Ein Leitfaden zur Erstellung, Durchf\u00fchrung und Pr\u00e4sentation wissenschaftlicher Abschlussarbeiten am Beispiel Informatik\n", "abstract": " Ziel dieses Leitfadens ist die Vermittlung von Regeln und Techniken fu\u0308r die Durchfu\u0308hrung wissenschaftlicher Arbeiten. Dazu geh\u00f6ren Seminar-, Bachelor-, Master-und Doktorarbeiten, also alle Pru\u0308fungsleistungen mit wissenschaftlichem Anspruch, die von Studierenden, Assistentinnen und Assistenten unter Anleitung, aber in gewisser Selbst\u00e4ndigkeit und u\u0308ber l\u00e4ngere Zeit hinweg erbracht werden. Im Mittelpunkt stehen Bachelor-und Masterarbeiten, doch auch auf Publikationen und auf Dokumentationen ohne wissenschaftlichen Anspruch lassen sich die meisten Aussagen anwenden. Der Leitfaden ist fu\u0308r Arbeiten in allen technischen und naturwissenschaftlichen Disziplinen hilfreich, die Informatik dient lediglich als Beispiel. Er wendet sich einerseits an Studierende, die lernen wollen, ein Projekt auszuw\u00e4hlen, vorzubereiten, durchzufu\u0308hren und zu pr\u00e4sentieren. Andererseits sind die Betreuerinnen und Betreuer angesprochen, die die Arbeiten definieren, unterstu\u0308tzen und schlie\u00dflich beurteilen.", "num_citations": "1\n", "authors": ["1248"]}
{"title": "Interacting with code: Observations, models, and tools for usable software development environments\n", "abstract": " Das Verstehen von Programmquellcode ist eine der essentiellen Aktivit\u00e4ten von Softwareentwicklern. Es ist nicht nur erforderlich um Wartungsarbeiten an existierender Software durchzuf\u00fchren, sondern auch, wenn bereits existierender Quellcode wiederverwendet werden soll. Viele Aspekte einer Softwareentwicklungsumgebung, wie zB Software-basierte Werkzeuge, Frameworks, oder Dokumentation, sind so gestaltet, dass sie das Verst\u00e4ndnis von Software unterst\u00fctzen. Die Gestaltung dieser Aspekte hilft jedoch Softwareentwicklern nicht nur ihre existierenden Strategien um Software zu verstehen effizienter anzuwenden, sondern \u00e4ndert welche Strategien sie nutzen. In dieser Arbeit werden wir untersuchen wie genau die Gestaltung der Entwicklungsumgebung die Strategien zum Verst\u00e4ndnis von Quellcode beeinflusst. Unsere Ergebnisse erweitern das Wissen \u00fcber die kognitiven Modelle von\u00a0\u2026", "num_citations": "1\n", "authors": ["1248"]}
{"title": "Towards A Design for An Extendable Reporting Interface\n", "abstract": " This paper proposes a design of an extendable reporting interface. The design of this interface is focused on how the data can be retrieved from a data processing software and how reports are generated to be consumed by another system. The reporting interface should be independent from its client software and from the report format that has to be produced. Therefore, there is a need for a very general data structure to handle various type of incoming data. We decided to use XML as a structure to create a report which later is consumed by another system. However, not all systems are able to process XML as an input. Therefore, the reporting interface should have the capability to produce several output formats. In addition, live reporting should also be supported to allow the user to retrieve information as soon as possible while the final report is being generated.", "num_citations": "1\n", "authors": ["1248"]}
{"title": "An Overview on Automated Test Data Generation\n", "abstract": " Test automation is a means of reducing the time and cost spent during software testing. It includes the automatic generation of test data which is an interesting, active and a vast area of research in software engineering. There is a large number of specific publications introducing new algorithms and concepts without linking them to the existing ones. In addition, some publications use expressions which create some confusion. As an example, the expressions\u201d test case generation\u201d and\u201d test data generation\u201d are often used interchangeably although they denote different problems. All that makes it hard for students and researchers interested in this area to get a solid understanding of what generating test data is about.In this article, we first introduce the test case and test data generation problems. Thereafter, we review some basic notions like constraint-based test data generation, symbolic and concrete execution. Next, we focus on the state of the art techniques of test data generation which are grouped under the term search-based test data generation. We also discuss some known limitations of test data generators. In the second part of the article we present an automated blackbox test data generation technique for web services which is based on Design by Contract and mutation testing. Thereafter, we present some tools which can be used by software testers to enrich their daily test automation experience. Finally, we conclude this article by giving our opinion on the subject.", "num_citations": "1\n", "authors": ["1248"]}
{"title": "Lessons Learned on Systematic Metric System Development at a large IT Service Provider\n", "abstract": " Even though a lot of work was contributed to extend and enhance metric requirements gathering techniques, metric systems are often developed chaotically and a solid dedicated metric system engineering approach is still missing. This paper provides our experiences at developing a metric system together with a large IT service provider and presents an overview on our reference architecture for enterprise measurement infrastructures. Furthermore we give some insights into our metric systems engineering approach which integrates software engineering best practices, modern ideas like micro services, and well established metric related techniques such as GQM.", "num_citations": "1\n", "authors": ["1248"]}
{"title": "Multi Back-Ends for a Model Library Abstraction Layer\n", "abstract": " Software development is moving in the direction of modeling as do quite a lot of other IT related tasks. This means, models become more and more important either as a means of communication or as parts of realizations. Unfortunately, these models are rarely reused which might be due to poor tool support.               A model recommender system is one possible way out, but it bases on high quality data which is most likely stored in a database and needs to blend into an environment. Hence, approaching model recommendations in a model driven way and generating the underlying data store which makes do with an existing infrastructure is desirable. In this paper we describe the underlying model and the obstacles we had to overcome to make this approach work for relational and non relational databases.", "num_citations": "1\n", "authors": ["1248"]}
{"title": "International Workshop on CMMI based Software Process Improvement in Small and Medium Sized Enterprises\n", "abstract": " The Workshop on CMMI based Process Improvement in Small and Medium Sized Enterprises aims at gathering together re-searchers and practitioners to discuss experiences in the application of CMMI in industrial software organizations. CMMI is one of the most accepted process improvement approaches. In software development CMMI-DEV is applied by many organizations. SEI reports that 60% of the appraised organizations are small and medium sized organizations. Another report shows that this number is increasing. Because a CMMI based process improvement program takes time and is expensive many small and medium size software development organizations are still facing problems in applying CMMI. One goal of this workshop is to exchange experience on how to set up, apply and organize a CMMI based process improvement processes in small and medium size enterprises.", "num_citations": "1\n", "authors": ["1248"]}
{"title": "A model-based simulation environment for structured textual use cases\n", "abstract": " Although use cases are nowadays one of the most widespread techniques for the specification of system behavior low quality use case descriptions regularly cause serious problems in later phases of the development process. The simulation of use case based descriptions may be an important technique to overcome these issues because it enables especially non technical stakeholder to assess the quality of use cases. In this paper we present a model-based use case simulation approach for semi-formal textual use cases. We motivate core requirements of a simulation environment and an underlying execution model. Additionally we describe our technical solution for a model-based simulation environment and present some first experiences.", "num_citations": "1\n", "authors": ["1248"]}
{"title": "Applying Test Case Metrics in a Tool Supported Iterative Architecture and Code Improvement Process\n", "abstract": " In order to support an iterative architecture and code improvement process a dedicated code analysis tool has been developed. But introducing the process and the tool in a medium sized company is always accompanied by difficulties, like understanding improvement needs. We therefore decided to use test effort as the central communication metaphor for code complexity. Hence, we developed a metric suite to calculate the number of test cases needed for branch coverage and (modified) boundary interior test. This paper introduces the developed metrics and also presents a case study performed at a medium sized software company to evaluate our approach. The main part of this paper is dedicated to the interpretation and comparison of the metrics. Finally their application in an iterative code improvement process is investigated.", "num_citations": "1\n", "authors": ["1248"]}
{"title": "The MeDUSA Reference Manual\n", "abstract": " MeDUSA (Method for UML2-based Construction of Embedded & Real-Time Software) is a model-based software construction method targeting the domain of small embedded & real-time software. MeDUSA was developed by the Research Group Software Construction of the RWTH Aachen University in close cooperation with the German ABB Corporate Research Centre in Ladenburg. It incorporates various practical experiences gained during the industrial development of embedded software in ABB Business Unit Instrumentation.Being Use Case-driven, MeDUSA systematically covers the software construction lifecycle phase from the early requirements up to implementation. Models are successively developed and employed throughout all activities. By enforcing a class-based rather than an object-oriented design (compare classification according to [Weg87]), a smooth transition of the resulting design model towards an implementation in a procedural programming language is facilitated. This is essential, as procedural programming languages as the C language are still state-of-the-art in the domain of small embedded & real-time software.", "num_citations": "1\n", "authors": ["1248"]}
{"title": "Werkzeugunterst\u00fctzung f\u00fcr die use case-modellierung\n", "abstract": " 3011062 GI-Proceedings Cover Page 1 Werkzeugunterst\u00fctzung f\u00fcr die Use Case-Modellierung Andreas Walter, Alexander Ny\u00dfen, Veit Hoffmann, Horst Lichter Research Group Software Construction, RWTH Aachen University, {awalt, any, vhoff, lichter}@swc.rwth-aachen.de Use Cases werden graphisch mit Hilfe von UML-Diagrammen modelliert, aber immer auch nat\u00fcrlichsprachlich beschrieben. F\u00fcr diese Beschreibungen schlagen zB Cockburn [Co00] oder Bittner und Spence [BS03] Notationen vor. Es gibt jedoch keinen einheitlichen Standard, und Werkzeugunterst\u00fctzung ist nicht verf\u00fcgbar. NaUTiluS (Narrative Use Case Description Toolkit for Evaluation and Simulation) unterst\u00fctzt die Use Case-Modellierung, indem UML-Diagramme und textuelle Beschreibungen miteinander verkn\u00fcpft werden. Die Beschreibungen basieren auf einem Metamodell, das an die Notation von Bittner und Spence [BS03] angelehnt \u2026", "num_citations": "1\n", "authors": ["1248"]}
{"title": "An integration framework for heterogeneous automatic software tests\n", "abstract": " Developing and maintaining large software systems can require the usage of a variety of different automatic test tools. The complexity of the tools leads to considerable overheads for administration and maintenance of the test cases, as well as for the analysis of the test results. The necessary know-how to handle the test tools may limit their acceptance. This paper describes an integration framework for heterogeneous automatic test tools that unifies the test case administration, test execution, and reporting of the test results.", "num_citations": "1\n", "authors": ["1248"]}
{"title": "BugzillaMetrics-Design of an adaptable tool for evaluating user-defined metric specifications on change requests\n", "abstract": " The evaluation of metrics on the data available in change request management (CRM) systems can give valuable information for the management of software development. It can for example be helpful in assessing the current workload, product quality or development process weaknesses. Metrics and charts on change requests are already available in current CRM systems. They provide information about common metrics, but their adaptability is limited with respect to the specification of metrics customized to organizationspecific needs.This paper describes a more flexible approach for the evaluation of metrics on change requests. The core part of the presented tool is an event driven evaluation algorithm for the calculation of time series data. It is parametrized with user defined metric specifications. This enables a separation between metric specification and information retrieval. Further design decisions enable a transparent execution optimization and an abstraction from the data sources of the underlying CRM database.", "num_citations": "1\n", "authors": ["1248"]}
{"title": "RequiLine: Ein Requirements Engineering Werkzeug f\u00fcr Software Produktlinien\n", "abstract": " \u201cA software product line is a set of softwareintensive systems that share a common, managed set of features satisfying the specific needs of a particular market segment or mission and that are developed from a common set of core assets in a prescribed way\u201d[1]. Eine Produktlinie besteht demnach aus einer Menge von Produkten, die einen gemeinsamen Kern von Merkmalen besitzen und die bei einer Reihe von Eigenschaften unterschiedliche Auspr\u00e4gungen besitzen und somit in diesen Eigenschaften variieren. Der Nutzen, den die Produktlinienentwicklung bringen soll, reicht von k\u00fcrzeren Release-Zyklen und einer breiteren Produktpalette, \u00fcber geringere Entwicklungs-und Wartungskosten, bis hin zu Standardisierungen in Produktnutzung und\u2013lizensierung. Diese offensichtlichen Vorteile, setzen allerdings eine hohe Anfangsinvestition und einen sorgf\u00e4ltigen Entwicklungsprozess voraus. Der Entwicklungsprozess, der sich in die Teilprozesse Domain-und Application-Engineering aufteilen l\u00e4sst, hat zur Aufgabe, die gemeinsamen Merkmale herauszuarbeiten und unter Wiederverwendung dieser und durch Hinzuf\u00fcgung variabler Charakteristiken neue Produkte zu instanziieren.Die Variabilit\u00e4t stellt somit ein Kernkonzept innerhalb der Produktlinienentwicklung dar. Die explizite Modellierung der Variabilit\u00e4t und der Abh\u00e4ngigkeiten zwischen variablen Merkmalen ist w\u00e4hrend der gesamten Entwicklung von entscheidender Bedeutung. W\u00e4hrend der Analysephase m\u00fcssen Variabilit\u00e4ten in der Dom\u00e4ne und in den Anforderungen analysiert und explizit modelliert werden. Da die Erfahrung zeigt, dass die Anforderungsmodelle f\u00fcr Produktlinien sehr\u00a0\u2026", "num_citations": "1\n", "authors": ["1248"]}
{"title": "Enabling local SPI in a multi-national company\n", "abstract": " ABB has a long tradition of improving software processes and of applying CMM in SPI projects. This paper presents the structure and results of a company-wide SPI initiative called ASPI. The initiative aims to complement the existing local SPI projects by harmonizing processes, methods and tools to be used in R&D software development throughout ABB in a common framework. We give an overview of the structure of this framework and present in detail the common decision model for product development projects, which forms an important part of the framework. This model is generic and has to be tailored to the needs of local ABB R&D units. We conclude by discussing the experiences gained during introducing the decision model and give a brief outlook on the SPI activities planned in the future.", "num_citations": "1\n", "authors": ["1248"]}
{"title": "Test Automation for Object-Oriented Frameworks\n", "abstract": " Department of Computer Science Aachen Technical University D-52056 Aachen {moritz, lichter}@ informatik. rwth-aachen. de", "num_citations": "1\n", "authors": ["1248"]}
{"title": "Software-Projektmanagement in der Industrie: Erfahrungen und Analysen\n", "abstract": " Viele Software-Entwicklungsprojekte haben eines gemeinsam: Es gelingt nicht, die geforderte Funktionalit\u00e4t in der geplanten Zeit und mit den geplanten Ressourcen zu entwickeln. Als Konsequenz davon werden viele Software-Entwicklungsprojekte erst mit erheblichem Zeitverzug und mit erheblicher \u00dcberschreitung des Entwicklungs-Budget abgeschlossen, oder aber sogar abgebrochen. Eine qualifizierte Projektleitung ist daher eine notwendige, wenn auch nicht hinreichende Voraussetzung, damit Software-Entwicklungsprojekte erfolgreich durchgef\u00fchrt und abgeschlossen werden k\u00f6nnen. Die Gr\u00fcnde, warum Software-Entwicklungsprojekte h\u00e4ufig nicht in der geplanten Zeit und mit dem geplanten Budget abgeschlossen werden k\u00f6nnen sind vielf\u00e4ltig. Mit dieser Studie sollen vor allem die allt\u00e4glichen Probleme, ihre Ursachen und Effekte erfasst werden, mit denen ein Projektleiter konfrontiert ist und die in\u00a0\u2026", "num_citations": "1\n", "authors": ["1248"]}
{"title": "Software-Entwicklung durch schrittweise Komplettierung\n", "abstract": " Die Arbeit beschreibt die Software-Entwicklung durch schrittweise Komplettierung. Darin sind die Prinzipien der traditionellen Programmentwicklung nach einem Phasenplan mit dem Prototyp-Ansatz verbunden. Auf diese Weise bleiben die Vorteile beider Ans\u00e4tze erhalten. Das Vorgehen erfordert starke Unterst\u00fctzung durch die Software-Entwicklungsdatenbank. Diese Datenbank wird gegenw\u00e4rtig in unserer Gruppe realisiert.", "num_citations": "1\n", "authors": ["1248"]}
{"title": "MeDUSA-Method for Designing UML2-based Embedded System Software Architectures\n", "abstract": " MeDUSA (Method for Designing UML2-based Embedded System Software Architectures) is a model-driven software design method targeting the domain of small embedded systems. It was developed by the Research Group Software Construction of the RWTH Aachen in close cooperation with the German ABB Research Centre in Ladenburg. MeDUSA incorporates various practical experiences gained during the industrial development of embedded software in ABB Business Unit Instrumentation.Regarding its applicability, the domain covered by MeDUSA can be characterized, as stated above, as software development of small embedded devices. However, as this application domain is rather broad\u2013and even if we think that MeDUSA would be applicable to quite a lot of its different sub domains\u2013understanding the method and its characteristics can be best achieved by taking into consideration the domain MeDUSA was initially developed for, namely that of software development for field devices.", "num_citations": "1\n", "authors": ["1248"]}