{"title": "Inheritance of workflows: an approach to tackling problems related to change\n", "abstract": " Inheritance is one of the key issues of object-orientation. The inheritance mechanism allows for the definition of a subclass which inherits the features of a specific superclass. When adapting a workflow process definition to specific needs (ad-hoc change) or changing the structure of the workflow process as a result of reengineering efforts (evolutionary change), inheritance concepts are useful to check whether the new workflow process inherits some desirable properties of the old workflow process. Today's workflow management systems have problems dealing with both ad-hoc changes and evolutionary changes. As a result, a workflow management system is not used to support dynamically changing workflow processes or the workflow processes are supported in a rigid manner, i.e., changes are not allowed or handled outside of the workflow management system. In this paper, we propose inheritance-preserving\u00a0\u2026", "num_citations": "691\n", "authors": ["574"]}
{"title": "SDF^ 3: SDF for free\n", "abstract": " SDF^3 is a tool for generating random Synchronous DataFlow Graphs (SDFGs), if desirable with certain guaranteed properties like strongly connectedness. It includes an extensive library of SDFG analysis and transformation algorithms as well as functionality to visualize them. The tool can create SDFG benchmarks that mimic DSP or multimedia applications.", "num_citations": "473\n", "authors": ["574"]}
{"title": "Diagnosing workflow processes using Woflan\n", "abstract": " Workflow management technology promises a flexible solution for business-process support facilitating the easy creation of new business processes and modification of existing processes. Unfortunately, today's workflow products have no support for workflow verification. Errors made at design-time are not detected and result in very costly failures at run-time. This paper presents the verification tool Woflan. Woflan analyzes workflow process definitions downloaded from commercial workflow products using state-of-the-art Petri-net-based analysis techniques. This paper describes the functionality of Woflan emphasizing diagnostics to locate the source of a design error. Woflan is evaluated via two case studies, one involving 20 groups of students designing a complex workflow process and one involving an industrial workflow process designed by Staffware Benelux. The results are encouraging and show that\u00a0\u2026", "num_citations": "433\n", "authors": ["574"]}
{"title": "Process algebra: equational theories of communicating processes\n", "abstract": " Process algebra is a widely accepted and much used technique in the specification and verification of parallel and distributed software systems. This book sets the standard for the field. It assembles the relevant results of most process algebras currently in use, and presents them in a unified framework and notation. The authors describe the theory underlying the development, realization and maintenance of software that occurs in parallel or distributed systems. A system can be specified in the syntax provided, and the axioms can be used to verify that a composed system has the required external behavior. As examples, two protocols are completely specified and verified in the text: the Alternating-Bit Protocol for Data Communication, and Fischer's Protocol of Mutual Exclusion. The book serves as a reference text for researchers and graduate students in computer science, offering a complete overview of the field and referring to further literature where appropriate.", "num_citations": "274\n", "authors": ["574"]}
{"title": "A scenario-aware data flow model for combined long-run average and worst-case performance analysis\n", "abstract": " Data flow models are used for specifying and analysing signal processing and streaming applications. However, traditional data flow models are either not capable of expressing the dynamic aspects of modern streaming applications or they do not support relevant analysis techniques. The dynamism in modern streaming applications often originates from different modes of operation (scenarios) in which data production and consumption rates and/or execution times may differ. This paper introduces a scenario-aware generalisation of the synchronous data flow model, which uses a stochastic approach to model the order in which scenarios occur. The formally defined operational semantics of a scenario-aware data flow model implies a Markov chain, which can be analysed for both long-run average and worst-case performance metrics using existing exhaustive or simulation-based techniques. The potential of using\u00a0\u2026", "num_citations": "257\n", "authors": ["574"]}
{"title": "Multiprocessor resource allocation for throughput-constrained synchronous dataflow graphs\n", "abstract": " Embedded multimedia systems often run multiple time-constrained applications simultaneously. These systems use multiprocessor systems-on-chip of which it must be guaranteed that enough resources are available for each application to meet its throughput constraints. This requires a task binding and scheduling mechanism that provides timing guarantees for each application independent of other applications while taking into account the available processor space, memory and communication bandwidth.", "num_citations": "214\n", "authors": ["574"]}
{"title": "Exploring trade-offs in buffer requirements and throughput constraints for synchronous dataflow graphs\n", "abstract": " Multimedia applications usually have throughput constraints. An implementation must meet these constraints, while it minimizes resource usage and energy consumption. The compute intensive kernels of these applications are often specified as synchronous dataflow graphs. Communication between nodes in these graphs requires storage space which influences throughput. We present exact techniques to chart the Pareto space of throughput and storage tradeoffs, which can be used to determine the minimal storage space needed to execute a graph under a given throughput constraint. The feasibility of the approach is demonstrated with a number of examples", "num_citations": "214\n", "authors": ["574"]}
{"title": "Inheritance of behavior\n", "abstract": " One of the key issues of object-oriented modeling and design is inheritance. It allows for the definition of subclasses that inherit features of some superclass. Inheritance is well defined for static properties of classes such as attributes and methods. However, there is no general agreement on the meaning of inheritance when considering the dynamic behavior of objects, captured by their life cycles. This paper studies inheritance of behavior both in a simple process-algebraic setting and in a Petri-net framework. Process algebra is chosen, because it concentrates on behavior, while abstracting from the internal states of processes. The result of the algebraic study is a clear conceptual understanding of inheritance of behavior. It can be expressed in terms of blocking and hiding method calls. The results in the algebraic framework inspire the development of the concept of inheritance of behavior in the Petri-net\u00a0\u2026", "num_citations": "208\n", "authors": ["574"]}
{"title": "System-scenario-based design of dynamic embedded systems\n", "abstract": " In the past decade, real-time embedded systems have become much more complex due to the introduction of a lot of new functionality in one application, and due to running multiple applications concurrently. This increases the dynamic nature of today's applications and systems, and tightens the requirements for their constraints in terms of deadlines and energy consumption. State-of-the-art design methodologies try to cope with these novel issues by identifying several most used cases and dealing with them separately, reducing the newly introduced complexity. This article presents a generic and systematic design-time/run-time methodology for handling the dynamic nature of modern embedded systems, which can be utilized by existing design methodologies to increase their efficiency. It is based on the concept of system scenarios, which group system behaviors that are similar from a multidimensional cost\u00a0\u2026", "num_citations": "199\n", "authors": ["574"]}
{"title": "Requirements on the execution of Kahn process networks\n", "abstract": " Kahn process networks (KPNs) are a programming paradigm suitable for streaming-based multimedia and signal-processing applications. We discuss the execution of KPNs, and the criteria for correct scheduling of their realisations. In [12], Parks shows how process networks can be scheduled in bounded memory; the proposed method is used in many implementations of KPNs. However, it does not result in the correct behaviour for all KPNs. We investigate the requirements for a scheduler to guarantee both correct and bounded execution of KPNs and present an improved scheduling strategy that satisfies them.", "num_citations": "186\n", "authors": ["574"]}
{"title": "Throughput-buffering trade-off exploration for cyclo-static and synchronous dataflow graphs\n", "abstract": " Multimedia applications usually have throughput constraints. An implementation must meet these constraints, while it minimizes resource usage and energy consumption. The compute intensive kernels of these applications are often specified as cyclo-static or synchronous dataflow graphs. Communication between nodes in these graphs requires storage space which influences throughput. We present an exact technique to chart the Pareto space of throughput and storage trade-offs, which can be used to determine the minimal buffer space needed to execute a graph under a given throughput constraint. The feasibility of the exact technique is demonstrated with experiments on a set of realistic DSP and multimedia applications. To increase scalability of the approach, a fast approximation technique is developed that guarantees both throughput and a, tight, bound on the maximal overestimation of buffer\u00a0\u2026", "num_citations": "168\n", "authors": ["574"]}
{"title": "Scenario-aware dataflow: Modeling, analysis and implementation of dynamic applications\n", "abstract": " Embedded multimedia and wireless applications require a model-based design approach in order to satisfy stringent quality and cost constraints. The Model-of-Computation (MoC) should appropriately capture system dynamics, support analysis and synthesis, and allow low-overhead model-driven implementations. This combination poses a significant challenge. The Scenario-Aware DataFlow (SADF) MoC has been introduced to address this challenge. This paper surveys SADF, and compares dataflow MoCs in terms of their ability to capture system dynamics, their support for analysis and synthesis, and their implementation efficiency.", "num_citations": "166\n", "authors": ["574"]}
{"title": "Branching bisimilarity is an equivalence indeed!\n", "abstract": " This note presents a detailed proof of a result in the theory of concurrency semantics that is already considered folklore, namely that branching bisimilarity is an equivalence relation. The \u201csimple proof\u201d, which in the literature is always assumed to exist, is shown to be incorrect. The proof in this note is based on the notion of a semi-branching bisimulation taken from (Van Glabbeek and Weijland, 1991). Branching bisimilarity can equivalently be defined in terms of semi-branching bisimulations; the results suggest that such a definition is more intuitive than the original definition of Van Glabbeek and Weijland (1989).", "num_citations": "149\n", "authors": ["574"]}
{"title": "Adaptive workflow\n", "abstract": " Today\u2019s information systems do not support adaptive workflow: either the information system abstracts from the workflow processes at hand and focuses on the management of data and the execution of individual tasks via applications or the workflow is supported by the information system but it is hard to handle changes. This paper addresses this problem by classifying the types of changes. Based on this classification, issues such as syntactic/semantic correctness, case transfer, and management information are discussed. It turns out that the trade-off between flexibility and support raises challenging questions. Only some of these questions are answered in this paper; most of them require further research. Since the success of the next generation of workflow management systems depends on the ability to support adaptive workflow, it is important to provide answers for the questions raised in this paper.", "num_citations": "148\n", "authors": ["574"]}
{"title": "Life-cycle inheritance\n", "abstract": " Inheritance is one of the key issues of object-orientation. The inheritance mechanism allows for the definition of a subclass which inherits the features of a specific superclass. This means that methods and attributes defined for the superclass are also available for objects of the subclass. Existing methods for object-oriented modeling and design abstract from the dynamic behavior of objects when defining inheritance. Nevertheless, it would be useful to have a mechanism which allows for the inheritance of dynamic behavior. This paper describes a Petri-net-based approach to the formal specification and verification of this type of inheritance. We use Petri nets to specify the dynamics of an object class. The Petri-net formalism allows for a graphical representation of the life cycle of objects which belong to a specific object class. Four possible inheritance relations are defined. These inheritance relations can be\u00a0\u2026", "num_citations": "136\n", "authors": ["574"]}
{"title": "Minimising buffer requirements of synchronous dataflow graphs with model checking\n", "abstract": " Signal processing and multimedia applications are often implemented on resource constrained embedded systems. It is therefore important to find implementations that use as little resources as possible. These applications are frequently specified as synchronous data flow graphs. Communication between actors of these graphs requires storage capacity. In this paper, we present an exact method to determine the minimum storage capacity required to execute the graph using model-checking techniques. This can be done for different measures of storage capacity. The problem is known to be NP-complete and because of this, existing buffer minimisation techniques are heuristics and hence not exact. Modern model-checking tools are quite efficient and they have been successfully applied to scheduling-related problems. We study the feasibility of this approach with examples.", "num_citations": "127\n", "authors": ["574"]}
{"title": "Congestion-controlled best-effort communication for networks-on-chip\n", "abstract": " Congestion has negative effects on network performance. In this paper, a novel congestion control strategy is presented for networks-on-chip (NoC). For this purpose we introduce a new communication service, congestion-controlled best-effort (CCBE). The load offered to a CCBE connection is controlled based on congestion measurements in the NoC. Link utilization is monitored as a congestion measure, and transported to a model predictive controller (MPC). Guaranteed bandwidth and latency connections in the NoC are used for this, to assure progress of link utilization data in a congested NoC. We also present a simple but effective model for link utilization for the model-based predictions. Experimental results show that the presented strategy is effective and has reaction speeds of several microseconds which is considered acceptable for realtime embedded systems", "num_citations": "125\n", "authors": ["574"]}
{"title": "Task-level timing models for guaranteed performance in multiprocessor networks-on-chip\n", "abstract": " We consider a dynamic application running on a multiprocessor network-on-chip as a set of independent jobs, each job possibly running on multiple processors. To provide guaranteed quality and performance, the scheduling of jobs, jobs themselves and the hardware must be amenable to timing analysis. For a certain class of applications and multiprocessor architectures, we propose exact timing models that effectively co-model both the computation and communication of a job. The models are based on interprocessor communication (IPC) graphs [4]. Our main contribution is a precise model of network-on-chip communication, including buffer models. We use a JPEG-decoder job as an example to demonstrate that our models can be used in practice to derive upper bounds on the job execution time and to reason about optimal buffer sizes.", "num_citations": "123\n", "authors": ["574"]}
{"title": "In terms of nets: System design with Petri nets and process algebra.\n", "abstract": " Degree: Dr.DegreeYear: 1998Institute: Technische Universiteit Eindhoven (The Netherlands)Publisher: University Press Facilities, Po Box 513, 5600 Mb Eindhoven, The Netherlands.To date, there are many different formal methods for describing and analyzing concurrent systems. Two of the most widely used formalisms are Petri nets and process algebra. The main motivation of this thesis is to study topics combining these two formalisms.", "num_citations": "105\n", "authors": ["574"]}
{"title": "An algebra of Pareto points\n", "abstract": " Multi-criteria optimisation problems occur naturally in many engineering practices. Pareto analysis has proven to be a powerful tool to characterise potentially interesting realisations of a particular engineering problem. It is therefore used frequently for design-space exploration problems. Depending on the optimisation goals, one of the Pareto-optimal alternatives will be the optimal realisation. It often happens however, that partial design decisions have to be taken, leaving other aspects of the optimisation problem to be decided at a later stage, and that Pareto-optimal configurations have to be composed (dynamically) from Pareto-optimal configurations of components. These aspects are not supported by current analysis methods. This paper introduces a novel, algebraic approach to Pareto analysis. The approach is particularly designed to allow for describing incremental design decisions and composing sets of\u00a0\u2026", "num_citations": "103\n", "authors": ["574"]}
{"title": "Ambient intelligence visions and achievements: linking abstract ideas to real-world concepts\n", "abstract": " The ambient intelligence vision is abstract and as such not useful for funding decisions, research project definition, and business plan development. This is in particular the case for the electronic design community. The European Commission intends for the EU to achieve world leadership in Information Societies technologies within ten years. To that end, it has incorporated the ambient intelligence vision in its Sixth Framework. Microelectronics and nano- and optical devices are seen as key technologies. Interesting chip-level challenges are found in, amongst others, explicit modeling of mobility and self-management, and novel computing substrates, based on electronic textiles or organic electronics.", "num_citations": "100\n", "authors": ["574"]}
{"title": "Latency minimization for synchronous data flow graphs\n", "abstract": " Synchronous data flow graphs (SDFGs) are a very useful means for modeling and analyzing streaming applications. Some performance indicators, such as throughput, have been studied before. Although throughput is a very useful performance indicator for concurrent real-time applications, another important metric is latency. Especially for applications such as video conferencing, telephony and games, latency beyond a certain limit cannot be tolerated. This paper proposes an algorithm to determine the minimal achievable latency, providing an execution scheme for executing an SDFG with this latency. In addition, a heuristic is proposed for optimizing latency under a throughput constraint. Experimental results show that latency computations are efficient despite the theoretical complexity of the problem. Substantial latency improvements are obtained, of 24-54% on average for a synthetic benchmark of 900 models\u00a0\u2026", "num_citations": "95\n", "authors": ["574"]}
{"title": "A predictable multiprocessor design flow for streaming applications with dynamic behaviour\n", "abstract": " The design of new embedded systems is getting more and more complex as more functionality is integrated into these systems. To deal with the design complexity, a predictable design flow is needed. The result should be a system that guarantees that an application can perform its own tasks within strict timing deadlines, independent of other applications running on the system. Synchronous Dataflow Graphs (SDFGs) provide predictability and are often used to model time-constrained streaming applications that are mapped onto a multiprocessor platform. However, the model abstracts from the dynamic application behaviour which may lead to a large overestimation of its resource requirements. We present a design flow that takes the dynamic behaviour of applications into account when mapping them onto a multiprocessor platform. The design flow provides throughput guarantees for each application independent\u00a0\u2026", "num_citations": "89\n", "authors": ["574"]}
{"title": "Reactive process networks\n", "abstract": " Data flow process networks are a good model of computation for streaming multimedia applications incorporating audio, video and/or graphics streams. Process networks are concurrent processes communicating streams of data through FIFO channels. They can be executed efficiently and determinately on multiprocessor platforms. However, such stream processing applications are becoming more dynamic, often requiring run-time reconfigurations. Moreover, stream processing is not always an application on its own, but may be a component of a larger application. This application, eg a game application, may be control oriented and event driven; events may interact with the streaming component and (re) configure it. In order to capture the interaction between reactive and streaming components as well as reconfiguration in dynamic stream processing, we introduce in this paper a formal, operational and\u00a0\u2026", "num_citations": "87\n", "authors": ["574"]}
{"title": "A robust protocol stack for multi-hop wireless body area networks with transmit power adaptation\n", "abstract": " Wireless Body Area Networks (WBANs) have characteristic properties that should be considered for designing a proper network architecture. Movement of on-body sensors, low quality and time-variant wireless links, and the demand for a reliable and fast data transmission at low energy cost are some challenging issues in WBANs. Using ultra low power wireless transceivers to reduce power consumption causes a limited transmission range. This implies that a multi-hop protocol is a promising design choice. This paper proposes a multi-hop protocol for human body health monitoring. The protocol is robust against frequent changes of the network topology due to posture changes, and variation of wireless link quality. A technique for adapting the transmit power of sensor nodes at run-time allows to optimize power consumption while ensuring a reliable outgoing link for every node in the network and avoiding network\u00a0\u2026", "num_citations": "86\n", "authors": ["574"]}
{"title": "A domain-independent descriptive design model and its application to structured reflection on design processes\n", "abstract": " Domain-independent models of the design process are an important means for facilitating interdisciplinary communication and for supporting multidisciplinary design. Many so-called domain-independent models are, however, not really domain independent. We state that to be domain independent, the models must abstract from domain-specific aspects, be based on the study of several design disciplines, and be useful for many design disciplines and for multidisciplinary design teams. This paper presents a domain-independent descriptive design model that is developed by studying similarities and differences between design processes in three design disciplines and which is based on the general theory of state-transition systems. The main concepts of the descriptive model are a design situation and a design activity. The descriptive model is applied in a domain-independent prescriptive model that\u00a0\u2026", "num_citations": "83\n", "authors": ["574"]}
{"title": "MoBAN: A configurable mobility model for wireless body area networks\n", "abstract": " A good mobility model is an essential prerequisite for performance evaluation of protocols for wireless networks with node mobility. Sensor nodes in a Wireless Body Area Network (WBAN) exhibit high mobility. The WBAN topology may completely change because of posture changes and movement even within a certain type of posture. The WBAN also moves as a whole in an ambient network. Therefore, an appropriate mobility model is of great importance for performance evaluation. This paper presents a comprehensive configurable mobility model MoBAN for evaluating intraand extra-WBAN communication. It implements different postures as well as individual node mobility within a particular posture. The model can be adapted to a broad range of applications for WBANs. The model is made available through http://www. es. ele. tue. nl/nes/, as an add-on to the mobility framework of the OMNeT++ simulator. Two case studies illustrate the use of the mobility model for performance evaluation of network protocols.", "num_citations": "82\n", "authors": ["574"]}
{"title": "Automatic scenario detection for improved WCET estimation\n", "abstract": " Modern embedded applications usually have real-time constraints and they are implemented using heterogeneous multiprocessor systems-on-chip. Dimensioning a system requires accurate estimations of the worst-case execution time (WCET). Overestimation leads to over-dimensioning. This paper introduces a method for automatic discovery of scenarios that incorporate correlations between different parts of applications. It is based on the application parameters with a large impact on the execution time. We show on a benchmark that, using scenarios, the estimated WCET may be reduced with 16%.", "num_citations": "73\n", "authors": ["574"]}
{"title": "An event-based monitoring service for networks on chip\n", "abstract": " Networks on chip (NoCs) are a scalable interconnect solution for multiprocessor systems on chip. We propose a generic reconfigurable online event-based NoC monitoring service, based on hardware probes attached to NoC components, offering run-time observability of NoC behavior and supporting system-level debugging. We present a probe architecture, its programming model, traffic management strategies, and a cost analysis. We prove feasibility via a prototype implementation for the \u00c6thereal NoC. Two MPEG NoC examples show that the monitoring service area, without advanced optimizations, is 17--24% of the NoC area. Two realistic monitoring examples show that monitoring traffic is several orders of magnitude lower than the 2GB/s/link raw bandwidth.", "num_citations": "70\n", "authors": ["574"]}
{"title": "Efficient Execution of Process Networks.\n", "abstract": " Efficient Execution of Process Networks. \u2014 Eindhoven University of Technology research portal Skip to main navigation Skip to search Skip to main content Eindhoven University of Technology research portal Logo Help & FAQ English Nederlands Home Researchers Research Output Organisational units Activities Projects Prizes Press / Media Facilities / Equipment Datasets Courses Research areas Student theses Efficient Execution of Process Networks. T. Basten, J. Hoogerbrugge Electronic Systems Research output: Chapter in Book/Report/Conference proceeding \u203a Conference contribution \u203a Academic \u203a peer-review Overview Original language English Title of host publication Proceedings of Communicating Process Arcitectures 2001 Editors A. Chalmers, M. Mirmehdi, H. Muller Place of Publication Amsterdam Publisher IOS Press Pages 1-14 ISBN (Print) 1-58603-202-X Publication status Published - 2001 Event \u2026", "num_citations": "70\n", "authors": ["574"]}
{"title": "Parametric throughput analysis of synchronous data flow graphs\n", "abstract": " Synchronous data flow graphs (SDFGs) have proved to be a very successful tool for modeling, analysis and synthesis of multimedia applications targeted at both single- and multiprocessor platforms. One of the most prominent performance constraints of concurrent real-time applications is throughput. For given actor execution times, throughput can be verified by analyzing the SDFG models of such applications, for instance using maximum cycle mean analysis or state space analysis. In various contexts, such as design space exploration or run-time reconfiguration, many fast throughput computations are required for varying actor execution times. We present methods to compute throughput of an SDFG where actor execution times can be parameters. The throughput of these graphs is obtained in the form of a function of these parameters. Recalculation of throughput is then merely an evaluation of this function for\u00a0\u2026", "num_citations": "68\n", "authors": ["574"]}
{"title": "Identifying commonalities and differences in object life cycles using behavioral inheritance\n", "abstract": " The behavioral-inheritance relations of [7,8] can be used to compare the life cycles of objects defined in terms of Petri nets. They yield partial orders on object life cycles (OLCs). Based on these orders, we define concepts such as the greatest common divisor and the least common multiple of a set of OLCs. These concepts have practical relevance: In component-based design, workflow management, ERP reference models, and electronic-trade procedures, there is a constant need for identifying commonalities and differences in OLCs. Our results provide the theoretical basis for comparing, customizing, and unifying OLCs.", "num_citations": "68\n", "authors": ["574"]}
{"title": "A parameterized compositional multi-dimensional multiple-choice knapsack heuristic for CMP run-time management\n", "abstract": " Modern embedded systems typically contain chip-multiprocessors (CMPs) and support a variety of applications. Applications may run concurrently and can be started and stopped over time. Each application may typically have multiple feasible configurations, trading off quality aspects (energy consumption, audio-visual quality) with resource usage for various types of resources. Overall system quality needs to be guaranteed and optimized at all times. This leads to the need for a run-time management solution that selects an appropriate system configuration from all the application configurations of active applications. This run-time management problem can be phrased as a multi-dimensional multiple-choice knapsack (MMKP) problem. We present a compositional heuristic to solve MMKP, that due to the compositionality is better suited to CMP run-time management than existing heuristics that are all not\u00a0\u2026", "num_citations": "67\n", "authors": ["574"]}
{"title": "Ambient intelligence: impact on embedded system design\n", "abstract": " Ambient intelligence: impact on embedded system design Page 2 AMBIENT INTELLIGENCE: IMPACT ON EMBEDDED SYSTEM DESIGN Page 3 Ambient Intelligence: Impact on Embedded Sytem Design Edited by Twan Basten Eindhoven University of Technology, Eindhoven, The Netherlands Marc Geilen Eindhoven University of Technology, Eindhoven, The Netherlands and Harmke de Groot Philips Research Laboratories Eindhoven, Eindhoven, The Netherlands KLUWER ACADEMIC PUBLISHERS NEW YORK, BOSTON, DORDRECHT, LONDON, MOSCOW Page 4 eBook ISBN: 0-306-48706-3 Print ISBN: 1-4020-7668-1 \u00a9 2004 Kluwer Academic Publishers New York, Boston, Dordrecht, London, Moscow Print\u00a9 2003 Kluwer Academic Publishers All rights reserved No part of this eBook may be reproduced or transmitted in any form or by any means, electronic, mechanical, recording, or otherwise, without \u2026", "num_citations": "67\n", "authors": ["574"]}
{"title": "Transaction monitoring in networks on chip: The on-chip run-time perspective\n", "abstract": " Networks-on-chip (NoC) are a scalable interconnect solution to multiprocessor systems on chip (MPSoC). NoCs transport data in packets which are fragments of transactions, such as read and write actions of IPs. For debug purposes, reconstructing transactions at run-time is essential. Run-time analysis of the NoC behavior at transaction level makes the complete MPSoC easier to understand. We present a NoC analyzer able to monitor NoC transactions at run-time. The proposed hardware transaction monitor is able to reconstruct on-chip, at run-time, NoC transactions from bit-level intercepted router link communication. Four NoC analyzer modes are detailed raising the abstraction level gradually from physical raw to logical connection-based, transaction-based and abstract transaction event-based. Each mode is analyzed for area and bandwidth in an experimental setup based on several AEligthereal NoC\u00a0\u2026", "num_citations": "67\n", "authors": ["574"]}
{"title": "An event-based network-on-chip monitoring service\n", "abstract": " Networks on chip (NoCs) are a scalable interconnect solution for large scale multiprocessor systems on chip (SoCs). However, little attention has been paid so far to the monitoring and debugging support for NoC-based systems. We propose a generic online event-based NoC monitoring service, based on hardware probes attached to NoC components. The proposed monitoring service offers run-time observability of NoC behavior and supports system-level and application debugging. The defined service can be accessed and configured at run-time from any network interface port. We present a probe architecture for the monitoring service, together with its associated programming model and traffic management strategies. We prove the feasibility of our approach via a prototype implementation for the AEthereal NoC. The additional monitoring traffic is low; typical monitoring connection configuration for a NoC-based\u00a0\u2026", "num_citations": "62\n", "authors": ["574"]}
{"title": "Poet: Target-system independent visualizations of complex distributed-application executions\n", "abstract": " Designing and implementing a visual debugger for distributed programs is a significant challenge. Distributed applications are often large and frequently exhibit a high degree of complexity. Consequently, a debugger must address problems of complexity and scale in at least two ways. First, appropriate user interfaces should allow a user to manage the vast amount of information typically obtained from distributed executions. Second, the tool itself, in handling this information, should be implemented efficiently, providing a user with reasonable response times for interactive use. Our research efforts, concentrating on these problems, have led to the development of Poet, a tool for the collection and presentation of event-based traces of distributed executions. Poet makes as few assumptions as possible about characteristics that must be possessed by all target environments. Information describing each target\u00a0\u2026", "num_citations": "62\n", "authors": ["574"]}
{"title": "Buffer sizing for rate-optimal single-rate data-flow scheduling revisited\n", "abstract": " Single-Rate Data-Flow (SRDF) graphs, also known as Homogeneous Synchronous Data-Flow (HSDF) graphs or Marked Graphs, are often used to model the implementation and do temporal analysis of concurrent DSP and multimedia applications. An important problem in implementing applications expressed as SRDF graphs is the computation of the minimal amount of buffering needed to implement a static periodic schedule (SPS) that is optimal in terms of execution rate, or throughput. Ning and Gao [1] propose a linear-programming-based polynomial algorithm to compute this minimal storage amount, claiming optimality. We show via a counterexample that the proposed algorithm is not optimal. We prove that the problem is, in fact, NP-complete. We give an exact solution, and experimentally evaluate the degree of inaccuracy of the algorithm of Ning and Gao.", "num_citations": "61\n", "authors": ["574"]}
{"title": "Application scenarios in streaming-oriented embedded-system design\n", "abstract": " A design method for handling increasingly dynamic real-time embedded-system applications can help developers cope with stringent system and market requirements. This method groups an application's operation modes into application scenarios and describes how to incorporate them in the overall design process. An automated scenario-based design trajectory reduces the energy consumption of a streaming application running on a single processor platform via dynamic voltage and frequency scaling.", "num_citations": "59\n", "authors": ["574"]}
{"title": "MCMAC: An optimized medium access control protocol for mobile clusters in wireless sensor networks\n", "abstract": " Wireless sensor networks (WSNs) are developing into a promising solution for many applications, for example in healthcare. In many scenarios, there is some form of node mobility. The medium access control (MAC) mechanisms should support the expected kind of mobility in the network. Mobility is particularly complicating for contention free MAC protocols like TDMA-based protocols, because they dedicate unique slots to every node in a neighborhood. In scenarios such as body-area networking, some clusters of nodes move together, creating further challenges and opportunities. This paper proposes MCMAC (Mobile Cluster MAC), a TDMA-based MAC protocol to support mobile clusters in WSNs. The proposed protocol does not need adaptation time after movement of clusters. Several optimization mechanisms are proposed to decrease power consumption. Simulation results show that the optimizations\u00a0\u2026", "num_citations": "48\n", "authors": ["574"]}
{"title": "NoC monitoring: Impact on the design flow\n", "abstract": " Networks-on-chip (NoCs) are a scalable interconnects solution to large scale multiprocessor systems on chip and are rapidly becoming reality. As the ratio of embedded cores per I/O pin increases, the run-time observability becomes a bottleneck. Run-time NoC monitoring can alleviate this problem. As NoCs are the result of sophisticated synthesis design flows, monitoring must be taken into account during this process. We present several scalable alternatives for NoC monitoring. The alternatives vary from using physically separated interconnects for user data and monitoring data, to a completely shared single interconnect. For each alternative we evaluate area cost, required design flow modifications, non-intrusiveness and reusability of monitoring resources for application communication traffic. An interesting trade-off is presented showing that what is area efficient requires efforts in modifying the NoC design flow\u00a0\u2026", "num_citations": "48\n", "authors": ["574"]}
{"title": "A monitoring-aware network-on-chip design flow\n", "abstract": " Networks-on-chip (NoC) are a scalable interconnect solution for systems on chip and are rapidly becoming reality. Monitoring is a key enabler for debugging or performance analysis and quality-of-service techniques. The NoC design problem and the NoC monitoring problem cannot be treated in isolation. We propose a monitoring-aware NoC design flow able to take into account the monitoring requirements in general. We illustrate our flow with a debug driven monitoring case study of transaction monitoring. By treating the NoC design and monitoring problems in synergy, the area cost of monitoring can be limited to 3\u201320% in general. We also investigate run-time configuration options for the NoC monitoring system resulting in acceptable configuration times.", "num_citations": "47\n", "authors": ["574"]}
{"title": "Modeling static-order schedules in synchronous dataflow graphs\n", "abstract": " Synchronous dataflow graphs (SDFGs) are used extensively to model streaming applications. An SDFG can be extended with scheduling decisions, allowing SDFG analysis to obtain properties like throughput or buffer sizes for the scheduled graphs. Analysis times depend strongly on the size of the SDFG. SDFGs can be statically scheduled using static-order schedules. The only generally applicable technique to model a static-order schedule in an SDFG is to convert it to a homogeneous SDFG (HSDFG). This conversion may lead to an exponential increase in the size of the graph and to sub-optimal analysis results (e.g., for buffer sizes in multi-processors). We present a technique to model periodic static-order schedules directly in an SDFG. Experiments show that our technique produces more compact graphs compared to the technique that relies on a conversion to an HSDFG. This results in reduced analysis\u00a0\u2026", "num_citations": "42\n", "authors": ["574"]}
{"title": "Intra-task scenario-aware voltage scheduling\n", "abstract": " Modern embedded applications usually have real-time constraints and they have requirements for low energy consumption. At system level, intra-task dynamic voltage scaling (DVS) is one of the most effective techniques for energy reduction. It changes the processor's supply voltage and clock frequency to the lowest level that still allows the real-time constraints to be met. In this paper, we present how intra-task scenarios, which capture correlations between different parts of the application, can be applied on top of existing DVS techniques, making them more effective. Furthermore, we extend our method for automatic discovery of scenarios and adapt it to the DVS requirements. We show that, by augmenting an existing DVS method with scenarios, the average energy consumption of two real-life benchmarks is reduced with 14% to 52%.", "num_citations": "39\n", "authors": ["574"]}
{"title": "Scaling into ambient intelligence\n", "abstract": " Envision the situation that high quality information and entertainment is easily accessible to anyone, anywhere, at any time, and on any device. How realistic is this vision? And what does it require from the underlying technology? Ambient Intelligence (AmI) integrates concepts ranging from ubiquitous computing to autonomous and intelligent systems. An AmI environment will be highly dynamic in many aspects. Underlying technology must be very flexible to cope with this dynamism. The scalability of technology is only one crucial aspect. This paper explores scalability from the processing, the communication, and the software perspectives.", "num_citations": "39\n", "authors": ["574"]}
{"title": "Automated bottleneck-driven design-space exploration of media processing systems\n", "abstract": " Media processing systems often have limited resources and strict performance requirements. An implementation must meet those design constraints while minimizing resource usage and energy consumption. Design-space exploration techniques help system designers to pinpoint bottlenecks in a system for a given configuration. The trade-offs between performance and resources in the design space can guide designers to tailor and tune the system. Many applications in those systems are computationally intensive and can be modeled by a synchronous dataflow graph. We present a bottleneck-analysis-driven technique to explore the design space of those systems automatically and incrementally. The feasibility and efficiency of the technique is demonstrated with experiments on a set of realistic application models ranging from multimedia to digital printing.", "num_citations": "38\n", "authors": ["574"]}
{"title": "Throughput-constrained DVFS for scenario-aware dataflow graphs\n", "abstract": " Dynamic behavior of streaming applications can be effectively modeled by scenario-aware dataflow graphs (SADFs). Many streaming applications must provide timing guarantees (e.g., throughput) to assure their quality-of-service. For instance, a video decoder which is running on a mobile device is expected to deliver a video stream with a specific frame rate. Moreover, the energy consumption of such applications on handheld devices should be as low as possible. This paper proposes a technique to select a suitable multiprocessor DVFS point for each mode (scenario) of a dynamic application described by an SADF. The technique assures strict timing guarantees while minimizing energy consumption. The technique is evaluated by applying it to several streaming applications. It solves the problem faster than the state of the art technique for dataflow graphs. Moreover, the DVFS controller devised using the\u00a0\u2026", "num_citations": "37\n", "authors": ["574"]}
{"title": "A fast and scalable multidimensional multiple-choice knapsack heuristic\n", "abstract": " Many combinatorial optimization problems in the embedded systems and design automation domains involve decision making in multidimensional spaces. The multidimensional multiple-choice knapsack problem (MMKP) is among the most challenging of the encountered optimization problems. MMKP problem instances appear for example in chip multiprocessor runtime resource management and in global routing of wiring in circuits. Chip multiprocessor resource management requires solving MMKP under real-time constraints, whereas global routing requires scalability of the solution approach to extremely large MMKP instances. This article presents a novel MMKP heuristic, CPH (for Compositional Pareto-algebraic Heuristic), which is a parameterized compositional heuristic based on the principles of Pareto algebra. Compositionality allows incremental computation of solutions. The parameterization allows\u00a0\u2026", "num_citations": "36\n", "authors": ["574"]}
{"title": "Vector time and causality among abstract events in distributed computations\n", "abstract": " An important problem in analyzing distributed computations is the amount of information. In event-based models, even for simple applications, the number of events is large and the causal structure is complex. Event abstraction can be used to reduce the apparent complexity of a distributed computation. This paper discusses one important aspect of event abstraction: causality among abstract events. Following Lamport [24], two causality relations are defined on abstract events, called weak and strong precedence. A general theoretical framework based on logical vector time is developed in which several meaningful timestamps for abstract events are derived. These timestamps can be used to efficiently determine causal relationships between arbitrary abstract events. The class of convex abstract events is identified as a subclass of abstract events that is general enough to be widely applicable and restricted\u00a0\u2026", "num_citations": "36\n", "authors": ["574"]}
{"title": "Enhanced time-slotted channel hopping in WSNs using non-intrusive channel-quality estimation\n", "abstract": " Cross-technology interference on the license-free ISM bands has a major negative effect on the performance of Wireless Sensor Networks (WSNs). Channel hopping has been adopted in the Time-Slotted Channel Hopping (TSCH) mode of IEEE 802.15.4e to eliminate blocking of wireless links caused by external interference on some frequency channels. This paper proposes an Enhanced version of the TSCH protocol (ETSCH) which restricts the used channels for hopping to the channels that are measured to be of good quality. The quality of channels is extracted using a new Non-Intrusive Channel-quality Estimation (NICE) technique by performing energy detections in selected idle periods every timeslot. NICE enables ETSCH to follow dynamic interference well, while it does not reduce throughput of the network. It also does not change the protocol, and does not require non-standard hardware. ETSCH uses a\u00a0\u2026", "num_citations": "34\n", "authors": ["574"]}
{"title": "Parametric throughput analysis of scenario-aware dataflow graphs\n", "abstract": " Scenario-aware dataflow graphs (SADFs) efficiently model dynamic applications. The throughput of an application is an important metric to determine the performance of the system. For example, the number of frames per second output by a video decoder should always stay above a threshold that determines the quality of the system. During design-space exploration (DSE) or run-time management (RTM), numerous throughput calculations have to be performed. Throughput calculations have to be performed as fast as possible. For synchronous dataflow graphs (SDFs), a technique exists that extracts throughput expressions from a parameterized SDF in which the execution time of the tasks (actors) is a function of some parameters. Evaluation of these expressions can be done in a negligible amount of time and provides the throughput for a specific set of parameter values. This technique is not applicable to SADFs\u00a0\u2026", "num_citations": "34\n", "authors": ["574"]}
{"title": "Modular model-based supervisory controller design for wafer logistics in lithography machines\n", "abstract": " Development of high-level supervisory controllers is an important challenge in the design of high-tech systems. It has become a significant issue due to increased complexity, combined with demands for verified quality, time to market, ease of development, and integration of new functionality. To deal with these challenges, model-based engineering approaches are suggested as a cost-effective way to support easy adaptation, validation, synthesis, and verification of controllers. This paper presents an industrial case study on modular design of a supervisory controller for wafer logistics in lithography machines. The uncontrolled system and control requirements are modeled independently in a modular way, using small, loosely coupled and minimally restrictive extended finite automata. The multiparty synchronization mechanism that is part of the specification formalism provides clear advantages in terms of\u00a0\u2026", "num_citations": "32\n", "authors": ["574"]}
{"title": "Quality-of-service trade-off analysis for wireless sensor networks\n", "abstract": " Quality of Service (QoS) support for wireless sensor networks (WSN) is a fairly new topic that is gaining more and more interest. This paper introduces a method for determining the node configurations of a WSN such that application-level QoS constraints are met. This is a complex task, since the search space is typically extremely large. The method is based on a recent algebraic approach to Pareto analysis, that we use to reason about QoS trade-offs. It features an algorithm that keeps the working set of possible configurations small, by analysing parts of the network in a modular fashion, and meanwhile discarding configurations that are inferior to other configurations. Furthermore, we give WSN models for two different applications, spatial mapping and target tracking, in which QoS trade-offs are made explicit. Test results for these applications and a heterogeneous WSN combining these two applications show that\u00a0\u2026", "num_citations": "31\n", "authors": ["574"]}
{"title": "Execution-time prediction for dynamic streaming applications with task-level parallelism\n", "abstract": " Programmable multiprocessor systems-on-chip are becoming the preferred implementation platform for embedded streaming applications. This enables using more software components, which leads to large and frequent dynamic variations of data-dependent execution times. In this context, accurate and conservative prediction of execution times helps in maintaining good audio/video quality and reducing energy consumption by dynamic evaluation of the amount of on-chip resources needed by applications. To be effective, multiprocessor systems have to employ the available parallelism. The combination of task-level parallelism and task delay variations makes predicting execution times a very hard problem. So far, under these conditions, no appropriate techniques exist for the conservative prediction of execution times with the required accuracy. In this paper, we present a novel technique for this problem\u00a0\u2026", "num_citations": "31\n", "authors": ["574"]}
{"title": "Exploring trade-offs between performance and resource requirements for synchronous dataflow graphs\n", "abstract": " Synchronous dataflow graphs (SDFGs) are widely used to model streaming applications such as signal processing and multimedia applications. These are often implemented on resource-constrained embedded platforms ranging from PDAs and cell phones to automobile equipment and printing systems. Trade-off analysis between resource usage and performance is critical in the life cycle of those products, from tailoring platforms to target applications at design time to resource management at runtime. We present a trade-off analysis method for SDFGs based on model-checking techniques and leveraging knowledge from the dataflow domain. We develop results to prune the state space of an SDFG for multi-objective model checking without loosing optimality. To achieve scalability to large state spaces, we combine these pruning techniques with pragmatic heuristics. We evaluate our techniques with two sets of\u00a0\u2026", "num_citations": "30\n", "authors": ["574"]}
{"title": "Scenario-aware dataflow\n", "abstract": " Dataflow models have proven their usefulness for specifying signal processing and streaming applications. However, traditional dataflow models such as Synchronous Dataflow (SDF) and Kahn Process Networks (KPN) either lack the capability of expressing the dynamic aspects of modern streaming applications or do not support desirable analysis techniques. The dynamism often originates from various modes of operation in which resource requirements differ considerably. Such scenarios cover for example variations in the amount of data to process or variations in the functionality to perform. Neglecting dynamism may lead to unrealistic performance analysis results and therefore to dimensioning the system inefficiently. To enable obtaining more realistic performance results than with traditional design-time analysable dataflow models, a scenario-aware generalisation of SDF was recently introduced. Next to representing the data processing part of an application, this Scenario-Aware Dataflow model (SADF) also captures the control part responsible for determining the various scenarios in which the data processing part may operate. Although improving the expressive power of traditional designtime analysable dataflow models with the possibility to express (more forms of) dynamism, design-time analysis of correctness and performance remains possible. This report presents SADF in detail, including all features for specifying complex correlations between scenario occurrences. The potential of using SADF for modelling and analysing modern streaming applications is illustrated for an MPEG-4 SP decoder and an MP3 decoder.", "num_citations": "30\n", "authors": ["574"]}
{"title": "Process algebra in PVS\n", "abstract": " The aim of this work is to investigate mechanical support for process algebra, both for concrete applications and theoretical properties. Two approaches are presented using the verification system PVS. One approach declares process terms as an uninterpreted type and specifies equality on terms by axioms. This is convenient for concrete applications where the rewrite mechanisms of PVS can be exploited. For the verification of theoretical results, often induction principles are needed. They are provided by the second approach where process terms are defined as an abstract datatype with a separate equivalence relation.", "num_citations": "30\n", "authors": ["574"]}
{"title": "Performance analysis of weakly-consistent scenario-aware dataflow graphs\n", "abstract": " The timed dataflow model of computation is a useful performance analysis tool for electronic system level design automation and embedded software synthesis. Its determinism gives it strong analyzability properties. Its monotonic temporal behavior provides hard real-time guarantees on throughput and latency. It is expressive enough to cover a large class of applications and platforms. The trend however, in both embedded applications and their platforms is to become more dynamic, reaching the limits of what the model can express and analyze with tight performance guarantees. Scenario-aware dataflow (SADF) allows more dynamism to be expressed, introducing a controlled amount of non-determinism into the model to represent different scenarios of behavior. We investigate so-called weakly consistent graphs in which the scenario changes are not tightly coupled with periods of repetitive behavior of the static\u00a0\u2026", "num_citations": "29\n", "authors": ["574"]}
{"title": "Resource-efficient routing and scheduling of time-constrained streaming communication on networks-on-chip\n", "abstract": " Network-on-chip-based multiprocessor systems-on-chip are considered as future embedded systems platforms. One of the steps in mapping an application onto such a parallel platform involves scheduling the communication on the network-on-chip. This paper presents different scheduling strategies that minimize resource usage by exploiting all scheduling freedom offered by networks-on-chip. It also introduces a technique to take the dynamism in applications into account when scheduling the communication of an application on the network-on-chip while minimizing the resource usage. Our experiments show that resource-utilization is improved when compared to existing techniques.", "num_citations": "29\n", "authors": ["574"]}
{"title": "RASW: a run-time adaptive sliding window to improve viola-jones object detection\n", "abstract": " In recent years accurate algorithms for detecting objects in images have been developed. Among these algorithms, the object detection scheme proposed by Viola and Jones gained great popularity, especially after the release of high-quality face classifiers by the OpenCV group. However, as any other sliding-window based object detector, it is affected by a strong increase in the computational cost as the size of the scene grows. Especially in real-time applications, a search strategy based on a sliding window can be computationally too expensive. In this paper, we propose an efficient approach to adapt at run time the sliding window step size in order to speed-up the detection task without compromising the accuracy. We demonstrate the effectiveness of the proposed Run-time Adaptive Sliding Window (RASW) in improving the performance of Viola-Jones object detection by providing better throughput-accuracy\u00a0\u2026", "num_citations": "28\n", "authors": ["574"]}
{"title": "Scenario selection and prediction for DVS-aware scheduling of multimedia applications\n", "abstract": " Modern multimedia applications usually have real-time constraints and they are implemented using application-domain specific embedded processors. Dimensioning a system requires accurate estimations of resources needed by the applications. Overestimation leads to over-dimensioning. For a good resource estimation, all the cases in which an application can run must be considered. To avoid an explosion in the number of different cases, those that are similar with respect to required resources are combined into, so called application scenarios. This paper presents a methodology and a tool that can automatically detect the most important variables from an application and use them to select and dynamically predict scenarios, with respect to the necessary time budget, for soft real-time multimedia applications. The tool was tested for three multimedia applications. Using a proactive scenario-based\u00a0\u2026", "num_citations": "28\n", "authors": ["574"]}
{"title": "A calculator for Pareto points\n", "abstract": " This paper presents the Pareto calculator, a tool for compositional computation of Pareto points, based on the algebra of Pareto points. The tool is a useful instrument for multidimensional optimisation problems, design-space exploration and development of quality management and control strategies. Implementations and their complexity of the operations of the algebra are discussed. In particular, a generalisation of the well-known divide-and-conquer algorithm was discussed to compute the Pareto points (optimal solutions) from a set of possible configurations, also known as the maximal vector or skyline problem. The generalisation lies in the fact that we allow for partially ordered domains instead of only totally ordered ones. The calculator is available through the following url: http://www.es.ele.tue.nl/pareto", "num_citations": "28\n", "authors": ["574"]}
{"title": "Topology management and TSCH scheduling for low-latency convergecast in in-vehicle WSNs\n", "abstract": " Wireless sensor networks (WSNs) are considered as a promising solution in intravehicle networking to reduce wiring and production costs. This application requires reliable and real-time data delivery, while the network is very dense. The time-slotted channel hopping (TSCH) mode of the IEEE 802.15.4 standard provides a reliable solution for low-power networks through guaranteed medium access and channel diversity. However, satisfying the stringent requirements of in-vehicle networks is challenging and demands for special consideration in network formation and TSCH scheduling. This paper targets convergecast in dense in-vehicle WSNs, in which all nodes can potentially directly reach the sink node. A cross-layer low-latency topology management and TSCH scheduling (LLTT) technique is proposed that provides a very high timeslot utilization for the TSCH schedule and minimizes communication latency\u00a0\u2026", "num_citations": "27\n", "authors": ["574"]}
{"title": "Efficient retiming of multirate DSP algorithms\n", "abstract": " Multirate digital signal processing (DSP) algorithms are often modeled with synchronous dataflow graphs (SDFGs). A lower iteration period implies a faster execution of a DSP algorithm. Retiming is a simple but efficient graph transformation technique for performance optimization, which can decrease the iteration period without affecting functionality. In this paper, we deal with two problems: feasible retiming-retiming a SDFG to meet a given iteration period constraint, and optimal retiming-retiming a SDFG to achieve the smallest iteration period. We present a novel algorithm for feasible retiming and based on that one, a new algorithm for optimal retiming, and prove their correctness. Both methods work directly on SDFGs, without explicitly converting them to their equivalent homogeneous SDFGs. Experimental results show that our methods give a significant improvement compared to the earlier methods.", "num_citations": "27\n", "authors": ["574"]}
{"title": "Resource-efficient routing and scheduling of time-constrained network-on-chip communication\n", "abstract": " Network-on-chip-based multiprocessor systems-on-chip are considered as future embedded systems platforms. One of the steps in mapping an application onto such a parallel platform involves scheduling the communication on the network-on-chip. This paper presents different scheduling strategies that minimize resource usage by exploiting all scheduling freedom offered by networks-on-chip. Our experiments show that resource-utilization is improved when compared to existing techniques", "num_citations": "27\n", "authors": ["574"]}
{"title": "Deciding life-cycle inheritance on Petri nets\n", "abstract": " One of the key issues of object-oriented modeling is inheritance. It allows for the definition of a subclass that inherits features from some super-class. When considering the dynamic behavior of objects, as captured by their life cycles, there is no general agreement on the meaning of inheritance. Basten and Van der Aalst introduced the notion of life-cycle inheritance for this purpose. Unfortunately, the search tree needed for deciding life-cycle inheritance is in general prohibitively large. This paper presents a backtracking algorithm to decide life-cycle inheritance on Petri nets. The algorithm uses structural properties of both the base life cycle and the potential sub life cycle to prune the search tree. Test cases show that the results are promising.", "num_citations": "27\n", "authors": ["574"]}
{"title": "An algebraic semantics for hierarchical P/T nets\n", "abstract": " The first part of this paper gives an algebraic semantics for Place/Transition nets in terms of an algebra which is based on the process algebra ACP. The algebraic semantics is such that a P/T net and its term representation have the same operational behavior. As opposed to other approaches in the literature, the actions in the algebra do not correspond to the firing of a transition, but to the consumption or production of tokens. Equality of P/T nets can be determined in a purely equational way.             The second part of this paper extends the results to hierarchical P/T nets. It gives a compositional algebraic semantics for both their complete operational behavior and their high-level, observable behavior. By means of a non-trivial example, the Alternating-Bit Protocol, it is shown that the notions of abstraction and verification in the process algebra ACP can be used to verify in an equational way whether a\u00a0\u2026", "num_citations": "27\n", "authors": ["574"]}
{"title": "Model-based design of adaptive embedded systems\n", "abstract": " It is with great pleasure that I welcome you to the final book on the ESI project Octopus, the last project funded under the Dutch BSIK programme Embedded Systems. This project has been executed by ESI, Oc\u00e9, Delft University of Technology, Eindhoven University of Technology, the University of Twente, and Radboud University Nijmegen. The project started in July 2007, ended June 2012, and encompasses an overall volume of 92 FTE. As for all of ESI\u2019s large projects, Octopus has followed the by now well-known industry-as-laboratory paradigm, in which scientific research is performed in the context of an industrial case. For Octopus, the case has been defined in the context of the development of high-end adaptive professional printing systems, thereby developing and using a model-based approach. Three main lines of attention were addressed:\u2022 Data path design: the development and use of analysis\u00a0\u2026", "num_citations": "24\n", "authors": ["574"]}
{"title": "Adaptive workflow: an approach based on inheritance\n", "abstract": " Today's information systems do not support adaptive workflow: either the information system abstracts from the workflow processes at hand and focuses on the management of data and the execution of individual tasks via applications or the workflow is supported by the information system but it is hard to handle changes. This paper addresses this problem by classifying the types of changes. Based on this classification, issues such as syntactic/semantic correctness, case transfer, and management information are discussed. It turns out that the trade-off between flexibility and support raises challenging questions. Some of these questions can be answered using advanced inheritance notions. This paper provides four inheritance-preserving transformation rules which can be used to avoid the typical problems related to change.", "num_citations": "24\n", "authors": ["574"]}
{"title": "Static rate-optimal scheduling of multirate DSP algorithms via retiming and unfolding\n", "abstract": " This paper presents an exact method and a heuristic method for static rate-optimal multiprocessor scheduling of real-time multi rate DSP algorithms represented by synchronous data flow graphs (SDFGs). Through exploring the state-space generated by a self-timed execution (STE) of an SDFG, a static rate-optimal schedule via explicit retiming and implicit unfolding can be found by our exact method. By constraining the number of concurrent firings of actors of an STE, the number of processors used in a schedule can be limited. Using this, we present a heuristic method for processor-constrained rate-optimal scheduling of SDFGs. Both methods do not explicitly convert an SDFG to its equivalent homogenous SDFG. Our experimental results show that the exact method gives a significant improvement compared to the existing methods, our heuristic method further reduces the number of processors used.", "num_citations": "23\n", "authors": ["574"]}
{"title": "Profiling driven scenario detection and prediction for multimedia applications\n", "abstract": " Modern multimedia applications usually have real-time constraints and they are implemented using heterogeneous multiprocessor systems-on-chip. Dimensioning a system requires accurate estimations of resources needed by the applications. Overestimation leads to over-dimensioning. For a good resource estimation, all the cases in which an application can run must be considered. To avoid an explosion in the number of different cases, those that are similar with respect to required resources are combined into, so called, scenarios. This paper presents a method and a tool that can automatically detect the most important variables from an application and use them to define and dynamically predict scenarios, with respect to the necessary time budget, for soft real-time multimedia applications. The tool was tested for two multimedia applications. Using a proactive scenario-based scheduler based on the scenarios\u00a0\u2026", "num_citations": "23\n", "authors": ["574"]}
{"title": "Cluster-based partial-order reduction\n", "abstract": " The verification of concurrent systems through an exhaustive traversal of the state space suffers from the infamous state-space-explosion problem, caused by the many interleavings of actions of different processes in the system. Partial-order reduction is a well-known technique to tackle this problem. In this paper, we present an enhancement of the partial-order-reduction scheme of Holzmann and Peled that uses the hierarchical structure of concurrent systems. Our technique tries to contain dependencies between actions within clusters of processes, capitalizing on the independence of actions in different clusters to reduce the state space to be verified while preserving properties of interest. The paper starts with a formalization of the partial-order-reduction technique and continues with a presentation of our enhanced technique, including a correctness argument. The new technique has been implemented in\u00a0\u2026", "num_citations": "23\n", "authors": ["574"]}
{"title": "Mapping of synchronous dataflow graphs on MPSoCs based on parallelism enhancement\n", "abstract": " Multi-processor systems-on-chips are widely adopted in implementing modern streaming applications to satisfy the ever increasing computation requirements. To take advantage of this kind of platform, it is necessary to map tasks of the application properly to different processors, so as to fully exploit the inherent task-level parallelism and satisfy the stringent timing requirements. We propose the Parallelism Graph to capture the task-level parallelism of the application and transform the mapping problem to a graph partitioning problem. The graph partitioning problem is formulated as an Integer Linear Programming problem, which is solved optimally using the ILP solver. To reduce the complexity, a two-step local search algorithm, i.e., the greedy partition and refinement algorithm, is proposed. Since one-shot heuristics cannot guarantee the solution quality, evolutionary algorithms are widely used to search the solution\u00a0\u2026", "num_citations": "22\n", "authors": ["574"]}
{"title": "xCPS: a tool to explore cyber physical systems\n", "abstract": " Cyber-Physical Systems (CPS) play an important role in the modern high-tech industry. Designing such systems is an especially challenging task due to the multi-disciplinary nature of these systems, and the range of abstraction levels involved. To facilitate hands-on experience with such systems, we develop a cyber-physical platform that aids in both research and education on CPS. This paper describes this platform, which contains all typical CPS components. The platform is used in various research and education projects for bachelor, master, and PhD students. We discuss the platform and illustrate its use with a number of projects and the educational opportunities they provide.", "num_citations": "22\n", "authors": ["574"]}
{"title": "Proactive reconfiguration of wireless sensor networks\n", "abstract": " Network dynamics, such as mobility and increase in network load, can influence the performance of a Wireless Sensor Network (WSN). In this paper, we introduce a method which exploits design-time knowledge of the application scenario dynamics to construct a proactive run-time reconfiguration approach. The approach anticipates for the impact that predefined dynamic events can have on the performance of the WSN by switching between various modes of operation defined at design-time. A mode defines the values for the controllable parameters of the network protocol stack. Our approach explicitly differentiates between parameters that can be adapted locally, per node, and those that should be considered globally for the whole WSN. Design-time definition of modes results in a very low run-time overhead as we only require detection of the mode to use and a low overhead synchronization to change global\u00a0\u2026", "num_citations": "22\n", "authors": ["574"]}
{"title": "Kahn process networks and a reactive extension\n", "abstract": " Kahn andMacQueen have introduced a generic class of determinate asynchronous data-flow applications, called Kahn Process Networks (KPNs) with an elegant mathematical model and semantics in terms of Scott-continuous functions on data streams together with an implementation model of independent asynchronous sequential programs communicating through FIFO buffers with blocking read and non-blocking write operations. The two are related by the Kahn Principle which states that a realization according to the implementationmodel behaves as predicted by the mathematical function. Additional steps are required to arrive at an actual implementation of a KPN to take care of scheduling of independent processes on a single processor and to manage communication buffers. Because of the expressiveness of the KPN model, buffer sizes and schedules cannot be determined at design time in general\u00a0\u2026", "num_citations": "22\n", "authors": ["574"]}
{"title": "System models in wireless sensor networks\n", "abstract": " \u00c5\u00d3 \u00d0\u00d7 \u00d4\u00d0 \u00dd \u00d2 \u00d1\u00d4\u00d3\u00d6\u00d8 \u00d2\u00d8 \u00d6\u00d3\u00d0 \u00d2 \u00d1 \u00d2\u00dd \u00d6 \u00d2\u00d8\u00d7 \u00d4\u00d0 \u00d2\u00d7 \u00ba \u00cc \u00d6\u00d3\u00d7 \u00d3\u00d4 \u00d3 \u00d4\u00d4\u00d0 \u00d0 \u00d8\u00dd \u00d3 \u00d1\u00d3 \u00d0\u00d7 \u00d6\u00d7 \u00d9\u00d0\u00d8\u00d7 \u00d2 \u00db \u00d6 \u00d2 \u00d3 types of models \u00d3\u00d6 \u00da \u00d2\u00d7 \u00dd\u00d7 \u00d8 \u00d1 \u00d3\u00d1\u00d4\u00d3\u00d2 \u00d2\u00d8 range of system components \u00d8 \u00d8 \u00d6 \u00d3 \u00d2\u00d8 \u00d6\u00d7 \u00d8 \u00d8\u00d3 \u00d1\u00d3 \u00d0 \u00d2 \u00d2\u00d7\u00d7 \u00d3\u00d6\u00d8\u00d1 \u00d2\u00d8 \u00d3 levels of detail \u00d4\u00d6\u00d3\u00da \u00d2 \u00d1\u00d3 \u00d0\u00d7 \u00ba \u00cf \u00d2\u00d8\u00d6\u00d3 \u00d9 \u00d0\u00d7\u00d7 \u00d8 \u00d3\u00d2\u00d7 \u00dd\u00d7 \u00d8 \u00d1 \u00d3\u00d6 \u00d1\u00d3 \u00d0\u00d7 \u00d3 \u00d2 \u00d8\u00db\u00d3\u00d6 \u00d1\u00d7 \u00dd\u00d7 \u00d8 \u00d1\u00d7\u00d7 \u00d9\u00d7\u00d7 \u00d2\u00d7 \u00d3\u00d6 \u00d2 \u00d8\u00db\u00d3\u00d6\u00d7 \u00d4\u00d6\u00d3\u00da \u00d8 \u00dc\u00d3\u00d2\u00d3\u00d1\u00dd \u00d3 \u00dc\u00d7 \u00d8 \u00d2 \u00d6\u00d7 \u00d6 \u00d3\u00d2 \u00d1\u00d3 \u00d0\u00d7 \u00d2 \u00d8 \u00d6\u00d1\u00d7 \u00d3 \u00d8 \u00d4\u00d6\u00d7 \u00d2\u00d8 \u00d0\u00d7\u00d7 \u00d8 \u00d3\u00d2 \u00d6 \u00d1 \u00db\u00d3\u00d6 \u00d2 \u00d0 \u00d8 \u00dc \u00d1\u00d4\u00d0 \u00d4\u00d4\u00d0 \u00d8 \u00d3\u00d2\u00d7 \u00d3 \u00d1\u00d3 \u00d0\u00d7 \u00d2 \u00d8 \u00d6\u00d7 \u00d6 \u00d0 \u00d8 \u00d6 \u00d8\u00d9\u00d6 \u00ba\u00d7 \u00d3\u00d2 \u00d8 \u00d2\u00d7 \u00d8 \u00d2 \u00d2 \u00da \u00d0\u00d3\u00d4 \u00d2 \u00d8 \u00d0\u00d7\u00d7 \u00d8 \u00d3\u00d2 \u00d6 \u00d1 \u00db\u00d3\u00d6 \u00d2 \u00d8 \u00dc\u00d3\u00d2\u00d3\u00d1\u00dd \u00db\u00d7 \u00d9\u00d7\u00d7 \u00d4\u00d3\u00d7\u00d7 \u00d0 \u00d9\u00d8\u00d9\u00d6 \u00d1\u00d3 \u00d0 \u00d2 \u00d6 \u00d8 \u00d3\u00d2\u00d7 \u00d2 \u00d8 \u00d6 \u00d3 \u00db \u00d6 \u00d0\u00d7\u00d7\u00d7 \u00d2\u00d7 \u00d3\u00d6 \u00d2 \u00d8\u00db\u00d3\u00d6\u00d7 \u00ba", "num_citations": "22\n", "authors": ["574"]}
{"title": "Iterative compilation for energy reduction\n", "abstract": " The rapidly increasing number of architectural changes in embedded processors puts compiler technology under an enormous stress. This is emphasized by new demands on compilers, like requirements to reduce static code size, energy consumption or power dissipation. Iterative compilation has been proposed as an approach to find the best sequence of optimizations (such as loop transformations) for an application, in order to improve its performance. In this paper, we study both the effect of several loop transformations on energy consumption as well as the possibility of using the iterative compilation method in order to find the best compiled code for energy. From analyzed benchmarks, we conclude that in most cases the decrease in energy consumption is coming together with performance improvement. However, the best compiled code for performance is not always the best one for energy. Thus, a\u00a0\u2026", "num_citations": "22\n", "authors": ["574"]}
{"title": "Simulating and analyzing railway interlockings in ExSpect\n", "abstract": " This paper describes a study on simulating and analyzing interlocking specifications in the Interlocking Specification Language (ISL), using the tool ExSpect. ExSpect is a toolkit based on the theory of coloured Petri nets.", "num_citations": "22\n", "authors": ["574"]}
{"title": "Linking Specifications, Abstraction, and Debugging\n", "abstract": " Designing and implementing a visual debugger for distributed programs is a significant challenge. Data about executing programs must be gathered and collated without unduly modifying the behaviour of the program under study. The data must be displayed in ways that are understandable to the user. One aspect of this problem is that human users are easily overwhelmed by huge amounts of detail, so the debugger must be capable of providing a variety of displays, ranging from high-level views of the entire execution to low-level views of primitive events. If the debugger is to be used interactively, all this must happen fairly quickly.", "num_citations": "22\n", "authors": ["574"]}
{"title": "The FitOptiVis ECSEL project: Highly efficient distributed embedded image/video processing in cyber-physical systems\n", "abstract": " Cyber-Physical Systems (CPS) are systems that are in feedback with their environment, possibly with humans in the loop. They are often distributed with sensors and actuators, smart, adaptive and predictive and react in real-time. Image-and video-processing pipelines are a prime source for environmental information improving the possibilities of active, relevant feedback. In such a context, FitOptiVis aims to provide end-to-end multi-objective optimization for imaging and video pipelines of CPS, with emphasis on energy and performance, leveraging on a reference architecture, supported by low-power, high-performance, smart devices, and by methods and tools for combined design-time and run-time multi-objective optimization within system and environment constraints.", "num_citations": "21\n", "authors": ["574"]}
{"title": "Compositional specification of functionality and timing of manufacturing systems\n", "abstract": " This paper introduces a formal modeling approach for compositional specification of both functionality and timing of manufacturing systems. Functionality aspects can be considered orthogonally to timing aspects. The functional aspects are specified using two abstraction levels; high-level activities and lower level actions. Design of a functionally correct controller is possible by looking only at the activity level, abstracting from the different execution orders of actions and their timing. As a result, controller design can be performed on a much smaller state space compared to an explicit model where timing and actions are present. The performance of the controller can be analyzed and optimized by taking into account the timing characteristics. Since formal semantics are given in terms of a (max, +) state space, various existing performance analysis techniques can be used. We illustrate the approach, including\u00a0\u2026", "num_citations": "21\n", "authors": ["574"]}
{"title": "Performance analysis and controller improvement for linear systems with (m, k)-firm data losses\n", "abstract": " This paper describes methods for the analysis and design of control applications with real-time constraints, which allow data losses in the sensing-to-actuation path governed by the property of (m, k)-firmness. An automaton consisting of open- and closed-loop dynamics and a graph representing (m, k)-firmness defines the overall system behavior as a constrained switched linear system. The worst-case quadratic cost is analyzed for a given optimal linear quadratic regulator design. A simple analytic upper bounding method is compared to a method based on solving a (computationally more complex) semidefinite program. Furthermore, control design methods for performance improvement for the worst case are presented. A known LMI-based method is compared to an iterative controller improvement scheme inspired by ideas from dynamic programming. Conservatism and computational effort of the methods are\u00a0\u2026", "num_citations": "21\n", "authors": ["574"]}
{"title": "Process algebra for parallel and distributed processing\n", "abstract": " Collects the Latest Research Involving the Application of Process Algebra to ComputingExploring state-of-the-art applications, Process Algebra for Parallel and Distributed Processing shows how one formal method of reasoning-process algebra-has become a powerful tool for solving design and implementation challenges of concurrent systems. Parallel Pr", "num_citations": "21\n", "authors": ["574"]}
{"title": "Multiconstraint static scheduling of synchronous dataflow graphs via retiming and unfolding\n", "abstract": " Synchronous dataflow graphs (SDFGs) are widely used to represent digital signal processing algorithms and streaming media applications. This paper presents several methods for binding and scheduling SDFGs on a multiprocessor platform. Exploring the state space generated by a self-timed execution (STE) of an SDFG, we present an exact method for static rate-optimal scheduling of SDFGs via implicit retiming and unfolding. By modeling a constraint as an extra enabling condition for the STE, we get a constrained STE which implies a schedule under the constraint. We present a general framework for scheduling SDFGs under constraints on the number of processors, buffer sizes, auto-concurrency, or combinations of them. Exploring the state space generated by the constrained STE, we can check whether a retiming, which leads to a rate-optimal schedule under the processor (or memory) constraint, exists\u00a0\u2026", "num_citations": "20\n", "authors": ["574"]}
{"title": "Online multi-face detection and tracking using detector confidence and structured SVMs\n", "abstract": " Online detection and tracking of a variable number of faces in video is a crucial component in many real-world applications ranging from video-surveillance to online gaming. In this paper we propose FAST-DT, a fully automated system capable of detecting and tracking a variable number of faces online without relying on any scene-specific cues. FAST-DT integrates a generic face detector with an adaptive structured output SVM tracker and uses the detector's continuous confidence to solve the target creation and removal problem. We improve in recall and precision over a state-of-the-art method on a video dataset of more than two hours while providing in addition an increase in throughput.", "num_citations": "20\n", "authors": ["574"]}
{"title": "Practical instruction set design and compiler retargetability using static resource models\n", "abstract": " The design of application (-domain) specific instruction-set processors (ASIPs), optimized for code size, has traditionally been accompanied by the necessity to program assembly, at least for the performance critical parts of the application. The highly encoded instruction sets simply lack the orthogonal structure present in e.g. VLIW processors, that allows efficient compilation. This lack of efficient compilation tools has also severely hampered the design space exploration of code-size efficient instruction sets, and correspondingly, their tuning to the application domain. In Zhao et al (Proc. 14th Int. Symp. on System Synthesis, 2001), a practical method is demonstrated to model a broad class of highly encoded instruction sets in terms of virtual resources easily interpreted by classic resource constrained schedulers (such as the popular list-scheduling algorithm), thereby allowing efficient compilation with well understood\u00a0\u2026", "num_citations": "20\n", "authors": ["574"]}
{"title": "Partial-order process algebra (and its relation to Petri nets)\n", "abstract": " To date, many different formalisms exist for describing and analyzing the behavior of concurrent systems. Petri nets and process algebras are two well-known classes of such formalisms. Petri-net theory is well suited for reasoning about concurrent systems in a partial-order framework; it handles causal relationships between actions of concurrent systems in an explicit way. Process algebras, on the other hand, often provide a total-order framework, which means that information about causalities is not always accurate. This chapter illustrates how to develop a partial-order process algebra in the style of ACP. It is shown how to extend such an algebraic theory with a causality mechanism inspired by Petri-net theory. In addition, the chapter clarifies the concepts of interleaving and non-interleaving process algebra; total-order semantics for concurrent systems are often incorrectly referred to as interleaving semantics.", "num_citations": "20\n", "authors": ["574"]}
{"title": "Dependable interference-aware time-slotted channel hopping for wireless sensor networks\n", "abstract": " IEEE 802.15.4 Time-Slotted Channel Hopping (TSCH) aims to improve communication reliability in Wireless Sensor Networks (WSNs) by reducing the impact of the medium access contention, multipath fading, and blocking of wireless links. While TSCH outperforms single-channel communications, cross-technology interference on the license-free ISM bands may affect the performance of TSCH-based WSNs. For applications such as in-vehicle networks for which interference is dynamic over time, it leads to non-guaranteed reliability of the communications over time. This article proposes an Enhanced version of the TSCH protocol together with a Distributed Channel Sensing technique (ETSCH+DCS) that dynamically detects good quality channels to be used for communication. The quality of channels is extracted using a combination of a central and a distributed channel-quality estimation technique. The central\u00a0\u2026", "num_citations": "19\n", "authors": ["574"]}
{"title": "Schedule-extended synchronous dataflow graphs\n", "abstract": " Synchronous dataflow graphs (SDFGs) are used extensively to model streaming applications. An SDFG can be extended with scheduling decisions, allowing SDFG analysis to obtain properties, such as throughput or buffer sizes for the scheduled graphs. Analysis times depend strongly on the size of the SDFG. SDFGs can be statically scheduled using static-order schedules. The only generally applicable technique to model a static-order schedule in an SDFG is to convert it to a homogeneous SDFG (HSDFG). This may lead to an exponential increase in the size of the graph and to suboptimal analysis results (e.g., for buffer sizes in multiprocessors). We present techniques to model two types of static-order schedules, i.e., periodic schedules and periodic single appearance schedules, directly in an SDFG. Experiments show that both techniques produce more compact graphs compared to the technique that relies on\u00a0\u2026", "num_citations": "19\n", "authors": ["574"]}
{"title": "On-demand data forwarding for automatic adaptation of data propagation in WBANs\n", "abstract": " Practical experience reveals the characteristic properties of Wireless Body Area Networks (WBANs), signifying the need for a well-designed communication protocol. High mobility, stringent resource constraints, and low and time-variant quality of wireless links are some of the challenging issues in WBANs. Typical applications further have varying Quality-of-Service requirements and demand reliable and fast data transmission at low energy cost. This paper proposes a simple, robust, and optimized protocol for data propagation in WBANs. A hybrid design approach is proposed that automatically adapts the network topology according to the connectivity status of the network. An on-demand data forwarding mechanism combined with an epidemic data propagation strategy realize a proper data delivery and robustness while minimizing the idle listening and unnecessary data forwarding. Several experiments using\u00a0\u2026", "num_citations": "19\n", "authors": ["574"]}
{"title": "Pareto analysis with uncertainty\n", "abstract": " Pareto analysis is a broadly applicable method to model and analyze tradeoffs in multi-objective optimization problems. The set of Pareto optimal solutions is guaranteed to contain the best solution for any arbitrary cost function or selection procedure. This work introduces a method to explicitly take uncertainty into account during Pareto analysis. A solution is not modeled by a single point in the solution space, but rather by a set of such points. This is useful in settings with much uncertainty, such as during model-based design space exploration for embedded systems. A bounding-box abstraction is introduced as a finite representation of Pareto optimal solutions under uncertainty. It is shown that the set of Pareto optimal solutions in the proposed approach still captures exactly the potentially best solutions for any cost function as well as any way of reducing the amount of uncertainty. During model-based design\u00a0\u2026", "num_citations": "19\n", "authors": ["574"]}
{"title": "Analysing QoS trade-offs in wireless sensor networks\n", "abstract": " Quality of Service (QoS) support for wireless sensor networks (WSN) is a fairly new topic that is gaining more and more interest. This paper introduces a method for configuring the nodes of a WSN such that application-level QoS constraints are met. This is a complex task, since the search space is typically extremely large. The method is based on a recent algebraic approach to Pareto analysis, that we use to reason about QoS trade-offs. It features an algorithm that keeps the working set of possible configurations small, by analysing parts of the network in a hierarchical fashion, and meanwhile discarding configurations that are inferior to other configurations. Furthermore, we give WSN models for two different applications, in which QoS trade-offs are made explicit. Test results show that the models are accurate and that the method is scalable and thus practically usable for WSN, even with large numbers of nodes.", "num_citations": "19\n", "authors": ["574"]}
{"title": "Robustness analysis of multiprocessor schedules\n", "abstract": " Tasks executing on general purpose multiprocessor platforms exhibit variations in their execution times. As such, there is a need to explicitly consider robustness, i.e., tolerance to these fluctuations. This work aims to quantify the robustness of schedules of directed acyclic graphs (DAGs) on multiprocessors by defining probabilistic robustness metrics and to present a new approach to perform robustness analysis to obtain these metrics. Stochastic execution times of tasks are used to compute completion time distributions which are then used to compute the metrics. To overcome the difficulties involved with the max operation on distributions, a new curve fitting approach is presented using which we can derive a distribution from a combination of analytical and limited simulation based results. The approach has been validated on schedules of time-critical applications in ASML wafer scanners.", "num_citations": "18\n", "authors": ["574"]}
{"title": "Fast multiprocessor scheduling with fixed task binding of large scale industrial cyber physical systems\n", "abstract": " Latest trends in embedded platform architectures show a steady shift from high frequency single core platforms to lower-frequency but highly-parallel execution platforms. Scheduling applications with stringent latency requirements on such multiprocessor platforms is challenging. Our work is motivated by the scheduling challenges faced by ASML, the world's leading provider of wafer scanners. A wafer scanner is a complex cyber-physical system that manipulates silicon wafers with extreme accuracy at high throughput. Typical control applications of the wafer scanner consist of thousands of precedence-constrained tasks with latency requirements. Machines are customized so that precise characteristics of the control applications to be scheduled and the execution platform are only known during machine start-up. This results in large-scale scheduling problems that need to be solved during start-up of the machine\u00a0\u2026", "num_citations": "18\n", "authors": ["574"]}
{"title": "Dynamic data prioritization for quality-of-service differentiation in heterogeneous wireless sensor networks\n", "abstract": " In many applications of Wireless Sensor Networks (WSNs), heterogeneity is a common property in terms of different sensor types and different circumstances like node location, link quality, and local node density. In many applications, there are several different sensor types with entirely different Quality-of-Service (QoS) requirements. The requirements may also vary over time according to the application scenario and also due to network dynamics. Different requirements appeal different approaches while forwarding sensed data through a multi-hop communication network. This paper proposes a dynamic priority assignment strategy to be used for data routing in heterogeneous WSNs aiming to fairly propagate information according to its importance and requirements. To cope with heterogeneity and dynamics, nodes in the routing path dynamically compute priorities for individual data items according to the\u00a0\u2026", "num_citations": "18\n", "authors": ["574"]}
{"title": "Enhancing partial-order reduction via process clustering\n", "abstract": " Partial-order reduction is a well-known technique to cope with the state-space-explosion problem in the verification of concurrent systems. Using the hierarchical structure of concurrent systems, we present an enhancement of the partial-order-reduction scheme of G.J. Holzman and D. Peled (1995) and D. Peled (1994). A prototype of the new algorithm has been implemented on top of the verification tool SPIN. The first experimental results are encouraging.", "num_citations": "18\n", "authors": ["574"]}
{"title": "Integrated model-driven design-space exploration for embedded systems\n", "abstract": " Embedded systems and their design trajectories are becoming increasingly complex, and there is a growing demand for performance, reliability, energy efficiency and low cost. To cope with these challenges, decision making early in the development trajectory needs to be supported by appropriate modeling and analysis. To achieve this support, we need to find the modeling abstractions that allow extensive design-space exploration, tune these modeling abstractions towards the users, and integrate support for different types of modeling and analysis.", "num_citations": "17\n", "authors": ["574"]}
{"title": "A blueprint for system-level performance modeling of software-intensive embedded systems\n", "abstract": " Exploration of design alternatives and estimation of their key performance metrics such as latency and energy consumption is essential for making the proper design decisions in the early phases of system development. Often, high-level models of the dynamic behavior of the system are used for the analysis of design alternatives. Our work presents a blueprint for building efficient and re-usable models for this purpose. It builds on the well-known Y-chart pattern in that it gives more structure for the proper modeling of interaction on shared resources that plays a prominent role in software-intensive embedded systems. We show how the blueprint can be used to model a small yet illustrative example system with the Uppaal tool, and with the Java general-purpose programming language, and reflect on their respective strengths and weaknesses. The Java-based approach has resulted in a very flexible and fast\u00a0\u2026", "num_citations": "16\n", "authors": ["574"]}
{"title": "Memory-constrained static rate-optimal scheduling of synchronous dataflow graphs via retiming\n", "abstract": " Synchronous dataflow graphs (SDFGs) are widely used to model digital signal processing (DSP) and streaming media applications. In this paper, we use retiming to optimize SDFGs to achieve a high throughput with low storage requirement. Using a memory constraint as an additional enabling condition, we define a memory constrained self-timed execution of an SDFG. Exploring the state-space generated by the execution, we can check whether a retiming exists that leads to a rate-optimal schedule under the memory constraint. Combining this with a binary search strategy, we present a heuristic method to find a proper retiming and a static scheduling which schedules the retimed SDFG with optimal rate (i.e., maximal throughput) and with as little storage space as possible. Our experiments are carried out on hundreds of synthetic SDFGs and several models of real applications. Differential synthetic graph results\u00a0\u2026", "num_citations": "16\n", "authors": ["574"]}
{"title": "Analyzing execution traces: critical-path analysis and distance analysis\n", "abstract": " System designers make trade-offs between metrics of interest such as execution time, functional quality and cost to create a properly balanced system. Execution traces, which are sequences of timestamped start and end events of system tasks, are a general and powerful means to understand the system behavior that gives rise to these trade-offs. Such traces can be produced by, e.g., executable models or prototype systems. Their interpretation, however, often is non-trivial. We present two automated analysis techniques that work on execution traces to help the system designer with interpretation. First, critical-path analysis can be used to answer the typical \u201cwhat is the bottleneck\u201d question, and we extend earlier work of [16] with a technique that uses application information to refine the analysis. Second, we define a pseudo-metric on execution traces, which is useful for calibration and validation purposes\u00a0\u2026", "num_citations": "15\n", "authors": ["574"]}
{"title": "A re-entrant flowshop heuristic for online scheduling of the paper path in a large scale printer\n", "abstract": " A Large Scale Printer (LSP) is a Cyber Physical System (CPS) printing thousands of sheets per day with high quality. The print requests arrive at run-time requiring online scheduling. We capture the LSP scheduling problem as online scheduling of reentrant flowshops with sequence dependent setup times and relative due dates with makespan minimization as the scheduling criterion. Exhaustive approaches like Mixed Integer Programming can be used, but they are compute intensive and not suited for online use. We present a novel heuristic for scheduling of LSPs that on average requires 0.3 seconds per sheet to find schedules for industrial test cases. We compare the schedules to lower bounds, to schedules generated by the current scheduler and schedules generated by a modified version of the classical NEH (MNEH) heuristic [1], [2]. On average, the proposed heuristic generates schedules that are 40\u00a0\u2026", "num_citations": "15\n", "authors": ["574"]}
{"title": "A probabilistic acknowledgment mechanism for wireless sensor networks\n", "abstract": " The inherently unreliable communication infrastructure compel WSN protocols to employ error control mechanisms. Traditionally, error control is achieved by a retransmission scheme using acknowledgment mechanisms. WSN architectures are severely resource constrained and the additional energy expense of transmitting error control messages can seriously degrade network lifetime. In this paper, we analyze performance of error control schemes for the case of point-to-multipoint communication. An explicit acknowledgment mechanism may provide for reliable communication, but has two major drawbacks: 1) the over head is significant for small data messages, and 2) in case of asymmetrical communication links, multi-hop dissemination of acknowledgments is required. As an alternative to such explicit acknowledgment schemes we propose the use of probabilistic acknowledgments. In this probabilistic scheme\u00a0\u2026", "num_citations": "15\n", "authors": ["574"]}
{"title": "A tool for fast ground truth generation for object detection and tracking from video\n", "abstract": " Object detection and tracking is one of the most important components in computer vision applications. To carefully evaluate the performance of detection and tracking algorithms, it is important to develop benchmark data sets. One of the most tedious and error-prone aspects when developing benchmarks, is the generation of the ground truth. This paper presents FAST-GT (FAst Semi-automatic Tool for Ground Truth generation), a new generic framework for the semiautomatic generation of ground truths. FAST-GT reduces the need for manual intervention thus speeding-up the ground-truthing process.", "num_citations": "14\n", "authors": ["574"]}
{"title": "Iteration-based trade-off analysis of resource-aware sdf\n", "abstract": " Synchronous dataflow graphs (SDFGs) are widely used to model streaming applications such as signal processing and multimedia applications in embedded systems. Trade-off analysis between performance and resource usage of SDFGs allows designers to explore implementation alternatives of a system while meeting its performance requirements and resource constraints. This type of analysis is computationally very challenging, particularly when resources may be shared among computations. With resource sharing, system scheduling decisions lead to a combinatorial explosion in the number of scheduling alternatives to be explored. We present a new approach to explore the trade-offs in a such systems. It breaks analysis down in iterations of dataflow graph execution and uses a max-plus algebra semantics. The experimental results on a set of realistic benchmark models show that the new iteration-based\u00a0\u2026", "num_citations": "14\n", "authors": ["574"]}
{"title": "Configuring multi-objective evolutionary algorithms for design-space exploration of wireless sensor networks\n", "abstract": " Wireless sensor networks (WSNs) consist of numerous sensor nodes with several possible configurations for each node. As there are a lot of nodes in a typical WSN, each with its own set of configurations, the number of configurations for the network as a whole is huge and the design space is extremely large. The configuration of a WSN has a strong effect on the quality of services of running applications and the performance of the WSN. Multi-objective evolutionary algorithms (EAs) are well suited to explore the trade-offs in a WSN design space. However, an EA has many configuration parameters in itself. This paper presents several guidelines for configuring a multi-objective EA for design space exploration, given a specification of the WSN to be configured and a time budget available for analysis. We demonstrate the effectiveness of these guidelines on a specific type of WSN that uses a gossip strategy for\u00a0\u2026", "num_citations": "14\n", "authors": ["574"]}
{"title": "Synthesizing and verifying multicore parallelism in categories of nested code graphs\n", "abstract": " Among the first generation of such processors, the Cell Broadband Engine (BE) is the most widely deployed. Using its resources efficiently requires explicit synchronisation of both code and data, and packaging of both to fit in small memory spaces and constrained communication infrastructures.ABSTRACT", "num_citations": "14\n", "authors": ["574"]}
{"title": "Predictable embedding of large data structures in multiprocessor networks-on-chip\n", "abstract": " This extended abstract presents models to derive timing and resource usage numbers for an application when distant, shared memories are used in an important class of future embedded platforms, namely network-on-chip-based multiprocessors.", "num_citations": "14\n", "authors": ["574"]}
{"title": "Optimising quality-of-control for data-intensive multiprocessor image-based control systems considering workload variations\n", "abstract": " Image-Based Control (IBC) systems have a long sample period. Sensing in these systems consists of compute-intensive image processing algorithms whose response times are dependent on image workload. IBC systems are typically designed for the worst-case workload that results in a long sample period and hence suboptimal quality-of-control (QoC). This worst-case based design is further considered for mapping of controller tasks and allocating platform resources, resulting in significant resource over-provisioning. Our design philosophy is to sample as fast as possible to optimise QoC for a given platform allocation, and for this, we present a structured design flow. Workload variations determine how fast we can sample and we model this dynamic behaviour using the concept of workload scenarios. Our choice of scenario-aware dataflow as the formal model for our application enables us to: i) model dynamic\u00a0\u2026", "num_citations": "13\n", "authors": ["574"]}
{"title": "Loop transformations leveraging hardware prefetching\n", "abstract": " Memory-bound applications heavily depend on the bandwidth of the system in order to achieve high performance. Improving temporal and/or spatial locality through loop transformations is a common way of mitigating this dependency. However, choosing the right combination of optimizations is not a trivial task, due to the fact that most of them alter the memory access pattern of the application and as a result interfere with the efficiency of the hardware prefetching mechanisms present in modern architectures. We propose an optimization algorithm that analytically classifies an algorithmic description of a loop nest in order to decide whether it should be optimized stressing its temporal or spatial locality, while also taking hardware prefetching into account. We implement our technique as a tool to be used with the Halide compiler and test it on a variety of benchmarks. We find an average performance improvement of\u00a0\u2026", "num_citations": "13\n", "authors": ["574"]}
{"title": "Online scheduling of 2-re-entrant flexible manufacturing systems\n", "abstract": " Online scheduling of operations is essential to optimize productivity of flexible manufacturing systems (FMSs) where manufacturing requests arrive on the fly. An FMS processes products according to a particular flow through processing stations. This work focusses on online scheduling of re-entrant FMSs with flows using processing stations where products pass twice and with limited buffering between processing stations. This kind of FMS is modelled as a re-entrant flow shop with due dates and sequence-dependent set-up times. Such flow shops can benefit from minimization of the time penalties incurred from set-up times. On top of an existing greedy scheduling heuristic we apply a meta-heuristic that simultaneously explores several alternatives considering trade-offs between the used metrics by the scheduling heuristic. We identify invariants to efficiently remove many infeasible scheduling options so that the\u00a0\u2026", "num_citations": "13\n", "authors": ["574"]}
{"title": "Predictable dynamic embedded data processing\n", "abstract": " Cyber-physical systems interact with their physical environment. In this interaction, non-functional aspects, most notably timing, are essential to correct operation. In modern systems, dynamism is introduced in many different ways. The additional complexity threatens timely development and reliable operation. Applications often have different modes of operation with different resource requirements and different levels of required quality-of-service. Moreover, multiple applications in dynamically changing combinations share a platform and its resources. To preserve efficient development of such systems, dynamism needs to be taken into account as a primary concern, not as a verification or tuning effort after the design is done. This requires a model-driven design approach in which timing of interaction with the physical environment is taken into consideration; formal models capture applications and their platforms in\u00a0\u2026", "num_citations": "13\n", "authors": ["574"]}
{"title": "Playing games with scenario-and resource-aware SDF graphs through policy iteration\n", "abstract": " The two-player mean-payoff game is a well-known game theoretic model that is widely used, for instance in economics and control theory. For controller synthesis, a controller is modeled as a player while the environment, or plant, is modeled as the opponent player (adversary). Synthesizing an optimal controller that satisfies a given criterion corresponds to finding a winning strategy for the controller player. Emerging streaming applications (audio, video, communication, etc.) for embedded systems exhibit both input sensitive and controller sensitive runtime behavior, where the controller's role is runtime management or scheduling. Embedded controllers need to be optimized for dynamic inputs, while guaranteeing throughput constraints. In this paper, we consider this design task for scenario- and resource-aware dataflow graphs that model streaming applications. Scenarios in these models capture classes of\u00a0\u2026", "num_citations": "13\n", "authors": ["574"]}
{"title": "Simultaneous budget and buffer size computation for throughput-constrained task graphs\n", "abstract": " Modern embedded multimedia systems process multiple concurrent streams of data processing jobs. Streams often have throughput requirements. These jobs are implemented on a multiprocessor system as a task graph. Tasks communicate data over buffers, where tasks wait on sufficient space in output buffers before producing their data. For cost reasons, jobs share resources. Because jobs can share resources with other jobs that include tasks with date-dependent execution rates, we assume run-time scheduling on shared resources. Budget schedulers are applied, because they guarantee a minimum budget in a maximum replenishment interval. Both the buffer sizes as well as the budgets influence the temporal behaviour of a job. Interestingly, a trade-off exists: a larger buffer size can allow for a smaller budget while still meeting the throughput requirement. This work is the first to address the simultaneous\u00a0\u2026", "num_citations": "13\n", "authors": ["574"]}
{"title": "An experimental study of cross-technology interference in in-vehicle wireless sensor networks\n", "abstract": " Wireless in-vehicle networks are considered as a flexible and cost-efficient solution for the new generation of cars. One of the candidate wireless technologies for these wireless sensor networks is the IEEE 802.15. 4 standard which operates in the 2.4 GHz ISM band. This is while the number of wireless devices that operate in this band is ever increasing. This broad usage of the same RF band may cause considerable performance degradation of wireless networks due to interference. There is some work on the coexistence of the IEEE 802.15. 4 protocol and other standard technologies such as IEEE 802.11 (Wi-Fi) and IEEE 802.15. 1 (Bluetooth), but none of it considers the highly dynamic conditions of in-vehicle networks. In this paper, we investigate the interference behavior in in-vehicle environments using real-world experiments. We consider different scenarios and measure the interference on all the 16\u00a0\u2026", "num_citations": "12\n", "authors": ["574"]}
{"title": "Fault-tolerant embedded control systems for unreliable hardware\n", "abstract": " Past years have seen intense research on reliability techniques for error detection recovery at various levels ranging from circuit level up to architectural level or even software level. In such scenarios, affordable techniques for error correction usually imply a timing penalty, e.g., check-pointing usually requires to repeat some part of the computation, which imposes a higher computation time. This can be problematic for real-time embedded control applications especially in the presence of intermittent hardware faults, for which delays due to re-computation are repeatedly encountered with high repetition rate. In this work, we investigate a setting where the control loops are executed on an unreliable embedded platform that may suffer from such intermittent faults. First, we characterize the impact of intermittent faults in the hardware by using an intermittent bit-flip fault model and RTL level error effect simulation\u00a0\u2026", "num_citations": "12\n", "authors": ["574"]}
{"title": "Semantic interoperability in sensor applications making sense of sensor data\n", "abstract": " Much effort has been spent on the optimization of sensor networks, mainly concerning their performance and power efficiency. Furthermore, open communication protocols for the exchange of sensor data have been developed and widely adopted, making sensor data widely available for software applications. However, less attention has been given to the interoperability of sensor networks and sensor network applications at a semantic level. This hinders the reuse of sensor networks in different applications and the evolution of existing sensor networks and their applications. The main contribution of this paper is an ontology-based approach and architecture to address this problem. We developed an ontology that covers concepts regarding examinations as well as measurements, including the circumstances in which the examination and measurement have been performed. The underlying architecture secures a\u00a0\u2026", "num_citations": "12\n", "authors": ["574"]}
{"title": "Fast simulation methods to predict wireless sensor network performance\n", "abstract": " With the increasing capabilities of Wireless Sensor Networks (WSN), complexity and expectation of the WSN applications increase as well. In order to make design-space exploration possible, it is necessary to have fast models that provide adequate insight in system behavior. In this paper, we propose a highly abstracted, hierarchical, system-level modeling method for WSN. Based on the model properties, fast simulation techniques can be applied. First, an abstract discrete event simulation based on a Probabilistic Graph Model (PGM) is introduced. Then, a fast Monte Carlo simulation approach is proposed for speeding up the simulation process. This approach combines Stochastic-Variable Graph Models (SVGM), providing a high level of abstraction, with shortest path calculations. As a case study, a temperature mapping application in a gossip-based WSN is used, showing a good accuracy of the model predictions.", "num_citations": "12\n", "authors": ["574"]}
{"title": "Qos management for wireless sensor networks with a mobile sink\n", "abstract": " The problem of configuration of Wireless Sensor Networks is an interesting challenge. The objective is to find the settings, for each sensor node, that optimise certain task-level QoS metrics. An existing configuration method is available for tree-based static networks. We extend this method to support a mobile sink. First, the routing tree is adapted to the sink\u2019s new location, after which the parameters of the nodes are optimised. Both algorithms are distributed and localised, and therefore efficient and scalable, and are able to flexibly trade reconfiguration cost (time and energy) for quality to match the demands of the application. Various options are analysed, and evaluated in simulation.", "num_citations": "12\n", "authors": ["574"]}
{"title": "Implementing face recognition using a parallel image processing environment based on algorithmic skeletons\n", "abstract": " Image processing is widely used in many applications, including medical imaging, industrial manufacturing, and security systems. Often the size of the image is very large, the processing time has to be very small and usually real-time constraints have to be met. Therefore, during the last decades there has been an increasing interest in the development and the use of parallel algorithms in image processing.", "num_citations": "12\n", "authors": ["574"]}
{"title": "Designing image-based control systems considering workload variations\n", "abstract": " We consider the problem of designing an Image-Based Control (IBC) application mapped to a multiprocessor platform. Sensing in IBC consists of compute-intensive image processing algorithms whose execution times are dependent on image workload. The challenge is that the IBC systems have a high (worst-case) workload with significant workload variations. Designing controllers for such IBC systems typically consider the worst-case workload that results in a long sensing delay with suboptimal quality-of-control (QoC). The challenge is: how to improve the QoC of IBC for a given multiprocessor platform allocation? We present a controller synthesis method based on a Markovian jump linear system (MJLS) formulation considering workload variations. Our method assumes that system knowledge is available for modelling the workload variations as a Markov chain. We compare the MJLS-based method with two\u00a0\u2026", "num_citations": "11\n", "authors": ["574"]}
{"title": "Fsm-based sadf\n", "abstract": " The Synchronous Dataflow (SDF) Model-of-Computation (MoC)[3] has become a popular model for modelling streaming applications. The SDF MoC fits well with the streaming and pipelining characteristics of these applications, it can capture many mapping decisions and resource constraints, and it allows design-time analysis of timing (throughput, latency) and resource usage. When designing a system with a predictable timing behaviour, the SDF model of an application assumes worst-case rates for the edges and worst-case execution times for the actors. In the situation that an application contains a lot of dynamism, the use of worst-case values could lead to over-dimensioning of the system for many run-time situations. Therefore, the concept of system scenarios has been introduced in [1, 2]. However, these scenarios cannot be modelled into an SDF graph. This report introduces an extension to the SDF MoC that can be used to model an application together with its scenarios. This new MoC is called the Finite State Machine-based Scenario-Aware Data-Flow (FSM-based SADF) MoC. The FSM-based SADF MoC is a restricted form of the general SADF MoC that has been introduced in [4, 5]. These restrictions make analysis of the timing behaviour of a model specified in the FSM-based SADF MoC faster than a model specified in the general SADF MoC. However, analysis result may be less tight due to the abstractions made in the FSM-based SADF MoC. The next section informally introduces the FSM-based SADF MoC by explaining how an H. 263 decoder can be modelled. Sec. 3 discusses the differences between the FSM-based SADF\u00a0\u2026", "num_citations": "11\n", "authors": ["574"]}
{"title": "A scenario-and platform-aware design flow for image-based control systems\n", "abstract": " Image-based control (IBC) systems are increasingly being used in various domains including autonomous driving. The key challenge in IBC is to deal with high computation demand while guaranteeing performance and safety requirements such as stability. While modern industrial heterogeneous platforms, such as NVIDIA Drive, offer the necessary compute power, application development on these platforms with performance and safety guarantees is still challenging. Alternative time-predictable platforms are not yet in widespread use.A typical design flow for IBC systems consists of three distinct elements: (i) mapping tasks onto platform resources; (ii) timing analysis, consisting of task-level worst-case execution time (WCET) analysis and application-level analysis to obtain worst-case performance bounds on aspects such as latency and throughput; (iii) controller design using the obtained performance bounds\u00a0\u2026", "num_citations": "10\n", "authors": ["574"]}
{"title": "Co-simulation framework for control, communication and traffic for vehicle platoons\n", "abstract": " Vehicle platooning has gained attention for its potential to achieve an increased road capacity and safety, and a higher fuel efficiency. Member vehicles of a platoon wirelessly communicate complying with industrial standards such as IEEE 802.11p. By exchanging information with other members via wireless communication, a platoon member computes its desired acceleration which is then passed on to the engine control system via in-vehicle network to physically realize the acceleration. This leads to a multi-layer control scheme. The upper-layer is influenced by the behavior of 802.11p communication and network congestion due to transmissions by other vehicles in the traffic. The lower-layer engine control loop communicates over the fast and reliable in-vehicle networks (e.g., FlexRay, Ethernet). Design of the overall system therefore depends on (i) the characteristics of 802.11p-based communication (ii) the\u00a0\u2026", "num_citations": "10\n", "authors": ["574"]}
{"title": "A systematic engineering tool chain approach for self-organizing building automation systems\n", "abstract": " There is a strong push towards smart buildings that aim to achieve comfort, safety and energy efficiency, through building automation systems (BAS) that incorporate multiple subsystems such as heating and air-conditioning, lighting, access control etc. The design, commissioning and operation of BAS is already challenging when handling an individual subsystem; however when introducing co-operation between systems the complexity increases dramatically. Balancing the contradictory requirements of comfort, safety and energy efficiency and coping with the dynamics of constantly changing environmental conditions, usage patterns, user needs etc. is a demanding task. This paper outlines an approach to the systematic engineering of cooperating, adaptive building automation systems, which aims to formalize the engineering approach in the form of an integrated tool chain that supports the building stakeholders\u00a0\u2026", "num_citations": "10\n", "authors": ["574"]}
{"title": "Architecture for self-organizing, co-operative and robust Building Automation Systems\n", "abstract": " This paper provides an overview of the architecture for self-organizing, co-operative and robust Building Automation Systems (BAS) proposed by the EC funded FP7 SCUBA 1  project. We describe the current situation in monitoring and control systems and outline the typical stakeholders involved in the case of building automation systems. We derive seven typical use cases which will be demonstrated and evaluated on pilot sites. From these use cases the project designed an architecture relying on six main modules that realize the design, commissioning and operation of self-organizing, co-operative, robust BAS.", "num_citations": "10\n", "authors": ["574"]}
{"title": "A Pareto-algebraic framework for signal power optimization in global routing\n", "abstract": " This paper proposes a framework for (signal) interconnect power optimization at the global routing stage. In a typical design flow, the primary objective of global routing is minimization of wirelength and via consumption. Our framework takes a global routing solution that is optimized for this objective, and quickly generates a new solution that is optimized for signal power, with only a small, controlled degradation in wirelength. Our model of signal power includes layer-dependent fringe and area capacitances of the routes, and their spacing. Our framework is fast compared to the existing global routing procedures, thereby not causing much overhead and fitting well in the design flow to optimize signal power after wirelength minimization. The framework is based on Pareto-algebraic operations and generates multiple global routing solutions to provide a tradeoff between power and wirelength, thereby allowing the user\u00a0\u2026", "num_citations": "10\n", "authors": ["574"]}
{"title": "RC-SIMD: Reconfigurable communication SIMD architecture for image processing applications\n", "abstract": " During the last two decades, Single Instruction Multiple Data (SIMD) processors have become important architectures in embedded systems for image processing applications. The main reasons are their area and energy efficiency. Often the processing elements (PEs) of an SIMD processor are only locally connected. This may result in a communication bottleneck (only access to direct neighbors). One way to solve this is to use a fully connected communication network (FC-SIMD) between PEs. However, this solution leads to an excessive communication area cost, low communication network utilization, and scalability problems. Eg, the area overhead of an FC-SIMD is more than 100% when the number of PEs gets bigger than 64.", "num_citations": "10\n", "authors": ["574"]}
{"title": "Inheritance of Dynamic Behavior Development of a Groupware Editor\n", "abstract": " One of the key issues of object-oriented modeling is inheritance. It allows for the definition of subclasses that inherit features of some superclass. Inheritance is well defined for static properties of classes such as attributes and methods. However, there is no general agreement on the meaning of inheritance when considering dynamic behavior of objects. This paper studies inheritance of dynamic behavior in a framework based on Petri nets. The notions of an object life cycle and inheritance between life cycles are defined. The inheritance relation is based on two fundamental concepts, namely blocking and hiding method calls. Several transformation rules are given to construct subclasses from a given superclass, thus allowing reuse of life-cycle specifications during a design. To show the validity of the approach, the results are applied to the development of a groupware editor.", "num_citations": "10\n", "authors": ["574"]}
{"title": "Parsing partially ordered multisets\n", "abstract": " A partially ordered multiset or pomset is a generalization of a string in which the total order has been relaxed to a partial order. Strings are often used as a model for sequential computation; pomsets are a natural model for parallel and distributed computation.           By viewing pomsets as a generalization of strings, the question is raised whether concepts from language theory can be generalized to pomsets. An important area in the theory of languages is parsing theory. This paper develops the fundamentals of a parsing theory for pomsets, called PLR parsing. It is based on the LR-parsing technique, which is the most powerful deterministic parsing technique in language theory. The basic algorithm in the class of PLR parsing algorithms, the PLR(0) algorithm is explained in detail.", "num_citations": "10\n", "authors": ["574"]}
{"title": "Interface modeling for quality and resource management\n", "abstract": " We develop an interface-modeling framework for quality and resource management that captures configurable working points of hardware and software components in terms of functionality, resource usage and provision, and quality indicators such as performance and energy consumption. We base these aspects on partially-ordered sets to capture quality levels, budget sizes, and functional compatibility. This makes the framework widely applicable and domain independent (although we aim for embedded and cyber-physical systems). The framework paves the way for dynamic (re-)configuration and multi-objective optimization of component-based systems for quality- and resource-management purposes.", "num_citations": "9\n", "authors": ["574"]}
{"title": "Schedule synthesis for Halide pipelines through reuse analysis\n", "abstract": " Efficient code generation for image processing applications continues to pose a challenge in a domain where high performance is often necessary to meet real-time constraints. The inherently complex structure found in most image-processing pipelines, the plethora of transformations that can be applied to optimize the performance of an implementation, as well as the interaction of these optimizations with locality, redundant computation and parallelism, can be indentified as the key reasons behind this issue. Recent domain-specific languages (DSL) such as the Halide DSL and compiler attempt to encourage high-level design-space exploration to facilitate the optimization process. We propose a novel optimization strategy that aims to maximize producer-consumer locality by exploiting reuse in image-processing pipelines. We implement our analysis as a tool that can be used alongside the Halide DSL to\u00a0\u2026", "num_citations": "9\n", "authors": ["574"]}
{"title": "Scalable analysis for multi-scale dataflow models\n", "abstract": " Multi-scale dataflow models have actors acting at multiple granularity levels, e.g., a dataflow model of a video processing application with operations on frame, line, and pixel level. The state of the art timing analysis methods for both static and dynamic dataflow types aggregate the behaviours across all granularity levels into one, often large iteration, which is repeated without exploiting the structure within such an iteration. This poses scalability issues to dataflow analysis, because behaviour of the large iteration is analysed by some form of simulation that involves a large number of actor firings. We take a fresh perspective of what is happening inside the large iteration. We take advantage of the fact that the iteration is a sequence of smaller behaviours, each captured in a scenario, that are typically repeated many times. We use the (max ,+) linear model of dataflow to represent each of the scenarios with a matrix\u00a0\u2026", "num_citations": "9\n", "authors": ["574"]}
{"title": "Performance engineering for industrial embedded data-processing systems\n", "abstract": " Performance is a key aspect of many embedded systems, embedded data processing systems in particular. System performance can typically only be measured in the later stages of system development. To avoid expensive re-work in the final stages of development, it is essential to have accurate performance estimations in the early stages. For this purpose, we present a model-based approach to performance engineering that is integrated with the well-known V-model for system development. Our approach emphasizes model accuracy and is demonstrated using five embedded data-processing cases from the digital printing domain. We show how lightweight models can be used in the early stages of system development to estimate the influence of design changes on system performance.", "num_citations": "9\n", "authors": ["574"]}
{"title": "Algebra of communicating processes\n", "abstract": " Process algebra is the study of concurrent communicating processes in an algebraic framework. As the initiator of this field we consider R. MILNER, with his Calculus of Communicating Systems [M80], which formed the basis for most of the axiom systems in the theory ACP of BERGSTRA & KLOP [BK84, BK85]. The endeavor of process algebra is to treat concurrency theory (the theory of concurrent communicating processes) in an axiomatic way, just as for instance the study of mathematical objects as groups or fields starts with an axiomatization of the intended objects. The axiomatic method which concerns us, is algebraic in the sense that we consider structures (also called process algebras by some people) which are models of some set of (mostly) equational axioms; these structures are equipped with several operators. Thus, we use the term algebra in the sense of model theory..There is ample motivation for uch\u00a0\u2026", "num_citations": "9\n", "authors": ["574"]}
{"title": "Using iterative compilation to reduce energy consumption\n", "abstract": " The rapid range of architectural changes in processors puts compiler technology under an enormous stress. This is emphasized by new demands added to compilers, like reducing static code size, energy consumption or power dissipation. Iterative compilation has been proposed as an approach to find the best sequence of optimizations (such as loop transformations) for an application, in order to improve its performance. In this paper, we study both the effect of loop transformations on energy consumption as well as the possibility of using the iterative compilation method in order to find the best compiled code for energy and for the combination of energy and performance. From analyzed benchmarks, we conclude that performance improvement is coming together with decreasing energy consumption. Iterative compilation seems therefore a promising approach to the compilation for energy problem, but a larger set of loop transformations and their combinations needs to be studied for a definitive conclusion.", "num_citations": "9\n", "authors": ["574"]}
{"title": "Breakpoints and time in distributed computations\n", "abstract": " This paper investigates how vector time can be used to set breakpoints in distributed computations for the purpose of analyzing and debugging distributed programs. A breakpoint is represented by a set of events in one or more processes. One interesting state in which a distributed computation can be halted is the earliest global state reflecting all events in a breakpoint. A simple expression in terms of vector time is derived to determine this state. Another state of interest is the global state reflecting only events preceding any of the breakpoint events, but reflecting none of the breakpoint events themselves. Two alternative expressions are presented for this state. The first one is in terms of vector time and a derived notion called reversed vector time. The second expression uses vector time and the convex closure of a set of events.", "num_citations": "9\n", "authors": ["574"]}
{"title": "Approximation trade offs in an image-based control system\n", "abstract": " Image-based control (IBC) systems use camera sensor(s) to perceive the environment. The inherent compute-heavy nature of image processing causes long processing delay that negatively influences the performance of the IBC systems. Our idea is to reduce the long delay using coarse-grained approximation of the image signal processing pipeline without affecting the functionality and performance of the IBC system. The question is: how is the degree of approximation related to the closed-loop quality-of-control (QoC), memory utilization and energy consumption? We present a software-in-the-loop (SiL) evaluation framework for the above approximation-in-the-loop system. We identify the error resilient stages and the corresponding coarse-grained approximation settings for the IBC system. We perform trade off analysis between the QoC, memory utilisation and energy consumption for varying degrees of coarse\u00a0\u2026", "num_citations": "8\n", "authors": ["574"]}
{"title": "IMACS: a framework for performance evaluation of image approximation in a closed-loop system\n", "abstract": " Image Processing (IP) applications have become popular with the advent of efficient algorithms and low-cost CMOS cameras with high resolution. However, IP applications are compute-intensive, consume a lot of energy and have long processing times. Image approximation has been proposed by recent works for an energy-efficient design of these applications. It also reduces the impact of long processing times. The challenge here is that the IP applications often work as a part of bigger closed-loop control systems, e.g. advanced driver assistance system (ADAS). The impact of image approximations that tolerate certain error on these image-based control (IBC) systems is very important. However, there is a lack of tool support to evaluate the performance of such closed-loop IBC systems when the IP is approximated. We propose a framework - for both software-in-the-loop (SiL) and hardware-in-the-loop (HiL\u00a0\u2026", "num_citations": "8\n", "authors": ["574"]}
{"title": "Efficient cluster mobility support for TDMA-based MAC protocols in wireless sensor networks\n", "abstract": " Node mobility is a key feature of using Wireless Sensor Networks (WSNs) in many sensory applications, such as healthcare. The Medium Access Control (MAC) protocol should properly support the mobility in the network. In particular, mobility is complicated for contention-free protocols like Time Division Multiple Access (TDMA). An efficient access to the shared medium is scheduled based on the node's local neighborhood. This neighborhood may vary over time due to node movement or other dynamics. In scenarios including body-area networking, for instance, some clusters of nodes move together, creating further challenges but also opportunities. This article presents a MAC protocol, MCMAC, that provides efficient support for cluster mobility in TDMA-based MAC protocols in WSNs. The proposed protocol exploits a hybrid contention-free and contention-based communication approach to support cluster\u00a0\u2026", "num_citations": "8\n", "authors": ["574"]}
{"title": "A Process-Algebraic Approach to Life-Cycle Inheritance-Inheritance= Encapsulation+ Abstraction\n", "abstract": " ion T. Basten and WMP van der Aalst Department of Mathematics and Computing Science Eindhoven University of Technology, The Netherlands email:{tbasten, wsinwa}@ win. tue. nl Abstract. One of the key issues of object-oriented modeling is inheritance. It allows for the definition of subclasses that inherit features of some superclass. Inheritance is well defined for static properties of classes such as attributes and methods. However, there is no general agreement on the meaning of inheritance when considering the dynamic behavior of objects, determined by their life cycles. This paper studies the latter in the context of a simple process algebra. Process algebra is chosen, because it concentrates on dynamic behavior, while abstracting from the internal states of processes. Inheritance can be expressed in terms of encapsulation and abstraction. The combination captures all basic operators for constructing life cycles of subclasses from life cycles of superclasses, namely choice, sequ...", "num_citations": "8\n", "authors": ["574"]}
{"title": "Schedule synthesis for halide pipelines on gpus\n", "abstract": " The Halide DSL and compiler have enabled high-performance code generation for image processing pipelines targeting heterogeneous architectures through the separation of algorithmic description and optimization schedule. However, automatic schedule generation is currently only possible for multi-core CPU architectures. As a result, expert knowledge is still required when optimizing for platforms with GPU capabilities. In this work, we extend the current Halide Autoscheduler with novel optimization passes to efficiently generate schedules for CUDA-based GPU architectures. We evaluate our proposed method across a variety of applications and show that it can achieve performance competitive with that of manually tuned Halide schedules, or in many cases even better performance. Experimental results show that our schedules are on average 10% faster than manual schedules and over 2\u00d7 faster than\u00a0\u2026", "num_citations": "7\n", "authors": ["574"]}
{"title": "Partial-order reduction for performance analysis of max-plus timed systems\n", "abstract": " This paper presents a partial-order reduction method for performance analysis of max-plus timed systems. A max-plus timed system is a network of automata, where the timing behavior of deterministic system tasks (events in an automaton) is captured in (max, +) matrices. These tasks can be characterized in various formalisms like synchronous data flow, Petri nets, or real-time calculus. The timing behavior of the system is captured in a (max, +) state space, calculated from the composition of the automata. This state space may exhibit redundant interleaving with respect to performance aspects like throughput or latency. The goal of this work is to obtain a smaller state space to speed up performance analysis. To achieve this, we first formalize state-space equivalence with respect to throughput and latency analysis. Then, we present a way to compute a reduced composition directly from the specification. This yields a\u00a0\u2026", "num_citations": "7\n", "authors": ["574"]}
{"title": "Task-FIFO co-scheduling of streaming applications on MPSoCs with predictable memory hierarchy\n", "abstract": " This article studies the scheduling of real-time streaming applications on multiprocessor systems-on-chips with predictable memory hierarchy. An iteration-based task-FIFO co-scheduling framework is proposed for this problem. We obtain FIFO size distributions using Pareto space searching, based on which the task-to-processor mapping is obtained with the potential FIFO allocation being taken into account; then, the FIFO-to-memory allocation is optimized to minimize the total memory access cost; finally, a self-timed throughput analysis method that considers memory and direct memory access controller contention is utilized to analyze the throughput. Our methods are validated by a set of synthesized and practical applications on different platforms.", "num_citations": "7\n", "authors": ["574"]}
{"title": "Robust online face tracking-by-detection\n", "abstract": " The problem of online face tracking from unconstrained videos is still unresolved. Challenges range from coping with severe online appearance variations to coping with occlusion. We propose RFTD (Robust Face Tracking-by-Detection), a system which combines tracking and detection into a single framework to robustly track a face from unconstrained videos. RFTD is based on the idea that adaptive and stable algorithmic components can complement each other in the task of online tracking. An online Structured Output SVM (SO-SVM) is combined with an offline trained face detector to break the self-learning loop typical in tracking. In turn, the face detector is supervised by a Deformable Part Model (DPM) landmark detector to asses the reliability of the face detection output. Extensive evaluation shows that RFTD delivers consistently good tracking performances across different scenarios, i.e., high mean success\u00a0\u2026", "num_citations": "7\n", "authors": ["574"]}
{"title": "Checking metric temporal logic with trace\n", "abstract": " Execution traces, time-stamped sequences of events, provide a general, domain-independent, view on the behavior of systems. They enable analysis of metrics such as latency, pipeline depth and throughput. Often, however, it is not clear what such metrics exactly mean and ad hoc methods are used to compute them. Metric Temporal Logic (MTL) can be used to address this issue: it enables the formal specification of quantitative properties on execution traces. We thus have added an MTL checking capability to the TRACE tool, which is a tool for viewing and analyzing execution traces [1]. We use a recursive memoization algorithm that generates concise explanations of the truth value of the given MTL formula. These explanations can be visualized in the TRACE viewer to aid interpretation by the user.", "num_citations": "7\n", "authors": ["574"]}
{"title": "Reconfigurable pipelined sensing for image-based control\n", "abstract": " Image-based control systems are becoming common in domains such as robotics, healthcare and industrial automation. Coping with a long sample period because of the latency of the image processing algorithm is an open challenge. Modern multi-core platforms allow to address this challenge by pipelining the sensing algorithm. Often, such systems share the resources with other tasks. We show that the performance of an image-based controller can be improved by pipelining the image processing algorithm on unallocated cores. It can be further improved by dynamically allocating (i.e. reconfiguring) cores that are temporarily not used by other tasks to the sensing pipeline. We present a state-based modelling strategy for pipelined and reconfigurable pipelined sensing. We introduce a control design strategy for reconfigurable pipelined systems that assures stability and shows improvement in the control\u00a0\u2026", "num_citations": "7\n", "authors": ["574"]}
{"title": "A distributed reconfiguration approach for quality-of-service provisioning in dynamic heterogeneous wireless sensor networks\n", "abstract": " Wireless Sensor Networks (WSNs) are commonly deployed in dynamic environments where events, such as moving sensor nodes and changing external interference, impact the performance, or Quality of Service (QoS), of the network. QoS is expressed by the values of multiple, possibly conflicting, network quality metrics, such as network lifetime and maximum latency of communicating a packet to the sink. Sufficient QoS should be provided by the WSN to ensure that the end-user can successfully use the WSN to perform its application. We propose a distributed reconfiguration approach that actively maintains a sufficient level of QoS at runtime for a heterogeneous WSN in a dynamic environment. Every node uses a feedback control strategy to resolve any difference between the current and required QoS of the network by adapting controllable parameters of the protocol stack. Example parameters are the\u00a0\u2026", "num_citations": "7\n", "authors": ["574"]}
{"title": "An empirical study of link quality estimation techniques for disconnection detection in WBANs\n", "abstract": " Sensor nodes in many Wireless Body Area Network (WBAN) architectures are supposed to deliver sensed data to a gateway node on the body. To satisfy the data delivery requirements, the network needs to adapt itself to the changes in connection status of the body nodes to the gateway. As a prerequisite, Link Quality Estimation (LQE) needs to be done to detect the connection status of the nodes. The quality of links in WBANs is highly time-varying. The LQE technique should be agile to react fast to such link quality dynamics while avoiding frequent fluctuations to reduce the network adaptation overhead. In this paper, we present an empirical study on using different LQE methods for detecting the connection status of body nodes to the gateway in WBANs. A set of experiments using 16 wireless motes deployed on a body are performed to log the behavior of the wireless links. We explore the trade-offs made by each\u00a0\u2026", "num_citations": "7\n", "authors": ["574"]}
{"title": "Hybrid code-data prefetch-aware multiprocessor task graph scheduling\n", "abstract": " The ever increasing performance gap between processors and memories is one of the biggest performance bottlenecks for computer systems. In this paper, we propose a task scheduling technique that schedules an application, modeled with a task graph, on a multiprocessor system-on chip (MPSoC) that contains a limited on-chip memory. The proposed scheduling technique explores the trade-off between executing tasks in a code-driven (i.e. executing parallel tasks) or data-driven (i.e. executing pipelined tasks) manner to minimize the run-time of the application. Our static scheduler identifies those task sequences in which it is useful to use a code-driven execution and those task sequences that benefit from a data-driven execution. We extend the proposed technique to consider prefetching when choosing a suitable task order. The technique is implemented using an integer linear programming framework. To\u00a0\u2026", "num_citations": "7\n", "authors": ["574"]}
{"title": "Analyzing concurrency in streaming applications\n", "abstract": " We present a concurrency model that allows reasoning about concurrency in executable specifications of streaming applications. It provides measures for five different concurrency properties. The aim of the model is to provide insight into concurrency bottlenecks in an application and to provide global direction when performing implementation-independent concurrency optimization. The model focuses on task-level concurrency. A concurrency optimization method and a prototype implementation of a supporting analysis tool have been developed. We use the model and tool to optimize the concurrency in a number of multimedia applications. The results show that the concurrency model allows target-architecture-independent concurrency optimization.", "num_citations": "7\n", "authors": ["574"]}
{"title": "A monitoring-aware NoC design flow\n", "abstract": " A Monitoring-aware NoC Design Flow \u2014 Eindhoven University of Technology research portal Skip to main navigation Skip to search Skip to main content Eindhoven University of Technology research portal Logo Help & FAQ English Nederlands Home Researchers Research Output Organisational units Activities Projects Prizes Press / Media Facilities / Equipment Datasets Courses Research areas Student theses Search by expertise, name or affiliation A Monitoring-aware NoC Design Flow C. Ciordas, MA Hansson, KGW Goossens, T. Basten Electronic Systems Research output: Chapter in Book/Report/Conference proceeding \u203a Conference contribution \u203a Academic \u203a peer-review 8 Citations (Scopus) Overview Original language English Title of host publication Proceedings of the 9th EUROMICRO Conference, DSD 2006 Editors V. Muthukumar Place of Publication Los Alamitos, USA Publisher IEEE Computer Society \u2026", "num_citations": "7\n", "authors": ["574"]}
{"title": "Designing area and performance constrained SIMD/VLIW image processing architectures\n", "abstract": " Image processing is widely used in many applications, including medical imaging, industrial manufacturing and security systems. In these applications, the size of the image is often very large, the processing time should be very small and the real-time constraints should be met. Therefore, during the last decades, there has been an increasing demand to exploit parallelism in applications. It is possible to explore parallelism along three axes: data-level parallelism (DLP), instruction-level parallelism (ILP) and task-level parallelism (TLP).               This paper explores the limitations and bottlenecks of increasing support for parallelism along the DLP and ILP axes in isolation and in combination. To scrutinize the effect of DLP and ILP in our architecture (template), an area model based on the number of ALUs (ILP) and the number of processing elements (DLP) in the template is defined, as well as a performance\u00a0\u2026", "num_citations": "7\n", "authors": ["574"]}
{"title": "Inheritance of Workflows: An approach to tackling problems related to change\n", "abstract": " Inheritance of workflows : an approach to tackling problems related to change (2000) | www.narcis.nl KNAW KNAW Narcis Back to search results Eindhoven University of Technology Publication Inheritance of workflows : an approach to tackling problems related to change (2000) Open access . Pagina-navigatie: Main Save publication Save as MODS Export to Mendeley Save as EndNote Export to RefWorks Title Inheritance of workflows : an approach to tackling problems related to change Series BETA publicatie : working papers, 50 Author Aalst, van der WMP; Basten, T. Publisher Department of Mathematics and Computer Science; Information Systems IE&IS; Information Systems - BETA Date issued 2000 Access Open Access Language English Type Report Publisher Technische Universiteit Eindhoven Publication https://research.tue.nl/nl/publications/inheritance-of-workf... ISBN 90-386-0883-7 Persistent Identifier \u2026", "num_citations": "7\n", "authors": ["574"]}
{"title": "Time and order of abstract events in distributed computations\n", "abstract": " Time and order of abstract events in distributed computations (1994) | www.narcis.nl KNAW KNAW Narcis Back to search results Eindhoven University of Technology Publication Time and order of abstract events in distributed computations (1994) Open access . Pagina-navigatie: Main Save publication Save as MODS Export to Mendeley Save as EndNote Export to RefWorks Title Time and order of abstract events in distributed computations Series Computing science notes, 9406 Author Basten, T.; Kunz, TH; Black, JP; Taylor, DJ Publisher Electronic Systems; VF-programme Information Systems (1985-1994) THE.INF.302.85.26 (1985) TUE.INF.303.90.26 (1990) Date issued 1994 Access Open Access Language English Type Report Publisher Technische Universiteit Eindhoven Publication https://research.tue.nl/nl/publications/time-and-order-of-ab... Persistent Identifier urn:nbn:nl:ui:25-2cfe6afa-9c9c-497b-b70e-\u2026", "num_citations": "7\n", "authors": ["574"]}
{"title": "Scenarios in the design of flexible manufacturing systems\n", "abstract": " Modern high-tech flexible manufacturing systems (FMS) such as lithography systems, professional printers, X-ray machines, and electron microscopes are characterized by an increasingly tight coupling between machine control software and the controlled physical processes. Control software and the design and configuration of FMS have an important impact on system productivity and product quality. Model-based, scenario-based design provides means for guaranteeing and optimizing system productivity while ensuring its proper functioning. We show that abstract system-level activity models, semantically grounded in (max,+) algebra with activities capturing execution scenarios of the FMS, can be used for fast and accurate productivity analysis of FMS in early design phases. The same models can be used for supervisory controller synthesis and optimization, providing safety and performance guarantees\u00a0\u2026", "num_citations": "6\n", "authors": ["574"]}
{"title": "Control of platooned vehicles in presence of traffic shock waves\n", "abstract": " Vehicle platooning has been attracting attention recently because of its ability to improve road capacity, safety and fuel efficiency. Vehicles communicate using Vehicle-to- Vehicle (V2V) wireless communication, making their status (acceleration, position, etc.) available to other vehicles. Shock waves, i.e. zones of reduced traffic speed that propagate upstream, are a well known emergent traffic phenomenon. Since vehicles entering such a zone need to decelerate sharply, shock waves cause a deterioration of fuel economy, driving comfort, and safety. While typically caused by bad driving behavior, recent studies have shown that it is possible to diminish or dissipate shock waves by applying certain good driving behavioral patterns. In this work, we use the information about the traffic situation to adapt the reference speed profile of the platoon we control, in order to mitigate the effect of a shock wave coming from\u00a0\u2026", "num_citations": "6\n", "authors": ["574"]}
{"title": "Compositional dataflow modelling for cyclo-static applications\n", "abstract": " Modular design is a common practice when designing complex applications for embedded systems. Another important practice in the embedded systems domain is the use of abstract models to realize predictable behaviour. Modular model-based design allows to construct a modular model of a complex system via model composition. The model of computation considered in this paper is scenario-aware dataflow, a dataflow model that allows for dynamic behaviour. We model applications with behaviour that changes according to a periodic pattern. Composing models with periodic patterns results in a model with a periodic pattern with a common hyper-period. We propose an efficient algorithmic method to compose cyclo-static scenario-aware dataflow models by generating composite patterns in a concise representation. We show that our approach can automatically generate concise models of several real-life\u00a0\u2026", "num_citations": "6\n", "authors": ["574"]}
{"title": "A fast estimator of performance with respect to the design parameters of self re-entrant flowshops\n", "abstract": " Self re-entrant flowshops consist of machines which process jobs several times. They are found in applications like TFT-LCD assembly, LED manufacturing and industrial printing. The structure of a self re-entrant flowshop influences its performance. To get better performance while reducing costs a fast performance estimation method can be used to explore the trade-offs between the structure and the performance during the design process. We present a novel performance estimator that uses the information in the jobs being processed to analyse the trade-offs. We study the impact of the design parameters of an industrial printer using the performance estimator with an average estimation time of 1.1 milliseconds per job and with an average accuracy of not less than 96%.", "num_citations": "6\n", "authors": ["574"]}
{"title": "Sample-drop firmness analysis of TDMA-scheduled control applications\n", "abstract": " This paper proposes methods for verification of (m, k)-firmness properties of control applications running on a shared TDMA-scheduled processor. We particularly consider dropped samples arising from processor sharing. Based on the available processor budget for any sample that is ready for execution, the Finite-Point (FP) method is proposed for quantification of the maximum number of dropped samples. The FP method is further generalized using a timed automata based model to consider the variation in the period of samples. The UPPAAL tool is used to validate and verify the timed automata based model. The FP method gives an exact bound on the number of dropped samples, whereas the timed-automata analysis provides a conservative bound. The methods are evaluated considering a realistic case study. Scalability analysis of the methods shows acceptable verification times for different sets of parameters.", "num_citations": "6\n", "authors": ["574"]}
{"title": "Online heuristic for the Multi-Objective Generalized traveling salesman problem\n", "abstract": " Today's manufacturing systems are typically complex cyber-physical systems where the physical and control aspects interact with the scheduling decisions. Optimizing such facilities requires ordering jobs and configuring the manufacturing system for each job. This optimization problem can be described as a Multi-Objective Generalized TSP where conflicting objectives lead to a trade-off space. This is the first work to address this TSP variant, introducing a compositional heuristic suitable to online application.", "num_citations": "6\n", "authors": ["574"]}
{"title": "Thermal-aware scratchpad memory design and allocation\n", "abstract": " Scratchpad memories (SPMs) have become a promising on-chip storage solution for embedded systems from an energy, performance and predictability perspective. The thermal behavior of these types of memories has not been considered in detail. This thermal behavior plays an important role in the reliability of silicon devices and in their static (leakage) power consumption. In this paper, we propose two different techniques to improve the thermal behavior of SPMs. First, we propose a hardware-based, thermal-aware address translation technique that physically distributes memory accesses to consecutive addresses evenly over the whole memory area. Second, we propose a software-based, thermal-aware address generation technique. This technique tries to distribute the variables that are allocated to the SPM in such a way that an even thermal distribution is achieved. The first technique works particularly well\u00a0\u2026", "num_citations": "6\n", "authors": ["574"]}
{"title": "CAST-a task-level concurrency analysis tool\n", "abstract": " CAST is a system-level software tool for target-architecture-independent concurrency optimization of streaming applications. It includes a design exploration method to guide a system designer in an intuitive way through the design-space.", "num_citations": "6\n", "authors": ["574"]}
{"title": "Constraint analysis and heuristic scheduling methods\n", "abstract": " Scheduling is one of the main problems that need to be solved by high-level hardware and software compilers. Existing heuristics are often incapable of finding feasible solutions for practical examples, because the tight time and resource constraints make the feasible-solution subspace very small compared to the size of the full search space. For that reason, constraint-analysis techniques that help the scheduler find feasible solutions are nowadays a subject of research. In this paper, the effect of constraint analysis on heuristic schedulers is experimentally quantified to investigate to which extent constraint analysis improves the quality of such schedulers, and also to see which heuristics complement it well. The results show that, for most experiments, constraint analysis helps to improve the obtained schedules in terms of the latency of the schedule. It combines particularly well with the freeing-count heuristic.", "num_citations": "6\n", "authors": ["574"]}
{"title": "Inheritance of Workflows\n", "abstract": " Inheritance is one of the key issues of object-orientation. The inheritance mechanism allows for the definition of a subclass which inherits the features of a specific superclass. When adapting a workflow process definition to specific needs (ad-hoc change) or changing the structure of the workflow process as a result of reengineering efforts (evolutionary change), inheritance concepts are useful to check whether the new workflow process inherits some desirable properties of the old workflow process. Today\u2019s workflow management systems have problems dealing with both ad-hoc changes and evolutionary changes. As a result, a workflow management system is not used to support dynamically changing workflow processes or the workflow processes are supported in a rigid manner, ie, changes are not allowed or handled outside of the workflow management system. In this paper, we propose inheritance-preserving transformation rules for workflow processes and show that these rules can be used to avoid problems such as the \u201cdynamic-change bug.\u201d The dynamic-change bug refers to errors introduced by migrating a case (ie, a process instance) from an old process definition to a new one. A transfer from an old process to a new process can lead to duplication of work, skipping of tasks, deadlocks, and livelocks. Restricting change to the inheritance-preserving transformation rules guarantees transfers without any of these problems. Moreover, the transformation rules can also be used to extract aggregate management information in case more than one version of a workflow process cannot be avoided.", "num_citations": "6\n", "authors": ["574"]}
{"title": "Programming tensor cores from an image processing DSL\n", "abstract": " Tensor Cores (TCUs) are specialized units first introduced by NVIDIA in the Volta microarchitecture in order to accelerate matrix multiplications for deep learning and linear algebra workloads. While these units have proved to be capable of providing significant speedups for specific applications, their programmability remains difficult for the average user. In this paper, we extend the Halide DSL and compiler with the ability to utilize these units when generating code for a CUDA based NVIDIA GPGPU. To this end, we introduce a new scheduling directive along with custom lowering passes that automatically transform a Halide AST in order to be able to generate code for the TCUs. We evaluate the generated code and show that it can achieve over 5X speedup compared to Halide manual schedules without TCU support, while it remains within 20% of the NVIDIA cuBLAS implementations for mixed precision GEMM\u00a0\u2026", "num_citations": "5\n", "authors": ["574"]}
{"title": "Designing a controller with image-based pipelined sensing and additive uncertainties\n", "abstract": " Pipelined image-based control uses parallel instances of its image-processing algorithm in a pipelined fashion to improve the quality of control. A performance-oriented control design improves the controller settling time with each additional processing resource, which creates a resources-performance trade-off. In real-life applications, it is common to have a continuous-time model with additive uncertainties in one or more parameters that may affect the controller performance and the aforementioned trade-off. We present a robustness analysis framework for performance-oriented pipelined controllers with additive model uncertainties. We present a technique to obtain discrete-time uncertainties based on the continuous-time uncertainties for given uncertainty bounds. To benchmark such uncertainty bounds for a real system, we consider uncertainties in one element of the system, potentially caused by multiple\u00a0\u2026", "num_citations": "5\n", "authors": ["574"]}
{"title": "Hybrid Timeslot Design for IEEE 802.15. 4 TSCH to Support Heterogeneous WSNs\n", "abstract": " The IEEE 802.15.4 Time-Slotted Channel Hopping (TSCH) protocol defines two types of timeslots for communications, namely dedicated and shared timeslots. An upper layer in the protocol stack uses these timeslots to design a communication schedule for the network links, based on the required bandwidth for each link. Considering a network with time-varying data traffic generation by each node, the bandwidth requirements are changing over time for each link. This leads to poor efficiency of a predefined schedule when there is no data traffic for the dedicated timeslots, or there is too much data traffic injected to the shared timeslots. In this paper, we propose a new type of timeslot, called hybrid timeslot. A hybrid timeslot acts as a dedicated timeslot for a specific link, when there are packets available to be transmitted on that link. Otherwise, it acts as a shared timeslot that can be accessed by other links, using a\u00a0\u2026", "num_citations": "5\n", "authors": ["574"]}
{"title": "Effective link quality estimation as a means to improved end-to-end packet delivery in high traffic mobile ad hoc networks\n", "abstract": " Accurate link quality estimation is a fundamental building block in quality aware multi hop routing. In an inherently lossy, unreliable and dynamic medium such as wireless, the task of accurate estimation becomes very challenging. Over the years ETX has been widely used as a reliable link quality estimation metric. However, more recently it has been established that under heavy traffic loads ETX performance gets significantly worse. We examine the ETX metric's behavior in detail with respect to the MAC layer and UDP data; and identify the causes of its unreliability. Motivated by the observations made in our analysis, we present the design and implementation of our link quality measurement metric xDDR \u2013 a variation of ETX. This article extends xDDR to support network mobility. Our experiments show that xDDR substantially outperforms minimum hop count, ETX and HETX in terms of end-to-end packet delivery\u00a0\u2026", "num_citations": "5\n", "authors": ["574"]}
{"title": "Exploring the trade-off between processing resources and settling time in image-based control through LQR tuning\n", "abstract": " Image-Based control systems extract information by a camera and an image processing algorithm. The challenge of such controllers is that the sensing latency deteriorates the control performance. Multi-core technology can be used to implement the sensing algorithm in a pipelined fashion. More processing resources potentially lead to better settling time. This results in a trade-off between resources and performance. We present a method to analyse this trade-off.", "num_citations": "5\n", "authors": ["574"]}
{"title": "Tight temporal bounds for dataflow applications mapped onto shared resources\n", "abstract": " We present an analysis method that provides tight temporal bounds for applications modeled by Synchronous Dataflow Graphs and mapped to shared resources. We consider the resource sharing effects on the temporal behaviour of the application by embedding worst case resource availability curves in the symbolic simulation of the application graph. Symbolic simulation of the application results in a (max, +) characterization matrix. This matrix specifies a set of recursive linear equations in (max, +) algebra that bound the worst case execution of the application. We obtain tighter temporal bounds on the completion times of tasks than state of the art analysis. This is achieved by improving the response times of the tasks by identifying possible consecutive task executions on the resources. This enables us to use accumulated response times which are less pessimistic. Applying the new approach to real-life\u00a0\u2026", "num_citations": "5\n", "authors": ["574"]}
{"title": "Demonstrating on-demand listening and data forwarding in wireless body area networks\n", "abstract": " Adaptation of the network architecture through on-demand data forwarding is an efficient mechanism to provide robustness against long outages in WBANs. We developed an experimental testbed that provides online observation of the network behavior for different data propagation approaches in WBANs. The demonstration shows how different approaches deal with special challenges in WBANs such as low quality of wireless links, topology variations due to posture changes, and mobility. Moreover, sensor nodes can be configured online to investigate how different protocols react in various situations.", "num_citations": "5\n", "authors": ["574"]}
{"title": "Parameterized timed partial orders with resources: Formal definition and semantics\n", "abstract": " In this note we define (task-level) timed partial orders (TPOs), as a lifting of standard timed event partial orders to the level of tasks (where every task consists of an enabling and a completing event). We also introduce a generic resource platform on which these tasks are to be executed, and propose a resource handling scheme. The whole mechanism is given an operational semantics. To simplify large, but structured, TPO specifications we next introduce Parameterized TPOs (PTPOs), a high-level representation of TPOs, obtained by adding index parameters to events and constraining precedence rules by boolean expressions.", "num_citations": "5\n", "authors": ["574"]}
{"title": "SPaC: A symbolic pareto calculator\n", "abstract": " The compositional computation of Pareto points in multi-dimensional optimization problems is an important means to efficiently explore the optimization space. This paper presents a symbolic Pareto calculator, SPaC, for the algebraic computation of multidimensional trade-offs. SPaC uses BDDs as a representation for solution sets and operations on them. The tool can be used in multi-criteria optimization and design-space exploration of embedded systems. The paper describes the design and implementation of Pareto algebra operations, and it shows that BDDs can be used effectively in Pareto optimization.", "num_citations": "5\n", "authors": ["574"]}
{"title": "Runtime networks-on-chip performance monitoring\n", "abstract": " Networks-on-Chip (NoC) are scalable interconnects for Systems-on-Chip (SoC). An event-based NoC monitoring service has been developed within the DEMONS project which supports runtime observability of NoC behavior. Runtime NoC performance monitoring is an instance of this monitoring service and enables observation of performance measures such as connection latency and link utilization, while a system is actually running. This can for instance be used to obtain network resource information for Quality-of-Service (QoS) management or to support communication centric debugging. This thesis investigates whether runtime NoC performance monitoring is feasible and how it can be used.A framework is presented that identifies NoC performance measures. In order to prove feasibility, runtime NoC performance monitoring is designed and implemented for the \u00c6thereal NoC. For most of the investigated performance measures, generated load heavily depends on the sampling period. Generated load is presented for each of the investigated performance measures. Experiments are conducted for an MPEG application to obtain realistic communication cost figures. These experiments show that the costs for runtime NoC performance monitoring can be low compared to existing traffic, even for very small sampling periods. For instance, link utilization for all links in a 3x1 mesh using a sampling period of 600 ns introduces 1, 46% extra traffic and requires 0, 76% extra energy compared to the communication costs of the MPEG application.", "num_citations": "5\n", "authors": ["574"]}
{"title": "Static resource models of instruction sets\n", "abstract": " Due to an increasing need for flexibility, embedded systems embody more and more programmable processors as their core components. Because of silicon area and power considerations, the corresponding instruction sets are often highly encoded to minimize code size for given performance requirements. This has hampered the development of robust optimizing compilers because the resulting irregular instruction set architectures are far from convenient compiler targets. Among others, they introduce a strong phase coupling between the tasks of instruction selection and scheduling. Traditional methods perform these tasks in different phases, thereby yielding inferior schedules. In this paper, we present an approach that reduces the need for explicit instruction selection by transferring constraints implied by the instruction set to static resource constraints. All resulting schedules are then guaranteed to correspond\u00a0\u2026", "num_citations": "5\n", "authors": ["574"]}
{"title": "In terms of nets\n", "abstract": " When I applied for a Ph. D. position almost five years ago, I thought that I knew what it meant to be doing research. I also thought that I understood what it meant to be working towards a Ph. D. thesis. However, research is harder than I expected and successfully completing a Ph. D. thesis is even more difficult than doing research. As a Ph. D. student, I started working in the Formal Methods group of Jos Baeten and the Information Systems group of Kees van Hee. Jos and Kees wanted to find out whether their favorite formalisms for describing and analyzing concurrent systems, namely process algebra and Petri nets, could be integrated. At the time, several members of both groups were interested in this topic. Thus, I had a very good start in my first year. The results that I obtained during that year form the basis of Chapter 3 of this thesis. Unfortunately, as any Ph. D. student experiences sooner or later, the good times did not last. Jos became Dean of the Faculty of Mathematics and Computing Science and Kees went to Bakkenist Management Consultants. In addition, the faculty had to cut back costs and was being reorganized. The atmosphere was spoiled and the interest in the topic of my research diminished. At that time, I had serious doubts whether I made the right choice to become a Ph. D. student.", "num_citations": "5\n", "authors": ["574"]}
{"title": "Adaptive predictive control for pipelined multiprocessor image-based control systems considering workload variations\n", "abstract": " Image-based control (IBC) systems have a long sensing delay. The advent of multiprocessor platforms helps to cope with this delay by pipelining of the sensing task. However, existing pipelined IBC system designs are based on linear timeinvariant models and do not consider constraint satisfaction, system nonlinearities, workload variations and/or given interframe dependencies which are crucial for practical implementation. A pipelined IBC system implementation using a model predictive control (MPC) approach that can address these limitations making a step forward towards real-life adaptation is thus promising. We present an adaptive MPC formulation based on linear parameter-varying input/output models for a pipelined implementation of IBC systems. The proposed method maximizes quality-of-control by taking into account workload variations in the image processing for individual pipes in the sensing\u00a0\u2026", "num_citations": "4\n", "authors": ["574"]}
{"title": "Monotonic optimization of dataflow buffer sizes\n", "abstract": " Many high data-rate video-processing applications are subject to a trade-off between throughput and the sizes of buffers in the system (the storage distribution). These applications have strict requirements with respect to throughput as this directly relates to the functional correctness. Furthermore, the size of the storage distribution relates to resource usage which should be minimized in many practical cases. The computation kernels of high data-rate video-processing applications can often be specified by cyclo-static dataflow graphs. We therefore study the problem of minimization of the total (weighted) size of the storage distribution under a throughput constraint for cyclo-static dataflow graphs. By combining ideas from the area of monotonic optimization with the causal dependency analysis from a state-of-the-art storage optimization approach, we create an algorithm that scales better than the state-of-the\u00a0\u2026", "num_citations": "4\n", "authors": ["574"]}
{"title": "Dependable Interference-aware Time-slotted Channel Hopping for Wireless Sensor Networks\n", "abstract": " TSCH divides time into fixed time periods called timeslots. Based on this, TSCH uses a TDMA-based mechanism together with a channel hopping scheme to assign different [timeslot, channel] pairs to each communication link in the network. Using this technique, TSCH provides availability of service by guaranteeing the access of wireless nodes to the medium. It also increases the reliability of the links against persistent multi-path fading and interference. There is a considerable work done on increasing performance and end-to-end reliability of low-power TSCH mesh networks. This includes works on configuring and improving performance of TSCH itself such as [8, 25, 30, 36, 37], and also works that consider the layers on top of TSCH such as [12, 13, 18, 23, 24, 34]. However, to meet the stringent requirements of industrial applications such as sub-second latency and reliable communications in in-vehicle networks, more work needs to be done [38]. IEEE 802.15. 4 [5] defines 16 frequency channels in the license-free 2.4 GHz ISM band. This band is also used by other standards including IEEE 802.11 Wi-Fi [2] and IEEE 802.15. 1 Bluetooth [1]. The common usage of this band leads to cross-technology interference and packet losses, especially for the WSNs that use low power communication. The authors of [32] categorize interference in in-vehicle environments into interference of in-car and out-of-car sources. They show that cross-technology interference of Wi-Fi and Bluetooth devices inside a car affects the performance of in-vehicle TSCH WSNs due to low distance of these interferers to the sensor nodes. It is also shown that out-of-car\u00a0\u2026", "num_citations": "4\n", "authors": ["574"]}
{"title": "Analysis and visualization of execution traces of dataflow applications\n", "abstract": " I. OBJECTIVES Embedded applications are an integral part of modern embedded systems. These applications typically have realtime constraints on throughput or latency. Temporal analysis techniques are required at the design stage to ensure that the applications meet their constraints and determine the required amount of resources (processors or memories for the application).The Synchronous Dataflow Graph (SDFG)[4] model of computation is a popular method for temporal analysis of applications. SDFG represents the application by a graph consisting of actors and channels. Actors represent the individual computations within the application. Each actor has an execution time which usually indicates the upper bound on the time it requires to complete its firing (execution), once it is started. Channels model the dependencies of individual computational tasks on the resources, on input data, and on the data produced by other tasks. When an actor starts and completes firing, it consumes and produces a fixed amount of tokens on the FIFO channels respectively. An actor is able to fire if its consumption rates are not greater than the number of tokens on the channels from which it consumes. Figure 1 shows two SDFGs. Each SDFG models a working mode of a single application. Each mode has three actors. The execution time of actors x, y and z are assumed to be 101, 73 and 125 milliseconds in both modes respectively. The numbers near the channel endings indicate the consumption and production rates. The actors are bound to different processors in different modes. This property is modeled by having a self edge on each actor which\u00a0\u2026", "num_citations": "4\n", "authors": ["574"]}
{"title": "Multi-constraint multi-processor resource allocation\n", "abstract": " This work proposes a Multi-Constraint Resource Allocation (MuCoRA) method for applications from multiple domains onto multi-processors. In particular, we address a mapping problem for multiple throughput-constrained streaming applications and multiple latency-constrained feedback control applications onto a multi-processor platform running under a Time-Division Multiple-Access (TDMA) policy. The main objective of the proposed method is to reduce resource usage while meeting constraints from both these two domains (i.e., throughput and latency constraints). We show by experiments that the overall resource usage for this mapping problem can be reduced by distributing the allocated resource (i.e., TDMA slots) to the control applications over the TDMA wheel instead of allocating consecutive slots.", "num_citations": "4\n", "authors": ["574"]}
{"title": "Motrusca: interactive model transformation use case repository\n", "abstract": " Modeling and model transformations tools are maturing and are being used in larger and more complex projects. The advantage of a modeling environment and its transformation tools cannot be easily exploited by non-expert users as many subtle intricacies determine the efficiency of transformation languages and their tools. We introduce transformation use case examples that highlight such language/tooling properties. These simple, non-trivial examples have been extracted from an experiment with transformations of Design Space Exploration models. These examples show some typical modeling patterns and we give some insight how to address the examples. We make a case for initiating an interactive, on-line repository for model transformation use cases. This repository is aimed to be example-centric and should facilitate the interaction between end-users and tooling developers, while providing a means for comparing the applicability, expressivity, and efficiency of transformation tools.", "num_citations": "4\n", "authors": ["574"]}
{"title": "Fast sink placement for gossip-based wireless sensor networks\n", "abstract": " In this paper we address the problem of sink placement for Gossip-based Wireless Sensor Networks (GWSN). Sink placement plays an important role in planning and deployment of sensor networks. It is an efficient means to improve performance and achieve design objectives. Sink deployment requires an optimization strategy to search a space of possible placement options, and a performance evaluation method to assess the quality of different sink placements. The stochastic nature of the gossip protocol makes this task challenging for GWSN. Simulation is the most common way to accurately evaluate gossiping performance; however, the time required to obtain statistically significant results is considerable and limits the scalability of the sink deployment process. We use a fast and accurate performance evaluation technique, which exploits specifics of the sink placement problem and significantly reduces\u00a0\u2026", "num_citations": "4\n", "authors": ["574"]}
{"title": "Collaborative multiobjective global routing\n", "abstract": " This paper presents a collaborative procedure for multiobjective global routing. Our procedure takes multiple global routing solutions, which are generated independently (e.g., by one router that runs in different modes concurrently or by different routers running in parallel), as input. It then performs multiobjective optimization based on Pareto algebra and quickly generates multiple global routing solutions with a tradeoff between the considered objectives. The user can control the number of generated solutions and the degree of exploring the tradeoff between them by constraining the maximum allowable degradation in each objective. This paper then considers the following three multiobjective case studies: 1) minimization of interconnect power and wirelength; 2) minimization of routing congestion and wirelength; and 3) minimization of wirelength with respect to the (finite-capacity) routing resources. The maximum\u00a0\u2026", "num_citations": "4\n", "authors": ["574"]}
{"title": "Distributed maintenance of minimum-cost path information in wireless sensor networks\n", "abstract": " The quality of the communication links in a Wireless Sensor Network often shows significant asymmetry and variation over time, due to, for example, heterogeneous settings of the transmission power, moving nodes or changing external interference. This makes it difficult for nodes to accurately maintain system-level properties, such as the minimum-energy path from the node to a given reference node, as required by many protocols. In this paper, we introduce a distributed service that allows nodes to maintain accurate information related to the minimum-cost path, such as its cost or parent on that path. Using controlled n-hop forwarding, to deal with asymmetric links, every node disseminates minimum-cost path and connectivity information allowing every connected node in the network to iteratively derive minimum-cost path information. This controlled n-hop forwarding is repeated to avoid stale information due to\u00a0\u2026", "num_citations": "4\n", "authors": ["574"]}
{"title": "A visual language for modeling and analyzing printer data path architectures\n", "abstract": " The data path is an important printer component that performs real-time image processing. Because of the large data sizes and high throughput requirements in high-performance multifunctional printers, the data path is usually implemented as a hybrid software/hardware system. Designing the architecture of a data path is a nontrivial problem, because of the many tradeoffs involved and because it is difficult to analyze how well a design conforms to many of the important quality attributes. One quality attribute that is difficult to deduce from a data path design by hand is its throughput, typically expressed as the amount of pages that it can handle per minute. Because this is hard to analyze by hand, it is also difficult to predict how well a data path will perform when requirements change. This limits how structured and flexible the data path design process can be.In order to improve this process, a solution is needed that helps architects to analyze the behavior of a model of a data path architecture, find its throughput and identify bottlenecks. The solution must be sustainable, so that support for increasingly detailed architecture models can be added.", "num_citations": "4\n", "authors": ["574"]}
{"title": "Predicting the throughput of multiprocessor applications under dynamic workload\n", "abstract": " This work contributes to throughput calculation for real-time multiprocessor applications experiencing dynamic workload variations. We focus on a method to predict the system throughput when processing an arbitrarily long data frame given the meta-characteristics of the workload in that frame. This is useful for different purposes, such as resource allocation or dynamic voltage scaling in embedded systems. An accurate enough analysis is not trivial when two factors are combined: parallelism and dynamic workload variations. In earlier work, two analysis methods showed good accuracy for several application examples, but no comparative experiments were carried out. In this work, we contribute new propositions to the theoretical basis of the previous methods. Based on these propositions, we remove a potential problem in a common subroutine and propose a new analysis method.We compare the methods\u00a0\u2026", "num_citations": "4\n", "authors": ["574"]}
{"title": "Real-time step motor emulator for hardware-in-the-loop simulation\n", "abstract": " It is not possible to do automatic testing with step motors in Hardware-in-the-Loop (HIL) simulators because motors may be overheated if working for a long time. Furthermore, possibilities for fault injection are limited and physical interaction is needed to inject faults like a breakdown that can actually be mimicked. We present an emulator in an FPGA that allows to emulate a step motor for automatic testing as well as fault injection for a variety of faults, with the option of emulating more than one step motor in the same FPGA.", "num_citations": "4\n", "authors": ["574"]}
{"title": "An Overview of Application Scenario Usage in Streaming-Oriented Embedded System Design\n", "abstract": " In the past years real-time embedded systems became more and more complex. From the user perspective, these systems have stringent requirements regarding size, performance and power consumption, and due to business competition, their time-to-market is a crucial factor. Therefore, much work has been done in developing design methodologies for embedded systems to cope with these tight requirements. In this report, we present a basic methodology based on the concept of application scenarios for real-time embedded systems design. We show the distinction between application scenarios and use-case scenarios. Moreover, we give a literature overview of application scenario usage in embedded system design for obtaining a faster implementation, an energy saving implementation, or a better estimation of the resources required by an application.", "num_citations": "4\n", "authors": ["574"]}
{"title": "Sharper WCET upper bounds using automatically detected scenarios\n", "abstract": " Modern embedded applications usually have real-time constraints and they are implemented using heterogeneous multiprocessor systems-on-chip. Dimensioning a system requires accurate estimations of the worst-case execution time (WCET). Overestimation leads to over-dimensioning. This paper introduces a method for automatic discovery of scenarios that incorporate correlation between different parts of applications. It is based on the application parameters with a large impact on the execution time. We show on a benchmark that using scenarios the estimated WCET may be reduced with 16%.", "num_citations": "4\n", "authors": ["574"]}
{"title": "Static resource models for code-size efficient embedded processors\n", "abstract": " Due to an increasing need for flexibility, embedded systems embody more and more programmable processors as their core components. Due to silicon area and power considerations, the corresponding instruction sets are often highly encoded to minimize code size for given performance requirements. This has hampered the development of robust optimizing compilers because the resulting irregular instruction set architectures are far from convenient compiler targets. Among other considerations, they introduce an interdependence between the tasks of instruction selection and scheduling. This so-called phase coupling is so strong that, in practice, instruction selection rather than scheduling is responsible for the quality of the schedule, which tends to disappoint. The lack of efficient compilation tools has also severely hampered the design space exploration of code-size efficient instruction sets, and\u00a0\u2026", "num_citations": "4\n", "authors": ["574"]}
{"title": "Omnia fieri possent\n", "abstract": " Tom is in a good mood this morning. It\u2019s Friday and tonight he\u2019s going to the movies with Amy. After a shower \u201ahe briefly reviews the movies that are showing tonight. Info and clips are displayed by his new bathroom mirror. He requests a preview of \u201cYou\u2019ve got mail \u201a\u201d which is a rerun of some old movie about an e-mail romance. Personally \u201ahe would like to see some more action \u201abut Amy will definitely love this one.After breakfast he hops into a PeopleMover to go to the office. It\u2019s quiet this morning. He requests some music. The audio system of the PeopleMover starts playing one of his favorite songs \u201ausing his preferences from his SmartId. He decides to book \u201cYou\u2019ve got mail.\u201d Payment goes through his SmartId \u201aand tickets are downloaded onto it. He also makes dinner reservations.[...] At ten past five \u201aTom hurries out of his office to a PeopleMover that will take him to the city center. Silly staff meetings. They always\u00a0\u2026", "num_citations": "4\n", "authors": ["574"]}
{"title": "Verifying Petri-Net Models Using Process Algebra\n", "abstract": " munication protocol between the various parts of the system plays an important role. It is not very well suited for data-oriented applications. However, if Petri nets and process algebra both focus on dynamic system behaviour, what then is the use of combining them? The answer is simple: They complement each other very well. Petri nets have an easy-to-understand, graphical representation and are well suited to describe the dynamic behaviour of a system including the states in which the system can be. Hence, Petri nets are very useful for purposes of system validation and simulation. Process algebra, on the other hand, is a compositional, purely symbolic formalism, designed to compare the dynamic behaviour of dierent systems. It is most often used in verication. By applying term rewriting techniques and equational reasoning, it can be veried whether an implementation satises a given specication, where both specication and implementation are algebraic terms. Based on the above obs", "num_citations": "4\n", "authors": ["574"]}
{"title": "Modelling the role of the design context in the design process. A Domain-independent approach\n", "abstract": " Domain-independent models of the design process are an important means for facilitating interdisciplinary communication and for supporting multidisciplinary design. Many so-called domain-independent models are, however, not really domain independent. We state that, to be domain independent, the models must abstract from domain-specific aspects, be based on the study of several design disciplines, and be useful for many design disciplines and for multidisciplinary design teams. This paper describes a domain-independent descriptive design model that is developed by studying similarities and differences between design processes in a few design disciplines. The model is based on the general theory of state transitions. We modelled a design situation as a state at a certain moment and a design activity as a transition. We also explicitly modelled the role of the design context in design processes. In our empirical studies, we noticed the influence of the design context on the product being designed and the design process and the importance of communication between designers and stakeholders in the design context regularly during the design process. Making designers aware of the role of the design context can improve the quality of both the product being designed and the design process. The role of the design context is, however, often not explicitly taken into account in design models. We modelled the design context as part of the state at a certain moment and interaction with the design context as one of the activities performed by designers.", "num_citations": "4\n", "authors": ["574"]}
{"title": "Event abstraction in modeling distributed computations\n", "abstract": " A well-known problem in event-based models of distributed computations is the amount and complexity of behavioral information. Event abstraction can be used to reduce the apparent complexity of a computation. Four aspects of event abstraction are studied: a model describing primitive behavior, a formalism for specifying abstract behavior, abstract descriptions of behavior, and verification of primitive or abstract descriptions against specified behavior. This paper discusses the issues involved in each of these four aspects, presents basic results, and identifies remaining problems.", "num_citations": "4\n", "authors": ["574"]}
{"title": "Design and management of image processing pipelines within CPS: 2 years of experience from the FitOptiVis ECSEL Project\n", "abstract": " Cyber-Physical Systems (CPS) are dynamic and reactive systems interacting with processes, environment and, sometimes, humans. They are often distributed with sensors and actuators, smart, adaptive, predictive and react in real-time. Indeed, as sight for human beings, image- and video-processing pipelines are a prime source for environmental information for systems allowing them to take better decisions according to what they see. Therefore, in FitOptiVis we are developing novel methods and tools to integrate complex image and video processing pipelines. FitOptiVis aims to deliver a reference architecture for describing and optimizing quality and resource management for imaging and video pipelines in CPS both at design- and run-time. The architecture is concretized in low-power, high-performance, smart components, and in methods and tools for combined design-time and run-time multi-objective\u00a0\u2026", "num_citations": "3\n", "authors": ["574"]}
{"title": "Trading digital accuracy for power in an RSSI computation of a Sensor Network Transceiver\n", "abstract": " To handle the rigid power and energy constraints in the Digital BaseBand (DBB) of Wireless Sensor Networks (WSN)s, we introduce approximate computing as a new power reduction method. The Received Signal Strength Indicator (RSSI) computation is a key element in DBB processing. We evaluate the trade-off in RSSI computation between Quality-of-Service (QoS) and power consumption through circuit-level approximation. RSSI elements are approximated in such a way that error propagation is minimized. In an industrial 40-nm CMOS technology, substantial energy savings up to 24% are achieved for every successfully transferred bit in DBB processing in a low- power listening WSN scenario.", "num_citations": "3\n", "authors": ["574"]}
{"title": "Parametric critical path analysis for event networks with minimal and maximal time lags\n", "abstract": " High-end manufacturing systems are cyber-physical systems, where productivity depends on the close cooperation of mechanical (physical) and scheduling (cyber) aspects. Mechanical and control constraints impose minimal and maximal time differences between events in the product flow. Sequence-dependent constraints are used by a scheduler to optimize system productivity while satisfying operational requirements. The numerous constraints in a schedule are typically related to a relatively small set of parameters, such as speeds, lengths, or settling times. We contribute a parametric critical path algorithm that identifies bottlenecks in terms of the feasible parameter combinations. This algorithm allows analysis of schedules to identify bottlenecks in terms of the underlying cause of constraints. We also contribute a way to find Pareto-optimal cost-performance tradeoffs and their associated parameter\u00a0\u2026", "num_citations": "3\n", "authors": ["574"]}
{"title": "Guard-time design for symmetric synchronization in IEEE 802.15. 4 time-slotted channel hopping\n", "abstract": " Time-Slotted Channel Hopping (TSCH) is considered as one of the most reliable MAC solutions for low- power wireless networking. In order to establish time-slotted communications, this technique requires all nodes to remain synchronized. The synchronization is continuously done through normal communications to compensate the clock drift between different nodes. In this paper, we present a detailed look into the behavior of the IEEE 802.15.4 PHY and MAC in terms of the synchronization task. We show that the relation between timeslot offsets provided by the standard leads to different synchronization error margins for positive and negative relative clock drifts. This is due to the time required for detection of ongoing transmissions at receivers. This may lead to the situation that two nodes are able to communicate in only one direction. Depending on which node is the source node, the available margin to\u00a0\u2026", "num_citations": "3\n", "authors": ["574"]}
{"title": "Iterative robust multiprocessor scheduling\n", "abstract": " General purpose platforms are characterized by unpredictable timing behavior. Real-time schedules of tasks on general purpose platforms need to be robust against variations in task execution times. We define robustness in terms of the expected number of tasks that miss deadlines. We present an iterative robust scheduler that produces robust multiprocessor schedules of directed acyclic graphs with a low expected number of tasks that miss their deadlines. We experimentally show that this robust scheduler produces significantly more robust schedules in comparison to a scheduler using nominal execution times on both real world and synthetic test cases.", "num_citations": "3\n", "authors": ["574"]}
{"title": "Improving end-to-end packet delivery in high traffic multi-hop wireless ad hoc networks\n", "abstract": " Accurate link quality estimation is an important building block in quality aware routing. In an inherently lossy, unreliable and dynamic medium such as wireless, the task of accurate estimation becomes very challenging. Over the years ETX has been widely used as a reliable link quality estimation metric. However, more recently it has been established that under heavy traffic loads ETX performance gets significantly worse [4, 18, 19]. Contributions made in this paper are twofold. Firstly, we examine the ETX metric\u2019s behavior in detail with respect to the MAC layer and UDP data; and identify the causes of its unreliability. Secondly, we present the design and implementation of the xDDR link quality measurement metric \u2013 a variation of ETX - motivated by the observations made in our analysis. Our experiments show that xDDR substantially outperforms minimum hop count, ETX and HETX in packet delivery ratio.", "num_citations": "3\n", "authors": ["574"]}
{"title": "A distributed feedback control mechanism for quality-of-service maintenance in wireless sensor networks\n", "abstract": " Wireless sensor networks are typically operating in a dynamic context where events, such as moving sensor nodes and changing external interference, constantly impact the quality-of-service of the network. We present a distributed feedback control mechanism that actively balances multiple conflicting network-wide quality metrics, such as power consumption and end-to-end packet latency, for a heterogeneous wireless sensor network operating in a dynamic context. Nodes constantly decide if and how to adapt controllable parameters of the entire protocol stack, using sufficient information of the current network state. Using experiments with an actual deployment we show that our controller allows to maintain the required network-wide quality-of-service, with up to 30% less power consumed, compared to the most applicable (re-)configuration approaches.", "num_citations": "3\n", "authors": ["574"]}
{"title": "Parameterized partial orders for modeling embedded system use cases: Formal definition and translation to coloured Petri nets\n", "abstract": " Model-driven Design-Space Exploration (DSE) for embedded systems has proven to speed up system design and improve quality. Parameterized Partial Orders (PPOs) are a simple yet powerful conservative extension of classical partial orders. They serve as an intermediate representation in our Octopus tool set, allowing to capture applications from different domains and enabling analysis with various tools. We present PPOs, their translation to Coloured Petri Nets, and their use in DSE for a printer case study.", "num_citations": "3\n", "authors": ["574"]}
{"title": "Computational Models for Concurrent Streaming Applications\n", "abstract": " Computational Models for Concurrent Streaming Applications Page 1 Computational Models for Concurrent Streaming Applications Twan Basten Based on joint work with Marc Geilen, Sander Stuijk, and many others \u2018Knowing is not understanding.\u2019 Charles Kettering Department of Electrical Engineering Electronic Systems 2 The challenges of today The problem: an example printer platform \u2022 Use-cases to be mapped onto a professional printer \u2022 Copying (black&white, color, various paper sizes, zoom factors, \u2026) \u2022 Printing \u2022 Scanning \u2022 Simultaneous printing and scanning 3 printer platform \u2022 How many CPUs, GPUs ? \u2022 Processor speeds ? \u2022 How to achieve X images/min ? \u2022 Double resolution ? \u2022 Run-time changes in speed, job type, power budget \u2026 ? challenges models the hierarchy analysis the future kpn rpn \u2022 Reliable, resource-efficient embedded systems \u2022 Fast, predictable design trajectories Objectives 4 \u2026", "num_citations": "3\n", "authors": ["574"]}
{"title": "Dynamic-SIMD for lens distortion compensation\n", "abstract": " An increasing computational demand is placed on the image processing capacity of current and future smart cameras. SIMD processor architectures provide an efficient solution because their repetitive structure matches the data-parallel execution pattern inherent in pixel-type processing. But the lack of support for communicating pixel data over variable distances has forced designers to allocate dedicated hardware or FPGAs for compensating lens distortion and other non-linear operations. We propose a hardware extension to SIMD processors that enables dynamic communication. Using detailed area cost models and a high-level simulator we optimize the extension with regard to the number of buses, bus arbitration policies, and local instruction buffer sizes", "num_citations": "3\n", "authors": ["574"]}
{"title": "Estimation of Execution Times of On-chip Multiprocessors Stream-oriented Applications.\n", "abstract": " Extended Abstract: Estimation of Execution Times of On-chip Multiprocessors Stream-oriented Applications. \u2014 Eindhoven University of Technology research portal Skip to main navigation Skip to search Skip to main content Eindhoven University of Technology research portal Logo Help & FAQ English Nederlands Home Researchers Research Output Organisational units Activities Projects Prizes Press / Media Facilities / Equipment Datasets Courses Research areas Student theses Search by expertise, name or affiliation Extended Abstract: Estimation of Execution Times of On-chip Multiprocessors Stream-oriented Applications. P. Poplavko, T. Basten, M. Pastrnak, J. Meerbergen, van, MJG Bekooij, PHN With, de Electronic Systems Signal Processing Systems Research output: Chapter in Book/Report/Conference proceeding \u203a Conference contribution \u203a Academic \u203a peer-review 2 Citations (Scopus) Overview Original \u2026", "num_citations": "3\n", "authors": ["574"]}
{"title": "Analyzing concurrency in computational networks\n", "abstract": " We present a concurrency model that allows reasoning about concurrency in executable specifications. The model mainly focuses on data-flow and streaming applications and at task-level concurrency. The aim of the model is to provide insight in concurrency bottlenecks in an application and to provide support for performing implementation independent concurrency optimization.", "num_citations": "3\n", "authors": ["574"]}
{"title": "Mapping of an mpeg-4 shape-texture decoder onto an on-chip multiprocessor\n", "abstract": " This paper presents a mapping approach targeting a distributed-memory on-chip multiprocessor platform. A differentiating factor of our approach is that we strive to ensure predictable performance. The approach is biased towards video-decoding application domain, and we a use the MPEG-4 shape-texture decoder job of [3] as a case study. We map that job to three processors and obtain the job worst-case execution time (JWCET) for predictable performance. However, highly dynamic data-dependent behavior of this benchmark can lead to huge overestimations of JWCET even when employing the approach of [1], which uses run-time knowledge of input data parameters. We improve this approach, by introducing scenarios, similar to [4]. For some reference input data stream, the use of scenarios has reduced JWCET overestimation from 177% to 55%.", "num_citations": "3\n", "authors": ["574"]}
{"title": "Diagnosing workflow processes using Woflan\n", "abstract": " Diagnosing workflow processes using Woflan (2000) | www.narcis.nl KNAW KNAW Narcis Back to search results Eindhoven University of Technology Publication Diagnosing workflow processes using Woflan (2000) Open access . Pagina-navigatie: Main Save publication Save as MODS Export to Mendeley Save as EndNote Export to RefWorks Title Diagnosing workflow processes using Woflan Series BETA publicatie : working papers, 48 Author Verbeek, HMW; Basten, T.; Aalst, van der WMP Publisher Department of Mathematics and Computer Science; Information Systems IE&IS; Information Systems - BETA Date issued 2000 Access Open Access Language English Type Report Publisher Technische Universiteit Eindhoven Publication https://research.tue.nl/nl/publications/diagnosing-workflow-... ISBN 90-386-0843-8 Persistent Identifier urn:nbn:nl:ui:25-5817f1da-0fdb-464a-bd0c-e91fd817203a Related Working \u2026", "num_citations": "3\n", "authors": ["574"]}
{"title": "Model-Driven System-Performance Engineering for Cyber-Physical Systems: Industry Session Paper\n", "abstract": " System-Performance Engineering (SysPE) encompasses modeling formalisms, methods, techniques, and industrial practices to design systems for performance, where performance is taken integrally into account during the whole system life cycle. Industrial SysPE state of practice is generally model-based. Due to the rapidly increasing complexity of systems, there is a need to develop and establish model-driven methods and techniques. To structure the field of SysPE, we identify (1) industrial challenges motivating the importance of SysPE, (2) scientific challenges that need to be addressed to establish model-driven SysPE, (3) important focus areas for SysPE and (4) best practices. We conducted a survey to collect feedback on our views. The responses were used to update and validate the identified challenges, focus areas, and best practices. The final result is presented in this paper. Interesting observations are\u00a0\u2026", "num_citations": "2\n", "authors": ["574"]}
{"title": "Multi-layer multi-rate model predictive control for vehicle platooning under IEEE 802.11 p\n", "abstract": " Vehicle platooning has gained attention for its potential to increase road capacity and safety, and higher fuel efficiency. Platoon controls are implemented over Vehicle-to-Vehicle (V2V) wireless communication, in-vehicle networks and Electronic Control Units (ECUs). V2V communication has a low message rate imposed by the V2V standard compared to the rate of modern in-vehicle networks and ECUs. The platoon control strategy should take into account such multi-rate nature of the implementation architecture for higher performance. Current literature does not explicitly consider such real-life constraints. We propose a two-layered control framework for vehicle platoons wirelessly communicating complying with the industrial standard IEEE 802.11p. In the upper-layer, vehicles receive state information from the immediate preceding vehicle over a control channel at 10\u00a0Hz under the IEEE 802.11p standard with\u00a0\u2026", "num_citations": "2\n", "authors": ["574"]}
{"title": "Trading sensitivity for power in an IEEE 802.15. 4 conformant adequate demodulator\n", "abstract": " In this work, a design of an IEEE 802.15.4 conformant O-QPSK demodulator is proposed, which is capable of trading off receiver sensitivity for power savings. Such design can be used to meet rigid energy and power constraints for many applications in the Internet-of-Things (IoT) context. In a Body Area Network (BAN), for example, the circuits need to operate with extremely limited energy sources, while still meeting the network performance requirements. This challenge can be addressed by the paradigm of adequate computing, which trades off excessive quality of service for power or energy using approximation techniques. Three different, adjustable approximation techniques are integrated into the demodulation to trade off effective signal quantization bit-width, filtering performance, and sampling frequency for power. Such approximations impact incoming signal sensitivity of the demodulator. For detailed tradeoff\u00a0\u2026", "num_citations": "2\n", "authors": ["574"]}
{"title": "SMT-based verification of temporal properties for component-based software systems\n", "abstract": " We introduce a technique to verify temporal properties expressed in MTL on Interval Message Sequence Charts (IMSC), a model based on UML2.0 MSC that captures the timed execution of component-based software systems. We accomplish this by encoding the IMSC and the property of interest in a constraint satisfaction problem, which is then solved with an SMT solver. We demonstrate the scalability of this technique with a synthetic case study and a large-scale industrial case study.", "num_citations": "2\n", "authors": ["574"]}
{"title": "Scenarios in dataflow modeling and analysis\n", "abstract": " Dataflow models can be used to model and program concurrent systems and applications. Static timed dataflow models commonly abstract the temporal behavior of systems in terms of their worst-case behaviors. This may lead to models that are very pessimistic. The scenario methodology can be applied to the dataflow modeling approach to group similar dynamic behaviors into static dataflow behaviors that abstract the system scenarios in a tight fashion. Constraints on the possible scenario transitions in the system can be modeled, among other options, by a finite state automaton. This approach leads to a model called scenario-aware dataflow (SADF) that is presented in this chapter. We introduce the model and its semantics and discuss its fundamental analysis techniques. We discuss a parameterized extension and its analysis. We discuss a dataflow programming model and its implementation\u00a0\u2026", "num_citations": "2\n", "authors": ["574"]}
{"title": "Parametric scheduler characterization\n", "abstract": " Schedulers assign starting times to events in a system such that a set of constraints is met and system productivity is maximized. We characterize the scheduler behaviour for the case where decisions are made by comparing affine expressions of design parameters such as task workload, processing speed, robot travelling speed, or a controller\u2019s rise and settling time. Deterministic schedulers can be extended with symbolic execution, to keep track of the affine conditions on the parameters for which the scheduling decisions are made. We introduce a divide-and-conquer algorithm that uses this information to determine parameter regions for which the same sequence of decisions is taken given a particular scenario. The results provide designers insight in the impact of parameter changes on the performance of their system. The exploration can also be executed with the KLEE symbolic execution engine of the LLVM\u00a0\u2026", "num_citations": "2\n", "authors": ["574"]}
{"title": "Implementation-aware design of image-based control with on-line measurable variable-delay\n", "abstract": " Image-based control uses image-processing algorithms to acquire sensing information. The sensing delay associated with the image-processing algorithm is typically platform-dependent and time-varying. Modern embedded platforms allow to characterize the sensing delay at design-time obtaining a delay histogram, and at run-time measuring its precise value. We exploit this knowledge to design variable-delay controllers. This design also takes into account the resource configuration of the image processing algorithm: sequential (with one processing resource) or pipelined (with multiprocessing capabilities). Since the control performance strongly depends on the model quality, we present a simulation benchmark that uses the model uncertainty and the delay histogram to obtain bounds on control performance. Our benchmark is used to select a variable-delay controller and a resource configuration that\u00a0\u2026", "num_citations": "2\n", "authors": ["574"]}
{"title": "Understanding the impact of circuit-level inaccuracy on sensor network performance\n", "abstract": " Energy efficiency is of paramount importance in designing lowpower wireless sensor nodes. Approximate computing is a new circuit-level technique for reducing power consumption. However, the gain in power by applying this technique is achieved at the cost of computational errors. The impact of such inaccuracies in the circuit level of a radio transceiver chip on the performance of Wireless Sensor Networks (WSNs) has not yet been explored. The applicability of such low-power chip design techniques depends on the overall energy gain and their impact on the network performance. In this paper, we analyze various inaccuracy fields in a radio chip, and quantify their impact on the network performance, in terms of packet latency, goodput, and energy per bit. The analysis is supported by extensive network simulations. The outcome can be used to investigate in which WSN application scenarios such power\u00a0\u2026", "num_citations": "2\n", "authors": ["574"]}
{"title": "Firmness analysis of real-time applications under static-priority preemptive scheduling\n", "abstract": " (m, k)-firm real-time tasks must meet the deadline of at least m jobs out of any k consecutive jobs to satisfy the firmness requirement. Scheduling of an (m,k)-firm task requires firmness analysis, whose results are used to provide system-level guarantees on the satisfaction of firmness conditions. We address firmness analysis of an (m, k)-firm task that is intended to be added to a set of asynchronous tasks scheduled under a Static-Priority Preemptive (SPP) policy. One of the main causes of deadline misses in periodic tasks running under an SPP policy is interference from higher priority tasks. Since the synchrony between the newly added task and higher priority tasks is unknown, the interference from the higher priority tasks is also unknown. We propose an analytic Firmness Analysis (FAn) method to obtain a synchrony that results in the maximum minimum number of deadline hit jobs in any k consecutive jobs of the\u00a0\u2026", "num_citations": "2\n", "authors": ["574"]}
{"title": "INLyD: Inter-network-layer delay as a low-cost quality metric for multi-hop routing in wireless mobile networks\n", "abstract": " The need for authentic and effective portrayal of the spatio-temporally changing quality of wireless links has gained wide attention especially over the last decade. Software-based link quality estimators (LQE) classify links with help of packet reception ratio (PRR), required number of packet transmissions (RNP) and scoring/grading schemes that again utilize PRR, RNP or retransmission based heuristics. On the contrary, this paper makes a case for inter-network-layer delay as a classification metric to boost end-to-end packet delivery in multi-hop communication. In essence our Inter-Network-Layer Delay metric (INLyD) uses a simplistic receiver-side in-band signaling scheme to passively accumulate queuing, retrying, back-off, transmission and propagation delay statistics while generating no additional control packet overhead. Our experiments show that the INLyD metric is not only light-weight (25% less MAC\u00a0\u2026", "num_citations": "2\n", "authors": ["574"]}
{"title": "Communication aware multiprocessor binding for shared memory systems\n", "abstract": " We present a three-step binding algorithm for applications in the form of directed acyclic graphs (DAGs) of tasks with deadlines, that need to be bound to a shared memory multiprocessor platform. The aim of the algorithm is to obtain a good binding that results in low makespans of the schedules of the DAGs. It first clusters tasks assuming unlimited resources using a deadline-aware shared memory extension of the existing dominant sequence clustering algorithm. Second, the clusters produced are merged based on communication dependencies to fit into the number of available platform resources. As a final step, the clusters are allocated to the available resources by balancing the workload. The approach is compared to the state of the art bounded dominant sequence clustering (BDSC) algorithm that also performs clustering on a limited number of resources. We show that our three-step algorithm makes better\u00a0\u2026", "num_citations": "2\n", "authors": ["574"]}
{"title": "Multi-Domain Virtual Prototyping in a SystemC SIL framework: A heating system case study\n", "abstract": " This paper presents a proof-of-concept for a modular SystemC SIL (Software-in-the-Loop) simulation environment, using a blackboard-like architecture. The proposed SIL framework integrates embedded control software with simulators developed in SystemC/SystemC-AMS or external tools, like MATLAB. The environment has been validated by a heating application for a professional printer, as example of an MDVP (Multi-Domain Virtual Prototyping) application. Our goal is to evaluate the use of SystemC/SystemC-AMS and to address the challenges in developing multiple-domain prototypes and blackboard-like SIL frameworks using this technology.", "num_citations": "2\n", "authors": ["574"]}
{"title": "Conto Exam: an ontology on context-aware\n", "abstract": " Patient observations in health care, subjective surveys in social research or dyke sensor data in water management are all examples of measurements. Several ontologies already exist to express measurements, W3C's SSN ontology being a prominent example. However, these ontologies address quantities and properties as being equal, and ignore the foundation required to establish comparability between sensor data. Moreover, a measure of an observation in itself is almost always inconclusive without the context in which the measure was obtained. ContoFxam addresses these aspects, providing for a unifying capability for context-aware expressions of observations about quantities and properties alike, by aligning them to ontological foundations, and by binding observations inextricably with their context.", "num_citations": "2\n", "authors": ["574"]}
{"title": "Adaptivity in professional printing systems\n", "abstract": " There is a constant pressure on developers of embedded systems to simultaneously increase system functionality and to decrease development costs. Aviable way to obtain a better system performance with the same physical hardware is adaptivity: a system should be able to adapt itself to dynamically changing circumstances. The development of adaptive embedded systems has been the topic of the Octopus project, an industry-as-laboratory project of the Embedded Systems Institute, with the professional printer domain of Oc\u00e9-Technologies B.V.as an industrial carrier. The project has resulted in techniques and tools for model-based development of adaptive embedded systems including component-level and system-level control strategies, system architecting tools, and automatic generation of system software. This introductory chapter presents the Octopus project and provides a reading guide for this\u00a0\u2026", "num_citations": "2\n", "authors": ["574"]}
{"title": "Designing next-generation real-time streaming systems\n", "abstract": " The design of next-generation systems running streaming applications is becoming extremely challenging as these systems are executing many real-time applications concurrently. To address this design challenge, predictable multi-processor systems-on-chip platforms and accompanying model-based design approaches are being developed. This tutorial presents an overview of future platforms and design approaches needed to design next-generation embedded systems for real-time streaming applications. During the hands-on session the participants apply this theory to a practical example.", "num_citations": "2\n", "authors": ["574"]}
{"title": "Run-time reconfiguration of communication in simd architectures\n", "abstract": " SIMD processors are increasingly used in embedded systems for multi-media applications because of their area- and energy-efficiency. Communication between the processing elements (PEs) in an SIMD processor has remained a cause of inefficiency however; the SIMD concept prescribes that all PEs communicate in the same clock cycle. Existing SIMD architectures solve this problem either by multi-hop communication (causing cycle overhead), or by a fully connected communication network (causing area overhead). To solve the communication bottleneck, we propose a reconfigurable SIMD architecture (RC-SIMD) with a set of delay-lines in the instruction bus, distributing the accesses to the communication network over time. We can (re-) configure the size and number of delay-lines, a specific configuration representing a trade-off between the number of clock cycles and the length of a clock period\u00a0\u2026", "num_citations": "2\n", "authors": ["574"]}
{"title": "A method for analysing the performance of certain testing techniques for concurrent systems\n", "abstract": " In this paper we develop a method for analysing and comparing the performance of different testing techniques for concurrent systems, and use it to give some evidence that the so-called \"exploration testing\" finds errors faster than traditional testing based on test cases. We model the system under test as a state space with a weight and cost assigned to each transition, and find the probability and expected cost of reaching terminal states. From this information, the probabilities and expected costs of finding errors using each method can be computed. A drawback of our method is that it is not feasible for arbitrarily large systems, but, in return, it gives results much quicker and with much higher precision than possible by running actual tests.", "num_citations": "2\n", "authors": ["574"]}
{"title": "Voltage-dependent Scanning Tunneling Microscopy on the {110}-surfaces of GaAs, AlGaAs and their heterostructures\n", "abstract": " Ever since the days of Galileo Galilei (1564-1642) and van Leeuwenhoek (1632-1723), telescopes and microscopes have played a vital role in the advancement of science. The importance of these instruments comes from the fact that they enable us to see what the physical universe looks like at a different characteristic length-scale than the one we know from our daily lives. And when we observe the universe at another length-scale than our own, it looks so different that it seems as if we enter an entirely new world. But do we really? In fact, we do not. Because regardless of the length-scale at which we choose to observe the universe, the physical laws that govern it remain the same. This means that what we observe at one length-scale, must have implications for the physical reality as we observe it at other length-scales. Herein lies the scientific value of microscopes and telescopes, whether we look at living cells and try to understand their chemistry, whether we gaze at stars and wonder about the physical processes that make them hot enough to emit vast amounts of light, or whether we study a crystal surface and ask ourselves what determines the distribution of its electronic states.A more recent addition to the different types of microscope available to scientists is the Scanning Tunneling Microscope (STM). The STM was invented by Binnig and Rohrer at the IBM research-laboratory near Z\u00fcrich, Switzerland, in 1981. Over the last 20 years, it has evolved from a new and interesting gadget to the fullyfledged experimental technique it is today. The first major success of the STM as an experimental tool has been the real-space imaging of the 7x7\u00a0\u2026", "num_citations": "2\n", "authors": ["574"]}
{"title": "Partial-Order Process Algebra\n", "abstract": " To date, many different formalisms exist for describing and analyzing the behavior of concurrent systems. Petri nets and process algebras are two well-known classes of such formalisms. Petri-net theory is well suited for reasoning about concurrent systems in a partial-order framework; it handles causal relationships between actions of concurrent systems in an explicit way. Process algebras, on the other hand, often provide a total-order framework, which means that information about causalities is not always accurate. This chapter illustrates how to develop a partial-order process algebra in the style of ACP. It is shown how to extend such an algebraic theory with a causality mechanism inspired by Petri-net theory. In addition, the chapter clarifies the concepts of interleaving and non-interleaving process algebra; total-order semantics for concurrent systems are often incorrectly referred to as interleaving semantics.", "num_citations": "2\n", "authors": ["574"]}
{"title": "Process algebra with autonomous actions\n", "abstract": " This paper introduces autonomous observable actions into process algebra. These actions can be observed but cannot be controlled by an environment. The proposed extension of ACP allows verifications without silent steps and fairness assumptions. The inclusion of inequalities makes it possible to verify that an implementation satisfies a given specification, with the specification indicating exactly where the implementation may reduce nondeterminism.", "num_citations": "2\n", "authors": ["574"]}
{"title": "Partial-order reduction for supervisory controller synthesis\n", "abstract": " One of the main challenges in the synthesis and analysis of supervisory controllers is the impact of state-space explosion caused by concurrency. The main bottleneck is often the memory needed to store the composition of plant and requirement automata and the resulting supervisor. Partial-order reduction is a well-established technique in the field of model checking that alleviates this issue. It does so by exploiting redundancy in the model with respect to the properties that are considered. In the context of controller synthesis these properties are nonblockingness, controllability, and least-restrictiveness. For performance analysis of controllers, we consider throughput and latency. We propose an on-the-fly partial-order reduction on the input model that preserves both synthesis and performance properties in the synthesized supervisory controller. This improves scalability of both the synthesis and performance\u00a0\u2026", "num_citations": "1\n", "authors": ["574"]}
{"title": "Firmness analysis of real-time tasks\n", "abstract": " (m,k)-firm real-time tasks require meeting the deadline of at least m jobs out of any k consecutive jobs. When compared to hard real-time tasks, (m,k)$-firm tasks open up the possibility of tighter resource-dimensioning in implementations. Firmness analysis verifies the satisfaction of (m,k)-firmness conditions. Scheduling policies under which a set of periodic tasks runs on a resource influence the number of deadline missed jobs. Therefore, the nature of the firmness analysis problem depends on scheduling policies. In this work, we present Firmness Analysis (FAn) methods for three common scheduling policies\u2014synchronous and asynchronous Static Priority Preemptive (SPP) policies and Time Division Multiple Access (TDMA). We first introduce the Balloon and Rake problem\u2014the problem of striking the maximum number of balloons in a balloon line with a rake. We show that the common core of firmness analysis\u00a0\u2026", "num_citations": "1\n", "authors": ["574"]}
{"title": "Inferring Timed Message Sequence Charts from Execution Traces of Large-scale Component-based Software Systems\n", "abstract": " This paper introduces a new measurement-based approach to get insights in timing bottlenecks of existing largescale component-based software systems. As a foundation we formalize a subset of the Message Sequence Charts standards (Z120 and UML2. 0) called Timed Message Sequence Charts (TMSC). TMSCs capture the execution of component-based software systems in an intuitive way and are amenable to formal timing analysis. We introduce a scalable heuristicsbased technique to automatically infer TMSCs from execution traces. We demonstrate the effectiveness of our approach by automatically computing critical paths in the software of an industrial lithography scanner to identify timing bottlenecks.", "num_citations": "1\n", "authors": ["574"]}
{"title": "DASA: an open-source design, analysis and simulation framework for automotive image-based control systems\n", "abstract": " \u2022 In reality, the camera is fixed to the vehicle body (Fig. 3) and any steering change would affect the region captured by the image.\u2022 This dynamism cannot be captured in a static image stream and a dynamic image stream that considers the change in vehicle dynamics due to IBC actuation is needed [2].", "num_citations": "1\n", "authors": ["574"]}
{"title": "Throughput-Buffering Trade-Off Analysis for Scenario-Aware Dataflow Models\n", "abstract": " In multi-media applications, buffers represent storage spaces that are used to store the data communicated between different tasks in the application, and throughput refers to the rate at which output data is produced by the application. The capacities of the buffers influence the throughput, by altering the waiting times for tasks that need to read or write data from or to the buffers. The buffers are realized using memory. To minimize the memory usage, we look for algorithms to compute the minimal capacity requirements for buffers to execute an application under a given throughput constraint. Synchronous dataflow (SDF) is a common formalism used to model applications in such algorithms. SDF however, is not suitable to describe today's dynamic applications, as it cannot express task variations. Finite-State-Machine Scenario-Aware Dataflow (FSM-SADF) is an extension of SDF that allows for not only task variations\u00a0\u2026", "num_citations": "1\n", "authors": ["574"]}
{"title": "Wireless body area network data delivery\n", "abstract": " This chapter discusses the requirements and mechanisms for efficient and reliable data delivery in Wireless body area networks (WBANs). It focuses on data delivery to a gateway node within a WBAN and discusses data delivery to a central station in a heterogeneous ambient network. Health-and well-being\u2013monitoring applications may use specific network organizations including WBANs. WBANs require proper network adaptation mechanisms in order to achieve acceptable data delivery performance. The objective of WBAN adaptation is to follow and adapt to the changes in the network connectivity in order to continuously satisfy the data delivery requirements and optimize the power consumption. Tree structures are commonly used for data routing in wireless sensor networks. Health-monitoring applications expect certain performance of WBAN data delivery. Depending on the nature of the biological signals\u00a0\u2026", "num_citations": "1\n", "authors": ["574"]}
{"title": "Robust co-synthesis of embedded control systems with occasional deadline misses\n", "abstract": " Feedback control applications are robust to occasional deadline misses. This opens up the possibility of saving scarce (computation and communication) resources on embedded platforms. Stability and performance requirements of a control loop impose restrictions on acceptable patterns of deadline misses (e.g., not too many misses in a row). Such requirements are captured by (m,k)-firmness conditions. That is, at least m control computation jobs must meet deadlines in any k consecutive jobs. (m,k)-firm design requires (i) representation of stability and performance requirements in terms of (m,k)-firm deadlines (ii) controller synthesis taking into account the (m,k)-firmness parameters (iii) schedule analysis to verify guarantees on meeting the firmness conditions. We present a co-synthesis framework for these three design components and illustrate its applicability with examples.", "num_citations": "1\n", "authors": ["574"]}
{"title": "Platform-aware design of embedded controllers\n", "abstract": " Correctness, implementation efficiency and good quality of control (QoC) are essential for embedded controllers in cyber-physical systems. Awareness of the implementation platform plays a key role in achieving these goals. Recent results from Eindhoven University of Technology (TU/e) and Technische Universit\u00e4t M\u00fcnchen (TUM) report substantial improvements in the design of embedded controllers.", "num_citations": "1\n", "authors": ["574"]}
{"title": "Kahn process networks and a reactive extension\n", "abstract": " Kahn Process Networks and a Reactive Extension Page 1 Kahn Process Networks and a Reactive Extension Twan Basten, Marc Geilen \u2018Knowing is not understanding.\u2019 Charles Kettering Summer School on Models for Embedded Signal Processing Systems Page 2 2 The challenges of today Page 3 The problem: an example printer platform \u2022 Use-cases to be mapped onto a professional printer \u2022 Copying (black&white, color, various paper sizes, zoom factors, \u2026) \u2022 Printing \u2022 Scanning \u2022 Simultaneous printing and scanning 3 printer platform \u2022 How many CPUs, GPUs ? \u2022 Processor speeds ? \u2022 How to achieve X images/min ? \u2022 Double resolution ? \u2022 Run-time changes in speed, job type, power budget \u2026 ? challenges models the hierarchy the future kpn rpn Page 4 \u2022 Reliable, resource-efficient embedded systems \u2022 Fast, predictable design trajectories Objectives 4 challenges models the hierarchy the future kpn rpn Page 5 \u2022 \u2026", "num_citations": "1\n", "authors": ["574"]}
{"title": "Reliable run-time adaptation in resource-constrained embedded systems\n", "abstract": " Pareto Algebra Page 1 Reliable Run-time Adaptation in Resource-constrained Embedded Systems Twan Basten Joint work with Marc Geilen, AmirHossein Ghamarian, Rob Hoes, Hamid Shojaei, Sander Stuijk, and others \u2018Knowing is not understanding.\u2019 Charles Kettering Funding: EC FP6 Betsy & WASP EC FP7 MNEMEE 2 Run-time Adaptation Encoding qualities Bandwidth requirements Available bandwidth under given circumstances Decoding streams of different quality Computational effort required Different levels of computation power Different levels of power consumption motivation Pareto algebra adaptation wsn cmp conclusions 3 Run-time Adaptation What is the optimal configuration? - given communication bandwidth - given battery status - given user preferences Requires run-time decision making - multi-dimensional problem - strict timing constraints - limited resources motivation Pareto algebra \u2026", "num_citations": "1\n", "authors": ["574"]}
{"title": "Reliable Embedded Multimedia Systems?\n", "abstract": " Reliable Embedded Multimedia Systems? Page 1 Reliable Embedded Multimedia Systems? \u2018Knowing is not understanding.\u2019 Charles Kettering Twan Basten Joint work with Marc Geilen, AmirHossein Ghamarian, Hamid Shojaei, Sander Stuijk, Bart Theelen, and others Funding: NWO PROMES EC FP6 Betsy, FP7 MNEMEE 2 Overview \u2022 Embedded Multi-media \u2022 Analysis of Synchronous Dataflow Graphs \u2022 Throughput Analysis \u2022 Throughput-Storage Trade-off Analysis \u2022 Scenario-aware Analysis \u2022 Run-time Adaptation \u2022 Looking Forward 3 Trends Concurrency Connectedness Interaction Variability Embedded Multi-media emb. mm throughput storage adaptation the future scenarios 4 Embedded Multi-media emb. mm throughput storage adaptation the future scenarios Page 2 5 Embedded Multi-media emb. mm throughput storage adaptation the future scenarios 6 Embedded Multi-media emb. mm throughput storage \u2026", "num_citations": "1\n", "authors": ["574"]}
{"title": "Time-Constrained Energy-Aware Routing and Scheduling of Network-on-Chip Communication\n", "abstract": " Network-on-chip-based multiprocessor systems-on-chip (NoC-based MP-SoCs) are considered as future embedded systems platforms. One of the steps in mapping an application onto such a parallel platform involves determining when data is sent between the tasks in the application. As a network-on-chip allows concurrent communication, a decision on the route through the network must also be made. Timing constraints and energy consumption are aspects that must be considered in this mapping. This paper presents different routing and scheduling strategies which try to minimize the resource usage and energy consumption when an application with timing constraints is mapped onto a NoC-based MP-SoC. Our experiments show that our strategies outperform an existing state-of-theart scheduling technique, and that in some cases random-based strategies perform the best.", "num_citations": "1\n", "authors": ["574"]}
{"title": "P. d. With. Run-time prediction of execution times of stream-oriented applications in multiprocessors on chip\n", "abstract": " For stream-oriented applications, it is a challenging problem to predict the total execution time of a loop consisting of multiple tasks with data-dependent task execution delays executed in a pipeline-like manner on a multiprocessor system on-chip. Embedded applications can profit from such prediction at run-time, eg for power and quality-of-service management. For this purpose, we propose a generic loop execution time estimate giving a tight upper bound and taking parallelism into account. Our estimate is an algebraic expression of a few a priori parameters describing the frequency and the value of changes of the task execution delays. Our method is based on a timing analysis of the loop. To illustrate how our method can be applied in practice, we use an MPEG-4 algorithm for decoding video object shape as a case study.", "num_citations": "1\n", "authors": ["574"]}
{"title": "A Process-algebraic Approach to Life-cycle: Inheritance\n", "abstract": " One of the key issues of object-oriented modeling is inheritance. It allows for the definition of subclasses that inherit features of some superclass. Inheritance is well defined for static properties of classes such as attributes and methods. However, there is no general agreement on the meaning of inheritance when considering the dynamic behavior of objects, determined by their life cycles. This paper studies the latter in the context of a simple process algebra. Process algebra is chosen, because it concentrates on dynamic behavior, while abstracting from the internal states of processes. Inheritance can be expressed in terms of encapsulation and abstraction. The combination captures all basic operators for constructing life cycles of subclasses from life cycles of superclasses, namely choice, sequential composition, and parallel composition.", "num_citations": "1\n", "authors": ["574"]}