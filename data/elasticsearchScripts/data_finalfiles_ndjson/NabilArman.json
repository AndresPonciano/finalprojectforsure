{"title": "Generating use case models from Arabic user requirements in a semiautomated approach using a natural language processing tool\n", "abstract": " Automated software engineering has attracted a large amount of research efforts. The use of object-oriented methods for software systems development has made it necessary to develop approaches that automate the construction of different Unified Modeling Language (UML) models in a semiautomated approach from textual user requirements. UML use case models represent an essential artifact that provides a perspective of the system under analysis or development. The development of such use case models is very crucial in an object-oriented development method. The main principles used in obtaining these models are described. A natural language processing tool is used to parse different statements of the user requirements written in Arabic to obtain lists of nouns, noun phrases, verbs, verb phrases, etc., that aid in finding potential actors and use cases. A set of steps that represent our approach for\u00a0\u2026", "num_citations": "16\n", "authors": ["1918"]}
{"title": "E-learning Materials Development: Applying and Implementing Software Reuse Principles and Granularity Levels in the Small\n", "abstract": " E-learning materials development is typically acknowledged as an expensive, complicated, and lengthy process, often producing materials that are of low quality and difficult to adapt and maintain. It has always been a challenge to identify proper e-learning materials that can be reused at a reasonable cost and effort. In this paper, software engineering reuse principles are applied to e-learning materials development process. These principles are then applied and implemented in a prototype that is integrated with an open-source course management systems. The reuse of existing e-learning materials is beneficial in improving developers of e-learning materials productivity. E-learning material reuse is performed, in this research, based on construct\u2019s granularity rather than on unified constructs of one size.", "num_citations": "15\n", "authors": ["1918"]}
{"title": "A path-compression approach for improving shortest-path algorithms\n", "abstract": " Given a weighted directed graph G=(V;E;w), where w is non-negative weight function, G\u2019 is a graph obtained from G by an application of path compression. Path compression reduces the graph G to a critical set of vertices and edges that affect the generation of shortest trees. The main contribution of this paper is finding shortest path between two selected vertices by applying a new algorithm that reduces number of nodes that needs to be traversed in the graph while preserving all graph properties. The main method of the algorithm is restructuring the graph in a way that only critical/relevant nodes are considered while all other neutral vertices and weights are preserved as sub paths' properties. Our algorithm can compress the graph paths into considerable improved percentage especially when the graph is sparse and hence improves performance significantly", "num_citations": "14\n", "authors": ["1918"]}
{"title": "Normalizer: A case tool to normalize relational database schemas\n", "abstract": " Relational Database Schemas represent the database schema as a collection of relation schemas. Sometimes, these relation schemas are poorly designed and need to be decomposed in an attempt to choose \"good\" relation schemas. In this stuty, we used the theory of relational database normalization to develop a case tool, called Normalizer, to automate the process of relational database normalization.", "num_citations": "13\n", "authors": ["1918"]}
{"title": "Constructing use case models from Arabic user requirements in a semi-automated approach\n", "abstract": " Automated software engineering has attracted a large amount of research efforts. The use of object-oriented methodologies for software systems development has made it necessary to develop approaches that automate the construction of different UML models in a semi-automated approach from textual user requirements. UML use case models represent an essential artifact that provide a perspective of the system under analysis or development The development of such use case models is very crucial in an object-oriented development methodology. The main principles used in obtaining these models are described. A natural language processing tool is used to parse different statements of the user requirements written in Arabic to obtain lists of nouns, noun phrases, verbs, verb phrases, etc. that aid in finding potential actors and use cases. A set of steps that represent our approach for constructing a use case\u00a0\u2026", "num_citations": "12\n", "authors": ["1918"]}
{"title": "Fault detection in dynamic rule bases using spanning trees and disjoint sets\n", "abstract": " Many fault detection techniques/algorithms for detecting faults in rule bases have appeared in the literature. These techniques assume that the rule base is static. This paper presents a new approach/algorithm for detecting faults in dynamic rule bases, where rules may be added/deleted in response to certain events happening in the system being controlled by the rule base. This is performed by maintaining a set of structures, where new rules can be added to the dynamic rule base without the need to rebuild the structures that represent the rule base. The approach makes use of spanning trees and disjoint sets to check a dynamic rule base for different kinds of faults. The algorithm devises a tree/forest of the underlying directed graph by treating the directed graph as an undirected graph, and then checks for various faults and properties. The algorithm devises a new rule base (which is a subset of the current rule base) that is equivalent, in terms of its reasoning capabilities, to the current rule base, with the properties that the new rule base is fault free. This is performed as rules are being added to the dynamic rule base one at a time.", "num_citations": "11\n", "authors": ["1918"]}
{"title": "Efficient multi-swarm binary harris hawks optimization as a feature selection approach for software fault prediction\n", "abstract": " Designing a solution for an optimization problem requires two main aspects; the optimization technique (e.g., search strategy) and the evaluation criteria (i.e., objective function). In this paper, an enhanced binary version of a recent metaheuristic algorithm, the Harris Hawk Optimization algorithm (EBHHO), is presented to find a (near) optimal solution for the Feature Selection (FS) problem. Moreover, three different classifiers called K-nearest neighbors (kNN), Decision Trees (DT), and Linear Discriminant Analysis (LDA) were used as evaluation criteria to formulate the objective function. In addition to reducing the dimensionality of the dataset using the FS technique, the Adaptive Synthetic (ADASYN) oversampling technique was used to enhance the quality of the learning algorithm by re-balancing the dataset. A set of well-known datasets in the field of Software Fault Prediction (SFP) were used to validate the\u00a0\u2026", "num_citations": "9\n", "authors": ["1918"]}
{"title": "A semi-automated approach for generating sequence diagrams from Arabic user requirements using a natural language processing tool\n", "abstract": " A sequence diagram is one of UML models that are usually used within the analysis phase in software system development. Since generating such sequence diagrams is performed manually, automated or semi-automated support is beneficial in providing important and practical help. In this paper, a new semi-automated approach for generating sequence diagrams from user requirements written in Arabic is proposed. In this novel approach, the used Arabic requirements are parsed using a natural language processing tool to generate corresponding part of speech. A set of proposed heuristics are to be applied to obtain the sequence diagram components; objects, messages and work flow transitions (messages). The generated sequence diagram is represented using XMI to be drawn using sequence diagrams drawing tools. Using three different case studies as a benchmark from Isra Computer and Programming\u00a0\u2026", "num_citations": "9\n", "authors": ["1918"]}
{"title": "An efficient algorithm for checking path existence between graph vertices\n", "abstract": " The development of efficient algorithms to determine path existence between vertices in a directed graph has attracted a large amount of research efforts due to the important role of these algorithms in many application domains, including deductive databases, rule bases verification, and graph theory to name a few. These algorithms are very crucial to answer certain queries about the path existence between any two graph vertices. This paper presents an efficient algorithm to determine the path existence between graph vertices by utilizing a special matrix representation of the graph.", "num_citations": "8\n", "authors": ["1918"]}
{"title": "Improvement of shortest-path algorithms using subgraphs heuristics\n", "abstract": " Given a graph G=(V,E,w), where V and E are finite set of vertices and edges respectively, is a directed weighted graph with weights denoted by w(e)>0 for each edge e \u2208E. P(s,t) is the shortest path between the given vertices  and  containing the least sum of edge weights on the path from  to . Properties of the graph representation, using different matrix structures to represent the graph in normal flow and reverse  representations,  are  considered.  Based  on  these  structures,  a  new  algorithm  determines  the candidate subgraphs and prunes every subgraph that is either unreachable from the given source vertex  or does not lead to the given destination, benefiting from the rich information inherent in the matrix and reverse matrix structure representations of the graph. The experiments were conducted using our heuristic and the conventional shortest path finding, namely Dijkstra\u2019s algorithm. Practical results are given showing considerable improvements of the proposed algorithm in performance. This improves the shortest path algorithm significantly.    Improvement of shortest-path algorithms using subgraphs heuristics. Available from: https://www.researchgate.net/publication/281061037_Improvement_of_shortest-path_algorithms_using_subgraphs_heuristics [accessed Jan 17, 2017].", "num_citations": "6\n", "authors": ["1918"]}
{"title": "An Efficient Multiple Sources Single Destination (MSSD) Heuristic Algorithm Using Nodes Exclusions\n", "abstract": " The problem of identifying the best paths between given set of nodes and a given single-destination in a graph of vertices is commonly referred to as network multiple sources single-destination problems. In real life researchers always find themselves in a critical situation that researchers seek the nearest set of related points such as the urgent need for fire stations. This study describes, the problem and proposes an algorithm for finding the shortest paths between the set of sources  and a single-destination  given that  and  \u2208 weighted graph G(V, E, w) with vertex set V and arc set E associated with non-negative real valued weight. An efficient algorithm is developed based on different graph representations. The proposed heuristic determines a candidate subgraph G' and excludes all nodes that do not lead to destination. The proposed algorithm improves partially the performance of improved traditional shortest path algorithms, i.e., Dijkstra's algorithm. This is shown obviously by applying the algorithm on set of random graphs.", "num_citations": "6\n", "authors": ["1918"]}
{"title": "Parallel algorithms for the generalized same generation query in deductive databases\n", "abstract": " The intelligence of traditional database systems can be improved by recursion. Using recursion, relational database systems are extended into knowledgebase systems (deductive database systems). Linear recursion is the most frequently found type of recursion in deductive databases. Deductive databases queries are computationally intensive and lend themselves naturally to parallelization to speed up the solution of such queries. In this paper, parallel algorithms to solve the generalized fully and partially instantiated forms of the same generation query in deductive databases are presented. The algorithms use special data structures, namely, a special matrix that stores paths from source nodes of the graph representing a two-attribute normalized database relation to all nodes reachable from these source nodes, and a reverse matrix that stores paths from any node to all source nodes related to that node.", "num_citations": "6\n", "authors": ["1918"]}
{"title": "Graph representation comparative study\n", "abstract": " There are a number of graph representation schemes that have been used in graph algorithms. In this short article, a comparison is conducted among three major representations of directed graphs to illustrate the main advantages and disadvantages of each representation scheme. The reason for conducting this study is to show that one of the schemes is overlooked despite the fact that it has more information than the other schemes and this information is very useful in improving the performance of many graph algorithms.", "num_citations": "6\n", "authors": ["1918"]}
{"title": "Towards e-case tools for software engineering\n", "abstract": " CASE tools are having an important role in all phases of software systems development and engineering. This is evident in the huge benefits obtained from using these tools including their cost-effectiveness, rapid software application development, and improving the possibility of software reuse to name just a few. In this paper, the idea of moving towards E-CASE tools, rather than traditional CASE tools, is advocated since these E-CASE tools have all the benefits and advantages of traditional CASE tools and add to that all the benefits of web technology. This is presented by focusing on the role of E-CASE tools in facilitating the trend of telecommuting and virtual workplaces among software engineering and information technology professionals. In addition, E-CASE tools integrates smoothly with the trend of E-learning in conducting software engineering courses. Finally, two surveys were conducted for a group of\u00a0\u2026", "num_citations": "5\n", "authors": ["1918"]}
{"title": "A systematic approach for constructing static class diagrams from software requirements\n", "abstract": " The trend towards the use of object-oriented methods for software systems development has made it necessary for the use of object-oriented approaches in object-oriented software systems development. Class diagrams represent an essential component in any object-oriented system design. The development of such class diagrams in a systematic way is very crucial in an object-oriented development methodology. The main principles used in obtaining these class diagrams in a systematic way are described since class diagrams are very essential in object-oriented development practice.", "num_citations": "5\n", "authors": ["1918"]}
{"title": "Requirements based Static class diagram constructor (SCDC) case tool\n", "abstract": " Object-Oriented development methodology is currently the main trend in software industry. Many tools were introduced to aid in the analysis and design phases of the object-oriented development methodology. However, tools that can aid in the requirements phase of the object-oriented development methodology and that can generate class diagrams as a major step in the design phase have attracted little attention and efforts. This paper introduces a tool to automate the process of constructing a static class diagram from software requirements. The CASE tool takes the static class diagram a step further and generates a skeleton code for popular object-oriented languages.", "num_citations": "5\n", "authors": ["1918"]}
{"title": "Teaching Software Engineering Courses: When?\n", "abstract": " Recently, we have noticed that there is an evident weakness among our students in applying and using software engineering principles in advanced courses that require major software projects. We have also noticed that many software graduation projects lack the concrete and correct usage of sound software engineering principles. In an attempt to determine the main reasons behind that, we reviewed the study plans of many IT-related departments, which generally distribute course over years and semesters, and found that software engineering courses are taught early in the plans. However, we argue that such courses should be taught as late as possible to emphasize the engineering principles rather than focusing on the details that are covered in other courses. We conducted a survey regarding that and the results were in favor of our argument.", "num_citations": "5\n", "authors": ["1918"]}
{"title": "An Efficient Algorithm For Line Recognition Based On Integer Arithmetic\n", "abstract": " Line recognition is an important aspect in image processing. Many line detection algorithms were introduced. However these algorithms involve expansive operations like floating point arithmetic and matrix operations, which increase their computational time significantly. In this paper, a line recognition algorithm is introduced which involves integer arithmetic only.", "num_citations": "5\n", "authors": ["1918"]}
{"title": "Graph representation: Comparative study and performance evaluation\n", "abstract": " In this study, a comparison is conducted among three major representations of directed graphs to illustrate major advantages and disadvantages of each representation scheme....", "num_citations": "5\n", "authors": ["1918"]}
{"title": "Structural and Syntactic Fault Correction Algorithms in Rule-Based Systems\n", "abstract": " The development of efficient algorithms to correct faults in rule-based systems is very crucial in extending the verification and validation of rule sets and in the development of rule-based systems. While it is important to detect various kinds of faults in rule sets, it is also equally important to provide a user/expert with a set of heuristics that can aid in correcting these faults. In this paper, a set of correction algorithms/heuristics for inconsistency, contradiction, circularity, redundancy, and unreachability faults are presented.", "num_citations": "5\n", "authors": ["1918"]}
{"title": "An Efficient Algorithm for the Generalized Partially Instantiated Same Generation Query in Deductive Databases\n", "abstract": " The expressive power and intelligence of traditional database systems can be improved by recursion. Using recursion, relational database systems are extended into knowledge-base systems (deductive database systems). Linear recursion is the most frequently found type of recursion in deductive databases. In this paper, an algorithm to solve the generalized partially instantiated form of the same generation query in deductive databases is presented. The algorithm uses special data structures, namely, a special matrix that stores paths from roots of the graph representing a two-attribute normalized database relation to all nodes reachable from these roots, and a reverse matrix that stores paths from any node to all roots related to that node. Using simulation, this paper also studies the performance of the algorithm and compares that with the standard depth-first search based algorithms.", "num_citations": "5\n", "authors": ["1918"]}
{"title": "An Intelligent Algorithm for the Generalized Fully Instantiated Same Generation Query in Deductive Databases\n", "abstract": " The expressive power and intelligence of traditional database systems can be improved by recursion. Using recursion, relational database systems are extended into knowledge-base systems (deductive database systems). Linear recursion is the most frequently found type of recursion in deductive databases. In this paper, an intelligent algorithm to solve the generalized fully instantiated form of the same generation query in deductive databases is presented. The algorithm uses special data structures, namely, a special matrix that stores paths from roots of the graph representing a two-attribute normalized database relation to all nodes reachable from these roots, and a reverse matrix that stores paths from any node to all roots related to that node. Using simulation, this paper also studies the performance of the algorithm and compares that with the standard depth-first search based techniques.", "num_citations": "5\n", "authors": ["1918"]}
{"title": "e-learning materials development: implementing software reuse principles and granularity levels in the small using taxonomy search\n", "abstract": " The development of e-learning materials is typically acknowledged as an expensive, complicated, and lengthy process, often producing materials that are of low quality and difficult to adapt and maintain. It has always been a challenge to identify proper e-learning materials that can be reused at a reasonable cost and effort. In this paper, software engineering reuse principles are applied to e-learning materials development process. These principles are then applied and implemented in a prototype that is integrated to an open-source course management systems. The reuse of existing e-learning materials is beneficial in improving developers of e-learning materials productivity. E-learning material reuse is performed, in this research, based on construct's granularity rather than on unified constructs of one size. In addition, search for potential reusable constructs is performed using a taxonomy of majors and subjects\u00a0\u2026", "num_citations": "4\n", "authors": ["1918"]}
{"title": "Detecting and correcting faults in chained-inference constrained rules in information distribution systems\n", "abstract": " Information Distribution Systems (IDSs) are subsystems of command, control, communication, computer, and intelligence (C4I) systems. A rule-based information distribution system (RBIDS) is an IDS that uses distributed rules to control message passing (communications) between distributed nodes within a real-time distributed environment so that only significant information is exchanged. The problem addressed in this research is that there is a need to improve the efficiency of algorithms that can be used to detect faults in rule-based systems, to extend the capabilities of these algorithms to inspect constrained rule-based systems such as RBIDSs, and to correct faults in these systems. This inspection is needed to ensure that these systems correctly behave/function in response to events occurring in the environment and to improve their reliability.", "num_citations": "4\n", "authors": ["1918"]}
{"title": "Using MADA+ TOKAN to Generate Use Case Models from Arabic User Requirements in a Semi-Automated Approach\n", "abstract": " Automated software engineering has attracted a large amount of research efforts. The need for new approaches that reduces the cost of developing software systems within project schedule has made it necessary to develop approaches that aid in the construction of different UML models in a semi-automated approach from Arabic textual user requirements. UML use case models represent an essential artifact that provide a perspective of the system under analysis or development. The development of such use case models is very crucial in an object-oriented development methodology. In this paper, MADA+TOKAN is used to parse different statements of the user requirements written in Arabic to obtain different components of a sentence like lists of nouns, noun phrases, verbs, verb phrases, etc. that aid in finding potential actors and use cases. A set of steps that represent our approach for constructing a use case model is presented. Finally, the proposed approach is to be validated and implemented at a later stage of the research project.", "num_citations": "3\n", "authors": ["1918"]}
{"title": "An efficient heuristic shortest path algorithm using candidate Subgraphs\n", "abstract": " Given a graph G=(V,E,w), where Vand E are finite set of vertices and edges respectively, in a directed weighted graph G with weights denoted by w(e)>0 for each edge e\u2208 E. Given two vertices  and \u2208 V, P(s,t) is the shortest path between  and  containing the least sum of edge-weights on the path from  to . The properties of the graph representation, using matrix structures to represent the graph in normal flow and reverse representations, are considered. Based on these structures, the new algorithm determines the candidate subgraphs and prunes every subgraph that is either unreachable from the given source vertex  or does not lead to the given destination , benefiting from the rich information inherent in the matrix structure representations of the graph", "num_citations": "3\n", "authors": ["1918"]}
{"title": "Improving rule base quality to enhance production systems performance\n", "abstract": " Production systems have a special value since they are used in state-space searching algorithms and expert systems in addition to their use as a model for problem solving in artificial intelligence. Therefore, it is of high importance to consider different techniques to improve their performance. In this research, rule base is the component of the production system that we aim to focus on. This work therefore seeks to investigate this component and its relationship with other components and demonstrate how the improvement of its quality has a great impact on the performance of the production system as a whole. In this paper, the improvement of rule base quality is accomplished in two steps. The first step involves re-writing the rules having conjunctions of literals and producing a new set of equivalent rules in which long inference chains can be obtained easily. The second step involves augmenting the rule base with inference short-cut rules devised from the long inference chains. These inference short-cut rules have a great impact on the performance of the production system. Finally, simulations are performed on randomly generated rule bases with different sizes and goals to be proved. The simulations demonstrate that the suggested enhancements are very beneficial in improving the performance of production systems.", "num_citations": "3\n", "authors": ["1918"]}
{"title": "Generating sequence diagrams from arabic user requirements using mada+ tokan tool.\n", "abstract": " A new semi-automated approach for generating sequence diagrams from Arabic user requirements is presented. In this novel approach, the Arabic user requirements are parsed using a natural language processing tool called MADA+ TOKAN to generate the Part Of Speech (POS) tags of the parsed user requirements, then a set of heuristics are applied on the resulted tags to obtain the sequence diagram components; objects, messages and work flow transitions (messages). The generated sequence diagram is expressed using Extensible Markup Language (XMI) to be drawn using sequence diagrams drawing tools. Our approach achieves better results than students in generating sequence diagrams. It also has better accuracy in generating the participants and less accuracy in generating messages exchanged between participants. The proposed approach is validated using a set of experiments involving a set of real cases evaluated by a group of software engineers and a group of graduate students who are familiar with sequence diagrams.", "num_citations": "2\n", "authors": ["1918"]}
{"title": "Comparing the Approaches of Graph Reduction and Landmark Shortest-Paths\n", "abstract": " We study the different recent improvements on shortest path algorithms. We suggest improvements to the classical path computing algorithms and we implement them using random generated graphs with various sizes. Many attempts exist for improving shortest path techniques. Computing shortest path is one of the most important and recent issues in combinatorial optimization, emergency routs, NoSQL data graph representation, road and public transportation networks, and other applications. One of the big obstacles in such real-word applications is the size of the graphs that motivates the attempts of enhancing the path finding procedures. Given a weighted graph G={V,E,w}, a heuristic method to improve conventional shortest-path for a given source node  is provided. In this paper, we address the complexity of shortest paths in large graphs and we present a graph structure and enhancement process of finding the shortest path in the given graph. We study the current improving algorithms and highlights the improvements over the classical ones. We evaluate our implemented techniques using randomly generated weighted graphs. The main procedure is compressing the graph without losing the graph properties. We then, compare our technique with the approach of using landmark optimization. We discuss the performance, storage, error rate in our approach compared to landmark. Our experiments show that the new technique of graph compression performs with better speedup and no path mistakes compared to fast landmark approach which leads to high overhead in most situations.", "num_citations": "2\n", "authors": ["1918"]}
{"title": "E-learning Materials Development: Applying Software Reuse Principles and Granularity Levels in the Small\n", "abstract": " The development of e-learning materials is typically acknowledged as an expensive, complicated, and lengthy process, often producing materials that are of low quality and difficult to adapt and maintain. It has always been a challenge to identify proper e-learning materials that can be reused at a reasonable cost and effort. In this paper, software engineering reuse principles are applied to e-learning materials development process. The reuse of existing e-learning materials is beneficial in improving developers of e-learning materials productivity. Elearning material reuse is performed, in this research, based on construct\u2019s granularity rather than on unified constructs of one size.", "num_citations": "2\n", "authors": ["1918"]}
{"title": "A Parallel Algorithm for the Generalized Fully Instantiated Same Generation Query in Deductive Databases\n", "abstract": " The expressive power and intelligence of traditional database systems can be improved by recursion. Using recursion, relational database systems are extended into knowledge-base systems (deductive database systems). Linear recursion is the most frequently found type of recursion in deductive databases. Deductive databases queries are computationally intensive and lend themselves naturally to parallelization to speed up the solution of such queries. In this paper, a parallel algorithm to solve the generalized fully instantiated form of the same generation query in deductive databases is presented. The algorithm uses special data structures, namely, a special matrix that stores paths from source nodes of the graph representing a two-attribute normalized database relation to all nodes reachable from these source nodes, and a reverse matrix that stores paths from any node to all source nodes related to that node.", "num_citations": "2\n", "authors": ["1918"]}
{"title": "A Parallel Algorithm for the Generalized Partially Instantiated Same Generation Query in Deductive Databases\n", "abstract": " The expressive power and intelligence of traditional database systems can be improved by recursion. Using recursion, relational database systems are extended into knowledge-base systems (deductive database systems). Linear recursion is the most frequently found type of recursion in deductive databases. Deductive databases queries are computationally intensive and lend themselves naturally to parallelization to speed up the solution of such queries. In this paper, a parallel algorithm to solve the generalized partially instantiated form of the same generation query in deductive databases is presented. The algorithm uses special data structures, namely, a special matrix that stores paths from source nodes of the graph representing a two-attribute normalized database relation to all nodes reachable from these source nodes, and a reverse matrix that stores paths from any node to all source nodes related to that node.", "num_citations": "2\n", "authors": ["1918"]}
{"title": "Joint crypto-compression based on selective encryption for wmsns\n", "abstract": " Wireless Multimedia Sensor Networks (WMSNs) have been widely used in many aspects of life such as monitoring aims, risk environments and medical services. However, WMSNs have many challenges due to resources limitation (e.g., restriction in processing, energy and memory). Moreover, security issues related to WMSNs attract many research efforts. Due to limitations of WMSNs resources and their internal encoding, standard methods of data encryption are inappropriate to be used in order to secure data of WMSNs. In this paper, a compression algorithm named Set Partitioning In Hierarchical Tree (SPIHT), jointly with selective encryption during the compression process cycle, is proposed. Selected bins to be encrypted are analyzed and tested to preserve format compliance and constant bit rate. As a result the decoder will not crash. Moreover, any standard decoder can be used without any modifications\u00a0\u2026", "num_citations": "1\n", "authors": ["1918"]}
{"title": "Current trends and approaches in synonyms extraction: Potential adaptation to arabic\n", "abstract": " Extracting synonyms from dictionaries or corpora is gaining a special attention as synonyms play an important role in improving NLP application performance. This paper presents a survey of the different approaches and trends used in automatically extracting the synonyms. These approaches can be divided into four main categories. The first approach is to find the Synonyms using a translation graph, The second approach is to discover new transition pairs such as (Arabic \u2013 English) (English \u2013 France) then (Arabic- France). The third approach is to construct new WordNets by exploring synonymy graphs, and the fourth approach is to find similar words from corpora using Deelp Learning methods, such as word embeddings and recently BERT models. The papers also presents comparative analysis between these approoaches, and highlights potential adaptation to generate synonyms automatically in the Arabic\u00a0\u2026", "num_citations": "1\n", "authors": ["1918"]}
{"title": "Towards a Hybrid Data Partitioning Technique for Secure Data Outsourcing\n", "abstract": " In light of the progress achieved by the technology sector in the areas of internet speed and cloud services development, and in addition to other advantages provided by the cloud such as reliability and easy access from anywhere and anytime, most data owners find an opportunity to take advantage of the cloud to store data. However, data owners find a challenge that was and is still facing them in the field of outsourcing, which is protecting sensitive data from leakage. Researchers found that partitioning data into partitions, based on data sensitivity, can be used to protect data from leakage and to increase performance by storing the partition, which contains sensitive data in an encrypted form. In this paper, we review the methods used in designing partitions and dividing data approaches. A hybrid data partitioning approach is proposed to improve these techniques. We consider the frequency attack types used to\u00a0\u2026", "num_citations": "1\n", "authors": ["1918"]}
{"title": "ERRDS: A Case Tool to Generate an ER Data Model from a Relational Database Schema\n", "abstract": " A relational database (RDB) schema is a description of database requirements in terms of a set of relations and a set of integrity constraints. An Entity- Relationship(ER) data model is a high-level conceptual data model that is used frequently for the conceptual design of databases. ER data models represent a concise description of users' data requirements without including implementation details. Because of that, ER data models are usually used to communicate with nontechnical users since they are easier to understand. Some relational database designers used the concept of a universal relation and perform normalization to come up with the relational database schema, without developing an ER data model. We advocate that the best practice for a relational database design is to start with developing a conceptual schema like an ER data model and then map it to a relational database schema (as many CASE tools support). In this article, a case tool to perform the reverse process, which is generating an ER data model from a relational database schema, is presented. This tool is very useful in obtaining a conceptual schema from a relational database schema. This tool can also be thought of as a kind of reverse engineering case tool that aids in the reverse engineering of legacy databases to consider new implementation technology options.", "num_citations": "1\n", "authors": ["1918"]}
{"title": "Generating Minimum-Cost Fault-Free Rule Bases Using Minimum Spanning Trees\n", "abstract": " This paper presents a new approach/algorithm for generating minimum-cost fault-free rule bases, which have no redundancy, circularity, inconsistency, contradiction/conflict and unreachability. The approach makes use of minimum spanning trees to check a rule base for different kinds of faults. The rule base is represented using a directed weighted graph. The algorithm devises a spanning tree/forest of the underlying directed graph by treating the directed graph as an undirected graph, and checks for various faults and properti es. The algorithm devises a new rule base (which is a subset of the original rule base) that is equivalent, in terms of its reasoning capabilities, to the original rule base, with the properties that the new rule base is free from redundancy and circularity and has the minimum cost. It also determines the set of rules that cause redundancy and circularity faults. After determining the new rule base, checking for the remaining faults, namely inconsistency, contradiction, and unreachability, can be performed in a straightforward manner using the generated structures.", "num_citations": "1\n", "authors": ["1918"]}
{"title": "Web-Enabled Computer Maintenance Management Application: PPU E-Maintenance Management System\n", "abstract": " This article presents an E-Maintenance Management System that was developed at Palestine Polytechnic University. The system was demoed last Spring, as a successful E-Business case study. In this article, the system development process is explained and the main benefits and advantages of the system are highlighted. In addition, a demo of the system and snapshots of a number of screens are presented.", "num_citations": "1\n", "authors": ["1918"]}
{"title": "An Efficient Algorithm for Generating Maximal Interval Groups in Interval Databases\n", "abstract": " The development of efficient algorithms to enumerate all intervals that have certain properties has attracted a large amount of research efforts due to the important role of interval-based reasoning in different areas like rule-based systems, including Expert Systems (ESs), Information Distribution Systems (IDSs), and database systems to name a few. These algorithms are very crucial to answer certain queries about these intervals. This paper presents an efficient algorithm to generate all maximal interval groups form a given interval set.", "num_citations": "1\n", "authors": ["1918"]}
{"title": "General Fault Detection Algorithms in Constrained Rule-Based Information Distribution Systems\n", "abstract": " A Rule-Based Information Distribution System (RBlDS) is a system that uses distributcd rules to control messagc passing between distributed nodes within a distributed environment. A rule represents a RBlUS requirement spccification. The problem addressed in this paper is a nccd to improve efficiency of algorithms that can be used to detect different kinds of faults in the requirement spccifications of a RilDS, To meet the requirements specifications of RBIDS, constraints are often imposed upon the requirements spccifications extcrnal cvents. The authors present a set of more eficient algorithms to inspect for faults cach rule subset gcncrated by a grouping algorithm.", "num_citations": "1\n", "authors": ["1918"]}