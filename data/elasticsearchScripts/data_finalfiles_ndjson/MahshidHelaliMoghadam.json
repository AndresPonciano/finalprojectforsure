{"title": "A street lighting control system based on holonic structures and traffic system\n", "abstract": " Street lighting system is one of the main sectors of energy consumers in the area of the electrical energy consumption in the country. Since suitable lighting system plays an important role in terms of individual and social security in the city, providing an optimal management plan in line with the aim of saving consumption of electrical energy while providing appropriate lighting levels, can be a great help to the field of energy consumption. In this article we have tried to provide a comprehensive and overall plan for controlling and intelligent managing the street lighting system based on passages traffic using holonic multi agent systems. This approach controls the lighting system by intelligent agents in a holonic organization mounted on the traffic infrastructure. This control is done at different levels in centralized and distributed form. We can see two levels in our holonic multi agent system. In the high level of the system\u00a0\u2026", "num_citations": "38\n", "authors": ["1266"]}
{"title": "Machine Learning to Guide Performance Testing: An Autonomous Test Framework\n", "abstract": " Satisfying performance requirements is of great importance for performance-critical software systems. Performance analysis to provide an estimation of performance indices and ascertain whether the requirements are met is essential for achieving this target. Model-based analysis as a common approach might provide useful information but inferring a precise performance model is challenging, especially for complex systems. Performance testing is considered as a dynamic approach for doing performance analysis. In this work-in-progress paper, we propose a self-adaptive learning-based test framework which learns how to apply stress testing as one aspect of performance testing on various software systems to find the performance breaking point. It learns the optimal policy of generating stress test cases for different types of software systems, then replays the learned policy to generate the test cases with less\u00a0\u2026", "num_citations": "18\n", "authors": ["1266"]}
{"title": "Makespan reduction for dynamic workloads in cluster-based data grids using reinforcement learning based scheduling\n", "abstract": " Scheduling is one of the important problems within the scope of control and management in grid and cloud-based systems. Data grid still as a primary solution to process data-intensive tasks, deals with managing large amounts of distributed data in multiple nodes. In this paper, a two-phase learning-based scheduling algorithm is proposed for data-intensive tasks scheduling in cluster-based data grids. In the proposed scheduling algorithm, a hierarchical multi agent system, consisting of one global broker agent and several local agents, is applied to scheduling procedure in the cluster-based data grids. At the first step of the proposed scheduling algorithm, the global broker agent selects the cluster with the minimum data cost based on the data communication cost measure, then an adaptive policy based on Q-learning is used by the local agent of the selected cluster to schedule the task to the proper node of the\u00a0\u2026", "num_citations": "13\n", "authors": ["1266"]}
{"title": "Adaptive Service Performance Control using Cooperative Fuzzy Reinforcement Learning in Virtualized Environments\n", "abstract": " Designing efficient control mechanisms to meet strict performance requirements with respect to changing workload demands without sacrificing resource efficiency remains a challenge in cloud infrastructures. A popular approach is fine-grained resource provisioning via auto-scaling mechanisms that rely on either threshold-based adaptation rules or sophisticated queuing/control-theoretic models. While it is difficult at design time to specify optimal threshold rules, it is even more challenging inferring precise performance models for the multitude of services. Recently, reinforcement learning have been applied to address this challenge. However, such approaches require many learning trials to stabilize at the beginning and when operational conditions vary thereby limiting their application under dynamic workloads. To this end, we extend the standard reinforcement learning approach in two ways: a) we formulate the\u00a0\u2026", "num_citations": "9\n", "authors": ["1266"]}
{"title": "Learning-based response time analysis in real-time embedded systems: A simulation-based approach\n", "abstract": " Response time analysis is an essential task to verify the behavior of real-time systems. Several response time analysis methods have been proposed to address this challenge, particularly for real-time systems with different levels of complexity. Static analysis is a popular approach in this context, but its practical applicability is limited due to the high complexity of the industrial real-time systems, as well as many unpredictable runtime events in these systems. In this work-in-progress paper, we propose a simulation-based response time analysis approach using reinforcement learning to find the execution scenarios leading to the worst-case response time. The approach learns how to provide a practical estimation of the worst-case response time through simulating the program without performing static analysis. Our initial study suggests that the proposed approach could be applicable in the simulation environments of\u00a0\u2026", "num_citations": "6\n", "authors": ["1266"]}
{"title": "From Requirements to Verifiable Executable Models using Rebeca\n", "abstract": " Software systems are complicated, and the scientific and engineering methodologies for software development are relatively young. We need robust methods for handling the ever-increasing complexity of software systems that are now in every corner of our lives. In this paper we focus on asynchronous event-based reactive systems and show how we start from the requirements, move to actor-based Rebeca models, and formally verify the models for correctness. The Rebeca models include the details of the signals and messages that are passed at the network level including the timing, and can be mapped to the executable code. We show how we can use the architecture design and structured requirements to build the behavioral models, including Rebeca models, and use the state diagrams to write the properties of interest, and then use model checking to check the properties. The formally verified\u00a0\u2026", "num_citations": "5\n", "authors": ["1266"]}
{"title": "Mutation score evaluation in terms of object-oriented metrics\n", "abstract": " Mutation testing is a means of creating more effective test cases. Mutation testing is primarily used as a program-based technique. It uses mutation operations to mutate the program and generate program mutants. The mutation testing aims at generating a test set that its behavior is different from the original program. More formally, the goal in mutation testing is killing the generated mutants by causing the mutant to have different behavior from the original program on the same input data. In this testing method mutation score is the proportion of the dead mutants to the total number of non-equivalent mutants. This paper focuses on using structural complexity of the program in calculating the mutation score. The proposed approach selects some object-oriented metrics which reflect the complexity of features that mutation operators are applied to them in the program. It calculates the total mutation score of the program in\u00a0\u2026", "num_citations": "5\n", "authors": ["1266"]}
{"title": "Machine learning-assisted performance testing\n", "abstract": " Automated testing activities like automated test case generation imply a reduction in human effort and cost, with the potential to impact the test coverage positively. If the optimal policy, ie, the course of actions adopted, for performing the intended test activity could be learnt by the testing system, ie, a smart tester agent, then the learnt policy could be reused in analogous situations which leads to even more efficiency in terms of required efforts. Performance testing under stress execution conditions, ie, stress testing, which involves providing extreme test conditions to find the performance breaking points, remains a challenge, particularly for complex software systems. Some common approaches for generating stress test conditions are based on source code or system model analysis, or use-case based design approaches. However, source code or precise system models might not be easily available for testing\u00a0\u2026", "num_citations": "4\n", "authors": ["1266"]}
{"title": "Performance Testing Using a Smart Reinforcement Learning-Driven Test Agent\n", "abstract": " Performance testing with the aim of generating an efficient and effective workload to identify performance issues is challenging. Many of the automated approaches mainly rely on analyzing system models, source code, or extracting the usage pattern of the system during the execution. However, such information and artifacts are not always available. Moreover, all the transactions within a generated workload do not impact the performance of the system the same way, a finely tuned workload could accomplish the test objective in an efficient way. Model-free reinforcement learning is widely used for finding the optimal behavior to accomplish an objective in many decision-making problems without relying on a model of the system. This paper proposes that if the optimal policy (way) for generating test workload to meet a test objective can be learned by a test agent, then efficient test automation would be possible without relying on system models or source code. We present a self-adaptive reinforcement learning-driven load testing agent, RELOAD, that learns the optimal policy for test workload generation and generates an effective workload efficiently to meet the test objective. Once the agent learns the optimal policy, it can reuse the learned policy in subsequent testing activities. Our experiments show that the proposed intelligent load test agent can accomplish the test objective with lower test cost compared to common load testing procedures, and results in higher test efficiency.", "num_citations": "2\n", "authors": ["1266"]}
{"title": "An Autonomous Performance Testing Framework using Self-Adaptive Fuzzy Reinforcement Learning\n", "abstract": " Test automation brings the potential to reduce costs and human effort, but several aspects of software testing remain challenging to automate. One such example is automated performance testing to find performance breaking points. Current approaches to tackle automated generation of performance test cases mainly involve using source code or system model analysis or use-case-based techniques. However, source code and system models might not always be available at testing time. On the other hand, if the optimal performance testing policy for the intended objective in a testing process instead could be learned by the testing system, then test automation without advanced performance models could be possible. Furthermore, the learned policy could later be reused for similar software systems under test, thus leading to higher test efficiency. We propose SaFReL, a self-adaptive fuzzy reinforcement learning\u00a0\u2026", "num_citations": "2\n", "authors": ["1266"]}
{"title": "Machine Learning-Assisted Performance Assurance\n", "abstract": " With the growing involvement of software systems in our life, assurance of performance, as an important quality characteristic, rises to prominence for the success of software products. Performance testing, preservation, and improvement all contribute to the realization of performance assurance. Common approaches to tackle challenges in testing, preservation, and improvement of performance mainly involve techniques relying on performance models or using system models or source code. Although modeling provides a deep insight into the system behavior, drawing a well-detailed model is challenging. On the other hand, those artifacts such as models and source code might not be available all the time. These issues are the motivations for using modelfree machine learning techniques such as model-free reinforcement learning to address the related challenges in performance assurance. Reinforcement\u00a0\u2026", "num_citations": "2\n", "authors": ["1266"]}
{"title": "Poster: Performance Testing Driven by Reinforcement Learning\n", "abstract": " Performance testing remains a challenge, particularly for complex systems. Different application-, platform- and workload-based factors can influence the performance of software under test. Common approaches for generating platform- and workload-based test conditions are often based on system model or source code analysis, real usage modeling and use-case based design techniques. Nonetheless, creating a detailed performance model is often difficult, and also those artifacts might not be always available during the testing. On the other hand, test automation solutions such as automated test case generation can enable effort and cost reduction with the potential to improve the intended test criteria coverage. Furthermore, if the optimal way (policy) to generate test cases can be learnt by testing system, then the learnt policy can be reused in further testing situations such as testing variants, evolved versions of\u00a0\u2026", "num_citations": "2\n", "authors": ["1266"]}
{"title": "Adaptive runtime response time control in PLC-based real-time systems using reinforcement learning\n", "abstract": " Timing requirements such as constraints on response time are key characteristics of real-time systems and violations of these requirements might cause a total failure, particularly in hard real-time systems. Runtime monitoring of the system properties is of great importance to check the system status and mitigate such failures. Thus, a runtime control to preserve the system properties could improve the robustness of the system with respect to timing violations. Common control approaches may require a precise analytical model of the system which is difficult to be provided at design time. Reinforcement learning is a promising technique to provide adaptive model-free control when the environment is stochastic, and the control problem could be formulated as a Markov Decision Process. In this paper, we propose an adaptive runtime control using reinforcement learning for real-time programs based on Programmable\u00a0\u2026", "num_citations": "2\n", "authors": ["1266"]}
{"title": "Learning-Based Self-Adaptive Assurance of Timing Properties in a Real-Time Embedded System\n", "abstract": " Providing an adaptive runtime assurance technique to meet the performance requirements of a real-time system without the need for a precise model could be a challenge. Adaptive performance assurance based on monitoring the status of timing properties can bring more robustness to the underlying platform. At the same time, the results or the achieved policy of this adaptive procedure could be used as feedback to update the initial model, and consequently for producing proper test cases. Reinforcement-learning has been considered as a promising adaptive technique for assuring the satisfaction of the performance properties of software-intensive systems in recent years. In this work-in-progress paper, we propose an adaptive runtime timing assurance procedure based on reinforcement learning to satisfy the performance requirements in terms of response time. The timing control problem is formulated as a\u00a0\u2026", "num_citations": "2\n", "authors": ["1266"]}
{"title": "A New Data-Intensive Task Scheduling in OptorSim, an Open Source Grid Simulator\n", "abstract": " Scheduling is one of the most important issues in executing tasks in grid systems. A data grid mainly deals with sharing and managing large amounts of distributed data in executing data-intensive applications. It is primarily a solution to satisfy the requirements of data-intensive tasks processing. OptorSim is a useful open source simulation tool for data grids. In this paper a new two-step data-intensive task scheduling called DSAS was proposed, implemented and, incorporated as a new scheduling package into OptorSim. As stated by the simulation results, the proposed scheduling strategy which was added to OptorSim, improves the mean response time and the mean waiting time of tasks compared to other common tasks scheduling strategies. The modified OptorSim benefits from a new scheduling package which improves the performance of task scheduling.", "num_citations": "2\n", "authors": ["1266"]}
{"title": "Integration of heterogeneous data sources in smart grid based on summary schema model\n", "abstract": " The modern infrastructure of electric grid known as smart grid is based on advanced communication and information technologies. The concept of data integration between heterogeneous data sources of smart grid reveals some challenges. The focus of this paper is on data integration as one of the major challenges in IT infrastructure of smart grid. In this paper, a semantic-based hierarchical integration model based on Summary Schema Model (SSM) has been proposed. The proposed model aims to optimize the cost of query in distributed heterogeneous databases. We represent how implementing a multidatabase system based on a Summary Schema Model would help to address and resolve data integration issues in IT infrastructure of smart grid. The analysis shows that the SSM-based integration model reduces the query response time compared to classic schema integration model.", "num_citations": "2\n", "authors": ["1266"]}
{"title": "A Multi-Objective Optimization Model for Data-Intensive Workflow Scheduling in Data Grids\n", "abstract": " The concept of workflow is used for modeling many of the data-intensive scientific applications executed on data grids. A Workflow is a series of interdependent tasks during which data is processed by different tasks. Scheduling the workflows in the grids is the process of assigning tasks to appropriate resources with the aim of achieving goals such as reducing workflow completion time while considering the data dependencies between the tasks. Data access time, processing time, and waiting time together constitute task completion time in the grids. Workflow scheduling aims to optimize these parameters in such a way that the workflow completion time decreases, and the system efficiency improves. In this paper, a scheduling model based on multi-objective optimization is proposed for scheduling data-intensive workflows in data grids. The scheduling model aims to optimize data communication cost, waiting time\u00a0\u2026", "num_citations": "2\n", "authors": ["1266"]}
{"title": "Deeper at the SBST 2021 Tool Competition: ADAS Testing Using Multi-Objective Search\n", "abstract": " Deeper is a simulation-based test generator that uses an evolutionary process, i.e., an archive-based NSGA-II augmented with a quality population seed, for generating test cases to test a deep neural network-based lane-keeping system. This paper presents Deeper briefly and summarizes the results of Deeper's participation in the Cyber-physical systems (CPS) testing competition at SBST 2021.", "num_citations": "1\n", "authors": ["1266"]}