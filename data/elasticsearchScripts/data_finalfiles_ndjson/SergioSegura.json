{"title": "Automated Analysis of Feature Models Using Atomic Sets.\n", "abstract": " Scalability is recognized as a key challenge in the automated analysis of Feature Models (FMs). Current solutions in this context mainly propose using different logic paradigms as a way to improve the performance at the solution level while the problem remains the same. Atomic Sets (ASs) were proposed as a promising solution for the simplification of FMs (ie reduction of the number of variables) in the context of automated analysis. However, years after their introduction, the lack of specific algorithms and performance results still hinder its integration into current proposals and tools. In this paper, we set the basis for the usage of ASs as a generic technique for the automated analysis of FMs. In particular, we first propose a specific algorithm to construct the ASs of an FM. Then, we present a performance test measuring the degree of improvement (in time and memory) when implementing ASs into CSP, BDD and SAT-based solutions.", "num_citations": "91\n", "authors": ["548"]}
{"title": "Debian Packages Repositories as Software Product Line Models. Towards Automated Analysis.\n", "abstract": " The automated analysis of variability models in general and feature models in particular is a thriving research topic. There have been numerous contributions along the last twenty years in this area including both, research papers and tools. However, the lack of realistic variability models to evaluate those techniques and tools is recognized as a major problem by the community. To address this issue, we looked for large\u2013scale variability models in the open source community. We found that the Debian package dependency language can be interpreted as software product line variability model. Moreover, we found that those models can be automatically analysed in a software product line variability model-like style. In this paper, we take a first step towards the automated analysis of Debian package dependency language. We provide a mapping from these models to propositional formulas. We also show how this could allow us to perform analysis operations on the repositories like the detection of anomalies (eg packages that cannot be installed).", "num_citations": "74\n", "authors": ["548"]}
{"title": "Assessment of C++ object\u2010oriented mutation operators: A selective mutation approach\n", "abstract": " Mutation testing is an effective but costly testing technique. Several studies have observed that some mutants can be redundant and therefore removed without affecting its effectiveness. Similarly, some mutants may be more effective than others in guiding the tester on the creation of high\u2010quality test cases. On the basis of these findings, we present an assessment of C++ class mutation operators by classifying them into 2 rankings: the first ranking sorts the operators on the basis of their degree of redundancy and the second regarding the quality of the tests they help to design. Both rankings are used in a selective mutation study analysing the trade\u2010off between the reduction achieved and the effectiveness when using a subset of mutants. Experimental results consistently show that leveraging the operators at the top of the 2 rankings, which are different, lead to a significant reduction in the number of mutants with a\u00a0\u2026", "num_citations": "24\n", "authors": ["548"]}
{"title": "Benchmarking on the Automated Analyses of Feature Models: A Preliminary Roadmap.\n", "abstract": " The automated analysis of Feature Models (FMs) is becoming a well-established discipline. New analysis operations, tools and techniques are rapidly proliferating in this context. However, the lack of standard mechanisms to evaluate and compare the performance of different solutions is starting to hinder the progress of this community. To address this situation, we propose the creation of a benchmark for the automated analyses of FMs. This benchmark would enable the objective and repeatable comparison of tools and techniques as well as promoting collaboration among the members of the discipline. Creating a benchmark requires a community to share a common view of the problem faced and come to agreement about a number of issues related to the design, distribution and usage of the benchmark. In this paper, we take a first step toward that direction. In particular, we first describe the main issues to be addressed for the successful development and maintenance of the benchmark. Then, we propose a preliminary research agenda setting milestones and clarifying the types of contributions expected from the community.", "num_citations": "24\n", "authors": ["548"]}
{"title": "Automated Analysis of Orthogonal Variability Models. A First Step.\n", "abstract": " The automated analysis of variability models is a challenge to be reached in SPLE (Software Product Line Engineering). Only recently researchers have devoted their attention to the reasoning on these models. However, their work has focused on Feature Models. Orthogonal Variability Modeling (OVM) is one of the approaches for modeling variability in software product line. Hence, an automated support is needed to reasoning on orthogonal variability models (OVMs). Although the automated analysis of OVMs has been proposed, it only deals with a small number of analysis operations, which are implemented using a specific logical representation and solver. In this position paper, we present the proposal that we will carry out to achieve an adequate tool to the analysis on OVMs. As part of this paper, we informally define some analysis operations on OVMs. In addition, we propose to study the possibility of extending FAMA framework for supporting analysis on OVMs. We consider that FAMA (FeAture Model Analyzer) could be a suitable option to automate this analysis since it provides a formal basis, integrate multiple solvers and already provide tools.", "num_citations": "18\n", "authors": ["548"]}
{"title": "Spectrum-based fault localization in software product lines\n", "abstract": " ContextSoftware Product Line (SPL) testing is challenging mainly due to the potentially huge number of products under test. Most of the research on this field focuses on making testing affordable by selecting a representative subset of products to be tested. However, once the tests are executed and some failures revealed, debugging is a cumbersome and time consuming task due to difficulty to localize and isolate the faulty features in the SPL.ObjectiveThis paper presents a debugging approach for the localization of bugs in SPLs.MethodThe proposed approach works in two steps. First, the features of the SPL are ranked according to their suspiciousness (i.e., likelihood of being faulty) using spectrum-based localization techniques. Then, a novel fault isolation approach is used to generate valid products of minimum size containing the most suspicious features, helping to isolate the cause of failures.ResultsFor the\u00a0\u2026", "num_citations": "14\n", "authors": ["548"]}
{"title": "GiGAn: Evolutionary mutation testing for C++ object-oriented systems\n", "abstract": " The reduction of the expenses of mutation testing should be based on well-studied cost reduction techniques to avoid biased results. Evolutionary Mutation Testing (EMT) aims at generating a reduced set of mutants by means of an evolutionary algorithm, which searches for potentially equivalent and difficult to kill mutants to help improve the test suite. However, there is little evidence of its applicability to other contexts beyond WS-BPEL compositions. This study explores its performance when applied to C++ object-oriented programs thanks to a newly developed system, GiGAn. The conducted experiments reveal that EMT shows stable behavior in all the case studies, where the best results are obtained when a low percentage of the mutants is generated. They also support previous studies of EMT when compared to random mutant selection, reinforcing its use for the goal of improving the fault detection capability of\u00a0\u2026", "num_citations": "14\n", "authors": ["548"]}
{"title": "A template-based approach to describing metamorphic relations\n", "abstract": " Metamorphic testing enables the generation of test cases in the absence of an oracle by exploiting relations among different executions of the program under test, called metamorphic relations. In a recent survey, we observed a great variability in the way metamorphic relations are described, typically in an informal manner using natural language. We noticed that the lack of a standard mechanism to describe metamorphic relations often makes them hard to read and understand, which hinders the widespread adoption of the technique. In this paper, we propose a template-based approach for the description of metamorphic relations. The proposed template aims to ease communication among practitioners as well as to contribute to research dissemination. Also, it provides a helpful guide for those approaching metamorphic testing for the first time. For the validation of the approach, we used the proposed template to\u00a0\u2026", "num_citations": "10\n", "authors": ["548"]}
{"title": "3 1Metamorphic Testing: A Literature Review\n", "abstract": " Copyright c\u00a9 2015 by ISA Research Group. Permission to reproduce this document and to prepare derivative works from this docu-ment for internal use is granted, provided the copyright and\u2019No Warranty\u2019statements are included with all reproductions and derivative works.", "num_citations": "8\n", "authors": ["548"]}
{"title": "Qos-aware metamorphic testing: An elevation case study\n", "abstract": " Elevators are among the oldest and most widespread transportation systems, yet their complexity increases rapidly to satisfy customization demands and to meet quality of service requirements. Verification and validation tasks in this context are costly, since they rely on the manual intervention of domain experts at some points of the process. This is mainly due to the difficulty to assess whether the elevators behave as expected in the different test scenarios, the so-called test oracle problem. Metamorphic testing is a thriving testing technique that alleviates the oracle problem by reasoning on the relations among multiple executions of the system under test, the so-called metamorphic relations. In this practical experience paper, we report on the application of metamorphic testing to verify an industrial elevator dispatcher. Together with domain experts from the elevation sector, we defined multiple metamorphic relations\u00a0\u2026", "num_citations": "7\n", "authors": ["548"]}
{"title": "Metamorphic testing: challenges ahead\n", "abstract": " Metamorphic testing is a popular testing technique that has shown to be effective at detecting faults in numerous domains such as web services and autonomous vehicles. Despite the many advances made in the last two decades, however, metamorphic testing is still a fertile soil for new contributions. This talk will provide an overview of the current state of the discipline and some of the key challenges to be addressed from three different perspectives: the technique, its applications, and the research community. The speech and the subsequent discussion aims to provide the audience with a common view of the field and the work to be done, paving the way for new promising contributions.", "num_citations": "7\n", "authors": ["548"]}
{"title": "Performance mutation testing: Hypothesis and open questions\n", "abstract": " Performance bugs are common, costly, and elusive. Performance tests aim to detect performance bugs by running the program with specific inputs and determining whether the observed behaviour is acceptable. There not exist mechanisms, however, to assess the effectiveness of performance tests. Mutation testing is a technique to evaluate and enhance functional test suites by seeding artificial faults in the program under test. In this new idea paper, we explore the applicability of mutation testing to assess and improve performance tests. This novel approach is motivated with examples and open questions.", "num_citations": "6\n", "authors": ["548"]}
{"title": "Exemplar: An experimental information repository for software engineering research\n", "abstract": " The number and variety of experiments carried out in software engineering research is growing, leading to an increasing need of replication and review. In order to support such needs the information about experiments should be provided as lab-packs. However, this information is often scattered, poorly structured, and even unavailable, implying a tedious process of search and gathering. EXEMPLAR is an online platform for managing experimental information, which allows the uploading and publication of experimental lab packs, and an efficient search. The platform also supports the use of formal languages for providing experimental descriptions (eg SEDL and MOEDL). In so doing, EXEMPLAR enables the automated analysis of lab-packs, in order to detect common validity threats and missing information which could hinder replicability.", "num_citations": "6\n", "authors": ["548"]}
{"title": "Performance mutation testing\n", "abstract": " Performance bugs are known to be a major threat to the success of software products. Performance tests aim to detect performance bugs by executing the program through test cases and checking whether it exhibits a noticeable performance degradation. The principles of mutation testing, a well\u2010established testing technique for the assessment of test suites through the injection of artificial faults, could be exploited to evaluate and improve the detection power of performance tests. However, the application of mutation testing to assess performance tests, henceforth called performance mutation testing (PMT), is a novel research topic with numerous open challenges. In previous papers, we identified some key challenges related to PMT. In this work, we go a step further and explore the feasibility of applying PMT at the source\u2010code level in general\u2010purpose languages. To do so, we revisit concepts associated with\u00a0\u2026", "num_citations": "5\n", "authors": ["548"]}
{"title": "Invirtiendo las clases de laboratorio en Ingenier\u00eda Inform\u00e1tica: Un enfoque \u00e1gil\n", "abstract": " En este art\u00edculo describimos nuestra experiencia al aplicar la metodolog\u00eda de clase invertida en la asignatura Arquitectura e Integraci\u00f3n de Sistemas Software, de segundo curso del grado de Ingenier\u00eda del Software. Varios aspectos caracterizan este estudio frente a los trabajos relacionados. En primer lugar, la metodolog\u00eda fue aplicada en las clases pr\u00e1cticas de la asignatura, donde conseguimos aumentar el tiempo dedicado a la resoluci\u00f3n de ejercicios en 24 minutos de media. En segundo lugar, la volatilidad del temario hizo necesario desarrollar una aproximaci\u00f3n \u00e1gil a la metodolog\u00eda, en la que los profesores deb\u00edan ser capaces de elaborar v\u00eddeos docentes de calidad en sus propios despachos y en unos pocos minutos. Este art\u00edculo resume algunas de las muchas lecciones aprendidas en relaci\u00f3n a la elaboraci\u00f3n del material. En tercer lugar, el estudio destaca tambi\u00e9n por el tama\u00f1o, habi\u00e9ndose realizado a lo largo de dos cursos acad\u00e9micos, 2017 y 2018, involucrando a un total de 434 alumnos y 6 profesores. Los resultados del estudio, respaldados por un s\u00f3lido an\u00e1lisis estad\u00edstico de los datos, demuestran la idoneidad de esta metodolog\u00eda para ser aplicada en las clases de laboratorio del \u00e1rea de Ingenier\u00eda del software.", "num_citations": "5\n", "authors": ["548"]}
{"title": "Automated testing on the analysis of variability-intensive artifacts: an exploratory study with sat solvers\n", "abstract": " The automated detection of faults on variability analysis tools is a challenging task often infeasible due to the combinatorial complexity of the analyses. In previous works, we successfully automated the generation of test data for feature model analysis tools using metamorphic testing. The positive results obtained have encouraged us to explore the applicability of this technique for the efficient detection of faults in other variability-intensive domains. In this paper, we present an automated test data generator for SAT solvers that enables the generation of random propositional formulas (inputs) and their solutions (expected output). In order to show the feasibility of our approach, we introduced 100 artificial faults (ie mutants) in an open source SAT solver and compared the ability of our generator and three related benchmarks to detect them. Our results are promising and encourage us to generalize the technique, which could be potentially applicable to any tool dealing with variability such as Eclipse repositories or Maven dependencies analyzers.", "num_citations": "5\n", "authors": ["548"]}
{"title": "Prueba de mutaci\u00f3n evolutiva aplicada a sistemas orientados a objetos\n", "abstract": " A pesar del beneficio que puede reportar la prueba de mutaciones en el proceso de prueba de software, el coste que supone su aplicaci\u00f3n siempre ha sido visto como un obst\u00e1culo para una mayor acogida por parte de la industria. Por esta raz\u00f3n, se han desarrollado diversas t\u00e9cnicas que tratan de paliar el problema, principalmente mediante la reducci\u00f3n del n\u00famero de mutantes que son generados. Entre ellas se encuentra la Prueba de Mutaci\u00f3n Evolutiva (PME), que propone el empleo de algoritmos evolutivos para encontrar un subconjunto de mutantes que presenta mayor posibilidad de ayudar a refinar el conjunto de casos de prueba empleado. La t\u00e9cnica solo hab\u00eda sido probada con \u00e9xito en operadores para el lenguaje de programaci\u00f3n WS-BPEL. En este art\u00edculo se presentan los experimentos llevados a cabo aplicando la t\u00e9cnica de PME con mutantes generados por operadores de mutaci\u00f3n para C++ relacionados con la orientaci\u00f3n a objetos. Los resultados obtenidos, usando los par\u00e1metros considerados como m\u00e1s apropiados para la configuraci\u00f3n del algoritmo, revelan que la t\u00e9cnica tambi\u00e9n es m\u00e1s efectiva que una estrategia aleatoria con operadores de clase para sistemas en C++.", "num_citations": "4\n", "authors": ["548"]}
{"title": "Tandem: A taxonomy and a dataset of real-world performance bugs\n", "abstract": " The detection of performance bugs, like those causing an unexpected execution time, has gained much attention in the last years due to their potential impact in safety-critical and resource-constrained applications. Much effort has been put on trying to understand the nature of performance bugs in different domains as a starting point for the development of effective testing techniques. However, the lack of a widely accepted classification scheme of performance faults and, more importantly, the lack of well-documented and understandable datasets makes it difficult to draw rigorous and verifiable conclusions widely accepted by the community. In this paper, we present TANDEM, a dual contribution related to real-world performance bugs. Firstly, we propose a taxonomy of performance bugs based on a thorough systematic review of the related literature, divided into three main categories: effects, causes and contexts of\u00a0\u2026", "num_citations": "4\n", "authors": ["548"]}
{"title": "Search-based mutation testing to improve performance tests\n", "abstract": " Performance bugs are common and can cause a significant deterioration in the behaviour of a program, leading to costly issues. To detect them and reduce their impact, performance tests are typically applied. However, there is a lack of mechanisms to evaluate the quality of performance tests, causing many of these bugs remain unrevealed. Mutation testing, a fault-based technique to assess and improve test suites, has been successfully studied with functional tests. In this paper, we propose the use of mutation testing together with a search-based strategy (evolutionary algorithm) to find mutants that simulate performance issues. This novel approach contributes to enhance the confidence on performance tests while reducing the cost of mutation testing.", "num_citations": "4\n", "authors": ["548"]}
{"title": "SmarTest: A test case prioritization tool for drupal\n", "abstract": " Test case prioritization techniques aim to identify the optimal ordering of tests to accelerate the detection of faults. The importance of these techniques has been recognized in the context of Software Product Lines (SPLs), where the potentially huge number of products makes testing extremely challenging. We found that the open source Drupal framework shares most of the principles and challenges of SPL development and it can be considered a real-world example of family of products. In a previous work, we represented the Drupal configuration space as a feature model and we collected extra functional information about its features from open repositories. Part of this data proved to be a good indicator of faults propensity in Drupal features. Thus, they become valuable assets to prioritize tests in individual Drupal products. In this paper, we present SmarTest, a test prioritization tool for accelerating the detection of\u00a0\u2026", "num_citations": "3\n", "authors": ["548"]}
{"title": "Flipping laboratory sessions: An experience in computer science\n", "abstract": " This paper reports our experience in flipping a second- year undergraduate course on software architecture and integration, taught in the second course of a Software Engineering degree. We compare the application of the flipped-classroom methodology with a traditional methodology. Our study encompasses two academic courses, in the years 2017 and 2018, and involves a total number of 434 students and 6 lecturers, placing this among the largest studies on flipped-classroom to date. The paper also reports on the production of the videos used with the flipped-classroom methodology, recorded by the lecturers in informal settings, and provides several lessons learned in this regard. The results of the study, backed by a solid statistical analysis of the data, demonstrate the suitability of the flipped-classroom methodology for laboratory sessions in the subject course. Among other results, our analysis concluded\u00a0\u2026", "num_citations": "2\n", "authors": ["548"]}
{"title": "Study of trivial compiler equivalence on C++ object-oriented mutation operators\n", "abstract": " Trivial Compiler Equivalence (TCE) has been recently proposed as an effective technique to detect equivalences between programs, where two or more programs are equivalent if the compiler produces the same binary code. Mutation testing can greatly benefit from TCE as a way to reveal some equivalent and duplicate mutants, which traditionally hinder the applicability of the technique. For instance, previous research has shown that about 28% of the mutants generated by traditional mutation operators in C programs can be removed using TCE. However, the effectiveness of TCE has not been assessed with class-level operators, where the percentage of equivalent mutants is known to be higher than when using traditional ones. In this paper, we present an empirical study on the effectiveness of TCE at identifying equivalent and duplicate mutants using C++ class operators. The results show that TCE is helpful to\u00a0\u2026", "num_citations": "2\n", "authors": ["548"]}
{"title": "Debian Packages Repositories as Software Product Line Models. Towards Automated Analysis\n", "abstract": " The automated analysis of variability models in general and feature models in particular is a thriving research topic. There have been numerous contributions along the last twenty years in this area including both, research papers and tools. However, the lack of realistic variability models to evaluate those techniques and tools is recognized as a major problem by the community. To address this issue, we looked for large\u2013 scale variability models in the open source community. We found that the Debian package dependency language can be interpreted as software product line variability model. Moreover, we found that those models can be automatically analysed in a software product line variability model-like style. In this paper, we take a first step towards the automated analysis of Debian package dependency language. We provide a mapping from these models to propositional formulas. We also show how this could allow us to perform analysis operations on the repositories like the detection of anomalies (e.g. packages that cannot be installed).", "num_citations": "2\n", "authors": ["548"]}
{"title": "5 A first step towards a framework for the automated analysis of feature models\n", "abstract": " Feature modelling is a common mechanism for variability management in the context of software product lines. After years of progress, the number of proposals to automatically analyse feature models is still modest and the data about the performance of the different solvers and logic representations used in such area are practically non-existent. Three of the most promising proposals for the automated analysis of feature models are based on the mapping of feature models into CSP, SAT and BDD solvers. In this paper we present a performance test between three off-the-shelf Java CSP, SAT and BDD solvers to analyse feature models which is a novel contribution. In addition, we conclude that the integration of such proposals in a framework will be a key challenge in the future.", "num_citations": "2\n", "authors": ["548"]}
{"title": "Inter-Parameter Dependencies in Real-World Web APIs: The IDEA Dataset\n", "abstract": " 102 Research and Evidence in Software Engineering\u25fe approaches still suffer to a large extent from one fundamental problem: the management of inter-parameter dependencies. An inter-parameter dependency imposes a constraint on how two or more input parameters can be combined to form valid calls to the service. For example, in the YouTube API, when searching for videos in high definition (parameter videoDefinition), the parameter type must be set to \u201cvideo\u201d, otherwise an HTTP 400 status code (\u201cbad request\u201d) is returned in the response. Unfortunately, current API specification languages such as the OpenAPI Specification (OAS)[3] or the RESTful API Modeling Language (RAML)[5] provide no support for the formal description of such dependencies. The interest of industry in having support for these is reflected in an open feature request in OAS entitled \u201cSupport interdependencies between query parameters\u201d[2], created in January 2015 with the message shown below. At the time of this writing, the request has received over 280 votes and 55 comments from 33 participants:It would be great to be able to specify interdependencies between query parameters. In my app, some query parameters become \u2018required\u2019only when some other query parameter is present. And when conditionally required parameters are missing when the conditions are met, the API fails. Of course I can have the API reply back that some required parameter is missing, but it would be great to have that built into Swagger.", "num_citations": "1\n", "authors": ["548"]}