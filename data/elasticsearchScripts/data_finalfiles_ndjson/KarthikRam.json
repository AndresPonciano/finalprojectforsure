{"title": "Point of view: How open science helps researchers succeed\n", "abstract": " Open access, open data, open source and other open scholarship practices are growing in popularity and necessity. However, widespread adoption of these practices has not yet been achieved. One reason is that researchers are uncertain about how sharing their work will affect their careers. We review literature demonstrating that open research is associated with increases in citations, media attention, potential collaborators, job opportunities and funding opportunities. These findings are evidence that open research practices bring significant benefits to researchers relative to more traditional closed practices.DOI: http://dx.doi.org/10.7554/eLife.16800.001", "num_citations": "460\n", "authors": ["859"]}
{"title": "Git can facilitate greater reproducibility and increased transparency in science\n", "abstract": " Reproducibility is the hallmark of good science. Maintaining a high degree of transparency in scientific reporting is essential not just for gaining trust and credibility within the scientific community but also for facilitating the development of new ideas. Sharing data and computer code associated with publications is becoming increasingly common, motivated partly in response to data deposition requirements from journals and mandates from funders. Despite this increase in transparency, it is still difficult to reproduce or build upon the findings of most scientific publications without access to a more complete workflow. Version control systems (VCS), which have long been used to maintain code repositories in the software industry, are now finding new applications in science. One such open source VCS, Git, provides a lightweight yet robust framework that is ideal for managing the full suite of research outputs such as datasets, statistical code, figures, lab notes, and manuscripts. For individual researchers, Git provides a powerful way to track and compare versions, retrace errors, explore new approaches in a structured manner, while maintaining a full audit trail. For larger collaborative efforts, Git and Git hosting services make it possible for everyone to work asynchronously and merge their contributions at any time, all the while maintaining a complete authorship trail. In this paper I provide an overview of Git along with use-cases that highlight how this tool can be leveraged to make science more reproducible and transparent, foster new collaborations, and support novel uses.", "num_citations": "196\n", "authors": ["859"]}
{"title": "Data carpentry: workshops to increase data literacy for researchers\n", "abstract": " In many domains the rapid generation of large amounts of data is fundamentally changing how research is done. The deluge of data presents great opportunities, but also many challenges in managing, analyzing and sharing data. However, good training resources for researchers looking to develop skills that will enable them to be more effective and productive researchers are scarce and there is little space in the existing curriculum for courses or additional lectures. To address this need we have developed an introductory two-day intensive workshop, Data Carpentry, designed to teach basic concepts, skills, and tools for working more effectively and reproducibly with data.", "num_citations": "93\n", "authors": ["859"]}
{"title": "The case for open preprints in biology\n", "abstract": " Biologists should submit their preprints to open servers, a practice common in mathematics and physics, to open and accelerate the scientific process.", "num_citations": "78\n", "authors": ["859"]}
{"title": "Neotoma: A programmatic interface to the Neotoma Paleoecological Database\n", "abstract": " Paleoecological data are integral to ecological and evolutionary analyses. First, they provide an opportunity to study ecological and evolutionary interactions between communities and abiotic environments across time scales. Second, they allow us to study the long-term outcomes of processes that occur infrequently, such as megadroughts, hurricanes, and rapid climate change. Third, the past allows us to study ecological processes in the absence of widespread anthropogenic influence.", "num_citations": "67\n", "authors": ["859"]}
{"title": "Sustainable computational science: the ReScience initiative\n", "abstract": " A 2017 paper on# OpenResearch,# SocialComputing and the ReScience initiative from@ etienneroesch and colleagues was the 3rd most-mentioned item in CentAUR last week. This article is# OpenAccess https://t. co/wYmoRpNmNv https://t. co/mK9g4KAZCM https://t. co/adEgBnQ3gE", "num_citations": "62\n", "authors": ["859"]}
{"title": "The importance of individual developmental variation in stage\u2010structured population models\n", "abstract": " Population stage structure is fundamental to ecology, and models of this structure have proven useful in many different systems. Many ecological variables other than stage, such as habitat type, site occupancy and metapopulation status are also modelled using transitions among discrete states. Transitions among life stages can be characterised by the distribution of time spent in each stage, including the mean and variance of each stage duration and within\u2010individual correlations among multiple stage durations. Three modelling traditions represent stage durations differently. Matrix models can be derived as a long\u2010run approximation from any distribution of stage durations, but they are often interpreted directly as a Markov model for stage transitions. Statistical stage\u2010duration distribution models accommodate the variation typical of cohort development data, but such realism has rarely been incorporated in\u00a0\u2026", "num_citations": "54\n", "authors": ["859"]}
{"title": "Trends in use of scientific workflows: insights from a public repository and recommendations for best practice\n", "abstract": " Scientific workflows are typically used to automate the processing, analysis and management of scientific data. Most scientific workflow programs provide a user-friendly graphical user interface that enables scientists to more easily create and visualize complex workflows that may be comprised of dozens of processing and analytical steps. Furthermore, many workflows provide mechanisms for tracing provenance and methodologies that foster reproducible science. Despite their potential for enabling science, few studies have examined how the process of creating, executing, and sharing workflows can be improved. In order to promote open discourse and access to scientific methods as well as data, we analyzed a wide variety of workflow systems and publicly available workflows on the public repository myExperiment. It is hoped that understanding the usage of workflows and developing a set of recommended best practices will lead to increased contribution of workflows to the public domain.", "num_citations": "54\n", "authors": ["859"]}
{"title": "Building software, building community: lessons from the rOpenSci project\n", "abstract": " rOpenSci is a developer collective originally formed in 2011 by graduate students and post-docs from ecology and evolutionary biology to collaborate on building software tools to facilitate a more open and synthetic approach in the face of transformative rise of large and heterogeneous data. Born on the internet (the collective only began through chance discussions over social media), we have grown into a widely recognized effort that supports an ecosystem of some 45 software packages, engages scores of collaborators, has taught dozens of workshops around the world, and has secured over $480,000 in grant support. As young scientists working in an academic context largely without direct support for our efforts, we have first hand experience with most of the the technical and social challenges WSSSPE seeks to address. In this paper we provide an experience report which describes our approach and success in building an effective and diverse community.", "num_citations": "43\n", "authors": ["859"]}
{"title": "Hack weeks as a model for data science education and collaboration\n", "abstract": " Across many scientific disciplines, methods for recording, storing, and analyzing data are rapidly increasing in complexity. Skillfully using data science tools that manage this complexity requires training in new programming languages and frameworks as well as immersion in new modes of interaction that foster data sharing, collaborative software development, and exchange across disciplines. Learning these skills from traditional university curricula can be challenging because most courses are not designed to evolve on time scales that can keep pace with rapidly shifting data science methods. Here, we present the concept of a hack week as an effective model offering opportunities for networking and community building, education in state-of-the-art data science methods, and immersion in collaborative project work. We find that hack weeks are successful at cultivating collaboration and facilitating the exchange of\u00a0\u2026", "num_citations": "31\n", "authors": ["859"]}
{"title": "Dynamics of a subterranean trophic cascade in space and time\n", "abstract": " Trophic cascades, whereby predators indirectly benefit plant biomass by reducing herbivore pressure, form the mechanistic basis for classical biological control of pest insects. Entomopathogenic nematodes (EPN) are lethal to a variety of insect hosts with soil-dwelling stages, making them promising biocontrol agents. EPN biological control programs, however, typically fail because nematodes do not establish, persist and/or recycle over multiple host generations in the field. A variety of factors such as local abiotic conditions, host quantity and quality, and rates of movement affect the probability of persistence. Here, we review results from 13 years of study on the biology and ecology of an endemic population of Heterorhabditis marelatus (Rhabditida: Heterorhabditidae) in a California coastal prairie. In a highly seasonal abiotic environment with intrinsic variation in soils, vegetation structure, and host availability\u00a0\u2026", "num_citations": "28\n", "authors": ["859"]}
{"title": "Enforcing public data archiving policies in academic publishing: A study of ecology journals\n", "abstract": " To improve the quality and efficiency of research, groups within the scientific community seek to exploit the value of data sharing. Funders, institutions, and specialist organizations are developing and implementing strategies to encourage or mandate data sharing within and across disciplines, with varying degrees of success. Academic journals in ecology and evolution have adopted several types of public data archiving policies requiring authors to make data underlying scholarly manuscripts freely available. The effort to increase data sharing in the sciences is one part of a broader \u201cdata revolution\u201d that has prompted discussion about a paradigm shift in scientific research. Yet anecdotes from the community and studies evaluating data availability suggest that these policies have not obtained the desired effects, both in terms of quantity and quality of available datasets. We conducted a qualitative, interview-based\u00a0\u2026", "num_citations": "27\n", "authors": ["859"]}
{"title": "Soil mediates the interaction of coexisting entomopathogenic nematodes with an insect host\n", "abstract": " We tested for soil substrate effects on the movement and infectivity of naturally co-occurring entomopathogenic nematodes Steinernema feltiae and Heterorhabditis marelatus, alone and in combination. We manipulated the presence and bulk density of soil and added Galleria mellonella baits within capped and perforated 15\u00a0mL centrifuge tubes. Sampling tubes were then deployed in situ into field and laboratory settings as experimental traps for infective juveniles. In comparisons with standard soil collections from Lupinus arboreus rhizospheres, sampling tubes were equally sensitive to the presence of H. marelatus and more sensitive to S. feltiae. In laboratory microcosms, both EPN species infected Galleria at high frequencies in tubes lacking soil and in the absence of heterospecifics. Infection frequency of S. feltiae was unaffected by the presence of H. marelatus, but it declined with higher soil bulk density inside\u00a0\u2026", "num_citations": "27\n", "authors": ["859"]}
{"title": "Journal of Open Source Software (JOSS): design and first-year review\n", "abstract": " This article describes the motivation, design, and progress of the Journal of Open Source Software (JOSS). JOSS is a free and open-access journal that publishes articles describing research software. It has the dual goals of improving the quality of the software submitted and providing a mechanism for research software developers to receive credit. While designed to work within the current merit system of science, JOSS addresses the dearth of rewards for key contributions to science made in the form of software. JOSS publishes articles that encapsulate scholarship contained in the software itself, and its rigorous peer review targets the software components: functionality, documentation, tests, continuous integration, and the license. A JOSS article contains an abstract describing the purpose and functionality of the software, references, and a link to the software archive. The article is the entry point of a JOSS submission, which encompasses the full set of software artifacts. Submission and review proceed in the open, on GitHub. Editors, reviewers, and authors work collaboratively and openly. Unlike other journals, JOSS does not reject articles requiring major revision; while not yet accepted, articles remain visible and under review until the authors make adequate changes (or withdraw, if unable to meet requirements). Once an article is accepted, JOSS gives it a digital object identifier (DOI), deposits its metadata in Crossref, and the article can begin collecting citations on indexers like Google Scholar and other services. Authors retain copyright of their JOSS article, releasing it under a Creative Commons Attribution 4.0 International License. In its\u00a0\u2026", "num_citations": "26\n", "authors": ["859"]}
{"title": "The utility of repeated presence data as a surrogate for counts: a case study using butterflies\n", "abstract": " Abundance data are widely used to monitor long-term population trends for management and conservation of species of interest. Programs that collect count data are often prohibitively expensive and time intensive, limiting the number of species that can be simultaneously monitored. Presence data, on the other hand, can often be collected in less time and for multiple species simultaneously. We investigate the relationship of counts to presence using 49 butterfly species across 4 sites over 9\u00a0years, and then compare trends produced from each index. We also employed simulated datasets to test the effect of reduced sampling on the relationship of counts to presence data and to investigate changes in each index\u2019s power to reveal population trends. Presence and counts were highly correlated for most species tested, and population trends based on each index were concordant for most species. The effect of\u00a0\u2026", "num_citations": "22\n", "authors": ["859"]}
{"title": "Metapopulation dynamics override local limits on long\u2010term parasite persistence\n", "abstract": " A simple null model, particularly germane to small and vulnerable organisms such as parasites, is that local conditions set a stage upon which larger\u2010scale dynamics play out. Soil moisture strongly influences survival of entomopathogenic nematodes (EPN), which in turn drive trophic cascades by protecting vegetation from root\u2010feeding herbivores. In this study, we examine the mechanisms responsible for patchy occurrence of an entomopathogenic nematode, Heterorhabditis marelatus, in a California coastal prairie. One hypothesis proposes that biotic factors such as competition and natural enemies could regulate occurrence of EPN populations. We found that fungi and other enemies of EPN, although locally potent, did not explain the patterns of incidence across sites. Abiotic factors also have strong effects on EPN persistence, especially for vulnerable free\u2010living stages. Thus, we tested the hypothesis that\u00a0\u2026", "num_citations": "22\n", "authors": ["859"]}
{"title": "The role of metadata in reproducible computational research\n", "abstract": " Reproducible computational research (RCR) is the keystone of the scientific method for in silico analyses, packaging the transformation of raw data to published results. In addition to its role in research integrity, improving the reproducibility of scientific studies can accelerate evaluation and reuse. This potential and wide support for the FAIR principles have motivated interest in metadata standards supporting reproducibility. Metadata provide context and provenance to raw data and methods and are essential to both discovery and validation. Despite this shared connection with scientific data, few studies have explicitly described how metadata enable reproducible computational research. This review employs a functional content analysis to identify metadata standards that support reproducibility across an analytic stack consisting of input data, tools, notebooks, pipelines, and publications. Our review provides\u00a0\u2026", "num_citations": "8\n", "authors": ["859"]}
{"title": "A community of practice around peer review for long-term research software sustainability\n", "abstract": " Scientific open source projects are responsible for enabling many of the major advances in modern science including recent breakthroughs such as the Laser Interferometer Gravitational-Wave Observatory project recognized in the 2017 Nobel Prize for physics. However, much of this software ecosystem is developed ad hoc with no regard for sustainable software development practices. This problem is further compounded by the fact that researchers who develop software have little in the way of resources or academic recognition for their efforts. The rOpenSci Project, founded in 2011 with the explicit mission of developing software to support reproducible science, has in recent years undertaken an effort to improve the long tail of scientific software. In this paper, we describe our software peer-review system, which brings together the best of traditional academic review with new ideas from industry code review.", "num_citations": "8\n", "authors": ["859"]}
{"title": "A realistic guide to making data available alongside code to improve reproducibility\n", "abstract": " Data makes science possible. Sharing data improves visibility, and makes the research process transparent. This increases trust in the work, and allows for independent reproduction of results. However, a large proportion of data from published research is often only available to the original authors. Despite the obvious benefits of sharing data, and scientists' advocating for the importance of sharing data, most advice on sharing data discusses its broader benefits, rather than the practical considerations of sharing. This paper provides practical, actionable advice on how to actually share data alongside research. The key message is sharing data falls on a continuum, and entering it should come with minimal barriers.", "num_citations": "7\n", "authors": ["859"]}
{"title": "Package \u2018spatialEco\u2019\n", "abstract": " Description Utilities to support spatial data manipulation, query, sampling and modelling. Functions include models for species population density, download utilities for climate and global deforestation spatial products, spatial smoothing, multivariate separability, point process model for creating pseudoabsences and sub-sampling, polygon and point-distance landscape metrics, auto-logistic model, sampling models, cluster optimization, statistical exploratory tools and raster-based metrics.", "num_citations": "6\n", "authors": ["859"]}
{"title": "Package \u2018rgbif\u2019\n", "abstract": " Description A programmatic interface to the Web Service methods provided by the Global Biodiversity Information Facility ('GBIF';< http://www. gbif. org/developer/summary>).'GBIF'is a database of species occurrence records from sources all over the globe.'rgbif'includes functions for searching for taxonomic names, retrieving information on data providers, getting species occurrence records, and getting counts of occurrence records.", "num_citations": "5\n", "authors": ["859"]}
{"title": "The rockerverse: packages and applications for containerization with r\n", "abstract": " The Rocker Project provides widely used Docker images for R across different application scenarios. This article surveys downstream projects that build upon the Rocker Project images and presents the current state of R packages for managing Docker images and controlling containers. These use cases cover diverse topics such as package development, reproducible research, collaborative work, cloud-based data processing, and production deployment of services. The variety of applications demonstrates the power of the Rocker Project specifically and containerisation in general. Across the diverse ways to use containers, we identified common themes: reproducible environments, scalability and efficiency, and portability across clouds. We conclude that the current growth and diversification of use cases is likely to continue its positive impact, but see the need for consolidating the Rockerverse ecosystem of packages, developing common practices for applications, and exploring alternative containerisation software.", "num_citations": "4\n", "authors": ["859"]}
{"title": "Building toward a future where reproducible, open science is the norm\n", "abstract": " 62| Building toward a Future psychology, Anil Potti in cancer research, Carmen Reinhart and Kenneth Rogoff in economics, and Marc Hauser in evolutionary biology. In addition, large-scale efforts to reproduce biomedical (Begley & Ellis, 2012) and psychological experiments (Open Science Collaboration, 2015) suggest that the prevalence of nonreproducible research has been underestimated, resulting in news headlines declaring a \u201creproducibility crisis\u201d in science. The issue of reproducibility is particularly timely given the recent rise in retractions from high-profile journals (Van Noorden, 2011). While some aspects of this crisis are due to bad agents, there are also broader systemic problems that result in the production of nonreproducible research. In this chapter, we briefly survey some of the gaps, challenges, and opportunities for improving the reproducibility of research.", "num_citations": "3\n", "authors": ["859"]}
{"title": "Package \u2018taxize\u2019\n", "abstract": " Arguments name(character) One or more scientific names. id(integer) One or more BOLD taxonomic identifiers. fuzzy(logical) Whether to use fuzzy search or not (default: FALSE). Only used if name passed. dataTypes(character) Specifies the datatypes that will be returned. See Details for options. This variable is ignored if name parameter is passed, but is used if the id parameter is passed. bold_search 9 includeTree(logical) If TRUE (default: FALSE), returns a list containing information for parent taxa as well as the specified taxon. Only used if id passed. response(logical) Note that response is the object that returns from the Curl call, useful for debugging, and getting detailed info on the API call.... Further args passed on to GET, main purpose being curl debugging", "num_citations": "3\n", "authors": ["859"]}
{"title": "NSF 19-501 AccelNet Proposal: Community of Open Scholarship Grassroots Networks (COSGN)\n", "abstract": " The Community of Open Scholarship Grassroots Networks (COSGN), includes 120 grassroots networks, representing virtually every region of the world and every research discipline. These networks communicate and coordinate on topics of common interest. We propose, using an NSF 19-501 Full-Scale implementation grant, to formalize governance and coordination of the networks to maximize impact and establish standard practices for sustainability. In the project period, we will increase the capacity of COSGN to advance the research and community goals of the participating networks individually and collectively, and establish governance, succession planning, shared resources, and communication pathways to ensure an active, community-sustained network of networks. By the end of the project period, we will have established a self-sustaining network of networks that leverages disciplinary and regional diversity, actively collaborates across networks for grassroots organizing, and shares resources for maximum impact on culture change for open scholarship.", "num_citations": "2\n", "authors": ["859"]}
{"title": "Package \u2018rnoaa\u2019\n", "abstract": " Description Client for many'NOAA'data sources including the'NCDC'climate'API'at< https://www. ncdc. noaa. gov/cdo-web/webservices/v2>, with functions for each of the'API''endpoints': data, data categories, data sets, data types, locations, location categories, and stations. In addition, we have an interface for'NOAA'sea ice data, the'NOAA'severe weather inventory,'NOAA'Historical Observing'Metadata'Repository ('HOMR') data,'NOAA'storm data via'IBTrACS', tornado data via the'NOAA'storm prediction center, and more.", "num_citations": "2\n", "authors": ["859"]}
{"title": "Metadictionary: advocating for a community-driven metadata vocabulary application\n", "abstract": " Metadata disorder and unnecessary costs are increasing due to the expanding population of scientific data schemes and standards. Metadata challenges are reviewed; and SeaIce1, a community driven metadata vocabulary application, is introduced as a potential solution. SeaIce functions and development challenges are presented. CAMP-4-DATA participants are called upon to experiment with the SeaIce application and actively participate in a discussion targeting noted metadata challenges.", "num_citations": "2\n", "authors": ["859"]}
{"title": "Individual heterogeneity in mortality mediates long-term persistence of a seasonal microparasite\n", "abstract": " One of the primary objectives in population ecology is to understand mechanisms that allow a species to persist or to be driven to extinction. In most population models, individuals are assumed to be equivalent within any particular category such as age, sex, or morphological grouping. Individuals within such groupings, however, may exhibit considerable variation in traits that can significantly affect population trajectories. Although ecologists have long been aware of such variation, they are frequently ignored to maintain computational tractability. The few statistical models that do incorporate such heterogeneity require prohibitively large amounts of data on many individuals, making them impractical. In California\u2019s coastal prairie, a parasitic nematode, Heterorhabditis marelatus, is an important natural enemy, whose presence determines the strength and extent of a trophic cascade. Mortality of H. marelatus\u00a0\u2026", "num_citations": "2\n", "authors": ["859"]}
{"title": "Giving software its due through community-driven review and publication\n", "abstract": " A recent editorial in Nature Methods,\u201cGiving Software its Due\u201d, described challenges related to the development of research software and highlighted, in particular, the challenge of software publication and citation. Here, we call attention to a system that we have developed that enables community-driven software review, publication, and citation: The Journal of Open Source Software (JOSS) is an open-source project and an open access journal that provides a light-weight publishing process for research software. Focused on and based in open platforms and on a community of contributors, JOSS evidently satisfies a pressing need, having already published more than 500 articles in approximately three years of existence.", "num_citations": "1\n", "authors": ["859"]}
{"title": "Resistance to Adoption of Best Practices\n", "abstract": " There are many recommendations of\" best practices\" for those doing data science, data-intensive research, and research in general. These documents usually present a particular vision of how people should work with data and computing, recommending specific tools, activities, mechanisms, and sensibilities. However, implementation of best (or better) practices in any setting is often met with resistance from individuals and groups, who perceive some drawbacks to the proposed changes to everyday practice. We offer some definitions of resistance, identify the sources of researchers' hesitancy to adopt new ways of working, and describe some of the ways resistance is manifested in data science teams. We then offer strategies for overcoming resistance based on our group members' experiences working alongside resistors or resisting change themselves. Our discussion concluded with many remaining questions left to tackle, some of which are listed at the end of this piece.", "num_citations": "1\n", "authors": ["859"]}
{"title": "The Journal of Open Source Software\n", "abstract": " Before you submit Please make sure you've read the submission instructions before submitting. In particular please make sure there is a paper. md present in your repository that is structured like this. We promise this will make things go much more quickly during the review process-\u00ba", "num_citations": "1\n", "authors": ["859"]}
{"title": "Lightning talk: A model for peer review and onboarding research software\n", "abstract": " Code review, in which peers manually inspect the source code of software written by others, is widely recognized as one of the best tools for finding bugs in software. Code review is relatively uncommon in scientific software development, though. Scientists, despite being familiar with the process of peer review, often have little exposure to code review due to lack of training and historically little incentive to share the source code from their research. So scientific code, from one-off scripts to reusable R packages, is rarely subject to review.", "num_citations": "1\n", "authors": ["859"]}
{"title": "rOpenSci-open tools for open science\n", "abstract": " Solving many of the basic and applied challenges in ecology and evolution requires access to large amounts of data, often spanning long spatial and temporal scales. The long-established model where researchers collect and analyze their own data will soon be replaced by one where disparate datasets are brought to bear on both basic and applied problems. As science becomes more data-driven, it faces a whole new set of challenges. Researchers will not only have to maintain expertise in their domains but also learn new skills to curate, retrieve, and analyze these newly available data. In order to fully realize the potential of data-driven science and allow researchers to draw insights from these vast data stores, we need to address challenges associated with all aspects of the research life cycle. To foster and support a new generation of data-driven science, my colleagues and I founded a project called\u00a0\u2026", "num_citations": "1\n", "authors": ["859"]}