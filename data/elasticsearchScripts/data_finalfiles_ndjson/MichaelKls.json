{"title": "Uncertainty in machine learning applications: A practice-driven classification of uncertainty\n", "abstract": " Software-intensive systems that rely on machine learning (ML) and artificial intelligence (AI) are increasingly becoming part of our daily life, e.g., in recommendation systems or semi-autonomous vehicles. However, the use of ML and AI is accompanied by uncertainties regarding their outcomes. Dealing with such uncertainties is particularly important when the actions of these systems can harm humans or the environment, such as in the case of a medical product or self-driving car. To enable a system to make informed decisions when confronted with the uncertainty of embedded AI/ML models and possible safety-related consequences, these models do not only have to provide a defined functionality but must also describe as precisely as possible the likelihood of their outcome being wrong or outside a given range of accuracy. Thus, this paper proposes a classification of major uncertainty sources that is\u00a0\u2026", "num_citations": "45\n", "authors": ["1997"]}
{"title": "Transparent combination of expert and measurement data for defect prediction: An industrial case study\n", "abstract": " Defining strategies on how to perform quality assurance (QA) and how to control such activities is a challenging task for organizations developing or maintaining software and software-intensive systems. Planning and adjusting QA activities could benefit from accurate estimations of the expected defect content of relevant artifacts and the effectiveness of important quality assurance activities. Combining expert opinion with commonly available measurement data in a hybrid way promises to overcome the weaknesses of purely data-driven or purely expert-based estimation methods. This article presents a case study of the hybrid estimation method HyDEEP for estimating defect content and QA effectiveness in the telecommunication domain. The specific focus of this case study is the use of the method for gaining quantitative predictions. This aspect has not been empirically analyzed in previous work. Among other\u00a0\u2026", "num_citations": "37\n", "authors": ["1997"]}
{"title": "Adapting Software Quality Models: Practical Challenges, Approach, and First Empirical Results\n", "abstract": " Measuring and evaluating software quality has become a fundamental task. Many models have been proposed to support stakeholders in dealing with software quality. However, in most cases, quality models do not fit perfectly for the target application context. Since approaches for efficiently adapting quality models are largely missing, many quality models in practice are built from scratch or reuse only high-level concepts of existing models. We present a tool-supported approach for the efficient adaptation of quality models. An initial empirical investigation indicates that the quality models obtained applying the proposed approach are considerably more consistently and appropriately adapted than those obtained following an ad-hoc approach. Further, we could observe that model adaptation is significantly more efficient (~factor 8) when using this approach.", "num_citations": "34\n", "authors": ["1997"]}
{"title": "Quality evaluation for big data: a scalable assessment approach and first evaluation results\n", "abstract": " High-quality data is a prerequisite for most types of analysis provided by software systems. However, since data quality does not come for free, it has to be assessed and managed continuously. The increasing quantity, diversity, and velocity that characterize big data today make these tasks even more challenging. We identified challenges that are specific for big data quality assessments with particular emphasis on their usage in smart ecosystems and make a proposal for a scalable cross-organizational approach that addresses these challenges. We developed an initial prototype to investigate scalability in a multi-node test environment using big data technologies. Based on the observed horizontal scalability behavior, there is an indication that the proposed approach also allows dealing with increasing volumes of heterogeneous data.", "num_citations": "23\n", "authors": ["1997"]}
{"title": "Support planning and controlling of early quality assurance by combining expert judgment and defect data\u2014A case study\n", "abstract": " Planning quality assurance (QA) activities in a systematic way and controlling their execution are challenging tasks for companies that develop software or software-intensive systems. Both require estimation capabilities regarding the effectiveness of the applied QA techniques and the defect content of the checked artifacts. Existing approaches for these purposes need extensive measurement data from historical projects. Due to the fact that many companies do not collect enough data for applying these approaches (especially for the early project lifecycle), they typically base their QA planning and controlling solely on expert opinion. This article presents a hybrid method combining commonly available measurement data and context-specific expert knowledge. To evaluate the method\u2019s applicability and usefulness, we conducted a case study in the context of independent verification and validation activities\u00a0\u2026", "num_citations": "23\n", "authors": ["1997"]}
{"title": "How to evaluate meta-models for software quality?\n", "abstract": " The use of appropriate software quality models is crucial for companies to achieve the product quality required to satisfy customer needs. Most current quality models provide little operationalization and lack adaptation guidelines, which limits their usefulness in practice. It has been proposed to use meta-models to specify an explicit structure in order to ensure that quality models conforming to it can be operationalized and adapted by requiring corresponding model elements and modeling constructs. To be applicable in practice, a meta-model needs to be general enough so that existing quality models can be transferred to the new structure provided by the meta-model while preserving the knowledge they contain. This paper presents an empirical approach for evaluating generality as well as its application to a selected meta-model and six industrial quality models. The results show that (1) the proposed meta-model is general enough to model most contents of the industrial quality models,(2) the generality of a meta-model contributes to its perceived ease of use and usefulness, and (3) the evaluation approach is applicable and reflects the perception of quality model experts well.", "num_citations": "22\n", "authors": ["1997"]}
{"title": "Predicting defect content and quality assurance effectiveness by combining expert judgment and defect data\u2014A case study\n", "abstract": " Planning quality assurance (QA) activities in a systematic way and controlling their execution are challenging tasks for companies that develop software or software-intensive systems. Both require estimation capabilities regarding the effectiveness of the applied QA techniques and the defect content of the checked artifacts. Existing approaches for these purposes need extensive measurement data from his-torical projects. Due to the fact that many companies do not collect enough data for applying these approaches (es-pecially for the early project lifecycle), they typically base their QA planning and controlling solely on expert opinion. This article presents a hybrid method that combines commonly available measurement data and context-specific expert knowledge. To evaluate the methodpsilas applicability and usefulness, we conducted a case study in the context of independent verification and validation activities\u00a0\u2026", "num_citations": "22\n", "authors": ["1997"]}
{"title": "The use of simulation techniques for hybrid software cost estimation and risk analysis\n", "abstract": " Cost estimation is a crucial field for companies developing software or software\u2010intensive systems. Besides point estimates, effective project management also requires information about cost\u2010related project risks, for example, a probability distribution of project costs. One possibility to provide such information is the application of Monte Carlo simulation. However, it is not clear whether other simulation techniques exist that are more accurate or efficient when applied in this context. We investigate this question with CoBRA\u00ae,1 a cost estimation method that applies simulation, that is, random sampling, for cost estimation. This chapter presents an empirical study, which evaluates selected sampling techniques employed within the CoBRA\u00ae method. One result of this study is that the usage of Latin Hypercube sampling can improve average simulation accuracy by 60% and efficiency by 77%. Moreover, analytical solutions\u00a0\u2026", "num_citations": "22\n", "authors": ["1997"]}
{"title": "A Large-Scale Technology Evaluation Study: Effects of Model-based Analysis and Testing\n", "abstract": " Besides model-based development, model-based quality assurance and the tighter integration of static and dynamic quality assurance activities are becoming increasingly relevant in the development of software-intensive systems. Thus, this paper reports on an empirical study aimed at investigating the promises regarding quality improvements and cost savings. The evaluation comprises data from 13 industry case studies conducted during a three-year large-scale research project in the transportation domain (automotive, avionics, rail system). During the evaluation, we identified major goals and strategies associated with (integrated) model-based analysis and testing and evaluated the improvements achieved. The aggregated results indicate an average cost reduction of between 29% and 34% for verification and validation and of between 22% and 32% for defect removal. Compared with these cost savings\u00a0\u2026", "num_citations": "16\n", "authors": ["1997"]}
{"title": "Balancing upfront definition and customization of quality models\n", "abstract": " The selection and customization of quality models for the development of software systems or software-intensive systems and services is a challenging task. Due to the nature of software development, quality models such as reliability models or defect models need to be adapted to specific project goals and environment characteristics. Currently, there is a tremendous deficit in understanding the selection and customization of appropriate quality models. Quality models that balance upfront definition and customization are widely missing. This article describes two types of quality models, ie, fixed models and define-your-own models, gives an initial overview of possible variabilities in quality models, and finally sketches elements for the definition of balanced quality models.", "num_citations": "16\n", "authors": ["1997"]}
{"title": "Uncertainty wrappers for data-driven models\n", "abstract": " In contrast to established safety-critical software components, we can neither prove nor assume that the outcomes of components containing models based on artificial intelligence (AI) or machine learning (ML) will be correct in any situation. Thus, uncertainty is an inherent part of decision-making when using the outcomes of data-driven models created by AI/ML algorithms. In order to deal with this \u2013 especially in the context of safety-related systems \u2013 we need to make uncertainty transparent via dependable statistical statements. This paper introduces both a conceptual model and the related mathematical foundation of an uncertainty wrapper solution for data-driven models. The wrapper enriches existing data-driven models such as provided by ML or other AI techniques with case-individual and sound uncertainty estimates. The task of traffic sign recognition is used to illustrate the approach, which\u00a0\u2026", "num_citations": "15\n", "authors": ["1997"]}
{"title": "Handling Estimation Uncertainty with Bootstrapping: Empirical Evaluation in the Context of Hybrid Prediction Methods\n", "abstract": " Reliable predictions are essential for managing software projects with respect to cost and quality. Several studies have shown that hybrid prediction models combining causal models with Monte Carlo simulation are especially successful in addressing the needs and constraints of today's software industry: They deal with limited measurement data and, additionally, make use of expert knowledge. Moreover, instead of providing merely point estimates, they support the handling of estimation uncertainty, e.g., estimating the probability of falling below or exceeding a specific threshold. Although existing methods do well in terms of handling uncertainty of information, we can show that they leave uncertainty coming from imperfect modeling largely unaddressed. One of the consequences is that they probably provide over-confident uncertainty estimates. This paper presents a possible solution by integrating bootstrapping\u00a0\u2026", "num_citations": "12\n", "authors": ["1997"]}
{"title": "Evaluating a Quality Model for Software Product Assessment\u2013A Case Study\n", "abstract": " Background: Software quality models have been proposed as a means for describing the concept of quality. Most quality models take an abstract view on quality characteristics. Therefore, they are not able to integrate measurement tools and metrics for conducting quality assessments of real software systems. To solve this problem, we developed a quality meta-model defining the structure of quality models that are detailed enough to specify quality characteristics and their links to metrics and measurement tools. Aim: In this paper, we present our evaluation of this meta-model in terms of its usability for constructing quality models that are suitable for quality assessments of real software systems. Method: For conducting the study, we developed an initial \u201cproof-of-concept\u201d quality model on the basis of static code analysis tools. This quality model was used for conducting quality assessments of Java-based software systems. The results were analyzed regarding two criteria:(1) the diversification provided by the results and (2) the congruence of the results with an independently conducted expert-based evaluation of the systems. Results: While the difference in the assessment results between the various systems is rather small, a correlation with the expert evaluation could be proven. Furthermore, the study provided useful insights for further work and improvements. Conclusions: We conclude that quality models based on the Quamoco meta-model are, in principle, capable of being operationalized for the automated quality assessment of software systems.", "num_citations": "10\n", "authors": ["1997"]}
{"title": "Managing software quality through a hybrid defect content and effectiveness model\n", "abstract": " Quality assurance (QA) plays a crucial role in today's software development. However, methods and models proposed in literature to support QA management suffer from several drawbacks. Many are specialized to certain activities like system test or inspections. They commonly support only one application purpose, eg, planning or controlling, and are often applicable only after measurement data has been collected for several historical applications. To overcome these drawbacks, we developed a method that can be applied to QA activities during any phase, and which supports comprehensive quality management related tasks: improvement, planning, and controlling. To be applicable in practice, the method combines the available measurement data with expert judgment to build context-specific models. In addition, the method provides early benefits, while motivating the collection of measurement data by\u00a0\u2026", "num_citations": "10\n", "authors": ["1997"]}
{"title": "A framework for building uncertainty wrappers for ai/ml-based data-driven components\n", "abstract": " More and more software-intensive systems include components that are data-driven in the sense that they use models based on artificial intelligence (AI) or machine learning (ML). Since the outcomes of such models cannot be assumed to always be correct, related uncertainties must be understood and taken into account when decisions are made using these outcomes. This applies, in particular, if such decisions affect the safety of the system. To date, however, hardly any AI-/ML-based model provides dependable estimates of the uncertainty remaining in its outcomes. In order to address this limitation, we present a framework for encapsulating existing models applied in data-driven components with an uncertainty wrapper in order to enrich the model outcome with a situation-aware and dependable uncertainty statement. The presented framework is founded on existing work on the concept and mathematical\u00a0\u2026", "num_citations": "6\n", "authors": ["1997"]}
{"title": "Increasing trust in data-driven model validation\n", "abstract": " In recent years, interest in autonomous systems has increased. To observe their environment and interact with it, such systems need to process sensor data including camera images. State-of-the-art methods for object recognition and image segmentation rely on complex data-driven models such as convolutional neural networks. Although no final answer exists yet on how to perform safety evaluation of systems containing such models, such evaluation should comprise at least validation with realistic input data, including settings with suboptimal data quality. Because many test datasets still lack a sufficient number of representative quality deficits, we consider augmenting existing data with quality deficits as necessary. For this purpose, a novel tool framework is presented and illustrated using traffic sign recognition as a use case. The extendable approach distinguishes between augmentation at the object\u00a0\u2026", "num_citations": "6\n", "authors": ["1997"]}
{"title": "Beyond herding cats: aligning quantitative technology evaluation in large-scale research projects\n", "abstract": " A large-scale research project involving many research and industry organizations working on a common goal should be an ideal basis for profound technology evaluations. The possibility for industrial case studies in multiple settings ought to enable reliable quantitative assessment of the performance of new technologies in various real-world settings. However, due to diverse challenges, such as internal agendas, implicit constraints, and unaligned objectives, leveraging this potential goes beyond the usual challenge of cat-herding in such projects. Based on our experience from coordinating technology evaluations in several research projects, this paper sketches the typical issues and outlines an approach for dealing with them. Although new in its composition, this approach brings together principles and techniques perceived to have been useful in earlier projects (e.g., cross-organizational alignment\u00a0\u2026", "num_citations": "5\n", "authors": ["1997"]}
{"title": "A framework for the balanced optimization of quality assurance strategies focusing on small and medium sized enterprises\n", "abstract": " The Quality Improvement Paradigm (QIP) offers a general framework for systematically improving an organization's development processes in a continuous manner. In the context of the LifeCycleQM project, the general QIP framework was concretized for a specific application area, namely, the balanced improvement of quality assurance (QA) strategies, i.e., a set of systematically applied QA activities. Especially with respect to small and medium-sized enterprises, the encompassing QIP framework presents limited guidance for easy and concrete application. Therefore, individual activities within the QIP framework were refined focusing on QA strategies, and proven measurement procedures such as the defect flow model and knowledge from the area of process improvement (e.g., with regard to individual QA procedures) was integrated for reuse in a practice-oriented manner. The feasibility of the developed\u00a0\u2026", "num_citations": "5\n", "authors": ["1997"]}
{"title": "Towards identifying and managing sources of uncertainty in AI and machine learning models-an overview\n", "abstract": " Quantifying and managing uncertainties that occur when data-driven models such as those provided by AI and machine learning methods are applied is crucial. This whitepaper provides a brief motivation and first overview of the state of the art in identifying and quantifying sources of uncertainty for data-driven components as well as means for analyzing their impact.", "num_citations": "4\n", "authors": ["1997"]}
{"title": "Goal-oriented adaptation of software quality models\n", "abstract": " Objectively measuring and evaluating software quality has become a fundamental task. Many models support software product quality stakeholders in dealing with software quality. In this contribution, we present an approach for adapting software quality models and the challenges that emerge in this regard. We propose an adaptation process based on the use of a core quality model and on the existence of a meta-model that provides an essential structure for the base and for the derived adapted models. We show different solution ideas for obtaining a correct adapted quality model and performing goaloriented, efficient adaptation.", "num_citations": "4\n", "authors": ["1997"]}
{"title": "WHAT MAKES BIG DATA DIFFERENT FROM A DATA QUALITY ASSESSMENT PERSPECTIVE?\n", "abstract": " WHAT MAKES BIG DATA DIFFERENT FROM A DATA QUALITY ASSESSMENT PERSPECTIVE? Page 1 \u00a9 Fraunhofer IESE Practical Challenges for Data and Information Quality Research Michael Kl\u00e4s, Adam Trendowicz, Andreas Jedlitschka WHAT MAKES BIG DATA DIFFERENT FROM A DATA QUALITY ASSESSMENT PERSPECTIVE? ODQ2015 30 March 2015, Garching, Germany Parts of this work are funded by \u00a9 Fraunhofer IESE 2 Open / Big Data Quality \u2013 The Motivation \u220e Data quality (DQ) \u220e Research topic for several decades \u220e Business intelligence raised awareness \u220e Big data (BD) \u220e Existing DQ means not directly transferable \u220e Still largely unclear how to assess DQ of BD \u220e Open data (OD) \u220e shows similar properties as other BD Page 2 \u00a9 Fraunhofer IESE 3 What makes BIG Data Different? \u2013 The 3 Vs [Laney2001] Volume Velocity Variety Laney, D., 3D Data Management: Controlling Data Volume, \u2026", "num_citations": "4\n", "authors": ["1997"]}
{"title": "Supporting the adaptation of software quality models\u2013An empirical investigation\n", "abstract": " Measuring and evaluating software quality are fundamental challenges for software engineers. Assessing software quality is hard to accomplish in practice not only because existing quality models are not easily applicable, but also because adjusting them to the needs of one\u2019s own organization and projects requires intensive effort. In this paper, we present a study on applying a flexible but rigorous adaptation process for quality models. The goal-oriented adaptation process is based on the existence of a quality meta-model that provides a structure for adapted models. In order to obtain first empirical insights, we compare adaptations guided by the tool-supported adaptation process with (ad-hoc) adaptations using a tool that can be used to create and edit quality models. In the study, we investigated the formal consistency, appropriateness, and efficiency of exemplary quality model adaptations. One important study result is that the quality models obtained applying the tool-supported process are considerably more consistently and appropriately adapted than the ones obtained by following an ad-hoc approach. Further, we could observe that model adaptation is significantly more efficient when applying the adaptation process.", "num_citations": "3\n", "authors": ["1997"]}
{"title": "Using complementary risk acceptance criteria to structure assurance cases for safety-critical AI components\n", "abstract": " Artificial Intelligence (AI), particularly current Machine Learning approaches, promises new and innovative solutions also for realizing safety-critical functions. Assurance cases can support the potential certification of such AI applications by providing an assessable, structured argument explaining why safety is achieved. Existing proposals and patterns for structuring the safety argument help to structure safety measures, but guidance for explaining in a concrete use case why the safety measures are actually sufficient is limited. In this paper, we investigate this and other challenges and propose solutions. In particular, we propose considering two complementary types of risk acceptance criteria as assurance objectives and provide, for each objective, a structure for the supporting argument. We illustrate our proposal on an excerpt of an automated guided vehicle use case and close with questions triggering further discussions on how to best use assurance cases in the context of AI certification.", "num_citations": "2\n", "authors": ["1997"]}
{"title": "Handling Uncertainties of Data-Driven Models in Compliance with Safety Constraints for Autonomous Behaviour\n", "abstract": " Assuring safety is a key challenge for market introduction of many kinds of autonomous systems. This is especially true in cases where data-driven models (DDMs) such as deep neural networks are used to perceive or anticipate hazardous situations. Treating failures of such models in the same way as failures in traditional software appears insufficient, due to the less predictable nature of DDM failures. Although existing safety standards do not yet sufficiently address this finding, research widely acknowledges that residual uncertainty remaining in the outcome of DDMs is a fact that needs to be dealt with. In this context, Uncertainty Wrappers constitute a model-agnostic framework to obtain dependable and situationaware uncertainty estimates. In contrast to many approaches, they are special in providing explainable and statisticallysafeguarded uncertainty estimates. Although these properties appear beneficial, the question of integrating them into an effective risk management approach remains open. This paper intends to further stimulate and contribute to this discussion by exemplifying how dependable uncertainty estimates may become part of a dynamic risk management approach at runtime. We explore how this can be achieved in the context of the Responsibility-Sensitive Safety model.", "num_citations": "2\n", "authors": ["1997"]}
{"title": "Handling Uncertainty in Collaborative Embedded Systems Engineering\n", "abstract": " As collaborative embedded systems operate autonomously in highly dynamic contexts, they must be able to handle uncertainties that can occur during operation. On the one hand, they must be able to handle uncertainties due to the imprecision of sensors and the behavior of data-driven components for perceiving and interpreting the context to enable decisions to be made during operation. On the other hand, uncertainties can emerge from the collaboration in a collaborative group, related to the exchange of information (e.g., context knowledge) between collaborative systems. This chapter presents methods for modeling uncertainty early in development and analyzing uncertainty during both design and operation. These methods allow for the identification of epistemic uncertainties that can occur when various, potentially heterogeneous systems are required to collaborate. The methods also enable graphical\u00a0\u2026", "num_citations": "2\n", "authors": ["1997"]}
{"title": "Prozessverbesserung \u00fcber Fehlerstrommessung bei einem mittelst\u00e4ndischen Unternehmen\n", "abstract": " Eine konstant hohe Produktqualit\u00e4t ist insbesondere f\u00fcr kleine und mittelst\u00e4ndische Unternehmen (KMUs) wichtig, um Kundenzufriedenheit gew\u00e4hrleisten zu k\u00f6nnen. Dabei ist ein guter Entwicklungs-und Qualit\u00e4tssicherungsprozess ma\u00dfgeblich f\u00fcr die Erreichung einer hohen Softwarequalit\u00e4t verantwortlich. Die systematische Fehlermessung nimmt dabei eine Schl\u00fcsselrolle ein, da nur so empirisch zu ermitteln ist, wie effektiv bestehende Qualit\u00e4tssicherungs-Prozesse sind, welche Fehlerarten durch welche Prozesse gefunden werden und welches Verbesserungspotential gegeben ist.In diesem Beitrag werden das Vorgehen und die Erfahrungen bei der Definition und Einf\u00fchrung eines Messprogramms zur Erfassung eines Fehlerstrommodells (FSM) bei einem mittelst\u00e4ndischen Unternehmen beschrieben. Das Messprogramm ist eingef\u00fchrt und wird aktiv betrieben. Dies ist unseres Wissens die erste Dokumentation der Einf\u00fchrung eines FSM bei einer KMU. Durch die gewonnenen Erfahrungen konnte der Definitions-und Einf\u00fchrungsprozess f\u00fcr KMUs verfeinert werden.", "num_citations": "2\n", "authors": ["1997"]}
{"title": "A Framework for the Balanced Optimization of Quality Assurance Strategies Focusing on Small and Medium Sized Enterprises\n", "abstract": " The Quality Improvement Paradigm (QIP) offers a general framework for systematically improving an organization's development processes in a continuous manner. In the context of the LifeCycleQM project, the general QIP framework was concretized for a specific application area, namely, the balanced improvement of quality assurance (QA) strategies, i.e., a set of systematically applied QA activities. Especially with respect to small and medium-sized enterprises, the encompassing QIP framework presents limited guidance for easy and concrete application. Therefore, individual activities within the QIP framework were refined focusing on QA strategies, and proven measurement procedures such as the defect flow model and knowledge from the area of process improvement (e.g., with regard to individual QA procedures) was integrated for reuse in a practice-oriented manner. The feasibility of the developed approach was initially explored by its application at IBS AG, a medium-sized enterprise, where improvement goals were defined, a corresponding measurement program was established, improvement potential was identified, and concrete improvement suggestions for the QA strategy were derived, assessed, and implemented.", "num_citations": "2\n", "authors": ["1997"]}
{"title": "Hardening of Artificial Neural Networks for Use in Safety-Critical Applications--A Mapping Study\n", "abstract": " Context: Across different domains, Artificial Neural Networks (ANNs) are used more and more in safety-critical applications in which erroneous outputs of such ANN can have catastrophic consequences. However, the development of such neural networks is still immature and good engineering practices are missing. With that, ANNs are in the same position as software was several decades ago. Today, standards for functional safety, such as ISO 26262 in the automotive domain, require the application of a collection of proven engineering principles and methods in the creation of software to increase its quality and reduce failure rates to an acceptable level. Objective: In the future, such a set of proven engineering methods needs to be established for the development of Artificial Neural Networks to allow their use in safety-critical applications. Method: This work takes a step in this direction by conducting a mapping study to extract challenges faced in the development of ANNs for safety-critical applications and to identify methods that have been used for the hardening of ANNs in such settings. Results: We extracted ten different challenges found to be repeatedly reported in the literature regarding the use of ANNs in critical contexts. All of these challenges are addressed by engineering methods, of which we identified 54 in our study that can be used for the hardening of networks. Conclusions: Various methods have been proposed to overcome the specific challenges of using ANNs in safety-critical applications. On the path towards defining best practices, we envision that future software engineering will need to focus on further investigating these\u00a0\u2026", "num_citations": "1\n", "authors": ["1997"]}
{"title": "Measuring the Impact of Emergence in Business Applications\n", "abstract": " Enterprise software systems must be designed for flexibility to allow adaptation of their inter-organizational relationships and their products to changing requirements or contexts while retaining existing functionality and user acceptance. To support this, we introduce the notion of Emergent Enterprise Software Systems. Emergent Enterprise Software Systems combine existing software paradigms with proactive and self-x behaviors into a stable and reliable software system. This is mainly achieved via new concepts, methods, tools and technologies. One of the main challenges is how to measure the impact of emergent software, i.e., to determine the benefit of these methodological and technological solutions with regard to business goals. This requires a goal-oriented measurement approach encompassing the definition of measurement goals, the definition of metrics, and the interpretation of measured data\u00a0\u2026", "num_citations": "1\n", "authors": ["1997"]}