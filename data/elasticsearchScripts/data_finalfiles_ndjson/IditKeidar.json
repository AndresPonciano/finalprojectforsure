{"title": "Group communication specifications: a comprehensive study\n", "abstract": " View-oriented group communication is an important and widely used building block for many distributed applications. Much current research has been dedicated to specifying the semantics and services of view-oriented group communication systems (GCSs). However, the guarantees of different GCSs are formulated using varying terminologies and modeling techniques, and the specifications vary in their rigor. This makes it difficult to analyze and compare the different systems. This survey provides a comprehensive set of clear and rigorous specifications, which may be combined to represent the guarantees of most existing GCSs. In the light of these specifications, over 30 published GCS specifications are surveyed. Thus, the specifications serve as a unifying framework for the classification, analysis, and comparison of group communication systems. The survey also discusses over a dozen different applications of\u00a0\u2026", "num_citations": "1082\n", "authors": ["514"]}
{"title": "Trusting the cloud\n", "abstract": " More and more users store data in \"clouds\" that are accessed remotely over the Internet. We survey well-known cryptographic tools for providing integrity and consistency for data stored in clouds and discuss recent research in cryptography and distributed computing addressing these problems.", "num_citations": "371\n", "authors": ["514"]}
{"title": "Byzantine disk paxos: optimal resilience with byzantine shared memory\n", "abstract": " We present Byzantine Disk Paxos, an asynchronous shared-memory consensus algorithm that uses a collection of n < 3t disks, t of which may fail by becoming non-responsive or arbitrarily corrupted. We give two constructions of this algorithm; that is, we construct two different t-tolerant (i.e., tolerating up to t disk failures) building blocks, each of which can be used, along with a leader oracle, to solve consensus. One building block is a t-tolerant wait-free shared safe register. The second building block is a t-tolerant regular register that satisfies a weaker termination (liveness) condition than wait freedom: its write operations are wait-free, whereas its read operations are guaranteed to return only in executions with a finite number of writes. We call this termination condition finite writes (FW), and show that wait-free consensus is solvable with FW-terminating registers and a leader oracle. We construct each of\u00a0\u2026", "num_citations": "176\n", "authors": ["514"]}
{"title": "NoC-based FPGA: architecture and routing\n", "abstract": " We present a novel network-on-chip-based architecture for future programmable chips (FPGAs). A key challenge for FPGA design is supporting numerous highly variable design instances with good performance and low cost. Our architecture minimizes the cost of supporting a wide range of design instances with given throughput requirements by balancing the amount of efficient hard-coded NoC infrastructure and the allocation of \"soft\" networking resources at configuration time. Although traffic patterns are design-specific, the physical link infrastructure is a performance bottleneck, and hence should be hard-coded. It is therefore important to employ routing schemes that allow for high flexibility to efficiently accommodate different traffic patterns during configuration. We examine the required capacity allocation for supporting a collection of typical traffic patterns on such chips under a number of routing schemes. We\u00a0\u2026", "num_citations": "172\n", "authors": ["514"]}
{"title": "Do not crawl in the DUST: Different URLs with similar text\n", "abstract": " We consider the problem of DUST: Different URLs with Similar Text. Such duplicate URLs are prevalent in Web sites, as Web server software often uses aliases and redirections, and dynamically generates the same page from various different URL requests. We present a novel algorithm, DustBuster, for uncovering DUST; that is, for discovering rules that transform a given URL to others that are likely to have similar content. DustBuster mines DUST effectively from previous crawl logs or Web server logs, without/examining page contents. Verifying these rules via sampling requires fetching few actual Web pages. Search engines can benefit from information about DUST to increase the effectiveness of crawling, reduce indexing overhead, and improve the quality of popularity statistics such as PageRank.", "num_citations": "166\n", "authors": ["514"]}
{"title": "On the cost of fault-tolerant consensus when there are no faults: preliminary version\n", "abstract": " We consider the consensus problem in an asynchronous model enriched with unreliable failure detectors and in the partial synchrony model. We consider algorithms that solve consensus and tolerate crash failures and/or message omissions. We prove tight lower bounds on the number of communication steps performed by such algorithms in failure-free executions. We present in a unified framework a number of related lower bound results. Thus, we shed light on the relationships among different known lower and upper bounds, and at the same time, illustrate a general technique for obtaining simple and elegant lower bound proofs. We also illustrate matching upper bounds: we algorithms that achieve the lower bound.", "num_citations": "166\n", "authors": ["514"]}
{"title": "GPUfs: Integrating a file system with GPUs\n", "abstract": " PU hardware is becoming increasingly general purpose, quickly outgrowing the traditional but constrained GPU-as-coprocessor programming model. To make GPUs easier to program and easier to integrate with existing systems, we propose making the host's file system directly accessible from GPU code. GPUfs provides a POSIX-like API for GPU programs, exploits GPU parallelism for efficiency, and optimizes GPU file access by extending the buffer cache into GPU memory. Our experiments, based on a set of real benchmarks adopted to use our file system, demonstrate the feasibility and benefits of our approach. For example, we demonstrate a simple self-contained GPU program which searches for a set of strings in the entire tree of Linux kernel source files over seven times faster than an eight-core CPU run.", "num_citations": "163\n", "authors": ["514"]}
{"title": "Many-core vs. many-thread machines: Stay away from the valley\n", "abstract": " We study the tradeoffs between many-core machines like Intelpsilas Larrabee and many-thread machines like Nvidia and AMD GPGPUs. We define a unified model describing a superposition of the two architectures, and use it to identify operation zones for which each machine is more suitable. Moreover, we identify an intermediate zone in which both machines deliver inferior performance. We study the shape of this ldquoperformance valleyrdquo and provide insights on how it can be avoided.", "num_citations": "134\n", "authors": ["514"]}
{"title": "On maintaining multiple versions in STM\n", "abstract": " An effective way to reduce the number of aborts in software transactional memory (STM) is to keep multiple versions of transactional objects. In this paper, we study inherent properties of STMs that use multiple versions to guarantee successful commits of all read-only transactions.", "num_citations": "120\n", "authors": ["514"]}
{"title": "Impossibility results and lower bounds for consensus under link failures\n", "abstract": " We provide a suite of impossibility results and lower bounds for the required number of processes and rounds for synchronous consensus under transient link failures. Our results show that consensus can be solved even in the presence of  moving omission and/or arbitrary link failures per round, provided that both the number of affected outgoing and incoming links of every process is bounded. Providing a step further toward the weakest conditions under which consensus is solvable, our findings are applicable to a variety of dynamic phenomena such as transient communication failures and end-to-end delay variations. We also prove that our model surpasses alternative link failure modeling approaches in terms of assumption coverage.", "num_citations": "102\n", "authors": ["514"]}
{"title": "Araneola: A scalable reliable multicast system for dynamic environments\n", "abstract": " Abstract This paper presents Araneola (Araneola means \u201clittle spider\u201d in Latin.), a scalable reliable application-level multicast system for highly dynamic wide-area environments. Araneola supports multi-point to multi-point reliable communication in a fully distributed manner, while incurring constant load (in terms of message and space complexity) on each node. For a tunable parameter k\u2265 3, Araneola constructs and dynamically maintains a basic overlay structure in which each node\u2019s degree is either k or k+ 1, and roughly 90% of the nodes have degree k. Empirical evaluation shows that Araneola\u2019s basic overlay achieves three important mathematical properties of k-regular random graphs (ie, random graphs in which each node has exactly k neighbors) with N nodes:(i) its diameter grows logarithmically with N;(ii) it is generally k-connected; and (iii) it remains highly connected following random removal of linear\u00a0\u2026", "num_citations": "100\n", "authors": ["514"]}
{"title": "Reliable distributed storage\n", "abstract": " A distributed storage service lets clients abstract a single reliable shared storage device using a collection of possibly unreliable computing units. Algorithms that implement this abstraction offer certain tradeoffs and vary according to dimensions such as complexity, the consistency semantics provided, and the types of failures tolerated.", "num_citations": "92\n", "authors": ["514"]}
{"title": "Utilizing shared data in chip multiprocessors with the Nahalal architecture\n", "abstract": " This paper addresses a new cache organization in a Chip Multiprocessors (CMP) environment. We introduce Nahalal, an architecture whose novel floorplan topology partitions cached data according to its usage (shared versus private data), and thus enables fast access to shared data for all processors while preserving the vicinity of private data to each processor. The Nahalal architecture combines the best of both shared caches and private caches, enabling fast accesses to data as in private caches while eliminating the need for inter-cache coherence transactions. Detailed simulations in Simics demonstrate that Nahalal decreases cache access latency by up to 41.1% compared to traditional CMP designs, yielding performance gains of up to 12.65% in run time.", "num_citations": "86\n", "authors": ["514"]}
{"title": "Scaling concurrent log-structured data stores\n", "abstract": " Log-structured data stores (LSM-DSs) are widely accepted as the state-of-the-art implementation of key-value stores. They replace random disk writes with sequential I/O, by accumulating large batches of updates in an in-memory data structure and merging it with the on-disk store in the background. While LSM-DS implementations proved to be highly successful at masking the I/O bottleneck, scaling them up on multicore CPUs remains a challenge. This is nontrivial due to their often rich APIs, as well as the need to coordinate the RAM access with the background I/O.", "num_citations": "82\n", "authors": ["514"]}
{"title": "Distributed compressed sensing for static and time-varying networks\n", "abstract": " We consider the problem of in-network compressed sensing from distributed measurements. Every agent has a set of measurements of a signal x, and the objective is for the agents to recover x from their collective measurements using only communication with neighbors in the network. Our distributed approach to this problem is based on the centralized Iterative Hard Thresholding algorithm (IHT). We first present a distributed IHT algorithm for static networks that leverages standard tools from distributed computing to execute in-network computations with minimized bandwidth consumption. Next, we address distributed signal recovery in networks with time-varying topologies. The network dynamics necessarily introduce inaccuracies to our in-network computations. To accommodate these inaccuracies, we show how centralized IHT can be extended to include inexact computations while still providing the same\u00a0\u2026", "num_citations": "80\n", "authors": ["514"]}
{"title": "A simple proof of the uniform consensus synchronous lower bound\n", "abstract": " We give a simple and intuitive proof of an f+2 round lower bound for uniform consensus. That is, we show that for every uniform consensus algorithm tolerating t failures, and for every f\u2a7dt\u22122, there is an execution with f failures that requires f+2 rounds.", "num_citations": "75\n", "authors": ["514"]}
{"title": "A highly available paradigm for consistent object replication\n", "abstract": " This work provides an e cient paradigm for object replication using the State Machine approach, overcoming network partitions and reconnects. The Consistent Object Replication Layer (COReL) supplies the application builder with long-term services such as reconciliation of states among recovered and reconnected processors and global message ordering. COReL is a high-level communication service layer, designed in the Transis environment. It supplies the services de ned for the Replication Service layer in HORUS and Transis. We present an algorithm for totally ordering messages in the face of network partitions and site failures. The novelty of this algorithm is that it always allows a majority (or quorum) of connected processors in the network to make progress (ie totally order messages), if they remain connected for su ciently long, regardless of past failures. Furthermore, our algorithm always allows processors to initiate messages, even when they are not members of a connected majority component in the network. Thus, messages can eventually become totally ordered even if their initiator is never a member of a majority component. The algorithm orders each message within two communication rounds, if no failures occur during these rounds.We describe how COReL may be used in the design of distributed and replicated database systems. We present an atomic commitment protocol (ACP) based on COReL. The novelty of this ACP is that it always allows a majority (or quorum) of processors that become connected to resolve the transaction, if they remain connected for su ciently long. We know of no other ACP with this feature. We\u00a0\u2026", "num_citations": "75\n", "authors": ["514"]}
{"title": "Octopus: A fault-tolerant and efficient ad-hoc routing protocol\n", "abstract": " Mobile ad-hoc networks (MANETs) are failure-prone environments; it is common for mobile wireless nodes to intermittently disconnect from the network, e.g., due to signal blockage. This paper focuses on withstanding such failures in large MANETs: we present Octopus, a fault-tolerant and efficient position-based routing protocol. Fault-tolerance is achieved by employing redundancy, i.e., storing the location of each node at many other nodes, and by keeping frequently refreshed soft state. At the same time, Octopus achieves a low location update overhead by employing a novel aggregation technique, whereby a single packet updates the location of many nodes at many other nodes. Octopus is highly scalable: for a fixed node density, the number of location update packets sent does not grow with the network size. And when the density increases, the overhead drops. Thorough empirical evaluation using\u00a0\u2026", "num_citations": "74\n", "authors": ["514"]}
{"title": "SMV: Selective multi-versioning STM\n", "abstract": " We present Selective Multi-Versioning (SMV), a new STM that reduces the number of aborts, especially those of long read-only transactions. SMV keeps old object versions as long as they might be useful for some transaction to read. It is able to do so while still allowing reading transactions to be invisible by relying on automatic garbage collection to dispose of obsolete versions.               SMV is most suitable for read-dominated workloads, for which it performs better than previous solutions. It has an up to \u00d77 throughput improvement over a single-version STM and more than a two-fold improvement over an STM keeping a constant number of versions per object. We show that the memory consumption of algorithms keeping a constant number of versions per object might grow exponentially with the number of objects, while SMV operates successfully even in systems with stringent memory constraints.", "num_citations": "69\n", "authors": ["514"]}
{"title": "Exposing and eliminating vulnerabilities to denial of service attacks in secure gossip-based multicast\n", "abstract": " We propose a framework and methodology for quantifying the effect of denial of service (DoS) attacks on a distributed system. We present a systematic study of the resistance of gossip-based multicast protocols to DoS attacks. We show that even distributed and randomized gossip-based protocols, which eliminate single points of failure, do not necessarily eliminate vulnerabilities to DoS attacks. We propose Drum - a simple gossip-based multicast protocol that eliminates such vulnerabilities. Drum was implemented in Java and tested on a large cluster. We show, using closed-form mathematical analysis, simulations, and empirical tests, that Drum survives severe DoS attacks.", "num_citations": "65\n", "authors": ["514"]}
{"title": "Evaluating the running time of a communication round over the Internet\n", "abstract": " We study the running time of distributed algorithms deployed in a widely distributed setting over the Internet using TCP. We consider a simple primitive that corresponds to a communication round in which every host sends information to every other host; this primitive occurs in numerous distributed algorithms. We experiment with four algorithms that typically implement this primitive. We run our experiments on ten hosts at geographically disperse locations over the Internet. We observe that message loss has a large impact on algorithm running times, which causes leader-based algorithms to usually outperform decentralized ones.", "num_citations": "60\n", "authors": ["514"]}
{"title": "Equicast: Scalable multicast with selfish users\n", "abstract": " Peer-to-peer (P2P) networks suffer from the problem of \u201cfreeloaders\u201d, i.e., users who consume resources without contributing anything in return. In this paper, we tackle this problem taking a game theoretic perspective by modeling the system as a non-cooperative game. We introduce EquiCast, a wide-area P2P multicast protocol for large groups of selfish nodes. EquiCast is the first P2P multicast protocol that is formally proven to enforce cooperation in selfish environments. Additionally, we prove that EquiCast incurs a low constant load on each user.", "num_citations": "59\n", "authors": ["514"]}
{"title": "Transactional data structure libraries\n", "abstract": " We introduce transactions into libraries of concurrent data structures; such transactions can be used to ensure atomicity of sequences of data structure operations. By focusing on transactional access to a well-defined set of data structure operations, we strike a balance between the ease-of-programming of transactions and the efficiency of custom-tailored data structures. We exemplify this concept by designing and implementing a library supporting transactions on any number of maps, sets (implemented as skiplists), and queues. Our library offers efficient and scalable transactions, which are an order of magnitude faster than state-of-the-art transactional memory toolkits. Moreover, our approach treats stand-alone data structure operations (like put and enqueue) as first class citizens, and allows them to execute with virtually no overhead, at the speed of the original data structure library.", "num_citations": "53\n", "authors": ["514"]}
{"title": "On avoiding spare aborts in transactional memory\n", "abstract": " This paper takes a step toward developing a theory for understanding aborts in transactional memory systems (TMs). Existing TMs may abort many transactions that could, in fact, commit without violating correctness. We call such unnecessary aborts spare aborts. We classify what kinds of spare aborts can be eliminated, and which cannot. We further study what kinds of spare aborts can be avoided efficiently. Specifically, we show that some unnecessary aborts cannot be avoided, and that there is an inherent tradeoff between the overhead of a TM and the extent to which it reduces the number of spare aborts. We also present an efficient example TM algorithm that avoids certain kinds of spare aborts, and analyze its properties and performance.", "num_citations": "53\n", "authors": ["514"]}
{"title": "A virtually synchronous group multicast algorithm for WANs: Formal approach\n", "abstract": " This paper presents a formal design for a novel group communication service targeted for wide-area networks (WANs). The service provides virtual synchrony semantics. Such semantics facilitate the design of fault tolerant distributed applications. The presented design is more suitable for WANs than previously suggested ones. In particular, it features the first algorithm to achieve virtual synchrony semantics in a single communication round. The design also employs a scalable WAN-oriented architecture: it effectively decouples the main two components of virtually synchronous group communication---group membership and reliable group multicast. The design is carried out formally and rigorously. This paper includes formal specifications of both safety and liveness properties. The algorithm is formally modeled and assertionally verified.", "num_citations": "50\n", "authors": ["514"]}
{"title": "Correctness of gossip-based membership under message loss\n", "abstract": " Due to their simplicity and effectiveness, gossip-based membership protocols have become the method of choice for maintaining partial membership in large peer-to-peer systems. A variety of gossip-based membership protocols were proposed. Some were shown to be effective empirically, lacking analytic understanding of their properties. Others were analyzed under simplifying assumptions, such as lossless and delayless network. It is not clear whether the analysis results hold in dynamic networks, where both nodes and network links can fail. In this paper we try to bridge this gap. We first enumerate the desirable properties of a gossip-based membership protocol, such as view uniformity, independence, and load balance. We then propose a simple send & forget protocol, and show that even in the presence of message loss, it achieves the desirable properties.", "num_citations": "49\n", "authors": ["514"]}
{"title": "Optimistic virtual synchrony\n", "abstract": " We present Optimistic Virtual Synchrony (OVS), a new form of group communication which provides the same capabilities as Virtual Synchrony with better performance. It does so by allowing applications to send messages during periods in which services implementing Virtual Synchrony block. OVS also allows applications to determine the policy as to when messages sent optimistically should be delivered and when they should be discarded. Thus, OVS gives applications fine grain control over the specific semantics they require, and does not impose costs for enforcing any semantics that they do not require. At the same time, OVS provides a single easy-to-use interface for all applications.", "num_citations": "48\n", "authors": ["514"]}
{"title": "Early-delivery dynamic atomic broadcast\n", "abstract": " We consider a problem of atomic broadcast in a dynamic setting where processes may join, leave voluntarily, or fail (by stopping) during the course of computation. We provide a formal definition of the Dynamic Atomic Broadcast problem and present and analyze a new algorithm for its solution in a variant of a synchronous model, where processes have approximately synchronized clocks.             Our algorithm exhibits constant message delivery latency in the absence of failures, even during periods when participants join or leave. To the best of our knowledge, this is the first algorithm for totally ordered multicast in a dynamic setting to achieve constant latency bounds in the presence of joins and leaves. When failures occur, the latency bound is linear in the number of actual failures. Our algorithm uses a solution to a variation on the standard distributed consensus problem, in which participants do not know a\u00a0\u2026", "num_citations": "44\n", "authors": ["514"]}
{"title": "Zooming in on network-on-chip architectures\n", "abstract": " The aim of this paper is to expose the networking community to the concept of network-on-chip (NoC), an emerging field of study within the VLSI realm, in which networking principles play a significant role, and new network architectures are in demand. Networking researchers will find new challenges in exploring solutions to familiar problems such as network design, routing, and quality-of-service, in unfamiliar settings under new constraints. We present a new classification of chip architectures into three categories with different requirements from their NoCs. In order to stimulate some specific research directions, we highlight research problems arising in each of these categories, focusing on routing and resource allocation (eg, capacity assignment). We provide initial solution directions to example problems.", "num_citations": "42\n", "authors": ["514"]}
{"title": "Veracity radius: capturing the locality of distributed computations\n", "abstract": " This paper focuses on local computations of distributed aggregation problems on fixed graphs. We define a new metric on problem instances, Veracity Radius (VR), which captures the inherent possibility to compute them locally. We prove that VR yields a tight lower bound on output-stabilization time, ie, the time until all nodes fix their outputs, as well as a lower bound on quiescence time. We present an efficient aggregation algorithm, I-LEAG, which reaches both output stabilization and quiescence within a time that is proportional to the VR of the problem instance, and is also efficient in terms of per-node communication and memory. We empirically show that the VR metric also effectively captures the performance of previously suggested efficient aggregation protocols, and that I-LEAG significantly outperforms these protocols in several respects.", "num_citations": "40\n", "authors": ["514"]}
{"title": "KiWi: A Key-value Map for Scalable Real-time Analytics\n", "abstract": " Modern big data processing platforms employ huge in-memory key-value (KV) maps. Their applications simultaneously drive high-rate data ingestion and large-scale analytics. These two scenarios expect KV-map implementations that scale well with both real-time updates and large atomic scans triggered by range queries.", "num_citations": "39\n", "authors": ["514"]}
{"title": "LiMoSense: live monitoring in dynamic sensor networks\n", "abstract": " We present LiMoSense, a fault-tolerant live monitoring algorithm for dynamic sensor networks. This is the first asynchronous robust average aggregation algorithm that performs live monitoring, i.e., it constantly obtains a timely and accurate picture of dynamically changing data. LiMoSense uses gossip to dynamically track and aggregate a large collection of ever-changing sensor reads. It overcomes message loss, node failures and recoveries, and dynamic network topology changes. The algorithm uses a novel technique to bound variable size. We present the algorithm and formally prove its correctness. We use simulations to illustrate its ability to quickly react to changes of both the network topology and the sensor reads, and to provide accurate information.", "num_citations": "38\n", "authors": ["514"]}
{"title": "An inheritance-based technique for building simulation proofs incrementally\n", "abstract": " This paper presents a formal technique for incremental construction of system specifications, algorithm descriptions, and simulation proofs showing that algorithms meet their specifications.The technique for building specifications and algorithms incrementally allows a child specification or algorithm to inherit from its parent by two forms of incremental modification: (a) signature extension, where new actions are added to the parent, and (b) specialization (subtyping), where the child's behavior is a specialization (restriction) of the parent's behavior. The combination of signature extension and specialization provides a powerful and expressive incremental modification mechanism for introducing new types of behavior without overriding behavior of the parent; this mechanism corresponds to the subclassing for extension form of inheritance.In the case when incremental modifications are applied to both a parent\u00a0\u2026", "num_citations": "38\n", "authors": ["514"]}
{"title": "Accordion: Better memory organization for LSM key-value stores\n", "abstract": " Log-structured merge (LSM) stores have emerged as the technology of choice for building scalable write-intensive key-value storage systems. An LSM store replaces random I/O with sequential I/O by accumulating large batches of writes in a memory store prior to flushing them to log-structured disk storage; the latter is continuously re-organized in the background through a compaction process for efficiency of reads. Though inherent to the LSM design, frequent compactions are a major pain point because they slow down data store operations, primarily writes, and also increase disk wear. Another performance bottleneck in today's state-of-the-art LSM stores, in particular ones that use managed languages like Java, is the fragmented memory layout of their dynamic memory store. In this paper we show that these pain points may be mitigated via better organization of the memory store. We present Accordion - an\u00a0\u2026", "num_citations": "36\n", "authors": ["514"]}
{"title": "Distributed data clustering in sensor networks\n", "abstract": " Low overhead analysis of large distributed data sets is necessary for current data centers and for future sensor networks. In such systems, each node holds some data value, e.g., a local sensor read, and a concise picture of the global system state needs to be obtained. In resource-constrained environments like sensor networks, this needs to be done without collecting all the data at any location, i.e., in a distributed manner. To this end, we address the distributed clustering problem, in which numerous interconnected nodes compute a clustering of their data, i.e., partition these values into multiple clusters, and describe each cluster concisely. We present a generic algorithm that solves the distributed clustering problem and may be implemented in various topologies, using different clustering types. For example, the generic algorithm can be instantiated to cluster values according to distance, targeting the\u00a0\u2026", "num_citations": "35\n", "authors": ["514"]}
{"title": "Modular composition of coordination services\n", "abstract": " Coordination services like ZooKeeper, etcd, Doozer, and Consul are increasingly used by distributed applications for consistent, reliable, and high-speed coordination. When applications execute in multiple geographic regions, coordination service deployments trade-off between performance,(achieved by using independent services in separate regions), and consistency.", "num_citations": "33\n", "authors": ["514"]}
{"title": "Distributed sparse signal recovery for sensor networks\n", "abstract": " We propose a distributed algorithm for sparse signal recovery in sensor networks based on Iterative Hard Thresholding (IHT). Every agent has a set of measurements of a signal x, and the objective is for the agents to recover x from their collective measurements at a minimal communication cost and with low computational complexity. A na\u00efve distributed implementation of IHT would require global communication of every agent's full state in each iteration. We find that we can dramatically reduce this communication cost by leveraging solutions to the distributed top-K problem in the database literature. Evaluations show that our algorithm requires up to three orders of magnitude less total bandwidth than the best-known distributed basis pursuit method.", "num_citations": "32\n", "authors": ["514"]}
{"title": "On formal modeling of agent computations\n", "abstract": " This paper describes a comparative study of three formal methods for modeling and validating agent systems. The study is part of a joint project by researchers in MIT\u2019s Theory of Distributed Systems research group and NTT\u2019s Cooperative Computing research group. Our goal is to establish a mathematical and linguistic foundation for describing and reasoning about agent-style systems.", "num_citations": "32\n", "authors": ["514"]}
{"title": "An architecture for adaptive intrusion\u2010tolerant applications\n", "abstract": " Applications that are part of a mission\u2010critical information system need to maintain a usable level of key services through ongoing cyber\u2010attacks. In addition to the well\u2010publicized denial of service (DoS) attacks, these networked and distributed applications are increasingly threatened by sophisticated attacks that attempt to corrupt system components and violate service integrity. While various approaches have been explored to deal with DoS attacks, corruption\u2010inducing attacks remain largely unaddressed. We have developed a collection of mechanisms based on redundancy, Byzantine fault tolerance, and adaptive middleware that help distributed, object\u2010based applications tolerate corruption\u2010inducing attacks. In this paper, we present the ITUA architecture, which integrates these mechanisms in a framework for auto\u2010adaptive intrusion\u2010tolerant systems, and we describe our experience in using the technology to\u00a0\u2026", "num_citations": "30\n", "authors": ["514"]}
{"title": "Threads vs. caches: Modeling the behavior of parallel workloads\n", "abstract": " A new generation of high-performance engines now combine graphics-oriented parallel processors with a cache architecture. In order to meet this new trend, new highly-parallel workloads are being developed. However, it is often difficult to predict how a given application would perform on a given architecture. This paper provides a new model capturing the behavior of such parallel workloads on different multi-core architectures. Specifically, we provide a simple analytical model, which, for a given application, describes its performance and power as a function of the number of threads it runs in parallel, on a range of architectures. We use our model (backed by simulations) to study both synthetic workloads and real ones from the PARSEC suite. Our findings recognize distinctly different behavior patterns for different application families and architectures.", "num_citations": "25\n", "authors": ["514"]}
{"title": "Fairledger: A fair blockchain protocol for financial institutions\n", "abstract": " Financial institutions are currently looking into technologies for permissioned blockchains. A major effort in this direction is Hyperledger, an open source project hosted by the Linux Foundation and backed by a consortium of over a hundred companies. A key component in permissioned blockchain protocols is a byzantine fault tolerant (BFT) consensus engine that orders transactions. However, currently available BFT solutions in Hyperledger (as well as in the literature at large) are inadequate for financial settings; they are not designed to ensure fairness or to tolerate selfish behavior that arises when financial institutions strive to maximize their own profit. We present FairLedger, a permissioned blockchain BFT protocol, which is fair, designed to deal with rational behavior, and, no less important, easy to understand and implement. The secret sauce of our protocol is a new communication abstraction, called detectable all-to-all (DA2A), which allows us to detect participants (byzantine or rational) that deviate from the protocol, and punish them. We implement FairLedger in the Hyperledger open source project, using Iroha framework, one of the biggest projects therein. To evaluate FairLegder's performance, we also implement it in the PBFT framework and compare the two protocols. Our results show that in failure-free scenarios FairLedger achieves better throughput than both Iroha's implementation and PBFT in wide-area settings.", "num_citations": "24\n", "authors": ["514"]}
{"title": "Wait-free regular storage from byzantine components\n", "abstract": " We consider the problem of implementing a wait-free regular register from storage components prone to Byzantine faults. We present a simple, efficient, and self-contained construction of such a register. Our construction utilizes a novel building block, called a 1-regular register, which can be efficiently implemented from Byzantine fault-prone components.", "num_citations": "24\n", "authors": ["514"]}
{"title": "The overhead of consensus failure recovery\n", "abstract": " Many reliable distributed systems are consensus-based and typically operate under two modes: a fast normal mode in failure-free synchronous periods, and a slower recovery mode following asynchrony and failures. A lot of work has been devoted to optimize the normal mode, but little has focused on optimizing the recovery mode. This paper seeks to understand whether the recovery mode is inherently slower than the normal mode. In particular, we consider consensus algorithms in the round-based eventually synchronous model of [11], where t out of n processes may fail by crashing, messages may be lost, and the system may be asynchronous for arbitrarily long, but eventually the system becomes synchronous and no new failure occurs (we say that the system becomes stable). For t \u00a0\u00a0\u2265\u00a0\u00a0 n/3, we prove a lower bound of three rounds for achieving a global decision whenever the system becomes stable\u00a0\u2026", "num_citations": "23\n", "authors": ["514"]}
{"title": "On correctness of data structures under reads-write concurrency\n", "abstract": " We study the correctness of shared data structures under reads-write concurrency. A popular approach to ensuring correctness of read-only operations in the presence of concurrent update, is read-set validation, which checks that all read variables have not changed since they were first read. In practice, this approach is often too conservative, which adversely affects performance. In this paper, we introduce a new framework for reasoning about correctness of data structures under reads-write concurrency, which replaces validation of the entire read-set with more general criteria. Namely, instead of verifying that all read shared variables still hold the values read from them, we verify abstract conditions over the shared variables, which we call base conditions. We show that reading values that satisfy some base condition at every point in time implies correctness of read-only operations executing in parallel\u00a0\u2026", "num_citations": "22\n", "authors": ["514"]}
{"title": "Caf\u00e9: Scalable task pools with adjustable fairness and contention\n", "abstract": " Task pools have many important applications in distributed and parallel computing. Pools are typically implemented using concurrent queues, which limits their scalability. We introduce CAF\u00c9, Contention and Fairness Explorer, a scalable and wait-free task pool which allows users to control the trade-off between fairness and contention. The main idea behind CAF\u00c9 is to maintain a list of TreeContainers, a novel tree-based data structure providing efficient task inserts and retrievals. TreeContainers don\u2019t guarantee FIFO ordering on task retrievals. But by varying the size of the trees, CAF\u00c9 can provide any type of pool, from ones using large trees with low contention but less fairness, to ones using small trees with higher contention but also greater fairness.               We demonstrate the scalability of TreeContainer by proving an O(log2                 N) bound on the step complexity of insert operations when there are\u00a0\u2026", "num_citations": "22\n", "authors": ["514"]}
{"title": "Space bounds for reliable storage: Fundamental limits of coding\n", "abstract": " We study the inherent space requirements of reliable storage algorithms in asynchronous distributed systems. A number of recent works have used codes in order to achieve a better storage cost than the well-known replication approach. However, a closer look reveals that they incur extra costs in certain scenarios. Specifically, if multiple clients access the storage concurrently, then existing asynchronous code-based algorithms may store a number of copies of the data that grows linearly with the number of concurrent clients. We prove here that this is inherent. Given three parameters,(1) the data size--D bits,(2) the concurrency level--c, and (3) the number of storage node failures that need to be tolerated--f, we show a lower bound of Omega (min (f, c) D) bits on the space complexity of asynchronous distributed storage algorithms. Intuitively, this implies that the asymptotic storage cost is either as high as with\u00a0\u2026", "num_citations": "21\n", "authors": ["514"]}
{"title": "Challenges in evaluating distributed algorithms\n", "abstract": " Theoretical evaluation of performance, availability, and reliability of distributed algorithms is always based on models and metrics that make some simplifying assumptions. Such assumptions are needed in order to have simple abstractions for reasoning about algorithms. However, such assumptions often lead to models, metrics, and analyses that fail to capture important aspects of actual system behavior. Using realistic system models and metrics is important, since distributed algorithms and systems are often designed to optimize over such metrics.", "num_citations": "20\n", "authors": ["514"]}
{"title": "Salsa: scalable and low synchronization numa-aware algorithm for producer-consumer pools\n", "abstract": " We present a highly-scalable non-blocking producer-consumer task pool, designed with a special emphasis on lightweight synchronization and data locality. The core building block of our pool is SALSA, Scalable And Low Synchronization Algorithm for a single-consumer container with task stealing support. Each consumer operates on its own SALSA container, stealing tasks from other containers if necessary. We implement an elegant self-tuning policy for task insertion, which does not push tasks to overloaded SALSA containers, thus decreasing the likelihood of stealing.", "num_citations": "18\n", "authors": ["514"]}
{"title": "Amnesic distributed storage\n", "abstract": " Distributed storage algorithms implement the abstraction of a shared register over distributed base objects. We study a specific class of storage algorithms, which we call amnesic: these have the pragmatic property that old values written in the implemented register might be eventually forgotten, i.e., they are not permanently kept in the storage and might be overwritten in the base objects by more recent values. This paper precisely captures this property and argues that most storage algorithms are amnesic. We establish a fundamental impossibility of an amnesic storage algorithm to implement a robust register abstraction over a set of base objects of which at least one can fail arbitrarily, even if only in a responsive manner, unless readers are allowed to write to the base objects. Our impossibility helps justify the assumptions made by practical robust storage algorithms. We also derive from this impossibility\u00a0\u2026", "num_citations": "18\n", "authors": ["514"]}
{"title": "QoS preserving totally ordered multicast\n", "abstract": " This paper studies the Quality of Service (QoS) guarantees of totally ordered multicast algorithms. The paper shows that totally ordered multicast can coexist with guaranteed predictable delays in certain network models. The paper considers two reservation models: constant bit rate (CBR) and variable bit rate (VBR). For these models, the paper presents totally ordered multicast algorithms that preserve the bandwidth and latency reserved by the application within certain additive constants. Furthermore, the paper presents an algorithm that tolerates message loss (in which case, there can be gaps in the total order) and allows for dynamic joining and leaving of processes while still preserving the QoS guarantees.", "num_citations": "18\n", "authors": ["514"]}
{"title": "EvenDB: optimizing key-value storage for spatial locality\n", "abstract": " Applications of key-value (KV-) storage often exhibit high spatial locality, such as when many data items have identical composite key prefixes. This prevalent access pattern is underused by the ubiquitous LSM design underlying high-throughput KV-stores today.", "num_citations": "17\n", "authors": ["514"]}
{"title": "On liveness of dynamic storage\n", "abstract": " Dynamic distributed storage algorithms such as DynaStore, Reconfigurable Paxos, RAMBO, and RDS, do not ensure liveness (wait-freedom) in asynchronous runs with infinitely many reconfigurations. We prove that this is inherent for asynchronous dynamic storage algorithms. Our result holds even if only one process may fail, provided that machines that were successfully removed from the system\u2019s configuration can be switched off by a system administrator. To circumvent this result, we define a dynamic eventually perfect failure detector, and present an algorithm that uses it to emulate wait-free dynamic atomic storage. Though some of the previous algorithms have been designed for eventually synchronous models, to the best of our knowledge, our algorithm is the first to ensure liveness for all operations without restricting the reconfiguration rate.", "num_citations": "17\n", "authors": ["514"]}
{"title": "Game of coins\n", "abstract": " The cryptocurrency market is blooming. Tens of new coins emerge every year and their total market cap keeps growing. The research community is trying to keep up by proposing improved mining protocols and attacking existing ones. However, surprisingly as it may sound, most existing works overlook the real-life multi-coin market, by focusing on a system with a single coin. To the best of our knowledge, this paper was the first to consider a system with many coins and strategic miners that are free to choose where to mine. We first formalize the current practice of strategic mining in multi-coin markets as a singleton weighted congestion game and prove that any better-response dynamics in such a game converges to an equilibrium. Then, in our main result, we present a reward design attack that moves the system configuration from any initial equilibrium to a desired one. The attack is executed via temporary\u00a0\u2026", "num_citations": "16\n", "authors": ["514"]}
{"title": "The need for realistic failure models in protocol design\n", "abstract": " Fault tolerant algorithms are often designed under the assumption that no more than t out of n processes or components can fail. This approach was pioneered by the SIFT project [22], and has since been widely applied to the design of algorithms for real critical systems, eg, air traffic control [6], other highly available services like file servers [15], and so on. It is such a common assumption that most fault tolerant algorithms found in the literature today adopt it without any justification (eg,[14, 19]).It is a common assumption because the t out of n model gives one a simple abstraction for reasoning about failure-prone environments and system reliability. With this assumption it is fairly easy to design and verify protocols and also to express lower and upper bounds. Unfortunately, when adopting this assumption, we often forget the relationship between the t out of n assumption and system reliability.", "num_citations": "16\n", "authors": ["514"]}
{"title": "A One-Round Algorithm for Virtually Synchronous Group Communication in Wide Area Networks\n", "abstract": " Group communication services, and especially those that implement Virtual Synchrony semantics, are powerful middleware systems that facilitate the development of fault-tolerant distributed applications. In this thesis, we present a high quality, theoretical design of a group communication service that implements Virtual Synchrony semantics and is aimed for deployment in wide-area networks (WANs). The design features a novel algorithm for implementing Virtual Synchrony semantics; the algorithm is more appropriate for WANs than the existing solutions because it involves fewer rounds of communication and operates in a scalable WAN-oriented architecture. The high quality of the design refers to the level of formality and rigor at which it is done: The design includes formal and precise specifications, algorithms, correctness proofs, and performance analyses. We develop the necessary supporting theory and methodology required for producing and evaluating this design. In particular, we develop a formal, inheritance-based, methodology that supports incremental construction of specifications, models, and proofs. This methodology helps us manage the complexity of the design and makes it evident which part of the algorithm implements which property of the system. We also develop new, formal approaches in the area of performance evaluation.", "num_citations": "16\n", "authors": ["514"]}
{"title": "Availability study of dynamic voting algorithms\n", "abstract": " Fault-tolerant distributed systems often select a primary component to allow a subset of the processes to function when failures occur. The dynamic voting paradigm defines rules for selecting the primary component adaptively: when a partition occurs, if a majority of the previous primary component is connected, a new and possibly smaller primary component is chosen. Several studies have shown that dynamic voting leads to more available solutions than other paradigms for maintaining a primary component. However, these studies have assumed that every attempt made by the algorithm to form a new primary component terminates successfully. Unfortunately, in real systems, this is not always the case: a change in connectivity can interrupt the algorithm while it is still attempting to form a new primary component; in such cases, algorithms may block until the processes can resolve the outcome of the interrupted\u00a0\u2026", "num_citations": "16\n", "authors": ["514"]}
{"title": "A constructive approach for proving data structures\u2019 linearizability\n", "abstract": " We present a comprehensive methodology for proving correctness of concurrent data structures. We exemplify our methodology by using it to give a roadmap for proving linearizability of the popular Lazy List implementation of the concurrent set abstraction. Correctness is based on our key theorem, which captures sufficient conditions for linearizability. In contrast to prior work, our conditions are derived directly from the properties of the data structure in sequential runs, without requiring the linearization points to be explicitly identified.", "num_citations": "15\n", "authors": ["514"]}
{"title": "Distributed clustering for robust aggregation in large networks\n", "abstract": " We present a scalable protocol for robust data aggregation in a large, error-prone network. The protocol aggregates the multidimensional distribution of any number of data samples (sensor reads) and removes data errors using constant size synopses, by clustering samples and detecting outliers. Initial simulations show that the protocol achieves robustness to both crashes and data errors.", "num_citations": "15\n", "authors": ["514"]}
{"title": "Scalable load-distance balancing\n", "abstract": " We introduce the problem of load-distance balancing in assigning users of a delay-sensitive networked application to servers. We model the service delay experienced by a user as a sum of a network-incurred delay, which depends on its network distance from the server, and a server-incurred delay, stemming from the load on the server. The problem is to minimize the maximum service delay among all users.               We address the challenge of finding a near-optimal assignment in a scalable distributed manner. The key to achieving scalability is using local solutions, whereby each server only communicates with a few close servers. Note, however, that the attainable locality of a solution depends on the workload \u2013 when some area in the network is congested, obtaining a near-optimal cost may require offloading users to remote servers, whereas when the network load is uniform, a purely local assignment\u00a0\u2026", "num_citations": "15\n", "authors": ["514"]}
{"title": "Expected linear round synchronization: The missing link for linear Byzantine SMR\n", "abstract": " State Machine Replication (SMR) solutions often divide time into rounds, with a designated leader driving decisions in each round. Progress is guaranteed once all correct processes synchronize to the same round, and the leader of that round is correct. Recently suggested Byzantine SMR solutions such as HotStuff, Tendermint, and LibraBFT achieve progress with a linear message complexity and a constant time complexity once such round synchronization occurs. But round synchronization itself incurs an additional cost. By Dolev and Reischuk's lower bound, any deterministic solution must have  communication complexity. Yet the question of randomized round synchronization with an expected linear message complexity remained open. We present an algorithm that, for the first time, achieves round synchronization with expected linear message complexity and expected constant latency. Existing protocols can use our round synchronization algorithm to solve Byzantine SMR with the same asymptotic performance.", "num_citations": "14\n", "authors": ["514"]}
{"title": "Exploiting group communication for highly available video-on-demand services\n", "abstract": " Video on Demand services are popular today in hotels and luxury cruise boats. Increasing improvement in communication technology, will invite widespread utilization of VoD services in private homes, provided by telecommunication companies and via the Internet. In such an environment, scalability and fault tolerance will be key issues. In this paper we describe a highly available distributed Video on Demand (VoD) service, which is inherently scalable and fault tolerant. The VoD service is provided by multiple servers, that may reside in di erent sites. When a server crashes (or disconnects from its clients), it is replaced by another server in a transparent way; the clients are unaware of the change in the service provider.The VoD service exploits the Transis group communication system. Transis assists in achieving fault tolerance, and greatly simpli es the overall service design. Furthermore, the fault tolerance is achieved practically for free: it consumes negligible bandwidth, storage space, and cpu time.", "num_citations": "14\n", "authors": ["514"]}
{"title": "Dynamic reconfiguration: Abstraction and optimal asynchronous solution\n", "abstract": " Providing clean and efficient foundations and tools for reconfiguration is a crucial enabler for distributed system management today. This work takes a step towards developing such foundations. It considers classic fault-tolerant atomic objects emulated on top of a static set of fault-prone servers, and turns them into dynamic ones. The specification of a dynamic object extends the corresponding static (non-dynamic) one with an API for changing the underlying set of fault-prone servers. Thus, in a dynamic model, an object can start in some configuration and continue in a different one. Its liveness is preserved through the reconfigurations it undergoes, tolerating a versatile set of faults as it shifts from one configuration to another. In this paper we present a general abstraction for asynchronous reconfiguration, and exemplify its usefulness for building two dynamic objects: a read/write register and a max-register. We first define a dynamic model with a clean failure condition that allows an administrator to reconfigure the system and switch off a server once the reconfiguration operation removing it completes. We then define the Reconfiguration abstraction and show how it can be used to build dynamic registers and max-registers. Finally, we give an optimal asynchronous algorithm implementing the Reconfiguration abstraction, which in turn leads to the first asynchronous (consensus-free) dynamic register emulation with optimal complexity. More concretely, faced with n requests for configuration changes, the number of configurations that the dynamic register is implemented over is n; and the complexity of each client operation is O (n).", "num_citations": "13\n", "authors": ["514"]}
{"title": "Dynamic Reconfiguration: A Tutorial (Tutorial)\n", "abstract": " A key challenge for distributed systems is the problem of reconfiguration. Clearly, any production storage system that provides data reliability and availability for long periods must be able to reconfigure in order to remove failed or old servers and add healthy or new ones. This is far from trivial since we do not want the reconfiguration management to be centralized or cause a system shutdown. In this tutorial we look into existing reconfigurable storage algorithms. We propose a common model and failure condition capturing their guarantees. We define a reconfiguration problem around which dynamic object solutions may be designed. To demonstrate its strength, we use it to implement dynamic atomic storage. We present a generic framework for solving the reconfiguration problem, show how to recast existing algorithms in terms of this framework, and compare among them.", "num_citations": "13\n", "authors": ["514"]}
{"title": "Efficient dynamic aggregation\n", "abstract": " We consider the problem of dynamic aggregation of inputs over a large fixed graph. A dynamic aggregation algorithm must continuously compute the result of a given aggregation function over a dynamically changing set of inputs. To be efficient, such an algorithm should refrain from sending messages when the inputs do not change, and should perform local communication whenever possible.               We present an instance-based lower bound on the efficiency of such algorithms, and provide two algorithms matching this bound. The first, MultI-LEAG, re-samples the inputs at intervals that are proportional to the graph size, achieving quiescence between samplings, and is extremely message efficient. The second, DynI-LEAG, more closely monitors the aggregate value by sampling it more frequently, at the cost of slightly higher message complexity.", "num_citations": "13\n", "authors": ["514"]}
{"title": "Multi-versioning in transactional memory\n", "abstract": " Reducing the number of aborts is one of the biggest challenges of most transactional systems: existing TMs may abort many transactions that could, in fact, commit without violating correctness. Historically, the commonly used method for reducing the abort rate was maintaining multiple object versions. Multiversion concurrency control is a classical approach for providing concurrent access to the database in database management systems. Its idea is to let a reading transaction obtain a consistent snapshot corresponding to an arbitrary point in time (e.g., defined at the beginning of a transaction) \u2013 concurrent updates are isolated through maintaining old versions rather than via scheduling decisions.               Multi-versioning was adopted by transactional memory algorithms as well. In this chapter we overview the multi-versioning approach by studying the inherent properties of STMs that use multiple versions\u00a0\u2026", "num_citations": "12\n", "authors": ["514"]}
{"title": "Nomadic service assignment\n", "abstract": " We consider the problem of dynamically assigning application sessions of mobile users or user groups to service points. Such assignments must balance the trade-off between two conflicting goals. On the one hand, we would like to connect a user to the closest server in order to reduce network costs and service latencies. On the other hand, we would like to minimize the number of costly session migrations, or handoffs, between service points. We tackle this problem using two approaches. First, we employ algorithmic online optimization to obtain algorithms whose worst-case performance is within a factor of the optimal. Next, we extend them with opportunistic heuristics that achieve near-optimal practical average performance and scalability. We conduct case studies of two settings where such algorithms are required: wireless mesh networks with mobile users and wide-area groupware applications with or without\u00a0\u2026", "num_citations": "12\n", "authors": ["514"]}
{"title": "Not a coincidence: Sub-quadratic asynchronous byzantine agreement whp\n", "abstract": " King and Saia were the first to break the quadratic word complexity bound for Byzantine Agreement in synchronous systems against an adaptive adversary, and Algorand broke this bound with near-optimal resilience (first in the synchronous model and then with eventual-synchrony). Yet the question of asynchronous sub-quadratic Byzantine Agreement remained open. To the best of our knowledge, we are the first to answer this question in the affirmative. A key component of our solution is a shared coin algorithm based on a VRF. A second essential ingredient is VRF-based committee sampling, which we formalize and utilize in the asynchronous model for the first time. Our algorithms work against a delayed-adaptive adversary, which cannot perform after-the-fact removals but has full control of Byzantine processes and full information about communication in earlier rounds. Using committee sampling and our shared coin, we solve Byzantine Agreement with high probability, with a word complexity of  and  expected time, breaking the  bit barrier for asynchronous Byzantine Agreement.", "num_citations": "11\n", "authors": ["514"]}
{"title": "Scalable real-time gateway assignment in mobile mesh networks\n", "abstract": " The perception of future wireless mesh network (WMN) deployment and usage is rapidly evolving. WMNs are now being envisaged to provide citywide\" last-mile\" access for numerous mobile devices running media-rich applications with stringent quality of service (QoS) requirements. Consequently, some current-day conceptions underlying application support in WMNs need to be revisited. In particular, in a large WMN, the dynamic assignment of users to Internet gateways will become a complex traffic engineering problem that will need to consider load peaks, user mobility, and handoff penalties. We propose QMesh, a framework for user-gateway assignment that runs inside the WMN, and is oblivious to underlying routing protocols. It solves the handoff management problem in a scalable distributed manner. We evaluate QMesh through an extensive simulation (mostly of VoIP), in two settings:(1) a real campus\u00a0\u2026", "num_citations": "11\n", "authors": ["514"]}
{"title": "Group communication\n", "abstract": " Traditional communication models and protocols like TCP (see Transmission Control Protocol-Internet Protocol (TCP-IP)) support point to point communication. Such protocols were designed for applications involving communication between no more than two processes at a time, usually a client and a server. Many modern applications do not adhere to this communication model. Consider for example an on-line game being played by several participants around the world; or a multi-media conference in which users see each other, talk to each other and also write on a shared white board. These applications involve more than two users exchanging information. They require multi-point to multi-point communication.Group communication is a means for providing multi-point to multi-point communication, by organizing processes in groups 1, 2, 3]. A process is an instance of an executing program at a certain location. A group (or process group) is a set of processes which are members of the group. So, for example, a group can consist of the users playing an on-line game with each other, in the same virtual universe. Another group can consist of the participants in a multi-media conference. Each group is associated with a logical name (or address). Processes communicate with group members by sending a message targeted to the group name; the group communication service delivers the message to the group members. Sending a message to multiple recipients in this way is called multicast (see Multicast Communication Systems). Groups are usually dynamic, in the sense that the set of group members continuously changes. Processes may\u00a0\u2026", "num_citations": "11\n", "authors": ["514"]}
{"title": "WatchIT: Who Watches Your IT Guy?\n", "abstract": " System administrators have unlimited access to system resources. As the Snowden case highlighted, these permissions can be exploited to steal valuable personal, classified, or commercial data. This problem is exacerbated when a third party administers the system. For example, a bank outsourcing its IT would not want to allow administrators access to the actual data. We propose WatchIT: a strategy that constrains IT personnel's view of the system and monitors their actions. To this end, we introduce the abstraction of perforated containers--while regular Linux containers are too restrictive to be used by system administrators, by\" punching holes\" in them, we strike a balance between information security and required administrative needs. Following the principle of least privilege, our system predicts which system resources should be accessible for handling each IT issue, creates a perforated container with the\u00a0\u2026", "num_citations": "10\n", "authors": ["514"]}
{"title": "Scalable conflict detection in transaction management\n", "abstract": " Multi-thread systems and methods are described for concurrently handling requests to commit data updates to a database by a plurality of data transactions. The database preferably supports multi-versioning and the data transactions are preferably isolated by snapshot isolation. In one embodiment, concurrent and lock-free handling of requests to commit data updates includes performing two types of concurrent data conflict detection. A transaction proceeds to commit only if it passes both types of conflict detection. The first type of conflict detection is based on a hash map between data keys and their commit timestamps whereas the second type of conflict detection is based on a log that keeps track of the status of transactions whose requests to commit are actively being processed. In another embodiment, concurrent conflict detection for data items in concurrent transactions is broken down into buckets and locks\u00a0\u2026", "num_citations": "10\n", "authors": ["514"]}
{"title": "Omid, reloaded: Scalable and highly-available transaction processing\n", "abstract": " We present Omid\u2014a transaction processing service that powers web-scale production systems at Yahoo. Omid provides ACID transaction semantics on top of traditional key-value storage; its implementation over Apache HBase is open sourced as part of Apache Incubator. Omid can serve hundreds of thousands of transactions per second on standard mid-range hardware, while incurring minimal impact on the speed of data access in the underlying key-value store. Additionally, as expected from always-on production services, Omid is highly available.", "num_citations": "10\n", "authors": ["514"]}
{"title": "Decentralized electronic mail\n", "abstract": " E-mail is one of the most popular Internet applications. Unfortunately, the server-centric architecture of today\u2019s commercial solutions inherently limits availability, efficiency, and scalability. The single point of failure as well as the increasing processing and storage stress on the server drives the 35 year old architecture to the limits of its abilities. This paper proposes decentralized electronic mail (DEM), a novel e-mail architecture that overcomes existing systems\u2019 shortcomings. Following the mobile-object paradigm, DEM offers a decentralized approach, which breaks the dependency between a mail user and a single service provider, while relying entirely on participants\u2019 resources.", "num_citations": "10\n", "authors": ["514"]}
{"title": "MaGMA: mobility and group management architecture for real\u2010time collaborative applications\n", "abstract": " We introduce MaGMA, a mobility and group management architecture, enabling real\u2010time collaborative group applications such as push\u2010to\u2010talk (PTT) for mobile users. MaGMA provides, for the first time, a comprehensive and scalable solution for group management, seamless mobility, and quality\u2010of\u2010service (QoS). MaGMA is a distributed IP\u2010based architecture consisting of an overlay server network deployed as part of the service infrastructure. MaGMA's architecture consists of a collection of mobile group managers (MGMs), which manage group membership and may also implement a multicast overlay for data delivery. The architecture is very flexible, and can co\u2010exist with current as well as emerging wireless network technologies. We see such services as essential components in beyond\u20103G (B3G) networks. We propose two group management approaches in the context of MaGMA. We devise protocols for\u00a0\u2026", "num_citations": "10\n", "authors": ["514"]}
{"title": "Designing a caching-based reliable multicast protocol\n", "abstract": " With the increasing use of the Internet, multi-party communication and collaboration applications are becoming mainstream. This trend calls for high-performance multicast services that scale to large groups and higher bandwidth requirements. Although packet loss characteristics have a large impact on the performance of multicast services, few protocols attempt to adapt and actively exploit such characteristics.In this paper, we describe a reliable multicast protocol that exploits packet loss locality through caching. Several studies [1, 3, 5] have observed that packet losses in multicast communication are bursty, ie, links drop numerous multicast packets while temporarily congested. Thus, consecutive losses as witnessed by individual hosts are likely to occur on the same lossy link. By caching pertinent information regarding the error recovery of prior losses and optimistically presuming that future losses occur on the link responsible for prior losses, our protocol streamlines the recovery of future losses. This scheme demonstrates how packet loss locality can be actively used to reduce the recovery latency and the bandwidth overhead of multicast error control. Moreover, in view of increasing our confidence in the correctness and performance of our protocol, we use a rigorous design approach.", "num_citations": "10\n", "authors": ["514"]}
{"title": "Method and system for concurrency control in log-structured merge data stores\n", "abstract": " The present teaching relates to concurrency control in log-structured merge (LSM) data stores. In one example, a call is received from a thread for writing a value to a key of LSM components. A shared mode lock is set on the LSM components in response to the call. The value is written to the key once the shared mode lock is set on the LSM components. The shared mode lock is released from the LSM components after the value is written to the key.", "num_citations": "9\n", "authors": ["514"]}
{"title": "Open Questions on Consensus Performance inWell-Behaved Runs\n", "abstract": " We consider the consensus problem in a message-passing system where processes can crash: Each process has an input, and each correct process must decide on an output, such that all correct processes decide on the same output, and this output is the input of one of the processes. Consensus is an important building block for fault-tolerant systems. It is well-known that consensus is not solvable in an asynchronous model even if only one process can crash [7.13]. However, real systems are not completely asynchronous. Some partially synchronous models [7.12], [7.10] where consensus is solvable better approximate real systems.We consider a partial synchronymodel defined as follows [7.12]1: (1) processes have bounded drift clocks; (2) there are known bounds on processing times and message delays; and (3) less than half of the processes can crash. In addition, this model allows the system to be\u00a0\u2026", "num_citations": "9\n", "authors": ["514"]}
{"title": "NearBucket-LSH: Efficient similarity search in P2P networks\n", "abstract": " We present NearBucket-LSH, an effective algorithm for similarity search in large-scale distributed online social networks organized as peer-to-peer overlays. As communication is a dominant consideration in distributed systems, we focus on minimizing the network cost while guaranteeing good search quality. Our algorithm is based on Locality Sensitive Hashing (LSH), which limits the search to collections of objects, called buckets, that have a high probability to be similar to the query. More specifically, NearBucket-LSH employs an LSH extension that searches in near buckets, and improves search quality but also significantly increases the network cost. We decrease the network cost by considering the internals of both LSH and the P2P overlay, and harnessing their properties to our needs. We show that our NearBucket-LSH increases search quality for a given network cost compared to previous art. In many\u00a0\u2026", "num_citations": "8\n", "authors": ["514"]}
{"title": "A QoS WMN with mobility support\n", "abstract": " We present QMesh, a software package that allows utilizing multiple geographically scattered Windows desktops as a wireless mesh network infrastructure with seamless user mobility support. QMesh supports its users through standard protocols, and does not require any client software installation. We optimize the solution's quality of service (QoS) by providing a centralized management infrastructure, which allows an assignment of users to Internet gateways that balances between distance and load considerations. QMesh is implemented as a Windows XP driver, on top of the Mesh Connectivity Layer (MCL) toolkit from Microsoft Research that provides basic routing capabilities. To the best of our knowledge, this is the first mobile mesh solution implemented within the Win32 kernel space.", "num_citations": "8\n", "authors": ["514"]}
{"title": "Evaluating unstructured peer-to-peer lookup overlays\n", "abstract": " Unstructured peer-to-peer lookup systems incur small constant overhead per single join or leave operation, and can easily support keyword searches. Hence, they are suitable for dynamic failure-prone environments. In this paper, we define metrics for evaluating unstructured overlays for peer-to-peer lookup systems. These metrics capture the search dependability and efficiency, and the granularity at which one can control the tradeoff between the two, as well as fairness. According to these metrics, we evaluate different graphs and overlays, including a Gnutella graph, a power law random graph, normal random graphs, a 3-regular random graph, and a 3-Araneola overlay. Our study shows that, according to our metrics, a 3-Araneola overlay achieves the best results, and hence it is an excellent solution for flooding-based peer-to-peer lookup system.", "num_citations": "8\n", "authors": ["514"]}
{"title": "Integrated bounds for disintegrated storage\n", "abstract": " We point out a somewhat surprising similarity between non-authenticated Byzantine storage, coded storage, and certain emulations of shared registers from smaller ones. A common characteristic in all of these is the inability of reads to safely return a value obtained in a single atomic access to shared storage. We collectively refer to such systems as disintegrated storage, and show integrated space lower bounds for asynchronous regular wait-free emulations in all of them. In a nutshell, if readers are invisible, then the storage cost of such systems is inherently exponential in the size of written values; otherwise, it is at least linear in the number of readers. Our bounds are asymptotically tight to known algorithms, and thus justify their high costs.", "num_citations": "7\n", "authors": ["514"]}
{"title": "Low-overhead error detection for networks-on-chip\n", "abstract": " In the current deep sub-micron age, interconnect reliability is a subject of major concern, and is crucial for a successful product. Coding is a widely-used method to achieve communication reliability, which can be very useful in a network-on-chip (NoC). A key challenge for NoC error detection is to provide a defined detection level, while minimizing the number of redundant parity bits, using small encoder and decoder circuits, and ensuring shortest path routing. We present parity routing (PaR), a novel method to reduce the number of redundant bits transmitted. PaR exploits NoC path diversity to reduce the number of redundant parity bits. Our analysis shows that, for example, on a 4\u00d74 NoC with a demand of one parity bit, PaR reduces the redundant information transmitted by 75%, and the savings increase asymptotically to 100% with the size of the NoC. In addition, we show that PaR can yield power savings due to\u00a0\u2026", "num_citations": "7\n", "authors": ["514"]}
{"title": "Deleting files in the Celeste peer-to-peer storage system\n", "abstract": " Celeste is a robust peer-to-peer object store built on top of a distributed hash table (DHT). Celeste is a working system, developed by Sun Microsystems Laboratories. During the development of Celeste, we faced the challenge of complete object deletion, and moreover, of deleting \u201cfiles\u201d composed of several different objects. This important problem is not solved by merely deleting meta-data, as there are scenarios in which all file contents must be deleted, e.g., due to a court order. Complete file deletion in a realistic peer-to-peer storage system has not been previously dealt with due to the intricacy of the problem \u2014 the system may experience high churn rates, nodes may crash or have intermittent connectivity, and the overlay network may become partitioned at times. We present an algorithm that eventually deletes all file contents, data and meta-data, in the aforementioned complex scenarios. The algorithm is fully\u00a0\u2026", "num_citations": "7\n", "authors": ["514"]}
{"title": "Management of transactions in a distributed transaction system\n", "abstract": " Priority date (The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed.) 2015-04-20", "num_citations": "6\n", "authors": ["514"]}
{"title": "Policy-aware optimization of parallel execution of composite services\n", "abstract": " Parallel execution and cloud technologies are the keys to speed-up service invocation when processing large-scale data. In SOA, service providers normally employ policies to limit parallel execution of the services based on arbitrary decisions. In order to attain optimal performance improvement, service users need to adapt to parallel execution policies of the services. A composite service is a combination of several atomic services provided by various providers. To use parallel execution for greater composite service efficiency we need to optimize the degree of parallelism (DOP) of the composite services by considering policies of all atomic services. We propose a model that embeds service policies into formulae to calculate composite service performance. From the calculation, we predict the optimal DOP for the composite service. Extensive experiments are conducted on real-world translation services. The results\u00a0\u2026", "num_citations": "6\n", "authors": ["514"]}
{"title": "Towards survivability of application-level multicast\n", "abstract": " This position paper focuses on challenges in providing survivable and scalable multi-point to multi-point reliable application-level multicast systems (ALMs) for very large groups in wide-area networks. A protocol deployed in such settings must be able to withstand frequent node failures as well as non-negligible message loss rates. A survivable system should also cope with uncooperative users. Moreover, in typical wide-scale multicast sessions, users frequently join and leave [1]. Rapid joining and leaving, also called churn, may effectively cause denial of service (DoS) if handling joins and leaves induces high overhead. Survivability also mandates withstanding attacks. One of the most devastating security threats faced by a distributed system is a DoS attack. Coping with DoS attacks is essential when deploying services in a hostile environment such as the Internet; in 2003, approximately", "num_citations": "6\n", "authors": ["514"]}
{"title": "Fast concurrent data sketches\n", "abstract": " Data sketches are approximate succinct summaries of long data streams. They are widely used for processing massive amounts of data and answering statistical queries about it. Existing libraries producing sketches are very fast, but do not allow parallelism for creating sketches using multiple threads or querying them while they are being built. We present a generic approach to parallelising data sketches efficiently and allowing them to be queried in real time, while bounding the error that such parallelism introduces. Utilising relaxed semantics and the notion of strong linearisability we prove our algorithm's correctness and analyse the error it induces in two specific sketches. Our implementation achieves high scalability while keeping the error small. We have contributed one of our concurrent sketches to the open-source data sketches library.", "num_citations": "5\n", "authors": ["514"]}
{"title": "Automatic lock removal method for scalable synchronization in dynamic data structures\n", "abstract": " In one embodiment, a set of lock and unlock instructions in a read phase of a computer-readable program is replaced with a first set of tracking instructions, wherein the first set of tracking instructions track a set of locked objects identifying objects that would have been locked by executing the set of lock and unlock instructions. A second set of tracking instructions is inserted into the read phase of the computer-readable program, wherein the second set of tracking instructions track a set of read objects indicating versions of objects that are read. Validation instructions are inserted into the computer-readable program, wherein the validation instructions validate that the versions of objects in the set of read objects have not changed since they were last read and lock the set of locked objects that would have been locked upon completing execution of the set of lock and unlock instructions. Update instructions are added to\u00a0\u2026", "num_citations": "5\n", "authors": ["514"]}
{"title": "Csr: Core surprise removal in commodity operating systems\n", "abstract": " One of the adverse effects of shrinking transistor sizes is that processors have become increasingly prone to hardware faults. At the same time, the number of cores per die rises. Consequently, core failures can no longer be ruled out, and future operating systems for many-core machines will have to incorporate fault tolerance mechanisms. We present CSR, a strategy for recovery from unexpected permanent processor faults in commodity operating systems. Our approach overcomes surprise removal of faulty cores, and also tolerates cascading core failures. When a core fails in user mode, CSR terminates the process executing on that core and migrates the remaining processes in its run-queue to other cores. We further show how hardware transactional memory may be used to overcome failures in critical kernel code. Our solution is scalable, incurs low overhead, and is designed to integrate into modern operating\u00a0\u2026", "num_citations": "5\n", "authors": ["514"]}
{"title": "Towards automatic lock removal for scalable synchronization\n", "abstract": " We present a code transformation for concurrent data structures, which increases their scalability without sacrificing correctness. Our transformation takes lock-based code and replaces some of the locking steps therein with optimistic synchronization in order to reduce contention. The main idea is to have each operation perform an optimistic traversal of the data structure as long as no shared memory locations are updated, and then proceed with pessimistic code. The transformed code inherits essential properties of the original one, including linearizability, serializability, and deadlock freedom.               Our work complements existing pessimistic transformations that make sequential code thread-safe by adding locks. In essence, we provide a way to optimize such transformations by reducing synchronization bottlenecks (for example, locking the root of a tree). The resulting code scales well and significantly\u00a0\u2026", "num_citations": "5\n", "authors": ["514"]}
{"title": "High availability for communications based on remote procedure calls\n", "abstract": " Examples of disclosed subject matter relate to: a method, comprising: in an RPC client side: generating an RPC request which corresponds to an RPC call, the RPC request is addressed to an RPC server side and the RPC request includes an RPC call ID; logging the RPC request in an entry that includes an ID of the RPC call; in the RPC server side, responsive to receiving the RPC request: logging the RPC request in an entry including the ID of the RPC call; generating a respective RPC reply that is addressed to the RPC client side and the RPC reply includes the ID of the RPC call; logging the RPC reply in the entry that includes the ID of the RPC call; and in the RPC client side, responsive to receiving the RPC reply: logging the RPC reply in the entry that includes the ID of the RPC call.", "num_citations": "5\n", "authors": ["514"]}
{"title": "The case for exploiting packet loss locality in multicast loss recovery\n", "abstract": " This paper makes the case for exploiting packet loss locality in the loss recovery of reliable multicast protocols, such as SRM [4]. We claim that packet loss locality in IP multicast transmissions can be exploited by simple caching schemes. In such schemes, receivers cache information about the recovery of recently recovered packets and use this information to expedite the recovery of subsequent losses. We present a methodology for estimating the potential effectiveness of caching within multicast loss recovery. We use this methodology on the IP multicast transmission traces of Yajnik et al.[14]. We observe that IP multicast losses exhibit substantial locality and that caching can be very effective.", "num_citations": "5\n", "authors": ["514"]}
{"title": "A framework for highly available services based on group communication\n", "abstract": " We present a framework for building highly available services. The framework uses group communication to coordinate a collection of servers. Our framework is configurable, in that one can adjust parameters such as the number of servers and the extent to which they are synchronized. We analyze the scenarios that can lead to the service availability being temporarily compromised, and we discuss the tradeoffs that govern the choice of parameters.", "num_citations": "5\n", "authors": ["514"]}
{"title": "All you need is dag\n", "abstract": " We present DAG-Rider, the first asynchronous Byzantine Atomic Broadcast protocol that achieves optimal resilience, optimal amortized communication complexity, and optimal time complexity. DAG-Rider is post-quantum safe and ensures that all messages proposed by correct processes eventually get decided. We construct DAG-Rider in two layers: In the first layer, processes reliably broadcast their proposals and build a structured Directed Acyclic Graph (DAG) of the communication among them. In the second layer, processes locally observe their DAGs and totally order all proposals with no extra communication.", "num_citations": "4\n", "authors": ["514"]}
{"title": "Brief announcement: Towards reduced instruction sets for synchronization\n", "abstract": " Contrary to common belief, a recent work by Ellen, Gelashvili, Shavit, and Zhu has shown that computability does not require multicore architectures to support \"strong\" synchronization instructions like compare-and-swap, as opposed to combinations of \"weaker\" instructions like decrement and multiply. However, this is the status quo, and in turn, most efficient concurrent data-structures heavily rely on compare-and-swap (e.g. for swinging pointers). We show that this need not be the case, by designing and implementing a concurrent linearizable Log data-structure (also known as a History object), supporting two operations: append(item), which appends the item to the log, and get-log(), which returns the appended items so far, in order. Readers are wait-free and writers are lock-free, hence this data-structure can be used in a lock-free universal construction to implement any concurrent object with a given sequential specification. Our implementation uses atomic read, xor, decrement, and fetch-and-increment instructions supported on X86 architectures, and provides similar performance to a compare-and-swap-based solution on today's hardware. This raises a fundamental question about minimal set of synchronization instructions that the architectures have to support.", "num_citations": "4\n", "authors": ["514"]}
{"title": "Dynamic atomic snapshots\n", "abstract": " Snapshots are useful tools for monitoring big distributed and parallel systems. In this paper, we adapt the well-known atomic snapshot abstraction to dynamic models with an unbounded number of participating processes. Our dynamic snapshot specification extends the API to allow changing the set of processes whose values should be returned from a scan operation. We introduce the ephemeral memory model, which consists of a dynamically changing set of nodes; when a node is removed, its memory can be immediately reclaimed. In this model, we present an algorithm for wait-free dynamic atomic snapshots.", "num_citations": "4\n", "authors": ["514"]}
{"title": "EFS: Energy-Friendly Scheduler for memory bandwidth constrained systems\n", "abstract": " Additional transistors available in each process generation are used to increase the number of cores on chip. This trend results in high execution unit performance relative to other available resources, such as memory bandwidth, I/O bandwidth, and power. Consequently, the performance bottleneck in modern systems has shifted from the execution units to other resources. In this paper we propose a dynamic scheduling scheme that avoids bottlenecks and thus saves energy. Current operating system schedulers are designed to always assign threads to available cores. We show that this approach may result in excessive loads on other resources, which can ultimately hamper performance and waste energy. Thus, perhaps paradoxically, in some cases it may be advantageous to under-utilize on-chip computing resources in order to achieve better performance and energy efficiency. More generally, we argue that\u00a0\u2026", "num_citations": "4\n", "authors": ["514"]}
{"title": "In-Network Analytics for Ubiquitous Sensing\n", "abstract": " We address the problem of in-network analytics for data that is generated by sensors at the edge of the network. Specifically, we consider the problem of summarizing a continuous physical phenomenon, such as temperature or pollution, over a geographic region like a road network. Samples are collected by sensors placed alongside roads as well as in cars driving along them. We divide the region into sectors and find a summary for each sector, so that their union is a continuous function that minimizes some global error function. We designate a node (either virtual or physical) that is responsible for estimating the function in each sector. Each node computes its estimate based on the samples taken in its sector and information from adjacent nodes.               The algorithm works in networks with bounded, yet unknown, latencies. It accommodates the addition and removal of samples and the arrival and\u00a0\u2026", "num_citations": "4\n", "authors": ["514"]}
{"title": "Want scalable computing? speculate!\n", "abstract": " Distributed computing is currently undergoing a paradigm shift, towards large-scale dynamic systems, where thousands of nodes collaboratively solve computational tasks. Examples of such emerging systems include autonomous sensor networks, data-grids, wireless mesh network (WMN) infrastructures, and more. We argue that speculative computations will be instrumental to successfully performing meaningful computations in such systems. Moreover, solutions deployed in such platforms will need to be as local as possible.", "num_citations": "4\n", "authors": ["514"]}
{"title": "Consistency and high availability of information dissemination in multi-processor networks\n", "abstract": " This thesis presents general tools for the development of highly available distributed applications such as replicated servers and Computer Supported Cooperative Work (CSCW) applications. A desktop and multi-media conferencing tool Rod91] is an example of a CSCW application, incorporating various activities such as video transmission and management of replicated work space. These services are becoming popular today, with the world-wide increase of communication capacity: Replicated servers in clusters are becoming a leading solutions for scalability, fault tolerance and performance, and world-spanning conferences and interactive games over the Internet are becoming more and more popular. Unfortunately, the subtleties involved in such systems are not well understood and many industries apply ad-hoc solutions without fully understanding their limitations and guarantees.The contribution of this thesis is in providing application builders with tools and concepts that facilitate the development of such systems while accurately understanding their limitations and guarantees. These concepts are demonstrated and were tested in prototype implementations. This thesis suggests a comprehensive framework for the development of highly available groupware and CSCW applications, geared towards multi-process failure prone environments (eg, the Internet). The services are fault tolerant and scalable. The suggested framework incorporates a wide variety of services ranging from e cient communication solutions to tools for maintaining consistency of distributed information in the face of faults. These services support multi-party\u00a0\u2026", "num_citations": "4\n", "authors": ["514"]}
{"title": "Oak: a scalable off-heap allocated key-value map\n", "abstract": " Efficient ordered in-memory key-value (KV-) maps are paramount for the scalability of modern data platforms. In managed languages like Java, KV-maps face unique challenges due to the high overhead of garbage collection (GC).", "num_citations": "3\n", "authors": ["514"]}
{"title": "Fishing in the stream: Similarity search over endless data\n", "abstract": " Similarity search is the task of retrieving data items that are similar to a given query. In this paper, we introduce the time-sensitive notion of similarity search over endless data-streams (SSDS), which takes into account data quality and temporal characteristics in addition to similarity. SSDS is challenging as it needs to process unbounded data, while computation resources are bounded. We propose Stream-LSH, a randomized SSDS algorithm that bounds the index size by retaining items according to their freshness, quality, and dynamic popularity attributes. We show that Stream-LSH increases recall when searching for similar items compared to alternative approaches using the same space capacity.", "num_citations": "3\n", "authors": ["514"]}
{"title": "Distributed computing column 43: using social networks to overcome Sybil attacks\n", "abstract": " We open the new academic year with Haifeng Yu\u2019s article on overcoming sybil attacks using social networks. In a sybil attack, a malicious user assumes multiple identities, and uses them to pose as multiple users. Sybil attacks are a threat of the new millennium\u2013they arise in Internet-based distributed systems with a dynamic user population. Indeed, such attacks were not a concern in traditional distributed systems, where the set of participating processes was statically pre-defined. Sybil attacks are inherently difficult to deal with in systems where users do not wish to disclose binding private information, like credit card numbers. A recent popular approach for overcoming sybil attacks is using social networks. Intuitively, even if a malicious user can create many identities, he will have a hard time getting many honest users to befriend all of them in a social network. Thus, the graph structure of a social network can assist\u00a0\u2026", "num_citations": "3\n", "authors": ["514"]}
{"title": "Order is power: Selective Packet Interleaving for energy efficient Networks-on-Chip\n", "abstract": " Network-on-Chip (NoC) links consume a significant fraction of the total NoC power. We present Selective Packet Interleaving (SPI), a flit transmission scheme that reduces power consumption in NoC links. SPI decreases the number of bit transitions in the links by exploiting the multiplicity of virtual channels in a NoC router. SPI multiplexes flits to the router's output link so as to minimize the number of bit transitions from the previously transmitted flit. Analysis and simulations demonstrate a reduction of up to 55% in the number of bit transitions and up to 40% savings in power consumed on the link. SPI benefits grow with the number of virtual channels. SPI works better for links with a small number of bits in parallel. While SPI compares favorably against bus inversion, combining both schemes helps to further reduce bit transitions.", "num_citations": "3\n", "authors": ["514"]}
{"title": "On the performance of quorum replication on the internet\n", "abstract": " Replicated systems often use quorums in order to increase their performance and availability. In such systems, a client typically accesses a quorum of the servers in order to perform an update. In this paper, we study the running time of quorum-based distributed systems over the Internet. We experiment with more than thirty servers at geographically dispersed locations we evaluate two different approaches for defining quorums. We study how the number of servers probed by a client impacts performance and availability. We also examine the extent to which cross-correlated message loss affects the ability to predict running times accurately from end-to-end traces.Descriptors:", "num_citations": "3\n", "authors": ["514"]}
{"title": "Supporting groupware in mobile networks\n", "abstract": " We present MaGMA (Mobility and Group Management Architecture), an architecture for groupware support in mobile networks. MaGMA\u2019s main objective is enabling mobile users to use real-time group applications over the IP infrastructure. Our solutions address group management as well as support for QoS and seamless handoff. We illustrate the advantages of MaGMA using mathematical analysis and simulations.", "num_citations": "3\n", "authors": ["514"]}
{"title": "A client-server approach to virtually synchronous group multicast: Specifications, algorithms, and proofs\n", "abstract": " This paper presents a formal design for a novel group multicast service that provides virtually synchronous semantics in asynchronous fault-prone environments. The design employs a clientserver architecture in which group membership is maintained not by every process but only by dedicated membership servers, while virtually synchronous group multicast is implemented by service end-points running at the clients. This architecture allows the service to be scalable in the topology it spans, in the number of groups, and in the number of clients. Our design allows the virtual synchrony algorithm to run in a single message exchange round, in parallel with the membership algorithm: it does not require pre-agreement upon a common identi er by the membership algorithm.Speci cally, the paper de nes service semantics for the client-server interface, that is, for the group membership service. The paper then speci es virtually synchronous semantics for the new group multicast service, as a collection of safety and liveness properties. These properties have been previously suggested and have been shown to be useful for distributed applications. The paper then presents new algorithms that use the de ned group membership service to implement the speci ed properties. The speci cations and algorithms are presented incrementally, using a novel inheritance-based formal construct 26]. The algorithm that provides the complete virtually synchronous semantics executes in a single message round, and is therefore more e cient than previously suggested algorithms providing such semantics. The algorithm has been implemented in C++. All the speci\u00a0\u2026", "num_citations": "3\n", "authors": ["514"]}
{"title": "Using Nesting to Push the Limits of Transactional Data Structure Libraries\n", "abstract": " Transactional data structure libraries (TDSL) combine the ease-of-programming of transactions with the high performance and scalability of custom-tailored concurrent data structures. They can be very efficient thanks to their ability to exploit data structure semantics in order to reduce overhead, aborts, and wasted work compared to general-purpose software transactional memory. However, TDSLs were not previously used for complex use-cases involving long transactions and a variety of data structures. In this paper, we boost the performance and usability of a TDSL, towards allowing it to support complex applications. A key idea is nesting. Nested transactions create checkpoints within a longer transaction, so as to limit the scope of abort, without changing the semantics of the original transaction. We build a Java TDSL with built-in support for nested transactions over a number of data structures. We conduct a case study of a complex network intrusion detection system that invests a significant amount of work to process each packet. Our study shows that our library outperforms publicly available STMs twofold without nesting, and by up to 16x when nesting is used.", "num_citations": "2\n", "authors": ["514"]}
{"title": "Taking omid to the clouds: Fast, scalable transactions for real-time cloud analytics\n", "abstract": " We describe how we evolve Omid, a transaction processing system for Apache HBase, to power Apache Phoenix, a cloud-grade real-time SQL analytics engine. Omid was originally designed for data processing pipelines at Yahoo, which are, by and large, throughput-oriented monolithic NoSQL applications. Providing a platform to support converged real-time transaction processing and analytics applications - dubbed translytics - introduces new functional and performance requirements. For example, SQL support is key for developer productivity, multi-tenancy is essential for cloud deployment, and latency is cardinal for just-in-time data ingestion and analytics insights. We discuss our efforts to adapt Omid to these new domains, as part of the process of integrating it into Phoenix as the transaction processing backend. A central piece of our work is latency reduction in Omid's protocol, which also improves scalability\u00a0\u2026", "num_citations": "2\n", "authors": ["514"]}
{"title": "Thinner clouds with preallocation\n", "abstract": " Different companies sharing the same cloud infrastructure often prefer to run their virtual machines (VMs) in isolation, ie, one VM per physical machine (PM) core, due to security and efficiency concerns. To accommodate load spikes, eg, those caused by flash-crowds, each service is allocated more machines than necessary for its instantaneous load. However, flash-crowds of different hosted services are not correlated, so at any given time, only a subset of the machines are used.", "num_citations": "2\n", "authors": ["514"]}
{"title": "Distributed computing column 42: game theory and fault tolerance in distributed computing\n", "abstract": " Game theory and fault tolerance offer two different flavors of robustness to distributed systems\u2013the former is robust against participants attempting to maximize their own utilities, whereas the latter offers robustness against unexpected faults. This column takes a look at attempts to combine the two. It features a review of recent work that provides both flavors of robustness by Ittai Abraham, Lorenzo Alvisi, and Joe Halpern. Ittai, Lorenzo, and Joe discuss how game theory-style strategic behavior can be accounted for in fault-tolerant distributed protocols. They make a compelling case for bringing a game-theoretic perspective to distributed computing problems. Many thanks to Ittai, Lorenzo and Joe for their article!", "num_citations": "2\n", "authors": ["514"]}
{"title": "Tolerant value speculation in coarse-grain streaming computations\n", "abstract": " Streaming applications are the subject of growing interest, as the need for fast access to data continues to grow. In this work, we present the design requirements and implementation of coarse-grain value speculation in streaming applications. We explain how this technique can be useful in cases where serial parts of applications constitute bottlenecks, and when slower I/O favors using available prefixes of the data. Contrary to previous work, we show how allowing some tolerance can justify early predictions on a scale of a large window of values. We suggest a methodology for runtime support of speculation, along with the mechanisms required for rollback. We present resource management issues consequent to our technique. We study how validation and speculation frequencies impact the performance of the program. Finally, we present our implementation in the context of the Huffman encoder benchmark\u00a0\u2026", "num_citations": "2\n", "authors": ["514"]}
{"title": "Transactifying Apache's cache module\n", "abstract": " Apache is a large-scale industrial multi-process and multithreaded application, which uses lock-based synchronization. We report on our experience in modifying Apache's cache module to employ transactional memory instead of locks, a process we refer to as transactification; we are not aware of any previous efforts to transactify legacy software of such a large scale. Along the way, we learned some valuable lessons about which tools one should use, which parts of the code one should transactify and which are better left untouched, as well as on the intricacy of commit handlers. We also stumbled across weaknesses of existing software transactional memory (STM) toolkits, leading us to identify desirable features they are currently lacking. Finally, we present performance results from running Apache on a 32-core machine, showing that, there are scenarios where the performance of the STM-based version is close\u00a0\u2026", "num_citations": "2\n", "authors": ["514"]}
{"title": "Distributed Computing\n", "abstract": " This volume contains 33 15-page-long regular papers and 15 2-page-long brief announcements selected for the 23rd International Symposium on Distributed Computing (DISC 2009), held during September 23-25, 2009, in Elche, Spain. This volume also includes the citation of the 2009 Edsger W. Dijkstra Prize in Distributed Computing, which was awarded at DISC this year, as well as abstracts of talks delivered in a mini symposium honoring the 60th birthdays of Michel Raynal and Shmuel Zaks.There were 121 submissions to DISC this year, of which 116 were considered for regular presentations, and the rest for brief announcements only. Every submitted paper was read and evaluated by Program Committee members assisted by external reviewers. The final decisions regarding acceptance or rejection of each paper were made during the phone-based Program Committee meeting held during June 2009\u00a0\u2026", "num_citations": "2\n", "authors": ["514"]}
{"title": "Formal Modeling, Analysis, and Design of Network Protocols\u2014A Case Study in Reliable Multicast\n", "abstract": " Introduction: To date, network protocols are designed and analyzed using predominantly non-rigorous techniques. Protocols are usually specified by informal descriptions that are often imprecise, incomplete, and have unclear or lacking assumptions. Moreover, informal protocol descriptions omit to specify the correctness and performance assumptions regarding the low-level communication services they rely on. Rigor is similarly lacking in protocol analysis techniques. Protocol correctness is seldom explicitly addressed. Rather, a protocol\u2019s correctness is validated through informal reasoning and simulations. Similarly, a protocol\u2019s performance is evaluated through statistical analyses and simulations.In contrast to these traditional protocol design and analysis techniques, we advocate the use of a formal approach in modeling, analyzing, and designing network protocols. This approach involves using the timed I/O\u00a0\u2026", "num_citations": "2\n", "authors": ["514"]}
{"title": "Byzantine Agreement with Less Communication: Recent Advances\n", "abstract": " The development of reliable distributed systems often relies on Byzantine Agreement (BA) [26]. In this problem, a set of correct processes aim to reach a common decision, despite the presence of malicious ones. BA has been around for four decades, yet practical use-cases for it in large-scale systems have emerged only in the last decade. One major application for BA is cryptocurrencies. For example, Bitcoin [30], the rst cryptocurrency, requires a large set of users to agree on the state of the blockchain. Since Bitcoin is a real currency with real value, the need to protect it against Byzantine users is crucial. Following Bitcoin, many other blockchains and FinTech platforms have emerged, e.g., [6,21,30,36]. Consequently, an efficient implementation, in terms of communication, has become one of the main foci of BA solutions.", "num_citations": "1\n", "authors": ["514"]}
{"title": "Economically Viable Randomness\n", "abstract": " We study the problem of providing blockchain applications with \\emph{economically viable randomness} (EVR), namely, randomness that has significant economic consequences. Applications of EVR include blockchain-based lotteries and gambling. An EVR source guarantees (i) secrecy, assuring that the random bits are kept secret until some predefined condition indicates that they are safe to reveal (e.g., the lottery's ticket sale closes), and (ii) robustness, guaranteeing that the random bits are published once the condition holds. We formalize the EVR problem and solve it on top of an Ethereum-like blockchain abstraction, which supports smart contracts and a transferable native coin. Randomness is generated via a distributed open commit-reveal scheme by game-theoretic agents who strive to maximize their coin holdings. Note that in an economic setting, such agents might profit from breaking secrecy or robustness, and may engage in side agreements (via smart contracts) to this end. Our solution creates an incentive structure that counters such attacks. We prove that following the protocol gives rise to a stable state, called Coalition-Proof Nash Equilibrium, from which no coalition comprised of a subset of the players can agree to deviate. In this stable state, robustness and secrecy are satisfied. Finally, we implement our EVR source over Ethereum.", "num_citations": "1\n", "authors": ["514"]}
{"title": "Towards reduced instruction sets for synchronization\n", "abstract": " Contrary to common belief, a recent work by Ellen, Gelashvili, Shavit, and Zhu has shown that computability does not require multicore architectures to support \"strong\" synchronization instructions like compare-and-swap, as opposed to combinations of \"weaker\" instructions like decrement and multiply. However, this is the status quo, and in turn, most efficient concurrent data-structures heavily rely on compare-and-swap (e.g. for swinging pointers and in general, conflict resolution). We show that this need not be the case, by designing and implementing a concurrent linearizable Log data-structure (also known as a History object), supporting two operations: append(item), which appends the item to the log, and get-log(), which returns the appended items so far, in order. Readers are wait-free and writers are lock-free, and this data-structure can be used in a lock-free universal construction to implement any concurrent object with a given sequential specification. Our implementation uses atomic read, xor, decrement, and fetch-and-increment instructions supported on X86 architectures, and provides similar performance to a compare-and-swap-based solution on today's hardware. This raises a fundamental question about minimal set of synchronization instructions that the architectures have to support.", "num_citations": "1\n", "authors": ["514"]}
{"title": "Composing ordered sequential consistency using leading updates\n", "abstract": " We define ordered sequential consistency (OSC), a correctness criterion for concurrent objects, which captures the typical behavior of many real-world services, eg, ZooKeeper, etcd, Chubby, Doozer, and Consul. A straightforward composition of OSC objects is not necessarily OSC. To remedy this, we recently implemented a composition framework that injects dummy updates in specific scenarios. We prove that injecting such updates, which we call here leading updates, enables correct OSC composition. We generalize OSC to define G-OSC, a generic criterion for concurrent objects, which encompasses a range of criteria, including sequential consistency and linearizability.", "num_citations": "1\n", "authors": ["514"]}
{"title": "Performance scalability and dynamic behavior of Parsec benchmarks on many-core processors\n", "abstract": " The Parsec benchmark suite is widely used in evaluation of parallel architectures, both existing and novel, the latter through simulation. In particular, it is used for evaluation of highly parallel architectures. It is well known that parallelism bottlenecks occur both in the architecture,(eg, shared-resource contention) and in the algorithm,(eg, data-dependency). In this paper we study the latter, ie, the inherent parallelism scalability and the dynamic behavior of the benchmark programs themselves, independently of the architecture.To this end, we present a new simulator that performs efficient, functionally accurate, simulation of a hypothetical ideal parallel architecture with no parallelism bottlenecks, where any measured parallelism limitation is necessarily due the benchmark itself. By applying this methodology to a continuum of simulated machines, ranging from a few processors to thousands of processors, we characterize the dynamic behavior and scalability of different benchmarks. We find that only a quarter of the Parsec benchmarks truly scale well to hundreds of processors. Moreover, somewhat surprisingly, we find the Amdahl effects are responsible for lack of scaling in only about half the non-scalable benchmarks. The rest are limited by their inability to produce sufficient work for all cores, and the others benchmarks\u2019 scalability is limited by Amdahl effects.", "num_citations": "1\n", "authors": ["514"]}
{"title": "Introducing speculative optimizations in task dataflow with language extensions and runtime support\n", "abstract": " We argue that speculation leads to increased parallelism in the coarse-grain dataflow paradigm. To do so, we present a framework for adding speculation in a popular and well-established framework. We specify a limited set of additions to the OmpSs language and changes required in its supporting runtime environment. These modifications enable speculation across the system in a flexible way. We evaluate our implementation using a simple benchmark leading to a promising 10% speedup.", "num_citations": "1\n", "authors": ["514"]}
{"title": "Distributed computing column 36 distributed computing: 2009 edition\n", "abstract": " It\u2019s now the season for colorful reviews of 2009. While you can read elsewhere about the year in sports, top-40 pop hit charts, people of the year, and so on, I throw my share into the mix with a (biased) review of this year\u2019s major distributed computing events.Awards First, let\u2019s look at awards. This year we learned that two women were recognized with ACM and IEEE prestigious awards for their achievements in,(among other things), distributed computing. Barbara Liskov won the 2008 ACM Turing Award for a range of contributions to practical and theoretical foundations of programming language and system design, some of which are in distributed computing. The award citation mentions her impact on distributed programming, decentralized information flow, replicated storage, and modular upgrading of distributed systems. I include below a short reflection, by Rodrigo Rodrigues, on Barbara Liskov\u2019s Turing Award\u00a0\u2026", "num_citations": "1\n", "authors": ["514"]}
{"title": "ACM SIGACT news distributed computing column 34: distributed computing in the clouds\n", "abstract": " It seems like \u201ccomputation clouds\u201d are cropping up everywhere nowadays... well, except perhaps, actually \u201cin the clouds\u201d, as a recent April Fool\u2019s joke by Amazon suggested1. While there is no commonly agreed-upon definition of what exactly constitutes a cloud, it is clear that there are some pretty interesting mega-scale distributed computing environments out there. Such environments require, and already deploy, many distributed services and applications. This column examines distributed computing research that seeks to develop new solutions for clouds, as well as to improve existing ones. Our main contribution is by Ken Birman, Gregory (Grisha) Chockler, and Robbert van Renesse, who identify a research agenda for cloud computing, based on insights gained at the 2008 LADIS workshop. They question whether contemporary research in distributed computing, which sometimes targets cloud environments\u00a0\u2026", "num_citations": "1\n", "authors": ["514"]}
{"title": "Discouraging Selfishness in Lossy Peer-to-Peer Networks\n", "abstract": " We present Loss-Tolerant Selfishness Monitor (LTSM), a generic service for detecting selfish behavior in various P2P applications, such as MANET routing and multicast. Unlike most previous selfishness-resistant protocols, LTSM can be used in networks subject to message loss, where selfish behavior detection is particularly challenging. One of our main contributions is mathematically analyzing the impact of various system parameters on the incentives for cooperation, and showing how to choose these parameters so as to ensure full cooperation at a minimal cost. We illustrate the applicability of LTSM in two exemplar contexts: multicast and MANET routing.", "num_citations": "1\n", "authors": ["514"]}
{"title": "On distributed computing principles in systems research: introduction\n", "abstract": " Distributed systems are increasingly deployed in the real world nowadays. Concepts like high-availability, disaster recovery, service-oriented architectures, grid computing, and peer-to-peer are now a standard part of a software engineer's vocabulary. Data is often stored on remote servers or disks, and redundancy is employed for fault-tolerance and high availability. Even computations on a single machine are becoming increasingly parallel due to the advent of multi-core architectures, as discussed in the previous Distributed Computing Column.", "num_citations": "1\n", "authors": ["514"]}
{"title": "How to Choose a Timing Model?\n", "abstract": " When employing a consensus algorithm for state machine replication, should one optimize for the case that all communication links are usually timely, or for fewer timely links? Does optimizing a protocol for better message complexity hamper the time complexity? In this paper, we investigate these types of questions using mathematical analysis as well as experiments over Planet-Lab (WAN) and a LAN. We present a new and efficient leader-based consensus protocol that has O (n) stablestate message complexity (in a system with n processes) and requires only O (n) links to be timely at stable times. We compare this protocol with several previously suggested protocols. Our results show that a protocol that requires fewer timely links can achieve better performance, even if it sends fewer messages.", "num_citations": "1\n", "authors": ["514"]}
{"title": "Intrusion tolerance by unpredictable adaptation (ITUA)\n", "abstract": " The ITUA project began with the research goals of using Byzantine fault-tolerant protocols to coordinate adaptation to attacks and exploring the use of unpredictability in adaptive responses to confuse and delay the attacker. These main factors distinguish the ITUA approach 1 dynamic adaptation-intrusions cause charges in the system, and a survivable system must cope with these changes, 2 a defense-enabled application that has an application and mission specific defense strategy, and 3 defense enabling builds the defense in middleware, intermediate between the application and the networks and operating systems on which the applications run. The ITUA approach was to respond and adapt to the effects of a malicious attack while it is in progress. If the defense-enabled application continues correct processing in spite of the attached, the defense was considered to be successful. The report reviews the motivation for the project and its historical context, then summarizes the ITUA research goals, progress toward achieving those goals, and lessons learned from the research. The report offers some plans for future research and draws a conclusion.Descriptors:", "num_citations": "1\n", "authors": ["514"]}
{"title": "Caching-enhanced scalable reliable multicast\n", "abstract": " We present the caching-enhanced scalable reliable multicast (CESRM) protocol. CESRM augments the scalable reliable multicast (SRM) protocol (S. Floyd et al., 1995 and 1997) with a caching-based expedited recovery scheme. CESRM exploits the packet loss locality occurring in IP multicast transmissions in order to expeditiously recover from losses in the manner in which recent losses were recovered. Trace-driven simulations show that CESRM reduces the average recovery latency of SRM by roughly 50% and, moreover, drastically reduces the overhead in terms of recovery traffic and control messages.", "num_citations": "1\n", "authors": ["514"]}
{"title": "Global estimation with local communication\n", "abstract": " We present a distributed optimization algorithm for estimating a continuous function such as temperature or pollution over a geographic region, eg, a road network. The estimate is generated from samples taken by sensors placed alongside roads or in cars driving along them. We employ piecewise estimation, that is, we divide the region into sectors and find an estimate for each sector, eg, a polynomial or a line, so that their union is a continuous function that minimizes some global error function. The computation is distributed by designating a node (either virtual or physical) that is responsible for estimating the function in each sector. The estimate is then computed based on the samples taken in the sector and information from adjacent nodes.", "num_citations": "1\n", "authors": ["514"]}