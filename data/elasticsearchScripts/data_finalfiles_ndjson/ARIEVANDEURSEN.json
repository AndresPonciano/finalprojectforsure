{"title": "Domain-specific language design requires feature descriptions\n", "abstract": " A domain-specific language (DSL) provides a notation tailored towards an application domain and is based on the relevant concepts and features of that domain. As such, a DSL is a means to describe and generate members of a family of programs in the domain.", "num_citations": "465\n", "authors": ["146"]}
{"title": "Little languages: Little maintenance?\n", "abstract": " So\u2010called little, or domain\u2010specific languages (DSLs), have the potential to make software maintenance simpler: domain experts can directly use the DSL to make required routine modifications. On the negative side, however, more substantial changes may become more difficult: such changes may involve altering the domain\u2010specific language. This will require compiler technology knowledge, which not every commercial enterprise has easily available. Based on experience taken from industrial practice, we discuss the role of DSLs in software maintenance, the dangers introduced by using them, and techniques for controlling the risks involved. \u00a9 1998 John Wiley & Sons, Ltd.", "num_citations": "389\n", "authors": ["146"]}
{"title": "Identifying objects using cluster and concept analysis\n", "abstract": " Many approaches to support (semi-automatic) identification of objects in legacy code take the data structures as starting point for candidate classes. Unfortunately, legacy data structures tend to grow over time, and may contain many unrelated fields at the time of migration. We propose a method for identifying objects by semi-automatically restructuring the legacy data structures. Issues involved include the selection of record fields of interest, the identification of procedures actually dealing with such fields, and the construction of coherent groups of fields and procedures into candidate classes. We explore the use of cluster and concept analysis for the purpose of object identification, and we illustrate their effect on a 100,000 LOC Cobol system. Furthermore, we use these results to contrast clustering with concept analysis techniques.", "num_citations": "332\n", "authors": ["146"]}
{"title": "On the use of clone detection for identifying crosscutting concern code\n", "abstract": " In systems developed without aspect-oriented programming, code implementing a crosscutting concern may be spread over many different parts of a system. Identifying such code automatically could be of great help during maintenance of the system. First of all, it allows a developer to more easily find the places in the code that must be changed when the concern changes and, thus, makes such changes less time consuming and less prone to errors. Second, it allows the code to be refactored to an aspect-oriented solution, thereby improving its modularity. In this paper, we evaluate the suitability of clone detection as a technique for the identification of crosscutting concerns. To that end, we manually identify five specific crosscutting concerns in an industrial C system and analyze to what extent clone detection is capable of finding them. We consider our results as a stepping stone toward an automated \"aspect miner\"\u00a0\u2026", "num_citations": "228\n", "authors": ["146"]}
{"title": "An empirical study into class testability\n", "abstract": " In this paper we investigate factors of the testability of object-oriented software systems. The starting point is given by a study of the literature to obtain both an initial model of testability and existing object-oriented metrics related to testability. Subsequently, these metrics are evaluated by means of five case studies of commercial and open source Java systems for which JUnit test cases exist. The goal of this paper is to identify and evaluate a set of metrics that can be used to assess the testability of the classes of a Java system.", "num_citations": "181\n", "authors": ["146"]}
{"title": "Building documentation generators\n", "abstract": " In order to maintain the consistency between sources and documentation, while at the same time providing documentation at the design level, it is necessary to generate documentation from sources in such a way that it can be integrated with hand-written documentation. In order to simplify the construction of documentation generators, we introduce island grammars, which only define those syntactic structures needed for (re)documentation purposes. We explain how they can be used to obtain various forms of documentation, such as data dependency diagrams for mainframe batch jobs. Moreover, we discuss how the derived information can be made available via a hypertext structure. We conclude with an industrial case study in which a 600,000 LOC COBOL legacy system is redocumented using the techniques presented in the paper.", "num_citations": "171\n", "authors": ["146"]}
{"title": "Can LSI help reconstructing requirements traceability in design and test?\n", "abstract": " Managing traceability data is an important aspect of the software development process. In this paper, we investigate to what extent latent semantic indexing (LSI), an information retrieval technique, can help recovering the information needed for automatically reconstructing traceability during the development process. We experimented with two different link selection strategies and applied LSI in multiple case studies varying in size and context. We discuss the results of a small lab study, a larger case study and a large industrial case study", "num_citations": "170\n", "authors": ["146"]}
{"title": "An evaluation of clone detection techniques for crosscutting concerns\n", "abstract": " Code implementing a crosscutting concern is often spread over many different parts of an application. Identifying such code automatically greatly improves both the maintainability and the evolvability of the application. First of all, it allows a developer to more easily find the places in the code that must be changed when the concern changes, and thus makes such changes less time consuming and less prone to errors. Second, it allows a developer to refactor the code, so that it uses modern and more advanced abstraction mechanisms, thereby restoring its modularity. We evaluate the suitability of clone detection as a technique for the identification of crosscutting concerns. To that end, we manually identify four specific concerns in an industrial C application, and analyze to what extent clone detection is capable of finding these concerns. We consider our results as a stepping stone toward an automated \"concern\u00a0\u2026", "num_citations": "169\n", "authors": ["146"]}
{"title": "Predicting class testability using object-oriented metrics\n", "abstract": " We investigate factors of the testability of object-oriented software systems. The starting point is given by a study of the literature to obtain both an initial model of testability and existing OO metrics related to testability. Subsequently, these metrics are evaluated by means of two case studies of large Java systems for which JUnit test cases exist. The goal of This work is to define and evaluate a set of metrics that can be used to assess the testability of the classes of a Java system.", "num_citations": "167\n", "authors": ["146"]}
{"title": "Origin tracking\n", "abstract": " We are interested in generating interactive programming environments from formal language specifications and use term rewriting to execute these specifications. Functions defined in a specification operate on the abstract syntax tree of programs and the initial term for the rewriting process will consist of an application of some function (e.g., a type checker, evaluator or translator) to the syntax tree of a program. During the term rewriting process, pieces of the program such as identifiers, expressions, or statements, recur in intermediate terms. We want to formalize these recurrences and use them, for example, for associating positional information with messages in error reports, visualizing program execution, and constructing language-specific debuggers. Origins are relations between subterms of intermediate terms and subterms of the initial term. Origin tracking is a method for incrementally computing origins during\u00a0\u2026", "num_citations": "134\n", "authors": ["146"]}
{"title": "Model-driven software evolution: A research agenda\n", "abstract": " Software systems need to evolve, and systems built using model-driven approaches are no exception. What complicates model-driven engineering is that it requires multiple dimensions of evolution. In regular evolution, the modeling language is used to make the changes. In meta-model evolution, changes are required to the modeling notation. In platform evolution, the code generators and application framework change to reflect new requirements on the target platform. Finally, in abstraction evolution, new modeling languages are added to the set of (modeling) languages to reflect increased understanding of a technical or business domain. While MDE has been optimized for regular evolution, presently little or no support exists for metamodel, platform and abstraction evolution. In this paper, we analyze the problems raised by the evolution of model-based software systems and identify challenges to be addressed by research in this area.", "num_citations": "109\n", "authors": ["146"]}
{"title": "An algebraic specification of a language for describing financial products\n", "abstract": " We report on the use of formal methods and supporting tools during the development of a language applied in a banking environment. This language, called RISLA, is used to define the nature of the interest products offered by a bank. ARisla description fixes the cash flows (amounts of money coming in or going out on particular dates) resulting from a product, and is used to generate COBOL code. The language has been developed with the use of algebraic specifications, the role of which is discussed.", "num_citations": "101\n", "authors": ["146"]}
{"title": "Industrial applications of ASF+ SDF\n", "abstract": " In recent years, a number of Dutch companies have used the algebraic specification formalism Asf+Sdf. Bank MeesPierson has specified a language for describing interest rate products, their translation into COBOL, and their generation from interactive questionnaires. A consultancy company has specified a language to represent the company's object-oriented models, and the compilation of this language into Access. Bank ABN-AMRO has started investigating the use of algebraic specifications for renovating legacy COBOL systems. We discuss the implications of such projects for teaching algebraic specifications and software engineering, and the role students have been playing in these projects.", "num_citations": "98\n", "authors": ["146"]}
{"title": "Discovering faults in idiom-based exception handling\n", "abstract": " In this paper, we analyse the exception handling mechanism of a state-of-the-art industrial embedded software system. Like many systems implemented in classic programming languages, our subject system uses the popular return-code idiom for dealing with exceptions. Our goal is to evaluate the fault-proneness of this idiom, and we therefore present a characterisation of the idiom, a fault model accompanied by an analysis tool, and empirical data. Our findings show that the idiom is indeed fault prone, but that a simple solution can lead to significant improvements.", "num_citations": "96\n", "authors": ["146"]}
{"title": "Source-based software risk assessment\n", "abstract": " The paper reports on a method for software risk assessments that take into account \"primary facts\" and \"secondary facts\". Primary facts are those obtained through automatically analyzing the source code of a system, and secondary facts are those facts obtained from people working with or on the system, and available documentation. We describe how both types of facts are retrieved, and how we are bridging the interpretation gap from the raw facts (either primary or secondary) to a concise risk assessment, which includes recommendations to minimize the risk. This method has been developed while performing numerous risk assessments, and is continuously being fine-tuned.", "num_citations": "75\n", "authors": ["146"]}
{"title": "Reconstructing requirements coverage views from design and test using traceability recovery via LSI\n", "abstract": " Requirements coverage views can help validate that all requirements are implemented in the system. This is not a trivial process. In this paper we present a method for generating requirements coverage views. To do this, information needs to be gathered from multiple sources in the development process. A traceability model defines the development work products and links that are required to generate the coverage views. Retrieving this information is done by using Latent Semantic Indexing (LSI). The method is applied in a lab study, Pacman, of which the preliminary results are also presented in this paper.", "num_citations": "68\n", "authors": ["146"]}
{"title": "A test-suite diagnosability metric for spectrum-based fault localization approaches\n", "abstract": " Current metrics for assessing the adequacy of a test-suite plainly focus on the number of components (be it lines, branches, paths) covered by the suite, but do not explicitly check how the tests actually exercise these components and whether they provide enough information so that spectrum-based fault localization techniques can perform accurate fault isolation. We propose a metric, called DDU, aimed at complementing adequacy measurements by quantifying a test-suite's diagnosability, i.e., the effectiveness of applying spectrum-based fault localization to pinpoint faults in the code in the event of test failures. Our aim is to increase the value generated by creating thorough test-suites, so they are not only regarded as error detection mechanisms but also as effective diagnostic aids that help widely-used fault-localization techniques to accurately pinpoint the location of bugs in the system. Our experiments show that\u00a0\u2026", "num_citations": "63\n", "authors": ["146"]}
{"title": "Program comprehension risks and opportunities in extreme programming\n", "abstract": " Investigates the relationship between reverse engineering and program comprehension on the one hand, and the software process on the other. To understand this relationship, we select one particular existing software process, extreme programming (XP), and study the role played in it by program comprehension and reverse engineering. To that end, we analyze five key XP practices in depth: pair programming, unit testing, refactoring, evolutionary design and collaborative planning. The contributions of this paper are: (1) the identification of promising research areas in the field of program comprehension; (2) the identification of new application perspectives for reverse engineering technology; (3) a critical analysis of XP resulting in research questions that could help resolve some of the uncertainties surrounding XP; and (4) a discussion of the role that comprehension and reverse engineering can play in software\u00a0\u2026", "num_citations": "62\n", "authors": ["146"]}
{"title": "Research issues in the renovation of legacy systems\n", "abstract": " The goals of this tutorial are to: (i) give the reader a quick introduction to the field of software renovation as a whole; (ii) show that many techniques from compiler technology and formal methods can be applied; (iii) demonstrate that research should be driven by real-life, industrial, case studies; and (iv) indicate that many challenging problems are still unsolved. During the presentation of this turorial, demonstrations will be given of several of the case studies discussed here.", "num_citations": "62\n", "authors": ["146"]}
{"title": "Evaluating an embedded software reference architecture-industrial experience report\n", "abstract": " In this paper, we discuss experiences gained during evaluation of the maintainability of a reference architecture in use at Oce, one of the world's leading copier manufacturers. The evaluation is conducted using an approach based on SEI's software architecture analysis method (SAAM). The paper proposes a variant of SAAM that helps to reduce the organisational impact of architecture evaluations. Second, we analyse the implications of evaluating reference architectures as opposed to single-product architectures. Furthermore, we share our experience of conducting the evaluation, draw lessons for practitioners, and propose new research topics.", "num_citations": "60\n", "authors": ["146"]}
{"title": "Harvesting software systems for MDA-based reengineering\n", "abstract": " In this paper we report on a feasibility study in reengineering legacy systems towards a model-driven architecture (MDA). Steps in our approach consist of (1) parsing the source code of the legacy system according to a grammar; (2) mapping the abstract syntax trees thus obtained to a grammar model that is defined in the Meta-Object Facility (MOF); (3) using model to model (M2M) transformations to turn the grammar model into a generic meta-model, called GenericAST, in which information about software systems can be stored in a language-independent way; (4) mapping the GenericAST models, again using M2M transformations, to UML models that can be either used for code generation or for documentation purposes. The steps have been implemented in a prototype model harvesting tool that is based on ArcStyler, the MDA environment provided by Interactive Objects. Our paper presents this\u00a0\u2026", "num_citations": "58\n", "authors": ["146"]}
{"title": "Domain-specific languages versus object-oriented frameworks: A financial engineering case study\n", "abstract": " The use of a domain-specific language can help to develop readable and maintainable applications in that domain with little effort. Alternatively, the same aims can be achieved by setting up an object-oriented framework. For the domain of financial engineering, independently both an objectoriented framework and a domain-specific language have been developed. We use this opportunity to contrast these two, to highlight the differences and to discuss opportunities for mutual benefits.", "num_citations": "56\n", "authors": ["146"]}
{"title": "Executable language definitions: Case studies and origin tracking techniques\n", "abstract": " Executable language definitions : case studies and origin tracking techniques (1994) | www.narcis.nl KNAW KNAW Narcis Back to search results CWI Publication Executable language definitions : case studies and origin tracking techniques (1994) Pagina-navigatie: Main Save publication Save as MODS Export to Mendeley Save as EndNote Export to RefWorks Title Executable language definitions : case studies and origin tracking techniques Series ILLC Dissertation Series Author A. van Deursen (Arie) Date issued 1994-09-29 Access Closed Access Language English Type Doctoral Thesis Publication https://ir.cwi.nl/pub/25632 OpenURL Search this publication in (your) library ISBN 978-90-74795-09-8 Persistent Identifier urn:NBN:nl:ui:18-25632 Metadata XML Source CWI Go to Website Navigation: Home about narcis login Nederlands contact Anna van Saksenlaan 51 2593 HW Den Haag narcis@dans.knaw.nl >\u2026", "num_citations": "56\n", "authors": ["146"]}
{"title": "Simple crosscutting concerns are not so simple: analysing variability in large-scale idioms-based implementations\n", "abstract": " This paper describes a method for studying idioms-based implementations of crosscutting concerns, and our experiences with it in the context of a real-world, large-scale embedded software system. In particular, we analyse a seemingly simple concern, tracing, and show that it exhibits significant variability, despite the use of a prescribed idiom. We discuss the consequences of this variability in terms of how aspect-oriented software development techniques could help prevent it, how it paralyses (automated) migration efforts, and which aspect language features are required in order to obtain precise and concise aspects. Additionally, we elaborate on the representativeness of our results and on the usefulness of our proposed method.", "num_citations": "47\n", "authors": ["146"]}
{"title": "An industrial case study in reconstructing requirements views\n", "abstract": " Requirements views, such as coverage and status views, are an important asset for monitoring and managing software development projects. We have developed a method that automates the process of reconstructing these views, and we have built a tool, ReqAnalyst, that supports this method. This paper presents an investigation as to which extent requirements views can be automatically generated in order to monitor requirements in industrial practice. The paper focuses on monitoring the requirements in test categories and test cases. In order to retrieve the necessary data, an information retrieval technique, called Latent Semantic Indexing, was used. The method was applied in an industrial study. A number of requirements views were defined and experiments were carried out with different reconstruction settings for generating these views. Finally, we explored how these views can help the developers\u00a0\u2026", "num_citations": "46\n", "authors": ["146"]}
{"title": "Feature-based product line instantiation using source-level packages\n", "abstract": " In this paper, we discuss the construction of software products from customer-specific feature selections. We address variability management with the Feature Description Language (FDL) to capture variation points of product line architectures. We describe feature packaging, which covers selecting and packaging implementation components according to feature selections using the autobundle tool. Finally, we discuss a generic approach, based on the abstract factory design pattern, to make instantiated (customer-specific) variability accessible in applications.             The solutions and techniques presented in this paper are based on our experience with the product line architecture of the commercial documentation generator DocGen.", "num_citations": "45\n", "authors": ["146"]}
{"title": "Managing evolving requirements in an outsourcing context: an industrial experience report\n", "abstract": " We discuss several difficulties managing evolving requirements by means of an industrial case study conducted at LogicaCMG. We report on setting up a requirements management system in an outsourcing context and its application in real-life. The experience results in several lessons learned, questions to be answered in the future on how to manage evolving requirements, and solution directions. We propose a conceptual framework of requirements engineering system tailored for outsourcing environments, which captures the experience results.", "num_citations": "44\n", "authors": ["146"]}
{"title": "Rapid system understanding: Two COBOL case studies\n", "abstract": " Rapid system understanding is required in the planning, feasibility assessment and cost estimating phases of a system renovation project. In this paper we apply a number of analyses on two large legacy COBOL systems from the banking field. We describe the analyses performed and discuss possible interpretations of these analyses. Lessons learned include: (1) The open architecture adopted is satisfactory, and can take advantage of a wide range of understanding tools available; and (2) To handle inter-system variability effectively, the flexibility of lexical analysis is required.", "num_citations": "43\n", "authors": ["146"]}
{"title": "Isolating idiomatic crosscutting concerns\n", "abstract": " This paper reports on our experience in automatically migrating the crosscutting concerns of a large-scale software system, written in C, to an aspect-oriented implementation. We present a systematic approach for isolating crosscutting concerns, and illustrate this approach by zooming in on one particular crosscutting concern. Additionally, we compare the already existing solution to the aspect-oriented solution, and discuss advantages as well as disadvantages of both in terms of selected quality attributes. Our results show that automated migration is feasible, and that adopting an aspect-oriented approach can lead to significant improvements in source code quality, if carefully designed and managed.", "num_citations": "41\n", "authors": ["146"]}
{"title": "AJHotDraw: A showcase for refactoring to aspects\n", "abstract": " Adoption of aspect-oriented techniques in existing systems is hindered by the fact that developers have difficulties adapting to a \u201cmulti-view\u201d, concern-based reasoning over the software systems, and by a lack of reference solutions that show how to address crosscutting functionality in real-life systems. In this paper, we argue for the need of a common showcase for the adoption of aspect-oriented techniques in existing systems and propose an open-source model application to serve this role. We present the AJHotDraw project whose goal is to take an existing well-designed open-source system (JHot-Draw) and migrate it to a functionally equivalent aspectoriented version. In addition to creating a showcase, the project aims to assess feasibility of aspect solutions in a real application, to document the crosscutting concerns in the original system and address the testing challenges that rise from ensuring behavior conservation between the original and the refactored version of the system. 1.", "num_citations": "41\n", "authors": ["146"]}
{"title": "Model-driven consistency checking of behavioural specifications\n", "abstract": " For the development of software intensive systems different types of behavioural specifications are used. Although such specifications should be consistent with respect to each other, this is not always the case in practice. Maintainability problems are the result. In this paper we propose a technique for assessing the consistency of two types behavioural specifications: scenarios and state machines. The technique is based on the generation of state machines from scenarios. We specify the required mapping using model transformations. The use of technologies related to the model driven architecture enables easy integration with widely adopted (UML) tools. We applied our technique to assess the consistency of the behavioural specifications for the embedded software of copiers developed by Oce. Finally, we evaluate the approach and discuss its generalisability and wider applicability", "num_citations": "36\n", "authors": ["146"]}
{"title": "Exception handling bug hazards in Android\n", "abstract": " Adequate handling of exceptions has proven difficult for many software engineers. Mobile app developers in particular, have to cope with compatibility, middleware, memory constraints, and battery restrictions. The goal of this paper is to obtain a thorough understanding of common exception handling bug hazards that app developers face. To that end, we first provide a detailed empirical study of over 6,000 Java exception stack traces we extracted from over 600 open source Android projects. Key insights from this study include common causes for system crashes, and common chains of wrappings between checked and unchecked exceptions. Furthermore, we provide a survey with 71 developers involved in at least one of the projects analyzed. The results corroborate the stack trace findings, and indicate that developers are unaware of frequently occurring undocumented exception handling behavior\u00a0\u2026", "num_citations": "35\n", "authors": ["146"]}
{"title": "Customer involvement in extreme programming: XP2001 Workshop report\n", "abstract": " This paper covers customer involvement challenges in light-weight software development processes. The report summarizes the presentations and discussions of the Workshop on Customer Involvement held during XP2001, the Second International Conference on Extreme Programming and Flexible Processes in Software Engineering, Cagliari, Italy, May 21, 2001.", "num_citations": "30\n", "authors": ["146"]}
{"title": "Visualisation of domain-specific modelling languages using UML\n", "abstract": " Currently, general-purpose modelling tools are often only used to draw diagrams for the documentation. The introduction of model-driven software development approaches involves the definition of domain-specific modelling languages that allow code generation. Although graphical representations of the involved models are important for documentation, the development of required visualisations and editors is cumbersome. In this paper we propose to extend the typical model-driven approach with the automatic generation of diagrams for documentation. We illustrate the approach using the model driven architecture in the domains of software architecture and control systems", "num_citations": "29\n", "authors": ["146"]}
{"title": "Software engineering for the web: the state of the practice\n", "abstract": " Today\u2019s web applications increasingly rely on client-side code execution. HTML is not just created on the server, but manipulated extensively within the browser through JavaScript code. In this paper, we seek to understand the software engineering implications of this. We look at deviations from many known best practices in such areas of performance, accessibility, and correct structuring of HTML documents. Furthermore, we assess to what extent such deviations manifest themselves through client-side code manipulation only. To answer these questions, we conducted a large scale experiment, involving automated client-enabled crawling of over 4000 web applications, resulting in over 100,000,000 pages analyzed, and close to 1,000,000 unique client-side user interface states. Our findings show that the majority of sites contain a substantial number of problems, making sites unnecessarily slow, inaccessible for\u00a0\u2026", "num_citations": "27\n", "authors": ["146"]}
{"title": "Program plan recognition for year 2000 tools\n", "abstract": " There are many commercial tools that address various aspects of the Year 2000 problem. None of these tools, however, addresses the closely related leap-year problem. In this paper, we provide experimental results that suggest that the leap-year problem can be addressed by plan-based techniques for automated concept recovery. In particular, we provide representative code fragments illustrating the leap-year problem, and we show the results of an empirical study that provides evidence that a plan-based approach can efficiently recognize both correct and incorrect leap-year computations and that the needed plan library is likely to be tractable in size. This paper furthermore argues that plan-based techniques are in fact mature enough to make a significant contribution to the Year 2000 problem itself, despite none of the existing tools making any documented use of these plan-based techniques.", "num_citations": "27\n", "authors": ["146"]}
{"title": "Adopting and evaluating service oriented architecture in industry\n", "abstract": " In this paper, we present a descriptive case study covering the re-engineering and further evolution of adopting service oriented architecture (SOA) in industry. The goal of this case study is to identify the possible benefits and bottlenecks of adopting SOA, as well as to come up with best practices and research directions based on real-life experience gained in IT industry. The case involves an application portfolio of over 700 systems for a company in the transport sector. First, the case study involves the engineering of a portal application involving the integration of various services via the Enterprise Service Bus (ESB). Second, the case study is concerned with the setting up of a central coordination point within the organization to deal with SOA-related integration requests and requirements coming from different business units. Finally, the case discusses the actual implementation and integration of a service through\u00a0\u2026", "num_citations": "24\n", "authors": ["146"]}
{"title": "An initial experiment in reverse engineering aspects\n", "abstract": " We evaluate the benefits of applying aspect-oriented software development techniques in the context of a large-scale industrial embedded software system implementing a number of crosscutting concerns. Additionally, we assess the feasibility of automatically extracting these crosscutting concerns from the source code. In order to achieve this, we present an approach for reverse engineering aspects from an ordinary application automatically. This approach incorporates both a concern verification and an aspect construction phase. Our results show that such automated support is feasible, and can lead to significant improvements in source code quality.", "num_citations": "24\n", "authors": ["146"]}
{"title": "Realizing service migration in industry\u2014lessons learned\n", "abstract": " In this paper, we present two descriptive case studies covering the re\u2010engineering and further evolution of adopting service\u2010oriented architecture (SOA) in the industry. The first case was carried out for a company in the transport sector with an application portfolio of over 700 systems. The second case study was conducted for an organization in the public sector. The goal of both case studies is to identify the possible benefits and drawbacks of realizing SOA in large organizations in order to obtain a better perspective on the real, rather than the assumed, benefits of SOA in practice. We describe how the two cases were developed and carried out, and discuss the experiences gained and lessons learned from adopting SOA in the two organizations. Based on these findings, we propose several directions for further research. Copyright \u00a9 2011 John Wiley & Sons, Ltd.", "num_citations": "23\n", "authors": ["146"]}
{"title": "Software architecture recovery and modelling: [WCRE 2001 discussion forum report]\n", "abstract": " This paper covers current trends and issues in software architecture recovery. It consists of a summary of the presentations and discussions of the Software Architecture Recovery and Modelling discussion forum held during WCRE 2001, the Working Conference on Reverse Engineering, Stuttgart, Germany, October 2, 2001.", "num_citations": "22\n", "authors": ["146"]}
{"title": "ASD: The action semantic description tools\n", "abstract": " Introduction Action Semantics is a framework for describing the semantics of programming languages [6, 9]. One of the main advantages of Action Semantics over other frameworks is that it scales up smoothly to the description of larger practical languages, such as Standard Pascal [7]. An increasing number of researchers and practitioners are starting to use action semantics in preference to other frameworks, eg,[8].The ASD tools include facilities for parsing, syntax-directed (and textual) editing, checking, and interpretation of action semantic descriptions. Such facilities significantly enhance accuracy and productivity when writing large specifications, and are also particularly useful for students learning about the framework. The notation supported by the ASD tools is a direct ASCII representation of the standard notation used for action semantic descriptions in the literature, as defined in [6, Appendices BF].", "num_citations": "22\n", "authors": ["146"]}
{"title": "An algebraic specification for the static semantics of Pascal\n", "abstract": " Over the last few years, several formal speci cations for the static semantics of Pascal have been published. Thus far, however, no algebraic speci cation has been given. In this document we discuss an algebraic speci cation we have made for the complete static semantics of Pascal as de ned by the International Standardization Organization (ISO). We explain how the speci cation has been set up, and how several details have been dealt with in a convenient way. Finally, we relate the speci cation to algebraic speci cations for other aspects of (other) programming languages, and we brie y compare the algebraic approach with the other formal speci cations for Pascal.", "num_citations": "22\n", "authors": ["146"]}
{"title": "Spreadsheet testing in practice\n", "abstract": " Despite being popular end-user tools, spreadsheets suffer from the vulnerability of error-proneness. In software engineering, testing has been proposed as a way to address errors. It is important therefore to know whether spreadsheet users also test, or how do they test and to what extent, especially since most spreadsheet users do not have the training, or experience, of software engineering principles. Towards this end, we conduct a two-phase mixed methods study. First, a qualitative phase, in which we interview 12 spreadsheet users, and second, a quantitative phase, in which we conduct an online survey completed by 72 users. The outcome of the interviews, organized into four different categories, consists of an overview of test practices, perceptions of spreadsheet users about testing, a set of preventive measures for avoiding errors, and an overview of maintenance practices for ensuring correctness of\u00a0\u2026", "num_citations": "19\n", "authors": ["146"]}
{"title": "Model-driven migration of supervisory machine control architectures\n", "abstract": " Supervisory machine control is the high-level control in advanced manufacturing machines that is responsible for the coordination of manufacturing activities. Traditionally, the design of such control systems is based on finite state machines. An alternative, more flexible approach is based on task-resource models. This paper describes an approach for the migration of supervisory machine control architectures towards this alternative approach. We propose a generic migration approach based on model transformations that includes normalisation of legacy architectures before their actual transformation. To this end, we identify a number of key concerns for supervisory machine control and a corresponding normalised design idiom. As such, our migration approach constitutes a series of model transformations, for which we define transformation rules. We illustrate the applicability of this model-driven approach by\u00a0\u2026", "num_citations": "18\n", "authors": ["146"]}
{"title": "Finding classes in legacy code using cluster analysis\n", "abstract": " Old software systems are still in use because they implement useful business tasks. Unfortunately, they are difficult to adapt. They have been subject to maintenance repeatedly, have become less and less comprehensible, and they are closely tied to old technology.To address these problems, much research has been carried out to extract business objects\u2014groups of data and associated operations\u2014from existing systems. These business objects are extracted by inspecting sources, documentation, or by asking the original developers to provide appropriate design information; see, eg,[6, 2] for techniques supporting this process. Once they are extracted, they form the basis for an object-oriented re-implementation of the kernel of the system, a re-implementation which thanks to the object-orientation is far more flexible and easier to adapt. There are three important steps in the extraction of business objects:(1) identification of potential instance variables;(2) identification of potential methods;(3) grouping of variables and methods into classes. In this paper, we concentrate on the third step, for which we propose the use of cluster analysis, a general technique for finding groups in data [4].", "num_citations": "16\n", "authors": ["146"]}
{"title": "Framework for measuring program comprehension\n", "abstract": " Program comprehension is a major human factor in software development. It often makes the difference between success and failure of a software product, because maintenance programmers spend most of their time with understanding code, and because maintenance is the main cost factor in software development. Thus, if program comprehension is not supported properly, time and cost for software development increase significantly.Although program comprehension has such importance, researchers and practitioners do not consider it properly, but use plausibility arguments to claim positive or negative effects on program comprehension. Program comprehension is an internal cognitive process, so we cannot rely on plausibility arguments only, but need to conduct controlled experiments to empirically evaluate what improves and what impairs program comprehension. We believe that one reason for this mismatch between the importance of program comprehension and its insufficient evaluation is the effort of conducting controlled experiments.", "num_citations": "15\n", "authors": ["146"]}
{"title": "A lightweight sanity check for implemented architectures\n", "abstract": " Software architecture has been loosely defined as the organizational structure of a software system, including the components, connectors, constraints, and rationale.1 Evaluating a system's software architecture helps stakeholders to check whether the architecture complies with their interests. Additionally, the evaluation can result in a common understanding of the architecture's strengths and weaknesses. All of this helps to determine which quality criteria the system meets because \"architectures allow or preclude nearly all of the system's quality attributes.\"2", "num_citations": "15\n", "authors": ["146"]}
{"title": "A benchmark-based evaluation of search-based crash reproduction\n", "abstract": " Crash reproduction approaches help developers during debugging by generating a test case that reproduces a given crash. Several solutions have been proposed to automate this task. However, the proposed solutions have been evaluated on a limited number of projects, making comparison difficult. In this paper, we enhance this line of research by proposing JCrashPack, an extensible benchmark for Java crash reproduction, together with ExRunner, a tool to simply and systematically run evaluations. JCrashPack contains 200 stack traces from various Java projects, including industrial open source ones, on which we run an extensive evaluation of EvoCrash, the state-of-the-art tool for search-based crash reproduction. EvoCrash successfully reproduced 43% of the crashes. Furthermore, we observed that reproducing NullPointerException, IllegalArgumentException, and IllegalStateException is relatively\u00a0\u2026", "num_citations": "14\n", "authors": ["146"]}
{"title": "Origin tracking in primitive recursive schemes\n", "abstract": " Algebraic speci cations of programming languages can be used to generate languagespeci c programming support tools. Some of these can be obtained in a straightforward way by executing language speci cations as term rewriting systems. More advanced tools can be obtained if the term rewriting machinery is extended with origin tracking. Origin tracking is a technique which automatically establishes a relation between subterms of the result value (normal form) and their origins, which are subterms of the initial term. For speci cations having a syntax-directed nature, as formalized by the class of so-called primitive recursive schemes, high-quality origins can be established. The de nition, properties, extensions, and implementation of these so-called syntax-directed origins are discussed.", "num_citations": "14\n", "authors": ["146"]}
{"title": "Testing web applications with state objects\n", "abstract": " Use states to drive your tests.", "num_citations": "13\n", "authors": ["146"]}
{"title": "Revisiting the practical use of automated software fault localization techniques\n", "abstract": " In the last two decades, a great amount of effort has been put in researching automated debugging techniques to support developers in the debugging process. However, in a widely cited user study published in 2011, Parnin and Orso found that research in automated debugging techniques made assumptions that do not hold in practice, and suggested four research directions to remedy this: absolute evaluation metrics, result comprehension, ecosystems, and user studies.In this study, we revisit the research directions proposed by the authors, offering an overview of the progress that the research community has made in addressing them since 2011. We observe that new absolute evaluation metrics and result comprehension techniques have been proposed, while research in ecosystems and user studies remains mostly unexplored. We analyze what is hard about these unexplored directions and propose avenues\u00a0\u2026", "num_citations": "12\n", "authors": ["146"]}
{"title": "Professions et m\u00e9tiers interdits: un aspect de l'histoire de la r\u00e9vocation de l'\u00e9dit de Nantes\n", "abstract": " Si nous passons en revue une fois de plus l'ensemble de la situation, il se confirmera en premier lieu que l'Edit de Nantes reconnaissait nettement l'egalite des droits des catholiques et des protestants pour toutes les charges, tous les offices et tous les metiers, dans plusieurs de ses articles, dont a cet egard l'article 27 est le plus important. Jusqu'a 1685, c'est l'Edit de Nantes qui sert de base a toute legislation concemant les huguenots: a moins que ce ne soit expressement precise, les reglements qui s' ecartent de la lettre ou de l'esprit de ce qui a ete ordonne en 1598 sont sans valeur envers l'Edit. C'est parfois exprime et reconnu avec tant de precision, comme daDS l'edit de 1606 concemant l'inspection ecclesiastique des ecoles, que celui-ci ne peut etre applique qu'aux ecoles catholiques, et non a l'ensei-gnement protestant. Parfois, cette reconnaissance fait defaut, comme dans de tres nombreux statuts de\u00a0\u2026", "num_citations": "12\n", "authors": ["146"]}
{"title": "An exploratory study on functional size measurement based on code\n", "abstract": " In this paper we explore opportunities, challenges, and obstacles that Functional Size Measurement (FSM) experts assume to be in automatically derived functional size, directly from the software project code itself. We designed a structured survey, that was answered by 336 FSM specialists. A majority of the respondents consider FSM to be an important tool for decision making. No indications are found for any perceived impact of agile methodology on the difficulty of applying FSM. Respondents overall think of automated FSM as important, but also difficult to realize. 54% of the respondents think that automated FSM will help measurement specialists, while 44% thinks that it will help decision makers too. The most preferred FSM method for automation is COSMIC (25%), followed by IFPUG (21%) and Nesma (16%). Respondents perceive automated FSM to be most suitable for baselining, benchmarking, and\u00a0\u2026", "num_citations": "11\n", "authors": ["146"]}
{"title": "Continuous deployment and schema evolution in SQL databases\n", "abstract": " Continuous Deployment is an important enabler of rapid delivery of business value and early end user feedback. While frequent code deployment is well understood, the impact of frequent change on persistent data is less understood and supported. SQL schema evolutions in particular can make it expensive to deploy a new version, and may even lead to downtime if schema changes can only be applied by blocking operations. In this paper we study the problem of continuous deployment in the presence of database schema evolution in more detail. We identify a number of shortcomings to existing solutions and tools, mostly related to avoidable downtime and support for foreign keys. We propose a novel approach to address these problems, and provide an open source implementation. Initial evaluation suggests the approach is effective and sufficiently efficient.", "num_citations": "11\n", "authors": ["146"]}
{"title": "Using cluster analysis to improve the design of component interfaces\n", "abstract": " For large software systems, interface structure has an important impact on their maintainability and build performance. For example, for complex systems written in C, recompilation due to a change in one central header file can run into hours. In this paper, we explore how automated cluster analysis can be used to refactor interfaces, in order to reduce the number of dependencies and to improve encapsulation, thus improving build performance and maintainability. We implemented our approach in a tool called \"Interface Regroup Wizard\", which we applied to several interfaces of a large industrial embedded system. From this, we not only learned that automated cluster analysis works surprisingly well to improve the design of interfaces, but also which of the refactoring steps are best done manually by an architect.", "num_citations": "11\n", "authors": ["146"]}
{"title": "An adaptive push/pull algorithm for ajax applications\n", "abstract": " Even though the AJAX paradigm helps web applications to become more responsive, AJAX alone does not provide an efficient mechanism for real-time data delivery. Use cases of applications that need such a service include stock tickers, auction sites or chat rooms. The user interface components of these applications must be kept up-to-date with the latest data from the server, and changes should be received immediately. There are two different static approaches used in the industry to provide real-time data delivery: Either the client pulls for the latest data, or the server pushes it to the client. However, such a static approach is not optimal, since both techniques have their own advantages and disadvantages. In this paper we present an adaptive algorithm that combines both solutions in order to increase scalability, network performance and userperceived latency.", "num_citations": "11\n", "authors": ["146"]}
{"title": "Guest editorial: Software reverse engineering\n", "abstract": " Guest editorial: Software reverse engineering: Journal of Systems and Software: Vol 77, No 3 ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Journal of Systems and Software Periodical Home Latest Issue Archive Authors Affiliations Award Winners More HomeBrowse by TitlePeriodicalsJournal of Systems and SoftwareVol. , No. Guest editorial: Software reverse engineering article Guest editorial: Software reverse engineering Share on Authors: Arie Van Deursen profile image Arie van Deursen Department of Software Engineering, CWI, PO Box 94079, 1090 GB Amsterdam, The Netherlands and Faculty of Electrical Engineering, Mathematics, and Computer Science, Delft University of Technology, 4, Delft\u2026", "num_citations": "11\n", "authors": ["146"]}
{"title": "Origin tracking for higher-order term rewriting systems\n", "abstract": " Origin Tracking is a technique which, in the framework of first-order term rewriting systems, establishes relations between each subterm t of a normal form and a set of subterms, the origins of t, in the initial term. Origin tracking is based on the notion of residuals. It has been used successfully for the generation of error handlers and debuggers from algebraic specifications of programming languages. Recent experiments with the use of higher-order algebraic specifications for the definition of programming languages revealed a need to extend origin tracking for higher-order term rewriting systems.             In this paper, we discuss how origin information can be maintained for \u03b1\u03b7 reductions and expansions, during higher-order rewriting. We give a definition of higher-order origin tracking. The suitability of this definition is illustrated with a small, existing specification.", "num_citations": "10\n", "authors": ["146"]}
{"title": "The delta maintainability model: measuring maintainability of fine-grained code changes\n", "abstract": " Existing maintainability models are used to identify technical debt of software systems. Targeting entire codebases, such models lack the ability to determine shortcomings of smaller, fine-grained changes. This paper proposes a new maintainability model - the Delta Maintainability Model (DMM) - to measure fine-grained code changes, such as commits, by adapting and extending the SIG Maintainability Model. DMM categorizes changed lines of code into low and high risk, and then uses the proportion of low risk change to calculate a delta score. The goal of the DMM is twofold: first, producing meaningful and actionable scores; second, compare and rank the maintainability of fine-grained modifications. We report on an initial study of the model, with the goal of understanding if the adapted measurements from the SIG Maintainability Model suit the fine-grained scope of the DMM. In a manual inspection process for\u00a0\u2026", "num_citations": "9\n", "authors": ["146"]}
{"title": "Reconstructing requirements traceability in design and test using latent semantic indexing\n", "abstract": " Managing traceability data is an important aspect of the software development process. In this paper we define a methodology, consisting of six steps, for reconstructing requirements views using traceability data. One of the steps concerns the reconstruction of the traceability data. We investigate to what extent Latent Semantic Indexing (LSI), an information retrieval technique, can help recovering the information needed for automatically reconstructing traceability of requirements during the development process. We experiment with different link selection strategies and apply LSI in multiple case studies varying in size and context. We discuss the results of a small lab study, a larger case study and a large industrial case study.", "num_citations": "9\n", "authors": ["146"]}
{"title": "Sort-based refactoring of crosscutting concerns to aspects\n", "abstract": " Crosscutting concerns in object-oriented programming hinder evolution because of their symptoms: tangling and scattering. To benefit from the modularisation capabilities for crosscutting concerns provided by aspect-oriented programming (which prevent tangling and scattering) aspect-introducing refactoring can be used. The first step in aspect-introducing refactoring is identifying and documenting crosscutting concerns in existing code. The second step is refactoring the identified concerns to aspects.", "num_citations": "8\n", "authors": ["146"]}
{"title": "Software architecture reconstruction\n", "abstract": " Architecture reconstruction is the reverse engineering process that aims at recovering the past design decisions that have been made about the software architecture of a system. To be a successful activity, we need to identify the proper architecturally significant information and to extract it from the artefacts. How to identify extract/present/analyse it? What are the critical issues that have to be considered? How to manage the reconstruction process in a product family? What tools are available? This paper will address these and other questions that are relevant for the development of large and complex software systems. We introduce the key concepts of a software architecture description and the context of the architecture reconstruction activity. We present our architecture reconstruction method with a strong emphasis on its practical aspects and the tools supporting it. The extraction of architecturally significant\u00a0\u2026", "num_citations": "8\n", "authors": ["146"]}
{"title": "From legacy to component: Software renovation in three steps\n", "abstract": " The major challenge for future business operations is to align changing business goals and changing technologies, while preserving the assets that are hidden in the legacy systems supporting today\u2019s business operations. In this paper we formulate the main questions system renovation has to solve, and we give a comprehensive overview of techniques and approaches. We discuss the analysis and transformation of legacy systems and also describe how domain engineering can help to identify reusable domain knowledge. By stressing the need for cooperation between renovated software and new software we naturally arrive at the need for component-based approaches and coordination architectures that define the cooperation between old and new components. We present a three step approach to system renovation: find components, global restructuring, and renovate per component. The necessary techniques for analysis, transformation, and regeneration of legacy systems are also discussed. The paper concludes with a description of domain engineering and domain-specific languages as viable techniques for the structuring and reuse of the application domain knowledge that is embedded in legacy systems.", "num_citations": "8\n", "authors": ["146"]}
{"title": "Validating year 2000 compliance\n", "abstract": " Validating year 2000 compliance involves the assessment of the correctness and quality of a year 2000 conversion. This entails inspecting both the quality of the conversion process followed, and of the result obtained, ie, the converted system. This document provides an overview of the techniques that can be used to validate year 2000 compliance. It includes typical code fragments, and a discussion of existing technology, impact analysis, solution strategies, code correction, testing, and tools.", "num_citations": "8\n", "authors": ["146"]}
{"title": "Beyond Page Objects: Testing Web Applications with State Objects: Use states to drive your tests\n", "abstract": " End-to-end testing of Web applications typically involves tricky interactions with Web pages by means of a framework such as Selenium WebDriver. The recommended method for hiding such Web-page intricacies is to use page objects, but there are questions to answer first: Which page objects should you create when testing Web applications? What actions should you include in a page object? Which test scenarios should you specify, given your page objects?", "num_citations": "7\n", "authors": ["146"]}
{"title": "Migrating a domain-specific modeling language to MDA technology\n", "abstract": " Migrating a domain-specific modeling language to MDA technology (2006) | www.narcis.nl KNAW KNAW Narcis Back to search results CWI Publication Migrating a domain-specific modeling language to MDA technology (2006) Pagina-navigatie: Main Save publication Save as MODS Export to Mendeley Save as EndNote Export to RefWorks Title Migrating a domain-specific modeling language to MDA technology Author D. Doyle; H. Geers; B. Graaf; A. van Deursen (Arie) Supporting host Software Analysis and Transformation Date issued 2006-01-01 Access Closed Access Language English Type Conference Paper Publisher Mainz University Publication https://ir.cwi.nl/pub/14260 OpenURL Search this publication in (your) library Persistent Identifier urn:NBN:nl:ui:18-14260 Metadata XML Source CWI Go to Website Navigation: Home about narcis login Nederlands contact Anna van Saksenlaan 51 2593 HW Den @..\u2026", "num_citations": "7\n", "authors": ["146"]}
{"title": "Origin tracking and its applications\n", "abstract": " Algebraic specifications of programming languages can be used to generate language-specific programming support tools. Tools can be obtained by executing these specifications as term rewriting systems. More advanced tools can be constructed if the term rewriting machinery is extended with origin tracking. Origin tracking is a technique which automatically establishes a relation between subterms of a result (normal form) or intermediate value, and their so-called origins, which are subterms of the initial term. Origin tracking can be used to associate positional information with messages in error reports, to visualize program execution, and to construct language-specific debuggers. This chapter gives detailed presentations of the definition, implementation, and applications of origin tracking.", "num_citations": "7\n", "authors": ["146"]}
{"title": "Introducing ASF+ SDF Using the-calculus as Example\n", "abstract": " This document aims at providing a gentle introduction to the use of ASF+ SDF. Asf+ Sdf is an algebraic speci cation formalism that can be used to specify properties of languages or data types. Using the translator of Asf+ Sdf to LaTEX, a documented de nition of a language de nition or data type can be obtained. Moreover, the speci cations can be executed by the Asf+ Sdf Meta-environment, a system that can generate prototype environments used to experiment with the speci ed objects. Rather than just listing the features of Asf+ Sdf, we illustrate its use by discussing a small example. Our example is the-calculus, which is (i) concise enough to be presented completely,(ii) su ciently well-known to be understood easily,(iii) nevertheless nontrivial, and (iv) useful in practice (indeed, the generated environment has been used to teach the-calculus).", "num_citations": "7\n", "authors": ["146"]}
{"title": "Evaluating automatic spreadsheet metadata extraction on a large set of responses from mooc participants\n", "abstract": " Spreadsheets are popular end-user computing applications and one reason behind their popularity is that they offer a large degree of freedom to their users regarding the way they can structure their data. However, this flexibility also makes spreadsheets difficult to understand. Textual documentation can address this issue, yet for supporting automatic generation of textual documentation, an important pre-requisite is to extract metadata inside spreadsheets. It is a challenge though, to distinguish between data and metadata due to the lack of universally accepted structural patterns in spreadsheets. Two existing approaches for automatic extraction of spreadsheet metadata were not evaluated on large datasets consisting of user inputs. Hence in this paper, we describe the collection of a large number of user responses regarding identification of spreadsheet metadata from participants of a MOOC. We describe the use\u00a0\u2026", "num_citations": "6\n", "authors": ["146"]}
{"title": "Think Twice Before Using the \u201cMaintainability Index\u201d\n", "abstract": " The Maintainability Index was introduced at the International Conference on Software Maintenance in 1992. To date, it is included in Visual Studio (since 2007), in the recent (2012) JSComplexity and Radon metrics reporters for Javascript and Python, and in older metric tool suites such as verifysoft.", "num_citations": "6\n", "authors": ["146"]}
{"title": "Managing clones using dynamic change tracking and resolution\n", "abstract": " Session 1 Industrial experience and practical application of dynamic analysis approaches Page 1 Managing Clones Using Dynamic Change Tracking and Resolution Michiel de Wit Andy Zaidman Arie van Deursen Page 2 Taking over Copy & Paste Replace copy & paste by \u201cclone-aware\u201d operations: \u2022 Move \u2022 Copy-identical \u2022 Copy-and-change \u2022 Copy-once \u2013 [ was: paste ] 2 ZA Mann, IEEE Computer, 2006 Page 3 Our Research Questions 1. Are developers willing to alter existing copy and paste habits? 2. In what way can the relations established by using explicit clone operators be used to enforce consistent editing of clones? 3. Will the new operators help reduce problems related to cloning? 3 Page 4 The CloneBoard Prototype \u2022 Eclipse plug-in intercepting copy and paste \u2022 Detects & resolves inconsistent changes to clones \u2013 Several resolution strategies \u2013 User can select strategy \u2013 Plug-in offers strategy ranking \u2022 \u201e/\u2026", "num_citations": "6\n", "authors": ["146"]}
{"title": "Using MDE for generic comparison of views\n", "abstract": " We investigate the application of technologies for modeldriven engineering to check the conformance of two software models. This involves their model-based comparison, and visualisation of the results. To generalise our approach we use reflection, metamodel generalisation, and higher-order transformations. We apply our approach to assess the extent to which the implementation of an academic example system does not violate the constraints defined by its architecture specification.", "num_citations": "6\n", "authors": ["146"]}
{"title": "Asf+ Sdf'95: a workshop on Generating Tools from Algebraic Specifications\n", "abstract": " Asf+Sdf'95: a workshop on Generating Tools from Algebraic Specifications University of Amsterdam University of Amsterdam UvA Terms of use Contact UvA-DARE (Digital Academic Repository) Home Advanced Search Browse My selection Search UvA-DARE Author MGJ van den Brand A. van Deursen TB Dinesh JFTh. Kamperman E. Visser [Unknown] (editors) Year 1995 Title Asf+Sdf'95: a workshop on Generating Tools from Algebraic Specifications Publisher CWI Series Technical Report, P9504 Document type Report Faculty Faculty of Science (FNWI) Institute Informatics Institute (IVI) Language Undefined/Unknown Persistent Identifier https://hdl.handle.net/11245/1.118070 Disclaimer/Complaints regulations If you believe that digital publication of certain material infringes any of your rights or (privacy) interests, please let the Library know, stating your reasons. In case of a legitimate complaint, the Library will the /. \u2026", "num_citations": "6\n", "authors": ["146"]}
{"title": "Executing Action Semantic Descriptions using ASF+ SDF\n", "abstract": " Action Semantics is a framework for describing the semantics of programming languages [3]. It is based on:                                                                Action Notation, used for expressing so-called actions, which represent the semantics of programming constructs; and                                                                                  Unified Algebras, used for specifying the data processed by actions, as well as for defining the abstract syntax and semantic functions for particular programming languages, and the symbols used in Action Notation.", "num_citations": "6\n", "authors": ["146"]}
{"title": "AI lifecycle models need to be revised\n", "abstract": " Tech-leading organizations are embracing the forthcoming artificial intelligence revolution. Intelligent systems are replacing and cooperating with traditional software components. Thus, the same development processes and standards in software engineering ought to be complied in artificial intelligence systems. This study aims to understand the processes by which artificial intelligence-based systems are developed and how state-of-the-art lifecycle models fit the current needs of the industry. We conducted an exploratory case study at ING, a global bank with a strong European base. We interviewed 17 people with different roles and from different departments within the organization. We have found that the following stages have been overlooked by previous lifecycle models: data collection, feasibility study, documentation, model monitoring, and model risk assessment. Our work shows that the real\u00a0\u2026", "num_citations": "5\n", "authors": ["146"]}
{"title": "Pricing via functional size-a case study of a company's portfolio of 77 outsourced projects\n", "abstract": " A medium-sized west-European telecom company experienced a worsening trend in performance, indicating that the organization did not learn from history, in combination with much time and energy spent on preparation and review of project proposals. In order to create more transparency in the supplier proposal process a pilot was started on Functional Size Measurement pricing (FSM-pricing). In this paper we evaluate the implementation of FSM-pricing in the software engineering domain of the company, as an instrument useful in the context of software management and supplier proposal pricing. We analyzed 77 finalized software engineering projects, covering 14 million Euro project cost and a project portfolio size of more than 5,000 function points. We found that a statistical, evidence-based pricing approach for software engineering, as a single instrument (without a connection with expert judgment), can be\u00a0\u2026", "num_citations": "5\n", "authors": ["146"]}
{"title": "Learning from Apple's# gotofail security bug\n", "abstract": " Yesterday, Apple announced iOS7. 0.6, a critical security update for iOS7\u2014and an update for OSX/Safari is likely to follow soon (if you haven\u2019t updated iOS yet, do it now).", "num_citations": "5\n", "authors": ["146"]}
{"title": "Migrating supervisory control architectures using model transformations\n", "abstract": " Migrating Supervisory Control Architectures Using Model Transformations \u2014 TU Delft Research Portal Skip to main navigation Skip to search Skip to main content TU Delft Research Portal Logo Help & FAQ Home Researchers Research Units Research output Activities Datasets Press / Media Prizes Projects Search by expertise, name or affiliation Migrating Supervisory Control Architectures Using Model Transformations B van der Graaf, S Weber, A van Deursen Software Engineering Research output: Chapter in Book/Conference proceedings/Edited volume \u203a Conference contribution \u203a Scientific \u203a peer-review 3 Citations (Scopus) Overview Original language Undefined/Unknown Title of host publication Proceedings of the 10th European Conference on Software Maintenance and Reengineering (CSMR 2006) Editors Giuseppe Visaggio, Giuseppe A Lucca, Nicolas Gold Publisher IEEE Pages 151-160 Number of 10 - .\u2026", "num_citations": "5\n", "authors": ["146"]}
{"title": "Test-driven development and software maintenance\n", "abstract": " Test-driven development is a relatively new approach to software engineering, involving the iterative construction of test cases first, and then the application code that passes the test cases second. This panel session will discuss the impacts of test-driven development on long-term software maintenance costs. The panelists represent different research disciplines related to this topic, including software maintenance, software testing, program redocumentation, program understanding, and empirical studies.", "num_citations": "5\n", "authors": ["146"]}
{"title": "The leap year problem\n", "abstract": " A significant number of programs incorrectly treats the year 2000 as a non-leap year. We list 21 real life code fragments illustrating the large variety of ways that are used to determine whether a given year is a leap year or not. Some of these fragments are correct; others will fail in the year 2000. The fragments are written in C, Pascal, COBOL, and assembly language. We discuss the consequences for automated tool support, as well as the organizational implications of the leap year problem.", "num_citations": "5\n", "authors": ["146"]}
{"title": "Incremental typechecking\n", "abstract": " We present a technique for deriving incremental implementations for a subclass of algebraic specifications, namely, well-presented primitive recursive schemes with parameters, a class well suited for specifying the static semantics of languages. We introduce a concept adapted from the translation of well-presented primitive recursive schemes to strongly non-circular attribute grammars, and store results of function applications and their parameters as attributes in an abstract syntax tree of the first argument of the function in question. An attribute dependency graph is then used to control incremental evaluation. The evaluation technique is based on a leftmost innermost rewrite strategy. Moreover, we present optimizations to handle updates in the declarations section of a program in an efficient incremental fashion. The method has been implemented as part of the rewrite engine of the ASF+SDF Meta-Environment.", "num_citations": "5\n", "authors": ["146"]}
{"title": "Second-order term rewriting specification of static semantics: An exercise\n", "abstract": " The static semantics of the simple programming language Pico is expressed using second-order rewrite rules in addition to first-order ones. The specification has a highly non-deterministic character and does not use a type environment. Furthermore, it supports error recovery and the early detection of errors in incomplete programs.", "num_citations": "5\n", "authors": ["146"]}
{"title": "Typechecking with modular error handling\n", "abstract": " Static semantics only determines the validity of a program but is not concerned with the pragmatic issues such as the location in the program where a violation of the static semantics occurred or even a textual explanation of the cause of that violation. A typechecker extends the specification of static semantics with facilities for identifying and presenting the type errors in invalid programs. We discuss a style of algebraically specifying the static semantics of a language which facilitates the automatic generation of a typechecker and a language specific error reporter. Such a specification can also be extended in a modular manner to yield human-readable error messages.", "num_citations": "5\n", "authors": ["146"]}
{"title": "Specification and Generation of a Lambda-calculus Environment\n", "abstract": " #))\"!#% $ & n'!)(1 2 H 134 (w 3& w 5 7 93} A@ A3 7 B! r 7 C $ D FE C34 (G (H3PIQ (B 7 93} $ f) C w HRT SU) V! F 3f)() $ p W3} C $ & w FE 234 (\" G (H3PIQ (u 3& w X!# 2$ &3T (C $ & $}YAacbAYAda fgUhpiVq8rtsu v@ A3} 7 ww w (u 2$ & $} 1 6YAa bxYAda y fi $ &3 ch (u 2) CE $} 2! 3&@ A3} 0 3p 8 (3} yy C A3 G (v3p w! r 6YAa bAYAd6a G (H3PIQ (u 3& w HR 3& $} v3} 1 X#@\" y5 $ H ed7f g2d7hCijilk m8g5 nohCmxg2p htgxqs rut fCdHvT hCm x1izyQ {&q| i} qHm hCuk Exy) t $ c v Tf) q d 1 j3T 1 G (H3P! y 1 (u C $4 (H z (u 1 93} R w v F@ n) C H 1 H (73D y 13& B! z (u C $4 (H 1R h) 2 H 1 V (HC@ 3} 9$} 3& w w 2! i w (C $4 (H $ &) A@ A3} G w 3T 3 2! 8$ T s) 73} z3p v@ 3& w 8$! f 7 h 9 Y v (3& w A $} 7 (y\" w oR 3T) C! p 3&@ w 2$ & FE C34 (s\" G (H3PIQ (u 3& w 2!(u 2 $4 (H $ &)34 (1) H 1 1 Hv! r yy 2$ & $ &! 3}\" xf~ rysxBzC g~ cx) cy\" s~# gw kv k~# n gw2w ky ry\" k k dd vQ k~ u G dhx1 ry d~ xf uy g~# g~ xfw9w y {~ v xf s~# gws k k dfzsxB~# y@ x1 ry g g~ u F ry\"@ xfu k~ u#\" & vy d~# g w~~ x1 ry z u dhxf ry~# hxfw2w2y {y {~ d d~ g\"\" gw z\" khxBy {Q ny@ x1 ry uw! xBz {y w xf hx1 y ry grw x@ z {y w u uy g", "num_citations": "5\n", "authors": ["146"]}
{"title": "A theoretical and empirical analysis of program spectra diagnosability\n", "abstract": " Current metrics for assessing the adequacy of a test-suite plainly focus on the number of components (be it lines, branches, paths) covered by the suite, but do not explicitly check how the tests actually exercise these components and whether they provide enough information so that spectrum-based fault localization techniques can perform accurate fault isolation. We propose a metric, called, aimed at complementing adequacy measurements by quantifying a test-suite's diagnosability, i.e., the effectiveness of applying spectrum-based fault localization to pinpoint faults in the code in the event of test failures. Our aim is to increase the value generated by creating thorough test-suites, so they are not only regarded as error detection mechanisms but also as effective diagnostic aids that help widely-used fault-localization techniques to accurately pinpoint the location of bugs in the system. We have performed a topology\u00a0\u2026", "num_citations": "4\n", "authors": ["146"]}
{"title": "Recovering rationale\n", "abstract": " Several approaches to architecture recovery are based on the notion of a system browser, which provides different linked views at various levels of abstraction of the legacy system [4, 5, 1]. In order to understand rationale, the original documentation, comments, and the problem tracking and version control remarks can be included in such a system browser. Moreover, some link insertion technique can be used to make the relationships between keywords in these texts and other concepts of the legacy system explicit.", "num_citations": "4\n", "authors": ["146"]}
{"title": "Customer Involvement Experiences in a Software Product Line\n", "abstract": " Background We cover challenges experienced and lessons learned concerning an XP product development and customization project. Some characteristics of this project are:", "num_citations": "4\n", "authors": ["146"]}
{"title": "The ASF+ SDF meta-environment\n", "abstract": " Algebraic specifications facilitate formal reasoning about software, in addition to providing means for rapid prototyping [2]. In particular, specifying various aspects of a programming language provides tools which can be part of a programming environment for the language. In Amsterdam, at CWI and UvA, the GIPE1 group has been investigating tool generation from algebraic specifications. Thus far, this has resulted in:                                         An algebraic specification formalism, ASF+SDF, especially designed for defining the syntax and semantics of programming languages [2, 6];                                                           The ASF+SDF tool generator, deriving parsers and term rewriting machines from algebraic specifications [7];                                                           The ASF+SDF Meta-environment, giving support when developing ASF+SDF specifications [7].", "num_citations": "4\n", "authors": ["146"]}
{"title": "Migrating supervisory control architectures using model transformations\n", "abstract": " This paper describes an approach for the migration of supervisory machine control architectures. This migration, from a paradigm based on finite-state machines to a paradigm based on task-resource systems, is described in terms of model transformations. We propose a generic migration approach that involves normalising a legacy architecture that, in turn, is transformed. Based on the architecture of a controller of a complex manufacturing machine, a wafer scanner developed by ASML, we define a number of concerns and corresponding architectural transformation rules", "num_citations": "3\n", "authors": ["146"]}
{"title": "Isolating crosscutting concerns in system software\n", "abstract": " This paper reports upon our experience in automatically migrating the crosscutting concerns of a large-scale software system, written in C, to an aspect-oriented implementation. We zoom in on one particular crosscutting concern, and show how detailed information about it is extracted from the source code, and how this information enables us to characterise this code and define an appropriate aspect automatically. Additionally, we compare the already existing solution to the aspect-oriented solution, and discuss advantages as well as disadvantages of both in terms of selected quality attributes. Our results show that automated migration is feasible, and can lead to significant improvements in source code quality.", "num_citations": "3\n", "authors": ["146"]}
{"title": "Understanding Legacy Architectures\n", "abstract": " This paper looks at architecture from the perspective of legacy systems. Legacy systems generally do not have a documented architecture, which complicates dealing with many of the problems pertaining to legacy systems. Extracting architectural structures from a legacy system and presenting them in a coherent hypertext framework can provide the architectural understanding needed to deal with these problems. A starting point is to compare the development view present in naming conventions with the logical view that can be extracted from the source. Component interfaces can be described using types extracted from the source; Novel componentizations can be obtained using grouping techniques such as cluster and concept analysis. The various architectural structures studied are illustrated using several example mainframe-based legacy systems.", "num_citations": "3\n", "authors": ["146"]}
{"title": "A comparison of Software Refinery and ASF+ SDF\n", "abstract": " Software Re nery is a tool for building tools for analyzing and modifying software automatically. The tools can either be built directly using Renery, or as an extension of one of the Re ne Language Tools such as Re ne/COBOL or Re ne/2000.Typical application areas are those where existing tools are not available or not satisfactory. Examples include systems built using proprietary languages or sitespeci c dialects of COBOL, systems requiring special year 2000 modi cations or special forms of global analysis, etc. To build such re-engineering tools, Software Renery uses the Re ne Language for programming such tools. The language features set-theoretic operations, logic, lisp-like symbols, objects and inheritance, grammar de nitions, and the use of concrete syntax for doing pattern matching. Users of Software Re nery can bene t from a large number of well-documented API's (Application Programming Interface). Re ne/COBOL gives access to (various dialects of) COBOL; Re ne/Workbench provides data structures and functions for building control ow graphs, structure charts, and coding standards reports; Rene/2000 provides functions for tracing date-related variables and modifying incorrect date operations.", "num_citations": "3\n", "authors": ["146"]}
{"title": "Software Quality and Testing\n", "abstract": " You will apply the different testing techniques we teach to a simple game called JPACMAN, inspired by Pacman and written in Java. The amount of coding that needs to be done is relatively small: the focus is on testing.", "num_citations": "2\n", "authors": ["146"]}
{"title": "Teaching software architecture: With GitHub\n", "abstract": " When teaching software architecture it is hard to strike the right balance between practice (learning how to work with real systems and painful trade offs) and theory (general solutions that any architect needs to thoroughly understand).", "num_citations": "2\n", "authors": ["146"]}
{"title": "Migrating a domain-specific modeling infrastructure to MDA technology\n", "abstract": " For many companies, legacy applications developed using a modeldriven approach based on (proprietary) domain-specific modeling languages (DSML\u2019s) form an important asset, as they implement key business functionality. Unfortunately, if the underlying infrastructure comprising code generators, libraries, and model repositories fails to meet new demands of, eg, modern web applications, the original benefits of the model-driven DSML approach can turn into a significant drawback.To remedy this, we explore how models specified with a proprietary DSML in use at a large financial services company can be migrated to models conform the MDA, in order to benefit from the range of MDA standards. We describe the legacy model-driven engineering infrastructure, propose a migration approach, discuss how we implemented each migration step using metamodeling and transformation activities, and offer an analysis of the lessons learned.", "num_citations": "2\n", "authors": ["146"]}
{"title": "De software-evolutieparadox\n", "abstract": " De software-evolutieparadox (2005) | www.narcis.nl KNAW KNAW Narcis Back to search results CWI Publication De software-evolutieparadox (2005) Open access . Pagina-navigatie: Main Save publication Save as MODS Export to Mendeley Save as EndNote Export to RefWorks Title De software-evolutieparadox Author A. van Deursen (Arie) Supporting host Software Analysis and Transformation Date issued 2005-01-01 Access Open Access Language Dutch Type Lecture Publication https://ir.cwi.nl/pub/23507 Persistent Identifier urn:NBN:nl:ui:18-23507 Metadata XML Source CWI Go to Website Navigation: Home about narcis login Nederlands contact Anna van Saksenlaan 51 2593 HW Den Haag narcis@dans.knaw.nl More >>> Youtube Newsletter >>> Privacy statement >>> Disclaimer >>> DANS is an institute of KNAW and NWO Go to page top Go back to contents Go back to site navigation \u2026", "num_citations": "2\n", "authors": ["146"]}
{"title": "How should software evolution and maintenance be taught?\n", "abstract": " The IEEE/ACM CCSE initiative to propose guidelines for an undergraduate program in software engineering provides an opportunity to rethink the role of software maintenance and evolution in software engineering curricula. The purpose of this panel is to share experiences and discuss novel ways in which evolution and maintenance can be incorporated in an undergraduate software engineering curriculum.", "num_citations": "2\n", "authors": ["146"]}
{"title": "The static semantics of pascal\n", "abstract": " One of the purposes of the ASF+SDF formalism is to simplify the specification of realistic programming languages. In this case study, we describe and evaluate an ASF+SDF specification of the complete static semantics of ISO Pascal. We propose a general layout for specifying typecheckers for large languages. Moreover, we discuss how the syntactic freedom of ASF+SDF can be used to create an easy-to-read description of the static semantics of Pascal that stays as close as possible to the ISO definition.", "num_citations": "2\n", "authors": ["146"]}
{"title": "Perceived relevance of automatic code inspection in end-user development: A study on VBA\n", "abstract": " Microsoft VBA (Visual Basic for Applications) is a programming language widely used by end-user programmers, often alongside the popular spreadsheet software Excel. Together they form the popular Excel-VBA application ecosystem. Despite being popular, spreadsheets are known to be fault-prone, and to minimize risk of faults in the overall Excel-VBA ecosystem, it is important to support end-user programmers in improving the code quality of their VBA programs also, in addition to improving spreadsheet technology and practices. In traditional software development, automatic code inspection using static analysis tools has been found effective in improving code quality, but the practical relevance of this technique in an end-user development context remains unexplored. With the aim of popularizing it in the end-user community, in this paper we examine the relevance of automatic code inspection in terms of how\u00a0\u2026", "num_citations": "1\n", "authors": ["146"]}
{"title": "Software engineering without borders\n", "abstract": " DevOps approaches software engineering by advocating the removal of borders between development and operations. DevOps emphasizes operational resilience, continuous feedback from operations back to development, and rapid deployment of features developed. In this talk we will look at selected (automation) aspects related to DevOps, based on our collaborations with various industrial partners. For example, we will explore (automated) methods for analyzing log data to support deployments and monitor REST API integrations,(search-based) test input generation for reproducing crashes and testing complex database queries, and zero downtime database schema evolution and deployment. We will close by looking at borders beyond those between development and operations, in order to see whether there are other borders we need to remove in order to strengthen the impact of software engineering\u00a0\u2026", "num_citations": "1\n", "authors": ["146"]}
{"title": "Workshop report from Web2SE 2011: 2nd international workshop on web 2.0 for software engineering\n", "abstract": " Web 2.0 technologies, such as wikis, blogs, tags and feeds, have been adopted and adapted by software engineers. With the annual Web2SE workshop, we provide a venue for research on Web 2.0 for software engineering by highlighting state-of-the-art work, identifying current research areas, discussing implications of Web 2.0 on software engineering, and outlining the risks and challenges for researchers. This report highlights the paper and tool presentations, and the discussions among participants at Web2SE 2011 in Honolulu, as well as future directions of the Web2SE workshop community.", "num_citations": "1\n", "authors": ["146"]}
{"title": "What your IDE could do once you understand your code.\n", "abstract": " What your IDE could do once you understand your code Page 1 What your IDE could do once you understand your code Arie van Deursen Delft University of Technology 1 Questions & Directions Page 2 Acknowledgments \u2022 WSE & VISSOFT Organizers \u2022 Members of the TU Delft Software Engineering Research Group, including \u2013 Ali Mesbah, Bas Cornelissen, Andy Zaidman, Martin Pinzger, Rini van Solingen, Cor-Paul Bezemer, \u2026 \u2022 Additional collaborators, including \u2013 Leon Moonen, Rainer Koschke, Danny Holten, Jack van Wijk, Bart van Rompaey, \u2026 \u2022 flickr photos from faisco, elizabethsalib, andywon 2 Page 3 Today\u2019s Structure \u2022 Part I \u2013 What\u2019s the problem? Documenting understanding \u2022 Part II \u2013 Solution direction: Web 2.0? \u2022 Part III \u2013 Evaluation: Begin with the end in mind \u2022 Part IV \u2013 Conclusions: Towards a Knowledgeable IDE 3 Page 4 4 Andreas Zeller: The Future of Programming Environments: Integration, , . : -. \u2026", "num_citations": "1\n", "authors": ["146"]}
{"title": "A model of maintainability-Suggestion for future research\n", "abstract": " A model of maintainability - Suggestion for future research (2006) | www.narcis.nl KNAW KNAW Narcis Back to search results CWI Publication A model of maintainability - Suggestion for future research (2006) Pagina-navigatie: Main Save publication Save as MODS Export to Mendeley Save as EndNote Export to RefWorks Title A model of maintainability - Suggestion for future research Author A. van Deursen (Arie); not CWI et al Editor HR Arabnia; not CWI et al Supporting host Software Analysis and Transformation Date issued 2006-01-01 Access Closed Access Language English Type Conference Paper Publisher CSREA Press Publication https://ir.cwi.nl/pub/14271 OpenURL Search this publication in (your) library Persistent Identifier urn:NBN:nl:ui:18-14271 Metadata XML Source CWI Go to Website Navigation: Home about narcis login Nederlands contact Anna van Saksenlaan 51 2593 HW Den Haag narcis@..>\u2026", "num_citations": "1\n", "authors": ["146"]}
{"title": "Omgaan met veranderende requirements in outsourcing-projecten\n", "abstract": " Dit artikel beschrijft de ervaringen opgedaan bij het opzetten van een requirements-managementsysteem. We beschouwen met name de problemen bij het consistent beheren van de requirements in geval van gedistribueerde ontwikkeling.", "num_citations": "1\n", "authors": ["146"]}
{"title": "The missing links\n", "abstract": " The missing links University of Amsterdam University of Amsterdam UvA Terms of use Contact UvA-DARE (Digital Academic Repository) Home Advanced Search Browse My selection Search UvA-DARE Author MGJ van den Brand Year 1997 Title The missing links Book title Dat Is Dus Heel Interessant, Liber Amicorum dedicated to Paul Klint Pages (from-to) 55-60 Publisher Amsterdam: CWI Document type Chapter Faculty Faculty of Science (FNWI) Institute Informatics Institute (IVI) Language Undefined/Unknown Persistent Identifier https://hdl.handle.net/11245/1.135587 Disclaimer/Complaints regulations If you believe that digital publication of certain material infringes any of your rights or (privacy) interests, please let the Library know, stating your reasons. In case of a legitimate complaint, the Library will make the material inaccessible and/or remove it from the website. Please Ask the Library, or send a letter to: of of \u2026", "num_citations": "1\n", "authors": ["146"]}
{"title": "Het jaar-2000-probleem\n", "abstract": " Op veel computersystemen draait programmatuur die datumgegevens uit het jaar 2000 incorrect afhandelt. Worden deze fouten niet verholpen, zullen zich de meest uiteenlopende computerstoringen voordoen. De reparatie ervan wordt bemoeilijkt door de omvang van het probleem en het gebrek aan automatiseringspersoneel. In deze bijdrage bespreken we de informatica-technische aspecten van het jaar-2000-probleem, zoals de oorzaken, gevolgen, oplossingsmogelijkheden, en projectinrichting. Doel van de bijdrage is het ondersteunen van de discussie over de juridische vragen rond het jaar-2000-probleem.", "num_citations": "1\n", "authors": ["146"]}
{"title": "A kernel object-oriented language\n", "abstract": " \u039aOOL, a kernel object-oriented language, is described and its dynamic and static semantics are given in ASF+SDF. \u03baOOL is a language with update-able self, with non-strict argument evaluation, and without alias-able state. The specification of its static semantics is derived from its dynamic semantics. This is achieved by taking a copy of the dynamic semantics as starting point and by systematically replacing concrete domain values by more abstract ones. This derivation is aided by the typechecker of the ASF+SDF Meta-Environment, since the type errors reported in the altered specification lead the specifier to accordingly modify the specification of dynamic semantics into a specification of static semantics. Justifying these modifications is easy and feasible in practice. The resulting specification is then extended, in a modular manner, into a typechecker specification.", "num_citations": "1\n", "authors": ["146"]}
{"title": "Origin Tracking.\n", "abstract": " Origin Tracking. | Guide books ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleReportsOrigin Tracking. ABSTRACT No abstract available. Comments Login options Check if you have access through your login credentials or your institution to get full access on this article. Sign in Full Access Get this Publication Information Contributors Published in Guide books cover image Origin Tracking. December 1992 Authors: Arie van Deursen profile image Arie Deursen , Paul Klint profile image Paul Klint, Frank Tip profile image Frank Tip Copyright \u00a9 1992 Publisher CWI (Centre for Mathematics and Computer Science) Netherlands Publication : - \u2026", "num_citations": "1\n", "authors": ["146"]}
{"title": "Product line evolution using source packages\n", "abstract": " We present a language-independent approach for product line initiation and evolution. Our approach is based on a decomposition of a product line into packages. These packages constitute the build time variation points of the product line. They can be configured, selected, combined, and extended in order to yield tailormade products for individual customers.In order to reduce initial investment involved in product line adoption, we propose an incremental method for designing the product line package structure. At each iteration, we analyze the variability required by the existing and currently anticipated products, and we recover the variability offered by the actual product line implementation, Given these two, we design a target package decomposition offering the required variability, as well as a migration path to arrive at this target from the current product line implementation. The proposed approach is illustrated using a commercial product line in the area of documentation generation for legacy systems.", "num_citations": "1\n", "authors": ["146"]}