{"title": "Machine learning techniques and chi-square feature selection for cancer classification using SAGE gene expression profiles\n", "abstract": " Recently developed Serial Analysis of Gene Expression (SAGE) technology enables us to simultaneously quantify the expression levels of tens of thousands of genes in a population of cells. SAGE is better than Microarray in that SAGE can monitor both known and unknown genes while Microarray can only measure known genes. SAGE gene expression profiling based cancer classification is a better choice since cancers may be due to some unknown genes. Whereas a wide range of methods has been applied to traditional Microarray based cancer classification, relatively few studies have been done on SAGE based cancer classification. In our study we evaluate popular machine learning methods (SVM, Naive Bayes, Nearest Neighbor, C4.5 and RIPPER) for classifying cancers based on SAGE data. In order to deal with the high dimensional problem, we propose to use Chi-square for tag/gene selection\u00a0\u2026", "num_citations": "195\n", "authors": ["430"]}
{"title": "Normalized distance, similarity measure, inclusion measure and entropy of interval-valued fuzzy sets and their relationship\n", "abstract": " In this paper, we introduce an axiomatic definition of an interval-valued fuzzy sets\u2019 inclusion measure which is different from Bustince\u2019s [H. Bustince, Indicator of inclusion grade for interval-valued fuzzy sets, Applications to approximate reasoning based on interval-valued fuzzy sets, International Journal of Approximate Reasoning, 23 (2000) 137\u2013209]. The relationship among the normalized distance, the similarity measure, the inclusion measure, and the entropy of interval-valued fuzzy sets is investigated in detail. Furthermore, six theorems are proposed showing how the similarity measure, the inclusion measure, and the entropy of interval-valued fuzzy sets can be deduced by the interval-valued fuzzy sets\u2019 normalized distance based on their axiomatic definitions. Some formulas have also been put forward to calculate the similarity measure, the inclusion measure, and the entropy of interval-valued fuzzy sets.", "num_citations": "194\n", "authors": ["430"]}
{"title": "A novel method for early software quality prediction based on support vector machine\n", "abstract": " The software development process imposes major impacts on the quality of software at every development stage; therefore, a common goal of each software development phase concerns how to improve software quality. Software quality prediction thus aims to evaluate software quality level periodically and to indicate software quality problems early. In this paper, we propose a novel technique to predict software quality by adopting support vector machine (SVM) in the classification of software modules based on complexity metrics. Because only limited information of software complexity metrics is available in early software life cycle, ordinary software quality models cannot make good predictions generally. It is well known that SVM generalizes well even in high dimensional spaces under small training sample conditions. We consequently propose a SVM-based software classification model, whose characteristic is\u00a0\u2026", "num_citations": "168\n", "authors": ["430"]}
{"title": "Visual analysis of the air pollution problem in Hong Kong\n", "abstract": " We present a comprehensive system for weather data visualization. Weather data are multivariate and contain vector fields formed by wind speed and direction. Several well-established visualization techniques such as parallel coordinates and polar systems are integrated into our system. We also develop various novel methods, including circular pixel bar charts embedded into polar systems, enhanced parallel coordinates with S-shape axis, and weighted complete graphs. Our system was used to analyze the air pollution problem in Hong Kong and some interesting patterns have been found.", "num_citations": "125\n", "authors": ["430"]}
{"title": "A pseudoinverse learning algorithm for feedforward neural networks with stacked generalization applications to software reliability growth data\n", "abstract": " A supervised learning algorithm, Pseudoinverse Learning Algorithm (PIL), for feedforward neural networks is developed. The algorithm is based on generalized linear algebraic methods, and it adopts matrix inner products and pseudoinverse operations. Incorporating with network architecture of which the number of hidden layer neuron is equal to the number of examples to be learned, the algorithm eliminates learning errors by adding hidden layers and will give an exact solution (perfect learning). Unlike the existing gradient descent algorithm, the PIL is a feedforward only, fully automated algorithm, including no critical user-dependent parameters such as learning rate or momentum constant. The algorithm is tested on case studies with stacked generalization applications to software reliability growth data. The results indicate that the proposed algorithm is very efficient for the investigation on the computation\u00a0\u2026", "num_citations": "92\n", "authors": ["430"]}
{"title": "Comparative studies on similarity measures for remote sensing image retrieval\n", "abstract": " Similarity measure is usually used to study the method for guiding to select a similarity measure or a dissimilar degree between multi-source data, which is the basis of pattern recognition on spatial data. For it is the core technique in content-based image retrieval, similarity measure has very wide applications. In this work eight similarity measures are experimental investigated through some remote sensing image retrieval. The features extracted in the experiments are frequency histogram and cumulative histogram vectors. From the experiment results it can be found that X/sup 2/ statistical distance measure and cosine of the angle measure perform better than others. The results described in This work are of significance in applications to multi-source data analysis.", "num_citations": "52\n", "authors": ["430"]}
{"title": "Complete two-dimensional PCA for face recognition\n", "abstract": " We propose a novel method, the complete two-dimensional principal component analysis (complete 2DPCA), for image features extraction. Compared to the original 2DPCA, complete 2DPCA not only gain a higher recognition rate, but also reduce the feature coefficients needed for face recognition. Complete 2DPCA is based on 2D image matrices. Two image covariance matrices are constructed directly using the original image matrix and theirs eigenvectors are derived for image feature extraction. Our experiments were performed on ORL face database, and experimental results show that the proposed method has an encouraging performance", "num_citations": "50\n", "authors": ["430"]}
{"title": "Improving image quality of diffuse optical tomography with a projection-error-based adaptive regularization method\n", "abstract": " Diffuse optical tomography (DOT) reconstructs the images of internal optical parameter distribution using noninvasive boundary measurements. The image reconstruction procedure is known to be an ill-posed problem. In order to solve such a problem, a regularization technique is needed to constrain the solution space. In this study, a projection-error-based adaptive regularization (PAR) technique is proposed to improve the reconstructed image quality. Simulations are performed using a diffusion approximation model and the simulated results demonstrate that the PAR technique can improve reconstruction precision of object more effectively. The method is demonstrated to have low sensitivity to noise at various noise levels. Moreover, with the PAR method, the detectability of an object located both at the center and near the peripheral regions has been increased largely.", "num_citations": "43\n", "authors": ["430"]}
{"title": "Software defect prediction using fuzzy support vector regression\n", "abstract": " Regression techniques have been applied to improve software quality by using software metrics to predict defect numbers in software modules. This can help developers allocate limited developing resources to modules containing more defects. In this paper, we propose a novel method of using Fuzzy Support Vector Regression (FSVR) in predicting software defect numbers. Fuzzification input of regressor can handle unbalanced software metrics dataset. Compared with the approach of support vector regression, the experiment results with the MIS and RSDIMU datasets indicate that FSVR can get lower mean squared error and higher accuracy of total number of defects for modules containing large number of defects.", "num_citations": "38\n", "authors": ["430"]}
{"title": "Automatic parking space detection system\n", "abstract": " Searching a suitable parking space in populated metropolitan city is extremely difficult for drivers. Serious traffic congestion may occur due to unavailable parking space. Automatic smart parking system is emerging field and attracted computer vision researchers to contribute in this arena of technology. In this paper, we have presented a vision based smart parking framework to assist the drivers in efficiently finding suitable parking slot and reserve it. Initially, we have segmented the parking area into blocks using calibration. Then, classify each block to identify car and intimate the driver about the status of parking either reserved or free. Potentially, the performance accuracy of recommended system is higher than state of the art hardware solutions, validating the supremacy of the proposed framework.", "num_citations": "36\n", "authors": ["430"]}
{"title": "A new automated spectral feature extraction method and its application in spectral classification and defective spectra recovery\n", "abstract": " Spectral feature extraction is a crucial procedure in automated spectral analysis. This procedure starts from the spectral data and produces informative and non-redundant features, facilitating the subsequent automated processing and analysis with machine-learning and data-mining techniques. In this paper, we present a new automated feature extraction method for astronomical spectra, with application in spectral classification and defective spectra recovery. The basic idea of our approach is to train a deep neural network to extract features of spectra with different levels of abstraction in different layers. The deep neural network is trained with a fast layer-wise learning algorithm in an analytical way without any iterative optimization procedure. We evaluate the performance of the proposed scheme on real-world spectral data. The results demonstrate that our method is superior regarding its comprehensive\u00a0\u2026", "num_citations": "36\n", "authors": ["430"]}
{"title": "Cross-domain collaborative filtering with review text\n", "abstract": " Most existing cross-domain recommendation algorithms focus on modeling ratings, while ignoring review texts. The review text, however, contains rich information, which can be utilized to alleviate data sparsity limitations, and interpret transfer patterns. In this paper, we investigate how to utilize the review text to improve cross-domain collaborative filtering models. The challenge lies in the existence of non-linear properties in some transfer patterns. Given this, we extend previous transfer learning models in collaborative filtering, from linear mapping functions to non-linear ones, and propose a cross-domain recommendation framework with the review text incorporated. Experimental verifications have demonstrated, for new users with sparse feedback, utilizing the review text obtains 10% improvement in the AUC metric, and the nonlinear method outperforms the linear ones by 4%.", "num_citations": "35\n", "authors": ["430"]}
{"title": "Comparative studies on feature extraction methods for multispectral remote sensing image classification\n", "abstract": " Feature extraction of multispectral remote sensing image is an important task before classifying the image. When land areas are clustered into groups of similar land cover, one of the most important things is to extract the key features of a given image. Usually multispectral remote sensing images have many bands, and there may have been much redundancy information and it becomes difficult to extract the key features of the image. Therefore, it is necessary to study methods regarding how to extract the main features of the image effectively. In this paper, five methods are comparatively studied to reduce the multi-bands into lower dimensions in order to extract the most available features. These methods include the Euclid distance measurement (EDM), the discrete measurement criteria function (DMCF), the minimum differentiated entropy (MDE), the probability distance criterion (PDC), and the principle component\u00a0\u2026", "num_citations": "34\n", "authors": ["430"]}
{"title": "A hierarchical mixture model for software reliability prediction\n", "abstract": " It is important to develop general prediction models in current software reliability research. In this paper, we propose a hierarchical mixture of software reliability models (HMSRM) for software reliability prediction. This is an application of the hierarchical mixtures of experts (HME) architecture. In HMSRM, individual software reliability models are used as experts. During the training of HMSRM, an Expectation\u2013Maximizing (EM) algorithm is employed to estimate the parameters of the model. Experiments illustrate that our approach performs quite well in the later stages of software development, and better than single classical software reliability models. We show that the method can automatically select the most appropriate lower-level model for the data and performances are well in prediction.", "num_citations": "33\n", "authors": ["430"]}
{"title": "Deep learning based software defect prediction\n", "abstract": " Software systems have become larger and more complex than ever. Such characteristics make it very challengeable to prevent software defects. Therefore, automatically predicting the number of defects in software modules is necessary and may help developers efficiently to allocate limited resources. Various approaches have been proposed to identify and fix such defects at minimal cost. However, the performance of these approaches require significant improvement. Therefore, in this paper, we propose a novel approach that leverages deep learning techniques to predict the number of defects in software systems. First, we preprocess a publicly available dataset, including log transformation and data normalization. Second, we perform data modeling to prepare the data input for the deep learning model. Third, we pass the modeled data to a specially designed deep neural network-based model to predict the\u00a0\u2026", "num_citations": "29\n", "authors": ["430"]}
{"title": "A completeness analysis of frequent weighted concept lattices and their algebraic properties\n", "abstract": " Frequent weighted concept lattice (FWCL) is an interesting version of the WCL (weighted concept lattice), which helps realize knowledge extraction in a more efficient way. One of the open issues is that the completeness of FWCL cannot be ensured (namely, some nodes would be removed since their intent weights are lower than intent importance thresholds specified by the user, so that it can occur that the supremum of their parent nodes or the infimum of their child nodes might not exist). In this study, we first introduce a virtual node into the structure of FWCL to retain the completeness of FWCL. Next, an algebraic system of FWCL is presented by introducing two operations, which form the least frequent upper bound and the greatest frequent lower bound of the FWCL. Finally, we discuss some algebraic properties of FWCL and prove its completeness of knowledge representation in this way providing the theoretical\u00a0\u2026", "num_citations": "29\n", "authors": ["430"]}
{"title": "Autoencoder, low rank approximation and pseudoinverse learning algorithm\n", "abstract": " Deep multi-layer neural networks are generally trained using variants of the gradient descent based algorithm. However, this kind of algorithms usually encounter a series of shortcomings, such as low training efficiency, local minimum, difficult control parameter tuning, and gradient vanishing or exploding. Besides, for a specific application, how to design the structure of the network, that is, how many neurons in each hidden layer and how many hidden layers is needed, is also a very tricky problem and is usually solved by trial and error in practice. To overcome the shortcomings mentioned above, we present a fast and fully automated method to train stacked autoencoders based deep neural networks in this paper. The proposed method trains the stacked autoencoders adopting the pseudoinverse learning algorithm with the low rank approximation. The entire training process neither need to set the learning control\u00a0\u2026", "num_citations": "26\n", "authors": ["430"]}
{"title": "A fast mean shift procedure with new iteration strategy and re-sampling\n", "abstract": " Mean-shift analysis is a general nonparametric clustering technique based on density estimation for the analysis of complex feature spaces. It has been successfully applied to many applications such as segmentation and tracking. However, despite its promising performance, there are applications for which the algorithm converges too slowly and is not practical. In this paper, an improved version of mean shift algorithm is proposed and implemented. The fast mean shift procedure uses a new iteration strategy and re-sampling. The new iteration strategy is based on updating cluster centers according to dynamically updated sample set. And the original data set is simplified by re-sampling, which accelerates the algorithm more significantly. Experimental results demonstrate the efficiency of the fast mean shift procedure in clustering problems.", "num_citations": "26\n", "authors": ["430"]}
{"title": "Software quality prediction using affinity propagation algorithm\n", "abstract": " Software metrics are collected at various phases of the software development process. These metrics contain the information of the software and can be used to predict software quality in the early stage of software life cycle. Intelligent computing techniques such as data mining can be applied in the study of software quality by analyzing software metrics. Clustering analysis, which can be considered as one of the data mining techniques, is adopted to build the software quality prediction models in the early period of software testing. In this paper, a new clustering method called Affinity Propagation is investigated for the analysis of two software metric datasets extracted from real-world software projects. Meanwhile, K-Means clustering method is also applied for comparison. The numerical experiment results show that the Affinity Propagation algorithm can be applied well in software quality prediction in the very early\u00a0\u2026", "num_citations": "25\n", "authors": ["430"]}
{"title": "Removal of random-valued impulse noise by local statistics\n", "abstract": " In this paper, a new method for the identification and removal of random-valued impulse noise (RVIN) from images is proposed. We propose to identify the central pixel of the current sliding window as a noisy or noise free pixel based on the similar local statistics of the current window. Our proposed RVIN identifier works in an iterative way. Pixel identified as a noisy pixel is replaced by proposed minimum difference similar value in an optimal directions. The performance of the proposed method is evaluated on different test images and compared with state-of-the-art methods. Experimental results show that the proposed method cannot only identify the impulse noise efficiently, but can also preserve the detailed information of an image.", "num_citations": "24\n", "authors": ["430"]}
{"title": "Image fusion by hierarchical joint sparse representation\n", "abstract": " Joint sparse representation (JSR)\u00a0based image fusion, as one of competitive sparse representation\u00a0based fusion methods, has been widely studied recently. In this kind of methods, image features are represented as sparse coefficients. They are typically calculated with two decomposition algorithms, namely orthogonal matching pursuit and basis pursuit. In both of them, an error tolerance parameter is specified to control the fineness of a fused image. Intuitively, the more detailed an image fineness is, the more micro-information is presented; the more rough it is, the more macro-information is summarized. Therefore, it is reasonable to assume that complementary information exists among the images generated by different error tolerance parameters. Motivated by this, in this paper, we have tried to combine the features in these images and verify the above assumption. Specifically, we have proposed a two\u00a0\u2026", "num_citations": "24\n", "authors": ["430"]}
{"title": "Blind image restoration based on wavelet analysis\n", "abstract": " Blind image restoration is important and full of challenge as an issue of image processing. Many conventional approaches have been developed to restore the original image at present. But since there are two unknown things: the original image and the point spread function (PSF), in many case it is difficult to reach the expected results, especially when the image is heavily degraded. In this paper, blind image restoration approach based on wavelet analysis is proposed. The key of the approach is the wavelet analysis implemented before the restoration with conventional approaches. Wavelet analysis returns some useful information about the degraded image as well as the restored image, and the information can help further restoration. The experimental results prove that the approach is satisfactory.", "num_citations": "24\n", "authors": ["430"]}
{"title": "A shadow detection method for remote sensing images using affinity propagation algorithm\n", "abstract": " Shadow detection in high spatial resolution remote sensing image is very critical for locating geographical targets. In this paper, we proposed a new shadow detection method using Affinity Propagation (AP) algorithm in the Hue-Saturation-Intensity (HSI) color space. Because the pixel matrix is a large-scale matrix, if we apply AP algorithm directly on the raw pixel space, it will be computation intensive to calculate the similarity matrix. To solve this problem, we propose to divide the matrix into several blocks and then applying AP to detect shadows in H, S and I components respectively. Then, three detected images are fused to obtain a final shadow detection result. Comparative experiments are performed for K-means and threshold segmentation methods. The experimental results show that higher detection accuracy of the proposed approach is obtained, and it can solve the problems of false dismissals of K-means\u00a0\u2026", "num_citations": "23\n", "authors": ["430"]}
{"title": "The effectiveness and experience of self-management following acute coronary syndrome: a review of the literature\n", "abstract": " ObjectivesTo evaluate the effectiveness of interventions used to support self-management, and to explore patients\u2019 experiences after acute coronary syndrome in relation to self-management.DesignScoping review.Data sourcesKeyword search of CINAHL Plus, Medline, the Cochrane Library, and PsycINFO databases for studies conducted with adult population and published in English between 1993 and 2014.Review methodsFrom title and abstract review, duplicated articles and obviously irrelevant studies were removed. The full texts of the remaining articles were assessed against the selection criteria. Studies were included if they were original research on: (1) effectiveness of self-management interventions among individuals following acute coronary syndrome; or (2) patients\u2019 experience of self-managing recovery from acute coronary syndrome.Results44 articles (19 quantitative and 25 qualitative) were\u00a0\u2026", "num_citations": "22\n", "authors": ["430"]}
{"title": "\u5927\u6570\u636e\u5206\u6790\u4e2d\u7684\u8ba1\u7b97\u667a\u80fd\u7814\u7a76\u73b0\u72b6\u4e0e\u5c55\u671b\n", "abstract": " \u968f\u7740\u4ea7\u4e1a\u754c\u548c\u79d1\u5b66\u754c\u6570\u636e\u91cf\u7684\u7206\u70b8\u5f0f\u589e\u957f, \u5927\u6570\u636e\u6280\u672f\u548c\u5e94\u7528\u5438\u5f15\u4e86\u4f17\u591a\u7684\u5173\u6ce8. \u5982\u4f55\u5206\u6790\u5927\u6570\u636e, \u5145\u5206\u6316\u6398\u5927\u6570\u636e\u7684\u6f5c\u5728\u4ef7\u503c, \u6210\u4e3a\u9700\u8981\u6df1\u5165\u63a2\u8ba8\u7684\u79d1\u5b66\u95ee\u9898. \u8ba1\u7b97\u667a\u80fd\u662f\u79d1\u5b66\u7814\u7a76\u548c\u5de5\u7a0b\u5b9e\u8df5\u4e2d\u89e3\u51b3\u590d\u6742\u95ee\u9898\u7684\u6709\u6548\u624b\u6bb5, \u662f\u4eba\u5de5\u667a\u80fd\u548c\u4fe1\u606f\u79d1\u5b66\u7684\u91cd\u8981\u7814\u7a76\u65b9\u5411, \u5e94\u7528\u8ba1\u7b97\u667a\u80fd\u65b9\u6cd5\u8fdb\u884c\u5927\u6570\u636e\u5206\u6790\u5177\u6709\u5de8\u5927\u7684\u6f5c\u529b. \u5bf9\u5927\u6570\u636e\u5206\u6790\u4e2d\u7684\u8ba1\u7b97\u667a\u80fd\u65b9\u6cd5\u8fdb\u884c\u7efc\u8ff0, \u7ed3\u5408\u5927\u6570\u636e\u7684\u7279\u5f81, \u8ba8\u8bba\u4e86\u5927\u6570\u636e\u5206\u6790\u4e2d\u8ba1\u7b97\u667a\u80fd\u7814\u7a76\u5b58\u5728\u7684\u95ee\u9898\u548c\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u65b9\u5411, \u9610\u8ff0\u4e86\u6570\u636e\u6e90\u5171\u4eab\u95ee\u9898, \u5e76\u5efa\u8bae\u5229\u7528\u4ee5\u5929\u6587\u5b66\u4e3a\u4ee3\u8868\u7684\u6570\u636e\u5bc6\u96c6\u578b\u57fa\u7840\u79d1\u7814\u9886\u57df\u7684\u6570\u636e\u5f00\u5c55\u5927\u6570\u636e\u5206\u6790\u7814\u7a76.", "num_citations": "22\n", "authors": ["430"]}
{"title": "Mean shift-based edge detection for color image\n", "abstract": " Edge detection is an important process in low level image processing. With the advent of powerful computers, it is now possible to move to the more computationally intensive realm of color image understanding. There are many benefits in doing so including the increased amount of information for object location and processing. However, many proposed methods for color edge detection are computational expensive and are not very robust to the image noise. In this paper, a new method based on mean shift algorithm to detect edge in color images is presented. The gradient-ascent mean shift localizes edges accurately in the presence of noise and provides a good computational performance, being based on local operators. Experimental results show the effectiveness and robustness of propose method", "num_citations": "22\n", "authors": ["430"]}
{"title": "A fusion method for multispectral and panchromatic images based on HSI and contourlet transformation\n", "abstract": " Fusion of multispectral and panchromatic remote sensing images is a procedure to obtain spatial resolution and quality of the panchromatic image as well as preserving spectral information of the multispectral image. In this paper, we present a new fusion method based on HSI (Hue-Saturation-Intensity) and Contourlet transform. First, we convert the multispectral image from the RGB color space into the HSI color space. Then, by applying Contourlet transform to the panchromatic image and the I component of the multispectral image, we utilize an improved fusion rule based on PCA for the low-frequency sub-images, and engage the maximum fusion rule for the high-frequency sub-images. Finally, a fusion image is obtained by the inverse HSI transform. The experimental results show that the proposed fusion method not only enhances the spatial resolution of the fusion image, but also preserves the spectral\u00a0\u2026", "num_citations": "20\n", "authors": ["430"]}
{"title": "Comparative studies of feature extraction methods with application to face recognition\n", "abstract": " In face recognition, the dimensionality of raw data is very high, dimension reduction (feature extraction) should be applied before classification. There exist several feature extraction methods, commonly used are principle component analysis (PCA) and linear discriminant analysis (LDA) techniques. In this paper, we present a comparative study of some feature extraction methods for face recognition in the same conditions. The methods evaluated here include eigenfaces, kernel principal component analysis (KPCA), fisherfaces, direct linear discriminant analysis (D-LDA), regularized linear discriminant analysis (R-LDA), and kernel direct discriminant analysis (KDDA). For the purpose of comparison on feature extraction methods, we adopt nearest neighbor (NN) algorithm from existed classifiers of face recognition, since this classifier is common and simpleness. Empirical studies are conducted to evaluate these\u00a0\u2026", "num_citations": "20\n", "authors": ["430"]}
{"title": "Reinforcement learning for build-order production in StarCraft II\n", "abstract": " StarCraft II is one of the most popular real-time strategy games and has become an important benchmark for AI research as it provides a complex environment with numerous challenges. The build order problem is one of the key challenges which concern the order and type of buildings and units to produce based on current game situation. In contrast to existing hand-craft methods, we propose two reinforcement learning based models: Neural Network Fitted Q-Learning (NNFQ) and Convolutional Neural Network Fitted Q-Learning (CNNFQ). NNFQ and CNNFQ have been applied into a simple bot for fighting against the enemy race. Experimental results show that both these two models are capable of finding the most effective production sequence to defeat the opponent.", "num_citations": "19\n", "authors": ["430"]}
{"title": "Ant colony optimization algorithm for feature selection and classification of multispectral remote sensing image\n", "abstract": " In classification of a multispectral remote sensing image, it is usually difficult to obtain higher classification accuracy if we only consider the image's spectral feature or texture feature alone. In this paper, we present a new approach by applying the Ant Colony Optimization (ACO) algorithm to find a multi-feature vector composed of spectral and texture features in order to get a better result in the classification. The experimental results show that ACO algorithm is helpful in subset searching of the features used to classify the multispectral remote sense image. Using the combination of the spectral and texture features obtained by ACO in classification always produces a better accuracy.", "num_citations": "19\n", "authors": ["430"]}
{"title": "Support vector regression for software reliability growth modeling and prediction\n", "abstract": " In this work, we propose to apply support vector regression (SVR) to build software reliability growth model (SRGM). SRGM is an important aspect in software reliability engineering. Software reliability is the probability that a given software will be functioning without failure during a specified period of time in a specified environment. In order to obtain the better performance of SRGM, practical selection of parameter C for SVR is discussed in the experiments. Experimental results with the classical Sys1 and Sys3 SRGM data set show that the performance of the proposed SVR-based SRGM is better than conventional SRGMs and relative good prediction and generalization ability are achieved.", "num_citations": "19\n", "authors": ["430"]}
{"title": "Blind image restoration based on RBF neural networks\n", "abstract": " In this paper, we propose a novel technique for blind image restoration and resolution enhancement based on radial basis function (RBF) neural network. The RBF network gives a solution of the regularization problem often seen in function estimation with certain standard smoothness functional used as stabilizers. A RBF network model is designed to represent the observed image. In this model, the number and distribution of the centers (which are set to the pixels of the observed image) are fixed. In addition, network output is set to the observed image pixel gray scale value. The RBF plays a role of point spread function. The technique can also be applied to image resolution enhancement by generating an interpolated image from the low resolution version. Experimental results show that the learning algorithm can effectively estimate the model parameters and the established neural network model has a high\u00a0\u2026", "num_citations": "19\n", "authors": ["430"]}
{"title": "Automated separation of stars and normal galaxies based on statistical mixture modeling with RBF neural networks\n", "abstract": " For LAMOST, the largest sky survey program in China, the solution of the problem of automatic discrimination of stars from galaxies by spectra has shown that the results of the PSF test can be significantly refined. However, the problem is made worse when the redshifts of galaxies are not available. We present a new automatic method of star/(normal) galaxy separation, which is based on Statistical Mixture Modeling with Radial Basis Function Neural Networks (SMM-RBFNN). This work is a continuation of our previous one, where active and non-active celestial objects were successfully segregated. By combining the method in this paper and the previous one, stars can now be effectively separated from galaxies and AGNs by their spectra\u2014a major goal of LAMOST, and an indispensable step in any automatic spectrum classification system. In our work, the training set includes standard stellar spectra from Jacoby's\u00a0\u2026", "num_citations": "19\n", "authors": ["430"]}
{"title": "Multispectral remote sensing image classification with multiple features\n", "abstract": " In this paper, we propose to combine the spectral and texture features to compose the multi-feature vectors for the classification of multispectral remote sensing image. It usually is difficult to obtain the higher classification accuracy if only considers one kind feature, especially for the case of different geographical objects have the same spectrum or texture specialty for a multispectral remote sensing image. The spectral feature and the texture feature are composed together to form a new feature vector, which can represent the most effective features of the given remote sensing image. In this way we can overcome shortcomings of only using the single feature and raise the classification accuracy. The system classification performance with composed feature vector is investigated by experimentations. By analysis of results we can learn how to combine the multi-feature vector can obtain a higher classification rate, and\u00a0\u2026", "num_citations": "17\n", "authors": ["430"]}
{"title": "Bottom-up merging segmentation for color images with complex areas\n", "abstract": " Most color images obtained from the real world usually contain complex areas, such as nature scene images, remote sensing images, and medical images. All these type of images are very difficult to be separated accurately and automatically for complex color and structures included. In this paper, we focus on detecting hybrid cues of color image to segment complex scene in a bottom-up framework. The main idea of the proposed segmentation method is based on a two-step procedure: 1) a reasonable superpixels computing method is conducted and 2) a Mumford-Shah (M-S) optimal merging model is proposed for presegment suerpixels. First, a set of seed pixels is positioned at the lowest texture energy map computed from structure tensor diffusion features. Next, we implement a growing procedure to extract superpixels from selected seed pixels with color and texture cues. After that, a color-texture histograms\u00a0\u2026", "num_citations": "16\n", "authors": ["430"]}
{"title": "A practical intrusion detection system for Internet of vehicles\n", "abstract": " Internet of Vehicles (henceforth called IoV) is a public network system and high-value target for intrusions that may cause efficiency issues, privacy leakages or even physical damage. Conventional intrusion detection methods are normally designed for the Internet infrastructures which cannot directly apply in the context of IoV. This work proposes an FPGA based intrusion detection method that can not only achieve real-time scanning performance but also be applied in vehicular environment. We evaluate our scheme on a Xilinx FPGA based platform. Experiments show that the proposed system can achieve a throughput of more than 39 Gbps on existing FPGA platform which is about 15% higher than state-of-the-art techniques, and the total power consumption for the prototype is about 7.5 w. Moreover, the processing latency of the prototype is about 4 us and is about one sixtieth part of the popular software IDS\u00a0\u2026", "num_citations": "16\n", "authors": ["430"]}
{"title": "A pseudoinverse incremental algorithm for fast training deep neural networks with application to spectra pattern recognition\n", "abstract": " Deep learning scheme has received significant attention during these years, particularly as a way of building hierarchical representations from unlabeled data for a variety of signal and information processing tasks. However, deep neural networks suffer from slow learning speed since most used training algorithms are based on variations of the gradient descent algorithms which require iterative optimization and thus are time-consuming. In addition, a series of control parameters need to be specified empirically which lacks of the theoretical guidance, and current learning algorithms for deep networks are not very suitable to incremental learning scenario. To address these issues, we propose a fast learning scheme in this paper. The basic idea of our approach is to pre-train basic units such as auto-encoders of the deep architecture in an analytical way without any iterative optimization procedure. This scheme is\u00a0\u2026", "num_citations": "15\n", "authors": ["430"]}
{"title": "Locality-constrained Low-rank Coding for Image Classification\n", "abstract": " Low-rank coding (LRC), originated from matrix decomposition, is recently introduced into image classification. Following the standard bag-of-words (BOW) pipeline, when coding the data matrix in the sense of low-rankness incorporates contextual information into the traditional BOW model, this can capture the dependency relationship among neighbor patches. It differs from the traditional sparse coding paradigms which encode patches independently. Current LRC-based methods use l_1 norm to increase the discrimination and sparseness of the learned codes. However, such methods fail to consider the local manifold structure between dataspace and dictionary space. To solve this problem, we propose a locality-constrained low-rank coding (LCLR) algorithm for image representations. By using the geometric structure information as a regularization term, we can obtain more discriminative representations. In addition, we present a fast and stable online algorithmto solve the optimization problem. In the experiments, we evaluate LCLR with four benchmarks, including one face recognition dataset (extended Yale B), one handwrittendigit recognition dataset (USPS), and two image datasets (Scene13 for scene recognition and Caltech101 for object recognition). Experimental results show thatour approach outperforms many state-of-the-art algorithmseven with a linear classifier.", "num_citations": "15\n", "authors": ["430"]}
{"title": "Software metrics data clustering for quality prediction\n", "abstract": " Software metrics are collected at various phases of the software development process. These metrics contain the information of software and can be used to predict software quality in the early stage of software life cycle. Intelligent computing techniques such as data mining can be applied in the study of software quality by analyzing software metrics. Clustering analysis, which is one of data mining techniques, is adopted to build the software quality prediction models in early period of software testing. In this paper, three clustering methods, k-means, fuzzy c-means and Gaussian mixture model, are investigated for the analysis of two real-world software metric datasets. The experiment results show that the best method in predicting software quality is dependent on practical dataset, and clustering analysis technique has advantages in software quality prediction since it can be used in the case having little prior\u00a0\u2026", "num_citations": "15\n", "authors": ["430"]}
{"title": "Face recognition by combining wavelet transform and K-nearest neighbor\n", "abstract": " A novel technique for face recognition is presented in this paper. Wavelet transform and k-nearest neighbor rule are combined in this technique. Wavelet transform is adopted to obtain the low pass images of the original face images in order to reduce the impact of facial expressions. When the scales of the head of an individual in sample images are different, wavelet transform is employed to extract the position of facial features. Then a new method is adopted to construct feature vectors using the grey values of face images. Finally, k-nearest neighbor rule is employed to complete the recognition process. Experimental results show that the proposed technique is efficient at computation and robust to the facial expressions.", "num_citations": "15\n", "authors": ["430"]}
{"title": "Pulsar candidate selection using ensemble networks for FAST drift-scan survey\n", "abstract": " The Commensal Radio Astronomy Five-hundred-meter Aperture Spherical radio Telescope (FAST) Survey (CRAFTS) utilizes the novel drift-scan commensal survey mode of FAST and can generate billions of pulsar candidate signals. The human experts are not likely to thoroughly examine these signals, and various machine sorting methods are used to aid the classification of the FAST candidates. In this study, we propose a new ensemble classification system for pulsar candidates. This system denotes the further development of the pulsar image-based classification system (PICS), which was used in the Arecibo Telescope pulsar survey, and has been retrained and customized for the FAST drift-scan survey. In this study, we designed a residual network model comprising 15 layers to replace the convolutional neural networks (CNNs) in PICS. The results of this study demonstrate that the new model can\u00a0\u2026", "num_citations": "14\n", "authors": ["430"]}
{"title": "Energy-based multi-plane detection from 3D point clouds\n", "abstract": " Detecting multi-plane from 3D point clouds can provide concise and meaningful abstractions of 3D data and give users higher-level interaction possibilities. However, existing algorithms are deficient in accuracy and robustness, and highly dependent on thresholds. To overcome these deficiencies, a novel method is proposed, which detects multi-plane from 3D point clouds by labeling points instead of greedy searching planes. It first generates initial models. Second, it computes energy terms and constructs the energy function. Third, the point labeling problem is solved by minimizing the energy function. Then, it refines the labels and parameters of detected planes. This process is iterated until the energy does not decrease. Finally, multiple planes are detected. Experimental results validate the proposed method. It outperforms existing algorithms in accuracy and robustness. It also alleviates the high\u00a0\u2026", "num_citations": "14\n", "authors": ["430"]}
{"title": "Removal of high-intensity impulse noise by Weber\u2019s law noise identifier\n", "abstract": " High-intensity impulse noise removal is a challenging task to restore the image. Weber\u2019s law states that the ratio of the increment threshold to the background intensity is constant. Inspired by Weber\u2019s law (WL), in this paper, a novel image de-noising method, named \u201cWeber\u2019s law Noise Identifier\u201d (WLNI), is proposed. By applying WLNI to a corrupted image, we can identify 100% of the impulse noise. For noise removal, we propose two methods to replace pixels classified as noise pixels. Experimental results show that our proposed WLNI cannot only efficiently identify the impulse noise, but can also preserve the detailed information of an image relative to existing methods more efficiently.", "num_citations": "14\n", "authors": ["430"]}
{"title": "Epileptic EEG signal classification with ANFIS based on harmony search method\n", "abstract": " In this paper, the Adaptive Neuro-Fuzzy Inference System (ANFIS) is used for the classification of the epileptic electroencephalogram (EEG) signals. The ANFIS combines the adaptation capability of the neural networks and the fuzzy logic-based qualitative approach together. A given input/output data set is deployed to construct a fuzzy inference system, whose membership function parameters are trained using a back propagation algorithm in combination with a least squares method. However, the training method sometimes may lead to local optima. We here propose a new strategy of hybrid training algorithm based on the fusion of the ANFIS and Harmony Search (HS), HS-ANFIS, which is adopted to tune all the parameters of the ANFIS. The validity of our method is verified by numerical experiments.", "num_citations": "14\n", "authors": ["430"]}
{"title": "Spatial local binary patterns for scene image classification\n", "abstract": " Local binary patterns (LBP), which is an effective and efficient texture descriptor, has been successfully applied to image analysis tasks such as face recognition and scene categorization. However, the conventional LBP histogram ignores spatial information of objects existing in images. In this paper, to address this problem, we propose a new Spatial Local Binary Patterns (SLBP) approach to encode geometric information of objects within images. The proposed method focuses on two critical aspects of scene classification: SLBP descriptor for image representation, and kernelized classifier for categorization. For the former one, SLBP descriptor is used to generate a series of ordered LBP histograms for capturing spatial information, by projecting LBP descriptor of an image onto different resolution and directions by linear projection, or points by circular projection. For the latter one, in order to fuse information from\u00a0\u2026", "num_citations": "14\n", "authors": ["430"]}
{"title": "RANSAC based ellipse detection with application to catadioptric camera calibration\n", "abstract": " In this paper, a simple method for ellipse detection is proposed and applied in central catadioptric camera calibration. It consists of two phases. Firstly it locates ellipse center candidates using center symmetry of ellipses, and the detected edge points are grouped into several subsets according to the center candidates. Then all the ellipses are fitted by performing RANSAC for each subset. We also present an approach for calibrating a central catadioptric camera based on the bounding ellipse of the catadioptric image. Using the proposed ellipse detection method, we can easily detect the bounding ellipse. As a result, a simple self-calibration can be realized, which can be used in some applications where high accuracy of the calibration is not required. Experiments show the proposed method is effective.", "num_citations": "14\n", "authors": ["430"]}
{"title": "Software risk prediction based on the hybrid algorithm of genetic algorithm and decision tree\n", "abstract": " Software systems are becoming increasingly important these days with the development of computer. Many countries and companies are investing much more in developing software systems to implement a lot of significant assignment, so the quality and reliability of the software needs to be assured. Hence, the characteristics of the source code of these systems need to be measured to obtain more information about it, and software metrics is needed to be analyzed. This paper introduces a hybrid learning method that incorporate with genetic algorithm and decision tree algorithm in order to evolve optimal subsets of software metrics for risk prediction during the early phase of the software life-circle. Experimental results are presented which illustrate the feasibility and improved performance of our approach when compared with using all metrics for risk prediction by decision tree.", "num_citations": "14\n", "authors": ["430"]}
{"title": "Isomap and neural networks based image registration scheme\n", "abstract": " A novel image registration scheme is proposed. In the proposed scheme, the complete isometric mapping (Isomap) is used to extract features from the image sets, and these features are input vectors of feedforward neural networks. Neural network outputs are those translation, rotation and scaling parameters with respect to reference and observed image sets. Comparative experiments for Isomap based method, the discrete cosine transform (DCT) and Zernike moment are performed. The results show that the proposed scheme is not only accurate but also remarkably robust to noise.", "num_citations": "14\n", "authors": ["430"]}
{"title": "Defocused image restoration using RBF network and kalman filter\n", "abstract": " A novel defocused image restoration technique is proposed, which is based on radial basis function (RBF) neural network and Kalman filter. In this technique, firstly a RBF neural network is trained in wavelet domain to estimate defocus parameter. After obtaining the point spread function (PSF) parameter, Kalman filter is adopted to complete the restoration. We experimentally illustrate its performance on simulated data and compare it with other methods. Results show that the proposed PSF parameter estimation technique is more robust to noise.", "num_citations": "14\n", "authors": ["430"]}
{"title": "An experimental case study on the relationship between workload and resource consumption in a commercial web server\n", "abstract": " Since software aging has been proposed for decades, resource consumption parameters and performance parameters have been used to identify whether running a commercial web server has been in aging state or failure state. However, the relationship between workload parameters and resource consumption parameters has not been analyzed and also sensitivity between resource consumption parameters and workload parameters has not been studied before. In this work, we give an experimental case study about resource consumption parameters and workload parameters in an Internet Information Services. Firstly, we use fitted resource consumption parameter to learn the relationship between workload parameters and resource consumption parameters through visual observation and calculation. Secondly, sensitivity analysis is used to find how resource consumption parameter changes when deleting\u00a0\u2026", "num_citations": "13\n", "authors": ["430"]}
{"title": "Color image segmentation based on regional saliency\n", "abstract": " In this paper, we propose a novel segmentation model integrated the salient regional features into mean shift (MS) clustering segmentation as fusion matrixes. Firstly, a regional visual saliency map of the given image is obtained based on quantification image in HSV color space. Then saliency factors are extracted from salience map from each channel in L*a*b space in two steps: region saliency(S-R) and pixels-region (P-R). Fuse the salient factors derived from former salient features with original components of the image as new input features, who are involved in the mean-shift procedure for segmentation. This paper takes advantage of regional salience to guide the MS vectors moving to accurate modes, and decreases premature and ill convergence at local area. The introduction of salient factors enhances the accuracy of the pixels clustering for region segment. Experiment results carried on Berkeley\u00a0\u2026", "num_citations": "13\n", "authors": ["430"]}
{"title": "Epileptic EEG signal classification with marching pursuit based on harmony search method\n", "abstract": " In Epilepsy EEG signal classification, the main time-frequency features can be extracted by using sparse representation with marching pursuit (MP) algorithm. However, the computational burden is so heavy that it is almost impossible to apply MP to real time signal processing. To reduce complexity of sparse representation, we propose to adopt harmony search method in searching the best atoms. Because harmony search method can find the best atoms in continuous time-frequency dictionary, the performance of epilepsy EEG signal classification is enhanced. The validity of this method is proved by experimental results.", "num_citations": "13\n", "authors": ["430"]}
{"title": "A shadow detection of remote sensing images based on statistical texture features\n", "abstract": " Shadow detection for high spatial resolution remote sensing images is very critical for image segmentation, feature extraction, image matching, automatic target detection and target location. In order to improve the accuracy of shadow detection, we propose a new shadow detection method based on a statistical mixture model, which combines several radial basis function neural networks. Four statistical features, including energy, entropy, contrast and inverse difference moment, extracted from grey level concurrence matrix are used as the model input features. EM-like algorithm is adopted to estimate the model parameters through optimizing the system cost function. Comparative experiments are performed between the Gaussian background model and the histogram threshold method. Experimental results show that higher detection accuracy of the proposed approach is obained. The p opo ed me hod can ol e he p oblem ch a high eflec ie egion and fal e ala m in he pe ence of ae, a well as the repeated threshold calculation.", "num_citations": "13\n", "authors": ["430"]}
{"title": "\u57fa\u4e8e\u7edf\u8ba1\u6df7\u5408\u6a21\u578b\u7684\u9065\u611f\u5f71\u50cf\u9634\u5f71\u68c0\u6d4b\n", "abstract": " \u4e3a\u63d0\u9ad8\u9634\u5f71\u68c0\u6d4b\u7cbe\u5ea6,\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u9065\u611f\u5f71\u50cf\u9634\u5f71\u68c0\u6d4b\u65b9\u6cd5\u2014\u5c06\u5f84\u5411\u57fa\u51fd\u6570\u795e\u7ecf\u7f51\u7edc\u6784\u5efa\u7684\u6df7\u5408\u6a21\u578b(\u79f0\u4f5cSMM-RBFNN)\u5e94\u7528\u4e8e\u9065\u611f\u5f71\u50cf\u9634\u5f71\u68c0\u6d4b.\u7070\u5ea6\u5171\u751f\u77e9\u9635\u4e2d\u7684\u80fd\u91cf,\u71b5,\u5bf9\u6bd4\u5ea6\u548c\u9006\u5dee\u77e94\u79cd\u7edf\u8ba1\u7279\u5f81\u91cf\u4f5c\u4e3a\u6df7\u5408\u6a21\u578b\u7684\u8f93\u5165\u7279\u5f81\u77e2\u91cf,\u91c7\u7528\u7c7b\"\u671f\u671b-\u6700\u5927\u5316\"\u7b97\u6cd5(\u7c7bEM)\u8fdb\u884c\u53c2\u6570\u4f30\u8ba1,\u8bad\u7ec3\u68c0\u6d4b\u5668\u5b9e\u73b0\u9634\u5f71\u68c0\u6d4b.\u5bf9\u591a\u5e45\u5e26\u6709\u6d53\u539a\u9634\u5f71\u7684\u9065\u611f\u5f71\u50cf\u8fdb\u884c\u5b9e\u9a8c,\u7ed3\u679c\u8868\u660e\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u660e\u663e\u4f18\u4e8e\u4f20\u7edf\u7684\u9ad8\u65af\u80cc\u666f\u6cd5\u548c\u76f4\u65b9\u56fe\u9608\u503c\u6cd5,\u80fd\u591f\u8f83\u597d\u5730\u89e3\u51b3\u5f3a\u53cd\u5c04\u6027\u5730\u7269\u6f0f\u68c0\u548c\u6c34\u4f53\u9519\u68c0\u95ee\u9898,\u80fd\u591f\u514b\u670d\u57fa\u4e8e\u9608\u503c\u601d\u60f3\u7684\u68c0\u6d4b\u6cd5\u9700\u8981\u53cd\u590d\u5b9e\u9a8c\u9009\u53d6\u9608\u503c\u7684\u7f3a\u70b9.", "num_citations": "13\n", "authors": ["430"]}
{"title": "KICA feature extraction in application to FNN based image registration\n", "abstract": " In this paper, a novel image registration method is proposed. In the proposed method, kernel independent component analysis (KICA) is applied to extract features from the image sets, and these features are input vectors of feedforward neural networks (FNN). Neural network outputs are those translation, rotation and scaling parameters with respect to reference and observed image sets. Comparative experiments are performed between KICA based method and other six feature extraction based method: principal component analysis (PCA), independent component analysis (ICA), kernel principal component analysis (KPCA), the discrete cosine transform (DCT), Zernike moment and the complete isometric mapping (Isomap). The results show that the proposed method is much improved not only at accuracy but also remarkably at robust to noise.", "num_citations": "13\n", "authors": ["430"]}
{"title": "Comparative studies on similarity measures for remote sensing image retrieval based on histogram\n", "abstract": " Similarity measure is usually used to study the similar degree between multisource data, which is the basis of pattern recognition on spatial data. In this paper two kinds of similarity measures are experimentally investigated through some remote sensing image retrievals, they are feature vector based measures and probabilistic measures, accordingly two groups experiments are designed to compare the measures for application to remote sensing image retrieval. From the experiment results we find that in the first group two measures seldom used in the literature perform well, they are \u03c7~ 2 statistical distance measure and cosine of the angle measure. And in the second group experiments, for computing the similarity degree of two images with their histograms obeying mixture Gaussian distributions, we present a method on the basis of class separability measures according to the K-nearest neighbor rule. The experiment results show that the method has good performance. We believe that the results described in this paper will be of significance in applications to multisource data analysis.", "num_citations": "13\n", "authors": ["430"]}
{"title": "Automated stellar classification for large surveys with EKF and RBF neural networks\n", "abstract": " An automated classification technique for large size stellar surveys is proposed. It uses the extended Kalman filter as a feature selector and pre-classifier of the data, and the radial basis function neural networks for the classification. Experiments with real data have shown that the correct classification rate can reach as high as 93%, which is quite satisfactory. When different system models are selected for the extended Kalman filter, the classification results are relatively stable. It is shown that for this particular case the result using extended Kalman filter is better than using principal component analysis.", "num_citations": "13\n", "authors": ["430"]}
{"title": "An interactive molecular visualization system for education in immersive multi-projection virtual environment\n", "abstract": " In this paper, our initial work on the use of visualization and virtual reality for education especially for providing three-dimensional concepts of molecular structure was presented. Our system is composed of a hybrid screen, multi-projectors, PC cluster, 6DOF haptic device etc. It offers a channel to reach into the molecular space in an immersive environment, allows user to employ an intuitive 6DOF haptic device Spidar-G to control the perspective. For educators, it can serve as a good instructional aid for helping students to understand molecular structure through effective visual representation and interactive manipulation.", "num_citations": "13\n", "authors": ["430"]}
{"title": "Pulsar candidate classification using generative adversary networks\n", "abstract": " Discovering pulsars is a significant and meaningful research topic in the field of radio astronomy. With the advent of astronomical instruments, the volume and rate of data acquisition have grown exponentially. This development necessitates a focus on artificial intelligence (AI) technologies that can mine large astronomical data sets. Automatic pulsar candidate identification (APCI) can be considered as a task determining potential candidates for further investigation and eliminating the noise of radio-frequency interference and other non-pulsar signals. As reported in the existing literature, AI techniques, especially convolutional neural network (CNN)-based techniques, have been adopted for APCI. However, it is challenging to enhance the performance of CNN-based pulsar identification because only an extremely limited number of real pulsar samples exist, which results in a crucial class imbalance problem\u00a0\u2026", "num_citations": "12\n", "authors": ["430"]}
{"title": "Hypoxia\u2010inducible factor 1\u03b1 (HIF\u20101\u03b1) is a major determinant in the enhanced function of muscle\u2010derived progenitors from MRL/MpJ mice\n", "abstract": " Although the mouse strain Murphy Roths Large (MRL/MpJ) possesses high regenerative potential, the mechanism of tissue regeneration, including skeletal muscle, in MRL/MpJ mice after injury is still unclear. Our previous studies have shown that muscle\u2010derived stem/progenitor cell (MDSPC) function is significantly enhanced in MRL/MpJ mice when compared with MDSPCs isolated from age\u2010matched wild\u2010type (WT) mice. Using mass spectrometry\u2013based proteomic analysis, we identified increased expression of hypoxia\u2010inducible factor (HIF) 1\u03b1 target genes (expression of glycolytic factors and antioxidants) in sera from MRL/MpJ mice compared with WT mice. Therefore, we hypothesized that HIF\u20101\u03b1 promotes the high muscle healing capacity of MRL/MpJ mice by increasing the potency of MDSPCs. We demonstrated that treating MRL/MpJ MDSPCs with dimethyloxalylglycine and CoCl2 increased the\u00a0\u2026", "num_citations": "12\n", "authors": ["430"]}
{"title": "PILAE: A non-gradient descent learning scheme for deep feedforward neural networks\n", "abstract": " In this work, a non-gradient descent learning scheme is proposed for deep feedforward neural networks (DNN). As we known, autoencoder can be used as the building blocks of the multi-layer perceptron (MLP) deep neural network. So, the MLP will be taken as an example to illustrate the proposed scheme of pseudoinverse learning algorithm for autoencoder (PILAE) training. The PILAE with low rank approximation is a non-gradient based learning algorithm, and the encoder weight matrix is set to be the low rank approximation of the pseudoinverse of the input matrix, while the decoder weight matrix is calculated by the pseudoinverse learning algorithm. It is worth to note that only few network structure hyperparameters need to be tuned. Hence, the proposed algorithm can be regarded as a quasi-automated training algorithm which can be utilized in autonomous machine learning research field. The experimental results show that the proposed learning scheme for DNN can achieve better performance on considering the tradeoff between training efficiency and classification accuracy.", "num_citations": "12\n", "authors": ["430"]}
{"title": "Image stitching with single-hidden layer feedforward neural networks\n", "abstract": " In this paper, a novel image stitching method is proposed, which utilizes scale-invariant feature transform (SIFT) feature and single-hidden layer feedforward neural network (SLFN) to get higher precision of parameter estimation. In this method, features are extracted from the image sets by the SIFT descriptor and form into the input vector of the SLFN. The output of the SLFN is those translation, rotation and scaling parameters with respect to reference and registered image sets. We also apply a fast learning scheme, called pseudoinverse learning, to train SLFN to get higher training efficiency. Comparative experiments are performed between our proposed method and the traditional random sample consensus (RANSAC) based method. The results show that our method has the advantage not only at accuracy but also remarkably at fast speed.", "num_citations": "12\n", "authors": ["430"]}
{"title": "Texture image classification with improved weber local descriptor\n", "abstract": " Texture features play an important role in image texture classification. Inspired by Weber\u2019s law, Weber Local Descriptor (WLD) has been proposed for image texture classification. Orientation component in Weber Local Descriptor is the gradient of an image, which does not properly represent the local spatial information of an image. In this paper for orientation component, we propose to compute the histogram of gradient instead of the gradient of an image. The gradient of an image is computed, then image is divided in to small spatial regions named as cells and histogram of each cell is obtained. We have tested our proposed scheme on publically available texture datasets named as Brodatz and KTH-TIPS2-a, which shows that our proposed method can achieve significant improvement as compared to the state-of-the-art method like Local Binary Pattern, Local Phase Quantization and Weber Local Descriptor.", "num_citations": "12\n", "authors": ["430"]}
{"title": "Combining affinity propagation with supervised dictionary learning for image classification\n", "abstract": " Recently support vector machines (SVM) using spatial pyramid matching (SPM) kernel have been highly successful in image classification applications. And linear spatial pyramid matching using sparse coding (ScSPM) scheme has been proposed to enhance the performance of SPM both in time and classification accuracy. In order to reduce the time complexity of dictionary construction process, sparse coding with affinity propagation method has been proposed in this paper. Because the dictionary used for sparse coding plays a key role in these methods, we also adopt supervised dictionary learning method to construct dictionary. The coding coefficients of each class have greater separability for SVM classification. Substantial experiments on Scene15 and CalTech101 image datasets have been conducted to investigate the performance of proposed approach in multi-class image classification; the results\u00a0\u2026", "num_citations": "12\n", "authors": ["430"]}
{"title": "Feature data optimization with LVQ technique in semantic image annotation\n", "abstract": " In order to improve the classifier performance in semantic image annotation, we propose a novel method which adopts learning vector quantization (LVQ) technique to optimize low level feature data extracted from given image. Some representative vectors are selected with LVQ to train support vector machine (SVM) classifier instead of using all feature data. Performance is compared between the methods with and without feature data optimization when SVM is applied to semantic image annotation. Experiment results show that the proposed method has a better performance than that without using LVQ technique.", "num_citations": "12\n", "authors": ["430"]}
{"title": "Comparison on Bayesian YING-YANG Theory based Clustering Number Selection Criterion with Information Theoretical Criteria\n", "abstract": " A criterion based on the Bayesian Ying Yang learning theory and system was proposed by Xu (1995, 1996, 1997) for selecting the number of clusters in the clustering analysis and the number of Gaussians in a finite mixture model. In this paper we compare the performance of this criterion with other existing cluster number selection criteria such as Akaike's information criterion (AIC), CAIC, etc.", "num_citations": "12\n", "authors": ["430"]}
{"title": "Fine-grained deep knowledge-aware network for news recommendation with self-attention\n", "abstract": " On-line news reading has become the most popular way for user to obtain real-time information. With the millions of news, it is a key challenge to help user find the articles that are interesting to read. Although great achievements have been made, there is little work to focus on combing news language with external knowledge graphs and expanding news text from a word-level. Taking this issue into consideration, we introduce a novel self-attention based mechanism in news recommendation. The key component of our model is multiple self-attention modules: the word-level attention, which takes tags of news, entities in external knowledge graph and entities' contexts as the input to calculate the semantic-level and knowledge-level representation of the news; the item-level attention module, which used to fuse the two-level representation into the same low-dimension and get a overall embedding of user history\u00a0\u2026", "num_citations": "11\n", "authors": ["430"]}
{"title": "Review of pseudoinverse learning algorithm for multilayer neural networks and applications\n", "abstract": " In this work, we give an overview of pseudoinverse learning (PIL) algorithm as well as applications. PIL algorithm is a non-gradient descent algorithm for multi-layer perception. The weight matrix of network can be exactly computed by PIL algorithm. So PIL algorithm can effectively avoid the problem of low convergence and local minima. Moreover, PIL does not require user-selected parameters, such as step size and learning rate. This algorithm has achieved good application in the fields of software reliability engineering, astronomical data analysis and so on.", "num_citations": "11\n", "authors": ["430"]}
{"title": "Self-running and self-floating two-dimensional actuator using near-field acoustic levitation\n", "abstract": " Non-contact actuators are promising technologies in metrology, machine-tools, and hovercars, but have been suffering from low energy efficiency, complex design, and low controllability. Here we report a new design of a self-running and self-floating actuator capable of two-dimensional motion with an unlimited travel range. The proposed design exploits near-field acoustic levitation for heavy object lifting, and coupled resonant vibration for generation of acoustic streaming for non-contact motion in designated directions. The device utilizes resonant vibration of the structure for high energy efficiency, and adopts a single piezo element to achieve both levitation and non-contact motion for a compact and simple design. Experiments demonstrate that the proposed actuator can reach a 1.65\u2009cm/s or faster moving speed and is capable of transporting a total weight of 80 g under 1.2\u2009W power consumption.", "num_citations": "11\n", "authors": ["430"]}
{"title": "A pre-selecting base kernel method in multiple kernel learning\n", "abstract": " The pre-defined base kernel greatly affects the performance of multiple kernel learning (MKL), but selecting the pre-defined base kernel still has no theoretical guidance. In practice, it is very difficult to select a set of appropriate base kernels without prior knowledge. In this paper, we propose a general strategy to pre-select a reasonable set of base kernels before the optimization process of MKL solvers. This strategy is based on the combination of minimal redundancy maximal relevance criteria and kernel target alignment (MRMRKA). First, we determine some candidate kernels while maintaining diversity of information; second, a set of base kernels with high discriminative ability and large diversity are selected using the MRMRKA method. These pre-selected base kernels will be used in the optimization process of the existing MKL solvers to generate better results. The experiments conducted on UCI and 15-scene\u00a0\u2026", "num_citations": "11\n", "authors": ["430"]}
{"title": "Building modeling from a single image applied in urban reconstruction\n", "abstract": " Image-based building reconstruction is a hot topic in computer vision and computer graphics. However, few studies have been conducted on reconstruction from a single image because it is an ill-conditioned problem and is very difficult to resolve. In the current paper, we present an efficient method by matching contours between an image and the projection of three-dimensional (3D) models. Our method simplifies the reconstruction process and avoids camera calibrating and human interaction. Given a building photo captured in daily life as input, we first segment the photo into different regions and then automatically extract the contour of the building. Finally, we obtain the 3D building model by matching the contour of the building with the projection contour of the 3D models from different views stored in the model database. Experiments show that our method is efficient and effective, especially for building photos\u00a0\u2026", "num_citations": "11\n", "authors": ["430"]}
{"title": "An improved random sampling LDA for face recognition\n", "abstract": " Linear Discriminant Analysis (LDA) is one of the most used feature extraction techniques for face recognition. However, it often suffers from the small sample size problem with high dimension setting. Random Subspace Method (RSM) is a popular combining technique to improve weak classifier. Nevertheless, it remains a problem how to construct an optimal random subspace for discriminant analysis. In this paper, we propose an improved random sampling LDA for face recognition. Firstly, AdaBoost is adopted to select Gabor feature and remove redundant information. Secondly, in the selected Gabor feature space, we combine principal component analysis and RSM approaches to construct optimal random subspaces for LDA. After that, direct LDA (D-LDA) and R-LDA is applied in each subspace, respectively. Final results are obtained by combining all the LDA classifiers using a fusion rule. Experiments with both\u00a0\u2026", "num_citations": "11\n", "authors": ["430"]}
{"title": "Empirically validating software metrics for risk prediction based on intelligent methods\n", "abstract": " The software systems which are related to national projects are always very crucial. This kind of systems always involves hi-tech factors and has to spend a large amount of money, so the quality and reliability of the software deserve to be further studied. Hence, we propose to apply three classification techniques most used in data mining fields: Bayesian belief networks (BBN), nearest neighbor (NN) and decision tree (DT), to validate the usefulness of software metrics for risk prediction. Results show that comparing with metrics such as Lines of code (LOQ and Cyclomatic complexity (V(G)) which are traditionally used for risk prediction, Halstead program difficulty (D), Number of executable statements (EXEC) and Halstead program volume (V) are the more effective metrics as risk predictors. By analyzing we also found that BBN was more effective than the other two methods in risk prediction", "num_citations": "11\n", "authors": ["430"]}
{"title": "Kernel ICA feature extraction for spectral recognition of celestial objects\n", "abstract": " In the literature of astronomical spectral classification, linear principle component analysis (PCA) was frequently employed to extract features of spectra data. However, the spectral data are too complicated to be well described by a linear model. In this paper, kernel independent component analysis (KICA), which contains a nonlinear kernel mapping component, is adopted to extract features from the spectra of galaxies. Then, a radial basis function neural network is adopted as a classifier to implement the classification. Experiments with real-world spectral data set show that KICA is a very appropriate technique to describe the important features of celestial objects, and the correct classification rate is improved compared with PCA method.", "num_citations": "11\n", "authors": ["430"]}
{"title": "A new strategy to improve image fusion effect\n", "abstract": " The purpose of image fusion is to combine information from several different source images to one image, which becomes reliable and much easier to be comprehended by people. Based on analyzing the relations of average and standard deviation of the two or more source images, a new strategy to improve image fusion effect and a new evaluation measure named RAS (the ratio between average and standard deviation) are proposed in this paper. We apply wavelet transform to decompose an image into low-frequency sub-image and high-frequency sub-images and apply different fusion rules respectively to low-frequency sub-image and high-frequency sub-images. According to subjective evaluation and objective criteria, such as entropy, root mean square error (RMSE), peak-to-peak signal-to-noise ratio (PSNR), RAS, the proposed strategy is very effective and universal to some extent for fusing a class of\u00a0\u2026", "num_citations": "11\n", "authors": ["430"]}
{"title": "Pseudoinverse learners: New trend and applications to big data\n", "abstract": " Pseudoinverse learner (PIL), a kind of multilayer neural networks (MLP) trained with pseudoinverse learning algorithm, is a novel learning framework. It has drawn increasing attention in the areas of large-scale computing, high-speed signal processing, artificial intelligence and so on. In this paper, we briefly review the pseudoinverse learning algorithm and discuss the characteristics as well as its variants. Some new viewpoints to PIL algorithm are presented, and currently developments of PIL algorithm for autoencoder is presented under the framework of deep learning. Some new trends on PIL-based learning are also discussed. Moreover, we present several interesting PIL applications to demonstrate the practical advances on the big data analysis topic.", "num_citations": "10\n", "authors": ["430"]}
{"title": "A deconvolution extraction method for 2D multi-object fibre spectroscopy based on the regularized least-squares QR-factorization algorithm\n", "abstract": " This paper presents an efficient method for the extraction of astronomical spectra from two-dimensional (2D) multifibre spectrographs based on the regularized least-squares QR-factorization (LSQR) algorithm. We address two issues: we propose a modified Gaussian point spread function (PSF) for modelling the 2D PSF from multi-emission-line gas-discharge lamp images (arc images), and we develop an efficient deconvolution method to extract spectra in real circumstances. The proposed modified 2D Gaussian PSF model can fit various types of 2D PSFs, including different radial distortion angles and ellipticities. We adopt the regularized LSQR algorithm to solve the sparse linear equations constructed from the sparse convolution matrix, which we designate the deconvolution spectrum extraction method. Furthermore, we implement a parallelized LSQR algorithm based on graphics processing unit\u00a0\u2026", "num_citations": "10\n", "authors": ["430"]}
{"title": "Diversity project: Mapping of diversity teaching and learning in nurse education curriculum\n", "abstract": " Diversity and inclusivity in higher education and health care have gained prominence in recent years and this means that institutions\u2019 educational programmes need to incorporate teaching and learning that is responsive to diversity. This paper reports findings from a diversity teaching and learning mapping project. The aim of the mapping project was to map out when and how the various themes on diversity in all course curricula are addressed in a university\u2019s School of Nursing. The project adopted the following methodologies: documentary reviews of curriculum documents, handbooks and timetables, followed by qualitative interviews with module leaders and teachers. The documentary reviews provided a map of where diversity teaching and learning tended to occur and the interviews yielded six major themes central to diversity: definition, importance, confidence, challenges, resources and future implications\u00a0\u2026", "num_citations": "10\n", "authors": ["430"]}
{"title": "\u56fe\u50cf\u8bed\u4e49\u81ea\u52a8\u6807\u6ce8\u53ca\u5176\u7c92\u5ea6\u5206\u6790\u65b9\u6cd5\n", "abstract": " \u6458 \u8981 \u7f29\u5c0f\u56fe\u50cf\u4f4e\u5c42\u89c6\u89c9\u7279\u5f81\u4e0e\u9ad8\u5c42\u8bed\u4e49\u4e4b\u95f4\u7684\u9e3f\u6c9f, \u4ee5\u63d0\u9ad8\u56fe\u50cf\u8bed\u4e49\u81ea\u52a8\u6807\u6ce8\u7684\u7cbe\u5ea6, \u8fdb\u800c\u5feb\u901f\u6ee1\u8db3\u7528\u6237\u68c0\u7d22\u56fe\u50cf\u7684\u9700\u6c42, \u4e00\u76f4\u662f\u56fe\u50cf\u8bed\u4e49\u81ea\u52a8\u6807\u6ce8\u7814\u7a76\u7684\u5173\u952e. \u7c92\u5ea6\u5206\u6790\u65b9\u6cd5\u662f\u4e00\u79cd\u5c42\u6b21\u7684, \u91cd\u8981\u7684\u6570\u636e\u5206\u6790\u65b9\u6cd5, \u4e3a\u590d\u6742\u95ee\u9898\u7684\u6c42\u89e3\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def. \u56fe\u50cf\u7406\u89e3\u4e0e\u5206\u6790\u7684\u7c92\u5ea6\u4e0d\u540c, \u56fe\u50cf\u8bed\u4e49\u6807\u6ce8\u7684\u7cbe\u5ea6\u5219\u4e0d\u540c, \u68c0\u7d22\u7684\u6548\u7387\u53ca\u51c6\u786e\u5ea6\u4e5f\u5c31\u4e0d\u540c. \u672c\u6587\u5bf9\u76ee\u524d\u56fe\u50cf\u8bed\u4e49\u81ea\u52a8\u6807\u6ce8\u6a21\u578b\u7684\u65b9\u6cd5\u8fdb\u884c\u7efc\u8ff0\u548c\u5206\u6790, \u9610\u8ff0\u4e86\u7c92\u5ea6\u5206\u6790\u65b9\u6cd5\u7684\u601d\u60f3, \u6a21\u578b\u53ca\u5176\u5728\u56fe\u50cf\u8bed\u4e49\u6807\u6ce8\u8fc7\u7a0b\u4e2d\u7684\u5e94\u7528, \u63a2\u7d22\u4e86\u4ee5\u7c92\u5ea6\u5206\u6790\u4e3a\u57fa\u7840\u7684\u56fe\u50cf\u8bed\u4e49\u81ea\u52a8\u6807\u6ce8\u65b9\u6cd5\u5e76\u7ed9\u51fa\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u65b9\u5411.", "num_citations": "10\n", "authors": ["430"]}
{"title": "Automated spectral classification using template matching\n", "abstract": " An automated spectral classification technique for large sky surveys is proposed. We firstly perform spectral line matching to determine redshift candidates for an observed spectrum, and then estimate the spectral class by measuring the similarity between the observed spectrum and the shifted templates for each redshift candidate. As a byproduct of this approach, the spectral redshift can also be obtained with high accuracy. Compared with some approaches based on computerized learning methods in the literature, the proposed approach needs no training, which is time-consuming and sensitive to selection of the training set. Both simulated data and observed spectra are used to test the approach; the results show that the proposed method is efficient, and it can achieve a correct classification rate as high as 92.9%, 97.9% and 98.8% for stars, galaxies and quasars, respectively.", "num_citations": "10\n", "authors": ["430"]}
{"title": "Stellar spectral recognition based on wavelet de-noising and SVM\n", "abstract": " The present paper describes a new technique for stellar spectral recognition. Considering the characteristics of stellar spectral data, support vector machine (SVM) was adopted to build a recognition system as kernel. Because stellar spectral data sets are usually extremely noisy, the correct classification rate of direct applying SVM is low. Consequently, wavelet de-noising method was proposed to reduce noise first and extract the main characteristics of stellar spectra. Then SVM was used for the recognition. Based on the real-world stellar spectra contributed by Jacoby et al.(1984), it has proven that there will be a better performance using this composite classifier which combines wavelet and SVM than using SVM with principle component analysis data dimension reduction technique. From the experiment of comparison of discriminant analysis and SVM based on stellar spectra for evolutionary synthesis, we can see that the correct classification rate of SVM is higher than that of discriminant analysis methods, and a well generalization ability is achieved.", "num_citations": "10\n", "authors": ["430"]}
{"title": "Preferences and experiences of muslim patients and their families in muslim-majority countries for end-of-life care: a systematic review and thematic analysis\n", "abstract": " BackgroundCare for people with progressive illness should be person-centred and account for their cultural values and spiritual beliefs. There are an estimated 1.7 billion Muslims worldwide, largely living in low-and middle-income countries.AimsThis study aimed to identify, appraise, and integrate the evidence for the experiences and preferences of Muslim patients/families for end-of-life care in Muslim-majority countriesDesignSystematic reviewData sourcesPsychoINFO, MEDLINE, Embase, Global Health, CINAHL, Cochrane Library and Registry of Clinical Trials Trial, Pubmed, ASSIA, Social Services Abstracts, Sociological Abstracts, Social Policy & Practice, and Scopus were searched until December 2018. Handsearching was performed, and grey literature, included. Qualitative studies analysed using thematic analysis and quantitative component provided triangulation.ResultsThe initial search yielded n=5,098\u00a0\u2026", "num_citations": "9\n", "authors": ["430"]}
{"title": "Pulsar candidate identification with artificial intelligence techniques\n", "abstract": " Discovering pulsars is a significant and meaningful research topic in the field of radio astronomy. With the advent of astronomical instruments such as he Five-hundred-meter Aperture Spherical Telescope (FAST) in China, data volumes and data rates are exponentially growing. This fact necessitates a focus on artificial intelligence (AI) technologies that can perform the automatic pulsar candidate identification to mine large astronomical data sets. Automatic pulsar candidate identification can be considered as a task of determining potential candidates for further investigation and eliminating noises of radio frequency interferences or other non-pulsar signals. It is very hard to raise the performance of DCNN-based pulsar identification because the limited training samples restrict network structure to be designed deep enough for learning good features as well as the crucial class imbalance problem due to very limited number of real pulsar samples. To address these problems, we proposed a framework which combines deep convolution generative adversarial network (DCGAN) with support vector machine (SVM) to deal with imbalance class problem and to improve pulsar identification accuracy. DCGAN is used as sample generation and feature learning model, and SVM is adopted as the classifier for predicting candidate's labels in the inference stage. The proposed framework is a novel technique which not only can solve imbalance class problem but also can learn discriminative feature representations of pulsar candidates instead of computing hand-crafted features in preprocessing steps too, which makes it more accurate for automatic pulsar\u00a0\u2026", "num_citations": "9\n", "authors": ["430"]}
{"title": "A practice guide of software aging prediction in a web server based on machine learning\n", "abstract": " In the past two decades, software aging has been studied by both academic and industry communities. Many scholars focused on analytical methods or time series to model software aging process. While machine learning has been shown as a very promising technique in application to forecast software state: normal or aging. In this paper, we proposed a method which can give practice guide to forecast software aging using machine learning algorithm. Firstly, we collected data from a running commercial web server and preprocessed these data. Secondly, feature selection algorithm was applied to find a subset of model parameters set. Thirdly, time series model was used to predict values of selected parameters in advance. Fourthly, some machine learning algorithms were used to model software aging process and to predict software aging. Fifthly, we used sensitivity analysis to analyze how heavily outcomes\u00a0\u2026", "num_citations": "9\n", "authors": ["430"]}
{"title": "A comparative study of different feature mapping methods for image\n", "abstract": " Automatic image annotation and tagging is necessary for indexing and searching of images using querying a text. It is widely used in search engines like Google, Yahoo, Baidu, etc. Fast Image Tagging (FastTag) algorithm is proposed to accelerate image annotation process, while keeping the precision of automatic image annotation results. Feature mapping is used to map image features vectors onto higher dimensional feature space. Feature mapping methods plays an important role in automatic image annotation. In this paper, we have compared 6 kernels, among which four kernels are used in homogeneous feature mapping and two kernels are used in discriminative tree based feature mapping, to investigate which feature mapping performs better for automatic image annotation. The performance of these methods has been analyzed by conducting intensive experiments on three different datasets as used by\u00a0\u2026", "num_citations": "9\n", "authors": ["430"]}
{"title": "A novel hybridization of artificial neural networks and ARIMA models for forecasting resource consumption in an IIS web server\n", "abstract": " Software aging has been observed in a long running software application. A technique named rejuvenation is proposed to counteract this problem. The key to the aging and rejuvenation problem is how to analyze/forecast the resource consumption of software system. In this paper, we propose a methodology of hybrid ARIMA and artificial neural networks to forecast resource consumption in an IIS web server which is a running commercial server and subjected to software aging. The proposed hybrid method consists of two steps. In the first step, an ARIMA model is used to analyze the linear component of the data. In the second step, an artificial neural network model is developed to model the residuals from ARIMA model. The results show that the proposed hybrid model can be a good trade-off to forecast resource consumption.", "num_citations": "9\n", "authors": ["430"]}
{"title": "BP neural networks with harmony search method-based training for epileptic EEG signal classification\n", "abstract": " In this paper, the Harmony Search (HS)-based BP neural networks are used for the classification of the epileptic electroencephalogram (EEG) signals. It is well known that the gradient descent-based learning method can result in local optima in the training of BP neural networks, which may significantly affect their approximation performances. Two HS methods, the original version and a new variation recently proposed by the authors of the present paper, are applied here to optimize the weights in the BP neural networks for the classification of the epileptic EEG signals. Simulations have demonstrated that the classification accuracy of the BP neural networks can be remarkably improved by the HS method-based training.", "num_citations": "9\n", "authors": ["430"]}
{"title": "Image modeling with combined optimization techniques for image semantic annotation\n", "abstract": " Image semantic annotation can be viewed as a multi-class classification problem, which maps image features to semantic class labels, through the procedures of image modeling and image semantic mapping. Bayesian classifier is usually adopted for image semantic annotation which classifies image features into class labels. In order to improve the accuracy and efficiency of classifier in image annotation, we propose a combined optimization method which incorporates affinity propagation algorithm, optimizing training data algorithm, and modeling prior distribution with Gaussian mixture model to build Bayesian classifier. The experiment results illustrate that the classifier performance is improved for image semantic annotation with proposed method.", "num_citations": "9\n", "authors": ["430"]}
{"title": "Palette-style volume visualization.\n", "abstract": " In this paper we propose a palette-style volume visualization interface which aims at providing users with an intuitive volume exploration tool. Our system is inspired by the widely used wheel-style color palette. The system initially creates a set of direct volume rendered images (DVRIs) manually or automatically, and arranges them over a circle in 2D image space. Based on the initial set of DVRIs called primary DVRIs which imitate the primary colors in the color wheel, users can create more DVRIs on the wheel using PhotoShop-style image editing operations such as the fusing operation. With our system, non-expert users can easily navigate and explore volumetric data. In addition, users can always know where they have been, where they are, and where they could go in a visualization process and hence redundant exploration can be avoided.", "num_citations": "9\n", "authors": ["430"]}
{"title": "Classification of stellar spectral data using svm\n", "abstract": " In this paper a new technique is developed on stellar spectral classification. Because stellar spectral data sets are usually extremely noisy, wavelet de-noising method is proposed to reduce noise first. Then the support vector machines (SVM) is used for the classification. Experimental results show that in most cases, there will be a better performance using this composite classifier than using SVM with principle component analysis data dimension reduction technique.", "num_citations": "9\n", "authors": ["430"]}
{"title": "Spectral pattern recognition with regularized Gaussian classifier\n", "abstract": " In this paper we propose to adopt a regularized Gaussian classifier for spectral pattern recognition. To deal with ill-posed covariance matrix estimation problem in constructing the classifier, we develop a novel technique for fast estimation of regularization parameter. Experiments are conducted to investigate the real-world stellar spectra data recognition with the developed technique. Higher classification accuracy results are obtained and demonstrated.", "num_citations": "9\n", "authors": ["430"]}
{"title": "The economic burden of cancer care for Syrian refugees: a population-based modelling study\n", "abstract": " BackgroundCancer represents a substantial health burden for refugees and host countries. However, no reliable data on the costs of cancer care for refugees are available, which limits the planning of official development assistance in humanitarian settings. We aimed to model the direct costs of cancer care among Syrian refugee populations residing in Jordan, Lebanon, and Turkey.MethodsIn this population-based modelling study, direct cost per capita and per incident case for cancer care were estimated using generalised linear models, informed by a representative dataset of cancer costs drawn from 27 EU countries. A range of regression specifications were tested, in which cancer costs were modelled using different independent variables: gross domestic product (GDP) per capita, crude or age-standardised incidence, crude or age-standardised mortality, and total host country population size. Models were\u00a0\u2026", "num_citations": "8\n", "authors": ["430"]}
{"title": "A novel method for traffic sign recognition based on dcgan and mlp with pilae algorithm\n", "abstract": " This paper centers on a novel method for traffic sign recognition (TSR). The method comprises of two major steps: 1) make strong representations for TSR images, by extraction deep features with the deep convolutional generative adversarial networks (DCGANs) and 2) classifier defined by multilayer perceptron (MLP) neural networks trained with a pseudoinverse learning autoencoder (PILAE) algorithm. The PILAE training process is considered efficient in which it does not require the number of hidden layers specified nor does it need the setting of the learning control parameters. This results in the PILAE classifier attaining a better performance in terms of both accuracy and efficiency. Empirical results from the German TSR (GTSRB) and Belgium traffic sign classification (BTSC) have proved that TSR achieves excellent results with other algorithms and reasonably low complexity.", "num_citations": "8\n", "authors": ["430"]}
{"title": "A study of deep belief network based chinese speech emotion recognition\n", "abstract": " This paper presents a deep learning method application to the extraction of emotions included in Chinese speech with a deep belief network (DBN) structure. Eight proper features such as pitch, mel frequency cepstrum coefficient (MFCC) are chosen from Mandarin speech used as network inputs, and a DBN classifier is used instead of traditional shallow learning methods to recognition of emotions. Experiment studies have proven that its recognition rate is higher than that of the traditional back propagation (BP) method and support vector machine (SVM) classifier.", "num_citations": "8\n", "authors": ["430"]}
{"title": "An adaptive regularization method for sparse representation\n", "abstract": " Sparse representation (SR) or sparse coding (SC), which assumes the data vector can be sparse represented by linear combination over basis vectors, has been successfully applied in machine learning and computer vision tasks. In order to solve sparse representation problem, regularization technique is applied to constrain the sparsity of coefficients of linear representation. In this paper, a reconstruction-error-based adaptive regularization parameter estimation method is proposed to improve the representation ability of SR. The adaptive regularization parameter aims to balance the reconstruction error and the sparsity of coefficient vector and to minimize reconstruction error. Substantial experiments are performed on some benchmark databases. Simulation results demonstrate that this adaptive regularization parameter estimation method can find a proper parameter for each test sample, consequently, can\u00a0\u2026", "num_citations": "8\n", "authors": ["430"]}
{"title": "Improved PSO algorithm with harmony search for complicated function optimization problems\n", "abstract": " Improved particle swarm optimization algorithm with harmony search (IHPSO) is proposed in this paper. This algorithm takes particle swarm search direction estimation mechanism and harmony search (HS) approach to particle swarm optimization (PSO) algorithm, which increases the search capability of PSO algorithm considerably. The proposed algorithm initializes a new search with harmony pitch adjusting or random selection when PSO search direction is estimated incorrectly. This can provide further opportunities of finding better solutions for the particle swarm by guiding the entire particle swarm to promising new regions of the search space and accelerating the search. PSO, HPSO and IHPSO, as well as other advanced PSO procedures from the literature were compared on several benchmark test functions extensively. Statistical analyses of the experimental results indicate that the performance of\u00a0\u2026", "num_citations": "8\n", "authors": ["430"]}
{"title": "Improvement of texture image segmentation based on visual model\n", "abstract": " As an important aspect of image segmentation, texture segmentation has long been one of the hot spots in segmentation field. In this paper, the human visual cognitive model is used as a new texture feature extraction method for image texture segmentation. In order to promote the effect of clustering segmentation method, spatial location information is considered to smooth the segment result. Experiments show that the proposed texture feature descriptor with visual cognitive model is more conducive than that of the Gabor feature.", "num_citations": "8\n", "authors": ["430"]}
{"title": "Combining the contrast information with LPQ for texture classification\n", "abstract": " Texture classification is an important problem in image analysis. A considerable amount of research work has been done for local or global rotation invariant feature extraction for texture classification. Local invariant features contain the spatial information, but usually do not have the contrast information. A new hybrid approach is proposed which considers the contrast information in spatial domain and the phase information in frequency domain of the image. It uses the joint histogram of the two complementary features, local phase quantization (LPQ) and the contrast of the image. Support vector machine is used for classification. The experimental results on standard benchmark datasets for texture classification Brodatz and KTH-TIPS2-a show that the proposed method can achieve significant improvement compared to the LPQ, Gabor filer or local Binary Pattern methods.", "num_citations": "8\n", "authors": ["430"]}
{"title": "Multi-level kernel machine for scene image classification\n", "abstract": " Recently, a new representation for recognizing instances and categories of scenes called spatial Principal component analysis of Census Transform histograms (PACT) has shown its excellent performance in the scene image classification task. PACT captures local structures of an image through the Census Transform (CT), meanwhile, large scale structures are captured by the strong correlation between neighboring CT values and the histogram. However, the original spatial PACT only simply concatenates all levels compact histograms together, and discards the difference between various levels. In order to improve this problem, we propose a multi-level kernel machine method, which computes a set of base kernels at each level of pyramid of PACT, and finds optimal weights for best fusing all these base kernels for scene recognition. Experiments on two popular benchmark datasets demonstrate that our\u00a0\u2026", "num_citations": "8\n", "authors": ["430"]}
{"title": "Epileptic Electroencephalogram Signal Classification based on Sparse Representation.\n", "abstract": " Epilepsy seizure detection in Electroencephalogram (EEG) is a major issue in the diagnosis of epilepsy and it can be considered as a classification problem. According to the particular property of EEG, a novel method based on sparse representation is proposed for epilepsy detection in this paper. Classification accuracy, robustness on noisy data and parameters (the size of dictionary and the number of features) of proposed method are tested and analysed on the public available data. The proposed method can obtain the highest classification accuracy among the discussed methods when the suitable parameters are set, and the proposed method based on sparse representations for classification is robust to noise. This is consistent with the theory that sparse representations can capture the inherent structure of signal. Furthermore, it is shown by experiments that the optimal selection of the parameters is critical to the performance of epilepsy detection.", "num_citations": "8\n", "authors": ["430"]}
{"title": "Improvement of image modeling with affinity propagation algorithm for semantic image annotation\n", "abstract": " Semantic image annotation can be viewed as a classification problem, which maps image features to semantic labels, through the procedures of image modeling and image-semantic mapping. In order to improve the performance of image modeling, we propose a novel method which is based on affinity propagation (AP) algorithm. For a given image, low-level image features are extracted from image sub-blocks, and the image feature distribution can be modeled by a mixture of Gaussian components. An adaptive mixture component number selection algorithm which is related to the image semantic information is also developed. The AP algorithm is adopted to improve the efficiency and accuracy of the distribution estimation. For a given label, the overall distribution is modeled, and the mixture component number is selected according to the mixture exemplars extracted from all images and the average\u00a0\u2026", "num_citations": "8\n", "authors": ["430"]}
{"title": "Regularization versus dimension reduction, which is better?\n", "abstract": " There exist two main solutions for the classification of high-dimensional data with small number settings. One is to classify them directly in high-dimensional space with regularization methods, and the other is to reduce data dimension first, then classify them in feature space. However, which is better on earth? In this paper, the comparative studies for regularization and dimension reduction approaches are given with two typical sets of high-dimensional data from real world: Raman spectroscopy signals and stellar spectra data. Experimental results show that in most cases, the dimension reduction methods can obtain acceptable classification results, and cost less computation time. When the training sample number is insufficient and distribution is unbalance seriously, performance of some regularization approaches is better than those dimension reduction ones, but regularization methods cost more\u00a0\u2026", "num_citations": "8\n", "authors": ["430"]}
{"title": "Image registration with regularized neural network\n", "abstract": " In this paper, we propose a new method to improve the image registration accuracy in feedforward neural networks (FNN) based scheme. In the proposed method, Bayesian regularization is applied to improve the generalization capability of the FNN. The features extracted from the image sets by kernel independent component analysis (KICA) technique are input vectors of regularized FNN. The outputs of the neural network are those translation, rotation and scaling parameters with respect to reference and observed image sets. Comparative experiments are performed between FNN with regularization and without regularization under various conditions. The results show that the proposed method is much improved not only at accuracy but also remarkably at robust to noise.", "num_citations": "8\n", "authors": ["430"]}
{"title": "Two-dimensional PCA combined with PCA for neural network based image registration\n", "abstract": " A novel image registration scheme is proposed. In the proposed scheme, two-dimensional principal component analysis (2DPCA) combined with principal component analysis (PCA) is used to extract features from the image sets and these features are fed into feedforward neural networks to provide translation, rotation and scaling parameters. Comparison experiments between 2DPCA combined with PCA based method and the other two former methods: discrete cosine transform (DCT) and Zernike moment, are performed. The results indicate that the proposed scheme is both accurate and remarkably robust to noise.", "num_citations": "8\n", "authors": ["430"]}
{"title": "Kernel independent component analysis for gene expression data clustering\n", "abstract": " We present the use of KICA to perform clustering of gene expression data. Comparison experiments between KICA and two other methods, PCA and ICA, are performed. Three clustering algorithms, including weighted graph partitioning, k-means and agglomerative hierarchical clustering, and two similarity measures, including Euclidean and Pearson correlation, are also evaluated. The results indicate that KICA is an efficient feature extraction approach for gene expression data clustering. Our empirical study showed that clustering with the components instead of the original variables does improve cluster quality. In particular, the first few components by KICA capture most of the cluster structure. We also showed that clustering with components has different impact on different algorithms and different similarity metrics. Overall, we would recommend KICA before clustering gene expression data.", "num_citations": "8\n", "authors": ["430"]}
{"title": "Mixture of experts for stellar data classification\n", "abstract": " In this paper, mixture of experts model is first applied to stellar data classification. In order to obtain input patterns of mixture of experts model, we present a feature extraction method for stellar data based on wavelet packet transformation. Then a mixture of experts model is built for classifying the feature vectors. A comparative study of different classification methods such as a single radial basis function neural network is given. Real world data experimental results show that the mixture of experts has a good generalization ability and the obtained correct classification rate is higher than that of using a single neural network.", "num_citations": "8\n", "authors": ["430"]}
{"title": "Comparison of discriminant analysis methods applied to stellar data classification\n", "abstract": " In this study, five classifiers, namely quadratic discriminant analysis, linear discriminant analysis, regularlized discriminant analysis, leave-one-out covariance matrix estimate and Killback-Leibler information measure based method are considered for classification of stellar spectra data. Because stellar spectra data sets are severly ill-posed, we first adopt some feature selection method such as principal component analysis to reduce data dimensionality. The input of the classifiers are those selected features, and the cross-validation technique is used to optimize the regularization parameters. Experimental results show that in most cases, regularized classifiers are high classification rates than that of quadratic discriminant analysis, but parameter optimization is time consuming. From experiments of exhaustive searching regularization parameter, it is found that in some cases cross-validation method is not always\u00a0\u2026", "num_citations": "8\n", "authors": ["430"]}
{"title": "An ensemble classification model with unsupervised representation learning for driving stress recognition using physiological signals\n", "abstract": " This paper presents an ensemble classification model with unsupervised feature learning for driving stress recognition under real-world driving conditions. The driving stress is detected using drivers\u2019 different physiological signals, specifically the electromyogram, electrocardiogram, galvanic skin response, heart rate and respiration. The proposed model consists of two modules: 1) a multilayer representation learning module using autoencoder as its building block. The autoencoders are trained with a quasi-automated, non-gradient descent based unsupervised learning algorithm; 2) an ensemble classification module under the AdaBoost framework. The proposed model is completely data driven, does not require additional feature extraction and feature selection process, and can perform in an end-to-end way in which it takes the physiological signal as the input instead of the handcrafted features. Experimental\u00a0\u2026", "num_citations": "7\n", "authors": ["430"]}
{"title": "Fine-grained News Recommendation by Fusing Matrix Factorization, Topic Analysis and Knowledge Graph Representation\n", "abstract": " Most news recommendation methods focus on using textual information of news to solve data sparseness problem of collaborative filtering. While if the text is not informative enough, these methods can't work well. A collaborative model combining matrix factorization, topic analysis and knowledge graph representation is proposed by introducing the knowledge from external knowledge base to alleviate the deficiency of the text. The experiment conducted on real life news dataset shows that the joint model outperforms the state-of-the-art method by 14% in Recall@200 metric, and improves the recommendation performance on sparse items by 20%.", "num_citations": "7\n", "authors": ["430"]}
{"title": "Deep neural networks with local connectivity and its application to astronomical spectral data\n", "abstract": " The success of deep learning proves that deep models are able to achieve much better performance than shallow models in representation learning. However, deep neural networks with auto-encoder stacked structure suffer from low learning efficiency since common used training algorithms are variations of iterative algorithms based on the time-consuming gradient descent, especially when the network structure is complicated. To deal with this complicated network structure problem, we employ a \u201cdivide and conquer\u201d strategy to design a locally connected network structure to decrease the network complexity. The basic idea of our approach is to force the basic units of the deep architecture, e.g., auto-encoders, to extract local features in an analytical way without iterative optimization and assemble these local features into a unified feature. We apply this method to process astronomical spectral data to illustrate the\u00a0\u2026", "num_citations": "7\n", "authors": ["430"]}
{"title": "Comparison of linear dimensionality reduction methods in image annotation\n", "abstract": " Dimension reduction methods are often used to analyzing high dimensional data, linear dimension methods are commonly used due to their simple geometric interpretations and for effective computational cost. Dimension reduction plays an important role for feature selection. In this paper, we have given a detailed comparison of state-of-the-art linear dimension reduction methods like principal component analysis (PCA), random projections (RP), and locality preserving projections (LPP). We have determined which dimension reduction method performs better under the FastTag Image annotation framework. Experiments are conducted on three standard bench mark image datasets such as CorelSk, IAPRTC-12 and ESP game to compare the efficiency, effectiveness and also memory usage. A detailed comparison among the aforementioned dimension reduction method is given.", "num_citations": "7\n", "authors": ["430"]}
{"title": "Learning open-domain comparable entity graphs from user search queries\n", "abstract": " A frequent behavior of internet users is to compare among various comparable entities for decision making. As an instance, a user may compare among iPhone 5, Lumia 920 etc. products before deciding which cellphone to buy. However, it is a challenging problem to know what entities are generally comparable from the users' viewpoints in the open domain Web. In this paper, we propose a novel solution, which is known as Comparable Entity Graph Mining (CEGM), to learn an open-domain comparable entity graph from the user search queries. CEGM firstly mine seed comparable entity pairs from user search queries automatically using predefined query patterns. Next, it discovers more entity pairs with a confidence classifier in a bootstrapping fashion. Newly discovered entity pairs are organized into an open-domain comparable entity graph. Based on our empirical study over 1 billion queries of a commercial\u00a0\u2026", "num_citations": "7\n", "authors": ["430"]}
{"title": "Feature extraction based on sparse representation with application to epileptic EEG classification\n", "abstract": " Epilepsy seizure detection in electroencephalogram (EEG) is a major issue in the diagnosis of epilepsy, and it can be considered as a classification problem. Considering the particular property of EEG, which is sparse in Garbor dictionary, a feature extraction method based on sparse representation has been applied to epilepsy detection. To improve classification accuracy, in this article, a novel feature vector is developed, which not only can reflect the main structure, but also can give expression to the relation between main structure and residual information. Classification accuracy, efficiency, and robustness to noise of the new feature are explored and analyzed with publicly available data set. It is demonstrated by experiments that the classification accuracy and the efficiency are simultaneously enhanced with this new feature extraction method, and that the novel classification feature proposed in this work greatly\u00a0\u2026", "num_citations": "7\n", "authors": ["430"]}
{"title": "Combining the contrast information with WLD for texture classification\n", "abstract": " A considerable amount of research work has been done for texture classification using local or global feature extraction methods. Inspired by Weber's Law, a simple and robust Weber Local Descriptor (WLD) is a recently developed for local feature extraction. This WLD method did not consider the contrast information. In order to improve texture classification accuracy, we propose a hybrid approach that combines the WLD with contrast information in this paper. It utilizes the histogram of two complementary features WLD and the image variance calculated with the Probability Weighted Moments. Support vector machine is used for classification. The comparison of the proposed method with state of art methods like local binary pattern and WLD is experimental investigated on two publically available dataset, named as Brodatz and KTH-TIPS2-a. Results show that our proposed method outperforms over the state of art\u00a0\u2026", "num_citations": "7\n", "authors": ["430"]}
{"title": "Iris image analysis based on affinity propagation algorithm\n", "abstract": " Biometric identification is getting more and more popular as the demand of security increases. Iris is a promising biometric because of its stability and uniqueness. In this paper, a novel iris analysis method is proposed by using Affinity Propagation (AP) Algorithm. AP algorithm is a new clustering method by transforming the input matrix of similarity between pairs of data points. The proposed method is evaluated using the Chinese Academy of Sciences-Institute of Automation (CASIA) iris image database, the similarity between two irises is measured by their negative Hamming Distance. Experiments indicate that the algorithm has excellent solution in iris analysis, when AP algorithm is used as preprocess in an iris identification system, it can greatly decrease the time complexity of iris recognition.", "num_citations": "7\n", "authors": ["430"]}
{"title": "Improving depth resolution of diffuse optical tomography with an exponential adjustment method based on maximum singular value of layered sensitivity\n", "abstract": " The sensitivity of diffuse optical tomography (DOT) imaging exponentially decreases with the increase of photon penetration depth, which leads to a poor depth resolution for DOT. In this letter, an exponential adjustment method (EAM) based on maximum singular value of layered sensitivity is proposed. Optimal depth resolution can be achieved by compensating the reduced sensitivity in the deep medium. Simulations are performed using a semi-infinite model and the simulation results show that the EAM method can substantially improve the depth resolution of deeply embedded objects in the medium. Consequently, the image quality and the reconstruction accuracy for these objects have been largely improved.", "num_citations": "7\n", "authors": ["430"]}
{"title": "Ant colony optimization algorithm for remote sensing image classification using combined features\n", "abstract": " Applying ant colony optimization algorithm on the remote sensing image classification is a new research topic, and the preliminary experiments showed many promising characters, but there are also some shortcomings such as needing longer computing time and the classification accuracy is not high enough when using single feature of the image. In order to overcome these defects, we propose to combine gray feature and texture features to improve the classification rate in this paper. We also investigated the relationship between the number of ants and the classifications accuracy. The experimental results prove that the improvement achieved by using combined features vector.", "num_citations": "7\n", "authors": ["430"]}
{"title": "Stellar data classification using SVM with wavelet transformation\n", "abstract": " This paper presents a novel stellar spectra recognition technique, which is based on a wavelet transform and support vector machines. Due to the very low signal-to-noise ratio of real world spectral data, a de-noising method for stellar spectra is proposed using a wavelet transform based on the traditional threshold technique. Then support vector machines are adopted to complete the classification. Features in the spatial and wavelet domain are extracted and then used as input of support vector machines. Experimental results show that our technique is robust against noise and efficient in computation. The obtained correct classification rate of the proposed methods is much higher than using either a support vector machine alone or the principle component analysis feature extraction method.", "num_citations": "7\n", "authors": ["430"]}
{"title": "Weighted dual hesitant fuzzy set and its application in group decision making\n", "abstract": " The dual hesitant fuzzy set(DHFS) is a useful tool to deal with situations in which people are hesitant about providing their satisfaction degree and dissatisfaction degree. In this paper, we introduce the concepts of weighted dual hesitant fuzzy set(WDHFS) and weighted dual hesitant fuzzy element(WDHFE). Furthermore, we introduce some basic operations such as union, intersection, complement, multiplication and power operation of weighted dual hesitant fuzzy elements, investigate their operation properties, propose the score function and the accuracy function of WDHFE to compare two weighted dual hesitant fuzzy elements, and present two kinds of aggregation operators such as WDHFWA operator and WDHFWG operator to fuse weighted dual hesitant fuzzy information. Besides, we introduce the concept of hesitance degree of WDHFE, and propose a distance measure between weighted dual hesitant fuzzy\u00a0\u2026", "num_citations": "6\n", "authors": ["430"]}
{"title": "Predicting software abnormal state by using classification algorithm\n", "abstract": " Software aging, also called smooth degradation or chronics, has been observed in a long running software application, accompanied by performance degradation, hang/crash failures or both. The key for software aging problem is how to fast and accurately detect software aging occurrence, which is a hard work due to the long delay before aging appearance. In this paper, two problems about software aging prediction are solved, which are how to accurately find proper running software system variables to represent system state and how to predict software aging state in a running software system with a minor error rate. Firstly, the authors use proposed stepwise forward selection algorithm and stepwise backward selection algorithm to find a proper subset of variables set. Secondly, a classification algorithm is used to model software aging process. Lastly, t-test with k-fold cross validation is used to compare\u00a0\u2026", "num_citations": "6\n", "authors": ["430"]}
{"title": "Synergetic learning systems: Concept, architecture, and algorithms\n", "abstract": " Drawing on the idea that brain development is a Darwinian process of ``evolution + selection'' and the idea that the current state is a local equilibrium state of many bodies with self-organization and evolution processes driven by the temperature and gravity in our universe, in this work, we describe an artificial intelligence system called the ``Synergetic Learning Systems''. The system is composed of two or more subsystems (models, agents or virtual bodies), and it is an open complex giant system. Inspired by natural intelligence, the system achieves intelligent information processing and decision-making in a given environment through cooperative/competitive synergetic learning. The intelligence evolved by the natural law of ``it is not the strongest of the species that survives, but the one most responsive to change,'' while an artificial intelligence system should adopt the law of ``human selection'' in the evolution process. Therefore, we expect that the proposed system architecture can also be adapted in human-machine synergy or multi-agent synergetic systems. It is also expected that under our design criteria, the proposed system will eventually achieve artificial general intelligence through long term coevolution.", "num_citations": "6\n", "authors": ["430"]}
{"title": "Evaluating the effects of the pharmacological and nonpharmacological interventions to manage delirium symptoms in palliative care patients: systematic review\n", "abstract": " It is too early to abandon the use of antipsychotic medication entirely in the management of delirium, however there remains inadequate evidence to support the routine use of either pharmacological or nonpharmacological interventions for delirium treatment. Clinicians should determine the delirium subtype and severity, using this to inform the most appropriate pharmacological treatment if required. Further rigorously designed research is needed to seek clarity over whether the alleviation of symptoms is dose dependent, and to determine whether there is a severity threshold over which pharmacological interventions are most effective. Future research is required to evaluate nonpharmacological interventions in this population.", "num_citations": "6\n", "authors": ["430"]}
{"title": "What are the main symptoms and concerns reported by patients with advanced chronic heart failure?\u2014a secondary analysis of the Palliative care Outcome Scale (POS) and\u00a0\u2026\n", "abstract": " There is a lack of valid disease-specific patient-reported outcome measures (PROMS) for detecting symptoms and concerns in patients with advanced chronic heart failure (CHF). The Palliative care Outcome Scale (POS) and Integrated Palliative care Outcome Scale (IPOS) are specifically developed to capture the main symptoms and concerns of people severely affected by advanced disease. The aim of this study was to determine whether POS and IPOS captures the main symptoms and concerns self-reported by patients with advanced CHF secondary analysis of existing POS/IPOS data collected in three longitudinal studies was conducted. POS and IPOS start with an open-ended question for patients to report their main problems and concerns, followed by subsequent closed questions on a range of symptoms and other concerns. Descriptive statistics were used to report the results. The 102 participants from the three datasets had median age 81 years (SD +/- 9.84 years); 62% male; 87% white. A total of 107 concerns were reported in the first, open POS/IPOS question seeking the patient's main concerns. Of these, 83 (77%) were reflected in the subsequent IPOS/POS dosed questions. The high correspondence between the free-text responses and the dosed questions indicates that most issues are captured by the POS/IPOS items. In conclusion, the generic versions of POS and IPOS do capture the main problems and concerns of patients with advanced CHF. Minor adaptations and further psychometric validation of POS and IPOS are needed in this population.", "num_citations": "6\n", "authors": ["430"]}
{"title": "Markers of accelerated skeletal muscle regenerative response in Murphy Roths large mice: characteristics of muscle progenitor cells and circulating factors\n", "abstract": " The \u201csuper\u2010healing\u201d Murphy Roths Large (MRL/MpJ) mouse possesses a superior regenerative capacity for repair of many tissues, which makes it an excellent animal model for studying molecular and cellular mechanisms during tissue regeneration. As the role of muscle progenitor cells (MPCs) in muscle\u2010healing capacity of MRL/MpJ mice has not been previously studied, we investigated the muscle regenerative capacity of MRL/MpJ mice following muscle injury, and the results were compared to results from C57BL/6J (B6) age\u2010matched control mice. Our results show that muscle healing upon cardiotoxin injury was accelerated in MRL/MpJ mice and characterized by reduced necrotic muscle area, reduced macrophage infiltration, and more regenerated myofibers (embryonic myosin heavy chain+/centronucleated fibers) at 3, 5, and 12 days postinjury, when compared to B6 age\u2010matched control mice. These\u00a0\u2026", "num_citations": "6\n", "authors": ["430"]}
{"title": "Pseudoinverse learning algorithom for fast sparse autoencoder training\n", "abstract": " Sparse autoencoder is one approach to automatically learn features from unlabeled data and received significant attention during the development of deep neural networks. However, the learning algorithm of sparse autoencoder suffers from slow learning speed because of gradient descent based algorithms have many drawbacks. In this paper, a fast learning algorithm for sparse autoenceder is proposed which based on pseudoinverse learning algorithm (PIL). The proposed method calculates encoder weight matrix by truncating the pseudoinverse matrix of input data. The pseudoinverse truncation matrix is used as the weights of encoder, and then the input data is mapped to the hidden layer space through the biased ReLU activation function. The decoder weights are also can computed by the PIL. Unlike the gradient descent based algorithm, the proposed method does not require a time-consuming iterative\u00a0\u2026", "num_citations": "6\n", "authors": ["430"]}
{"title": "A GPU-based statistical image up-sampling method by using edge templates\n", "abstract": " Image up-sampling is very important in different fields, so an appropriate high-quality fast and efficient image up-sampling method is needed. Many interpolation-based up-sampling methods have been proposed by many researchers, but the quality of the resulting images is not satisfactory. The details of these images often cannot be accepted when we use them in many fields. On one hand, some of these methods are very fast, but produce images that are lacking many details and information of the original image; the others can produce high quality images, but the methods are very slow. In this paper, we propose a fast statistical image up-sampling method, and we use GPU to accelerate our up-sampling algorithm. We can obtain high quality images based on reducing the input resolution-grids dependency artefacts. And we can rebuild low resolution images' sharp edges fast and get high-quality up-sampled\u00a0\u2026", "num_citations": "6\n", "authors": ["430"]}
{"title": "Pulsar candidate selection by assembling positive sample emphasized classifiers\n", "abstract": " Pulsar candidate selection identifies prospective observations of modern radio pulsar surveys for further inspection in search of real pulsars. Typically, human experts visually select valuable candidates and eliminate radio frequency interference or other noises. Recently, machine learning methods are adopted to automate this task, which saves human labor and makes it possible for processing millions of observations efficiently. Considering the number of positive training samples are relatively too small and the cost of incorrectly labeling a real pulsar candidate as negative is large, we propose a novel hierarchical candidate-sifting model by emphasizing the cost of incorrect prediction of positive samples and assembling multiple classifiers trained with different weighting parameters. Experiments on three pulsar selection datasets demonstrate our proposed method improves the pulsar-sifting performance a lot\u00a0\u2026", "num_citations": "6\n", "authors": ["430"]}
{"title": "Removal of random-valued impulse noise by Khalimsky grid\n", "abstract": " In this paper, based on Khalimsky grid, a new Random-valued Impulse noise identification and removal method is proposed. Khalimsky grid can presents the neighborhood relationship among the pixels in the sliding window, effectively. The local statistics of Khalimsky grid is used to define an adaptive threshold range to identify the central pixel in current sliding window as noisy or noise free in an iterative way. The identified noisy pixel is replaced by local statistics of propose vertical direction based noise removal method. The performance of the propose method is evaluated on different test images and compared with state-of-the-art methods. Experimental results show that the propose method can identify the impulse noise, as well as can preserve the detailed information of an image, efficiently.", "num_citations": "6\n", "authors": ["430"]}
{"title": "Texture superpixels merging by color-texture histograms for color image segmentation\n", "abstract": " Pre-segmented pixels can reduce the difficulty of segmentation and promote the segmentation performance. This paper proposes a novel segmentation method based on merging texture superpixels by computing inner similarity. Firstly, we design a set of Gabor filters to compute the amplitude responses of original image and compute the texture map by a salience model. Secondly, we employ the simple clustering to extract superpixles by affinity of color, coordinates and texture map. Then, we design a normalized histograms descriptor for superpixels integrated color and texture information of inner pixels. To obtain the final segmentation result, all adjacent superpixels are merged by the homogeneity comparison of normalized color-texture features until the stop criteria is satisfied. The experiments are conducted on natural scene images and synthesis texture images demonstrate that the proposed segmentation algorithm can achieve ideal segmentation on complex texture regions.", "num_citations": "6\n", "authors": ["430"]}
{"title": "\u57fa\u4e8e\u8d1d\u53f6\u65af\u901a\u7528\u80cc\u666f\u6a21\u578b\u7684\u56fe\u50cf\u6807\u6ce8\n", "abstract": " \u6458 \u8981 \u5728\u9ad8\u65af\u56fe\u7279\u5f81\u63d0\u53d6\u8fc7\u7a0b\u4e2d, \u901a\u7528\u80cc\u666f\u6a21\u578b (Universal background model, UBM) \u65b9\u6cd5\u5e38\u7528\u4e8e\u6839\u636e\u603b\u4f53\u5206\u5e03\u4f30\u8ba1\u6bcf\u4e00\u5e45\u56fe\u50cf\u4e2d\u7279\u5f81\u70b9\u5206\u5e03\u7684\u9ad8\u65af\u6df7\u5408\u6a21\u578b (Gaussian mixture model, GMM) \u53c2\u6570. \u7136\u800c UBM \u4f30\u8ba1\u7684 GMM \u6743\u91cd\u53c2\u6570\u4e2d\u6709\u5f88\u591a\u63a5\u8fd1\u96f6\u7684\u6570\u503c, \u5b83\u4eec\u6240\u5bf9\u5e94\u7684\u9ad8\u65af\u5206\u91cf\u5bf9\u5206\u5e03\u4f30\u8ba1\u8d21\u732e\u5c0f\u5374\u53c8\u90fd\u53c2\u4e0e\u4e86\u8ba1\u7b97, \u56e0\u6b64 UBM \u7684\u65f6\u95f4\u590d\u6742\u5ea6\u8f83\u9ad8. \u4e3a\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898, \u672c\u6587\u63d0\u51fa Bayes UBM \u65b9\u6cd5. \u901a\u8fc7\u5f15\u5165\u53d7\u9650\u7684\u5bf9\u79f0 Dirichlet \u5206\u5e03\u6765\u63cf\u8ff0 GMM \u6743\u91cd\u53c2\u6570\u7684\u5148\u9a8c\u5206\u5e03, \u5229\u7528 Bayes \u6700\u5927\u540e\u9a8c\u6982\u7387\u5bf9 GMM \u53c2\u6570\u96c6\u8fdb\u884c\u4f30\u8ba1. \u5b9e\u9a8c\u8868\u660e Bayes UBM \u65b9\u6cd5\u4e0d\u4ec5\u6709\u6548\u5730\u964d\u4f4e\u4e86\u65f6\u95f4\u590d\u6742\u5ea6, \u800c\u4e14\u63d0\u9ad8\u4e86 Corel \u6570\u636e\u96c6\u4e0a\u7684\u56fe\u50cf\u6807\u6ce8\u7cbe\u5ea6.", "num_citations": "6\n", "authors": ["430"]}
{"title": "Combining LVQ with SVM technique for image semantic annotation\n", "abstract": " When support vector machine (SVM) classifier is applied to image semantic annotation, it usually encounters the problem of excessive training samples. In this paper, we propose a novel method, which is by combining learning vector quantization (LVQ) technique and SVM classifier, to improve annotation accuracy and speed. Affinity propagation algorithm-based LVQ technique is used to optimize the training set, and a few number of optimized representative feature vectors are used to train SVM. This approach not only meets the small sample size characteristic of SVM, but also greatly accelerates the training and annotating process. Comparative experimental studies confirm the validity of the proposed method.", "num_citations": "6\n", "authors": ["430"]}
{"title": "Investigating visual feature extraction methods for image annotation\n", "abstract": " In order to investigate the performance of visual feature extraction method for automatic image annotation, three visual feature extraction methods, namely discrete cosine transform, Gabor transform and discrete wavelet transform, are studied in this paper. These three methods are used to extract low-level visual feature vectors from images in a given database separately, then these feature vectors are mapped to high-level semantic words to annotate images with labels in a given semantic label set. As it is more efficient to depict the visual features of an image by the feature distribution than to resort to image segmentation technology for semantic image blocks, this paper is going to find out which of the three feature extraction methods performs better in image annotation based on the distribution of feature vectors from the image. The performance of three different kinds of feature extraction method is fully analyzed\u00a0\u2026", "num_citations": "6\n", "authors": ["430"]}
{"title": "Methodology for reliability evaluation of N-version programming software fault tolerance system\n", "abstract": " Software reliability can be improved by tolerating software faults, such as using N-version programming technique. Reliability evaluation is focused on the modeling and analysis techniques for fault prediction purpose. In this paper, a straightforward analysis method for evaluating reliability of software system established by N-version programming is proposed. The dependent failure parameters are assumed as random variables instead of constant. A case study is presented of the analysis of failure data from two software projects; the effectiveness of proposed evaluation methodology is demonstrated.", "num_citations": "6\n", "authors": ["430"]}
{"title": "A new cascade software reliability model\n", "abstract": " There are many kinds of software reliability models at present. However, a universal model, which can be used in different types of reliability data set, is never existed until now. This phenomenon blocks the development of software reliability model. In order to resolve the problem on software reliability model's limitation and precision of model's prediction, this paper proposed a new kind of method, with which four classical models are combined with a feedback neural network to form a new model. With the real world software failure data set SYSl and CSRl, we experimental investigated the new model and compared with four classical ones. It can be proved that the new model's performance to predict is much better than any one of four classical models, and what's more, it can be more widely used.", "num_citations": "6\n", "authors": ["430"]}
{"title": "Further studies on the distribution of the shortest linear recurring sequences for the stream cipher over the ring\n", "abstract": " In this paper, the distribution of the shortest linear recurring sequence over the ring is studied, it is found that the amount of sequences whose length is n can be calculated and the recurring distribution regulation of the shortest linear recurring sequences is proposed. The possibility of finding the non-recurring distribution of the shortest linear recurring length of some special sequences over the ring is also discussed which can be used in the further research work.", "num_citations": "6\n", "authors": ["430"]}
{"title": "Mallat fusion for multi-source remote sensing classification\n", "abstract": " The fusion of multi-source remote sensing data is to offer improved accuracies in land cover classification. The conventional fusion methods such as HIS and PCA can not enhance information and simultaneously preserve high fidelity. Thus, the fused image is not preferable for classification. In this paper, the multi-source remote sensing data fusion based on Mallat algorithm for classification is proposed. The purpose of fusion is to create a new image that is more suitable for recognition. The topic focuses on the pyramid decomposition and choosing coefficients in the fusion process. The performance of proposed method is assessed by statistical methods and its effectiveness also testified by classification accuracies", "num_citations": "6\n", "authors": ["430"]}
{"title": "\u9ad8\u65af\u5149\u675f\u901a\u8fc7\u975e\u7ebf\u6027\u4ecb\u8d28\u5c42\u7684\u9650\u5e45\u6548\u5e94\n", "abstract": " \u5149\u8c31\u5b66\u4e0e\u5149\u8c31\u5206\u6790 \u5149\u8c31\u5b66\u4e0e\u5149\u8c31\u5206\u6790 \u672c\u520a\u4e3a\u4e2d\u56fd\u81ea\u7136\u79d1\u5b66\u6838\u5fc3\u671f\u520a; \u4e2d\u56fd\u79d1\u534f\u4f18\u79c0\u79d1\u6280\u671f\u520a; \u4e2d\u56fd\u79d1\u534f\u62e9\u4f18\u652f\u6301\u57fa\u7840\u6027, \u9ad8\u79d1\u6280\u5b66\u672f\u671f\u520a. \u6240\u8f7d\u8bba\u6587\u88ab\u56fd\u5185\u5916 CSCI, SCI, EI, CAAA \u7b49\u6743\u5a01\u6570\u636e\u5e93\u6536\u5f55. \u6b32\u6295\u672c\u520a\u7684\u4f5c\u8005\u9700\u7ecf\u672c\u520a\u7f16\u59d4\u6216\u672c\u4e13\u4e1a\u77e5\u540d\u4e13\u5bb6\u63a8\u8350\u5e76\u8bf7\u9644\u5355\u4f4d\u4fdd...... \u8be6\u7ec6", "num_citations": "6\n", "authors": ["430"]}
{"title": "Simplified purification of AAV and delivery to the pancreas by intraductal administration\n", "abstract": " Genetic manipulation is a very powerful tool for studying diabetes, pancreatitis, and pancreatic cancer. Here we discuss the use of an adeno-associated virus (AAV) vector to modify gene expression, such as to introduce a green fluorescence protein (GFP) in wild-type mice, cre recombinase in loxP mice, or to inactivate a gene with shRNA. The use of viruses for genetic modification allows for time-specific genetic changes which have advantages over time-consuming and often complex cross-breeding strategies. Here we provide a detailed approach for this process from viral production and purification through pancreatic ductal infusion. Our protocol allows efficient delivery of AAV to mediate GFP or cre expression for cell lineage tracing in the mouse pancreas or for the delivery of transgenes under a specific promoter to these cells.", "num_citations": "5\n", "authors": ["430"]}
{"title": "Blind deconvolution for astronomical spectrum extraction from two-dimensional multifiber spectrum images\n", "abstract": " Although advances in astronomical observation techniques and fiber optic technology have enabled two-dimensional (2D) multifiber spectrum images, astronomers often need one-dimensional (1D) spectroscopy to study physical and chemical properties of astronomical objects. Because of faint optical flux and light pollution, determining point spread functions (PSF) for large-scale multifiber spectroscopic telescopes is difficult. We propose a new optimal extraction method that uses blind deconvolution to extract 1D astronomical spectroscopy from 2D multifiber spectrum images without knowing the exact PSF. A comparison of the performance of our blind deconvolution extraction method and those of other extraction methods showed consistent results, indicating that the blind deconvolution extraction methodology is useful in analyzing 2D multifiber spectrum images and reducing fiber-to-fiber crosstalk without\u00a0\u2026", "num_citations": "5\n", "authors": ["430"]}
{"title": "Combining Local Binary Patterns for Scene Recognition.\n", "abstract": " Recently, spatial principal component analysis of census transform histograms (PACT) was proposed to recognize instance and categories of places or scenes in an image. An improved representation called Local Difference Binary Pattern (LDBP) also was proposed and performed better than that of PACT. LDBP is based on the comparisons between center pixel and its neighboring pixels, but the relationship among neighbor pixels is not considered. In this paper, we propose to combine Local Neighbor Binary Pattern (LNBP) with LDBP to construct a spatial representation for scene recognition, because that LNBP can provide complementary information regarding neighboring pixels for LDBP. Experiments on widely used datasets demonstrate that the performance of image recognition is further improved with proposed method.", "num_citations": "5\n", "authors": ["430"]}
{"title": "Gas dehumidification by microporous coordination polymers\n", "abstract": " A gas-dehumidification method can include passing a humid gas stream through a water-sorbing sorbent comprising a microporous coordination polymer or derivative thereof, wherein the sorbent sorbs water from the passing humid gas stream to produce a water-sorbed sorbent and a dehumidified gas stream. The method can further include passing a drying gas through the water-sorbed sorbent under conditions sufficient to desorb the water and to regenerate the water-sorbing sorbent.", "num_citations": "5\n", "authors": ["430"]}
{"title": "Efficient texture classification using short-time Fourier transform with spatial pyramid matching\n", "abstract": " Texture feature extraction plays an important role in texture image classification. In this paper, we have proposed a texture feature extraction method by utilizing the Short-time Fourier Transform to provide local image information, and for the global geometric correspondence we have proposed to use Spatial Pyramid Matching in frequency domain named as Short-time Fourier Transform with Spatial Pyramid Matching (STFT-SPM). The experiments are conducted on standard benchmark datasets for texture classification like Brodatz and KTH-TIPS2-a, shows that STFT-SPM can achieve significant improvement compared to the Local Phase Quantization, Weber local Descriptor and local Binary Pattern methods.", "num_citations": "5\n", "authors": ["430"]}
{"title": "Covariance matrix estimation with multi-regularization parameters based on MDL principle\n", "abstract": " Regularization is a solution for the problem of unstable estimation of covariance matrix with a small sample set in Gaussian classifier. In many applications such as image restoration, sparse representation, we have to deal with multi-regularization parameters problem. In this paper, the case of covariance matrix estimation with multi-regularization parameters is investigated, and an estimate method called as KLIM_L is derived theoretically based on Minimum Description Length (MDL) principle for the small sample size problem with high dimension setting. KLIM_L estimator can be regarded as a generalization of KLIM estimator in which local difference in each dimension is considered. Under the framework of MDL principle, a selection method of multi-regularization parameters is also developed based on the minimization of the Kullback-Leibler information measure, which is simply and directly estimated by\u00a0\u2026", "num_citations": "5\n", "authors": ["430"]}
{"title": "OMP or BP? a comparison study of image fusion based on joint sparse representation\n", "abstract": " In image fusion techniques based on joint sparse representation (JSR), the composite image is calculated from the fusion of features, which are represented with sparse coefficients. Orthogonal matching pursuit (OMP) and basis pursuit (BP) are the main candidates to estimate the coefficients. Previously OMP is utilized for the advantage of low complexity. However, noticeable errors occur when the dictionary of JSR cannot ensure the coefficients are sparse enough. Alternatively, BP is more robust than OMP in such cases (though suffered from larger complexity). Unfortunately, it has never been studied in image fusion tasks. In this paper, we investigate JSR based on BP for image fusion. The target is to verify that 1) to what extent can BP outperform OMP; and 2) what is the trade-off between BP and OMP. Finally, we conclude, in some cases, fusion with BP obviously outperforms the one with OMP under an\u00a0\u2026", "num_citations": "5\n", "authors": ["430"]}
{"title": "Speed up image annotation based on LVQ technique with affinity propagation algorithm\n", "abstract": " For a support vector machine (SVM) classifier applied to image annotation, if too many training samples are used, the training speed might be very slow and also bring the problem of declining the classification accuracy. Learning vector quantization (LVQ) technique provides a framework to select some representative vectors which can be used to train the classifier instead of using original training data. A novel method which combines affinity propagation algorithm based LVQ technique and SVM classifier is proposed to annotate images. Experimental results demonstrate that proposed method has a better speed performance than that of SVM without applying LVQ.", "num_citations": "5\n", "authors": ["430"]}
{"title": "Decomposition mixed pixels of remote sensing image based on 2-dwt and kernel ica\n", "abstract": " In this paper, we propose a novel method for decomposing mixed-pixels of remote sensing images, which integrates two-Dimensional Wavelet Transform (2-DWT) and Kernel Independent Component Analysis (KICA) technique. In order to improve the signal and noise ratio of the original mixed-pixel images, we apply wavelet analysis method to reduce the noise of the images. High-frequency sub-image in wavelet domain is approximately represented by a kind of super-Gaussian Laplace distribution, and KICA is adopted for this distribution with greater kurtosis for obtaining higher accuracy and faster convergence rate. The experiments show that decomposition result with the proposed method is much improved not only at accuracy but also remarkably robust to noise compared those obtained with 2-DWT-ICA or KICA.", "num_citations": "5\n", "authors": ["430"]}
{"title": "Structure and seasonal dynamics of arthropods in transgenic cotton fields\n", "abstract": " Structure and seasonal dynamics of arthropods in transgenic cotton (cv. SGK321, with inserted genes of Cry1Ac and CpTI) and population dynamics of pests and natural enemies were studied in Nanpi County, Hebei Province in 2002, with the non-transgenic parental cotton (Shiyuan321) as control. It showed that the composition of pest and predatory species was similar between the plots of SGK321 and the control, but the accumulated numbers of each species were different. SGK321 had good control not only to cotton bollworm (89.5%), but also to some non-target pests, such as cotton aphid Aphis gossypii, grean leaf bug Lygus lucorum, tobacco whitefly Bemisia tabaci and green leafhopper Empoasca flavescens, and their accumulated numbers decreased by 64.5%, 21.8%, 15.6% and 33.7%, respectively. For the dominant natural enemy species, the accumulated numbers of Propylaea japonica and Chrysopa sinica increased by 34.0% and 9.1%, respectively; but those of Harmonia axyridis, Orius minutus, Campylomma diversicornis, Lysiphlebia japonicus and spiders decreased by 28.6%, 6.5%, 43.1%, 44.7% and 14.0%, respectively. Arthropod diversity in SGK321 was similar to that in Shiyuan321, and the Shannon-Weiner diversity index was 0.975 and 0.967, respectively. Whereas the total number of arthropods in SGK321 decreased by 53.9%, which was mainly caused by the reduction of basal species. It indicated that SGK321 had good control not only to cotton bollworm, but also to some non-target pests. SGK321 had some negative effects on certain natural enemy populations. But it had no significant impacts on the arthropod\u00a0\u2026", "num_citations": "5\n", "authors": ["430"]}
{"title": "Image de-noising using cross-validation method with RBF network representation\n", "abstract": " This paper presents a new image de-noising method, which based on the image representation model of radial basis function neural network. In this model, the number and distribution of the centers (which are set to the pixels of the observed image) are fixed, and the model parameters of the image representation are chosen by cross-validation method. Experimental results show that the model can represent the image well, and proposed method can reduce the noises in images without need any noise knowledge in priori.", "num_citations": "5\n", "authors": ["430"]}
{"title": "Classification of stellar spectral data based on kalman filter and rbf neural networks\n", "abstract": " In this paper, a novel stellar spectral classification technique is proposed. Which is composed of the following two steps: In the first step, Kalman filter is adopted to conduct de-noising process. At the same time, Kalman filter is also used for optimal feature extraction. The second step, radial basis function neural network is employed for the final classification. The proposed technique can be considered as a composite classifier which combines Kalman filter and radial basis function networks. The experiments show that our new technique is both robust and efficient, the obtained correct classification rate is much improved by the composite classifier, and these results are much better than the best results obtained from regularized discriminant analysis with principle component analysis data dimension reduction technique.", "num_citations": "5\n", "authors": ["430"]}
{"title": "Studies of model selection and regularization for generalization in neural networks with applications\n", "abstract": " This thesis investigates the generalization problem in artificial neural networks, attacking it from two major approaches: regularization and model selection.", "num_citations": "5\n", "authors": ["430"]}
{"title": "Dynamics of a coupled double-cavity optical interference filter\n", "abstract": " The model of a coupled double-cavity optical interference filter consisting of three mirror layers and two one-wavelength cavities is developed. The transmission response of the coupled double-cavity filter containing absorbing thermo-optical media is predicted, when a laser pulse is incident on the filter. Pulse narrowing and pulse regeneration are observed for a restricted range of frequencies and intensities.", "num_citations": "5\n", "authors": ["430"]}
{"title": "Region Number Determination in Automatic Image Segmentation Based on BKYY Model Selection Criterion\n", "abstract": " In the feature space clustering approach to image segmentation, each cluster corresponds to a region in the image. Determination of the appropriate number of clusters (regions) has long been an open problem. In this paper, we apply the Baysian-Kullback Ying Yang (BKYY) Model Selection Criterian on this feature space clustering problem to give an appropriate number of regions in image segmentation. Experimental demonstrations show the results of image segmentation with this automatically determined number of regions.", "num_citations": "5\n", "authors": ["430"]}
{"title": "Pseudoinverse learning autoencoder with DCGAN for plant diseases classification\n", "abstract": " Pest infestation of crops and plants impacts agricultural development. Generally, farmers or specialist observe the plants with the naked eye to recognise and diagnose ailments. However, this technique can be time-consuming, costly and inexact. In contrast, auto-detection using image processing methods gives fast and precise results. This paper introduces a new plant disease identification model predicated on leaf image classification that employs a deep convolutional generative adversarial network (DCGAN) along with a classifier identified by multilayer perceptron (MLP) neural networks trained with a pseudoinverse learning autoencoder (PILAE) algorithm. The DCGAN performes two tasks: (1) synthesis of the minor class images to overcome the issue of imbalance in the dataset and (2) extracting deep features of all images within the dataset. The PILAE training procedure is not required to identify the learning\u00a0\u2026", "num_citations": "4\n", "authors": ["430"]}
{"title": "Learning Behavior Analysis in Classroom Based on Deep Learning\n", "abstract": " The following topics are dealt with: learning (artificial intelligence); convolutional neural nets; neural nets; feature extraction; control system synthesis; mobile robots; image classification; closed loop systems; neurocontrollers; nonlinear control systems.", "num_citations": "4\n", "authors": ["430"]}
{"title": "Broad and pseudoinverse learning for autoencoder\n", "abstract": " Autoencoder is one approach to automatically learn features from unlabeled data and received significant attention during the development of deep neural networks. However, the learning algorithm of autoencoder suffers from slow learning speed because of gradient descent based algorithms have many drawbacks. Pseudoinverse learning algorithm is a fast and fully automated method to train autoencoders. While when the dimension of data is far less than the number of data, the pseudoinverse learning can only obtain the optimal initial value of the autoencoder network and need further learning to achieve satisfactory results. In order to overcome the shortcomings mentioned above, we present a broad learning strategy to transform the input space to the high dimensional space through receptive function in this paper. The transformed data can be more suitable to pseudoinverse learning algorithm which can be\u00a0\u2026", "num_citations": "4\n", "authors": ["430"]}
{"title": "Live fingerprint detection using magnitude of perceived spatial stimuli and local phase information\n", "abstract": " Fingerprint recognition systems are widely used for authentication purposes in security systems. However, fingerprint recognition systems can easily be spoofed by imitations of fingerprints using various spoof materials. A compact and discriminative set of features is needed to discriminate between live and spoof fingerprints. We explore combined Shepard magnitude and orientation for live fingerprint detection using independent quantization of global and local features extracted in spatial and frequency domain. The spatial domain features that are extracted comprise of the magnitude of perceived spatial stimuli that is computed from the net variation of perceived edge information. Rotation invariance is achieved by extracting local features based on phase information of significant frequency components in the frequency domain. The concatenated feature vector associated with a fingerprint image is represented as\u00a0\u2026", "num_citations": "4\n", "authors": ["430"]}
{"title": "A hierarchical model with pseudoinverse learning algorithm optimazation for pulsar candidate selection\n", "abstract": " Pulsars search has always been one of the most concerned problem in the field of astronomy. Nowadays, with the development of astronomical instruments and observation technology, the amount of data is getting bigger and bigger. Radio pulsar surveys have generated and will generate vast amounts of data. To handle big data, developing new technologies and frameworks to efficiently and accurately analyze these data become increasing urgent. The number of positive and negative samples in pulsar candidate data set is very unbalanced, if we only use these a few positive samples to train a deep neural network (DNN), the trained DNN is prone because of the problem of overfitting and will affect the generalization ability. Motivated by the mixtures of experts network architecture, we proposed a hierarchical model for pulsar candidate selection which assembles a set of trained base classifiers. Moreover\u00a0\u2026", "num_citations": "4\n", "authors": ["430"]}
{"title": "Image recognition with histogram of oriented gradient feature and pseudoinverse learning autoencoders\n", "abstract": " Neural network is an artificial intelligence technology which achieve good results in computer vision, natural language processing and other related fields. Currently the most used model for image recognition is convolutional neural networks, however, it has complex structure, there many group open sources of code but it is difficult to reuse. Moreover, most of training algorithm of the model is based on the gradient descent which takes a lot of time to adjust parameters. In order to solve these problems, this paper presents a model combining the histogram of oriented gradient and the pseudoinverse learning autoencoders. Our model does not require any iterative optimization, the number of the neurons and the number of hidden layers are automatically determined in the model. At the same time, our model has a simple structure, do not requires a huge amount of computing resources. Experimental results\u00a0\u2026", "num_citations": "4\n", "authors": ["430"]}
{"title": "A practice of forecasting software aging in an IIS web server using SVM\n", "abstract": " Software aging is a phenomenon observed in a long running software application, where the state of software degrades and leads to performance degradation, hang/crash failures or both. In fact, it is difficult to detect software aging due to the long delay before aging appearance. Therefore, how to fast and accurately detect software aging problem in a long running system is a big challenge. Since software aging has been studied two decades, many scholars focused on Markov model or time series to model software aging process, however, classification algorithm as a power method has been neglected. In this paper, a classification algorithm called support vector machine is used to model software aging process through collected parameters of an IIS web server that is a running commercial server. Through the analysis of the experiment results, using SVM for software aging prediction is an efficient way to predict\u00a0\u2026", "num_citations": "4\n", "authors": ["430"]}
{"title": "Optimal classification of epileptic eeg signals using neural networks and harmony search methods\n", "abstract": " In this paper, the Harmony Search (HS)-aided BP neural networks are used for the classification of the epileptic electroencephalogram (EEG) signals. It is well known that the gradient descent-based learning method can result in local optima in the training of BP neural networks, which may significantly affect their approximation performances. Three HS methods, the original version and two new variations recently proposed by the authors of the present paper, are applied here to optimize the weights in the BP neural networks for the classification of the epileptic EEG signals. Simulations have demonstrated that the classification accuracy of the BP neural networks can be remarkably improved by the HS method-based training.", "num_citations": "4\n", "authors": ["430"]}
{"title": "Design and analysis of helical needle tip grinding process\n", "abstract": " A generalized helical needle tip geometry model, which can describe many typical needle tip geometries, including conical, bevel, blunt and helical shapes with proper geometric parameters, is presented based on analogy to the helical point drill geometry. The generality of this model offers a general way for manufacturing various needle tip geometries. A mathematical model of the helical needle tip geometry is provided along with the formulation of the kinematic model of the tip grinding process. The control strategy on a 5-axis grinding machine system is also developed to implement the designed kinematic model. The needle tip\u2019s motions in the grinding process are simulated to characterize the effects of grinding parameters on needle tip properties and to predict the trajectory of the needle tip point during the grinding process. Finally, several types of needle geometries have been manufactured by the developed\u00a0\u2026", "num_citations": "4\n", "authors": ["430"]}
{"title": "A generalized subspace projection approach for sparse representation classification\n", "abstract": " In this paper, we propose a subspace projection approach for sparse representation classification (SRC), which is based on Principal Component Analysis (PCA) and Maximal Linearly Independent Set (MLIS). In the projected subspace, each new vector of this space can be represented by a linear combination of MLIS. Substantial experiments on Scene15 and CalTech101 image datasets have been conducted to investigate the performance of proposed approach in multi-class image classification. The statistical results show that using proposed subspace projection approach in SRC can reach higher efficiency and accuracy.", "num_citations": "4\n", "authors": ["430"]}
{"title": "Medical needle insertion: Effects of needle tip and surface texturing\n", "abstract": " Medical Needle Insertion: Effects of Needle Tip and Surface Texturing \u2014 Northwestern Scholars Skip to main navigation Skip to search Skip to main content Northwestern Scholars Logo Help & FAQ Home Experts Organizations Research Output Grants Core Facilities Search by expertise, name or affiliation Medical Needle Insertion: Effects of Needle Tip and Surface Texturing P. Han, K. Pallav, P. Guo, Kornel Ehmann Mechanical Engineering Research output: Chapter in Book/Report/Conference proceeding \u203a Conference contribution Overview Original language English Title of host publication Proceedings of the 6th International Conference on MicroManufacturing (ICOMM) State Published - 2011 Event 6th International Conference on MicroManufacturing (ICOMM) - Tokyo Duration: Jan 1 2011 \u2192 \u2026 Conference Conference 6th International Conference on MicroManufacturing (ICOMM) Period 1/1/11 \u2192 \u2026 Cite this , ..\u2026", "num_citations": "4\n", "authors": ["430"]}
{"title": "The discussions on implementing QoS for IPv6\n", "abstract": " Regarding network, QoS is a very important issue. IPv6 will be a mainstream of the network in the two or five years. It is very significant to do more research on IPv6 QoS, which will do good to the development and large-scale application of IPv6. We have introduced QoS mechanisms and two different approaches to QoS on the Internet, analyzed current status of IPv6 QoS and mainly discussed some important factors to implement QoS for IPv6.", "num_citations": "4\n", "authors": ["430"]}
{"title": "Experimental study of discriminant method with application to fault-prone module detection\n", "abstract": " Some techniques have been applied to improving software quality by classifying the software modules into fault-prone or non fault-prone categories. This can help developers focus on some high risk fault-prone modules. In this paper, a distribution-based Bayesian quadratic discriminant analysis (D-BQDA) technique is experimental investigated to identify software fault-prone modules. Experiments with software metrics data from two real projects indicate that this technique can classify software modules into a proper class with a lower misclassification rate and a higher efficiency.", "num_citations": "4\n", "authors": ["430"]}
{"title": "ECoG analysis with affinity propagation algorithm\n", "abstract": " Analyzing notor imagery electrocardiogram (ECoG) signal is very challenging for it is hard to set up a classifier based on the labeled ECoG obtained in the first session and apply it to the unlabeled test data obtained in the second session. Here we propose a new approach to analyze ECoG trails in the case of session-to-session transfer exists. In our approach, firstly, dimension reduction is performed with independent component analysis (ICA) decomposition. Secondly, ECoG trials are clustered by an unsupervised learning algorithm called affinity propagation. Primary experimental results show that the proposed approach gives the reasonable result than that using the classical K-means clustering algorithm.", "num_citations": "4\n", "authors": ["430"]}
{"title": "Complete two-dimensional principal component analysis for image registration\n", "abstract": " We present a new feature extraction method, which called the complete two-dimensional principal component analysis (Complete 2DPCA), for image registration. Complete 2DPCA is based on 2D image matrices. Two image covariance matrices are constructed directly using the original image matrix and their eigenvectors are derived for image feature extraction. In the 2D image registration scheme, we propose complete 2DPCA to extract features from the image sets, and these features are input vectors of feedforward neural networks (FNN). Neural network outputs are registration parameters with respect to reference and observed image sets. Comparative experiments are performed between complete 2DPCA based method and other feature based methods. The results show that the proposed method has an encouraging performance.", "num_citations": "4\n", "authors": ["430"]}
{"title": "Improving depth resolution of diffuse optical tomography with intelligent method\n", "abstract": " Near-infrared diffuse optical tomography imaging (DOT) suffers from a poor depth resolution due to the depth sensitivity decreases markedly in tissues. In this paper, an intelligent method, which is called layered maximum-singular-values adjustment (LMA), is proposed to compensate the decrease of sensitivity in depth dimension, and hence obtain improved depth resolution of DOT imaging. Simulations are performed with a semi-infinite model, and the simulated results for objects located in different depths demonstrate that the LMA technique can improve significantly the depth resolution of reconstructed objects. The positional errors of less than 3 mm can be obtained in the depth dimension for all depths from -1 cm to -3 cm.", "num_citations": "4\n", "authors": ["430"]}
{"title": "Face recognition research based on anti-symmetrical wavelet and eigenface\n", "abstract": " In this paper, a new human face recognition method based on anti-symmetrical biorthogonal wavelet transformation (ASBWT) and eigenface was proposed. First the anti-symmetrical biorthogonal wavelet is chosen to degrade the face image dimension, meanwhile complete the process of face location and segmentation; And then human face is reverted through the face space of eigenface, the traditional average human face is replaced in the within-class scatter matrix. This within-class scatter matrix is used to calculate within-class and between-class distance proportion as a rule function, calculate the twice eigenface through discrete Karhunen-Loeve transform (DKLT), and use singular value decomposition (SVD) method to calculate the eigenvector. Finally we compute the weights and classify the face images. The results show that the proposed method has higher recognition rate and more robust than the\u00a0\u2026", "num_citations": "4\n", "authors": ["430"]}
{"title": "Special Distribution of the Shortest Linear Recurring Sequences in Z /(p) Field\n", "abstract": " In this paper, the distribution of the shortest linear recurring sequences in Z /(p) is studied. It is found that the shortest linear recurrent length is always equal to n / 2 when n is even and is always equal to n / 2+1 when n is odd for any sequence whose length is n. In other words, the shortest linear recurring length is always equal to the half of the length of the given sequence. The probability of finding the distribution of the shortest linear recurring length of two sequences in Z / (p) field is also given.", "num_citations": "4\n", "authors": ["430"]}
{"title": "On the Study of BKYY Cluster Number Selection Criterion for Small Sample Data Set with Bootstrap Technique\n", "abstract": " The Bayesian-Kullback ying-yang (BKYY) learning theory and system has been proposed by Xu (1995, 1997), and one special case of ying-yang system can provide the model selection criteria for selecting the number of clusters in the clustering analysis. In this paper, we present an experimental study of this cluster number selection criterion in a small number sample set case. The results show that the criterion performed reasonable well when mixture parameters were estimated by incorporating a bootstrap technique with the EM algorithm.", "num_citations": "4\n", "authors": ["430"]}
{"title": "A Robust Automated Machine Learning System with Pseudoinverse Learning\n", "abstract": " Developing a robust deep neural network (DNN) for a specific task is not only time-consuming but also requires lots of experienced human experts. In order to make deep neural networks easier to apply or even take the human experts out of the design of network architecture completely, a growing number of researches focus on robust automated machine learning (AutoML). In this paper, we investigated the robustness problem of AutoML systems based on contractive pseudoinverse learners. In our proposed method, deep neural networks were built with stacked contractive pseudoinverse learners (CPILer). Each CPILer has a Jacobian regularized reconstruction loss function and is trained with pseudoinverse learning algorithm. When sigmoid activation function is adopted in the hidden layer, the graph Laplace regularizer is derived from square Frobenius norm of the Jacobian matrix. This learning scheme not\u00a0\u2026", "num_citations": "3\n", "authors": ["430"]}
{"title": "Heterogenetic parabiosis between healthy and dystrophic mice improve the histopathology in muscular dystrophy\n", "abstract": " Duchenne muscular dystrophy (DMD) is a progressive muscle disease, characterized by mutations in the X-linked dystrophin, that has several therapeutic options but no curative treatment. Transplantation of muscle progenitor cells for treatment of DMD has been widely investigated; however, its application is hindered by limited cell survival due to the harmful dystrophic microenvironment. An alternative approach to utilize progenitor cells and circulatory factors and to improve the dystrophic muscle pathology and microenvironment is through parabiotic pairing, where mice are surgically sutured to create a joint circulatory system. Parabiotic mice were generated by surgically joining wild type (WT) mice expressing green fluorescent protein (GFP) with mdx mice. These mice developed a common circulation (approximately 50% green cells in the blood of mdx mice) 2-weeks after parabiotic pairing. We observed\u00a0\u2026", "num_citations": "3\n", "authors": ["430"]}
{"title": "Relation extraction via attention-based cnns using token-level representations\n", "abstract": " Relation extraction is an important task in the field of natural language processing (NLP). Most existing methods usually utilize word-level representations, ignoring massive information from the texts. To address this issue, we utilize BERT to pretrain token-level bidirectional contextual representations from raw sentences, then employ a Transformer encoder to train token-level representations mentioned above again. To capture the most important information of the sentences, we employ a convolutional neural network (CNN) with entity-aware attention to extract high-level features from these token-level representations of the sentences. On the SemEval-2010 Task 8 dataset, our model achieves 87.8% F1-score and outperforms several previous models without rich prior knowledge.", "num_citations": "3\n", "authors": ["430"]}
{"title": "Fast image recognition with Gabor filter and pseudoinverse learning autoencoders\n", "abstract": " Deep neural network has been successfully used in various fields, and it has received significant results in some typical tasks, especially in computer vision. However, deep neural network are usually trained by using gradient descent based algorithm, which results in gradient vanishing and gradient explosion problems. And it requires expert level professional knowledge to design the structure of the deep neural network and find the optimal hyper parameters for a given task. Consequently, training a deep neural network becomes a very time consuming problem. To overcome the shortcomings mentioned above, we present a model which combining Gabor filter and pseudoinverse learning autoencoders. The method referred in model optimization is a non-gradient descent algorithm. Besides, we presented the empirical formula to set the number of hidden neurons and the number of hidden layers in the\u00a0\u2026", "num_citations": "3\n", "authors": ["430"]}
{"title": "An indefinite cycle traffic light timing strategy\n", "abstract": " Intelligent transportation signal control plays an important role in reducing traffic congestion and improving road capacity. The key of signal control is to adjust the traffic lights appropriately according to the traffic flow, which is an adaptive control. In this paper, we propose a new timing strategy. This strategy includes green time optimization and lane combination calculation. According to the real-time traffic flow, we optimize green time and calculate lane combination to adjust the cycle and then we can get the timing plan. The simulation results of random data and actual traffic data show that the strategy we proposed can increase traffic efficiency by more than 15% at intersections, reduce vehicle detention, and relieve traffic congestion.", "num_citations": "3\n", "authors": ["430"]}
{"title": "Computational intelligence in astronomy: A survey\n", "abstract": " With explosive growth of the astronomical data, astronomy has become a representative data-rich discipline so as to defy traditional research methodologies and paradigm to analyze data and discover new knowledge from the data. How to effectively process and analyze the astronomical data is a fundamental work while a key scientific requirement of modern astronomical surveys. This situation has motivated needs for fostering of a wide range of cooperation with the astronomers and computer scientists. Computational intelligence, an important research direction of artificial intelligence and information sciences, has been shown to be promising to solve complex problems in scientific research and engineering. This paper presents a review of the current state of the application of computational intelligence in astronomy. We believe that computational intelligence is expected to provide powerful tools for addressing challenges in astronomical data analysis.", "num_citations": "3\n", "authors": ["430"]}
{"title": "AP system for solving all-solutions of TSP\n", "abstract": " P system is a parallel computing system based on a membrane computing model. Since the calculation process of the P system has the characteristics of maximum parallelism and Non-determinism, it has been used to solve the NP-hard problem in polynomial time. This paper designs a P system for TSP problem solving. This P system can not only determine whether the TSP problem has solution, but also give the allsolution when the TSP problem is solved. Finally, an example is given to illustrate the feasibility and effectiveness of the P system designed in this paper.", "num_citations": "3\n", "authors": ["430"]}
{"title": "Generalization of impulse noise removal.\n", "abstract": " In this paper, a generalization for the identification and removal of an impulse noise is proposed. To remove the salt-and-pepper noise an Improved Directional Weighted Median Filter (IDWMF) is proposed. Number of optimal direction are proposed to increase from four to eight directions to preserve the edges and to identify the noise, effectively. Modified Switching Median Filter (MSMF) is proposed to replace the identified noisy pixel. In which, two special cases are considered to replace the identified noisy pixel. To remove the random-valued impulse noise, we have proposed an efficient randomvalued impulse noise identifier and removal algorithm named as Local Noise Identifier and Multi-Texton Removal (LNI-MTR). We have proposed to use the local statistics of four neighbouring and the central pixel for the identification of noisy pixel in current sliding window. The pixel identified as noisy, is proposed to replace by using the information of multi-texton in current sliding window. Experimental results show that the proposed methods cannot only identify the impulse noise efficiently, but also can preserve the detailed information of an image.", "num_citations": "3\n", "authors": ["430"]}
{"title": "Lstm with matrix factorization for road speed prediction\n", "abstract": " Road speed prediction is a key point of Intelligent Transport System. Plenty of work have proved the effectiveness and efficiency of neural network in forecasting freeway velocity. However, the missing values are obstacles when applying the widely used trajectory data to neural network. In trajectory data, most roads may not be covered by enough trajectories in a short time. Due to highly sparsity, it will bring extra cost if we first fill missing data then perform training. To solve this issue, we propose a collaborative model that combines LSTM neural network with matrix factorization to reduce sparsity and make prediction simultaneously. We conduct experiments with a sufficient amount of trajectories and the results show that our model outperforms cascaded methods in both MAE and RMSE.", "num_citations": "3\n", "authors": ["430"]}
{"title": "A divide and conquer method for automatic image annotation\n", "abstract": " Fast and accurate automatic image annotation is of great significance. Linear regression provides a fast and simple automatic image annotation method. However, it is a linear model and it is trained on the whole training data set. The computational complexity of linear regression increases with the number of training samples. In this paper, we propose a new automatic image annotation method based on data grouping. First, training samples are mapped into a new space. Next, these samples are grouped in this new space by constrained clustering. Finally, a system consisting of a softmax gate network and multiple experts is trained on the partitioned data sets. Each expert is a single-hidden-layer feedforward neural network. Experimental results on three image annotation benchmark data sets show that our method achieves better results. In addition, our experimental results show that effective grouping of training\u00a0\u2026", "num_citations": "3\n", "authors": ["430"]}
{"title": "A rank minimization-based late fusion method for multi-label image annotation\n", "abstract": " Image annotation is a hard multi-label learning problem which aims at automatically tagging each input image with relevant keywords reflecting its semantic concepts. Recently, several late fusion methods were proposed to improve the accuracy of image annotation. But these late fusion methods need normalization of confidence score vectors of independent models corresponding to distinct representations. Choosing a good normalization function is tricky and difficult. In this paper, we propose a new method of late fusion for image annotation based on rank minimization. The proposed method avoids normalization by transforming confidence score vectors into pairwise relationship matrices. And an optimal matrix is obtained by solving a minimization optimization problem. With the optimal matrix, a fused confidence score vector can be recovered, which gives the final prediction of tags. Experiments on standard\u00a0\u2026", "num_citations": "3\n", "authors": ["430"]}
{"title": "Method of evolving non-stationary multiple kernel learning\n", "abstract": " Recently, evolving multiple kernel learning methods have attracted researchers\u2019 attention due to the ability to find the composite kernel with the optimal mapping model in a large high-dimensional feature space. However, it is not suitable to compute the composite kernel in a stationary way for all samples. In this paper, we propose a method of evolving non-stationary multiple kernel learning, in which base kernels are encoded as tree kernels and a gating function is used to determine the weights of the tree kernels simultaneously. Obtained classifiers have the composite kernel with the optimal mapping model and select the most appropriate combined weights according to the input samples. Experimental results on several UCI datasets illustrate the validity of proposed method.", "num_citations": "3\n", "authors": ["430"]}
{"title": "Interval-valued intuitionistic trapezoidal fuzzy number and its application\n", "abstract": " In this paper, we propose the new type of fuzzy number, intuitionistic trapezoidal fuzzy number(ITFN) and interval-valued intuitionistic trapezoidal fuzzy number(IVITFN), study some properties of them, and investigate some algebraic operations between two IVITFNs. We also present the sorting criteria for IVITFN based on its definition. Finally, we use our proposed IVITFN and algebraic operation to assess production line, the experiment results show that our proposed method is effective and available.", "num_citations": "3\n", "authors": ["430"]}
{"title": "Adaptive regularization deconvolution extraction algorithm for spectral signal processing\n", "abstract": " Deconvolution is known as an ill-posed problem. In order to solve such a problem, a regularization method is needed to constrain the solution space and find a plausible and stable solution. In practice, it is very computation intensive when using cross-validation method to select the regularization parameter. In this paper, we present an adaptive regularization method to find the optimal regularization parameter value and represent the trade-off between model fitness of the data and the smoothness of the extracted signal. Spectral signal extraction experimental results demonstrate that the time complexity the proposed method is much lower than the one without adaptive regularization and is convenient for users also. And quantitative performance analysis show that the proposed intelligent approach performs better than that of current deconvolution extraction method and other extraction method used in the Large\u00a0\u2026", "num_citations": "3\n", "authors": ["430"]}
{"title": "Multiple kernel learning method using mrmr criterion and kernel alignment\n", "abstract": " Multiple kernel learning (MKL) is a widely used kernel learning method, but how to select kernel is lack of theoretical guidance. The performance of MKL is depend on the users\u2019 experience, which is difficult to choose the proper kernels in practical applications. In this paper, we propose a MKL method based on minimal redundant maximal relevance criterion and kernel alignment. The main feature of this method compared to others in the literature is that the selection of kernels is considered as a feature selection issue in the Hilbert space, and can obtain a set of base kernels with the highest relevance to the target task and the minimal redundancies among themselves. Experimental results on several benchmark classification data sets show that our proposed method can enhance the performance of MKL.", "num_citations": "3\n", "authors": ["430"]}
{"title": "Adaptive multilevel kernel machine for scene classification\n", "abstract": " Scene classification is a challenging problem in computer vision applications and can be used to model and analyze a special complex system, the internet community. The spatial PACT (Principal component Analysis of Census Transform histograms) is a promising representation for recognizing instances and categories of scenes. However, since the original spatial PACT only simply concatenates compact census transform histograms at all levels together, all levels have the same contribution, which ignores the difference among various levels. In order to ameliorate this point, we propose an adaptive multilevel kernel machine method for scene classification. Firstly, it computes a set of basic kernels at each level. Secondly, an effective adaptive weight learning scheme is employed to find the optimal weights for best fusing all these base kernels. Finally, support vector machine with the optimal kernel is used for scene classification. Experiments on two popular benchmark datasets demonstrate that the proposed adaptive multilevel kernel machine method outperforms the original spatial PACT. Moreover, the proposed method is simple and easy to implement.", "num_citations": "3\n", "authors": ["430"]}
{"title": "Experimental comparison of geometric, arithmetic and harmonic means for EEG event related potential detection\n", "abstract": " In this paper, we experimentally evaluate three different averaging methods for processing of electroencephalogram (EEG) event related potentials (ERPs) measured from scalp in response to repeated stimulus. In ERP applications, arithmetic mean (AM) is normally employed in processing the ERPs prior to ERP detection, whereas also other averaging methods might have beneficial properties. Fast ERP detection is essential, for example, in brain computer interfaces and during spine surgery. Thus, it is of interest to search for methods to aid in detecting ERPs with as few stimulus repetitions as possible. Here, noise reduction properties of AM, geometric mean (GM), and harmonic mean (HM) are demonstrated with simulations, and ERP processing by the three methods is illustrated by processing real visual evoked potentials (VEPs).", "num_citations": "3\n", "authors": ["430"]}
{"title": "An algorithm for calculating the hypervolume contribution of a set\n", "abstract": " The reliability model can be optimized with a multi-objective optimization algorithm, while hypervolume-based multi-objective evolutionary algorithms (MOEAs) have been shown to produce better results for multi-objective problem in practice. When hypervolume is used in some MOEAs as archiving strategy, diversity mechanism or selection criterion to guide the search, it is necessary to determine which subset contributes the least hypervolume contribution. Few algorithms have been designed for this purpose. In this paper a new algorithm based on HSO (hypervolume by slicing objective) is proposed for calculating the exclusive hypervolume contributions of each subset to the whole nondominated set directly for small dimension. The new algorithm is composed of two parts: the algorithm SHSO (set hypervolume contribution by slicing objective) and the algorithm SHSO*. SHSO is used to calculate the exclusive\u00a0\u2026", "num_citations": "3\n", "authors": ["430"]}
{"title": "Software fault prediction framework based on aiNet algorithm\n", "abstract": " Software fault prediction techniques are helpful in developing dependable software. In this paper, we proposed a novel framework that integrates testing and prediction process for unit testing prediction. Because high fault prone metrical data are much scattered and multi-centers can represent the whole dataset better, we used artificial immune network (aiNet) algorithm to extract and simplify data from the modules that have been tested, then generated multi-centers for each network by Hierarchical Clustering. The proposed framework acquires information along with the testing process timely and adjusts the network generated by aiNet algorithm dynamically. Experimental results show that higher accuracy can be obtained by using the proposed framework.", "num_citations": "3\n", "authors": ["430"]}
{"title": "Experimental studies of visual models in automatic image annotation\n", "abstract": " Semantic image annotation can be viewed as a mapping procedure from image features to semantic labels, by the steps of image feature extraction and image-semantic mapping. The features can be low-level visual features, such as color, texture, shape, etc., and the semantic labels can be related to the knowledge of human on the image understanding. However, these linear representations are insufficient to describe the complex natural scene. In this paper, we study currently existing visual models that are able to imitate the way the human visual system acts for the tasks of object recognition and scene interpretation. Therefore, it is expected to bring a better understanding to the image visual content in human cortex will. In the experiments, there are three state-of-the-art visual models are investigated for the application of automatic image annotation. The results demonstrate that with our proposed\u00a0\u2026", "num_citations": "3\n", "authors": ["430"]}
{"title": "Iris feature extraction based on the complete 2DPCA\n", "abstract": " Iris recognition has been paid more attentions due to its high reliability in personal identification recently. Iris feature extraction is very critical in the identification system. In this paper, in order to obtain the effective iris feature matrices with lower dimension, we explore a feature extraction method called Complete Two-Dimension Principal Component Analysis (C- 2DPCA). We also employed other two methods, Two-Dimension Linear Discriminant Analysis (2DLDA) and 2DPCA for comparison. Experiments with the public iris dataset from Chinese Academy of Science - Institute of Automation (CASIA) indicate that the C-2DPCA performs better than both 2DLDA and 2DPCA with a lower Equal Error Rate (EER) and average computation time.", "num_citations": "3\n", "authors": ["430"]}
{"title": "Blind image restoration using divisional regularization and wavelet technique\n", "abstract": " Regularization method has been widely used in blind image restoration. Most regularization operators, however, are applied uniformly without considering difference of edge regions, which results in an unsolved trade-off conflict between smooth and edge regions. In this paper, we apply suitable regularization operators to smooth regions and edge regions respectively according to their characteristics instead of a global and constant one, and further employ the wavelet technique to control the noise amplification in order to improve the quality of divisional regularization. Experiment results show that our proposed Divisional Regularization and Wavelet Technique (DRWT) can deblur effectively without ringing effect in the restored images, thus improves edge restoration and reduces noise amplification.", "num_citations": "3\n", "authors": ["430"]}
{"title": "A Comparative Study on Clustering Algorithms for Multispectral Remote Sensing Image Recognition\n", "abstract": " Since little prior knowledge about remote sensing images can be obtained before performing recognition tasks, various unsupervised classification methods have been applied to solve such problem. Therefore, choosing an appropriate clustering method is very critical to achieve good results. However, there is no standard criterion on which clustering method is more suitable or more effective. In this paper, we conduct a comparative study on three clustering methods, including C-Means, Finite Mixture Model clustering, and Affinity Propagation. The advantages and disadvantages of each method are evaluated by experiments and classification results.", "num_citations": "3\n", "authors": ["430"]}
{"title": "Software Metrics Analysis with Genetic Algorithm and Affinity Propagation Clustering.\n", "abstract": " Software metrics are collected in software development process and can be utilized to quantify software products, especially to predict software quality in the early stage of software life cycle. Data mining techniques have been applied to study software quality by analyzing software metrics. And clustering analysis, one of data mining techniques, has also been adopted to build software quality prediction models in the early period of software life cycle. However, not all kinds of software metrics are proper to be engaged in clustering analysis, and it is quite difficult to manually select them appropriately. Therefore, in this paper, based on the Genetic Algorithm (GA) and a new clustering method called Affinity Propagation (AP), we propose a novel strategy (GA-AP) to analyze software metrics for predicting software quality. Furthermore, we validate our new approach with two real-world software metrics datasets, and the experimental results show that GA-AP performs well in software metrics selection for clustering analysis.", "num_citations": "3\n", "authors": ["430"]}
{"title": "Probabilistic similarity measures analysis for remote sensing image retrieval\n", "abstract": " In image database retrieval there are many classical similarity measures that can be used to find the target image, these measures mostly belong to geometry model from the point of view of the data model, while little attention has been devoted to the studies on methods based on probability density distribution. In this paper we experimentally investigate some probabilistic similarity measures, present two methods for design of the similarity function of two mixture Gaussian distributions, on the basis of the nearest neighbor rule and K nearest neighbor rule respectively. An experimental study was conducted to examine and evaluate the measures for application to image databases, and the experimental results show that the methods based on K nearest neighbor rule achieve better performance", "num_citations": "3\n", "authors": ["430"]}
{"title": "Joint blurred image restoration with partially known information\n", "abstract": " A new restoration method for joint blurred images with partially known information is proposed in this paper. The joint blur is assumed to be motion blurs and defocus blur mixed together. Under the condition of two blur effects are supposed to be independent linear shift-invariant processes and motion blur parameter can be obtained with known information, a reduced update Kalman filter (RUKF) is used for degraded image restoration and the best defocus point spread function (PSF) parameter is determined based on the maximum entropy principle (MEP). Experimental results with real images show that the proposed approach works well", "num_citations": "3\n", "authors": ["430"]}
{"title": "Effect of notoginsenoside-Rg1 on the expression of several proteins in the striatum of rat models with Parkinson's disease\n", "abstract": " After establishing hemi-Parkinsonian rat models, the relationships between neuron death and the expression of several proteins, such as c-Fos, GFAP, GDNF, NF-kB and some cytokines were determined. Therapeutics experiments with notoginsenoside-Rg1 were carried out. The research results show that the expressions of GFAP, NF-kB and c-Fos will obviously increase in the lesion side of the striatum and the expression of GDNF will decrease, which implies that the signal transduction pathway may participate in the apoptosis in neurons. The levels of some cytokines such as TNF-\u03b1, IL-1\u03b2 in the striatum of PD rat models increased compared to those of normal rats. The results of the therapeutics experiments show that notoginsenoside-Rg1 may repress the immune inflammation response and regulate the immune function through the neuro-immune molecular network. Therefore, notoginsenoside-Rg1 can be\u00a0\u2026", "num_citations": "3\n", "authors": ["430"]}
{"title": "Comparative Studies on Dimension Reduction Methods for Multispectral Remote Sensing Image\n", "abstract": " The number of Earth observation satellites that are in operations is rising every year (Nezamoddin-Kachouie & al. 2004). These satellites carry a diverse spectrum of radar and optical sensors capital of accruing imagery and these imageries are applied in every field such as generating classification maps. Before the applications, texture feature is an important processing procedure. Gray value is an important characteristic for the analysis of various types of the remote sensing images. It is believed that the gray value plays an important role in the visual systems for recognition and interpretation of data. Texture analysis is an important research field in remote sensing image processing, texture describes the attribution between a pixel and the other pixels around it. So texture extraction must be considered in a small region not a single pixel, but this idea of the analysis method gives a shortcoming: the edge between different classes may be mistakenly classified. Although a number of techniques have been developed for texture feature extraction, segmentation, classification and synthesis (Manjunath & al. 1996), in this paper we adopt the gray values as the features of the original multispectral remote sensing image. Extracting the most important features of the multispectral remote sensing image is a necessary technology. Possibly the image has much redundancy information and is difficult to extract the key features. Here we investigate five dimension reduction methods (Bian Zhaoqi & al. 2002) such as the Euclid distance measurement method (EDM), the discrete measurement criteria function method (DMCF), the minimum differentiated entropy\u00a0\u2026", "num_citations": "3\n", "authors": ["430"]}
{"title": "Spectral analysis and recognition using multi-scale features and neural networks\n", "abstract": " This paper presents a novel spectral analysis and classification technique, which is based on multi-scale feature extraction and neural networks. We propose two feature extraction methods in wavelet domain to implement de-noising process and construct feature spectra. Then a radial basis function network is employed for classifying spectral lines. The input of the neural network is the feature spectra, which is produced by the proposed methods. Real world data experimental results show that our technique is robust and efficient. The classification results are much better than the best results obtained by principle component analysis feature extraction method.", "num_citations": "3\n", "authors": ["430"]}
{"title": "A Novel Approach to Stellar Recognition by Combining EKF and RBF Net\n", "abstract": " A new approach to stellar recognition is proposed. It uses extended Kalman filter as a feature selector and pre-classifier for stellar spectra data, while radial basis function neural networks is adopted for classification. Experiments with real-world data set show that the performance of the proposed technique is quite well, and the correct classification rate can reach as high as 93%. It is shown that the result using EKF is better than that using principle component analysis data dimension reduction technique.", "num_citations": "3\n", "authors": ["430"]}
{"title": "Averaging Ensemble Neural Networks in Parameter Space\n", "abstract": " Averaging Ensemble Neural Networks in Parameter Space - CERN Document Server CERN Accelerating science Sign in Directory CERN Document Server Access articles, reports and multimedia content in HEP Main menu Search Submit Help Personalize Your alerts Your baskets Your comments Your searches Home > Averaging Ensemble Neural Networks in Parameter Space Information Discussion (0) Files Article Title Averaging Ensemble Neural Networks in Parameter Space Author(s) Guo, P In: 5th International Conference on Neural Information Processing : ICONIP '98, Kitakyushu, Japan, 21 - 23 Oct 1998, pp.486-489 Back to search Record created 2000-09-14, last modified 2007-04-15 Similar records Add to personal basket Export as BibTeX, MARC, MARCXML, DC, EndNote, NLM, RefWorks CERN Document Server :: Search :: Submit :: Personalize :: Help :: Privacy Notice Powered by Invenio v1.1.3.-by ..\u2026", "num_citations": "3\n", "authors": ["430"]}
{"title": "Bayesian Pseudoinverse Learners: From Uncertainty to Deterministic Learning\n", "abstract": " Pseudo-inverse learners (PILs) are a kind of feedforward neural network trained with the pseudoinverse learning algorithm, which can be traced back to 1995 originally. PIL is an approach for nongradient descent learning, and its main advantage is the lower computational cost and fast learning procedure, which is especially relevant in the edge computing research field. However, PIL is mostly applied to a deterministic learning problem, while in the real world, the greatest case that is of concern is the uncertainty learning problem. In this work, under the framework of the synergetic learning system (SLS), we introduce an approximated synergetic learning scheme, which can transform uncertainty learning into deterministic learning. We call this new learning framework the Bayesian PIL, and the advantages are also demonstrated in this work.", "num_citations": "2\n", "authors": ["430"]}
{"title": "Learning from imbalanced pulsar data by combine DCGAN and PILAE algorithm\n", "abstract": " A pulsar is a rapidly rotating neutron star and transmits periodic oscillations of power to the earth. We introduce a novel method for pulsar candidate classification. The method contains two major steps: (1) make strong representations for pulsar candidate in the image domain by extracting deep features with the deep convolutional generative adversarial Networks (DCGAN) and (2) develop a classifier defined by multilayer perceptron (MLP) neural networks trained with pseudoinverse learning autoencoder (PILAE) algorithm. We utilized the synthetic minority over-sampling technique (SMOTE) to handle the imbalance in the dataset. We report a variety of measure scores from the output of the PILAE method on datasets utilized in the experiments. The PILAE training process does not have to determine the learning control parameters or indicate the number of hidden layers. Therefore, the PILAE classifier can fulfil\u00a0\u2026", "num_citations": "2\n", "authors": ["430"]}
{"title": "Integrated practice effect analysis of teaching design pattern on TPACK\n", "abstract": " The paper analyzes the university curriculum, including analysis of context, pedagogical content knowledge, technology technological content knowledge, and technological pedagogical knowledge\u00a0with the technological pedagogical and content knowledge (TPACK) framework. By integrating classroom teaching with the TPACK framework, through the analysis of the effect of the teaching practice of three stages in four semesters, the following conclusions are drawn: (a) Proper teaching methods and teaching techniques will greatly expand the content of the textbook; (b) integrating TPACK framework requires teachers to have more extensive knowledge and strong organization capacity; (c) through TPACK integration, all kinds of new teaching methods and teaching technologies have plenty of time to use in the classes, and the new idea of educational technology will cause the emergence of educational technologies.", "num_citations": "2\n", "authors": ["430"]}
{"title": "Palliative care in the greater China region: a systematic review of needs, models, and outcomes\n", "abstract": " ContextThere is rapidly increasing need for palliative care in Greater China because of rapidly aging populations.ObjectivesThis study aimed to systematically review and appraise evidence for palliative care needs, models of care, interventions, and outcomes in Greater China.MethodsFour databases (MEDLINE, EMBASE, CINAHL, and PsycINFO) were searched, with hand searching of local journals and databases. Narrative synthesis was applied to the qualitative and quantitative evidence.ResultsNineteen qualitative studies and 47 quantitative studies were retained. With respect to care needs, nine themes were synthesized: pain control, reduced aggressive end-of-life care, truth telling, physical, emotional, and spiritual supports, and achieving preferred place of care/death. Informal caregivers expressed their needs for education and burden reduction. Health care professionals called for training and national\u00a0\u2026", "num_citations": "2\n", "authors": ["430"]}
{"title": "Probability weighted moments regularization based blind image De-blurring\n", "abstract": " The main objective of blind image de-blurring is to recover a sharp image from a given blurry image. A good estimation of the kernel plays an important role in recovering a sharp image. However, if the local object textures are neglected when the kernel is being estimated, this can lead to over-smoothing or can produce a strong ringing effect. In this paper, a new image regularization term based on the Probability Weighted Moments (PWM) for kernel estimation is proposed named as Probability Weighted Moments Regularization (PWMR). PWMR has the ability to preserve the small local texture structure in an image while minimizing the artifacts. Further, it can preserve the better contrast information between neighboring pixels and their corresponding central pixels in a current sliding window; moreover, it has the ability to resist outliers even in a small sample size. The kernel estimated by PWMR is subsequently\u00a0\u2026", "num_citations": "2\n", "authors": ["430"]}
{"title": "The first principles for artificial intelligence\n", "abstract": " In this paper, the first principle of artificial intelligence is explained by the expression of \u201cseven questions\u201d. That is, 1. What is the first principles? 2. Why the first principle is used? 3. What is first principle thinking? 4. How to use the first principle? 5. Is there the first principles in the field of artificial intelligence? 6. Why the physics-based AI is fundamental? 7. How to make AI have common sense? By these questions being answered, a novel idea is proposed for solving the lack of basic natural science knowledge of artificial intelligence by using the first principle thinking; And it is suggested that the least action principle should be considered as the first principle of artificial intelligence.", "num_citations": "2\n", "authors": ["430"]}
{"title": "On the structure evolutionary of the pseudoinverse learners in synergetic learning systems\n", "abstract": " In a two-models synergetic learning systems (SLS), one or both models is/are assigned to be the Pseudoinverse Learners (PILer). In this work, a more general framework of PIL\u2019s structure evolutionary is investigated, and extreme deep and extreme wide PILer architecture is proposed. Moreover, we present that the high order neural network such as random vector functional link network (RVFL) can evolve to ResNetlike deep network structure under our developed new viewpoint. This is very significance that full connect neural network can be described with ordinary/partial differential equations, which can be categorized into the reaction-diffusion equations in governing synergetic learning systems.", "num_citations": "2\n", "authors": ["430"]}
{"title": "Multi-channel expected patch log likelihood for color image denoising\n", "abstract": " Due to its flexibility and good restoration performance, the Expected Patch Log Likelihood (EPLL) method has attracted extensive attention and has been further developed. However, the basic EPLL method is mainly applied for gray image restoration. For color image denoising with different channel noise levels, concatenating the RGB values into a vector and applying the basic EPLL directly can produce false colors and artifacts. In this paper, a Multi-Channel Expected Patch Log Likelihood (MC-EPLL) method is proposed for color image denoising with different channel noise levels. Considering the within and between channel correlation, the noise model of the concatenated vector of RGB channels can be constructed as a Matrix Normal Distribution. Under the KL divergence framework, the MC-EPLL model can be derived by combining the noise model and Gaussian Mixture Model (GMM) based patch prior\u00a0\u2026", "num_citations": "2\n", "authors": ["430"]}
{"title": "An ensemble model for error modeling with pseudoinverse learning algorithm\n", "abstract": " In Bayesian theory, the maximum posterior estimator uses prior information to estimate the noise in the machine learning model by adding the regularization term. The regularization terms L 1  and L 2  correspond to Laplacian prior and Guassian prior, respectively. In existing deep learning models, in order to use the gradient descent optimization algorithm and achieve good results, most models take L 2  regularization as the regularization term of the network model to fit the complex Guassian noise. However in practice, the Laplace noise and the Guassian noise are both considered as data noise. For multi-layer perceptrons, the difficulty caused by adding L 1  and L 2  into the optimization function of the network is solved by proposing an ensemble model for error modeling through adopting the divide and conquer strategy. First, several base learners are trained to fit different noise distributions of data, then the final\u00a0\u2026", "num_citations": "2\n", "authors": ["430"]}
{"title": "An unified view on the feedforward neural network architecture\n", "abstract": " In this paper, an unified view on feedforward neural networks (FNNs) is provided from the free perception of the architecture design, learning algorithm, cost function, regularization, activation functions, etc. Furthermore, we consider the ensemble networks and swarm intelligence as the same sytems which consists of multiple learning algorithms or collective behavior of decentralized, self-organized systems with similar unified view of FNNs based architecture. This work is a small step on the road toward to the general theory of neural networks.", "num_citations": "2\n", "authors": ["430"]}
{"title": "Patients\u2019 views on care and their association with outcomes in palliative care\n", "abstract": " MethodsWe conducted a survey to examine patients\u2019 views on care (using VOC) and the relationship between these views and changes in health status. Participants were adults receiving specialist palliative care in eight hospital, hospice inpatient and community settings across England, recruited in 2014\u20132015. We collected demographic details (age, gender, ethnicity, marital status, if living alone, presence of informal caregiver, diagnosis, palliative phase of illness and performance status), plus patient-reported survey at baseline and follow-up (3\u20135 days later for inpatient and 7\u201321 days later for community settings)(see Table 1). The survey included VOC and the Integrated Palliative Care Outcome Scale (IPOS). We report VOC at follow-up and change in IPOS between baseline and follow-up. Descriptive statistics characterise sample demographics and VOC responses, and chi-square statistic tests the\u00a0\u2026", "num_citations": "2\n", "authors": ["430"]}
{"title": "Marine floating raft aquaculture back scattering feature analysis based on ISAR imagery\n", "abstract": " Synthetic Aperture Radar (SAR) is an important composition on remote sensing. Computer intelligence is widely used in SAR data classification, this addresses the importance of studying the back scatter feature of the studied object. In this paper, Inverse Synthetic Aperture Radar (ISAR) images of floating raft aquaculture (FRA) are designed to analyze detail scattering features of FRA. And the Pierson-Moskowitz (P-M) sea wave spectrum is adopted to imitate sea surface under a certain wind speed. Commercial E-M software FEKO is used for calculate the back scatter data of combined scenario. And polar format algorithm is used to generate ISAR images. After that, the ISAR images of different circumstances combined with FRA and sea are compared and analyzed. The results demonstrate that proposed method is capable of exhibiting the changes of back scatter feature in different scenarios. And the backscatter\u00a0\u2026", "num_citations": "2\n", "authors": ["430"]}
{"title": "Mixture of matrix normal distributions for color image inpainting\n", "abstract": " Gaussian mixture model is commonly used as image prior model to solve image restoration problem. However, vector representation leads to lose the inherent spatial relevant information and cause unstable estimation. In this paper, a mixture of matrix normal distributions (MMND) based image restoration algorithm is proposed, which incorporates the hidden structural information into prior image modeling. MMND is used as the prior image model and expectation maximization algorithm is used to optimize the maximum posterior criterion. Experiments conducted on color images indicate that MMND can achieve better peak signal to noise ratio (PSNR) as compared to other state-of-the-art methods.", "num_citations": "2\n", "authors": ["430"]}
{"title": "Saliency based object detection and enhancements in static images\n", "abstract": " Human visual system always focuses on the salient region of an image. From that region the salient features are obtained and can be collected by generating the saliency map. Natural statistics measures are used to measure the saliency from data collection of natural images. ICA filters are used to generate the saliency map that can blur the image. We have improved it by using different techniques like edge detection and morphological operations. By applying these algorithms we have successfully reduced the blur in images. That makes the salient objects more prominent by sharpening the edges. Proposed method is also compared with the state-of-the-art method like Achanta model.", "num_citations": "2\n", "authors": ["430"]}
{"title": "Kernel selection with evolutionary algorithm for multiple kernel independent component analysis\n", "abstract": " Kernel independent component analysis (KICA) has an important application in blind source separation, in which how to select the optimal kernel, including the kernel functional form and its parameters, is the key issue for obtaining the optimal performance. In practices, a single kernel is usually chosen as the kernel model of KICA in light of experience. However, selecting a suitable kernel model is a more difficult problem if one has not sufficient experience. To deal with this problem, an evolution based method to select the kernel model of KICA is proposed in this paper. There are two main features of the proposed method: one is that using a multiple kernel model, a convex combination of several single kernels, replaces the single kernel model; another is that particle swarm optimization (PSO) algorithm is utilized to find the combination weights of the composite kernel. Experiments conducted on separating one\u00a0\u2026", "num_citations": "2\n", "authors": ["430"]}
{"title": "Angular quantization based affinity propagation clustering and its application to astronomical big spectra data\n", "abstract": " Affinity Propagation (AP) algorithm is a useful clustering technique with a lot of noteworthy advantages. It has been successfully applied in many applications. However, this algorithm does not scale for large scale data sets because it requires quadratic computational time and memory usage in the problem size. In this paper, we concentrate on the needs of big data analytics and propose an effective and efficient scheme to decrease the computational complexity and memory usage of AP algorithm. The basic idea of our approach is embedding data points in distance-preserving binary codes and then decomposing the original big data set into a series of small subsets by aggregating similar data points according to their binary codes. The experimental results and the real world astronomical spectral data application demonstrate the effectiveness of our approach quantitatively and visually.", "num_citations": "2\n", "authors": ["430"]}
{"title": "Blind source separation with evolution based kica\n", "abstract": " Kernel independent component analysis (KICA) has been widely used in the field of blind source separation. The selection of kernel function and its parameters plays an important role in KICA algorithm performance. An optimal kernel model should be rich enough to well map the given samples. However, users usually use a singular kernel based model in their experiments, which leads to a suboptimal kernel model. In order to solve this problem, we propose the evolution based multiple kernel independent component analysis (EMKICA), in which a convex combination of multiple base kernels is used instead of single kernel of KICA. The combination weights are learned by particle swarm optimization algorithm. Firstly, we elaborate the basic theory of KICA and concept of EMKICA, also the combination form of the composition kernel used in EMKICA. Secondly, we describe the presentation of the individuals in the\u00a0\u2026", "num_citations": "2\n", "authors": ["430"]}
{"title": "An efficient and scalable learning algorithm for near-earth objects detection in astronomy big image data\n", "abstract": " In this paper, we investigate the efficiency and scalability of Gaussian mixture model based learning algorithm for the detection of Near-Earth objects in large scale astronomy image data. We propose an effective scheme to reduce the computational complexity of current learning algorithm, this is achieved by adopting the perceptual image hashing method. Our proposed scheme is validated on raw astronomy image data. The experiment results illustrate that both efficiency and scalability are improved significantly in astronomical scenario and other scenario.", "num_citations": "2\n", "authors": ["430"]}
{"title": "Texture Region Merging with Histogram Feature for Color Image Segmentation\n", "abstract": " This paper presents a novel region merging segmentation method for color image based on color and texture distribution features. The segmentation strategy includes two phases. In the first phase, we select initial seed points for superpixels extraction in the texture energy image at average intervals. Then we implement pixels clustering to extract over segmentation regions at local areas using color and texture information. In the second phase, a hybird texture histograms is introduced to represent the local color distribution information of internal pixels in over segmentation regions. The region merging employs computing corresponding histograms, which are normalized into fixed bins. Experiment results on Berkeley Segmentation Dataset (BSD) demonstrated that the proposed segmented algorithm can achieve good applications on the nature images with complex textures.", "num_citations": "2\n", "authors": ["430"]}
{"title": "Global matching to enhance the strength of local intensity order pattern feature descriptor\n", "abstract": " Local intensity order pattern feature descriptor is proposed to extract the feature of image recently. However, it did not provide the global information of an image. In this paper, a simple, efficient and robust feature descriptor is presented, which is realized by adding the global information to local intensity features. A descriptor, which utilizes local intensity order pattern and/or global matching, is proposed to gather the global information with local intensity order. Experimental results shows that the proposed hybrid approach outperform over the state-of-the art feature extraction method like scale-invariant feature transform, local intensity order pattern and\u00a0DAISY for standard oxford dataset.", "num_citations": "2\n", "authors": ["430"]}
{"title": "Scene Recognition via Combining Information of Neighbors\n", "abstract": " Recently, spatial principal component analysis of census transform histograms (PACT) was proposed to recognize instance and categories of places or scenes in an image. When combining PACT with Local difference Magnitude Binary Pattern (LMBP), a new representation called Local Difference Binary Pattern (LDBP) was proposed and performed better. LDBP is based on the comparisons between center pixel and its neighboring pixels. However, the relationship among neighbor pixels is not considered. In this paper we proposed Local Neighbor Binary Pattern (LNBP) to utilize the relationship among neighboring pixels. LNBP provides complementary information regarding neighboring pixels for LDBP. We propose to combine LDBP with LNBP, and used a spatial representation for scene recognition. Experiments on two widely used dataset demonstrate the proposed method can improve the performance of\u00a0\u2026", "num_citations": "2\n", "authors": ["430"]}
{"title": "Text-independent Speaker Identification Using Fisher Discrimination Dictionary Learning Method\n", "abstract": " In last decades, text-independent speaker recognition is a hot research topic attracted many researchers. In this paper, we proposed to apply the Fisher discrimination dictionary learning method to identify the text-independent speaker recognition. The feature used in classification is the Gaussian Mixture Model super vector. The proposed method is evaluated with public ally available dataset TIMIT. Experimental results show that the proposed method outperforms the Sparse Representation Classifier used for text-independent speaker recognition in both clean and noisy condition.", "num_citations": "2\n", "authors": ["430"]}
{"title": "A multiple scattering in participating media for real time rendering\n", "abstract": " At present, multiple scattering problems in participating media is still very challenging for real time rendering. Some methods have proposed to describe multiple scattering phenomena, however, there are some restriction conditions such as requiring the medium is static, etc., and rendering speed is not satisfied real-time requirement. In order to speed up the multiple scattering rendering, we propose a GPU based algorithm in this paper. First of all, the media is initialized with a particle system and the property of each particle is defined; secondly, according to the properties of each particle, a method of tracing the particle path, which is generated by uniformly sampling the surrounding particles of one particle, is proposed and this method is used to compute in-scattering radiance for each particle; finally, the total radiance is calculated by summing up contributions of particles along ray paths and the final image is\u00a0\u2026", "num_citations": "2\n", "authors": ["430"]}
{"title": "Combined Descriptors in Spatial Pyramid Domain for Image Classification\n", "abstract": " Recently spatial pyramid matching (SPM) with scale invariant feature transform (SIFT) descriptor has been successfully used in image classification. Unfortunately, the codebook generation and feature quantization procedures using SIFT feature have the high complexity both in time and space. To address this problem, in this paper, we propose an approach which combines local binary patterns (LBP) and three-patch local binary patterns (TPLBP) in spatial pyramid domain. The proposed method does not need to learn the codebook and feature quantization processing, hence it becomes very efficient. Experiments on two popular benchmark datasets demonstrate that the proposed method always significantly outperforms the very popular SPM based SIFT descriptor method both in time and classification accuracy.", "num_citations": "2\n", "authors": ["430"]}
{"title": "Color Image Segmentation Based on Blocks Clustering and Region Growing\n", "abstract": " In order to overcome the discontinuity in clustering segmentation, a novel color image segmentation algorithm is proposed, which is based on seeds clustering and can locate the seeds of regions quickly. Firstly, the image is divided into a series of non-overlapping blocks with the size of n(n pixels in HSI color space. For each block, the centroid pixel of salient homogeneous region is selected as a feature point of the block. Secondly, based on the principles of color similarity centroids are clustered to obtain the clustered centroids as seeds for region growing. Finally, invalid and noisy regions are merged to get the complete segmentation results. Comparing with other segmentation algorithms, the experimental results demonstrate that the proposed method can accurately segment regions and objects, it outperforms other methods in terms of human visual perception.", "num_citations": "2\n", "authors": ["430"]}
{"title": "Speed up spatial pyramid matching using sparse coding with affinity propagation algorithm\n", "abstract": " Recently support vector machines (SVMs) combining spatial pyramid matching (SPM) kernel have been highly successful in image annotation. And linear spatial pyramid matching using sparse coding (ScSPM) scheme was proposed to enhance the performance of SPM both in time and annotation accuracy. However, both of these algorithms suffer from expansibility problem, and ScSPM needs quite a long time for codebook construction. In this paper, we proposed an adjusted framework for the ScSPM algorithm, which applies multi-level affinity propagation (AP) algorithm to the codebook construction process (AP-ScSPM). This novel approach can remarkably reduces the time complexity of codebook construction process. Furthermore, as AP algorithm can automatically determine the representative vector number, the expansibility of the algorithm is improved. By a series of experiments, we find that the\u00a0\u2026", "num_citations": "2\n", "authors": ["430"]}
{"title": "Scale estimate of self-organizing map for color image segmentation\n", "abstract": " Self-Organizing Maps (SOM) have presented excellent effect in color image segmentation; the scale of SOM will directly affect the accuracy of segmentation results. In this paper, we proposed a novel scale estimated of self-organizing map (SE-SOM) for color image segmentation based on SOM clustering. Different from conventional SOM model, it determines the number of nodes of competition layer by 3-D spatial distribution of pixels in HSV (Hue-Saturation-value) color space. Then sample pixels to train the map topology of the image and segment pixels by computing similarity between their feature vectors with weights of each node. Finally, design a connectivity filter to update labels of image to decrease noise. Statistical information are used to design map scale, which adapted the final SOM scale to the distribution feature of pixels, clustering results more accurate and stable, Experiments results show that the\u00a0\u2026", "num_citations": "2\n", "authors": ["430"]}
{"title": "Speed Up Reliability Model Optimization With Hypervolume Contribution Calculating Algorithm\n", "abstract": " Software dependability modelling involves simultaneous consideration of several incompatible and often conflicting objectives, while hypervolume-based multi-objective evolutionary algorithm (MOEA) has been shown to produce better results for multi-objective problem in practice. A frame of reliability model optimization with hypervolume based MOEA is presented. Focusing on the key issue of hypervolume based MOEA, a new algorithm, set hypervolume contribution by slicing objective (SHSO), is proposed for calculating the exclusive hypervolume contribution of a subset to the whole nondominated set directly for small dimension. For the special case of SHSO, CHSO (the contribution of a point to hypervolume by slicing objective) is improved with heuristics. The feasibility and efficiency of developed algorithms are shown by experiments.", "num_citations": "2\n", "authors": ["430"]}
{"title": "Image segmentation based on visual perception model\n", "abstract": " Image segmentation is the basis of image processing and image analysis. However, there are no common method that can be used in natural images, and present methods fail to explain understandings of human\u2019s visual system. In this paper, we propose to apply Karklin's visual perception model to extract feature vectors of images, and the features are clustered with K-means method. The results obtained in feature space are projected back to the image space to finish segmentation. A comparison with the Normalized Cuts (Ncut) method is done, and it turns out that proposed method outperform Ncut in texture rich images.", "num_citations": "2\n", "authors": ["430"]}
{"title": "Optimization of training samples with affinity propagation algorithm for multi-class SVM classification\n", "abstract": " This paper presents a novel optimization method of training samples with Affinity Propagation (AP) clustering algorithm for multi-class Support Vector Machine (SVM) classification problem. The method of optimizing training samples is based on region clustering with affinity propagation algorithm. Then the multi-class support vector machines are trained for natural image classification with AP optimized samples. The feature space constructed in this paper is a composition of combined histogram with color, texture and edge descriptor of images. Experimental results show that better classification accuracy can be obtained by using the proposed method.", "num_citations": "2\n", "authors": ["430"]}
{"title": "An Ortho-Rectification Method for Space-Borne SAR Image with Imaging Equation\n", "abstract": " An ortho-rectification scheme for space-borne Synthetic Aperture Radar (SAR) image is investigated in this paper. It was usually achieved by indirect mapping between real SAR image pixels and the Digital Evaluation Model (DEM) grids. However, the precise orbit data cannot be easily obtained and using the Newton algorithm needs more calculation. In order to reduce the time consumed during iteration and further improving the accuracy of the SAR image, we propose a new ortho-rectification method with imaging equation. It removes the coordinate conversion by uniformly using the World Geodetic System 1984 (WGS-84). Moreover, the initial time of each DEM grid can be set according to the iteration result of its adjacent point. Compared to other methods, such as Collinearity Equation method, it costs less time and makes the SAR image more accurate. It is also much easier to be implemented in practice.", "num_citations": "2\n", "authors": ["430"]}
{"title": "Combining LPP with PCA for microarray data clustering\n", "abstract": " DNA microarray technique has produced large amount of gene expression data. To analyze these data, many excellent machine learning techniques have been proposed in recent related work. In this paper, we try to perform the clustering of microarray data by combining the recently proposed locality preserving projection (LPP) method with PCA, i.e. PCA-LPP. The comparison between PCA and PCA-LPP is performed based on two clustering algorithms, K-means and agglomerative hierarchical clustering. As we already known, clustering with the components extracted by PCA instead of the original variables does improve cluster quality. Moreover, our empirical study shows that by using LPP to perform further process the dimensions of components extracted by PCA can be further reduced and the quality of the clusters can be improved greatly meanwhile. Particularly, the first few components obtained by PCA\u00a0\u2026", "num_citations": "2\n", "authors": ["430"]}
{"title": "Assessment of transgenic Bt insect-resistant cotton on the digestive enzymes of Aphis gossypii (Homoptera: Aphidae)\n", "abstract": " Cotton aphid Aphis gossypii (Homoptera: Aphidae) is one of the seriously occurred non-target pests in transgenic Bt cotton fields. The activities and specific activities of midgut digestive enzymes, including proteinase, amylase, trehalase and sucrase, of cotton aphids fed on Bt cotton cv. GK12 for different generations were detected with microtiter plate reader, and were compared with those of cotton aphids fed on the non-Bt parental cotton cv. simian 3. Thus the short-term and long-term effects of Bt cotton on the digestive enzymes of cotton aphids were determined. The results showed that there were no significant differences in the activities and specific activities of the four digestive enzymes between the cotton aphids fed on Bt cotton and non-Bt parental cotton, no matter for one to three generations, or for over sixty generations. And there were no significant difference among the cotton aphids fed on Bt cotton for different generations. It indicated that Bt cotton had no significant impacts on the activities of cotton aphid\u2032 s midgut digestive enzymes both in the short run and long term.", "num_citations": "2\n", "authors": ["430"]}
{"title": "Foam capacity in tertiary oil recovery and application in pilot [J]\n", "abstract": " The foam capacity in pore medium was investigated on in-house lab setup. The results show that foam has high flowing resistant, and its apparent viscocity is larger than any single coponent viscocity. The apparent viscocity of foam system increases with the permeability increasing. As a result of uniform distribution of foam pressure difference, end jam can't form. The block of foam has selectivity to oil and water. With low-content remaining oil, foam has strong block capacity and low flow velocity. With high-content remaining oil, foam has poor stability and weak block capacity. The foam system can enhance oil recovery by more than 20%. The pilot test results show that the foam can increase injection pressure enormously, improve the injection profile, enhance oil production and decrease water cut.", "num_citations": "2\n", "authors": ["430"]}
{"title": "Improving diffuse optical tomography imaging with adaptive regularization method\n", "abstract": " Diffuse optical tomography (DOT) is to reconstruct the images of internal optical parameters distribution from boundary measurements. Due to the amount of available boundary measurements is less than the number of unknown optical parameters to be recovered, this inverse problem usually shows the ill-posed characteristics. This will result in the problem of low reconstruction image quality. In this paper, an adaptive regularization method based on the objective function values is proposed, which reduces the ill-posed characteristics in the inverse problem by selecting an appropriate regularization value at teach iteration. Results from computer simulations indicated that using this regularization technique, DOT imaging quality is improved effectively. Furthermore, using the regularization technique, the sensitivity to noise of the reconstructed images can be decreased greatly.", "num_citations": "2\n", "authors": ["430"]}
{"title": "Hydraulics Simulation Investigation on Tundish for Slab Casting\n", "abstract": " In order to improve the quality of continuous casting steel slab, the flow rule of liquid steel in tundish has been studied by hydraulics simulation test. Liquid steel critical highness of preventing from slag entrapment in tundish is measured at the condition of non-steady casting. The controlling scheme of installing weir, dam and turbulence inhibitor was defined in tundish. The test results showed that with installed designed flow control devices in tundish, the average residence time was prolonged to improve the ability of removing the inclusion from liquid steeel in tundish. The critical highness of slag entrapment was gained in tundish.", "num_citations": "2\n", "authors": ["430"]}
{"title": "Stellar spectral feature extraction and combination analysis for classification with ENN\n", "abstract": " This paper presents a novel stellar spectral classification method. Wavelet packet transform is adopted to extract continuums and absorptions in the spectra. Then a method for constructing combinatorial features is introduced, which is suitable for both temperature and luminosity classification. Finally both temperature and luminosity classes of the stars are determined using ensemble neural networks. Experiments with real world data show that the feature extraction process is efficient and the obtained correct classification rate is quite satisfying. The results also show that the ensemble neural networks give a better generalization than a single back propagation neural network.", "num_citations": "2\n", "authors": ["430"]}
{"title": "\u73bb\u7483\u4e0e\u6db2\u6676\u975e\u7ebf\u6027\u5149\u5b66\u754c\u9762\u53cd\u5c04\u7279\u6027\u7684\u7814\u7a76\n", "abstract": " \u672c\u6587\u7cfb\u7edf\u5730\u7814\u7a76\u4e86\u7531\u73bb\u7483\u4e0e\u6db2\u6676\u6784\u6210\u7684\u975e\u7ebf\u6027\u5149\u5b66\u754c\u9762. \u7528\u4e00\u53f0\u8c03 O \u7684\u7ea2\u5b9d\u77f3 \u6fc0\u5149\u5668\u7814\u7a76\u4e86\u7531\u73bb\u7483\u4e0e\u5904\u4e8e\u5404\u5411\u540c\u6027\u6db2\u76f8\u7684\u6db2\u6676\u6240\u6784\u6210\u7684\u975e\u7ebf\u6027\u754c\u9762. \u5728\u4e0d\u540c\u5165\u5c04\u89d2\u65f6\u975e \u7ebf\u6027\u754c\u9762\u7531\u5185\u90e8\u5168\u53cd\u5c04\u8dc3\u53d8\u5230\u90e8\u5206\u900f\u5c04\u7684\u95ed\u503c\u5149\u5f3a\u4e0e K: pl en \u7684\u5e73\u9762\u6ce2\u7406\u8bba\u8ba1\u7b97\u7ed3\u679c\u76f8 \u4e00\u81f4. \u5728 T \u4e00 T.~ 2. 5\u2103 \u6761\u4ef6\u4e0b\u6d4b\u91cf\u4e86\u65f6\u95f4\u5206\u8fa8\u7684\u975e\u7ebf\u6027\u754c\u9762\u7684\u53cd\u5c04\u7387. \u89c2\u5bdf\u5230\u4e86\u53cd\u5c04\u7387\u7684\u6ede\u540e\u8fe5\u7ebf. \u975e\u7ebf\u6027\u754c\u9762\u7684\u8fd9\u79cd\u53cd\u5c04\u7387\u7684\u6ede\u540e\u8fe5\u7ebf\u53ef\u4ee5\u5f52\u4e4b\u4e8e\u6db2\u6676\u5206\u5b50\u9000\u53d6\u5411\u7684\u5f1b\u8c6b\u8fc7\u7a0b. \u7528 A+ r \u6fc0\u5149\u5668\u7814\u7a76\u4e86\u73bb\u7483\u4e0e\u5411\u5217\u76f8\u6db2\u6676\u6240\u6784\u6210\u7684\u975e\u7ebf\u6027\u5149\u5b66\u754c\u9762, \u89c2\u5bdf\u5230\u4e86\u7531\u76f8\u53d8\u800c\u4ea7\u751f\u7684\u5185\u90e8\u5168\u53cd\u5c04\u5230\u90e8\u5206\u900f\u5c04\u72b6\u6001\u7684\u8dc3\u53d8.", "num_citations": "2\n", "authors": ["430"]}
{"title": "An efficient and effective deep convolutional kernel pseudoinverse learner with multi-filter\n", "abstract": " The convolutional neural network is the most widely used deep neural network. However, it still has some disadvantages. First, the back-propagation method is usually used in the training of convolutional neural networks, but it has several inherent defects, such as the vanishing gradient problem and exploding gradient problem. Moreover, the training of a convolutional neural network often needs substantial computational resources and time. To solve the above problems, based on pseudoinverse learning (PIL), kernel pseudoinverse learning (KPIL) is proposed, showing improved performance. The number of hidden layer neurons of KPIL is equal to the number of input data and does not need to be set. KPIL uses the kernel method to calculate the output of hidden layer, avoiding the uncertainty of random input weights. Based on KPIL, a deep convolutional kernel pseudoinverse learner with a multi-filter design is\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "TPGN: A Time-Preference Gate Network for e-commerce purchase intention recognition\n", "abstract": " The studies on users\u2019 purchase intentions based on e-commerce data are of great significance to marketers, buyers, and society. Current studies on users\u2019 intentions with traditional machine learning methods usually focus on unique features and are time-consuming. Due to the characteristics of user behaviors and the importance of time sequence, deep learning methods are increasingly applied in relevant studies. In the study, in order to predict online user\u2019s purchase intentions, based on Long-Short Term Memory (LSTM) model, we proposed Time-Preference Gate Network (TPGN). A pair of preference gates and a pair of time interval gates are added to the model. The preference gates are used to capture the users\u2019 category preferences at different time and the time interval gates are used to capture the users\u2019 long-term interest. In our model, through coupling the input gate with the forget gate, the parameters of\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "Should end\u2010of\u2010life patients be enrolled as participants in clinical research? A best\u2010fit framework synthesis\n", "abstract": " Aim To identify and appraise evidence about ethical concerns regarding conducting medical research with end\u2010of\u2010life patients.   Design A best\u2010fit framework synthesis of the literature regarding ethical issues in research involving adult patients at the end of life was conducted.   Data sources Five databases were searched (Cumulative Index to Nursing and Allied Health Literature, Web of Science, Embase, MEDLINE, and PsychINFO) between January 2000\u2013August 2019.   Review methods Data were synthesized and categorized according to the moral positions described by Foster.   Results In all, 18 papers that met the inclusion criteria were included in this review. These papers provided rich knowledge not only about various ethical objections to researching the end of life but also about the social, moral, and clinical requirements to perform rigorous studies on clinical interventions in this field\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "Partial Differential Equations is All You Need for Generating Neural Architectures--A Theory for Physical Artificial Intelligence Systems\n", "abstract": " In this work, we generalize the reaction-diffusion equation in statistical physics, Schr\\\"odinger equation in quantum mechanics, Helmholtz equation in paraxial optics into the neural partial differential equations (NPDE), which can be considered as the fundamental equations in the field of artificial intelligence research. We take finite difference method to discretize NPDE for finding numerical solution, and the basic building blocks of deep neural network architecture, including multi-layer perceptron, convolutional neural network and recurrent neural networks, are generated. The learning strategies, such as Adaptive moment estimation, L-BFGS, pseudoinverse learning algorithms and partial differential equation constrained optimization, are also presented. We believe it is of significance that presented clear physical image of interpretable deep neural networks, which makes it be possible for applying to analog computing device design, and pave the road to physical artificial intelligence.", "num_citations": "1\n", "authors": ["430"]}
{"title": "DNA sequence classification based on MLP with PILAE algorithm\n", "abstract": " In the bioinformatics field, the classification of unknown biological sequences is a key task that is fundamental for simplifying the consistency, aggregation, and survey of organisms and their evolution. We can view biological sequences as data components of higher non-fixed dimensions, corresponding to the length of the sequences. Numerical encoding performs an important function in DNA sequence evaluation via computational procedures such as one-hot encoding (OHE). However, the OHE method has drawbacks: 1) it does not add any details that may produce the additional predictive variable, and 2) if the variable has many classes, then OHE increases the feature space significantly. To overcome these drawbacks, this paper presents a computationally effective framework for classifying DNA sequences of living organisms in the image domain. The proposed strategy relies upon multilayer\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "Chemical pancreatectomy treats chronic pancreatitis while preserving endocrine function in preclinical models\n", "abstract": " Chronic pancreatitis affects over 250,000 people in the US and millions worldwide. It is associated with chronic debilitating pain, pancreatic exocrine failure, and high risk of pancreatic cancer and usually progresses to diabetes. Treatment options are limited and ineffective. We developed a new potential therapy, wherein a pancreatic ductal infusion of 1%\u20132% acetic acid in mice and nonhuman primates resulted in a nonregenerative, near-complete ablation of the exocrine pancreas, with complete preservation of the islets. Pancreatic ductal infusion of acetic acid in a mouse model of chronic pancreatitis led to resolution of chronic inflammation and pancreatitis-associated pain. Furthermore, acetic acid\u2013treated animals showed improved glucose tolerance and insulin secretion. The loss of exocrine tissue in this procedure would not typically require further management in patients with chronic pancreatitis because they\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "An Empirical Study of Pre-trained Embedding on Ultra-Fine Entity Typing\n", "abstract": " The embedding generated by pre-trained models has attracted the attention of many scholars in the past few years. Most of the context-sensitive embeddings have confirmed the positive impact on some basic tasks of classification, which have only a few types. In this paper, we make an empirical comparison of different pre-trained embeddings on the task of ultra-fine entity typing which has more than 10k types. We apply 7 kinds of pre-trained embedding to the typing model to prove whether the pre-trained embedding has a positive effect. The results indicate that almost all context-sensitive pre-trained embeddings improve the performance of models using Glove. The pre-trained embedding generated by BERT achieves the best performance in the Ultra-Fine dataset and OntoNotes dataset, which shows BERT has better capability to extract finer-grained information than other pre-trained models.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Radio frequency interference mitigation using pseudoinverse learning autoencoders\n", "abstract": " Radio frequency interference (RFI) is an important challenge in radio astronomy. RFI comes from various sources and increasingly impacts astronomical observation as telescopes become more sensitive. In this study, we propose a fast and effective method for removing RFI in pulsar data. We use pseudo-inverse learning to train a single hidden layer auto-encoder (AE). We demonstrate that the AE can quickly learn the RFI signatures and then remove them from fast-sampled spectra, leaving real pulsar signals. This method has the advantage over traditional threshold-based filter method in that it does not completely remove contaminated channels, which could also contain useful astronomical information.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Cancer research in the 57 Organisation of Islamic Cooperation (OIC) countries, 2008\u201317\n", "abstract": " ResultsThere were 49,712 cancer research papers over this period. The leading countries in terms of output were Turkey, Iran, Egypt and Malaysia, but the most cited papers were from Qatar, Indonesia and Saudi Arabia. International collaboration was low, except in Qatar and the United Arab Emirates. The site-specific cancers accounting for most research were breast and blood, correlating with their disease burden in the OIC countries, but lung, cervical and oesophageal cancers were relatively under-researched. Most funding from within the OIC countries was from their own university sector.ConclusionCancer is seriously under-researched in most of the OIC countries. This will undermine the ability of these countries and OIC as a whole to deliver on better cancer control for their populations. New policies, OIC leadership and funding are urgently needed to address this situation.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Chinese NER by Span-Level Self-Attention\n", "abstract": " In this paper, we investigate how to improve Chinese named entity recognition (NER) by applying self-attention mechanism on span-level semantic representations. Specifically, we propose a model which acquires character representations through pre-trained BERT, then extracts features of each possible character-span through LSTM, estimates the semantic reference value of each span, then explicitly leverages span-level information by performing self-attention calculation among span representations. Experiments on OntoNotes 4.0 dataset have demonstrated that the proposed model achieves 79.97% F1-score, outperforming our baseline methods.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Two-Dimensional Fiber Spectral Bending Correction Based on Curve Distance Method\n", "abstract": " The multi-target fiber spectroscopic telescope can obtain a large number of spectral data of different celestial bodies in one observation. The light detected from the celestial body passes through the slit of the spectrometer, and after passing through the optical fiber, it is transmitted to the CCD sensor to obtain a two-dimensional spectral image. After a series of processing by the fiber optic spectral data processing system, the available spectral data is finally output and stored. The one-dimensional spectrum is the main means by which we obtain information about the target celestial body. The LAMOST telescope is used to obtain the observed celestial information. Taking LAMOST as an example, before obtaining a one-dimensional spectrum, the telescope system first obtains a two-dimensional spectrum consisting of 250 optical fiber spectra after one observation, and then undergoes a series of processing to obtain a\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "A Delayed Neural Network for Solving a Class of Constrained Pseudoconvex Optimizations\n", "abstract": " This paper presents a delayed neural network (DNN) to solve a pseudoconvex optimization problem with equality constraints. Based on differential inclusion theory, the equilibrium point of the proposed DNN is proved to be exponentially stable. Moreover, for any initial value, the state of the DNN reaches equality constraint set in finite time and finally converges to an optimal solution to the pseudoconvex optimization problem. As far as we know, it is the first time that DNN is applied to solve pseudoconvex optimization problems. Compared with the existing neural networks for solving pseudoconvex optimization problems, the neural network here considers the time delays appearing in signal transmission. Furthermore, unlike convergence results based on complicated conditions, the convergence of states to the proposed DNN in this paper only rely on the assumption that the gradient of objective function in the\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "Image Recognition Based on Combined Filters with Pseudoinverse Learning Algorithm\n", "abstract": " Deep convolution neural network (CNN) is one of the most popular Deep neural networks (DNN). It has won state-of-the-art performance in many computer vision tasks. The most used method to train DNN is Gradient descent-based algorithm such as Backpropagation. However, backpropagation algorithm usually has the problem of gradient vanishing or gradient explosion, and it relies on repeated iteration to get the optimal result. Moreover, with the need to learn many convolutional kernels, the traditional convolutional layer is the main computational bottleneck of deep CNNs. Consequently, the current deep CNN is inefficient on computing resource and computing time. To solve these problems, we proposed a method which combines Gabor kernel, random kernel and pseudoinverse kernel, incorporating with pseudoinverse learning (PIL) algorithm to speed up DNN training processing. With the multiple\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "TIPE2 gene transfer with adeno-associated virus 9 ameliorates dystrophic pathology in mdx mice\n", "abstract": " Duchenne muscle dystrophy (DMD), characterized by progressive loss of muscle architecture and function, is caused by lack of dystrophin expression in the sarcolemma of myofibers. Recurrent muscle damages in DMD patients and DMD mouse model, mdx, lead to chronic inflammation, which further exacerbate the muscle histopathology. It is critical to find a successful therapy that will improve the histopathology of muscles of DMD patients and restore skeletal muscle function. TIPE2 (tumor necrosis factor \u03b1-induced-protein 8-like 2), identified as a negative regulator of immune response, has been found to be expressed in various types of immune cells including macrophages. However, whether and how TIPE2 plays a role in the DMD-related inflammation remains unknown. In this study, we found the basal expression levels of TIPE2 in skeletal muscle from mdx mice are significantly lower than wild-type (WT\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "Hyperspectral Image Denoising Based on Low Rank and Expected Patch Log Likelihood\n", "abstract": " Denoising is a necessary and fundamental step in the hyperspectral image (HSI) analysis process. Since the spectral channels of HSI are highly correlated, they are characterized by a low rank structure and can be well approximated by low rank representation. Therefore, based on low rank structure and the EPLL, a 4-step algorithm is proposed to denoise the hyperspectral images with Gaussian noise. PCA is used to explore the high correlation and capture the low rank structure in spectral domain of HSI. The EPLL is used to further denoise the HSI in spatial domain. Compared with four state-of-the-art denoising algorithms, the proposed algorithm performs well in HSI denoising, especially for moderate and high noise levels.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Expected Patch Log Likelihood with a Prior of Mixture of Matrix Normal Distributions for Image Denoising\n", "abstract": " Mixture of Matrix Normal Distributions (MMND) is the two dimensional extension of Gaussian Mixture Model, which has been widely applied for clustering three-way data. It is the key issue to build image prior model for solving image denoising problem. In this paper, the Expected Patch Log Likelihood (EPLL) with a prior of MMND is proposed for image denoising. Expectation Maximization algorithm and flip-flop algorithm are adopted to estimate the parameters in MMND. Regularization parameter of covariance matrix is selected by the criterion of minimization the Kullback-Leibler information measure (KLIM) with a heuristic approximation. Under the framework of the EPLL, the approximate MAP estimation for the unknown image x is developed. It is shown by experiments that MMND based patch prior performs well on image denoising problem.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Personalized Response Generation for Customer Service Agents\n", "abstract": " Natural language generation is a critical component of dialogue system and plenty of works have proved the effectiveness and efficiency of sequence-to-sequence (seq2seq) model for generation. Seq2seq model is a kind of neural networks which usual require massive data to learn its parameters. For many small shops in customer service dialogue systems, there is not large dialogue dataset to be utilized to train this model, resulting in performance of trained model cannot meet real application requirements. In this work, we present the Tensor Encoder Generative Model (TEGM) collaborating data of many shops in customer service dialogue system, and expect to alleviate the disadvantage of data insufficiency. The generator fully trained from data can be capable of encoding personalized feature of each shop. Experimental results show that the TEGM indeed can improve performance compared to baseline.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Training neural networks by marginalizing out hidden layer noise\n", "abstract": " The generalization ability of neural networks is influenced by the size of the training set. The training process for single-hidden-layer feedforward neural networks (SLFNs) consists of two stages: nonlinear feature mapping and predictor optimization in the hidden layer space. In this paper, we propose a new approach, called marginalizing out hidden layer noise (MHLN), in which the predictor of SLFNs is trained with infinite samples. First, MHLN augments the training set in the hidden layer space with constrained samples, which are generated by corrupting the hidden layer outputs of the training set with given noise. For any given training sample, when the number of corruptions is close to infinity, according to the weak law of large numbers, the explicitly generated constrained samples can be replaced with their expectations. In this way, the training set is implicitly extended in the hidden layer space by an\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "A patch analysis based repairing method for two dimensional fiber spectrum image\n", "abstract": " As production of the telescope observation system, spectrum CCD images are affected by cosmic rays, dust, atmospheric and other natural conditions, which add noise to the spectrum information in image and make the image data difficult to study. The process of repairing the noise influence for CCD image is important. Existing methods such as median filter process and template matching cannot get balance for speed and precision. This paper presents a method based on local patch analysis. First, source image is compressed in order to target the noise area patch efficiently. Second, noise area patches in source CCD image are captured by building mapping relationship of noise area patches between compression image and source image. Finally noise area patches are fixed by using the local patch analysis method. Experiment proves that this algorithm can get better result and remove the cosmic rays affect\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "Extracting Company-Specific Keyphrases from News Media\n", "abstract": " Recently, with rapid growth of news media in the Internet, it presents both challenges and opportunities. One challenge lies in how to automatically extract a small group of company-specific keyphrases from news media that can accurately describe a company. Company-specific keyphrase extraction is an ef cient way to mine information from the news article. There are mainly two kinds of approaches for keyphrase extraction: supervised and the unsupervised. In this paper, we propose entity-rank, a novel unsupervised model which is based PageRank and integrate it with the specific company entity information. The experiment result shows that our model has an improvement compared with several other baseline models.", "num_citations": "1\n", "authors": ["430"]}
{"title": "A comprehensive study of blind and non-blind deconvolution methods applied to spectrum extraction\n", "abstract": " Spectrum extraction which is applied to extract one-dimensional (1D) astronomical spectroscopy from two-dimensional (2D) multi-fiber spectrum images plays a key role in data processing of 2D optical fiber spectrum. In this paper, we have given a detailed comparison of spectrum extraction methods between the blind deconvolution and the non-blind deconvolution to find out their specialities. The simulated arc spectrum data is used in Comparative experiments. The results show that the blind deconvolution is better than the non-blind deconvolution not only at spectrum extraction result but also remarkably at signal noise ratio (SNR).", "num_citations": "1\n", "authors": ["430"]}
{"title": "Collaborative response content recommendation for customer service agents\n", "abstract": " The rapid development of artificial intelligence (AI) has motivated extensive research on dialog system. Using dialog system to automatize customer service is a common practice in many business fields. In this paper, we investigate a novel task to recommend response for customer service agents of each shop. A major challenge is the problem of data insufficiency for each shop. Meanwhile, we want to keep the personalized information for shops with very different commodities. To deal with such problems, we propose a LSTM (Long Short-Term Memory) Neuron Tensor Network architecture to encode the common features of all shops\u2019 data and model the personalized features of each shop. Extensive experiments demonstrate that our method outperforms four baseline methods evaluated by recall metric.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Two-dimensional spectral image calibration based on feed-forward neural network\n", "abstract": " In this paper, we present a novel method on image calibration, utilizing Total Least Square (TLS) method and Feedforward Neural Network, to solve the aberration problem of LAMOST two-dimensional astronomical spectral images. In our method, training sample set is generated with domain knowledge, from which a number of discrete points are are extracted from spectral images with fiber tracing method, and output vectors are formed by the corresponding calibrated points, obtained by utilizing the TLS method. The Feed-forward Neural Network is trained to obtain the transformation matrix, casting about for the matching relationship between the input and output sets. We also perform comparative experiments on fiber tracing and spectrum extraction results between calibrated spectral images and uncalibrated spectral images, the results show an advantage of higher accuracy and precision by our proposed method.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Image representation via sub-dictionary based sparse coding\n", "abstract": " In this paper, a sub-dictionary based sparse coding method is proposed for image representation. The novel sparse coding method substitutes a new regularization item for L1-norm in the sparse representation model. The proposed sparse coding method involves a series of sub-dictionaries. Each sub-dictionary contains all the training samples except for those from one particular category. For the test sample to be represented, all the sub-dictionaries should linearly represent it apart from the one that does not contain samples from that label, and this sub-dictionary is called irrelevant sub-dictionary. This new regularization item restricts the sparsity of each sub-dictionary's residual, and this restriction is helpful for classification. The experimental results demonstrate that the proposed method is superior to the previous related sparse representation based classification.", "num_citations": "1\n", "authors": ["430"]}
{"title": "A fast ray tracing algorithm based on a hybrid structure\n", "abstract": " This paper proposes a new group-based accelerating structure called hybrid structure for the ray tracing of dynamic scenes, whose main advantage is that we can choose a suitable local accelerating structure for each object in the scene. In the hybrid structure, the objects in the scene are organized into a hierarchical bounding volume structure by surface area heuristic (SAH) cost model with each object group node including only one object, and a local accelerating structure is constructed for each object. For a hybrid structure, a scene is divided into static part and dynamic part by the movement, and only dynamic part is updated in each frame. In addition, we design an efficient storage format according to the graphics processing unit (GPU) storage characteristics, which makes it easy to realize the parallel ray tracing on GPU. Experimental results show that the hybrid structure is efficient to deal with the\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "A hybrid image feature descriptor for classification\n", "abstract": " Feature extraction methods have an important role in image classification. In this paper, a hybrid texture feature descriptor is proposed by utilizing the attributes of two complementary features, PRICoLBP and LPQ. PRICoLBP performs well in the case of geometric and photometric variations however it does not properly express the local texture of an image, while LPQ method performs well for the local structure of an image. We propose to use the hybrid scheme by combining the properties of PRICoLBP and LPQ and name it as Pair wise Rotation Invariant Co-occurrence Local Phase Quantization (PRICLPQ). Standard texture and material datasets have been used to verify the robustness of proposed hybrid scheme. The experiments show that the proposed hybrid scheme outperforms the state-of-the-art feature extraction methods like LBP, LPQ, CLBP, LBPV, SIFT, MSLBP, Lazebnik and PRICoLBP in term of accuracy.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Neural networks with marginalized corrupted hidden layer\n", "abstract": " Overfitting is an important problem in neural networks (NNs) training. When the number of samples in the training set is limited, explicitly extending the training set with artificially generated samples is an effective solution. However, this method has the problem of high computational costs. In this paper we propose a new learning scheme to train single-hidden layer feedforward neural networks (SLFNs) with implicitly extended training set. The training set is extended by corrupting the hidden layer outputs of training samples with noise from exponential family distribution. When the number of corruption approaches infinity, in objective function explicitly generated samples can be expressed as the form of expectation. Our method, called marginalized corrupted hidden layer (MCHL), trains SLFNs by minimizing the loss function expected values under the corrupting distribution. In this way MCHL is trained with\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "Erratum to: Image Fusion by Hierarchical Joint Sparse Representation\n", "abstract": " Erratum to: Image Fusion by Hierarchical Joint Sparse Representation Page 1 ERRATUM Erratum to: Image Fusion by Hierarchical Joint Sparse Representation Yao Yao1 \u2022 Ping Guo1 \u2022 Xin Xin1 \u2022 Ziheng Jiang1 Published online: 20 May 2015 \u00a9 Springer Science+Business Media New York 2015 Erratum to: Cogn Comput (2014) 6:281\u2013292 DOI 10.1007/s12559-013-9235-y Unfortunately, the corresponding author information was incorrect in the original publication of this article. The correct information is given below. Dr. Xin Xin is the main corresponding author and Dr. P. Guo is the co-corresponding author. The online version of the original article can be found under doi:10.1007/s12559-013-9235-y. & Ping Guo pguo@ieee.org & Xin Xin xxin@bit.edu.cn Yao Yao bityaoyao@bit.edu.cn Ziheng Jiang jiangziheng@bit.edu.cn 1 School of Computer Science and Technology, Beijing Institute of Technology, Beijing , 123 (:\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "Regularized covariance matrix estimation based on MDL principle\n", "abstract": " When Gaussian Mixture Model (GMM) is used for classification for small sample problem with high dimension, the estimation of the sample covariance matrix will be singular, which can lead to lower classification accuracy or can not achieve credible results. KLIM is a regularization method proposed for solving the problem. However, the regularization parameter in the KLIM is single and fixed which makes it suitable for a certain class of problems. In this chapter, under the framework of minimum description length (MDL) principle, the extensions of KLIM are investigated. One is the covariance matrix estimation with multi-regularization parameters, and the other is the covariance matrix estimation with variable regularization parameters. In the developed methods, based on MDL principle, regularization parameters are selected by the criterion of minimization the KL divergence and approximated efficiently by second\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "Balance function analysis in variable weight decision making\n", "abstract": " In this paper, we introduce two concepts, penalty capability and reward capability of decomposable balance function, discuss some properties of two kinds of balance function including summing and multiplying decomposable balance function invariable weight decision making, and investigate the influence of the balance function for the measure of orness for the variable weight vector. These results will beapplied in decision making and support system.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Rendering scenes with participating media based on RBFs for photon mapping using graphics hardware\n", "abstract": " The photon mapping is one of the more widely used algorithms for rendering scenes with participating media. Currently, it suffers from two main problems: one is how to improve the rendering efficiency, and another is how to reduce large memory requirement to store the photons. In this paper, we propose a hardware-accelerated algorithm that is based on radial basis function model for rendering participating media with multiple scattering. The radial basis function model is used to describe the photon distribution in participating media, and the main purpose is to provide high reconstruction quality using a relatively low number of basis function terms. Consequently, it can result in faster rendering. The radiance estimation is designed according to the radial basis function model. The implementation demonstrates that proposed method is the attractive low memory representation and it is capable of fully simulating the\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "Kernel based weighted group sparse representation classifier\n", "abstract": " Sparse representation classification (SRC) is a new framework for classification and has been successfully applied to face recognition. However, SRC can not well classify the data when they are in the overlap feature space. In addition, SRC treats different samples equally and ignores the cooperation among samples belong to the same class. In this paper, a kernel based weighted group sparse classifier (KWGSC) is proposed. Kernel trick is not only used for mapping the original feature space into a high dimensional feature space, but also as a measure to select members of each group. The weight reflects the importance degree of training samples in different group. Substantial experiments on benchmark databases have been conducted to investigate the performance of proposed method in image classification. The experimental results demonstrate that the proposed KWGSC approach has a higher\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "Statistical image upsampling method based on CUDA\n", "abstract": " In many application fields, an appropriate high-quality fast image upsampling method is required. Although many interpolation-based upsampling methods have been proposed, the quality of result images is not satisfactory. Some of them are very fast, but produce poor quality images, the others can produce high quality images, but the methods in them are slow. In our paper, we proposed a fast statistical image upsampling method based on CUDA, it can obtain high quality images based on reducing the input resolution-grids dependency artifacts. Thus, we can rebuild low resolution images' sharp edges fast and get high-quality upsampled images in real time. We have applied this method in the multi-resolution texture generation of large scale terrain rendering. Experiments prove that our method can receive ideal effects in real time.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Image Completion with Automatic Structure Propagation\n", "abstract": " In this paper, we propose a novel approach for image completion with automatic structure propagation. This method integrates two stages: Firstly, it extends the salient structure lines from the known regions to the unknown by following a local self-similarity assumption on natural images. Then guided by the structure information, it restores the missing region by patch-based texture synthesis. Experiment results demonstrate a better effect of our method than that of the previous patch-based texture synthesis image completion algorithm.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Fast Multiple Scattering in Participating Media with Beamlet Decomposition\n", "abstract": " We propose a fast algorithm which is based on the beam let decomposition for real-time rendering of scenes in participating media with multiple scattering. Firstly, the light source radiation is considered as composed by all particles in the media and each particle radiation is decomposed along different forward directions using the plane decomposition method. Then the multiple scattering radiation of one particle is calculated by the decomposition radiations from its adjacent particles and the light source. Finally, according to the multiple scattering radiation value of each particle, the radiation of the ray which is from viewpoint is calculated using ray marching method, which can be implemented on the graphics processing unit (GPU), and rendering process is highly parallel. The experimental results show that the algorithm can achieve real-time rendering efficiency and enhance the practicality of multiple scattering.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Learning multiple pooling combination for image classification\n", "abstract": " Recently sparse coding with spatial pyramid matching method has shown its excellent performance in image classification. Inspired by this technique, we present an image classification approach by learning the optimal Multiple Pooling Combination strategy based on Non-Negative Sparse Coding (MPC-NNSC) in this paper. First, non-negative sparse coding with three different pooling methods as well as spatial pyramid matching method are utilized to encode local descriptors for image representation, respectively. Then a promising weight learning approach is employed to find a set of optimal weights for best fusing all these pooling methods in different scales. Lastly, support vector machine classifier with linear and histogram intersection kernel is employed for the final classification task. Experiments on two popular benchmark datasets are presented and they demonstrate the better performance of the proposed\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "Multi-regularization Parameters Estimation for Gaussian Mixture Classifier based on MDL Principle.\n", "abstract": " Regularization is a solution to solve the problem of unstable estimation of covariance matrix with a small sample set in Gaussian classifier. And multi-regularization parameters estimation is more difficult than single parameter estimation. In this paper, KLIM_L covariance matrix estimation is derived theoretically based on MDL (minimum description length) principle for the small sample problem with high dimension. KLIM_L is a generalization of KLIM (Kullback-Leibler information measure) which considers the local difference in each dimension. Under the framework of MDL principle, multi-regularization parameters are selected by the criterion of minimization the KL divergence and estimated simply and directly by point estimation which is approximated by two-order Taylor expansion. It costs less computation time to estimate the multi-regularization parameters in KLIM_L than in RDA (regularized discriminant analysis) and in LOOC (leave-one-out covariance matrix estimate) where cross validation technique is adopted. And higher classification accuracy is achieved by the proposed KLIM_L estimator in experiment.", "num_citations": "1\n", "authors": ["430"]}
{"title": "A study of block-global feature based supervised image annotation\n", "abstract": " In order to get better semantic annotation performance, block-global features are extracted as low-level visual features for image semantic annotation. Specifically, wellknown global feature extraction method, namely two-dimensional principal component analysis (2DPCA) is applied to extract the image block-global features. Unlike typical image annotation methods which use local features or global features separately, we propose to extract global features from image local regions (block) with the expectation of: a) combining the advantages of local and global features; b) discovering multiple semantic meanings in one image. In the experiment, comparative studies have been done for the performance of block-global feature extraction methods with widely used local feature extraction method such as scale invariant feature transform. The results show that 2DPCA has a significantly better performance than the\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "Remote sensing image fusion based on multi-objective evolutionary algorithm\n", "abstract": " The purpose of fusion the multispectral (MS) and panchromatic (PAN) remote sensing images is to obtain high spatial resolution and quality of the PAN image as well as to preserve spectral information of the MS image. The parameter selection of fusion rule will directly affect the fusion result. In this paper, a new fusion method is presented based on multi-objective evolutionary algorithm (called SMS-EMOA). First, the MS image is converted from the RGB color space into the HSI (Hue-Saturation-Intensity) color space. Then, by applying Contourlet transform to the PAN image and the Intensity component of the MS image, the weighted model is used to fuse the sub-images, and the SMS-EMOA is adopted for optimal parameter selection. Finally, a fusion image is obtained by the inverse Contourlet and HSI transform. The experimental results show that the proposed fusion rule optimization method not only can gain the\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "Kernel ICA applied to feature extraction for image annotation\n", "abstract": " In automatic image annotation, it is often extracting low-level visual features from original image for the purpose of mapping to high level image semantic information. In this paper, we propose a novel method which integrates kernel independent component analysis (KICA) and support vector machine (SVM) for analyzing the semantic information of natural images. KICA, which contains a nonlinear kernel mapping component, is adopted to extract low-level features from the original image data. Then these feature vectors are mapped to high-level semantic words using SVM to annotate images with labels in a given semantic label set. Comparative studies have done for the performance of KICA with traditional color histogram and discrete cosine transform features. The experimental results show that the proposed method is capable of extracting the components of images as key features, and with these features to\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "A batch constructing method of weighted concept lattice based on deviance analysis\n", "abstract": " Concept lattice is an effective formal tool for data expression and knowledge acquisition. Weighted concept lattice (WCL) is a structure of concept lattice which depicts the importance of intents. A batch constructing method of weighted concept lattice based on deviance analysis is presented in this paper. The importance deviance value among the multi-attribute intent is computed by the standard deviation. According to the importance threshold and importance deviance threshold of the intent which are given by the user, strongly frequent weighted nodes and their edges are generated from bottom to top, so that the time and storage complexity of constructing weighted concept lattice is reduced, and the practicability and pertinence of concept lattice are improved. The experiment results validate the correctness and validity of the algorithm with the celestial spectrum data as the formal context.", "num_citations": "1\n", "authors": ["430"]}
{"title": "One-class SVM applied to identification of diffractive optical variable image\n", "abstract": " In this paper, we propose a method by engaging the one class support vector machine (OC-SVM) in the identification of diffractive optically variable images (DOVIs). OC-SVM, as a special SVM, can solve the problems of high-dimensional data sets and small sample size (SSS) with positive and negative unbalance training data. Image feature matrix is built by extracting image features from texture aspects. OC-SVM can be trained with the high-dimensional matrix directly, and does not have to reduce the dimensionality of feature matrix as the usual methods. The experiment results show the effectiveness of the proposed approach against linear discriminant analysis. Considering time cost and correct classification rate, OC-SVM is suitable for the identification of DOVIs.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Comparison of discriminant analysis methods applied to diffractive optically variable image\n", "abstract": " As a kind of powerful anti-counterfeiting device, diffractive optically variable image (DOVI) has been developed and widely used in information security field. However, the identification of DOVI today by bare eyes is not reliable. In this paper we investigate the recognition of DOVI with machine learning method, and five kinds of algorithms, namely quadratic discriminate analysis (QDA), linear discriminate analysis (LDA), regularized discriminate analysis (RDA), leave-one-out covariance matrix estimate (LOOC), and Kullback-Leibler information measure based method (KLIM) are applied to the recognition of DOVI. Considering both time cost and correct classification rate, KLIM classifier exceeds others.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Modeling multisource remote sensing image classifier based on the MDL principle: theoretical aspects\n", "abstract": " A theoretical study for modeling technique of the remote sensing image classification based on the minimum description length (MDL) principle is presented in the paper. According to the MDL principle, modeling problem is an optimization procedure to find the shortest expected code length. Kullback-Leibler (KL) divergence is adopted as the system cost function to measure expected codelength, and the codelength will be the model we desired. The advantage of using the MDL principle to build appropriate model is analyzed theoretically, model optimization technique also is described.", "num_citations": "1\n", "authors": ["430"]}
{"title": "An Improved Relaxation Algorithm for Image Matching\n", "abstract": " This paper presents an improved relaxation algorithm for image matching. The original relaxation algorithm includes two steps: rough matching and accurate matching. It usually is time-consuming for most practical problems. With the improved relaxation algorithm proposed in this paper, the number of matching points that take part in the next pass iteration can be reduced, consequently, the algorithm has the higher efficiency. An image stabilization system is taken as a platform to verify the algorithm. The experimental results demonstrate the significant improvement of the iteration speed.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Determination of 28 trace impurities in high purity tantalum oxide by inductively coupled plasma mass spectrometry [J]\n", "abstract": " An ICP-MS method is proposed for the determination of 28 trace impurity elements in high purity tantalum oxide. The mass spectral interference and interface effect were discussed. The matrix effect was suppressed by standard addition method. The detection limits for impurities are 0.001~ 0.1 \u03bcg/g, The recoveries of standard addition are 90%~ 115%. The method has been applied to the determination of trace impurities in high purity tantalum oxide with purity of 99.999%.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Application of optimized Elman neural network to network traffic prediction [J]\n", "abstract": " Quantum-behaved particle swarm optimization (QPSO) algorithm is researched and adaptive quantum-behaved particle swarm optimization (AQPSO) algorithm is proposed in order to improve networks\u2019 performance. By applying AQPSO algorithm to train the net parameters adopted in the Elman neural network, the generalization ability of the Elman neural network is improved. Ex-perimental results with network traffic time series data forecasting sets show that obtained network model has not only good generalization properties, but also has better stability. It illustrates that Elman net with AQPSO optimization algorithm has the promising application in network traffic time series data prediction.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Blind image restoration based on parzen-window estimate and regularization method\n", "abstract": " To investigate blind image restoration problem, we propose to combine Parzen-window estimate with regularization technique (PWERT) in this paper. Parzen-window estimate method is engaged to obtain point spread function. And regularization technique is utilized to control the noise deterioration and ill-posed case during image restoration. Experiment results show that PWERT is able to deblur degraded image effectively and is robust to noise.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Multi-source remote sensing classification based on Mallat fusion and residual error feature selection\n", "abstract": " Classification of multi-source remote sensing images has been studied for decades, and many methods have been proposed or improved. Most of these studies focus on how to improve the classifiers in order to obtain higher classification accuracy. However, as we know, even if the most promising method such as neural network, its performance not only depends on the classifier itself, but also has relation with the training pattern (ie features). On consideration of this aspect, we propose an approach to feature selection and classification of multi-source remote sensing images based on Mallat fusion and residual error in this paper. Firstly, the fusion of multi-source images can provide a fused image which is more preferable for classification. And then a feature-selection scheme approach based on fused image is proposed, which is to select effective subsets of features as inputs of a classifier by taking into account\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "Numerical simulation on fluid field in mold for slab casting\n", "abstract": " Fluid field in the mold for slab casting was simulated using k-\u03b5 combined equation model. A three dimensional software was used to solve the combined equations of the turbulent flow pulse dynamic energy k equation and the turbulent flow dynamic energy consumption rate \u03b5 equation under given numerical calculation conditions. Using this model, the influences of outlet area and the emerged depth of SEN, slab section dimensions on fluid flow in the mold can be studied. It can provide an assistance to the optimum designing on caster mold and SEN.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Experimental study of the addtion of MAC powders to the sintering ore [J]\n", "abstract": " The sintering experiment with certain proportion of MAC powders was conducted in order to reduce the production cost and conform the change of sintering raw material. The experimental results provide the advantageous reference for deciding the content of MAC powders in sintering process.", "num_citations": "1\n", "authors": ["430"]}
{"title": "\u57fa\u4e8e RBF \u7f51\u7edc\u56fe\u50cf\u8868\u793a\u7684 CT \u91cd\u5efa\u7b97\u6cd5\u7814\u7a76\n", "abstract": " \u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5f84\u5411\u57fa\u51fd\u6570(Radial Basis Function-RBF)\u795e\u7ecf\u7f51\u7edc\u56fe\u50cf\u8868\u793a\u5b9e\u73b0\u5bf9\u8ba1\u7b97\u673a\u65ad\u5c42\u6210\u50cf\u88c5\u7f6e\u4e0d\u5b8c\u5907\u6295\u5f71\u6570\u636e\u7684\u91cd\u5efa\u65b9\u6cd5,\u5e76\u5206\u6790\u4e86\u65b9\u6cd5\u7684\u8ba1\u7b97\u6548\u7387,\u91cd\u5efa\u8d28\u91cf\u548c\u9002\u7528\u8303\u56f4.\u8be5\u65b9\u6cd5\u91c7\u7528RBF\u795e\u7ecf\u7f51\u7edc\u8868\u793a\u65ad\u5c42\u56fe\u50cf,\u964d\u4f4e\u4e86\u95ee\u9898\u7684\u8ba1\u7b97\u89c4\u6a21,\u5e76\u901a\u8fc7ART(Algebraic Reconstruction Technique)\u8fed\u4ee3\u7b97\u6cd5\u91cd\u5efa\u51fa\u65ad\u5c42\u56fe\u50cf.\u5728\u6a21\u62df\u5b9e\u9a8c\u4e2d,\u6211\u4eec\u5c06\u672c\u65b9\u6cd5\u4e0eFBP,ART\u7684\u91cd\u5efa\u56fe\u50cf\u7b97\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83.\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5176\u91cd\u5efa\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u90fd\u6709\u660e\u663e\u5730\u6539\u8fdb.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Further Studies on the Vehicle Recognition Based on Fuzzy Theory\n", "abstract": " In this paper, we proposed an effective method to classify traffic vehicle based on fuzzy theory. Such method uses two-hierarchy synthesis evaluation model based on fuzzy clustering which can accurately reflect practical situations. It can not only reduce influences caused by subjective factors greatly, but also be performed in a highly efficient way, satisfied real-time requisition. The results of study show that it improves the rate of recognition and meanwhile has a well expandable capability", "num_citations": "1\n", "authors": ["430"]}
{"title": "Alignment of Shanghai Electron Beam Ion Trap facility\n", "abstract": " [en] A collimating telescope was used to make alignment of the Shanghai Electron Beam Ion Trap (EBIT) facility. To get precise result, high precision adjustments and special tools were designed and adopted. Several experiments have been made to test the reliability and precision of these adjustments and tools. After careful alignment, the EBIT can be operated stably with an electron beam of 100 kV/110 mA. It was shown that the method of alignment is successful.(authors)", "num_citations": "1\n", "authors": ["430"]}
{"title": "Comparative studies on the CT image reconstruction based on the RBF neural network\n", "abstract": " To reconstruct two-dimensional computerized tomography (CT) images from a small amount of projection data is a very difficult task. In this paper, two methods based on radial basis function (RBF) neural network are investigated to perform such a work. In the first method, we take projection data as the input and original image as the output of the network, after trained with some samples, the network can be applied to reconstruct CT image in the same class. In the second method, we adopt coordinate and a cross-section image as the input and the output respectively. For converting the image to its projections, an additional integral module is cascaded with the network. To evaluate these two methods, a comparative study is presented. A pixel-wise error estimator is adopted to calculate the overall error of the reconstructed images. Experiments show that the second method is the best for moderate projection data in\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}
{"title": "On the singular points of the Abelian integral transformation in the GPS/LEO occultation technique\n", "abstract": " In the inversion terrestrial atmosphere technique the inversion of theAbelian integral is one of the most often used methods for deriving the refractive index profile of the terrestrial atmosphere from GPS/LLEO radio occultation data. There exists the problem of singular point in the Abelian integral. Different methods for solving this problem are discussed and a method of finding an analytic solution of the Abelian integral after a variable transformation is proposed. The accuracies of the various methods are compared by means of simulation calculations.", "num_citations": "1\n", "authors": ["430"]}
{"title": "Identification of Defocus Blur Parameters and Restoration of Degraded Images\n", "abstract": " The problem of restoration of images blurred by uniform defocus is important in many applications. The solution proposed here identifies important parameters with which to characterize the point spread function (PSF) of the blur, given only the blurred image itself. We take advantage of the feature that there are a series of concentric circles in the Fourier spectrum domain of the defocused image, and the distance between two neighbor circles is in inverse proportion to the defocus radius R. In order to estimate the distance between circles, we use a coordinate transform to map the spectrum image into a new Cartesian coordinate system, in which the concentric circles turn out to be parallel lines. After detecting the distance between two neighbor lines, the blur parameter can be obtained according to the relationship of inverse proportion. When the PSF is estimated, a fast Kalman filter is adopted to restore the given\u00a0\u2026", "num_citations": "1\n", "authors": ["430"]}