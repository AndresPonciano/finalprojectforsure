{"title": "Method and system for analyzing advertisements delivered to a mobile unit\n", "abstract": " Accurate location information about a mobile telecommunication transceiver is used to generate advertising content responsive to a user approaching the location of a business. This advertising content is tailored to the user's preferences and the particular business involved. Once the advertising content is delivered, the position of the user is monitored to track the effectiveness of the advertisement. If the user enters the business' store and/or makes a purchase, the advertisement is logged as having been successful. If the user does not enter the store within a predetermined period of time or moves away from the store, the advertisement is considered to have been ineffective.", "num_citations": "880\n", "authors": ["1481"]}
{"title": "Method and system for connecting mobile users based on degree of separation\n", "abstract": " A method and system for selectively connecting proximately located telecommunications units are disclosed. The method and system may be used in a location aware telecommunications system that can determine the location of a telecommunications unit (TU) being used within the system. A first TU may be connected to a second TU when the first and second TUs are within a predetermined distance of each other and when a first user associated with the first TU may be connected to a second user associated with the second TU on a graph representing individual relationships, such as an acquaintance graph or genealogical tree. The connection may further be based on whether the first and second users have a less than a maximum threshold degree of separation within the relationship graph.", "num_citations": "584\n", "authors": ["1481"]}
{"title": "Method and system for selectively connecting mobile users based on physical proximity\n", "abstract": " A method and system for selectively connecting proximately located telecommunications units are disclosed. The method and system may be used in a location aware telecommunications system that can determine the location of a telecommunications unit (TU) being used within the system. Proximately located TUs within a predefined group may be connected when an initiating TU requests a group connection. A predetermined number of group TUs located within a predetermined distance of the initiating TU may be connected together with the initating TU in a single telecommunications connection.", "num_citations": "558\n", "authors": ["1481"]}
{"title": "Cyclic redundancy code (CRC) polynomial selection for embedded networks\n", "abstract": " Cyclic redundancy codes (CRCs) provide a first line of defense against data corruption in many networks. Unfortunately, many commonly used CRC polynomials provide significantly less error detection capability than they might. An exhaustive exploration reveals that most previously published CRC polynomials are either inferior to alternatives or are only good choices for particular message lengths. Unfortunately these shortcomings and limitations often seem to be overlooked. This paper describes a polynomial selection process for embedded network applications and proposes a set of good general-purpose polynomials. A set of 35 new polynomials in addition to 13 previously published polynomials provides good performance for 3- to 16-bit CRCs for data word lengths up to 2048 bits.", "num_citations": "487\n", "authors": ["1481"]}
{"title": "Challenges in autonomous vehicle testing and validation\n", "abstract": " Software testing is all too often simply a bug hunt rather than a well-considered exercise in ensuring quality. A more methodical approach than a simple cycle of system-level test-fail-patch-test will be required to deploy safe autonomous vehicles at scale. The ISO 26262 development V process sets up a framework that ties each type of testing to a corresponding design or requirement document, but presents challenges when adapted to deal with the sorts of novel testing problems that face autonomous vehicles. This paper identifies five major challenge areas in testing according to the V model for autonomous vehicles: driver out of the loop, complex requirements, non-deterministic algorithms, inductive learning algorithms, and fail-operational systems. General solution approaches that seem promising across these different challenge areas include: phased deployment using successively relaxed operational\u00a0\u2026", "num_citations": "424\n", "authors": ["1481"]}
{"title": "Autonomous vehicle safety: An interdisciplinary challenge\n", "abstract": " Ensuring the safety of fully autonomous vehicles requires a multi-disciplinary approach across all the levels of functional hierarchy, from hardware fault tolerance, to resilient machine learning, to cooperating with humans driving conventional vehicles, to validating systems for operation in highly unstructured environments, to appropriate regulatory approaches. Significant open technical challenges include validating inductive learning in the face of novel environmental inputs and achieving the very high levels of dependability required for full-scale fleet deployment. However, the biggest challenge may be in creating an end-to-end design and deployment process that integrates the safety concerns of a myriad of technical specialties into a unified approach.", "num_citations": "359\n", "authors": ["1481"]}
{"title": "Method and system for connecting proximately located mobile users based on compatible attributes\n", "abstract": " A method and system for connecting proximately located telecommunications units are disclosed. The method and system may be used in a location aware telecommunications system that can determine the location of a telecommunications unit (TU) being used within the system. A user may be connected to one or more other users when they have compatible attributes and when they are located within a predetermined distance of each other. The connection may be established between TUs of two or more users, based on attribute and distance information maintained by a server computer, upon the request of an initiating user's TU.", "num_citations": "316\n", "authors": ["1481"]}
{"title": "Automated robustness testing of off-the-shelf software components\n", "abstract": " Mission-critical system designers may have to use a commercial off-the-shelf (COTS) approach to reduce costs and shorten development time, even though COTS software components may not specifically be designed for robust operation. Automated testing can assess component robustness without sacrificing the advantages of a COTS approach. This paper describes the Ballista methodology for scalable, portable, automated robustness testing of component interfaces. An object-oriented approach based on parameter data types rather than component functionality essentially eliminates the need for function-specific test scaffolding. A full-scale implementation that automatically tests the robustness of 233 operating system software components has been ported to ten POSIX systems. Between 42% and 63% of components tested had robustness problems, with a normalized failure rate ranging from 10% to 23% of\u00a0\u2026", "num_citations": "303\n", "authors": ["1481"]}
{"title": "Pseudorandom number generation and cryptographic authentication\n", "abstract": " An automobile door lock receiver module (30) and a plurality of keychain fob transmitter units (16) contain identification numbers, secret initial values, and secret feedback masks so as to authenticate encrypted messages from any of the assigned fobs, indicative of commands registered by closing switches on the fob. Each fob is synchronized with the receiving module by means of a truly random number concatenated with a secret initial value and encrypted, through a linear feedback shift register or other operations. A second secret initial value is encrypted and command bits are exclusive ORed into the low order bit positions; the two encrypted numbers are concatenated and encrypted to form a key word which is transmitted with the fob ID. Synchronization includes decrypting to recover the truly random number and the secret initial value concatenated therewith; the truly random number is compared with\u00a0\u2026", "num_citations": "268\n", "authors": ["1481"]}
{"title": "32-bit cyclic redundancy codes for internet applications\n", "abstract": " Standardized 32-bit cyclic redundancy codes provide fewer bits of guaranteed error detection than they could, achieving a Hamming Distance (HD) of only 4 for maximum-length Ethernet messages, whereas HD=6 is possible. Although research has revealed improved codes, exploring the entire design space has previously been computationally intractable, even for special-purpose hardware. Moreover, no CRC polynomial has yet been found that satisfies an emerging need to attain both HD=6 for 12K bit messages and HD=4 for message lengths beyond 64 Kbits. This paper presents results from the first exhaustive search of the 32-bit CRC design space. Results from previous research are validated and extended to include identifying all polynomials achieving a better HD than the IEEE 802.3 CRC-32 polynomial. A new class of polynomials is identified that provides HD=6 up to nearly 16K bit and HD=4 up to\u00a0\u2026", "num_citations": "263\n", "authors": ["1481"]}
{"title": "Method and system for automatically initiating a telecommunications connection based on distance\n", "abstract": " A method and system for connecting proximately located telecommunications units are disclosed. The method and system may be used in a location aware telecommunications system that can determine the location of a telecommunications unit (TU) being used within the system. A user of a mobile telecommunications unit (MU) is connected to a TU when the MU is within a predetermined distance of a predetermined geographic location meeting predefined criteria. The TU to which the MU is connected may be automated or manually operated. In some embodiments, multiple MUs are connected when they are within a predetermined proximity to each other and a predefined criteria is met.", "num_citations": "242\n", "authors": ["1481"]}
{"title": "Stack Computers: the new wave\n", "abstract": " . abstract This book presents another view of the RISC versus CISC controversy, and if only for its commentary on that debate, it would be worthwhile. Yet it does considerably more. It provides key insights into how stack machines work and what their strengths and weaknesses are. It presents a taxonomy of existing serial processors and shows that for over 25 years the stack architecture has been subtly influencing both hardware and software, but that major computational gains have begun only in the past few years. Although stack processors are unlikely to dominate the much-publicized engineering workstation market, they may very well fill enormously larger niches in everything from consumer electronics to high-performance military avionics.\u2014From the Foreword The author of this book is very knowledgeable on stack computers. He was the chief architect for the two stack computers WISC CPU/16 and CPU/32\u00a0\u2026", "num_citations": "242\n", "authors": ["1481"]}
{"title": "Comparing the robustness of POSIX operating systems\n", "abstract": " Critical system designers are turning to off-the-shelf operating system (OS) software to reduce costs and time-to-marker. Unfortunately general-purpose OSes do not always respond to exceptional conditions robustly, either accepting exceptional values without complaint, or suffering abnormal task termination. Even though direct measurement is impractical, this paper uses a multiversion comparison technique to reveal a 6% to 19% normalized rate at which exceptional parameter values cause no error report in commercial POSIX OS implementations. Additionally, 168 functions across 13 OSes are compared to reveal common mode robustness failures. While the best single OS has a 12.6% robustness failure rare for system calls, 3.8% of failures are common across all 13 OSes examined. However, combining C library calls with system calls increases these rates to 29.5% for the best single OS and 17.0% for\u00a0\u2026", "num_citations": "234\n", "authors": ["1481"]}
{"title": "Comparing operating systems using robustness benchmarks\n", "abstract": " When creating mission-critical distributed systems using off-the-shelf components, it is important to assess the dependability of not only the hardware, but the software as well. This paper proposes a way to test operating system dependability. The concept of response regions is presented as a way to visualize erroneous system behavior and gain insight into failure mechanisms. A 5-point \"CRASH\" (catastrophic, restart, abort, silent, hindering) scale is defined for grading the severity of robustness vulnerabilities encountered. Test results from five operating systems are analyzed for robustness vulnerabilities, and exhibit a range of dependability. Robustness benchmarking comparisons of this type may provide important information to both users and designers of off-the-shelf software for dependable systems.", "num_citations": "225\n", "authors": ["1481"]}
{"title": "Embedded system security\n", "abstract": " From cars to cell phones, video equipment to MP3 players, and dishwashers to home thermostats - embedded computers increasingly permeate our lives. But security for these systems is an open question and could prove a more difficult long-term problem than security does today for desktop and enterprise computing. Security issues are nothing new for embedded systems. However, as more embedded systems are connected to the Internet, the potential damages from such vulnerabilities scale up dramatically. Internet connections expose applications to intrusions and malicious attacks. Unfortunately, security techniques developed for enterprise and desktop computing might not satisfy embedded application requirements.", "num_citations": "201\n", "authors": ["1481"]}
{"title": "Work-arounds, make-work, and kludges\n", "abstract": " Paradigms are often defined partly in terms of what they are not, or in terms of what they are reacting against. The paradigm of human-centered computing is no exception. We discuss about a user-hostile system. We decided that the terms kludge and work-around, and also the related concept of make-work, has yet to be clearly defined for the intelligent systems community. Human-centered systems are different from user-hostile systems as well as from systems based on a designer-centered approach. We try to clarify the senses of these three terms and suggest ways we might study work-around, make-work, and kludges as an integral part of human-computer systems-rather than as embarrassing necessities that are best swept under the computing research rug.", "num_citations": "201\n", "authors": ["1481"]}
{"title": "The exception handling effectiveness of POSIX operating systems\n", "abstract": " Operating systems form a foundation for robust application software, making it important to understand how effective they are at handling exceptional conditions. The Ballista testing system was used to characterize the handling of exceptional input parameter values for up to 233 POSIX functions and system calls on each of 15 widely used operating system (OS) implementations. This identified ways to crash systems with a single call, ways to cause task hangs within OS code, ways to cause abnormal task termination within OS and library code, failures to implement defined POSIX functionality, and failures to report unsuccessful operations. Overall, only 55 percent to 76 percent of the exceptional tests performed generated error codes, depending on the operating system being tested. Approximately 6 percent to 19 percent of tests failed to generate any indication of error despite exceptional inputs. Approximately 1\u00a0\u2026", "num_citations": "184\n", "authors": ["1481"]}
{"title": "Method of generating secret identification numbers\n", "abstract": " The present invention teaches a method of generating a secret identification number from a random digital data stream. The method comprises the step of initially selecting a first and a second group of bytes from the random digital data stream, wherein the first and second groups of bytes have a first and second numerical value. Subsequently, a first maximal length LFSR feedback term is looked up from a list in response to said first numerical value, while a second maximal length LFSR feedback term is looked up from the list in response to said second numerical value. The method additionally comprises the step of generating a cyclic redundancy code feedback term in response to executing a cyclic redundancy code check on a third group of bytes selected from the random digital data stream. Moreover, the method comprises the step of forming the secret identification number from the first and second maximal\u00a0\u2026", "num_citations": "180\n", "authors": ["1481"]}
{"title": "Embedded system design issues (the rest of the story)\n", "abstract": " Many embedded systems have substantially different design constraints than desktop computing applications. No single characterization applies to the diverse spectrum of embedded systems. However, some combination of cost pressure, long life-cycle, real-time requirements, reliability requirements, and design culture dysfunction can make it difficult to successfully apply traditional computer design methodologies and tools to embedded applications. Embedded systems in many cases must be optimized for life-cycle and business-driven factors rather than for maximum computing throughput. There is currently little tool support for expanding embedded computer design to the scope of holistic embedded system design. However, knowing the strengths and weaknesses of current approaches can set expectations appropriately, identify risk areas to tool adopters, and suggest ways in which tool builders can meet\u00a0\u2026", "num_citations": "171\n", "authors": ["1481"]}
{"title": "Software testing\n", "abstract": " Software testing is any activity aimed at evaluating an attribute or capability of a program or system and determining that it meets its required results.[Hetzel88] Although crucial to software quality and widely deployed by programmers and testers, software testing still remains an art, due to limited understanding of the principles of software. The difficulty in software testing stems from the complexity of software: we can not completely test a program with moderate complexity. Testing is more than just debugging. The purpose of testing can be quality assurance, verification and validation, or reliability estimation. Testing can be used as a generic metric as well. Correctness testing and reliability testing are two major areas of testing. Software testing is a trade-off between budget, time and quality.Contents:", "num_citations": "144\n", "authors": ["1481"]}
{"title": "Elements of the self-healing system problem space\n", "abstract": " One of the potential approaches to achieving dependable system operation is to incorporate so-called \u201cself-healing\u201d mechanisms into system architectures and implementations. A previous workshop on this topic exposed a wide diversity of researcher perspectives on what self-healing systems really are. This paper proposes a taxonomy for describing the problem space for self-healing systems including fault models, system responses, system completeness, and design context. It is hoped that this taxonomy will help researchers understand what aspects of the system dependability problem they are (and aren\u2019t) addressing with specific research projects.", "num_citations": "142\n", "authors": ["1481"]}
{"title": "Cryptographic authentication of transmitted messages using pseudorandom numbers\n", "abstract": " An automobile door lock receiver module (30) and a plurality of keychain fob transmitter units (16) contain identification numbers, secret initial values, and secret feedback masks so as to authenticate encrypted messages from any of the assigned fobs, indicative of commands registered by closing switches on the fob. Each fob is synchronized with the receiving module by means of a truly random number concatenated with a secret initial value and encrypted, through a linear feedback shift register or other operations. A second secret initial value is encrypted and command bits are exclusive ORed into the low order bit positions; the two encrypted numbers are concatenated and encrypted to form a key word which is transmitted with the fob ID. Synchronization includes decrypting to recover the truly random number and the secret initial value concatenated therewith; the truly random number is compared with\u00a0\u2026", "num_citations": "135\n", "authors": ["1481"]}
{"title": "Random number generating system and process based on chaos\n", "abstract": " The present invention teaches a method of generating a plurality of random numbers is disclosed. The method comprises the initial step of generating chaotic noise. Subsequently, the chaotic noise is sampled such that a plurality of samples are created. Each sample of the plurality of samples is then converted into digital data such that each converted sample corresponds with a random number of the plurality of random numbers.", "num_citations": "133\n", "authors": ["1481"]}
{"title": "The effectiveness of checksums for embedded control networks\n", "abstract": " Embedded control networks commonly use checksums to detect data transmission errors. However, design decisions about which checksum to use are difficult because of a lack of information about the relative effectiveness of available options. We study the error detection effectiveness of the following commonly used checksum computations: exclusive or (XOR), two's complement addition, one's complement addition, Fletcher checksum, Adler checksum, and cyclic redundancy codes (CRCs). A study of error detection capabilities for random independent bit errors and burst errors reveals that XOR, two's complement addition, and Adler checksums are suboptimal for typical network use. Instead, one's complement addition should be used for networks willing to sacrifice error detection effectiveness to reduce compute cost, Fletcher checksum for networks looking for a balance of error detection and compute cost, and\u00a0\u2026", "num_citations": "101\n", "authors": ["1481"]}
{"title": "Robustness testing of the Microsoft Win32 API\n", "abstract": " Although Microsoft Windows is being deployed in mission-critical applications, little quantitative data has been published about its robustness. We present the results of executing over two million Ballista-generated exception handling tests across 237 functions and system calls involving six Windows variants, as well as similar tests conducted on the Linux operating system. Windows 95, Windows 98 and Windows CE were found to be vulnerable to complete system crashes caused by very simple C programs for several different functions. No system crashes were observed on Windows NT, Windows 2000 or Linux. Linux was significantly more graceful at handling exceptions from system calls in a program-recoverable manner than Windows NT and Windows 2000, but those Windows variants were more robust than Linux (with glibc) at handling C library exceptions. While the choice of operating systems cannot be\u00a0\u2026", "num_citations": "91\n", "authors": ["1481"]}
{"title": "A framework for scalable analysis and design of system-wide graceful degradation in distributed embedded systems\n", "abstract": " We present a framework that will enable scalable analysis and design of graceful degradation in distributed embedded systems. We define graceful degradation in terms of utility. A system that gracefully degrades suffers a proportional loss of system utility as individual software and hardware components fail. However, explicitly designing a system to gracefully degrade; i.e. handle all possible combinations of component failures, becomes impractical for systems with more than a few components. We avoid this exponential complexity of component combinations by exploiting the structure of the system architecture to partition components into subsystems. We view each subsystem as a configuration of components that changes when components are removed or added. Thus, a subsystem's utility changes when components fail or are repaired. We then view the system as a composition of subsystems that each\u00a0\u2026", "num_citations": "87\n", "authors": ["1481"]}
{"title": "Method and apparatus for location-sensitive, subsidized cell phone billing\n", "abstract": " A method and system for determining a billing rate of a telecommunications connection is disclosed. The method and system may be used in a location aware telecommunications system that can determine the location of a telecommunications unit (TU) being used within the system. The geographic location of a mobile unit (MU) is determined, and compared to a list a predetermined subsidized zones. When the MU initiates or receives a call from within a subsidized zone, and the MU is otherwise responsible for paying a predetermined billing rate associated with the call, the predetermined rate is subsidized for at least the portion of the call made while the MU is located within the subsidized zone.", "num_citations": "84\n", "authors": ["1481"]}
{"title": "A case study of Toyota unintended acceleration and software safety\n", "abstract": " A Case Study of Toyota Unintended Acceleration and Software Safety Page 1 \u00a9 Copyright 2014, Philip Koopman. CC Attribution 4.0 International license. A Case Study of Toyota Unintended Acceleration and Software Safety 1 Prof. Phil Koopman September 18, 2014 Carnegie Mellon University koopman@cmu.edu betterembsw.blogspot.com http://creativecommons.org/licenses/by/4.0/legalcode Page 2 \u00a9 Copyright 2014, Philip Koopman. CC Attribution 4.0 International license. Overview \u2022 Brief history of Toyota UA events \u2022 Recalls, investigations, lawsuits \u2022 Fines & jury awards \u2013 $$Billions \u2022 Technical discussion of the problems \u2022 This is a Case Study \u2013 what can we learn? \u2022 What does this mean for future automobiles? \u2022 The bar is raised, at least for now \u2022 Eg, handling of GM ignition switch & Honda hybrid SW UA \u2022 I testified as a Plaintiff expert witness \u2022 I saw a whole lot of stuff, but not \u201csource code\u201d \u2022 I can only talk \u2026", "num_citations": "83\n", "authors": ["1481"]}
{"title": "How to write an abstract\n", "abstract": " Because on-line search databases typically contain only abstracts, it is vital to write a complete but concise description of your work to entice potential readers into obtaining a copy of the full paper. This article describes how to write a good computer architecture abstract for both conference and journal papers. Writers should follow a checklist consisting of: motivation, problem statement, approach, results, and conclusions. Following this checklist should increase the chance of people taking the time to obtain and read your complete paper.", "num_citations": "76\n", "authors": ["1481"]}
{"title": "Toward a framework for highly automated vehicle safety validation\n", "abstract": " Validating the safety of Highly Automated Vehicles (HAVs) is a significant autonomy challenge. HAV safety validation strategies based solely on brute force on-road testing campaigns are unlikely to be viable. While simulations and exercising edge case scenarios can help reduce validation cost, those techniques alone are unlikely to provide a sufficient level of assurance for full-scale deployment without adopting a more nuanced view of validation data collection and safety analysis. Validation approaches can be improved by using higher fidelity testing to explicitly validate the assumptions and simplifications of lower fidelity testing rather than just obtaining sampled replication of lower fidelity results. Disentangling multiple testing goals can help by separating validation processes for requirements, environmental model sufficiency, autonomy correctness, autonomy robustness, and test scenario sufficiency. For\u00a0\u2026", "num_citations": "71\n", "authors": ["1481"]}
{"title": "A product family approach to graceful degradation\n", "abstract": " Design of gracefully degrading systems, where functionality is gradually reduced in the face of faults, has traditionally been a very difficult and error prone task. General approaches to graceful degradation are typically limited to re-implementation of the system for a number of pre-designated fallback configurations. We describe an architecture-based approach to gracefully degrading systems based upon Product Family Architectures (PFAs) combined with automatic reconfiguration.", "num_citations": "70\n", "authors": ["1481"]}
{"title": "A case study on runtime monitoring of an autonomous research vehicle (ARV) system\n", "abstract": " Runtime monitoring is a versatile technique for detecting property violations in safety-critical (SC) systems. Although instrumentation of the system under monitoring is a common approach for obtaining the events relevant for checking the desired properties, the current trend of using black-box commercial-off-the-shelf components in SC system development makes these systems unamenable to instrumentation. In this paper we develop an online runtime monitoring approach targeting an autonomous research vehicle (ARV) system and recount our experience with it. To avoid instrumentation we passively monitor the target system by generating atomic propositions from the observed network state. We then develop an efficient runtime monitoring algorithm, EgMon, that eagerly checks for violations of desired properties written in future-bounded, propositional metric temporal logic. We show the efficacy of\u00a0\u2026", "num_citations": "58\n", "authors": ["1481"]}
{"title": "Random clock composition-based cryptographic authentication process and locking system\n", "abstract": " The first and second devices exchange randomly generated messages that are used in a composition-based encryption/decryption process. At least one of the randomly generated messages is, itself, encrypted before transmission. The composition-based process (a cyclic redundancy code process, preferably enhanced with midcycle non-Galois Field operation) is embedded in both devices and not readily discernable by playback attack.", "num_citations": "58\n", "authors": ["1481"]}
{"title": "Efficient high hamming distance CRCs for embedded networks\n", "abstract": " Cyclic redundancy codes (CRCs) are widely used in network transmission and data storage applications because they provide better error detection than lighter weight checksum techniques. 24- and 32-bit CRC computations are becoming necessary to provide sufficient error detection capability (Hamming distance) for critical embedded network applications. However, the computational cost of such CRCs can be too high for resource-constrained embedded systems, which are predominantly equipped with 8-bit microcontrollers that have limited computing power and small memory size. We evaluate the options for speeding up CRC computations on 8-bit processors, including comparing variants of table lookup approaches for memory cost and speed. We also evaluate classes of CRC generator polynomials which have the same computational cost as 24- or 16-bit CRCs, but provide 32-bit CRC levels of error\u00a0\u2026", "num_citations": "57\n", "authors": ["1481"]}
{"title": "Stack-memory-based writable instruction set computer having a single data bus\n", "abstract": " A computer is provided as an add-on processor for attachment to a host computer. Included are a single data bus, a 32-bit arithmetic logic unit, a data stack, a return stack, a main program memory, data registers, program memory addressing logic, micro-program memory, and a micro-instruction register. Each machine instruction contains an opcode as well as a next address field and subroutine call/return or unconditional branching information. The return address stack, memory addressing logic, program memory, and microcoded control logic are separated from the data bus to provide simultaneous data operations with program control flow processing and instruction fetching and decoding. Subroutine calls, subroutine returns, and unconditional branches are processed with a zero execution time cost. Program memory may be written as either bytes or full words without read/modify/write operations. The top of data\u00a0\u2026", "num_citations": "57\n", "authors": ["1481"]}
{"title": "Flexible multicast authentication for time-triggered embedded control network applications\n", "abstract": " Security for wired embedded networks is becoming a greater concern as connectivity to the outside world increases. Protocols used in these networks omit support for authenticating messages to prevent masquerade and replay attacks. The unique constraints of embedded control systems make incorporating existing multicast authentication schemes impractical. Our approach provides multicast authentication for time-triggered applications by validating truncated message authentication codes (MACs) across multiple packets. We extend this approach to tolerate occasional invalid MACs, analyze our approach through simulated attacks, and give an upper bound on the probability of successful attack. This approach allows a tradeoff among per-packet authentication cost, application level latency, tolerance to invalid MACs, and probability of induced failure, while satisfying typical embedded system constraints.", "num_citations": "56\n", "authors": ["1481"]}
{"title": "Critical embedded automotive networks\n", "abstract": " Designing automotive computer systems is a very challenging task, involving stringent cost requirements along with a need for highly reliable operation in adverse environments. Nonetheless, electronic and computer-based features are proliferating in vehicles, leading to widespread use of embedded real-time control networks [Leen02]. In the next few years, networked vehicle control will reach a level of sophistication that requires giving up mechanical linkages between the driver and the vehicle in exchange for additional performance and safety features. In such vehicles, networked computers will control vehicle operation just as they do today in fly-by-wire aircraft designs.A move to vehicles that have throttle-by-wire, brake-by-wire, and steer-by-wire control systems (generically called X-by-wire) is already in progress and seems likely to be completed within this decade. Among the benefits anticipated are better fuel economy, better vehicle performance in difficult driving conditions, and advanced safety features such as collision warning and even automatic collision avoidance systems [Bretz01]. Among the biggest questions remaining is which communication protocol to use for determining the timing and content of messages to be sent on wires (or optical fibers) that will be entrusted with safety-critical vehicle operations.", "num_citations": "56\n", "authors": ["1481"]}
{"title": "Robustness testing and hardening of CORBA ORB implementations\n", "abstract": " Before using CORBA (Common Object Request Broker Architecture) applications in mission-critical scenarios, it is important to understand the robustness of the Object Request Broker (ORB) being used, which forms the platform for CORBA applications. We have extended the Ballista software testing technique to test the exception-handling robustness of C++ ORB client-side application interfaces, and have tested two major versions of three ORB implementations on two operating systems, yielding robustness failure rates ranging from 26% to 42%. To improve ORB robustness, we also propose a probing method to harden object and pseudo-object related data types against exceptional inputs. Using these probes on omniORB 2.8 has proven to be effective in eliminating some cases of robustness failures found during testing. These results suggest that CORBA implementations currently have significant robustness\u00a0\u2026", "num_citations": "56\n", "authors": ["1481"]}
{"title": "Multi-bit error vulnerabilities in the controller area network protocol\n", "abstract": " Embedded networks will increasingly be used in safety-critical applications such as drive-by-wire automobiles. Because of potentially high network noise in such systems, reliably detecting bit errors could become vital to preventing the dissemination of corrupted data. Unfortunately, an interaction between bit stuffing and use of a cyclic redundancy code (CRC) can create a vulnerability to undetected multi-bit errors. Simulations of the widely used Controller Area Network (CAN) protocol indicate that this problem can cause a double-bit error to result in a 1.3 x 10-7 probability of undetected corruption. This number, although small, becomes an issue when magnified by a fleet size of hundreds of millions of vehicles. This vulnerability and related CAN specification problems can be fixed, albeit at a cost. A generalized lesson is that transmission encoding can undermine the effectiveness of error detection codes to the point that a system might not provide a required level of robustness.", "num_citations": "54\n", "authors": ["1481"]}
{"title": "Low cost multicast authentication via validity voting in time-triggered embedded control networks\n", "abstract": " Wired embedded networks must include multicast authentication to prevent masquerade attacks within the network. However, unique constraints for these networks make most existing multicast authentication techniques impractical. Our previous work provides multicast authentication for time-triggered applications on embedded networks by validating truncated message authentication codes across multiple packets. In this work, we improve overall bandwidth efficiency and reduce authentication latency by using unanimous voting on message value and validity amongst a group of nodes. This technique decreases the probability of successful per-packet forgery by using one extra bit per additional voter, regardless of the number of total receivers. This can permit using fewer authentication bits per receiver. We derive an upper bound on the probability of successful forgery and experimentally verify it using simulated\u00a0\u2026", "num_citations": "53\n", "authors": ["1481"]}
{"title": "Coverage and the use of cyclic redundancy codes in ultra-dependable systems\n", "abstract": " A cyclic redundancy code (CRC), when used properly, can be an effective and relatively inexpensive method to detect data corruption across communication channels. However, some systems use CRCs in ways that violate common assumptions made in analyzing CRC effectiveness, resulting in an overly optimistic prediction of system dependability. CRCs detect errors with some finite probability, which depends on factors including the strength of the particular code used, the bit-error rate, and the message length being checked. Common assumptions also include a passive network inter-stage, explicit data words, memoryless channels, and random independent symbol errors. In this paper we identify some examples of CRC usage that compromise ultra-dependable system design goals, and recommend alternate ways to improve system dependability via architectural approaches rather than error detection\u00a0\u2026", "num_citations": "53\n", "authors": ["1481"]}
{"title": "How many operational design domains, objects, and events?\n", "abstract": " A first step toward validating an autonomous vehicle is deciding what aspects of the system need to be validated. This paper lists factors we have found to be relevant in the areas of operational design domain, object and event detection and response, vehicle maneuvers, and fault management. While any such list is unlikely to be complete, our contribution can form a starting point for a publicly available master list of considerations to ensure that autonomous vehicle validation efforts do not contain crucial gaps due to missing known issues.", "num_citations": "51\n", "authors": ["1481"]}
{"title": "Better embedded system software\n", "abstract": " Better Embedded System Software Page 1 Better Embedded System Software Philip Koopman & Electrical Computer ENGINEERING Page 2 2 Empirical Approach To Content \u25c6 Based on 90+ industry design reviews \u2022 Real companies, products, problems \u2022 Some reviews were to save failing projects \u2022 Other reviews were to check up on otherwise good projects \u25c6 Professional book for practicing embedded system designers \u2022 Dug out the \u201cred flag\u201d issues from the review reports \u2022 Sorted, aggregated, sifted \u2022 6 areas; 29 topics within those areas \u2022 Each chapter is 8-15 pages about a red flag topic \u2022 This is the stuff designers get wrong in real projects \u25c6 Also see my blog at: http://betterembsw.blogspot.com/ Page 3 3 Software Development Process (Numbers are chapter numbers: 2-29) 2. No Written Development Plan \u2022 And, often, no defined methodical development process 3. Insufficient paper trail \u2022 Things other than \u2026", "num_citations": "50\n", "authors": ["1481"]}
{"title": "Monitor based oracles for cyber-physical system testing: Practical experience report\n", "abstract": " Testing Cyber-Physical Systems is becoming increasingly challenging as they incorporate advanced autonomy features. We investigate using an external runtime monitor as a partial test oracle to detect violations of critical system behavioral requirements on an automotive development platform. Despite limited source code access and using only existing network messages, we were able to monitor a hardware-in-the-loop vehicle simulator and analyze prototype vehicle log data to detect violations of high-level critical properties. Interface robustness testing was useful to further exercise the monitors. Beyond demonstrating feasibility, the experience emphasized a number of remaining research challenges, including: approximating system intent based on limited system state observability, how to best balance the simplicity and expressiveness of the specification language used to define monitored properties, how to\u00a0\u2026", "num_citations": "48\n", "authors": ["1481"]}
{"title": "A safety standard approach for fully autonomous vehicles\n", "abstract": " Assuring the safety of self-driving cars and other fully autonomous vehicles presents significant challenges to traditional software safety standards both in terms of content and approach. We propose a safety standard approach for fully autonomous vehicles based on setting scope requirements for an overarching safety case. A viable approach requires feedback paths to ensure that both the safety case and the standard itself co-evolve with the technology and accumulated experience. An external assessment process must be part of this approach to ensure lessons learned are captured, as well as to ensure transparency. This approach forms the underlying basis for the UL 4600 initial draft standard.", "num_citations": "47\n", "authors": ["1481"]}
{"title": "Communication protocols for embedded systems\n", "abstract": " In this article, we will first discuss the special considerations for networking real-time embedded systems. Then, we describe several media access protocols that demonstrate fundamentally different ways of accessing the shared medium. The protocols we discuss are: Connection Oriented Protocols, Polling, Time Division Multiple Access (TDMA), Token Ring, Token Bus, Binary Countdown, Carrier Sense Multiple Access with Collision Detection (CSMA/CD), and Carrier Sense Multiple Access with Collision Avoidance (CSMA/CA). For each of these protocols, we will evaluate the strengths and weaknesses against the special considerations. We conclude the article by presenting a protocol tradeoff chart which will enable you the select a protocol to fit your needs. While no protocol is perfect for all purposes, we think that a variation of CSMA/CA offers the most versatility for many embedded systems.", "num_citations": "47\n", "authors": ["1481"]}
{"title": "A philosophy for developing trust in self-driving cars\n", "abstract": " For decades, our lives have depended on the safe operation of automated mechanisms around and inside us. The autonomy and complexity of these mechanisms is increasing dramatically. Autonomous systems such as self-driving cars rely heavily on inductive inference and complex software, both of which confound traditional software-safety techniques that are focused on amassing sufficient confirmatory evidence to support safety claims. In this paper we survey existing methods and tools that, taken together, can enable a new and more productive philosophy for software safety that is based on Karl Popper\u2019s idea of falsificationism.", "num_citations": "43\n", "authors": ["1481"]}
{"title": "A taxonomy of decomposition strategies based on structures, behaviors, and goals\n", "abstract": " Designs are often decomposed into subdesigns in a divide-and-conquer approach to dealing with complexity. A wide variety of strategies are in common use for accomplishing decomposition. This paper describes a taxonomy of decomposition strategies based on the design attributes of structures, behaviors, and goals as an aid to understanding when each different strategy may be appropriate. The taxonomy is descriptive rather than prescriptive; it concentrates on providing a common ground for representing both business-driven and technically-driven design decisions. An example is presented that suggests hierarchically layering diverse decomposition strategies can accommodate diverse designs and design processes.", "num_citations": "43\n", "authors": ["1481"]}
{"title": "A flexible approach to embedded network multicast authentication\n", "abstract": " Distributed embedded systems are becoming increasingly vulnerable to attack as they are connected to external networks. Unfortunately, they often have no built-in authentication capability. Multicast authentication mechanisms required to secure embedded networks must function within the unique constraints of these systems, making it difficult to apply previously proposed schemes. We propose an authentication approach using message authentication codes which exploits the time-triggered nature of many embedded systems by putting only a few authentication code bits in each message, and by requiring authentication to be confirmed by the correct reception of multiple messages. This approach can work for both state transition commands and reactive control messages, and enables a tradeoff among per-message authentication cost, application-level latency, and the probability of induced system failure. Authentication parameters can be tuned on a per-message basis while satisfying typical wired embedded network constraints.", "num_citations": "41\n", "authors": ["1481"]}
{"title": "Vehicle security system with combined key fob and keypad anti-driveaway protection\n", "abstract": " A vehicle security system combines anti-driveaway protection with vehicle entry signalling. Either a remote signalling device is used to generate a remote signal or an input device, mounted on the vehicle, is used to generate an access signal. An entry control unit receives and interprets the remote signal or the access signal and unlocks the vehicle doors when appropriate. At the same time, the entry control unit communicates with an engine controller that an appropriate signal has been received. In response, the engine controller enables the vehicle engine to be started so that the vehicle can be driven in a conventional manner.", "num_citations": "40\n", "authors": ["1481"]}
{"title": "Robust software-no more excuses\n", "abstract": " Software developers identify two main reasons why software systems are not made robust: performance and practicality. We demonstrate the effectiveness of general techniques to improve robustness that are practical and yield high performance. We present data from treating three systems to improve robustness by a factor of 5 or more, with a measured performance penalty of under 5% in nearly every case, and usually under 2%. We identify a third possible reason why software systems are not made robust: developer awareness. A case study on three professional development groups evaluated their ability to estimate the robustness of their software. Two groups were able to estimate their software's robustness to some extent, while one group had more divergent results. Although we can overcome the technical challenges, it appears that even experienced developers can benefit from tools to locate robustness\u00a0\u2026", "num_citations": "39\n", "authors": ["1481"]}
{"title": "A preliminary exploration of optimized stack code generation\n", "abstract": " This paper presents an experimental code generator that performs intra-block stack scheduling for a stack-based execution model.  For small test programs, 91% to 100% of redundant local variable accesses were eliminated using this compiler.  Compiled intra-block stack scheduling and hand-performed global stack scheduling show that significant opportunities exist to keep temporary variable values on the expression evaluation stack when compiling conventional languages.", "num_citations": "38\n", "authors": ["1481"]}
{"title": "Interface robustness testing: Experience and lessons learned from the ballista project\n", "abstract": " When the Ballista project started in 1996 as a 3-year DARPA-funded research project, the original goal was to create a Web-based testing service to identify robustness faults in software running on client computers via the Internet. Previous experience suggested that such tests would \ufb01nd interesting problems but it was unclear how to make robustness test\u2014ing scalable to large interfaces. A major challenge was \ufb01nding a way to test something as large and complex as an operating system (OS) application programming interface (API) without having to resort to labor-intensive manual test construction for each API fimction to be tested. In the end, a scalable approach was found and was successfully applied not only to operating system APIs but several other nonoperating system APIs as well. The robustness testing methodology Ballista is based upon using combinational tests of valid and invalid parameter values for system calls and functions. In each test case, a single software module under test (or MuT) is called once. An MuT can be a stand\u2014alone program, function, system call, method, or any other software that can be invoked with a procedure call.(The term MuT is similar in meaning to the more recent term dependability benchmark target [DBench 2004].) In most cases, MuTs are calling points into an API. Each invocation of a test case determines whether a particular MuT provides robust ex\u2014ception handling when called with a particular set of parameter values. These parameter values, or test values, are drawn from a pool of normal and exceptional values based on the data type of each argument passed to the MuT. Each test value has\u00a0\u2026", "num_citations": "37\n", "authors": ["1481"]}
{"title": "Dependability Benchmarking: making choices in an n-dimensional problem space\n", "abstract": " Dependability benchmarks should provide cost-effective ways to evaluate the behavior of components and computer systems in the presence of faults, allowing the quantification of dependability attributes or the characterization of the systems into well defined dependability classes. Beyond existing evaluation techniques, a dependability benchmark should represent an agreement accepted by the computer industry or/and by the user community, and specify the measures, the methods, and techniques required to perform measurements. This paper discusses the different dimensions involved in the dependability benchmarking problem and presents basic components required to specify dependability benchmarks. Although several obstacles still persist and are currently the subject of research, the definition of all the dimensions of the problem and the agreement of the community on a basic set of components that constitute a possible framework for dependability benchmarking seem to us a first step in the proposal of actual dependability benchmarks.", "num_citations": "36\n", "authors": ["1481"]}
{"title": "System safety as an emergent property in composite systems\n", "abstract": " Decomposition is used to manage system complexity, but is problematic for emergent properties such as system safety. Previously, we introduced Indirect Control Path Analysis (ICPA) for elaborating system safety goals in composite systems. We now provide mathematical definitions of emergent and composable system behaviors in the context of formal specifications and ICPA, and identify useful special cases in which partial decomposition of emergent safety goals is possible. We apply ICPA to a semi-autonomous automotive system to identify safety goals for key subsystems, and then monitor the system and subsystem goals at run-time in an implementation of the vehicle. Although false negatives at the subsystem level indicate the subgoals do not fully compose the original safety goal, some system-level goal violations are detected by subsystem monitors. In addition, monitoring at both the system and\u00a0\u2026", "num_citations": "35\n", "authors": ["1481"]}
{"title": "Cache behavior of combinator graph reduction\n", "abstract": " The results of cache-simulation experiments with an abstract machine for reducing combinator graphs are presented. The abstract machine, called TIGRE, exhibits reduction rates that, for similar kinds of combinator graphs on similar kinds of hardware, compare favorably with previously reported techniques. Furthermore, TIGRE maps easily and efficiently onto standard computer architectures, particularly those that allow a restricted form of self-modifying code. This provides some indication that the conventional \"stored program\" organization of computer systems is not necessarily an inappropriate one for functional programming language implementations. This is not to say, however, that present day computer systems are well equipped to reduce combinator graphs. In particular,   the behavior of the cache memory has a significant effect on performance. In order to study and quantify this effect, trace-driven cache\u00a0\u2026", "num_citations": "33\n", "authors": ["1481"]}
{"title": "Using architectural properties to model and measure graceful degradation\n", "abstract": " System-wide graceful degradation may be a viable approach to improving dependability in computer systems. In order to evaluate and improve system-wide graceful degradation we present a system model that will explicitly define graceful degradation as a system property, and measure how well a system gracefully degrades in the presence of multiple combinations of component failures. The system\u2019s software architecture plays a major role in this model, because the interface and component specifications embody the architecture\u2019s abstraction principle. We use the architecture to group components into subsystems that enable reasoning about overall system utility. We apply this model to an extensive example of a distributed embedded control system architecture to specify the relative utility of all valid system configurations. We then simulate working system configurations and compare their ability to\u00a0\u2026", "num_citations": "32\n", "authors": ["1481"]}
{"title": "Autonomous vehicles meet the physical world: Rss, variability, uncertainty, and proving safety\n", "abstract": " The Responsibility-Sensitive Safety (RSS) model offers provable safety for vehicle behaviors such as minimum safe following distance. However, handling worst-case variability and uncertainty may significantly lower vehicle permissiveness, and in some situations safety cannot be guaranteed. Digging deeper into Newtonian mechanics, we identify complications that result from considering vehicle status, road geometry and environmental parameters. An especially challenging situation occurs if these parameters change during the course of a collision avoidance maneuver such as hard braking. As part of our analysis, we expand the original RSS following distance equation to account for edge cases involving potential collisions mid-way through a braking process.", "num_citations": "31\n", "authors": ["1481"]}
{"title": "Improving system dependability with functional alternatives\n", "abstract": " We present the concept of alternative functionality for improving dependability in distributed embedded systems. Alternative functionality is a mechanism that complements traditional performability and graceful degradation techniques. Rather than providing reduced performance or functionality when components or subsystems fail, alternative functionality replaces a lost feature with another existing system junction that can substitute for the lost service. This can provide improved system dependability when it is not feasible to allocate dedicated backup systems for fault tolerance. We show how alternative functionality can be applied to enhance system dependability with a case study of an elevator control system. In simulation, an elevator design that implemented alternative functionality in some of its subsystems tolerated many combinations of component failures that caused system failures in the original design.", "num_citations": "31\n", "authors": ["1481"]}
{"title": "System and method of updating communications in a security system\n", "abstract": " An anti-theft system includes a strategy for providing secure communications between a system controller and a remote signaling device. A communications initiator allows the transfer of information or signals between the system controlling and the remote signaling device only under pre-defined conditions. The system controller preferably includes a transmitter portion for transmitting signals or information to the remote device and a receiver portion for receiving signals from the remote device. Similarly, the remote device preferably includes a transceiver so that two-way communication is accomplished between the controller and the remote signalling device.", "num_citations": "29\n", "authors": ["1481"]}
{"title": "Representing embedded system sequence diagrams as a formal language\n", "abstract": " Sequence Diagrams (SDs) have proven useful for describing transaction-oriented systems, and can form a basis for creating statecharts. However, distributed embedded systems require special support for branching, state information, and composing SDs. Actors must traverse many SDs when using a complex embedded system. Current techniques are insufficiently rich to represent the behavior of real systems, such as elevators, without augmentation, and cannot identify the correct SD to execute next from any given state of the system. We propose the application of formal language theory to ensure that SDs (which can be thought of as specifying a grammar) have sufficient information to create statecharts (which implement the automata that recognize that grammar). A promising approach for SD to statechart synthesis then involves \u2018compiling\u2019 SDs represented in an LL(1) grammar into statecharts, and\u00a0\u2026", "num_citations": "28\n", "authors": ["1481"]}
{"title": "Dependability benchmarking & prediction: a grand challenge technology problem\n", "abstract": " We propose the grand challenge problem of dependability benchmarking and prediction for real-time mission-critical systems (RTMCSs).  Evaluating dependability would quantify the degree of reliance that could justifiably be placed on a critical system, even in the face of partial failures or exceptional conditions.  A comprehensive result would require an inter-disciplinary approach embracing the entire product lifecycle.  While there are significant technical hurdles to both assessing the dependability of individual elements and combining resultant measures, a viable approach must be found to ensure that the computing systems our society is coming to depend upon will be reliable, available, safe, and secure. The participation of several communities, including the Real Time Computing community, is vital to success fully address this challenge.", "num_citations": "28\n", "authors": ["1481"]}
{"title": "The amaranth framework: Policy-based quality of service management for high-assurance computing\n", "abstract": " System resource management for high-assurance applications such as the command and control of a battle group is a complex problem. These applications often require guaranteed computing services that must satisfy both hard and soft deadlines. Over time, their resource demands can also vary significantly with bursts of high activity amidst periods of inactivity. A traditional solution has been to dedicate resources to critical application tasks and to share resources among non-critical tasks. With the increasing complexity of high-assurance applications and the need to reduce system costs, dedicating resources is not a satisfactory solution. The Amaranth Project at Carnegie Mellon is researching and developing a framework for allocating shared resources to support multiple quality of service (QoS) dimensions and to provide probabilistic assurances of service. This paper is an overview of the Amaranth framework\u00a0\u2026", "num_citations": "27\n", "authors": ["1481"]}
{"title": "Vehicle anti-theft system including vehicle identification numbers programmed into on-board computers\n", "abstract": " A vehicle anti-theft system includes programming vehicle identification numbers or a corresponding identifier value into a read-only memory portion of each computer on board the vehicle. The computers are all linked through a multiplex communication system that has a monitoring port. The monitoring port facilitates coupling an external device to the multiplex communication link. The external monitoring device is used to determine the contents of the read only memory portion on each component to determine whether any of the components were stolen from another vehicle, for example.", "num_citations": "25\n", "authors": ["1481"]}
{"title": "Time division multiple access without a bus master\n", "abstract": " Time Division Multiple Access (TDMA) protocols have the potential to provide simple but effective broadcast bus communications for embedded systems. However, bus-master based protocols such as TDMA can be undesirable in practice because the bus master node constitutes a single-point failure vulnerability and adds to system expense. We present the Jam-TDMA (J-TDMA) protocol, which eliminates the need for having a bus master through the use of a nondestructive jamming signal for frame synchronization. We give a detailed description of the J-TDMA protocol and show how to minimize the effects of speed differences among nodes on TDMA systems, which can be critical for low-cost implementations. We believe that J-TDMA reaps the benefits of TDMA protocols without suffering the reliability and system complexity drawbacks of other TDMA methods.", "num_citations": "25\n", "authors": ["1481"]}
{"title": "Toward a scalable method for quantifying aspects of fault tolerance, software assurance, and computer security\n", "abstract": " Quantitative assessment tools are urgently needed in the areas of fault tolerance, software assurance, and computer security. Assessment methods typically employed in various combinations are fault injection, formal verification, and testing. However these methods are expensive because they are labor-intensive, with costs scaling at least linearly with the number of software modules tested. Additionally, they are subject to human lapses and oversights because they require two different representations for each system, and then base results on a direct or an indirect representation comparison. The Ballista project has found that robustness testing forms a niche in which scalable quantitative assessment can be achieved at low cost. This scalability stems from two techniques. Associating state-setting information with test cases based on data types, and using one generic, but narrow, behavioral specification for all\u00a0\u2026", "num_citations": "24\n", "authors": ["1481"]}
{"title": "A dimensionality model approach to testing and improving software robustness\n", "abstract": " Software robustness problems may hinder the use of Commercial Off-The-Shelf (COTS) software modules and legacy software modules in mission-critical and safety-critical applications. This research focuses on hardening COTS and legacy software modules against robustness failures triggered by exceptional inputs. An automated approach is presented that is capable of identifying the triggers of the robustness failures. A fault model-the dimensionality model-is used to guide analysis. An experiment is described which demonstrates the feasibility of automating the process of analyzing failure causes and hardening against certain data types in POSIX function calls, for example, NULL pointer values and scalar data types such as INT and FLOAT. The final goal of this research is to provide users a tool to harden COTS and legacy software modules automatically.", "num_citations": "22\n", "authors": ["1481"]}
{"title": "A fresh look at combinator graph reduction\n", "abstract": " We present a new abstract machine for graph reduction called TIGRE. Benchmark results show that TIGRE's execution speed compares quite favorably with previous combinator-graph reduction techniques on similar hardware. Furthermore, the mapping of TIGRE onto conventional hardware is simple and efficient. Mainframe implementations of TIGRE provide performance levels exceeding those previously available on custom graph reduction hardware.", "num_citations": "22\n", "authors": ["1481"]}
{"title": "Hardware/software codesign of aerospace and automotive systems\n", "abstract": " Electronics systems for modern vehicles must be designed to meet stringent requirements on real-time performance, safety, power consumption, and security. Hardware/software codesign techniques allow system designers to create platforms that can both meet those requirements and evolve as components and system requirements evolve. Design methodologies have evolved that allow systems-of-systems to be built from subsystems that are themselves embedded computing systems. Software performance is a key metric in the design of these systems. A number of methods-of-methods for the analysis of worst case execution time have been developed. More recently, we have developed new methods for software performance analysis based on design of experiments. Formal methods can be used to verify system properties. Systems must be architected to maintain their integrity in the face of attacks from the\u00a0\u2026", "num_citations": "21\n", "authors": ["1481"]}
{"title": "Safety argument considerations for public road testing of autonomous vehicles\n", "abstract": " Autonomous vehicle (AV) developers test extensively on public roads, potentially putting other road users at risk. A safety case for human supervision of road testing could improve safety transparency. A credible safety case should include:(1) the supervisor must be alert and able to respond to an autonomy failure in a timely manner,(2) the supervisor must adequately manage autonomy failures, and (3) the autonomy failure profile must be compatible with effective human supervision.Human supervisors and autonomous test vehicles form a combined human-autonomy system, with the total rate of observed failures including the product of the autonomy failure rate and the rate of unsuccessful failure mitigation by the supervisor. A difficulty is that human ability varies in a nonlinear way with autonomy failure rates, counter-intuitively making it more difficult for a supervisor to assure safety as autonomy maturity improves. Thus, road testing safety cases must account for both the expected failures during testing and the practical effectiveness of human supervisors given that failure profile. This paper outlines a high level safety case that identifies key factors for credibly arguing the safety of an onroad AV test program. A similar approach could be used to analyze potential safety issues for high capability semiautonomous production vehicles.", "num_citations": "20\n", "authors": ["1481"]}
{"title": "Putting image manipulations in context: robustness testing for safe perception\n", "abstract": " We introduce a method to evaluate the robustness of perception systems to the wide variety of conditions that a deployed system will encounter. Using person detection as a sample safety-critical application, we evaluate the robustness of several state-of-the-art perception systems to a variety of common image perturbations and degradations. We introduce two novel image perturbations that use \u201ccontextual information\u201d (in the form of stereo image data) to perform more physically-realistic simulation of haze and defocus effects. For both standard and contextual mutations, we show cases where performance drops catastrophically in response to barely-perceptible changes. We also show how robustness to contextual mutators can be predicted without the associated contextual information in some cases.", "num_citations": "20\n", "authors": ["1481"]}
{"title": "Design time reliability analysis of distributed fault tolerance algorithms\n", "abstract": " Designing a distributed fault tolerance algorithm requires careful analysis of both fault models and diagnosis strategies. A system will fail if there are too many active faults, especially active Byzantine faults. But, a system will also fail if overly aggressive convictions leave inadequate redundancy. For high reliability, an algorithm's hybrid fault model and diagnosis strategy must be tuned to the types and rates of faults expected in the real world. We examine this balancing problem for two common types of distributed algorithms: clock synchronization and group membership. We show the importance of choosing a hybrid fault model appropriate for the physical faults expected by considering two clock synchronization algorithms. Three group membership service diagnosis strategies are used to demonstrate the benefit of discriminating between permanent and transient faults. In most cases, the probability of failure is\u00a0\u2026", "num_citations": "20\n", "authors": ["1481"]}
{"title": "Analysis of the train communication network protocol error detection capabilities\n", "abstract": " The Train Communication Network (TCN) has been adopted as an international standard for use in critical transportation applications on trains. This paper discusses the results of a general review of the specification for error detection properties as an important factor of overall system safety. In general, TCN has excellent error detection properties and is much more thoroughly specified in this regard than other embedded network protocols. The only significant recommendation for improvement is prohibiting the use of variable-or multiple-length frames for any particular frame ID value to guard against corruptions that can cause undetected changes in message lengths (current implementations use only single lengths, but this is not specifically required by the standard). Additionally, it is important that designers pay close attention to receiver circuitry to minimize vulnerability to \u201cbit slips\u201d that could cause phase shifting and resultant burst errors in received Manchester-encoded bit streams.", "num_citations": "20\n", "authors": ["1481"]}
{"title": "A widely deployable Web-based network simulation framework using CORBA IDL-based APIs\n", "abstract": " Web-based network simulation frameworks are becoming highly portable and extensible. However, they still lack the degree of language and platform independence required for large-scale deployment on the World Wide Web. Our approach to enabling large-scale deployment uses a set of standard CORBA-IDL based programming interfaces, a publisher-subscriber model for communication, and dynamic composition of all simulation entities (simulated network hosts and links). A prototype application for testing distributed computing policies demonstrates that the CORBA components not only provide language and platform-independence, but also provide the ability for simulationists to connect objects to a third party distributed simulation. By using a uniform messaging approach to all simulation events, objects can be reassigned to different simulation entities without requiring code modifications. Dynamic loading\u00a0\u2026", "num_citations": "19\n", "authors": ["1481"]}
{"title": "Perils of the PC Cache\n", "abstract": " While the cache memory designed into advanced processors can significantly speed up the average performance of many programs, it also causes performance varations that surprise system designers and cause problems during product integration and deployment. This paper gives a description of cache memory behavior for real-time embedded systems, using the example of real data collected from an 80486 CPU interrupt service routine. While vendor-supported tools for predicting and bounding worst-case CPU delays are still in their infancy, there are some coping strategies that will reduce problems while minimizing risk.", "num_citations": "19\n", "authors": ["1481"]}
{"title": "Design constraints on embedded real time control systems\n", "abstract": " Today's embedded real time control applications place extraordinary demands on microprocessors. They have stringent constraints on size, weight, power, co o ling, computi ng performance, reliability, and cost. Unfortunately for the designers of such systems, modern processor architectures usually incorporate design features that are valuable for general-purpose computing, but violate constraints for hard real time problems.", "num_citations": "18\n", "authors": ["1481"]}
{"title": "Toward middleware fault injection for automotive networks\n", "abstract": " As embedded communication networks pervade widely fielded safety-critical distributed systems, it is important to understand their robustness. Middleware fault injection offers advantages in flexibility and cost over adding specialized fault injecting network nodes. The research goal is accelerated testing of an automated vehicle system with respect to transient communication network faults.", "num_citations": "17\n", "authors": ["1481"]}
{"title": "Credible autonomy safety argumentation\n", "abstract": " A significant challenge to deploying mission-and safety-critical autonomous systems is the difficulty of creating a credible assurance argument. This paper collects lessons learned from having observed both credible and faulty assurance argumentation attempts, with a primary emphasis on autonomous ground vehicle safety cases. Various common argumentation approaches are described, including conformance to a non-autonomy safety standard, proven in use, field testing, simulation, and formal verification. Of particular note are argumentation faults and anti-patterns that have shown up in numerous safety cases that we have encountered. These observations can help both designers and auditors detect common mistakes in safety argumentation for autonomous systems.", "num_citations": "16\n", "authors": ["1481"]}
{"title": "Selection of cyclic redundancy code and checksum algorithms to ensure critical data integrity\n", "abstract": " This report explores the characteristics of checksums and cyclic redundancy codes (CRCs) in an aviation context. It includes a literature review, a discussion of error detection performance metrics, a comparison of various checksum and CRC approaches, and a proposed methodology for mapping CRC and checksum design parameters to aviation integrity requirements. Specific examples studied are Institute of Electrical and Electronics Engineers (IEEE) 802.3 CRC-32; Aeronautical Radio, Incorporated (ARINC)-629 error detection; ARINC-825 Controller Area Network (CAN) error detection; Fletcher checksum; and the Aeronautical Telecommunication Network (ATN)-32 checksum. Also considered are multiple error codes used together, specific effects relevant to communication networks, memory storage, and transferring data from nonvolatile to volatile memory. Key findings include: (1) significant differences exist in effectiveness between error-code approaches, with CRCs being generally superior to checksums in a wide variety of contexts; (2) common practices and published standards may provide suboptimal (or sometimes even incorrect) information, requiring diligence in selecting practices to adopt in new standards and new systems; (3) error detection effectiveness depends on many factors, with the Hamming distance of the error code being of primary importance in many practical situations; (4) no one-size-fits-all error-coding approach exists, although this report does propose a procedure that can be followed to make a methodical decision as to which coding approach to adopt; and (5) a number of secondary considerations must be\u00a0\u2026", "num_citations": "16\n", "authors": ["1481"]}
{"title": "Revisiting fletcher and adler checksums\n", "abstract": " Checksums are routinely used to detect data transmission errors. However, design decisions about which check-sum to use are difficult because of a lack of information about relative effectiveness of available options. We study the error detection effectiveness of the Fletcher and Adler checksums for random independent bit errors and burst errors. Our study reveals that in most cases the Fletcher checksum should be used instead of the Adler checksum.", "num_citations": "16\n", "authors": ["1481"]}
{"title": "Critical Message Integrity Over A Shared Network\n", "abstract": " Cost and efficiency concerns can force distributed embedded systems to use a single network for both critical and non-critical messages. Such designs must protect against masquerading faults caused by defects in and failures of non-critical network processes. Cyclic Redundancy Codes (CRCs) offer protection against random bit errors caused by environmental interference and some hardware faults, but typically do not defend against most design defects. A way to protect against such arbitrary, non-malicious faults is to make critical messages cryptographically secure. An alternative to expensive, full-strength cryptographic security is the use of lightweight digital signatures based on CRCs for critical processes. Both symmetric and asymmetric key digital signatures based on CRCs form parts of the cost/performance tradeoff space to improve critical message integrity.", "num_citations": "16\n", "authors": ["1481"]}
{"title": "Lost messages and system failures\n", "abstract": " Lost or delayed messages are common in networked communications, and require a change in thinking to avoid designing systems that are too brittle. If you fail to anticipate the loss of multiple messages in a row, you can experience system failures. This article discusses the potential severity of the problem, and shows how to predict system failures based on the likelihood of message losses, with Ethernet and Echelon's LonTalk used as examples. The article discusses sources of message losses and steps you can take to reduce or eliminate problems.", "num_citations": "16\n", "authors": ["1481"]}
{"title": "Embedded communication protocol options\n", "abstract": " Developers are realizing that traditional low-speed, point-to-point links are inadequate for their increasingly complex distributed embedded applications. Consequently, they are investigating multiplexed communication network protocols to incorporate advanced System capabilities, increase reliability, and reduce wiring requirements. This paper discusses special considerations for embedded system networks, a family tree of \u201cstandard\" protocols, media access tradeoffs, and attractive options for off-the-shelf solutions. Based on real-time performance, cost, and hardware availability, ARCnet, CAN, and LON are strong contenders for most embedded systems.", "num_citations": "16\n", "authors": ["1481"]}
{"title": "Risk areas in embedded software industry projects\n", "abstract": " A powerful way to understand where gaps are in the expertise of embedded system designers is to look at what goes wrong in real industry projects. In this paper we summarize the\" red flag\" issues found in approximately 90 design reviews of embedded system products conducted over a ten year period across a variety of embedded system industries. The problems found can be roughly categorized into the areas of process, requirements, architecture, design, implementation, verification/validation, dependability, project management, and people. A few problem areas, such as watchdog timers and real time scheduling, are standard embedded education topics. But many areas, such as peer reviews, requirements, SQA, and user interface design might be worthy of increased attention in texts and education programs.", "num_citations": "15\n", "authors": ["1481"]}
{"title": "Quantifying the reliability of proven SPIDER group membership service guarantees\n", "abstract": " For safety-critical systems, it is essential to quantify the reliability of the assumptions that underlie proven guarantees. We investigate the reliability of the assumptions of the SPIDER group membership service with respect to transient and permanent faults. Modeling 12,600 possible system configurations, the probability that SPIDER's maximum fault assumption does not hold for an hour mission varies from less likely than l0/sup -11/ to more likely than 10/sup -3/. In most cases examined, a transient fault tolerance strategy was superior to the permanent fault tolerance strategy previously in use for the range of transient fault arrival rates expected in aerospace systems. Reliability of the maximum fault assumption (upon which the proofs are based) differs greatly when subjected to asymmetric, symmetric, and benign faults. This case study demonstrates the benefits of quantifying the reliability of assumptions for proven\u00a0\u2026", "num_citations": "15\n", "authors": ["1481"]}
{"title": "Performance evaluation of exception handling in I/O libraries\n", "abstract": " Lack of data quantifying the performance cost of implementing good exception handling often causes developers to skimp on exception handling based on its overestimated perceived cost. In an effort to remedy this problem we provide performance data on the cost of building good exception handling into software. We use the Safe Fast IO library as a basis for this study. SFIO improves robustness by a factor of 3 to 10 over STDIO without sacrificing performance. We were able to improve the robustness of the critical SFIO functions by another factor of 5, thus quantifying and reducing robustness failure rates by a factor of up to 70 from standard I/O functions, with an average performance penalty of 1% as measured by the original SFIO benchmark scheme. Future processor architecture improvements will further improve checking speed, essentially eliminating performance as an obstacle to improving software robustness.", "num_citations": "15\n", "authors": ["1481"]}
{"title": "The Heavy Tail Safety Ceiling\n", "abstract": " Creating safe autonomous vehicles will require not only extensive training and testing against realistic operational scenarios, but also dealing with uncertainty. The real world can present many rare but dangerous events, suggesting that these systems will need to be robust when encountering novel, unforeseen situations. Generalizing from observed road data to hypothesize various classes of unusual situations will help. However, a heavy tail distribution of surprises from the real world could make it impossible to use a simplistic drive/fail/fix development process to achieve acceptable safety. Autonomous vehicles will need to be robust in handling novelty, and will additionally need a way to detect that they are encountering a surprise so that they can remain safe in the face of uncertainty.", "num_citations": "14\n", "authors": ["1481"]}
{"title": "Representing design tradeoffs in safety-critical systems\n", "abstract": " Different fault-tolerance strategies have been shown to be effective at achieving fail-safe behavior in a number of safety-critical application domains with different dependability, service, and cost requirements. A technique for comparing the domain profiles and their fault-tolerance strategies could assist architects of new safety-critical systems in choosing an appropriate fault-tolerance strategy. We suggest an approach using Kiviat graphs to visually represent the dependability, service, and cost profile of a system, and show how such a graph can be used to analyze automotive x-by-wire applications.", "num_citations": "14\n", "authors": ["1481"]}
{"title": "A graceful degradation framework for distributed embedded systems\n", "abstract": " Automatic graceful degradation can be accomplished by reconfiguring the software elements of a distributed embedded system to accommodate the available hardware upon detection of a fault.  The reconfiguration algorithm selects software components from a Product Family Architecture in order to maximize the functionality of the system.  The mobile software components must then be allocated to the hardware so as to ensure network and processor resources are conserved.  As the allocation step is NP-complete, care must be taken to ensure it is attempted only when a good chance of success exists, otherwise the rest of the algorithm merely wraps polynomial time (or worse) loop constructs around this hard core.  Therefore, good heuristics are critical to success of this algorithm.", "num_citations": "14\n", "authors": ["1481"]}
{"title": "The amaranth framework: Probabilistic, utility-based quality of service management for high-assurance computing\n", "abstract": " System resource management for high-assurance applications such as the command and control of a battle group is a complex problem. These applications often require guaranteed computing services that must satisfy both hard and soft deadlines. In addition, their resource demands can vary significantly over time with bursts of high activity amidst periods of inactivity. A traditional solution has been to dedicate resources to critical application tasks and to share resources among noncritical tasks. With the increasing complexity of high-assurance applications and the need to reduce system costs, dedicating resources is not a satisfactory solution. The Amaranth Project at Carnegie Mellon is researching and developing a framework for allocating shared resources to support multiple quality of service (QoS) dimensions and to provide probabilistic assurances of service. This paper is an overview of the Amaranth\u00a0\u2026", "num_citations": "14\n", "authors": ["1481"]}
{"title": "Robustness testing of a distributed simulation backplane\n", "abstract": " Creating robust software requires not only careful specification and implementation, but also quantitative measurement. This paper describes Ballista exception handling testing of the High Level Architecture RunTime Infrastructure (HLA RTI). The RTI is a standard distributed simulation system intended to provide completely robust exception handling, yet implementations have normalized robustness failure rates as high as 10%. Non-robust testing responses include exception handler crashes, segmentation violations, \"unknown\" exceptions, and task hangs. Other issues include different robustness failure modes across ports to two operating systems, and mandatory client machine rebooting after a particular RTl failure. Testing the RTI led to scalable extensions of the Ballista architecture for handling exception-based error reporting models, testing object-oriented software structures (including call-backs, pass by\u00a0\u2026", "num_citations": "14\n", "authors": ["1481"]}
{"title": "Implicit token media access protocol without collision detection\n", "abstract": " If a transceiver has a message to send during an idle medium condition, it transmits a jam pattern onto the medium for a predetermined time (based on maximum network propagation delay). If a transceiver detects a jamming pattern, it inhibits its own transmissions and waits for the next slot progression. If multiple transceivers begin jamming within a propagation delay of each other (within the network vulnerable time), their jamming transmissions will not destructively interfere with each other. When jamming ceases, all transceivers begin a slot progression. Thus, the end of the jamming period when all transceivers have finished jamming serves as a network-wide synchronization for the start of an implicit token slot progression.", "num_citations": "14\n", "authors": ["1481"]}
{"title": "What\u2019s wrong with fault injection as a benchmarking tool?\n", "abstract": " This paper attempts to solidify the technical issues involved in the long-standing debate about the representativeness of fault injection as a tool for measuring the dependability of general-purpose software systems. While direct fault injection seems appropriate for evaluating fault tolerant computers, most current software systems are not designed in a way that makes injection of faults directly into a module under test relevant for dependability benchmarking. Approaches that seem more likely to create representative faults are ones that induce exceptional operating conditions external to a module under test in terms of exceptional system state, exceptional parameters/return values at an API, failed system components, or exceptional human interface inputs.", "num_citations": "13\n", "authors": ["1481"]}
{"title": "Challenges in autonomous vehicle validation: Keynote presentation abstract\n", "abstract": " Developers of autonomous systems face distinct challenges in conforming to established methods of validating safety. It is well known that testing alone is insufficient to assure safety, because testing long enough to establish ultra-dependability is generally impractical. Thatfis why software safety standards emphasize high quality development processes. Testing then validates process execution rather than directly validating dependability.", "num_citations": "12\n", "authors": ["1481"]}
{"title": "Transportation CPS safety challenges\n", "abstract": " Creating safe Transportation Cyber-Physical Systems (CPSs) presents new challenges as autonomous operation is attempted in unconstrained operational environments. The extremely high safety level required of such systems (perhaps one critical failure per billion operating hours) means that validation approaches will need to consider not only normal operation, but also operation with system faults and in exceptional environments. Additional challenges will need to be overcome in the areas of rigorously defining safety requirements, trusting the safety of multi-vendor distributed system components, tolerating environmental uncertainty, providing a realistic role for human oversight, and ensuring sufficiently rigorous validation of autonomy technology.", "num_citations": "12\n", "authors": ["1481"]}
{"title": "Jini meets embedded control networking: A case study in portability failure\n", "abstract": " The Robust Self-Configuring Embedded Systems (RoSES) project seeks to achieve graceful degradation through software reconfiguration. To accomplish this goal, systems must automatically reconfigure despite nodes failing, being replaced by inexact spares, or being upgraded. Jini seemed to provide the required spontaneous networking infrastructure, but turned out to make deep assumptions about using TCP and UDP This is appropriate for the Intern et-enabled devices that the Jini designers envisioned, but typical distributed embedded systems employ real-time, reliable data transmission such as the Control Area Network (CAN), rather than TCR Object-oriented technology such as Jini is often represented as being suitable for use in real-time embedded systems. But despite Jini goal of platform-independence, it required extensive re-engineering to function on CAN. This case study of an actual\u00a0\u2026", "num_citations": "12\n", "authors": ["1481"]}
{"title": "Practical experience report: Automotive safety practices vs. accepted principles\n", "abstract": " This paper documents the state of automotive computer-based system safety practices based on experiences with unintended acceleration litigation spanning multiple vehicle makers. There is a wide gulf between some observed automotive practices and established principles for safety critical system engineering. While some companies strive to do better, at least some car makers in the 2002\u20132010 era took a test-centric approach to safety that discounted non-reproducible and \u201cunrealistic\u201d faults, instead blaming driver error for mishaps. Regulators still follow policies from the pre-software safety assurance era. Eight general areas of contrast between accepted safety principles and observed automotive safety practices are identified. While the advent of ISO 26262 promises some progress, deployment of highly autonomous vehicles in a non-regulatory environment threatens to undermine safety\u00a0\u2026", "num_citations": "11\n", "authors": ["1481"]}
{"title": "The architecture of supercomputers: Titan, a case study\n", "abstract": " The Architecture of Supercomputers: Titan, A Case Study describes the architecture of the first member of an entirely new computing class, the graphic supercomputing workstation known as Titan. This book is divided into seven chapters. Chapter 1 provides an overview of the Titan architecture, including the motivation, organization, and processes that created it. A survey of all the techniques to speed up computation is presented in Chapter 2. Chapter 3 reviews the issue of particular benchmarks and measures, while Chapter 4 analyzes a model of a concurrency hierarchy extending from the register set to the entire operating system. The architecture of Titan graphics supercomputer and its implementation are considered in Chapter 5. Chapter 6 examines the performance of Titan in terms of the various information flow data rates. The last chapter is devoted to the actual performance on benchmark kernels and how the architecture and implementation affect performance. This publication is recommended for architects and engineers designing processors and systems.", "num_citations": "11\n", "authors": ["1481"]}
{"title": "Data management mechanisms for embedded system gateways\n", "abstract": " It is becoming increasingly common to connect traditional embedded system networks to the Internet for remote monitoring, high-level control and integration. It is necessary to protect each part of the interconnected system from faults and attacks which propagate from the other side. One architectural approach is to add a gateway to the embedded system to receive Internet traffic and disperse data to the embedded system, but there is no clear recipe for building such gateways. Since Internet routers commonly use queues to manage traffic, we examine the effectiveness of queues for the embedded system gateway domain. We perform a series of experiments to evaluate the effectiveness of the queue mechanism and various queue management techniques. We show that queues can exhibit poor performance in the context of real-time embedded system gateways due to problems with message latency and dropped\u00a0\u2026", "num_citations": "11\n", "authors": ["1481"]}
{"title": "Developing a software architecture for graceful degradation in an elevator control system\n", "abstract": " Many embedded systems have high safety and dependability requirements, which makes ensuring software robustness a top priority in these systems. As embedded computer systems become more complex and incorporate increasing functionality, their software systems become increasingly more difficult to design, build, and maintain. One approach to achieving software robustness is graceful degradation. However, graceful degradation is a difficult property to define or construct. Traditional hardware redundancy is not enough to achieve software safety and dependability. The system's software architecture may be the key to building graceful degradation into a software system. This paper describes a proposal for a software architecture that may enhance graceful degradation for an example elevator control system, and discussion about implementing and evaluating the architecture.", "num_citations": "11\n", "authors": ["1481"]}
{"title": "Modern stack computer architecture\n", "abstract": " A new generation of stack processors based on the Forth abstract machine has recently been developed for embedded real-time control applications. These processors are optimized for minimum system complexity, small program size, fast but consistent processor performance, and excel-lent response to external events. The Harris RTX 2000 is described as an example of a typical stack processor.", "num_citations": "11\n", "authors": ["1481"]}
{"title": "Integrity in embedded control networks\n", "abstract": " Many embedded systems, such as in cars, use a network to coordinate control actions in real time. Usually, the system doesn't employ an Ethernet network but rather a specialized realtime control protocol running on severely resource-constrained computing nodes (mostly 8-bit and 16-bit CPUs). This presents unique challenges. Ensuring integrity in such systems involves a combination of safety and security needs, and the usual big-system security approaches aren't necessarily practical. Nonetheless, as threats of attacks increase, integrity approaches in networked embedded systems will have to evolve to provide both the security and safety aspects of integrity in a unified way. And they'll have to do it on a shoestring, using only a few bits per message.", "num_citations": "10\n", "authors": ["1481"]}
{"title": "The FlexRay Protocol\n", "abstract": " 23 The FlexRay Protocol Page 1 23 The FlexRay Protocol Philip Koopman Significant material drawn from FlexRay Specification Version 2.0, June 2004 30 Nov 2015 \u00a9 Copyright 2005-2015, Philip Koopman Page 2 2 Preview \u25c6 FlexRay \u2013 automotive choice for X-by-Wire applications \u2022 Created by industry consortium founded in 2000 \u2022 Core members: BMW, DaimlerChrysler, General Motors, Motorola, Philips, Volkswagen, and Robert Bosch. \u25c6 First public FlexRay protocol specification June 30, 2004 [FlexRay04] \u2022 Combination Time-Triggered & Event-Triggered Approach \u2022 Intended for use in safety critical, fault-tolerant systems \u25c6 Dec. 7, 2006: \u201cFlexRay protocol has entered its production phase with devices from NXP(formerly Philips Semiconductors) and Freescale Semiconductor in BMW's newest X5 sport activity vehicle.\u201d \u25c6 High volume production reached in about 2010 \u2022 Eg, NXP had shipped 1 million Flexray \u2026", "num_citations": "10\n", "authors": ["1481"]}
{"title": "Representing user workarounds as a component of system dependability\n", "abstract": " Evaluation of system-level dependability can benefit from representing and assessing the effects of user workarounds as a response to system component failures. We assemble sequence diagrams that represent UML scenarios into mission graphs that contain all possible paths from a particular mission starting point to a particular mission success goal point. Analysis of these graphs reveals potential dependability bottlenecks and the existence of possible workarounds that can be intentionally added to a design, retrofitted to fit an existing design, or discovered as an emergent property of existing system and user behaviors. Simulations of a moderately complex distributed embedded system demonstrate that this approach has potential benefits for representing and improving system-level dependability by including the ability of users to perform simple workarounds to achieve mission objectives.", "num_citations": "10\n", "authors": ["1481"]}
{"title": "Embedded systems in the real world\n", "abstract": " Embedded Systems In the Real World Page 1 Embedded Systems In the Real World Introduction to Embedded Systems Philip Koopman January 14, 1999 Further Reading: http://www.ices.cmu.edu/koopman/embedded.html Page 2 Preview x What is an embedded system? \u2022 More than just a computer x What makes them different? \u2022 Real time operation \u2022 Many sets of constraints on designs x What embedded system designers need to know \u2022 The big picture \u2022 Skills required to \u201cplay\u201d in this area Page 3 WHAT IS AN EMBEDDED SYSTEM? Page 4 Definition of an Embedded Computer x Computer purchased as part of some other piece of equipment \u2022 Typically dedicated software (may be user-customizable) \u2022 Often replaces previously electromechanical components \u2022 Often no \u201creal\u201d keyboard \u2022 Often limited display or no general-purpose display device x But, every system is unique -- there are always exceptions Page 5 !\u2026", "num_citations": "10\n", "authors": ["1481"]}
{"title": "A brief introduction to Forth\n", "abstract": " Two-Stack Abstract Machine At the most superficial level, Forth is a directly executable language for a stack-based abstract machine. In its essential form, the Forth abstract machine has a program counter, memory, ALU, data evaluation pushdown stack, and subroutine return address pushdown stack.", "num_citations": "10\n", "authors": ["1481"]}
{"title": "Functional evolution of automated highway system for incremental deployment\n", "abstract": " A combination of market forces, cost constraints, and other factors necessitates incremental evolution of a fully automated highway system (AHS) rather than instantaneous deployment. Thus, an understanding of the interdependencies among required AHS functional capabilities is essential for planning. In this paper a set of three AHS functional evolution reference models is proposed that include essential as well as supplemental functions. The reference models include lateral motion handling, longitudinal motion handling, obstacle handling, and selected infrastructure support functions. This family of three models is used to present the needs of baseline autonomous tactical vehicle operation, the benefits of adding inter-vehicle communications, and the benefits of adding infrastructure support. The reference models reveal a critical need for vehicle motion prediction capability and suggest that both communications\u00a0\u2026", "num_citations": "9\n", "authors": ["1481"]}
{"title": "An Architecture for Combinator Graph Reduction\n", "abstract": " An Architecture for Combinator Graph Reduction examines existing methods of evaluating lazy functional programs using combinator reduction techniques, implementation, and characterization of a means for accomplishing graph reduction on uniprocessors, and analysis of the potential for special-purpose hardware implementations. Comprised of eight chapters, the book begins by providing a background on functional programming languages and existing implementation technology. Subsequent chapters discuss the TIGRE (Threaded Interpretive Graph Reduction Engine) methodology for implementing combinator graph reduction; the TIGRE abstract machine, which is used to implement the graph reduction methodology; the results of performance measurements of TIGRE on a variety of platforms; architectural metrics for TIGRE executing on the MIPS R2000 processor; and the potential for special-purpose hardware to yield further speed improvements. The final chapter summarizes the results of the research, and suggests areas for further investigation. Computer engineers, programmers, and computer scientists will find the book interesting.", "num_citations": "8\n", "authors": ["1481"]}
{"title": "Indirect control path analysis and goal coverage strategies for elaborating system safety goals in composite systems\n", "abstract": " Correctly specifying requirements for composite systems is essential to system safety, particularly in a distributed development environment. Goal-oriented requirements engineering can be used to formally specify system goals and decompose them into realizable subgoals for system components. However, an additional aim of safety goal elaboration is to meet a goal coverage strategy. In this paper we propose new tactics for elaborating system safety goals across a composite system. First, indirect control path analysis (ICPA) is used to identify safety-related components and their relationships to the parent goals. Then, goal coverage strategies guide goal elaboration along indirect control paths identified by the ICPA. We demonstrate applicability in real safety critical embedded systems with two case studies: a distributed elevator and a semiautonomous automotive system.", "num_citations": "8\n", "authors": ["1481"]}
{"title": "Reliability, safety, and security in everyday embedded systems\n", "abstract": " \u25c6 In September 2000, Production of year 2001 models of Ford Windstar, Crown Victoria, Mercury Grand and Lincoln stopped because of software defect causing airbags to deploy on their own and seatbelts to tighten suddenly. This stopped production for several days at Ford of Canada and other sites.\u2022 http://www. findarticles. com/p/articles/mi_m3165/is_2000_Oct/ai_68324491", "num_citations": "8\n", "authors": ["1481"]}
{"title": "Main Memory Architecture\n", "abstract": " 13 Main Memory Architecture Page 1 18-548/15-548 Main Memory Architecture 10/19/98 1 13 Main Memory Architecture 18-548/15-548 Memory System Architecture Philip Koopman October 19, 1998 Required Reading: Cragon 5.1 - 5.1.5 Supplemental Reading: Hennessy & Patterson 5.6 IBM App. Note: Understanding DRAM Assignments \u25c6 By next class read about Main Memory Performance: \u2022 Cragon 5.1.6 - 5.1.7 \u2022 Fast DRAM article from EDN (Feb. 1997) \u2022 Supplemental Reading: \u2013 Siewiorek & Koopman 5.2.2 \u25c6 Homework 7 due October 21 \u25c6 Lab 4 due October 23 \u25c6 Test #2 Wednesday October 28 \u2022 Emphasizes material since Test #1 \u2022 In-class review Monday October 26 \u2022 Closed book, closed notes; bring erasers, sharpened pencils, calculator Page 2 18-548/15-548 Main Memory Architecture 10/19/98 2 Where Are We Now? \u25c6 Where we\u2019ve been: \u2022 Cache memory \u2022 Tuning for performance \u25c6 Where we\u2019re \u2026", "num_citations": "8\n", "authors": ["1481"]}
{"title": "Orthogonal capability building blocks for flexible AHS deployment\n", "abstract": " Once a baseline level of full automation is possible for an Automated Highway System (AHS), there are numerous choices to be made in deploying enhanced capabilities to improve safely, throughput, and travel time. Identifying a set of orthogonal capabilities enables describing multiple deployment paths within a common framework. Sixteen AHS configurations can be formed from a proposed set of orthogonal capabilities including: number of vehicles grouped into an entity (free agent vs. platoon), number of automated lanes (single or multiple), obstacle strategy (exclusion or detection), and system vigilance (trusting or vigilant). Given these capabilities, this systematic approach reveals a maximally enhanced end-slate configuration: a platooned, multi-lane, obstacle detecting, vigilant AHS that could be attained using any of 24 incremental deployment paths. A mapping technique is presented that can assist\u00a0\u2026", "num_citations": "8\n", "authors": ["1481"]}
{"title": "Elevator level control system using elevator/landing gap as a reflection duct\n", "abstract": " An emitter and a plurality of sensors and are used to detect the relative positions between an elevator platform and landing sill. The emitters radiate energy through a reflection duct formed between the elevator platform and the landing sill. The plurality of sensors monitor the reflection duct so that radiated energy is detected. The sensors provide level signals in response to the radiated energy. A means responsive to the level signals determines when the platform is level with respect to the landing sill.", "num_citations": "8\n", "authors": ["1481"]}
{"title": "Towards execution models of distributed systems: a case study of elevator design\n", "abstract": " Many of United Technologies' products contain or will soon contain a distributed network of processors. In order to explore issues related to designing such systems, two different methods of modeling system functionality have been applied to a simplified elevator controller. One method results in data flow oriented models which are executable within a context of the association of units of functionality with distributed processors. Execution thus produces processing and communication workloads which can be used for design analysis. In order to allow rapid assessment f alternative designs, an automated approach was developed which allowed the units of allocated functionality to be arbitrarily fine. However, neither the data flow approach not this automated allocation handle the complexity of large models sufficiently well. A similar elevator model has been defined with a technique which combines object-oriented analysis with formal specification. This combination avoids unnecessary complexity yet allows the model to have a formal semantics, which is necessary (bit not sufficient) to achieve the key methodological requirement of executability. Future work will integrate the object-oriented and data-flow approaches into a framework which supports specification, automated fine-grain allocation, and execution for large models.", "num_citations": "8\n", "authors": ["1481"]}
{"title": "Wireless automotive door\n", "abstract": " A wireless vehicle door assembly includes a conductive layer sandwiched between two nonconductive layers. An input terminal provides a connection between the conductive layer and a plurality of wires from another portion of the vehicle. A plurality of connectors couple a plurality of loads to the conductive layer. Electrical power and signals are propagated along the conductive layer to control the various loads.", "num_citations": "7\n", "authors": ["1481"]}
{"title": "Explicit and implicit token media access protocol with multi-level bus arbitration\n", "abstract": " Primary implicit token slots (that is, token slots following a message or jam used to restart network activity) are assigned to multiple transceivers. When a transceiver assigned to a shared slot has data to transmit, it emits a jamming signal instead of a message in its token slot. This jamming signal serves as a synchronization for a second implicit token slot progression in which only transceivers sharing the primary level implicit token slot participate.", "num_citations": "7\n", "authors": ["1481"]}
{"title": "Cache Performance of Combinator Graph Reduction.\n", "abstract": " The Threaded Interpretive Graph Reduction Engine (TIGRE) was developed for the efficient reduction of combinator graphs in support of functional programming languages and other applications. We present the results of cache simulations of the TIGRE graph reducer with the following parameters varied: cache size, cache organization, block size, associativity, replacement policy, write policy, and write allocation. As a check on our results, we compare the simulations to measured performance on real hardware. From the results of the simulation study, we conclude that graph reduction in TIGRE has a very heavy dependence on a write-allocate strategy for good performance, and very high spatial and temporal locality.", "num_citations": "7\n", "authors": ["1481"]}
{"title": "Learning product set models of fault triggers in high-dimensional software interfaces\n", "abstract": " We propose a method for generating interpretable descriptions of inputs that cause faults in high-dimensional software interfaces. Our method models the set of fault-triggering inputs as a Cartesian product and identifies this set by actively querying the system under test. The active sampling scheme is very efficient in the common case that few fields in the interface are relevant to causing the fault. This scheme also solves the problem of efficiently finding sufficient examples to model rare faults, which is problematic for other learning-based methods. Compared to other techniques, ours requires no parameter turning or post-processing in order to produce useful results. We analyze the method qualitatively, theoretically, and empirically. An experimental evaluation demonstrates superior performance and reliability compared to a basic decision tree approach. We also briefly discuss how the method has assisted in\u00a0\u2026", "num_citations": "6\n", "authors": ["1481"]}
{"title": "Reliability validation of group membership services for X-by-wire protocols\n", "abstract": " Distributed fault tolerance algorithms are used for many ultra-reliable systems. For example, aviation fly-by-wire and automotive drive-by-wire network protocols need to reliably deliver data despite the presence of faults. Careful design is required, since ultra-reliable systems permit a failure rate on the order of just 10\u2212 9 failures per hour. Unfortunately, investing more effort at the design stage does not assure a more reliable product if no objective measurement technique is used at this stage.", "num_citations": "6\n", "authors": ["1481"]}
{"title": "Performance of cyclic redundancy codes for embedded networks\n", "abstract": " The Cyclic Redundancy Code (CRC) in a network message forms a primary defense against system failures. Because embedded systems often operate in noisy environments, it is vital that CRC polynomials be selected to be optimal with respect to detecting errors in expected traffic workloads. Unfortunately, most standard CRCs do not perform well for the short messages that are commonly sent in embedded system applications, and in general were apparently not designed with short messages in mind. This paper describes a methodology to determine an optimal CRC polynomial for applications using short messages. Additionally, standard 16-bit CRC polynomials are shown to be grossly suboptimal in error detection performance for short messages. Our methodology has identified an optimal 12-bit CRC that yields better error detection than the widely used CCITT 16-bit CRC for embedded network workloads having typical message lengths of 64 bits. Adoption of optimal CRCs would provide improved cost/detection performance tradeoffs for new dependable embedded system designs. 1.", "num_citations": "6\n", "authors": ["1481"]}
{"title": "Analyzing dependability of embedded systems from the user perspective\n", "abstract": " Embedded systems of today pose difficult dependability challenges. Hardware and software requirements as well as human interface components all contribute to or detract from the overall dependability of a system. Assigning a \u2018dependability number\u2019to a system is becoming increasingly subjective due to the confluence of these three areas. In particular it is important to go beyond composing individual component reliability predictions, and additionally consider factors such as ease of user workaround in the face of a partial system failure. We suggest evaluating the opportunity for success of a user\u2019s mission in terms of flexibility in selecting a series of tasks to accomplish a specified goal. With this user perspective, we create graphs to represent user states and tasks, and explain how some aspects of system dependability can be assessed through standard graph analysis techniques.", "num_citations": "6\n", "authors": ["1481"]}
{"title": "The WISC concept\n", "abstract": " THE TRADITIONAL COMPLEX ir-struction set computer architecture with its large, complicated instruction set has become the mainstay of the microproces-sor industry. Recently, however, proponents of the reduced instruction set computer architecture have made the controversial claim that RISC architec-tures can execute programs more quickly than CISC machines. Before you decide which side of the line you're on, I'd like to present an alternative computer archi-tecture that combines elements of both RISC and CISC philosophies to produce an interesting, streamlined, flexible, and potentially fast machine. My proposed architecture is called WISC, for writable instruction set com-puter. My purpose is not to show that either the RISC or CISC approach is somehow wrong, but rather to introduce an alternative that blends RISC and CISC concepts into a simple but powerful ar-chitecture. First, I want to look at the key\u00a0\u2026", "num_citations": "6\n", "authors": ["1481"]}
{"title": "Critical Systems and Software Safety\n", "abstract": " \u25c6 Uses \u201cguide words\u201d in specification to trigger analysis items\u2022\u201cno\u201d\u2013what if there is no flow?\u2022\u201cmore\u201d\u2013what if a limit is exceeded?\u2022\u201cas well as\u201d\u2013what if something additional happens?\u2022\u201cpart of\u201d\u2013what if something only partially completes?\u2022\u201creverse\u201d\u2013what if flow is reversed?\u2022\u201cother than\u201d\u2013something else happens, eg, incorrect data\u2022\u201cearly\u201d\u2013signal earlier than deadline window\u2022\u201clate\u201d\u2013signal later than deadline window\u2022\u201cbefore\u201d\u2013out of order; arrives early\u2022\u201cafter\u201d\u2013out of order; arrives late", "num_citations": "5\n", "authors": ["1481"]}
{"title": "Challenges in representing CPS safety\n", "abstract": " This position paper describes the challenge of ensuring run-time safety in cyber-physical systems. The overarching problem is ensuring that computerbased systems will maintain safe operations even in the face of design-time and run-time faults. One way to address this problem is by creating an ability to perform run-time safety checks on CPS applications that can be used to record hazards, trigger emergency shutdowns (where doing so is safe), or perform other actions to minimize the consequences of an unsafe system behavior. Existing foundations for creating such a capability exist in the areas of software safety, temporal logic, model based diagnosis, and fault tolerance.", "num_citations": "5\n", "authors": ["1481"]}
{"title": "Building safer UGVs with run-time safety invariants\n", "abstract": " \u2022 The use of physical safety barriers and large stand-off distances is acceptable only during testing; it is infeasible for use in the real world.\u2022 We are developing safeguards to reduce dependence on physical barriers and large standoff distances for UGV operating alongside personnel in real, dynamic operations.", "num_citations": "5\n", "authors": ["1481"]}
{"title": "Software Defect masquerade Faults in Distributed Embedded Systems\n", "abstract": " Distributed embedded systems often consist of multiple nodes that communicate over a shared network. For such systems, dependable message delivery among nodes is crucial to overall system dependability. One threat to this dependable message delivery is a software defect masquerade fault, where a software defect causes one node or process to send a message as having come from another node or process. Unfortunately, many embedded system designs do not address this particular failure mode. This paper outlines what software defect masquerade faults are and why they are often ignored in current embedded systems. We also present preliminary research into methods to prevent them in embedded system design.", "num_citations": "5\n", "authors": ["1481"]}
{"title": "Synchronous time division multiplexing using jam-based frame synchronization\n", "abstract": " If a transceiver has a message to send during an idle medium condition, it transmits a jam pattern onto the medium for a predetermined time (based on maximum network propagation delay). If a transceiver detects a jamming pattern, it inhibits its own transmissions and waits for the end of the jamming pattern. If multiple transceivers begin jamming within a propagation delay of each other (within the network vulnerable time), their jamming transmissions will not destructively interfere with each other. When jamming ceases, all transceivers begin a time slice progression. Thus, the end of the jamming period when all transceivers have finished jamming serves as a network-wide synchronization for the start of an implicit token time slice progression.", "num_citations": "5\n", "authors": ["1481"]}
{"title": "32 bit RTX chip prototype\n", "abstract": " WISCTechnologies and Harris Semiconductor have jointly developed a 32-bit member of the Harris Real Time Express (RTX) family. The result is the RTX32P, a prototype implementation of the WISCTechnologies CPU/32 processor that was previously implemented using dis-crete components. The RTX32P is now fabricated and operational as a 2-chip microprocessor. It is being used as a research tool for a commercially available implementation now under development.", "num_citations": "5\n", "authors": ["1481"]}
{"title": "Writable instruction set stack oriented computers: The WISC concept\n", "abstract": " Conversely, modern programing practices stress the importance of non-sequential control flow and small procedures. The result of this hardware/software mismatch in today\" s general purpose computers is a costly, suboptimal, self-perpetuating compromise. The solution to this problem is to change the paradigm for the computing environment. The two central concepts required in this new paradigm are efficient procedure calls and a user-modifiable instruction set. Hardware that is fundamentally based on the concept of modularity will lead to changes in computer languages that will better support efficient software development. Software that is able to customize the hardware to meet critical application-specific processing requirements will be able to attempt more difficult tasks on less expensive hardware. Writable Instruction Set/Stack Oriented Computers (WISC computers) exploit the synergism between multiple\u00a0\u2026", "num_citations": "5\n", "authors": ["1481"]}
{"title": "Positive Trust Balance for Self-driving Car Deployment\n", "abstract": " The crucial decision about when self-driving cars are ready to deploy is likely to be made with insufficient lagging metric data to provide high confidence in an acceptable safety outcome. A Positive Trust Balance approach can help with making a responsible deployment decision despite this uncertainty. With this approach, a reasonable initial expectation of safety is based on a combination of a practicable amount of testing, engineering rigor, safety culture, and a strong commitment to use post-deployment operational feedback to further reduce uncertainty. This can enable faster deployment than would be required by more traditional safety approaches by reducing the confidence necessary at time of deployment in exchange for a more stringent requirement for Safety Performance Indicator (SPI) field feedback in the context of a strong safety culture.", "num_citations": "4\n", "authors": ["1481"]}
{"title": "Lessons learned in teaching a complex distributed embedded system project course\n", "abstract": " Teaching Cyber-Physical System (CPS) design requires covering significant breadth while ensuring students experience how all the pieces fit together. This paper describes a distributed elevator control system design project that addresses many of the areas required in a CPS project experience. Mapping project aspects to ABET accreditation areas frames a discussion of the course\u2019s treatment of CPS issues. The most important lesson learned is that students benefit from being immersed in and reflecting upon a carefully curated experience with a CPS engineering process rather than being turned loose to invent their own ad hoc approach to building complex systems.", "num_citations": "4\n", "authors": ["1481"]}
{"title": "Avoiding the top 43 embedded software risks\n", "abstract": " \u25aa Not simply \u201cyou should do this because it is best practice\u201d\u2026\u2026 but rather \u201cthis will cause a big problem for this project\u201d", "num_citations": "4\n", "authors": ["1481"]}
{"title": "Embedded software testing\n", "abstract": " \u2022 Failure to provide required behavior\u2022 Providing an incorrect behavior\u2022 Providing an undocumented behavior or behavior that is not required\u2022 Failure to conform to a design constraint (eg, timing, safety invariant)\u2022 Omission or defect in requirements/specification\u2022 Instance in which software performs as designed, but it\u2019s the \u201cwrong\u201d outcome\u2022 Any \u201creasonable\u201d complaint from a customer\u2022\u2026 other variations on this theme\u2026", "num_citations": "4\n", "authors": ["1481"]}
{"title": "Using CAD tools for embedded system design: Obstacles encountered in an automotive case study\n", "abstract": " Historically, digital system CAD research has emphasized increasing the size and complexity of the largest feasible design. However, the success of embedded system design efforts may depend more on design exibility and lifecycle cost optimization than on an ability to synthesize hardware containing millions of transistors. This paper reports the results of a case study using a commercial CAD tool to redesign an automotive electronics product. Although the tool was in fact able to perform the required design synthesis, the case study uncovered obstacles to the adoption of CAD tools by some classes of embedded system designers.", "num_citations": "4\n", "authors": ["1481"]}
{"title": "Doing the right thing\n", "abstract": " Codes of conduct were at the heart of guild organization in Europe in the Middle Ages.Were you competent to do something? Could you vouch for a product's quality? Would you promise to charge a fair price? Today, most engineers think of themselves as professionals, rather than as members of a craft. And as more and more engineers have been taken into the employ of large corporate or governmental organizations, very few still work as independents, certified and bound by guild conventions. Yet just about every engineer would agree that rules of right conduct exist and are more fundamental than technical standards or an employer's edicts. Those basic rules bear a spiritual kinship to the craft conventions of old\u2013even if they are not direct descendants of them the way the rules of war can be traced to medieval codes of chivalry, which maintained that, for example, no knight should kill another in battle who\u00a0\u2026", "num_citations": "4\n", "authors": ["1481"]}
{"title": "Performance of the harris rtx 2000 stack architecture versus the sun 4 sparc and the sun 3 m68020 architectures\n", "abstract": " This study compares a stack machine, the Harris RTX 2000, a RISC machine, the Sun 4/SPARC, and a CISC machine, the Sun3/M68020. An attempt is made to compare the generic features of each machine which are characteristic of their architectural classes as opposed to being characteristic of the individual machine only. Performance is compared based on execution of the Stanford Integer Benchmark series (12) and on interrupt response characteristics. The data indicates that, for these benchmarks, the RTX stack architecture approaches or exceeds the SPARC machine performance for such measures as total execution cycles required, clock cycles per instruction, native MIPS, static code size, and dynamic instruction count. The 68020 machine is by far the slowest of the three. When scaled to account for disparities in process technology, the RTX 2000 is as fast as (or faster than) the SPARC in actual program\u00a0\u2026", "num_citations": "4\n", "authors": ["1481"]}
{"title": "Bresenham Line-Drawing Algorithm\n", "abstract": " The task of drawing a straight line on a graphics screen is a fundamental building block for most computer graphics applications. Unfortunately, this capability is not included in many Forth implementations and, for that matter, is not included in the ROM support programs for many personal computers. This article will show you how to draw lines on almost any graphics display, and gives complete listings in MVP-FORTH.", "num_citations": "4\n", "authors": ["1481"]}
{"title": "Position paper: Deeply embedded survivability\n", "abstract": " This position paper identifies three significant research challenges in support of deeply embedded system survivability: achieving dependability at the enterprise/embedded interface gateway, finding a viable security patch approach for embedded systems, and surviving run-time software faults.", "num_citations": "3\n", "authors": ["1481"]}
{"title": "The Problem of Embedded Software in UCITA and Drafts of Revised Article 2\n", "abstract": " This is the first part of a two-part article. This one focuses primarily on UCITA; the next will focus more on Article 2. All references to UCITA are to the amended, commented draft dated July 28-August 4 2000, at www. law. upenn. edu/bll/ulc/ucita/ucita1200. htm.", "num_citations": "3\n", "authors": ["1481"]}
{"title": "Challenges in embedded systems research and education\n", "abstract": " Challenges in Embedded Systems Research & Education Page 1 Challenges in Embedded Systems Research & Education Philip Koopman koopman@cmu.edu - http://www.ices.cmu.edu/koopman Institute for Complex Engineered Systems & Electrical Computer ENGINEERING Page 2 Circa 1980: What in the world are you going to do with all those computers? It's not as if you want one in every doorknob! - Danny Hillis, circa 1980, as told by Guy Steele at 1996 CMU SCS commencement 1981: Atari 800 used by hotel control startup company Page 3 3 Overview 20 Years Later, What\u2019s Left To Research? \u25c6 What\u2019s an embedded system? \u25c6 Why can\u2019t you just design them like desktop systems? \u2022 Or, how to succeed in a research project and find out you were asking the wrong question \u25c6 What\u2019s coming next? \u2022 It\u2019s not only stranger than we imagine, It\u2019s probably stranger than we can imagine. \u25c6 What does it take to do \u2026", "num_citations": "3\n", "authors": ["1481"]}
{"title": "TIGRE: Combinator Graph Reduction on the RTX 2000\n", "abstract": " My dissertation work investigated an efficient evaluation technique for lazy functional programs based on combinator graph reduction. Graph reduction is widely believed to be slow and inefficient, but an abstract machine called the Threaded Interpretive Graph Reduction Engine (TIGRE) achieves a substantial speedup over previous reduction techniques. The runtime system of TIGRE is a threaded system that permits self-modifying program execution with compiler-guaranteed safety. This paper describes an implementation of TIGRE in Forth for the Harris RTX2000 stack processor.", "num_citations": "3\n", "authors": ["1481"]}
{"title": "The big picture for self-driving car safety\n", "abstract": " \u25cf 17V-713: Engine does not reduce power due to ESP software defect\u25cf 17V-686 and MANY others: Airbags disabled\u25cf 15V-569: Unexpected steering motion causes loss of control\u25cf 15V-460 and others: Airbags deploy when they should not\u25cf 15V-145: Unattended vehicle starts engine\u2192 carbon monoxide poisoning\u25cf 14V-370: Turns off headlights when driving\u25cf 14V-204: 1.5 seconds reverse while displaying Drive Voluntary Recalls:\u25cf 2018 hybrid engine stall at high speeds (https://bloom. bg/2y21T71)\u25cf 2014 sudden unintended acceleration (https://goo. gl/R9zgL1)", "num_citations": "2\n", "authors": ["1481"]}
{"title": "Learning adaptive sampling distributions for motion planning by self-imitation\n", "abstract": " Sampling based motion planning algorithms are widely used due to their effectiveness on problems with large state spaces by incremental tree growth in conjunction with uniform, random sampling. The major bottleneck in the performance of such algorithms is the amount of collision checks performed, which in turns depends on the sampling distribution itself. In this work, we present a framework to learn an adaptive, non-stationary sampling distribution which explicitly minimizes the search effort, given by the amount of collision checks performed. Our framework models the sequential nature of the problem by leveraging both the instantaneous search tree over the robot configuration space, as well as the workspace environment, by encoding them with a conditional variational auto-encoder, to learn a stochastic sampling policy. We encode the workspace environment with a convolutional network, and the configuration space planning tree with a recurrent neural network. We introduce an approximate oracle which can return multiple label samples for a partially solved planning problem, by forward simulating it. We use an imitation via iterative supervised learning framework to learn a stochastic sampling policy. We call this self-supervised imitation of an oracle generated by forward simulation as self-imitation. We validate our approach on a 4D kinodynamic helicopter planning problem with glideslope and curvature constraints, and a 2D holonomic problem.", "num_citations": "2\n", "authors": ["1481"]}
{"title": "Ride-through for autonomous vehicles\n", "abstract": " Safety critical systems often have shutdown mechanisms to bring the system to a safe state in the event of a malfunction. We ex- amine the use of ride-through, a technique to reduce the frequency of safety shutdowns by allowing small transient violations of safety rules. An illustrative example of enforcing a speed limit for an autonomous vehicle shows that using a rate-limited ride-through bound permits a tighter safety limit on speed than a xed threshold without creating false alarm shutdowns. Adding state machines to select speci c safety bounds based on vehicle state accommodates expected control system transients. Testing these principles on an autonomous utility vehicle resulted in im- proved detection of speed limit violations and shorter shutdown stopping distances without needing to increase the false alarm shutdown rate.", "num_citations": "2\n", "authors": ["1481"]}
{"title": "Tutorial: Checksum and CRC data integrity techniques for aviation\n", "abstract": " \u2013Motivation\u2013why isn\u2019t this a solved problem?\u2013Parity computations as an example\u2013Error code construction and evaluation (without scary math)\u2013Example using parity codes", "num_citations": "2\n", "authors": ["1481"]}
{"title": "Distributed embedded systems\n", "abstract": " 18-540 Distributed Embedded Systems Page 1 18-540 Distributed Embedded Systems Prof. Philip Koopman Fall, 2000 Lecture: Mon/Wed 12:30-2:20 PM -- PH A18A Recitations: Fridays 1:30-2:20 -- PH A18C Recommended Text: Kopetz, Real-Time Systems: design principles for distributed embedded applications, Kluwer Academic Publishers Page 2 18-540 Distributed Embedded Systems x Based on lecture notes & practitioner-oriented papers \u2022 Book offers additional info, but is not testable beyond lecture coverage x Course objectives detailed on web pages \u2022 System Engineering \u2013 Requirements, design, verification/validation, certification, management-lite \u2022 System Architecture \u2013 Modeling/Abstraction, Design Methodology, Business Issues \u2022 Embedded Systems \u2013 Design Issues, scheduling, time, distributed implementations, performance \u2022 Embedded Networks \u2013 Protocol mechanisms, performance, CAN, TTP, \u2026", "num_citations": "2\n", "authors": ["1481"]}
{"title": "Data Network Evaluation Criteria Handbook\n", "abstract": " Databus and data network technology continues to play an ever-increasing role in aviation digital electronics architectures throughout the range of aviation markets.  The evolution of integrated modular aviation digital electronics architectures comprising multiple subsystems integrated into single and redundant data networks is increasing the influence of data networking.  The criticality of data networks has previously led avionics manufacturers and aircraft original equipment manufacturers to design specific aerospace solutions to meet their requirements.  In recent years, cost challenges have led to the adoption of commercial off-the-shelf (COTS) communication solutions in avionics.  Although attractive from a cost perspective, the adoption of COTS presents certification issues, particularly as the complexity and increased leverage of technology continues to evolve.  Subtleties may escape the system designer and leave dependability holes.  An example is the interference of the Controller Area Network bit-error stuffing mechanism with message cyclic redundancy code coverage.  COTS can be adopted as is, or with fixes added so it is a better fit for dependable avionics requirements, i.e., the adaptation of Ethernet to Aeronautical Radio, Incorporated (ARINC\u00ae) Part 7.  Helping this trend is the arrival of \u201csafety-critical COTS\u201d in the marketplace, particularly in automobile and process-control areas.  However, even with designed-for-purpose technology, it is necessary to ensure that the technology has dependability consistent with real-world requirements and redundancy management schemes.  Development and evaluation of aviation digital\u00a0\u2026", "num_citations": "2\n", "authors": ["1481"]}
{"title": "Deeply Embedded Survivability\n", "abstract": " This position paper identifies three significant research challenges in support of deeply embedded system survivability achieving dependability at the enterpriseembedded interface gateway, finding a viable security patch approach for embedded systems, and surviving run-time software faults.Descriptors:", "num_citations": "2\n", "authors": ["1481"]}
{"title": "A period-based group membership strategy for nodes of TDMA networks\n", "abstract": " Group membership provides strong guarantees for safety-critical fieldbus systems. However, using a single group for all messages provides an unnecessarily high risk of temporary node outages in the face of transient faults. Using groups based on virtual nodes that are divided by message period can increase the availability for the most critical, high-speed network messages with potentially reasonable bandwidth cost and without giving up the assurances of strong group membership algorithms.", "num_citations": "2\n", "authors": ["1481"]}
{"title": "Self-Healing vs. Fault Tolerance\n", "abstract": " Self-Healing vs. Fault Tolerance Page 1 Self-Healing vs. Fault Tolerance & Electrical Computer ENGINEERING Phil Koopman Carnegie Mellon University WADS, May 2003 Page 2 5 Overview x Perhaps this isn\u2019t even the right question \u2022 But people are going to ask it anyway x Is some Fault Tolerance also Self Healing? \u2013 Yes x Is all FT also Self Healing \u2013 No x Is all Self Healing also FT \u2013 Maybe \u2022 Assume \u201cyes\u201d until proven otherwise? Page 3 6 Is This Even The Right Question? x \u201cFault Tolerance\u201d is an emergent property \u2022 Systems are fault tolerant (or not), to varying degrees \u2022 It is perhaps a measurable property \u2013 Fault injection experiments to see which faults can really be tolerated \u2013 But this is a difficult area x \u201cSelf Healing\u201d seems like an approach (or point of view) \u2022 What is an \u201cinjury\u201d, and what isn\u2019t? \u2022 Are there unifying themes to \u201cself-healing\u201d \u2022 Are there self-healing outcomes that are not fault tolerance? \u2013 (That are \u2026", "num_citations": "2\n", "authors": ["1481"]}
{"title": "Roses: Robust self-configuring embedded systems\n", "abstract": " As highly distributed computers are embedded into everyday products, it is becoming vital to ensure that systems degrade gracefully rather than break due to software brittleness. For example, the failure of a single component shouldn\u2019t cause an entire system to fail, but instead cause a modest reduction in capabilities in keeping with the severity of the component failure. Graceful degradation has traditionally been viewed as a fault tolerance issue. Redundant components and fail-over code are the usual approaches to managing failures. These approaches can be made to work, but are too expensive for many applications, and tend to scale poorly as the complexity of a system increases. Instead, we view graceful degradation as a novel application of product family architecture approaches. If a product contains dozens or hundreds of processors contained within distributed sensors, actuators, and other components\u00a0\u2026", "num_citations": "2\n", "authors": ["1481"]}
{"title": "Workshop on Dependability Benchmarking.\n", "abstract": " Classical features such as raw performance and functionality have long driven the computer industry to improve their products. But now, dependability and maintainability are seen as equally important. While there are relatively straightforward ways to evaluate and compare performance and functionality of different systems or components, the evaluation of dependability and maintainability features is much more difficult. Among the challenges that must be addressed are: incorporating the effects of software failures, characterizing the dependability of opaque off-the-shelf hardware and software components, including the effects of typical maintenance, operational, and configuration management procedures, and accommodating the fact that different application areas have different requirements for the various factors influencing dependability. The goal of the Dependability Benchmarking Workshop is to provide a forum for the computer industry and academia to discuss problems associated with the evaluation and characterization of dependability and maintainability of components and computer systems. The identification of dependability benchmarking measures and the essential technologies for dependability benchmarking, including both experimental measuring and modeling technologies, are central aspects of this large discussion meant to garner ideas on practical and cost-effective ways to evaluate dependability and maintainability features. This workshop is the outcome of the first two years of work of the IFIP 10.4 WG SIG on Dependability Benchmarking (SIGDeB)[SIGDeB02]. That SIG was formed in November 1999 under the IFIP 10.4\u00a0\u2026", "num_citations": "2\n", "authors": ["1481"]}
{"title": "Verification, Validation & Certification\n", "abstract": " \u2022 Unit test\u2013testing small pieces of code; done by programmer\u2022 Module/functional test\u2013testing at API level; done by testing group\u2022 Integration test\u2013testing pieces working together; done by testing group\u2022 Acceptance test\u2013testing whole system; done by customer (or surrogate)\u2022 Beta test\u2013letting a few customers use product before full production\u2022 Regression test\u2013make sure changes haven\u2019t re-activated old bugs", "num_citations": "2\n", "authors": ["1481"]}
{"title": "Mission Failure Probability Calculations for Critical Function Mechanizations in the Automated Highway System\n", "abstract": " Reliability analysis is an important part of the Automated Highway System (AHS) research and development. In 1994, Honeywell released the \u201cMalfunction Management Activity Area Report for AHS Health Management Precursor System Analysis\u201d which showed a reliability analysis of the AHS vehicle system. However, the Honeywell report does not describe in detail how they arrived at their answers. In this paper, we will be providing a more detailed analysis of how Honeywell arrived at the probability of failure vs. time plots for both the different subsystems in an AHS vehicle and the overall system. Matlab programs were written to calculate system reliabilities for series and parallel systems. In performing the analysis, there were several places as stated in the paper where our answers differed from Honeywell\u2019s answers. Because of these differences, our results and conclusions are different from Honeywell\u2019s results and conclusions. Based on a 95% test coverage and a system failure rate limit of 1 x 10-6 failures per mission, Honeywell determined that triplex redundancy for all subsystems is necessary to meet these requirements. However, for the purposes of our study, and assuming 100% test coverage and also a system failure rate limit of 1 x 10-6 failures per mission, we determined that duplex redundancy will result in a mission time of 3.5 hours, which is still satisfactory.", "num_citations": "2\n", "authors": ["1481"]}
{"title": "Real-time performance of the HARRIS RTX 2000 stack architecture versus the Sun 4 SPARC and the Sun 3 M68020 architectures with a proposed real-time performance benchmark\n", "abstract": " This study compares a stack machine, the Harris RTX 2000, a RISC machine, the Sun 4/SPARC, and a CISC machine, the Sun3/M68020 for real-time applications. An attempt is made to compare the generic features of each machine which are characteristic of their architectural classes as opposed to being characteristic of the individual machine only. Performance is compared based on execution of the Stanford Integer Benchmark series and on interrupt response characteristics. A simple Real-Time Performance BenchMark which integrates raw compute power and interrupt response is proposed, then used to estimate the real-time performance of the machines. It is shown that the RTX 2000 outperforms the others for applications which have a very large number of interrupts per second, confirming that stack architectures should perform well in real-time applications such as high-speed computer communication\u00a0\u2026", "num_citations": "2\n", "authors": ["1481"]}
{"title": "\u2018The Impact of Rent\u2019s Rule on Massive Parallelism,\u2019\u2019\n", "abstract": " Rent\u2019s Rule is an empirical relationship stating that the number of pins on a chip increases as the number of'. gates on the chip increases. In massively parallel systems, every extra pin is multiplied by the number of processors.", "num_citations": "2\n", "authors": ["1481"]}
{"title": "RTX 4000\n", "abstract": " Harris Semiconductor has begun design of the RTX 4000, a 32-bit member of the Real Time Express (RTX) product family. The RTX 4000 will be a 32-bit stack processor optimized for real time control applications, with similar design objectives as the RTX", "num_citations": "2\n", "authors": ["1481"]}
{"title": "Software quality, dependability and safety in embedded systems\n", "abstract": " We often trust embedded systems with mission-critical functions, and even our own lives. But the designers of such systems (and especially their managers) are often domain experts who have not been formally trained in software development. While many embedded systems work well, in my design reviews I frequently see problems ranging from the subtle to the catastrophic. I have identified commonly occurring technical, process, and quality assurance issues based on my experience performing more than 135 industry design reviews. Common problems include a lack of embedded-specific software engineering skills, software process gaps, and a failure to appreciate that more than just product-level testing is required to create high quality software. Most of these problems cannot simply be fixed by adopting a tool, but rather require a change of culture and perspective in engineering organizations. All too often\u00a0\u2026", "num_citations": "1\n", "authors": ["1481"]}
{"title": "On being the bearer of bad news\n", "abstract": " \" Though it be honest, it is never good to bring bad news; give to a gracious message a host of tongues, but let ill tidings tell themselves when they be felt.\" Antony and Cleopatra, William Shakespeare ngineers are sometimes in the position of being the bearers of bad news. An experienced engineer will not report a problem empty-handed-it is always wise to have some idea of a solution to present to management. Nonetheless, finding a major problem that disrupts the execution of a project plan can make life difficult for an engineer.", "num_citations": "1\n", "authors": ["1481"]}
{"title": "Graceful Degradation in Distributed Embedded Systems\n", "abstract": " As embedded systems become more distributed they provide more flexibility, the potential for greater functionality, and, unfortunately, more pieces to break. But what if there were a way to turn this proliferation of small processors into a reliability asset instead of vulnerability? What if when one component broke, the rest of the system kept working with minimal disruption? And what if we could do that elegantly, rather than just by throwing money at the problem with brute-force redundancy? We think that we can accomplish this as part of a long-term research project on the topic of graceful degradation.A gracefully degradable system is one in which the user does not see errors except, perhaps, as a reduced level of system functionality\u2014quite a contrast to most of the systems we often see. We all have heard horror stories of automobiles that need expensive trips to the shop at inconvenient times to replace $1.48 parts. Or perhaps a home security system doesn't work because a single window sensor has failed open. We like to call these systems\" disgracefully degrading.\" These systems should still accomplish something useful\u2014admittedly not at the same performance levels. Given a choice, we'd prefer not to call a tow truck. And the security system should still work against burglars who don't know which window to enter.", "num_citations": "1\n", "authors": ["1481"]}
{"title": "Robustness Testing and Hardening of CORBA ORB Implementations\n", "abstract": " Before using CORBA (Common Object Request Broker Architecture) applications in mission-critical scenarios, it is important to understand the robustness of the Object Request Broker (ORB) being used, which forms the platform for CORBA applications. We have extended the Ballista software testing technique to test the exception-handling robustness of C++ ORB client-side application interfaces, and have tested two major versions of three ORB implementations on two operating systems, yielding robustness failure rates ranging from 26% to 42%. To improve ORB robustness, we also introduce a probing method to harden object and pseudo-object related data types against exceptional inputs. A simple probing method for omniORB 2.8 has proven to be effective in eliminating simple cases of robustness failures found during testing. These results suggest that CORBA implementations currently have significant robustness vulnerabilities, but that the problems largely can be overcome with better exception handling approaches.", "num_citations": "1\n", "authors": ["1481"]}
{"title": "Thoughts on System Architecture Research & Education\n", "abstract": " Our society has an insatiable appetite for complex systems, and such systems are increasingly becoming critical to our daily lives. Designers routinely attempt to implement systems of overly ambitious complexity. Sometimes such attempts fail, resulting in mere economic loss. Sometimes projects succeed (by luck and brute force), but yield short-lived systems that must be replaced quickly. And, in arguably the worst case, sometimes unfit systems are declared successes and adopted for use in critical applications even when it is inappropriate to do so. One does not have to look far to see examples of all three classes of outcomes today. In the future, the stakes will be raised dramatically because of the increasing connectedness of our world\u2019s people, economy and infrastructure. Traditionally, the role of engineers has often been to build systems that are as ambitious as possible, get them mostly working, and then work on patches and extensions after the fact. True, many systems are limited enough in complexity that they can be built well most of the time. But, because of the thirst for ever-increasing complexity, a system architect often perceives these tractable systems as components (things that we know how to get right) rather than systems (things that we have to think about how to build).", "num_citations": "1\n", "authors": ["1481"]}
{"title": "Obstacles to Using CAD Tools for Embedded System Design: an automotive case study\n", "abstract": " Historically, Computer Aided Design (CAD) research for digital electronics design has emphasized support for the largest and most technically difficult projects. However, the success of many embedded system design efforts depends more on system-level and lifecycle cost optimization than on an ability to synthesize hardware containing millions of transistors. Thus, existing CAD tools may not offer embedded system developers the capabilities they need. This paper reports the results of a case study using a digital design synthesis tool to redesign an automotive electronics product. Although the tool was in fact able to perform the required design synthesis, the case study uncovered obstacles to the adoption of CAD tools by some clases of embedded system designers. Problems having to do with electronics design, system-level design, and engineering/business processes are reported. At least some of these\u00a0\u2026", "num_citations": "1\n", "authors": ["1481"]}
{"title": "Engineering workstations-ICs: the brains of a workstation\n", "abstract": " Fast central processors and their supporting team of complementary chips, including graphics, I/O, and cache memory ICs, are reviewed. The trend to higher levels of system integration, with more functions or capacity on each chip, is discussed. New architectures are examined.< >", "num_citations": "1\n", "authors": ["1481"]}
{"title": "Embedded control as a path to Forth acceptance\n", "abstract": " This paper presents a strategy for promoting Forth acceptance based on a narrow focus of concentration on a target application area. Theproposed goal is to make Forth the language of choice for embedded real time control systems, and thus establish afoothold in the general computing community.INTRODUCTION.", "num_citations": "1\n", "authors": ["1481"]}
{"title": "An architecture for combinator graph reduction\n", "abstract": " Functional programming offers a new way of writing programs and a new way of thinking about problem solving. Claimed advantages of functional programs are that they are amenable to automatic verification techniques, are easier to write, and are more reliable than other types of programs. Lazy functional languages provide powerful features such as implicit coroutining and support for infinite length data structures. Furthermore, it is possible that lazy functional languages will provide an easy path to exploit parallelism without programmer intervention.  A major problem with lazy functional languages is that they are notoriously slow, often as much as two orders of magnitude slower than \"eager\" functional languages and imperative languages. This speed problem has hindered exploration of the strengths and weaknesses of functional programming languages. This thesis investigates an efficient evaluation\u00a0\u2026", "num_citations": "1\n", "authors": ["1481"]}
{"title": "Compiling for direct execution of combinator graphs\n", "abstract": " We have designed and implemented an abstract machine called TIGRE for combinator graph reduction. TIGRE supports an assembly language that can be easily expanded into native code for both conventional and special-purpose architectures. Furthermore, optimizations can be ma\u0111c Over the assembly instructions that take advantage of special features of the architecture, such as long instruction pipelines and caches. The results of compile time analyses such as strictness analysis can also be usefully incorporated.", "num_citations": "1\n", "authors": ["1481"]}
{"title": "Microcoded vs. Hard-Wired Control\n", "abstract": " THE INSTRUCTION decoding and exe-cution control sections of modern com-puters are prime areas for using programmable hardware. Two of the most widely used methods for designing CPU control sections in microprocessors, minicomputers, and mainframes are microcode and hard-wired logic. Each method has its advantages, and both are natural applications for programmable hardware devices.Architectural Description I'll start by giving the specifications for a simple computer architecture, then walk through the implementation of this architecture using both microcoded and hardwired design strategies. While both approaches require the same description and specification groundwork, they use different schemes to generate control signals. I will examine the CPU architecture of Toy, a fictitious computer designed especially for this article. The CPU has an accumulator (ACC), an arithmetic logic unit (ALU), an\u00a0\u2026", "num_citations": "1\n", "authors": ["1481"]}
{"title": "MVP microcoded CPU/16: architecture\n", "abstract": " The MVP Microcoded CPU/16 is a 16-bit coprocessor board that directly executes high level stack-oriented programs. The CPU/16 may be micro-programmed to execute any stackoriented language. FORTH was used as the initial implementation language to reduce development time and costs.", "num_citations": "1\n", "authors": ["1481"]}