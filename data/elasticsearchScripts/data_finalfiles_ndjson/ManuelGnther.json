{"title": "Bob: a free signal processing and machine learning toolbox for researchers\n", "abstract": " Bob is a free signal processing and machine learning toolbox originally developed by the Biometrics group at Idiap Research Institute, Switzerland. The toolbox is designed to meet the needs of researchers by reducing development time and efficiently processing data. Firstly, Bob provides a researcher-friendly Python environment for rapid development. Secondly, efficient processing of large amounts of multimedia data is provided by fast C++ implementations of identified bottlenecks. The Python environment is integrated seamlessly with the C++ library, which ensures the library is easy to use and extensible. Thirdly, Bob supports reproducible research through its integrated experimental protocols for several databases. Finally, a strong emphasis is placed on code clarity, documentation, and thorough unit testing. Bob is thus an attractive resource for researchers due to this unique combination of ease of use\u00a0\u2026", "num_citations": "174\n", "authors": ["865"]}
{"title": "MOON: A mixed objective optimization network for the recognition of facial attributes\n", "abstract": " Attribute recognition, particularly facial, extracts many labels for each image. While some multi-task vision problems can be decomposed into separate tasks and stages, e.g., training independent models for each task, for a growing set of problems joint optimization across all tasks has been shown to improve performance. We show that for deep convolutional neural network (DCNN) facial attribute extraction, multi-task optimization is better. Unfortunately, it can be difficult to apply joint optimization to DCNNs when training data is imbalanced, and re-balancing multi-label data directly is structurally infeasible, since adding/removing data to balance one label will change the sampling of the other labels. This paper addresses the multi-label imbalance problem by introducing a novel mixed objective optimization network (MOON) with a loss function that mixes multiple task objectives with domain adaptive re\u00a0\u2026", "num_citations": "168\n", "authors": ["865"]}
{"title": "Genetic determination of human facial morphology: links between cleft-lips and normal variation\n", "abstract": " Recent genome-wide association studies have identified single nucleotide polymorphisms (SNPs) associated with non-syndromic cleft lip with or without cleft palate (NSCL/P), and other previous studies showed distinctly differing facial distance measurements when comparing unaffected relatives of NSCL/P patients with normal controls. Here, we test the hypothesis that genetic loci involved in NSCL/P also influence normal variation in facial morphology. We tested 11 SNPs from 10 genomic regions previously showing replicated evidence of association with NSCL/P for association with normal variation of nose width and bizygomatic distance in two cohorts from Germany (N= 529) and the Netherlands (N= 2497). The two most significant associations found were between nose width and SNP rs1258763 near the GREM1 gene in the German cohort (P= 6\u00d7 10\u2212 4), and between bizygomatic distance and SNP\u00a0\u2026", "num_citations": "123\n", "authors": ["865"]}
{"title": "A Survey of Stealth Malware Attacks, Mitigation Measures, and Steps Toward Autonomous Open World Solutions\n", "abstract": " As our professional, social, and financial existences become increasingly digitized and as our government, healthcare, and military infrastructures rely more on computer technologies, they present larger and more lucrative targets for malware. Stealth malware in particular poses an increased threat because it is specifically designed to evade detection mechanisms, spreading dormant, in the wild for extended periods of time, gathering sensitive information or positioning itself for a high-impact zero-day attack. Policing the growing attack surface requires the development of efficient anti-malware solutions with improved generalization to detect novel types of malware and resolve these occurrences with as little burden on human experts as possible. In this paper, we survey malicious stealth technologies as well as existing solutions for detecting and categorizing these countermeasures autonomously. While machine\u00a0\u2026", "num_citations": "111\n", "authors": ["865"]}
{"title": "Reducing network agnostophobia\n", "abstract": " Agnostophobia, the fear of the unknown, can be experienced by deep learning engineers while applying their networks to real-world applications. Unfortunately, network behavior is not well defined for inputs far from a networks training set. In an uncontrolled environment, networks face many instances that are not of interest to them and have to be rejected in order to avoid a false positive. This problem has previously been tackled by researchers by either a) thresholding softmax, which by construction cannot return \"none of the known classes\", or b) using an additional background or garbage class. In this paper, we show that both of these approaches help, but are generally insufficient when previously unseen classes are encountered. We also introduce a new evaluation metric that focuses on comparing the performance of multiple approaches in scenarios where such unseen classes or unknowns are encountered. Our major contributions are simple yet effective Entropic Open-Set and Objectosphere losses that train networks using negative samples from some classes. These novel losses are designed to maximize entropy for unknown inputs while increasing separation in deep feature space by modifying magnitudes of known and unknown samples. Experiments on networks trained to classify classes from MNIST and CIFAR-10 show that our novel loss functions are significantly better at dealing with unknown inputs from datasets such as Devanagari, NotMNIST, CIFAR-100, and SVHN.", "num_citations": "108\n", "authors": ["865"]}
{"title": "A novel approach to the detection of acromegaly: accuracy of diagnosis by automatic face classification\n", "abstract": " Context:           The delay between onset of first symptoms and diagnosis of the acromegaly is 6\u201310 yr. Acromegaly causes typical changes of the face that might be recognized by face classification software.                             Objective:           The objective of the study was to assess classification accuracy of acromegaly by face-classification software.                             Design:           This was a diagnostic study.                             Setting:           The study was conducted in specialized care.                             Participants:           Participants in the study included 57 patients with acromegaly (29 women, 28 men) and 60 sex- and age-matched controls.                             Interventions:           We took frontal and side photographs of the faces and grouped patients into subjects with mild, moderate, and severe facial features of acromegaly by overall impression. We then analyzed all pictures using computerized similarity analysis\u00a0\u2026", "num_citations": "97\n", "authors": ["865"]}
{"title": "Towards Robust Deep Neural Networks with BANG\n", "abstract": " Machine learning models, including state-of-the-art deep neural networks, are vulnerable to small perturbations that cause unexpected classification errors. This unexpected lack of robustness raises fundamental questions about their generalization properties and poses a serious concern for practical deployments. As such perturbations can remain imperceptible - the formed adversarial examples demonstrate an inherent inconsistency between vulnerable machine learning models and human perception - some prior work casts this problem as a security issue. Despite the significance of the discovered instabilities and ensuing research, their cause is not well understood and no effective method has been developed to address the problem. In this paper, we present a novel theory to explain why this unpleasant phenomenon exists in deep neural networks. Based on that theory, we introduce a simple, efficient, and effective training approach, Batch Adjusted Network Gradients (BANG), which significantly improves the robustness of machine learning models. While the BANG technique does not rely on any form of data augmentation or the utilization of adversarial images for training, the resultant classifiers are more resistant to adversarial perturbations while maintaining or even enhancing the overall classification performance.", "num_citations": "76\n", "authors": ["865"]}
{"title": "Toward open-set face recognition\n", "abstract": " Much research has been conducted on both face identification and face verification, with greater focus on the latter. Research on face identification has mostly focused on using closed-set protocols, which assume that all probe images used in evaluation contain identities of subjects that are enrolled in the gallery. Real systems, however, where only a fraction of probe sample identities are enrolled in the gallery, cannot make this closed-set assumption. Instead, they must assume an open set of probe samples and be able to reject/ignore those that correspond to unknown identities. In this paper, we address the widespread misconception that thresholding verification-like scores is a good way to solve the open-set face identification problem, by formulating an open-set face identification protocol and evaluating different strategies for assessing similarity. Our open-set identification protocol is based on the canonical labeled faces in the wild (LFW) dataset. Additionally to the known identities, we introduce the concepts of known unknowns (known, but uninteresting persons) and unknown unknowns (people never seen before) to the biometric community. We compare three algorithms for assessing similarity in a deep feature space under an open-set protocol: thresholded verification-like scores, linear discriminant analysis (LDA) scores, and an extreme value machine (EVM) probabilities. Our findings suggest that thresholding EVM probabilities, which are open-set by design, outperforms thresholding verification-like scores.", "num_citations": "58\n", "authors": ["865"]}
{"title": "AFFACT: Alignment-free facial attribute classification technique\n", "abstract": " Facial attributes are soft-biometrics that allow limiting the search space, e.g., by rejecting identities with non-matching facial characteristics such as nose sizes or eyebrow shapes. In this paper, we investigate how the latest versions of deep convolutional neural networks, ResNets, perform on the facial attribute classification task. We test two loss functions: the sigmoid cross-entropy loss and the Euclidean loss, and find that for classification performance there is little difference between these two. Using an ensemble of three ResNets, we obtain the new state-of-the-art facial attribute classification error of 8.00 % on the aligned images of the CelebA dataset. More significantly, we introduce the Alignment-Free Facial Attribute Classification Technique (AFFACT), a data augmentation technique that allows a network to classify facial attributes without requiring alignment beyond detected face bounding boxes. To our best\u00a0\u2026", "num_citations": "54\n", "authors": ["865"]}
{"title": "The 2013 Face Recognition Evaluation in Mobile Environment\n", "abstract": " Automatic face recognition in unconstrained environments is a challenging task. To test current trends in face recognition algorithms, we organized an evaluation on face recognition in mobile environment. This paper presents the results of 8 different participants using two verification metrics. Most submitted algorithms rely on one or more of three types of features: local binary patterns, Gabor wavelet responses including Gabor phases, and color information. The best results are obtained from UNILJ-ALP, which fused several image representations and feature types, and UC-HU, which learns optimal features with a convolutional neural network. Additionally, we assess the usability of the algorithms in mobile devices with limited resources.", "num_citations": "53\n", "authors": ["865"]}
{"title": "Learning and the unknown: Surveying steps toward open world recognition\n", "abstract": " As science attempts to close the gap between man and machine by building systems capable of learning, we must embrace the importance of the unknown. The ability to differentiate between known and unknown can be considered a critical element of any intelligent self-learning system. The ability to reject uncertain inputs has a very long history in machine learning, as does including a background or garbage class to account for inputs that are not of interest. This paper explains why neither of these is genuinely sufficient for handling unknown inputs\u2013uncertain is not unknown, and unknowns need not appear to be uncertain to a learning system. The past decade has seen the formalization and development of many open set algorithms, which provably bound the risk from unknown classes. We summarize the state of the art, core ideas, and results and explain why, despite the efforts to date, the current techniques are genuinely insufficient for handling unknown inputs, especially for deep networks.", "num_citations": "47\n", "authors": ["865"]}
{"title": "Facial Attributes: Accuracy and Adversarial Robustness\n", "abstract": " Facial attributes, emerging soft biometrics, must be automatically and reliably extracted from images in order to be usable in stand-alone systems. While recent methods extract facial attributes using deep neural networks (DNNs) trained on labeled facial attribute data, the robustness of deep attribute representations has not been evaluated. In this paper, we examine the representational stability of several approaches that recently advanced the state of the art on the CelebA benchmark by generating adversarial examples formed by adding small, non-random perturbations to inputs yielding altered classifications. We show that our fast flipping attribute (FFA) technique generates more adversarial examples than traditional algorithms, and that the adversarial robustness of DNNs varies highly between facial attributes. We also test the correlation of facial attributes and find that only for related attributes do the formed\u00a0\u2026", "num_citations": "44\n", "authors": ["865"]}
{"title": "Are facial attributes adversarially robust?\n", "abstract": " Facial attributes are emerging soft biometrics that have the potential to reject non-matches, for example, based on mismatching gender. To be usable in stand-alone systems, facial attributes must be extracted from images automatically and reliably. In this paper, we propose a simple yet effective solution for automatic facial attribute extraction by training a deep convolutional neural network (DCNN) for each facial attribute separately, without using any pre-training or dataset augmentation, and we obtain new state-of-the-art facial attribute classification results on the CelebA benchmark. To test the stability of the networks, we generated adversarial images - formed by adding imperceptible non-random perturbations to original inputs which result in classification errors - via a novel fast flipping attribute (FFA) technique. We show that FFA generates more adversarial examples than other related algorithms, and that\u00a0\u2026", "num_citations": "42\n", "authors": ["865"]}
{"title": "Continuously Reproducing Toolchains in Pattern Recognition and Machine Learning Experiments\n", "abstract": " Pattern recognition and machine learning research work often contains experimental results on real-world data, which corroborates hypotheses and provides a canvas for the development and comparison of new ideas. Results, in this context, are typically summarized as a set of tables and figures, allowing the comparison of various methods, highlighting the advantages of the proposed ideas. Unfortunately, result reproducibility is often an overlooked feature of original research publications, competitions, or benchmark evaluations. The main reason for such a gap is the complexity on the development of software associated with these reports. Software frameworks are difficult to install, maintain, and distribute, while scientific experiments often consist of many steps and parameters that are difficult to report. The increasingly rising complexity of research challenges make it even more difficult to reproduce experiments and results. In this paper, we emphasize that a reproducible research work should be repeatable, shareable, extensible, and stable, and discuss important lessons we learned in creating, distributing, and maintaining software and data for reproducible research in pattern recognition and machine learning. We focus on a specific use-case of face recognition and describe in details how we can make the recognition experiments reproducible in practice.", "num_citations": "41\n", "authors": ["865"]}
{"title": "Are accuracy and robustness correlated\n", "abstract": " Machine learning models are vulnerable to adversarial examples formed by applying small carefully chosen perturbations to inputs that cause unexpected classification errors. In this paper, we perform experiments on various adversarial example generation approaches with multiple deep convolutional neural networks including Residual Networks, the best performing models on ImageNet Large-Scale Visual Recognition Challenge 2015. We compare the adversarial example generation techniques with respect to the quality of the produced images, and measure the robustness of the tested machine learning models to adversarial examples. Finally, we conduct large-scale experiments on cross-model adversarial portability. We find that adversarial examples are mostly transferable across similar network topologies, and we demonstrate that better machine learning models are less vulnerable to adversarial examples.", "num_citations": "41\n", "authors": ["865"]}
{"title": "Automated syndrome detection in a set of clinical facial photographs\n", "abstract": " Computer systems play an important role in clinical genetics and are a routine part of finding clinical diagnoses but make it difficult to fully exploit information derived from facial appearance. So far, automated syndrome diagnosis based on digital, facial photographs has been demonstrated under study conditions but has not been applied in clinical practice. We have therefore investigated how well statistical classifiers trained on study data comprising 202 individuals affected by one of 14 syndromes could classify a set of 91 patients for whom pictures were taken under regular, less controlled conditions in clinical practice. We found a classification accuracy of 21% percent in the clinical sample representing a ratio of 3.0 over a random choice. This contrasts with a 60% accuracy or 8.5 ratio in the training data. Producing average images in both groups from sets of pictures for each syndrome demonstrates that the\u00a0\u2026", "num_citations": "41\n", "authors": ["865"]}
{"title": "An open source framework for standardized comparisons of face recognition algorithms\n", "abstract": " In this paper we introduce the facereclib, the first software library that allows to compare a variety of face recognition algorithms on most of the known facial image databases and that permits rapid prototyping of novel ideas and testing of meta-parameters of face recognition algorithms. The facereclib is built on the open source signal processing and machine learning library Bob. It uses well-specified face recognition protocols to ensure that results are comparable and reproducible. We show that the face recognition algorithms implemented in Bob as well as third party face recognition libraries can be used to run face recognition experiments within the framework of the facereclib. As a proof of concept, we execute four different state-of-the-art face recognition algorithms: local Gabor binary pattern histogram sequences (LGBPHS), Gabor graph comparisons with a Gabor phase based similarity measure, inter\u00a0\u2026", "num_citations": "40\n", "authors": ["865"]}
{"title": "Bi-modal biometric authentication on mobile phones in challenging conditions\n", "abstract": " This paper examines the issue of face, speaker and bi-modal authentication in mobile environments when there is significant condition mismatch. We introduce this mismatch by enrolling client models on high quality biometric samples obtained on a laptop computer and authenticating them on lower quality biometric samples acquired with a mobile phone. To perform these experiments we develop three novel authentication protocols for the large publicly available MOBIO database. We evaluate state-of-the-art face, speaker and bi-modal authentication techniques and show that inter-session variability modelling using Gaussian mixture models provides a consistently robust system for face, speaker and bi-modal authentication. It is also shown that multi-algorithm fusion provides a consistent performance improvement for face, speaker and bi-modal authentication. Using this bi-modal multi-algorithm system we\u00a0\u2026", "num_citations": "38\n", "authors": ["865"]}
{"title": "The 2013 Speaker Recognition Evaluation in Mobile Environment\n", "abstract": " This paper evaluates the performance of the twelve primary systems submitted to the evaluation on speaker verification in the context of a mobile environment using the MOBIO database. The mobile environment provides a challenging and realistic test-bed for current state-of-the-art speaker verification techniques. Results in terms of equal error rate (EER), half total error rate (HTER) and detection error trade-off (DET) confirm that the best performing systems are based on total variability modeling, and are the fusion of several sub-systems. Nevertheless, the good old UBM-GMM based systems are still competitive. The results also show that the use of additional data for training as well as gender-dependent features can be helpful.", "num_citations": "38\n", "authors": ["865"]}
{"title": "Face recognition with disparity corrected Gabor phase differences\n", "abstract": " We analyze the relative relevance of Gabor amplitudes and phases for face recognition. We propose an algorithm to reliably estimate offset point disparities from phase differences and show that disparity-corrected Gabor phase differences are well suited for face recognition in difficult lighting conditions. The method reaches 74.8% recognition rate on the Lighting set of the CAS-PEAL database and 35.7% verification rate on experiment 2.4 of the FRGC database.", "num_citations": "35\n", "authors": ["865"]}
{"title": "Unconstrained Face Detection and Open-Set Face Recognition Challenge\n", "abstract": " Face detection and recognition benchmarks have shifted toward more difficult environments. The challenge presented in this paper addresses the next step in the direction of automatic detection and identification of people from outdoor surveillance cameras. While face detection has shown remarkable success in images collected from the web, surveillance cameras include more diverse occlusions, poses, weather conditions and image blur. Although face verification or closed-set face identification have surpassed human capabilities on some datasets, open-set identification is much more complex as it needs to reject both unknown identities and false accepts from the face detector. We show that unconstrained face detection can approach high detection rates albeit with moderate false accept rates. By contrast, open-set face recognition is currently weak and requires much more attention.", "num_citations": "32\n", "authors": ["865"]}
{"title": "Face Recognition in Challenging Environments: An Experimental and Reproducible Research Survey\n", "abstract": " One important type of biometric authentication is face recognition         , a research area of high popularity with a wide spectrum of approaches that have been proposed in the last few decades. The majority of existing approaches are conceived for or evaluated on constrained still images. However, more recently research interests have shifted toward unconstrained \u201cin-the-wild         \u201d still images and videos. To some extent, current state-of-the-art systems are able to cope with variability due to pose, illumination, expression, and size, which represent the challenges in unconstrained face recognition. To date, only few attempts have addressed the problem of face recognition in mobile environment         , where high degradation is present during both data acquisition and transmission. This book chapter deals with face recognition in mobile and other challenging environments, where both still images and video\u00a0\u2026", "num_citations": "29\n", "authors": ["865"]}
{"title": "Score calibration in face recognition\n", "abstract": " An evaluation of the verification and calibration performance of a face recognition system based on inter-session variability modelling is presented. As an extension to calibration through linear transformation of scores, categorical calibration is introduced as a way to include additional information about images for calibration. The cost of likelihood ratio, which is a well-known measure in the speaker recognition field, is used as a calibration performance metric. The results obtained from the challenging mobile biometrics and surveillance camera face databases indicate that linearly calibrated face recognition scores are less misleading in their likelihood ratio interpretation than uncalibrated scores. In addition, the categorical calibration experiments show that calibration can be used not only to improve the likelihood ratio interpretation of scores, but also to improve the verification performance of a face recognition system.", "num_citations": "28\n", "authors": ["865"]}
{"title": "Automatic Face Classification of Cushing's Syndrome in Women-A Novel Screening Approach\n", "abstract": " Cushing\u2019s syndrome causes considerable harm to the body if left untreated, yet often remains undiagnosed for prolonged periods of time. In this study we aimed to test whether face classification software might help in discriminating patients with Cushing\u2019s syndrome from healthy controls.  Diagnostic study.  Using a regular digital camera, we took frontal and profile pictures of 20 female patients with Cushing\u2019s syndrome and 40 sex- and age-matched controls.  Semi-automatic analysis of the pictures was performed by comparing texture and geometry within a grid of nodes placed on the pictures. The leave-one-out cross-validation method was employed to classify subjects by the software.  The software correctly classified 85.0% of patients and 95.0% of controls, resulting in a total classification accuracy of 91.7%.  In this preliminary analysis we found a good classification accuracy of Cushing\u2019s syndrome by face\u00a0\u2026", "num_citations": "26\n", "authors": ["865"]}
{"title": "LOTS about attacking deep features\n", "abstract": " Deep neural networks provide state-of-the-art performance on various tasks and are, therefore, widely used in real world applications. DNNs are becoming frequently utilized in biometrics for extracting deep features, which can be used in recognition systems for enrolling and recognizing new individuals. It was revealed that deep neural networks suffer from a fundamental problem, namely, they can unexpectedly misclassify examples formed by slightly perturbing correctly recognized inputs. Various approaches have been developed for generating these so-called adversarial examples, but they aim at attacking end-to-end networks. For biometrics, it is natural to ask whether systems using deep features are immune to or, at least, more resilient to attacks than end-to-end networks. In this paper, we introduce a general technique called the layerwise origin-target synthesis (LOTS) that can be efficiently used to form\u00a0\u2026", "num_citations": "25\n", "authors": ["865"]}
{"title": "Face detection and recognition using maximum likelihood classifiers on Gabor graphs\n", "abstract": " We present an integrated face recognition system that combines a Maximum Likelihood (ML) estimator with Gabor graphs for face detection under varying scale and in-plane rotation and matching as well as a Bayesian intrapersonal/extrapersonal classifier (BIC) on graph similarities for face recognition. We have tested a variety of similarity functions and achieved verification rates (at FAR 0.1%) of 90.5% on expression-variation and 95.8% on size-varying frontal images within the CAS-PEAL database. Performing Experiment 1 of FRGC ver2.0, the method achieved a verification rate of 72%.", "num_citations": "24\n", "authors": ["865"]}
{"title": "Adversarial Robustness: Softmax versus Openmax\n", "abstract": " Deep neural networks (DNNs) provide state-of-the-art results on various tasks and are widely used in real world applications. However, it was discovered that machine learning models, including the best performing DNNs, suffer from a fundamental problem: they can unexpectedly and confidently misclassify examples formed by slightly perturbing otherwise correctly recognized inputs. Various approaches have been developed for efficiently generating these so-called adversarial examples, but those mostly rely on ascending the gradient of loss. In this paper, we introduce the novel logits optimized targeting system (LOTS) to directly manipulate deep features captured at the penultimate layer. Using LOTS, we analyze and compare the adversarial robustness of DNNs using the traditional Softmax layer with Openmax, which was designed to provide open set recognition by defining classes derived from deep representations, and is claimed to be more robust to adversarial perturbations. We demonstrate that Openmax provides less vulnerable systems than Softmax to traditional attacks, however, we show that it can be equally susceptible to more sophisticated adversarial generation techniques that directly work on deep representations.", "num_citations": "20\n", "authors": ["865"]}
{"title": "PARAPH: Presentation Attack Rejection by Analyzing Polarization Hypotheses.\n", "abstract": " For applications such as airport border control, biometric technologies that can process many capture subjects quickly, efficiently, with weak supervision, and with minimal discomfort are desirable. Facial recognition is particularly appealing because it is minimally invasive yet offers relatively good recognition performance. Unfortunately, the combination of weak supervision and minimal invasiveness makes even highly accurate facial recognition systems susceptible to spoofing via presentation attacks. Thus, there is great demand for an effective and low cost system capable of rejecting such attacks. To this end we introduce PARAPH--a novel hardware extension that exploits different measurements of light polarization to yield an image space in which presentation media are readily discernible from Bona Fide facial characteristics. The PARAPH system is inexpensive with an added cost of less than 10 US dollars. The system makes two polarization measurements in rapid succession, allowing them to be approximately pixel-aligned, with a frame rate limited by the camera, not the system. There are no moving parts above the molecular level, due to the efficient use of twisted nematic liquid crystals. We present evaluation images using three presentation attack media next to an actual face--high quality photos on glossy and matte paper and a video of the face on an LCD. In each case, the actual face in the image generated by PARAPH is structurally discernible from the presentations, which appear either as noise (print attacks) or saturated images (replay attacks).", "num_citations": "18\n", "authors": ["865"]}
{"title": "Incremental Open Set Intrusion Recognition Using Extreme Value Machine\n", "abstract": " Typically, most network intrusion detection systems use supervised learning techniques to identify network anomalies. A problem exists when identifying the unknowns and automatically updating a classifier with new query classes. This is defined as an open set incremental learning problem and we propose to extend a recently introduced method, the Extreme Value Machine (EVM) to address the issue of identifying new classes during query time. The EVM is derived from the statistical extreme value theory and is the first classifier that can perform kernel-free, nonlinear, variable bandwidth outlier detection combined with incremental learning. In this paper, we utilize the EVM for intrusion detection and measure the open set recognition performance of identifying known and unknown classes. Additionally, we evaluate the performance on the KDDCUP'99 dataset and compare the results with the state-of-the-art\u00a0\u2026", "num_citations": "17\n", "authors": ["865"]}
{"title": "The Overlooked Elephant of Object Detection: Open Set\n", "abstract": " Even though object detection is a popular area of research that has found considerable applications in the real world, it has some fundamental aspects that have never been formally discussed and experimented. One of the core aspects of evaluating object detectors has been the ability to avoid false detections. While major datasets like PASCAL VOC or MSCOCO extensively test the detectors on their ability to avoid false positives, they do not differentiate between their closed-set and open-set performance. Despite systems being trained to reject everything other than the classes of interest, unknown objects from the open world end up being incorrectly detected as known objects, often with very high confidence. This paper is the first to formalize the problem of open-set object detection and propose the first open-set object detection protocol. Moreover, the paper provides a new evaluation metric to analyze the performance of some state-of-the-art detectors and discusses their performance differences.", "num_citations": "16\n", "authors": ["865"]}
{"title": "Impact of eye detection error on face recognition performance\n", "abstract": " The locations of the eyes are the most commonly used features to perform face normalisation (i.e. alignment of facial features), which is an essential preprocessing stage of many face recognition systems. In this study, the authors study the sensitivity of open source implementations of five face recognition algorithms to misalignment caused by eye localisation errors. They investigate the ambiguity in the location of the eyes by comparing the difference between two independent manual eye annotations. They also study the error characteristics of automatic eye detectors present in two commercial face recognition systems. Furthermore, they explore the impact of using different eye detectors for training/enrolment and query phases of a face recognition system. These experiments provide an insight into the influence of eye localisation errors on the performance of face recognition systems and recommend a strategy for\u00a0\u2026", "num_citations": "13\n", "authors": ["865"]}
{"title": "2D Face Recognition: An Experimental and Reproducible Research Survey\n", "abstract": " Due to its wide range of applications, automatic face recognition is a research area with high popularity. Many different face recognition algorithms have been proposed in the last decades. Nearly every day there is a new face recognition paper sent to a conference or a journal. Often, researchers provide results that rely on a hand-made non-standard evaluation protocol and that are, hence, incomparable to state-of-theart algorithms. Additionally, the source code for the algorithms is often not provided by the researchers. In consequence, face recognition survey papers can only report the results of other papers. In this paper we provide to our best knowledge the first experimental and evaluative study of a variety of state-of-the-art face recognition algorithms that solely relies on open source software, including color-based linear discriminant analysis, local Gabor binary pattern histogram sequence, Gabor graphs using a Gabor-phase based similarity measure and inter-session variability modeling. Together with this paper we supply the source code to re-run all the experiments that we execute in this study. Experiments are performed on many freely available image databases, always following the evaluation protocols that are attached to them. First, we optimize the parameters of all tested algorithms on a single database. This includes finding the best image preprocessing for each algorithm. Then, we test the algorithms against facial variations as expressions, pose and occlusions using the Multi-PIE and the AR face database. Finally, we report the results of these algorithms on CAS-PEAL, MOBIO, SC face, GBU, FRGC and LFW and discuss some\u00a0\u2026", "num_citations": "12\n", "authors": ["865"]}
{"title": "Statistical Gabor Graph Based Techniques for the Detection, Recognition, Classification, and Visualization of Human Faces\n", "abstract": " In this work, I focus in a simple parameter-free statistical model that requires few training data and can be trained fast. I show that the model is well suited for face detection, person identification, and classification of facial properties. For face detection, the well known elastic bunch graph matching algo-rithm is adapted to learn appearance probabilities of facial features. Fur-thermore, texture features are transformed to be used for the detection of faces in different sizes and in-plane rotation angles. In order to place facial landmarks more reliably and to increase face recognition accuracy, images are automatically standardized according to the found scale and angle of the face. It is shown that both extensions of the elastic bunch graph matching algorithm work well with only few hand-labeled training examples and that the face detection can be accelerated. After applying small changes to the model, it can be employed for iden-", "num_citations": "10\n", "authors": ["865"]}
{"title": "Reconstruction of images from Gabor graphs with applications in facial image processing\n", "abstract": " Graphs labeled with complex-valued Gabor jets are one of the important data formats for face recognition and the classification of facial images into medically relevant classes like genetic syndromes. We here present an interpolation rule and an iterative algorithm for the reconstruction of images from these graphs. This is especially important if graphs have been manipulated for information processing. One such manipulation is averaging the graphs of a single syndrome, another one building a composite face from the features of various individuals. In reconstructions of averaged graphs of genetic syndromes, the patients' identities are suppressed, while the properties of the syndromes are emphasized. These reconstructions from average graphs have a much better quality than averaged images.", "num_citations": "6\n", "authors": ["865"]}
{"title": "On the Improvements of Uni-modal and Bi-modal Fusions of Speaker and Face Recognition for Mobile Biometrics\n", "abstract": " The MOBIO database provides a challenging test-bed for speaker and face recognition systems because it includes voice and face samples as they would appear in forensic scenarios. In this paper, we investigate uni-modal and bimodal multi-algorithm fusion using logistic regression. The source speaker and face recognition systems were taken from the 2013 speaker and face recognition evaluations that were held in the context of the last International Conference on Biometrics (ICB-2013). Using the unbiased MOBIO protocols, the employed evaluation measures are the equal error rate (EER), the half-total error rate (HTER) and the detection error trade-off (DET). The results show that by uni-modal algorithm fusion, the HTER\u2019s of the speaker recognition system are reduced by around 35%, and of the face recognition system by between 15% and 20%. Bi-modal fusion drastically boosts recognition by a relative gain of 65%-70% of performance compared to the best uni-modal system.", "num_citations": "5\n", "authors": ["865"]}
{"title": "ECLIPSE: Ensembles of Centroids Leveraging Iteratively Processed Spatial Eclipse Clustering\n", "abstract": " Clustering is an unsupervised technique for machine learning and data analysis. Different clustering methods such as centroid, connectivity, density, or distribution-based clustering have been applied as a step in many vision applications. Recently, face clustering has become an important task in the face recognition field, and evaluation benchmarks on the LFW and IJB-B datasets have been created. In this paper, we present the Ensembles of Centroids Leveraging Iteratively Processed Spatial Eclipse (ECLIPSE) clustering algorithm, where we combine the advantages of centroid, density, and connectivity-based clustering algorithms. We show that ECLIPSE can work with most kinds of distance measures such as Euclidean, Cosine, and Bray-Curtis distance. We present the Alignment-Free Facial Feature Extraction (AFFFE) network to extract deep features for the LFW and IJB-B datasets. Using these features, our\u00a0\u2026", "num_citations": "3\n", "authors": ["865"]}
{"title": "Improving Deep Network Robustness to Unknown Inputs with Objectosphere.\n", "abstract": " Deep Neural Networks trained on academic datasets often fail when applied to the real world. These failures generally arise from unknown inputs that are not of interest to the system. The mis-classification of these unknown inputs as one of the known classes highlights the need for more robust deep networks. The problem of identifying samples that are not of interest to the system has previously been tackled by either thresholding softmax, which by construction cannot return none of the known classes itself, or by learning new features for the unknown inputs using an additional background or garbage class. As demonstrated, both of these approaches help but are generally insufficient when previously unseen classes are encountered. This paper overviews our recent publication Reducing Network Agnostophobia, NeurIPS 2018. The paper presented two novel loss functions that effectively handle unseen classes while providing a new measure for uncertainty. The ability to identify unknown samples plays a crucial role in developing robust networks that may be used in open-world problems. The paper also introduced an evaluation metric that focused on comparing performance of multiple approaches in an open-set setting.", "num_citations": "2\n", "authors": ["865"]}
{"title": "Gender Classification by LUT Based Boosting of Overlapping Block Patterns\n", "abstract": " The paper addresses the problem of gender classification from face images. For feature extraction, we propose discrete Overlapping Block Patterns (OBP), which capture the characteristic structure from the image at various scales. Using integral images, these features can be computed in constant time. The feature extraction at multiple scales results in a high dimensionality and feature redundancy. Therefore, we apply a boosting algorithm for feature selection and classification. Look-Up Tables (LUT) are utilized as weak classifiers, which are appropriate to the discrete nature of the OBP features. The experiments are performed on two publicly available data sets, Labeled Faces in the Wild (LFW) and MOBIO. The results demonstrate that Local Binary Pattern (LBP) features with LUT boosting outperform the commonly used block-histogram-based LBP approaches and that OBP features gain over Multi\u00a0\u2026", "num_citations": "2\n", "authors": ["865"]}
{"title": "Watchlist Adaptation: Protecting the Innocent\n", "abstract": " One of the most important government applications of face recognition is the watchlist problem, where the goal is to identify a few people enlisted on a watchlist while ignoring the majority of innocent passersby. Since watchlists dynamically change and training times can be expensive, the deployed approaches use pre-trained deep networks only to provide deep features for face comparison. Since these networks never specifically trained on the operational setting or faces from the watchlist, the system will often confuse them with the faces of innocent non-watchlist subjects leading to difficult situations, e.g., being detained at the airport to resolve their identity. We develop a novel approach to take an existing pre-trained face network and use adaptation layers trained with our recently developed Objectosphere loss to provide an open-set recognition system that is rapidly adapted to the gallery while also ignoring non\u00a0\u2026", "num_citations": "1\n", "authors": ["865"]}
{"title": "Evaluating a Convolutional Neural Network on Short-Wave Infra-Red Images\n", "abstract": " Machine learning algorithms, both traditional and neuralnetwork-based, have been tested against RGB facial images for years, but these algorithms are prone to fail when illumination conditions are insufficient, for example, at night or when images are taken from long distances. Short-Wave Infra-Red (SWIR) illumination provides a much higher intensity and a much more ambient structure than visible light, which makes it better suited for face recognition in different conditions. However, current neural networks require lots of training data, which is not available in the SWIR domain. In this paper, we examine the ability of a convolutional neural network, specifically, the VGG Face network, which was trained on visible spectrum images, to work on SWIR images. Utilizing a dataset containing both RGB and SWIR images, we hypothesize that the VGG Face network will perform well both on facial images taken in RGB and\u00a0\u2026", "num_citations": "1\n", "authors": ["865"]}
{"title": "Two kinds of statistics for better face recognition\n", "abstract": " We briefly review the base techniques of elastic graph matching [1] and elastic bunch graph matching [2], which provide a method for face detection, matching, comparison, and identity decision. We then present a method that combines the advantages of Gabor\u2010labeled graphs with maximum likelihood decision making. The improvements over pure bunch graph matching have been studied, and the method has been successfully applied to large face databases like the one for the Face Recognition Grand Challenge [3]. Finally, we describe a system based on rank order statistics that can learn invariances in a minimally supervised way from a set of examples of individual faces in several situations like different head pose or illumination. Recognition rates are improved significantly without explicit modeling of the image formation process [4].", "num_citations": "1\n", "authors": ["865"]}