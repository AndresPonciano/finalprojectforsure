{"title": "Evolutionary programming made faster\n", "abstract": " Evolutionary programming (EP) has been applied with success to many numerical and combinatorial optimization problems in recent years. EP has rather slow convergence rates, however, on some function optimization problems. In the paper, a \"fast EP\" (FEP) is proposed which uses a Cauchy instead of Gaussian mutation as the primary search operator. The relationship between FEP and classical EP (CEP) is similar to that between fast simulated annealing and the classical version. Both analytical and empirical studies have been carried out to evaluate the performance of FEP and CEP for different function optimization problems. The paper shows that FEP is very good at search in a large neighborhood while CEP is better at search in a small local neighborhood. For a suite of 23 benchmark problems, FEP performs much better than CEP for multimodal functions with many local minima while being comparable\u00a0\u2026", "num_citations": "3858\n", "authors": ["537"]}
{"title": "Evolving artificial neural networks\n", "abstract": " Learning and evolution are two fundamental forms of adaptation. There has been a great interest in combining learning and evolution with artificial neural networks (ANNs) in recent years. This paper: 1) reviews different combinations between ANNs and evolutionary algorithms (EAs), including using EAs to evolve ANN connection weights, architectures, learning rules, and input features; 2) discusses different search operators which have been used in various EAs; and 3) points out possible future research directions. It is shown, through a considerably large literature review, that combinations between ANNs and EAs can lead to significantly better intelligent systems than relying on ANNs or EAs alone.", "num_citations": "3590\n", "authors": ["537"]}
{"title": "Stochastic ranking for constrained evolutionary optimization\n", "abstract": " Penalty functions are often used in constrained optimization. However, it is very difficult to strike the right balance between objective and penalty functions. This paper introduces a novel approach to balance objective and penalty functions stochastically, i.e., stochastic ranking, and presents a new view on penalty function methods in terms of the dominance of penalty and objective functions. Some of the pitfalls of naive penalty methods are discussed in these terms. The new ranking method is tested using a (/spl mu/, /spl lambda/) evolution strategy on 13 benchmark problems. Our results show that suitable ranking alone (i.e., selection), without the introduction of complicated and specialized variation operators, is capable of improving the search performance significantly.", "num_citations": "1916\n", "authors": ["537"]}
{"title": "A new evolutionary system for evolving artificial neural networks\n", "abstract": " This paper presents a new evolutionary system, i.e., EPNet, for evolving artificial neural networks (ANNs). The evolutionary algorithm used in EPNet is based on Fogel's evolutionary programming (EP). Unlike most previous studies on evolving ANN's, this paper puts its emphasis on evolving ANN's behaviors. Five mutation operators proposed in EPNet reflect such an emphasis on evolving behaviors. Close behavioral links between parents and their offspring are maintained by various mutations, such as partial training and node splitting. EPNet evolves ANN's architectures and connection weights (including biases) simultaneously in order to reduce the noise in fitness evaluation. The parsimony of evolved ANN's is encouraged by preferring node/connection deletion to addition. EPNet has been tested on a number of benchmark problems in machine learning and ANNs, such as the parity problem, the medical\u00a0\u2026", "num_citations": "1209\n", "authors": ["537"]}
{"title": "Diversity creation methods: a survey and categorisation\n", "abstract": " Ensemble approaches to classification and regression have attracted a great deal of interest in recent years. These methods can be shown both theoretically and empirically to outperform single predictors on a wide range of tasks. One of the elements required for accurate prediction when using an ensemble is recognised to be error \u201cdiversity\u201d. However, the exact meaning of this concept is not clear from the literature, particularly for classification tasks. In this paper we first review the varied attempts to provide a formal explanation of error diversity, including several heuristic and qualitative explanations in the literature. For completeness of discussion we include not only the classification literature but also some excerpts of the rather more mature regression literature, which we believe can still provide some insights. We proceed to survey the various techniques used for creating diverse ensembles, and categorise\u00a0\u2026", "num_citations": "1152\n", "authors": ["537"]}
{"title": "A review of evolutionary artificial neural networks\n", "abstract": " Research on potential interactions between connectionist learning systems, i.e., artificial neural networks (ANNs), and evolutionary search procedures, like genetic algorithms (GAs), has attracted a lot of attention recently. Evolutionary ANNs (EANNs) can be considered as the combination of ANNs and evolutionary search procedures. This article first distinguishes among three kinds of evolution in EANNs, i.e., the evolution of connection weights, of architectures, and of learning rules. Then it reviews each kind of evolution in detail and analyzes critical issues related to different evolutions. the review shows that although a lot of work has been done on the evolution of connection weights and architectures, few attempts have been made to understand the evolution of learning rules. Interactions among different evolutions are seldom mentioned in current research. However, the evolution of learning rules and its\u00a0\u2026", "num_citations": "1099\n", "authors": ["537"]}
{"title": "A survey on evolutionary computation approaches to feature selection\n", "abstract": " Feature selection is an important task in data mining and machine learning to reduce the dimensionality of the data and increase the performance of an algorithm, such as a classification algorithm. However, feature selection is a challenging task due mainly to the large search space. A variety of methods have been applied to solve feature selection problems, where evolutionary computation (EC) techniques have recently gained much attention and shown some success. However, there are no comprehensive guidelines on the strengths and weaknesses of alternative approaches. This leads to a disjointed and fragmented field with ultimately lost opportunities for improving performance and successful applications. This paper presents a comprehensive survey of the state-of-the-art work on EC for feature selection, which identifies the contributions of these different algorithms. In addition, current issues and\u00a0\u2026", "num_citations": "1006\n", "authors": ["537"]}
{"title": "Large scale evolutionary optimization using cooperative coevolution\n", "abstract": " Evolutionary algorithms (EAs) have been applied with success to many numerical and combinatorial optimization problems in recent years. However, they often lose their effectiveness and advantages when applied to large and complex problems, e.g., those with high dimensions. Although cooperative coevolution has been proposed as a promising framework for tackling high-dimensional optimization problems, only limited studies were reported by decomposing a high-dimensional problem into single variables (dimensions). Such methods of decomposition often failed to solve nonseparable problems, for which tight interactions exist among different decision variables. In this paper, we propose a new cooperative coevolution framework that is capable of optimizing large scale nonseparable problems. A random grouping scheme and adaptive weighting are introduced in problem decomposition and coevolution\u00a0\u2026", "num_citations": "928\n", "authors": ["537"]}
{"title": "Benchmark functions for the CEC\u20192008 special session and competition on large scale global optimization\n", "abstract": " In the past decades, different kinds of metaheuristic optimization algorithms [1, 2] have been developed; Simulated Annealing (SA)[3, 4], Evolutionary Algorithms (EAs)[5\u20137], Differential Evolution (DE)[8, 9], Particle Swarm Optimization (PSO)[10, 11], Ant Colony Optimization (ACO)[12, 13], and Estimation of Distribution Algorithms (EDAs)[14, 15] are just a few of them. These algorithms have shown excellent search abilities but often lose their efficacy when applied to large and complex problems, eg, problem instances with high dimensions, such as those with more than one hundred decision variables.Many optimization methods suffer from the \u201ccurse of dimensionality\u201d[16, 17], which implies that their performance deteriorates quickly as the dimensionality of the search space increases. The reasons for this phenomenon appear to be two-fold. First, the solution space of a problem often increases exponentially with the problem dimension [16, 17] and more efficient search strategies are required to explore all promising regions within a given time budget. Second, also the characteristics of a problem may change with the scale. Rosenbrock\u2019s function [18](see also Section 2.6), for instance, is unimodal for two dimension but becomes multimodal for higher ones [19]. Because of such a worsening of the features of an optimization problem resulting from an increase in scale, a previously successful search strategy may no longer be capable of finding the optimal solution. Historically, scaling EAs to large-scale problems has attracted much interest, including both theoretical and practical studies. The earliest practical approach might be parallelizing an\u00a0\u2026", "num_citations": "909\n", "authors": ["537"]}
{"title": "Ensemble learning via negative correlation\n", "abstract": " This paper presents a learning approach, i.e. negative correlation learning, for neural network ensembles. Unlike previous learning approaches for neural network ensembles, negative correlation learning attempts to train individual networks in an ensemble and combines them in the same learning process. In negative correlation learning, all the individual networks in the ensemble are trained simultaneously and interactively through the correlation penalty terms in their error functions. Rather than producing unbiased individual networks whose errors are uncorrelated, negative correlation learning can create negatively correlated networks to encourage specialisation and cooperation among the individual networks. Empirical studies have been carried out to show why and how negative correlation learning works. The experimental results show that negative correlation learning can produce neural network\u00a0\u2026", "num_citations": "782\n", "authors": ["537"]}
{"title": "Cooperatively coevolving particle swarms for large scale optimization\n", "abstract": " This paper presents a new cooperative coevolving particle swarm optimization (CCPSO) algorithm in an attempt to address the issue of scaling up particle swarm optimization (PSO) algorithms in solving large-scale optimization problems (up to 2000 real-valued variables). The proposed CCPSO2 builds on the success of an early CCPSO that employs an effective variable grouping technique random grouping. CCPSO2 adopts a new PSO position update rule that relies on Cauchy and Gaussian distributions to sample new points in the search space, and a scheme to dynamically determine the coevolving subcomponent sizes of the variables. On high-dimensional problems (ranging from 100 to 2000 variables), the performance of CCPSO2 compared favorably against a state-of-the-art evolutionary algorithm sep-CMA-ES, two existing PSO algorithms, and a cooperative coevolving differential evolution algorithm. In\u00a0\u2026", "num_citations": "681\n", "authors": ["537"]}
{"title": "MWMOTE--majority weighted minority oversampling technique for imbalanced data set learning\n", "abstract": " Imbalanced learning problems contain an unequal distribution of data samples among different classes and pose a challenge to any classifier as it becomes hard to learn the minority class samples. Synthetic oversampling methods address this problem by generating the synthetic minority class samples to balance the distribution between the samples of the majority and minority classes. This paper identifies that most of the existing oversampling methods may generate the wrong synthetic minority samples in some scenarios and make learning tasks harder. To this end, a new method, called Majority Weighted Minority Oversampling TEchnique (MWMOTE), is presented for efficiently handling imbalanced learning problems. MWMOTE first identifies the hard-to-learn informative minority class samples and assigns them weights according to their euclidean distance from the nearest majority class samples. It then\u00a0\u2026", "num_citations": "624\n", "authors": ["537"]}
{"title": "Many-objective evolutionary algorithms: A survey\n", "abstract": " Multiobjective evolutionary algorithms (MOEAs) have been widely used in real-world applications. However, most MOEAs based on Pareto-dominance handle many-objective problems (MaOPs) poorly due to a high proportion of incomparable and thus mutually nondominated solutions. Recently, a number of many-objective evolutionary algorithms (MaOEAs) have been proposed to deal with this scalability issue. In this article, a survey of MaOEAs is reported. According to the key ideas used, MaOEAs are categorized into seven classes: relaxed dominance based, diversity-based, aggregation-based, indicator-based, reference set based, preference-based, and dimensionality reduction approaches. Several future research directions in this field are also discussed.", "num_citations": "583\n", "authors": ["537"]}
{"title": "Evolutionary programming using mutations based on the L\u00e9vy probability distribution\n", "abstract": " Studies evolutionary programming with mutations based on the Levy probability distribution. The Levy probability distribution has an infinite second moment and is, therefore, more likely to generate an offspring that is farther away from its parent than the commonly employed Gaussian mutation. Such likelihood depends on a parameter /spl alpha/ in the Levy distribution. We propose an evolutionary programming algorithm using adaptive as well as nonadaptive Levy mutations. The proposed algorithm was applied to multivariate functional optimization. Empirical evidence shows that, in the case of functions having many local optima, the performance of the proposed algorithm was better than that of classical evolutionary programming using Gaussian mutation.", "num_citations": "580\n", "authors": ["537"]}
{"title": "Performance scaling of multi-objective evolutionary algorithms\n", "abstract": " MOEAs are getting immense popularity in the recent past, mainly because of their ability to find a wide spread of Pareto-optimal solutions in a single simulation run. Various evolutionary approaches to multi-objective optimization have been proposed since 1985. Some of fairly recent ones are NSGA-II, SPEA2, PESA (which are included in this study) and others. They all have been mainly applied to two to three objectives. In order to establish their superiority over classical methods and demonstrate their abilities for convergence and maintenance of diversity, they need to be tested on higher number of objectives. In this study, these state-of-the-art MOEAs have been investigated for their scalability with respect to the number of objectives (2 to 8). They have also been compared on the basis of -(1) Their ability to converge to Pareto front, (2) Diversity of obtained non-dominated solutions and (3) Their running\u00a0\u2026", "num_citations": "555\n", "authors": ["537"]}
{"title": "Promises and challenges of evolvable hardware\n", "abstract": " Evolvable hardware (EHW) has attracted increasing attention since the early 1990s with the advent of easily reconfigurable hardware, such as field programmable gate arrays (FPGAs). It promises to provide an entirely new approach to complex electronic circuit design and new adaptive hardware. EHW has been demonstrated to be able to perform a wide range of tasks, from pattern recognition to adaptive control. However, there are still many fundamental issues in EHW that remain open. This paper reviews the current status of EHW, discusses the promises and possible advantages of EHW, and indicates the challenges we must meet in order to develop practical and large-scale EHW.", "num_citations": "536\n", "authors": ["537"]}
{"title": "Evolutionary ensembles with negative correlation learning\n", "abstract": " Based on negative correlation learning and evolutionary learning, this paper presents evolutionary ensembles with negative correlation learning (EENCL) to address the issues of automatic determination of the number of individual neural networks (NNs) in an ensemble and the exploitation of the interaction between individual NN design and combination. The idea of EENCL is to encourage different individual NNs in the ensemble to learn different parts or aspects of the training data so that the ensemble can learn better the entire training data. The cooperation and specialization among different individual NNs are considered during the individual NN design. This provides an opportunity for different NNs to interact with each other and to specialize. Experiments on two real-world problems demonstrate that EENCL can produce NN ensembles with good generalization ability.", "num_citations": "533\n", "authors": ["537"]}
{"title": "Search biases in constrained evolutionary optimization\n", "abstract": " A common approach to constraint handling in evolutionary optimization is to apply a penalty function to bias the search toward a feasible solution. It has been proposed that the subjective setting of various penalty parameters can be avoided using a multiobjective formulation. This paper analyzes and explains in depth why and when the multiobjective approach to constraint handling is expected to work or fail. Furthermore, an improved evolutionary algorithm based on evolution strategies and differential variation is proposed. Extensive experimental studies have been carried out. Our results reveal that the unbiased multiobjective approach to constraint handling may not be as effective as one may have assumed.", "num_citations": "532\n", "authors": ["537"]}
{"title": "Cooperative co-evolution with differential grouping for large scale optimization\n", "abstract": " Cooperative co-evolution has been introduced into evolutionary algorithms with the aim of solving increasingly complex optimization problems through a divide-and-conquer paradigm. In theory, the idea of co-adapted subcomponents is desirable for solving large-scale optimization problems. However, in practice, without prior knowledge about the problem, it is not clear how the problem should be decomposed. In this paper, we propose an automatic decomposition strategy called differential grouping that can uncover the underlying interaction structure of the decision variables and form subcomponents such that the interdependence between them is kept to a minimum. We show mathematically how such a decomposition strategy can be derived from a definition of partial separability. The empirical studies show that such near-optimal decomposition can greatly improve the solution quality on large-scale global\u00a0\u2026", "num_citations": "503\n", "authors": ["537"]}
{"title": "Multiclass imbalance problems: Analysis and potential solutions\n", "abstract": " Class imbalance problems have drawn growing interest recently because of their classification difficulty caused by the imbalanced class distributions. In particular, many ensemble methods have been proposed to deal with such imbalance. However, most efforts so far are only focused on two-class imbalance problems. There are unsolved issues in multiclass imbalance problems, which exist in real-world applications. This paper studies the challenges posed by the multiclass imbalance problems and investigates the generalization ability of some ensemble solutions, including our recently proposed algorithm AdaBoost.NC, with the aim of handling multiclass and imbalance effectively and directly. We first study the impact of multiminority and multimajority on the performance of two basic resampling techniques. They both present strong negative effects. \u201cMultimajority\u201d tends to be more harmful to the generalization\u00a0\u2026", "num_citations": "475\n", "authors": ["537"]}
{"title": "Using class imbalance learning for software defect prediction\n", "abstract": " To facilitate software testing, and save testing costs, a wide range of machine learning methods have been studied to predict defects in software modules. Unfortunately, the imbalanced nature of this type of data increases the learning difficulty of such a task. Class imbalance learning specializes in tackling classification problems with imbalanced distributions, which could be helpful for defect prediction, but has not been investigated in depth so far. In this paper, we study the issue of if and how class imbalance learning methods can benefit software defect prediction with the aim of finding better solutions. We investigate different types of class imbalance learning methods, including resampling techniques, threshold moving, and ensemble algorithms. Among those methods we studied, AdaBoost.NC shows the best overall performance in terms of the measures including balance, G-mean, and Area Under the Curve\u00a0\u2026", "num_citations": "461\n", "authors": ["537"]}
{"title": "A novel evolutionary data mining algorithm with applications to churn prediction\n", "abstract": " Classification is an important topic in data mining research. Given a set of data records, each of which belongs to one of a number of predefined classes, the classification problem is concerned with the discovery of classification rules that can allow records with unknown class membership to be correctly classified. Many algorithms have been developed to mine large data sets for classification models and they have been shown to be very effective. However, when it comes to determining the likelihood of each classification made, many of them are not designed with such purpose in mind. For this, they are not readily applicable to such problems as churn prediction. For such an application, the goal is not only to predict whether or not a subscriber would switch from one carrier to another, it is also important that the likelihood of the subscriber's doing so be predicted. The reason for this is that a carrier can then choose\u00a0\u2026", "num_citations": "454\n", "authors": ["537"]}
{"title": "An analysis of diversity measures\n", "abstract": " Diversity among the base classifiers is deemed to be important when constructing a classifier ensemble. Numerous algorithms have been proposed to construct a good classifier ensemble by seeking both the accuracy of the base classifiers and the diversity among them. However, there is no generally accepted definition of diversity, and measuring the diversity explicitly is very difficult. Although researchers have designed several experimental studies to compare different diversity measures, usually confusing results were observed. In this paper, we present a theoretical analysis on six existing diversity measures (namely disagreement measure, double fault measure, KW variance, inter-rater agreement, generalized diversity and measure of difficulty), show underlying relationships between them, and relate them to the concept of margin, which is more explicitly related to the success of ensemble learning\u00a0\u2026", "num_citations": "445\n", "authors": ["537"]}
{"title": "Diversity analysis on imbalanced data sets by using ensemble models\n", "abstract": " Many real-world applications have problems when learning from imbalanced data sets, such as medical diagnosis, fraud detection, and text classification. Very few minority class instances cannot provide sufficient information and result in performance degrading greatly. As a good way to improve the classification performance of weak learner, some ensemble-based algorithms have been proposed to solve class imbalance problem. However, it is still not clear that how diversity affects classification performance especially on minority classes, since diversity is one influential factor of ensemble. This paper explores the impact of diversity on each class and overall performance. As the other influential factor, accuracy is also discussed because of the trade-off between diversity and accuracy. Firstly, three popular re-sampling methods are combined into our ensemble model and evaluated for diversity analysis, which\u00a0\u2026", "num_citations": "444\n", "authors": ["537"]}
{"title": "Drift analysis and average time complexity of evolutionary algorithms\n", "abstract": " The computational time complexity is an important topic in the theory of evolutionary algorithms (EAs). This paper reports some new results on the average time complexity of EAs. Based on drift analysis, some useful drift conditions for deriving the time complexity of EAs are studied, including conditions under which an EA will take no more than polynomial time (in problem size) to solve a problem and conditions under which an EA will take at least exponential time (in problem size) to solve a problem. The paper first presents the general results, and then uses several problems as examples to illustrate how these general results can be applied to concrete problems in analyzing the average time complexity of EAs. While previous work only considered (1+ 1) EAs without any crossover, the EAs considered in this paper are fairly general, which use a finite population, crossover, mutation, and selection.", "num_citations": "435\n", "authors": ["537"]}
{"title": "Fast Evolutionary Programming.\n", "abstract": " Evolutionary programming (EP) has been applied to many numerical and combinatorial optimisation problems successfully in recent years. One disadvantage of EP is its slow convergence to a good near optimum for some function optimisation problems. In this paper, we propose a fast EP (FEP) which uses a Cauchy instead of Gaussian mutation operator as the primary search operator. The relationship between FEP and classical EP (CEP) is similar to that between the fast simulated annealing and the classical version. Extensive empirical studies have been carried out to evaluate the performance of FEP for di erent function optimisation problems. Fifty runs have been conducted for each of the 23 test functions in our studies. Our experimental results show that FEP performs much better than CEP for multi-modal functions with many local minima while being comparable to CEP in performance for unimodal and multi-modal functions with only a few local minima. We emphasise in the paper that no single algorithm can be the best for all problems. What we need is to identify the relationship between an algorithm and a class of problems which are most amenable to the algorithm.", "num_citations": "421\n", "authors": ["537"]}
{"title": "Self-adaptive differential evolution with neighborhood search\n", "abstract": " In this paper we investigate several self-adaptive mechanisms to improve our previous work on NSDE, which is a recent DE variant for numerical optimization. The self-adaptive methods originate from another DE variant, SaDE, but are remarkably modified and extended to fit our NSDE. And thus a self-adaptive NSDE (SaNSDE) is proposed to improve NSDEpsilas performance. Three self-adaptive mechanisms are utilized in SaNSDE: self-adaptation for two candidate mutation strategies, self-adaptations for controlling scale factor F and crossover rate CR, respectively. Experimental studies are carried out on a broad range of different benchmark functions, and the proposed SaNSDE has shown significant superiority over NSDE.", "num_citations": "405\n", "authors": ["537"]}
{"title": "Fast evolution strategies\n", "abstract": " Evolution strategies are a class of general optimisation algorithms which are applicable to functions that are multimodal, non-differentiable, or even discontinuous. Although recombination operators have been introduced into evolution strategies, their primary search operator is still mutation. Classical evolution strategies rely on Gaussian mutations. A new mutation operator based on the Cauchy distribution is proposed in this paper. It is shown empirically that the new evolution strategy based on Cauchy mutation outperforms the classical evolution strategy on most of the 23 benchmark problems tested in this paper. These results, along with those obtained by fast evolutionary programming", "num_citations": "392\n", "authors": ["537"]}
{"title": "A constructive algorithm for training cooperative neural network ensembles\n", "abstract": " Presents a constructive algorithm for training cooperative neural-network ensembles (CNNEs). CNNE combines ensemble architecture design with cooperative training for individual neural networks (NNs) in ensembles. Unlike most previous studies on training ensembles, CNNE puts emphasis on both accuracy and diversity among individual NNs in an ensemble. In order to maintain accuracy among individual NNs, the number of hidden nodes in individual NNs are also determined by a constructive approach. Incremental training based on negative correlation is used in CNNE to train individual NNs for different numbers of training epochs. The use of negative correlation learning and different training epochs for training individual NNs reflect CNNEs emphasis on diversity among individual NNs in an ensemble. CNNE has been tested extensively on a number of benchmark problems in machine learning and\u00a0\u2026", "num_citations": "390\n", "authors": ["537"]}
{"title": "Software module clustering as a multi-objective search problem\n", "abstract": " Software module clustering is the problem of automatically organizing software units into modules to improve program structure. There has been a great deal of recent interest in search-based formulations of this problem in which module boundaries are identified by automated search, guided by a fitness function that captures the twin objectives of high cohesion and low coupling in a single-objective fitness function. This paper introduces two novel multi-objective formulations of the software module clustering problem, in which several different objectives (including cohesion and coupling) are represented separately. In order to evaluate the effectiveness of the multi-objective approach, a set of experiments was performed on 17 real-world module clustering problems. The results of this empirical study provide strong evidence to support the claim that the multi-objective approach produces significantly better solutions\u00a0\u2026", "num_citations": "369\n", "authors": ["537"]}
{"title": "Making use of population information in evolutionary artificial neural networks\n", "abstract": " This paper is concerned with the simultaneous evolution of artificial neural network (ANN) architectures and weights. The current practice in evolving ANN's is to choose the best ANN in the last generation as the final result. This paper proposes a different approach to form the final result by combining all the individuals in the last generation in order to make best use of all the information contained in the whole population. This approach regards a population of ANN's as an ensemble and uses a combination method to integrate them. Although there has been some work on integrating ANN modules, little has been done in evolutionary learning to make best use of its population information. Four linear combination methods have been investigated in this paper to illustrate our ideas. Three real-world data sets have been used in our experimental studies, which show that the recursive least-square (RLS) algorithm\u00a0\u2026", "num_citations": "358\n", "authors": ["537"]}
{"title": "Multilevel cooperative coevolution for large scale optimization\n", "abstract": " In this paper, we propose a multilevel cooperative coevolution (MLCC) framework for large scale optimization problems. The motivation is to improve our previous work on grouping based cooperative coevolution (EACC-G), which has a hard-to-determine parameter, group size, in tackling problem decomposition. The problem decomposer takes group size as parameter to divide the objective vector into low dimensional subcomponents with a random grouping strategy. In the MLCC, a set of problem decomposers is constructed based on the random grouping strategy with different group sizes. The evolution process is divided into a number of cycles, and at the start of each cycle MLCC uses a self-adapted mechanism to select a decomposer according to its historical performance. Since different group sizes capture different interaction levels between the original objective variables, MLCC is able to self-adapt among\u00a0\u2026", "num_citations": "334\n", "authors": ["537"]}
{"title": "Two_Arch2: An improved two-archive algorithm for many-objective optimization\n", "abstract": " Many-objective optimization problems (ManyOPs) refer, usually, to those multiobjective problems (MOPs) with more than three objectives. Their large numbers of objectives pose challenges to multiobjective evolutionary algorithms (MOEAs) in terms of convergence, diversity, and complexity. Most existing MOEAs can only perform well in one of those three aspects. In view of this, we aim to design a more balanced MOEA on ManyOPs in all three aspects at the same time. Among the existing MOEAs, the two-archive algorithm (Two_Arch) is a low-complexity algorithm with two archives focusing on convergence and diversity separately. Inspired by the idea of Two_Arch, we propose a significantly improved two-archive algorithm (i.e., Two_Arch2) for ManyOPs in this paper. In our Two_Arch2, we assign different selection principles (indicator-based and Pareto-based) to the two archives. In addition, we design a new Lp\u00a0\u2026", "num_citations": "329\n", "authors": ["537"]}
{"title": "Simultaneous training of negatively correlated neural networks in an ensemble\n", "abstract": " This paper presents a new cooperative ensemble learning system (CELS) for designing neural network ensembles. The idea behind CELS is to encourage different individual networks in an ensemble to learn different parts or aspects of a training data so that the ensemble can learn the whole training data better. In CELS, the individual networks are trained simultaneously rather than independently or sequentially. This provides an opportunity for the individual networks to interact with each other and to specialize. CELS can create negatively correlated neural networks using a correlation penalty term in the error function to encourage such specialization. This paper analyzes CELS in terms of bias-variance-covariance tradeoff. CELS has also been tested on the Mackey-Glass time series prediction problem and the Australian credit card assessment problem. The experimental results show that CELS can produce\u00a0\u2026", "num_citations": "328\n", "authors": ["537"]}
{"title": "Experimental study on population-based incremental learning algorithms for dynamic optimization problems\n", "abstract": " Evolutionary algorithms have been widely used for stationary optimization problems. However, the environments of real world problems are often dynamic. This seriously challenges traditional evolutionary algorithms. In this paper, the application of population-based incremental learning (PBIL) algorithms, a class of evolutionary algorithms, for dynamic problems is investigated. Inspired by the complementarity mechanism in nature a Dual PBIL is proposed, which operates on two probability vectors that are dual to each other with respect to the central point in the genotype space. A diversity maintaining technique of combining the central probability vector into PBIL is also proposed to improve PBIL\u2019s adaptability in dynamic environments. In this paper, a new dynamic problem generator that can create required dynamics from any binary-encoded stationary problem is also formalized. Using this generator, a\u00a0\u2026", "num_citations": "309\n", "authors": ["537"]}
{"title": "Population-based incremental learning with associative memory for dynamic environments\n", "abstract": " In recent years, interest in studying evolutionary algorithms (EAs) for dynamic optimization problems (DOPs) has grown due to its importance in real-world applications. Several approaches, such as the memory and multiple population schemes, have been developed for EAs to address dynamic problems. This paper investigates the application of the memory scheme for population-based incremental learning (PBIL) algorithms, a class of EAs, for DOPs. A PBIL-specific associative memory scheme, which stores best solutions as well as corresponding environmental information in the memory, is investigated to improve its adaptability in dynamic environments. In this paper, the interactions between the memory scheme and random immigrants, multipopulation, and restart schemes for PBILs in dynamic environments are investigated. In order to better test the performance of memory schemes for PBILs and other EAs in\u00a0\u2026", "num_citations": "302\n", "authors": ["537"]}
{"title": "Scaling up fast evolutionary programming with cooperative coevolution\n", "abstract": " Evolutionary programming (EP) has been applied with success to many numerical and combinatorial optimization problems in recent years. However, most analytical and experimental results on EP have been obtained using low-dimensional problems. It is interesting to know whether the empirical results obtained from the low-dimensional problems still hold for high-dimensional cases. It was discovered that neither classical EP (CEP) nor fast EP (FEP) performed satisfactorily for some large-scale problems. The paper shows empirically that FEP with cooperative coevolution (FEPCC) can speed up convergence rates on the large-scale problems whose dimension ranges from 100 to 1000. Cooperative coevolution adopts the divide-and-conquer strategy. It divides the system into many modules, and evolves each module separately and cooperatively. The results of FEPCC on the problems investigated here are\u00a0\u2026", "num_citations": "270\n", "authors": ["537"]}
{"title": "Evolutionary optimization\n", "abstract": " Evolutionary computation techniques have attracted increasing att-tions in recent years for solving complex optimization problems. They are more robust than traditional methods based on formal logics or mathematical programming for many real world OR/MS problems. E-lutionary computation techniques can deal with complex optimization problems better than traditional optimization techniques. However, most papers on the application of evolutionary computation techniques to Operations Research/Management Science (OR/MS) problems have scattered around in different journals and conference proceedings. They also tend to focus on a very special and narrow topic. It is the right time that an archival book series publishes a special volume which-cludes critical reviews of the state-of-art of those evolutionary com-tation techniques which have been found particularly useful for OR/MS problems, and a collection of papers which represent the latest devel-ment in tackling various OR/MS problems by evolutionary computation techniques. This special volume of the book series on Evolutionary-timization aims at filling in this gap in the current literature. The special volume consists of invited papers written by leading-searchers in the field. All papers were peer reviewed by at least two recognised reviewers. The book covers the foundation as well as the practical side of evolutionary optimization.", "num_citations": "257\n", "authors": ["537"]}
{"title": "A study of drift analysis for estimating computation time of evolutionary algorithms\n", "abstract": " This paper introduces drift analysis and its applications in estimating average computation time of evolutionary algorithms. Firstly, drift conditions for estimating upper and lower bounds of the mean first hitting times of evolutionary algorithms are presented. Then drift analysis is applied to two specific evolutionary algorithms and problems. Finally, a general classification of easy and hard problems for evolutionary algorithmsis given based on the analysis.", "num_citations": "252\n", "authors": ["537"]}
{"title": "Time complexity of evolutionary algorithms for combinatorial optimization: A decade of results\n", "abstract": " Computational time complexity analyzes of evolutionary algorithms (EAs) have been performed since the mid-nineties. The first results were related to very simple algorithms, such as the (1+1)-EA, on toy problems. These efforts produced a deeper understanding of how EAs perform on different kinds of fitness landscapes and general mathematical tools that may be extended to the analysis of more complicated EAs on more realistic problems. In fact, in recent years, it has been possible to analyze the (1+1)-EA on combinatorial optimization problems with practical applications and more realistic population-based EAs on structured toy problems. This paper presents a survey of the results obtained in the last decade along these two research lines. The most common mathematical techniques are introduced, the basic ideas behind them are discussed and their elective applications are highlighted. Solred\u00a0\u2026", "num_citations": "243\n", "authors": ["537"]}
{"title": "An evolutionary approach to materialized views selection in a data warehouse environment\n", "abstract": " A data warehouse (DW) contains multiple views accessed by queries. One of the most important decisions in designing a DW is selecting views to materialize for the purpose of efficiently supporting decision making. The search space for possible materialized views is exponentially large. Therefore heuristics have been used to search for a near optimal solution. In this paper, we explore the use of an evolutionary algorithm for materialized view selection based on multiple global processing plans for queries. We apply a hybrid evolutionary algorithm to solve three related problems. The first is to optimize queries. The second is to choose the best global processing plan from multiple global processing plans. The third is to select materialized views from a given global processing plan. Our experiment shows that the hybrid evolutionary algorithm delivers better performance than either the evolutionary algorithm or\u00a0\u2026", "num_citations": "235\n", "authors": ["537"]}
{"title": "Cooperative co-evolution with delta grouping for large scale non-separable function optimization\n", "abstract": " Many evolutionary algorithms have been proposed for large scale optimization. Parameter interaction in non-separable problems is a major source of performance loss specially on large scale problems. Cooperative Co-evolution(CC) has been proposed as a natural solution for large scale optimization problems, but lack of a systematic way of decomposing large scale non-separable problems is a major obstacle for CC frameworks. The aim of this paper is to propose a systematic way of capturing interacting variables for a more effective problem decomposition suitable for cooperative co-evolutionary frameworks. Grouping interacting variables in different subcomponents in a CC framework imposes a limit to the extent interacting variables can be optimized to their optimum values, in other words it limits the improvement interval of interacting variables. This is the central idea of the newly proposed technique which is\u00a0\u2026", "num_citations": "232\n", "authors": ["537"]}
{"title": "Towards designing artificial neural networks by evolution\n", "abstract": " Designing artificial neural networks (ANNs) for different applications has been a key issue in the ANN field. At present, ANN design still relies heavily on human experts who have sufficient knowledge about ANNs and the problem to be solved. As ANN complexity increases, designing ANNs manually becomes more difficult and unmanageable. Simulated evolution offers a promising approach to tackle this problem. This paper describes an evolutionary approach to design ANNs. The ANNs designed by the evolutionary process are referred to as evolutionary ANNs (EANNs). They represent a special class of ANNs in which evolution is another fundamental form of adaptation in addition to learning (also known as weight training). This paper describes an evolutionary programming (EP) based system to evolve both architectures and connection weights (including biases) of ANNs. Five mutation operators have been\u00a0\u2026", "num_citations": "225\n", "authors": ["537"]}
{"title": "Differential evolution for high-dimensional function optimization\n", "abstract": " Most reported studies on differential evolution (DE) are obtained using low-dimensional problems, e.g., smaller than 100, which are relatively small for many real-world problems. In this paper we propose two new efficient DE variants, named DECC-I and DECC-II, for high-dimensional optimization (up to 1000 dimensions). The two algorithms are based on a cooperative coevolution framework incorporated with several novel strategies. The new strategies are mainly focus on problem decomposition and subcomponents cooperation. Experimental results have shown that these algorithms have superior performance on a set of widely used benchmark functions.", "num_citations": "218\n", "authors": ["537"]}
{"title": "From an individual to a population: An analysis of the first hitting time of population-based evolutionary algorithms\n", "abstract": " Almost all analyses of time complexity of evolutionary algorithms (EAs) have been conducted for (1 + 1) EAs only. Theoretical results on the average computation time of population-based EAs are few. However, the vast majority of applications of EAs use a population size that is greater than one. The use of population has been regarded as one of the key features of EAs. It is important to understand in depth what the real utility of population is in terms of the time complexity of EAs, when EAs are applied to combinatorial optimization problems. This paper compares (1 + 1) EAs and (N + N) EAs theoretically by deriving their first hitting time on the same problems. It is shown that a population can have a drastic impact on an EA's average computation time, changing an exponential time to a polynomial time (in the input size) in some cases. It is also shown that the first hitting probability can be improved by introducing a\u00a0\u2026", "num_citations": "215\n", "authors": ["537"]}
{"title": "Evolving diverse ensembles using genetic programming for classification with unbalanced data\n", "abstract": " In classification, machine learning algorithms can suffer a performance bias when data sets are unbalanced. Data sets are unbalanced when at least one class is represented by only a small number of training examples (called the minority class), while the other class(es) make up the majority. In this scenario, classifiers can have good accuracy on the majority class, but very poor accuracy on the minority class(es). This paper proposes a multiobjective genetic programming (MOGP) approach to evolving accurate and diverse ensembles of genetic program classifiers with good performance on both the minority and majority of classes. The evolved ensembles comprise of nondominated solutions in the population where individual members vote on class membership. This paper evaluates the effectiveness of two popular Pareto-based fitness strategies in the MOGP algorithm (SPEA2 and NSGAII), and investigates\u00a0\u2026", "num_citations": "212\n", "authors": ["537"]}
{"title": "Population-based algorithm portfolios for numerical optimization\n", "abstract": " In this paper, we consider the scenario that a population-based algorithm is applied to a numerical optimization problem and a solution needs to be presented within a given time budget. Although a wide range of population-based algorithms, such as evolutionary algorithms, particle swarm optimizers, and differential evolution, have been developed and studied under this scenario, the performance of an algorithm may vary significantly from problem to problem. This implies that there is an inherent risk associated with the selection of algorithms. We propose that, instead of choosing an existing algorithm and investing the entire time budget in it, it would be less risky to distribute the time among multiple different algorithms. A new approach named population-based algorithm portfolio (PAP), which takes multiple algorithms as its constituent algorithms, is proposed based upon this idea. PAP runs each constituent\u00a0\u2026", "num_citations": "211\n", "authors": ["537"]}
{"title": "Evolutionary computation: Theory and applications\n", "abstract": " Evolutionary computation is the study of computational systems which use ideas and get inspiration from natural evolution and adaptation. This book is devoted to the theory and application of evolutionary computation. It is a self-contained volume which covers both introductory material and selected advanced topics. The book can roughly be divided into two major parts: the introductory one and the one on selected advanced topics. Each part consists of several chapters which present an in-depth discussion of selected topics. A strong connection is established between evolutionary algorithms and traditional search algorithms. This connection enables us to incorporate ideas in more established fields into evolutionary algorithms. The book is aimed at a wide range of readers. It does not require previous exposure to the field since introductory material is included. It will be of interest to anyone who is interested in adaptive optimization and learning. People in computer science, artificial intelligence, operations research, and various engineering fields will find it particularly interesting.", "num_citations": "204\n", "authors": ["537"]}
{"title": "Benchmark generator for CEC 2009 competition on dynamic optimization\n", "abstract": " Over the years, researchers have applied a number of dynamic test problems to compare the performance of EAs in dynamic environments, eg, the \u201cmoving peaks\u201d benchmark (MPB) proposed by Branke [1], the DF1 generator introduced by Morrison and De Jong [6], the singleand multi-objective dynamic test problem generator by dynamically combining different objective functions of exiting stationary multi-objective benchmark problems suggested by Jin and Sendhoff [2], Yang and Yao\u2019s exclusive-or (XOR) operator [10, 11, 12], Kang\u2019s dynamic traveling salesman problem (DTSP)[3] and dynamic multi knapsack problem (DKP), etc. Though a number of DOP generators exist in the literature, there is no unified approach of constructing dynamic problems across the binary space, real space and combinatorial space so far. This report uses the generalized dynamic benchmark generator (GDBG) proposed in [4], which construct dynamic environments for all the three solution spaces. Especially, in the real space, we introduce a rotation method instead of shifting the positions of peaks as in the MPB and DF1 generators. The rotation method can overcome the problem of unequal challenge per change for algorithms of the MPB generator, which happens when the peak positions bounce back from the boundary of the landscape.This report gives two benchmark instances from the GDBG system in the real space. The source code for the two benchmark instances and an test example using the PSO algorithm are available at http://www. cs. le. ac. uk/people/syang/ECiDUE/DBG. tar. gz and http://www. ntu. edu. sg/home/epnsugan/DBG. tar. gz respectively\u00a0\u2026", "num_citations": "201\n", "authors": ["537"]}
{"title": "Towards an analytic framework for analysing the computation time of evolutionary algorithms\n", "abstract": " In spite of many applications of evolutionary algorithms in optimisation, theoretical results on the computation time and time complexity of evolutionary algorithms on different optimisation problems are relatively few. It is still unclear when an evolutionary algorithm is expected to solve an optimisation problem efficiently or otherwise. This paper gives a general analytic framework for analysing first hitting times of evolutionary algorithms. The framework is built on the absorbing Markov chain model of evolutionary algorithms. The first step towards a systematic comparative study among different EAs and their first hitting times has been made in the paper.", "num_citations": "201\n", "authors": ["537"]}
{"title": "An experimental study of n-person iterated prisoner\u2019s dilemma games\n", "abstract": " The Iterated Prisoner's Dilemma game has been used extensively in the study of the evolution of cooperative behaviours in social and biological systems. There have been a lot of experimental studies on evolving strategies for 2-player Iterated Prisoner's Dilemma games (2IPD). However, there are many real world problems, especially many social and economic ones, which cannot be modelled by the 2IPD. The n-player Iterated Prisoner's Dilemma (NIPD) is a more realistic and general game which can model those problems. This paper presents two sets of experiments on evolving strategies for the NIPD. The rst set of experiments examine the impact of the number of players in the NIPD on the evolution of cooperation in the group. Our experiments show that cooperation is less likely to emerge in a large group than in a small group. The second set of experiments study the generalisation ability of evolved strategies from the point of view of machine learning. Our experiments reveal the e ect of changing the evolutionary environment of evolution on the generalisation ability of evolved strategies.", "num_citations": "200\n", "authors": ["537"]}
{"title": "Decomposition-based memetic algorithm for multiobjective capacitated arc routing problem\n", "abstract": " The capacitated arc routing problem (CARP) is a challenging combinatorial optimization problem with many real-world applications, e.g., salting route optimization and fleet management. There have been many attempts at solving CARP using heuristic and meta-heuristic approaches, including evolutionary algorithms. However, almost all such attempts formulate CARP as a single-objective problem although it usually has more than one objective, especially considering its real-world applications. This paper studies multiobjective CARP (MO-CARP). A new memetic algorithm (MA) called decomposition-based MA with extended neighborhood search (D-MAENS) is proposed. The new algorithm combines the advanced features from both the MAENS approach for single-objective CARP and multiobjective evolutionary optimization. Our experimental studies have shown that such combination outperforms significantly\u00a0\u2026", "num_citations": "195\n", "authors": ["537"]}
{"title": "Memetic algorithm with extended neighborhood search for capacitated arc routing problems\n", "abstract": " The capacitated arc routing problem (CARP) has attracted much attention during the last few years due to its wide applications in real life. Since CARP is NP-hard and exact methods are only applicable to small instances, heuristic and metaheuristic methods are widely adopted when solving CARP. In this paper, we propose a memetic algorithm, namely memetic algorithm with extended neighborhood search (MAENS), for CARP. MAENS is distinct from existing approaches in the utilization of a novel local search operator, namely Merge-Split (MS). The MS operator is capable of searching using large step sizes, and thus has the potential to search the solution space more efficiently and is less likely to be trapped in local optima. Experimental results show that MAENS is superior to a number of state-of-the-art algorithms, and the advanced performance of MAENS is mainly due to the MS operator. The application of\u00a0\u2026", "num_citations": "185\n", "authors": ["537"]}
{"title": "Ensemble learning using multi-objective evolutionary algorithms\n", "abstract": " Multi-objective evolutionary algorithms for the construction of neural ensembles is a relatively new area of research. We recently proposed an ensemble learning algorithm called DIVACE (DIVerse and ACcurate Ensemble learning algorithm). It was shown that DIVACE tries to find an optimal trade-off between diversity and accuracy as it searches for an ensemble for some particular pattern recognition task by treating these two objectives explicitly separately. A detailed discussion of DIVACE together with further experimental studies form the essence of this paper. A new diversity measure which we call Pairwise Failure Crediting (PFC) is proposed. This measure forms one of the two evolutionary pressures being exerted explicitly in DIVACE. Experiments with this diversity measure as well as comparisons with previously studied approaches are hence considered. Detailed analysis of the results show that\u00a0\u2026", "num_citations": "185\n", "authors": ["537"]}
{"title": "Cooperative co-evolution for large scale optimization through more frequent random grouping\n", "abstract": " In this paper we propose three techniques to improve the performance of one of the major algorithms for large scale continuous global function optimization. Multilevel Cooperative Co-evolution (MLCC) is based on a Cooperative Co-evolutionary framework and employs a technique called random grouping in order to group interacting variables in one subcomponent. It also uses another technique called adaptive weighting for co-adaptation of subcomponents. We prove that the probability of grouping interacting variables in one subcomponent using random grouping drops significantly as the number of interacting variables increases. This calls for more frequent random grouping of variables. We show how to increase the frequency of random grouping without increasing the number of fitness evaluations. We also show that adaptive weighting is ineffective and in most cases fails to improve the quality of found\u00a0\u2026", "num_citations": "180\n", "authors": ["537"]}
{"title": "A memetic algorithm for VLSI floorplanning\n", "abstract": " Floorplanning is an important problem in very large scale integrated-circuit (VLSI) design automation as it determines the performance, size, yield, and reliability of VLSI chips. From the computational point of view, VLSI floorplanning is an NP-hard problem. In this paper, a memetic algorithm (MA) for a nonslicing and hard-module VLSI floorplanning problem is presented. This MA is a hybrid genetic algorithm that uses an effective genetic search method to explore the search space and an efficient local search method to exploit information in the search region. The exploration and exploitation are balanced by a novel bias search strategy. The MA has been implemented and tested on popular benchmark problems. Experimental results show that the MA can quickly produce optimal or nearly optimal solutions for all the tested benchmark problems", "num_citations": "179\n", "authors": ["537"]}
{"title": "Making a difference to differential evolution\n", "abstract": " Differential evolution (DE) and evolutionary programming (EP) are two major algorithms in evolutionary computation. They have been applied with success to many real-world numerical optimization problems. Neighborhood search (NS) is a main strategy underpinning EP.There have been analyses of different NS operators\u2019 characteristics. Although DE might be similar to the evolutionary process in EP, it lacks the relevant concept of neighborhood search. In this chapter, DE with neighborhood search (NSDE) is proposed based on the generalization of NS strategy. The advantages of NS strategy in DE are analyzed theoretically. These analyses mainly focus on the change of search step size and population diversity after using neighborhood search. Experimental results have shown that DE with neighborhood search has significant advantages over other existing algorithms on a broad range of different\u00a0\u2026", "num_citations": "170\n", "authors": ["537"]}
{"title": "Mathematical modeling and multi-objective evolutionary algorithms applied to dynamic flexible job shop scheduling problems\n", "abstract": " Dynamic flexible job shop scheduling is of significant importance to the implementation of real-world manufacturing systems. In order to capture the dynamic and multi-objective nature of flexible job shop scheduling, and provide different trade-offs among objectives, this paper develops a multi-objective evolutionary algorithm (MOEA)-based proactive\u2013reactive method. The novelty of our method is that it is able to handle multiple objectives including efficiency and stability simultaneously, adapt to the new environment quickly by incorporating heuristic dynamic optimization strategies, and deal with two scheduling policies of machine assignment and operation sequencing together. Besides, a new mathematical model for the multi-objective dynamic flexible job shop scheduling problem (MODFJSSP) is constructed. With the aim of selecting one solution that fits into the decision maker\u2019s preferences from the trade-off\u00a0\u2026", "num_citations": "169\n", "authors": ["537"]}
{"title": "DG2: A faster and more accurate differential grouping for large-scale black-box optimization\n", "abstract": " Identification of variable interaction is essential for an efficient implementation of a divide-and-conquer algorithm for large-scale black-box optimization. In this paper, we propose an improved variant of the differential grouping (DG) algorithm, which has a better efficiency and grouping accuracy. The proposed algorithm, DG2, finds a reliable threshold value by estimating the magnitude of roundoff errors. With respect to efficiency, DG2 reuses the sample points that are generated for detecting interactions and saves up to half of the computational resources on fully separable functions. We mathematically show that the new sampling technique achieves the lower bound with respect to the number of function evaluations. Unlike its predecessor, DG2 checks all possible pairs of variables for interactions and has the capacity to identify overlapping components of an objective function. On the accuracy aspect, DG2 outperforms\u00a0\u2026", "num_citations": "165\n", "authors": ["537"]}
{"title": "Evolving hybrid ensembles of learning machines for better generalisation\n", "abstract": " Ensembles of learning machines have been formally and empirically shown to outperform (generalise better than) single predictors in many cases. Evidence suggests that ensembles generalise better when they constitute members which form a diverse and accurate set. Additionally, there have been a multitude of theories on how one can enforce diversity within a combined predictor setup. We recently attempted to integrate these theories together into a co-evolutionary framework with a view to synthesising new evolutionary ensemble learning algorithms using the fact that multi-objective evolutionary optimisation is a formidable ensemble construction technique. This paper explicates on the intricacies of the proposed framework in addition to presenting detailed empirical results and comparisons with a wide range of algorithms in the machine learning literature. The framework treats diversity and accuracy as\u00a0\u2026", "num_citations": "165\n", "authors": ["537"]}
{"title": "A competitive divide-and-conquer algorithm for unconstrained large-scale black-box optimization\n", "abstract": " This article proposes a competitive divide-and-conquer algorithm for solving large-scale black-box optimization problems for which there are thousands of decision variables and the algebraic models of the problems are unavailable. We focus on problems that are partially additively separable, since this type of problem can be further decomposed into a number of smaller independent subproblems. The proposed algorithm addresses two important issues in solving large-scale black-box optimization: (1) the identification of the independent subproblems without explicitly knowing the formula of the objective function and (2) the optimization of the identified black-box subproblems. First, a Global Differential Grouping (GDG) method is proposed to identify the independent subproblems. Then, a variant of the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) is adopted to solve the subproblems resulting from\u00a0\u2026", "num_citations": "155\n", "authors": ["537"]}
{"title": "A survey on problem models and solution approaches to rescheduling in railway networks\n", "abstract": " Rescheduling in railway networks is a challenging problem in both practice and theory. It requires good quality solutions in reasonable computation time to resolve unexpected situations, involving different problem scales, railway network infrastructures, objectives, and constraints. This paper presents a comprehensive survey on different problem models for rescheduling in railway networks by a clear classification. Some frequently used models are described in detail through reviewing their variables and constraints. This paper also focuses on the solution approaches proposed in the literature. The main ideas of the solution approaches with the objectives are described. Based on our review results, the analysis of the problem models used in various problem types and the solution approaches used in different problem models are presented. Conclusion and suggestions for further research to rescheduling in\u00a0\u2026", "num_citations": "155\n", "authors": ["537"]}
{"title": "Materialized view selection as constrained evolutionary optimization\n", "abstract": " One of the important issues in data warehouse development is the selection of a set of views to materialize in order to accelerate a large number of on-line analytical processing (OLAP) queries. The maintenance-cost view-selection problem is to select a set of materialized views under certain resource constraints for the purpose of minimizing the total query processing cost. However, the search space for possible materialized views may be exponentially large. A heuristic algorithm often has to be used to find a near optimal solution. In this paper, for the maintenance-cost view-selection problem, we propose a new constrained evolutionary algorithm. Constraints are incorporated into the algorithm through a stochastic ranking procedure. No penalty functions are used. Our experimental results show that the constraint handling technique, i.e., stochastic ranking, can deal with constraints effectively. Our algorithm is able\u00a0\u2026", "num_citations": "154\n", "authors": ["537"]}
{"title": "Thermodynamic Pareto optimization of turbojet engines using multi-objective genetic algorithms\n", "abstract": " Multi-objective genetic algorithms (GAs) are used for Pareto approach optimization of thermodynamic cycle of ideal turbojet engines. On this behalf, a new diversity preserving algorithm is proposed to enhance the performance of multi-objective evolutionary algorithms (MOEAs) in optimization problems with more than two objective functions. The important conflicting thermodynamic objectives that have been considered in this work are, namely, specific thrust (ST), thrust-specific fuel consumption (TSFC), propulsive efficiency (\u03b7 p), and thermal efficiency (\u03b7 t). In this paper, different pairs of these objective functions have been selected for two-objective optimization processes. Moreover, these objectives have also been considered for a four-objective optimization problem using the new diversity preserving algorithm of this work. The comparison results demonstrate the superiority of the new algorithm in preserving the\u00a0\u2026", "num_citations": "153\n", "authors": ["537"]}
{"title": "Evolutionary generative adversarial networks\n", "abstract": " Generative adversarial networks (GANs) have been effective for learning generative models for real-world data. However, accompanied with the generative tasks becoming more and more challenging, existing GANs (GAN and its variants) tend to suffer from different training problems such as instability and mode collapse. In this paper, we propose a novel GAN framework called evolutionary GANs (E-GANs) for stable GAN training and improved generative performance. Unlike existing GANs, which employ a predefined adversarial objective function alternately training a generator and a discriminator, we evolve a population of generators to play the adversarial game with the discriminator. Different adversarial training objectives are employed as mutation operations and each individual (i.e., generator candidature) are updated based on these mutations. Then, we devise an evaluation mechanism to measure the\u00a0\u2026", "num_citations": "152\n", "authors": ["537"]}
{"title": "Dynamic sampling approach to training neural networks for multiclass imbalance classification\n", "abstract": " Class imbalance learning tackles supervised learning problems where some classes have significantly more examples than others. Most of the existing research focused only on binary-class cases. In this paper, we study multiclass imbalance problems and propose a dynamic sampling method (DyS) for multilayer perceptrons (MLP). In DyS, for each epoch of the training process, every example is fed to the current MLP and then the probability of it being selected for training the MLP is estimated. DyS dynamically selects informative data to train the MLP. In order to evaluate DyS and understand its strength and weakness, comprehensive experimental studies have been carried out. Results on 20 multiclass imbalanced data sets show that DyS can outperform the compared methods, including pre-sample methods, active learning methods, cost-sensitive methods, and boosting-type methods.", "num_citations": "151\n", "authors": ["537"]}
{"title": "Interaction dynamics of neuronal oscillations analysed using wavelet transforms\n", "abstract": " This paper describes the use of a computational tool based on the Morlet wavelet transform to investigate the interaction dynamics between oscillations generated by two anatomically distinct neuronal populations. The tool uses cross wavelet transform, coherence, bi-spectrum/bi-coherence and phase synchronization.Using specimen data recorded from the hippocampus of a rat with experimentally induced focal epilepsy, linear and non-linear correlations between neuronal oscillations in the CA1 and CA3 regions have been computed.The results of this real case study show that the computational tool can successfully analyse and quantify the temporal interactions between neuronal oscillators and could be employed to investigate the mechanisms underlying epilepsy.", "num_citations": "149\n", "authors": ["537"]}
{"title": "A new adaptive merging and growing algorithm for designing artificial neural networks\n", "abstract": " This paper presents a new algorithm, called adaptive merging and growing algorithm (AMGA), in designing artificial neural networks (ANNs). This algorithm merges and adds hidden neurons during the training process of ANNs. The merge operation introduced in AMGA is a kind of a mixed mode operation, which is equivalent to pruning two neurons and adding one neuron. Unlike most previous studies, AMGA puts emphasis on autonomous functioning in the design process of ANNs. This is the main reason why AMGA uses an adaptive not a predefined fixed strategy in designing ANNs. The adaptive strategy merges or adds hidden neurons based on the learning ability of hidden neurons or the training progress of ANNs. In order to reduce the amount of retraining after modifying ANN architectures, AMGA prunes hidden neurons by merging correlated hidden neurons and adds hidden neurons by splitting existing\u00a0\u2026", "num_citations": "145\n", "authors": ["537"]}
{"title": "Stochastic ranking algorithm for many-objective optimization based on multiple indicators\n", "abstract": " Traditional multiobjective evolutionary algorithms face a great challenge when dealing with many objectives. This is due to a high proportion of nondominated solutions in the population and low selection pressure toward the Pareto front. In order to tackle this issue, a series of indicator-based algorithms have been proposed to guide the search process toward the Pareto front. However, a single indicator might be biased and lead the population to converge to a subregion of the Pareto front. In this paper, a multi-indicator-based algorithm is proposed for many-objective optimization problems. The proposed algorithm, namely stochastic ranking-based multi-indicator Algorithm (SRA), adopts the stochastic ranking technique to balance the search biases of different indicators. Empirical studies on a large number (39 in total) of problem instances from two well-defined benchmark sets with 5, 10, and 15 objectives\u00a0\u2026", "num_citations": "140\n", "authors": ["537"]}
{"title": "Evolving artificial neural network ensembles\n", "abstract": " Using a coordinated group of simple solvers to tackle a complex problem is not an entirely new idea. Its root could be traced back hundreds of years ago when ancient Chinese suggested a team approach to problem solving. For a long time, engineers have used the divide-and-conquer strategy to decompose a complex problem into simpler sub-problems and then solve them by a group of solvers. However, knowing the best way to divide a complex problem into simpler ones relies heavily on the available domain knowledge. It is often a manual process by an experienced engineer. There have been few automatic divide-and-conquer methods reported in the literature. Fortunately, evolutionary computation provides some of the interesting avenues to automatic divide-and-conquer methods. An in-depth study of such methods reveals that there is a deep underlying connection between evolutionary computation and\u00a0\u2026", "num_citations": "140\n", "authors": ["537"]}
{"title": "Multiobjective neural network ensembles based on regularized negative correlation learning\n", "abstract": " Negative Correlation Learning (NCL) [CHECK END OF SENTENCE], [CHECK END OF SENTENCE] is a neural network ensemble learning algorithm which introduces a correlation penalty term to the cost function of each individual network so that each neural network minimizes its mean-square-error (MSE) together with the correlation. This paper describes NCL in detail and observes that the NCL corresponds to training the entire ensemble as a single learning machine that only minimizes the MSE without regularization. This insight explains that NCL is prone to overfitting the noise in the training set. The paper analyzes this problem and proposes the multiobjective regularized negative correlation learning (MRNCL) algorithm which incorporates an additional regularization term for the ensemble and uses the evolutionary multiobjective algorithm to design ensembles. In MRNCL, we define the crossover and\u00a0\u2026", "num_citations": "139\n", "authors": ["537"]}
{"title": "Recent advances in evolutionary computation\n", "abstract": " Evolutionary computation has experienced a tremendous growth in the last decade in both theoretical analyses and industrial applications. Its scope has evolved beyond its original meaning of \u201cbiological evolution\u201d toward a wide variety of nature inspired computational algorithms and techniques, including evolutionary, neural, ecological, social and economical computation, etc., in a unified framework. Many research topics in evolutionary computation nowadays are not necessarily \u201cevolutionary\u201d. This paper provides an overview of some recent advances in evolutionary computation that have been made in CERCIA at the University of Birmingham, UK. It covers a wide range of topics in optimization, learning and design using evolutionary approaches and techniques, and theoretical results in the computational time complexity of evolutionary algorithms. Some issues related to future development of\u00a0\u2026", "num_citations": "139\n", "authors": ["537"]}
{"title": "Speciation as automatic categorical modularization\n", "abstract": " Many natural and artificial systems use a modular approach to reduce the complexity of a set of subtasks while solving the overall problem satisfactorily. There are two distinct ways to do this. In functional modularization, the components perform very different tasks, such as subroutines of a large software project. In categorical modularization, the components perform different versions of basically the same task, such as antibodies in the immune system. This second aspect is the more natural for acquiring strategies in games of conflict, An evolutionary learning system is presented which follows this second approach to automatically create a repertoire of specialist strategies for a game-playing system. This relieves the human effort of deciding how to divide and specialize. The genetic algorithm speciation method used is one based on fitness sharing. The learning task is to play the iterated prisoner's dilemma. The\u00a0\u2026", "num_citations": "139\n", "authors": ["537"]}
{"title": "Diversity assessment in many-objective optimization\n", "abstract": " Maintaining diversity is one important aim of multiobjective optimization. However, diversity for manyobjective optimization problems is less straightforward to define than for multiobjective optimization problems. Inspired by measures for biodiversity, we propose a new diversity metric for many-objective optimization, which is an accumulation of the dissimilarity in the population, where an Lp-norm-based (p<;1) distance is adopted to measure the dissimilarity of solutions. Empirical results demonstrate our proposed metric can more accurately assess the diversity of solutions in various situations. We compare the diversity of the solutions obtained by four popular many-objective evolutionary algorithms using the proposed diversity metric on a large number of benchmark problems with two to ten objectives. The behaviors of different diversity maintenance methodologies in those algorithms are discussed in depth based\u00a0\u2026", "num_citations": "138\n", "authors": ["537"]}
{"title": "An evolutionary clustering algorithm for gene expression microarray data analysis\n", "abstract": " Clustering is concerned with the discovery of interesting groupings of records in a database. Many algorithms have been developed to tackle clustering problems in a variety of application domains. In particular, some of them have been used in bioinformatics research to uncover inherent clusters in gene expression microarray data. In this paper, we show how some popular clustering algorithms have been used for this purpose. Based on experiments using simulated and real data, we also show that the performance of these algorithms can be further improved. For more effective clustering of gene expression microarray data, which is typically characterized by a lot of noise, we propose a novel evolutionary algorithm called evolutionary clustering (EvoCluster). EvoCluster encodes an entire cluster grouping in a chromosome so that each gene in the chromosome encodes one cluster. Based on such encoding\u00a0\u2026", "num_citations": "138\n", "authors": ["537"]}
{"title": "Regularized negative correlation learning for neural network ensembles\n", "abstract": " Negative correlation learning (NCL) is a neural network ensemble learning algorithm that introduces a correlation penalty term to the cost function of each individual network so that each neural network minimizes its mean square error (MSE) together with the correlation of the ensemble. This paper analyzes NCL and reveals that the training of NCL (when \u00bf = 1) corresponds to training the entire ensemble as a single learning machine that only minimizes the MSE without regularization. This analysis explains the reason why NCL is prone to overfitting the noise in the training set. This paper also demonstrates that tuning the correlation parameter \u00bf in NCL by cross validation cannot overcome the overfitting problem. The paper analyzes this problem and proposes the regularized negative correlation learning (RNCL) algorithm which incorporates an additional regularization term for the whole ensemble. RNCL\u00a0\u2026", "num_citations": "137\n", "authors": ["537"]}
{"title": "Tackling high dimensional nonseparable optimization problems by cooperatively coevolving particle swarms\n", "abstract": " This paper attempts to address the question of scaling up particle swarm optimization (PSO) algorithms to high dimensional optimization problems. We present a cooperative coevolving PSO (CCPSO) algorithm incorporating random grouping and adaptive weighting, two techniques that have been shown to be effective for handling high dimensional nonseparable problems. The proposed CCPSO algorithms out-performed a previously developed coevolving PSO algorithm on nonseparable functions of 30 dimensions. Furthermore, the scalability of the proposed algorithm to high dimensional nonseparable problems (of up to 1000 dimensions) is examined and compared with two existing coevolving differential evolution (DE) algorithms, and new insights are obtained. Our experimental results show the proposed CCPSO algorithms can perform reasonably well with only a small number of evaluations. The results\u00a0\u2026", "num_citations": "137\n", "authors": ["537"]}
{"title": "Evolutionary search of approximated n-dimensional landscapes\n", "abstract": " Finding the global optimum on a large, multimodal, complex, and discontinuous (or nondifferentiable) landscape is usually very hard, even using the evolutionary approach. However, some of these complex landscapes can be approximated and smoothened without changing the nature of the problem, ie, without modifying the global optimum and its location. The approximated and smoothened landscape is often much easier to search than the original one. In this paper, we propose a new algorithm using landscape approximation and hybrid evolutionary and local search. We also list several algorithm design principles. Following the basic algorithm, an example algorithm is given from our previous work of the combination of landscape approximation and local search (LALS). Furthermore, we develop a novel evolutionary algorithm with n-dimensional approximation (EANA), which shares the same rules as the basic algorithm, but remedies some of the drawbacks found in the LALS. Comparisons with evolution strategies and improved fast evolutionary programming are also given in this paper to show the advantages and disadvantages of the proposed algorithms.", "num_citations": "137\n", "authors": ["537"]}
{"title": "On evolving robust strategies for iterated prisoner's dilemma\n", "abstract": " Evolution is a fundamental form of adaptation in a dynamic and complex environment. Genetic algorithms are an effective tool in the empirical study of evolution. This paper follows Axelrod's work [2] in using the genetic algorithm to evolve strategies for playing the game of Iterated Prisoner's Dilemma, using co-evolution, where each member of the population (each strategy) is evaluated by how it performs against the other members of the current population. This creates a dynamic environment in which the algorithm is optimising to a moving target instead of the usual evaluation against some fixed set of strategies. The hope is that this will stimulate an \u201carms race\u201d of innovation [3].             We conduct two sets of experiments. The first set investigates what conditions evolve the best strategies. The second set studies the robustness of the strategies thus evolved, that is, are the strategies useful only in the round\u00a0\u2026", "num_citations": "136\n", "authors": ["537"]}
{"title": "Relationships between diversity of classification ensembles and single-class performance measures\n", "abstract": " In class imbalance learning problems, how to better recognize examples from the minority class is the key focus, since it is usually more important and expensive than the majority class. Quite a few ensemble solutions have been proposed in the literature with varying degrees of success. It is generally believed that diversity in an ensemble could help to improve the performance of class imbalance learning. However, no study has actually investigated diversity in depth in terms of its definitions and effects in the context of class imbalance learning. It is unclear whether diversity will have a similar or different impact on the performance of minority and majority classes. In this paper, we aim to gain a deeper understanding of if and when ensemble diversity has a positive impact on the classification of imbalanced data sets. First, we explain when and why diversity measured by Q-statistic can bring improved overall\u00a0\u2026", "num_citations": "132\n", "authors": ["537"]}
{"title": "A new multi-objective evolutionary optimisation algorithm: The two-archive algorithm\n", "abstract": " Many multi-objective evolutionary algorithms (MOEAs) have been proposed in recent years. However, almost all MOEAs have been evaluated on problems with two to four objectives only. It is unclear how well these MOEAs will perform on problems with a large number of objectives. Our preliminary study (V. Khare et al., 2003) showed that performance of some MOEAs deteriorates significantly as the number of objectives increases. This paper proposes a new MOEA that performs well on problems with a large number of objectives. The new algorithm separates non-dominated solutions into two archives, and is thus called the two-archive algorithm. The two archives focused on convergence and diversity, respectively, in optimisation. Computational studies have been carried out to evaluate and compare our new algorithm against the best MOEA for problems with a large number of objectives. Our experimental\u00a0\u2026", "num_citations": "132\n", "authors": ["537"]}
{"title": "Probabilistic classification vector machines\n", "abstract": " In this paper, a sparse learning algorithm, probabilistic classification vector machines (PCVMs), is proposed. We analyze relevance vector machines (RVMs) for classification problems and observe that adopting the same prior for different classes may lead to unstable solutions. In order to tackle this problem, a signed and truncated Gaussian prior is adopted over every weight in PCVMs, where the sign of prior is determined by the class label, i.e., +1 or -1. The truncated Gaussian prior not only restricts the sign of weights but also leads to a sparse estimation of weight vectors, and thus controls the complexity of the model. In PCVMs, the kernel parameters can be optimized simultaneously within the training algorithm. The performance of PCVMs is extensively evaluated on four synthetic data sets and 13 benchmark data sets using three performance metrics, error rate (ERR), area under the curve of receiver operating\u00a0\u2026", "num_citations": "128\n", "authors": ["537"]}
{"title": "The iterated prisoners' dilemma: 20 years on\n", "abstract": " In 1984, Robert Axelrod published a book, relating the story of two competitions which he ran, where invited academics entered strategies for the Iterated Prisoners' Dilemma. The book, almost 20 years on, is still widely read and cited by academics and the general public. As a celebration of that landmark work, we have recreated those competitions to celebrate its 20th anniversary, by again inviting academics to submit prisoners' dilemma strategies. The first of these new competitions was run in July 2004, and the second in April 2005. Iterated Prisoners' Dilemma: 20 Years On essentially provides an update of the Axelrod's book. Specifically, it? Presents the prisoners' dilemma, its history and variants? Highlights original Axelrod's work and its impact? Discusses results of new competitions? Showcases selected papers that reflect the latest researches in the area", "num_citations": "128\n", "authors": ["537"]}
{"title": "An empirical study of genetic operators in genetic algorithms\n", "abstract": " Genetic algorithms are multi-agent search strategies applicable to a wide range of problems. However, it is often very difficult in practice to design an optimal set of genetic operators for a problem, because a genetic operator which works well for a problem might not work well for another problem. This paper tries to understand when and why some genetic operators are useful and how we can combine them together to improve the performance of genetic algorithms. Experiments have been carried out to analyse the role of crossover and mutation as well as selection mechanisms. Several genetic algorithms with different genetic operators and selection mechanisms are used in the empirical study. The study suggests that \u201cgreedy\u201d crossover and \u201chard\u201d selection with a low mutation rate often give genetic algorithms better performance.", "num_citations": "128\n", "authors": ["537"]}
{"title": "Robust online time series prediction with recurrent neural networks\n", "abstract": " Time series forecasting for streaming data plays an important role in many real applications, ranging from IoT systems, cyber-networks, to industrial systems and healthcare. However the real data is often complicated with anomalies and change points, which can lead the learned models deviating from the underlying patterns of the time series, especially in the context of online learning mode. In this paper we present an adaptive gradient learning method for recurrent neural networks (RNN) to forecast streaming time series in the presence of anomalies and change points. We explore the local features of time series to automatically weight the gradients of the loss of the newly available observations with distributional properties of the data in real time. We perform extensive experimental analysis on both synthetic and real datasets to evaluate the performance of the proposed method.", "num_citations": "124\n", "authors": ["537"]}
{"title": "Linear dimensionality reduction using relevance weighted LDA\n", "abstract": " The linear discriminant analysis (LDA) is one of the most traditional linear dimensionality reduction methods. This paper incorporates the inter-class relationships as relevance weights into the estimation of the overall within-class scatter matrix in order to improve the performance of the basic LDA method and some of its improved variants. We demonstrate that in some specific situations the standard multi-class LDA almost totally fails to find a discriminative subspace if the proposed relevance weights are not incorporated. In order to estimate the relevance weights of individual within-class scatter matrices, we propose several methods of which one employs the evolution strategies.", "num_citations": "121\n", "authors": ["537"]}
{"title": "Cooperative coevolution with route distance grouping for large-scale capacitated arc routing problems\n", "abstract": " In this paper, a divide-and-conquer approach is proposed to solve the large-scale capacitated arc routing problem (LSCARP) more effectively. Instead of considering the problem as a whole, the proposed approach adopts the cooperative coevolution (CC) framework to decompose it into smaller ones and solve them separately. An effective decomposition scheme called the route distance grouping (RDG) is developed to decompose the problem. Its merit is twofold. First, it employs the route information of the best-so-far solution, so that the quality of the decomposition is upper bounded by that of the best-so-far solution. Thus, it can keep improving the decomposition by updating the best-so-far solution during the search. Second, it defines a distance between routes, based on which the potentially better decompositions can be identified. Therefore, RDG is able to obtain promising decompositions and focus the search\u00a0\u2026", "num_citations": "120\n", "authors": ["537"]}
{"title": "An evolutionary multiobjective approach to sparse reconstruction\n", "abstract": " This paper addresses the problem of finding sparse solutions to linear systems. Although this problem involves two competing cost function terms (measurement error and a sparsity-inducing term), previous approaches combine these into a single cost term and solve the problem using conventional numerical optimization methods. In contrast, the main contribution of this paper is to use a multiobjective approach. The paper begins by investigating the sparse reconstruction problem, and presents data to show that knee regions do exist on the Pareto front (PF) for this problem and that optimal solutions can be found in these knee regions. Another contribution of the paper, a new soft-thresholding evolutionary multiobjective algorithm (StEMO), is then presented, which uses a soft-thresholding technique to incorporate two additional heuristics: one with greater chance to increase speed of convergence toward the PF\u00a0\u2026", "num_citations": "119\n", "authors": ["537"]}
{"title": "A new evolutionary approach to cutting stock problems with and without contiguity\n", "abstract": " Evolutionary algorithms (EAs) have been applied to many optimization problems successfully in recent years. The genetic algorithm (GAs) and evolutionary programming (EP) are two different types of EAs. GAs use crossover as the primary search operator and mutation as a background operator, while EP uses mutation as the primary search operator and does not employ any crossover. This paper proposes a novel EP algorithm for cutting stock problems with and without contiguity. Two new mutation operators are proposed. Experimental studies have been carried out to examine the effectiveness of the EP algorithm. They show that EP can provide a simple yet more effective alternative to GAs in solving cutting stock problems with and without contiguity. The solutions found by EP are significantly better (in most cases) than or comparable to those found by GAs.Scope and purposeThe one-dimensional cutting stock\u00a0\u2026", "num_citations": "119\n", "authors": ["537"]}
{"title": "Corner sort for Pareto-based many-objective optimization\n", "abstract": " Nondominated sorting plays an important role in Pareto-based multiobjective evolutionary algorithms (MOEAs). When faced with many-objective optimization problems multiobjective optimization problems (MOPs) with more than three objectives, the number of comparisons needed in nondominated sorting becomes very large. In view of this, a new corner sort is proposed in this paper. Corner sort first adopts a fast and simple method to obtain a nondominated solution from the corner solutions, and then uses the nondominated solution to ignore the solutions dominated by it to save comparisons. Obtaining the nondominated solutions requires much fewer objective comparisons in corner sort. In order to evaluate its performance, several state-of-the-art nondominated sorts are compared with our corner sort on three kinds of artificial solution sets of MOPs and the solution sets generated from MOEAs on benchmark\u00a0\u2026", "num_citations": "118\n", "authors": ["537"]}
{"title": "Every niching method has its niche: Fitness sharing and implicit sharing compared\n", "abstract": " Various extensions to the Genetic Algorithm (GA) attempt to find all or most optima in a search space containing several optima. Many of these emulate natural speciation. For co-evolutionary learning to succeed in a range of management and control problems, such as learning game strategies, such methods must find all or most optima. However, suitable comparison studies are rare. We compare two similar GA speciation methods, fitness sharing and implicit sharing. Using a realistic letter classification problem, we find they have advantages under different circumstances. Implicit sharing covers optima more comprehensively, when the population is large enough for a species to form at each optimum. With a population not large enough to do this, fitness sharing can find the optima with larger basins of attraction, and ignore the peaks with narrow bases, while implicit sharing is more easily distracted. This\u00a0\u2026", "num_citations": "116\n", "authors": ["537"]}
{"title": "Evolutionary design of artificial neural networks with different nodes\n", "abstract": " Evolutionary design of artificial neural networks (ANNs) offers a very promising and automatic alternative to designing ANNs manually. The advantage of evolutionary design over the manual design is their adaptability to a dynamic environment. Most research in evolving ANNs only deals with the topological structure of ANNs and little has been done on the evolution of both topological structures and node transfer functions. The paper presents a new automatic method to design general neural networks (GNNs) with different nodes. GNNs combine generalisation capabilities of distributed neural networks (DNNs) and computational efficiency of local neural networks (LNNs). We use an evolutionary programming (EP) algorithm with new mutation operators which are very effective for evolving GNN architectures and weights simultaneously. Our EP algorithm allows GNNs to grow as well as shrink during the\u00a0\u2026", "num_citations": "116\n", "authors": ["537"]}
{"title": "A learning-to-rank approach to software defect prediction\n", "abstract": " Software defect prediction can help to allocate testing resources efficiently through ranking software modules according to their defects. Existing software defect prediction models that are optimized to predict explicitly the number of defects in a software module might fail to give an accurate order because it is very difficult to predict the exact number of defects in a software module due to noisy data. This paper introduces a learning-to-rank approach to construct software defect prediction models by directly optimizing the ranking performance. In this paper, we build on our previous work, and further study whether the idea of directly optimizing the model performance measure can benefit software defect prediction model construction. The work includes two aspects: one is a novel application of the learning-to-rank approach to real-world data sets for software defect prediction, and the other is a comprehensive\u00a0\u2026", "num_citations": "115\n", "authors": ["537"]}
{"title": "A hybrid Hopfield network-genetic algorithm approach for the terminal assignment problem\n", "abstract": " This paper presents a hybrid Hopfield network-genetic algorithm (GA) approach to tackle the terminal assignment (TA) problem. TA involves determining minimum cost links to form a communications network, by connecting a given set of terminals to a given collection of concentrators. Some previous approaches provide very good results if the cost associated with assigning a single terminal to a given concentrator is known. However, there are situations in which the cost of a single assignment is not known in advance, and only the cost associated with feasible solutions can be calculated. In these situations, previous algorithms for TA based on greedy heuristics are no longer valid, or fail to get feasible solutions. Our approach involves a Hopfield neural network (HNN) which manages the problem's constraints, whereas a GA searches for high quality solutions with the minimum possible cost. We show that our\u00a0\u2026", "num_citations": "115\n", "authors": ["537"]}
{"title": "A novel evolutionary algorithm for determining unified creep damage constitutive equations\n", "abstract": " The determination of material constants within unified creep damage constitutive equations from experimental data can be formulated as a problem of finding the global minimum of a well defined objective function. However, such an objective function is usually complex, non-convex and non-differentiable. It is difficult to be optimised by classical gradient-based methods. In this paper, the difficulties in the optimisation are firstly identified. Two different objective functions are proposed, analysed and compared. Then three evolutionary programming algorithms are introduced to solve the global optimisation problem. The evolutionary algorithms are particularly good at dealing with problems which are complex, multi-modal and non-differentiable. The results of the study shows that the evolutionary algorithms are ideally suited to the problem. Computational results of using the algorithms to determine the material\u00a0\u2026", "num_citations": "115\n", "authors": ["537"]}
{"title": "Neural-based learning classifier systems\n", "abstract": " UCS is a supervised learning classifier system that was introduced in 2003 for classification in data mining tasks. The representation of a rule in UCS as a univariate classification rule is straightforward for a human to understand. However, the system may require a large number of rules to cover the input space. Artificial neural networks (NNs), on the other hand, normally provide a more compact representation. However, it is not a straightforward task to understand the network. In this paper, we propose a novel way to incorporate NNs into UCS. The approach offers a good compromise between compactness, expressiveness, and accuracy. By using a simple artificial NN as the classifier's action, we obtain a more compact population size, better generalization, and the same or better accuracy while maintaining a reasonable level of expressiveness. We also apply negative correlation learning (NCL) during the training\u00a0\u2026", "num_citations": "113\n", "authors": ["537"]}
{"title": "A large population size can be unhelpful in evolutionary algorithms\n", "abstract": " The utilization of populations is one of the most important features of evolutionary algorithms (EAs). There have been many studies analyzing the impact of different population sizes on the performance of EAs. However, most of such studies are based on computational experiments, except for a few cases. The common wisdom so far appears to be that a large population would increase the population diversity and thus help an EA. Indeed, increasing the population size has been a commonly used strategy in tuning an EA when it did not perform as well as expected for a given problem. He and Yao (2002)\u00a0[8] showed theoretically that for some problem instance classes, a population can help to reduce the runtime of an EA from exponential to polynomial time. This paper analyzes the role of population further in EAs and shows rigorously that large populations may not always be useful. Conditions, under which large\u00a0\u2026", "num_citations": "112\n", "authors": ["537"]}
{"title": "A new simulated annealing algorithm\n", "abstract": " Simulated Annealing (SA) is a powerful stochastic search algorithm applicable to a wide range of problems for which little prior knowledge is available. The annealing schedule, i.e., the temperature decreasing rate used in SA is an important factor which affects SA's rate of convergence. This paper investigates annealing schedules used in various SA algorithms, e.g., the classical SA (CSA) [1], fast SA (FSA) [2] and very fast SA (VFSA) [3], and proposes a new SA (NSA) algorithm whose annealing schedule is exponentially faster than that of VFSA. The heuristic proof given in the paper follows the same method as that used by Szu and Hartley [2] and Ingber [3] in their studies. The paper also discusses the relationship between the annealing schedule and SA's rate of convergence", "num_citations": "109\n", "authors": ["537"]}
{"title": "A cooperative coevolutionary algorithm with correlation based adaptive variable partitioning\n", "abstract": " A cooperative coevolutionary algorithm (CCEA) is an extension to an evolutionary algorithm (EA); it employs a divide and conquer strategy to solve an optimization problem. In its basic form, a CCEA splits the variables of an optimization problem into multiple smaller subsets and evolves them independently in different subpopulations. The dynamics of a CCEA is far more complex than an EA and its performance can vary from good to bad depending on the separability of the optimization problem. This paper provides some insights into why CCEA in its basic form is not suitable for nonseparable problems and introduces a cooperative coevolutionary algorithm with correlation based adaptive variable partitioning (CCEA-AVP) to deal with such problems. The performance of CCEA-AVP is compared with CCEA and EA to highlight its benefits. CCEA-AVP offers the possibility to deal with problems where separability\u00a0\u2026", "num_citations": "108\n", "authors": ["537"]}
{"title": "Scalability of generalized adaptive differential evolution for large-scale continuous optimization\n", "abstract": " Differential evolution (DE) has become a very powerful tool for global continuous optimization problems. Parameter adaptations are the most commonly used techniques to improve its performance. The adoption of these techniques has assisted the success of many adaptive DE variants. However, most studies on these adaptive DEs are limited to some small-scale problems, e.g. with less than 100 decision variables, which may be quite small comparing to the requirements of real-world applications. The scalability performance of adaptive DE is still unclear. In this paper, based on the analyses of similarities and drawbacks of existing parameter adaptation schemes in DE, we propose a generalized parameter adaptation scheme. Applying the scheme to DE results in a new generalized adaptive DE (GaDE) algorithm. The scalability performance of GaDE is evaluated on 19 benchmark functions with problem\u00a0\u2026", "num_citations": "106\n", "authors": ["537"]}
{"title": "Gene selection algorithms for microarray data based on least squares support vector machine\n", "abstract": " In discriminant analysis of microarray data, usually a small number of samples are expressed by a large number of genes. It is not only difficult but also unnecessary to conduct the discriminant analysis with all the genes. Hence, gene selection is usually performed to select important genes. A gene selection method searches for an optimal or near optimal subset of genes with respect to a given evaluation criterion. In this paper, we propose a new evaluation criterion, named the leave-one-out calculation (LOOC, A list of abbreviations appears just above the list of references) measure. A gene selection method, named leave-one-out calculation sequential forward selection (LOOCSFS) algorithm, is then presented by combining the LOOC measure with the sequential forward selection scheme. Further, a novel gene selection algorithm, the gradient-based leave-one-out gene selection (GLGS) algorithm, is also\u00a0\u2026", "num_citations": "106\n", "authors": ["537"]}
{"title": "Behavioral diversity, choices and noise in the iterated prisoner's dilemma\n", "abstract": " Real-world dilemmas rarely involve just two choices and perfect interactions without mistakes. In the iterated prisoner's dilemma (IPD) game, intermediate choices or mistakes (noise) have been introduced to extend its realism. This paper studies the IPD game with both noise and multiple levels of cooperation (intermediate choices) in a coevolutionary environment, where players can learn and adapt their strategies through an evolutionary algorithm. The impact of noise on the evolution of cooperation is first examined. It is shown that the coevolutionary models presented in this paper are robust against low noise (when mistakes occur with low probability). That is, low levels of noise have little impact on the evolution of cooperation. On the other hand, high noise (when mistakes occur with high probability) creates misunderstandings and discourages cooperation. However, the evolution of cooperation in the IPD with\u00a0\u2026", "num_citations": "106\n", "authors": ["537"]}
{"title": "DIVACE: Diverse and accurate ensemble learning algorithm\n", "abstract": " In order for a neural network ensemble to generalise properly, two factors are considered vital. One is the diversity and the other is the accuracy of the networks that comprise the ensemble. There exists a tradeoff as to what should be the optimal measures of diversity and accuracy. The aim of this paper is to address this issue. We propose the DIVACE algorithm which tries to produce an ensemble as it searches for the optimum point on the diversity-accuracy curve. The DIVACE algorithm formulates the ensemble learning problem as a multi-objective problem explicitly.", "num_citations": "106\n", "authors": ["537"]}
{"title": "Two-archive evolutionary algorithm for constrained multiobjective optimization\n", "abstract": " When solving constrained multiobjective optimization problems, an important issue is how to balance convergence, diversity, and feasibility simultaneously. To address this issue, this paper proposes a parameter-free constraint handling technique, a two-archive evolutionary algorithm, for constrained multiobjective optimization. It maintains two collaborative archives simultaneously: one, denoted as the convergence-oriented archive (CA), is the driving force to push the population toward the Pareto front; the other one, denoted as the diversity-oriented archive (DA), mainly tends to maintain the population diversity. In particular, to complement the behavior of the CA and provide as much diversified information as possible, the DA aims at exploring areas under-exploited by the CA including the infeasible regions. To leverage the complementary effects of both archives, we develop a restricted mating selection\u00a0\u2026", "num_citations": "105\n", "authors": ["537"]}
{"title": "Clustering and learning Gaussian distribution for continuous optimization\n", "abstract": " Since the Estimation of Distribution Algorithm (EDA) was introduced, different approaches in continuous domains have been developed. Initially, the single Gaussian distribution was broadly used when building the probabilistic models, which would normally mislead the search when dealing with multimodal functions. Some researchers later constructed EDAs that take advantage of mixture probability distributions by using clustering techniques. But their algorithms all need prior knowledge before applying clustering, which is unreasonable in real life. In this paper, two new EDAs for continuous optimization are proposed, both of which incorporate clustering techniques into estimation process to break the single Gaussian distribution assumption. The new algorithms, Clustering and Estimation of Gaussian Network Algorithm based on BGe metric and Clustering and Estimation of Gaussian Distribution Algorithm, not\u00a0\u2026", "num_citations": "104\n", "authors": ["537"]}
{"title": "Learning in the model space for cognitive fault diagnosis\n", "abstract": " The emergence of large sensor networks has facilitated the collection of large amounts of real-time data to monitor and control complex engineering systems. However, in many cases the collected data may be incomplete or inconsistent, while the underlying environment may be time-varying or unformulated. In this paper, we develop an innovative cognitive fault diagnosis framework that tackles the above challenges. This framework investigates fault diagnosis in the model space instead of the signal space. Learning in the model space is implemented by fitting a series of models using a series of signal segments selected with a sliding window. By investigating the learning techniques in the fitted model space, faulty models can be discriminated from healthy models using a one-class learning algorithm. The framework enables us to construct a fault library when unknown faults occur, which can be regarded as\u00a0\u2026", "num_citations": "103\n", "authors": ["537"]}
{"title": "Model-based kernel for efficient time series analysis\n", "abstract": " We present novel, efficient, model based kernels for time series data rooted in the reservoir computation framework. The kernels are implemented by fitting reservoir models sharing the same fixed deterministically constructed state transition part to individual time series. The proposed kernels can naturally handle time series of different length without the need to specify a parametric model class for the time series. Compared with most time series kernels, our kernels are computationally efficient. We show how the model distances used in the kernel can be calculated analytically or efficiently estimated. The experimental results on synthetic and benchmark time series classification tasks confirm the efficiency of the proposed kernel in terms of both generalization accuracy and computational speed. This paper also investigates on-line reservoir kernel construction for extremely long time series.", "num_citations": "101\n", "authors": ["537"]}
{"title": "Inverse modelling of multi-objective thermodynamically optimized turbojet engines using GMDH-type neural networks and evolutionary algorithms\n", "abstract": " A novel approach is presented in this article for obtaining inverse mapping of thermodynamically Pareto-optimized ideal turbojet engines using group method of data handling (GMDH)-type neural networks and evolutionary algorithms (EAs). EAs are used in two different aspects. Firstly, multi-objective EAs (non\u2013dominated sorting genetic algorithm-II) with a new diversity preserving mechanism are used for Pareto-based optimization of the thermodynamic cycle of ideal turbojet engines considering four important conflicting thermodynamic objectives, namely, specific thrust ({ST}), specific fuel consumption ({SFC}), propulsive efficiency (\u03b7p), and thermal efficiency (\u03b7t). The best obtained Pareto front, as a result, is a data table representing data pairs of non-dominated vectors of design variables, which are Mach number and pressure ratio, and the corresponding four objective functions. Secondly, EAs and singular value\u00a0\u2026", "num_citations": "101\n", "authors": ["537"]}
{"title": "Multi-objective approaches to optimal testing resource allocation in modular software systems\n", "abstract": " Software testing is an important issue in software engineering. As software systems become increasingly large and complex, the problem of how to optimally allocate the limited testing resource during the testing phase has become more important, and difficult. Traditional Optimal Testing Resource Allocation Problems (OTRAPs) involve seeking an optimal allocation of a limited amount of testing resource to a number of activities with respect to some objectives (e.g., reliability, or cost). We suggest solving OTRAPs with Multi-Objective Evolutionary Algorithms (MOEAs). Specifically, we formulate OTRAPs as two types of multi-objective problems. First, we consider the reliability of the system and the testing cost as two objectives. Second, the total testing resource consumed is also taken into account as the third objective. The advantages of MOEAs over state-of-the-art single objective approaches to OTRAPs will be\u00a0\u2026", "num_citations": "100\n", "authors": ["537"]}
{"title": "Analysis of computational time of simple estimation of distribution algorithms\n", "abstract": " Estimation of distribution algorithms (EDAs) are widely used in stochastic optimization. Impressive experimental results have been reported in the literature. However, little work has been done on analyzing the computation time of EDAs in relation to the problem size. It is still unclear how well EDAs (with a finite population size larger than two) will scale up when the dimension of the optimization problem (problem size) goes up. This paper studies the computational time complexity of a simple EDA, i.e., the univariate marginal distribution algorithm (UMDA), in order to gain more insight into EDAs complexity. First, we discuss how to measure the computational time complexity of EDAs. A classification of problem hardness based on our discussions is then given. Second, we prove a theorem related to problem hardness and the probability conditions of EDAs. Third, we propose a novel approach to analyzing the\u00a0\u2026", "num_citations": "100\n", "authors": ["537"]}
{"title": "Continuous dynamic constrained optimization\u2014the challenges\n", "abstract": " Many real-world dynamic problems have constraints, and in certain cases not only the objective function changes over time, but also the constraints. However, there is no research in answering the question of whether current algorithms work well on continuous dynamic constrained optimization problems (DCOPs), nor is there any benchmark problem that reflects the common characteristics of continuous DCOPs. This paper contributes to the task of closing this gap. We will present some investigations on the characteristics that might make DCOPs difficult to solve by some existing dynamic optimization (DO) and constraint handling (CH) algorithms. We will then introduce a set of benchmark problems with these characteristics and test several representative DO and CH strategies on these problems. The results confirm that DCOPs do have special characteristics that can significantly affect algorithm performance. The\u00a0\u2026", "num_citations": "99\n", "authors": ["537"]}
{"title": "Negative correlation learning for classification ensembles\n", "abstract": " This paper proposes a new negative correlation learning (NCL) algorithm, called AdaBoost.NC, which uses an ambiguity term derived theoretically for classification ensembles to introduce diversity explicitly. All existing NCL algorithms, such as CELS and NCCD, and their theoretical backgrounds were studied in the regression context. We focus on classification problems in this paper. First, we study the ambiguity decomposition with the 0-1 error function, which is different from the one proposed by Krogh et al.. It is applicable to both binary-class and multi-class problems. Then, to overcome the identified drawbacks of the existing algorithms, AdaBoost.NC is proposed by exploiting the ambiguity term in the decomposition to improve diversity. Comprehensive experiments are performed on a collection of benchmark data sets. The results show AdaBoost.NC is a promising algorithm to solve classification problems\u00a0\u2026", "num_citations": "98\n", "authors": ["537"]}
{"title": "A survey of automatic parameter tuning methods for metaheuristics\n", "abstract": " Parameter tuning, that is, to find appropriate parameter settings (or configurations) of algorithms so that their performance is optimized, is an important task in the development and application of metaheuristics. Automating this task, i.e., developing algorithmic procedure to address parameter tuning task, is highly desired and has attracted significant attention from the researchers and practitioners. During last two decades, many automatic parameter tuning approaches have been proposed. This paper presents a comprehensive survey of automatic parameter tuning methods for metaheuristics. A new classification (or taxonomy) of automatic parameter tuning methods is introduced according to the structure of tuning methods. The existing automatic parameter tuning approaches are consequently classified into three categories: 1) simple generate-evaluate methods; 2) iterative generate-evaluate methods; and 3) high\u00a0\u2026", "num_citations": "96\n", "authors": ["537"]}
{"title": "Short-term load forecasting with neural network ensembles: A comparative study [application notes]\n", "abstract": " Load Forecasting plays a critical role in the management, scheduling and dispatching operations in power systems, and it concerns the prediction of energy demand in different time spans. In future electric grids, to achieve a greater control and flexibility than in actual electric grids, a reliable forecasting of load demand could help to avoid dispatch problems given by unexpected loads, and give vital information to make decisions on energy generation and purchase, especially market-based dynamic pricing strategies. Furthermore, accurate prediction would have a significant impact on operation management, e.g. preventing overloading and allowing an efficient energy storage.", "num_citations": "96\n", "authors": ["537"]}
{"title": "Predictive ensemble pruning by expectation propagation\n", "abstract": " An ensemble is a group of learners that work together as a committee to solve a problem. The existing ensemble learning algorithms often generate unnecessarily large ensembles, which consume extra computational resource and may degrade the generalization performance. Ensemble pruning algorithms aim to find a good subset of ensemble members to constitute a small ensemble, which saves the computational resource and performs as well as, or better than, the unpruned ensemble. This paper introduces a probabilistic ensemble pruning algorithm by choosing a set of ldquosparserdquo combination weights, most of which are zeros, to prune the ensemble. In order to obtain the set of sparse combination weights and satisfy the nonnegative constraint of the combination weights, a left-truncated, nonnegative, Gaussian prior is adopted over every combination weight. Expectation propagation (EP) algorithm is\u00a0\u2026", "num_citations": "96\n", "authors": ["537"]}
{"title": "Bagging and boosting negatively correlated neural networks\n", "abstract": " In this paper, we propose two cooperative ensemble learning algorithms, i.e., NegBagg and NegBoost, for designing neural network (NN) ensembles. The proposed algorithms incrementally train different individual NNs in an ensemble using the negative correlation learning algorithm. Bagging and boosting algorithms are used in NegBagg and NegBoost, respectively, to create different training sets for different NNs in the ensemble. The idea behind using negative correlation learning in conjunction with the bagging/boosting algorithm is to facilitate interaction and cooperation among NNs during their training. Both NegBagg and NegBoost use a constructive approach to automatically determine the number of hidden neurons for NNs. NegBoost also uses the constructive approach to automatically determine the number of NNs for the ensemble. The two algorithms have been tested on a number of benchmark\u00a0\u2026", "num_citations": "96\n", "authors": ["537"]}
{"title": "Dynamic multiobjectives optimization with a changing number of objectives\n", "abstract": " Existing studies on dynamic multiobjective optimization (DMO) focus on problems with time-dependent objective functions, while the ones with a changing number of objectives have rarely been considered in the literature. Instead of changing the shape or position of the Pareto-optimal front/set (PF/PS) when having time-dependent objective functions, increasing or decreasing the number of objectives usually leads to the expansion or contraction of the dimension of the PF/PS manifold. Unfortunately, most existing dynamic handling techniques can hardly be adapted to this type of dynamics. In this paper, we report our attempt toward tackling the DMO problems with a changing number of objectives. We implement a dynamic two-archive evolutionary algorithm which maintains two co-evolving populations simultaneously. In particular, these two populations are complementary to each other: one concerns more about\u00a0\u2026", "num_citations": "95\n", "authors": ["537"]}
{"title": "Analysis of the -EA for Finding Approximate Solutions to Vertex Cover Problems\n", "abstract": " Vertex cover is one of the best known NP-hard combinatorial optimization problems. Experimental work has claimed that evolutionary algorithms (EAs) perform fairly well for the problem and can compete with problem-specific ones. A theoretical analysis that explains these empirical results is presented concerning the random local search algorithm and the (1+1)-EA. Since it is not expected that an algorithm can solve the vertex cover problem in polynomial time, a worst case approximation analysis is carried out for the two considered algorithms and comparisons with the best known problem-specific ones are presented. By studying instance classes of the problem, general results are derived. Although arbitrarily bad approximation ratios of the (1+1)-EA can be proved for a bipartite instance class, the same algorithm can quickly find the minimum cover of the graph when a restart strategy is used. Instance classes\u00a0\u2026", "num_citations": "95\n", "authors": ["537"]}
{"title": "Fractal spectral analysis of pre-epileptic seizures in terms of criticality\n", "abstract": " The analysis of pre-epileptic seizure through EEG (electroencephalography) is an important issue for epilepsy diagnosis. Currently, there exist some methods derived from the dynamics to analyse the pre-epileptic EEG data. It is still necessary to create a novel method to better fit and explain the EEG data for making sense of the seizures' predictability. In this paper, a fractal wavelet-based spectral method is proposed and applied to analyse EEG recordings from rat experiments. Three types of patterns are found from the 12 experiments; moreover three typical cases corresponding to the three types of seizures are sorted out and analysed in detail by using the new method. The results indicate that this method can reveal the characteristic signs of an approaching seizure, which includes the emergence of long-range correlation, the decrease of anti-persistence behaviour with time and the decrease of the fractal\u00a0\u2026", "num_citations": "95\n", "authors": ["537"]}
{"title": "Evolutionary multitasking for single-objective continuous optimization: Benchmark problems, performance metric, and baseline results\n", "abstract": " In this report, we suggest nine test problems for multi-task single-objective optimization (MTSOO), each of which consists of two single-objective optimization tasks that need to be solved simultaneously. The relationship between tasks varies between different test problems, which would be helpful to have a comprehensive evaluation of the MFO algorithms. It is expected that the proposed test problems will germinate progress the field of the MTSOO research.", "num_citations": "94\n", "authors": ["537"]}
{"title": "Smart use of computational resources based on contribution for cooperative co-evolutionary algorithms\n", "abstract": " Standard Cooperative Co-evolution uses a round-robin method to select subcomponents to undergo optimization. In a non-separable (epistatic) optimization problem, dividing the computational budget equally between all of the subcomponents is not necessarily the best strategy. When dealing with non-separable problems, there is usually an imbalance between the contribution of various subcomponents to the global fitness of the individuals. Using a round-robin fashion treats all of the subcomponents equally and wastes the computational budget. In this paper, we propose a Contribution Based Cooperative Co-evolution (CBCC) that selects the subcomponents based on their contributions to the global fitness. This alleviates the imbalance issue and allows the computational resources to be used more efficiently. Experiments on several benchmark functions with the\" imbalance issue\" show that this new scheme is\u00a0\u2026", "num_citations": "93\n", "authors": ["537"]}
{"title": "Introduction to evolvable hardware\n", "abstract": " This chapter provides an introduction to evolvable hardware. First, the basic idea of evolvable hardware is outlined. Because evolvable hardware involves the integration of programmable logic device and evolutionary computation, these are both explained briefly. Then, an overview of current research on evolvable hardware is presented. Finally, the chapter discusses some directions for future research.", "num_citations": "92\n", "authors": ["537"]}
{"title": "The grd chip: Genetic reconfiguration of dsps for neural network processing\n", "abstract": " This paper describes the GRD (Genetic Reconfiguration of DSPs) chip, which is evolvable hardware designed for neural network applications. The GRD chip is a building block for the configuration of a scalable neural network hardware system. Both the topology and the hidden layer node functions of a neural network mapped on the GRD chips are dynamically reconfigured using a genetic algorithm (GA). Thus, the most desirable network topology and choice of node functions (e.g., Gaussian or sigmoid function) for a given application can be determined adaptively. This approach is particularly suited to applications requiring the ability to cope with time-varying problems and real-time constraints. The GRD chip consists of a 100 MHz 32-bit RISC processor and 15 33 MHz 16-bit DSPs connected in a binary-tree network. The RISC processor is the NEC V830 which executes mainly the GA. According to chromosomes\u00a0\u2026", "num_citations": "91\n", "authors": ["537"]}
{"title": "Dynamical characteristics of pre-epileptic seizures in rats with recurrence quantification analysis\n", "abstract": " Understanding the transition of brain activity towards an epileptic seizure, called pre-epileptic seizure, is a challenge in epilepsy. In this Letter, a recurrence quantification analysis (RQA) is proposed to describe dynamical characteristics of EEG (electroencephalograph) recordings on rat experiments, which is helpful to predict seizures. One of the advantages of this method does not require any assumptions to EEG data, such as linear, stationary, noiseless and so on. A series of experimental tests in this study show that the dynamical characteristics of EEG data with RQA can identify the differences among inter-ictal, pre-ictal and ictal phases; and support the hypothesis that complexity of brain electrical activity has a significant decrease prior to an epileptic seizure. This change could be useful in predicting epileptic seizures.", "num_citations": "89\n", "authors": ["537"]}
{"title": "Ensemble structure of evolutionary artificial neural networks\n", "abstract": " Evolutionary artificial neural networks (EANNs) refer to a special class of artificial neural networks (ANNs) in which evolution is another fundamental form of adaptation in addition to learning. Evolution can be introduced at various levels of ANNs. It can be used to evolve weights, architectures, and learning parameters and rules. The paper is concerned with the evolution of ANN architectures, where an evolutionary algorithm is used to evolve a population of ANNs. The current practice in evolving ANNs is to choose the best ANN in the last population as the final result. The paper proposes a novel approach to form the final result by combining all the individuals in the last generation in order to make best use of all the information contained in the whole population. This approach regards a population of ANNs as an ensemble of ANNs and use a method to combine them. We have used four simple methods in our\u00a0\u2026", "num_citations": "89\n", "authors": ["537"]}
{"title": "Self-Aware Computing Systems\n", "abstract": " This book is the first ever to focus on the emerging field of self-aware computing from an engineering perspective. It first comprehensively introduces fundamentals for self-awareness and self-expression in computing systems, proposing the new notion of computational self-awareness. It then focuses on architectures and techniques for designing self-aware computing systems at the node and network levels. Finally, the effectiveness of these techniques is demonstrated on a variety of case studies. While a number of books on related topics such as self-adaption and selforganisation, and even self-awareness concepts in computing, have already been published, this book is unique as it provides a holistic view of self-aware computing including its relationship with self-expression, and the process of engineering such systems, ie, a thorough understanding of how to model and build self-aware computing systems\u00a0\u2026", "num_citations": "88\n", "authors": ["537"]}
{"title": "Scaling up estimation of distribution algorithms for continuous optimization\n", "abstract": " Since estimation of distribution algorithms (EDAs) were proposed, many attempts have been made to improve EDAs' performance in the context of global optimization. So far, the studies or applications of multivariate probabilistic model-based EDAs in continuous domain are still mostly restricted to low-dimensional problems. Traditional EDAs have difficulties in solving higher dimensional problems because of the curse of dimensionality and rapidly increasing computational costs. However, scaling up continuous EDAs for large-scale optimization is still necessary, which is supported by the distinctive feature of EDAs: because a probabilistic model is explicitly estimated, from the learned model one can discover useful properties of the problem. Besides obtaining a good solution, understanding of the problem structure can be of great benefit, especially for black box optimization. We propose a novel EDA framework\u00a0\u2026", "num_citations": "88\n", "authors": ["537"]}
{"title": "A multi-objective approach to redundancy allocation problem in parallel-series systems\n", "abstract": " The Redundancy Allocation Problem (RAP) is a kind of reliability optimization problems. It involves the selection of components with appropriate levels of redundancy or reliability to maximize the system reliability under some predefined constraints. We can formulate the RAP as a combinatorial problem when just considering the redundancy level, while as a continuous problem when considering the reliability level. The RAP employed in this paper is that kind of combinatorial optimization problems. During the past thirty years, there have already been a number of investigations on RAP. However, these investigations often treat RAP as a single objective problem with the only goal to maximize the system reliability (or minimize the designing cost). In this paper, we regard RAP as a multi-objective optimization problem: the reliability of the system and the corresponding designing cost are considered as two different\u00a0\u2026", "num_citations": "88\n", "authors": ["537"]}
{"title": "Simulated annealing with extended neighbourhood\n", "abstract": " Simulated Annealing (SA) is a powerful stochastic search method applicable to a wide range of problems for which little prior knowledge is available. It can produce very high quality solutions for hard combinatorial optimization problems. However, the computation time required by SA is very large. Various methods have been proposed to reduce the computation time, but they mainly deal with the careful tuning of SA'ol parameters. This paper first analyzes the impact of SA'neighbourhood on SA'performance and shows that SA with a larger neighbourhood is better than SA with a smaller one. The paper also gives a general model of SA, which has both dynamic generation probability and acceptance probability, and proves its convergence. All variants of SA can be unified under such a generalization. Finally, a method of extending SA's neighbourhood is proposed, which uses a discrete approximation to some\u00a0\u2026", "num_citations": "88\n", "authors": ["537"]}
{"title": "An overview of evolutionary computation\n", "abstract": " This paper presents a brief overview of the eld of evolutionary computation. Three major research areas of evolutionary computation will be discussed; evolutionary computation theory, evolutionary optimisation and evolutionary learning. The state-of-the-art and open issues in each area will be addressed. It is indicated that while evolutionary computation techniques have enjoyed great success in many engineering applications, the progress in theory has been rather slow. This paper also gives a brief introduction to parallel evolutionary algorithms. Two models of parallel evolutionary algorithms, the island model and the cellular model, are described.", "num_citations": "87\n", "authors": ["537"]}
{"title": "How well do multi-objective evolutionary algorithms scale to large problems\n", "abstract": " In spite of large amount of research work in multi- objective evolutionary algorithms, most have evaluated their algorithms on problems with only two to four objectives. Little has been done to understand the performance of the multi- objective evolutionary algorithms on problems with a larger number of objectives. It is unclear whether the conclusions drawn from the experiments on problems with a small number of objectives could be generalised to those with a large number of objectives. In fact, some of our preliminary work [1] has indicated that such generalisation may not be possible. This paper first presents a comprehensive set of experimental studies, which show that the performance of multi-objective evolutionary algorithms, such as NSGA-II and SPEA2, deteriorates substantially as the number of objectives increases. NSGA-II, for example, did not even converge for problems with six or more objectives. This\u00a0\u2026", "num_citations": "86\n", "authors": ["537"]}
{"title": "Co-evolution in iterated prisoner's dilemma with intermediate levels of cooperation: Application to missile defense\n", "abstract": " There is a widespread perception that in conflict situations, more intermediate choices between full peace and total war makes full peace less likely. This view is a motivation for opposing the proposed National Missile Defense. This perception is partly due to research in the abstract game of Iterated Prisoner's Dilemma. This paper critically evaluates this perception.", "num_citations": "85\n", "authors": ["537"]}
{"title": "Socio-economic vision graph generation and handover in distributed smart camera networks\n", "abstract": " In this article we present an approach to object tracking handover in a network of smart cameras, based on self-interested autonomous agents, which exchange responsibility for tracking objects in a market mechanism, in order to maximise their own utility. A novel ant-colony inspired mechanism is used to learn the vision graph, that is, the camera neighbourhood relations, during runtime, which may then be used to optimise communication between cameras. The key benefits of our completely decentralised approach are on the one hand generating the vision graph online, enabling efficient deployment in unknown scenarios and camera network topologies, and on the other hand relying only on local information, increasing the robustness of the system. Since our market-based approach does not rely on a priori topology information, the need for any multicamera calibration can be avoided. We have evaluated our\u00a0\u2026", "num_citations": "84\n", "authors": ["537"]}
{"title": "Synchronization measurement of multiple neuronal populations\n", "abstract": " The purpose of the present paper is to develop a method, based on equal-time correlation, correlation matrix analysis and surrogate resampling, that is able to quantify and describe properties of synchronization of population neuronal activity recorded simultaneously from multiple sites. Initially, Lorenz-type oscillators were used to model multiple time series with different patterns of synchronization. Eigenvalue and eigenvector decomposition was then applied to identify \u201cclusters\u201d of locally synchronized activity and to calculate a \u201cglobal synchronization index.\u201d This method was then applied to multichannel data recorded from an in vitro model of epileptic seizures. The results demonstrate that this novel method can be successfully used to analyze synchronization between multiple neuronal population series.", "num_citations": "84\n", "authors": ["537"]}
{"title": "A new approach for analyzing average time complexity of population-based evolutionary algorithms on unimodal problems\n", "abstract": " In the past decades, many theoretical results related to the time complexity of evolutionary algorithms (EAs) on different problems are obtained. However, there is not any general and easy-to-apply approach designed particularly for population-based EAs on unimodal problems. In this paper, we first generalize the concept of the takeover time to EAs with mutation, then we utilize the generalized takeover time to obtain the mean first hitting time of EAs and, thus, propose a general approach for analyzing EAs on unimodal problems. As examples, we consider the so-called ( N  +  N ) EAs and we show that, on two well-known unimodal problems, leadingones and onemax , the EAs with the bitwise mutation and two commonly used selection schemes both need  O ( n ln n  +  n   2 / N ) and  O ( n  lnln n  +  n ln n / N ) generations to find the global optimum, respectively. Except for the new results above, our approach can\u00a0\u2026", "num_citations": "83\n", "authors": ["537"]}
{"title": "Compositional evolution: Interdisciplinary investigations in evolvability, modularity, and symbiosis\n", "abstract": " Conventionally, evolution by natural selection is almost inseparable from the notion of accumulating successive slight variations. Although it has been suggested that symbiotic mechanisms that combine together existing entities provide an alternative to gradual, or \u2018accretive\u2019, evolutionary change, there has been disagreement about what impact these mechanisms have on our understanding of evolutionary processes. Meanwhile, in artificial evolution methods used in computer science, it has been suggested that the composition of genetic material under sexual recombination may provide adaptation that is not available under mutational variation, but there has been considerable difficulty in demonstrating this formally. Thus far, it has been unclear what types of systems, if any, can be evolved by such \u2018compositional\u2019mechanisms that cannot be evolved by accretive mechanisms.", "num_citations": "83\n", "authors": ["537"]}
{"title": "Concept drift adaptation by exploiting historical knowledge\n", "abstract": " Incremental learning with concept drift has often been tackled by ensemble methods, where models built in the past can be retrained to attain new models for the current data. Two design questions need to be addressed in developing ensemble methods for incremental learning with concept drift, i.e., which historical (i.e., previously trained) models should be preserved and how to utilize them. A novel ensemble learning method, namely, Diversity and Transfer-based Ensemble Learning (DTEL), is proposed in this paper. Given newly arrived data, DTEL uses each preserved historical model as an initial model and further trains it with the new data via transfer learning. Furthermore, DTEL preserves a diverse set of historical models, rather than a set of historical models that are merely accurate in terms of classification accuracy. Empirical studies on 15 synthetic data streams and 5 real-world data streams (all with\u00a0\u2026", "num_citations": "82\n", "authors": ["537"]}
{"title": "Hybrid meta-heuristics algorithms for task assignment in heterogeneous computing systems\n", "abstract": " In this paper we tackle the task assignment problem (TSAP) in heterogeneous computer systems. The TSAP consists of assigning a given distributed computer program formed by a number of tasks to a number of processors, subject to a set of constraints, and in such a way a given cost function to be minimized. We introduce a novel formulation of the problem, in which each processor is limited in the number of task it can handle, due to the so called resource constraint. We propose two hybrid meta-heuristic approaches for solving this problem. Both hybrid approaches use a Hopfield neural network to solve the problem's constraints, mixed with a genetic algorithm (GA) and a simulated annealing for improving the quality of the solutions found. We test the performance of the proposed algorithms in several computational TSAP instances, using a GA with a penalty function and a GA with a repairing heuristic for\u00a0\u2026", "num_citations": "82\n", "authors": ["537"]}
{"title": "Global optimisation by evolutionary algorithms\n", "abstract": " Evolutionary algorithms (EAs) are a class of stochastic search algorithms which are applicable to a wide range of problems in learning and optimisation. They have been applied to numerous problems in combinatorial optimisation, function optimisation, artificial neural network learning, fuzzy logic system learning, etc. This paper first introduces EAs and their basic operators. Then, an overview of three major branches of EAs, i.e. genetic algorithms (GAs), evolutionary programming (EP) and evolution strategies (ESs), is given. Different search operators and selection mechanisms are described. The emphasis of the discussion is on global optimisation by EAs. The paper also presents three simple models for parallel EAs. Finally, some open issues and future research directions in evolutionary optimisation and evolutionary computation in general are discussed.", "num_citations": "82\n", "authors": ["537"]}
{"title": "Machine learning\n", "abstract": " Machine learning is a very active sub-field of artificial intelligence concerned with the development of computational models of learning. Machine learning is inspired by the work in several disciplines: cognitive sciences, computer science, statistics, computational complexity, information theory, control theory, philosophy and biology. Simply speaking, machine learning is learning by machine. From a computational point of view, machine learning refers to the ability of a machine to improve its performance based on previous results. From a biological point of view, machine learning is the study of how to create computers that will learn from experience and modify their activity based on that learning as opposed to traditional computers whose activity will not change unless the programmer explicitly changes it.", "num_citations": "81\n", "authors": ["537"]}
{"title": "Reusing genetic programming for ensemble selection in classification of unbalanced data\n", "abstract": " Classification algorithms can suffer from performance degradation when the class distribution is unbalanced. This paper develops a two-step approach to evolving ensembles using genetic programming (GP) for unbalanced data. The first step uses multiobjective (MO) GP to evolve a Pareto-approximated front of GP classifiers to form the ensemble by trading-off the minority and the majority class against each other during learning. The MO component alleviates the reliance on sampling to artificially rebalance the data. The second step, which is the focus this paper, proposes a novel ensemble selection approach using GP to automatically find/choose the best individuals for the ensemble. This new GP approach combines multiple Pareto-approximated front members into a single composite genetic program solution to represent the (optimized) ensemble. This ensemble representation has two main advantages\u00a0\u2026", "num_citations": "81\n", "authors": ["537"]}
{"title": "On the impact of mutation-selection balance on the runtime of evolutionary algorithms\n", "abstract": " The interplay between mutation and selection plays a fundamental role in the behavior of evolutionary algorithms (EAs). However, this interplay is still not completely understood. This paper presents a rigorous runtime analysis of a non-elitist population-based EA that uses the linear ranking selection mechanism. The analysis focuses on how the balance between parameter \u03b7, controlling the selection pressure in linear ranking, and parameter \u03c7 controlling the bit-wise mutation rate, impacts the runtime of the algorithm. The results point out situations where a correct balance between selection pressure and mutation rate is essential for finding the optimal solution in polynomial time. In particular, it is shown that there exist fitness functions which can only be solved in polynomial time if the ratio between parameters \u03b7 and \u03c7 is within a narrow critical interval, and where a small change in this ratio can increase the runtime\u00a0\u2026", "num_citations": "79\n", "authors": ["537"]}
{"title": "Dynamic evolutionary optimisation: an analysis of frequency and magnitude of change\n", "abstract": " In this paper, we rigorously analyse how the magnitude and frequency of change may affect the performance of the algorithm (1+ 1) EA dyn on a set of artificially designed pseudo-Boolean functions, given a simple but well-defined dynamic framework. We demonstrate some counter-intuitive scenarios that allow us to gain a better understanding of how the dynamics of a function may affect the runtime of an algorithm. In particular, we present the function Magnitude, where the time it takes for the (1+ 1) EA dyn to relocate the global optimum is less than n 2 log n (ie, efficient) with overwhelming probability if the magnitude of change is large. For small changes of magnitude, on the other hand, the expected time to relocate the global optimum is e \u03a9 (n)(ie, highly inefficient). Similarly, the expected runtime of the (1+ 1) EA dyn on the function Balance is O (n 2)(efficient) for a high frequencies of change and n \u03a9 (\u221a n)(highly\u00a0\u2026", "num_citations": "79\n", "authors": ["537"]}
{"title": "On the approximation ability of evolutionary optimization with application to minimum set cover\n", "abstract": " Evolutionary algorithms (EAs) are heuristic algorithms inspired by natural evolution. They are often used to obtain satisficing solutions in practice. In this paper, we investigate a largely underexplored issue: the approximation performance of EAs in terms of how close the solution obtained is to an optimal solution. We study an EA framework named simple EA with isolated population (SEIP) that can be implemented as a single-or multi-objective EA. We analyze the approximation performance of SEIP using the partial ratio, which characterizes the approximation ratio that can be guaranteed. Specifically, we analyze SEIP using a set cover problem that is NP-hard. We find that in a simple configuration, SEIP efficiently achieves an H n-approximation ratio, the asymptotic lower bound, for the unbounded set cover problem. We also find that SEIP efficiently achieves an (H k\u2212 k\u2212 1 8 k 9)-approximation ratio, the currently\u00a0\u2026", "num_citations": "78\n", "authors": ["537"]}
{"title": "Benchmarking and solving dynamic constrained problems\n", "abstract": " Many real-world dynamic optimisation problems have constraints, and in certain cases not only the objective function changes over time, but the constraints also change as well. However, in academic research there is not many research on continuous dynamic constrained optimization, and particularly there is little research on whether current numerical dynamic optimization algorithms would work well in dynamic constrained environments nor there is any numerical dynamic constrained benchmark problems. In this paper, we firstly investigate the characteristics that might make a dynamic constrained problems difficult to solve by existing dynamic optimization algorithms. We then introduce a set of numerical dynamic benchmark problems with these characteristics. To verify our hypothesis about the difficulty of these problems, we tested several canonical dynamic optimization algorithms on the proposed\u00a0\u2026", "num_citations": "78\n", "authors": ["537"]}
{"title": "How to read many-objective solution sets in parallel coordinates [educational forum]\n", "abstract": " Rapid development of evolutionary algor ithms in handling many-objective optimization problems requires viable methods of visualizing a high-dimensional solution set. The parallel coordinates plot which scales well to high-dimensional data is such a method, and has been frequently used in evolutionary many-objective optimization. However, the parallel coordinates plot is not as straightforward as the classic scatter plot to present the information contained in a solution set. In this paper, we make some observations of the parallel coordinates plot, in terms of comparing the quality of solution sets, understanding the shape and distribution of a solution set, and reflecting the relation between objectives. We hope that these observations could provide some guidelines as to the proper use of the parallel coordinates plot in evolutionary manyobjective optimization.", "num_citations": "77\n", "authors": ["537"]}
{"title": "Robust route optimization for gritting/salting trucks: A CERCIA experience\n", "abstract": " Highway authorities in marginal winter climates are responsible for the precautionary gritting/salting of the road network in order to prevent frozen roads. For efficient and effective road maintenance, accurate road surface temperature prediction is required. However, this information is useless if an effective means of utilizing this information is unavailable. This is where gritting route optimization plays a crucial role. The decision whether to grit the road network at marginal nights is a difficult problem. The consequences of making a wrong decision are serious, as untreated roads are a major hazard. However, if grit/salt is spread when it is not actually required, there are unnecessary financial and environmental costs. The goal here is to minimize the financial and environmental costs while ensuring roads that need treatment will. In this article, a salting route optimization (SRO) system that combines evolutionary\u00a0\u2026", "num_citations": "77\n", "authors": ["537"]}
{"title": "A population-based learning algorithm which learns both architectures and weights of neural networks\n", "abstract": " One of the major issues in the eld of arti cial neural networks (ANNs) is the design of their architectures. There are strong biological and engineering evidences to support that the information processing capability of an ANN is determined by its architecture. This paper proposes a new population-based learning algorithm (PBLA) which learns both ANN's architecture and weights. The evolutionary approach is used to evolve a population of ANNs. Unlike other evolutionary approaches to ANN learning, each ANN (ie, individual) in the population is evaluated by partial training rather than complete training. Substantial savings in computational cost can be achieved by such progressive partial training. This training process can change both ANN's architecture and weights. Our preliminary experiments have demonstrated the e ectiveness of our algorithm.", "num_citations": "77\n", "authors": ["537"]}
{"title": "Efficient resource allocation in cooperative co-evolution for large-scale global optimization\n", "abstract": " Cooperative co-evolution (CC) is an explicit means of problem decomposition in multipopulation evolutionary algorithms for solving large-scale optimization problems. For CC, subpopulations representing subcomponents of a large-scale optimization problem co-evolve, and are likely to have different contributions to the improvement of the best overall solution to the problem. Hence, it makes sense that more computational resources should be allocated to the subpopulations with greater contributions. In this paper, we study how to allocate computational resources in this context and subsequently propose a new CC framework named CCFR to efficiently allocate computational resources among the subpopulations according to their dynamic contributions to the improvement of the objective value of the best overall solution. Our experimental results suggest that CCFR can make efficient use of computational\u00a0\u2026", "num_citations": "76\n", "authors": ["537"]}
{"title": "Benchmarking optimization algorithms: An open source framework for the traveling salesman problem\n", "abstract": " We introduce an experimentation procedure for evaluating and comparing optimization algorithms based on the Traveling Salesman Problem (TSP). We argue that end-of-run results alone do not give sufficient information about an algorithm's performance, so our approach analyzes the algorithm's progress over time. Comparisons of performance curves in diagrams can be formalized by comparing the areas under them. Algorithms can be ranked according to a performance metric. Rankings based on different metrics can then be aggregated into a global ranking, which provides a quick overview of the quality of algorithms in comparison. An open source software framework, the TSP Suite, applies this experimental procedure to the TSP. The framework can support researchers in implementing TSP solvers, unit testing them, and running experiments in a parallel and distributed fashion. It also has an evaluator\u00a0\u2026", "num_citations": "76\n", "authors": ["537"]}
{"title": "Unified eigen analysis on multivariate Gaussian based estimation of distribution algorithms\n", "abstract": " Multivariate Gaussian models are widely adopted in continuous estimation of distribution algorithms (EDAs), and covariance matrix plays the essential role in guiding the evolution. In this paper, we propose a new framework for multivariate Gaussian based EDAs (MGEDAs), named eigen decomposition EDA (ED-EDA). Unlike classical EDAs, ED-EDA focuses on eigen analysis of the covariance matrix, and it explicitly tunes the eigenvalues. All existing MGEDAs can be unified within our ED-EDA framework by applying three different eigenvalue tuning strategies. The effects of eigenvalue on influencing the evolution are investigated through combining maximum likelihood estimates of Gaussian model with each of the eigenvalue tuning strategies in ED-EDA. In our experiments, proper eigenvalue tunings show high efficiency in solving problems with small population sizes, which are difficult for classical MGEDA\u00a0\u2026", "num_citations": "76\n", "authors": ["537"]}
{"title": "A note on problem difficulty measures in black-box optimization: Classification, realizations and predictability\n", "abstract": " Various methods have been defined to measure the hardness of a fitness function for evolutionary algorithms and other black-box heuristics. Examples include fitness landscape analysis, epistasis, fitness-distance correlations etc., all of which are relatively easy to describe. However, they do not always correctly specify the hardness of the function. Some measures are easy to implement, others are more intuitive and hard to formalize. This paper rigorously defines difficulty measures in black-box optimization and proposes a classification. Different types of realizations of such measures are studied, namely exact and approximate ones. For both types of realizations, it is proven that predictive versions that run in polynomial time in general do not exist unless certain complexity-theoretical assumptions are wrong.", "num_citations": "75\n", "authors": ["537"]}
{"title": "Universal multi-objective function for optimising superplastic-damage constitutive equations\n", "abstract": " Based on the dominated deformation mechanisms of superplastic materials, an assumption for micro-damage evolution is presented. Then, a set of unified viscoplastic-damage constitutive equations is proposed to model material hardening due to the increase of dislocation density and grain growth, as well as material softening due to intergranular void nucleation and growth. The effects of the hardening and softening state variables on superplastic flows are characterised. To overcome the difficulties associated with the difference between predicted and experimental life spans and the variation in scales during multi-objective optimisations of material constants arising in the constitutive equations from experimental data, a unitless objective function has been formulated. This enables all experimental data to be involved in the optimisation. The constitutive equation set has been characterised for two superplastic\u00a0\u2026", "num_citations": "74\n", "authors": ["537"]}
{"title": "Automatic modularization by speciation\n", "abstract": " Real-world problems are often too difficult to solve by a single monolithic system. There are many examples of natural and artificial systems which show that a modular approach can reduce the total complexity of the system while solving a difficult problem satisfactorily. The success of modular artificial neural networks in speech and image processing is a typical example. However, designing a modular system is a difficult task. It relies heavily on human experts and prior knowledge about the problem. There is no systematic and automatic way to form a modular system for a problem. This paper proposes a novel evolutionary learning approach to designing a modular system automatically, without human intervention. Our starting point is speciation, using a technique based on fitness sharing. While speciation in genetic algorithms is not new, no effort has been made towards using a speciated population as a\u00a0\u2026", "num_citations": "74\n", "authors": ["537"]}
{"title": "A memetic algorithm for periodic capacitated arc routing problem\n", "abstract": " This paper investigates the Periodic Capacitated Arc Routing Problem (PCARP), which is often encountered in the waste collection application. PCARP is an extension of the well-known Capacitated Arc Routing Problem (CARP) from a single period to a multi-period horizon. PCARP is a hierarchical optimization problem which has a primary objective (minimizing the number of vehicles ) and a secondary objective (minimizing the total cost ). An important factor that makes PCARP challenging is that its primary objective is little affected by existing operators and thus difficult to improve. We propose a new Memetic Algorithm (MA) for solving PCARP. The MA adopts a new solution representation scheme and a novel crossover operator. Most importantly, a Route-Merging (RM) procedure is devised and embedded in the algorithm to tackle the insensitive objective . The MA with RM (MARM) has been compared with\u00a0\u2026", "num_citations": "73\n", "authors": ["537"]}
{"title": "A GA approach to the optimal placement of sensors in wireless sensor networks with obstacles and preferences\n", "abstract": " The wireless sensor network (WSN) has recently become an intensive research focus due to its potential applications in many areas. In this paper, we propose a new and efficient genetic algorithm (GA) to the optimal placement of sensors in a grid area with obstacles and preferences to minimize the number of sensors. A new sensor detection model is also introduced in this paper. Experiments show that our algorithm is able to achieve better results than previous heuristic algorithms.", "num_citations": "73\n", "authors": ["537"]}
{"title": "An evolutionary approach to the multidepot capacitated arc routing problem\n", "abstract": " The capacitated arc routing problem (CARP) is a challenging vehicle routing problem with numerous real world applications. In this paper, an extended version of CARP, the multidepot capacitated arc routing problem (MCARP), is presented to tackle practical requirements. Existing CARP heuristics are extended to cope with MCARP and are integrated into a novel evolutionary framework: the initial population is constructed either by random generation, the extended random path-scanning heuristic, or the extended random Ulusoy's heuristic. Subsequently, multiple distinct operators are employed to perform selection, crossover, and mutation. Finally, the partial replacement procedure is implemented to maintain population diversity. The proposed evolutionary approach (EA) is primarily characterized by the exploitation of attributes found in near-optimal MCARP solutions that are obtained throughout the execution of\u00a0\u2026", "num_citations": "72\n", "authors": ["537"]}
{"title": "Fast evolutionary algorithms\n", "abstract": " This chapter discusses a number of recent results in evolutionary optimization. In particular, we show that the search step size of a variation operator plays a vital role in its efficient search of a landscape. We have derived the optimal search step size of mutation operators in evolutionary optimization. Based on this theoretical analysis, we have developed several new evolutionary algorithms which outperform existing evolutionary algorithms significantly on many benchmark functions.               Most of the existing work in evolutionary optimization concentrates on different variation (i.e., search) operators, such as crossover and mutation. However, there may be a better way to solve a complex problem by transforming it into a simpler one first and then solving it. The key issue here is how to approximate the problem without changing the nature of the problem (i.e., the optima we wish to find). This chapter will\u00a0\u2026", "num_citations": "72\n", "authors": ["537"]}
{"title": "Population-based algorithm portfolios with automated constituent algorithms selection\n", "abstract": " Population-based Algorithm Portfolios (PAP) is an appealing framework for integrating different Evolutionary Algorithms (EAs) to solve challenging numerical optimization problems. Particularly, PAP has shown significant advantages to single EAs when a number of problems need to be solved simultaneously. Previous investigation on PAP reveals that choosing appropriate constituent algorithms is crucial to the success of PAP. However, no method has been developed for this purpose. In this paper, an extended version of PAP, namely PAP based on Estimated Performance Matrix (EPM-PAP) is proposed. EPM-PAP is equipped with a novel constituent algorithms selection module, which is based on the EPM of each candidate EAs. Empirical studies demonstrate that the EPM-based selection method can successfully identify appropriate constituent EAs, and thus EPM-PAP outperformed all single EAs considered\u00a0\u2026", "num_citations": "71\n", "authors": ["537"]}
{"title": "A hybrid ant colony optimization algorithm for the extended capacitated arc routing problem\n", "abstract": " The capacitated arc routing problem (CARP) is representative of numerous practical applications, and in order to widen its scope, we consider an extended version of this problem that entails both total service time and fixed investment costs. We subsequently propose a hybrid ant colony optimization (ACO) algorithm (HACOA) to solve instances of the extended CARP. This approach is characterized by the exploitation of heuristic information, adaptive parameters, and local optimization techniques: Two kinds of heuristic information, arc cluster information and arc priority information, are obtained continuously from the solutions sampled to guide the subsequent optimization process. The adaptive parameters ease the burden of choosing initial values and facilitate improved and more robust results. Finally, local optimization, based on the two-opt heuristic, is employed to improve the overall performance of the\u00a0\u2026", "num_citations": "71\n", "authors": ["537"]}
{"title": "An analysis of evolutionary algorithms based on neighbourhood and step sizes\n", "abstract": " Evolutionary algorithms (EAs) can be regarded as algorithms based on neighbourhood search, where different search operators (such as crossover and mutation) determine different neighbourhood and step sizes. This paper analyses the efficiency of various mutations in evolutionary programming (EP) by examining their neighbourhood and step sizes. It shows analytically when and why Cauchy mutation-based fast EP (FEP) [1, 2] is better than Gaussian mutation-based classical EP (CEP). It also studies the relationship between the optimality of the solution and the time used to find the solution. Based on the theoretical analysis, an improved FEP (IFEP) is proposed, which combines the advantages of both Cauchy and Gaussian mutations in EP. Although IFEP is very simple and requires no extra parameters, it performs better than both FEP and CEP for a number of benchmark problems.", "num_citations": "71\n", "authors": ["537"]}
{"title": "A preliminary study on designing artificial neural networks using co-evolution\n", "abstract": " The design of optimal arti cial neural networks (ANNs) is a key issue in the study of ANNs from the point of view of both theory and applications. There are strong biological and engineering evidences to support that the information processing capability of an ANN is determined by its architecture. However, no systematic method for designing ANNs exists although there are many attempts in attacking this problem. This paper adopts an evolutionary approach to ANN design. The indirect encoding scheme of ANN architectures is used. That is, a genetic algorithm is used to evolve a set of grammar rules which generate an ANN architecture. A novel method of co-evolving a set of rules is proposed in this paper. In our coevolutionary system, each individual in a population represents a rule. The whole population is the complete set of grammar rules which are used to generate an architecture. Preliminary experiments have been carried out to evolve ANN architectures for the parity problem with various sizes.", "num_citations": "71\n", "authors": ["537"]}
{"title": "Robust optimization over time\u2014a new perspective on dynamic optimization problems\n", "abstract": " Dynamic optimization problems (DOPs) are those whose specifications change over time during the optimization, resulting in continuously moving optima. Most research work on DOPs is based on the assumption that the goal of addressing DOPs is to track the moving optima. In this paper, we first point out the practical limitations on tracking the moving optima. We then propose to find optimal solutions that are robust over time as an alternative goal, which leads to a new concept of robust optimization over time (ROOT) problem. In order to investigate the properties of ROOT in more depth, we study the new characteristics of ROOT and investigate its similarities to and differences from the traditional robust optimization problem, which hereafter is referred to as robust optimization for short. To facilitate future research on ROOT, we suggest a ROOT benchmark problem by modifying the moving peaks test problem\u00a0\u2026", "num_citations": "69\n", "authors": ["537"]}
{"title": "Performance of infeasibility driven evolutionary algorithm (IDEA) on constrained dynamic single objective optimization problems\n", "abstract": " A number of population based optimization algorithms have been proposed in recent years to solve unconstrained and constrained single and multi-objective optimization problems. Most of such algorithms inherently prefer a feasible solution over an infeasible one during the course of search, which translates to approaching the constraint boundary from the feasible side of the search space. Previous studies have already demonstrated the benefits of explicitly maintaining a fraction of infeasible solutions in infeasiblity Driven Evolutionary Algorithm (IDEA) for single and multiobjective constrained optimization problems. In this paper, the benefits of IDEA as a sub-evolve mechanism are highlighted for dynamic, constrained single objective optimization problems. IDEA is particularly attractive for such problems as it offers a faster rate of convergence over a conventional EA, which is of significant interest in dynamic\u00a0\u2026", "num_citations": "69\n", "authors": ["537"]}
{"title": "A global repair operator for capacitated arc routing problem\n", "abstract": " Capacitated arc routing problem (CARP) has attracted much attention during the last few years due to its wide applications in real life. Since CARP is NP-hard and exact methods are only applicable for small instances, heuristics and metaheuristic methods are widely adopted when solving CARP. This paper demonstrates one major disadvantage encountered by traditional search algorithms and proposes a novel operator named global repair operator (GRO) to address it. We further embed GRO in a recently proposed tabu search algorithm (TSA) and apply the resultant repair-based tabu search (RTS) algorithm to five well-known benchmark test sets. Empirical results suggest that RTS not only outperforms TSA in terms of quality of solutions but also converges to the solutions faster. Moreover, RTS is also competitive with a number of state-of-the-art approaches for CARP. The efficacy of GRO is thereby justified\u00a0\u2026", "num_citations": "69\n", "authors": ["537"]}
{"title": "Metaheuristics for agricultural land use optimization. A review\n", "abstract": " Agricultural landscapes presently cover about 46\u00a0% of earth terrestrial surface. This cultivated area is decreasing, whereas the global food demand is projected to increase up to 70\u00a0% in 2050. The intensification of agriculture is not a solution to this food issue because intensive agriculture has often resulted in pollution and loss of biodiversity. On the other hand, mechanistic models with optimization algorithms can be used to design alternative land uses for sustainable agriculture. Here, we present a review of metaheuristics for land use optimization reported in 50 articles including 38 case studies carried out in 16 countries. Our main conclusions are: 1) the success of metaheuristics is problem-dependent. In general, metaheuristics enable search to escape from local optima and find a good global approximation solution. 2) The choice of a given metaheuristic for solving a given problem seems to be driven\u00a0\u2026", "num_citations": "68\n", "authors": ["537"]}
{"title": "A framework for finding robust optimal solutions over time\n", "abstract": " Dynamic optimization problems (DOPs) are those whose specifications change over time, resulting in changing optima. Most research on DOPs has so far concentrated on tracking the moving optima (TMO) as closely as possible. In practice, however, it will be very costly, if not impossible to keep changing the design when the environment changes. To address DOPs more practically, we recently introduced a conceptually new problem formulation, which is referred to as robust optimization over time (ROOT). Based on ROOT, an optimization algorithm aims to find an acceptable (optimal or sub-optimal) solution that changes slowly over time, rather than the moving global optimum. In this paper, we propose a generic framework for solving DOPs using the ROOT concept, which searches for optimal solutions that are robust over time by means of local fitness approximation and prediction. Empirical\u00a0\u2026", "num_citations": "68\n", "authors": ["537"]}
{"title": "Why more choices cause less cooperation in iterated prisoner's dilemma\n", "abstract": " The classic iterated prisoner's dilemma (IPD) has only 2 choices, cooperate or defect. However, most real-world situations offer intermediate responses, between full cooperation and full defection. Previous studies observed that with intermediate levels, mutual cooperation is less likely to emerge, and even if it does it is less stable. Exactly why has been a mystery. This paper demonstrates two mechanisms that sabotage the emergence of full mutual cooperation. First, to increase cooperation requires behavioral (phenotypic) diversity to explore different possible outcomes, and once evolution has converged somewhat on a particular degree of cooperation, it is unlikely to shift. Secondly, more choices allows a richer choice of stable strategies that are not simply cooperating with each other to exclude an invader, but which are symbiotic. Such non-symmetric and symbiotic players in the space of strategies act as\u00a0\u2026", "num_citations": "68\n", "authors": ["537"]}
{"title": "A dilemma for fitness sharing with a scaling function\n", "abstract": " Fitness sharing has been used widely in genetic algorithms for multi-objective function optimization and machine learning. It is often implemented with a scaling function, which adjusts an individual\u2019s raw fitness to improve the performance of the genetic algorithm. However, choosing a scaling function is an ad hoc affair that lacks sufficient theoretical foundation. Although this is already known, an explanation of why scaling works is lacking. This paper explains why a scaling function is often needed for fitness sharing. We investigate fitness sharing\u2019s performance at multi-objective optimization, demonstrate t. he need for a scaling function of some kind, and discuss what form of scaling function would be best. We provide both theoretical and empirical evidence that fitness sharing with a scaling function suffers a dilemma which can easily be mistaken for decept, ion. Our theoretical analyses and empirical studies explain why a larger-than-necessary population is needed for fitness sharing with a scaling function to work, and give an explanation for common fixes such as further processing with a hill-climbing algorithm. Our explanation predicts that annealing the scaling power during a run will improve results, and we verify that it does.", "num_citations": "68\n", "authors": ["537"]}
{"title": "A memetic algorithm for multi-level redundancy allocation\n", "abstract": " Redundancy allocation problems (RAPs) have attracted much attention for the past thirty years due to its wide applications in improving the reliability of various engineering systems. Because RAP is an NP-hard problem, and exact methods are only applicable to small instances, various heuristic and meta-heuristic methods have been proposed to solve it. In the literature, most studies on RAPs have been conducted for single-level systems. However, real-world engineering systems usually contain multiple levels. In this paper, the RAP on multi-level systems is investigated. A novel memetic algorithm (MA) is proposed to solve this problem. Two genetic operators, namely breadth-first crossover and breadth-first mutation, and a local search method are designed for the MA. Comprehensive experimental studies have shown that the proposed MA outperformed the state-of-the-art approach significantly on two\u00a0\u2026", "num_citations": "67\n", "authors": ["537"]}
{"title": "Application of genetic algorithm and k-nearest neighbour method in medical fraud detection\n", "abstract": " K-nearest neighbour (KNN) algorithm in combination with a genetic algorithm were applied to a medical fraud detection problem. The genetic algorithm was used to determine the optimal weighting of the features used to classify General Practitioners\u2019 (GP) practice profiles. The weights were used in the KNN algorithm to identify the nearest neighbour practice profiles and then two rules (i.e. the majority rule and the Bayesian rule) were applied to determine the classifications of the practice profiles. The results indicate that this classification methodology achieved good generalisation in classifying GP practice profiles in a test dataset. This opens the way towards its application in the medical fraud detection at Health Insurance Commission (HIC).", "num_citations": "67\n", "authors": ["537"]}
{"title": "R-metric: Evaluating the performance of preference-based evolutionary multiobjective optimization using reference points\n", "abstract": " Measuring the performance of an algorithm for solving multiobjective optimization problem has always been challenging simply due to two conflicting goals, i.e., convergence and diversity of obtained tradeoff solutions. There are a number of metrics for evaluating the performance of a multiobjective optimizer that approximates the whole Pareto-optimal front. However, for evaluating the quality of a preferred subset of the whole front, the existing metrics are inadequate. In this paper, we suggest a systematic way to adapt the existing metrics to quantitatively evaluate the performance of a preference-based evolutionary multiobjective optimization algorithm using reference points. The basic idea is to preprocess the preferred solution set according to a multicriterion decision making approach before using a regular metric for performance assessment. Extensive experiments on several artificial scenarios, and benchmark\u00a0\u2026", "num_citations": "66\n", "authors": ["537"]}
{"title": "Evolving Artificial Neural Networks through Evolutionary Programming.\n", "abstract": " Arti cial neural network (ANN) architecture design has been one of the most tedious and di cult tasks in ANN applications due to the lack of satisfactory and systematic methods of designing a near optimal architecture. Evolutionary algorithms have been shown to be very e ective in evolving novel ANN architectures for various problems. This paper proposes a new automatic method for simultaneously evolving ANN architectures and weights. The method has been applied to four realworld data sets in the medical domain and achieved very good results.", "num_citations": "66\n", "authors": ["537"]}
{"title": "Accelerating large-scale multiobjective optimization via problem reformulation\n", "abstract": " In this paper, we propose a framework to accelerate the computational efficiency of evolutionary algorithms on large-scale multiobjective optimization. The main idea is to track the Pareto optimal set (PS) directly via problem reformulation. To begin with, the algorithm obtains a set of reference directions in the decision space and associates them with a set of weight variables for locating the PS. Afterwards, the original large-scale multiobjective optimization problem is reformulated into a low-dimensional single-objective optimization problem. In the reformulated problem, the decision space is reconstructed by the weight variables and the objective space is reduced by an indicator function. Thanks to the low dimensionality of the weight variables and reduced objective space, a set of quasi-optimal solutions can be obtained efficiently. Finally, a multiobjective evolutionary algorithm is used to spread the quasi-optimal\u00a0\u2026", "num_citations": "65\n", "authors": ["537"]}
{"title": "Empirical analysis of evolutionary algorithms with immigrants schemes for dynamic optimization\n", "abstract": " In recent years, there has been a growing interest in studying evolutionary algorithms (EAs) for dynamic optimization problems (DOPs). Among approaches developed for EAs to deal with DOPs, immigrants schemes have been proven to be beneficial. Immigrants schemes for EAs on DOPs aim at maintaining the diversity of the population throughout the run via introducing new individuals into the current population. In this paper, we carefully examine the mechanism of generating immigrants, which is the most important issue among immigrants schemes for EAs in dynamic environments. We divide existing immigrants schemes into two types, namely the direct immigrants scheme and the indirect immigrants scheme, according to the way in which immigrants are generated. Then experiments are conducted to understand the difference in the behaviors of different types of immigrants schemes and to compare\u00a0\u2026", "num_citations": "65\n", "authors": ["537"]}
{"title": "Cost-sensitive classification with genetic programming\n", "abstract": " Cost-sensitive classification is an attractive topic in data mining. Although genetic programming (GP) technique has been applied to general classification, to our knowledge, it has not been exploited to address cost-sensitive classification in the literature, where the costs of misclassification errors are non-uniform. To investigate the applicability of GP to cost-sensitive classification, this paper first reviews the existing methods of cost-sensitive classification in data mining. We then apply GP to address cost-sensitive classification by means of two methods through: a) manipulating training data, and b) modifying the learning algorithm. In particular, a constrained genetic programming (CGP), a GP-based cost-sensitive classifier, has been introduced in this study. CGP is capable of building decision trees to minimize not only the expected number of errors, but also the expected misclassification costs through a novel\u00a0\u2026", "num_citations": "65\n", "authors": ["537"]}
{"title": "Meta-heuristic algorithms in car engine design: A literature survey\n", "abstract": " Meta-heuristic algorithms are often inspired by natural phenomena, including the evolution of species in Darwinian natural selection theory, ant behaviors in biology, flock behaviors of some birds, and annealing in metallurgy. Due to their great potential in solving difficult optimization problems, meta-heuristic algorithms have found their way into automobile engine design. There are different optimization problems arising in different areas of car engine management including calibration, control system, fault diagnosis, and modeling. In this paper we review the state-of-the-art applications of different meta-heuristic algorithms in engine management systems. The review covers a wide range of research, including the application of meta-heuristic algorithms in engine calibration, optimizing engine control systems, engine fault diagnosis, and optimizing different parts of engines and modeling. The meta-heuristic\u00a0\u2026", "num_citations": "64\n", "authors": ["537"]}
{"title": "Adapting self-adaptive parameters in evolutionary algorithms\n", "abstract": " The lognormal self-adaptation has been used extensively in evolutionary programming (EP) and evolution strategies (ES) to adjust the search step size for each objective variable. However, it was discovered in our previous study (K.-H. Liang, X. Yao, Y. Liu, C. Newton, and D. Hoffman, in Evolutionary Programming VII. Proc. of the Seventh Annual Conference on Evolutionary Programming, vol. 1447, edited by V. Porto, N. Saravanan, D. Waagen, and A. Eiben, Lecture Notes in Computer Science, Springer: Berlin, pp. 291\u2013300, 1998) that such self-adaptation may rapidly lead to a search step size that is far too small to explore the search space any further, and thus stagnates search. This is called the loss of step size control. It is necessary to use a lower bound of search step size to avoid this problem. Unfortunately, the optimal setting of lower bound is highly problem dependent. This paper first analyzes both\u00a0\u2026", "num_citations": "64\n", "authors": ["537"]}
{"title": "Estimation of the distribution algorithm with a stochastic local search for uncertain capacitated arc routing problems\n", "abstract": " The uncertain capacitated arc routing problem is a challenging problem in which the demands of tasks, the costs of edges, and the presence of tasks and edges are uncertain. The objective of this problem is to find a robust optimal solution for a finite set of possible scenarios. In this paper, we propose a novel robust optimization approach, called an estimation of distribution algorithm (EDA) with stochastic local search (SLS), to tackle this problem. The proposed method integrates an EDA with a novel two phase SLS procedure to minimize the maximal total cost over a set of different scenarios. The SLS procedure avoids excessive fitness evaluations of unpromising moves in local search. Our experimental results on two sets of benchmark problems (a total of 55 problem instances) showed that the proposed approach outperformed existing state-of-the-art algorithms.", "num_citations": "62\n", "authors": ["537"]}
{"title": "Graph-based approaches for over-sampling in the context of ordinal regression\n", "abstract": " The classification of patterns into naturally ordered labels is referred to as ordinal regression or ordinal classification. Usually, this classification setting is by nature highly imbalanced, because there are classes in the problem that are a priori more probable than others. Although standard over-sampling methods can improve the classification of minority classes in ordinal classification, they tend to introduce severe errors in terms of the ordinal label scale, given that they do not take the ordering into account. A specific ordinal over-sampling method is developed in this paper for the first time in order to improve the performance of machine learning classifiers. The method proposed includes ordinal information by approaching over-sampling from a graph-based perspective. The results presented in this paper show the good synergy of a popular ordinal regression method (a reformulation of support vector machines) with\u00a0\u2026", "num_citations": "62\n", "authors": ["537"]}
{"title": "Measuring generalization performance in coevolutionary learning\n", "abstract": " Coevolutionary learning involves a training process where training samples are instances of solutions that interact strategically to guide the evolutionary (learning) process. One main research issue is with the generalization performance, i.e., the search for solutions (e.g., input-output mappings) that best predict the required output for any new input that has not been seen during the evolutionary process. However, there is currently no such framework for determining the generalization performance in coevolutionary learning even though the notion of generalization is well-understood in machine learning. In this paper, we introduce a theoretical framework to address this research issue. We present the framework in terms of game-playing although our results are more general. Here, a strategy's generalization performance is its average performance against all test strategies. Given that the true value may not be\u00a0\u2026", "num_citations": "62\n", "authors": ["537"]}
{"title": "A cooperative ensemble learning system\n", "abstract": " This paper presents a new cooperative ensemble learning system (CELS) for designing neural network ensembles. The idea behind CELS is to encourage different individual networks in an ensemble to learn different parts or aspects of the training data so that the ensemble can learn the whole training data better. Rather than producing unbiased individual networks whose errors are uncorrelated, CELS tends to create negatively correlated networks with a novel correlation penalty term in the error function to encourage such specialisation. In CELS, individual networks are trained simultaneously rather than sequentially. This provides an opportunity for different networks to cooperate with each other and to specialise. This paper analyses CELS in terms of bias-variance-covariance trade-off. Experiments on a real-world problem demonstrate that CELS can produce neural network ensembles with good\u00a0\u2026", "num_citations": "62\n", "authors": ["537"]}
{"title": "Negatively correlated search\n", "abstract": " Evolutionary algorithms (EAs) have been shown to be powerful tools for complex optimization problems, which are ubiquitous in both communication and big data analytics. This paper presents a new EA, namely negatively correlated search (NCS), which maintains multiple individual search processes in parallel and models the search behaviors of individual search processes as probability distributions. NCS explicitly promotes negatively correlated search behaviors by encouraging differences among the probability distributions (search behaviors). By this means, individual search processes share information and cooperate with each other to search diverse regions of a search space, which makes NCS a promising method for nonconvex optimization. The co-operation scheme of NCS could also be regarded as a novel diversity preservation scheme that, different from other existing schemes, directly promotes\u00a0\u2026", "num_citations": "61\n", "authors": ["537"]}
{"title": "Combining landscape approximation and local search in global optimization\n", "abstract": " Local search techniques have been applied in variant global optimization methods. The effect of local search to the function landscape can make multimodal problems easier to solve. For evolutionary algorithms, the usage of the step size control concept normally will result in failure by the individual to escape from the local optima during the final stage. We propose an algorithm combining landscape approximation and local search (LALS) which is designed to tackle those difficult multimodal problems. We demonstrate that LALS can solve problems with very rough landscapes and also that LALS has very good global reliability.", "num_citations": "61\n", "authors": ["537"]}
{"title": "Turning high-dimensional optimization into computationally expensive optimization\n", "abstract": " Divide-and-conquer (DC) is conceptually well suited to deal with high-dimensional optimization problems by decomposing the original problem into multiple low-dimensional subproblems, and tackling them separately. Nevertheless, the dimensionality mismatch between the original problem and subproblems makes it nontrivial to precisely assess the quality of a candidate solution to a subproblem, which has been a major hurdle for applying the idea of DC to nonseparable high-dimensional optimization problems. In this paper, we suggest that searching a good solution to a subproblem can be viewed as a computationally expensive problem and can be addressed with the aid of meta-models. As a result, a novel approach, namely self-evaluation evolution (SEE) is proposed. Empirical studies have shown the advantages of SEE over four representative compared algorithms increase with the problem size on the\u00a0\u2026", "num_citations": "60\n", "authors": ["537"]}
{"title": "On investigation of interdependence between sub-problems of the travelling thief problem\n", "abstract": " In this paper, the interdependence between sub-problems in a complex overall problem is investigated using a benchmark problem called Travelling Thief Problem (TTP), which is a combination of Travelling Salesman Problem (TSP) and Knapsack Problem (KP). First, the analysis on the mathematical formulation shows that it is impossible to decompose the problem into independent sub-problems due to the non-linear relationship in the objective function. Therefore, the algorithm for TTP is not straightforward although each sub-problem alone has been investigated intensively. Then, two meta-heuristics are proposed for TTP. One is the Cooperative Co-evolution (CC) that solves the sub-problems separately and transfers the information between them in each generation. The other is the Memetic Algorithm (MA) that solves TTP as a whole. The comparative results showed that MA consistently obtained much\u00a0\u2026", "num_citations": "59\n", "authors": ["537"]}
{"title": "Solving equations by hybrid evolutionary computation techniques\n", "abstract": " Evolutionary computation techniques have mostly been used to solve various optimization and learning problems. This paper describes a novel application of evolutionary computation techniques to equation solving. Several combinations of evolutionary computation techniques and classical numerical methods are proposed to solve linear and partial differential equations. The hybrid algorithms have been compared with the well-known classical numerical methods. The experimental results show that the proposed hybrid algorithms outperform the classical numerical methods significantly in terms of effectiveness and efficiency.", "num_citations": "59\n", "authors": ["537"]}
{"title": "Optimization by genetic annealing\n", "abstract": " Simulated Annealing (SA) is a general stochastic search algorithm. It is usually employed as an optimization method to nd a near optimal solution for hard combinatorial optimization problems, but it is very di cult to give the accuracy of the solution found. In order to nd a better solution, an often used strategy is to run the algorithm many times and select the best solution as the nal one. This paper gives an algorithm called Genetic Annealing (GA), which connects each run of SA and gradually improve the solution. It introduces the concept of evolution into the annealing process. The basic idea is to use genetic operations adopted in genetic algorithms to inherit the possible bene ts of the solutions found in former runs. Experiments have shown that GA is better than classical SA. The parallelization of GA is also discussed in the paper.", "num_citations": "59\n", "authors": ["537"]}
{"title": "Multi-scale statistical process monitoring in machining\n", "abstract": " Most practical industrial process data contain contributions at multiple scales in time and frequency. Unfortunately, conventional statistical process control approaches often detect events at only one scale. This paper addresses a new method, called multiscale statistical process monitoring, for tool condition monitoring in a machining process, which integrates discrete wavelet transform (WT) and statistical process control. Firstly, discrete WT is applied to decompose the collected data from the manufacturing system into uncorrelated components. Next, the detection limits are formed for each decomposed component by using Shewhart control charts. A case study, i.e., tool condition monitoring in turning using an acoustic emission signal, demonstrates that the new method is able to detect abnormal events (serious tool wear or breakage) in the machining process.", "num_citations": "58\n", "authors": ["537"]}
{"title": "Evolving materialized views in data warehouse\n", "abstract": " A data warehouse contains multiple views accessed by queries. One of the most important decisions in designing a data warehouse is the selection of materialized views for the purpose of efficiently implementing decision making. The search space for the selection of materialized views is exponentially large, therefore, heuristics have been used to search a small fraction of the space to get a near optimal solution. In this paper, we explore the use of a genetic algorithm for the selection of materialized views based on multiple global processing plans for many queries. Our experimental studies indicate that the genetic algorithm delivers better solutions than some heuristics.", "num_citations": "58\n", "authors": ["537"]}
{"title": "Neural networks for breast cancer diagnosis\n", "abstract": " Breast cancer diagnosis has been approached by various machine learning techniques for many years. The paper describes two neural network based approaches to breast cancer diagnosis, both of which have displayed good generalisation. The first approach is based on evolutionary artificial neural networks. In this approach, a feedforward neural network is evolved using an evolutionary programming algorithm. Both the weights and architectures (i.e., connectivity of the network) are evolved in the same evolutionary process. The network may grow as well as shrink. The second approach is based on neural network ensembles. In this approach, a number of feedforward neural networks are trained simultaneously in order to solve the breast cancer diagnosis problem cooperatively. The basic idea behind using a group of neural networks rather than a monolithic one is divide-and-conquer. The negative\u00a0\u2026", "num_citations": "58\n", "authors": ["537"]}
{"title": "Evolutionary stability in the n-person iterated prisoner's dilemma\n", "abstract": " The iterated prisoner's dilemma game has been used extensively in the study of the evolution of cooperative behaviours in social and biological systems. The concept of evolutionary stability provides a useful tool to analyse strategies for playing the game. Most results on evolutionary stability, however, are based on the 2-person iterated prisoner's dilemma game. This paper extends the results in the 2-person game and shows that no finite mixture of pure strategies in the n-person iterated prisoner's dilemma game can be evolutionarily stable, where n > 2. The paper also shows that evolutionary stability can be achieved if mistakes are allowed in the n-person game.", "num_citations": "58\n", "authors": ["537"]}
{"title": "A new constructive algorithm for architectural and functional adaptation of artificial neural networks\n", "abstract": " The generalization ability of artificial neural networks (ANNs) is greatly dependent on their architectures. Constructive algorithms provide an attractive automatic way of determining a near-optimal ANN architecture for a given problem. Several such algorithms have been proposed in the literature and shown their effectiveness. This paper presents a new constructive algorithm (NCA) in automatically determining ANN architectures. Unlike most previous studies on determining ANN architectures, NCA puts emphasis on architectural adaptation and functional adaptation in its architecture determination process. It uses a constructive approach to determine the number of hidden layers in an ANN and of neurons in each hidden layer. To achieve functional adaptation, NCA trains hidden neurons in the ANN by using different training sets that were created by employing a similar concept used in the boosting algorithm. The\u00a0\u2026", "num_citations": "57\n", "authors": ["537"]}
{"title": "Multi-start JADE with knowledge transfer for numerical optimization\n", "abstract": " JADE is a recent variant of differential evolution (DE) for numerical optimization, which has been reported to obtain some promising results in experimental study. However, we observed that the reliability, which is an important characteristic of stochastic algorithms, of JADE still needs to be improved. In this paper we apply two strategies together on the original JADE, to dedicatedly improve the reliability of it. We denote the new algorithm as rJADE. In rJADE, we first modify the control parameter adaptation strategy of JADE by adding a weighting strategy. Then, a ldquorestart with knowledge transferrdquo strategy is applied by utilizing the knowledge obtained from previous failures to guide the subsequent search. Experimental studies show that the proposed rJADE achieved significant improvements on a set of widely used benchmark functions.", "num_citations": "57\n", "authors": ["537"]}
{"title": "Trade-off between diversity and accuracy in ensemble generation\n", "abstract": " Abstract                              Ensembles of learning machines have been formally and empirically shown to outperform (generalise better than) single learners in many cases. Evidence suggests that ensembles generalise better when they constitute members which form a diverse and accurate set. Diversity and accuracy are hence two factors that should be taken care of while designing ensembles in order for them to generalise better. There exists a trade-off between diversity and accuracy. Multi-objective evolutionary algorithms can be employed to tackle this issue to good effect. This chapter includes a brief overview of ensemble learning in general and presents a critique on the utility of multi-objective evolutionary algorithms for their design. Theoretical aspects of a committee of learners viz. the bias-variance-covariance decomposition and ambiguity decomposition are further discussed in order to support\u00a0\u2026", "num_citations": "57\n", "authors": ["537"]}
{"title": "Evolutionary algorithms with adaptive l\u00e9vy mutations\n", "abstract": " An evolutionary programming algorithm with adaptive mutation operators based on Levy probability distribution is studied. Levy stable distribution has an infinite second moment. Because of this, Levy mutation is more likely to generate an offspring that is farther away from its parent than Gaussian mutation, which is often used in evolutionary algorithms. Such likelihood depends on a parameter /spl alpha/ in the distribution. Based on this, we propose an adaptive Levy mutation in which four different candidate offspring are generated by each parent, according to /spl alpha/=1.0, 1.3, 1.7, and 2.0, and the best one is chosen as the offspring for the next generation. The proposed algorithm was applied to several multivariate function optimization problems. We show empirically that the performance of the proposed algorithm was better than that of classical evolutionary algorithms using Gaussian mutation.", "num_citations": "57\n", "authors": ["537"]}
{"title": "An experimental study of N-person iterated prisoner's dilemma games\n", "abstract": " The Iterated Prisoner's Dilemma game has been used extensively in the study of the evolution of cooperative behaviours in social and biological systems. There have been a lot of experimental studies on evolving strategies for 2-player Iterated Prisoner's Dilemma games (2IPD). However, there are many real world problems, especially many social and economic ones, which cannot be modelled by the 2IPD. The n-player Iterated Prisoner's Dilemma (NIPD) is a more realistic and general game which can model those problems. This paper presents two sets of experiments on evolving strategies for the NIPD. The first set of experiments examine the impact of the number of players in the NIPD on the evolution of cooperation in the group. Our experiments show that cooperation is less likely to emerge in a large group than in a small group. The second set of experiments study the generalisation ability of evolved\u00a0\u2026", "num_citations": "57\n", "authors": ["537"]}
{"title": "Anxiety and depression among haematological cancer patients attending treatment centres: prevalence and predictors\n", "abstract": " BackgroundThis study aimed to: (1) estimate the prevalence of anxiety and/or depression among haematological cancer patients attending treatment centres; and (2) explore the demographic, disease and treatment characteristics associated with anxiety and/or depression.MethodsA cross-sectional study was conducted with outpatients from three haematology clinics in Australia. Patients with a confirmed diagnosis of haematological cancer were approached by a research assistant while waiting for their appointment and invited to participate in the survey. Participants completed the Hospital Anxiety and Depression Scale (HADS) and self-reported demographic, disease and treatment characteristics.ResultsQuestionnaires from 304 participants were returned. Twenty-seven percent of patients reported anxiety and 17% reported depression. Specifically, 15% reported anxiety without depression, 5% reported\u00a0\u2026", "num_citations": "56\n", "authors": ["537"]}
{"title": "Evolutionary computation\n", "abstract": " This chapter gives a gentle introduction to evolutionary computation, a field in which evolutionary optimisation is one of the most important research areas. Unlike most introductions to evolutionary computation which are based on its simplified biological link, this chapter emphasises the link between evolutionary computation and artificial intelligence and computer science. In fact, this whole book is centred around problem-solving, e.g., optimisation, using evolutionary computation techniques. It does not deal with the issue of biological modelling.", "num_citations": "56\n", "authors": ["537"]}
{"title": "The impact of payoff function and local interaction on the N-player iterated prisoner's dilemma\n", "abstract": " The N-player iterated prisoner's dilemma (NIPD) game has been widely used to study the evolution of cooperation in social, economic and biological systems. This paper studies the impact of different payoff functions and local interactions on the NIPD game. The evolutionary approach is used to evolve game-playing strategies starting from a population of random strategies. The different payoff functions used in our study describe different behaviors of cooperation and defection among a group of players. Local interaction introduces neighborhoods into the NIPD game. A player does not play against every other player in a group any more. He only interacts with his neighbors. We investigate the impact of neighborhood size on the evolution of cooperation in the NIPD game and the generalization ability of evolved strategies.", "num_citations": "56\n", "authors": ["537"]}
{"title": "Objective reduction based on nonlinear correlation information entropy\n", "abstract": " It is hard to obtain the entire solution set of a many-objective optimization problem (MaOP) by multi-objective evolutionary algorithms (MOEAs) because of the difficulties brought by the large number of objectives. However, the redundancy of objectives exists in some problems with correlated objectives (linearly or nonlinearly). Objective reduction can be used to decrease the difficulties of some MaOPs. In this paper, we propose a novel objective reduction approach based on nonlinear correlation information entropy (NCIE). It uses the NCIE matrix to measure the linear and nonlinear correlation between objectives and a simple method to select the most conflicting objectives during the execution of MOEAs. We embed our approach into both Pareto-based and indicator-based MOEAs to analyze the impact of our reduction method on the performance of these algorithms. The results show that our approach\u00a0\u2026", "num_citations": "55\n", "authors": ["537"]}
{"title": "How to make best use of evolutionary learning\n", "abstract": " Evolutionary learning has been developing rapidly in the last decade. It is a powerful and general learning approach which has been used successfully in both symbolic systems, for example, rule-based systems, and subsymbolic systems, for example, artificial neural networks. However, most evolutionary learning systems have paid little attention to the fact that they are population-based learning. The common practice is to select the best individual in the last generation as the final learned system. Such practice, in essence, treats these learning systems as optimization ones. This paper emphasizes the difference between a learning system and an optimization one, and shows that such difference requires a different approach to population-based learning and that the current practice of selecting the best individual as the learned system is not the best choice. The paper then argues that a population contains more information than the best individual and thus should be used as the final learned system. Two examples are presented in this paper to show that even some simple methods which make full use of a population can improve the performance of a learned system greatly. The first example is in the subsymbolic domain of artificial neural networks. The second example is in the symbolic domain of rule-based systems.", "num_citations": "55\n", "authors": ["537"]}
{"title": "Cognitive fault diagnosis in Tennessee Eastman Process using learning in the model space\n", "abstract": " This paper focuses on the Tennessee Eastman (TE) process and for the first time investigates it in a cognitive way. The cognitive fault diagnosis does not assume prior knowledge of the fault numbers and signatures. This approach firstly employs deterministic reservoir models to fit the multiple-input and multiple-output signals in the TE process, which map the signal space to the (reservoir) model space. Then we investigate incremental learning algorithms in this reservoir model space based on the \u201cfunction distance\u201d between these models. The main contribution of this paper is to provide a cognitive solution to this popular benchmark problem. Our approach is not only applicable to fault detection, but also to fault isolation without knowing the prior information about the fault signature. Experimental comparisons with other state-of-the-art approaches confirmed the benefits of our approach. Our algorithm is efficient\u00a0\u2026", "num_citations": "53\n", "authors": ["537"]}
{"title": "Efficient probabilistic classification vector machine with incremental basis function selection\n", "abstract": " Probabilistic classification vector machine (PCVM) is a sparse learning approach aiming to address the stability problems of relevance vector machine for classification problems. Because PCVM is based on the expectation maximization algorithm, it suffers from sensitivity to initialization, convergence to local minima, and the limitation of Bayesian estimation making only point estimates. Another disadvantage is that PCVM was not efficient for large data sets. To address these problems, this paper proposes an efficient PCVM (EPCVM) by sequentially adding or deleting basis functions according to the marginal likelihood maximization for efficient training. Because of the truncated prior used in EPCVM, two approximation techniques, i.e., Laplace approximation and expectation propagation (EP), have been used to implement EPCVM to obtain full Bayesian solutions. We have verified Laplace approximation and EP\u00a0\u2026", "num_citations": "53\n", "authors": ["537"]}
{"title": "An adaptive coevolutionary differential evolution algorithm for large-scale optimization\n", "abstract": " In this paper, we propose a new algorithm, named JACC-G, for large scale optimization problems. The motivation is to improve our previous work on grouping and adaptive weighting based cooperative coevolution algorithm, DECC-G [1], which uses random grouping strategy to divide the objective vector into subcomponents, and solve each of them in a cyclical fashion. The adaptive weighting mechanism is used to adjust all the subcomponents together at the end of each cycle. In the new JACC-G algorithm: (1) A most recent and efficient Differential Evolution (DE) variant, JADE [2], is employed as the subcomponent optimizer to seek for a better performance; (2) The adaptive weighting is time-consuming and expected to work only in the first few cycles, so a detection module is added to prevent applying it arbitrarily; (3) JADE is also used to optimize the weight vector in adaptive weighting process instead of using a\u00a0\u2026", "num_citations": "53\n", "authors": ["537"]}
{"title": "A new self-adaptation scheme for differential evolution\n", "abstract": " The performance of Differential Evolution (DE) largely depends on the choice of trial vector generation strategy and the values of its control parameters. In the past years, quite a few DE variants have been developed to adaptively adjust the strategy and control parameters during the search process. However, these variants may not perform satisfactorily when coping with computationally expensive problems (CEPs) for which a satisfying solution needs to be obtained with very limited fitness evaluations (FEs). In this paper, we demonstrate that not only can surrogate models be used to approximate the fitness function, they can also provide a good alternative method to adapt the strategy and control parameters of DE, and thus propose a framework called DE with Surrogate-assisted Self-Adaptation (DESSA). DESSA generates multiple trial vectors using different trial vector generation strategies and parameter settings\u00a0\u2026", "num_citations": "52\n", "authors": ["537"]}
{"title": "Analysis of population-based evolutionary algorithms for the vertex cover problem\n", "abstract": " Recently it has been proved that the (1+1)-EA produces poor worst-case approximations for the vertex cover problem. In this paper the result is extended to the (1+lambda)-EA by proving that, given a polynomial time, the algorithm can only find poor covers for an instance class of bipartite graphs. Although the generalisation of the result to the (mu+1)-EA is more difficult, hints are given in this paper to show that this algorithm may get stuck on the local optimum of bipartite graphs as well because of premature convergence. However a simple diversity maintenance mechanism can be introduced into the EA for optimising the bipartite instance class effectively. It is proved that the diversity mechanism combined with one point crossover can change the runtime for some instance classes from exponential to polynomial in the number of nodes of the graph.", "num_citations": "52\n", "authors": ["537"]}
{"title": "Semisupervised classification with cluster regularization\n", "abstract": " Semisupervised classification (SSC) learns, from cheap unlabeled data and labeled data, to predict the labels of test instances. In order to make use of the information from unlabeled data, there should be an assumed relationship between the true class structure and the data distribution. One assumption is that data points clustered together are likely to have the same class label. In this paper, we propose a new algorithm, namely, cluster-based regularization (ClusterReg) for SSC, that takes the partition given by a clustering algorithm as a regularization term in the loss function of an SSC classifier. ClusterReg makes predictions according to the cluster structure together with limited labeled data. The experiments confirmed that ClusterReg has a good generalization ability for real-world problems. Its performance is excellent when data follows this cluster assumption. Even when these clusters have misleading\u00a0\u2026", "num_citations": "51\n", "authors": ["537"]}
{"title": "The evolution of connectionist networks\n", "abstract": " Learning and evolution are two fundamental processes of adaptation. Various models have been proposed to explain their behaviour. Rather than discussing these models in detail, this paper concentrates on the interaction between learning and evolution as well as the interaction between different levels of evolution. We will argue that the evolution of learning rules and its interaction with other evolutionary developments (in either artificial or biological systems) plays a key role in accounting for the creativity of those systems. We will concentrate on two models of learning and evolution: connectionistlearning (artificial neural networks, or ANNs) and genetic algorithms (GAs).", "num_citations": "51\n", "authors": ["537"]}
{"title": "Improving efficiency of heuristics for the large scale traveling thief problem\n", "abstract": " The Traveling Thief Problem (TTP) is a novel problem that combines the well-known Traveling Salesman Problem (TSP) and Knapsack Problem (KP). In this paper, the complexity of the local-search-based heuristics for solving TTP is analyzed, and complexity reduction strategies for TTP are proposed to speed up the heuristics. Then, a two-stage local search process with fitness approximation schemes is designed to further improve the efficiency of heuristics. Finally, an efficient Memetic Algorithm (MA) with the two-stage local search is proposed to solve the large scale TTP. The experimental results on the tested large scale TTP benchmark instances showed that the proposed MA can obtain competitive results within a very short time frame for the large scale TTP. This suggests the potential benefits of designing intelligent divide-and-conquer strategies that solves the sub-problems separately while taking\u00a0\u2026", "num_citations": "50\n", "authors": ["537"]}
{"title": "Runtime analysis of the (1+ 1) EA on computing unique input output sequences\n", "abstract": " Computing unique input output (UIO) sequences is a fundamental and hard problem in conformance testing of finite state machines (FSM). Previous experimental research has shown that evolutionary algorithms (EAs) can be applied successfully to find UIOs for some FSMs. However, before EAs can be recommended as a practical technique for computing UIOs, it is necessary to better understand the potential and limitations of these algorithms on this problem. In particular, more research is needed in determining for what instance classes of the problem EAs are feasible, and for what instance classes EAs are provably better than random search strategies.This paper presents rigorous theoretical and numerical analyses of the runtime of the (1\u00a0+\u00a01) EA and random search on several selected instance classes of this problem. The theoretical analysis shows firstly, that there are instance classes where the EA is\u00a0\u2026", "num_citations": "50\n", "authors": ["537"]}
{"title": "Dynamic time-linkage problems revisited\n", "abstract": " Dynamic time-linkage problems (DTPs) are common types of dynamic optimization problems where \u201ddecisions that are made now ... may influence the maximum score that can be obtained in the future\u201d [3]. This paper contributes to understanding the questions of what are the unknown characteristic of DTPs and how to characterize DTPs. Firstly, based on existing definitions we will introduce a more detailed definition to help characterize DTPs. Secondly, although it is believed that DTPs can be solved to optimality with a perfect prediction method to predict function values [3] [4], in this paper we will discuss a new class of DTPs where even with such a perfect prediction method algorithms might still be deceived and hence will not be able to get the optimal results. We will also propose a benchmark problem to study that particular type of time-linkage problems.", "num_citations": "50\n", "authors": ["537"]}
{"title": "Using negative correlation to evolve fault-tolerant circuits\n", "abstract": " In this paper, we show how artificial evolution can be used to improve the fault-tolerance of electronic circuits. We show that evolution is able to improve the fault tolerance of a digital circuit, given a known fault model. Evolution is also able to create sets of different circuits that, when combined into an ensemble of circuits, have reduced correlation in their fault pattern, and therefore improved fault tolerance. An important part of the algorithm used to create the circuits is a measure of the correlation between the fault patterns of different circuits. Using this measure in the fitness, the circuits evolve towards different, highly fault-tolerant circuits. The measure also proves very useful for fitness sharing purposes. We have evolved a number of circuits for a simple 2x3 multiplier problem, and use these to demonstrate the performance under different simulated fault models.", "num_citations": "50\n", "authors": ["537"]}
{"title": "How important is your reputation in a multi-agent environment\n", "abstract": " Most work on the evolutionary approach to the iterated prisoner's dilemma (IPD) game uses a binary model where the choice of each player can only be cooperation or defection. However, we rarely commit ourselves to complete cooperation or defection in the real world. The paper examines the continuous IPD game and similarities and differences between the discrete and continuous games. The paper also studies the issue of reputation of a player, following Nowak and Sigmund's (1998) work, and how it affects the evolution of cooperation. This study differs from Nowak and Sigmund's in that players in a population can have more than two levels of cooperation (or even continuous). The players are also changing all the time under the influence of selection, crossover and mutation. We think that this is a more realistic model of the evolution of society in the real world.", "num_citations": "50\n", "authors": ["537"]}
{"title": "Following the path of evolvable hardware\n", "abstract": " There are differing views on the definition of EHW. Some regard it as the application of evolutionary computation techniques to electronic hardware design, for example, filter design. Some regard it as hardware that is capable of online adaptation by reconfiguring its architecture dynamically and autonomously. The former emphasizes evolutionary computation techniques as potential design tools, while the latter emphasizes adaptation of hardware. It is worth pointing out that EHW is quite different from the hardware implementation of evolutionary algorithms, in which hardware is used to speed up various evolutionary operations. The hardware itself does not change or adapt.There are two major aspects to EHW: simulated evolution and electronic hardware. The simulated evolution can be driven by genetic algorithms, genetic programming, evolutionary programming, or evolution strategies. There is no uniform\u00a0\u2026", "num_citations": "50\n", "authors": ["537"]}
{"title": "An experimental investigation of self-adaptation in evolutionary programming\n", "abstract": " Evolutionary programming (EP) has been widely used in numerical optimization in recent years. One of EP's key features is its self-adaptation scheme. In EP, mutation is typically the only operator used to generate new offspring. The mutation is often implemented by adding a random number from a certain distribution (e.g., Gaussian in the case of classical EP) to the parent. An important parameter of the Gaussian distribution is its standard deviation (or equivalently the variance). In the widely used self-adaptation scheme of EP, this parameter is evolved, rather than manually fixed, along with the objective variables. This paper investigates empirically how well the self-adaptation scheme works on a set of benchmark functions. Some anomalies have been observed in the empirical studies, which demonstrate that the self-adaptation scheme may not work as well as hoped for some functions. An experimental\u00a0\u2026", "num_citations": "49\n", "authors": ["537"]}
{"title": "Evolving modular neural networks which generalise well\n", "abstract": " In dealing with complex problems, a monolithic neural network often becomes too large and complex to design and manage. The only practical way is to design modular neural network systems consisting of simple modules. While there has been a lot of work on combining different modules in a modular system in the fields of neural networks, statistics and machine learning, little work has been done on how to design those modules automatically and how to exploit the interaction between individual module design and module combination. This paper proposes an evolutionary approach to designing modular neural networks. The approach addresses the issue of automatic determination of the number of individual modules and the exploitation of the interaction between individual module design and module combination. The relationship among different modules is considered during the module design. This is quite\u00a0\u2026", "num_citations": "49\n", "authors": ["537"]}
{"title": "Integration of preferences in decomposition multiobjective optimization\n", "abstract": " Rather than a whole Pareto-optimal front, which demands too many points (especially in a high-dimensional space), the decision maker (DM) may only be interested in a partial region, called the region of interest (ROI). In this case, solutions outside this region can be noisy to the decision-making procedure. Even worse, there is no guarantee that we can find the preferred solutions when tackling problems with complicated properties or many objectives. In this paper, we develop a systematic way to incorporate the DM's preference information into the decomposition-based evolutionary multiobjective optimization methods. Generally speaking, our basic idea is a nonuniform mapping scheme by which the originally evenly distributed reference points on a canonical simplex can be mapped to new positions close to the aspiration-level vector supplied by the DM. By this means, we are able to steer the search process\u00a0\u2026", "num_citations": "48\n", "authors": ["537"]}
{"title": "Dealing with Multiple Classes in Online Class Imbalance Learning.\n", "abstract": " Online class imbalance learning deals with data streams having very skewed class distributions in a timely fashion. Although a few methods have been proposed to handle such problems, most of them focus on two-class cases. Multi-class imbalance imposes additional challenges in learning. This paper studies the combined challenges posed by multiclass imbalance and online learning, and aims at a more effective and adaptive solution. First, we introduce two resampling-based ensemble methods, called MOOB and MUOB, which can process multi-class data directly and strictly online with an adaptive sampling rate. Then, we look into the impact of multi-minority and multi-majority cases on MOOB and MUOB in comparison to other methods under stationary and dynamic scenarios. Both multi-minority and multi-majority make a negative impact. MOOB shows the best and most stable G-mean in most stationary and dynamic cases.", "num_citations": "48\n", "authors": ["537"]}
{"title": "Model metric co-learning for time series classification\n", "abstract": " We present a novel model-metric co-learning (MMCL) methodology for sequence classification which learns in the model space--each data item (sequence) is represented by a predictive model from a carefully designed model class. MMCL learning encourages sequences from the same class to be represented by \u2018close\u2019model representations, well separated from those for different classes. Existing approaches to the problem either fit a single model to all the data, or a (predominantly linear) model on each sequence. We introduce a novel hybrid approach spanning the two extremes. The model class we use is a special form of adaptive high-dimensional non-linear state space model with a highly constrained and simple dynamic part. The dynamic part is identical for all data items and acts as a temporal filter providing a rich pool of dynamic features that can be selectively extracted by individual (static) linear readout mappings representing the sequences. Alongside learning the dynamic part, we also learn the global metric in the model readout space. Experiments on synthetic and benchmark data sets confirm the effectiveness of the algorithm compared to a variety of alternative methods.", "num_citations": "48\n", "authors": ["537"]}
{"title": "The neuropathology of Huntington\u2019s disease: classical findings, recent developments and correlation to functional neuroanatomy\n", "abstract": " This monograph describes the progress in neuropathological HD research made during the last century, the neuropathological hallmarks of HD and their pathogenic relevance. Starting with the initial descriptions of the progressive degeneration of the striatum as one of the key events in HD, the worldwide practiced Vonsattel HD grading system of striatal neurodegeneration will be outlined. Correlating neuropathological data with results on the functional neuroanatomy of the human brain, subsequent chapters will highlight recent HD findings: the neuronal loss in the cerebral neo-and allocortex, the neurodegeneration of select thalamic nuclei, the affection of the cerebellar cortex and nuclei, the involvement of select brainstem nuclei, as well as the pathophysiological relevance of these pathologies for the clinical picture of HD. Finally, the potential pathophysiological role of neuronal huntingtin aggregations and the most important and enduring challenges of neuropathological HD research are discussed.", "num_citations": "47\n", "authors": ["537"]}
{"title": "A socio-economic approach to online vision graph generation and handover in distributed smart camera networks\n", "abstract": " In this paper we propose an approach based on self-interested autonomous cameras, which exchange responsibility for tracking objects in a market mechanism, in order to maximise their own utility. A novel ant-colony inspired mechanism is used to grow the vision graph during runtime, which may then be used to optimise communication between cameras. The key benefits of our completely decentralised approach are on the one hand generating the vision graph online which permits the addition and removal cameras to the network during runtime and on the other hand relying only on local information, increasing the robustness of the system. Since our market-based approach does not rely on a priori topology information, the need for any multi-camera calibration can be avoided.", "num_citations": "47\n", "authors": ["537"]}
{"title": "Capacitated arc routing problem in uncertain environments\n", "abstract": " In this paper, the Uncertain CARP (UCARP) is investigated. In UCARP, the demands of tasks and the deadheading costs of edges are stochastic and one has to design a robust solution for all possible environments. A problem model and a robustness measure for solutions are defined according to the requirements in reality. Three benchmark sets with uncertain parameters are generated by extending existing benchmark sets for static cases. In order to explore the solution space of UCARP, the most competitive algorithms for static CARP are tested on one of the generated uncertain benchmark sets. The experimental results showed that the optimal solution in terms of robustness in uncertain environment may be far away from the optimal one in terms of quality in a static environment and thus, utilizing only the expected value of the random variables can hardly lead to robust solutions.", "num_citations": "47\n", "authors": ["537"]}
{"title": "Multiple choices and reputation in multiagent interactions\n", "abstract": " Coevolutionary learning provides a framework for modeling more realistic iterated prisoner's dilemma (IPD) interactions and to study conditions of how and why certain behaviors (e.g., cooperation) in a complex environment can be learned through an adaptation process guided by strategic interactions. The coevolutionary learning of cooperative behaviors can be attributed to the mechanism of direct reciprocity (e.g., repeated encounters). However, for the more complex IPD game with more choices, it is unknown precisely why the mechanism of direct reciprocity is less effective in promoting the learning of cooperative behaviors. Here, our study suggests that the evolution of defection may be a result of strategies effectively having more opportunities to exploit others when there are more choices. We note that strategies are less able to resolve the intention of an intermediate choice, e.g., whether it is a signal to\u00a0\u2026", "num_citations": "47\n", "authors": ["537"]}
{"title": "Using multiple representations in evolutionary algorithms\n", "abstract": " Although evolutionary algorithms are very different from other artificial intelligence search algorithms, they face similar fundamental issues-representation and searching. There has been a large amount of work done in evolutionary computation on searching, such as recombination operators, mutation operators, selection schemes and various specialised operators. In comparison, research on different representations has not been as active. Most such research has been focused on a single representation, e.g. bit strings, real-valued vectors using Cartesian coordinates, etc. This paper proposes and studies multiple representations in an evolutionary algorithm and shows empirically how multiple representations can benefit searches as much as a good search operator could.", "num_citations": "47\n", "authors": ["537"]}
{"title": "CBCC3\u2014A contribution-based cooperative co-evolutionary algorithm with improved exploration/exploitation balance\n", "abstract": " Cooperative Co-evolution (CC) is a promising framework for solving large-scale optimization problems. However, the round-robin strategy of CC is not an efficient way of allocating the available computational resources to components of imbalanced functions. The imbalance problem happens when the components of a partially separable function have non-uniform contributions to the overall objective value. Contribution-Based Cooperative Co-evolution (CBCC) is a variant of CC that allocates the available computational resources to the individual components based on their contributions. CBCC variants (CBCC1 and CBCC2) have shown better performance than the standard CC in a variety of cases. In this paper, we show that over-exploration and over-exploitation are two major sources of performance loss in the existing CBCC variants. On that basis, we propose a new contribution-based algorithm that\u00a0\u2026", "num_citations": "46\n", "authors": ["537"]}
{"title": "Feature selection for microarray data using least squares svm and particle swarm optimization\n", "abstract": " Feature selection is an important preprocessing technique for many pattern recognition problems. When the number of features is very large while the number of samples is relatively small as in the micro-array data analysis, feature selection is even more important. This paper proposes a novel feature selection method to perform gene selection from DNA microarray data. The method originates from the least squares support vector machine (LSSVM). The particle swarm optimization (PSO) algorithm is also employed to perform optimization. Experimental results clearly demonstrate good and stable performance of the proposed method.", "num_citations": "46\n", "authors": ["537"]}
{"title": "A scalable indicator-based evolutionary algorithm for large-scale multiobjective optimization\n", "abstract": " The performance of traditional multiobjective evolutionary algorithms (MOEAs) often deteriorates rapidly as the number of decision variables increases. While some efforts were made to design new algorithms by adapting existing techniques to large-scale single-objective optimization to the MOEA context, the specific difficulties that may arise from large-scale multiobjective optimization have rarely been studied. In this paper, the exclusive challenges along with the increase of the number of variables of a multiobjective optimization problem (MOP) are examined empirically, and the popular benchmarks are categorized into three groups accordingly. Problems in the first category only require MOEAs to have stronger convergence, and can thus be mitigated using techniques employed in large-scale single-objective optimization. Problems that require MOEAs to have stronger diversification but ignore a correlation\u00a0\u2026", "num_citations": "45\n", "authors": ["537"]}
{"title": "Scalable graph-based semi-supervised learning through sparse bayesian model\n", "abstract": " Semi-supervised learning (SSL) concerns the problem of how to improve classifiers\u2019 performance through making use of prior knowledge from unlabeled data. Many SSL methods have been developed to integrate unlabeled data into the classifiers based on either the manifold or cluster assumption in recent years. In particular, the graph-based approaches, following the manifold assumption, have achieved a promising performance in many real-world applications. However, most of them work well on small-scale data sets only and lack probabilistic outputs. In this paper, a scalable graph-based SSL framework through sparse Bayesian model is proposed by defining a graph-based sparse prior. Based on the traditional Bayesian inference technique, a sparse Bayesian SSL algorithm (SBS  L) is obtained, which can remove the irrelevant unlabeled samples and make probabilistic prediction for out-of-sample data. Moreover, in order\u00a0\u2026", "num_citations": "45\n", "authors": ["537"]}
{"title": "Resource allocation in decentralised computational systems: an evolutionary market-based approach\n", "abstract": " We present a novel market-based method, inspired by retail markets, for resource allocation in fully decentralised systems where agents are self-interested. Our market mechanism requires no coordinating node or complex negotiation. The stability of outcome allocations, those at equilibrium, is analysed and compared for three buyer behaviour models. In order to capture the interaction between self-interested agents, we propose the use of competitive coevolution. Our approach is both highly scalable and may be tuned to achieve specified outcome resource allocations. We demonstrate the behaviour of our approach in simulation, where evolutionary market agents act on behalf of service providing nodes to adaptively price their resources over time, in response to market conditions. We show that this leads the system to the predicted outcome resource allocation. Furthermore, the system remains stable in\u00a0\u2026", "num_citations": "45\n", "authors": ["537"]}
{"title": "Evolving edited k-nearest neighbor classifiers\n", "abstract": " The k-nearest neighbor method is a classifier based on the evaluation of the distances to each pattern in the training set. The edited version of this method consists of the application of this classifier with a subset of the complete training set in which some of the training patterns are excluded, in order to reduce the classification error rate. In recent works, genetic algorithms have been successfully applied to determine which patterns must be included in the edited subset. In this paper we propose a novel implementation of a genetic algorithm for designing edited k-nearest neighbor classifiers. It includes the definition of a novel mean square error based fitness function, a novel clustered crossover technique, and the proposal of a fast smart mutation scheme. In order to evaluate the performance of the proposed method, results using the breast cancer database, the diabetes database and the letter recognition database\u00a0\u2026", "num_citations": "45\n", "authors": ["537"]}
{"title": "Co-evolutionary modular neural networks for automatic problem decomposition\n", "abstract": " Decomposing a complex computational problem into sub-problems, which are computationally simpler to solve individually and which can be combined to produce a solution to the full problem, can efficiently lead to compact and general solutions. Modular neural networks represent one of the ways in which this divide-and-conquer strategy can be implemented. Here we present a co-evolutionary model which is used to design and optimize modular neural networks with task-specific modules. The model consists of two populations. The first population consists of a pool of modules and the second population synthesizes complete systems by drawing elements from the pool of modules. Modules represent a part of the solution, which co-operates with others in the module population to form a complete solution. With the help of two artificial supervised learning tasks created by mixing two sub-tasks we demonstrate that\u00a0\u2026", "num_citations": "45\n", "authors": ["537"]}
{"title": "Evolutionary path control strategy for solving many-objective optimization problem\n", "abstract": " The number of objectives in many-objective optimization problems (MaOPs) is typically high and evolutionary algorithms face severe difficulties in solving such problems. In this paper, we propose a new scalable evolutionary algorithm, called evolutionary path control strategy (EPCS), for solving MaOPs. The central component of our algorithm is the use of a reference vector that helps simultaneously minimizing all the objectives of an MaOP. In doing so, EPCS employs a new fitness assignment strategy for survival selection. This strategy consists of two procedures and our algorithm applies them sequentially. It encourages a population of solutions to follow a certain path reaching toward the Pareto optimal front. The essence of our strategy is that it reduces the number of nondominated solutions to increase selection pressure in evolution. Furthermore, unlike previous work, EPCS is able to apply the classical Pareto\u00a0\u2026", "num_citations": "44\n", "authors": ["537"]}
{"title": "Sparse approximation through boosting for learning large scale kernel machines\n", "abstract": " Recently, sparse approximation has become a preferred method for learning large scale kernel machines. This technique attempts to represent the solution with only a subset of original data points also known as basis vectors, which are usually chosen one by one with a forward selection procedure based on some selection criteria. The computational complexity of several resultant algorithms scales as O(NM 2 ) in time and O(NM) in memory, where N is the number of training points and M is the number of basis vectors as well as the steps of forward selection. For some large scale data sets, to obtain a better solution, we are sometimes required to include more basis vectors, which means that M is not trivial in this situation. However, the limited computational resource (e.g., memory) prevents us from including too many vectors. To handle this dilemma, we propose to add an ensemble of basis vectors instead of only\u00a0\u2026", "num_citations": "44\n", "authors": ["537"]}
{"title": "Evolving a cooperative population of neural networks by minimizing mutual information\n", "abstract": " Evolutionary ensembles with negative correlation learning (EENCL) is an evolutionary learning system for learning and designing neural network ensembles (Liu et al., 2000). The fitness sharing used in EENCL was based on the idea of \"covering\" the same training patterns by shared individuals. This paper explores connection between fitness sharing and information concept, and introduces mutual information into EENCL. Through minimization of mutual information, a diverse and cooperative population of neural networks can be evolved by EENCL. The effectiveness of such evolutionary learning approach was tested on two real-world problems.", "num_citations": "44\n", "authors": ["537"]}
{"title": "Evolving artificial neural networks for medical applications\n", "abstract": " Arti cial neural network (ANN) architecture design has been one of the most tedious and di cult tasks in ANN applications due to the lack of satisfactory and systematic methods of designing a near optimal architecture. Evolutionary algorithms have been shown to be very e ective in evolving novel ANN architectures for various problems. This paper proposes a new method for evolving ANN architectures and weights at the same time. The new method has been applied to four real-world data sets in the medical domain and achieved very good results. The traditional trial-and-error approach to designing ANNs has been replaced by an automatic evolutionary system which can nd a near optimal architecture and connection weights for a problem.", "num_citations": "44\n", "authors": ["537"]}
{"title": "Finding robust solutions to dynamic optimization problems\n", "abstract": " Most research in evolutionary dynamic optimization is based on the assumption that the primary goal in solving Dynamic Optimization Problems (DOPs) is Tracking Moving Optimum (TMO). Yet, TMO is impractical in cases where keeping changing solutions in use is impossible. To solve DOPs more practically, a new formulation of DOPs was proposed recently, which is referred to as Robust Optimization Over Time (ROOT). In ROOT, the aim is to find solutions whose fitnesses are robust to future environmental changes. In this paper, we point out the inappropriateness of existing robustness definitions used in ROOT, and therefore propose two improved versions, namely survival time and average fitness. Two corresponding metrics are also developed, based on which survival time and average fitness are optimized respectively using population-based algorithms. Experimental results on benchmark problems\u00a0\u2026", "num_citations": "43\n", "authors": ["537"]}
{"title": "Improving generalization performance in co-evolutionary learning\n", "abstract": " Recently, the generalization framework in co-evolutionary learning has been theoretically formulated and demonstrated in the context of game-playing. Generalization performance of a strategy (solution) is estimated using a collection of random test strategies (test cases) by taking the average game outcomes, with confidence bounds provided by Chebyshev's theorem. Chebyshev's bounds have the advantage that they hold for any distribution of game outcomes. However, such a distribution-free framework leads to unnecessarily loose confidence bounds. In this paper, we have taken advantage of the near-Gaussian nature of average game outcomes and provided tighter bounds based on parametric testing. This enables us to use small samples of test strategies to guide and improve the co-evolutionary search. We demonstrate our approach in a series of empirical studies involving the iterated prisoner's dilemma\u00a0\u2026", "num_citations": "43\n", "authors": ["537"]}
{"title": "Evolutionary multi-criterion optimization\n", "abstract": " Evolutionary multi-criterion optimization Page 1 Multiobjective Optimization Evolutionary Multi-Objective Optimization Kalyanmoy Deb Deva Raj Chair Professor Indian Institute of Technology Kanpur Kanpur, PIN 208016, INDIA deb@iitk.ac.in http://www.iitk.ac.in/kangal/deb.htm GECCO-2010 Tutorial on EMO Portland, USA (8 July'10) 1 Copyright is held by the author/owner(s). GECCO\u201910, July 7\u201311, 2010, Portland, Oregon, USA. ACM 978-1-4503-0073-5/10/07. 8 July 2010 10:40-12:30 Hrs. Instructor Biography GECCO-2010 Tutorial on EMO Portland, USA (8 July'10) 2 Kalyanmoy Deb holds Deva Raj Chair Professor at Indian Institute of Technology Kanpur in India. He is the recipient of the MCDM Edgeworth-Pareto award by the Multiple Criterion Decision Making (MCDM) Society. He has also received Shanti Swarup Bhatnagar Prize in Engineering Sciences for the year 2005 from Govt. of India. He has also \u2026", "num_citations": "43\n", "authors": ["537"]}
{"title": "Digital filter design using multiple pareto fronts\n", "abstract": " Evolutionary approaches have been used in a large variety of design domains, from aircraft engineering to the designs of analog filters. Many of these approaches use measures to improve the variety of solutions in the population. One such measure is clustering. In this paper, clustering and Pareto optimisation are combined into a single evolutionary design algorithm. The population is split into a number of clusters, and parent and offspring selection, as well as fitness calculation, are performed on a per-cluster basis. The objective of this is to prevent the system from converging prematurely to a local minimum and to encourage a number of different designs that fulfil the design criteria. Our approach is demonstrated in the domain of digital filter design. Using a polar coordinate based pole-zero representation, two different lowpass filter design problems are explored. The results are compared to designs\u00a0\u2026", "num_citations": "43\n", "authors": ["537"]}
{"title": "Convex hull-based multiobjective genetic programming for maximizing receiver operating characteristic performance\n", "abstract": " The receiver operating characteristic (ROC) is commonly used to analyze the performance of classifiers in data mining. An important topic in ROC analysis is the ROC convex hull (ROCCH), which is the least convex majorant (LCM) of the empirical ROC curve and covers potential optima for a given set of classifiers. ROCCH maximization problems have been taken as multiobjective optimization problem (MOPs) in some previous work. However, the special characteristics of ROCCH maximization problem makes it different from traditional MOPs. In this paper, the difference will be discussed in detail and a new convex hull-based multiobjective genetic programming (CH-MOGP) is proposed to solve ROCCH maximization problems. Specifically, convex hull-based without redundancy sorting (CWR-sorting) is introduced, which is an indicator-based selection scheme that aims to maximize the area under the convex hull\u00a0\u2026", "num_citations": "42\n", "authors": ["537"]}
{"title": "Dynamic multi-objective optimization: a survey of the state-of-the-art\n", "abstract": " Many optimization problems involve multiple objectives, constraints and parameters that change over time. These problems are called dynamic multiobjective optimization problems (DMOPs) and have recently attracted a lot of research. In this chapter, we provide a survey of the state-of-the-art on the field of dynamic multi-objective optimization with regards to the definition and classification of DMOPS, test problems, performance measures and optimization approaches. We provide a comprehensive definition of DMOPs and identify gaps, challenges and future works in dynamic multi-objective optimization.", "num_citations": "42\n", "authors": ["537"]}
{"title": "Dynamic salting route optimisation using evolutionary computation\n", "abstract": " On marginal winter nights, highway authorities face a difficult decision as to whether or not to salt the road network. The consequences of making a wrong decision are serious, as an untreated network is a major hazard. However, if salt is spread when it is not actually required, there are unnecessary financial and environmental consequences. In this paper, a new salting route optimisation system is proposed which combines evolutionary computation (EC) with the next generation road weather information systems (XRWIS). XRWIS is a new high resolution forecast system which predicts road surface temperature and condition across the road network over a 24 hour period. ECs are used to optimise a series of salting routes for winter gritting by considering XRWIS temperature data along with treatment vehicle and road network constraints. This synergy realises daily dynamic routing and it will yield considerable\u00a0\u2026", "num_citations": "42\n", "authors": ["537"]}
{"title": "On the easiest and hardest fitness functions\n", "abstract": " The hardness of fitness functions is an important research topic in the field of evolutionary computation. In theory, this paper can help with understanding the ability of evolutionary algorithms (EAs). In practice, this paper may provide a guideline to the design of benchmarks. The aim of this paper is to answer the following research questions. Given a fitness function class, which functions are the easiest with respect to an EA? Which are the hardest? How are these functions constructed? This paper provides theoretical answers to these questions. The easiest and hardest fitness functions are constructed for an elitist (1 + 1) EA to maximize a class of fitness functions with the same optima. It is demonstrated that the unimodal functions are the easiest and deceptive functions are the hardest in terms of the time-based fitness landscape. This paper also reveals that in a fitness function class, the easiest function to one\u00a0\u2026", "num_citations": "41\n", "authors": ["537"]}
{"title": "Similarities in precursory features in seismic shocks and epileptic seizures\n", "abstract": " Theoretical studies suggest that the final earthquake (EQ) and neural-seizure dynamics should have many similar features and could be analyzed within similar mathematical frameworks. Herein, by monitoring the temporal evolution of the fractal spectral characteristics in EEG time series and pre-seismic electromagnetic (EM) time series we show that many similar distinctive symptoms (including common alterations in associated scaling parameters) emerge as epileptic seizures (ES) and EQs are approaching. These alterations reveal a gradual reduction of complexity as the catastrophic events approach. The transition from anti-persistent to persistent behaviour may indicate that the onset of a severe crisis is imminent. The observations find a unifying explanation within the school of the\" Intermittent Criticality\".", "num_citations": "41\n", "authors": ["537"]}
{"title": "Fitness-probability cloud and a measure of problem hardness for evolutionary algorithms\n", "abstract": " Evolvability is an important feature directly related to problem hardness for Evolutionary Algorithms (EAs). A general relationship that holds for Evolvability and problem hardness is the higher the degree of evolvability, the easier the problem is for EAs. This paper presents, for the first time, the concept of Fitness-Probability Cloud (fpc) to characterise evolvability from the point of view of escape probability and fitness correlation. Furthermore, a numerical measure called Accumulated Escape Probability (aep) based on fpc is proposed to quantify this feature, and therefore problem difficulty. To illustrate the effectiveness of our approach, we apply it to four test problems: OneMax, Trap, OneMix and Subset Sum. We then contrast the predictions made by the aep to the actual performance measured using the number of fitness evaluations. The results suggest that the new measure can reliably indicate problem\u00a0\u2026", "num_citations": "40\n", "authors": ["537"]}
{"title": "An immigrants scheme based on environmental information for genetic algorithms in changing environments\n", "abstract": " Addressing dynamic optimization problems (DOPs) has been a challenging task for the genetic algorithm (GA) community. One approach is to maintain the diversity of the population via introducing immigrants. This paper intensively examines several design decisions when employing immigrants schemes, and from these observations an environmental information-based immigrants scheme is derived for GAs to deal with DOPs. In the scheme, the environmental information (e.g., the allele distribution over the population in this paper) from previous generation is used to create immigrants to replace the worst individuals in the current population. In this way, the introduced immigrants are more adapted to the changing environment. A hybrid scheme combining immigrants based on current environmental information and its complementation is also proposed in this paper to address different degrees of changes\u00a0\u2026", "num_citations": "40\n", "authors": ["537"]}
{"title": "Evolutionary framework for the construction of diverse hybrid ensembles.\n", "abstract": " Enforcing diversity explicitly in ensembles while at the same time making individual predictors accurate as well has been shown to be promising. This idea was recently taken into account in the algorithm DIVACE. There have been a multitude of theories on how one can enforce diversity within a combined predictor setup. This paper aims to bring these theories together in an attempt to synthesise a framework that can be used to engender new evolutionary ensemble learning algorithms. The framework treats diversity and accuracy as evolutionary pressures that can be exerted at multiple levels of abstraction and is shown to be effective.", "num_citations": "40\n", "authors": ["537"]}
{"title": "Analysing crossover operators by search step size\n", "abstract": " Crossover plays an important role in GA based search. There have been many empirical comparisons of different crossover operators in the literature. However, analytical results are limited. No theory has explained the behaviours of different crossover operators satisfactorily. The paper analyses crossover from quite a different point of view from the classical schema theorem. It explains the behaviours of different crossover operators through the investigation of crossover's search neighbourhood and search step size. It is shown that given the binary chromosome encoding scheme, GAs with a large search step size are better than GAs with a small step size for most problems. Since uniform crossover's search step size is larger than that of either one point or two point crossover, uniform crossover is expected to perform better than the other two. Similarly, two point crossover is expected to perform better than one point\u00a0\u2026", "num_citations": "40\n", "authors": ["537"]}
{"title": "Model-based evolutionary algorithms: a short survey\n", "abstract": " The evolutionary algorithms (EAs) are a family of nature-inspired algorithms widely used for solving complex optimization problems. Since the operators (e.g. crossover, mutation, selection) in most traditional EAs are developed on the basis of fixed heuristic rules or strategies, they are unable to learn the structures or properties of the problems to be optimized. To equip the EAs with learning abilities, recently, various model-based evolutionary algorithms (MBEAs) have been proposed. This survey briefly reviews some representative MBEAs by considering three different motivations of using models. First, the most commonly seen motivation of using models is to estimate the distribution of the candidate solutions. Second, in evolutionary multi-objective optimization, one motivation of using models is to build the inverse models from the objective space to the decision space. Third, when solving computationally\u00a0\u2026", "num_citations": "39\n", "authors": ["537"]}
{"title": "Layered ensemble architecture for time series forecasting\n", "abstract": " Time series forecasting (TSF) has been widely used in many application areas such as science, engineering, and finance. The phenomena generating time series are usually unknown and information available for forecasting is only limited to the past values of the series. It is, therefore, necessary to use an appropriate number of past values, termed lag, for forecasting. This paper proposes a layered ensemble architecture (LEA) for TSF problems. Our LEA consists of two layers, each of which uses an ensemble of multilayer perceptron (MLP) networks. While the first ensemble layer tries to find an appropriate lag, the second ensemble layer employs the obtained lag for forecasting. Unlike most previous work on TSF, the proposed architecture considers both accuracy and diversity of the individual networks in constructing an ensemble. LEA trains different networks in the ensemble by using different training sets with\u00a0\u2026", "num_citations": "39\n", "authors": ["537"]}
{"title": "Multi-colony ant algorithms for the dynamic travelling salesman problem\n", "abstract": " A multi-colony ant colony optimization (ACO) algorithm consists of several colonies of ants. Each colony uses a separate pheromone table in an attempt to maximize the search area explored. Over the years, multi-colony ACO algorithms have been successfully applied on different optimization problems with stationary environments. In this paper, we investigate their performance in dynamic environments. Two types of algorithms are proposed: homogeneous and heterogeneous approaches, where colonies share the same properties and colonies have their own (different) properties, respectively. Experimental results on the dynamic travelling salesman problem show that multi-colony ACO algorithms have promising performance in dynamic environments when compared with single colony ACO algorithms.", "num_citations": "39\n", "authors": ["537"]}
{"title": "Robust optimization over time: Problem difficulties and benchmark problems\n", "abstract": " The focus of most research in evolutionary dynamic optimization has been tracking moving optimum (TMO). Yet, TMO does not capture all the characteristics of real-world dynamic optimization problems (DOPs), especially in situations where a solution's future fitness has to be considered. To account for a solution's future fitness explicitly, we propose to find robust solutions to DOPs, which are formulated as the robust optimization over time (ROOT) problem. In this paper we analyze two robustness definitions in ROOT and then develop two types of benchmark problems for the two robustness definitions in ROOT, respectively. The two types of benchmark problems are motivated by the inappropriateness of existing DOP benchmarks for the study of ROOT. Additionally, we evaluate four representative methods from the literature on our proposed ROOT benchmarks, in order to gain a better understanding of ROOT\u00a0\u2026", "num_citations": "39\n", "authors": ["537"]}
{"title": "Multiobjective genetic programming for maximizing ROC performance\n", "abstract": " In binary classification problems, receiver operating characteristic (ROC) graphs are commonly used for visualizing, organizing and selecting classifiers based on their performances. An important issue in the ROC literature is to obtain the ROC convex hull (ROCCH) that covers potentially optima for a given set of classifiers [1]. Maximizing the ROCCH means to maximize the true positive rate (tpr) and minimize the false positive rate (fpr) for every classifier in ROC space, while tpr and fpr are conflicting with each other. In this paper, we propose multiobjective genetic programming (MOGP) to obtain a group of nondominated classifiers, with which the maximum ROCCH can be achieved. Four different multiobjective frameworks, including Nondominated Sorting Genetic Algorithm II (NSGA-II), Multiobjective Evolutionary Algorithms Based on Decomposition (MOEA/D), Multiobjective selection based on dominated\u00a0\u2026", "num_citations": "39\n", "authors": ["537"]}
{"title": "Runtime analysis of evolutionary algorithms for discrete optimization\n", "abstract": " Theoretical studies of evolutionary algorithms (EAs) have existed since the seventies when EAs started to become popular. These early studies contributed towards the understanding of EAs but did not explain their performance in terms of their dynamical or limit behaviour. Only in the nineties the first convergence and time complexity results appeared for simple algorithms and toy problems. Nowadays, it is possible to analyse the time complexity of more complicated algorithms for combinatorial optimization problems with practical applications. This chapter overviews the most popular mathematical techniques used in the runtime analysis of EAs and gives some simple examples of their application.", "num_citations": "39\n", "authors": ["537"]}
{"title": "NichingEDA: Utilizing the diversity inside a population of EDAs for continuous optimization\n", "abstract": " Since the estimation of distribution algorithms (EDAs) have been introduced, several single model based EDAs and mixture model based EDAs have been developed. Take Gaussian models as an example, EDAs based on single Gaussian distribution have good performance on solving simple unimodal functions and multimodal functions whose landscape has an obvious trend towards the global optimum. But they have difficulties in solving multimodal functions with irregular landscapes, such as wide basins, flat plateaus and deep valleys. Gaussian mixture model based EDAs have been developed to remedy this disadvantage of single Gaussian based EDAs. A general framework NichingEDA is presented in this paper from a new perspective to boost single model based EDAspsila performance. Through adopting a niching method and recombination operators in a population of EDAs, NichingEDA significantly\u00a0\u2026", "num_citations": "39\n", "authors": ["537"]}
{"title": "On the analysis of average time complexity of estimation of distribution algorithms\n", "abstract": " Estimation of Distribution Algorithm (EDA) is a well-known stochastic optimization technique. The average time complexity is a crucial criterion that measures the performance of the stochastic algorithms. In the past few years, various kinds of EDAs have been proposed, but the related theoretical study on the time complexity of these algorithms is relatively few. This paper analyzed the time complexity of two early versions of EDA, the Univariate Marginal Distribution Algorithm (UMDA) and the Incremental UMDA (IUMDA). We generalize the concept of convergence to convergence time, and manage to estimate the upper bound of the mean First Hitting Times (FHTs) of UMDA (IUMDA) on a well-known pseudo-modular function, which is frequently studied in the field of genetic algorithms. Our analysis shows that UMDA (IUMDA) has O(n) behaviors on the pseudo-modular function. In addition, we analyze the mean FHT\u00a0\u2026", "num_citations": "39\n", "authors": ["537"]}
{"title": "Evolving neural networks for Hang Seng stock index forecast\n", "abstract": " This paper describes an evolutionary neural network approach to Hang Seng stock index forecast. In this approach, a feedforward neural network is evolved using an evolutionary programming algorithm. Both the weights and architectures (i.e., connectivity of the network) are evolved in the same evolutionary process. The network may grow as well as shrink. The experimental results show that the evolutionary neural network approach can produce very compact neural networks with good prediction.", "num_citations": "39\n", "authors": ["537"]}
{"title": "Binarization with boosting and oversampling for multiclass classification\n", "abstract": " Using a set of binary classifiers to solve multiclass classification problems has been a popular approach over the years. The decision boundaries learnt by binary classifiers (also called base classifiers) are much simpler than those learnt by multiclass classifiers. This paper proposes a new classification framework, termed binarization with boosting and oversampling (BBO), for efficiently solving multiclass classification problems. The new framework is devised based on the one-versus-all (OVA) binarization technique. Unlike most previous work, BBO employs boosting for solving the hard-to-learn instances and oversampling for handling the class-imbalance problem arising due to OVA binarization. These two features make BBO different from other existing works. Our new framework has been tested extensively on several multiclass supervised and semi-supervised classification problems using five different base\u00a0\u2026", "num_citations": "38\n", "authors": ["537"]}
{"title": "Learning to be different: Heterogeneity and efficiency in distributed smart camera networks\n", "abstract": " In this paper we study the self-organising behaviour of smart camera networks which use market-based handover of object tracking responsibilities to achieve an efficient allocation of objects to cameras. Specifically, we compare previously known homogeneous configurations, when all cameras use the same marketing strategy, with heterogeneous configurations, when each camera makes use of its own, possibly different marketing strategy. Our first contribution is to establish that such heterogeneity of marketing strategies can lead to system wide outcomes which are Pareto superior when compared to those possible in homogeneous configurations. However, since the particular configuration required to lead to Pareto efficiency in a given scenario will not be known in advance, our second contribution is to show how online learning of marketing strategies at the individual camera level can lead to high performing\u00a0\u2026", "num_citations": "38\n", "authors": ["537"]}
{"title": "Optimal switch location in mobile communication networks using hybrid genetic algorithms\n", "abstract": " The optimal positioning of switches in a mobile communication network is an important task, which can save costs and improve the performance of the network. In this paper we propose a model for establishing which are the best nodes of the network for allocating the available switches, and several hybrid genetic algorithms to solve the problem. The proposed model is based on the so-called capacitated p-median problem, which have been previously tackled in the literature. This problem can be split in two subproblems: the selection of the best set of switches, and a terminal assignment problem to evaluate each selection of switches. The hybrid genetic algorithms for solving the problem are formed by a conventional genetic algorithm, with a restricted search, and several local search heuristics. In this work we also develop novel heuristics for solving the terminal assignment problem in a fast and accurate way\u00a0\u2026", "num_citations": "38\n", "authors": ["537"]}
{"title": "A wavelet-based data pre-processing analysis approach in mass spectrometry\n", "abstract": " Recently, mass spectrometry analysis has a become an effective and rapid approach in detecting early-stage cancer. To identify proteomic patterns in serum to discriminate cancer patients from normal individuals, machine-learning methods, such as feature selection and classification, have already been involved in the analysis of mass spectrometry (MS) data with some success. However, the performance of existing machine learning methods for MS data analysis still needs improving. The study in this paper proposes a wavelet-based pre-processing approach to MS data analysis. The approach applies wavelet-based transforms to MS data with the aim of de-noising the data that are potentially contaminated in acquisition. The effects of the selection of wavelet function and decomposition level on the de-noising performance have also been investigated in this study. Our comparative experimental results\u00a0\u2026", "num_citations": "38\n", "authors": ["537"]}
{"title": "A comparative study of three evolutionary algorithms incorporating different amounts of domain knowledge for node covering problem\n", "abstract": " This paper compares three different evolutionary algorithms for solving the node covering problem: EA-I relies on the definition of the problem only without using any domain knowledge, while EA-II and EA-III employ extra heuristic knowledge. In theory, it is proven that all three algorithms can find an optimal solution in finite generations and find a feasible solution efficiently; but none of them can find the optimal solution efficiently for all instances of the problem. Through experiments, it is observed that all three algorithms can find a feasible solution efficiently, and the algorithms with extra heuristic knowledge can find better approximation solutions, but none of them can find the optimal solution to the first instance efficiently. This paper shows that heuristic knowledge is helpful for evolutionary algorithms to find good approximation solutions, but it contributes little to search for the optimal solution in some instances.", "num_citations": "38\n", "authors": ["537"]}
{"title": "Scaling up evolutionary programming algorithms\n", "abstract": " Most analytical and experimental results on evolutionary programming (EP) are obtained using low-dimensional problems, e.g., smaller than 50. It is unclear, however, whether the empirical results obtained from the low-dimensional problems still hold for high-dimensional cases. This paper investigates the behaviour of four different EP algorithms for large-scale problems, i.e., problems whose dimension ranges from 100 to 300. The four are classical EP (CEP) [1, 2], fast EP (FEP).", "num_citations": "38\n", "authors": ["537"]}
{"title": "Multiobjective learning in the model space for time series classification\n", "abstract": " A well-defined distance is critical for the performance of time series classification. Existing distance measurements can be categorized into two branches. One is to utilize handmade features for calculating distance, e.g., dynamic time warping, which is limited to exploiting the dynamic information of time series. The other methods make use of the dynamic information by approximating the time series with a generative model, e.g., Fisher kernel. However, previous distance measurements for time series seldom exploit the label information, which is helpful for classification by distance metric learning. In order to attain the benefits of the dynamic information of time series and the label information simultaneously, this paper proposes a multiobjective learning algorithm for both time series approximation and classification, termed multiobjective model-metric (MOMM) learning. In MOMM, a recurrent network is exploited as\u00a0\u2026", "num_citations": "37\n", "authors": ["537"]}
{"title": "An efficient local search heuristic with row weighting for the unicost set covering problem\n", "abstract": " Abstract The Set Covering Problem (SCP) is NP-hard. We propose a new Row Weighting Local Search (RWLS) algorithm for solving the unicost variant of the SCP, ie, USCPs where the costs of all sets are identical. RWLS is a heuristic algorithm that has three major components united in its local search framework:(1) a weighting scheme, which updates the weights of uncovered elements to prevent convergence to local optima,(2) tabu strategies to avoid possible cycles during the search, and (3) a timestamp method to break ties when prioritizing sets. RWLS has been evaluated on a large number of problem instances from the OR-Library and compared with other approaches. It is able to find all the best known solutions (BKS) and improve 14 of them, although requiring a higher computational effort on several instances. RWLS is especially effective on the combinatorial OR-Library instances and can improve the\u00a0\u2026", "num_citations": "37\n", "authors": ["537"]}
{"title": "An improved two archive algorithm for many-objective optimization\n", "abstract": " Multi-Objective Evolutionary Algorithms have been deeply studied in the research community and widely used in the real-world applications. However, the performance of traditional Pareto-based MOEAs, such as NSGA-II and SPEA2, may deteriorate when tackling Many-Objective Problems, which refer to the problems with at least four objectives. The main cause for the degradation lies in that the high-proportional non-dominated solutions severely weaken the differentiation ability of Pareto-dominance. This may lead to stagnation. The Two Archive Algorithm (TAA) uses two archives, namely Convergence Archive (CA) and Diversity Archive (DA) as non-dominated solution repositories, focusing on convergence and diversity respectively. However, as the objective dimension increases, the size of CA increases enormously, leaving little space for DA. Besides, the update rate of CA is quite low, which causes severe\u00a0\u2026", "num_citations": "37\n", "authors": ["537"]}
{"title": "Cooperative coevolutionary algorithm-based model predictive control guaranteeing stability of multirobot formation\n", "abstract": " This paper proposes a novel cooperative coevolutionary algorithm (CCEA)-based distributed model predictive control (MPC) that guarantees asymptotic stability of multiagent systems whose state vectors are coupled and nonseparable in a cost function. While conventional evolutionary algorithm-based MPC approaches cannot guarantee stability, the proposed CCEA-based MPC approach guarantees asymptotic stability regardless of the optimality of the solution that the CCEA-based algorithm generates with a small number of individuals. To guarantee stability, a terminal state constraint is found, and then a repair algorithm is applied to all candidate solutions to meet the constraint. Furthermore, as the proposed CCEA-based algorithm finds the Nash-equilibrium state in a distributed way, robots can quickly move into a desired formation from their locations. A novel dynamic cooperatively coevolving particle swarm\u00a0\u2026", "num_citations": "37\n", "authors": ["537"]}
{"title": "Innovative batik design with an interactive evolutionary art system\n", "abstract": " This paper describes an evolutionary art system, which explores the potential ability of evolutionary computation in Batik design. We investigate the use of Interactive Evolutionary Algorithm (IEA) in our system, with the goal of enhancing user\u2019s creativity to generate innovative Batik-like patterns. We focus mainly on two crucial aspects of the system. First, a new representation is proposed to capture the features in Batik and create innovative patterns through evolutionary processes. Second, an out-breeding mechanism is applied to our system, in order to sustain user\u2019s interest for a longer period. Our system can search a much larger design space than other systems and can avoid being trapped in a local optimum. We describe the system in detail and the methodology we have adopted in the system. Our experimental results have shown that our newly developed system is effective and has great potentials in\u00a0\u2026", "num_citations": "37\n", "authors": ["537"]}
{"title": "What weights work for you? Adapting weights for any Pareto front shape in decomposition-based evolutionary multiobjective optimisation\n", "abstract": " The quality of solution sets generated by decomposition-based evolutionary multi-objective optimisation (EMO) algorithms depends heavily on the consistency between a given problem's Pareto front shape and the specified weights' distribution. A set of weights distributed uniformly in a simplex often leads to a set of well-distributed solutions on a Pareto front with a simplex-like shape, but may fail on other Pareto front shapes. It is an open problem on how to specify a set of appropriate weights without the information of the problem's Pareto front beforehand. In this article, we propose an approach to adapt weights during the evolutionary process (called AdaW). AdaW progressively seeks a suitable distribution of weights for the given problem by elaborating several key parts in weight adaptation\u2014weight generation, weight addition, weight deletion, and weight update frequency. Experimental results have shown\u00a0\u2026", "num_citations": "36\n", "authors": ["537"]}
{"title": "A multi-agent evolutionary algorithm for software module clustering problems\n", "abstract": " The aim of software module clustering problems (SMCPs) is to automatically find a good quality clustering of software modules based on relationships among modules. In this paper, we propose a multi-agent evolutionary algorithm to solve this problem, labeled as MAEA-SMCPs. With the intrinsic properties of SMCPs in mind, three evolutionary operators are designed for agents to realize the purpose of competition, cooperation, and self-learning. In the experiments, practical problems are used to validate the performance of MAEA-SMCPs. The results show that MAEA-SMCPs can find clusters with high quality and small deviations. The comparison results also show that MAEA-SMCPs outperforms two existing multi-objective algorithms, namely MCA and ECA, and two existing single-objective algorithms, namely GGA and GNE, in terms of MQ.", "num_citations": "36\n", "authors": ["537"]}
{"title": "A scalable approach to capacitated arc routing problems based on hierarchical decomposition\n", "abstract": " The capacitated arc routing problem (CARP) is a challenging optimization problem with lots of applications in the real world. Numerous approaches have been proposed to tackle this problem. Most of these methods, albeit showing good performance on CARP instances of small and median sizes, do not scale well to large-scale CARPs, e.g., taking at least a few hours to achieve a satisfactory solution on a CARP instance with thousands of tasks. In this paper, an efficient and scalable approach is proposed for CARPs. The key idea of the proposed approach is to hierarchically decompose the tasks involved in a CARP instance into subgroups and solve the induced subproblems recursively. The output of the subproblems at the lower layer in the hierarchy is treated as virtual tasks and new subproblems are formulated based on these virtual tasks using clustering techniques. By this means, the number of tasks (or\u00a0\u2026", "num_citations": "36\n", "authors": ["537"]}
{"title": "Relationship between generalization and diversity in coevolutionary learning\n", "abstract": " Games have long played an important role in the development and understanding of coevolutionary learning systems. In particular, the search process in coevolutionary learning is guided by strategic interactions between solutions in the population, which can be naturally framed as game playing. We study two important issues in coevolutionary learning - generalization performance and diversity - using games. The first one is concerned with the coevolutionary learning of strategies with high generalization performance, that is, strategies that can outperform against a large number of test strategies (opponents) that may not have been seen during coevolution. The second one is concerned with diversity levels in the population that may lead to the search of strategies with poor generalization performance. It is not known if there is a relationship between generalization and diversity in coevolutionary learning. This\u00a0\u2026", "num_citations": "36\n", "authors": ["537"]}
{"title": "Diversity exploration and negative correlation learning on imbalanced data sets\n", "abstract": " Class imbalance learning is an important research area in machine learning, where instances in some classes heavily outnumber the instances in other classes. This unbalanced class distribution causes performance degradation. Some ensemble solutions have been proposed for the class imbalance problem. Diversity has been proved to be an influential aspect in ensemble learning, which describes the degree of different decisions made by classifiers. However, none of those proposed solutions explore the impact of diversity on imbalanced data sets. In addition, most of them are based on re-sampling techniques to rebalance class distribution, and over-sampling usually causes overfitting (high generalisation error). This paper investigates if diversity can relieve this problem by using negative correlation learning (NCL) model, which encourages diversity explicitly by adding a penalty term in the error function of\u00a0\u2026", "num_citations": "36\n", "authors": ["537"]}
{"title": "Hybrid evolutionary approaches to terminal assignment in communications networks\n", "abstract": " Terminal assignment is an NP-hard problem in communications networks. It involves assigning a set of terminals to a set of concentrators with a cost for each assignment. The objective is to minimize the total cost of the assignment and the number of concentrators used. A number of heuristic algorithms, including genetic algorithms, have been proposed for solving this problem. This chapter studies several evolutionary and hybrid approaches to terminal assignment. Firstly, a novel chromosome representation scheme based on concentrators is proposed. This representation compares favourably against the existing terminal-based representation, which scales poorly for large problems. Extensive experiments have been carried out. The results show that our evolutionary algorithms using the concentrator-based representation outperform significantly existing genetic algorithms using the terminal-based\u00a0\u2026", "num_citations": "36\n", "authors": ["537"]}
{"title": "Evolving neural network ensembles by minimization of mutual information\n", "abstract": " Learning and evolution are two fundamental forms of adaptation. There has been a great interest in combining learning and evolution with neural networks in recent years. This paper presents a hybrid learning system for learning and designing of neural network ensembles based on negative correlation learning and evolutionary learning. The idea of the hybrid learning system is to regard the population of neural networks as an ensemble, and the evolutionary process as the design of neural network ensembles. Two fitness sharing techniques have been used in the evolutionary process. One is based on the covering set. The other is to use the concept of mutual information. The effectiveness of such hybrid learning approach was tested on two real-world problems.", "num_citations": "36\n", "authors": ["537"]}
{"title": "Neural network ensembles and their application to traffic flow prediction in telecommunications networks\n", "abstract": " It is well-known that large neural networks with many unshared weights can be very difficult to train. A neural network ensemble consisting of a number of individual neural networks usually performs better than a complex monolithic neural network. One of the motivations behind neural network ensembles is the divide-and-conquer strategy, where a complex problem is decomposed into different components each of which is tackled by an individual neural network. A promising algorithm for training neural network ensembles is the negative correlation learning algorithm which penalizes positive correlations among individual networks by introducing a penalty term in the error function. A penalty coefficient is used to balance the minimization of the error and the minimization of the correlation. It is often very difficult to select an optimal penalty coefficient for a given problem because as yet there is no systematic method\u00a0\u2026", "num_citations": "36\n", "authors": ["537"]}
{"title": "EPNet for chaotic time-series prediction\n", "abstract": " EPNet is an evolutionary system for automatic design of artificial neural networks (ANNs) [1, 2, 3]. Unlike most previous methods on evolving ANNs, EPNet puts its emphasis on evolving ANN'S behaviours rather than circuitry. The parsimony of evolved ANNs is encouraged by the sequential application of architectural mutations. In this paper, EP Net is applied to a couple of chaotic time-series prediction problems (i.e., the Mackey-Glass differential equation and the logistic map). The experimental results show that EPNet can produce very compact ANNs with good prediction ability in comparison with other algorithms.", "num_citations": "36\n", "authors": ["537"]}
{"title": "Static, dynamic, and adaptive heterogeneity in distributed smart camera networks\n", "abstract": " We study heterogeneity among nodes in self-organizing smart camera networks, which use strategies based on social and economic knowledge to target communication activity efficiently. We compare homogeneous configurations, when cameras use the same strategy, with heterogeneous configurations, when cameras use different strategies. Our first contribution is to establish that static heterogeneity leads to new outcomes that are more efficient than those possible with homogeneity. Next, two forms of dynamic heterogeneity are investigated: nonadaptive mixed strategies and adaptive strategies, which learn online. Our second contribution is to show that mixed strategies offer Pareto efficiency consistently comparable with the most efficient static heterogeneous configurations. Since the particular configuration required for high Pareto efficiency in a scenario will not be known in advance, our third contribution is\u00a0\u2026", "num_citations": "35\n", "authors": ["537"]}
{"title": "Classification-assisted differential evolution for computationally expensive problems\n", "abstract": " Like most Evolutionary Algorithms (EAs), Differential Evolution (DE) usually requires a large number of fitness evaluations to obtain a sufficiently good solution. This is an obstacle for applying DE to computationally expensive problems. Many previous studies have been carried out to develop surrogate assisted approaches for EAs to reduce the number of real fitness evaluations. Existing methods typically build surrogates with either regression or ranking methods. However, due to the pairwise selection scheme of DE, it is more appropriate to formulate the construction of surrogate as a classification problem rather than a regression or ranking problem. Hence, we propose a classification-assisted DE in this paper. Experimental studies showed that the classification-assisted DE has great potential when compared to the DE that uses regression or ranking techniques to build surrogates.", "num_citations": "35\n", "authors": ["537"]}
{"title": "Robust solution of salting route optimisation using evolutionary algorithms\n", "abstract": " The precautionary salting of the road network is an important maintenance issue for countries with a marginal winter climate. On many nights, not all the road network will require treatment as the local geography will mean some road sections are warmer than others. Hence, there is a logic to optimising salting routes based on known road surface temperature distributions. In this paper, a robust solution of salting route optimisation using a training dataset of daily predicted temperature distributions is proposed. Evolutionary algorithms are used to produce salting routes which group together the colder sections of the road network. Financial savings can then be made by not treating the warmer routes on the more marginal of nights. Experimental results on real data also reveal that the proposed methodology reduced total distance traveled on the new routes by around 10 conventional salting routes.", "num_citations": "35\n", "authors": ["537"]}
{"title": "Towards designing neural network ensembles by evolution\n", "abstract": " This paper proposes a co-evolutionary learning system, i.e., CELS, to design neural network (NN) ensembles. CELS addresses the issue of automatic determination of the number of individual NNs in an ensemble and the exploitation of the interaction between individual NN design and combination. The idea of CELS is to encourage different individual NNs in the ensemble to learn different parts or aspects of the training data so that the ensemble can learn the whole training data better. The cooperation and specialisation among different individual NNs are considered during the individual NN design. This provides an opportunity for different NNs to interact with each other and to specialise. Experiments on two real-world problems demonstrate that CELS can produce NN ensembles with good generalisation ability.", "num_citations": "35\n", "authors": ["537"]}
{"title": "Robust twin boosting for feature selection from high-dimensional omics data with label noise\n", "abstract": " Omics data such as microarray transcriptomic and mass spectrometry proteomic data are typically characterized by high dimensionality and relatively small sample sizes. In order to discover biomarkers for diagnosis and prognosis from omics data, feature selection has become an indispensable step to find a parsimonious set of informative features. However, many previous studies report considerable label noise in omics data, which will lead to unreliable inferences to select uninformative features. Yet, to the best of our knowledge, very few feature selection methods are proposed to address this problem. This paper proposes a novel ensemble feature selection algorithm, robust twin boosting feature selection (RTBFS), which is robust to label noise in omics data. The algorithm has been validated on an omics feature selection test bed and seven real-world heterogeneous omics datasets, of which some are known\u00a0\u2026", "num_citations": "34\n", "authors": ["537"]}
{"title": "A benchmark generator for dynamic permutation-encoded problems\n", "abstract": " Several general benchmark generators (BGs) are available for the dynamic continuous optimization domain, in which generators use functions with adjustable parameters to simulate shifting landscapes. In the combinatorial domain the work is still on early stages. Many attempts of dynamic BGs are limited to the range of algorithms and combinatorial optimization problems (COPs) they are compatible with, and usually the optimum is not known during the dynamic changes of the environment. In this paper, we propose a BG that can address the aforementioned limitations of existing BGs. The proposed generator allows full control over some important aspects of the dynamics, in which several test environments with different properties can be generated where the optimum is known, without re-optimization.", "num_citations": "34\n", "authors": ["537"]}
{"title": "When is an estimation of distribution algorithm better than an evolutionary algorithm?\n", "abstract": " Despite the wide-spread popularity of estimation of distribution algorithms (EDAs), there has been no theoretical proof that there exist optimisation problems where EDAs perform significantly better than traditional evolutionary algorithms. Here, it is proved rigorously that on a problem called SUBSTRING, a simple EDA called univariate marginal distribution algorithm (UMDA) is efficient, whereas the (1+1) EA is highly inefficient. Such studies are essential in gaining insight into fundamental research issues, i.e., what problem characteristics make an EDA or EA efficient, under what conditions an EDA is expected to outperform an EA, and what key factors are in an EDA that make it efficient or inefficient.", "num_citations": "34\n", "authors": ["537"]}
{"title": "Improved memetic algorithm for capacitated arc routing problem\n", "abstract": " Capacitated arc routing problem (CARP) has attracted much interest because of its wide applications in the real world. Recently, a memetic algorithm proposed by Lacomme et al. (LMA) has been demonstrated to be a competitive approach to CARP. The crossover operation of LMA is carried out based on an implicit representation scheme, while it conducts local search on the basis of an explicit representation scheme. Hence, the search process of LMA involves frequent switch between the spaces defined by the two representation schemes. However, a good solution in one space is not necessarily good in the other. In this paper, we show that the local search process of LMA might be ineffective due to such reason, and suggest adopting a more careful way to coordinate the local search. As a result, two new local search methods are proposed, which resulted in two improved LMA (ILMA) algorithms. Experimental\u00a0\u2026", "num_citations": "34\n", "authors": ["537"]}
{"title": "Heuristic evolution with genetic programming for traveling thief problem\n", "abstract": " In many real-world applications, one needs to deal with a large multi-silo problem with interdependent silos. In order to investigate the interdependency between silos (sub-problems), the Traveling Thief Problem (TTP) was designed as a benchmark problem. TTP is a combination of two well-known sub-problems, Traveling Salesman Problem (TSP) and Knapsack Problem (KP). Although each sub-problem has been intensively investigated, the interdependent combination has been demonstrated to be challenging, and cannot be solved by simply solving the sub-problems separately. The Two-Stage Memetic Algorithm (TSMA) is an effective approach that has decent solution quality and scalability, which consists of a tour improvement stage and an item picking stage. Unlike the traditional TSP local search operators adopted in the former stage, the heuristic for the latter stage is rather intuitive. To further investigate\u00a0\u2026", "num_citations": "33\n", "authors": ["537"]}
{"title": "Negative correlation ensemble learning for ordinal regression\n", "abstract": " In this paper, two neural network threshold ensemble models are proposed for ordinal regression problems. For the first ensemble method, the thresholds are fixed a priori and are not modified during training. The second one considers the thresholds of each member of the ensemble as free parameters, allowing their modification during the training process. This is achieved through a reformulation of these tunable thresholds, which avoids the constraints they must fulfill for the ordinal regression problem. During training, diversity exists in different projections generated by each member is taken into account for the parameter updating. This diversity is promoted in an explicit way using a diversity-encouraging error function, extending the well-known negative correlation learning framework to the area of ordinal regression, and inheriting many of its good properties. Experimental results demonstrate that the proposed\u00a0\u2026", "num_citations": "33\n", "authors": ["537"]}
{"title": "Diversity guided evolutionary programming: a novel approach for continuous optimization\n", "abstract": " Avoiding premature convergence to local optima and rapid convergence towards global optima has been the major concern with evolutionary systems research. In order to avoid premature convergence, sufficient amount of genetic diversity within the evolving population is considered necessary. Several studies have focused to devise techniques to control and preserve population diversity throughout the evolution. Since mutation is the major operator in many evolutionary systems, such as evolutionary programming and evolutionary strategies, a significant amount of research has also been done for the elegant control and adaptation of the mutation step size that is proper for traversing across the locally optimum points and reach for the global optima. This paper introduces Diversity Guided Evolutionary Programming, a novel approach to combine the best of both these research directions. This scheme\u00a0\u2026", "num_citations": "33\n", "authors": ["537"]}
{"title": "Self-adapting payoff matrices in repeated interactions\n", "abstract": " Traditional iterated prisoner's dilemma (IPD) assumed a fixed payoff matrix for all players, which may not be realistic because not all players are the same in the real-world. This paper introduces a novel co-evolutionary framework where each strategy has its own self-adaptive payoff matrix. This framework is generic to any simultaneous two-player repeated encounter game. Here, each strategy has a set of behavioral responses based on previous moves, and an adaptable payoff matrix based on reinforcement feedback from game interactions that is specified by update rules. We study how different update rules affect the adaptation of initially random payoff matrices, and how this adaptation in turn affects the learning of strategy behaviors", "num_citations": "33\n", "authors": ["537"]}
{"title": "Dual population-based incremental learning for problem optimization in dynamic environments\n", "abstract": " In recent years there is a growing interest in the research of evolutionary algorithms for dynamic optimization problems since real world problems are usually dynamic, which presents serious challenges to traditional evolutionary algorithms. In this paper, we investigate the application of Population-Based Incremental Learning (PBIL) algorithms, a class of evolutionary algorithms, for problem optimization under dynamic environments. Inspired by the complementarity mechanism in nature, we propose a Dual PBIL that operates on two probability vectors that are dual to each other with respect to the central point in the search space. Using a dynamic problem generating technique we generate a series of dynamic knapsack problems from a randomly generated stationary knapsack problem and carry out experimental study comparing the performance of investigated PBILs and one traditional genetic algorithm. Experimental results show that the introduction of dualism into PBIL improves its adaptability under dynamic environments, especially when the environment is subject to significant changes in the sense of genotype space.", "num_citations": "33\n", "authors": ["537"]}
{"title": "A new memetic algorithm with fitness approximation for the defect-tolerant logic mapping in crossbar-based nanoarchitectures\n", "abstract": " The defect-tolerant logic mapping (DTLM), which has been proved to be an NP-complete combinatorial search problem, is a key step for logic implementation in emerging crossbar-based nano-architectures. However, no practically satisfactory solution has been suggested for the DTLM until now. In this paper, the problem of DTLM is first modeled as a combinatorial optimization problem through the introduction of maximum-bipartite-matching. Then, a new memetic algorithm with fitness approximation (MA/FA) is proposed to solve the optimization problem efficiently. In MA/FA, a new greedy reassignment local search operator, capable of utilizing the domain knowledge and information from problem instances, is designed to help the algorithm find optimal logic mapping with consumption of relatively lower computational resources. A fitness approximation method is adopted to reduce the time consumption of fitness\u00a0\u2026", "num_citations": "32\n", "authors": ["537"]}
{"title": "Addressing the EU sovereign ratings using an ordinal regression approach\n", "abstract": " The current European debt crisis has drawn considerable attention to credit-rating agencies' news about sovereign ratings. From a technical point of view, credit rating constitutes a typical ordinal regression problem because credit-rating agencies generally present a scale of risk composed of several categories. This fact motivated the use of an ordinal regression approach to address the problem of sovereign credit rating in this paper. Therefore, the ranking of different classes will be taken into account for the design of the classifier. To do so, a novel model is introduced in order to replicate sovereign rating, based on the negative correlation learning framework. The methodology is fully described in this paper and applied to the classification of the 27 European countries' sovereign rating during the 2007-2010 period based on Standard and Poor's reports. The proposed technique seems to be competitive and robust\u00a0\u2026", "num_citations": "32\n", "authors": ["537"]}
{"title": "Crossover can be constructive when computing unique input\u2013output sequences\n", "abstract": " Unique input\u2013output (UIO) sequences have important applications in conformance testing of finite state machines (FSMs). Previous experimental and theoretical research has shown that evolutionary algorithms (EAs) can compute UIOs efficiently on many FSM instance classes, but fail on others. However, it has been unclear how and to what degree EA parameter settings influence the runtime on the UIO problem. This paper investigates the choice of acceptance criterion in the (1\u00a0+\u00a01) EA and the use of crossover in the  Steady State Genetic Algorithm. It is rigorously proved that changing these parameters can reduce the runtime from exponential to polynomial for some instance classes of the UIO problem.", "num_citations": "32\n", "authors": ["537"]}
{"title": "The dynamic knapsack problem revisited: A new benchmark problem for dynamic combinatorial optimisation\n", "abstract": " In this paper we propose a new benchmark problem for dynamic combinatorial optimisation. Unlike most previous benchmarks, we focus primarily on the underlying dynamics of the problem and consider the distances between successive global optima only as an emergent property of those dynamics. The benchmark problem is based upon a class of difficult instances of the 0/1-knapsack problem that are generated using a small set of real-valued parameters. These parameters are subsequently varied over time by some set of difference equations: It is possible to model approximately different types of transitions by controlling the shape and degree of interactions between the trajectories of the parameters. We conduct a set of experiments to highlight some of the intrinsic properties of this benchmark problem and find it not only to be challenging but also more representative of real-world scenarios than\u00a0\u2026", "num_citations": "32\n", "authors": ["537"]}
{"title": "Direction matters in high-dimensional optimisation\n", "abstract": " Directional biases are evident in many benchmarking problems for real-valued global optimisation, as well as many of the evolutionary and allied algorithms that have been proposed for solving them. It has been shown that directional biases make some kinds of problems easier to solve for similarly biased algorithms, which can give a misleading view of algorithm performance. In this paper we study the effects of directional bias for high- dimensional optimisation problems. We show that the impact of directional bias is magnified as dimension increases, and can in some cases lead to differences in performance of many orders of magnitude. We present a new version of the classical evolutionary programming algorithm, which we call unbiased evolutionary programming (UEP), and show that it has markedly improved performance for high-dimensional optimisation.", "num_citations": "32\n", "authors": ["537"]}
{"title": "Evolutionary algorithms and the vertex cover problem\n", "abstract": " Experimental results have suggested that evolutionary algorithms may produce higher quality solutions for instances of vertex cover than a very well known approximation algorithm for this NP-complete problem. A theoretical analysis of the expected runtime of the (1+1)-EA on a well studied instance class confirms such a conjecture for the considered class. Furthermore, a class for which the (1+1)-EA takes exponential optimization time is examined. Nevertheless, given polynomial time, the evolutionary algorithm still produces a better solution than the approximation algorithm. Recently, the existence of an instance class has been proved for which the (1+1)-EA produces poor approximate solutions, given polynomial time. Here it is pointed out that, by using multiple runs, the (1+1)-EA finds the optimal cover of each instance of the considered graph class in polynomial time.", "num_citations": "32\n", "authors": ["537"]}
{"title": "Does extra genetic diversity maintain escalation in a co-evolutionary arms race\n", "abstract": " In evolutionary computation (EC), genetic diversity (or its absence) gets the credit (or the blame) for a multitude of effects\u2014and so mutation operators, population initialization, and even pseudo-random number generators, all get probed and prodded to improve genetic diversity. This paper demonstrates how extra initial diversity can appear to cause improvements in the performance of coevolutionary learning, but the true cause is in unforeseen effects of the problem-specific representation. The learning task considered in this paper is a variation on the game of Iterated Prisoner\u2019s Dilemma (IPD): here players have a fine-grained range of intermediate choices between full cooperation and full defection.", "num_citations": "32\n", "authors": ["537"]}
{"title": "Cooperative co-evolutionary module identification with application to cancer disease module discovery\n", "abstract": " Module identification or community detection in complex networks has become increasingly important in many scientific fields because it provides insight into the relationship and interaction between network function and topology. In recent years, module identification algorithms based on stochastic optimization algorithms such as evolutionary algorithms have been demonstrated to be superior to other algorithms on small- to medium-scale networks. However, the scalability and resolution limit (RL) problems of these module identification algorithms have not been fully addressed, which impeded their application to real-world networks. This paper proposes a novel module identification algorithm called cooperative co-evolutionary module identification to address these two problems. The proposed algorithm employs a cooperative co-evolutionary framework to handle large-scale networks. We also incorporate a\u00a0\u2026", "num_citations": "31\n", "authors": ["537"]}
{"title": "An efficient evolutionary approach to parameter identification in a building thermal model\n", "abstract": " Thermal models of buildings are often used to identify energy savings within a building. Given that a significant proportion of that energy is typically used to maintain building temperature, establishing the optimal control of the buildings thermal system is important. This requires an understanding of the thermal dynamics of the building, which is often obtained from physical thermal models. However, these models require detailed building parameters to be specified and these can often be difficult to determine. In this paper, we propose an evolutionary approach to parameter identification for thermal models that are formulated as an optimization task. A state-of-the-art evolutionary algorithm, i.e., SaNSDE+, has been developed. A fitness function is defined, which quantifies the difference between the energy-consumption time-series data that are derived from the identified parameters and that given by simulation with a\u00a0\u2026", "num_citations": "31\n", "authors": ["537"]}
{"title": "An experimental study of hybridizing cultural algorithms and local search\n", "abstract": " In this paper the performance of the Cultural Algorithms-Iterated Local Search (CA-ILS), a new continuous optimization algorithm, is empirically studied on multimodal test functions proposed in the Special Session on Real-Parameter Optimization of the 2005 Congress on Evolutionary Computation. It is compared with state-of-the-art methods attending the Session to find out whether the algorithm is effective in solving difficult problems. The test results show that CA-ILS may be a competitive method, at least in the tested problems. The results also reveal the classes of problems where CA-ILS can work well and/or not well.", "num_citations": "31\n", "authors": ["537"]}
{"title": "Parallel Problem Solving from Nature-PPSN VI: 6th International Conference, Paris, France, September 18-20 2000 Proceedings\n", "abstract": " We are proud to introduce the proceedings of the Sixth International Conference on Parallel Problem Solving from Nature, PPSN VI, held in Paris, Prance, on 18-20 September 2000. PPSN VI was organized in association with the Genetic and Evolutionary Computing Conference (GECCO'2000) and the Congress on Evolutionary Computation (CEC'2000), reflecting the beneficial interaction between the conference activities in Europe and in the USA in the field of natural computation. Starting in 1990 in Dortmund, Germany (Proceedings, LNCS vol. 496, Sprin ger, 1991), this biannual meeting has been held in Brussels, Belgium (Procee dings, Elsevier, 1992), Jerusalem, Israel (Proceedings, LNCS vol. 866, Springer, 1994), Berlin, Germany (Proceedings, LNCS vol. 1141, Springer, 1996), and Amsterdam, The Netherlands (Proceedings, LNCS vol. 1498, Springer, 1998), where it was decided that Paris would be the location of the 2000 conference with Marc Schoenauer as the general chair. The scientific content of the PPSN conference focuses on problem solving pa radigms gleaned from a natural models. Characteristic for Natural Computing is the metaphorical use of concepts, principles and mechanisms underlying natural systems, such as evolutionary processes involving mutation, recombination, and selection in natural evolution, annealing or punctuated equilibrium processes of many-particle systems in physics, growth processes in nature and economics, collective intelligence in biology, DNA-based computing in molecular chemistry, and multi-cellular behavioral processes in neural and immune networks.", "num_citations": "31\n", "authors": ["537"]}
{"title": "Erratum to: Drift analysis and average time complexity of evolutionary algorithms:[Artificial Intelligence 127 (2001) 57\u201385]\n", "abstract": " The proof of Theorem 6 in the paper by J. He and X. Yao [Artificial Intelligence 127 (1)(2001) 57\u201385] contains a mistake, although the theorem is correct [S. Droste et al., Theoret. Comput. Sci. 276 (2002) 51\u201381]. This note gives a revised proof and theorem. It turns out that the revised theorem is more general than the original one given an evolutionary algorithm with mutation probability pm= 1/(2n), using the same proof method as given by J. He and X. Yao [Artificial Intelligence 127 (1)(2001) 57\u201385].", "num_citations": "31\n", "authors": ["537"]}
{"title": "Evolutionary artificial neural networks that learn and generalise well\n", "abstract": " Evolutionary arti cial neural networks (EANNs) refer to a special class of arti cial neural networks (ANNs) in which evolution is another fundamental form of adaptation in addition to learning. The evolution in EANNs is often simulated by genetic algorithms (GAs), evolutionary programming (EP), or other evolutionary algorithms. This paper describes an EP-based EANNs which learn both their weights and architectures through the combination of a hybrid learning algorithm and the EP algorithm. A nonlinear ranking scheme and ve mutation operators are used in our EP. These ve mutation operators are applied sequentially and selectively to each individual in a population. Such sequential application encourages the evolution of smaller ANNs with fewer hidden nodes and connections. We have tested our EP-based EANNs on the parity problem of various sizes. Very good results have been achieved. For example, a three hidden node feed-forward ANN can be evolved for the 9-parity problem. In order to improve the generalisation capability of our EP-based EANNs, we have introduced two validation sets in the combined evolution and learning process. Such an approach can improve the generalisation ability of our EP-based EANNs signi cantly. Our experimental study with a credit card problem has con rmed that EP-based EANNs can generalise well, at least for the problem concerned. In fact, it produces one of the best results we are aware of.", "num_citations": "31\n", "authors": ["537"]}
{"title": "Ensemble of classifiers based on multiobjective genetic sampling for imbalanced data\n", "abstract": " Imbalanced datasets may negatively impact the predictive performance of most classical classification algorithms. This problem, commonly found in real-world, is known in machine learning domain as imbalanced learning. Most techniques proposed to deal with imbalanced learning have been proposed and applied only to binary classification. When applied to multiclass tasks, their efficiency usually decreases and negative side effects may appear. This paper addresses these limitations by presenting a novel adaptive approach, E-MOSAIC (Ensemble of Classifiers based on MultiObjective Genetic Sampling for Imbalanced Classification). E-MOSAIC evolves a selection of samples extracted from training dataset, which are treated as individuals of a MOEA. The multiobjective process looks for the best combinations of instances capable of producing classifiers with high predictive accuracy in all classes. E-MOSAIC\u00a0\u2026", "num_citations": "30\n", "authors": ["537"]}
{"title": "Efficient user involvement in semiautomatic ontology matching\n", "abstract": " Semiautomatic ontology matching poses a new challenge of how to implement an efficient user interactions. To address this challenge, we answer three questions in this paper: (1) when should we activate the interacting process; (2) which correspondences should be presented for user validation; and (3) how to make use of the validating results. In particular, we present an interactive compact memetic algorithm (ICMA) based semiautomatic ontology matching technique to: (1) determine the timing of getting a user involved; (2) determine the problematic correspondences; and (3) propagate the user validating results. The experimental results show that three proposed strategies can effectively reduce the user\u2019s workload and the algorithm\u2019s runtime, increase the alignment\u2019s quality, and the performance of ICMA outperforms the state-of-the-art semiautomatic ontology matching techniques.", "num_citations": "30\n", "authors": ["537"]}
{"title": "Interactive decomposition multiobjective optimization via progressively learned value functions\n", "abstract": " Decomposition has become an increasingly popular technique for evolutionary multiobjective optimization (EMO). A decomposition-based EMO algorithm is usually designed to approximate a whole Pareto-optimal front (PF). However, in practice, a decision maker (DM) might only be concerned in her/his region of interest (ROI), i.e., a part of the PF. Solutions outside that might be useless or even noisy to the decision-making procedure. Furthermore, there is no guarantee that the preferred solutions will be found when many-objective problems. This paper develops an interactive framework for the decomposition-based EMO algorithm to lead a DM to the preferred solutions of her/his choice. It consists of three modules, i.e., consultation, preference elicitation, and optimization. Specifically, after every several generations, the DM is asked to score a few candidate solutions in a consultation session. Thereafter, an\u00a0\u2026", "num_citations": "30\n", "authors": ["537"]}
{"title": "Covariance matrix repairing in Gaussian based EDAs\n", "abstract": " Gaussian models are widely adopted in continuous Estimation of Distribution Algorithms (EDAs). In this paper, we analyze continuous EDAs and show that they don't always work because of computation error: covariance matrix of Gaussian model can be ill-posed and Gaussian based EDAs using full covariance matrix will fail under specific conditions. It is a universal problem that all existing Gaussian based EDAs using full covariance matrix suffer from. Through theoretical analysis with examples of simulated data and experiments, we show that the ill-posed covariance matrix strongly affects those EDAs. This paper proposes a Covariance Matrix Repairing (CMR) method to fix ill-posed covariance matrix. CMR significantly improves the robustness of EDAs. Even some EDA's performance that was previously thought inefficient can be improved surprisingly with the help of CMR. CMR can also guarantee those EDAs\u00a0\u2026", "num_citations": "30\n", "authors": ["537"]}
{"title": "On the effectiveness of negative correlation learning\n", "abstract": " Neural network ensembles are well accepted as a route to combining a group of weaker learning systems in order to make a composite, stronger one. It has been shown that low correlation of errors (\" diverse members\") will give rise to better ensemble performance. Most techniques for creating diverse ensemble members indirectly aect the learning trajectories, and are built upon heuristics and intuition. Other techniques directly influence the learning trajectory, by altering the training algorithm itself. For a particular direct technique, Negative Correlation Learning, we demonstrate the effectiveness of the algorithm in reducing correlations, as it relates to the size and complexity of the ensemble. We oer some possible research avenues on this class of ensemble methods. This work is a first step towards understanding the effectiveness of explicitly incorporating diversity measures in error functions during ensemble training.", "num_citations": "30\n", "authors": ["537"]}
{"title": "Interactive ontology matching based on partial reference alignment\n", "abstract": " The technique that enables the user and the automatic ontology matching tool to cooperate with each other to generate high-quality alignments in a reasonable amount of time is referred to as the interactive ontology matching. Interactive ontology matching poses a new challenge in a way of how to efficiently leverage user validation to improve the ontology alignment. To address this challenge, this paper presents an innovative interactive ontology matching technique based on Partial Reference Alignment (PRA) to better balance between the large workload posed on users and the demand of improving the quality of ontology alignment. In particular, a PRA-based Interactive Compact Hybrid Evolutionary Algorithm (ICHEA) is proposed to reduce user workload, by adaptively determining the timing of involving users, showing them the most problematic mappings, and helping them to deal with multiple conflicting\u00a0\u2026", "num_citations": "29\n", "authors": ["537"]}
{"title": "On the effectiveness of sampling for evolutionary optimization in noisy environments\n", "abstract": " In real-world optimization tasks, the objective (ie, fitness) function evaluation is often disturbed by noise due to a wide range of uncertainties. Evolutionary algorithms are often employed in noisy optimization, where reducing the negative effect of noise is a crucial issue. Sampling is a popular strategy for dealing with noise: to estimate the fitness of a solution, it evaluates the fitness multiple () times independently and then uses the sample average to approximate the true fitness. Obviously, sampling can make the fitness estimation closer to the true value, but also increases the estimation cost. Previous studies mainly focused on empirical analysis and design of efficient sampling strategies, while the impact of sampling is unclear from a theoretical viewpoint. In this article, we show that sampling can speed up noisy evolutionary optimization exponentially via rigorous running time analysis. For the (1 1)-EA solving the\u00a0\u2026", "num_citations": "29\n", "authors": ["537"]}
{"title": "Camsim: A distributed smart camera network simulator\n", "abstract": " Smart cameras allow pre-processing of video data on the camera instead of sending it to a remote server for further analysis. Having a network of smart cameras allows various vision tasks to be processed in a distributed fashion. While cameras may have different tasks, we concentrate on distributed tracking in smart camera networks. This application introduces various highly interesting problems. Firstly, how can conflicting goals be satisfied such as cameras in the network try to track objects while also trying to keep communication overhead low? Secondly, how can cameras in the network self adapt in response to the behavior of objects and changes in scenarios, to ensure continued efficient performance? Thirdly, how can cameras organise themselves to improve the overall network's performance and efficiency? This paper presents a simulation environment, called CamSim, allowing distributed self-adaptation\u00a0\u2026", "num_citations": "29\n", "authors": ["537"]}
{"title": "Assignment of cells to switches in a cellular mobile network using a hybrid Hopfield network-genetic algorithm approach\n", "abstract": " Handoff and cabling cost management plays a key role in the design of cellular telecommunications networks. The efficient assignment of cells to switches in this type of networks is an NP-complete problem which cannot be solved efficiently unless P\u00a0=\u00a0NP. This paper presents a hybrid Hopfield network-genetic algorithm approach to the cell-to-switches assignment problem, in which a Hopfield network manages the problem's constraints, and a genetic algorithm searches for high quality solutions with the minimum possible cost in terms of handoff and cable displayed. We show, by means of computational experiments, the good performance of our approach to this problem.", "num_citations": "29\n", "authors": ["537"]}
{"title": "A game-theoretic approach for designing mixed mutation strategies\n", "abstract": " Different mutation operators have been proposed in evolutionary programming. However, each operator may be efficient in solving a subset of problems, but will fail in another one. Through a mixture of various mutation operators, it is possible to integrate their advantages together. This paper presents a game-theoretic approach for designing evolutionary programming with a mixed mutation strategy. The approach is applied to design a mixed strategy using Gaussian and Cauchy mutations. The experimental results show the mixed strategy can obtain the same performance as, or even better than the best of pure strategies.", "num_citations": "29\n", "authors": ["537"]}
{"title": "Touchable computing: Computing-inspired bio-detection\n", "abstract": " We propose a new computing-inspired bio-detection framework called touchable computing (TouchComp). Under the rubric of TouchComp, the best solution is the cancer to be detected, the parameter space is the tissue region at high risk of malignancy, and the agents are the nanorobots loaded with contrast medium molecules for tracking purpose. Subsequently, the cancer detection procedure (CDP) can be interpreted from the computational optimization perspective: a population of externally steerable agents (i.e., nanorobots) locate the optimal solution (i.e., cancer) by moving through the parameter space (i.e., tissue under screening), whose landscape (i.e., a prescribed feature of tissue environment) may be altered by these agents but the location of the best solution remains unchanged. One can then infer the landscape by observing the movement of agents by applying the \u201cseeing-is-sensing\u201d principle. The\u00a0\u2026", "num_citations": "28\n", "authors": ["537"]}
{"title": "Regularity model for noisy multiobjective optimization\n", "abstract": " Regularity models have been used in dealing with noise-free multiobjective optimization problems. This paper studies the behavior of a regularity model in noisy environments and argues that it is very suitable for noisy multiobjective optimization. We propose to embed the regularity model in an existing multiobjective evolutionary algorithm for tackling noises. The proposed algorithm works well in terms of both convergence and diversity. In our experimental studies, we have compared several state-of-the-art of algorithms with our proposed algorithm on benchmark problems with different levels of noises. The experimental results showed the effectiveness of the regularity model on noisy problems, but a degenerated performance on some noisy-free problems.", "num_citations": "28\n", "authors": ["537"]}
{"title": "What are dynamic optimization problems?\n", "abstract": " Dynamic Optimization Problems (DOPs) have been widely studied using Evolutionary Algorithms (EAs). Yet, a clear and rigorous definition of DOPs is lacking in the Evolutionary Dynamic Optimization (EDO) community. In this paper, we propose a unified definition of DOPs based on the idea of multiple-decision-making discussed in the Reinforcement Learning (RL) community. We draw a connection between EDO and RL by arguing that both of them are studying DOPs according to our definition of DOPs. We point out that existing EDO or RL research has been mainly focused on some types of DOPs. A conceptualized benchmark problem, which is aimed at the systematic study of various DOPs, is then developed. Some interesting experimental studies on the benchmark reveal that EDO and RL methods are specialized in certain types of DOPs and more importantly new algorithms for DOPs can be developed by\u00a0\u2026", "num_citations": "28\n", "authors": ["537"]}
{"title": "Community detection using cooperative co-evolutionary differential evolution\n", "abstract": " In many scientific fields, from biology to sociology, community detection in complex networks has become increasingly important. This paper, for the first time, introduces Cooperative Co-evolution framework for detecting communities in complex networks. A Bias Grouping scheme is proposed to dynamically decompose a complex network into smaller subnetworks to handle large-scale networks. We adopt Differential Evolution (DE) to optimize network modularity to search for an optimal partition of a network. We also design a novel mutation operator specifically for community detection. The resulting algorithm, Cooperative Co-evolutionary DE based Community Detection (CCDECD) is evaluated on 5 small to large scale real-world social and biological networks. Experimental results show that CCDECD has very competitive performance compared with other state-of-the-art community detection algorithms.", "num_citations": "28\n", "authors": ["537"]}
{"title": "The role of degenerate robustness in the evolvability of multi-agent systems in dynamic environments\n", "abstract": " It has been proposed that degeneracy plays a fundamental role in biological evolution by facilitating robustness and adaptation within heterogeneous and time-variant environments. Degeneracy occurs whenever structurally distinct agents display similar functions within some contexts but unique functions in others. In order to test the broader applicability of this hypothesis, especially to the field of evolutionary dynamic optimisation, we evolve multi-agent systems (MAS) in time-variant environments and investigate how degeneracy amongst agents influences the system\u2019s robustness and evolvability. We find that degeneracy freely emerges within our framework, leading to MAS architectures that are robust towards a set of similar environments and quickly adaptable to large environmental changes. Detailed supplementary experiments, aimed particularly at the scaling behaviour of these results, demonstrate\u00a0\u2026", "num_citations": "28\n", "authors": ["537"]}
{"title": "Evolutionary design of digital filters with application to subband coding and data transmission\n", "abstract": " In this paper, two evolutionary programming (EP) algorithms (classical EP and fast EP) are applied to design prototype lowpass Finite Impulse Response filters for use in a modulated filterbank. The chosen filter design technique is based on frequency-sampling (where the Fourier transform magnitudes of the filter are the objective variables). Design is simplified by constraining most of these values, leaving only a small number of values in the filter transition band to be optimized. The EP algorithms were used to determine the optimum values for this subset of values. Since there is an additional monotonic constraint on the transition band values, a modification to the EP algorithms was developed called variable limits evolutionary programming. Results indicate that a) both EP algorithms were insensitive to initial conditions, and reliably found the minimum values of the chosen objective functions, and b) the designed\u00a0\u2026", "num_citations": "28\n", "authors": ["537"]}
{"title": "Credit assignment among neurons in co-evolving populations\n", "abstract": " Different credit assignment strategies are investigated in a two level co-evolutionary model which involves a population of Gaussian neurons and a population of radial basis function networks consisting of neurons from the neuron population. Each individual in neuron population can contribute to one or more networks in network population, so there is a two-fold difficulty in evaluating the effectiveness (or fitness) of a neuron. Firstly, since each neuron only represents a partial solution to the problem, it needs to be assigned some credit for the complete problem solving activity. Secondly, these credits need to be accumulated from different networks the neuron participates in. This model, along with various credit assignment strategies, is tested on a classification (Heart disease diagnosis problem from UCI machine learning repository) and a regression problem (Mackey-Glass time series prediction problem).", "num_citations": "28\n", "authors": ["537"]}
{"title": "Continuous selection and self-adaptive evolution strategies\n", "abstract": " The intention of this work is to eliminate the need for a synchronous generation scheme in the (/spl mu//sup /spl plusmn///spl lambda/) evolution strategy. It is motivated by the need for a more practical implementation of selection strategies on parallel machine architectures. This strategy is known as continuous or steady state selection. Continuous selection is known to reduce significantly the number of function evaluations needed to reach an optimum in evolutionary search. Evolution strategy theory is used to illustrate when continuous selection is more efficient than generational selection. The authors also consider how this gain in efficiency may influence the overall effectiveness of the evolution strategy. The implementation of continuous selection becomes problematic for algorithms using explicitly encoded self-adaptive strategy parameters. Self-adaption is therefore given special consideration. The discussion\u00a0\u2026", "num_citations": "28\n", "authors": ["537"]}
{"title": "Emergence of cooperative coalition in NIPD game with localization of interaction and learning\n", "abstract": " The N-player iterated prisoner's dilemma (NIPD) game has been used widely to study the evolution of cooperation in social, economic and biological systems. Previous work on the NIPD game studied the impact of the number of players and the payoff function on the evolution of cooperation. This paper studies the localization issue in the NIPD game and investigates the impact of local interaction on genetically evolved strategies for the NIPD game. Our experimental results show that localization of interaction has a major impact on the evolution of cooperative coalitions, while localized learning makes the population oscillate. This paper also investigates the effect of the history length in the NIPD game. It is found experimentally that a longer history makes a population more stable, but it takes longer time to reach this stable state.", "num_citations": "28\n", "authors": ["537"]}
{"title": "A perspective on evolutionary computation\n", "abstract": " During the last three decades there has been a growing interest in algorithms which rely on analogies to natural processes. The emergence of massively parallel computers made these algorithms of practical interest. The best known algorithms in this class include evolutionary programming, genetic algorithms, evolution strategies, simulated annealing, classifier systems, and neural networks.             In this paper we discuss a subclass of these algorithms\u2014those which are based on the principle of evolution (survival of the fittest). A common term, recently accepted, refers to such techniques as \u2018evolutionary computation\u2019 methods.             The paper presents a perspective of the field of evolutionary computation. It discusses briefly the concept of evolutionary computation, presents the author's first experience with these methods, provides a discussion on relationship between evolutionary computation techniques\u00a0\u2026", "num_citations": "28\n", "authors": ["537"]}
{"title": "DiME: a scalable disease module identification algorithm with application to glioma progression\n", "abstract": " Disease module is a group of molecular components that interact intensively in the disease specific biological network. Since the connectivity and activity of disease modules may shed light on the molecular mechanisms of pathogenesis and disease progression, their identification becomes one of the most important challenges in network medicine, an emerging paradigm to study complex human disease. This paper proposes a novel algorithm, DiME (Disease Module Extraction), to identify putative disease modules from biological networks. We have developed novel heuristics to optimise Community Extraction, a module criterion originally proposed for social network analysis, to extract topological core modules from biological networks as putative disease modules. In addition, we have incorporated a statistical significance measure, B-score, to evaluate the quality of extracted modules. As an application to complex diseases, we have employed DiME to investigate the molecular mechanisms that underpin the progression of glioma, the most common type of brain tumour. We have built low (grade II) - and high (GBM) - grade glioma co-expression networks from three independent datasets and then applied DiME to extract potential disease modules from both networks for comparison. Examination of the interconnectivity of the identified modules have revealed changes in topology and module activity (expression) between low- and high- grade tumours, which are characteristic of the major shifts in the constitution and physiology of tumour cells during glioma progression. Our results suggest that transcription factors E2F4, AR and ETS1 are potential\u00a0\u2026", "num_citations": "27\n", "authors": ["537"]}
{"title": "Dynamic combinatorial optimisation problems: an analysis of the subset sum problem\n", "abstract": " The field of evolutionary computation has traditionally focused on static optimisation problems. Recently, many new approaches have been proposed that adapt traditional evolutionary algorithms to the dynamic domain to deal with the task of tracking high-quality solutions as the search space changes over time. These novel algorithms are subsequently evaluated on a wide range of different optimisation problems, including well-specified benchmark generators. However, due to a lack of theoretical results, as well as a general lack of references to actual real-world scenarios, it is not entirely clear whether these benchmarks capture any of the characteristics found in NP-hard dynamic optimisation problems. In this paper, we extensively analyse the properties of the NP-hard (dynamic) subset sum problem. In particular, we highlight the correlation between the dynamic parameters of the problem and the\u00a0\u2026", "num_citations": "27\n", "authors": ["537"]}
{"title": "A memetic genetic programming with decision tree-based local search for classification problems\n", "abstract": " In this work, we propose a new genetic programming algorithm with local search strategies, named Memetic Genetic Programming(MGP), for classification problems. MGP aims to acquire a classifier with large Area Under the ROC Curve (AUC), which has been proved to be a better performance metric for traditionally used metrics (e.g., classification accuracy). Three new points are presented in our new algorithm. First, a new representation called statistical genetic decision tree (SGDT) for GP is proposed on the basis of Genetic Decision Tree (GDT). Second, a new fitness function is designed by using statistic in formation from SGDT. Third, the concept of memetic computing is introduced into SGDT. As a result, the MGP is equipped with a local search method based on the training algorithms for decision trees. The efficacy of the MGP is empirically justified against a number of relevant approaches.", "num_citations": "27\n", "authors": ["537"]}
{"title": "Handling constraints for search based software test data generation\n", "abstract": " A major issue in software testing is the automatic generation of the inputs to be applied to the programme under test. To solve this problem, a number of approaches based on search methods have been developed in the last few years, offering promising results for adequacy criteria like, for instance, branch coverage. We devise branch coverage as the satisfaction of a number of constraints. This allows to formulate the test data generation as a constrained optimisation problem or as a constraint satisfaction problem. Then, we can see that many of the generators so far have followed the same particular approach. Furthermore, this constraint-handling point of view overcomes this limitation and opens the door to new designs and search strategies that, to the best of our knowledge, have not been considered yet. As a case study, we develop test data generators employing different penalty objective functions or\u00a0\u2026", "num_citations": "27\n", "authors": ["537"]}
{"title": "Hybridizing cultural algorithms and local search\n", "abstract": " In this paper, we propose a new population-based framework for combining local search with global explorations to solve single-objective unconstrained numerical optimization problems. The idea is to use knowledge about local optima found during the search to a) locate promising regions in the search space and b) identify suitable step sizes to move from one optimum to others in each region. The search knowledge was maintained using a Cultural Algorithm-based structure, which is updated by behaviors of individuals and is used to actively guide the search. Some experiments have been carried out to evaluate the performance of the algorithm on well-known continuous problems. The test results show that the algorithm can get comparable or superior results to that of some current well-known unconstrained numerical optimization algorithms in certain classes of problems.", "num_citations": "27\n", "authors": ["537"]}
{"title": "Genetic algorithms and evolutionary games\n", "abstract": " Genetic algorithms (GAs) have been used widely in evolving game-playing strategies since the mid-1980's. This paper looks at a particular game| the iterated prisoner's dilemma game, which is of interest to many economists, social scientists, evolutionary computation researchers and computer scientists. The paper describes a computational approach which uses a GA to evolve strategies for the 2 or more player iterated prisoner's dilemma game. Three important issues are addressed in this paper:(1) Can cooperation be evolved from a population of random strategies when the number of players is more than 2?(2) What is the impact of the group size, ie, the number of players on the evolution of cooperation?(3) How stable are evolved strategies? Although the above three issues have been studied for the 2 player iterated prisoner's dilemma game, few results are available for the N player (N> 2) iterated prisoner's dilemma game. This paper concentrates on the N player game. The answers to the rst two questions are not xed. They depend on the group size, ie, the number of players in the game. It is observed that as the group size increases it is more di cult to evolve cooperative strategies in a population, a phenomenon which is analogous to the real-life situation in our society, eg, an agreement is normally more di cult to reach in a large group. This paper addresses the third issue by presenting a theoretical result on evolutionarily stable strategies.", "num_citations": "27\n", "authors": ["537"]}
{"title": "Pipe failure prediction: A data mining method\n", "abstract": " Pipe breaks in urban water distribution network lead to significant economical and social costs, putting the service quality as well as the profit of water utilities at risk. To cope with such a situation, scheduled preventive maintenance is desired, which aims to predict and fix potential break pipes proactively. Physical models developed for understanding and predicting the failure of pipes are usually expensive, thus can only be used on a limited number of trunk pipes. As an alternative, statistical models that try to predict pipe breaks based on historical data are far less expensive, and therefore have attracted a lot of interests from water utilities recently. In this paper, we report a novel data mining prediction system that has been built for a water utility in a big Chinese city. Various aspects of how to build such a system are described, including problem formulation, data cleaning, model construction, as well as evaluating\u00a0\u2026", "num_citations": "26\n", "authors": ["537"]}
{"title": "Crossover can be constructive when computing unique input output sequences\n", "abstract": " Unique input output (UIO) sequences have important applications in conformance testing of finite state machines (FSMs). Previous experimental and theoretical research has shown that evolutionary algorithms (EAs) can compute UIOs efficiently on many FSM instance classes, but fail on others. However, it has been unclear how and to what degree EA parameter settings influence the runtime on the UIO problem. This paper investigates the choice of acceptance criterion in the (1+1) EA and the use of crossover in the (\u03bc+1) Steady State Genetic Algorithm. It is rigorously proved that changing these parameters can reduce the runtime from exponential to polynomial for some instance classes.", "num_citations": "26\n", "authors": ["537"]}
{"title": "Attributes of dynamic combinatorial optimisation\n", "abstract": " The field of evolutionary computation has traditionally focused on static optimisation problems but recently, many new approaches have been proposed that adapt traditional evolutionary algorithms to deal with the task of tracking high-quality solutions as the search space changes over time. Algorithms developed specifically for dynamic domains have been tested on a wide range of different problems, including well-specified benchmark generators. However, the lack of theoretical results, a general omission of references to actual real-world scenarios, as well as a substantial emphasis on the continuous domain may divert attention away from some highly relevant issues. Here we review the state of the field and analyse dynamics in the combinatorial domain, using the subset sum problem as an example. It is shown that some of the assumptions underlying the development of new algorithms do not\u00a0\u2026", "num_citations": "26\n", "authors": ["537"]}
{"title": "Target shape design optimization by evolving splines\n", "abstract": " Target shape design optimization problem (TS-DOP) is a miniature model for real world design optimization problems. It is proposed as a test bed to design and analyze optimization approaches for design optimization with tremendously reducing the running period of optimization process, while, the merit can be only achieved by correctly approximating the real design situation and satisfying the causality of design and evaluation. The representation of the designed object is mostly described by parameterization techniques. To realize the design optimization, is to vary the parameterized object by means of operating the relevant parameters. The solution of design optimization often involved the choice of suitable description for the designed object, which can be obtained by expanding the design freedom. When changing the description length, the original parameters of the designed object will then varied. This\u00a0\u2026", "num_citations": "26\n", "authors": ["537"]}
{"title": "On the architectures of complex multi-agent systems\n", "abstract": " This paper presents a literature review on the architectures of complex multi-agent systems. Firstly, the concept of general architectures and three orientations of systems architectures, ie, information flow oriented, control oriented and role oriented ones, are presented. Secondly, a literature review is presented upon the architectures of complex multi-agent systems in terms of control oriented and role oriented architectures. Finally, a novel autonomic architecture is put forward for complex multi-agent systems.", "num_citations": "26\n", "authors": ["537"]}
{"title": "Evolutionary large-scale multiobjective optimization for ratio error estimation of voltage transformers\n", "abstract": " Ratio error (RE) estimation of the voltage transformers (VTs) plays an important role in modern power delivery systems. Existing RE estimation methods mainly focus on periodical calibration but ignore the time-varying property. Consequently, it is difficult to efficiently estimate the state of the VTs in real time. To address this issue, we formulate a time-varying RE estimation (TREE) problem into a large-scale multiobjective optimization problem, where the multiple objectives and inequality constraints are formulated by statistical and physical rules extracted from the power delivery systems. Furthermore, a set of TREE problems from different substations is systematically formulated into a benchmark test suite for characterizing their different properties. The formulation of these TREE problems not only transfers an expensive RE estimation task to a relatively cheaper optimization problem but also promotes the research in\u00a0\u2026", "num_citations": "25\n", "authors": ["537"]}
{"title": "Benchmark problems for CEC2018 competition on dynamic multiobjective optimisation\n", "abstract": " The past decade has witnessed a growing amount of research interest in dynamic multiobjective optimisation, a challenging yet very important topic that deals with problems with multi-objective and time-dependent properties [3\u20137, 10]. Due to the presence of dynamics, dynamic multiobjective problems (DMOPs) are more complex and challenging than static multiobjective problems. As a result, evolutionary algorithms (EAs) face great difficulties in solving them. Generally speaking, DMOPs pose at least three main challenges. First, environmental changes can exhibit any dy namics. A variety of dynamics pose different levels of difficulties to algorithms, and there is no single change reaction mechanism that can handle all dynamics. Second, diversity, the key driving force of population-based algorithms, is sensitive to dynamics and therefore difficult to be well maintained. Finally, often than not the response time for\u00a0\u2026", "num_citations": "25\n", "authors": ["537"]}
{"title": "A multi-objective approach to testing resource allocation in modular software systems\n", "abstract": " Nowadays, as the software systems become increasingly large and complex, the problem of allocating the limited testing-resource during the testing phase has become more and more difficult. In this paper, we propose to solve the testing-resource allocation problem (TRAP) using multi-objective evolutionary algorithms. Specifically, we formulate TRAP as two multi-objective problems. First, we consider the reliability of the system and the testing cost as two objectives. In the second formulation, the total testing-resource consumed is also taken into account as the third goal. Two multi-objective evolutionary algorithms, non-dominated sorting genetic algorithm II (NSGA2) and multi-objective differential evolution algorithms (MODE), are applied to solve the TRAP in the two scenarios. This is the first time that the TRAP is explicitly formulated and solved by multi-objective evolutionary approaches. Advantages of our\u00a0\u2026", "num_citations": "25\n", "authors": ["537"]}
{"title": "A probabilistic ensemble pruning algorithm\n", "abstract": " An ensemble is a group of learners that work together as a committee to solve a problem. However, the existing ensemble training algorithms sometimes generate unnecessary large ensembles, which consume extra computational resource and may degrade the performance. Ensemble pruning algorithm aims to find a good subset of ensemble members to constitute a small ensemble, which saves the computational resource and performs as well as, or better than, the non-pruned ensemble. This paper introduces a probabilistic ensemble pruning algorithm by choosing a set of \"sparse\" combination weights, most of which are zero, to prune the large ensemble. In order to obtain the set of sparse combination weights and satisfy the non-negative restriction of the combination weights, a left-truncated, non-negative, Gaussian prior is adopted over every combination weight. Expectation-maximization algorithm is\u00a0\u2026", "num_citations": "25\n", "authors": ["537"]}
{"title": "Evolutionary multiobjective ensemble learning based on bayesian feature selection\n", "abstract": " This paper proposes to incorporate evolutionary multiobjective algorithm and Bayesian Automatic Relevance Determination (ARD) to automatically design and train ensemble. The algorithm determines almost all the parameters of ensemble automatically. Our algorithm adopts different feature subsets, selected by Bayesian ARD, to maintain accuracy and promote diversity among individual NNs in an ensemble. The multiobjective evaluation of the fitness of the networks encourages the networks with lower error rate and fewer features. The proposed algorithm is applied to several real-world classification problems and in all cases the performance of the method is better than the performance of other ensemble construction algorithms.", "num_citations": "25\n", "authors": ["537"]}
{"title": "Dynamic control of adaptive parameters in evolutionary programming\n", "abstract": " Evolutionary programming (EP) has been widely used in numerical optimization in recent years. The adaptive parameters, also named step size control, in EP play a significant role which controls the step size of the objective variables in the evolutionary process. However, the step size control may not work in some cases. They are frequently lost and then make the search stagnate early. Applying the lower bound can maintain the step size in a work range, but it also constrains the objective variables from being further explored. In this paper, an adaptively adjusted lower bound is proposed which supports better fine-tune searches and spreads out exploration as well.", "num_citations": "25\n", "authors": ["537"]}
{"title": "Progress in Evolutionary Computation: AI'93 and AI'94 Workshops on Evolutionary Computation, Melbourne, Victoria, Australia, November 16, 1993, Armidale, NSW, Australia\u00a0\u2026\n", "abstract": " This volume contains the best carefully revised full papers selected from the presentations accepted for the AI'93 and AI'94 Workshop on Evolutionary Computation held in Australia. The 21 papers included cover a wide range of topics in the field of evolutionary computation, from constrained function optimization to combinatorial optimization, from evolutionary programming to genetic programming, from robotic strategy learning to co-evolutionary game strategy learning. The papers reflect important recent progress in the field; more than half of the papers come from overseas.", "num_citations": "25\n", "authors": ["537"]}
{"title": "Scaling up dynamic optimization problems: A divide-and-conquer approach\n", "abstract": " Scalability is a crucial aspect of designing efficient algorithms. Despite their prevalence, large-scale dynamic optimization problems are not well studied in the literature. This paper is concerned with designing benchmarks and frameworks for the study of large-scale dynamic optimization problems. We start by a formal analysis of the moving peaks benchmark (MPB) and show its nonseparable nature irrespective of its number of peaks. We then propose a composite MPB suite with exploitable modularity covering a wide range of scalable partially separable functions suitable for the study of large-scale dynamic optimization problems. The benchmark exhibits modularity, heterogeneity, and imbalance features to resemble real-world problems. To deal with the intricacies of large-scale dynamic optimization problems, we propose a decomposition-based coevolutionary framework which breaks a large-scale dynamic\u00a0\u2026", "num_citations": "24\n", "authors": ["537"]}
{"title": "A memetic algorithm for uncertain capacitated arc routing problems\n", "abstract": " The Capacitated Arc Routing Problem (CARP) is a widely investigated classic combinatorial optimization problem. Being a deterministic model, it is far away from the real world. A more practical problem model of CARP is the Uncertain CARP (UCARP), with the objective of finding a robust solution which performs well in all possible environments. There exist few algorithms for UCARP in previous work. In this paper, a Memetic Algorithm (MA) and its modified version in time consumption for UCARP are proposed. Experimental results on two benchmark test sets show that with an integrated fitness function and a large step-size local search operator, the new MAs show excellent ability to find robust solutions for UCARP. We also present a less time-consuming version of our MA which shows significant advantages in time consumption.", "num_citations": "24\n", "authors": ["537"]}
{"title": "Iterated prisoner's dilemma and evolutionary game theory\n", "abstract": " The prisoner\u2019s dilemma is a type of non-zero-sum game in which two players try to maximize their payoff by cooperating with, or betraying the other player. The term non-zero-sum indicates that whatever benefits accrue to one player do not necessarily imply similar penalties imposed on the other player. The Prisoner\u2019s dilemma was originally framed by Merrill Flood and Melvin Dresher working at RAND Corporation in 1950. Albert W. Tucker formalized the game with prison sentence payoffs and gave it the \u201cPrisoner\u2019s Dilemma\u201d name. The classical prisoner\u2019s dilemma (PD) is as follows:Two suspects, A and B, are arrested by the police. The police have insufficient evidence for a conviction, and, having separated both prisoners, visit each of them to offer the same deal: if one testifies for the prosecution against the other and the other remains silent, the betrayer goes free and the silent accomplice receives the full 10-year sentence. If both stay silent, the police can sentence both prisoners to only six months in jail for a minor charge. If each betrays the other, each will receive a two-year sentence. Each prisoner must make the choice of whether to betray the other or to remain silent. However, neither prisoner knows for sure what choice the other prisoner will make. So the question this dilemma poses is: What will happen? How will the prisoners act?", "num_citations": "24\n", "authors": ["537"]}
{"title": "Extracting a set of robust Pareto-optimal parameters for hydrologic models using NSGA-II and SCEM\n", "abstract": " In this paper, we will present a heuristic method in order to combine the information about the parametric space of a conceptual hydrologic model from two different sources. On one hand, multi-objective evolutionary optimization algorithm NSGA-II is used to find a set of pareto optimal solutions. On the other hand, a Markov Chain Monte Carlo-based algorithm, i.e. Shuffled Complex Evolution Metropolis (SCEM) is used to highlight a set of parameters with higher posterior distribution. By covering the interval between the most crowded locations in the parametric space extracted by both algorithms, we will identify a set of pareto optimal solutions which is more robust than the initial non-dominated set extracted by only NSGA-II.", "num_citations": "24\n", "authors": ["537"]}
{"title": "Multi-network evolutionary systems and automatic decomposition of complex problems\n", "abstract": " Multi-network systems, i.e. multiple neural network systems, can often solve complex problems more effectively than their monolithic counterparts. Modular neural networks (MNNs) tackle a complex problem by decomposing it into simpler subproblems and then solving them. Unlike the decomposition in MNNs, a neural network ensemble usually includes redundant component nets and is often inspired by statistical theories. This paper presents different types of problem decompositions and discusses the suitability of various multi-network systems for different decompositions. A classification of various multi-network systems, in the context of problem decomposition, is obtained by exploiting these differences. Then a specific type of problem decomposition, which gives no information about the subproblems and is often ignored in literature, is discussed in detail and a novel MNN architecture for problem\u00a0\u2026", "num_citations": "24\n", "authors": ["537"]}
{"title": "Evolutionary search and constraint violations\n", "abstract": " The aim of this work is towards a better understanding of the effect of using constraint violations in guiding evolutionary search for nonlinear programming problems. Different penalty functions, based on constraint violations, create different search biases. However, this bias may be eliminated when treating the nonlinear programming problem as a multiobjective task. The different search behaviors are illustrated using a new artificial test function. The effectiveness of the multiobjective approach is also compared with the standard penalty function method on a number of commonly used benchmark problems. It is shown that in practice multiobjective methods are not an efficient or effective approach to constrained evolutionary optimization.", "num_citations": "24\n", "authors": ["537"]}
{"title": "Dynamic neighbourhood size in simulated annealing\n", "abstract": " Simulated annealing has been shown to be a powerful stochastic method of tackling hard combinatorial optimisation problems, but it demands a vast amount of computation time to arrive at a good approximate solution. A lot of research has been done on the cooling schedule of simulated annealing to speed up its convergence, but only limited attention has been paid to the impact of the neighbourhood size on the performance of simulated annealing. It has been shown that the performance of simulated annealing can be improved by adopting a suitable neighbourhood size. However, previous studies usually assumed that the neighbourhood size was fixed during search after decided at the beginning. This paper presents a simulated annealing algorithm with a dynamic neighbourhood size which depends on the current \u201ctemperature\u201d value during search. A method of dynamically deciding the neighbourhood size by approximating a continuous probability distribution is given. Four continuous probability distributions are used in our experiments to generate neighbourhood sizes dynamically, and the results are compared.", "num_citations": "24\n", "authors": ["537"]}
{"title": "Probabilistic feature selection and classification vector machine\n", "abstract": " Sparse Bayesian learning is a state-of-the-art supervised learning algorithm that can choose a subset of relevant samples from the input data and make reliable probabilistic predictions. However, in the presence of high-dimensional data with irrelevant features, traditional sparse Bayesian classifiers suffer from performance degradation and low efficiency due to the incapability of eliminating irrelevant features. To tackle this problem, we propose a novel sparse Bayesian embedded feature selection algorithm that adopts truncated Gaussian distributions as both sample and feature priors. The proposed algorithm, called probabilistic feature selection and classification vector machine (PFCVMLP) is able to simultaneously select relevant features and samples for classification tasks. In order to derive the analytical solutions, Laplace approximation is applied to compute approximate posteriors and marginal likelihoods\u00a0\u2026", "num_citations": "23\n", "authors": ["537"]}
{"title": "A critical review of: \" a practical guide to select quality indicators for assessing pareto-based search algorithms in search-based software engineering\": essay on quality\u00a0\u2026\n", "abstract": " This paper presents a critical review of the work published at ICSE'2016 on a practical guide of quality indicator selection for assessing multiobjective solution sets in search-based software engineering (SBSE). This review has two goals. First, we aim at explaining why we disagree with the work at ICSE'2016 and why the reasons behind this disagreement are important to the SBSE community. Second, we aim at providing a more clarified guide of quality indicator selection, serving as a new direction on this particular topic for the SBSE community. In particular, we argue that it does matter which quality indicator to select, whatever in the same quality category or across different categories. This claim is based upon the fundamental goal of multiobjective optimisation---supplying the decision-maker a set of solutions which are the most consistent with their preferences.", "num_citations": "23\n", "authors": ["537"]}
{"title": "Optimal relay placement for lifetime maximization in wireless underground sensor networks\n", "abstract": " Because of highly lossy underground channels and the difficulty in recharging the buried sensor nodes (SNs), power conservation is a primary objective in the design of wireless underground sensor networks (WUSNs). One promising approach to prolonging the lifetimes of WUSNs is to deploy aboveground relay nodes (RNs) to relay the traffic. However, there are several challenges. First, the candidate locations of RNs are affected by the terrestrial environment. Second, signal attenuation is complex because of the multimedium propagation. Third, the optimal placement problem has to be considered in a three-dimensional space. Finally, load balancing among RNs is required to ensure that there is no overloading or exhausting of a single node. In this paper, the RN placement problem in WUSNs is modeled and formulated for the first time; the goal is to deploy a limited number of RNs to maximize the lifetimes of\u00a0\u2026", "num_citations": "23\n", "authors": ["537"]}
{"title": "Population evolvability: Dynamic fitness landscape analysis for population-based metaheuristic algorithms\n", "abstract": " Fitness landscape analysis (FLA) is an important approach for studying how hard problems are for metaheuristic algorithms to solve. Static FLA focuses on extracting the properties of a problem and does not consider any information about the optimization algorithms; thus, it is not adequate for indicating whether a particular algorithm is suitable for solving a problem. By contrast, dynamic FLA considers the behavior of algorithms in combination with the properties of an optimization problem to determine the effectiveness of a given algorithm for solving that problem. However, previous dynamic FLA approaches are all individually based and lack statistical significance. In this paper, the concept of population evolvability is presented, as an extension of dynamic FLA, to quantify the effectiveness of population-based metaheuristic algorithms for solving a given problem. Specifically, two measures of population evolvability\u00a0\u2026", "num_citations": "23\n", "authors": ["537"]}
{"title": "An iterative pseudo-gap enumeration approach for the Multidimensional Multiple-choice Knapsack Problem\n", "abstract": " The Multidimensional Multiple-choice Knapsack Problem (MMKP) is an important NP-hard combinatorial optimization problem with many applications. We propose a new iterative pseudo-gap enumeration approach to solving MMKPs. The core of our algorithm is a family of additional cuts derived from the reduced costs constraint of the nonbasic variables by reference to a pseudo-gap. We then introduce a strategy to enumerate the pseudo-gap values. Joint with CPLEX, we evaluate our approach on two sets of benchmark instances and compare our results with the best solutions reported by other heuristics in the literature. It discovers 10 new better lower bounds on 37 well-known benchmark instances with a time limit of 1 hour for each instance. We further give direct comparison between our algorithm and one state-of-the-art \u201creduce and solve\u201d approach on the same machine with the same CPLEX, experimental\u00a0\u2026", "num_citations": "23\n", "authors": ["537"]}
{"title": "A new evolutionary algorithm with structure mutation for the maximum balanced biclique problem\n", "abstract": " The maximum balanced biclique problem (MBBP), an NP-hard combinatorial optimization problem, has been attracting more attention in recent years. Existing node-deletion-based algorithms usually fail to find high-quality solutions due to their easy stagnation in local optima, especially when the scale of the problem grows large. In this paper, a new algorithm for the MBBP, evolutionary algorithm with structure mutation (EA/SM), is proposed. In the EA/SM framework, local search complemented with a repair-assisted restart process is adopted. A new mutation operator, SM, is proposed to enhance the exploration during the local search process. The SM can change the structure of solutions dynamically while keeping their size (fitness) and the feasibility unchanged. It implements a kind of large mutation in the structure space of MBBP to help the algorithm escape from local optima. An MBBP-specific local search\u00a0\u2026", "num_citations": "23\n", "authors": ["537"]}
{"title": "Combining learning in model space fault diagnosis with data validation/reconstruction: Application to the Barcelona water network\n", "abstract": " In this paper, an integrated data validation/reconstruction and fault diagnosis approach is proposed for critical infrastructure systems. The proposed methodology is implemented in a two-stage approach. In the first stage, sensor communication faults are detected and corrected, in order to facilitate a reliable dataset to perform system fault diagnosis in the second stage. On the one hand, sensor validation and reconstruction are based on the combined use of spatial and time series models. Spatial models take advantage of the (mass-balance) relation between different variables in the system, whilst time series models take advantage of the temporal redundancy of the measured variables by means of Holt-Winters time series models. On the other hand, fault diagnosis is based on the learning-in-model-space approach that is implemented by fitting a series of models using a series of signal segments selected with a\u00a0\u2026", "num_citations": "23\n", "authors": ["537"]}
{"title": "Characterizing environmental changes in robust optimization over time\n", "abstract": " Evolutionary dynamic optimization has been drawing more and more research attention, and yet most work in this area is focused on Tracking Moving Optimum (TMO), which is to optimize the current fitness function at any time point. Recently, we proposed a more practical way to solve dynamic optimization problems, which is referred to as Robust Optimization Over Time (ROOT). In ROOT, we are trying to find solutions whose performances are acceptable over more than one environmental state, i.e., fitness functions. Before any development of benchmarks or algorithms for ROOT, it is necessary to have some understanding of what aspects of an environment can change and more importantly how these changes influence the solving of ROOT problems. In this paper, we develop a number of measures which can be used to characterize and analyse the underlying changing environment in the framework of ROOT\u00a0\u2026", "num_citations": "23\n", "authors": ["537"]}
{"title": "An evaluation of differential evolution in software test data generation\n", "abstract": " One of the main tasks software testing involves is the generation of the test inputs to be used during the test. Due to its expensive cost, the automation of this task has become one of the key issues in the area. Recently, this generation has been explicitly formulated as the resolution of a set of constrained optimisation problems. Differential Evolution (DE) is a population based evolutionary algorithm which has been successfully applied in a number of domains, including constrained optimisation. We present a test data generator employing DE to solve each of the constrained optimisation problems, and empirically evaluate its performance for several DE models. With the aim of comparing this technique with other approaches, we extend the experiments to the Breeder Genetic Algorithm and face it to DE, and compare different test data generators in the literature with the DE approach. The results present DE as a\u00a0\u2026", "num_citations": "23\n", "authors": ["537"]}
{"title": "Interactive Genetic Algorithms with Individual Fitness Not Assigned by Human.\n", "abstract": " Interactive genetic algorithms (IGAs) are effective methods to solve optimization problems with implicit or fuzzy indices. But human fatigue problem, resulting from evaluation on individuals and assignment of their fitness, is very important and hard to solve in IGAs. Aiming at solving the above problem, an interactive genetic algorithm with an individual fitness not assigned by human is proposed in this paper. Instead of assigning an individual fitness directly, we record time to choose an individual from a population as a satisfactory or unsatisfactory one according to sensitiveness to it, and its fitness is automatically calculated by a transformation from time space to fitness space. Then subsequent genetic operation is performed based on this fitness, and offspring is generated. We apply this algorithm to fashion design, and the experimental results validate its efficiency.", "num_citations": "23\n", "authors": ["537"]}
{"title": "A grey-box approach to automated mechanism design\n", "abstract": " This paper presents an approach to automated mechanism design in the domain of double auctions. We describe a novel parameterized space of double auctions, and then introduce an evolutionary search method that searches this space of parameters. The approach evaluates auction mechanisms using the framework of the TAC Market Design Game and relates the performance of the markets in that game to their constituent parts using reinforcement learning. Experiments show that the strongest mechanisms we found using this approach not only win the Market Design Game against known, strong opponents, but also exhibit desirable economic properties when they run in isolation.", "num_citations": "22\n", "authors": ["537"]}
{"title": "Recurring two-stage evolutionary programming: A novel approach for numeric optimization\n", "abstract": " In the application of evolutionary algorithms (EAs) to complex problem solving, it is essential to maintain proper balance between global exploration and local exploitation to achieve a good near-optimum solution to the problem. This paper presents a recurring two-stage evolutionary programming (RTEP) to balance the explorative and exploitative features of the conventional EAs. Unlike most previous works, RTEP is based on repeated and alternated execution of two different stages, namely, the exploration and exploitation stages, each with its own mutation operator, selection strategy, and explorative/exploitative objective. Both analytical and empirical studies have been carried out to understand the necessity of repeated and alternated exploration and exploitation operations in EAs. A suite of 48 benchmark numerical optimization problems has been used in the empirical studies. The experimental results show\u00a0\u2026", "num_citations": "22\n", "authors": ["537"]}
{"title": "Choosing selection pressure for wide-gap problems\n", "abstract": " To exploit an evolutionary algorithm\u2019s performance to the full extent, the selection scheme should be chosen carefully. Empirically, it is commonly acknowledged that low selection pressure can prevent an evolutionary algorithm from premature convergence, and is thereby more suitable for wide-gap problems. However, there are few theoretical time complexity studies that actually give the conditions under which a high or a low selection pressure is better. In this paper, we provide a rigorous time complexity analysis showing that low selection pressure is better for the wide-gap problems with two optima.", "num_citations": "22\n", "authors": ["537"]}
{"title": "Using a genetic algorithm for editing k-nearest neighbor classifiers\n", "abstract": " The edited k-nearest neighbor consists of the application of the k-nearest neighbor classifier with an edited training set, in order to reduce the classification error rate. This edited training set is a subset of the complete training set in which some of the training patterns are excluded. In recent works, genetic algorithms have been successfully applied to generate edited sets. In this paper we propose three improvements of the edited k-nearest neighbor design using genetic algorithms: the use of a mean square error based objective function, the implementation of a clustered crossover, and a fast smart mutation scheme. Results achieved using the breast cancer database and the diabetes database from the UCI machine learning benchmark repository demonstrate the improvement achieved by the joint use of these three proposals.", "num_citations": "22\n", "authors": ["537"]}
{"title": "Evolutionary random neural ensembles based on negative correlation learning\n", "abstract": " This paper proposes to incorporate bootstrap of data, random feature subspace and evolutionary algorithm with negative correlation learning to automatically design accurate and diverse ensembles. The algorithm utilizes both bootstrap of training data and random feature subspace techniques to generate an initial and diverse ensemble and evolves the ensemble with negative correlation learning. The idea of generating ensemble by simultaneous randomization of data and feature is to promote the diversity within the ensemble and encourage different individual NNs in the ensemble to learn different parts or aspects of the training data so that the ensemble can learn better the entire training data. Evolving the ensemble with negative correlation learning emphasizes not only the accuracy of individual NNs but also the cooperation among different individual NNs and thus improves the generalization. As a byproduct\u00a0\u2026", "num_citations": "22\n", "authors": ["537"]}
{"title": "Teaching advanced features of evolutionary algorithms using Japanese puzzles\n", "abstract": " In this paper, a method to teach advanced features of evolutionary algorithms (EAs), using a famous game known as Japanese puzzles is presented. The authors show that Japanese puzzles are constrained combinatorial optimization problems, that can be solved using EAs with different encodings, and are challenging problems for EAs. Other features, such as special operators and local search heuristics and its hybridization with genetic algorithms, can also be taught using these puzzles. The authors report an experience using this method in a course taught at the Universidad de Alcalaacute, Madrid, Spain", "num_citations": "22\n", "authors": ["537"]}
{"title": "Control of bloat in genetic programming by means of the island model\n", "abstract": " This paper presents a new proposal for reducing bloat in Genetic Programming. This proposal is based in a well-known parallel evolutionary model: the island model. We firstly describe the theoretical motivation for this new approach to the bloat problem, and then we present a set of experiments that gives us evidence of the findings extracted from the theory. The experiments have been performed on a representative problem extracted from the GP field: the even parity 5 problem. We analyse the evolution of bloat employing different settings for the parameters employed. The conclusion is that the Island Model helps to prevent the bloat phenomenon.", "num_citations": "22\n", "authors": ["537"]}
{"title": "An analysis of evolutionary algorithms for finding approximation solutions to hard optimisation problems\n", "abstract": " In practice, evolutionary algorithms are often used to find good feasible solutions to complex optimisation problems in a reasonable running time, rather than the optimal solutions. In theory, an important question we should answer is that: how good approximation solutions can evolutionary algorithms produce in a polynomial time? This paper makes an initial discussion on this question and connects evolutionary algorithms with approximation algorithms together. It is shown that evolutionary algorithms can't find good approximation solution to two families of hard problems.", "num_citations": "22\n", "authors": ["537"]}
{"title": "Computational intelligence in control\n", "abstract": " The problem of controlling uncertain dynamic systems, which are subject to external disturbances, uncertainty and sheer complexity is of considerable interest in computer science, Operations Research and Business domains. The application of intelligent systems has been found useful in problems when the process is either difficult to model or difficult to solve by conventional methods. Intelligent systems have attracted increasing attention in recent years for solving many complex problems. Computational Intelligence in Control will be a repository for the theory and applications of intelligent systems techniques in modelling control and automation.", "num_citations": "22\n", "authors": ["537"]}
{"title": "Finding approximate solutions to NP-hard problems by neural networks is hard\n", "abstract": " Finding approximate solutions to hard combinatorial optimization problems by neural networks is a very attractive prospect. Many empirical studies have been done in the area. However, recent research about a neural network model indicates that for any NP-hard problem the existence of a polynomial size network that solves it implies that NP=co-NP, which is contrary to the well-known conjecture that NP \u2260 co-NP. This paper shows that even finding approximate solutions with guaranteed performance to some NP-hard problems by a polynomial size network is also impossible unless NP = co-NP.", "num_citations": "22\n", "authors": ["537"]}
{"title": "An outlook for self-awareness in computing systems\n", "abstract": " Design implications:Need not require that a self-aware system possesses a global omniscient controller.", "num_citations": "21\n", "authors": ["537"]}
{"title": "Improved adaptivity and robustness in decentralised multi-camera networks\n", "abstract": " In this paper we present increased adaptivity and robustness in distributed object tracking by multi-camera networks using a socio-economic mechanism for learning the vision graph. To build-up the vision graph autonomously within a distributed smart-camera network, we use an ant-colony inspired mechanism, which exchanges responsibility for tracking objects using Vickrey auctions. Employing the learnt vision graph allows the system to optimise its communication continuously. Since distributed smart camera networks are prone to uncertainties in individual cameras, such as failures or changes in extrinsic parameters, the vision graph should be sufficiently robust and adaptable during runtime to enable seamless tracking and optimised communication. To better reflect real smart-camera platforms and networks, we consider that communication and handover are not instantaneous, and that cameras may be\u00a0\u2026", "num_citations": "21\n", "authors": ["537"]}
{"title": "Neuronal population oscillations of rat hippocampus during epileptic seizures\n", "abstract": " Neuronal population oscillations in the hippocampus have an important effect in the information processing in the brain and the generation of epileptic seizures. In this paper, we investigate the neuronal population oscillations in the hippocampus of epileptic rats in vivo using an empirical mode decomposition (EMD) method. A neuronal population oscillation can be decomposed into several relaxation oscillations, which possess a recovery and release phase, with the different frequencies that ranges from 0 to 600\u00a0Hz. The natures of relaxation oscillations at the pre-ictal, seizure onset and ictal states are distinctly different. The analysis of relaxation oscillations show that the gamma wave is a lead relaxation oscillation at the pre-ictal stage, then it moves to beta oscillation or theta oscillation while the ictal stage starts; the fast relaxation oscillations are associated with the slow relaxation oscillations in the CA1 or CA3\u00a0\u2026", "num_citations": "21\n", "authors": ["537"]}
{"title": "Evolving artificial neural network ensembles\n", "abstract": " Artificial neural networks (ANNs) and evolutionary algorithms (EAs) are both abstractions of natural processes. In the mid 1990s, they were combined into a computational model in order to utilize the learning power of ANNs and adaptive capabilities of EAs. Evolutionary ANNs (EANNs) is the outcome of such a model. They refer to a special class of ANNs in which evolution is another fundamental form of adaptation in addition to learning [52\u201357]. The essence of EANNs is their adaptability to a dynamic environment. The two forms of adaptation in EANNs \u2013 namely evolution and learning \u2013 make their adaptation to a dynamic environment much more effective and efficient. In a broader sense, EANNs can be regarded as a general framework for adaptive systems \u2013 in other words, systems that can change their architectures and learning rules appropriately without human intervention.", "num_citations": "21\n", "authors": ["537"]}
{"title": "Nadir point estimation for many-objective optimization problems based on emphasized critical regions\n", "abstract": " Nadir points play an important role in many-objective optimization problems, which describe the ranges of their Pareto fronts. Using nadir points as references, decision makers may obtain their preference information for many-objective optimization problems. As the number of objectives increases, nadir point estimation becomes a more difficult task. In this paper, we propose a novel nadir point estimation method based on emphasized critical regions for many-objective optimization problems. It maintains the non-dominated solutions near extreme points and critical regions after an individual number assignment to different critical regions. Furthermore, it eliminates similar individuals by a novel self-adaptive -clearing strategy. Our approach has been shown to perform better on many-objective optimization problems (between 10 objectives and 35 objectives) than two other state-of-the-art nadir point\u00a0\u2026", "num_citations": "20\n", "authors": ["537"]}
{"title": "Meta-heuristic combining prior online and offline information for the quadratic assignment problem\n", "abstract": " The construction of promising solutions for NP-hard combinatorial optimization problems (COPs) in meta-heuristics is usually based on three types of information, namely a priori information, a posteriori information learned from visited solutions during the search procedure, and online information collected in the solution construction process. Prior information reflects our domain knowledge about the COPs. Extensive domain knowledge can surely make the search effective, yet it is not always available. Posterior information could guide the meta-heuristics to globally explore promising search areas, but it lacks local guidance capability. On the contrary, online information can capture local structures, and its application can help exploit the search space. In this paper, we studied the effects of using this information on metaheuristic's algorithmic performances for the COPs. The study was illustrated by a set of heuristic\u00a0\u2026", "num_citations": "20\n", "authors": ["537"]}
{"title": "Evolutionary mechanics: new engineering principles for the emergence of flexibility in a dynamic and uncertain world\n", "abstract": " Engineered systems are designed to deftly operate under predetermined conditions yet are notoriously fragile when unexpected perturbations arise. In contrast, biological systems operate in a highly flexible manner; learn quickly adequate responses to novel conditions, and evolve new routines and traits to remain competitive under persistent environmental change. A recent theory on the origins of biological flexibility has proposed that degeneracy\u2014the existence of multi-functional components with partially overlapping functions\u2014is a primary determinant of the robustness and adaptability found in evolved systems. While degeneracy\u2019s contribution to biological flexibility is well documented, there has been little investigation of degeneracy design principles for achieving flexibility in systems engineering. Actually, the conditions that can lead to degeneracy are routinely eliminated in engineering design. With\u00a0\u2026", "num_citations": "20\n", "authors": ["537"]}
{"title": "Resource-aware configuration in smart camera networks\n", "abstract": " A recent trend in smart camera networks is that they are able to modify the functionality during runtime to better reflect changes in the observed scenes and in the specified monitoring tasks. In this paper we focus on different configuration methods for such networks. A configuration is given by three components: (i) a description of the camera nodes, (ii) a specification of the area of interest by means of observation points and the associated monitoring activities, and (iii) a description of the analysis tasks. We introduce centralized, distributed and proprioceptive configuration methods and compare their properties and performance.", "num_citations": "20\n", "authors": ["537"]}
{"title": "Evolutionary and principled search strategies for sensornet protocol optimization\n", "abstract": " Interactions between multiple tunable protocol parameters and multiple performance metrics are generally complex and unknown; finding optimal solutions is generally difficult. However, protocol tuning can yield significant gains in energy efficiency and resource requirements, which is of particular importance for sensornet systems in which resource availability is severely restricted. We address this multi-objective optimization problem for two dissimilar routing protocols and by two distinct approaches. First, we apply factorial design and statistical model fitting methods to reject insignificant factors and locate regions of the problem space containing near-optimal solutions by principled search. Second, we apply the Strength Pareto Evolutionary Algorithm 2 and Two-Archive evolutionary algorithms to explore the problem space, with each iteration potentially yielding solutions of higher quality and diversity than the\u00a0\u2026", "num_citations": "20\n", "authors": ["537"]}
{"title": "Non-uniform mutation rates for problems with unknown solution lengths\n", "abstract": " Many practical optimisation problems allow candidate solutions of varying lengths, and where the length of the optimal solution is thereby a priori unknown. We suggest that non-uniform mutation rates can be beneficial when solving such problems. In particular, we consider a mutation operator that flips each bit with a probability that is inversely proportional to the bit position, rather than the bitstring length. The runtime of the (1+ 1) EA using this mutation operator is analysed rigorously on standard example functions. Furthermore, the behaviour of the new mutation operator is investigated empirically on a real world software engineering problem that has variable, and unknown solution lengths. The results show how the speedup that can be achieved with the new operator depends on the distribution of the solution lengths in the solution space. We consider a truncated geometric distribution, and show that the new\u00a0\u2026", "num_citations": "20\n", "authors": ["537"]}
{"title": "Uncovering delayed patterns in noisy and irregularly sampled time series: an astronomy application\n", "abstract": " We study the problem of estimating the time delay between two signals representing delayed, irregularly sampled and noisy versions of the same underlying pattern. We propose and demonstrate an evolutionary algorithm for the (hyper)parameter estimation of a kernel-based technique in the context of an astronomical problem, namely estimating the time delay between two gravitationally lensed signals from a distant quasar. Mixed types (integer and real) are used to represent variables within the evolutionary algorithm. We test the algorithm on several artificial data sets, and also on real astronomical observations of quasar Q0957+561. By carrying out a statistical analysis of the results we present a detailed comparison of our method with the most popular methods for time delay estimation in astrophysics. Our method yields more accurate and more stable time delay estimates. Our methodology can be readily\u00a0\u2026", "num_citations": "20\n", "authors": ["537"]}
{"title": "Proceedings of the 6th International Conference on Parallel Problem Solving from Nature\n", "abstract": " Proceedings of the 6th International Conference on Parallel Problem Solving from Nature | Guide Proceedings ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleProceedingsPPSN VI ABSTRACT No abstract available. Comments Login options Check if you have access through your login credentials or your institution to get full access on this article. Sign in Full Access Get this Publication Information Contributors Published in Guide Proceedings cover image PPSN VI: Proceedings of the 6th International Conference on Parallel Problem Solving from Nature September 2000 881 pages ISBN:3540410562 Editors: Marc Schoenauer, \u2026", "num_citations": "20\n", "authors": ["537"]}
{"title": "Does preference always help? A holistic study on preference-based evolutionary multiobjective optimization using reference points\n", "abstract": " The ultimate goal of multiobjective optimization is to help a decision maker (DM) identify solution(s) of interest (SOI) achieving satisfactory tradeoffs among multiple conflicting criteria. This can be realized by leveraging DM\u2019s preference information in evolutionary multiobjective optimization (EMO). No consensus has been reached on the effectiveness brought by incorporating preference in EMO (either  a priori  or  interactively ) versus  a posteriori  decision making after a complete run of an EMO algorithm. Bearing this consideration in mind, this article: 1) provides a pragmatic overview of the existing developments of preference-based EMO (PBEMO) and 2) conducts a series of experiments to investigate the effectiveness brought by preference incorporation in EMO for approximating various SOI. In particular, the DM\u2019s preference information is elicited as a reference point, which represents her/his aspirations for\u00a0\u2026", "num_citations": "19\n", "authors": ["537"]}
{"title": "Solving Japanese puzzles with heuristics\n", "abstract": " This paper presents two heuristics algorithms to solve Japanese puzzles, both black and white puzzles and color puzzles. First, we present ad-hoc heuristics which use the information in rows, columns, and puzzle's constraints to obtain the solution of the puzzle. The best heuristic developed for black and white puzzles is then extended to solving color Japanese puzzles. We show the performance of the proposed heuristics in several examples from a well known Web page devoted to this kind of puzzles. Comparison with an existing solver based on constraint programming and with a genetic algorithm is carried out", "num_citations": "19\n", "authors": ["537"]}
{"title": "Non-standard cost terminal assignment problems using tabu search approach\n", "abstract": " Terminal assignment (TA) is important in increasing the telecommunication networks' capacity and reducing the cost of it. We propose a tabu search (TS) approach to solve the problem with non-standard cost functions. A greedy decoding approach is used to generate the initial solution and then an effective and unique search approach is proposed to produce the neighborhood, which exchange one of the terminals in each concentrator to improve the quality of solution. Simulation results with the proposed TS approach are compared with those using genetic and greedy algorithms. Computer simulations show that our approach achieves very good results in solving this problem.", "num_citations": "19\n", "authors": ["537"]}
{"title": "Artificial speciation of neural network ensembles\n", "abstract": " Modular approach of solving a complex problem can reduce the total complexity of the system while solving a difficult problem satisfactorily. To implement this idea, an EANN system is developed here for classifying data. The system evolved is speciated in such a manner that members of a particular species solve certain parts of the problem and complement each other in solving one big problem. Fitness sharing is used in evolving the group of ANNs to achieve the required speciation. Sharing was performed at phenotypic level using modified Kullback-Leibler entropy as the distance measure. Since the group as a unit solves the classification problem, outputs of all the ANNs are used in finding the final output. For the combination of ANN outputs 3 different methods\u2013Voting, averaging and recursive least square are used. The evolved system is tested on two data classification problems (Heart Disease Dataset and Breast Cancer Dataset) taken from UCI machine learning benchmark repository.", "num_citations": "19\n", "authors": ["537"]}
{"title": "Solving real-world lecture room assignment problems by genetic algorithms\n", "abstract": " This paper proposes a genetic algorithm-based approach to the lecture room assignment problem (LRAP). A two-dimensional chromosome representation is used in our genetic algorithm, which employs a column-based crossover operator in order to preserve potential\" building blocks\". Our algorithm has been tested on a real-world case at the Australian Defence Force Academy where the lecture room assignment is currently done by a human domain expert. Our experimental results show that the GA results are better than those produced by the expert using the same set of constraints and criteria.", "num_citations": "19\n", "authors": ["537"]}
{"title": "SNR-constrained heuristics for optimizing the scaling parameter of robust audio watermarking\n", "abstract": " In spread spectrum (SS) based robust audio watermarking, the scaling parameter is an important factor for balancing between robustness and imperceptibility. There have been intense studies of the embedded parameter optimization in light of the signal-to-noise ratio (SNR), but little attention has been given to the constrained SNR. Moreover, traditional population-based stochastic search algorithms for optimizing the embedded parameter significantly increase the computation pressure of the corresponding audio watermarking schemes. This paper comprehensively investigates the effect of the constrained SNR on the optimization of the scaling parameter, from both model and algorithmic perspectives. Specifically, the empirical relationship between the scaling parameter, robustness, and imperceptibility is first analyzed in detail. Next, an SNR-constrained optimization model is presented. Then, to solve the\u00a0\u2026", "num_citations": "18\n", "authors": ["537"]}
{"title": "A cluster-based semisupervised ensemble for multiclass classification\n", "abstract": " Semisupervised classification (SSC) algorithms use labeled and unlabeled data to predict labels of unseen instances. Classifier ensembles have been successfully studied and employed as a SSC approach. However, the generalization of existing semisupervised ensembles can be strongly affected by incorrect label estimates produced by ensemble algorithms in order to train supervised base learners. These ensembles do not optimize the objective function present in their base learners, which causes their supervised base classifiers to be sensitive to incorrect labeling and to reinforce errors during training. We propose cluster-based boosting (CBoost), a multiclass classification algorithm with cluster regularization. In contrast to existing algorithms, CBoost and its base learners jointly perform a cluster-based semisupervised optimization, which allows base classifiers to overcome potential incorrect label estimates\u00a0\u2026", "num_citations": "18\n", "authors": ["537"]}
{"title": "Knowledge-based particle swarm optimization for PID controller tuning\n", "abstract": " A proportional-integral-derivative (PID) controller is a control loop feedback mechanism widely employed in industrial control systems. The parameters tuning is a sticking point, having a great effect on the control performance of a PID system. There is no perfect rule for designing controllers, and finding an initial good guess for the parameters of a well-performing controller is difficult. In this paper, we develop a knowledge-based particle swarm optimization by incorporating the dynamic response information of PID into the optimizer. Prior knowledge not only empowers the particle swarm optimization algorithm to quickly identify the promising regions, but also helps the proposed algorithm to increase the solution precision in the limited running time. To benchmark the performance of the proposed algorithm, an electric pump drive and an automatic voltage regulator system are selected from industrial applications. The\u00a0\u2026", "num_citations": "18\n", "authors": ["537"]}
{"title": "QoS-aware long-term based service composition in cloud computing\n", "abstract": " Cloud service composition problem (CSCP) is usually long-term based in practice. A logical request is to maximize end users' long-term benefit. Thus, the overall long-term QoS properties of the composite service should be optimized and the users' requirements during the period should be satisfied. However, the benefit-maximization has not been considered under the background of long-term based CSCP in existing research yet. To fill this gap, in this paper, a new formulation LCSCP is proposed to define the long-term based CSCP as an optimization problem. Then, for the sake of efficiency, three meta-heuristic approaches (i.e, Genetic Algorithm, Simulated Annealing and Tabu Search) are studied. Comprehensive experiments are designed and conducted to test their various aspects of performance on different test sets with different workflows. Experimental results provide a basic perspective of how these three\u00a0\u2026", "num_citations": "18\n", "authors": ["537"]}
{"title": "Variable neighborhood decomposition for large scale capacitated arc routing problem\n", "abstract": " In this paper, a Variable Neighborhood Decomposition (VND) is proposed for Large Scale Capacitated Arc Routing Problems (LSCARP). The VND employs the Route Distance Grouping (RDG) scheme, which is a competitive decomposition scheme for LSCARP, and generates different neighborhood structures with different tradeoffs between exploration and exploitation. The search first uses a neighborhood structure that is considered to be the most promising, and then broadens the neighborhood gradually as it is getting stuck in a local optimum. The experimental studies show that the VND performed better than the state-of-the-art RDG-MAENS counterpart, and the improvement is more significant when the subcomponent size is smaller. This implies a great potential of combining the VND with small subcomponents.", "num_citations": "18\n", "authors": ["537"]}
{"title": "Frequency fitness assignment\n", "abstract": " Metaheuristic optimization procedures such as evolutionary algorithms are usually driven by an objective function that rates the quality of a candidate solution. However, it is not clear in practice whether an objective function adequately rewards intermediate solutions on the path to the global optimum and it may exhibit deceptiveness, epistasis, neutrality, ruggedness, and a lack of causality. In this paper, we introduce the frequency fitness H, subject to minimization, which rates how often solutions with the same objective value have been discovered so far. The ideas behind this method are that good solutions are difficult to find and that if an algorithm gets stuck at a local optimum, the frequency of the objective values of the surrounding solutions will increase over time, which will eventually allow it to leave that region again. We substitute a frequency fitness assignment process (FFA) for the objective function into\u00a0\u2026", "num_citations": "18\n", "authors": ["537"]}
{"title": "Analysis of premalignant pancreatic cancer mass spectrometry data for biomarker selection using a group search optimizer\n", "abstract": " This paper presents a novel group search optimizer (GSO)-based biomarker discovery method for pancreatic cancer diagnosis using mass spectrometry (MS) data. The GSO was inspired by animal social searching behaviour. It has been shown that the global search performance of the GSO is competitive to other biologically inspired optimization algorithms. In this study, we applied a GSO as a feature selection method to MS data analysis for premalignant pancreatic cancer biomarker discovery. We first applied a smooth non-linear energy operator to detect peaks. Then a GSO with linear discriminant analysis was used to select a parsimonious set of peak windows (biomarkers) that can distinguish cancer. After selecting a set of biomarkers, a support vector machine was then applied to build a classifier to diagnosis premalignant cancer cases. We compared the GSO algorithm with a genetic algorithm, evolution\u00a0\u2026", "num_citations": "18\n", "authors": ["537"]}
{"title": "Unpacking and understanding evolutionary algorithms\n", "abstract": " Theoretical analysis of evolutionary algorithms (EAs) has made significant progresses in the last few years. There is an increased understanding of the computational time complexity of EAs on certain combinatorial optimisation problems. Complementary to the traditional time complexity analysis that focuses exclusively on the problem, e.g., the notion of NP-hardness, computational time complexity analysis of EAs emphasizes the relationship between algorithmic features and problem characteristics. The notion of EA-hardness tries to capture the essence of when and why a problem instance class is hard for what kind of EAs. Such an emphasis is motivated by the practical needs of insight and guidance for choosing different EAs for different problems. This chapter first introduces some basic concepts in analysing EAs. Then the impact of different components of an EA will be studied in depth, including\u00a0\u2026", "num_citations": "18\n", "authors": ["537"]}
{"title": "Improving scheduling techniques in heterogeneous systems with dynamic, on-line optimisations\n", "abstract": " Computational performance increasingly depends on parallelism, and many systems rely on heterogeneous resources such as GPUs and FPGAs to accelerate computationally intensive applications. However, implementations for such heterogeneous systems are often hand-crafted and optimised to one computation scenario, and it can be challenging to maintain high performance when application parameters change. In this paper, we demonstrate that machine learning can help to dynamically choose parameters for task scheduling and load-balancing based on changing characteristics of the incoming workload. We use a financial option pricing application as a case study. We propose a simulation of processing financial tasks on a heterogeneous system with GPUs and FPGAs, and show how dynamic, on-line optimisations could improve such a system. We compare on-line and batch processing algorithms, and\u00a0\u2026", "num_citations": "18\n", "authors": ["537"]}
{"title": "Solving dynamic constrained optimisation problems using repair methods\n", "abstract": " It has been shown that (i) dynamic constrained optimisation problems (DCOPs), a very common class of problems in real-world applications, have some special characteristics that make them very different from unconstrained dynamic problems and stationary constrained problems and (ii) some existing dynamic optimisation (DO) and constraint handling (CH) algorithms might not work effectively in solving DCOPs. The ineffectiveness of existing algorithms in solving DCOPs, and the lack of algorithms specificaly designed for solving continuous DCOPs create an important gap in current research about DO. In this paper, we propose a set of new mechanisms to effectively handle dynamics in DCOPs and use them to develop new algorithms for solving DCOPs. The goal is to combine the advantages of DO and CH strategies while overcoming the drawbacks of these methods in solving DCOPs. To evaluate the performance of the new algorithms, we compare them against several representative DO and CH algorithms using a set of new performance measures and a set of 18 benchmark problems, which were designed to simulate the characteristics of DCOPs. The test results confirm the advantages of the newly proposed mechanisms and algorithms. Not only do they overcome all existing drawbacks and hence perform significantly better than the tested existing algorithms in solving DCOPs, they also perform equally to or better than these existing DO and CH algorithms in other groups of tested problems except in static problems.In this paper we also (i) carry out detailed analyses of how and why the newly proposed mechanisms/algorithms work\u00a0\u2026", "num_citations": "18\n", "authors": ["537"]}
{"title": "Robust salting route optimization using evolutionary algorithms\n", "abstract": " In winter, roads need to be salted and gritted when temperature drops to around the freezing point, in order to ensure the safety of road users (especially motor vehicles). In the UK, there are approximately 3000 salting routes covering about 120,000 km (approximately 30% of the road network). Given limited resources and severe time constraints, it is imperative that salting routes are planned in advance for efficient and effective treatment. Unfortunately, there is no automatic route optimization system for salting trucks that can deal with different road conditions and constraints. Almost all published systems make unrealistic assumptions that do not hold in practice. This chapter describes a novel route optimization system based on newly proposed memetic algorithms. The system is designed with dynamic problems in mind. That is, given different road temperatures and different temperature distributions in a road\u00a0\u2026", "num_citations": "18\n", "authors": ["537"]}
{"title": "Computational neuronal oscillations using morlet wavelet transform\n", "abstract": " This paper introduces the use of a new tool based on Morlet wavelet transform to detect the interaction dynamics between two neuronal population oscillations. This toolbox can describe the power spectrum, cross wavelet transform, coherence, bi-coherence, cross phase angle and phase synchronization of two neuronal oscillations. Through a case study of focus epilepsy model, a linear and nonlinear correlation between the neuronal oscillations in the CA1 and CA3 of rat hippocampus are computed. The results show that the tool can be directly applied to analyze and quantify the instantaneous interaction of two neuronal oscillations, which could be a helpful tool to analyze and understand the mechanism of epileptic seizure in EEG recordings", "num_citations": "18\n", "authors": ["537"]}
{"title": "Application of fuzzy similarity to prediction of epileptic seizures using EEG signals\n", "abstract": " The prediction of epileptic seizures is a very attractive issue for all patients suffering from epilepsy in EEG (electroencephalograph) signals. It can assist to develop an intervention system to control / prevent upcoming seizures and change the current treatment method of epilepsy. This paper describes a new method based on wavelet transform and fuzzy similarity measurement to predict the seizures by using EEG signals. One part of the method is to calculate the energy and entropy of EEG data at the different scale; another part of this method is to calculate the similarity between the features set of the reference segment and the test segment using fuzzy measure. The test results of real rats show this method detect temporal dynamic changes prior to a seizure in real time.", "num_citations": "18\n", "authors": ["537"]}
{"title": "Learning and evolution by minimization of mutual information\n", "abstract": " Based on negative correlation learning [1] and evolutionary learning, evolutionary ensembles with negative correlation learning (EENCL) was proposed for learning and designing of neural network ensembles [2]. The idea of EENCL is to regard the population of neural networks as an ensemble, and the evolutionary process as the design of neural network ensembles. EENCL used a fitness sharing based on the covering set. Such fitness sharing did not make accurate measurement on the similarity in the population. In this paper, a fitness sharing scheme based on mutual information is introduced in EENCL to evolve a diverse and cooperative population. The effectiveness of such evolutionary learning approach was tested on two real-world problems. This paper has also analyzed negative correlation learning in terms of mutual information on a regression task in the different noise conditions.", "num_citations": "18\n", "authors": ["537"]}
{"title": "Lamarckian evolution in global optimization\n", "abstract": " Lamarckian evolution explains how an individual's ability of learning can help to guide the evolutionary process. Performing a local search is regarded as a learning process for an individual. We propose the concept of re-learning based on Lamarckian evolution. After all individuals have learned, the local search information is then collected for a second learning process using approximation techniques. Under the situation of using quadratic approximation, we mathematically analyze the basic algorithm developed under this concept. We also develop a novel algorithm based on the basic algorithm and the analysis results. The experimental results show that the algorithm can provide a more reliable and efficient performance on high dimensional multimodal problems.", "num_citations": "18\n", "authors": ["537"]}
{"title": "Exploiting coalition in co-evolutionary learning\n", "abstract": " Adaptive behaviors often emerge through interactions between adjacent neighbors in dynamic systems, such as social and economic systems. In many cases, an individual's behavior can be modeled by a stimulus-response system in a dynamic environment. In this paper, we use the iterated prisoner's dilemma (IPD) game, which is simple yet capable of dealing with complex problems, to model a dynamic system such as social or economic systems. We investigate coalitions consisting of many players and their emergence in a co-evolutionary learning environment. We introduce the concept of confidence for players in a coalition and show how such confidences help to improve the generalization ability of the whole coalition. Experimental results are presented to demonstrate that co-evolutionary learning with coalitions and player confidences can produce IPD game-playing strategies that generalize well.", "num_citations": "18\n", "authors": ["537"]}
{"title": "Maximizing submodular or monotone approximately submodular functions by multi-objective evolutionary algorithms\n", "abstract": " Evolutionary algorithms (EAs) are a kind of nature-inspired general-purpose optimization algorithm, and have shown empirically good performance in solving various real-word optimization problems. During the past two decades, promising results on the running time analysis (one essential theoretical aspect) of EAs have been obtained, while most of them focused on isolated combinatorial optimization problems, which do not reflect the general-purpose nature of EAs. To provide a general theoretical explanation of the behavior of EAs, it is desirable to study their performance on general classes of combinatorial optimization problems. To the best of our knowledge, the only result towards this direction is the provably good approximation guarantees of EAs for the problem class of maximizing monotone submodular functions with matroid constraints. The aim of this work is to contribute to this line of research\u00a0\u2026", "num_citations": "17\n", "authors": ["537"]}
{"title": "Cooperative co-evolution-based design optimization: A concurrent engineering perspective\n", "abstract": " As a well-known engineering practice, concurrent engineering (CE) considers all elements involved in a product's life cycle from the early stages of product development, and emphasizes executing all design tasks simultaneously. As a result, there exist various complex design problems in CE, which usually have many design parameters or require different disciplinary knowledge to solve them. To address these problems and enable concurrent design, different methods have been developed. The original problem is usually divided into small subproblems so that each subproblem can be solved individually and simultaneously. However, good decomposition, optimization, and communication strategies among subproblems are still needed in the field of CE. This paper attempts to study and analyze cooperative co-evolution (CC) based design optimization in CE by employing a parallel CC framework. Furthermore\u00a0\u2026", "num_citations": "17\n", "authors": ["537"]}
{"title": "Multiobjective optimization for interwoven systems\n", "abstract": " In practical situations, complex systems are often composed of subsystems or subproblems with single or multiple objectives. These subsystems focus on different aspects of the overall system, but they often have strong interactions with each other and they are usually not sequentially ordered or obviously decomposable. Thus, the individual solutions of subproblems do not generally induce a solution for the overall system. Here, we strive to identify \u201cre\u2010composition architectures\u201d of such \u201cinterwoven\u201d systems. Our intention is to connect the subsystems adequately, analyze the resulting performance, model/solve the overall system, and improve the overall solution instead of just solving each subsystem separately. We review recent developments in this field and discuss modeling and solution paradigms in a general and unified framework using the example of an interwoven system consisting of two interacting\u00a0\u2026", "num_citations": "17\n", "authors": ["537"]}
{"title": "Decomposing large-scale capacitated arc routing problems using a random route grouping method\n", "abstract": " In this paper, a simple but effective Random Route Grouping (RRG) scheme is developed to decompose the LargeScale Capacitated Arc Routing Problem (LSCARP). A theoretical analysis is given to show that the decomposition is guaranteed to be improved by RRG along with the improvement of the best-sofar solution during the search process. Then, RRG is combined with a cooperative co-evolution model to solve LSCARP. The experimental results on the EGL-G LSCARP set showed that given the same computational budget, the proposed approach obtained much better results than its counterpart without using decomposition.", "num_citations": "17\n", "authors": ["537"]}
{"title": "Evolutionary dynamic optimization: methodologies\n", "abstract": " In recent years, Evolutionary Dynamic Optimization (EDO) has attracted a lot of research effort and has become one of the most active research areas in evolutionary computation (EC) in terms of the number of activities and publications. This chapter provides a summary of main EDO approaches in solving DOPs. The strength and weakness of each approach and their suitability for different types of DOPs are discussed. Current gaps, challenging issues and future directions regarding EDO methodolgies are also presented.", "num_citations": "17\n", "authors": ["537"]}
{"title": "Evolving Functional Symmetry in a Three Dimensional Model of an Elongated Organism.\n", "abstract": " In evolutionary\u2013developmental biology, it is well established that neural organization is coupled to a given organism\u2019s body-plan. Many theories attempt to underpin this coupling and the transitions involved during the organism\u2019s evolution, for example the transition from radial to bilateral symmetry. Before theoretically tackling these transitions however, we felt it essential to first address, in this paper, precisely why bilateral symmetry might be advantageous for a simple eel-like agent. We find that neural architectures affording the best motor-coordinated behavior (architectures that allow directional swimming of the agent), will readily emerge in a way that is functionally\u2013bilaterally symmetric, suggesting therefore, that bilaterally symmetrical emergence for a long elongated creature can be essential if it needs to travel over some distance.", "num_citations": "17\n", "authors": ["537"]}
{"title": "A parallel divide-and-conquer-based evolutionary algorithm for large-scale optimization\n", "abstract": " Large-scale optimization problems that involve thousands of decision variables have extensively arisen from various industrial areas. As a powerful optimization tool for many real-world applications, evolutionary algorithms (EAs) fail to solve the emerging large-scale problems both effectively and computationally efficiently. In this paper, we propose a novel Divide-and-Conquer (DC) based EA that can not only produce high-quality solutions by solving sub-problems separately, but also benefits significantly from the power of parallel computing by solving the sub-problems simultaneously. Existing DC-based EAs that were thought to enjoy the same advantages of the proposed algorithm, are shown to be practically incompatible with the parallel computing scheme, unless some trade-offs are made by compromising the solution quality.", "num_citations": "16\n", "authors": ["537"]}
{"title": "Parallel population-based algorithm portfolios: An empirical study\n", "abstract": " Although many algorithms have been proposed, no single algorithm is better than others on all types of problems. Therefore, the search characteristics of different algorithms that show complementary behavior can be combined through portfolio structures to improve the performance on a wider set of problems. In this work, a portfolio of the Artificial Bee Colony, Differential Evolution and Particle Swarm Optimization algorithms was constructed and the first parallel implementation of the population-based algorithm portfolio was carried out by means of a Message Passing Interface environment. The parallel implementation of an algorithm or a portfolio can be performed by different models such as master-slave, coarse-grained or a hybrid of both, as used in this study. Hence, the efficiency and running time of various parallel implementations with different parameter values and combinations were investigated on\u00a0\u2026", "num_citations": "16\n", "authors": ["537"]}
{"title": "Variable interaction in multi-objective optimization problems\n", "abstract": " Variable interaction is an important aspect of a problem, which reflects its structure, and has implications on the design of efficient optimization algorithms. Although variable interaction has been widely studied in the global optimization community, it has rarely been explored in the multi-objective optimization literature. In this paper, we empirically and analytically study the variable interaction structures of some popular multi-objective benchmark problems. Our study uncovers nontrivial variable interaction structures for the ZDT and DTLZ benchmark problems which were thought to be either separable or non-separable.", "num_citations": "16\n", "authors": ["537"]}
{"title": "Homogeneous and heterogeneous island models for the set cover problem\n", "abstract": " We propose and analyse two island models that provably find good approximations for the SetCover problem. A homogeneous island model running parallel instances of the SEMO algorithm\u2014following Friedrich et al. (Evolutionary Computation 18(4), 2010, 617-633)\u2014leads to significant speedups over a single SEMO instance, but at the expense of large communication costs. A heterogeneous island model, where each island optimises a different single-objective fitness function, provides similar speedups at reduced communication costs. We compare different topologies for the homogeneous model and different migration policies for the heterogeneous one.", "num_citations": "16\n", "authors": ["537"]}
{"title": "Immigrant schemes for evolutionary algorithms in dynamic environments: Adapting the replacement rate\n", "abstract": " One approach for evolutionary algorithms (EAs) to address dynamic optimization problems (DOPs) is to maintain diversity of the population via introducing immigrants. So far all immigrant schemes developed for EAs have used fixed replacement rates. This paper examines the impact of the replacement rate on the performance of EAs with immigrant schemes in dynamic environments, and proposes a self-adaptive mechanism for EAs with immigrant schemes to address DOPs. Our experimental study showed that the new approach could avoid the tedious work of fine-tuning the parameter and outperformed other immigrant schemes using a fixed replacement rate with traditionally suggested values in most cases.", "num_citations": "16\n", "authors": ["537"]}
{"title": "Evolutionary market agents for resource allocation in decentralised systems\n", "abstract": " We introduce self-interested evolutionary market agents, which act on behalf of service providers in a large decentralised system, to adaptively price their resources over time. Our agents competitively co-evolve in the live market, driving it towards the Bertrand equilibrium, the non-cooperative Nash equilibrium, at which all sellers charge their reserve price and share the market equally. We demonstrate that this outcome results in even load-balancing between the service providers.               Our contribution in this paper is twofold; the use of on-line competitive co-evolution of self-interested service providers to drive a decentralised market towards equilibrium, and a demonstration that load-balancing behaviour emerges under the assumptions we describe.               Unlike previous studies on this topic, all our agents are entirely self-interested; no cooperation is assumed. This makes our problem a non-trivial\u00a0\u2026", "num_citations": "16\n", "authors": ["537"]}
{"title": "Evolving cooperation in the non-iterated prisoner\u2019s dilemma: A social network inspired approach\n", "abstract": " Online service provision is becoming increasingly decentralized as system designers pursue the benefits gained from utilizing nodes at the periphery of the network. However, distributing control means relying on the cooperation of participating agents, and it is a significant challenge to design mechanisms that incentivise optimal global behavior in a population of selfish, rational agents. This is particularly evident in peer-to-peer file-sharing, where a high incidence of selfish behavior in the form of downloading without uploading, leads to the network losing the benefits of a decentralized network. In this paper a notion of reputation based on simple social network analysis is used to significantly improve cooperation rates in the one-shot game of prisoner's dilemma, where without such a technique the dominant strategy would be for all agents to defect.", "num_citations": "16\n", "authors": ["537"]}
{"title": "Evolutionary computation benchmarking repository [Developmental Tools]\n", "abstract": " Evolutionary computation has been used with great success for the solution of hard optimization problems. Theoretical analysis, although important in its own right, e.g. for understanding underlying phenomena and characteristics of evolutionary search, can only provide upper and/or lower bounds of performance estimation of evolutionary algorithms for hard optimization problems. In practice, empirical analysis is the most important means to assess and compare the performance of algorithms. In order to facilitate this fair and transparent comparison, the Evolutionary Computation Benchmarking Repository (EvoCoBR) by M. Roberts et al. (2006) has been designed and put into operation in a beta version and trial phase. The aim is to create a central Web-based repository for storing detailed benchmark problem descriptions. However, with EvoCoBR we want to go one step further and archive, along with the problem\u00a0\u2026", "num_citations": "16\n", "authors": ["537"]}
{"title": "A novel memetic algorithm with random multi-local-search: A case study of TSP\n", "abstract": " Memetic algorithms (MAs) have been shown to be very effective in finding near optimal solutions to hard combinatorial optimization problems. We propose a novel memetic algorithm (MsMA), in which a new local search scheme is introduced. We called this local search scheme as random multi-local-search (MLS). The MLS is composed of several local search schemes, each of which executes with a predefined probability to increase the diversity of the population. The combination of MsMA with the crossover operator edge assembly crossover (EAX) on the classic combinatorial optimization problem traveling salesman problem (TSP) is studied, and comparisons are also made with some best known MAs. We have found that it is significantly outperforming the known MAs on almost all of the selected instances. Furthermore, we have proposed a new crossover named M-EAX, which has more powerful local search\u00a0\u2026", "num_citations": "16\n", "authors": ["537"]}
{"title": "Negatively correlated neural networks for classification\n", "abstract": " This paper presents a new algorithm for designing neural network ensembles for classification problems with noise. The idea behind this new algorithm is to encourage different individual networks in an ensemble to learn different parts or aspects of the training data so that the whole ensemble can learn the whole training data better. Negatively correlated neural networks are trained with a novel correlation penalty term in the error function to encourage such specialization. In our algorithm, individual networks are trained simultaneously rather than independently or sequentially. This provides an opportunity for different networks to interact with each other and to specialize. Experiments on two real-world problems demonstrate that the new algorithm can produce neural network ensembles with good generalization ability.", "num_citations": "16\n", "authors": ["537"]}
{"title": "Automatic acquisition of strategies by co-evolutionary learning\n", "abstract": " Co-evolutionary learning is a new learning approach emerged in recent years. It is designed to deal with dynamic learning tasks, ie, the target to be learned changes over time. Such learning problems are particularly di cult to solve by traditional machine learning methods. This paper studies coevolutionary learning, identi es its strength and weakness, and presents some experimental results using the N-player Iterated Prisoner's Dilemma game (NIPD). The paper also investigates the impact of group size N on the evolution of strategies and generalisation issue in co-evolutionary learning.", "num_citations": "16\n", "authors": ["537"]}
{"title": "Comparison of different neighbourhood sizes in simulated annealing\n", "abstract": " Neighbourhood structure and size are important parameters in local search algorithms. This is also true for generalised local search algorithms like simulated annealing. It has been shown that the performance of simulated annealing can be improved by adopting a suitable neighbourhood size. However, previous studies usually assumed that the neighbourhood size was xed during search. This paper presents a simulated annealing algorithm with a dynamic neighbourhood size which depends on the current\\temperature\" value during search. A method of dynamically deciding the neighbourhood size by approximating a continuous probability distribution is given. Four continuous probability distributions are used in our experiments to generate neighbourhood sizes dynamically, and the results are compared.", "num_citations": "16\n", "authors": ["537"]}
{"title": "A learning-to-rank algorithm for constructing defect prediction models\n", "abstract": " This paper applies the learning-to-rank approach to software defect prediction. Ranking software modules in order of defect-proneness is important to ensure that testing resources are allocated efficiently. However, prediction models that are optimized for predicting explicitly the number of defects often fail to correctly predict rankings based on those defect numbers. We show in this paper that the model construction methods, which include the ranking performance measure in the objective function, perform better in predicting defect-proneness rankings of multiple modules. We present the experimental results, in which our method is compared against three other methods from the literature, using five publicly available data sets.", "num_citations": "15\n", "authors": ["537"]}
{"title": "Runtime analysis of search heuristics on software engineering problems\n", "abstract": " Many software engineering tasks can potentially be automated using search heuristics. However, much work is needed in designing and evaluating search heuristics before this approach can be routinely applied to a software engineering problem. Experimental methodology should be complemented with theoretical analysis to achieve this goal. Recently, there have been significant theoretical advances in the runtime analysis of evolutionary algorithms (EAs) and other search heuristics in other problem domains. We suggest that these methods could be transferred and adapted to gain insight into the behaviour of search heuristics on software engineering problems while automating software engineering.", "num_citations": "15\n", "authors": ["537"]}
{"title": "Analysis of scalable parallel evolutionary algorithms\n", "abstract": " Inherent parallelism is regarded as one of the most important advantages of evolutionary algorithms. This paper aims at making an initial study on the speedup of scalable parallel evolutionary algorithms. First the scalable parallel evo lutionary algo rithms are described; then the speedup of such scalable algorithms is defined based on the first hitting time; Using the new definition, the relationship between population diversity and superlinear speedup is analyzed; finally a case study demonstra tes how population diversity plays a crucial role in generating the superlinear speedup.", "num_citations": "15\n", "authors": ["537"]}
{"title": "Volatility forecasting with sparse bayesian kernel models\n", "abstract": " Motivated by previous findings that discretization of financial time series can effectively filter the data and reduce the noise, this experimental study, performed in a realistic setting of trading straddles via predicting volatility, compares trading performances of symbol-based models with those of probabilistic models operating on real-valued sequences. We show that carefully designed probabilistic models trained in a Bayesian framework of automatic relevance determination can achieve superior trading performances.", "num_citations": "15\n", "authors": ["537"]}
{"title": "Time complexity analysis of an evolutionary algorithm for finding nearly maximum cardinality matching\n", "abstract": " Most of works on the time complexity analysis of evolutionary algorithms have always focused on some artificial binary problems The time complexity of the algorithms for combinatorial optimisation has not been well understood. This paper considers the time complexity of an evolutionary algorithm for a classical combinatorial optimisation problem, to find the maximum cardinality matching in a graph. It is shown that the evolutionary algorithm can produce, a matching with nearly maximum cardinality in average polynomial time.", "num_citations": "15\n", "authors": ["537"]}
{"title": "Solving cutting stock problems by evolutionary programming\n", "abstract": " Evolutionary algorithms (EAs) have been applied to many optimisation problems successfully in recent years. The genetic algorithm (GA) and evolutionary programming (EP) are two of the major branches of EAs. GAs use crossover as the main search operator and mutation as a background operator in search. EP typically uses mutation only. This paper investigates a novel EP algorithm for cutting stock problems. It adopts a mutation operator based on the concept of distance between a parent and its offspring. Without using crossover, the algorithm is less time consuming and more efficient in comparison with a GA-based approach. Experimental studies have been carried out to examine the effectiveness of the EP algorithm. They illustrate that EP can provide a simple yet more efficient alternative to GAs in solving some combinatorial optimisation problems.", "num_citations": "15\n", "authors": ["537"]}
{"title": "Self-aware and self-expressive systems\n", "abstract": " Systems that gather unpredictable input data while responding and self-adapting in uncertain environments are transforming our relationship with and use of computers. This issue of Computer explores a variety of approaches and applications for such systems.", "num_citations": "14\n", "authors": ["537"]}
{"title": "Adaptive, dynamic, and resilient systems\n", "abstract": " As the complexity of today\u2019s networked computer systems grows, they become increasingly difficult to understand, predict, and control. Addressing these challenges requires new approaches to building these systems. Adaptive, Dynamic, and Resilient Systems supplies readers with various perspectives of the critical infrastructure that systems of networked computers rely on. It introduces the key issues, describes their interrelationships, and presents new research in support of these areas. The book presents the insights of a different group of international experts in each chapter. Reporting on recent developments in adaptive systems, it begins with a survey of application fields. It explains the requirements of such fields in terms of adaptation and resilience. It also provides some abstract relationship graphs that illustrate the key attributes of distributed systems to supply you with a better understanding of these factors and their dependencies. The text examines resilient adaptive systems from the perspectives of mobile, infrastructure, and enterprise systems and protecting critical infrastructure. It details various approaches for building adaptive, dynamic, and resilient systems\u2014including agile, grid, and autonomic computing; multi-agent-based and biologically inspired approaches; and self-organizing systems. The book includes many stories of successful applications that illustrate a diversified range of cutting-edge approaches. It concludes by covering related topics and techniques that can help to boost adaptation and resilience in your systems.", "num_citations": "14\n", "authors": ["537"]}
{"title": "Non\u2013uniform layered clustering for ensemble classifier generation and optimality\n", "abstract": " In this paper we present an approach to generate ensemble of classifiers using non\u2013uniform layered clustering. In the proposed approach the dataset is partitioned into variable number of clusters at different layers. A set of base classifiers is trained on the clusters at different layers. The decision on a pattern at each layer is obtained from the classifier trained on the nearest cluster and the decisions from the different layers are fused using majority voting to obtain the final verdict. The proposed approach provides a mechanism to obtain the optimal number of layers and clusters using a Genetic Algorithm. Clustering identifies difficult\u2013to\u2013classify patterns and layered non\u2013uniform clustering approach brings in diversity among the base classifiers at different layers. The proposed method performs relatively better than the other state\u2013of\u2013art ensemble classifier generation methods as evidenced from the\u00a0\u2026", "num_citations": "14\n", "authors": ["537"]}
{"title": "Comparing design of experiments and evolutionary approaches to multi-objective optimisation of sensornet protocols\n", "abstract": " The lifespan, and hence utility, of sensornets is limited by the energy resources of individual motes. Network designers seek to maximise energy efficiency while maintaining an acceptable network quality of service. However, the interactions between multiple tunable protocol parameters and multiple sensornet performance metrics are generally complex and unknown. In this paper we address this multi-dimensional optimisation problem by two distinct approaches. Firstly, we apply a Design Of Experiments approach to obtain a generalised linear interaction model, and from this derive an estimated near-optimal solution. Secondly, we apply the Two-Archive evolutionary algorithm to improve solution quality for a specific problem instance. We demonstrate that, whereas the first approach yields a more generally applicable solution, the second approach yields a broader range of viable solutions at potentially lower\u00a0\u2026", "num_citations": "14\n", "authors": ["537"]}
{"title": "Greedy forward selection algorithms to sparse gaussian process regression\n", "abstract": " This paper considers the basis vector selection issue invloved in forward selection algorithms to sparse Gaussian Process Regression (GPR). Firstly, we re-examine a previous basis vector selection criterion proposed by Smola and Bartlett [20], referred as loss-smola and give some new formulae to implement this criterion for the full-greedy strategy more efficiently in  O (n 2 k max ) time instead of the original  O (n 2 k 2   max ), where n is the number of training examples and kmax Lt n is the maximally allowed number of selected basis vectors. Secondly, in order to make the algorithm linearly scaling in n, which is quite preferable for large datasets, we present an approximate version loss-sun to loss-smola criterion. We compare the full greedy algorithms induced by the loss-sun and loss-smola criteria, respectively, on several medium-scale datasets. In contrast to loss-smola, the advantage associated with loss-sun\u00a0\u2026", "num_citations": "14\n", "authors": ["537"]}
{"title": "Current developments and future directions of bio-inspired computation and implications for ecoinformatics\n", "abstract": " Evolutionary and neural computation has been used widely in solving various problems in biological ecosystems. This paper reviews some of the recent work in evolutionary computation and neural network ensembles that could be explored further in the context of ecoinformatics. Although these bio-inspired techniques were not developed specifically for ecoinformatics, their successes in solving complex problems in other fields demonstrate how these techniques could be adapted and used for tackling difficult problems in ecoinformatics. Firstly, we will review our work in modelling and model calibration, which is an important topic in ecoinformatics. Secondly one example will be given to illustrate how coevolutionary algorithms could be used in problem-solving. Thirdly, we will describe our work on neural network ensembles, which can be used for various classification and prediction problems in ecoinformatics\u00a0\u2026", "num_citations": "14\n", "authors": ["537"]}
{"title": "Parallel evolutionary programming\n", "abstract": " This work presents a study of parallel evolutionary programming (EP). The paper is divided into two parts. The first part proposes a concept of parallel EP. Four numerical functions are used to compare the performance between the serial algorithm and the parallel algorithm. In the second part, we apply parallel EP to a more complicated problem - an evolving neural networks problem. The results from this problem show that the parallel version is not only faster than the serial version, but the parallel version also more reliably finds optimal solutions.", "num_citations": "14\n", "authors": ["537"]}
{"title": "The impact of noise on iterated prisoner's dilemma with multiple levels of cooperation\n", "abstract": " Real world dilemma rarely involved just two choices and perfect interactions without mistakes. In extending the realism of the iterated prisoner's evolutionary approaches included intermediate choices or mistakes (noise). This study takes a step further using a coevolving population of neural networks playing the IPD game with both intermediate choices and noise. Several issues will be addressed, which include the evolution of cooperation and the evolutionary stability in the presence of noise and more choices. Our experimental study shows that noise has a negative impact on the evolution of cooperation, but could improve, surprisingly, the evolutionary stability.", "num_citations": "14\n", "authors": ["537"]}
{"title": "Exploiting ensemble diversity for automatic feature extraction\n", "abstract": " We present an automatic method, based on a neural network ensemble, for extracting multiple, diverse and complementary sets of useful classification features from high-dimensional data. We demonstrate the utility of these diverse representations for an image dataset, showing good classification accuracy and a high degree of dimensionality reduction. We then outline a number of possible extensions to the project in an evolutionary computation context.", "num_citations": "14\n", "authors": ["537"]}
{"title": "Evolving SQL queries for data mining\n", "abstract": " This paper presents a methodology for applying the principles of evolutionary computation to knowledge discovery in databases by evolving SQL queries that describe datasets. In our system, the fittest queries are rewarded by having their attributes being given a higher probability of surviving in subsequent queries. The advantages of using SQL queries include their readability for non-experts and ease of integration with existing databases. The evolutionary algorithm (EA) used in our system is very different from existing EAs, but seems to be effective and efficient according to the experiments to date with three different testing data sets.", "num_citations": "14\n", "authors": ["537"]}
{"title": "How to control search step size in fast evolutionary programming\n", "abstract": " This paper investigates three approaches to controlling the search step size in fast evolutionary programming (FEP): the first approach is based on using the different parameters in a Cauchy mutation; the second approach is through mixing different mutation operators; and the third approach is by applying cooperative coevolution in FEP. Experimental studies on some function optimization problems have shown that the three approaches can help FEP find better solutions while FEP maintains its fast convergence rate.", "num_citations": "14\n", "authors": ["537"]}
{"title": "Parallel genetic algorithm on PVM\n", "abstract": " In this paper we describe an implementation of some kinds of parallel genetic algorithms on the PVM. Parallel Virtual Machine, a portable parallel environment. We give details of a genetic algorithm running on many small subpopulations with an occasional identification and exchange of their useful information among subpopulations by means of message-passing functions of PVM. In this work, experiments were done to compare the parallel genetic algorithm and traditional sequential genetic algorithms.", "num_citations": "14\n", "authors": ["537"]}
{"title": "Learning topological representation for networks via hierarchical sampling\n", "abstract": " The topological information is essential for studying the relationship between nodes in a network. Recently, Network Representation Learning (NRL), which projects a network into a low-dimensional vector space, has been shown their advantages in analyzing large-scale networks. However, most existing NRL methods are designed to preserve the local topology of a network and they fail to capture the global topology. To tackle this issue, we propose a new NRL framework, named HSRL, to help existing NRL methods capture both local and global topological information of a network. Specifically, HSRL recursively compresses an input network into a series of smaller networks using a community-awareness compressing strategy. Then, an existing NRL method is used to learn node embeddings for each compressed network. Finally, the node embeddings of the input network are obtained by concatenating the node\u00a0\u2026", "num_citations": "13\n", "authors": ["537"]}
{"title": "Solving transit network design problem using many-objective evolutionary approach\n", "abstract": " In many cities around the world, private vehicles are increasingly causing severe traffic congestion, pollution, and accidents. Public transports have been widely recognized as an effective way to improve urban life. To dissuade citizens from using private vehicles, it is necessary to design a practical, efficient, and economical public bus network. The transit network design problem (TNDP) determines the transit network (i.e., public bus network) for a city. It involves different stakeholders with diverse interests and values. To capture their conflicting expectations, numerous optimization objectives arise naturally. This paper introduces the TNDP as a many-objective optimization problem that generates a diverse set of alternative solutions. We apply several state-of-the-art many-objective evolutionary algorithms for the newly formulated TNDP. To efficiently explore the high-dimensional objective space of the TNDP, we\u00a0\u2026", "num_citations": "13\n", "authors": ["537"]}
{"title": "On multiset selection with size constraints\n", "abstract": " This paper considers the multiset selection problem with size constraints, which arises in many real-world applications such as budget allocation. Previous studies required the objective function f to be submodular, while we relax this assumption by introducing the notion of the submodularity ratios (denoted by \u03b1_f and \u03b2_f). We propose an anytime randomized iterative approach POMS, which maximizes the given objective f and minimizes the multiset size simultaneously. We prove that POMS using a reasonable time achieves an approximation guarantee of max {1-1/e^(\u03b2_f),(\u03b1_f/2)(1-1/e^(\u03b1_f))}. Particularly, when f is submdoular, this bound is at least as good as that of the previous greedy-style algorithms. In addition, we give lower bounds on the submodularity ratio for the objectives of budget allocation. Experimental results on budget allocation as well as a more complex application, namely, generalized influence maximization, exhibit the superior performance of the proposed approach.", "num_citations": "13\n", "authors": ["537"]}
{"title": "Empirical investigations of reference point based methods when facing a massively large number of objectives: First results\n", "abstract": " Multi-objective optimization with more than three objectives has become one of the most active topics in evolutionary multi-objective optimization (EMO). However, most existing studies limit their experiments up\u00a0to 15 or 20 objectives, although they claimed to be capable of handling as many objectives as possible. To broaden the insights in the behavior of EMO methods when facing a massively large number of objectives, this paper presents some preliminary empirical investigations on several established scalable benchmark problems with 25, 50, 75 and 100 objectives. In particular, this paper focuses on the behavior of the currently pervasive reference point based EMO methods, although other methods can also be used. The experimental results demonstrate that the reference point based EMO method can be viable for problems with a massively large number of objectives, given an appropriate choice\u00a0\u2026", "num_citations": "13\n", "authors": ["537"]}
{"title": "Target shape design optimization by evolving B-splines with cooperative coevolution\n", "abstract": " With high reputation in handling non-linear and multi-model problems with little prior knowledge, evolutionary algorithms (EAs) have successfully been applied to design optimization problems as robust optimizers. Since real-world design optimization is often computationally expensive, target shape design optimization problems (TSDOPs) have been frequently used as efficient miniature model to check algorithmic performance for general shape design. There are at least three important issues in developing EAs for TSDOPs, i.e., design representation, fitness evaluation and evolution paradigm. Existing work has mainly focused on the first two issues, in which (1) an adaptive encoding scheme with B-spline has been proposed as a representation, and (2) a symmetric Hausdorff distance based metric has been used as a fitness function. But for the third issue, off-the-shelf EAs were used directly to evolve B-spline\u00a0\u2026", "num_citations": "13\n", "authors": ["537"]}
{"title": "Theoretical study of the relationship between diversity and single-class measures for class imbalance learning\n", "abstract": " This paper presents the theoretical research about the relationship between diversity of classification ensembles and single-class measures that are commonly used in class imbalance learning. Although there have been studies on diversity and its links to overall ensemble accuracy, little work has been done on the impact of diversity on single-class performance measures in class imbalance learning. The study of class imbalance learning is important, because many real-world problems, such as those in medical diagnosis, fraud detection, condition monitoring, etc., have imbalanced classes, where a minority class is usually more important and interesting than the majority class. In order to gain a deeper understanding of ensemble learning for imbalanced classes, this paper studies the impact of diversity on single-class performance measures theoretically and empirically. One of the main objectives of this paper is\u00a0\u2026", "num_citations": "13\n", "authors": ["537"]}
{"title": "Rigorous time complexity analysis of univariate marginal distribution algorithm with margins\n", "abstract": " Univariate Marginal Distribution Algorithms (UMDAs) are a kind of Estimation of Distribution Algorithms (EDAs) which do not consider the dependencies among the variables. In this paper, on the basis of our proposed approach in [1], we present a rigorous proof for the result that the UMDA with margins (in [1] we merely showed the effectiveness of margins) cannot find the global optimum of the TRAPLEADINGONES problem [2] within polynomial number of generations with a probability that is super-polynomially close to 1. Such a theoretical result is significant in sheding light on the fundamental issues of what problem characteristics make an EDA hard/easy and when an EDA is expected to perform well/poorly for a given problem.", "num_citations": "13\n", "authors": ["537"]}
{"title": "Getting most out of evolutionary approaches\n", "abstract": " Evolutionary algorithms (EAs) have been widely used in evolvable hardware. The very term, evolvable hardware, reflects the importance and omnitude of EAs in this field. However, EAs have primarily been used as an optimisation or search tool, which can explore a large and complex space. While success has been demonstrated by EAs in exploring unconventional designs that are hard to reach by human experts, it is interesting to ask the question whether we have fully used all the potentialities of EAs. We argue in this paper that there is rich information in a population which can and should be exploited. The classical approach of evolving the best individual in a population may not be the best one. A truly population-based approach that emphasizes population rather than the best individual can often bring in several important benefits to evolvable hardware, including efficiency, accuracy, adaptiveness, and fault\u00a0\u2026", "num_citations": "13\n", "authors": ["537"]}
{"title": "Solving optimal control problems with a cost changing control by evolutionary algorithms\n", "abstract": " Many mathematical solutions to certain classes of optimal control problems, particularly problems which give rise to 'chattering controls', make some physically unrealistic assumptions in order to solve the problems. These solutions often ignore the cost of changing control and thus fail to give physically realistic results due to the physical reality of this cost in many applications. When this cost is incorporated into the problem, the problem can become very difficult to solve numerically. The paper considers an evolutionary approach to solving optimal control problems which take the cost of changing control into account. A novel chromosome representation and an insert mutation have been proposed and tested against three different problems. The experimental results show that the evolutionary approach is quite competitive in comparison with the existing method based on dynamic programming.", "num_citations": "13\n", "authors": ["537"]}
{"title": "An efficient recursive differential grouping for large-scale continuous problems\n", "abstract": " Cooperative co-evolution (CC) is an efficient and practical evolutionary framework for solving large-scale optimization problems. The performance of CC is affected by the variable decomposition. An accurate variable decomposition can help to improve the performance of CC on solving an optimization problem. The variable grouping methods usually spend many computational resources obtaining an accurate variable decomposition. To reduce the computational cost on the decomposition, we propose an efficient recursive differential grouping (ERDG) method in this article. By exploiting the historical information on examining the interrelationship between the variables of an optimization problem, ERDG is able to avoid examining some interrelationship and spend much less computation than other recursive differential grouping methods. Our experimental results and analysis suggest that ERDG is a competitive\u00a0\u2026", "num_citations": "12\n", "authors": ["537"]}
{"title": "Temperature management for heterogeneous multi-core FPGAs using adaptive evolutionary multi-objective approaches\n", "abstract": " Heterogeneous multi-core FPGAs contain different types of cores, which can improve efficiency when used with an effective online task scheduler. However, it is not easy to find the right cores for tasks when there are multiple objectives or dozens of cores. Inappropriate scheduling may cause hot spots which decrease the reliability of the chip. Given that, our research builds a simulating platform to evaluate all kinds of scheduling algorithms on a variety of architectures. On this platform, we provide an online scheduler which uses multi-objective evolutionary algorithm (EA). Comparing the EA and current algorithms such as Predictive Dynamic Thermal Management (PDTM) and Adaptive Temperature Threshold Dynamic Thermal Management (ATDTM), we find some drawbacks in previous work. First, current algorithms are overly dependent on manually set constant parameters. Second, those algorithms neglect\u00a0\u2026", "num_citations": "12\n", "authors": ["537"]}
{"title": "Evolving exact integer algorithms with genetic programming\n", "abstract": " The synthesis of exact integer algorithms is a hard task for Genetic Programming (GP), as it exhibits epistasis and deceptiveness. Most existing studies in this domain only target few and simple problems or test a small set of different representations. In this paper, we present the (to the best of our knowledge) largest study on this domain to date. We first propose a novel benchmark suite of 20 non-trivial problems with a variety of different features. We then test two approaches to reduce the impact of the negative features: (a) a new nested form of Transactional Memory (TM) to reduce epistatic effects by allowing instructions in the program code to be permutated with less impact on the program behavior and (b) our recently published Frequency Fitness Assignment method (FFA) to reduce the chance of premature convergence on deceptive problems. In a full-factorial experiment with six different loop instructions, TM\u00a0\u2026", "num_citations": "12\n", "authors": ["537"]}
{"title": "Can diversity amongst learners improve online object tracking?\n", "abstract": " We present a novel analysis of the state of the art in object tracking with respect to diversity found in its main component, an ensemble classifier that is updated in an online manner. We employ established measures for diversity and performance from the rich literature on ensemble classification and online learning, and present a detailed evaluation of diversity and performance on benchmark sequences in order to gain an insight into how the tracking performance can be improved.", "num_citations": "12\n", "authors": ["537"]}
{"title": "Neural networks ensembles for short-term load forecasting\n", "abstract": " This paper proposes a new approach for short-term load forecasting based on neural networks ensembling methods. A comparison between traditional statistical linear seasonal model and ANN-based models has been performed on the real-world building load data, considering the utilisation of external data such as the day of the week and building occupancy data. The selected models have been compared to the prediction of hourly demand for the electric power up to 24 hours for a testing week. Both neural networks ensembles achieved lower average and maximum errors than other models. Experiments showed how the introduction of external data had helped the forecasting.", "num_citations": "12\n", "authors": ["537"]}
{"title": "An experimental comparison of ensemble learning methods on decision boundaries\n", "abstract": " This paper presents an experimental comparison on different kinds of neural network ensemble learning methods on a patter classification problems. To summarize, there are three ways of designing neural network ensembles in these methods: independent training, sequential training and simultaneous training. The purpose of such comparison is not only to illustrate the learning behavior of different neural network ensemble learning methods, but also to cast light on how to design more effective neural network ensembles. The experimental results show that the decision boundary of the trained neural network ensemble by negative correlation learning is almost as good as the optimum decision boundary.", "num_citations": "12\n", "authors": ["537"]}
{"title": "Universal approximation by genetic programming\n", "abstract": " Genetic programming (GP) has been applied successfully to many di cult problems. However, little theory is currently available to explain why GP works or does not work for a particular problem. We investigate the power of GP in terms of its approximation capability to arbitrary functions. The relationship between arti cial neural networks (ANNs) and GP is discussed. Such relationship enables us to apply the existing theoretical results in ANNs to GP and show that GP can be a universal approximator. This result shows at least partially why GP is capable of solving some very di cult problems. It also sheds some light on choosing the function set for GP applications.", "num_citations": "12\n", "authors": ["537"]}
{"title": "The importance of maintaining behavioural link between parents and offspring\n", "abstract": " In a study of evolutionary artificial neural networks (Yao and Liu, 1996), it has been argued that a partial training process after an architectural mutation plays an important role in maintaining the behavioural link between parents and their offspring and thus is beneficial to the simulated evolution. This paper investigates the issue further through a number of experiments. The experimental results show that a closer behavioural link between parents and their offspring due to the partial training process does lead to better performance, i.e., evolved ANNs generalise better. The results also illustrate that given a fixed amount of time there is an optimal balance of time between evolution and training (learning).", "num_citations": "12\n", "authors": ["537"]}
{"title": "A hybrid clustering and evolutionary approach for wireless underground sensor network lifetime maximization\n", "abstract": " Wireless Underground Sensor Networks (WUSNs) have attracted significant interest in recent years because of their applications in various fields. The major difference between WUSNs and terrestrial wireless sensor networks is that their signals travel through multiple layers: soil, air and a medium interface. As communications in heterogeneous channels result in more transmission loss, a solution is to deploy relay nodes to relay traffic from sensors to base stations/sinks. However, this poses several new challenges, including load balancing and transmission loss minimization in heterogeneous environments. This paper considers the problem of deploying relay nodes to prolong network lifetime under load balancing constraints. This problem can be formalized using a Mixed Integer Linear Programming model as a basis to achieve lower bound solutions. We show that the problem is NP-hard as it can be reduced to\u00a0\u2026", "num_citations": "11\n", "authors": ["537"]}
{"title": "Bandit-based cooperative coevolution for tackling contribution imbalance in large-scale optimization problems\n", "abstract": " This paper addresses the issue of computational resource allocation within the context of cooperative coevolution. Cooperative coevolution typically works by breaking a problem down into smaller subproblems (or components) and coevolving them in a round-robin fashion, resulting in a uniform resource allocation among its components. Despite its success on a wide range of problems, cooperative coevolution struggles to perform efficiently when its components do not contribute equally to the overall objective value. This is of crucial importance on large-scale optimization problems where such difference are further magnified. To resolve this imbalance problem, we extend the standard cooperative coevolution to a new generic framework capable of learning the contribution of each component using multi-armed bandit techniques. The new framework allocates the computational resources to each component\u00a0\u2026", "num_citations": "11\n", "authors": ["537"]}
{"title": "Semisupervised negative correlation learning\n", "abstract": " Negative correlation learning (NCL) is an ensemble learning algorithm that introduces a correlation penalty term to the cost function of each individual ensemble member. Each ensemble member minimizes its mean square error and its error correlation with the rest of the ensemble. This paper analyzes NCL and reveals that adopting a negative correlation term for unlabeled data is beneficial to improving the model performance in the semisupervised learning (SSL) setting. We then propose a novel SSL algorithm, Semisupervised NCL (SemiNCL) algorithm. The algorithm considers the negative correlation terms for both labeled and unlabeled data for the semisupervised problems. In order to reduce the computational and memory complexity, an accelerated SemiNCL is derived from the distributed least square algorithm. In addition, we have derived a bound for two parameters in SemiNCL based on an analysis of\u00a0\u2026", "num_citations": "11\n", "authors": ["537"]}
{"title": "The future of camera networks: Staying smart in a chaotic world\n", "abstract": " Camera networks become smart when they can interpret video data on board, in order to carry out tasks as a collective, such as target tracking and (re-) identification of objects of interest. Unlike today's deployments, which are mainly restricted to lab settings and highly controlled high-value applications, future smart camera networks will be messy and unpredictable. They will operate on a vast scale, drawing on mobile resources connected in networks structured in complex and changing ways. They will comprise heterogeneous and decentralised aggregations of visual sensors, which will come together in temporary alliances, in unforeseen and rapidly unfolding scenarios. The potential to include and harness citizen-contributed mobile streaming, body-worn video, and robot-mounted cameras, alongside more traditional fixed or PTZ cameras, and supported by other non-visual sensors, leads to a number of difficult\u00a0\u2026", "num_citations": "11\n", "authors": ["537"]}
{"title": "A review of concurrent optimisation methods\n", "abstract": " During the past decades, products and their manufacturing processes have become much more complex than before. This has led to complex optimisation problems that require optimising the complicated product development process or the physical aspects of products with respect to a lot of design variables. A common approach to address these problems is to decompose the problem into a number of simpler sub-problems and optimise each sub-problem concurrently. This idea has been investigated in different research fields, including concurrent engineering (CE) and cooperative coevolution (CC). In this paper, main topics in CE and CC are reviewed, and the relationships between CE and CC are discussed along with some potential combinations between them.", "num_citations": "11\n", "authors": ["537"]}
{"title": "Recent advances in evolutionary algorithms for job shop scheduling\n", "abstract": " Scheduling decides the order of tasks to efficiently use resources considering criteria such as minimization of the number of late tasks, minimization of the completion time, minimization of the idle times of the machines, etc. Approaches for solving scheduling problems can be divided into three broad groups: (a) exact methods that produce exact optimal solutions, (b) approximation methods that find high quality near optimal, and (c) hybrid methods based on the first two. Approximate methods can be easily combined with other types of heuristics and can be applied to a wide range of problems.             In the category of approximation algorithms, evolutionary algorithms (EAs) are very promising tools for the problems with dynamic characteristics, contradicting multi-objectives and highly nonlinear constraints. For EAs to be effective and efficient for a combinatorial optimisation problem like scheduling, the\u00a0\u2026", "num_citations": "11\n", "authors": ["537"]}
{"title": "Dynamic combinatorial optimization problems: A fitness landscape analysis\n", "abstract": " The role of representations and variation operators in evolutionary computation is relatively well understood for the case of static optimization problems thanks to a variety of empirical studies as well as some theoretical results. In the field of evolutionary dynamic optimization very few studies exist to date that explicitly analyse the impact of these elements on the algorithm\u2019s performance. In this chapter we utilise the fitness landscape metaphor to review previous work on evolutionary dynamic combinatorial optimization. This review highlights some of the properties unique to dynamic combinatorial optimization problems and paves the way for future research related to these important issues.", "num_citations": "11\n", "authors": ["537"]}
{"title": "On the role of modularity in evolutionary dynamic optimisation\n", "abstract": " The field of evolutionary dynamic optimisation is concerned with the application of evolutionary algorithms to dynamic optimisation problems. In recent years, numerous new algorithms have been proposed to track the problem's potentially moving global optimum as closely as possible. A large proportion of these techniques attempts to exploit possible similarities between successive problem instances, primarily using previously found solutions as starting points for future instances: If the previous global optimum is in close proximity to the new global optimum (in the genotype space), such transfer of knowledge should allow the algorithm to locate the new global optimum in less time than a random restart may require. However, it is clear that distance alone may be insufficient to guarantee such computational savings. In this paper, we propose a simple framework that may be used to create bi-modular problems with\u00a0\u2026", "num_citations": "11\n", "authors": ["537"]}
{"title": "How specialised are specialists? Generalisation properties of entries from the 2008 and 2009 TAC market design competitions\n", "abstract": " Unlike the classic Trading Agent competition (tac), where participants enter trading strategies into a market, the tac Market Design Competition (cat) allows participants to create rules for their own double auction market and set fees for traders, which they embody in agents known as specialists. Although the generalisation properties of traders when the specialist (i.e., the market mechanism) is fixed have been assessed, generalisation properties of specialists have not. It is unclear whether and how a specialist might (intentionally or unintentionally) favour certain trading strategies. We present an empirical analysis of specialists\u2019 generalisation abilities in various trading environments. Our results show that specialists can be sensitive to a number of factors, including the other trading and specialist strategies in the environment.", "num_citations": "11\n", "authors": ["537"]}
{"title": "Special issue on\" nature inspired problem-solving\"\n", "abstract": " Editorial: Special Issue on \"Nature Inspired Problem-Solving\": Information Sciences: an International Journal: Vol 178, No 15 ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Information Sciences: an International Journal Periodical Home Latest Issue Archive Authors Affiliations Award Winners More HomeBrowse by TitlePeriodicalsInformation Sciences: an International JournalVol. , No. Editorial: Special Issue on \"Nature Inspired Problem-Solving\" article Editorial: Special Issue on \"Nature Inspired Problem-Solving\" Share on Authors: Ke Tang Search about this author , Xin Yao profile image Xin Yao View Profile Authors Info & Affiliations Publication: Information Sciences: an International JournalAugust \u2026", "num_citations": "11\n", "authors": ["537"]}
{"title": "Robust evolution strategies use adaptive search strategies to design the continuous-time recurrent neural networks\n", "abstract": " This paper empirically investigates the use and behaviour of Evolution Strategies (ES) algorithms on problems such as function optimisation and the use of evolutionary artificial neural networks in evolutionary robotics. Computer simulations are conducted which compare the performance of Classical-ES (CES) and Robust-ES (RES). We show that the performance of the RES algorithm improves on that of the CES algorithm. Most importantly statistical analyses of the evolutionary behaviour show that the CES algorithm keeps the same search strategy regardless of domain while the RES algorithm changes the search strategy to fit the problem.", "num_citations": "11\n", "authors": ["537"]}
{"title": "Evolving market design\n", "abstract": " This chapter outlines the scope of our work and presents a broad overview of the rest of the thesis.", "num_citations": "11\n", "authors": ["537"]}
{"title": "How good is fitness sharing with a scaling function\n", "abstract": " Fitness sharing has been used widely in genetic algorithms for multi-objective function optimization and machine learning. It is often implemented with a scaling function, which adjusts an individual's raw tness to improve the performance of the genetic algorithm. However, choosing a scaling function is an ad hoc a air that lacks su cient theoretical foundation, and which often gives results that need further processing with a hill-climbing algorithm. Although this is already known, an explanation as to why this is so has been lacking. This paper explains why tness sharing with a scaling function performs in this way. We investigate tness sharing's performance at multiobjective optimization, demonstrate the need for a scaling function of some kind, and discuss what form of scaling function works best. An arti cial search space was created for our study. We provide both theoretical and empirical evidence that tness sharing with a scaling function su ers a dilemma which can easily be mistaken for deception. Our theoretical analyses and empirical studies explain why a larger-than-necessary population is needed for tness sharing with a scaling function to work, and give an explanation for common xes such as further processing with a hill-climbing algorithm. Our explanation predicts that annealing the scaling power during a run will improve results, and we verify that it does.", "num_citations": "11\n", "authors": ["537"]}
{"title": "A survey of evolutionary continuous dynamic optimization over two decades\u2013part b\n", "abstract": " This paper presents the second part of a two-part survey that reviews evolutionary dynamic optimization for singleobjective unconstrained continuous problems over the last two decades. While in the first part we reviewed the components of dynamic optimization algorithms, in this part, we present an indepth review of the most commonly used benchmark problems, performance analysis methods, static optimization methods used in the framework of dynamic optimization algorithms, and realworld applications. Compared to the previous works, this paper provides a new taxonomy for the benchmark problems used in the field based on their baseline functions and dynamics. In addition, this survey classifies the commonly used performance indicators into fitness/error based and efficiency based ones. Different types of plots used in the literature for analyzing the performance and behavior of algorithms are also\u00a0\u2026", "num_citations": "10\n", "authors": ["537"]}
{"title": "Kernel truncated regression representation for robust subspace clustering\n", "abstract": " Subspace clustering aims to group data points into multiple clusters of which each corresponds to one subspace. Most existing subspace clustering approaches assume that input data lie on linear subspaces. In practice, however, this assumption usually does not hold. To achieve nonlinear subspace clustering, we propose a novel method, called kernel truncated regression representation. Our method consists of the following four steps: 1) projecting the input data into a hidden space, where each data point can be linearly represented by other data points; 2) calculating the linear representation coefficients of the data representations in the hidden space; 3) truncating the trivial coefficients to achieve robustness and block-diagonality; and 4) executing the graph cutting operation on the coefficient matrix by solving a graph Laplacian problem. Our method has the advantages of a closed-form solution and the capacity\u00a0\u2026", "num_citations": "10\n", "authors": ["537"]}
{"title": "Automatic construction of parallel portfolios via explicit instance grouping\n", "abstract": " Exploiting parallelism is becoming more and more important in designing efficient solvers for computationally hard problems. However, manually building parallel solvers typically requires considerable domain knowledge and plenty of human effort. As an alternative, automatic construction of parallel portfolios (ACPP) aims at automatically building effective parallel portfolios based on a given problem instance set and a given rich configuration space. One promising way to solve the ACPP problem is to explicitly group the instances into different subsets and promote a component solver to handle each of them. This paper investigates solving ACPP from this perspective, and especially studies how to obtain a good instance grouping. The experimental results on two widely studied problem domains, the boolean satisfiability problems (SAT) and the traveling salesman problems (TSP), showed that the parallel portfolios constructed by the proposed method could achieve consistently superior performances to the ones constructed by the state-of-the-art ACPP methods, and could even rival sophisticated hand-designed parallel solvers.", "num_citations": "10\n", "authors": ["537"]}
{"title": "Model-based computational intelligence multi-objective optimization for gasoline direct injection engine calibration\n", "abstract": " For modern engines, the number of adjustable variables is increasing considerably. With an increase in the number of degrees of freedom and the consequent increase in the complexity of the calibration process, traditional design of experiments\u2013based engine calibration methods are reaching their limits. As a result, an automated engine calibration approach is desired. In this paper, a model-based computational intelligence multi-objective optimization approach for gasoline direct injection engine calibration is developed, which can optimize the engine\u2019s indicated specific fuel consumption, indicated specific particulate matter by mass, and indicated specific particulate matter by number simultaneously, by intelligently adjusting the engine actuators\u2019 settings through Strength Pareto Evolutionary Algorithm 2. A mean-value model of gasoline direct injection engine is developed in the author\u2019s earlier work and used to\u00a0\u2026", "num_citations": "10\n", "authors": ["537"]}
{"title": "Computational intelligence nonmodel-based calibration approach for internal combustion engines\n", "abstract": " Over the past 20 years, with the increase in the complexity of engines, and the combinatorial explosion of engine variables space, the engine calibration process has become more complex, costly, and time consuming. As a result, an efficient and economic approach is desired. For this purpose, many engine calibration methods are under development in original equipment manufacturers and universities. The state-of-the-art model-based steady-state design of experiments (DOE) technique is mature and is used widely. However, it is very difficult to further reduce the measurement time. Additionally, the increasingly high requirements of engine model accuracy and robust testing process with high data quality by high-quality testing facility also constrain the further development of model-based DOE engine calibration. This paper introduces a new computational intelligence approach to calibrate internal combustion\u00a0\u2026", "num_citations": "10\n", "authors": ["537"]}
{"title": "Average drift analysis and population scalability\n", "abstract": " This paper aims to study how the population size affects the computation time of evolutionary algorithms (EAs) in a rigorous way. The computation time of EAs can be measured by either the number of generations (hitting time) or the number of fitness evaluations (running time) to find an optimal solution. Population scalability is the ratio of the expected hitting time between a benchmark algorithm and an algorithm using a larger population size. Average drift analysis is introduced to compare the expected hitting time of two algorithms and to estimate lower and upper bounds on the population scalability. Several intuitive beliefs are rigorously analyzed. It is proven that: 1) using a population sometimes increases rather than decreases the expected hitting time; 2) using a population cannot shorten the expected running time of any elitist EA on any unimodal function on the time-fitness landscape, however, this statement\u00a0\u2026", "num_citations": "10\n", "authors": ["537"]}
{"title": "Diversity-driven selection of multiple crossover operators for the capacitated arc routing problem\n", "abstract": " The Capacitated Arc Routing Problem (CARP) is a NP-Hard routing problem with strong connections with real world problems. In this work we aim to enhance the performance of MAENS, a state-of-the-art algorithm, through a self-adaptive scheme to choose the most suitable operator and a diversity-driven ranking operator. Experimental results on 181 problem instances show how these techniques can both improve the results of the current state-of-the-art algorithms and provide good directions to develop EAs with a more robust approximation ratio.", "num_citations": "10\n", "authors": ["537"]}
{"title": "Dynamic time-linkage evolutionary optimization: Definitions and potential solutions\n", "abstract": " Dynamic time-linkage optimization problems (DTPs) are special dynamic optimization problems (DOPs) where the current solutions chosen by the solver can influence how the problems might change in the future. Although DTPs are very common in real-world applications (e.g. online scheduling, online vehicle routing, and online optimal control problems), they have received very little attention from the evolutionary dynamic optimization (EDO) research community. Due to this lack of research there are still many characteristics that we do not fully know about DTPs. For example, how should we define and classify DTPs in detail; are there any characteristics of DTPs that we do not know; with these characteristics are DTPs still solvable; and what is the appropriate strategy to solve them. In this chapter these issues will be partially addressed. First, we will propose a detailed definition framework to help\u00a0\u2026", "num_citations": "10\n", "authors": ["537"]}
{"title": "The effectiveness of a new negative correlation learning algorithm for classification ensembles\n", "abstract": " In an earlier paper, we proposed a new negative correlation learning (NCL) algorithm for classification ensembles, called AdaBoost.NC, which has significantly better performance than the standard AdaBoost and other NCL algorithms on many benchmark data sets with low computation cost. In this paper, we give deeper insight into this algorithm from both theoretical and experimental aspects to understand its effectiveness. We explain why AdaBoost.NC can reduce error correlation within the ensemble and improve the classification performance. We also show the role of the amb (penalty) term in the training error. Finally, we examine the effectiveness of AdaBoost.NC by varying two pre-defined parameters penalty strength \u03bb and ensemble size T. Experiments are carried out on both artificial and real-world data sets, which show that AdaBoost.NC does produce smaller error correlation along with training epochs\u00a0\u2026", "num_citations": "10\n", "authors": ["537"]}
{"title": "Using GP to evolve decision rules for classification in financial data sets\n", "abstract": " Financial forecasting is a lucrative and complicated application of machine learning. In this paper, we focus on the finding investment opportunities. We therefore explore four different Genetic Programming approaches and compare their performances on real-world data. We find that the novelties we introduced in some of these approaches indeed improve the results. However, we also show that the Genetic Programming process itself is still very inefficient and that further improvements are necessary if we want this application of GP to become successful.", "num_citations": "10\n", "authors": ["537"]}
{"title": "A hybrid estimation of distribution algorithm for cdma cellular system design\n", "abstract": " This paper proposes a hybrid estimation of distribution algorithm (HyEDA) to address the design problem of code division multiple access cellular system configuration. Given a service area, the problem is to find a set of optimal locations of base stations, associated with their corresponding powers and antenna heights in the area, in order to maximize call quality and service coverage, at the same time, to minimize the total cost of the system configuration. HyEDA is a two-stage hybrid approach which integrates an estimation of distribution algorithm, a K-means clustering method, and a simple local search algorithm. We have compared HyEDA with a simulated annealing method on a number of instances. Our simulation results have demonstrated that HyEDA outperforms the simulated annealing method in terms of the solution quality and computational cost.", "num_citations": "10\n", "authors": ["537"]}
{"title": "Automatic feature-queried bird identification system based on entropy and fuzzy similarity\n", "abstract": " Birdwatching is one of the very interesting hobbies and most important work. Many birdwatching assistant systems have been developed. However, most of them do not have any intelligence and cannot tolerate noises either. A bird identification system, BirdID is proposed and implemented. To identify birds, BirdID imitates bird experts to automatically direct birdwatchers to provide features. It also tries to list the most likely species after each feature is entered. In BirdID, entropy and fuzzy similarity are used to select most appropriate queried features and calculate similarity, respectively, which makes BirdID more intelligent and noise-tolerant. The experiments on a dataset with 106 species show that BirdID works well.", "num_citations": "10\n", "authors": ["537"]}
{"title": "A computational intelligence approach to railway track intervention planning\n", "abstract": " Railway track intervention planning is the process of specifying the location and time of required maintenance and renewal activities. To facilitate the process, decision support tools have been developed and typically use an expert system built with rules specified by track maintenance engineers. However, due to the complex interrelated nature of component deterioration, it is problematic for an engineer to consider all combinations of possible deterioration mechanisms using a rule based approach. To address this issue, this chapter describes an approach to the intervention planning using a variety of computational intelligence techniques. The proposed system learns rules for maintenance planning from historical data and incorporates future data to update the rules as they become available thus the performance of the system improves over time. To determine the failure type, historical deterioration patterns of\u00a0\u2026", "num_citations": "10\n", "authors": ["537"]}
{"title": "The iterated Prisoner\u2019s Dilemma: 20 years on\n", "abstract": " In 1984, Robert Axelrod reported the results of two iterated prisoner\u2019s dilemma (IPD) competitions [Axelrod (1984)]. The booked was to be a catalyst for much of the research in this area since that time. It is unlikely that you would write a scientific paper about IPD, without citing Axelrod\u2019s 1984 book. The book is even more remarkable in that it is just as accessible to a general audience, as well as being an important source of inspiration for the scientific community.In 2001, whilst attending the Congress on Evolutionary Computation (CEC) conference, we were discussing some of the presentations we had seen which reported recent some of the latest work on the iterated prisoner\u2019s dilemma. We were paying tribute to the fact that Axelrod\u2019s book had stood the test of time when somebody made a casual comment suggesting that we should re-run the competition in 2004, to celebrate the 20th anniversary. And, so, this book was born.", "num_citations": "10\n", "authors": ["537"]}
{"title": "Boosting kernel models for regression\n", "abstract": " This paper proposes a general boosting framework for combining multiple kernel models in the context of both classification and regression problems. Our main approach is built on the idea of gradient boosting together with a new regularization scheme and aims at reducing the cubic complexity of training kernel models. We focus mainly on using the proposed boosting framework to combine kernel ridge regression (KRR) models for regression tasks. Numerical experiments on four large-scale data sets have shown that boosting multiple small KRR models is superior to training a single large KRR model on both improving generalization performance and reducing computational requirements.", "num_citations": "10\n", "authors": ["537"]}
{"title": "Metaheuristic approaches to traffic grooming in WDM optical networks\n", "abstract": " The widespread deployment of WDM optical networks posts lots of new challenges for network designers. Traffic grooming is one of the most common problems. Efficient grooming of traffic can effectively reduce the overall cost of the network. But unfortunately, traffic grooming problems have been shown to be NP-hard. Therefore, new heuristics must be devised to tackle them. Among these approaches, metaheuristics are among the most promising ones. In this paper, we present a thorough and comprehensive survey on various metaheuristic approaches to the grooming of traffic in both static and dynamic patterns in WDM optical networks. Some future challenges and research directions are also discussed in this paper.", "num_citations": "10\n", "authors": ["537"]}
{"title": "An evolutionary approach to modeling radial brightness distributions in elliptical galaxies\n", "abstract": " A reasonably good description of the luminosity profiles of galaxies is needed as it serves as a guide towards understanding the process of galaxy formation and evolution. To obtain a radial brightness profile model of a galaxy, the way varies both in terms of the exact mathematical form of the function used and in terms of the algorithm used for parameters fitting for the function given. Traditionally, one builds such a model by means of fitting parameters for a functional form assumed beforehand. As a result, such a model depends crucially on the assumed functional form. In this paper we propose an approach that enables one to build profile models from data directly without assuming a functional form in advance by using evolutionary computation. This evolutionary approach consists of two major steps that serve two goals. The first step applies the technique of genetic programming with the aim of finding a\u00a0\u2026", "num_citations": "10\n", "authors": ["537"]}
{"title": "An improved constructive neural network ensemble approach to medical diagnoses\n", "abstract": " Neural networks have played an important role in intelligent medical diagnoses. This paper presents an Improved Constructive Neural Network Ensemble (ICNNE) approach to three medical diagnosis problems. New initial structure of the ensemble, new freezing criterion, and a different error function are presented. Experiment results show that our ICNNE approach performed better for most problems.", "num_citations": "10\n", "authors": ["537"]}
{"title": "Generalized LDA using relevance weighting and evolution strategy\n", "abstract": " In pattern classification area, linear discriminant analysis (LDA) is one of the most traditional methods to find a linear solution to the feature extraction problem, which maximise the ratio between between-class scatter and the within class scatter (Fisher's criterion). We propose a variant of LDA which incorporates the class conjunctions thereby making LDA more robust for the problems in which the within class scatter is quite different from one class to another, while retaining all the merits of conventional LDA. We also integrate an evolutionary search procedure in our algorithm to make it more unbiased to the training samples and to improve the robustness.", "num_citations": "10\n", "authors": ["537"]}
{"title": "Parallel Problem Solving from Nature (PPSN VIII)\n", "abstract": " - University of Birmingham research gateway University of Birmingham research gateway University of Birmingham research gateway Research Portal Schools Publications Researchers Research Projects Activities Datasets Staff login HomePublicationsParallel Problem Solving from Nature (PPSN VIII) Parallel Problem Solving from Nature (PPSN VIII) Research output: Book/Report \u203a Book Overview Citation formats Authors Xin Yao John Bullinaria Jon Rowe Peter Tino Ata Kaban And 5 others E Burke JA Lozano J Smith JJ Merelo-Guervos HP Schwefel Colleges, School and Institutes Computer Science Details Original language English Publisher Springer Publication status Published - 1 Jan 2004 Save citation Saved citations (0) Copy the text from this field... Close View graph of relations By the same authors Structure from Randomness in Halfspace Learning with the Zero-One Loss Ata Kaban, 15 Sep 2020, (\u2026", "num_citations": "10\n", "authors": ["537"]}
{"title": "Analysis of noisy evolutionary optimization when sampling fails\n", "abstract": " In noisy evolutionary optimization, sampling is a common strategy to deal with noise. By the sampling strategy, the fitness of a solution is evaluated multiple times (called sample size) independently, and its true fitness is then approximated by the average of these evaluations. Most previous studies on sampling are empirical, and the few theoretical studies mainly showed the effectiveness of sampling with a sufficiently large sample size. In this paper, we theoretically examine what strategies can work when sampling with any fixed sample size fails. By constructing a family of artificial noisy examples, we prove that sampling is always ineffective, while using parent or offspring populations can be helpful on some examples. We also construct an artificial noisy example to show that when using neither sampling nor populations is effective, a tailored adaptive sampling (i.e., sampling with an adaptive sample size\u00a0\u2026", "num_citations": "9\n", "authors": ["537"]}
{"title": "Uncertainty analysis of wind power probability density forecasting based on cubic spline interpolation and support vector quantile regression\n", "abstract": " Accurate forecasting of wind power plays an important role in an effective and reliable power system. However, the fact of non-schedulability and fluctuation of wind power significantly increases the uncertainty of power systems. The output power of a wind farm is usually mixed with uncertainties, which reduce the effectiveness and accuracy of wind power forecasting. In order to handle the uncertainty of wind power, this paper first proposes to conduct outlier detection and reconstruct data before the prediction. Then, a wind power probability density forecasting method is proposed, based on cubic spline interpolation and support vector quantile regression (CSI-SVQR), which can better estimate the whole wind power probability density curve. However, the probability density prediction method can not acquire the optimal point prediction and interval prediction results at the same time. In order to analyze the\u00a0\u2026", "num_citations": "9\n", "authors": ["537"]}
{"title": "Fitness landscapes and problem difficulty in evolutionary algorithms: from theory to applications\n", "abstract": " Above many successes of evolutionary algorithms in solving computationally hard optimisations problems, a major challenge in practice remains how to select/construct the best suited algorithm when solving a problem. The well-known no free lunch theorem rules out the possibility of developing one best algorithmgenerally suitable for solving all problems. Within the realm of algorithm selection in general, the problem becomes how can we characterise problem hardness with reference to evolutionary algorithms (EAs). For the first time, this chapter rigorously derives a problem hardness measure from a theoretical difficulty measure widely used in complexity theory of EAs. Furthermore, the proposed measure is applied to construct an offline optimisation algorithm and an online optimisation algorithm. On one hand, the measure is incorporated with a machine learning algorithm for parameter tuning and\u00a0\u2026", "num_citations": "9\n", "authors": ["537"]}
{"title": "Re-scheduling in railway networks\n", "abstract": " Railway transport is one of the convenient public transports, known for its safety, reliability of service, and punctuality. Railway networks, as an important part of railway infrastructure, have been extended in the scale and complexity to meet constantly increasing demand of passengers and goods transports. Since railway networks face disturbances more frequently than before as a result of severe weather conditions, signal faults, and increased demand etc., highly efficient re-scheduling approaches are needed to help train dispatchers to re-schedule trains. Many re-scheduling approaches in railway networks have been proposed considering different disturbances scenarios. These approaches are classified by their characteristics and reviewed in detail in this paper. Since re-scheduling problem is usually formulated by different models in the literature, these models are also reviewed along with the approaches\u00a0\u2026", "num_citations": "9\n", "authors": ["537"]}
{"title": "Some recent work on multi-objective approaches to search-based software engineering\n", "abstract": " Multi-objective algorithms have been used to solve difficult software engineering problems for a long time. This article summarises some selected recent work of applying latest meta-heuristic optimisation algorithms and machine learning algorithms to software engineering problems, including software module clustering, testing resource allocation in modular software system, protocol tuning, Java container testing, software project scheduling, software project effort estimation, and software defect prediction. References will be given, from which the details of such application of computational intelligence techniques to software engineering problems can be found.", "num_citations": "9\n", "authors": ["537"]}
{"title": "Hardware design using evolution algorithms\n", "abstract": " The design of a hardware component such as a digital filter is optimized by taking an initial population of filter designs and encoding them as chromosomes. The fitness of each chromosome is then evaluated and parent chromosomes are then selected based on the fitness criteria. Offspring chromosomes are then generated using genetic operations such as mutation and cross-over from the pool of offspring, and optionally, parents. Individuals are selected to survive using a combination of Pareto fronts based on non-dominated individuals and clustering. The process is repeated or until a termination criteria is satisfied.", "num_citations": "9\n", "authors": ["537"]}
{"title": "Profiling MS proteomics data using smoothed non\u2010linear energy operator and Bayesian additive regression trees\n", "abstract": " This paper proposes a novel profiling method for SELDI\u2010TOF and MALDI\u2010TOF MS data that integrates a novel peak detection method based on modified smoothed non\u2010linear energy operator, correlation\u2010based peak selection and Bayesian additive regression trees. The peak detection and classification performance of the proposed approach is validated on two publicly available MS data sets, namely MALDI\u2010TOF simulation data and high\u2010resolution SELDI\u2010TOF ovarian cancer data. The results compared favorably with three state\u2010of\u2010the\u2010art peak detection algorithms and four machine\u2010learning algorithms. For the high\u2010resolution ovarian cancer data set, seven biomarkers (m/z windows) were found by our method, which achieved 97.30 and 99.10% accuracy at 25th and 75th percentiles, respectively, from 50 independent cross\u2010validation samples, which is significantly better than other profiling and dimensional\u00a0\u2026", "num_citations": "9\n", "authors": ["537"]}
{"title": "Selective negative correlation learning algorithm for incremental learning\n", "abstract": " Negative correlation learning (NCL) is a successful scheme for constructing neural network ensembles. In batch learning mode, NCL outperforms many other ensemble learning approaches. Recently, NCL is also shown to be a potentially powerful approach to incremental learning, while the advantage of NCL has not yet been fully exploited. In this paper, we propose a selective NCL approach for incremental learning. In the proposed approach, the previously trained ensemble is cloned when a new data set presents and the cloned ensemble is trained on the new data set. Then, the new ensemble is combined with the previous ensemble and a selection process is applied to prune the whole ensemble to a fixedsize. Simulation results on several benchmark datasets show that the proposed algorithm outperforms two recent incremental learning algorithms based on NCL.", "num_citations": "9\n", "authors": ["537"]}
{"title": "Meta-heuristic algorithms for FPGA segmented channel routing problems with non-standard cost functions\n", "abstract": " In this paper we present three meta-heuristic approaches for FPGA segmented channel routing problems (FSCRPs) with a new cost function in which the cost of each assignment is not known in advance, and the cost of a solution only can be obtained from entire feasible assignments. Previous approaches to FSCPs cannot be applied to this kind of cost functions, and meta-heuristics are a good option to tackle the problem. We present two hybrid algorithms which use a Hopfield neural network to solve the problem's constraints, mixed with a Genetic Algorithm (GA) and a Simulated Annealing (SA). The third approach is a GA which manages the problem's constraints with a penalty function. We provide a complete analysis of the three metaheuristics, by tested them in several FSCRP instances, and comparing their performance and suitability to solve the FSCRP.", "num_citations": "9\n", "authors": ["537"]}
{"title": "Simultaneous learning of negatively correlated neural network\n", "abstract": " ABSTRACT A new approach to designing neural network ensembles has been proposed recently 1]. Experimental studies on some regression tasks have shown that the new approach performs signi cantly better than previous ones 1]. This paper presents a new algorithm for designing neural network ensembles for classi cation problems with noise. This new algorithm is different from that used for regression tasks although the idea is similar. The idea behind this new algorithm is to encourage di erent individual networks in an ensemble to learn di erent parts or aspects of the training data so that the whole ensemble can learn the whole training data better. Negatively correlated networks are trained with a novel correlation penalty term in the error function to encourage such specialisation. In our algorithm, individual networks are trained simultaneously rather than sequentially. This provides an opportunity for di erent networks to interact with other and to specialise. Experiments on two real-world problems demonstrate that the new algorithm can produce neural network ensembles with good generalisation ability.", "num_citations": "9\n", "authors": ["537"]}
{"title": "Lightweight evolution strategies for nanoswimmers-oriented in vivo computation\n", "abstract": " We propose two novel evolution strategies of swarm intelligence for nanoswimmer-oriented in vivo computation, which corresponds to the computing model of the direct targeting strategy (DTS) where externally manipulable magnetic nanoswimmers are employed for cancer detection. In the DTS, the nanoswimmers move in the high-risk tissue region guided by an external magnetic field to search for the early cancer that cannot be visualized using traditional imaging modalities due to their limited resolution. Subject to the constraint of the state-of-the-art controlling technology which can only generate a uniform magnetic field to steer all the nanoswimmers simultaneously, we revisit the conventional gravitational search algorithm (GSA) and propose the orthokinetic gravitational search algorithm (OGSA) to carry out the DTS. Furthermore, we propose the general evolution strategy (G-ES) and the weak priority evolution\u00a0\u2026", "num_citations": "8\n", "authors": ["537"]}
{"title": "Voronoi-based efficient surrogate-assisted evolutionary algorithm for very expensive problems\n", "abstract": " Very expensive problems are very common in practical system that one fitness evaluation costs several hours or even days. Surrogate assisted evolutionary algorithms (SAEAs) have been widely used to solve this crucial problem in the past decades. However, most studied SAEAs focus on solving problems with a budget of at least ten times of the dimension of problems which is unacceptable in many very expensive real-world problems. In this paper, we employ Voronoi diagram to boost the performance of SAEAs and propose a novel framework named Voronoi-based efficient surrogate assisted evolutionary algorithm (VESAEA) for very expensive problems, in which the optimization budget, in terms of fitness evaluations, is only 5 times of the problem's dimension. In the proposed framework, the Voronoi diagram divides the whole search space into several subspace and then the local search is operated in some\u00a0\u2026", "num_citations": "8\n", "authors": ["537"]}
{"title": "Benchmark Functions for the CEC'2018 Competition on Dynamic Multiobjective Optimization\n", "abstract": " The past decade has witnessed a growing amount of research interest in dynamic multiobjective optimisation, a challenging yet very important topic that deals with problems with multi-objective and time-dependent properties [3\u20137, 10]. Due to the presence of dynamics, dynamic multiobjective problems (DMOPs) are more complex and challenging than static multiobjective problems. As a result, evolutionary algorithms (EAs) face great difficulties in solving them. Generally speaking, DMOPs pose at least three main challenges. First, environmental changes can exhibit any dynamics. A variety of dynamics pose different levels of difficulties to algorithms, and there is no single change reaction mechanism that can handle all dynamics. Second, diversity, the key driving force of population-based algorithms, is sensitive to dynamics and therefore difficult to be well maintained. Finally, often than not the response time for environmental changes is rather tight for algorithms. Time restriction on DMOPs requires algorithms to reach a good balance between diversity and convergence such that any environmental changes can be promptly handled in order to closely track time-varying Pareto fronts or sets. All these suggest there be a great need for new methodologies for tacking DMOPs.", "num_citations": "8\n", "authors": ["537"]}
{"title": "Defect-and variation-tolerant logic mapping in nanocrossbar using bipartite matching and memetic algorithm\n", "abstract": " High defect density and extreme parameter variation make it very difficult to implement reliable logic functions in crossbar-based nanoarchitectures. It is a major design challenge to tolerate defects and variations simultaneously for such architectures. In this paper, a method based on a bipartite matching and memetic algorithm is proposed for defect- and variation-tolerant logic mapping (D/VTLM) problem in crossbar-based nanoarchitectures. In the proposed method, the search space of the D/VTLM problem can be dramatically reduced through the introduction of the min-max weight maximum-bipartite-matching (MMW-MBM) and a related heuristic bipartite matching method. MMW-MBM is defined on a weighted bipartite graph as an MBM, where the maximal weight of the edges in the matching has a minimal value. In addition, a defect- and variation-aware local search (D/VALS) operator is proposed for D/VTLM and\u00a0\u2026", "num_citations": "8\n", "authors": ["537"]}
{"title": "The time complexity analysis of a class of gene expression programming\n", "abstract": " This paper studies the time complexity of gene expression programming based on maintaining elitist (ME-GEP). Using the theory of Markov chain and the technique of artificial fitness level, the properties of transition matrices of ME-GEP are analyzed. Based on the properties, the upper and lower bounds of the average time complexity of ME-GEP are obtained. Furthermore, the upper bound is estimated, which is determined by the parameters of ME-GEP algorithm. And the theoretical results acquired in this paper are used to analyze ME-GEP for solving function modeling and clustering problem. At last, a set of experiments are performed on these problems to illustrate the effectiveness of theoretical results. The results show that the upper bound of expected first hitting time can be used to direct the algorithm design of ME-GEP.", "num_citations": "8\n", "authors": ["537"]}
{"title": "Evolutionary optimization on continuous dynamic constrained problems-an analysis\n", "abstract": " Many real-world dynamic problems have constraints, and in certain cases not only the objective function changes over time, but also the constraints. However, there is little research on whether current algorithms work well on continuous dynamic constrained optimization problems (DCOPs). This chapter investigates this issue. The chapter will present some studies on the characteristics that can make DCOPs difficult to solve by some existing dynamic optimization (DO) algorithms. We will then introduce a set of benchmark problems with these characteristics and test several representative DO strategies on these problems. The results confirm that DCOPs do have special characteristics that can significantly affect algorithm performance. Based on the analyses of the results, a list of potential requirements that an algorithm should meet to solve DCOPs effectively will be proposed.", "num_citations": "8\n", "authors": ["537"]}
{"title": "Evolutionary computation for dynamic capacitated arc routing problem\n", "abstract": " In this chapter, a new dynamic capacitated arc routing problem (CARP) is defined and investigated. Compared with the static CARP and other dynamic CARP investigated by the existing researches, the new dynamic CARP is more general and closer to reality, and thus is more worthwhile to be solved. Due to the stochastic factors included in the dynamic CARP, the objective is not to obtain the optimal solution in a specific environment, but to find a robust solution that shows good performance in all the possible environments. For the dynamic CARP, a robustness measure based on repair operator is defined. The corresponding repair operator is designed according to the real-world considerations. Then, the benchmark instances of the dynamic CARP are generated by extending from the static counterparts to facilitate evaluating potential approaches. After that, the preliminary analysis for the fitness\u00a0\u2026", "num_citations": "8\n", "authors": ["537"]}
{"title": "Detailed experimental results of GA, RIGA, HyperM and GA+ Repair on the G24 set of benchmark problems\n", "abstract": " All Pop size (pop_size) 5, 15, 25 (medium), 50, 100 algorithms Elitism Elitism & non-elitism if applicable (exceptions Selection method Non-linear ranking as in [3] below) Mutation method Uniform, P= 0.15. Crossover method Arithmetic, P= 0.1. HyperM Triggered mutate Uniform, P= 0.5 as in [1]. RIGA Rand-immig. rate P= 0.3 as in [2]. GA+ Repair Search pop size pop_sizex (4/5) Reference pop size pop_sizex (1/5) Replacement rate 0 (default is 0.25 as in [3]). Benchmark Number of runs 50 problem Number of changes 5/k (see below) settings Change frequency 250, 500, 1000 (med), 2000, 4000 evaluations", "num_citations": "8\n", "authors": ["537"]}
{"title": "Evolving neural networks with maximum AUC for imbalanced data classification\n", "abstract": " Real-world classification problems usually involve imbalanced data sets. In such cases, a classifier with high classification accuracy does not necessarily imply a good classification performance for all classes. The Area Under the ROC Curve (AUC) has been recognized as a more appropriate performance indicator in such cases. Quite a few methods have been developed to design classifiers with the maximum AUC. In the context of Neural Networks (NNs), however, it is usually an approximation of AUC rather than the exact AUC itself that is maximized, because AUC is non-differentiable and cannot be directly maximized by gradient-based methods. In this paper, we propose to use evolutionary algorithms to train NNs with the maximum AUC. The proposed method employs AUC as the objective function. An evolutionary algorithm, namely the Self-adaptive Differential Evolution with Neighborhood Search\u00a0\u2026", "num_citations": "8\n", "authors": ["537"]}
{"title": "How specialised are specialists? Generalisation properties of entries from the 2008 TAC Market Design Competition\n", "abstract": " Unlike the classic Trading Agent competition (TAC), where participants enter trading strategies into a market, the TAC Market Design Competition (CAT) allows participants to create rules for their own double auction market and set fees for traders, which they embody in agents known as specialists. Although the generalisation properties of traders when the specialist (ie, the market mechanism) is fixed have been assessed, generalisation properties of specialists have not. It is unclear whether and how a specialist might (intentionally or unintentionally) favour certain trading strategies. We present an empirical analysis of specialists\u2019 generalisation abilities in various trading environments. Our results show that specialists can be sensitive to a number of factors, including the other trading and specialist strategies in the environment.", "num_citations": "8\n", "authors": ["537"]}
{"title": "Evolving neural network ensembles by fitness sharing\n", "abstract": " The difference between evolving neural networks and evolving neural network ensembles is that the solution of evolving neural networks is an evolved neural network while the solution of evolving neural network ensemble is an evolved population of neural networks. In the practice of evolving neural network ensemble, it is common that each individual rather the whole population is evaluated. During the evolution, the solution of evolving neural networks would be better and better while it might not be the case for the solution of evolving neural network ensembles. It suggests that the final evolved population might be worse so that it is not wise to choose the final population as a solution. Through experimental studies, this paper gives ideas of how to evolve better populations.", "num_citations": "8\n", "authors": ["537"]}
{"title": "An extended contract net mechanism for dynamic supply chain formation and its application in China petroleum supply chain management\n", "abstract": " Software agents representing supply chain partners make it possible to automate supply chain management and particularly can address the challenging problem of automating the process of dynamic supply chain formation. This paper puts forward an extended contract net mechanism for dynamic supply chain formation and applies it to China petroleum supply chain management, which is characterized by a semi-monopolized market, where conventional negotiation protocols are limited because they are based on the assumption of a pure market. The proposed multi-agent negotiation mechanism is algorithmized and validated in two scenarios of dynamic supply chain formation, ie, semi-monopolized market and emergency, respectively.", "num_citations": "8\n", "authors": ["537"]}
{"title": "Data mining by evolutionary learning for robust churn prediction in the telecommunications industry\n", "abstract": " Data Mining by Evolutionary Learning for Robust Churn Prediction in the Telecommunications Industry \u2014 University of Birmingham Skip to main navigation Skip to search Skip to main content University of Birmingham Home University of Birmingham Logo Help & FAQ Home Research output Profiles Research Units Projects Activities Datasets Equipment Prizes Press / Media Search by expertise, name or affiliation Data Mining by Evolutionary Learning for Robust Churn Prediction in the Telecommunications Industry WH Au, KCC Chan, Xin Yao Computer Science Research output: Contribution to journal \u203a Article Overview Original language English Pages (from-to) 545 Number of pages 1 Journal IEEE Transactions on Evolutionary Computation Volume 7 Issue number 6 Publication status Published - 1 Jan 2003 Cite this APA Author BIBTEX Harvard Standard RIS Vancouver Au, WH., Chan, KCC., & Yao, X. (2003). \u2026", "num_citations": "8\n", "authors": ["537"]}
{"title": "Designing Neural Network Ensembles by Minimizing Mutual Information\n", "abstract": " This chapter describes negative correlation learning for designing neural network ensembles. Negative correlation learning has been firstly analysed in terms of minimising mutual information on a regression task. By minimising the mutual information between variables extracted by two neural networks, they are forced to convey different information about some features of their input. Based on the decision boundaries and correct response sets, negative correlation learning has been further studied on two pattern classification problems. The purpose of examining the decision boundaries and the correct response sets is not only to illustrate the learning behavior of negative correlation learning, but also to cast light on how to design more effective neural network ensembles. The experimental results showed the decision boundary of the trained neural network ensemble by negative correlation learning is almost as\u00a0\u2026", "num_citations": "8\n", "authors": ["537"]}
{"title": "On performance estimation in automatic algorithm configuration\n", "abstract": " Over the last decade, research on automated parameter tuning, often referred to as automatic algorithm configuration (AAC), has made significant progress. Although the usefulness of such tools has been widely recognized in real world applications, the theoretical foundations of AAC are still very weak. This paper addresses this gap by studying the performance estimation problem in AAC. More specifically, this paper first proves the universal best performance estimator in a practical setting, and then establishes theoretical bounds on the estimation error, ie, the difference between the training performance and the true performance for a parameter configuration, considering finite and infinite configuration spaces respectively. These findings were verified in extensive experiments conducted on four algorithm configuration scenarios involving different problem domains. Moreover, insights for enhancing existing AAC methods are also identified.", "num_citations": "7\n", "authors": ["537"]}
{"title": "Domination-based ordinal regression for expensive multi-objective optimization\n", "abstract": " Most surrogate-assisted evolutionary algorithms save expensive evaluations by approximating fitness functions. However, many real-world applications are high-dimensional multi-objective expensive optimization problems, and it is difficult to approximate their fitness functions accurately using a very limited number of fitness evaluations. This paper proposes a domination-based ordinal regression surrogate, in which a Kriging model is employed to learn the domination relationship values and to approximate the ordinal landscape of fitness functions. Coupling with a hybrid surrogate management strategy, the solutions with higher probabilities to dominate others are selected and evaluated in fitness functions. Our empirical studies on the DTLZ testing functions demonstrate that the proposed algorithm is more efficient when compared with other state-of-the-art expensive multi-objective optimization methods.", "num_citations": "7\n", "authors": ["537"]}
{"title": "Automatic parameter tuning using bayesian optimization method\n", "abstract": " The Capacitated Arc Routing Problem (CARP) is an essential and challenging problem in smart logistics. Parameter tuning is commonly encountered in designing and applying heuristic or meta-heuristic algorithms for CARP. Recently, automatic parameter tuning or hyper-parameter optimization, which focuses on automatically finding an optimal parameter setting of an algorithm for problems at hand, has attracted considerable attention and become popular for addressing parameter tuning problems. This paper studies automatic parameter tuning for advanced algorithms in solving CARP. When designing algorithms for CARP, parameters are usually determined through empirical analysis or following some rules of thumb. This paper uses an automatic parameter tuning approach, that is, Bayesian optimization method, to tune an algorithm called SAHiD, which is a scalable approach based on hierarchical\u00a0\u2026", "num_citations": "7\n", "authors": ["537"]}
{"title": "Symbolic sequence classification in the fractal space\n", "abstract": " Sequence classification has a range of applications and attracted a lot of attentions. Different from feature vectors, symbolic sequences have no explicit features. Due to this limitation, even with sophisticated feature selection techniques, the dimension of potential feature space could be very high, making classification methods hard to capture the nature of sequences. In this paper, we propose a novel scheme that first constructs a new lower dimensional representation space for symbolic sequences. Next, we carry out learning in this newly generated space rather than on the sequences. The first step is implemented with a chaos game representation, which converts a long sequence into a graphical form by applying an iterated function system on the input. For this reason, this new target space is referred as \u201cfractal space\u201d in this paper. The second step consists of carrying out sequence comparison and quantitative\u00a0\u2026", "num_citations": "7\n", "authors": ["537"]}
{"title": "Changing or keeping solutions in dynamic optimization problems with switching costs\n", "abstract": " Dynamic optimization problems (DOPs) are problems that change over time. However, most investigations in this domain are focused on tracking moving optima (TMO) without considering the cost of switching from one solution to another when the environment changes. Robust optimization over time (ROOT) tries to address this shortcoming by finding solutions which remain acceptable for several environments. However, ROOT methods change solutions only when they become unacceptable. Indeed, TMO and ROOT are two extreme cases in the sense that in the former, the switching cost is considered zero and in the latter, it is considered very large. In this paper, we propose a new semi ROOT algorithm based on a new approach to switching cost. This algorithm changes solutions when: 1) the current solution is not acceptable and 2) the current solution is still acceptable but algorithm has found a better solution\u00a0\u2026", "num_citations": "7\n", "authors": ["537"]}
{"title": "Improving the performance of evolutionary algorithms in grid-based puzzles resolution\n", "abstract": " This paper proposes several modifications to existing hybrid evolutionary algorithms in grid-based puzzles, using a-priori probabilities of 0/1 occurrence in binary encodings. This calculation of a-priori probabilities of bits is possible in grid-based problems (puzzles in this case) due to their special structure, with the solution confined into a grid. The work is focused in two different grid-based puzzles, the Japanese puzzles and the Light-up puzzle, each one having special characteristics in terms of constraints, which must be taken into account for the probabilities of bit calculation. For these puzzles, we show the process of a-priori probabilities calculation, and we modify the initialization of the EAs to improve their performance. We also include novel mutation operators based on a-priori probabilities, which makes more effective the evolutionary search of the algorithms in the tackled puzzles. The performance of\u00a0\u2026", "num_citations": "7\n", "authors": ["537"]}
{"title": "Selecting representative parameters of rainfall-runoff models using multi-objective calibration results and a fuzzy clustering algorithm\n", "abstract": " Selecting the representative model parameters from calibration solutions is not a trivial task due to several sources of uncertainty such as the lack of identifiability. This problem will be even more complicated if calibration is going to be extended to multi-objective optimisation. A procedure is introduced, based on fuzzy clustering of Pareto calibration solutions in the parametric space and monitoring the overall optimality and robustness in the objective space. As a result, a fuzzy cluster with a certain degree of belongingness can be identified as the representative parametric region. The application of this method is illustrated for multiobjective calibration results of a five-parameter conceptual model using 24 USA MOPEX catchments and the results compared with other methods for selection of representative model parameters based on objective optimality of single and multi-objective solutions.", "num_citations": "7\n", "authors": ["537"]}
{"title": "Ensemble regression trees for time series predicitions\n", "abstract": " This paper propose to combine Bootstrap sam-pling and random subspace method for time series forecasting problems. The algorithm and methodology are described for the NN3 forecasting competition. A simple model selection approach based on minimizing in-sample Symmetric Mean Absolute Percent Error (SMAPE) is employed.", "num_citations": "7\n", "authors": ["537"]}
{"title": "Speciation techniques in evolved ensembles with negative correlation learning\n", "abstract": " The EENCL algorithm has been proposed as a method for designing neural network ensembles for classification tasks, combining global evolution with a local search based on gradient descent. Two mechanisms encourage diversity: negative correlation learning (NCL) and implicit fitness sharing. In order to better understand the success of EENCL, this work replaces speciation by fitness sharing with an island model population structure. We find that providing a population structure that allows for diversity to emerge, rather than enforcing diversity through a similarity penalty in the fitness evaluation, we are able to produce more accurate ensembles, since a more diverse population does not necessarily lead to a more accurate ensemble.", "num_citations": "7\n", "authors": ["537"]}
{"title": "A research-led and industry-oriented MSc program in natural computation\n", "abstract": " Natural computation is the study of computational systems that use ideas and get inspirations from natural systems, including biological, physical, chemical, economical and social systems. It covers many active research fields, such as evolutionary computation, neural computation, molecular computation, quantum computation, ecological computation, etc. It has made tremendous progress in academic research and real-world applications. Many university departments have been offering individual modules/courses in one form or another on related topics. However, few universities have been offering an entire postgraduate program in natural computation. This article summarises one such MSc program in natural computation at the University of Birmingham, UK.", "num_citations": "7\n", "authors": ["537"]}
{"title": "Lower bound on number of ADMs in WDM rings with nonuniform traffic demands\n", "abstract": " A new and tight lower bound on the number of ADMs with arbitrary nonuniform traffic demands in a SONET/WDM ring network is derived. Simulations show that this lower bound is much tighter than the previous one and for some cases it reaches the infimum.", "num_citations": "7\n", "authors": ["537"]}
{"title": "From evolving a single neural network to evolving neural network ensembles\n", "abstract": " Evolutionary artificial neural networks (EANNs) refer to a special class of artificial neural networks (ANNs) in which evolution is another fundamental form of adaptation in addition to learning. The evolution in EANNs is often simulated by an evolutionary algorithm. This chapter describes an evolutionary programming-based EANNs which learn both their weights and architectures simultaneously using a hybrid algorithm. A nonlinear ranking scheme and five mutation operators are used in our algorithm. These five mutation operators are applied sequentially and selectively to each individual in a population. Such sequential application encourages the evolution of smaller ANNs with fewer hidden nodes and connections. We have tested our evolutionary programmingbased EANNs on a wide range of problems, include parity problems of various size, the two-spiral problem, four different medical diagnosis problems, the Australian credit card problem, and a couple of time-series prediction problems. Very good results have been achieved. While the evolutionary approach to ANN design and training has produced some of the best results for many test problems, there are rooms for further improvements. For example, most evolutionary approaches to ANN design and training use an evolutionary algorithm to minimize certain error function. The best individual in a population gets most attention and is used as the final output from the evolutionary system. The rest of the population is discarded. We argue in this chapter that a population contains more useful information than the best individual. Such information can be used to improve the performance of\u00a0\u2026", "num_citations": "7\n", "authors": ["537"]}
{"title": "Time series prediction by using negatively correlated neural networks\n", "abstract": " Negatively correlated neural networks (NCNNs) have been proposed to design neural network (NN) ensembles [1]. The idea of NC-NNs is to encourage different individual NNs in the ensemble to learn different parts or aspects of a training data so that the ensemble can learn the whole training data better. The cooperation and specialisation among different individual NNs are considered during the individual NN design. This provides an opportunity for different NNs to interact with each other and to specialise. In this paper, NCNNs are applied to two time series prediction problems (i.e., the Mackey-Glass differential equation and the chlorophyll-a prediction in Lake Kasumigaura). The experimental results show that NCNNs can produce NN ensembles with good generalisation ability.", "num_citations": "7\n", "authors": ["537"]}
{"title": "Simulated Evolution and Learning First Asia-Pacific Conference, SEAL'96 Taejon, Korea, November 9\u201312, 1996 Seclected Papers\n", "abstract": " The 23 revised full papers were selected for inclusion in this book on the basis of 2 rounds of reviewing and improvements. Also included are invited papers by John L. Casti and Lawrence J. Fogel. The volume covers a wide range of current topics in simulated evolution and learning eg evolutionary optimization, evolutionary learning, artificial life, hybrid evolutionary fuzzy systems, evolutionary artificial neural networks, co-evolution, novel evolutionary approaches to computer tomography image reconstruction, power systems load flow control, and water flow control in cropped soils.", "num_citations": "7\n", "authors": ["537"]}
{"title": "Power transformer fault diagnosis considering data imbalance and data set fusion\n", "abstract": " Improving the accuracy of transformer dissolved gas analysis is always an important demand for power companies. However, the requirement for large numbers of fault samples becomes an obstacle to this demand. This article creatively uses a large number of health data, which is much easier to obtain by power companies, to improve diagnosis accuracy. Comprehensive investigations from the view of both data set and methodology to deal with this problem are presented. A data set consists of 9595 health samples and 993 fault samples is used for analysis. The characteristics of the data set and the influence of the health data on diagnostic accuracy are discussed. The performance of many state\u2010of\u2010art algorithms that handle the imbalanced problem is evaluated. Meanwhile, an efficient fault diagnosis algorithm named self\u2010paced ensemble (SPE) is presented. In SPE, classification hardness is proposed to\u00a0\u2026", "num_citations": "6\n", "authors": ["537"]}
{"title": "Microrobots Based In Vivo Evolutionary Computation in Two-Dimensional Microchannel Network\n", "abstract": " In vivo evolutionary computation is a novel knowledge-aided, microrobots-oriented tumor targeting framework, where externally manipulable microrobots are employed to detect the cancer in the human vascular network similar to the procedure of solving an optimization problem by swarm intelligence algorithms. The microrobots play the role of computational agents in the optimization procedure, the vascular network is the search space, and the tumor represents the maximum or minimum to be found by agents. Previous work on this topic provided basic computational models and search strategies, which, however, were solely verified in silico. In this letter, we use Janus microparticles as magnetic microrobots, a two-dimensional microchannel network as the human vasculature, and two representative test functions as the exemplar tumor-triggered biological gradient fields to validate in vitro the orthokinetic\u00a0\u2026", "num_citations": "6\n", "authors": ["537"]}
{"title": "SaaS for automated job performance appraisals using service technologies and big data analytics\n", "abstract": " In this paper, we present a new SaaS (software as a service) design for employee job performance appraisals, SaaS-JPA. We use IoT and computer systems to collect data related to the daily works of employees. A semantic model is developed to guide the data collection process, facilitate data interpretation and interoperation, and enable big data analysis to make job performance appraisal decisions. We also propose two new performance assessment models: The similarity-based relative performance model and the revenue-based performance model. These performance models are enabled by the service technologies and big data analytics. Finally, we discuss the design of SaaS-JPA.", "num_citations": "6\n", "authors": ["537"]}
{"title": "Speciated evolutionary algorithm for dynamic constrained optimisation\n", "abstract": " Dynamic constrained optimisation problems (DCOPs) have specific characteristics that do not exist in dynamic optimisation problems with bounded constraints or without constraints. This poses difficulties for some existing dynamic optimisation strategies. The maintaining/introducing diversity approaches might become less effective due to the presence of infeasible areas, and thus might not well handle with the switch of global optima between disconnected feasible regions. In this paper, a speciation-based approach was firstly proposed to overcome this, which utilizes deterministic crowding to maintain diversity, assortative mating and local search to promote exploitation, as well as feasibility rules to deal with constraints. The experimental studies demonstrate that the newly proposed method generally outperforms the state-of-the-art algorithms on a benchmark set of DCOPs.", "num_citations": "6\n", "authors": ["537"]}
{"title": "Learning in the model space for fault diagnosis\n", "abstract": " The emergence of large scaled sensor networks facilitates the collection of large amounts of real-time data to monitor and control complex engineering systems. However, in many cases the collected data may be incomplete or inconsistent, while the underlying environment may be time-varying or un-formulated. In this paper, we have developed an innovative cognitive fault diagnosis framework that tackles the above challenges. This framework investigates fault diagnosis in the model space instead of in the signal space. Learning in the model space is implemented by fitting a series of models using a series of signal segments selected with a rolling window. By investigating the learning techniques in the fitted model space, faulty models can be discriminated from healthy models using one-class learning algorithm. The framework enables us to construct fault library when unknown faults occur, which can be regarded as cognitive fault isolation. This paper also theoretically investigates how to measure the pairwise distance between two models in the model space and incorporates the model distance into the learning algorithm in the model space. The results on three benchmark applications and one simulated model for the Barcelona water distribution network have confirmed the effectiveness of the proposed framework.", "num_citations": "6\n", "authors": ["537"]}
{"title": "Co-learning segmentation in marketplaces\n", "abstract": " We present the problem of automatic co-niching in which potential suppliers of some product or service need to determine which offers to make to the marketplace at the same time as potential buyers need to determine which offers (if any) to purchase. Because both groups typically face incomplete or uncertain information needed for these decisions, participants in repeated market interactions engage in a learning process, making tentative decisions and adjusting these in the light of experiences they gain. Perhaps surprisingly, real markets typically then exhibit a form of parallel clustering: buyers cluster into segments of similar preferences and buyers into segments of similar offers. For computer scientists, the interesting question is whether such co-niching behaviours can be automated. We report on the first simulation experiments showing automated co-niching is possible using reinforcement learning in\u00a0\u2026", "num_citations": "6\n", "authors": ["537"]}
{"title": "Market-based control of computational systems: introduction to the special issue\n", "abstract": " We introduce the Special Issue of the journal on the topic of Market-Based Control of Computational Systems. The special issue collects six peer-reviewed papers arising from an International Workshop on the topic held in Liverpool, UK, in September 2008.", "num_citations": "6\n", "authors": ["537"]}
{"title": "Solving very difficult Japanese puzzles with a hybrid evolutionary-logic algorithm\n", "abstract": " In this paper we present a hybrid evolutionary algorithm to solve a popular logic-type puzzle, the so called Japanese puzzle. We propose to use the evolutionary algorithm in order to initialize a logic ad-hoc algorithm, which works as a local search and implicitly defines the fitness function of the problem. Two novel operators, one for initializing the evolutionary algorithm and a second one providing a novel type of mutation adapted to Japanese puzzles are described in the paper.", "num_citations": "6\n", "authors": ["537"]}
{"title": "Computational intelligence in economic games and policy design [Research Frontier]\n", "abstract": " Developing CI techniques for economic games and policies is a very promising and fast-growing field. Several interesting multi-disciplinary subfields exist, which require researchers of various disciplines to collaborate with each other and contribute to the advances of knowledge in this emerging new field. Obviously, in both computer science and economics, there are still many open questions and challenges, ranging from robustness issues to co-learning aspects, and from economic modeling, validation, and interpretation to large- scale simulation of complex adaptive systems. It is essential that such multi- disciplinary research challenges are tackled in a true multi disciplinary approach by both computer scientists and economists. We hope this short article will encourage more researchers and practitioners to join the exciting research in CI in economics.", "num_citations": "6\n", "authors": ["537"]}
{"title": "Hybridisation of particle swarm optimization and fast evolutionary programming\n", "abstract": " Particle swarm optimization (PSO) and fast evolutionary programming (FEP) are two widely used population-based optimisation algorithms. The ideas behind these two algorithms are quite different. While PSO is very efficient in local converging to an optimum due to its use of directional information, FEP is better at global exploration and finding a near optimum globally. This paper proposes a novel hybridisation of PSO and FEP, i.e., fast PSO (FPSO), where the strength of PSO and FEP is combined. In particular, the ideas behind Gaussian and Cauchy mutations are incorporated into PSO. The new FPSO has been tested on a number of benchmark functions. The preliminary results have shown that FPSO outperformed both PSO and FEP significantly.", "num_citations": "6\n", "authors": ["537"]}
{"title": "The evolution of evolutionary computation\n", "abstract": " Evolutionary computation has enjoyed a tremendous growth for at least a decade in both its theoretical foundations and industrial applications. Its scope has gone far beyond binary string optimisation using a simple genetic algorithm. Many research topics in evolutionary computation nowadays are not necessarily \u201dgenetic\u201d or \u201devolutionary\u201d in any biological sense. This talk will describe some recent research efforts in addressing several fundamental as well as more applied issues in evolutionary computation. Links with traditional computer science and artificial intelligence will be explored whenever appropriate.", "num_citations": "6\n", "authors": ["537"]}
{"title": "Adaptive divide-and-conquer using populations and ensembles\n", "abstract": " Adaptive Divide-and-Conquer Using Populations and Ensembles \u2014 University of Birmingham Skip to main navigation Skip to search Skip to main content University of Birmingham Home University of Birmingham Logo Help & FAQ Home Research output Profiles Research Units Projects Activities Datasets Equipment Prizes Press / Media Search by expertise, name or affiliation Adaptive Divide-and-Conquer Using Populations and Ensembles Xin Yao, MA Wani Computer Science Research output: Contribution to conference (unpublished) \u203a Paper Overview Original language English Pages 13-20 Number of pages 8 Publication status Published - 1 Jan 2003 Event 2003 International Conference on Machine Learning and Applications - Duration: 1 Jan 2003 \u2192 \u2026 Conference Conference 2003 International Conference on Machine Learning and Applications Period 1/01/03 \u2192 \u2026 Cite this APA Author BIBTEX Harvard \u2026", "num_citations": "6\n", "authors": ["537"]}
{"title": "Automatic discovery of relational information in comprehensible control rules by evolutionary algorithms\n", "abstract": " This paper examines the use of evolutionary methods in deriving comprehensible solutions in a relational problem domain. Evolution is used to manipulate a rule set with pre-defined relational functions to control the two-pole cart balancing problem. The evolved structures demonstrate that the representation can make use of relational information in a comprehensible rule set. Comprehensible solutions allow elucidation of the underlying behaviours and motivations of the control strategy derived, and also allow this knowledge to be shared and reused. This is demonstrated by solving the single pole balancing problem and using the rule set to seed solutions of the two-pole balancing problem.", "num_citations": "6\n", "authors": ["537"]}
{"title": "Benchmarking continuous dynamic optimization: Survey and generalized test suite\n", "abstract": " Dynamic changes are an important and inescapable aspect of many real-world optimization problems. Designing algorithms to find and track desirable solutions while facing challenges of dynamic optimization problems is an active research topic in the field of swarm and evolutionary computation. To evaluate and compare the performance of algorithms, it is imperative to use a suitable benchmark that generates problem instances with different controllable characteristics. In this article, we give a comprehensive review of existing benchmarks and investigate their shortcomings in capturing different problem features. We then propose a highly configurable benchmark suite, the generalized moving peaks benchmark, capable of generating problem instances whose components have a variety of properties, such as different levels of ill-conditioning, variable interactions, shape, and complexity. Moreover, components\u00a0\u2026", "num_citations": "5\n", "authors": ["537"]}
{"title": "Generative adversarial construction of parallel portfolios\n", "abstract": " Since automatic algorithm configuration methods have been very effective, recently there is increasing research interest in utilizing them for automatic solver construction, resulting in several notable approaches. For these approaches, a basic assumption is that the given training set could sufficiently represent the target use cases such that the constructed solvers can generalize well. However, such an assumption does not always hold in practice since in some cases, we might only have scarce and biased training data. This article studies effective construction approaches for the parallel algorithm portfolios that are less affected in these cases. Unlike previous approaches, the proposed approach simultaneously considers instance generation and portfolio construction in an adversarial process, in which the aim of the former is to generate instances that are challenging for the current portfolio, while the aim of the\u00a0\u2026", "num_citations": "5\n", "authors": ["537"]}
{"title": "Representation learning for heterogeneous information networks via embedding events\n", "abstract": " Network Representation Learning (NRL) has been widely used to analyze networks by mapping original networks into a low-dimensional vector space. However, existing NRL methods ignore the impact of properties of relations on the object relevance in heterogeneous information networks (HINs). To tackle this issue, this paper proposes a new NRL framework, called Event2vec, for HINs to consider both quantities and properties of relations during the representation learning process. Specifically, an event (i.e., a complete semantic unit) is used to represent the relation among multiple objects, and both event-driven first-order and second-order proximities are defined to measure the object relevance according to the quantities and properties of relations. We theoretically prove how event-driven proximities can be preserved in the embedding space by Event2vec, which utilizes event embeddings to facilitate\u00a0\u2026", "num_citations": "5\n", "authors": ["537"]}
{"title": "Efficient cluster-based boosting for semisupervised classification\n", "abstract": " Semisupervised classification (SSC) consists of using both labeled and unlabeled data to classify unseen instances. Due to the large number of unlabeled data typically available, SSC algorithms must be able to handle large-scale data sets. Recently, various ensemble algorithms have been introduced with improved generalization performance when compared to single classifiers. However, existing ensemble methods are not able to handle typical large-scale data sets. We propose efficient cluster-based boosting (ECB), a multiclass SSC algorithm with cluster-based regularization that avoids generating decision boundaries in high-density regions. A semisupervised selection procedure reduces time and space complexities by selecting only the most informative unlabeled instances for the training of each base learner. We provide evidences to demonstrate that ECB is able to achieve good performance with small\u00a0\u2026", "num_citations": "5\n", "authors": ["537"]}
{"title": "Search based recommender system using many-objective evolutionary algorithm\n", "abstract": " With the explosively increase of information and products, recommender systems have played a more and more important role in the recent years. Various recommendation algorithms, such as content-based methods and collaborative filtering methods, have been proposed. There are a number of performance metrics for evaluating recommender systems, and considering only the precision or diversity might be inappropriate. However, to the best of our knowledge, no existing work has considered recommendation with many objectives. In this paper, we model a many-objective search-based recommender system and adopt a recently proposed many-objective evolutionary algorithm to optimize it. Experimental results on the Movielens data set demonstrate that our algorithm performs better in terms of Generational Distance (GD), Inverted Generational Distance (IGD) and Hypervolume (HV) on most test cases.", "num_citations": "5\n", "authors": ["537"]}
{"title": "Increasingly cautious optimism for practical PAC-MDP exploration\n", "abstract": " Exploration strategy is an essential part of learning agents in model-based Reinforcement Learning. R-MAX and V-MAX are PAC-MDP strategies proved to have polynomial sample complexity; yet, their exploration behavior tend to be overly cautious in practice. We propose the principle of Increasingly Cautious Optimism (ICO) to automatically cut off unnecessarily cautious exploration, and apply ICO to R-MAX and V-MAX, yielding two new strategies, namely Increasingly Cautious R-MAX (ICR) and Increasingly Cautious V-MAX (ICV). We prove that both ICR and ICV are PACMDP, and show that their improvement is guaranteed by a tighter sample complexity upper bound. Then, we demonstrate their significantly improved performance through empirical results.", "num_citations": "5\n", "authors": ["537"]}
{"title": "Ensemble learning by negative correlation learning\n", "abstract": " This chapter investigates a specific ensemble learning approach by negative correlation learning (NCL) [21, 22, 23]. NCL is an ensemble learning algorithm which considers the cooperation and interaction among the ensemble members. NCL introduces a correlation penalty term into the cost function of each individual learner so that each learner minimizes its mean-square-error (MSE) error together with the correlation with other ensemble members.", "num_citations": "5\n", "authors": ["537"]}
{"title": "Fitness landscape-based parameter tuning method for evolutionary algorithms for computing unique input output sequences\n", "abstract": " Unique Input Output (UIO) sequences are used in conformance testing of Finite state machines (FSMs). Evolutionary algorithms (EAs) have recently been employed to search UIOs. However, the problem of tuning evolutionary algorithm parameters remains unsolved. In this paper, a number of features of fitness landscapes were computed to characterize the UIO instance, and a set of EA parameter settings were labeled with either \u2019good\u2019 or \u2019bad\u2019 for each UIO instance, and then a predictor mapping features of a UIO instance to \u2019good\u2019 EA parameter settings is trained. For a given UIO instance, we use this predictor to find good EA parameter settings, and the experimental results have shown that the correct rate of predicting \u2019good\u2019 EA parameters was greater than 93%. Although the experimental study in this paper was carried out on the UIO problem, the paper actually addresses a very important issue, i.e., a\u00a0\u2026", "num_citations": "5\n", "authors": ["537"]}
{"title": "The impact of mutation rate on the computation time of evolutionary dynamic optimization\n", "abstract": " Mutation has traditionally been regarded as an important operator in evolutionary algorithms. In particular, there have been many experimental studies which showed the effectiveness of adapting mutation rates for various static optimization problems. Given the perceived effectiveness of adaptive and self-adaptive mutation for static optimization problems, there have been speculations that adaptive and self-adaptive mutation can benefit dynamic optimization problems even more since adaptation and self-adaptation are capable of following a dynamic environment. However, few theoretical results are available in analyzing rigorously evolutionary algorithms for dynamic optimization problems. It is unclear when adaptive and self-adaptive mutation rates are likely to be useful for evolutionary algorithms in solving dynamic optimization problems. This paper provides the first rigorous analysis of adaptive mutation and its impact on the computation times of evolutionary algorithms in solving certain dynamic optimization problems. More specifically, for both individual-based and population-based EAs, we have shown that any time-variable mutation rate scheme will not significantly outperform a fixed mutation rate on some dynamic optimization problem instances. The proofs also offer some insights into conditions under which any time-variable mutation scheme is unlikely to be useful and into the relationships between the problem characteristics and algorithmic features (e.g., different mutation schemes).", "num_citations": "5\n", "authors": ["537"]}
{"title": "Co-evolution of optimal agents for the alternating offers bargaining game\n", "abstract": " Bargaining, as an instance of sequential games, is a widely studied problem in game theory, experimental and computational economics. We consider the problem of evolving computational agents with optimal (Subgame Perfect Equilibrium) strategies for the Alternating Offers Bargaining Game. Previous work co-evolving agents for this problem has argued that it is not possible to achieve optimal agents at the end of the co-evolutionary process due to the myopic properties of the evolutionary agents. Emphasising the notion of a co-evolutionary solution concept, we show that this conclusion is mis-leading and present a co-evolutionary algorithm that evolves optimal strategies for the bargaining game with one round. We conclude by explaining why, using previous evaluation procedures and strategy representations, the algorithm is not able to converge to optimal strategies for games with more rounds.", "num_citations": "5\n", "authors": ["537"]}
{"title": "Evolution of neural organization in a hydra-like animat\n", "abstract": " The role of efficient information processing in organizing nervous systems is investigated. For this purpose, we have developed a computational model termed the Hydramat Simulation Environment, so named since it simulates certain structural aspects of fresh water hydra. We compare the evolution of neural organization in architectures that remain static throughout their lifetimes and neural architectures that are perturbed by small random amounts. We find that (a) efficient information processing directly contributes to the structural organization of a model nervous system and (b) lifetime architectural perturbations can facilitate novel architectural features.", "num_citations": "5\n", "authors": ["537"]}
{"title": "Intelligent Data Engineering and Automated Learning-IDEAL 2007: 8th International Conference, Birmingham, UK, December 16-19, 2007, Proceedings\n", "abstract": " This book constitutes the refereed proceedings of the 8th International Conference on Intelligent Data Engineering and Automated Learning, IDEAL 2007, held in Birmingham, UK, in December 2007. The papers include topical sections on learning and information processing, data mining and information management, bioinformatics and neuroinformatics, agents and distributed systems, financial engineering and modeling, and agent-based approach to service sciences.", "num_citations": "5\n", "authors": ["537"]}
{"title": "A novel and practicable on-chip adaptive lossless image compression scheme using intrinsic evolvable hardware\n", "abstract": " Adaptive lossless image compression is one of the most important applications in the field of evolvable hardware (EHW). However, related studies in the past focused on implementations with extrinsic EHW, which uses a host computer to run software simulation and compiling, and then download the final circuit to the silicon chip. This is not suitable for tasks of on-chip adaptation. This paper presents a novel technique to reformulate the problem as a task of evolving a set of switches. As a result, the whole scheme can be implemented easily using intrinsic EHW. In order to enhance the scalability of the whole scheme, a strategy based on data-decomposition and pyramidal fitness evaluation strategy is developed for evolving larger scale images. Software simulation shows that the proposed method can largely reduce the computation time, and can scale up the image size up to 70 times with relatively slow increase in\u00a0\u2026", "num_citations": "5\n", "authors": ["537"]}
{"title": "Multi-objective ensemble construction, learning and evolution\n", "abstract": " An ensemble of learning machines has been theoretically and empirically shown to generalise better than single learners. Diversity and accuracy are two key properties that ensemble members should possess in order for this generalisation principle to hold. Viewing these properties as objectives, we take the position of rendering multi-objective evolutionary algorithms as effective solution concepts to the problem of ensemble construction and learning.", "num_citations": "5\n", "authors": ["537"]}
{"title": "Nature inspired creative design\u2014Bringing together ideas from nature, computer science, engineering, art, design\n", "abstract": " The Nature Inspired Creative Design network brings together people from three different main areas: Nature and Biology, Art and Design, and Science and Computing. It aims to establish a forum for crossfertilization between the disciplines, within the overall topic of adopting nature inspired approaches to creative design. Its members explore a wide range of subjects, including evolution, growth and development, emergence and self organization, robustness, natural structures, and human design behaviour and performance 1.", "num_citations": "5\n", "authors": ["537"]}
{"title": "Maximum cardinality matching by evolutionary algorithms\n", "abstract": " The analysis of time complexity of evolutionary algorithms has always focused on some artificial binary problems. This paper considers the average time complexity of an evolutionary algorithm for maximum cardinality matching in a graph. It is shown that the evolutionary algorithm can produce matchings with nearly maximum cardinality in average polynomial time.", "num_citations": "5\n", "authors": ["537"]}
{"title": "Evolutionary Optimization\n", "abstract": " Penalty functions are often used in constrained optimization. However, it is very dicult to strike the right balance between objective and penalty functions. This paper introduces a novel approach to balance objective and penalty functions stochastically, ie, stochastic ranking, and presents a new view on penalty function methods in terms of the dominance of penalty and objective functions. Some of the pitfalls of naive penalty methods are discussed in these terms. The new ranking method is tested using a (;) evolution strategy on 13 benchmark problems. Our results show that suitable ranking alone (ie, selection), without the introduction of complicated and specialized variation operators, is capable of improving the search performance signicantly.", "num_citations": "5\n", "authors": ["537"]}
{"title": "Evolving neural networks for chlorophyll-a prediction\n", "abstract": " The paper studies the application of evolutionary artificial neural networks to chlorophyll-a prediction in Lake Kasumigaura (in Japan). Unlike previous applications of artificial neural networks in this field, the architecture of the artificial neural network is evolved automatically rather than designed manually. The evolutionary system is able to find a near optimal architecture of the artificial neural network for the prediction task. Our experimental results have shown that evolved artificial neural networks are very compact and generalise well. The evolutionary system is able to explore a large space of possible artificial neural networks and discover novel artificial neural networks for solving a problem.", "num_citations": "5\n", "authors": ["537"]}
{"title": "Automatic discovery of comprehensible control rules by evolutionary algorithms\n", "abstract": " Computational intelligence techniques in control have facilitated the automatic generation of control strategies with little or no human input about the system. The present research examines the use of evolution in the generation of rule-based controllers for nonlinear problems, where the derived controllers are in a compact, comprehensible form. The approach is able to evolve rule structures simultaneously with the parameters required to automatically find controllers for non-linear control problems. Evolution enables the use of a complex, information rich data structure which expresses the solution to the control problem with information about how the system is being controlled. In particular, ripple-down rules were used in our study. This is quite different from any previous work on classical classifier systems where rules are simple binary strings [1].", "num_citations": "5\n", "authors": ["537"]}
{"title": "Memetic Search for Vehicle Routing with Simultaneous Pickup-Delivery and Time Windows\n", "abstract": " The Vehicle Routing Problem with Simultaneous Pickup-Delivery and Time Windows (VRPSPDTW) has attracted much research interest in the last decade, due to its wide application in modern logistics. Since VRPSPDTW is NP-hard and exact methods are only applicable to small-scale instances, heuristics and meta-heuristics are commonly adopted. In this paper we propose a novel Memetic Algorithm with efficienT local search and Extended neighborhood, dubbed MATE, to solve this problem. Compared to existing algorithms, the advantages of MATE lie in two aspects. First, it is capable of more effectively exploring the search space, due to its novel initialization procedure, crossover and large-step-size operators. Second, it is also more efficient in local exploitation, due to its sophisticated constant-time-complexity move evaluation mechanism. Experimental results on public benchmarks show that MATE\u00a0\u2026", "num_citations": "4\n", "authors": ["537"]}
{"title": "Analysis of evolutionary algorithms on fitness function with time-linkage property\n", "abstract": " In real-world applications, many optimization problems have the time-linkage property, that is, the objective function value relies on the current solution as well as the historical solutions. Although the rigorous theoretical analysis on evolutionary algorithms (EAs) has rapidly developed in recent two decades, it remains an open problem to theoretically understand the behaviors of EAs on time-linkage problems. This article takes the first step to rigorously analyze EAs for time-linkage functions. Based on the basic OneMax function, we propose a time-linkage function where the first bit value of the last time step is integrated but has a different preference from the current first bit. We prove that with probability    , randomized local search and (1 + 1) EA cannot find the optimum, and with probability    ,     EA is able to reach the optimum.", "num_citations": "4\n", "authors": ["537"]}
{"title": "Few-Shots Parallel Algorithm Portfolio Construction via Co-Evolution\n", "abstract": " Generalization, i.e., the ability of solving problem instances that are not available during the system design and development phase, is a critical goal for intelligent systems. A typical way to achieve good generalization is to learn a model from vast data. In the context of heuristic search, such a paradigm could be implemented as configuring the parameters of a parallel algorithm portfolio (PAP) based on a set of \u201ctraining\u201d problem instances, which is often referred to as PAP construction. However, compared to the traditional machine learning, PAP construction often suffers from the lack of training instances, and the obtained PAPs may fail to generalize well. This article proposes a novel competitive co-evolution scheme, named co-evolution of parameterized search (CEPS), as a remedy to this challenge. By co-evolving a configuration population and an instance population, CEPS is capable of obtaining generalizable\u00a0\u2026", "num_citations": "4\n", "authors": ["537"]}
{"title": "A novel CNET-assisted evolutionary level repairer and its applications to Super Mario Bros\n", "abstract": " Applying latent variable evolution to game level design has become more and more popular as little human expert knowledge is required. However, defective levels with illegal patterns may be generated due to the violation of constraints for level design. A traditional way of repairing the defective levels is programming specific rule-based repairers to patch the flaw. However, programming these constraints is sometimes complex and not straightforward. An autonomous level repairer which is capable of learning the constraints is needed. In this paper, we propose a novel approach, CNet, to learn the probability distribution of tiles giving its surrounding tiles on a set of real levels, and then detect the illegal tiles in generated new levels. Then, an evolutionary repairer is designed to search for optimal replacement schemes equipped with a novel search space being constructed with the help of CNet and a novel heuristic\u00a0\u2026", "num_citations": "4\n", "authors": ["537"]}
{"title": "Consensus learning for distributed fuzzy neural network in big data environment\n", "abstract": " Uncertainty and distributed nature inherently exist in big data environment. Distributed fuzzy neural network (D-FNN) that not only employs fuzzy logics to alleviate the uncertainty problem but also deal with data in a distributed manner, is effective and crucial for big data. Existing D-FNNs always avoided consensus for their antecedent layer due to computational difficulty. Hence such D-FNNs are not really distributed since a single model can not be agreed by multiple agents. This article proposes a true D-FNN model to handle the uncertainty and distributed challenges in the big data environment. The proposed D-FNN model considers consensus for both the antecedent and consequent layers. A novel consensus learning, which involves a distributed structure learning and a distributed parameter learning, is proposed to handle the D-FNN model. The proposed consensus learning algorithm is built on the well\u00a0\u2026", "num_citations": "4\n", "authors": ["537"]}
{"title": "How to evaluate solutions in Pareto-based search-based software engineering? A critical review and methodological guidance\n", "abstract": " With modern requirements, there is an increasing tendancy of considering multiple objectives/criteria simultaneously in many Software Engineering (SE) scenarios. Such a multi-objective optimization scenario comes with an important issue---how to evaluate the outcome of optimization algorithms, which typically is a set of incomparable solutions (ie, being Pareto non-dominated to each other). This issue can be challenging for the SE community, particularly for practitioners of Search-Based SE (SBSE). On one hand, multiobjective optimization may still be relatively new to SE/SBSE researchers, who may not be able to identify right evaluation methods for their problems. On the other hand, simply following the evaluation methods for general multiobjective optimisation problems may not be appropriate for specific SE problems, especially when the problem nature or decision maker's preferences are explicitly/implicitly\u00a0\u2026", "num_citations": "4\n", "authors": ["537"]}
{"title": "Toward efficient design space exploration for fault-tolerant multiprocessor systems\n", "abstract": " The design space exploration (DSE) of fault-tolerant multiprocessor systems is very complex, as it contains three interacting NP-hard problems: 1) task hardening; 2) task mapping; and 3) task scheduling. In addition, replication-based task hardening can introduce new tasks, called replicas, into the system, enlarging the design space further. As a population-based global optimization algorithm, evolutionary algorithms (EAs) have been widely used to explore this huge design space over the last decade. However, as analyzed in this paper, the search space of previous works is highly redundant, resulting in poor efficiency and scalability. This paper proposes an efficient EA-based DSE method for the design of large-scale fault-tolerant multiprocessor systems. The main novelties of this paper include: 1) mapping exploration is explicitly separated, i.e., task mapping is optimized during the evolutionary search, while\u00a0\u2026", "num_citations": "4\n", "authors": ["537"]}
{"title": "Explicit planning for efficient exploration in reinforcement learning\n", "abstract": " Efficient exploration is crucial to achieving good performance in reinforcement learning. Existing systematic exploration strategies (R-MAX, MBIE, UCRL, etc.), despite being promising theoretically, are essentially greedy strategies that follow some predefined heuristics. When the heuristics do not match the dynamics of Markov decision processes (MDPs) well, an excessive amount of time can be wasted in travelling through already-explored states, lowering the overall efficiency. We argue that explicit planning for exploration can help alleviate such a problem, and propose a Value Iteration for Exploration Cost (VIEC) algorithm which computes the optimal exploration scheme by solving an augmented MDP. We then present a detailed analysis of the exploration behaviour of some popular strategies, showing how these strategies can fail and spend O (n2md) or O (n2m+ nmd) steps to collect sufficient data in some tower-shaped MDPs, while the optimal exploration scheme, which can be obtained by VIEC, only needs O (nmd), where n, m are the numbers of states and actions and d is the data demand. The analysis not only points out the weakness of existing heuristic-based strategies, but also suggests a remarkable potential in explicit planning for exploration.", "num_citations": "4\n", "authors": ["537"]}
{"title": "Hydrodynamic coefficients identification of pitch and heave using multi-objective evolutionary algorithm\n", "abstract": " The parameters of ship heave and pitch motions obtained by system identification is a popular approach in recent years. However, the single-objective optimization algorithm can only get one group of parameters, and these parameters are usually fail to achieve the optimal state of the heave and pitch motions simultaneously. To address this situation, we develop a multi-objective strategy to identify the parameters of pitch and heave coupled motions. We discuss the mathematical models for heave and pitch coupled motions and the unknown parameters in these equations are then identified using NSGA II, MOEA/D and MOPSO approaches. Firstly, the forming filters are modeled for the wave disturb and the wave force of heave and moment of pitch are simulated, and then the multi-objective functions and constrained conditions are designed and a decision maker are used to help the customer to select the proper\u00a0\u2026", "num_citations": "4\n", "authors": ["537"]}
{"title": "What weights work for you\n", "abstract": " The quality of solution sets generated by decomposition-based evolutionary multiobjective optimisation (EMO) algorithms depends heavily on the consistency between a given problem\u2019s Pareto front shape and the specified weights\u2019 distribution. A set of weights distributed uniformly in a simplex often lead to a set of well-distributed solutions on a Pareto front with a simplex-like shape, but may fail on other Pareto front shapes. It is an open problem on how to specify a set of appropriate weights without the information of the problem\u2019s Pareto front beforehand. In this paper, we propose an approach to adapt weights during the evolutionary process (called AdaW). AdaW progressively seeks a suitable distribution of weights for the given problem by elaborating several key parts in weight adaptation\u2014weight generation, weight addition, weight deletion, and weight update frequency. Experimental results have shown the effectiveness of the proposed approach. AdaW works well for Pareto fronts with very different shapes: 1) the simplex-like, 2) the inverted simplex-like, 3) the highly nonlinear, 4) the disconnect, 5) the degenerate, 6) the scaled, and 7) the highdimensional.", "num_citations": "4\n", "authors": ["537"]}
{"title": "Simulated annealing and joint manufacturing batch-sizing\n", "abstract": " We address an important problem of a manufacturing system. The system procures raw materials from outside suppliers in a lot and processes them to produce finished goods. It proposes an ordering policy for raw materials to meet the requirements of a production facility. In return, this facility has to deliver finished products demanded by external buyers at fixed time intervals. First, a general cost model is developed considering both raw materials and finished products. Then this model is used to develop a simulated annealing approach to determining an optimal ordering policy for procurement of raw materials and also for the manufacturing batch size to minimize the total cost for meeting customer demands in time. The solutions obtained were compared with those of traditional approaches. Numerical examples are presented.", "num_citations": "4\n", "authors": ["537"]}
{"title": "Complex coevolutionary dynamics\u2014Structural stability and finite population effects\n", "abstract": " Unlike evolutionary dynamics, coevolutionary dynamics can exhibit a wide variety of complex regimes. This has been confirmed by numerical studies, e.g., in the context of evolutionary game theory (EGT) and population dynamics of simple two-strategy games with various types of replication and selection mechanisms. Using the framework of shadowing lemma, we study to what degree can such infinite population dynamics: 1) be reliably simulated on finite precision computers; and 2) be trusted to represent coevolutionary dynamics of possibly very large, but finite, populations. In a simple EGT setting of two-player symmetric games with two pure strategies and a polymorphic equilibrium, we prove that for (\u03bc,\u03bb), truncation, sequential tournament, best-of-group tournament, and linear ranking selections, the coevolutionary dynamics do not possess the shadowing property. In other words, infinite population simulations\u00a0\u2026", "num_citations": "4\n", "authors": ["537"]}
{"title": "Benchmark generator for the IEEE WCCI-2014 competition on evolutionary computation for dynamic optimization problems: dynamic rotation peak benchmark generator (DRPBG) and\u00a0\u2026\n", "abstract": " Based on our previous benchmark generator for the IEEE CEC\u201912 Competition on Dynamic Optimization, this report updates the two benchmark instances where two new features have 1been developed as well as a constraint to the benchmark instance of the dynamic rotation peak benchmark generator. The source code in C++ language for the two benchmark instances is included in the library of EAlib, which is an open platform to test and compare the performances of EAs.", "num_citations": "4\n", "authors": ["537"]}
{"title": "Evolutionary dynamic optimization: Challenges and perspectives\n", "abstract": " The field of evolutionary dynamic optimization is concerned with the study and application of evolutionary algorithms to dynamic optimization problems. In this chapter we highlight some of the challenges associated with the time-variant nature of these problems.We focus particularly on the different problem definitions that have been proposed, the modelling of dynamic optimization problems in terms of benchmark suites and the way the performance of an algorithm is assessed. Amid significant developments in the last decade, several practitioners have highlighted shortcomings with all of these fundamental issues. In this chapter we review the work done in each of these areas, evaluate the criticism and subsequently identify some perspectives for the future of the field.", "num_citations": "4\n", "authors": ["537"]}
{"title": "Market niching in multi-attribute computational resource allocation systems\n", "abstract": " We propose a novel method for allocating multi-attribute computational resources via competing marketplaces. Trading agents, working on behalf of resource consumers and providers, choose to trade in resource markets where the resources being traded best align with their preferences and constraints. Market-exchange agents, in competition with each other, attempt to provide resource markets that attract traders, with the goal of maximising their profit. Because exchanges can only partially observe global supply and demand schedules, novel strategies are required to automate their search for market niches. Novel attribute-level selection (ALS) strategies are empirically analysed in simulated competitive market environments, and results suggest that using these strategies, market-exchanges can seek out market niches under a variety of environmental conditions.", "num_citations": "4\n", "authors": ["537"]}
{"title": "Selected applications of natural computing\n", "abstract": " The study of Natural Computation has borne several fruits for science, industry and commerce. By providing exemplary strategies for designing complex biological organisms, nature has suggested ways in which we can explore design spaces and develop innovative new products. By exhibiting examples of effective cooperation among organisms, nature has hinted at new ideas for search and control engineering. By showing us how highly interconnected networks of simple biological processing units can learn and adapt, nature has paved the way for our development of computational systems that can discriminate between complex patterns, and improve their abilities over time. And the list goes on. It is instructive to note that the methods we use that have been inspired by nature are far more than simply \u2018alternative approaches\u2019 to the problems and applications that they address. In many domains, nature-inspired methods have broken through barriers in the erstwhile achievements and capabilities of \u2018classical\u2019computing. In many cases, the role of natural inspiration in such breakthroughs can be viewed as that of a strategic pointer, or a kind of \u2018tie-breaker\u2019. For example, there are many, many ways that one might build complex multi-parameter statistical models for general use in classification or prediction; however, nature has extensive experience in a particular area of this design space, namely neural networks\u2013this inspiration has guided much of the machine learning and pattern recognition community towards exploiting a particular style of statistical approach that has proved extremely successful. Similar can be said of the use of immune\u00a0\u2026", "num_citations": "4\n", "authors": ["537"]}
{"title": "Evolutionary market agents and heterogeneous service providers: Achieving desired resource allocations\n", "abstract": " In future massively distributed service-based computational systems, resources will span many locations, organisations and platforms. In such systems, the ability to allocate resources in a desired configuration, in a scalable and robust manner, will be essential.We build upon a previous evolutionary market-based approach to achieving resource allocation in decentralised systems, by considering heterogeneous providers. In such scenarios, providers may be said to value their resources differently. We demonstrate how, given such valuations, the outcome allocation may be predicted. Furthermore, we describe how the approach may be used to achieve a stable, uneven load-balance of our choosing. We analyse the system's expected behaviour, and validate our predictions in simulation. Our approach is fully decentralised; no part of the system is weaker than any other. No cooperation between nodes is assumed\u00a0\u2026", "num_citations": "4\n", "authors": ["537"]}
{"title": "Infeasibility driven evolutionary algorithm for constrained optimization\n", "abstract": " A number of population based optimization algorithms have been proposed in recent years to solve unconstrained and constrained single and multi-objective optimization problems. Most of such algorithms inherently prefer a feasible solution over an infeasible one during the course of search, which translates to approaching the constraint boundary from the feasible side of the search space. Previous studies [1],[2] have already demonstrated the benefits of explicitly maintaining a fraction of infeasible solutions in Infeasiblity Driven Evolutionary Algorithm (IDEA) for single and multiobjective constrained optimization problems. In this paper, the benefits of IDEA as a sub-evolve mechanism are highlighted for dynamic, constrained single objective optimization problems. IDEA is particularly attractive for such problems as it offers a faster rate of convergence over a conventional EA, which is of significant interest in dynamic optimization problems. The algorithm is tested on two new dynamic constrained test problems. For both the problems, the performance of IDEA is found to be significantly better than conventional EA. I.", "num_citations": "4\n", "authors": ["537"]}
{"title": "A online demo of evolutionary programming using mixed mutation strategy for solving function optimization\n", "abstract": " This paper presents an online demo of evolutionary programming using a mixed mutation strategy for solving function optimization problems. The strategy combines three different mutation operators: Gaussian, Cauchy and L\u00e9vy mutations. The algorithm has been implemented by a client-server web application, which is convenient for users to access through Internet. The web application architecture is divided into two parts: a client to deal with users\u2019 input and a server to execute the computation. Experiments have shown that EP using mixed mutation strategies can produce high quality solutions on most of 14 benchmark functions.", "num_citations": "4\n", "authors": ["537"]}
{"title": "A selected introduction to evolutionary computation\n", "abstract": " There have been many different views and definitions about evolu- tionary computation. Some regard evolutionary computation as genetic algorithms (GAs), although GAs are only one of many possible types of evolutionary algorithms (EAs). In this chapter, we will take a much broader view of what evolutionary computation is by emphasizing its computational nature. In short, evolutionary computation refers to the study of computational systems that use ideas and draw inspirations from natural evolution. Evolutionary computation techniques can be used to solve a wide range of practical problems in optimization, machine learning and design. This chapter gives a brief introduction to evolutionary computation. A few important issues that may have been overlooked in evolutionary computation will be emphasized. Pointers to further details in the literature will be given whenever appropriate.", "num_citations": "4\n", "authors": ["537"]}
{"title": "Genetic design of GMDH-type neural networks for modelling of thermodynamically pareto optimized turbojet engines.\n", "abstract": " Firstly, a multi-objective genetic algorithm (GAs) is used for Pareto based optimization of thermodynamic cycle of ideal turbojet engines considering four important conflicting thermodynamic objectives, namely, specific thrust (ST), specific fuel consumption (SFC), propulsive efficiency (h p), and thermal efficiency (h t). This provides the best Pareto front of such four-objective optimization from the space of design variables, which are Mach number and pressure ratio, to the space of the above-mentioned four thermo-mechanical objective functions. Secondly, genetic algorithms (GA) with a new encoding scheme are used for optimal design of both connectivity configuration and the values of coefficients, respectively, involved in GMDH-type neural networks for the inverse modelling of the input-output data table obtained as the best Pareto front.", "num_citations": "4\n", "authors": ["537"]}
{"title": "Applications of Evolutionary Computing: EvoWorkshops 2001: EvoCOP, EvoFlight, EvoIASP, EvoLearn, and EvoSTIM, Como, Italy, April 18-20, 2001 Proceedings\n", "abstract": " This book constitutes the refereed proceedings of five application-oriented workshops held concurrently as EvoWorkshops 2001 in Como, Italy in April 2001. The 52 revised full papers presented were carefully reviewed and selected out of 75 submissions. The papers are organized in topical sections on graph problems, Knapsack problems, ant algorithms, assignment problems, evolutionary algorithms analysis, permutative problems, aeronautics, image analysis and signal processing, evolutionary learning, and evolutionary scheduling and timetabling.", "num_citations": "4\n", "authors": ["537"]}
{"title": "Evolutionary design calibration\n", "abstract": " Evolutionary methods are nowb eginning to be used routinely in design applications. However, even with computing speeds growing continuously, for many complex design problems evolutionary computing times are so long that their use is not practical. Divide and conquer based methods sometimes improve the situation, but in most cases the biggest speed improvement can be gained by adding domain knowledge. Combining evolutionary methods with conventional design methods is one way of doing this. This paper shows how evolutionary computation can be used to improve designs created by conventional design methods. A digital filter design problem is used to illustrate howa conventionally derived design can be further improved by evolutionary calibration. Our experimental results showthat the evolutionary calibration algorithm is able to consistently improve the original designs by a\u00a0\u2026", "num_citations": "4\n", "authors": ["537"]}
{"title": "A preliminary study into evolutionary search of an approximated n-dimensional landscape\n", "abstract": " Finding the global optimum on a large, multimodal, complex, and discontinuous (or nondifferentiable) landscape is usually very hard, even using the evolutionary approach. However, some of these complex landscapes can be approximated and smoothened without changing the nature of the problem, ie, without modifying the global optimum and its location. The approximated and smoothened landscape is often much easier to search than the original one. Our previous work on the combination of landscape approximation and local search (LALS) with evolutionary algorithms has shown some very promising results along this direction [11]. This paper further extends our previous method and proposes a novel evolutionary algorithm with n-dimensional approximation (EANA). The n-dimensional approximation can be regarded as a recombination operator in our new algorithm which integrates evolutionary and local search. Numerical experiments have been carried out to show the effectiveness and efficiency of the propo...", "num_citations": "4\n", "authors": ["537"]}
{"title": "Special issue on evolutionary computation,\"\n", "abstract": " Evolutionary computation is the study of computational systems that use ideas and get inspirations from natural evolution. There has been a sharp increase of interest in the field in recent years. The first five papers included in this special issue are selected from papers presented at the AI'93 Workshop on Evolutionary Computation held at the Grand Hyatt Hotel, Melbourne, Australia, on 16 November 1993. Although the papers do not represent all the subfields of evolutionary computation, they do cover the three major branches, ie, genetic algorithms, evolution strategies and evolutionary programming.The first five papers address a wide range of issues related to evolutionary computation. The paper by Crosher discusses the evolution of adaptive processes in simulated environments. He tries to confirm his hypothesis that``the answer to the question of how adaptive or learning processes can evolve is through an\u00a0\u2026", "num_citations": "4\n", "authors": ["537"]}
{"title": "Robust Optimization in Uncertain Capacitated Arc Routing Problems: Progresses and Perspectives\n", "abstract": " The capacitated arc routing problem is an important NP-hard problem with numerous real-world applications. The capacitated arc routing problem with uncertainties refers to those instances where there are uncertainties in decision variables, objective functions and/or constraints. The capacitated arc routing problem with uncertainties captures real-world situations much better than a static capacitated arc routing problem because few real-world problems are static and certain. Uncertainties in the capacitated arc routing problem pose new research challenges. Algorithms that work well for a static and certain capacitated arc routing problem may not work on the version with uncer-tainties. There have been increasing progresses in studying the capacitated arc routing problem with uncertainties during the past two decades. However, the papers on the capacitated arc rout-ing problem with uncertainties have been\u00a0\u2026", "num_citations": "3\n", "authors": ["537"]}
{"title": "NGA-inspired nanorobots-assisted detection of multifocal cancer\n", "abstract": " We propose a new framework of computing-inspired multifocal cancer detection procedure (MCDP). Under the rubric of MCDP, the tumor foci to be detected are regarded as solutions of the objective function, the tissue region around the cancer areas represents the parameter space, and the nanorobots loaded with contrast medium molecules for cancer detection correspond to the optimization agents. The process that the nanorobots detect tumors by swimming in the high-risk tissue region can be regarded as the process that the agents search for the solutions of an objective function in the parameter space with some constraints. For multimodal optimization (MMO) aiming to locate multiple optimal solutions in a single simulation run, the niche technology has been widely used. Specifically, the niche genetic algorithm (NGA) has been shown to be particularly effective in solving MMO. It can be used to identify the\u00a0\u2026", "num_citations": "3\n", "authors": ["537"]}
{"title": "Self-awareness for autonomous systems\n", "abstract": " The articles in this month\u2019s special issue cover concepts and fundamentals, architectures and techniques, and applications and case studies in the exciting area of self-awareness in autonomous systems.", "num_citations": "3\n", "authors": ["537"]}
{"title": "Dynamic multi-objective optimization of the travelling thief problem\n", "abstract": " Investigation of detailed and complex optimisation problem formulations that reflect realistic scenarios is a burgeoning field of research. A growing body of work exists for the Travelling Thief Problem, including multi-objective formulations and comparisons of exact and approximate methods to solve it. However, as many realistic scenarios are non-static in time, dynamic formulations have yet to be considered for the TTP. Definition of dynamics within three areas of the TTP problem are addressed; in the city locations, availability map and item values. Based on the elucidation of solution conservation between initial sets and obtained non-dominated sets, we define a range of initialisation mechanisms using solutions generated via solvers, greedily and randomly. These are then deployed to seed the population after a change and the performance in terms of hypervolume and spread is presented for comparison. Across a range of problems with varying TSP-component and KP-component sizes, we observe interesting trends in line with existing conclusions; there is little benefit to using randomisation as a strategy for initialisation of solution populations when the optimal TSP and KP component solutions can be exploited. Whilst these separate optima don't guarantee good TTP solutions, when combined, provide better initial performance and therefore in some examined instances, provides the best response to dynamic changes. A combined approach that mixes solution generation methods to provide a composite population in response to dynamic changes provides improved performance in some instances for the different dynamic TTP formulations\u00a0\u2026", "num_citations": "3\n", "authors": ["537"]}
{"title": "Algorithm portfolio for individual-based surrogate-assisted evolutionary algorithms\n", "abstract": " Surrogate-assisted evolutionary algorithms (SAEAs) are powerful optimisation tools for computationally expensive problems (CEPs). However, a randomly selected algorithm may fail in solving unknown problems due to no free lunch theorems, and it will cause more computational resource if we re-run the algorithm or try other algorithms to get a much solution, which is more serious in CEPs. In this paper, we consider an algorithm portfolio for SAEAs to reduce the risk of choosing an inappropriate algorithm for CEPs. We propose two portfolio frameworks for very expensive problems in which the maximal number of fitness evaluations is only 5 times of the problem's dimension. One framework named Par-IBSAEA runs all algorithm candidates in parallel and a more sophisticated framework named UCB-IBSAEA employs the Upper Confidence Bound (UCB) policy from reinforcement learning to help select the most\u00a0\u2026", "num_citations": "3\n", "authors": ["537"]}
{"title": "Surrogate-assisted expensive many-objective optimization by model fusion\n", "abstract": " Surrogate-assisted evolutionary algorithms have played an important role in expensive optimization where a small number of real-objective function evaluations are allowed. Usually, the surrogate models are used for the same purpose, e.g., to approximate the real-objective function or the aggregation fitness function. However, there is little work on surrogate-assisted optimization by model fusion, i.e., different surrogate models are fused for different purposes to improve the performance of the algorithm. In this work, we propose a surrogate-assisted approach by model fusion for solving expensive many-objective optimization problems, in which the Kriging assisted objective function approximation method is fused with the classifier assisted approach. The proposed algorithm is compared with some state-of-the-art surrogate-assisted algorithms on DTLZ problems and a real-world problem, and some encouraging\u00a0\u2026", "num_citations": "3\n", "authors": ["537"]}
{"title": "Solving Incremental Optimization Problems via Cooperative Coevolution\n", "abstract": " Engineering designs can involve multiple stages, where at each stage, the design models are incrementally modified and optimized. In contrast to traditional dynamic optimization problems, where the changes are caused by some objective factors, the changes in such incremental optimization problems (IOPs) are usually caused by the modifications made by the decision makers during the design process. While existing work in the literature is mainly focused on traditional dynamic optimization, little research has been dedicated to solving such IOPs. In this paper, we study how to adopt cooperative coevolution to efficiently solve a specific type of IOPs, namely, those with increasing decision variables. First, we present a benchmark function generator on the basis of some basic formulations of IOPs with increasing decision variables and exploitable modular structure. Then, we propose a contribution-based\u00a0\u2026", "num_citations": "3\n", "authors": ["537"]}
{"title": "Maximizing non-monotone/non-submodular functions by multi-objective evolutionary algorithms\n", "abstract": " Evolutionary algorithms (EAs) are a kind of nature-inspired general-purpose optimization algorithm, and have shown empirically good performance in solving various real-word optimization problems. However, due to the highly randomized and complex behavior, the theoretical analysis of EAs is difficult and is an ongoing challenge, which has attracted a lot of research attentions. During the last two decades, promising results on the running time analysis (one essential theoretical aspect) of EAs have been obtained, while most of them focused on isolated combinatorial optimization problems, which do not reflect the general-purpose nature of EAs. To provide a general theoretical explanation of the behavior of EAs, it is desirable to study the performance of EAs on a general class of combinatorial optimization problems. To the best of our knowledge, this direction has been rarely touched and the only known result is the provably good approximation guarantees of EAs for the problem class of maximizing monotone submodular set functions with matroid constraints, which includes many NP-hard combinatorial optimization problems. The aim of this work is to contribute to this line of research. As many combinatorial optimization problems also involve non-monotone or non-submodular objective functions, we consider these two general problem classes, maximizing non-monotone submodular functions without constraints and maximizing monotone non-submodular functions with a size constraint. We prove that a simple multi-objective EA called GSEMO can generally achieve good approximation guarantees in polynomial expected running time.", "num_citations": "3\n", "authors": ["537"]}
{"title": "Improvement of reference points for decomposition based multi-objective evolutionary algorithms\n", "abstract": " A multi-objective optimization problem\u00a0(MOP) involves simultaneous minimization or maximization of more than one conflicting objectives. Such problems are commonly encountered in a number of domains, such as engineering, finance, operations research, etc. In the recent years, algorithms based on decomposition have shown commendable success in solving MOPs. In particular they have been helpful in overcoming the limitation of Pareto-dominance based ranking when the number of objectives is large. Decomposition based evolutionary algorithms divide an MOP into a number of simpler sub-problems and solve them simultaneously in a cooperative manner. In order to define the sub-problems, a reference point is needed to construct reference vectors in the objective space to guide the corresponding sub-populations. However, the effect of the choice of this reference point has been scarcely\u00a0\u2026", "num_citations": "3\n", "authors": ["537"]}
{"title": "Combining conformal prediction and genetic programming for symbolic interval regression\n", "abstract": " Symbolic regression has been one of the main learning domains for Genetic Programming. However, most work so far on using genetic programming for symbolic regression only focus on point prediction. The problem of symbolic interval regression is for each input to find a prediction interval containing the output with a given statistical confidence. This problem is important for many risk-sensitive domains (such as in medical and financial applications). In this paper, we propose the combination of conformal prediction and genetic programming for solving the problem of symbolic interval regression. We study two approaches called black-box conformal prediction genetic programming (black-box CPGP) and white-box conformal prediction genetic programming (white-box CPGP) on a number of benchmarks and previously used problems. We compare the performance of these approaches with two popular interval\u00a0\u2026", "num_citations": "3\n", "authors": ["537"]}
{"title": "Experience-based optimization: A coevolutionary approach\n", "abstract": " This paper studies improving solvers based on their past solving experiences, and focuses on improving solvers by offline training. Specifically, the key issues of offline training methods are discussed, and research belonging to this category but from different areas are reviewed in a unified framework. Existing training methods generally adopt a two-stage strategy in which selecting the training instances and training instances are treated in two independent phases. This paper proposes a new training method, dubbed LiangYi, which addresses these two issues simultaneously. LiangYi includes a training module for a population-based solver and an instance sampling module for updating the training instances. The idea behind LiangYi is to promote the population-based solver by training it (with the training module) to improve its performance on those instances (discovered by the sampling module) on which it performs badly, while keeping the good performances obtained by it on previous instances. An instantiation of LiangYi on the Travelling Salesman Problem is also proposed. Empirical results on a huge testing set containing 10000 instances showed LiangYi could train solvers that perform significantly better than the solvers trained by other state-of-the-art training method. Moreover, empirical investigation of the behaviours of LiangYi confirmed it was able to continuously improve the solver through training.", "num_citations": "3\n", "authors": ["537"]}
{"title": "Heuristic optimization for software project management with impacts of team efficiency\n", "abstract": " Most of the studies on project scheduling problems assume that every assigned participant or every team of the same number of participants, completes tasks with an equal efficiency, but this is usually not the case for real world problems. This paper presents a more realistic and complex model with extra consideration on team efficiency which are quantitatively measured on employee-task assignment. This study demonstrates the impacts of team efficiency in a well-studied software project management problem. Moreover, this study illustrates how a heuristic optimization method, population-based incremental learning, copes with such added complexity. The experimental results show that the resulting near optimal solutions not only satisfy constraints, but also reflect the impacts of team efficiency. The findings will hopefully motivate future studies on comprehensive understandings of the quality and efficiency of\u00a0\u2026", "num_citations": "3\n", "authors": ["537"]}
{"title": "A Q-learning based evolutionary algorithm for sequential decision making problems\n", "abstract": " Both Evolutionary Dynamic Optimization (EDO) methods and Reinforcement Learning (RL) methods tackle forms of Sequential Decision Making Problems (SDMPs), yet with different key assumptions. In this paper, we combine the strength of both EDO methods and RL methods to develop a new algorithm for SDMPs. Assuming that the environmental state is observable and that a computational model of the reward function is available, the key idea in our algorithm is to employ an evolutionary algorithm to search on the reward function at each time step, the outcome of which is exploited to speed up convergence to optimal policies in RL methods. Some preliminary experimental studies demonstrate that our algorithm is a promising approach for SDMPs.", "num_citations": "3\n", "authors": ["537"]}
{"title": "A Unified Markov Chain Approach to Analysing Randomised Search Heuristics\n", "abstract": " The convergence, convergence rate and expected hitting time play fundamental roles in the analysis of randomised search heuristics. This paper presents a unified Markov chain approach to studying them. Using the approach, the sufficient and necessary conditions of convergence in distribution are established. Then the average convergence rate is introduced to randomised search heuristics and its lower and upper bounds are derived. Finally, novel average drift analysis and backward drift analysis are proposed for bounding the expected hitting time. A computational study is also conducted to investigate the convergence, convergence rate and expected hitting time. The theoretical study belongs to a prior and general study while the computational study belongs to a posterior and case study.", "num_citations": "3\n", "authors": ["537"]}
{"title": "Ubiquity symposium: Evolutionary computation and the processes of life: evolutionary computation in physical world\n", "abstract": " In this ninth symposium article, Luk\u00e1\u0161 Sekanina addresses evolutionary and evolvable hardware; answering the questions what it means for a physical system to be designed evolutionarily and on what kinds of computations such physical systems perform will be answered.", "num_citations": "3\n", "authors": ["537"]}
{"title": "Revision\n", "abstract": " 4. One can invent as many different forms of search operators, whether they are called crossover/, utation or not, as they like, as long as the probability of finding the global optimal solution from the offspring is higher than that from the parent. We can use the generic term of search operators or random variations.", "num_citations": "3\n", "authors": ["537"]}
{"title": "A diversity dilemma in evolutionary markets\n", "abstract": " Markets are useful mechanisms for performing resource allocation in fully decentralised computational and other systems, since they can possess a range of desirable properties, such as efficiency, decentralisation, robustness and scalability. In this paper we investigate the behaviour of co-evolving evolutionary market agents as adaptive offer generators for sellers in a multi-attribute posted-offer market. We demonstrate that the evolutionary approach enables sellers to automatically position themselves in market niches, created by heterogeneous buyers. We find that a trade-off exists for the evolutionary sellers between maintaining high population diversity to facilitate movement between niches and low diversity to exploit the current niche and maximise cumulative payoff. We characterise the trade-off from the perspective of the system as a whole, and subsequently from that of an individual seller. Our results\u00a0\u2026", "num_citations": "3\n", "authors": ["537"]}
{"title": "Ensemble Learning through Diversity Management: Theory, Algorithms, and Applications\n", "abstract": " Ensemble Learning through Diversity Management: Theory, Algorithms, and Applications Page 1 Ensemble Learning through Diversity Management: Theory, Algorithms, and Applications Huanhuan Chen and Xin Yao School of Computer Science University of Birmingham *Slides and references available at http://www.cs.bham.ac.uk/~hxc/tutorial/ IJCNN 2011 Page 2 Outline \u2022 An overview of ensemble methods \u2022 Diversity generation methods \u2022 Theoretical analysis of diversity \u2022 Mange diversity in ensemble \u2013 Semi-supervised learning \u2013 Ensemble pruning \u2013 Multi-objective optimization \u2022 Further topics and open discussions Page 3 Ensemble \u2026\u2026 model 1 model 2 model k Ensemble model Ensemble is a group of learners that work together as a committee to solve a problem. Combine multiple models into one! Data Page 4 One Example \u2022 Certain problems are just too difficult for a given classifier to solve \u2022 Separate two \u2026", "num_citations": "3\n", "authors": ["537"]}
{"title": "The minimum redundancy\u2013maximum relevance approach to building sparse support vector machines\n", "abstract": " Recently, building sparse SVMs becomes an active research topic due to its potential applications in large scale data mining tasks. One of the most popular approaches to building sparse SVMs is to select a small subset of training samples and employ them as the support vectors. In this paper, we explain that selecting the support vectors is equivalent to selecting a number of columns from the kernel matrix, and is equivalent to selecting a subset of features in the feature selection domain. Hence, we propose to use an effective feature selection algorithm, namely the Minimum Redundancy \u2013 Maximum Relevance (MRMR) algorithm to solve the support vector selection problem. MRMR algorithm was then compared to two existing methods, namely back-fitting (BF) and pre-fitting (PF) algorithms. Preliminary results showed that MRMR generally outperformed BF algorithm while it was inferior to PF algorithm, in\u00a0\u2026", "num_citations": "3\n", "authors": ["537"]}
{"title": "Theoretical foundations of evolutionary computation\n", "abstract": " In recent decades, evolutionary algorithms have been used successfully to solve a wide range of optimization problems. However, a review of the literature suggests that the theoretical works on evolutionary algorithms are still lagging behind their applications. This special issue features three of the latest theoretical contributions, each representing a different theoretical aspect of evolutionary algorithms. These three papers were initially selected from SEAL\u201906 and further extended from the authors\u2019 original works. The extended papers were again rigorously reviewed in two rounds by at least three anonymous reviewers. In the first paper, Mitavskiy, Rowe, Wright and Schmitt present a study of the properties of Markov chains modelling evolutionary algorithms, by using a quotient construction method. This innovative Markov chains quotient construction method provides a simpler way for deduction of known and new\u00a0\u2026", "num_citations": "3\n", "authors": ["537"]}
{"title": "Learning IPD strategies through co-evolution\n", "abstract": " Complex behavioral interactions can be abstracted and modelled using a game. One particular aspect in modelling interactions that is of great interest is in understanding the specific conditions that lead to cooperation between selfish individuals. The iterated prisoner\u2019s dilemma (IPD) game is one famous example. In its classical form, two players engaged in repeated interactions, are given two choices: cooperate and defect [Axelrod (1984)]. The dilemma of the game is captured by having both players who are better off mutually cooperating than mutually defecting being vulnerable to exploitation by one of the party who defects. Although the IPD game has become a popular model to study conditions for cooperation to occur among selfish individuals, which was due in large part to a series of tournaments reported in [Axelrod (1980a, b)], it has also received much attention in many other areas of study, and used to model social, economic, and biological interactions [Axelrod (1984)].The classical IPD can be easily defined as a nonzero-sum, noncooperative, two-player game [Chellapilla and Fogel (1999)]. It is nonzero-sum because the benefits that a player obtains do not necessarily lead to similar penalties given to the other player. It is noncooperative because it assumes no preplay communication between the two players. The IPD game can be formulated by considering a predefined payoff matrix that specifies the payoff that a player receives for the choice it makes for a particular move given the choice that the opponent makes. Referring", "num_citations": "3\n", "authors": ["537"]}
{"title": "Towards intrinsic evolvable hardware for predictive lossless image compression\n", "abstract": " This paper presents a novel method for predictive lossless image compression via evolving a set of switches, which can be implemented easily by intrinsic evolvable hardware mode. A set of compounded mutations for binary chromosome through combining the local asexually reproducing with multiple mean step size search was proposed, and a gradually approach method for evolving larger scale images was fabricated. Experimental results show that the proposed method can reduce the computing time much more, and can scale up the image size increasing up to 70 times with relative slower increase speed of computing time.", "num_citations": "3\n", "authors": ["537"]}
{"title": "Salting route optimisation using XRWIS and evolutionary computation\n", "abstract": " With limited resources and treatment time constraints, it is imperative that salting routes are planned in advance for efficient and effective winter road maintenance. To aid this process, a salting route optimisation system which combines evolutionary algorithms with the neXt generation Road Weather Information System (XRWIS) has been developed. The system can cope with large-scale instances in the real world within reasonable computation times, to the extent that daily dynamic salting route optimisation can be realised. However, the use of a dynamic system, that each day adjusts salting routes in line with forecast road temperatures, may increase complexity to the extent that user error will occur in the treatment regime. Therefore, a robust (static) solution of salting route optimisation is also presented. Here, the emphasis is placed on thermally ranking optimised routes so that the'warmer'routes could be left untreated on marginal nights.", "num_citations": "3\n", "authors": ["537"]}
{"title": "Environments conducive to evolution of modularity\n", "abstract": " Modularity has been recognised as one of the crucial aspects of natural complex systems. Since these are results of evolution, it has been argued that modular systems must have selective advantages over their monolithic counterparts. Simulation results with artificial neuro-evolutionary complex systems, however, are indecisive in this regard. It has been shown that advantages of modularity, if judged on a static task, in these systems are very much dependent on various factors involved in the training of these systems. We present a couple of dynamic environments and argue that environments like these might be partly responsible for the evolution of modular systems. These environments allow for a better, more direct use of structural information present within modular systems hence limit the influence of other factors. We support these arguments with the help of a co-evolutionary model and a fitness\u00a0\u2026", "num_citations": "3\n", "authors": ["537"]}
{"title": "Diversity creation in local search for the evolution of neural network ensembles.\n", "abstract": " The EENCL algorithm [1] automatically designs neural network ensembles for classification, combining global evolution with local search based on gradient descent. Two mechanisms encourage diversity: Negative Correlation Learning (NCL) and implicit fitness sharing. This paper analyses EENCL, finding that NCL is not an essential component of the algorithm, while implicit fitness sharing is. Furthermore, we find that a local search based on independent training is equally effective in both accuracy and diversity. We propose that NCL is unnecessary in EENCL for the tested datasets, and that complementary diversity in local search and global evolution may lead to better ensembles.", "num_citations": "3\n", "authors": ["537"]}
{"title": "Computational neuronal oscillation with morlet wavelet transform\n", "abstract": " Computational neuronal oscillation with Morlet wavelet transform \u2014 University of Birmingham Skip to main navigation Skip to search Skip to main content University of Birmingham Home University of Birmingham Logo Help & FAQ Home Research output Profiles Research Units Projects Activities Datasets Equipment Prizes Press / Media Search by expertise, name or affiliation Computational neuronal oscillation with Morlet wavelet transform Xiaoli Li, Xin Yao, JRG Jeffreys, J Fox Computer Science Research output: Contribution to conference (unpublished) \u203a Paper 13 Citations (Scopus) Overview Original language English Publication status Published - 1 Jan 2005 Event 27th Annual International Conference of the IEEE Engineering in Medicine and Biology Society - Duration: 1 Jan 2005 \u2192 \u2026 Conference Conference 27th Annual International Conference of the IEEE Engineering in Medicine and Biology Society \u2026", "num_citations": "3\n", "authors": ["537"]}
{"title": "Understanding and Predicting Dynamical Behaviours in Financial Markets: Financial Application Research in CERCIA\n", "abstract": " The Centre of Excellence for Research in Computational Intelligence and Applications (CERCIA) is a unique new initiative, aimed to be an international leader in applied research and knowledge transfer of computational intelligence techniques for the benefit of industry and business. Computational finance research is one of the applied areas, which is of interest to CERCIA.In this paper, we shall very briefly present some of our research work in computational finance that has been carried out so far since the inception of CERCIA. Six research studies with different subjects are summarised here. The techniques that we employ in the studies vary from evolutionary computation approaches (eg genetic programming), signal processing techniques (eg the power spectrum, the wavelet analysis, the correlation) to fractal analysis methods (eg detrended fluctuation analysis, fractal geometry). The applied areas range from stock market predictions, stock picking, automatic trading strategies and financial market understanding, etc. Some of the studies have already been published, whilst some are still in the pipeline and others are just in their initial stages. Thus, the quality of work is varied.", "num_citations": "3\n", "authors": ["537"]}
{"title": "To understand one-dimensional continuous fitness landscapes by drift analysis\n", "abstract": " This work shows that we could describe the characteristics of easy and hard fitness landscapes in one-dimensional continuous space by drift analysis. The work expends the existing results in the discrete space into the continue space. A fitness landscape, here, is regarded as the behaviour of an evolutionary algorithm on fitness functions. Based on the drift analysis, easy fitness landscapes are thought to be a \"short-distance\" landscape, which is easy for the evolutionary algorithm to find the optimal point; and hard fitness landscapes then are as a far-distance landscape, which the evolutionary algorithm had to spend a long time to find the optimal point.", "num_citations": "3\n", "authors": ["537"]}
{"title": "How powerful/efficient is your evolutionary algorithm\n", "abstract": " Unlike the analysis of deterministic algorithms, which is usually about the worst case, we need to consider the mean (average) of the first hitting time in our case. Many existing tools used in analysing complexity are difficult to be applied to evolutionary algorithms. We need \u2018new\u2019analytical tools and a unified framework for analysing different EAs for different problems, and for convergence, computation time, characterisation of EA-hardness/-easiness,...\u2013p. 6", "num_citations": "3\n", "authors": ["537"]}
{"title": "Simulated annealing for solving a manufacturing batch-sizing problem\n", "abstract": " Simulated Annealing for Solving a Manufacturing Batch-Sizing Problem Page 1 This paper addresses the problem of a manufacturing system that procures raw materials from suppliers in a lot and processes them to convert into finished products. It proposes an ordering policy for raw materials to meet the requirements of a production facility. In turn, this facility must deliver finished products demanded by outside buyers at fixed time intervals. First, a general cost model is developed considering both raw materials and finished products. Then this model is used to develop a simulated annealing approach to determining an optimal ordering policy for procurement of raw materials and also for the manufacturing batch size to minimize the total cost for meeting customer demand on time. The solutions obtained were compared with those of traditional approaches. Numerical examples are presented. Simulated Annealing for \u2026", "num_citations": "3\n", "authors": ["537"]}
{"title": "Maintaining population diversity by minimizing mutual information\n", "abstract": " Based on negative correlation learning [1] and evolutionary learning, evolutionary ensembles with negative correlation learning (EENcL) was proposed for learning and designing of neural network ensembles [2]. The idea of EENcL is to regard the population of neural networks as an ensemble, and the evolutionary process as the design of neural network ensembles. EENcL used a fitness sharing based on the covering set. \u042buch fitness sharing did not make accurate measurement on the similarity in the population. In this paper, a fitness sharing scheme based on mutual information is introduced in EENcL to evolve a diverse and cooperative population. The effectiveness of such evolutionary learning approach was tested on two real-world problems.", "num_citations": "3\n", "authors": ["537"]}
{"title": "\u2019Evolving rules for nonlinear control\u2019\n", "abstract": " Computational intelligence techniques in control have facilitated the automatic generation of control strategies with little or no human input about the control system. The present research examines the use of evolution in the generation of rule-based controllers for difficult nonlinear problems, where the derived controllers are in a compact, comprehensible form. The approach is able to evolve rule structures simultaneously with the parameters required to automatically find controllers for non-linear control problems. Evolution enables the use of a complex, infor-mation rich data structure which expresses the solution to the control problem with information about how the system is being controlled.", "num_citations": "3\n", "authors": ["537"]}
{"title": "Evolutionary computation comes of age\n", "abstract": " Evolutionary computation is a field of study of computational systems which uses ideas and gets inspirations from natural evolution and adaptation. Although the history of evolutionary computation can be traced back to 1950s, it was only in the last decade or so that the field started to grow rapidly. In recent years, there have been many successful applications of various evolutionary computation techniques in artificial intelligence, machine learning, numerical optimization, combinatorial optimization, etc. The theory of evolutionary computation has also been enriched greatly. There is a much better understanding of why and how evolutionary computation techniques work (or do not work) than five or six years ago. This article reports some of the latest developments presented at the recent 1999 Congress on Evolutionary Computation (CEC '99).", "num_citations": "3\n", "authors": ["537"]}
{"title": "How does evolutionary computation fit into IT postgraduate teaching\n", "abstract": " Evolutionary computation courses have been offered by a wide range of departments/schools to students with many different backgrounds. The paper describes three postgraduate courses with significant evolutionary computation components, offered by the University College of the University of New South Wales at the Australian Defence Force Academy. The courses have been offered as part of the Master of Science in Information Technology programme and Master of Science in Operations Research and Statistics programme. The paper also summarises the result of a recent survey on evolutionary computation teaching conducted over the Internet.", "num_citations": "3\n", "authors": ["537"]}
{"title": "Recent New Development in Evolutionary Programming\n", "abstract": " Evolutionary programming (EP) is one of the major branches of evolutionary computation. It has been applied to many learning and optimisation problems with success in recent years. This paper gives an overview of the latest results on evolutionary programming. In particular, the paper will analyse why the recently proposed fast EP performs better than classical EP for most benchmark functions, discuss the scalability of EP, and demonstrate how EP has been used to solve the function optimisation problem and neural network design problem.", "num_citations": "3\n", "authors": ["537"]}
{"title": "A Note on Neural Sorting Networks with 0 (1) Time Complexity\n", "abstract": " Xin Yao Department of Computer Science University College, The University of New South Wales Australian Defence Force Academy, Canberra, ACT, Australia 2600", "num_citations": "3\n", "authors": ["537"]}
{"title": "A Study of Maximum Matching on Boltzmann Machines\n", "abstract": " The Boltzmann machine is one of the most popular neural network models used to cope with difficult combinatorial optimisation problems. It has been used to find near optimum solutions to such hard problems as graph partitioning and the Travelling Salesman problem. However, very little is known about the time complexity of solving combinatorial optimisation problems on Boltzmann machines. This issue is important because it will help us better understand the power of Boltzmann machines in dealing with hard problems. This paper studies the time complexity of maximum matching in a graph on Boltzmann machines. It is shown that some widely-used Boltzmann machines cannot find a maximum matching in average time polynomial in the number of nodes of the graph although there are conventional deterministic algorithms which solve the problem in polynomial time. On the other hand, this paper also shows\u00a0\u2026", "num_citations": "3\n", "authors": ["537"]}
{"title": "When non-elitism meets time-linkage problems\n", "abstract": " Many real-world applications have the time-linkage property, and the only theoretical analysis is recently given by Zheng, et al. (TEVC 2021) on their proposed time-linkage OneMax problem, OneMax. However, only two elitist algorithms (1+1)EA and (+1)EA are analyzed, and it is unknown whether the non-elitism mechanism could help to escape the local optima existed in OneMax. In general, there are few theoretical results on the benefits of the non-elitism in evolutionary algorithms. In this work, we analyze on the influence of the non-elitism via comparing the performance of the elitist (1+)EA and its non-elitist counterpart (1,)EA. We prove that with probability  (1+)EA will get stuck in the local optima and cannot find the global optimum, but with probability , (1,)EA can reach the global optimum and its expected runtime is  with  for the constant . Noting that a smaller offspring size is helpful for escaping from the local optima, we further resort to the compact genetic algorithm where only two individuals are sampled to update the probabilistic model, and prove its expected runtime of . Our computational experiments also verify the efficiency of the two non-elitist algorithms.", "num_citations": "2\n", "authors": ["537"]}
{"title": "In vivo computing strategies for tumor sensitization and targeting\n", "abstract": " Several evolution strategies for in vivo computation are proposed with the aim of realizing tumor sensitization and targeting (TST) by externally manipulable nanoswimmers. In such targeting systems, nanoswimmers assembled by magnetic nanoparticles are externally manipulated to search for the tumor in the high-risk tissue by a rotating magnetic field produced by a coil system. This process can be interpreted as in vivo computation, where the tumor in the high-risk tissue corresponds to the global maximum or minimum of the in vivo optimization problem, the nanoswimmers are seen as the computational agents, the tumor-triggered biological gradient field (BGF) is used for fitness evaluation of the agents, and the high-risk tissue is the search space. Considering that the state-of-the-art magnetic nanoswimmer control method can only actuate all the nanoswimmers heading in the same direction simultaneously, we\u00a0\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "Representing experience in continuous evolutionary optimisation through problem-tailored search operators\n", "abstract": " Evolutionary algorithms are a class of population-based meta-heuristic methods partially inspired by natural evolution. Specifically, they rely on stochastic variation and selection processes to sequentially find optimal solutions of a function of interest. We attempt in this work to extract preferences in these stochastic evolutionary operators in form of empirical and improved distributions as basis for model-based mutation operators. The latter can be considered as representing problem-tailored search operators which exist independently from the optimisation run and thus can be transferred to similar problem instances. This offline approach is different to existing model-based optimisation techniques, e.g. EDA's, CMA-ES and Bayesian approaches, where adaption happens rather in an online manner without the influence of prior experience. Our approach can be rather considered to follow the recent line of research on\u00a0\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "Few-shots Parameter Tuning via Co-evolution\n", "abstract": " Generalization, ie, the ability of addressing problem instances that are not available during the system design and development phase, is a critical goal for intelligent systems. A typical way to achieve good generalization is to exploit vast data to train a model. In the context of heuristic search, such a paradigm is termed parameter tuning or algorithm configuration, ie, configuring the parameters of a search method based on a set of\" training\" problem instances. However, compared to its counterpart in machine learning, parameter tuning could more often suffer from the lack of training instances, and the obtained configuration may fail to generalize. This paper suggests competitive co-evolution as a remedy to this challenge and proposes a framework named Co-Evolution of Parameterized Search (CEPS). By alternately evolving a configuration population and an instance population, CEPS is capable of obtaining\u00a0\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "Self-adaptive decomposition and incremental hyperparameter tuning across multiple problems\n", "abstract": " The Capacitated Arc Routing Problem (CARP) is a NP-hard combinatorial optimisation problem with numerous real-world applications. Several divide-and-conquer approaches, controlled by one or more hyperparameters, have been proposed to tackle large-scale CARPs. The tuning of hyperparameters can be computationally expensive due to the lack of priori knowledge, the size of the configuration space, and the time required for solving a CARP instance. Motivated by this time consuming task, we propose a scalable approach based on self-adaptive hierarchical decomposition (SASAHiD) to scale up existing methods. We take a state-of-the-art decomposition method for large-scale CARPs called SAHiD as an example to carry out experiments on two sets of real-world CARP instances with hundreds to thousands of tasks. The results demonstrate that SASAHiD outperforms SAHiD significantly with fewer\u00a0\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "Learning transferable variation operators in a continuous genetic algorithm\n", "abstract": " The notion of experience has often been neglected within the domain of evolutionary computation while in machine learning a large variety of methods has emerged in the recent years under the umbrella of transfer learning. Notably, realizing experience-based methods suffers from a variety of conceptual key problems. The first one being in regards to what constitutes problem-similarity from an algorithm perspective and the second one being what constitutes the transferable experience by itself. Ideally, one would envision that a learning optimization algorithm could be expected to act similarly to a human-problem solver who tackles novel tasks initially without any preconceptions. Experience only comes into play until sufficient similarity to known problems is established. Our paper therefore has two aims. First, to outline existing related fields and methodologies and highlight their insufficiencies. Second, to make\u00a0\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "Learning Time-Series Data of Industrial Design Optimization using Recurrent Neural Networks\n", "abstract": " In automotive digital development, 3D shape morphing techniques are used to create new designs in order to match design targets, such as aerodynamic or stylistic requirements. Control-point based shape morphing alters existing geometries either through human user interactions or through computational optimization algorithms that optimize for product performance targets. Shape morphing is typically continuous and results in potentially large data sets of time-series recordings of control point movements. In the present paper, we utilize recurrent neural networks to model such time-series recordings in order to predict future design steps based on the history of currently performed design modifications. To build a data set sufficiently large for the training of neural networks, we use target shape matching optimization as digital analogy for a human user interactive shape modification and to build data sets of control\u00a0\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "Computing-inspired detection of multiple cancers\n", "abstract": " A new computing-inspired multiple-cancer detection procedure (MCDP) is proposed. In the MCDP, the cancer areas to be detected can be regarded as solutions of an objective function, the tissue region around the cancer areas can be mapped to the parameter space of the solutions, and the nanorobots correspond to the agents in the optimization procedure. The process that the nanorobots look for the cancer areas by swimming in the tissue region can be mapped to the process that the agents search for the solutions in the parameter space. Niche Genetic Algorithm (NGA) is widely used in multimodal function optimization and non-monotonic function optimization. It can search all global optimums of multiple hump function in a running, keep the diversity of the population effectively, and avoid premature of solutions got from normal GA. Inspired by the optimization procedure of NGA, the multiple cancer detection\u00a0\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "Log-normality and skewness of estimated state/action values in reinforcement learning\n", "abstract": " Under/overestimation of state/action values are harmful for reinforcement learning agents. In this paper, we show that a state/action value estimated using the Bellman equation can be decomposed to a weighted sum of path-wise values that follow log-normal distributions. Since log-normal distributions are skewed, the distribution of estimated state/action values can also be skewed, leading to an imbalanced likelihood of under/overestimation. The degree of such imbalance can vary greatly among actions and policies within a single problem instance, making the agent prone to select actions/policies that have inferior expected return and higher likelihood of overestimation. We present a comprehensive analysis to such skewness, examine its factors and impacts through both theoretical and empirical results, and discuss the possible ways to reduce its undesirable effects.", "num_citations": "2\n", "authors": ["537"]}
{"title": "Surrogate model assisted multi-objective differential evolution algorithm for performance optimization at software architecture level\n", "abstract": " This paper proposes a surrogate model assisted differential evolutionary algorithm for performance optimization at the software architecture (SA) level, which is named SMDE4PO. In SMDE4PO, different strategies of crossover and mutation are adopted to enhance the algorithm\u2019s search capability and speed up its convergence. Random forests are used as surrogate models to reduce the time of performance evaluation (i.e., fitness evaluation). Our comparative experiments on four different sizes of cases between SMDE4PO and NSGA-II are conducted. From the results, we can conclude that (1) SMDE4PO is significantly better than NSGA-II according to the three quality indicators of Contribution, Generation Distance and Hyper Volume; (2) By using random forests as surrogates, the run time of SMDE4PO is reduced by up to 48% in comparison with NSGA-II in our experiments.", "num_citations": "2\n", "authors": ["537"]}
{"title": "Touchable computation: Computing-inspired bio-detection\n", "abstract": " We propose a new computing-inspired bio-detection framework called touchable computation (TouchComp). Under the rubric of TouchComp, the best solution in the parameter space is associated with the target to be detected. A population of externally steerable agents locate the optimal solution by moving through the parameter space, whose landscape (objective function) may be altered by these agents but the location of the best solution remains unchanged. Thus, one can infer the parameter space by observing the movement of agents. The term \u201ctouchable\u201d emphasizes the framework's similarity to controlling by touching the screen with a finger, where the external field for controlling and tracking acts as the finger. We apply the TouchComp model to cancer detection, where the target is the cancer, the parameter space is the tissue region at high risk of malignancy, and agents are nanorobots loaded with\u00a0\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "Improving the performance of evolutionary engine calibration algorithms with principal component analysis\n", "abstract": " By studying the fitness landscape properties of engine calibration problem we propose a new Principal Component Analysis (PCA) based optimisation algorithm for the problem. The engine calibration problem in this paper is to minimise the fuel consumption, gas emission and particle emission of a Jaguar car engine. To evaluate the fuel consumption and emissions of the engine, a model of the engine that was developed in University of Birmingham was used. A strength Pareto method is used to convert the three objectives into one fitness value. Then a local search algorithm is used to find local optima. We then study these local optima to find the properties of good solutions in the landscape. Our studies on the good solutions show that the best solutions in the landscape show some patterns. We perform Principal Component Analysis (PCA) on the good solutions and show that these components present certain\u00a0\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "A multi-modal optimization approach to single path planning for unmanned aerial vehicle\n", "abstract": " In the past few years, Evolutionary Algorithms (EAs) based UAV path planners have drawn increasing research interests. However, they are not scalable to large-scale problems, i.e., lots of waypoints. Recently, we have proposed a novel EA-based framework, named Separately Evolving Waypoints (SEW), that can deal with large-scale problems. However, the difficulty of UAV path planning depends not only on the number of waypoints, but on the number of constraints it has to satisfy, especially the number of obstacles. In particular, the number of waypoints required is also partly determined by the number of constraints. Hence, it is critical to further improve SEW with respect to large number of obstacles. Originally, a state-of-the-art global optimization approach is employed. In this work, we discuss how the increasing number of obstacles will deteriorate the performance of the global optimizer, then we propose\u00a0\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "The performance effects of interaction frequency in parallel cooperative coevolution\n", "abstract": " Cooperative coevolution (CC) employs a divide-and-conquer paradigm for tackling complex optimization problems. Its performance is influenced by many design decisions. Therefore, to beneficially use it, it is important to acquire some knowledge of the effects of different design settings on the performance of CC. In this paper, we investigate experimentally the performance effects of interaction frequency in parallel CC. The experimental results show that it is overall best for subpopulations to interact with each other as frequently as possible when communication cost is ignored; when communication cost is considered, the best interaction frequency varies from problem to problem and a dynamic change of it is desirable during the optimization process.", "num_citations": "2\n", "authors": ["537"]}
{"title": "Self-aware and self-expressive systems\n", "abstract": " Engineering self-awareness and self-expression in computing systems is an emerging trend in design and operation of modern computing systems, which have increasingly complex, heterogeneous structures and growing requirements. Embedded avionics systems could make particularly good use of self-awareness and self-expression. These concepts offer flexibility to avionic subsystems, allowing them to adapt and deal with the lack of knowledge, changes and unpredictability of their deployment environments, and also to work around or even overcome their functional and performance limitations due to their strict weight, power, size and density constraints. Many efforts have been made previously to integrate selfawareness in computing systems. Some studies, such as that by Cox, consider self-awareness as a part of metacognition. 1 Other studies, such as that of Agarwal, focus on self-awareness in computing systems as an ability of a system to explicitly consider knowledge about itself. 2 As for the concept of self-expression, it has barely been considered in the engineering and computer science context.Given the disparate and occasionally overly rigid use of the term \u2018self-awareness\u2019 in the literature and the lack of previous treatment of the idea of self-expression in the computing and engineering literature, we developed a more general working definition for self-aware and self-expressive computing systems inspired by biology. Based upon that working definition and with the aim of guiding the design of self-aware and self-expressive systems, we developed a reference architectural framewok which structures their requirements. 3 Then\u00a0\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "Challenges and opportunities in dynamic optimisation\n", "abstract": " Dynamic optimisation has been studied for many years within the evolutionary computation community. Many strategies have been proposed to tackle the challenge, eg, memory schemes, multiple populations, random immigrants, restart schemes, etc. This talk will first review a few of such strategies in dealing with dynamic optimisation. Then some less researched areas are discussed, including dynamic constrained optimisation, dynamic combinatorial optimisation, time-linkage problems, and theoretical analyses in dynamic optimisation. A couple of theoretical results, which were rather unexpected at the first sight, will be mentioned. Finally, a few future research directions are highlighted. In particular, potential links between dynamic optimisation and online learning are pointed out as an interesting and promising research direction in combining evolutionary computation with machine learning.", "num_citations": "2\n", "authors": ["537"]}
{"title": "Theoretical advances in evolutionary dynamic optimization\n", "abstract": " The field of evolutionary dynamic optimization is concerned with the study and application of evolutionary algorithms to dynamic optimization problems: a significant number of new algorithms have been proposed in recent years that are designed specifically to overcome the limitations faced by traditional algorithms in the dynamic domain. Subsequently, a wealth of empirical studies have been published that evaluate the performance of these algorithms on a variety of benchmark problems. However, very few theoretical results have been obtained during this time. This relative lack of theoretical findings makes it difficult to fully assess the strengths and weaknesses of the individual algorithms. In this chapter we provide a review of theoretical advances in evolutionary dynamic optimization. In particular, we argue the importance of theoretical results, highlight the challenges faced by theoreticians and\u00a0\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "Embrace the New Trend in SBSE with Fitness-Landscape Based Adaptive Evolutionary Algorithm\n", "abstract": " Search Based Software Engineering (SBSE) has seen its success in the last decade. A new trend has recently emerged to explore the potential of SBSE in adaptivity, and to achieve the grand vision of selfoptimised software systems. This paper proposes a Fitness Landscape-Based Adaptive Algorithm, for tackling software engineering problems with complex problem structure or dynamic features.", "num_citations": "2\n", "authors": ["537"]}
{"title": "Evolution of neural symmetry and its coupled alignment to body plan morphology\n", "abstract": " Body morphology is thought to have heavily influenced the evolution of neural architecture. However, the extent of this interaction and its underlying principles are largely unclear. To help us elucidate these principles, we examine the artificial evolution of a hypothetical nervous system embedded in a fish-inspired animat. The aim is to observe the evolution of neural structures in relation to both body morphology and required motor primitives. Our investigations reveal that increasing the pressure to evolve a wider range of movements also results in higher levels of neural symmetry. We further examine how different body shapes affect the evolution of neural structure; we find that, in order to achieve optimal movements, the neural structure integrates and compensates for asymmetrical body morphology. Our study clearly indicates that different parts of the animat-specifically, nervous system and body plan-evolve in\u00a0\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "An efficient particle swarm optimizer for multi-level redundancy allocation problem\n", "abstract": " Redundancy allocation problem (RAP) has attracted much attention during the past thirty years due to its wide and valuable applications to improve the reliability in designing phase of various engineering systems. Up to now, most simulated systems in these attempts have focused on singlelevel systems whereas real world engineering systems always contain multiple levels where the entire system at the highest level, components at the lowest level, and subsystems locate at levels in between. Thus, it is desirable to study the redundancy allocation problem on multi-level systems, which is referred to as multi-level redundancy allocation problem (MLRAP). Now there are only two approaches to tackle with the MLRAP, however, when the complexity of MLRAP increases (ie, the infeasible solution space becomes very small, or the employed simulation system becomes very large), both approaches cannot work well. In\u00a0\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "Profiling of mass spectrometry data for ovarian cancer detection using negative correlation learning\n", "abstract": " This paper proposes a novel Mass Spectrometry data profiling method for ovarian cancer detection based on negative correlation learning (NCL). A modified Smoothed Nonlinear Energy Operator (SNEO) and correlation-based peak selection were applied to detected informative peaks for NCL to build a prediction model. In order to evaluate the performance of this novel method without bias, we employed randomization techniques by dividing the data set into testing set and training set to test the whole procedure for many times over. The classification performance of the proposed approach compared favorably with six machine learning algorithms.", "num_citations": "2\n", "authors": ["537"]}
{"title": "Adaptive differential evolution for multi-objective optimization\n", "abstract": " No existing multi-objective evolutionary algorithms (MO-EAs) have ever been applied to problems with more than 1000 real-valued decision variables. Yet the real world is full of large and complex multi-objective problems. Motivated by the recent success of SaNSDE [1], an adaptive differential evolution algorithm that is capable of dealing with more than 1000 real-valued decision variables effectively and efficiently, this paper extends the ideas behind SaNSDE to develop a novel MOEA named MOSaNSDE. Our preliminary experimental studies have shown that MOSaNSDE outperforms state-of-the-art MOEAs significantly on most problems we have tested, in terms of both convergence and diversity metrics. Such encouraging results call for a more in-depth study of MOSaNSDE in the future, especially about its scalability.", "num_citations": "2\n", "authors": ["537"]}
{"title": "Toward a gene regulatory network model for evolving chemotaxis behavior\n", "abstract": " Inspired from bacteria, a gene regulatory network model for signal transduction is presented in this paper. After describing experiments on stabilizing the population size for sustained open-ended evolution, we examine the ability of the model to evolve gradient-following behavior resembling bacterial chemotaxis. Under the conditions defined in this paper, an overwhelming chemotaxis behavior does not seem to emerge. Further experimentation suggests that chemotaxis is selectively favored, however, it is shown that the gradient information, which is critical for evolving chemotaxis, is heavily degraded under the current regime. It is hypothesized that lack of consistent gradient information results in the selection of non chemotaxis behavior. Future work on revising the model as well as the environmental setups is discussed.", "num_citations": "2\n", "authors": ["537"]}
{"title": "Hybridisation of evolutionary programming and machine learning with k-nearest neighbor estimation\n", "abstract": " Evolutionary programming (EP) focus on the search step size which decides the ability of escaping local minima, however does not touch the issue of search in promising region. Estimation of distribution algorithms (EDAs) focus on where the promising region is, however have less consideration about behavior of each individual in solution search algorithms. Since the basic ideas of EP and EDAs are quite different, it is possible to make them reinforce each other. In this paper, we present a hybrid evolutionary framework to make use of both the ideas of EP and EDAs through introducing a mini estimation operator into EP's search cycle. Unlike previous EDAs that use probability density function (PDF), the estimation mechanism used in the proposed framework is the k-nearest neighbor estimation which can perform better with relative small amount of training samples. Our experimental results have shown that the\u00a0\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "Application of grid task scheduling algorithm rr to medium-grained evolution strategies\n", "abstract": " A computational method for implementation of Evolution Strategies (ES) in Grid computing environments is discussed. In this paper, list scheduling with Round-robin order Replication (RR) is adopted to reduce waiting times due to synchronization in Medium-grained ES. Our results show that the replication in RR can reduce the synchronous waiting time in comparison with Work Queue (WQ) methods.", "num_citations": "2\n", "authors": ["537"]}
{"title": "Evolutionary ensemble for in silico prediction of ames test mutagenicity\n", "abstract": " Driven by new regulations and animal welfare, the need to develop in silico models has increased recently as alternative approaches to safety assessment of chemicals without animal testing. This paper describes a novel machine learning ensemble approach to building an in silico model for the prediction of the Ames test mutagenicity, one of a battery of the most commonly used experimental in vitro and in vivo genotoxicity tests for safety evaluation of chemicals. Evolutionary random neural ensemble with negative correlation learning (ERNE) [1] was developed based on neural networks and evolutionary algorithms. ERNE combines the method of bootstrap sampling on training data with the method of random subspace feature selection to ensure diversity in creating individuals within an initial ensemble. Furthermore, while evolving individuals within the ensemble, it makes use of the negative correlation\u00a0\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "A Gradient-Based Forward Greedy Algorithm for Space Gaussian Process Regression\n", "abstract": " In this chaper, we present a gradient-based forward greedy method for sparse approximation of Bayesian Gaussian Process Regression (GPR) model. Different from previous work, which is mostly based on various basis vector selection strategies, we propose to construct instead of select a new basis vector at each iterative step. This idea was motivated from the well-known gradient boosting approach. The resulting algorithm built on gradient-based optimisation packages incurs similar computational cost and memory requirements to other leading sparse GPR algorithms. Moreover, the proposed work is a general framework which can be extended to deal with other popular kernel machines, including Kernel Logistic Regression (KLR) and Support Vector Machines (SVMs). Numerical experiments on a wide range of datasets are presented to demonstrate the superiority of our algorithm in terms of generalisation\u00a0\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "A hybrid estimation of distribution algorithm for CDMA cellular system design\n", "abstract": " While code division multiple access (CDMA) is becoming a promising cellular communication system, the design for a CDMA cellular system configuration has posed a practical challenge in optimisation. The study in this paper proposes a hybrid estimation of distribution algorithm (HyEDA) to optimize the design of a cellular system configuration. HyEDA is a two-stage hybrid approach built on estimation of distribution algorithms (EDAs), coupled with a K-means clustering method and a simple local search algorithm. Compared with the simulated annealing method on some test instances, HyEDA has demonstrated its superiority in terms of both the overall performance in optimisation and the number of fitness evaluations required.", "num_citations": "2\n", "authors": ["537"]}
{"title": "Parallel Problem Solving from Nature-PPSN IX: 9th International Conference, Reykjavik, Iceland, September 9-13, 2006, Proceedings\n", "abstract": " We are very pleased to present this LNCS volume, the proceedings of the 9th International Conference on Parallel Problem Solving from Nature (PPSN IX). PPSNisoneofthemostrespectedandhighlyregardedconferenceseriesinevo-tionary computation and natural computing/computation. This biennial event was? rst held in Dortmund in 1990, and then in Brussels (1992), Jerusalem (1994), Berlin (1996), Amsterdam (1998), Paris (2000), Granada (2002), and Birmingham (2004). PPSNcontinuestobetheconferenceofchoicebyresearchers all over the world, who value its high quality. We received 255 paper submissions this year. After an extensive peer review process involving more than 1000 reviews, the programme committee selected the top 106 papers for inclusion in this volume and, of course, for presentation at the conference. This represents an acceptance rate of 42%. The papers included in this volume cover a wide range of topics, from e-lutionary computation to swarm intelligence and from bio-inspired computing to real-world applications. They represent some of the latest and best research in evolutionary and natural computation. Following the PPSN tradition, all-pers at PPSN IX were presented as posters. There were 7 sessions: each session consisting of around 15 papers. For each session, we covered as wide a range of topics as possible so that participants with di? erent interests could? nd some relevant papers in every session.", "num_citations": "2\n", "authors": ["537"]}
{"title": "COMPLEXITY AND SYNCHRONIZATION OF EEG WITH PARAMETRIC MODELING\n", "abstract": " EEG recordings are often applied in the neuroscience research and the diagnosis of neural disorder. So far, EEG data analysis still is one of the vital topics in the neuroscience this is because that the series analysis of EEG could be used to understand the complex behavior of neural networks. We firstly review the analysis method of EEG recordings, it is found that the complexity and synchronization of the EEG recordings are recently paid more attentions because these definitions are more helpful to understand the dynamics of neural networks than others. In this chapter a simple parametric modeling of EEG series is introduced to compute the complexity and synchronization of EEG data sets. The parametric modeling is expected to measure the complexity and synchronization of EEG data sets, except that it has been widely applied to obtain the features and spectrum of EEG data. First of all, a timeb varying auto\u00a0\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "Evolving cooperation in complex behavioral interactions through reputation\n", "abstract": " The iterated prisoner\u2019s dilemma (IPD) has long been used to study the conditions that promote cooperative behaviors among selfish individuals. In particular, studies using the co-evolutionary learning framework have shown that cooperative behaviors can be learned through a process of adaptation of strategies based solely on direct interactions through repeated encounters in playing IPD. However, complex behavioral interactions (eg, by humans) may involve more than just direct interactions between two individuals. In many real-world situations, it is impossible to interact with all other individuals. It is very important to study indirect interactions, eg, in the form of estimating behaviors of future partners through their perceived reputation based on previous behaviors to other individuals. Here, we study the co-evolutionary learning of IPD with reputation where behavioral interactions for a pair of strategies depend not only on choices made in their previous moves, but also choices made to other strategies that are reflected by their reputation scores. We show that for more complex IPD interactions involving more choices where direct interaction alone is ineffective to promote cooperation, the addition of reputation helps to promote cooperation. We further show that different implementations of reputation estimation, which reflect the accuracy of reputation estimation from using memory of games from previous generation and more frequent updating of reputation scores, is for the evolution of cooperation. Finally, we also investigate the situation where strategies can misperceive their partner\u2019s reputation and show that even in the circumstances that\u00a0\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "The Iterated Prisoner's Dilemma\n", "abstract": " In 1984, Robert Axelrod published a book, relating the story of two competitions which he ran, where invited academics entered strategies for the Iterated Prisoners' Dilemma. The book, almost 20 years on, is still widely read and cited by academics and the general public.As a celebration of that landmark work, we have recreated those competitions to celebrate its 20th anniversary, by again inviting academics to submit prisoners' dilemma strategies. The first of these new competitions was run in July 2004, and the second in April 2005. Iterated Prisoners' Dilemma: 20 Years On essentially provides an update of the Axelrod's book.", "num_citations": "2\n", "authors": ["537"]}
{"title": "Nonlinear feature extraction using evolutionary algorithm\n", "abstract": " We propose a method of nonlinear feature extraction for 2-class problems. A simple sigmoid function is used to extract features that are negatively correlated to each other. To evaluate the effectiveness of the proposed method, we employ linear and non-linear support vector machines to classify using the extracted feature sets and the original feature sets. Comparison on 4 datasets shows that our method is effective for nonlinear feature extraction.", "num_citations": "2\n", "authors": ["537"]}
{"title": "Near-optimal dynamic grid task scheduling of evolution strategies\n", "abstract": " Near-Optimal Dynamic Grid Task Scheduling of Evolution Strategies \u2014 University of Birmingham Skip to main navigation Skip to search Skip to main content University of Birmingham Home University of Birmingham Logo Help & FAQ Home Research output Profiles Research Units Projects Activities Datasets Equipment Prizes Press / Media Search by expertise, name or affiliation Near-Optimal Dynamic Grid Task Scheduling of Evolution Strategies Yoshiyuki Matsumura, N Fujimoto, Xin Yao, Jeremy Wyatt, K Hagihara Computer Science Research output: Contribution to conference (unpublished) \u203a Paper Overview Original language English Pages 175-180 Number of pages 6 Publication status Published - 1 Jan 2004 Event 4th International Conference on Advanced Mechatronics (ICAM 04) - Duration: 1 Jan 2004 \u2192 \u2026 Conference Conference 4th International Conference on Advanced Mechatronics (ICAM 04) Period \u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "Evolution strategies on grid computing\n", "abstract": " Evolution Strategies on Grid Computing \u2014 University of Birmingham Skip to main navigation Skip to search Skip to main content University of Birmingham Home University of Birmingham Logo Help & FAQ Home Research output Profiles Research Units Projects Activities Datasets Equipment Prizes Press / Media Search by expertise, name or affiliation Evolution Strategies on Grid Computing Yoshiyuki Matsumura, N Fujimoto, Xin Yao, Jeremy Wyatt, K Hagihara Computer Science Research output: Contribution to conference (unpublished) \u203a Paper Overview Original language English Pages 105-106 Number of pages 2 Publication status Published - 1 Jan 2004 Event Joint Conference on Mechatronics - Duration: 1 Jan 2004 \u2192 \u2026 Conference Conference Joint Conference on Mechatronics Period 1/01/04 \u2192 \u2026 Cite this APA Author BIBTEX Harvard Standard RIS Vancouver Matsumura, Y., Fujimoto, N., Yao, X., Wyatt, J.\u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "Characterizing genetic algorithm approaches to job shop scheduling\n", "abstract": " In most production environments, there is a requirement for effective use of the available resources. Job shop-scheduling problem (JSSP) because of its key impact on revenues is at the crux of Production planning, of late also known as Enterprise Resource Planning (ERP). Being an NP complete and highly constrained problem, exact methods take exponential time and heuristic methods give suboptimal solutions. Genetic Algorithms (GA) are the most sought after techniques to get global optimal solutions, and this paper reviews various GA approaches to solve JSSP.The parameters, representation schemes, and operators used in a GA strongly affect the quality of search. The paper starts with analysis on the use of heuristics for JSSP, and it is pointed out why evolutionary approaches are better than heuristics. This is followed by a detailed discussion on various representation schemes for a feasible schedule. These schemes are reviewed in terms of their ease of implementation in GA, choice of crossover and mutation operators, and their commensurate advantages and disadvantages. In the end some schemes are analyzed as to their suitability in improving the performance of GA\u2018s. The motivation behind such a paper is to lay out a critical discussion on the GA methodologies for JSSP, based on representation schemes, in order to better serve the needs of manufacturing community trying to apply GA on their problems.", "num_citations": "2\n", "authors": ["537"]}
{"title": "Multi-micro processor-array: EHW for a control system\n", "abstract": " This paper introduces the Multi-Micro Processor-Array (MMPA) as a kind of Evolvable Hardware (EHW) for an industry control system. At first it describes one of the traditional methods, logic method, for the reconfiguration of a system. Then it applies an evolutionary algorithm to improve the reconfiguration so that the architecture of the control system can be configured dynamically and optimally. The evolutionary algorithm is executed in the structure of the MMPA. Relationship among the components and tasks is employed to speed up searching solutions. Physically the bus connects the microprocessors that form an array. Logically the microprocessors construct a ring: token ring. The microprocessor that gets the token can send message to any other microprocessor. Each microprocessor stores overall data so when it gets the token it can reconfigure the whole system if necessary.", "num_citations": "2\n", "authors": ["537"]}
{"title": "Evolutionary approach for vehicle routing problem with time windows and facility location allocation problem\n", "abstract": " Evolutionary approach for vehicle routing problem with time windows and facility location allocation problem \u2014 University of Birmingham Skip to main navigation Skip to search Skip to main content University of Birmingham Home University of Birmingham Logo Help & FAQ Home Research output Profiles Research Units Projects Activities Datasets Equipment Prizes Press / Media Search by expertise, name or affiliation Evolutionary approach for vehicle routing problem with time windows and facility location allocation problem K Gupta, Xin Yao, John Bullinaria Computer Science Research output: Contribution to conference (unpublished) \u203a Paper Overview Original language English Pages 45-52 Number of pages 8 Publication status Published - 1 Jan 2002 Event Proceedings of the 2002 UK Workshop on Computational Intelligence - Duration: 1 Jan 2002 \u2192 \u2026 Conference Conference Proceedings of the 2002 UK \u2026", "num_citations": "2\n", "authors": ["537"]}
{"title": "Exploiting population information in evolutionary learning\n", "abstract": " Evolutionary learning has been developing rapidly in the last decade. It is a powerful and general learning approach which has been used successfully in both symbolic systems, eg, rule-based systems, and subsymbolic systems, eg, arti cial neural networks. However, most evolutionary learning systems have paid little attention to the fact that they are population-based learning. The common practice is to select the best individual in the last generation as the nal learned system. Such practice in essence treats these learning systems as optimisation ones. This paper emphasises the di erence between a learning system and an optimisation one, and shows that such di erence requires a di erent approach to population-based learning and that the current practice of selecting the best individual as the learned system is not the best choice. The paper then argues that a population contains more information than the best individual and thus should be exploited to form the nal integrated system. Two examples are presented in this paper to show that even some simple methods which exploit population information can improve the performance of a learned system greatly. The rst example is in the subsymbolic domain of arti cial neural networks. The second example is in the symbolic domain of rule-based systems.", "num_citations": "2\n", "authors": ["537"]}
{"title": "Parallel exploration via negatively correlated search\n", "abstract": " Effective exploration is key to a successful search process. The recently proposed negatively correlated search (NCS) tries to achieve this by coordinated parallel exploration, where a set of search processes are driven to be negatively correlated so that different promising areas of the search space can be visited simultaneously. Despite successful applications of NCS, the negatively correlated search behaviors were mostly devised by intuition, while deeper (e.g., mathematical) understanding is missing. In this paper, a more principled NCS, namely NCNES, is presented, showing that the parallel exploration is equivalent to a process of seeking probabilistic models that both lead to solutions of high quality and are distant from previous obtained probabilistic models. Reinforcement learning, for which exploration is of particular importance, are considered for empirical assessment. The proposed NCNES is\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "Exponential Evolution Mechanism for In Vivo Computation\n", "abstract": " We have proposed a novel framework of in vivo computation, which is used for tumor sensitization and targeting (TST) in our previous investigations. In the framework, the process of nanorobots-assisted TST is rendered into an in vivo optimization problem, where nanorobots are utilized as computing agents; the tumor targeted can be seen as the global optimal solution; the high-risk tissue plays the role of the search space; and the tumor-triggered biological gradient field (BGF) provides the aided knowledge for fitness evaluation. Our previous works have proposed the weak priority evolution strategy (WP-ES) to adapt to the actuating mode of the homogeneous magnetic field used in the state-of-the-art nanorobot control platforms. Though the previous works provide an optimal movement direction for the nanorobots at each update, the step size for each iteration, which is called the evolution mechanism in this paper\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "Generalized Moving Peaks Benchmark\n", "abstract": " This document describes the Generalized Moving Peaks Benchmark (GMPB) that generates continuous dynamic optimization problem instances. The landscapes generated by GMPB are constructed by assembling several components with a variety of controllable characteristics ranging from unimodal to highly multimodal, symmetric to highly asymmetric, smooth to highly irregular, and various degrees of variable interaction and ill-conditioning. In this document, we explain how these characteristics can be generated by different parameter settings of GMPB. The MATLAB source code of GMPB is also explained. This document forms the basis for a range of competitions on Evolutionary Continuous Dynamic Optimization in the upcoming well-known conferences.", "num_citations": "1\n", "authors": ["537"]}
{"title": "Cooperative Coevolution-based Design Space Exploration for Multi-mode Dataflow Mapping\n", "abstract": " Some signal processing and multimedia applications can be specified by synchronous dataflow (SDF) models. The problem of SDF mapping to a given set of heterogeneous processors has been known to be NP-hard and widely studied in the design automation field. However, modern embedded applications are becoming increasingly complex with dynamic behaviors changes over time. As a significant extension to the SDF, the multi-mode dataflow (MMDF) model has been proposed to specify such an application with a finite number of behaviors (or modes) and each behavior (mode) is represented by an SDF graph. The multiprocessor mapping of an MMDF is far more challenging as the design space increases with the number of modes. Instead of using traditional genetic algorithm (GA)-based design space exploration (DSE) method that encodes the design space as a whole, this article proposes a novel\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "Enhanced Constraint Handling for Reliability-Constrained Multiobjective Testing Resource Allocation\n", "abstract": " The multiobjective testing resource allocation problem (MOTRAP) is how to efficiently allocate the finite testing time to various modules, with the aim of optimizing system reliability, testing cost, and testing time simultaneously. To deal with this problem, a common approach is to use multiobjective evolutionary algorithms (MOEAs) to seek a set of tradeoff solutions between the three objectives. However, such a tradeoff set may contain a substantial proportion of solutions with very low reliability level, which consume lots of computational resources but may be valueless to the software project manager. In this article, a MOTRAP model with a prespecified reliability is first proposed. Then, new lower bounds on the testing time invested in different modules are theoretically deduced from the necessary condition for the achievement of the given reliability, based on which an exact algorithm for determining the new lower\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "Nanorobots-Assisted Natural Computation for Multifocal Tumor Sensitization and Targeting\n", "abstract": " We have proposed a new tumor sensitization and targeting (TST) framework, named  in vivo  computation, in our previous investigations. The problem of TST for an early and microscopic tumor is interpreted from the computational perspective with nanorobots being the \u201cnatural\u201d computing agents, the high-risk tissue being the search space, the tumor targeted being the global optimal solution, and the tumor-triggered biological gradient field (BGF) providing the aided knowledge for fitness evaluation of nanorobots. This natural computation process can be seen as on-the-fly path planning for nanorobot swarms with an unknown target position, which is different from the traditional path planning methods. Our previous works are focusing on the TST for a solitary lesion, where we proposed the weak priority evolution strategy (WP-ES) to adapt to the actuating mode of the homogeneous magnetic field used in the state-of\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "D-MAENS2: A Self-adaptive D-MAENS Algorithm with Better Decision Diversity\n", "abstract": " The capacitated arc routing problem is a challenging combinatorial optimization problem with numerous real-world applications. In recent years, several multi-objective optimization algorithms have been applied to minimize both the total cost and makespan for capacitated arc routing problems, among which the decomposition-based memetic algorithm with extended neighborhood search has shown promising results. In this paper, we propose an improved decomposition-based memetic algorithm with extended neighborhood search, called D-MAENS2, which uses a novel method to construct a gene pool to measure and improve the diversity of solutions in decision variable space. Additionally, D-MAENS2 is capable of adapting online its hyper-parameters to various problem instances. Experimental studies show that our novel D-MAENS2 significantly outperforms D-MAENS on 81 benchmark instances and shows\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "A Hybrid Evolutionary Algorithm for Reliable Facility Location Problem\n", "abstract": " The reliable facility location problem (RFLP) is an important research topic of operational research and plays a vital role in the decision-making and management of modern supply chain and logistics. Through solving RFLP, the decision-maker can obtain reliable location decisions under the risk of facilities\u2019 disruptions or failures. In this paper, we propose a novel model for the RFLP. Instead of assuming allocating a fixed number of facilities to each customer as in the existing works, we set the number of allocated facilities as an independent variable in our proposed model, which makes our model more close to the scenarios in real life but more difficult to be solved by traditional methods. To handle it, we propose EAMLS, a hybrid evolutionary algorithm, which combines a memorable local search (MLS) method and an evolutionary algorithm (EA). Additionally, a novel metric called l3-value is proposed to assist the\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "Improving sampling in evolution strategies through mixture-based distributions built from past problem instances\n", "abstract": " The notion of learning from different problem instances, although an old and known one, has in recent years regained popularity within the optimization community. Notable endeavors have been drawing inspiration from machine learning methods as a means for algorithm selection and solution transfer. However, surprisingly approaches which are centered around internal sampling models have not been revisited. Even though notable algorithms have been established in the last decades. In this work, we progress along this direction by investigating a method that allows us to learn an evolutionary search strategy reflecting rough characteristics of a fitness landscape. This latter model of a search strategy is represented through a flexible mixture-based distribution, which can subsequently be transferred and adapted for similar problems of interest. We validate this approach in two series of experiments in which we\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "Support Matching: A Novel Regularization to Escape from Mode Collapse in GANs\n", "abstract": " Generative adversarial network (GAN) is an implicit generative model known for its ability to generate sharp images. However, it is poor at generating diverse data, which refers to the mode collapse problem. It turns out that GAN is prone to emphasizing the quality of samples but ignoring their diversity. When mode collapse happens, the support of the generated data distribution is not aligned with that of the real data distribution. We thus propose Support Regularized-GAN (SR-GAN) to address such a mode collapse issue by matching their support. Our experiments on synthetic and real-world datasets show that our regularization can mitigate the mode collapse and also improve the data quality.", "num_citations": "1\n", "authors": ["537"]}
{"title": "Adaptive-SAHiD algorithm for capacitated arc routing problems\n", "abstract": " The Capacitated Arc Routing Problem (CARP) is a seminal and challenging problem in combinatorial optimization. Heuristics and meta-heuristics are usually used to address it. When designing or applying heuristics and meta-heuristics, parameter setting, that is, identifying optimal parameter setting for the algorithms, is routinely encountered. Automatic parameter setting, which is dedicated to automatically finding optimal parameter settings for the algorithms, has attracted considerable attention in recent years. However, automatic parameter setting approaches are rarely investigated for CARP. At present, when designing algorithms for CARPs, parameter settings are commonly determined by empirical experimental analysis or according to some guidelines. This paper introduces an adaptive parameter setting method using kernel density estimation to the SAHiD algorithm, which is a scalable approach to CARP\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "A Simple Yet Effective Approach to Robust Optimization Over Time\n", "abstract": " Robust optimization over time (ROOT) refers to an optimization problem where its performance is evaluated over a period of future time. Most of the existing algorithms use particle swarm optimization combined with another method which predicts future solutions to the optimization problem. We argue that this approach may perform subpar and suggest instead a method based on a random sampling of the search space. We prove its theoretical guarantees and show that it significantly outperforms the state-of-the-art methods for ROOT.", "num_citations": "1\n", "authors": ["537"]}
{"title": "Adaptive initialization method for K-means algorithm\n", "abstract": " The K-means algorithm is a widely used clustering algorithm that offers simplicity and efficiency. However, the traditional K-means algorithm uses the random method to determine the initial cluster centers, which make clustering results prone to local optima and then result in worse clustering performance. Many initialization methods have been proposed, but none of them can dynamically adapt to datasets with various characteristics. In our previous research, an initialization method for K-means based on hybrid distance was proposed, and this algorithm can adapt to datasets with different characteristics. However, it has the following drawbacks: (a) When calculating density, the threshold cannot be uniquely determined, resulting in unstable results. (b) Heavily depending on adjusting the parameter, the parameter must be adjusted five times to obtain better clustering results. (c) The time complexity of the algorithm is quadratic, which is difficult to apply to large datasets. In the current paper, we proposed an adaptive initialization method for the K-means algorithm (AIMK) to improve our previous work. AIMK can not only adapt to datasets with various characteristics but also obtain better clustering results within two interactions. In addition, we then leverage random sampling in AIMK, which is named as AIMK-RS, to reduce the time complexity. AIMK-RS is easily applied to large and high-dimensional datasets. We compared AIMK and AIMK-RS with 10 different algorithms on 16 normal and six extra-large datasets. The experimental results show that AIMK and AIMK-RS outperform the current initialization methods and several well-known clustering\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "Investigation of Asynchrony in Dynamic Multi-Objective Optimization\n", "abstract": " Dynamic multi-objective optimization problems are very common in many real-world applications. Such problems are often characterized by time varying objectives, constraints or parameters. Consideration of dynamics is typically limited to a single dynamic time scale; a restriction on the realistic description of real-world scenarios. In this paper, we investigate the effects of asynchrony on algorithm performance for two and three objective benchmark optimization problems with two independent time variables. The independent update of these time variables is parameterized on a logarithmic scale between slow-relative change, synchronous change and fast-relative changes. To evaluate the effect of the asynchronous modes, six established multi-objective optimization algorithms, tailored specifically for dynamic problems, were used to solve the problems. The hybrid-based methods achieve significantly better\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "An Experimental Study of Large-scale Capacitated Vehicle Routing Problems\n", "abstract": " The recently proposed Scalable Approach Based on Hierarchical Decomposition (SAHiD) has shown its superiority on large-scale capacitated arc routing problems (CARP) in terms of both computational efficiency and solution quality. The main idea of SAHiD is that the underlying Hierarchical decomposition (HD) scheme is able to efficiently obtain a good permutation of tasks for CARP in a hierarchical divide-and-conquer way, where both the number and size of subproblems can be kept in tractable for large-scale problems with thousands of tasks. Motivated by the frequent observations of the similarity between CARP and Capacitated Vehicle Routing Problem (CVRP), the HD scheme and SAHiD algorithm are expected to work well on CVRPs. This paper applies SAHiD to large-scale CVRPs and discovers that SAHiD does not work as well as expected on large-scale CVRP. Possible reasons for this are given after\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "A New Framework for Analysis of Coevolutionary Systems\u2014Directed Graph Representation and Random Walks\n", "abstract": " Studying coevolutionary systems in the context of simplified models (i.e., games with pairwise interactions between coevolving solutions modeled as self plays) remains an open challenge since the rich underlying structures associated with pairwise-comparison-based fitness measures are often not taken fully into account. Although cyclic dynamics have been demonstrated in several contexts (such as intransitivity in coevolutionary problems), there is no complete characterization of cycle structures and their effects on coevolutionary search. We develop a new framework to address this issue. At the core of our approach is the directed graph (digraph) representation of coevolutionary problems that fully captures structures in the relations between candidate solutions. Coevolutionary processes are modeled as a specific type of Markov chains\u2014random walks on digraphs. Using this framework, we show that\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "Concept Drift Detection in Histogram-Based Straightforward Data Stream Prediction\n", "abstract": " Mainstream research in concept drift detection for on-line classification focuses on monitoring a measure of the learner's performance, thus assuming that a reduction of its prediction ability implies a change in the relation between the input variables and the class labels. This approach makes the detector highly dependent on the learner, which can be problematic in some situations, for example, when the learner includes adaptability mechanisms, when it is unable to converge, or when it shows a high overfitting. Ultimately, the concept drift is something that happens in the data, not learners, so detecting drifts indirectly through a learner's performance adds bias into the result. Besides, it makes the process highly inefficient. This paper proposes a new mechanism to detect concept drifts without supervising the learning process. The data distribution is summarized in univariate histograms based on which an on-line\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "Guest editors introduction: Intelligence in the cloud\n", "abstract": " This special issue is intended to introduce the state-of-the-art, open research challenges, new solutions, and applications for intelligence in the cloud computing. Specifically, we choose three high-quality papers for this special issue, covering different aspects of resource management, machine learning based framework, and a Blockchain-based mechanism that enables intelligent cloud computing.", "num_citations": "1\n", "authors": ["537"]}
{"title": "High-dimensional black-box optimization via divide and approximate conquer\n", "abstract": " Divide and Conquer (DC) is conceptually well suited to high-dimensional optimization by decomposing a problem into multiple small-scale sub-problems. However, appealing performance can be seldom observed when the sub-problems are interdependent. This paper suggests that the major difficulty of tackling interdependent sub-problems lies in the precise evaluation of a partial solution (to a sub-problem), which can be overwhelmingly costly and thus makes sub-problems non-trivial to conquer. Thus, we propose an approximation approach, named Divide and Approximate Conquer (DAC), which reduces the cost of partial solution evaluation from exponential time to polynomial time. Meanwhile, the convergence to the global optimum (of the original problem) is still guaranteed. The effectiveness of DAC is demonstrated empirically on two sets of non-separable high-dimensional problems.", "num_citations": "1\n", "authors": ["537"]}
{"title": "Self-aware Computing: Introduction and Motivation\n", "abstract": " Designing and operating computing and communication systems are becoming increasingly challenging tasks, due to a multitude of reasons. First, compute nodes are evolving towards parallel and heterogeneous architectures to realise performance gains while minimising their power consumption. Progress in micro(nano)- electronics allows us to integrate more and more functionality on a single compute node, but at the same time requires us to deal with increasing numbers of faulty and unreliable components. Second, distributed systems are growing in the numbers and heterogeneity of nodes and must be able to cope with an increasing level of dynamics. The network topology and the collective resources of a distributed system can vary strongly during runtime since nodes may leave and enter the network dynamically. The position, functionality and available resources of each node may also change\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "Towards a dynamic evolutionary approach to fpga temperature management\n", "abstract": " Reconfigurable computing systems, such as FPGAs, provide great promise for on-the-fly adaptive computation. Such systems can be modified while in use, to deal with newly arriving computational tasks. However, how to adapt, and with respect to what objectives, is not yet well established. Typically, one might be interested to achieve an allocation of tasks, as they arrive, to differently sized regions of the FPGA, in order to provide the most efficient computation. At the same time, it is important to also maintain healthy on-chip temperature. In this paper, we propose a novel description of this dynamic FPGA temperature management problem. We formulate the problem as a dynamic multiobjective optimisation problem, with three objectives and a time-linkage characteristic. We discuss the implications of the availability or otherwise of a model of the FPGA, and propose the use of evolutionary algorithms as a method to tackle the problem.", "num_citations": "1\n", "authors": ["537"]}
{"title": "Average drift analysis and its application\n", "abstract": " Drift analysis is a useful tool for estimating the running time of evolutionary algorithms. A new representation of drift analysis, called average drift analysis, is described in this paper. It takes a weaker requirement than point-wise drift analysis does. Point-wise drift theorems are corollaries of our average drift theorems. Therefore average drift analysis is more powerful than point-wise drift analysis. To demonstrate the application of average drift analysis, we choose a (1+ N) evolutionary algorithms for linear-like functions as a case study. Linear-like functions are proposed as a natural extension of linear functions. For the (1+ N) evolutionary algorithms to maximise linear-like functions, the lower and upper bounds on their running time have been derived using the average drift analysis.", "num_citations": "1\n", "authors": ["537"]}
{"title": "Convex Hull-Based Multi-objective Genetic Programming for Maximizing ROC Performance\n", "abstract": " ROC is usually used to analyze the performance of classifiers in data mining. ROC convex hull (ROCCH) is the least convex major-ant (LCM) of the empirical ROC curve, and covers potential optima for the given set of classifiers. Generally, ROC performance maximization could be considered to maximize the ROCCH, which also means to maximize the true positive rate (tpr) and minimize the false positive rate (fpr) for each classifier in the ROC space. However, tpr and fpr are conflicting with each other in the ROCCH optimization process. Though ROCCH maximization problem seems like a multi-objective optimization problem (MOP), the special characters make it different from traditional MOP. In this work, we will discuss the difference between them and propose convex hull-based multi-objective genetic programming (CH-MOGP) to solve ROCCH maximization problems. Convex hull-based sort is an indicator based selection scheme that aims to maximize the area under convex hull, which serves as a unary indicator for the performance of a set of points. A selection procedure is described that can be efficiently implemented and follows similar design principles than classical hyper-volume based optimization algorithms. It is hypothesized that by using a tailored indicator-based selection scheme CH-MOGP gets more efficient for ROC convex hull approximation than algorithms which compute all Pareto optimal points. To test our hypothesis we compare the new CH-MOGP to MOGP with classical selection schemes, including NSGA-II, MOEA/D) and SMS-EMOA. Meanwhile, CH-MOGP is also compared with traditional machine learning algorithms\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "Preface. Discovery of electricity.\n", "abstract": " Preface. Discovery of electricity. - Abstract - Europe PMC Sign in or create an account https://orcid.org Europe PMC Menu About About Europe PMC Preprints in Europe PMC Funders Joining Europe PMC Governance Roadmap Outreach Tools Tools overview ORCID article claiming Journal list Grant finder External links service RSS feeds Annotations Annotations submission service Developers Developer resources Articles RESTful API Grants RESTful API API use cases SOAP web service Annotations API OAI service Bulk downloads Developers Forum Help Help using Europe PMC Search syntax reference Contact us Contact us Helpdesk Feedback Twitter Blog Tech blog Developer Forum Europe PMC plus Search worldwide, life-sciences literature Search Advanced Search Recent history Saved searches Abstract Full text Citations & impact Preface. Discovery of electricity. Lozano AM, Hallett M Handbook of \u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "Benchmark Generator for the IEEE WCCI-2014 Competition on Evolutionary Computation for Dynamic Optimization Problems: Dynamic Travelling Salesman Problem Benchmark Generator\n", "abstract": " In this report, the dynamic benchmark generator for permutation-encoded problems for the travelling salesman problem (DBGPTSP) proposed in is used to convert any static travelling salesman problem benchmark to a dynamic optimization problem, by modifying the encoding of the instance instead of the fitness landscape.", "num_citations": "1\n", "authors": ["537"]}
{"title": "Self-awareness, Self-expression and Meta-self-awareness in the Relevant Neighbourhood Selection Problem\n", "abstract": " In this report we introduce the relevant neighbourhood selection problem, a parallel online reinforcement learning problem under uncertainty, with high relevance to practical applications of self-aware collective systems composed of multiple selfinterested agents. Firstly, we motivate and clearly formulate the problem framework, before discussing approaches for specifying particular instantiations of the problem, including a proposed model of uncertainty. We subsequently introduce a socially-inspired heuristic solution technique, based on ant pheromones. We present experimental results on some baseline problem instances, comparing our proposed approach with existing state-of-the-art techniques ported from the related multiarmed bandit problem. We show that none of the solution techniques presented dominates all others across the range of problem instances considered, even those techniques which are so\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "Theoretical runtime analyses of search algorithms on the test data generation for the\n", "abstract": " Curriculum Vitae Page 1 Curriculum Vitae 1 Personal Information NAME Xin YAO WORK ADDRESS The Centre of Excellence for Research in Computational Intelligence and Applications (CERCIA) School of Computer Science, The University of Birmingham Edgbaston, Birmingham B15 2TT, UK Email: X.Yao@cs.bham.ac.uk URL: http://www.cs.bham.ac.uk/\u223cxin Phone: +44 121 414 3747, Fax: +44 121 414 2799 QUALIFICATIONS BSc (1982), MSc (1985), PhD (1990). MAJOR RECOGNITIONS IEEE Fellow; Royal Society Wolfson Research Merit Award; IEEE Computational Intelligence Society Evolutionary Computation Pioneer Award. 2 Employment History Jan. 2003 \u2013 : Director of The Centre of Excellence for Research in Computational Intelligence and Applications (CERCIA), the University of Birmingham, Edgbaston, Birmingham B15 2TT, UK. Apr. 1999 \u2013 : Chair of Computer Science, School of Computer \u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "Editorial to the special issue on \u201cTheoretical Foundations of Evolutionary Computation\u201d\n", "abstract": " Editorial to the special issue on \u201cTheoretical Foundations of Evolutionary Computation\u201d | Theoretical Computer Science ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Theoretical Computer Science Periodical Home Latest Issue Archive Authors Affiliations Award Winners More HomeBrowse by TitlePeriodicalsTheoretical Computer ScienceVol. Editorial to the special issue on \u201cTheoretical Foundations of Evolutionary Computation\u201d article Editorial to the special issue on \u201cTheoretical Foundations of Evolutionary Computation\u201d Share on Authors: Per Kristian Lehre profile image Per Kristian Lehre View Profile , Frank Neumann profile image Frank Neumann View Profile , Jonathan E Rowe profile image \u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "Evolutionary algorithms as guaranteed approximation optimizers\n", "abstract": " Evolutionary algorithms (EAs) are heuristic algorithms inspired from natural evolution. They are often used to obtain good enough solutions in practice. In this paper, we investigate a largely underexplored issue: the approximation performance of EAs, ie, how much the obtained solution is close to the optimal solution. We study an EA framework simple evolutionary algorithm with isolated population, abbreviated as SEIP, which is generalized from recent advances in multi-objective EAs.We analyze the approximation performance of SEIP through partial ratio, which characterizes the behaviors of SEIP that lead to solutions with guaranteed approximation ratios. Specifically, we analyze SEIP on the set cover problem which is NP-hard. We find that, for unbounded set cover problem, SEIP efficiently achieves Hn-approximation ratio, the asymptotic lower bound; and for the k-set cover problem, it efficiently achieves (Hk\u2212 k\u2212 1", "num_citations": "1\n", "authors": ["537"]}
{"title": "Emergent distribution of computational workload in the evolution of an undulatory animat\n", "abstract": " The coupling between an agent\u2019s body and its nervous system ensures that optimal behaviour generation can be undertaken in a specific niche. Depending on this coupling, nervous system or body plan architecture can partake in more or less of the behaviour. We will refer to this as the automatic distribution of computational workload. It is automatic since the coupling is evolved and not pre-specified. In order to investigate this further, we attempt to identify how, in models of undulatory fish, the coupling between body plan morphology and nervous system architecture should emerge in several constrained experimental setups. It is found that neural circuitry emerges minimalistically in all cases and that when certain body segmentation features are not coevolved, the agents exhibit higher levels of neural activity. On account of this, it is suggested that an unconstrained body plan morphology permits greater\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "IEEE Computational Intelligence Society\n", "abstract": " Piuri provided a brief view of IEEE with regards to its vision, goal and core values, highlighting the position of IEEE as a whole. He also provided details on the structure of IEEE and it governing bodies and well as the future growth of IEEE.", "num_citations": "1\n", "authors": ["537"]}
{"title": "Evolving, training and designing neural network ensembles\n", "abstract": " \u2022 An ensemble is a collection of learning systems. In this talk, I will only consider artificial neural networks (ANNs) although rule-based systems, decision trees and other learners can also be used.", "num_citations": "1\n", "authors": ["537"]}
{"title": "The effect of proprioceptive feedback on the distribution of sensory information in a model of an undulatory organism\n", "abstract": " In an animal, a crucial factor concerning the arrival of information at the sensors and subsequent transmission to the effectors, is how it is distributed. At the same time, higher animals also employ proprioceptive feedback so that their respective neural circuits have information regarding the state of the animal body. In order to disseminate what this practically means for the distribution of sensory information, we have modeled a segmented swimming organism (animat) coevolving its nervous system and body plan morphology. In a simulated aquatic environment, we find that animats artificially endowed with proprioceptive feedback are able to evolve completely decoupled central pattern generators (CPGs) meaning that they emerge without any connections made to neural circuits in adjacent body segments. Without such feedback however, we also find that the distribution of sensory information from the head\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "A Memetic Algorithm For Multi-level Redundancy Allocation Problem\n", "abstract": " Redundancy allocation problems (RAPs) have attracted much attention for the past thirty years due to its wide applications in improving the reliability of various engineering systems. Since RAP is an NP-hard problem and exact methods are only applicable to small instances, various heuristic and meta-heuristic methods have been proposed to solve it. In the literature, most studies on RAPs have been conducted for single-level systems. However, real-world engineering systems usually contain multiple levels. In this paper, the RAP on multi-level systems is investigated. A novel memetic algorithm (MA) is proposed to solve this problem. Two genetic operators, namely breadth-first crossover and breadth-first mutation, and a local search method are designed for the MA. Comprehensive experimental studies have shown that the proposed MA outperformed the state-of-the-art approach significantly on two representative examples.", "num_citations": "1\n", "authors": ["537"]}
{"title": "A Self-adaptive Evolutionary Programming Based on Optimum Search Direction\n", "abstract": " The Classical Evolutionary Programming (CEP) relies on Gaussian mutation, whereas Fast Evolutionary Programming (FEP) selects Cauchy distribution as the primary mutation operator, Improved Fast Evolutionary (IFEP) selects the better Gaussian and Cauchy distribution as the primary mutation operator. In this paper, we propose a self-adaptive Evolutionary Programming based on Optimum Search Direction (OSDEP) in which we introduce the current best global individual into mutation to guide individuals to converge according to the global search direction. Extensive empirical studies have been carried out to evaluate the performance of OSDEP, IFEP, FEP and CEP. From the experimental results on seven widely used test functions, we can show that OSDEP outperforms all of IFEP, FEP and CEP for all the test functions.", "num_citations": "1\n", "authors": ["537"]}
{"title": "A Comparison of GAs penalizing infeasible solutions and repairing infeasible solutions on the 0-1 knapsack problem\n", "abstract": " Constraints exist in almost every optimization problem. Different constraint handling techniques have been incorporated with genetic algorithms (GAs), however most of current studies are based on computer experiments. An example is Michalewicz's comparison among GAs using different constraint handling techniques on the 0-1 knapsack problem. The following phenomena are observed in experiments: 1) the penalty method needs more generations to find a feasible solution to the restrictive capacity knapsack than the repair method; 2) the penalty method can find better solutions to the average capacity knapsack. Such observations need a theoretical explanation. This paper aims at providing a theoretical analysis of Michalewicz's experiments. The main result of the paper is that GAs using the repair method are more efficient than GAs using the penalty method on both restrictive capacity and average capacity knapsack problems. This result of the average capacity is a little different from Michalewicz's experimental results. So a supplemental experiment is implemented to support the theoretical claim. The results confirm the general principle pointed out by Coello: a better constraint-handling approach should tend to exploit specific domain knowledge.", "num_citations": "1\n", "authors": ["537"]}
{"title": "Editorial| Ecological Informatics-Volume 1, Issue 1\n", "abstract": " It is my pleasure to welcome you to the first issue of the new international journal Ecological Informatics. The journal belongs to the novel frontier between ecology and information sciences and supplements Elsevier's family of interdisciplinary ecology journals.Ecological Informatics is the first scientific journal specialised in the interdisciplinary research on understanding of information processing from genomes to ecosystems, meta-information concepts for ecological data management, computational ordination, clustering and forecasting of complex ecological interactions, and facilitating informed decision making for sustainable ecosystem management. The journal promotes both novel concepts and techniques for the most efficient exploitation and integration of ecological data and knowledge by means of state-of-the-art computer technology. It promotes object-oriented approaches for ecological data and model\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "Efficient Forward Regression with Marginal Likelihood.\n", "abstract": " We propose an efficient forward regression algorithm based on greedy optimization of marginal likelihood. It can be understood as a forward selection procedure which adds a new basis vector at each step with the largest increment to the marginal likelihood. The computational cost of our algorithm is linear in the number n of training examples and quadratic in the number k of selected basis vectors, ie O (nk2). Moreover, our approach is only required to store a small fraction of all columns of the full design matrix. We compare our algorithm with the well-known Relevance Vector Machines (RVM) which also optimizes marginal likelihood iteratively. The results show that our algorithm can achieve comparable prediction accuracy but with significantly better scaling performance in terms of both computational cost and memory requirements.", "num_citations": "1\n", "authors": ["537"]}
{"title": "Parallel Problem Solving from Nature-PPSN VIII: 8th International Conference, Birmingham, UK, September 18-22, 2004, Proceedings\n", "abstract": " We are very pleased to present this LNCS volume, the proceedings of the 8th InternationalConferenceonParallelProblemSolvingfromNature (PPSNVIII). PPSN is one of the most respected and highly regarded conference series in evolutionary computation and natural computing/computation. This biennial eventwas? rstheldinDortmundin1990, andtheninBrussels (1992), Jerusalem (1994), Berlin (1996), Amsterdam (1998), Paris (2000), and Granada (2002). PPSN VIII continues to be the conference of choice by researchers all over the world who value its high quality. We received a record 358 paper submissions this year. After an extensive peer review process involving more than 1100 reviews, the programme c-mittee selected the top 119 papers for inclusion in this volume and, of course, for presentation at the conference. This represents an acceptance rate of 33%. Please note that review reports with scores only but no textual comments were not considered in the chairs\u2019 ranking decisions. The papers included in this volume cover a wide range of topics, from e-lutionary computation to swarm intelligence and from bio-inspired computing to real-world applications. They represent some of the latest and best research in evolutionary and natural computation. Following the PPSN tradition, all-persatPPSNVIII werepresentedasposters. Therewere7 sessions: eachsession consisting of around 17 papers. For each session, we covered as wide a range of topics as possible so that participants with di? erent interests would? nd some relevant papers at every session.", "num_citations": "1\n", "authors": ["537"]}
{"title": "To understand fitness landscapes in continuous space by using drift analysis\n", "abstract": " This paper gives an explanation of fitness landscapes in continuous space by using drift analysis. Firstly we first describe the characteristics of easy and hard landscapes, and then verify these characteristics by case study.", "num_citations": "1\n", "authors": ["537"]}
{"title": "Automatic divide-and-conquer using populations and ensembles\n", "abstract": " Summary form only given. Real-world problems are often too large and complex for a single monolithic system to solve. In practice, the divide-and-conquer strategy has often been used to decompose a large and complex problem into smaller tractable sub-problems and then solve them. However, good decomposition of large and complex problems requires experienced human experts and rich prior domain knowledge, which are usually unavailable for real-world problems. This paper explores some of our research efforts towards an adaptive approach to divide-and-conquer in the design of machine learning systems, e.g., evolutionary and neural learning systems. The basic idea is to move away from designing a single monolithic system that would solve a large and complex problem, and to employ a population of simpler sub-systems that will cooperatively solve the problem. In such populations based systems\u00a0\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "A gentle introduction to evolutionary computation\n", "abstract": " A Gentle Introduction to Evolutionary Computation Page 1 ' & $ % A Gentle Introduction to Evolutionary Computation Xin Yao (x.yao@cs.bham.ac.uk) 1. What Is Evolutionary Computation 2. Different Evolutionary Algorithms 3. Major Areas Within Evolutionary Computation 4. Summary Page 2 Yao: Intro to Evolutionary Computation ' & $ % What Is Evolutionary Computation 1. It is the study of computational systems which use ideas and get inspirations from natural evolution. 2. One of the principles borrowed is survival of the fittest. 3. Evolutionary computation (EC) techniques can be used in optimisation, learning and design. 4. EC techniques do not require rich domain knowledge to use. However, domain knowledge can be incorporated into EC techniques. Page 3 Yao: Intro to Evolutionary Computation ' & $ % A Simple Evolutionary Algorithm 1. Generate the initial population P(0) at random, and set i \u2190 0; 2. REPEAT (\u2026", "num_citations": "1\n", "authors": ["537"]}
{"title": "From Evolutionary Computation to Natural Computation\n", "abstract": " Evolutionary computation has enjoyed a tremendous growth in more than a decade in both its theoretical foundations and industrial applications. Its scope has gone beyond its earlier meaning of \u201cgenetic evolution\u201d. Many research topics in evolutionary computation nowadays are not necessarily \u201cevolutionary\u201d in any sense. There is a need for studying a wide variety of nature inspired computational algorithms and techniques, including evolutionary, neural, ecological computation, etc., in a unified framework This paper gives an overview of some work that has been going on in the Natural Computation Group at The University of Birmingham, UK. It covers topics in optimisation, learning and design using nature inspired algorithms and techniques. Some recent theoretical results in the computational time complexity of evolutionary and neural optimisation algorithms will also be mentioned.", "num_citations": "1\n", "authors": ["537"]}
{"title": "Simulated evolution and learning: an introduction\n", "abstract": " Evolution and learning are two fundamental forms of adaptation. There has been a strong interest in recent years in exploring these two forms of adaptation and their roles and interactions in adaptive systems. The four papers included in this special issue study various aspects of simulated evolution and learning. They demonstrate that simulated evolution and learning can be applied to a wide range of problems, from game-playing to algorithm self-adaptation and from timetabling to numerical optimisation. The four papers in this special issue originated from the Second Asia-Pacific Conference on Simulated Evolution and Learning (SEAL\u201998) held in Canberra,", "num_citations": "1\n", "authors": ["537"]}
{"title": "The Exploitation of Cooperation in Iterated Prisoner's Dilemma\n", "abstract": " We follow Axelrod 2] in using the genetic algorithm to play Iterated Prisoner's Dilemma. Each member of the population (ie, each strategy) is evaluated by how it performs against the other members of the current population. This creates a dynamic environment in which the algorithm is optimising to a moving target instead of the usual evaluation against some xed set of strategies, causing an\\arms race\" of innovation 3].We conduct two sets of experiments. The rst set investigates what conditions evolve the best strategies. The second set studies the robustness of the strategies thus evolved, that is, are the strategies useful only in the round robin of its population or are they e ective against a wide variety of opponents? Our results indicate that the population has nearly always converged by about 250 generations, by which time the bias in the population has almost always stabilised at 85%. Our results con rm that cooperation almost always becomes the dominant strategy 1, 2]. We can also con rm that seeding the population with expert strategies is best done in small amounts so as to leave the initial population with plenty of genetic diversity 7].", "num_citations": "1\n", "authors": ["537"]}