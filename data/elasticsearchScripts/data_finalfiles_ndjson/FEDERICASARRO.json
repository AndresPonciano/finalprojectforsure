{"title": "Multi-objective Software Effort Estimation\n", "abstract": " We introduce a bi-objective effort estimation algorithm that combines Confidence Interval Analysis and assessment of Mean Absolute Error. We evaluate our proposed algorithm on three different alternative formulations, baseline comparators and current state-of-the-art effort estimators applied to five real-world datasets from the PROMISE repository, involving 724 different software projects in total. The results reveal that our algorithm outperforms the baseline, state-of-the-art and all three alternative formulations, statistically significantly (p <; 0.001) and with large effect size (A 12  \u2265 0.9) over all five datasets. We also provide evidence that our algorithm creates a new state-of-the-art, which lies within currently claimed industrial human-expert-based thresholds, thereby demonstrating that our findings have actionable conclusions for practicing software engineers.", "num_citations": "128\n", "authors": ["228"]}
{"title": "Causal Impact Analysis for App Releases in Google Play\n", "abstract": " App developers would like to understand the impact of their own and their competitors\u2019 software releases. To address this we introduce Causal Impact Release Analysis for app stores, and our tool, CIRA, that implements this analysis. We mined 38,858 popular Google Play apps, over a period of 12 months. For these apps, we identified 26,339 releases for which there was adequate prior and posterior time series data to facilitate causal impact analysis. We found that 33% of these releases caused a statistically significant change in user ratings. We use our approach to reveal important characteristics that distinguish causal significance in Google Play. To explore the actionability of causal impact analysis, we elicited the opinions of app developers: 56 companies responded, 78% concurred with the causal assessment, of which 33% claimed that their company would consider changing its app release strategy as a\u00a0\u2026", "num_citations": "73\n", "authors": ["228"]}
{"title": "Web Effort Estimation: Function Points Analysis vs. COSMIC\n", "abstract": " Context: software development effort estimation is a crucial management task that critically depends on the adopted size measure. Several Functional Size Measurement (FSM) methods have been proposed. COSMIC is considered a 2nd generation FSM method, to differentiate it from Function Point Analysis (FPA) and its variants, considered as 1st generation ones. In the context of Web applications, few investigations have been performed to compare the effectiveness of the two generations. Software companies could benefit from this analysis to evaluate if it is worth to migrate from a 1st generation method to a 2nd one.Objective: the main goal of the paper is to empirically investigate if COSMIC is more effective than FPA for Web effort estimation. Since software companies using FPA cannot build an estimation model based on COSMIC as long as they do not have enough COSMIC data, the second goal of the\u00a0\u2026", "num_citations": "43\n", "authors": ["228"]}
{"title": "Cross-validation based K nearest neighbor imputation for software quality datasets: an empirical study\n", "abstract": " Being able to predict software quality is essential, but also it pose significant challenges in software engineering. Historical software project datasets are often being utilized together with various machine learning algorithms for fault-proneness classification. Unfortunately, the missing values in datasets have negative impacts on the estimation accuracy and therefore, could lead to inconsistent results. As a method handling missing data, K nearest neighbor (KNN) imputation gradually gains acceptance in empirical studies by its exemplary performance and simplicity. To date, researchers still call for optimized parameter setting for KNN imputation to further improve its performance. In the work, we develop a novel incomplete-instance based KNN imputation technique, which utilizes a cross-validation scheme to optimize the parameters for each missing value. An experimental assessment is conducted on eight quality\u00a0\u2026", "num_citations": "38\n", "authors": ["228"]}
{"title": "Linear Programming as a Baseline for Software Effort Estimation\n", "abstract": " Software effort estimation studies still suffer from discordant empirical results (i.e., conclusion instability) mainly due to the lack of rigorous benchmarking methods. So far only one baseline model, namely, Automatically Transformed Linear Model (ATLM), has been proposed yet it has not been extensively assessed. In this article, we propose a novel method based on Linear Programming (dubbed as Linear Programming for Effort Estimation, LP4EE) and carry out a thorough empirical study to evaluate the effectiveness of both LP4EE and ATLM for benchmarking widely used effort estimation techniques. The results of our study confirm the need to benchmark every other proposal against accurate and robust baselines. They also reveal that LP4EE is more accurate than ATLM for 17% of the experiments and more robust than ATLM against different data splits and cross-validation methods for 44% of the cases. These\u00a0\u2026", "num_citations": "34\n", "authors": ["228"]}
{"title": "Causal impact analysis applied to app releases in google play and windows phone store\n", "abstract": " App developers would like to know the characteristics of app releases that achieve high impact. To address this, we mined the most consistently popular Google Play and Windows Phone apps, once per week, over a period of 12 months. In total we collected 3,187 releases, from which we identified 1,547 for which there was adequate prior and posterior time series data to facilitate causal impact assessment, analysing the properties that distinguish impactful and non-impactful releases. We find that 40% of target releases impacted performance in the Google store and 55% of target releases impacted performance in the Windows store. We find evidence that more mentions of features and fewer mentions of bug fixing can increase the chance for a release to be impactful, and to improve rating.", "num_citations": "23\n", "authors": ["228"]}
{"title": "Empirical Comparison of Text-Based Mobile Apps Similarity Measurement Techniques\n", "abstract": " Context                 Code-free software similarity detection techniques have been used to support different software engineering tasks, including clustering mobile applications (apps). The way of measuring similarity may affect both the efficiency and quality of clustering solutions. However, there has been no previous comparative study of feature extraction methods used to guide mobile app clustering.                                               Objective                 In this paper, we investigate different techniques to compute the similarity of apps based on their textual descriptions and evaluate their effectiveness using hierarchical agglomerative clustering.                                               Method                 To this end we carry out an empirical study comparing five different techniques, based on topic modelling and keyword feature extraction, to cluster 12,664 apps randomly sampled from the Google Play App Store. The\u00a0\u2026", "num_citations": "14\n", "authors": ["228"]}
{"title": "Predictive analytics for software testing\n", "abstract": " This keynote discusses the use of Predictive Analytics for Software Engineering, and in particular for Software Defect Prediction and Software Testing, by presenting the latest results achieved in these fields leveraging Artificial Intelligence, Search-based and Machine Learning methods, and by giving some directions for future work.", "num_citations": "12\n", "authors": ["228"]}
{"title": "Search-based approaches for software development effort estimation\n", "abstract": " In the last years the use of Search-Based techniques has been suggested to estimate software development effort. These techniques are meta-heuristics able to find optimal or near optimal solutions to problems characterized by large space. In the context of effort estimation Search-Based approaches can be exploited to build estimation models or to enhance the effectiveness of other methods. The preliminary investigations carried out so far have provided promising results. Nevertheless, the capabilities of these approaches have not been fully explored and the empirical analyses carried out so far have not considered the more recent recommendations on how to perform this kind of empirical assessment in the effort estimation context and in Search-Based Software Engineering. The main aim of the PhD dissertation is to provide an insight on the use of Search-Based techniques for effort estimation trying to\u00a0\u2026", "num_citations": "10\n", "authors": ["228"]}
{"title": "Cost measures matter for mutation testing study validity\n", "abstract": " Mutation testing research has often used the number of mutants as a surrogate measure for the true execution cost of generating and executing mutants. This poses a potential threat to the validity of the scientific findings reported in the literature. Out of 75 works surveyed in this paper, we found that 54 (72%) are vulnerable to this threat. To investigate the magnitude of the threat, we conducted an empirical evaluation using 10 real-world programs. The results reveal that: i) percentages of randomly sampled mutants differ from the true execution time, on average, by 44%, varying in difference from 19% to 91%; ii) errors arising from using the surrogate correlate with program size (\u03c1= 0.74) and number of mutants (\u03c1= 0.76), making the problem more pernicious for more realistic programs; iii) scientific findings concerning sampling strategies would have approximately 37% rank disagreement, indicating potentially\u00a0\u2026", "num_citations": "5\n", "authors": ["228"]}
{"title": "Game-theoretic analysis of development practices: Challenges and opportunities\n", "abstract": " Developers continuously invent new practices, usually grounded in hard-won experience, not theory. Game theory studies cooperation and conflict; its use will speed the development of effective processes. A survey of game theory in software engineering finds highly idealised models that are rarely based on process data. This is because software processes are hard to analyse using traditional game theory since they generate huge game models. We are the first to show how to use game abstractions, developed in artificial intelligence, to produce tractable game-theoretic models of software practices. We present Game-Theoretic Process Improvement (GTPI), built on top of empirical game-theoretic analysis. Some teams fall into the habit of preferring \u201cquick-and-dirty\u201d code to slow-to-write, careful code, incurring technical debt. We showcase GTPI\u2019s ability to diagnose and improve such a development process\u00a0\u2026", "num_citations": "5\n", "authors": ["228"]}
{"title": "A Survey of Performance Optimization for Mobile Applications\n", "abstract": " Nowadays there is a mobile application for almost everything a user may think of, ranging from paying bills and gathering information to playing games and watching movies. In order to ensure user satisfaction and success of applications, it is important to provide high performant applications. This is particularly important for resource constraint systems such as mobile devices. Thereby, non-functional performance characteristics, such as energy and memory consumption, play an important role for user satisfaction. This paper provides a comprehensive survey of non-functional performance optimization for Android applications. We collected 155 unique publications, published between 2008 and 2020, that focus on the optimization of non-functional performance of mobile applications. We target our search at four performance characteristics, in particular: responsiveness, launch time, memory and energy\u00a0\u2026", "num_citations": "4\n", "authors": ["228"]}
{"title": "Evaluating Automatic Program Repair Capabilities to Repair API Misuses\n", "abstract": " API misuses are well-known causes of software crashes and security vulnerabilities. However, their detection and repair is challenging given that the correct usages of (third-party) APIs might be obscure to the developers of client programs. This paper presents the first empirical study to assess the ability of existing automated bug repair tools to repair API misuses, which is a class of bugs previously unexplored. Our study examines and compares 14 Java test-suite-based repair tools (11 proposed before 2018, and three afterwards) on a manually curated benchmark (APIREPBENCH) consisting of 101 API misuses. We develop an extensible execution framework (APIARTY) to automatically execute multiple repair tools. Our results show that the repair tools are able to generate patches for 28% of the API misuses considered. While the 11 less recent tools are generally fast (the median execution time of the repair\u00a0\u2026", "num_citations": "4\n", "authors": ["228"]}
{"title": "FrUITeR: A Framework for Evaluating UI Test Reuse\n", "abstract": " FrUITeR: A Framework for Evaluating UI Test Reuse - UCL Discovery UCL Logo UCL Discovery UCL home \u00bb Library Services \u00bb Electronic resources \u00bb UCL Discovery Enter your search terms Advanced search Browse by: Department | Year UCL Theses | Latest RSS feed Deposit your research Open Access About UCL Discovery UCL Discovery Plus REF and open access UCL Press UCL e-theses guidelines Statistics FAQs Notices and policies Contact us Bookmark & Share FrUITeR: A Framework for Evaluating UI Test Reuse Chen, J; Zhao, Y; Sej a, A; Schmitt Laser, M; Zhang, J; Sarro, F; Harman, M; (2020) FrUITeR: A Framework for Evaluating UI Test Reuse. In: Proceedings of the ESEC/FSE \u201920. The Institute of Electrical and Electronics Engineers (IEEE) (In press). [img] Text FSE2020fruiter.pdf - Accepted version Access restricted to UCL open access staff until 30 March 2021. Download (2MB) Type: Proceedings -\u2026", "num_citations": "4\n", "authors": ["228"]}
{"title": "Search-Based Predictive Modelling for Software Engineering: How Far Have We Gone?\n", "abstract": " In this keynote I introduce the use of Predictive Analytics for Software Engineering (SE) and then focus on the use of search-based heuristics to tackle long-standing SE prediction problems including (but not limited to) software development effort estimation and software defect prediction. I review recent research in Search-Based Predictive Modelling for SE in order to assess the maturity of the field and point out promising research directions. I conclude my keynote by discussing best practices for a rigorous and realistic empirical evaluation of search-based predictive models, a condicio sine qua non to facilitate the adoption of prediction models in software industry practices.", "num_citations": "4\n", "authors": ["228"]}
{"title": "A New Approach to Distribute MOEA Pareto Front Computation\n", "abstract": " Multi-Objective Evolutionary Algorithms (MOEAs) offer compelling solutions to many real world problems, including software engineering ones. However, their efficiency decreases with the growing size of the problems at hand, hindering their applicability in practice.", "num_citations": "3\n", "authors": ["228"]}
{"title": "Enhancing genetic improvement of software with regression test selection\n", "abstract": " Genetic improvement uses artificial intelligence to automatically improve software with respect to non-functional properties (AI for SE). In this paper, we propose the use of existing software engineering best practice to enhance Genetic Improvement (SE for AI).We conjecture that existing Regression Test Selection (RTS) techniques (which have been proven to be efficient and effective) can and should be used as a core component of the GI search process for maximising its effectiveness.To assess our idea, we have carried out a thorough empirical study assessing the use of both dynamic and static RTS techniques with GI to improve seven real-world software programs.The results of our empirical evaluation show that incorporation of RTS within GI significantly speeds up the whole GI process, making it up to 68% faster on our benchmark set, being still able to produce valid software improvements.Our findings are\u00a0\u2026", "num_citations": "2\n", "authors": ["228"]}
{"title": "Learning From Mistakes:  Machine Learning Enhanced Human Expert Effort Estimates\n", "abstract": " In this paper, we introduce a novel approach to predictive modeling for software engineering, named Learning From Mistakes (LFM). The core idea underlying our proposal is to automatically learn from past estimation errors made by human experts, in order to predict the characteristics of their future misestimates, therefore resulting in improved future estimates. We show the feasibility of LFM by investigating whether it is possible to predict the type, severity and magnitude of errors made by human experts when estimating the development effort of software projects, and whether it is possible to use these predictions to enhance future estimations. To this end we conduct a thorough empirical study investigating 402 maintenance and new development industrial software projects. The results of our study reveal that the type, severity and magnitude of errors are all, indeed, predictable. Moreover, we find that by\u00a0\u2026", "num_citations": "2\n", "authors": ["228"]}
{"title": "The assessor's dilemma: Improving bug repair via empirical game theory\n", "abstract": " Priority inflation occurs when a QA engineer or a project manager requesting a feature inflates the priority of their task so that developers deliver the fix or the new functionality faster. We survey developers and show that priority inflation occurs and misallocates developer time. We are the first to apply empirical game-theoretic analysis (EGTA) to a software engineering problem, specifically priority inflation. First, we extract prioritization strategies from 42,620 issues from Apache's JIRA, then use TaskAssessor, our EGTA-based modelling approach, to confirm conventional wisdom and show that the common process of a QA engineer assigning priority labels is susceptible to priority inflation. We then show that the common mitigation strategy of having a bug triage team assigning priorities does not resolve priority inflation and slows development. We then use mechanism design to devise assessor-throttling, a new\u00a0\u2026", "num_citations": "2\n", "authors": ["228"]}
{"title": "Multi-Objective Software Effort Estimation: A Replication Study\n", "abstract": " Replication studies increase our confidence in previous results when the findings are similar each time, and help mature our knowledge by addressing both internal and external validity aspects. However, these studies are still rare in certain software engineering fields. In this paper, we replicate and extend a previous study, which denotes the current state-of-the-art for multi-objective software effort estimation, namely CoGEE. We investigate the original research questions with an independent implementation and the inclusion of a more robust baseline (LP4EE), carried out by the first author, who was not involved in the original study. Through this replication, we strengthen both the internal and external validity of the original study. We also answer two new research questions investigating the effectiveness of CoGEE by using four additional evolutionary algorithms (i.e., IBEA, MOCell, NSGA-III, SPEA2) and a well\u00a0\u2026", "num_citations": "1\n", "authors": ["228"]}
{"title": "Learning Techniques for Systems in Evolution in Software Defect Prediction\n", "abstract": " Context: Software Defect Prediction (SDP) seeks for a classification model that will effectively aid the verification and validation activities in software development life cycle. Among various soft computing techniques, the use of Genetic Programming (GP) as a classification model was recently proposed. GP was found capable of dealing with unbalanced data, which is a common problem in SDP. Objective: The use of GP offers a wide range of possible configurations and it is important to find the most suitable one. Systems in evolution contain valuable information in their past releases that could be used for learning. In this paper, we examine the potential of GP in SDP and compare different learning techniques of fitness functions (Accuracy, F-measure, G-mean, Weighted Average Accuracy and Mathews Correlation Coefficient) and training scenarios (learning from the most recent release or from all previous releases\u00a0\u2026", "num_citations": "1\n", "authors": ["228"]}