{"title": "Indoor and outdoor location based services for portable wireless devices\n", "abstract": " Designing and developing location-aware portable software applications is challenging, since most location-estimation methods i) require non-standard features either in the mobile terminal or in the network infrastructure, and ii) they are specifically designed for either indoor or outdoor. Moreover, installing and tuning systems that rely on such location methods may be quite a complex operation. In this paper we propose a software architecture that makes a combined use of indoor and outdoor location-sensing technologies. On top of the architecture there is a generic API, aimed at supporting the development of hybrid (indoor/outdoor) applications at a high level of abstraction, independent of the location technology. The API is meant to support applications for which the exact position of a mobile terminal is not a primary requirement, but it suffices to identify the terminal position in a known set of zones (e.g., rooms\u00a0\u2026", "num_citations": "87\n", "authors": ["429"]}
{"title": "Security requirements in service oriented architectures for ubiquitous computing\n", "abstract": " This work presents a detailed analysis of the security requirements for Service Oriented Architecture in mobile computing, still missing in the current literature. The purpose of this work is twofold. First, to provide protocol architects and software engineers with a map of security requirements in ubiquitous computing, through the evaluation of existing protocols and architectures. Second, to highlight architectural issues, including technologies and trade offs, in the design and implementation of a secure service oriented architecture for ubiquitous computing.", "num_citations": "68\n", "authors": ["429"]}
{"title": "On reliability in publish/subscribe services\n", "abstract": " Modern large-scale mission-critical systems demand efficient and robust multi-point data dissemination infrastructures. Since such infrastructures have to exhibit good performance when scaling up the number of interacting entities and managing large amounts of data, publish/subscribe services represent a suitable middleware solution due to their decoupling properties. However, since data are conveyed by networks where failures may occur, and since nodes may present a faulty behavior, such services also have to adopt proper mechanisms to deal with several kinds of failures and to guarantee event dissemination despite their occurrence. Although significant efforts have been made on this topic, many issues are still open.This article covers an introduction to the principles of assuring event notification even in the presence of faults, and an analysis of relevant state-of-the-art by both surveying the academic\u00a0\u2026", "num_citations": "66\n", "authors": ["429"]}
{"title": "Characterizing aging phenomena of the java virtual machine\n", "abstract": " In this work we investigate software aging phenomena inside the Java Virtual Machine (JVM). Starting from an experimental campaign on real world testbeds, this work isolates the contribution of the JVM to the overall aging trend, and identifies, through statistical methods, which workload parameters are more relevant to aging dynamics. Experimental results show that the Sun Hotpost JVM experiences software aging phenomena. A consistent memory depletion trend (up to 50 KB/min) has been observed during periods of low garbage collector activity; the Just-In-Time compiler is also responsible for a lighter, but not negligible, memory depletion trend; finally, a consistent throughput loss (up to 24 KB/min) has been observed.", "num_citations": "53\n", "authors": ["429"]}
{"title": "Performance assessment of OMG compliant data distribution middleware\n", "abstract": " Event-driven architectures (EDAs) are widely used to make distributed mission critical software systems more- efficient and scalable. In the context of EDAs, data distribution service (DDS) is a recent standard by the object management group that offers a rich support for quality- of-service and balances predictable behavior and implementation efficiency. The DDS specification does not outline how messages are delivered, so several architectures are nowadays available. This paper focuses on performance assessment of OMG DDS-compliant middleware technologies. It provides three contributions to the study of evaluating the performance of DDS implementations: 1) describe the challenges to be addressed; 2) propose possible solutions; 3) define a representative workload scenario for evaluating the performance and scalability of DDS platforms. At the end of the paper, a case study of DDS performance\u00a0\u2026", "num_citations": "45\n", "authors": ["429"]}
{"title": "Failure classification and analysis of the java virtual machine\n", "abstract": " This paper presents a failure analysis of the Java Virtual Machine providing useful insights into the nature of reported failures and to improve the understanding of its dependability aspects. Failure data is extracted from publicly available bug databases, where developers and users of Java applications usually submit failures/bugs. Presented results clearly indicate that much more efforts have still to be done in order to improve the dependability of the JVM. In particular, the conducted analysis revealed that i) builtin error detection mechanism are characterized by a low coverage; ii) the JVM does not achieve the same levels of dependability across different platforms iii) developers have to pursue a tradeoff between performance and reliability. Finally, code fragments reproducing failures submitted in bug database are injected into Java Applications. Preliminary results show that often these faults could be removed\u00a0\u2026", "num_citations": "45\n", "authors": ["429"]}
{"title": "Improving dependability of service oriented architectures for pervasive computing\n", "abstract": " Service oriented programming - which combines distributed object computing, component-based and Web-based concepts - has recently emerged as a promising approach to develop dynamic and heterogeneous service provision environments. Such systems are referenced in literature as service oriented architectures. Classic strategies to address dependability in distributed object computing middleware may not be straightforwardly applied to service oriented architectures (SOAs) for pervasive computing, since they operate in quite different contexts compared to traditional DOC middleware. In this paper, our focus is on dependability issues of SOAs. In particular, we identify dependability requirements of such systems during their life cycle showing how these requirements may change depending on the time phase (discovery, lookup, setup, delivery). We also explore the suitability of Jini technology as an\u00a0\u2026", "num_citations": "41\n", "authors": ["429"]}
{"title": "A hybrid positioning system for technology\u2010independent location\u2010aware computing\n", "abstract": " Location\u2010aware computing is a form of context\u2010aware mobile computing that refers to the ability of providing users with services that depend on their position. Locating the user terminal, often called positioning, is essential in this form of computing. Towards this aim, several technologies exist, ranging from personal area networking, to indoor, outdoor, and up to geographic area systems. Developers of location\u2010aware software applications have to face with a number of design choices, that typically depend on the chosen technology. This work addresses the problem of easing the development of pull location\u2010aware applications, by allowing uniform access to multiple heterogeneous positioning systems. Towards this aim, the paper proposes an approach to structure location\u2010aware mobile computing systems in a way independent of positioning technologies. The approach consists in structuring the system into a\u00a0\u2026", "num_citations": "39\n", "authors": ["429"]}
{"title": "Modeling and Assessing the Dependability of Wireless Sensor Networks\n", "abstract": " This paper proposes a flexible framework for dependability modeling and assessing of Wireless Sensor Networks (WSNs). The framework takes into account network related aspects (topology, routing, network traffic) as well as hardware/software characteristics of nodes (type of sensors, running applications, power consumption). It is composed of two basic elements: i) a parametric Stochastic Activity Networks (SAN) failure model, reproducing WSN failure behavior as inferred from a detailed Failure Mode Effect Analysis (FMEA), and ii) an external library reproducing network behavior on behalf of the SAN model. This library specializes the SAN model by feeding it with quantitative parameters obtained by simulation or by experimental campaigns; it is also in charge of updating the network state in response to failure events during the simulation (e.g., routing tree updated due to node failures). The framework is thus\u00a0\u2026", "num_citations": "37\n", "authors": ["429"]}
{"title": "Assessment and improvement of hang detection in the Linux operating system\n", "abstract": " We propose a fault injection framework to assess hang detection facilities within the Linux operating system (OS). The novelty of the framework consists in the adoption of a more representative fault load than existing ones, and in the effectiveness in terms of number of hang failures produced; representativeness is supported by a field data study on the Linux OS. Using the proposed fault injection framework, along with realistic workloads, we find that the Linux OS is unable to detect hangs in several cases. We experience a relative coverage of 75%. To improve detection facilities, we propose a simple yet effective hang detector, which periodically tests OS liveness, as perceived by applications, by means of I/O system calls; it is shown that this approach can improve relative coverage up to 94%. The hang detector can be deployed on any Linux system, with an acceptable overhead.", "num_citations": "36\n", "authors": ["429"]}
{"title": "Detection of software failures through event logs: An experimental study\n", "abstract": " Software faults are recognized to be among the main responsible for system failures in many application domains. Event logs play a key role to support the analysis of failures occurring under real workload conditions. Nevertheless, field experience suggests that event logs may be inaccurate at reporting software failures or they fail to provide accurate support for understanding their causes. This paper analyzes the factors that determine accurate detection of software failures through event logs. The study is based on a data set of 17,387 experiments where failures have been induced by means of software fault injection into three systems. Analysis reveals that the reporting ability of logs collected during the experiments, is not influenced by the type of fault that is activated at runtime. More importantly, analysis demonstrates that, despite the considered systems adopt very similar detection mechanisms, the ability of\u00a0\u2026", "num_citations": "35\n", "authors": ["429"]}
{"title": "Avr-inject: A tool for injecting faults in wireless sensor nodes\n", "abstract": " As the incidence of faults in real Wireless Sensor Networks (WSNs) increases, fault injection is starting to be adopted to verify and validate their design choices. Following this recent trend, this paper presents a tool, named AVR-INJECT, designed to automate the fault injection, and analysis of results, on WSN nodes. The tool emulates the injection of hardware faults, such as bit flips, acting via software at the assembly level. This allows to attain simplicity, while preserving the low level of abstraction needed to inject such faults. The potential of the tool is shown by using it to perform a large number of fault injection experiments, which allow to study the reaction to faults of real WSN software.", "num_citations": "34\n", "authors": ["429"]}
{"title": "An OS-level framework for anomaly detection in complex software systems\n", "abstract": " Revealing anomalies at the operating system (OS) level to support online diagnosis activities of complex software systems is a promising approach when traditional detection mechanisms (e.g., based on event logs, probes and heartbeats) are inadequate or cannot be applied. In this paper we propose a configurable detection framework to reveal anomalies in the OS behavior, related to system misbehaviors. The detector is based on online statistical analyses techniques, and it is designed for systems that operate under variable and non-stationary conditions. The framework is evaluated to detect the activation of software faults in a complex distributed system for Air Traffic Management (ATM). Results of experiments with two different OSs, namely Linux Red Hat EL5 and Windows Server 2008, show that the detector is effective for mission-critical systems. The framework can be configured to select the monitored\u00a0\u2026", "num_citations": "33\n", "authors": ["429"]}
{"title": "Formal specification of concurrent systems: a structured approach\n", "abstract": " CSP and Petri Nets are powerful formalisms for the specification and the analysis of concurrent systems. We present an approach to their integration to take advantage of both formalisms. In particular the GSPN class is used to address dependability and real-time aspects. In this paper an algorithmic transformation from a trace-based specification of a concurrent system to a Petri Net model is described. Causal dependencies between behaviours of the system components are introduced in the net model through the definition of external assumptions. The steps of the integration are illustrated by applying them to an unmanned transportation problem.", "num_citations": "30\n", "authors": ["429"]}
{"title": "Implementing positioning services over an ubiquitous infrastructure\n", "abstract": " Ubiquitous computing is rapidly emerging as a framework for deploying mobile and context-aware applications. We focus on a new approach, and the resulting architecture, for implementing positioning services over ubiquitous infrastructures. Our driving idea is to estimate zones where mobile devices operate measuring the power level of wireless communications for locating them. The proposed architecture is largely independent from the devices used and from the wireless communication technologies. We experiment the approach over a Bluetooth and Wi-Fi infrastructure.", "num_citations": "28\n", "authors": ["429"]}
{"title": "Collecting and analyzing failure data of bluetooth personal area networks\n", "abstract": " This work presents a failure data analysis campaign on Bluetooth personal area networks (PANs) conducted on two kind of heterogeneous testbeds (working for more than one year). The obtained results reveal how failures distribution is characterized and suggest how to improve the dependability of Bluetooth PANs. Specifically, we define the failure model and we then identify the most effective recovery actions and masking strategies that can be adopted for each failure. We then integrate the discovered recovery actions and masking strategies in our testbeds, improving the availability and the reliability of 3.64% (up to 36.6%) and 202% (referred to the mean time to failure), respectively", "num_citations": "25\n", "authors": ["429"]}
{"title": "A systematic approach to the Petri net based specification of concurrent systems\n", "abstract": " We describe an approach to the specification of concurrent systems which enables a Petri net model of a system to be built up in a systematic way starting from a trace-based CSP specification. This method enables the separate specification of the behavior of each component (process) and their interactions in terms of the feasible sequences of events in which they can be involved. A set of rules is then applied to transform the trace-based specifications into a complete Petri net that is analyzed and/or executed to validate system behavior. The domain transformation procedure is fully automatable. The specification of a safety-critical railway control system is used as a case study.", "num_citations": "23\n", "authors": ["429"]}
{"title": "Unearthing design patterns to support context-awareness\n", "abstract": " The lack of structured methodologies and software engineering efforts on designing the support of context-awareness in pervasive systems hinders the potential advantages of analyzing and reusing other practitioners' experience on solving common problems. This paper proposes to exploit design patterns to identify and capture common aspects of various design solutions. Specifically, we reverse-architect existing context-awareness support systems and unearth design patterns that have been implicitly (and rarely explicitly) adopted to solve similar problems", "num_citations": "20\n", "authors": ["429"]}
{"title": "Achieving reliable and timely event dissemination over wan\n", "abstract": " The design of large-scale critical infrastructures demands for innovative data dissemination services, able to jointly provide reliability and timeliness guarantees. Current middleware solutions do not address both these aspects. Indeed, fault tolerance is typically achieved at the cost of severe performance fluctuations, or timeliness is always obtained by softening the fault-tolerance requirements. In this paper we propose to fulfill this lack by combining two different approaches, namely coding and gossiping. We provide a theoretical model to evaluate the potential benefit of coding on the information delivery performance. These results are also confirmed by an experimental analysis conducted on a real air traffic control workload, which evidences how coding mitigates latency and overhead penalties to ensure reliable event notification.", "num_citations": "17\n", "authors": ["429"]}
{"title": "Software architecture of the EPOCA integrated environment\n", "abstract": " We describe the software architecture of EPOCA (Environment for analysis and Performance evaluation Of Concurrent Applications), a tool for the analysis of concurrent programs. The analysis is based on a formal model of the application. The class of models chosen is that of stochastic Petri nets (in particular we adopt Generalized Stochastic Petri Nets \u2014 GSPN [1]): starting from a concurrent program written in DISC (DIStributed C), an extension of C to include concurrent constructs of the CSP type [12], a GSPN model is automatically generated, and GSPN analysis tools can then be applied. EPOCA is built as an integration of the DISC environment (a graphical interface based environment that provides compiling, monitoring and profiling facilities for DISC programs) and GreatSPN [6] (a graphical interface based environment for the definition and the analysis of GSPN).", "num_citations": "16\n", "authors": ["429"]}
{"title": "Trust management in fog/edge computing by means of blockchain technologies\n", "abstract": " Trust management is extremely important for sensor networks, and the emerging vision of the Internet of Things (IoT) does not represent an exception. In fact, it allows to realize a dynamic access control needed to cope with internal attacks conducted by compromised nodes, which are likely to occur in real world. However, trust management implies a considerable consumption of energy, due to the amount of messages exchanged to collect reputation scores. Consumption is further exacerbated by the means needed to protect from attacks the trust management entities themselves. This work proposes a suitable trust management for the IoT by exploiting the eventual consistency and security guarantees of blockchain. The design of a solution based on such a technology is described, and a qualitative assessment of its protection degree is provided.", "num_citations": "15\n", "authors": ["429"]}
{"title": "Optimized task allocation on private cloud for hybrid simulation of large-scale critical systems\n", "abstract": " Simulation represents a powerful technique for the analysis of dependability and performance aspects of distributed systems. For large-scale critical systems, simulation demands complex experimentation environments and the integration of different tools, in turn requiring sophisticated modeling skills. Moreover, the criticality of the involved systems implies the set-up of expensive testbeds on private infrastructures. This paper presents a middleware for performing hybrid simulation of large-scale critical systems. The services offered by the middleware allow the integration and interoperability of simulated and emulated subsystems, compliant with the reference interoperability standards, which can provide greater realism of the scenario under test. The hybrid simulation of complex critical systems is a research challenge due to the interoperability issues of emulated and simulated subsystems and to the cost\u00a0\u2026", "num_citations": "15\n", "authors": ["429"]}
{"title": "A statistical anomaly-based algorithm for on-line fault detection in complex software critical systems\n", "abstract": " The next generation of software systems in Large-scale Complex Critical Infrastructures (LCCIs) requires efficient runtime management and reconfiguration strategies, and the ability to take decisions on the basis of current and past behavior of the system. In this paper we propose an anomalybased approach for the detection of online faults, which is able to (i) cope with highly variable and non-stationary environment and to (ii) work without any initial training phase. The novel algorithm is based on Statistical Predictor and Safety Margin (SPS), which was initially developed to estimate the uncertainty in time synchronization mechanisms.               The SPS anomaly detection algorithm has been experimented on a case study from the Air Traffic Management (ATM) domain. Results have been compared with an algorithm, which adopts static thresholds, in the same scenarios [5]. Experimental results show\u00a0\u2026", "num_citations": "15\n", "authors": ["429"]}
{"title": "Java Virtual Machine monitoring for dependability benchmarking\n", "abstract": " A monitoring infrastructure is a key component in each task aimed at evaluating the dependability of a system. This paper presents a monitoring infrastructure for the Java Virtual Machine (JVM), which is starting to be employed in mission and safety critical application, often with real-time requirements. This infrastructure, named JVMMon, collects data about both the state and the failures of the monitored Virtual Machine. The state of the JVM was defined according to the Java Virtual Machine specification. JVMMon is constituted by three components: a monitoring agent which collects data from the monitored VM; a local monitor daemon that receives data from such agent and updates the state of the JVM; a data collector, which stores events and state snapshots in a database. The impact on the performance of the JVM has been evaluated running the SPEC JVM98 benchmark suite", "num_citations": "14\n", "authors": ["429"]}
{"title": "Achieving all the time, everywhere access in next-generation mobile networks\n", "abstract": " The anytime, anywhere access view of nomadic computing is evolving towards all the time, everywhere views of pervasive computing. The all the time access requires mobile devices to be always connected, even if connectivity may be compromised due to Access Point overload and to transient signal degradations. The everywhere access requires mobile devices to use heterogeneous Access Points (ranging from Bluetooth and 802.11 to 2.5G and 3G cellulars), leading to high variability of the connection status. A mobility management solution that leverages connection availability, while enabling applications to be aware of the connection status, is thus needed. This paper proposes a Last Second Soft Handoff scheme that leverages the availability of connection. The proposed scheme has been integrated in a mobility management architecture, which provides connection awareness via an API, named NCSOCKS\u00a0\u2026", "num_citations": "14\n", "authors": ["429"]}
{"title": "Blockchain-empowered decentralised trust management for the Internet of Vehicles security\n", "abstract": " Internet of Vehicles (IoV) requires trust management to implement effective authentication and authorization of nodes, as it is not possible to establish trusted connections to the roadside components that eventually a vehicle will meet during its journey, ahead of time. To cope with this issue, dynamic access control is required, where authorizations are granted considering security policies and the node trustworthiness. However, decentralized trust management is a preferable solution, but it implies a considerable consumption of energy. Consumption is further exacerbated by the means needed to protect from attacks the trust management entities themselves.This work proposes suitable trust management for the IoT and IoV by exploiting the eventual consistency and security guarantees of blockchain. The design of a solution based on such technology is described, and an empirical assessment of its protection\u00a0\u2026", "num_citations": "13\n", "authors": ["429"]}
{"title": "Development of a digital radiography system based on silicon microstrip detector\n", "abstract": " We are developing a digital radiography system based on double sided microstrip silicon crystal. The read-out system consists of a VLSI integrated circuit that has the following properties: low noise preamplification, pulse shaping, threshold discrimination. The current signals coming out of the integrated circuit are converted into TTL level signals by discrete component electronics. A Time-to-Digital-Converter + Transputer-based acquisition system reads the TTL signals and reconstructs the impact point of the incident photon. We made a study of the spatial resolution by measuring the Square Wave Resolution Function. To test the imaging capability of the system, we made some radiographs of low contrast (<10%) phantoms. Moreover, an image of a small sample of bone tissue has been obtained by scanning technique (average contrast of the phantom is 20%).", "num_citations": "13\n", "authors": ["429"]}
{"title": "Use of GSPNs for concurrent software validation in EPOCA\n", "abstract": " The main issues related to the use of the Generalized Stochastic Petri Nets (GSPN) formalism for computer supported concurrent software comprehension and validation are discussed. A GSPN-based approach is currently under investigation in the EPOCA Project, based on the integration of the DIStributed C development system with the GreatSPN tool for editing and analysis of GSPN models.", "num_citations": "13\n", "authors": ["429"]}
{"title": "Cloud reliability: Possible sources of security and legal issues?\n", "abstract": " Cloud computing is a key supporting technology driving the fourth industrial revolution, spanning from the Internet of Things (IoT) and Cloud for Telecoms (C4T) to Industry 4.0 to Smart Cities. This pervasiveness of cloud technology is due to its ability to easily share and obtain resources on a pay-peruse and elastic provisioning model. Several enterprises use the cloud as a cheap solution to achieve computational and storage capabilities they need without incurring in the costs associated with owning and maintaining data centers. This implies that cloud-based applications rely on the correctness of the services provided by the cloud platforms and that any possible outage could result in considerable loss of reputation and money to the application provider. This could also effectively bring actions against the cloud service provider for violations to the agreed Service Level Agreement (SLA).", "num_citations": "12\n", "authors": ["429"]}
{"title": "Cost-benefit analysis of virtualizing batch systems: Performance-energy-dependability trade-offs\n", "abstract": " Performance, energy efficiency, and dependability are key characteristics of batch systems, which can be differently affected when adopting virtualization. Scientific literature usually analyzes the variation with respect to different configurations of one characteristic, or the trade-off between two. In this paper, instead, we assess the impact of virtualization encompassing all of them. Results show that the joint analysis helps in finding the proper tuning of the system for balancing costs and benefits due to virtualization and related techniques.", "num_citations": "11\n", "authors": ["429"]}
{"title": "An enhanced service oriented architecture for developing web-based applications\n", "abstract": " Web serves architectures have recently emerged as standard, service oriented approach for developing Internet-scale distributed systems. Such architectures are characterized by discovery and delivery infrastructures since service provisioning follows the publish-find-bind paradigm", "num_citations": "11\n", "authors": ["429"]}
{"title": "To Cloudify or Not to Cloudify: The Question for a Scientific Data Center\n", "abstract": " The idea of turning data centers executing scientific batch jobs into private clouds is as attractive as troubling. Cloud platforms may help both in limiting power consumption and in implementing fault tolerance strategies. However, there is also the fear that performance may worsen, and that the electricity required for longer job duration and fault tolerance implementation may overcome the saved one. In this paper, we present the consumability analysis for assessing the impact of cloud and fault tolerance tunings on scientific processing systems. The analysis considers performance, consumption, and dependability aspects, jointly. The aim is to pinpoint if, for a given system, there is a setting where consumption and job failure rate decrease, while performance is not affected. Applied to the scientific data center at our University, the analysis allowed us to find the proper selection of virtual machines' configuration\u00a0\u2026", "num_citations": "10\n", "authors": ["429"]}
{"title": "Keeping pace with an information society\n", "abstract": " There is no doubt we are witnessing a tech-nology revolution that is shaping impor-tant aspects of our society. Education is no exception. Even the staunchest advocates of traditional teaching methods are finding themselves using e-mail to supplement office hours. Desktop computers are showing up in faculty offices, class sessions are held in computer labs, software packages and simulators accompany textbooks, and homework often consists of Web searches. But merely using the techniques and tools afforded by computing and information technology is not itself the solution to fitting education to the demands of an information society. We must do much more than be caught up in technology. We must aggressively go after the skills and methods needed to produce designers of the complex information systems our society requires. If we do not, we jeopardize not only the future of our graduates, but also our\u00a0\u2026", "num_citations": "10\n", "authors": ["429"]}
{"title": "A transputer-based list mode parallel system for digital radiography with 2D silicon detectors\n", "abstract": " The authors argue that a dedicated parallel computer system can represent an effective and flexible approach to the problem of list mode acquisition and reconstruction of digital radiographic images obtained with a double-sided silicon microstrip detector. A transputer-based implementation of a parallel system for the data acquisition and image reconstruction from a silicon crystal with 200- mu m read-out pitch is presented. A prototype of the system connected to a detector with a 10 mm/sup 2/ sensitive area is under development.< >", "num_citations": "10\n", "authors": ["429"]}
{"title": "State-driven testing of distributed systems\n", "abstract": " In distributed systems, failures are often caused by software faults that manifest themselves only when the system enters a particular, rarely occurring system state. It thus becomes important to identify these failure-prone states during testing. We propose a state-driven testing approach for distributed systems, able to execute tests in hard-to-reach states in a repeatable and accurate way. Moreover, we present the implementation and experimental evaluation of the approach in the context of a fault-tolerant flight data processing system. Experimental results confirm the feasibility of the approach, and the accuracy and reproducibility of tests.", "num_citations": "9\n", "authors": ["429"]}
{"title": "Supporting mobile context-aware applications through a modular service infrastructure\n", "abstract": " This work presents a modular service infrastructure to support context-awareness in nomadic computing. The proposed approach aims to ease the tasks of (i) deploying,(ii) maintaining, and (iii) extending mobile context-aware systems. The infrastructure allows applications to retrieve and share well-known context attributes by means of ontology-based context-provider components. Moreover, the infrastructure provides applications with a contextchange notification service, which is specially designed to cope with user mobility. We describe potential benefits of our infrastructure, and our future research directions.", "num_citations": "9\n", "authors": ["429"]}
{"title": "X-ray imaging test of a \u03bc-strip silicon detector with a transputer DAQ\n", "abstract": " The authors have developed a TDC+Transputer-based acquisition system to study the X-ray imaging capabilities of a silicon /spl mu/-strip detector with 100 and 200 /spl mu/m read-out pitch. This system allows real-time image acquisition and display. The authors present images obtained with an X-ray mammography tube using sub-millimeter high contrast test objects on a 16*16 channels prototype.< >", "num_citations": "9\n", "authors": ["429"]}
{"title": "Towards identifying OS-level anomalies to detect application software failures\n", "abstract": " The next generation of critical systems, namely complex Critical Infrastructures (LCCIs), require efficient runtime management, reconfiguration strategies, and the ability to take decisions on the basis of current and past behavior of the system. Anomaly-based detection, leveraging information gathered at Operating System (OS) level (e.g., number of system call errors, signals, and holding semaphores in the time unit), seems to be a promising approach to reveal online application faults. Recently an experimental campaign to evaluate the performance of two anomaly detection algorithms was performed on a case study from the Air Traffic Management (ATM) domain, deployed under the popular OS used in the production environment, i.e., Red Hat 5 EL. In this paper we investigate the impact of the OS and the monitored resources on the quality of the detection, by executing experiments on Windows Server 2008\u00a0\u2026", "num_citations": "8\n", "authors": ["429"]}
{"title": "Clobetasol 17-propionate cream as an effective preventive treatment for drug induced superficial thrombophlebitis\n", "abstract": " Commonly used therapies for thrombophlebitis have a high failure rate. There are scant data on the application of topical corticosteroids to treat thrombophlebitis. The present study investigated if the potent topical corticosteroid clobetasol 17-propionate cream (Dermovate, Glaxo Wellcome) can be an effective treatment for drug-induced thrombophlebitis.DP-b99, a neuroprotective agent currently undergoing development for acute stroke, can cause injectionsite phlebitis. DP-b99 was administered at doses of 1 and 2 mg/kg by a 1 hour intravenous infusion into the lateral ear vein of groups of 6 and 5 rabbits, respectively. Each rabbit served as its own control by injecting both ears with DP-b99, while treating only one ear with clobetasol cream immediately after treatment, with subsequent applications twice daily for 3 days. Phlebitis was evaluated 1, 3, 5, 24, 32, 48, 56 and 72 hours after DP-b99 treatment using a clinical score ranging from 0 (no reaction) to 4. After 3 days the rabbits were sacrificed for histological analysis of the ears.", "num_citations": "8\n", "authors": ["429"]}
{"title": "Improving the availability of Web services\n", "abstract": " In order to maintain the popularity and reputation of a web site, the quality of service perceived by users, especially the service availability, is a success factor. A service that is frequently unavailable may have negative effects on the reputation of the service provider, or result in loss of business opportunities. From the user\u2019s perspective, a service that exhibits poor quality is virtually equivalent to an unavailable service. In this work, we present the overall architecture and the evaluation of a middleware infrastructure which provides quality-of-service differentiation among classes of communication-bound processes. By communication-bound processes we mean processes whose activity is typically dominated by network communication, eg a video server. The proposed architecture supports different classes of service, each with different quality attributes concerning the network data delivery performance. In particular, the architecture is able to provide a class of service, namely guaranteed service class, which is suitable for increasing the service availability for a group of premium users, especially in overloaded servers (in absence of external faults).", "num_citations": "8\n", "authors": ["429"]}
{"title": "Effective metadata models for web-based educational systems\n", "abstract": " This paper deals with the exploration of proper information technologies and services to support a number of activities in web-based distance educational initiatives, and with the description of related experiments performed in some university courses of a computer engineering curriculum. These activities, usually carried out by course authors, tutors and learners, include searching and locating educational resources over the Internet, sharing and reusing them, and online delivery to the learner, possibly in a way adaptive with respect to learner's skill and preferences. Specifically, in this paper we present the work done within the project GESTALT of the European Union 4th Framework Programme, and continuing within the project EASEL of the 5th Framework Programme, to develop standard-based metadata models, which facilitate the development of efficient resource discovery services and management of\u00a0\u2026", "num_citations": "8\n", "authors": ["429"]}
{"title": "Modular data acquisition system based on transputer technology for bi-dimensional time coincidence counting\n", "abstract": " We describe the rationale and the test of a modular Data AcQuisition system (DAQ) for bi-dimensional (X\u2212Y) digital imaging, based on a 16 channel Time-to-Digital Converter (TDC) NIM module connected to a specially designed TRAnsputer Module (TRAM). TDC time resolution is 12.5 ns (LSB) with a 40 MHz clock, time range is 3.3 s (28 bits), for a maximum rate of 500 kHz/channel guaranteed. The TDC + TRAM pair is the basic unit that can be scaled in modules of 8X + 8Y channels to meet the user's requirement for a larger number of X\u2212Y channels to be considered simultaneously. TDC directly accesses the large RAM memory (32 Mbytes) of the INMOS T805 (20 MHz) transputer on the TRAM board. Each transputer in the modular system is a node of a ring network, whose root transputer node is hosted in a i386-based personal computer. After real-time data acquisition, a parallel reconstruction algorithm\u00a0\u2026", "num_citations": "8\n", "authors": ["429"]}
{"title": "A reliable crisis information system to share data after the event of a large-scale disaster\n", "abstract": " Crisis information systems have reliability as a key technical concern to be guaranteed, given the critical role of information sharing in crisis management. However, a common agreement is missing about the requirements to be satisfied. Moreover, scarce details are provided to describe the means to apply in order to satisfy the reliability requirements and/or to tolerate the faults that may affect a crisis information system. The scope of this paper is to determine the requirements to be satisfied in order to provide reliability, to survey the available literature and practice on this topic, and to propose an innovative solution for reliable crisis information systems in the context of the platform under development within the EU-funded DESTRIERO project.", "num_citations": "7\n", "authors": ["429"]}
{"title": "Reliable event dissemination over wide-area networks without severe performance fluctuations\n", "abstract": " Publish/subscribe middleware is being increasingly used to devise large-scale critical systems. Although several reliable publish/subscribe solutions have been proposed, none of them properly address the problem of assuring message dissemination even if network omissions happen without breaking any temporal constraints. In order to fill this gap, we have investigated how to guarantee a resilient and timely event dissemination despite of message losses. The contribution of this paper is on proposing a FEC approach, where encoding functionality is placed at the root and on a subset of interior nodes in the multicast tree, combined to a gossiping algorithm. Simulation-based experiments demonstrate that the proposed approach allows all the interested subscribers to receive all the published messages and the adopted resiliency mean does not affect the timeliness of the multicast protocol.", "num_citations": "7\n", "authors": ["429"]}
{"title": "Securing services in nomadic computing environments\n", "abstract": " This work addresses the existing research gap regarding the security of service oriented architectures and their integration in the context of nomadic computing. The state of the art of Service Oriented Architectures (SOAs) is thoroughly investigated to understand what secure service provision means for different SOAs and whether an established notion of secure SOA existed. Based on the analysis of existing SOAs, we define a set of requirements for securing services among different nomadic computing domains. Such requirements concern the security of service registration and that of the discovery and delivery phases. The surveyed SOAs are then evaluated in the light of the defined requirements, revealing interesting observations about how current SOAs address security issues. The second part of this work addresses the research issue of achieving secure service provision in a nomadic computing environment\u00a0\u2026", "num_citations": "7\n", "authors": ["429"]}
{"title": "A user-driven adaptation strategy for mobile video streaming applications\n", "abstract": " Recent advances in mobile and wireless technologies make possible the bear of new services and the extension of traditional ones in new scenarios. Adaptation strategies play a crucial role in achieving effective solutions for enabling traditional applications to such environments. This paper proposes a video adaptation strategy for real-time multimedia applications, which exploits a novel spacial reduction technique. This technique is suitable for all applications having the need to deliver the best video quality for a particular region of the frame, irrespective of remaining contour. Examples of these applications are those concerning video surveillance. For such applications, it is more important to guarantee the delivery of the only user-selected portion than to deliver the entire, but degraded, video frame when the network conditions are no longer sufficient. Preliminary experimental measurements are conducted in\u00a0\u2026", "num_citations": "7\n", "authors": ["429"]}
{"title": "An automated distributed infrastructure for collecting bluetooth field failure data\n", "abstract": " The widespread use of mobile and wireless computing platforms is leading to a growing interest on dependability issues. Several research studies have been conducted on dependability of mobile environments, but none of them attempted to identify system bottlenecks and to quantify dependability measures. This paper proposes a distributed automated infrastructure for monitoring and collecting spontaneous failures of the Bluetooth infrastructure, which is nowadays more and more recognized as an enabler for mobile systems. Information sources for failure data are presented, and preliminary experimental results are discussed.", "num_citations": "7\n", "authors": ["429"]}
{"title": "Metadata-based Distributed Architecture for Personalized Information Access\n", "abstract": " In this paper we propose a novel architecture for the provision of a personalized service for information discovery and retrieval where we shift the paradigm for personalization from the information creator, who may not produce truly personalize-able information, to a search service that associates users and their needs to specific information. Our architecture uses metadata, based on existing standards, to describe information objects, content providers, and user needs. The work here presented has been undertaken in the framework of IST project GUARDIANS which addresses issues related to the support of on-line discovery and delivery of digital information objects over multiple platforms such as the web and iDTV. The application domain chosen for the experimental part of the project is the educational domain. Here, we first analyze the state of the art of content personalization; we then describe the data models and the architectural model, showing how several metadata standards and technologies can be combined to support content personalization in future information management systems. Finally we describe the project approach to content personalization, emphasizing the need for appropriate metadata models.", "num_citations": "7\n", "authors": ["429"]}
{"title": "Integrating trace logic and Petri nets specifications\n", "abstract": " Presents an experience in formal method integration for the specification and validation of distributed fault-tolerant systems. The specification formalisms we deal with are trace logic, based on CSP (communicating sequential processes) theory, and stochastic Petri nets. Their integration allows us to combine the power of event traces (to specify the behaviour of a system in an intuitive and modular way) with the power of Petri nets (for the analysis of concurrent systems). The integrated specification technique is discussed by applying it to a real industrial control system, which uses redundant modules to guarantee given operational conditions, despite failures, and incorporates a voting algorithm for arbitration over the replicated units.", "num_citations": "7\n", "authors": ["429"]}
{"title": "An operating system independent WORM archival system\n", "abstract": " We describe the organization of a general purpose data archival system for Write\u2010Once, Read\u2010Many (WORM) optical disks. The system has been designed for large\u2010scale and long\u2010term data storage and retrieval. The archival system is independent of the operating system, flat, self\u2010consistent, does not use any write cache on magnetic disk, and allows the exploitation of auxiliary information on magnetic disk, which can be rebuilt immediately in case of a crash, to speed up file retrieval. A library in C language, called pODLIB, has been implemented as a portable interface to the archival system.", "num_citations": "7\n", "authors": ["429"]}
{"title": "Integration and verification testing of the LSST camera\n", "abstract": " The Integration and Verification Testing of the Large Synoptic Survey Telescope (LSST) Camera is described. The LSST Camera will be the largest astronomical camera ever constructed, featuring a 3.2 giga-pixel focal plane mosaic of 189 CCDs with in-vacuum controllers and readout, dedicated guider and wavefront CCDs, a three element corrector with a 1.6-meter diameter initial optic, six optical filters covering wavelengths from 320 to 1000 nm with a novel filter exchange mechanism, and camera-control and data acquisition capable of digitizing each image in two seconds. In this paper, we describe the integration processes under way to assemble the Camera and the associated verification testing program. The Camera assembly proceeds along two parallel paths: one for the focal plane and cryostat and the other for the Camera structure itself. A range of verification tests will be performed interspersed with\u00a0\u2026", "num_citations": "6\n", "authors": ["429"]}
{"title": "Automatic invariant selection for online anomaly detection\n", "abstract": " Invariants are stable relationships among system metrics expected to hold during normal operating conditions. The violation of such relationships can be used to detect anomalies at runtime. However, this approach does not scale to large systems, as the number of invariants quickly grows with the number of considered metrics. The resulting \u201cbackground noise\u201d for the invariant-based detection system hinders its effectiveness. In this paper we propose a general and automatic approach for identifying a subset of mined invariants that properly model system runtime behavior with a reduced amount of background noise. This translates into better overall performance (i.e., less false positives).", "num_citations": "6\n", "authors": ["429"]}
{"title": "Big data in critical infrastructures security monitoring: Challenges and opportunities\n", "abstract": " Critical Infrastructures (CIs), such as smart power grids, transport systems, and financial infrastructures, are more and more vulnerable to cyber threats, due to the adoption of commodity computing facilities. Despite the use of several monitoring tools, recent attacks have proven that current defensive mechanisms for CIs are not effective enough against most advanced threats. In this paper we explore the idea of a framework leveraging multiple data sources to improve protection capabilities of CIs. Challenges and opportunities are discussed along three main research directions: i) use of distinct and heterogeneous data sources, ii) monitoring with adaptive granularity, and iii) attack modeling and runtime combination of multiple data analysis techniques.", "num_citations": "6\n", "authors": ["429"]}
{"title": "An investigation on flexible communications in publish/subscribe services\n", "abstract": " Novel embedded and ubiquitous infrastructures are being realized as collaborative federations of heterogeneous systems over wide-area networks by means of publish/subscribe services. Current publish/subscribe middleware do not jointly support two key requirements of these infrastructures: timeliness, i.e., delivering data to the right destination at the right time, and flexibility, i.e., enabling heterogeneous interacting applications to properly retrieve and comprehend exchanged data. In fact, some middleware solutions pay more attention to timeliness by using serialization formats that minimize delivery time, but also reduce flexibility by constraining applications to adhere to predefined data structures. Other solutions adopt XML to improve flexibility, whose redundant syntax strongly affects the delivery latency.               We have investigated the consequences of the adoption of several light-weight formats\u00a0\u2026", "num_citations": "6\n", "authors": ["429"]}
{"title": "An architecture for providing Java applications with indoor and outdoor hybrid location sensing\n", "abstract": " This paper presents a software architecture that enables either the combined and separate use of indoor and outdoor location-sensing technologies. The architecture has been implemented in compliance with the specifications of the location API for Java. It is explicitly designed to provide applications with a hybrid location information, i.e., it allows to identify the terminal position among a known set of indoor or outdoor zones (e.g., building rooms, or predefined outdoor areas). The architecture relies on a low-cost, easily deployable and tunable indoor positioning infrastructure, and on existing outdoor location sensing infrastructures as well. In this paper, we specifically describe the design and the implementation of a prototype based on Bluetooth and GPS technologies", "num_citations": "6\n", "authors": ["429"]}
{"title": "Indoor positioning for location-aware applications on Java-based mobile devices\n", "abstract": " The Java Community Process (JCP) has recently finalized a Java Specification Request (JSR) to cope with location-awareness (JSR-179) in Connected Limited Device Configuration (CLDC). Implementations of this specification may rely on several location methods, including satellite based methods like GPS, as well as short-range positioning methods based on Received Signal Strength (RSS). Though RSS is a good location fingerprint for indoor positioning, no standard technique to tailor RSS-based approaches to the JSR-179 API has been proposed yet. In this paper we propose such a technique, and we evaluate its effectiveness through a Bluetooth-based prototype. Specifically, we show how to extend the Java APIs for Bluetooth (JSR-82) in order to provide the Location API with RSS-based position-information. Moreover, we show how to adapt RSS-based approaches to Location-API\u2019s semantics\u00a0\u2026", "num_citations": "6\n", "authors": ["429"]}
{"title": "Metadata models for QoS-aware information management systems\n", "abstract": " The provisioning of multimedia services with guaranteed Quality-of-Service (QoS) is currently an important research issue in computer engineering, especially in the networking and information management areas. In this paper, we concentrate on the QoS-based provisioning of discovery and delivery services of multimedia resources in the educational application domain. We present a generic model for QoS-aware information management systems, able to support guarantee of the QoS in search and delivery of information objects over a network infrastructure (such as the Internet or an inter-organizations network). The model identifies actors and components involved, and their role. The metadata models we analyse are specialized for the education domain. For this application domain, we also propose QoS extensions to standard metadata models for profiling users, information services and resources, capable of\u00a0\u2026", "num_citations": "6\n", "authors": ["429"]}
{"title": "Finding a way in the model driven jungle: Invited keynote talk\n", "abstract": " Model-driven concepts have been introduced in software engineering methodologies since many years. They were not really new, as engineers have always been using models, but they have been tailored to engineering software. Research in the area has progressed in many directions: languages, processes, standards, technologies, tools. While they have proved to be effective in some application sectors, such as for embedded systems, it is hard to find documented success stories for real-world systems in many other fields. Indeed, there is some skepticism on their applicability for large-scale and for critical industrial systems, which have high complexity and/or high costs of verification and validation: many companies still consider them risky. Full comprehension of risks, costs and benefits is not easy to achieve. A crucial factor is that their adoption requires changes in consolidated processes, and advanced\u00a0\u2026", "num_citations": "5\n", "authors": ["429"]}
{"title": "Towards secure monitoring and control systems: Diversify!\n", "abstract": " Cyber attacks have become surprisingly sophisticated over the past fifteen years. While early infections mostly targeted individual machines, recent threats leverage the widespread network connectivity to develop complex and highly coordinated attacks involving several distributed nodes [1]. Attackers are currently targeting very diverse domains, e.g., e-commerce systems, corporate networks, datacenter facilities and industrial systems, to achieve a variety of objectives, which range from credentials compromise to sabotage of physical devices, by means of smarter and smarter worms and rootkits. Stuxnet is a recent worm that well emphasizes the strong technical advances achieved by the attackers' community. It was discovered in July 2010 and firstly affected Iranian nuclear plants [2]. Stuxnet compromises the regular behavior of the supervisory control and data acquisition (SCADA) system by reprogramming the\u00a0\u2026", "num_citations": "5\n", "authors": ["429"]}
{"title": "ROCRSSI++: An efficient localization algorithm for wireless sensor networks\n", "abstract": " Localization within a Wireless Sensor Network consists of defining the position of a given set of sensors by satisfying some non-functional requirements such as (1) efficient energy consumption,(2) low communication or computation overhead,(3) no, or limited, use of particular hardware components,(4) fast localization,(5) robustness, and (6) low localization error. Although there are several algorithms and techniques available in literature, localization is viewed as an open issue because none of the current solutions are able to jointly satisfy all the previous requirements. An algorithm called ROCRSSI appears to be a suitable solution; however, it is affected by several inefficiencies that limit its effectiveness in real case scenarios. This paper proposes a refined version of this algorithm, called ROCRSSI++, which resolves such inefficiencies using and storing information gathered by the sensors in a more efficient\u00a0\u2026", "num_citations": "5\n", "authors": ["429"]}
{"title": "On the benefit of network coding for timely and reliable event dissemination in WAN\n", "abstract": " Many interoperable software systems atop of large-scale critical infrastructures are based on the publish/subscribe paradigm. They are developed using data dissemination middleware services, which are required to provide reliability and timeliness in multicast communications. The literature of event dissemination and the market of publish/subscribe middleware technologies are rich of solutions, however, they hardly achieve the goal of providing fault-tolerance without violating the timeliness requirements. In this paper we present an analysis of the related work on this topic and propose an approach for combining two different approaches, namely coding and gossiping, able to satisfy timeliness and reliability requirements, respectively. We evaluate the potential benefit of coding on the information delivery performance, even when the sender introduces a redundancy to improve reliability.", "num_citations": "5\n", "authors": ["429"]}
{"title": "An approach for assessing logs by software fault injection\n", "abstract": " Nowadays, an increasing number of systems needs to be kept running for long periods without showing failures, but several factors compromise their correct behavior during the operational phase. Logs play a key role to address dependability issues of current systems and to enable proactive actions against failures (eg, proactive maintenance, failure prediction). Nevertheless, they may lack any information in case of software faults, which escape the testing phase and are activated on the field by complex environmental conditions. In this paper, we evaluate built-in logging capabilities of a software system, namely the Apache Web Server, by means of an extensive software fault injection campaign. We experience that, in most of cases, software faults lead to failures without leaving any information in Apache logs. For this reason, we provide a few guidelines for developers that can be used during the development cycle, in order to improve the effectiveness of logs during the operational phase.", "num_citations": "5\n", "authors": ["429"]}
{"title": "Modeling and detecting failures in next-generation distributed multimedia applications\n", "abstract": " In this paper we investigate dependability issues of next-generation distributed multimedia applications. Examples of such applications are autonomous vehicle control, tele-medicine, and audio/video control. For these applications the quality of the delivered multimedia data is a critical factor. According to the ITU-T (working group SG 12), the quality of a multimedia service as perceived by end-users is defined by three parameters: delay, delay variation, and information loss. It is paramount to formalize the concept of a failure from the user's perspective. This paper defines the correctness of a multimedia service as a function of temporal distributions of the user-related parameters. It proposes a strategy for modeling and detecting failures of the considered applications. In particular, the detection process is based on error filtering functions. We show that the combination of threshold-based mechanisms is suitable for\u00a0\u2026", "num_citations": "5\n", "authors": ["429"]}
{"title": "Providing digital time stamping services to mobile devices\n", "abstract": " Technology evolution in wireless communication is enabling pervasive connectivity to Internet scale systems. In this scenario, security critical applications are being deployed over platforms which include mobile devices. It is thus key that security services be provided to mobile devices as well. Since security functions are typically based on computationally intensive cryptographic algorithms, achieving this goal is none of a simple task, for the following characteristics of mobile devices: 1) limited computing power, and 2) constraints imposed by peculiarities of the software platforms. This work presents an architecture which allows the provision of digital Time-Stamping services to mobile devices with limited resources. The architecture is described with respect to a case study system.", "num_citations": "5\n", "authors": ["429"]}
{"title": "Building a dependable system from a legacy application with CORBA\n", "abstract": " This paper presents a dependability oriented, fault tolerance based system design, development, and deployment approach. The approach relies on an architectural framework, which allows legacy software modules to be reused as the basic building blocks of a distributed dependable application. Different levels of replication and alternative adjudication strategies are implemented behind a unified interface. These can be configured for achieving the optimal compromise between dependability and performance, according to application, deployment environment, and fault characteristics. The suggested solution can be implemented on top of any CORBA infrastructure. The architecture has been developed and tested. Experimental results are presented and discussed.", "num_citations": "5\n", "authors": ["429"]}
{"title": "A JINI framework for distributed service flexibility\n", "abstract": " Existing distributed middleware technologies and Enterprise Application frameworks lack in support to service flexibility from both the developer's and user's point of view. In this paper we propose a JINI-based framework, namely PRINCEPS (Pluggable Reliable Infrastructure for Network Computing and Enhanced Properties of Service), which provides a distributed and dynamic environment for flexible service provision. We claim that the adoption of JINI makes it possible to dramatically improve service flexibility by federating services in a dynamic and self-healing networked community. The framework provides the clients with a (web-based) mechanism for selecting services according to functional requirements (i.e., the service interface) and non-functional requirements (the quality of service, i.e., reliability, performance). More implementations of the same service can coexist in the framework, each of one satisfying\u00a0\u2026", "num_citations": "5\n", "authors": ["429"]}
{"title": "Experience with the GESTALT on-line learning support system\n", "abstract": " With the spread of the Internet and the Web, higher education institutions are becoming increasingly interested in exploiting modern standard information and communication technologies to provide learners and trainees with advanced services for tele-education. Within the European Union 4th Framework Programme, the GESTALT project has defined and implemented a flexible, component-based architecture aimed at supporting on-line discovery and delivery of multimedia educational resources on the Web. In this paper, we describe the on-going experience with the GESTALT system at University of Naples, and report first results of on-field trials during the first academic semester.", "num_citations": "5\n", "authors": ["429"]}
{"title": "Formal methods integration for the specification of dependable distributed systems\n", "abstract": " This paper describes a real-world case study in the specification and analysis of dependable distributed systems. The case study is an automated transport system with safety requirements. In order to manage the complexity of the problem of specifying the dynamic behavior of the whole system, a compositional approach is used, based on the integration of the trace logic of the Communicating Sequential Processes (CSP) theory, and stochastic Petri nets (SPNs). It is argued that the integration of different formal methods is a useful approach in the definition of practical engineering methodologies for the specification, design and analysis of complex dependable distributed systems.", "num_citations": "5\n", "authors": ["429"]}
{"title": "In production performance testing of sdn control plane for telecom operators\n", "abstract": " One of the biggest emerging challenges for telco operators is to dynamically create new services while maintaining the network at its optimal performance/revenue break point. To this end, operators are moving to a much leaner cloud-based Software Defined Network (SDN) infrastructure to achieve a truly programmable network fabric. While cloud services can be provisioned in seconds and tested in-production, service provisioning in SDNs still lasts many weeks and requires substantial manual effort. A large part of this service creation time can be attributed to testing and tuning the control plane. In this paper we present SCP-CLUB (SDN Control Plane CLoUd-based Benchmarking), a platform for in-production performance testing of telco operator SDNs, offering a level of automation as available in deploying cloud services. Telco cloud SDN performance testing with SCP-CLUB focuses on the analysis of how\u00a0\u2026", "num_citations": "4\n", "authors": ["429"]}
{"title": "The Dual Nature of Software Aging: Twenty Years of Software Aging Research\n", "abstract": " Twenty years have passed since the expression software aging was coined. Research in this area has progressed in two almost autonomous directions. A software engineering perspective, concerned with the aging of software products over their lifetime, and a software dependability perspective, concerned with run time aging of (long) running applications. I argue these two visions should be reconciled, in the hope to open new research areas able to provide a wider and deeper understanding of the very nature of software aging phenomena.", "num_citations": "4\n", "authors": ["429"]}
{"title": "CSAR-2: A case study of parallel file system dependability analysis\n", "abstract": " Modern cluster file systems such as PVFS that stripe files across multiple nodes have shown to provide high aggregate I/O bandwidth but are prone to data loss since the failure of a single disk or server affects the whole file system. To address this problem a number of distributed data redundancy schemes have been proposed that represent different trade-offs between performance, storage efficiency and level of fault tolerance. However the actual level of dependability of an enhanced striped file system is determined by more than just the redundancy scheme adopted, depending in general on other factors such as the type of fault detection mechanism, the nature and the speed of the recovery. In this paper we address the question of how to assess the dependability of CSAR, a version of PVFS augmented with a RAID5 distributed redundancy scheme we described in a previous work.", "num_citations": "4\n", "authors": ["429"]}
{"title": "ESPERANTO: a middleware platform to achieve interoperability in nomadic computing domains\n", "abstract": " Summary form only given. The most challenging issues in nomadic computing environments arise from the combination of heterogeneity, dynamism, context-awareness, and mobility. Driven by these issues, this paper presents a new middleware infrastructure, named ESPERANTO, to support the integration of diverse nomadic computing domains. This middleware aims to glue the emerging heterogeneous nomadic computing technologies and service oriented architectures.", "num_citations": "4\n", "authors": ["429"]}
{"title": "An architecture for security-oriented perfective maintenance of legacy software\n", "abstract": " This work presents an implementation strategy which exploits the separation of concerns and reuse in a multi-tier architecture to improve the security (availability, integrity, and confidentiality) level of an existing application. Functional properties are guaranteed via wrapping of the existing software modules. Security mechanisms are handled by the business logic of the middle-tier: availability and integrity are achieved via replication of the functional modules and the confidentiality is obtained via cryptography. The technique is presented with regard to a case study application. We believe that our experience can be used as a guideline for software practitioners to solve similar problems. We thus describe the conceptual model behind the architecture, discuss implementation issues, and present technical solutions.", "num_citations": "4\n", "authors": ["429"]}
{"title": "A method for predictive performance of distributed programs\n", "abstract": " We present a method for performance evaluation and prediction of programs running on a heterogeneous distributed system. The method is hybrid, in that it is based on the construction of a formal Petri net model of the program, supplemented with quantitative information obtained with program monitoring and architecture benchmarking techniques. The desired performance indices are computed via simulation, through net execution. The proposed method can be automated to a large extent. We show the application of the method to the evaluation of tasks or data allocation strategies on a network of workstations. The results of the experiments with two case studies are discussed.", "num_citations": "4\n", "authors": ["429"]}
{"title": "Petri net modelling of PARSE designs\n", "abstract": " PARSE is a staged object-based design methodology for parallel and distributed software systems. In the highest stage, a graphical notation is used to describe the system components (objects) and their interconnections. In the subsequent stage, the designer introduces the behaviour of the objects, by means of a textual notation. This paper shows a mechanical transformation of the textual representation of a PARSE design into a complete Petri net model. This supports the integration of formal analysis techniques into the early stage of the software development process, and provides a formal semantics for the design notation.", "num_citations": "4\n", "authors": ["429"]}
{"title": "Using CSP languages to program parallel workstation systems\n", "abstract": " During the last decade one of the most relevant events in the computer market has been the large diffusion of workstations. In both industrial and research environments a huge amount of computing is done on personal workstations. Despite the rapid growth in networking technologies, however, a network of workstations cannot be easily seen as a global computational resource, although it represents a large amount of computing power. Moreover, its inherent parallelism is not accessible without a heavy effort to modify existing software and/or to develop new code. It is our belief that the CSP model is suitable to develop distributed applications for a particular class of such systems that can be defined Parallel Workstation Systems. This thesis has been tested in the course of the DISC project. In DISC, the language implementation of the CSP model tries to minimize the programming effort toward the development of\u00a0\u2026", "num_citations": "4\n", "authors": ["429"]}
{"title": "Model-based software engineering and certification: Some open issues\n", "abstract": " Model-based software engineering methodologies, languages, standards, technologies, and tools are in place since many years. While they proved to be effective in several application sectors, e.g. for embedded systems, empirical studies show that their use in industries pursues a variety of goals and that often they are only partially applied, so it is still not clear to what extent they are actually adopted in the engineering practice and whether they achieve the claimed advantages. Notwithstanding this, model-based techniques are being increasingly advocated for use in critical systems engineering. As critical systems have to undergo certification, the question raised to what extent model-based engineering supports certification. While this is not a new issue, the literature is still at the beginning. We examine key aspects in this respect, and identify some open issues.", "num_citations": "3\n", "authors": ["429"]}
{"title": "Improving FFDA of Web Servers through a Rule-Based Logging Approach\n", "abstract": " Log production is known to be a developerdependent, error-prone process. This results in heterogeneous and inaccurate logs, which can mislead Field Failure Data Analysis (FFDA). Research papers face logs issues by proposing manipulation techniques to be applied to the field data source as it is. This source can however miss important log entries, decreasing the level of trust on FFDA results. This paper describes how to improve the field data production by means of a rule-based logging approach preventing inaccurate logs. It also presents an experimental evaluation with reference to the widely used Apache Web Server. Results show that the rule-based approach significantly improves exiting Web Server logs through a better coverage of timing failures.", "num_citations": "3\n", "authors": ["429"]}
{"title": "The Esperanto Broker: a communication platform for nomadic computing systems\n", "abstract": " There is an increasing demand for middleware for nomadic computing applications. Owing to the inherent characteristics of such environments, these platforms have to address two fundamental issues: (i) device disconnections and the limitations of wireless networks may force users to experience short periods of service unavailability; and (ii) the complexity to design and develop next\u2010generation mobile computing applications. This paper proposes the Esperanto Broker (EB), a communication platform that addresses mobility issues via an integrated approach, i.e. at data\u2010link, network, and middleware levels. Decoupling interactions are achieved via a tuple\u2010space underlying infrastructure. To support developers with advanced services, the EB enhances the distributed objects computing model providing the abstraction for the communication paradigms standardized by the W3C. Esperanto applications can be\u00a0\u2026", "num_citations": "3\n", "authors": ["429"]}
{"title": "Design and implementation of a high performance architecture for providing digital time stamping services to mobile devices\n", "abstract": " Technology evolution in wireless communication is enabling pervasive connectivity and ubiquitous access to the Internet. In this scenario, more and more security critical applications are being deployed over platforms which include mobile devices. It is thus crucial that security services be provided to mobile devices as well. Since security functions are typically based on computationally intensive cryptographic algorithms, achieving this goal turns out to be a hard task due to 1) limited computing power, and 2) constraints imposed by peculiarities of the software platforms. This work presents an architecture which allows the provision of digital Time-Stamping services to mobile devices with limited resources. The architecture is described with respect to a case study system, and experimental results are also discussed.", "num_citations": "3\n", "authors": ["429"]}
{"title": "The time of flight system and trigger electronics for the PAMELA experiment in space\n", "abstract": " The PAMELA experiment is a space-borne apparatus devoted to the study of the antiparticle component of cosmic rays. In addition The time-of-flight (ToF) scintillator system must provide the fast trigger to the experiment, the rejection of albedo particles, the possibility to distinguish electrons from antiprotons up to about 2 GeV and the measurement of the absolute charge of the particle. A readout electronics with wide dynamic range and a time resolution better than 100 ps is requested. The developed readout electronics for the PAMELA ToF system is capable of time resolution better than 50 ps with very low power consumption and has a dynamic range of about 12 bit. The developed board implements different trigger modes coming from the various subdetectors. The rate-meters of the ToF system and the logic to evaluate the live and dead time are implemented on this board, which also handles the busy signals\u00a0\u2026", "num_citations": "3\n", "authors": ["429"]}
{"title": "Integration of legacy client-server applications in a secure multi-tier architecture\n", "abstract": " Presents a CORBA-based multi-tier architecture which is capable of adding security to an existing service. We assume the legacy application is available as a compiled program consisting of a client and a server module. Under these assumptions, we show how to build a new system which re-integrates the original service and secures it. The architecture we propose is quite flexible and represents a framework which can be adopted - with minor changes - for improving the security level of a wide class of legacy systems. A system prototype has been developed and its performance evaluated. The prototype uses digital certificates which can be provided by virtually any certification authority. A fundamental advantage of the proposed approach is that the legacy server is integrated in the secure system with no changes being made to it. This minimizes the development effort, since full reuse of existing software is\u00a0\u2026", "num_citations": "3\n", "authors": ["429"]}
{"title": "Implementing a CORBA-based architecture for leveraging the security level of existing applications\n", "abstract": " This work presents an implementation technique which exploits separation of concerns and reuse in a CORBA-based, multi-tier architecture to improve the security (availability, integrity, and confidentiality) level of an existing application. Functional properties are guaranteed via wrapping of the existing software modules. All security mechanisms are handled by the business logic of the middle-tier. Availability and integrity are achieved via replication of the functional modules. Confidentiality is obtained via cryptography. The technique is presented with regard to a case study application. We describe the conceptual model behind the architecture, discuss implementation issues, and present technical solutions.", "num_citations": "3\n", "authors": ["429"]}
{"title": "Integrating mobile agent infrastructures with CORBA-based distributed multimedia applications\n", "abstract": " The increased computing power and the enhanced connectivity of current open computing systems are encouraging the deployment of new classes of services both centered around dynamically changing user requirements and based on the exploitation of the Internet infrastructure. Distributed Multimedia Applications (DMAs) are a typical class of services with challenging requirements in terms of resource demand, dynamicity and QoS adaptation. The paper claims that distributed objects and mobile agents can complement each other to provide a flexible middleware for DMAs, and describes the case study of MADAMA (Mobile Agent-based Distributed Architecture for Multimedia Applications). MADAMA adopts mobile agents to simplify the distribution of service control and to provide location-aware adaptability. In addition, MADAMA is compliant with CORBA to achieve large accessibility and interoperability.", "num_citations": "3\n", "authors": ["429"]}
{"title": "A CORBA-based architecture for adding dependability to legacy servers\n", "abstract": " This work presents a flexible, CORBA compliant Middle-Tier Server architecture, which is capable of adding dependability (namely, reliability, availability, and performability) to an existing service. The architecture provides a flexible and cost-effective framework for building fault-tolerant applications via straightforward integration of legacy software. In the typical scenario, the service would be originally provided by some legacy server, which is integrated in the new system with no changes being made to it. This has two main advantages. First, the development effort is minimized, since full reuse of existing software is achieved. Second, backward compatibility is preserved, since it is possible to integrate new clients with existing applications and databases, protecting the investment in legacy systems. To the best of our knowledge, the architecture we propose is novel, although it builds upon redundancy techniques\u00a0\u2026", "num_citations": "3\n", "authors": ["429"]}
{"title": "A Case Study in Object-Oriented Modeling and Design of Distributed Multimedia Applications.\n", "abstract": " This paper investigates the use of object-oriented techniques for the specification and design of distributed multimedia applications (DMAs). DMAs are a class of software applications with a range of strong-often conflicting-requirements of dynamicity, interactivity, real-time synchronized processing of several media types, network distribution, high-performance, fault-tolerance, load balancing and security. The development of complex DMAs can benefit from the adoption of object design methods and distributed object implementation technologies. The paper describes the use of two modeling approaches, based on the standard UML modeling language, and on the TRIO formal specification language, respectively. The problem of defining steps to move from the UML or TRIO specification to a CORBA IDL implementation is addressed. An experimental distributed video-on-demand system is used throughout the paper\u00a0\u2026", "num_citations": "3\n", "authors": ["429"]}
{"title": "Client-server programs analysis in the EPOCA environment\n", "abstract": " Client-server processing is a popular paradigm for distributed computing. In the development of client-server programs, the designer has first to ensure that the implementation behaves correctly, in particular that it is deadlock free. Second, he has to guarantee that the program meets predefined performance requirements. This paper addresses the issues in the analysis of client-server programs in EPOCA. EPOCA is a computer-aided software engeneering (CASE) support system that allows the automated construction and analysis of generalized stochastic Petri net (GSPN) models of concurrent applications. The paper describes, on the basis of a realistic case study, how client-server systems are modelled in EPOCA, and the kind of qualitative and quantitative analysis supported by its tools.", "num_citations": "3\n", "authors": ["429"]}
{"title": "Paradigms for the parallelization of Branch&Bound algorithms\n", "abstract": " Branch&Bound (B&B) algorithms represent a typical example of techniques used to solve irregularly structured problems. When porting sequential B&B applications to a network of workstations, a very popular class of MIMD distributed memory machines, several issues have to be coped with, such as sharing a global computation state and balancing workload among processors. The parallel programming paradigm to adopt has to be chosen as a compromise between simplicity and efficiency. In this paper we discuss issues in the parallelization of B&B algorithms according to two paradigms: coordinator/workers and SPMD (Single Program Multiple Data). The implementation according to the message-passing mechanisms provided by the PVM parallel programming environment is presented. The two approaches are compared qualitatively, with respect to the solutions adopted for knowledge sharing\u00a0\u2026", "num_citations": "3\n", "authors": ["429"]}
{"title": "Teaching software architecture in industrial and academic contexts: similarities and differences\n", "abstract": " In this chapter, the authors describe their experiences in designing, developing, and teaching a course on Software Architecture that tested both in an academic context with their graduate Computer Science students and in an advanced context of professional updating and training with scores of system engineers in a number of different companies. The course has been taught in several editions in the last five years. The authors describe its rationale, the way in which they teach it differently in academia and in industry, and how they evaluate the students' learning in the different contexts. Finally, the authors discuss the lessons learnt and describe how this experience is inspiring for the future of this course.", "num_citations": "2\n", "authors": ["429"]}
{"title": "A communication broker for nomadic computing systems\n", "abstract": " This paper presents the Esperanto Broker, a communication platform for nomadic computing applications. By using this broker, developers can model application components as a set of objects that are distributed over wireless devices and interact via remote method invocations. The Esperanto Broker is able to guarantee remote object interactions despite device movements and/or disconnections. We describe the conceptual model behind the architecture, discuss implementation issues, and present preliminary experimental results.", "num_citations": "2\n", "authors": ["429"]}
{"title": "A strategy for application-transparent integration of nomadic computing domains\n", "abstract": " Nomadic computing environments are composed of heterogeneous mobile computing domains. Unfortunately, the service discovery platforms suitable for each domain are scarcely interoperable with each other. This work proposes a novel architecture to mitigate the diversity of service representations, technologies, and interaction models of current service discovery platforms. The ultimate goal is to allow nomadic users to discover services across domain borders. The proposed architecture is composed of discovery agents that connect domains into a single logical domain, and allow services to be imported and exported between heterogeneous domains.", "num_citations": "2\n", "authors": ["429"]}
{"title": "Supporting location-aware distributed applications on mobile devices\n", "abstract": " This work proposes to extend the Java APIs for Bluetooth (JSR82) in order to provide the Location API (JSR179) with a source of indoor-location information. The proposed extension relies on a specific indoor positioning technique to track current location. The adopted technique uses the Received Signal Strength Indicator (RSSI) as a good room-fingerprint. We evaluate the effectiveness of the approach by examining preliminary experimental results obtained from our first system prototype.", "num_citations": "2\n", "authors": ["429"]}
{"title": "CLM and NCSOCKS: a technical report\n", "abstract": " This report provides the technical details of the CLM (Connection and Location Management) components and NCSOCKS (Nomadic Computing Sockets) API developed by the Mobilab Group. The aim of this work is supporting the application developer with a middleware architecture providing an API specifically suited for Nomadic Computing environments. Nomadic Computing (NC) is referred in literature as a distributed computing model in which the communication takes place over strongly heterogeneous network infrastructures. Such infrastructures are composed of one or more wireless domains, glued together by a fixed infrastructure (the core network), and provide anytime, anywhere access to mobile devices [1]. In this kind of infrastructure, the mobile terminals communicate each other through the core network which is accessed by means of Access Points (APs). Each AP, with its covering zone, defines a cell in which a mobile device can communicate with the fixed infrastructure.", "num_citations": "2\n", "authors": ["429"]}
{"title": "A real time-based architecture for qos multimedia provisioning\n", "abstract": " According to the ITU-T, the quality of a multimedia service is defined by a set of user-related parameters: delay, delay variation, and information loss. To provide multimedia applications with end-to-end QoS guarantees, an efficient resource reservation and management strategy has to be adopted. This paper presents a schema for satisfying multimedia QoS parameters over a real-time operating system, which adopts the rate monotonic as a scheduling algorithm. Such a schema is implemented in a real-time based architecture for QoS multimedia provisioning. This architecture allows to define classes of services with different quality attributes concerning the multimedia data delivery.", "num_citations": "2\n", "authors": ["429"]}
{"title": "A fault tolerant access to legacy database systems using CORBA technology\n", "abstract": " This work presents a software-implemented fault tolerance approach for building a reliable database application in a CORBA environment. Database applications have functional requirements and non-functional requirements, such as dependability and performance. We provide an architectural framework that makes it possible to separately address these issues. More precisely, it is possible to: i) guarantee functional properties by incorporating existing software modules, and ii) add dependability to the resulting system via proper programming of the business logic of the Middle Tier. The legacy software is integrated in the new system with no changes. This strategy can effectively reduce the development effort for building a reliable system, while protecting the investment in legacy appli-* Contact author\u2019s contact info: Dipartimento di Informatica e Sistemistica, Via Claudio 21\u201380125 Napoli, Italy; tel:+ 39-0817683824; fax:+ 39-0817683816", "num_citations": "2\n", "authors": ["429"]}
{"title": "Service Differentiation of Communication-bound Processes in a real-time Operating System\n", "abstract": " The majority of today's Internet-based services are generally not concerned about the level of quality of service (QoS) presented to their users. For many such services, however, the QoS perceived by users is becoming a critical success factor. The main QoS attributes include those related to the service availability and timeliness. Ensuring them is essential to many services. In our opinion, this has to be achieved not only by providing services with appropriate access bandwidth, or through QoS awareness of the network communication protocols used, but also by means of a differentiation of the usage of system resources by server processes. We focus on Internet-based multimedia data delivery services (e.g., services provided by Web, FTP and video-on-demand servers). These services are run by processes whose activity is typically dominated by network communication; we call them communication-bound\u00a0\u2026", "num_citations": "2\n", "authors": ["429"]}
{"title": "An Architecture for Streaming Control in Distributed Multimedia Systems\n", "abstract": " The development of distributed multimedia systems can benefit from the availability of a flexible infrastructure able to support the interoperation between components, and capable of dynamically adapt itself to the system configuration. CORBA-compliant distributed multimedia applications permit a high level of accessibility, decentralization and interoperability with other components. However, a large number of non-CORBA-compliant multimedia client applications are already available and commercialized. These applications have been designed according to a protocol-centric interoperation scheme. In this paper we present an innovative architecture for streaming control which allows client applications implementing the standard RTSP multimedia streaming protocol access a Multimedia Storage Server which provides a set of services through a CORBA interface. Our proposed scheme is particularly suitable in the case of proxybased scenarios, where clients do not directly interact with the storage server, but receive streams from an intermediate caching element.", "num_citations": "2\n", "authors": ["429"]}
{"title": "Object-oriented Design of an Intelligent Building Management System\n", "abstract": " The use of object technology is proliferating in the development of software, and in order to build robust and maintainable complex systems, mastering object-oriented (OO) analysis and design is essential. Although the object-orientation area is converging towards standard modeling notations, namely UML, and standard middleware platforms, such as OMG\u2019s CORBA, a large variety of OO development methods are available for software engineers to design complex systems. The main goal of this paper is to report on the experience of applying a patternbased, object-oriented analysis and design methodology to a real-world complex system represented by an intelligent building. Specifically, the OO GRASP approach has been used to design the software infrastructure, which handles the interactions among processing elements in a modern building. Benefits of the adoption of this OO process, and issues and problems encountered, are discussed. We believe that this process communicate very fundamental principles of responsibility assignment in object-oriented design.", "num_citations": "2\n", "authors": ["429"]}
{"title": "Are We Ready to Scale up Information Technology?\n", "abstract": " November 1997 53 even modern countries, computer use in the elementary and high schools is far from common practice? Mastering basic information technology will be the key to equal opportunities in this society. Those without the basics are likely to find it harder and harder to get well-paying jobs. It is true that for most people, information technology will remain simply a tool that supports business or leisure activities. However, the use of this tool involves myriad social and technical issues. We should begin dealing with these in the elementary schools, laying the foundation for more complex topics in much the same way we educate in other curricula. Our goals should be to provide everyone with basic concepts and skills on the use of information technology and to keep pace with the rapid developments in this field. Second, how do we teach responsibility in the use of information technology when we pay little\u00a0\u2026", "num_citations": "2\n", "authors": ["429"]}
{"title": "Un algoritmo Branch-and-Bound parallelo per Sistemi Multicomputer\n", "abstract": " Un algoritmo Branch-and-Bound parallelo per Sistemi Multicomputer\" Home Page Chi siamo Collane E-book Percorsi di lettura Come acquistare Book orders Come Contattarci Help Login Password? Edizioni Franco Angeli. La passione per le conoscenze Elenco alfabetico delle riviste Riviste (in corso) per disciplina Come effettuare una ricerca Servizi per gli Autori Servizi per biblioteche ed enti Come abbonarsi alla versione cartacea Come abbonarsi alla versione online Servizi online per atenei Servizi per utenti privati Abbonarsi ad una versione cartacea o online Scaricare un articolo online Il costo di un download credit Acquistare un download credit Acquistare un singolo fascicolo come e-book Foreign orders Come acquistare arretrati Canoni abbonamenti Fotocopie e diritto d'autore: domande e risposte Centro licenze e autorizzazioni riproduzioni editoriali Fare copie \"in regola\" \u00e8 pi\u00f9 semplice di quanto si ... Un /\u2026", "num_citations": "2\n", "authors": ["429"]}
{"title": "Parallel Simulation of a Neural Error-Correcting Decoder\n", "abstract": " We show a simulation of a neural network model devoted to decode codewords belonging to a binary linear code and to correct noisy patterns which are received from a transmission channel. Simulation is done in DISC, a general purpose parallel programming environment based on the CSP model.", "num_citations": "2\n", "authors": ["429"]}
{"title": "Universita degli Studi di Napoli\u201d Federico II\u201d\n", "abstract": " Il presente lavoro di tesi si inquadra nell\u2019ambito dell\u2019esperimento NEMO (NEutrino Mediterranean Observatory) finanziato dall\u2019INFN (Istituto Nazionale di Fisica Nucleare) e volto all\u2019osservazione dei neutrini provenienti da sorgenti astrofisiche. Lo studio di tale particelle risulta molto importante per la comprensione dei meccanismi di formazione e di evoluzione stellare e permette di ampliare le conoscenze attuali in merito alle formazione e all\u2019evoluzione dell\u2019universo. Le sonde astrofisiche normalmente utilizzate sono fotoni e raggi cosmici. I fotoni rappresentano la sonda piu antica mai utilizzata. Di essa ci sie serviti fin dall\u2019antichita quando si osservava il cosmo mediante strumenti ottici. Tale impiego tuttavia comporta una serie di limiti poich\u00e9 con i fotonie possibile osservare solo sorgenti luminose che si trovano a breve distanza dalla Terra. Queste particelle, infatti, vengono facilmente assorbite dalle polveri interstellari e quindi non percorrono distanze superiori alle frazioni di Megaparsec. Anche le particelle piu energetiche, come i raggi gamma di alta energia, soffrono di problemi simili e quindi la loro propagazione non supera i Megaparsec. L\u2019evoluzione scientifica e tecnologica ha portato ad utilizzare come sonde astrofisiche anche i raggi cosmici ossia quelle particelle cariche che vengono emesse dai corpi celesti durante la loro evoluzione. Con tali particellee possibile spingere l\u2019osservazione a distanze piu elevate (dell\u2019ordine della decina di Mpc). Tuttavia esse, durante la propagazione verso la Terra, subiscono una serie di deflessioni dovute all\u2019interazione con i campi magnetici intergalattici perdendo ogni informazione riguardo la\u00a0\u2026", "num_citations": "2\n", "authors": ["429"]}
{"title": "Error monitoring for legacy mission-critical systems\n", "abstract": " Error data collected at runtime play a key role for dependability analysis and improvement of software systems. The use of monitoring frameworks for legacy mission-critical systems is hindered by limited intervention degree and low intrusiveness requirements. We present the design and experimentation of an error monitoring service for a legacy large-scale critical system in the Air Traffic Control (ATC) domain. We describe the details of the API realized to collect both direct data (event logs, execution traces) and indirect data (system resources' utilization). We present experiments with the ATC industrial case study, showing the efficacy of combining different data sources for error detection and propagation analysis, with an acceptable overhead at high monitoring rates for such a class of systems.", "num_citations": "1\n", "authors": ["429"]}
{"title": "A Course on Software Architecture for Defense Applications\n", "abstract": " What is the role of a software architecture when building a large software system, for instance a command and control system for defense purposes? How it is created? How it is managed? In which way can we form software architects for this kind of systems? We describe an experience of designing and teaching several editions of a course on software architecture in the context of a large system integrator of defense mission-critical systems\u2014ranging from air traffic control to vessel traffic control systems\u2014namely SELEX Sistemi Integrati, a company of the Finmeccanica group. In the last few years, the company has been engaged in a comprehensive restructuring initiative for valorizing existing software assets and products and enhancing their productivity for software development. The course was intended as a baseline introduction to a School of Complex Software Systems for the many software engineers\u00a0\u2026", "num_citations": "1\n", "authors": ["429"]}
{"title": "Reliable monitoring of network-related performance parameters in wireless environments\n", "abstract": " End-to-end delay estimation is a crucial issue in the design of network monitoring systems for wireless best-effort infrastructures. This work demonstrates that estimations based on one-way delay are the most suitable for evaluating the delay on wireless networks such as Wi-Fi LANs and Bluetooth piconets. To prevent delay measurement from being affected by clock synchronization issues, raw measures need to be corrected by estimating clock synchronism attributes such as clock skew and offset. However, due to network noise and clock adjustments, this estimation process may affect the reliability of network monitoring systems. In this paper, we propose a trustworthy network performance monitor designed to support adaptive and/or soft real-time applications in wireless environments. The monitor corrects one-way delay measurements through an on-line algorithm for evaluating clock synchronism attributes\u00a0\u2026", "num_citations": "1\n", "authors": ["429"]}
{"title": "A Pattern-Oriented Approach to Enhance Context Infrastructures\n", "abstract": " A plethora of context infrastructures have been developed to support the deployment of context-aware systems. Unfortunately, it is not easy to re-use the design principles adopted in a certain context infrastructure in order to leverage some characteristics of another one, as such principles are often hidden into the infrastructure and not independently explicated. The aim of this work is to propose a methodology to develop a pattern language for context-infrastructures and promote the re-usability of proved techniques to support context-awareness. We describe the proposed methodology with respect to a specific requirement, that is to ensure the interoperability among context-sensitive entities. We specifically define a design pattern to reach this goal, namely the Context Matcher pattern, and we show how to apply such pattern to an existing infrastructure in order to leverage its interoperability.", "num_citations": "1\n", "authors": ["429"]}
{"title": "Mobility Management and Communication Support for Nomadic Applications\n", "abstract": " There is an increasing demand for realizing communication services for nomadic environments, capable to provide applications with mobility management facilities and application-aware adaptation support. This paper proposes a novel mobility management and communication architecture specifically suited for nomadic environments, offering communication facilities and adaptation support by means of an API, named NCSOCKS. The driving idea is to provide application and middleware developers of nomadic services with essential mobility-enabled communication support, while hiding network heterogeneity in terms of wireless technology and leveraging the availability level of communication in spite of transient signal degradations. Transient signal degradations, due to device movements and/or shadowing, have the effect of increasing the handoff frequency. The proposed architecture integrates a\u00a0\u2026", "num_citations": "1\n", "authors": ["429"]}
{"title": "A Distributed Object Platform to Achieve Nomadic Interactions\n", "abstract": " Network infrastructures composed of wireless access points (e.g. IEEE 802.11 APs) connected via a LAN have been enabling a form of mobile computing known as Nomadic Computing (NC). In order to manage migrations of a mobile terminal among different wireless networks, such infrastructures are often decomposed in several domains: a domain can be a building floor, a building room, or a certain zone of a campus. Since the traditional middleware are unsuitable for mobile computing\u00a0[1], during the past years a great deal of research has been conducted. Research efforts have been progressed along the following directions: i) providing mechanisms, such as context awareness, reconfiguration, spontaneous discovery; ii) dealing with QoS aspects such as security. While we recognize these studies as fundamental milestones for the pursuit of new middleware for mobile computing, most of them do not\u00a0\u2026", "num_citations": "1\n", "authors": ["429"]}
{"title": "An integrated approach to design complex CORBA systems\n", "abstract": " The paper presents an approach for designing complex distributed systems based on CORBA. The approach stems from the integration of an object oriented (OO) development process, the GRASP patterns, and the environmental object model. GRASP is a structured OO analysis and design method; it is use-cases driven, pattern-based, iterative and incremental, and it provides the software engineer with guidelines for analyzing system requirements and for high-level design of the software infrastructure. The environmental object model is the basis of a component oriented design method specifically defined to address issues of distribution in the design of CORBA systems. Our approach is based on the integration of the environmental model into the GRASP approach. We use the Unified Modeling Language (UML) for system modeling. We define a new UML stereotype, the environmental class, in order to include\u00a0\u2026", "num_citations": "1\n", "authors": ["429"]}
{"title": "Building formal models of concurrent and distributed systems: an experience in applicability with two different Petri nets approaches\n", "abstract": " Building formal models of concurrent and distributed systems: an experience in applicability with two different Petri nets approaches: Systems Analysis Modelling Simulation: Vol 36, No 2 ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Systems Analysis Modelling Simulation Periodical Home Latest Issue Archive Authors Affiliations Award Winners More HomeBrowse by TitlePeriodicalsSystems Analysis Modelling SimulationVol. , No. Building formal models of concurrent and distributed systems: an experience in applicability with two different Petri nets approaches article Building formal models of concurrent and distributed systems: an experience in applicability with two different Petri nets approaches on : \u2026", "num_citations": "1\n", "authors": ["429"]}
{"title": "The modelling process and Petri nets: reasoning on different approaches\n", "abstract": " Well defined procedures for the construction of models are necessary in order to support the real applicability of modelling techniques in the industrial settings where practical engineering means are required to model and evaluate complex systems and productive processes. This paper describes the application of two different approaches to the construction of Petri Nets models and provides some general hints on the modelling process. In particular, starting from a simple working example we suggest that a behavioural approach, modularity in the model construction phases, and integration of different modelling techniques could contribute to improve the efficiency in many fields of research, development and its controlling.", "num_citations": "1\n", "authors": ["429"]}
{"title": "PARSE and DISC integration for parallel software development\n", "abstract": " The production of parallel software requires the use of automated tools to support a range of activities within the development process. This paper describes the translation of systems developed using the PARSE design methodology to DISC program code. The Translation rules are defined to convert the PARSE Behavioural Specification Language features into DISC code constructs. The conversion process is demonstrated in terms of the whole system design within a case study. The translation rules an the first step towards the development of a coherent environment to support the whole parallel software development process. This includes design support automated code generation, verification and performance prediction.", "num_citations": "1\n", "authors": ["429"]}
{"title": "EPOCA: status and prospects\n", "abstract": " In this paper we present a review of the aims, achievements and prospects of the EPOCA project. EPOCA is a Petri net based system for performance evaluation and analysis of concurrent applications. Research issues, current outcomes and future directions of the project are described.", "num_citations": "1\n", "authors": ["429"]}
{"title": "DISC-GreatSPN: an integrated system for distributed software development and validation\n", "abstract": " Il report seguente simula gli indicatori relativi alla produzione scientifica in relazione alle soglie ASN 2018-2020 del proprio SC/SSD. Si ricorda che il superamento dei valori soglia (almeno 2 su 3) \u00e8 requisito necessario ma non sufficiente al conseguimento dell'abilitazione.La simulazione si basa sui dati IRIS e presenta gli indicatori calcolati alla data indicata sul report. Si ricorda che in sede di domanda ASN presso il MIUR gli indicatori saranno invece calcolati a partire dal 1 gennaio rispettivamente del quinto/decimo/quindicesimo anno precedente la scadenza del quadrimestre di presentazione della domanda (art 2 del DM 598/2018).", "num_citations": "1\n", "authors": ["429"]}
{"title": "A parallel architecture for Digital Radiography\n", "abstract": " Off-line reconstruction of digital radiographic images obtained with a double side silicon micostrip detector requires a huge amount of computing resources. We suggest the use of a distributed-memory parallel architecture to increase the speed of a possible \u2018in list\u2019 system for Digital Radiography. We present a mathematical model of the expected performances of a pipeline parallel architecture. Results of experiments made with software synthetized images on a Transputer-based system with up to eight nodes show the effectiveness of our approach.", "num_citations": "1\n", "authors": ["429"]}
{"title": "Sistemi Distribuiti\n", "abstract": " Una transazione \u00e8 un insieme di elaborazioni che-pur eseguite in concorrenza con le elaborazioni di altre transazioni in competizione per l\u2019accesso a risorse condivise, ed in un contesto in cui sono possibili malfunzionamenti-costituiscono un\u2019unit\u00e0 di lavoro indivisibile, che gode di opportune propriet\u00e0 atte a garantirne la correttezza e la persistenza degli effetti. Tali propriet\u00e0 sono in letteratura con l\u2019acronimo ACID", "num_citations": "1\n", "authors": ["429"]}