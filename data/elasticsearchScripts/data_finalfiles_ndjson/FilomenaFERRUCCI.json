{"title": "Exploratory spatio-temporal data mining and visualization\n", "abstract": " Spatio-temporal data sets are often very large and difficult to analyze and display. Since they are fundamental for decision support in many application contexts, recently a lot of interest has arisen toward data-mining techniques to filter out relevant subsets of very large data repositories as well as visualization tools to effectively display the results. In this paper we propose a data-mining system to deal with very large spatio-temporal data sets. Within this system, new techniques have been developed to efficiently support the data-mining process, address the spatial and temporal dimensions of the data set, and visualize and interpret results. In particular, two complementary 3D visualization environments have been implemented. One exploits Google Earth to display the mining outcomes combined with a map and other geographical layers, while the other is a Java3D-based tool for providing advanced interactions\u00a0\u2026", "num_citations": "191\n", "authors": ["1210"]}
{"title": "Class point: an approach for the size estimation of object-oriented systems\n", "abstract": " In this paper, we present an FP-like approach, named class point, which was conceived to estimate the size of object-oriented products. In particular, two measures are proposed, which are theoretically validated showing that they satisfy well-known properties necessary for size measures. An initial, empirical validation is also performed, meant to assess the usefulness and effectiveness of the proposed measures to predict the development effort of object-oriented systems. Moreover, a comparative analysis is carried out, taking into account several other size measures.", "num_citations": "189\n", "authors": ["1210"]}
{"title": "Symbol\u2013relation grammars: a formalism for graphical languages\n", "abstract": " A common approach to the formal description of pictorial and visual languages makes use of formal grammars and rewriting mechanisms. The present paper is concerned with the formalism of Symbol\u2013Relation Grammars (SR grammars, for short). Each sentence in an SR language is composed of a set of symbol occurrences representing visual elementary objects, which are related through a set of binary relational items. The main feature of SR grammars is the uniform way they use context-free productions to rewrite symbol occurrences as well as relation items. The clearness and uniformity of the derivation process for SR grammars allow the extension of well-established techniques of syntactic and semantic analysis to the case of SR grammars. The paper provides an accurate analysis of the derivation mechanism and the expressive power of the SR formalism. This is necessary to fully exploit the capabilities of\u00a0\u2026", "num_citations": "58\n", "authors": ["1210"]}
{"title": "Effort estimation modeling techniques: a case study for web applications\n", "abstract": " A reliable effort estimation is crucial for a successful web application development planning. Several approaches exist to address this issue. Among them, the algorithmic approach is one of the most widely used and investigated methods. It is based on suitable effort prediction models which relate the development effort with project characteristics. The size represents one of the most interesting characteristics of software products and several measures can be defined in order to estimate the size of web systems. Moreover, several techniques have been proposed in the literature to build the effort prediction models. Thus, of special interest should be to establish the most effective size measures to be employed in effort prediction models and the most suitable techniques for the model construction. To this aim some empirical studies have been undertaken so far. Since it is widely recognized that several investigations\u00a0\u2026", "num_citations": "57\n", "authors": ["1210"]}
{"title": "A predictive parser for visual languages specified by relation grammars\n", "abstract": " We define a class of relation grammars that satisfy the context-freeness property, which is an essential condition to solve the membership problem in polynomial time. The context-freeness property is used to design a predictive parsing algorithm for such grammars. The algorithm has a polynomial time behaviour when applied to grammars which generate languages having the additional properties of connections and degree-boundedness. One remarkable result is that a polynomial time complexity is obtained without imposing (total or partial) ordering on the symbols of input sentences.< >", "num_citations": "51\n", "authors": ["1210"]}
{"title": "A case study using web objects and cosmic for effort estimation of web applications\n", "abstract": " Some size measures have been proposed in the literature to be employed in estimating Web application development effort, but to date few empirical studies have been undertaken to validate them and compare their effectiveness. To address this issue we have performed an empirical study by using as size measures COSMIC and Web Objects, with the aim of verifying their effectiveness as indicators of development effort. In particular, we have built two effort estimation models by applying the Ordinary Least-Squares regression and by using a dataset of 15 Web applications developed by an italian software company. The performance of the obtained models have been evaluated by using a dataset of further 4 Web applications developed by the same software company some time after the first 15 Web applications. The results reveal that both Web Objects and COSMIC are good indicators of the development effort.", "num_citations": "46\n", "authors": ["1210"]}
{"title": "Towards a framework for mining and analysing spatio\u2010temporal datasets\n", "abstract": " High\u2010resolution spatio\u2010temporal datasets are being collected every day to record the behaviour of several natural phenomena. However, data\u2010mining techniques are needed to extract relevant patterns from very large repositories and reveal spatial and temporal patterns in the behaviour of these phenomena. To this aim, we propose a system for mining data with spatial and temporal characteristics, and for visualizing and interpreting the results. Within this system, we have developed two complementary 3D visualization environments, one based on Google Earth and one relying on a Java3D graphical user interface. In this paper, we illustrate the main features of the system we have developed, and report on the main results we have obtained by analysing the Hurricane Isabel dataset.", "num_citations": "46\n", "authors": ["1210"]}
{"title": "Web effort estimation: function point analysis vs. COSMIC\n", "abstract": " Context: software development effort estimation is a crucial management task that critically depends on the adopted size measure. Several Functional Size Measurement (FSM) methods have been proposed. COSMIC is considered a 2nd generation FSM method, to differentiate it from Function Point Analysis (FPA) and its variants, considered as 1st generation ones. In the context of Web applications, few investigations have been performed to compare the effectiveness of the two generations. Software companies could benefit from this analysis to evaluate if it is worth to migrate from a 1st generation method to a 2nd one.Objective: the main goal of the paper is to empirically investigate if COSMIC is more effective than FPA for Web effort estimation. Since software companies using FPA cannot build an estimation model based on COSMIC as long as they do not have enough COSMIC data, the second goal of the\u00a0\u2026", "num_citations": "43\n", "authors": ["1210"]}
{"title": "Web engineering: Models and methodologies for the design of hypermedia applications\n", "abstract": " The development of Web applications requires a variety of tasks, some of them involving aesthetic and cognitive aspects. As a consequence, there is a need for appropriate models and methodologies which allow the heterogeneus members of hypermedia projects to effectively communicate and guide them during the development process. In this chapter, we describe some hypermedia models and methodologies proposed for the development of hypermedia applications.", "num_citations": "40\n", "authors": ["1210"]}
{"title": "Efficient parsing of multidimensional structures\n", "abstract": " Visual languages have motivated growing interests in he investigation of grammatical formalisms and parsing algorithms for modelling and recognizing multidimensional structures.\" h effectiveness of visual languages quire that some effons must be sxomplished to otnain efficient parsing techniques. In this paper, a general parsing scheme for Relation Grammars is presented. The class RG/l of gramman is-terized which seems U) be well suited for modelling visual languages of practical use. An efficient O (n log n)@ ne algorithm iS also given.", "num_citations": "40\n", "authors": ["1210"]}
{"title": "A SCORM thin client architecture for e-learning systems based on web services\n", "abstract": " In this paper we propose an architecture of e-learning systems characterized by the use of Web services and a suitable middleware component. These technical infrastructures allow us to extend the system with new services as well as to integrate and reuse heterogeneous software e-learning components. Moreover, they let us better support the \u201canytime and anywhere\u201d learning paradigm. As a matter of fact, the proposal provides an implementation of the run-time environment suggested in the sharable content object reference model (SCORM) to trace learning processes, which is also suitable for mobile learning.", "num_citations": "39\n", "authors": ["1210"]}
{"title": "Speed up genetic algorithms in the cloud using software containers\n", "abstract": " Scalability issues might prevent Genetic Algorithms from being applied to real world problems. Exploiting parallelisation in the cloud might be an affordable approach to getting time efficient solutions that benefit of the appealing features of scalability, resource discovery, reliability, fault-tolerance and cost-effectiveness. Nevertheless, parallel computation is very prone to cause considerable overhead for communication. Also, making Genetic Algorithms distributed in an on-demand fashion is not trivial. Aiming at keeping under control the communication cost and, at the same time, supporting developers in the construction and deployment of parallel Genetic Algorithms, we designed and implemented a novel approach to distribute Genetic Algorithms in the form of a cloud-based application. It is based on the master/slave model, exploiting software containers, their cloud orchestration and message queues. We also\u00a0\u2026", "num_citations": "32\n", "authors": ["1210"]}
{"title": "Integrating google earth within olap tools for multidimensional exploration and analysis of spatial data\n", "abstract": " Spatial OnLine Analytical Processing solutions are a type of Business Information Tool meant to support a Decision Maker in extracting hidden knowledge from data warehouses containing spatial data. To date, very few SOLAP tools are available, each presenting some drawbacks reducing their flexibility. To overcome these limitations, we have developed a web-based SOLAP tool, obtained by suitably integrating into an ad-hoc architecture the Geobrowser Google Earth with a freely available OLAP engine, namely Mondrian. As a consequence, a Decision Maker can perform exploration and analysis of spatial data both through the Geobrowser and a Pivot Table in a seamlessly fashion. In this paper, we illustrate the main features of the system we have developed, together with the underlying architecture, using a simulated case study.", "num_citations": "32\n", "authors": ["1210"]}
{"title": "Scorm run-time environment as a service\n", "abstract": " Standardization efforts in e-learning are aimed at achieving interoperability among Learning Management Systems (LMSs) and Learning Object (LO) authoring tools. Some of the specifications produced have reached quite a good maturity level and have been adopted in software systems. Some others, such as SCORM Run-Time Environment (RTE), have not reached the same success, probably due to their intrinsic difficulty in being understood adequately and implemented properly. The SCORM RTE defines a set of functionalities which allow LOs to be launched in the LMS and to exchange data with it. Its adoption is crucial in the achievement of full interoperability among LMSs and LO authoring tools. In order to boost the adoption of SCORM RTE in LMSs, we propose a Service Oriented Architecture (SOA)-based reference model for offering the SCORM RTE functionalities as a service, external to the LMS. By\u00a0\u2026", "num_citations": "32\n", "authors": ["1210"]}
{"title": "Agile methodologies in education: A review\n", "abstract": " One of the main challenges faced by teachers in education, both at K-12 and academy levels, is related to the need to attract and retain the attention and the commitment by students, and ensure they achieve the required learning outcomes. Thus, new and exciting methodologies were developed to support teachers. Many of them have been inspired by approaches devised for Agile software development. This chapter aims to review the main Agile methodologies that have inspired educational approaches and to provide a description of the features retained in the educational context. Several experiences reported in the literature are also described.", "num_citations": "31\n", "authors": ["1210"]}
{"title": "Visual programming\n", "abstract": " The widely recognized value of icons, diagrams, and other graphical notations in human\u2013computer interaction and human\u2013human (interhuman) communication, and the decreasing cost of hardware technologies and graphics software have caused the development of a novel approach termed visual programming or graphical programming. Visual programming covers a wide variety of activities that make extensive use of icons and diagrams to convey information and to allow for multimodal communication and interaction between humans and computers. Indeed, in spite of the terminology adopted, \u201cvisual programming\u201d does not denote merely the specification of visual programs but rather refers to the ability of using graphics as a communication means in any activity that involves human\u2013computer interaction. Typical activities that benefit from the use of visual languages are generation of graphical user interfaces\u00a0\u2026", "num_citations": "30\n", "authors": ["1210"]}
{"title": "Cosmic functional measurement of mobile applications and code size estimation\n", "abstract": " The paper presents the application of the COSMIC functional size measurement method in mobile environment. In particular, we describe how COSMIC has been applied to Android mobile applications, also through an example of measurement, and the identification of some possible recurrent patterns. Moreover, we report the results of an empirical study carried out to verify the ability of the COSMIC measure to estimate mobile applications code sizes, ie, the amount of needed memory. The results show that in the considered domain it is possible to get early and accurate prediction of the needed memory space in bytes.", "num_citations": "28\n", "authors": ["1210"]}
{"title": "Approximate COSMIC size to early estimate web application development effort\n", "abstract": " The aim of the paper is to investigate to what extend some COSMIC-based approximate countings can be useful for project managers to early estimate effort of Web applications. We considered the number of COSMIC Functional Processes and the Average Functional Process approach proposed by the COSMIC method documentation. We carried out an empirical analysis employing data from 25 Web applications to assess whether the two approximate sizes can be exploited to get accurate effort estimations. We compared the obtained estimations with those achieved with baseline benchmarks and employing the standard COSMIC method. The analysis highlights that the considered approximate countings provide good early estimations, significantly better than those obtained with baseline benchmarks. Moreover, the first counting provides results better than the Average Functional Process approach. The use of\u00a0\u2026", "num_citations": "24\n", "authors": ["1210"]}
{"title": "Constructing meta-CASE workbenches by exploiting visual language generators\n", "abstract": " In this paper, we propose an approach for the construction of meta-CASE workbenches, which suitably integrates the technology of visual language generation systems, UML metamodeling, and interoperability techniques based on the GXL (graph exchange language) format. The proposed system consists of two major components. Environments for single visual languages are generated by using the modeling language environment generator (MEG), which follows a metamodel/grammar-approach. The abstract syntax of a visual language is defined by UML class diagrams, which serve as a base for the grammar specification of the language. The workbench generator (WoG) allows designers to specify the target workbench by means of a process model given in terms of a suitable activity diagram. Starting from the supplied specification WoG generates the customized workbench by integrating the required\u00a0\u2026", "num_citations": "24\n", "authors": ["1210"]}
{"title": "Spatial online analytical processing of geographic data through the Google Earth interface\n", "abstract": " OnLine Analytical Processing (OLAP) tools act as support systems for Decision Makers to discover new knowledge hidden\u00a0within data warehouses. In the spatial domain this capability is crucial. However, notwithstanding the pressing need for Spatial OLAP (SOLAP) tools, only very few are currently available. Such tools present several limitations in terms of their flexibility in the functionality and the analytical properties they provide.\u00a0 To overcome these limitations, we have developed a web-based SOLAP tool, which relies on the integration of a standard Geobrowser (Google Earth) with a freely available OLAP engine, namely Mondrian. Our system allows a Decision Maker to perform exploration and analysis of spatial data both through the Geobrowser and a Pivot Table in a seamlessly fashion. In this paper, we illustrate the main features of the system we have developed, together with the underlying\u00a0\u2026", "num_citations": "23\n", "authors": ["1210"]}
{"title": "Cloud forensic readiness: Foundations\n", "abstract": " The advances of the ICT industry in recent years has led to huge popularity of Cloud Computing Services. Due to the fact that the Cloud is distributed and hosts numerous users, its use to commit crimes becomes a critical issue. Proactive cloud forensics becomes a matter of urgency: its capability to collect critical data before crimes happen, thus saving time and energy for the investigations is its primary objective. In this paper, we discuss the basis of Cloud Forensic Readiness, because we believe that such a system is of huge necessity. We begin by carefully defining Digital Forensic Readiness in the Cloud Computing context. We propose a reference architecture for a Cloud Forensic Readiness System (CFRS) together with its features, components, and challenges.", "num_citations": "22\n", "authors": ["1210"]}
{"title": "Estimating web application development effort using web-cobra and COSMIC: an empirical study\n", "abstract": " Even if the adaptation of the COBRA method to the web has many appealing characteristics, its effectiveness in predicting Web application development effort has been previously assessed only in one empirical study, using the Web Objects measure. The study provided positive results,but it is widely recognized that several empirical investigations should be performed to validate/confirm the usefulness of effort estimation approaches. Moreover, the use of other size measures in combination with Web-COBRA has not yet been investigated in the literature. These two aspects encouraged us to further analyze the effectiveness of Web-COBRA. In particular, we used a dataset of 15 Web applications, whose functional size was measured using COSMIC. In this paper we describe the empirical analysis we conducted, whose results confirm that Web-COBRA can be profitably exploited for estimating Web application\u00a0\u2026", "num_citations": "22\n", "authors": ["1210"]}
{"title": "An approach for authoring 3D cultural heritage exhibitions on the web\n", "abstract": " The development of desktop virtual reality cultural exhibitions on the web is a challenging process, because it requires a collection of skills, ranging from art to 3D Internet technologies, and involves a variety of tasks. The need of suited approaches able to support the development of such exhibitions has motivated the introduction of the approach proposed in the paper. Such an approach is characterized by a strong attention towards the content experts, by a clear identification of the actors involved in the development process, and by a set of visual modeling languages, which support the high-level design of the exhibition and allow a more effective communication between the heterogeneous members of the project. Such modeling languages have been embedded in an authoring system which profitably supports the main figures to carry out their tasks.", "num_citations": "20\n", "authors": ["1210"]}
{"title": "A framework for genetic algorithms based on hadoop\n", "abstract": " Genetic Algorithms (GAs) are powerful metaheuristic techniques mostly used in many real-world applications. The sequential execution of GAs requires considerable computational power both in time and resources. Nevertheless, GAs are naturally parallel and accessing a parallel platform such as Cloud is easy and cheap. Apache Hadoop is one of the common services that can be used for parallel applications. However, using Hadoop to develop a parallel version of GAs is not simple without facing its inner workings. Even though some sequential frameworks for GAs already exist, there is no framework supporting the development of GA applications that can be executed in parallel. In this paper is described a framework for parallel GAs on the Hadoop platform, following the paradigm of MapReduce. The main purpose of this framework is to allow the user to focus on the aspects of GA that are specific to the problem to be addressed, being sure that this task is going to be correctly executed on the Cloud with a good performance. The framework has been also exploited to develop an application for Feature Subset Selection problem. A preliminary analysis of the performance of the developed GA application has been performed using three datasets and shown very promising performance.", "num_citations": "19\n", "authors": ["1210"]}
{"title": "A set of metrics for the effort estimation of mobile apps\n", "abstract": " In this work, we report a study carried out to identify a set of metrics to early estimate the development effort of mobile apps. The applied methodology was inspired by the work of Mendes et al. who addressed a similar problem in the field of web apps. In particular, we extracted an initial set of metrics by analyzing the online quotes forms that companies made available on their websites. Afterward, a Delphi approach with four project managers was employed to identify the proposed set of 41 relevant factors.", "num_citations": "16\n", "authors": ["1210"]}
{"title": "Handy: A new interaction device for vehicular information systems\n", "abstract": " The design of interfaces for automotive information systems is a critical task. In fact, such design must take into account that user is busy in the primary driving task, and any visual distraction determined by telematics systems can cause serious safety problems. To limit such distraction and enhance safety, in this paper we propose a novel multimodal user interface. The key element of the proposal is a new interaction device, named Handy, conceived to exploit the driver\u2019s tactile channel to minimize the workload of visual channel. Moreover Handy is suitably integrated with the graphical user interface, which is characterized by a reduced number of choices for each state and has been designed in agreement with the self-revealing approach.", "num_citations": "16\n", "authors": ["1210"]}
{"title": "Exploiting visual languages in software engineering\n", "abstract": " In the present chapter, we illustrate some methodologies and assessed results achieved in the area of visual languages that can be profitably exploited in the field of software engineering. The discussion will start with an overview of the most common graphical notations used to support software engineering activities, and with the description of some popular visual environments. Then, we will illustrate some tools for the automatic generation of visual languages, based on formalisms for the specification of visual languages. A discussion on some relevant applications of the described tools will conclude the chapter.", "num_citations": "16\n", "authors": ["1210"]}
{"title": "A system for rapid prototyping of visual language environments\n", "abstract": " The paper describes a visual environment generator, the VLPEG system, based on the Symbol Relation Grammar model. The system exploits a classification of visual languages in terms of graphical symbols and the relationships among them. For each class a lexical analyzer is able to interpret the physical layout of any drawn visual sentence and to provide a corresponding high level representation. Thanks to this capability the visual language designer may disregard the physical features and specify the language at a high abstraction level. VLPEG supports the rapid prototyping of visual environments and offers the designer the possibility to operate in automatic generation mode, by exploiting a grammar inference module. This capability allows the designer to focus on the structural features of the target language and quickly receive feedback from the customer during the language prototyping process.", "num_citations": "15\n", "authors": ["1210"]}
{"title": "Supporting hybrid and hierarchical visual language definition\n", "abstract": " In this paper we present an enhanced version of VLCC, a graphical system for the automatic generation of visual programming environments. The enhancement has been obtained by introducing a new syntactic model based on the concepts of hybrid and hierarchical visual languages. The resulting system is able to support the development of complex real world visual languages which occur in the field of software engineering.", "num_citations": "15\n", "authors": ["1210"]}
{"title": "An extensive evaluation of ensemble techniques for software change prediction\n", "abstract": " Predicting the areas of the source code having a higher likelihood to change in the future represents an important activity to allow developers to plan preventive maintenance operations. For this reason, several change prediction models have been proposed. Moreover, research community demonstrated how different classifiers impact on the performance of devised models as well as classifiers tend to perform similarly even though they are able to correctly predict the change proneness of different code elements, possibly indicating the presence of some complementarity among them. In this paper, we deeper investigated whether the use of ensemble approaches, ie, machine learning techniques able to combine multiple classifiers, can improve the performances of change prediction models. Specifically, we built three change prediction models based on different predictors, ie, product\u2010, process\u2010 metrics\u2010, and\u00a0\u2026", "num_citations": "14\n", "authors": ["1210"]}
{"title": "A WebML-based visual language for the development of Web GIS Applications\n", "abstract": " In the present paper, we propose a visual language meant to support the design of Web GIS applications. The proposal is based on the observation that Web GIS can be considered as a particular class of data- intensive Web applications, since they are mainly devoted to handle (spatial) information to and from the user. The success of WebML (Web Modeling Language) for designing traditional data-intensive Web applications suggested us to extend this visual formalism to model relevant interaction and navigation operations typical of Web GIS. The proposed extension consists of a set of content units specifically tailored for GIS concepts and tasks.", "num_citations": "14\n", "authors": ["1210"]}
{"title": "A COSMIC-FFP based method to estimate web application development effort\n", "abstract": " In the paper we address the problem of estimating the effort required to develop dynamic web applications. In particular, we provide an adaptation of the Cosmic Full Function Point method to be applied on design documents for counting data movements. We also describe the empirical analysis carried out to verify the usefulness of the method for predicting web application development effort.", "num_citations": "14\n", "authors": ["1210"]}
{"title": "Using extended positional grammars to develop visual modeling languages\n", "abstract": " In this paper we present the approach based on the formalism of Extended Positional Grammars for specifying, designing and implementing visual modeling languages. In order to stress the main characteristics of the approach and highlight its power, we describe the use of the formalism to implement statecharts languages which represent one of the most complex visual modeling languages used in the software engineering field. In the paper special emphasis is put on describing the benefits deriving from the use of such formal specifications such as incrementality, easy customization, and automatic generation of visual programming environments. Such features turn out to be especially important because visual modeling languages are subjected to continuous changes as the history of statecharts languages and UML diagrams shows. Moreover, visual languages can be effectively used only if they are supported\u00a0\u2026", "num_citations": "14\n", "authors": ["1210"]}
{"title": "Non-redundant 2d strings\n", "abstract": " Introduces a variation of the 2D string representation for symbolic pictures, the non-redundant 2D string, and analyze it with respect to compactness and non-ambiguity. It results that the non-redundant 2D string is a more compact representation than the 2D string, and that the class of unambiguous pictures under the non-redundant 2D string is almost equal to the class of unambiguous pictures under the reduced 2D string, up to a special case. Moreover, we show that the compactness of the new index does not affect the time complexity of picture retrieval.< >", "num_citations": "14\n", "authors": ["1210"]}
{"title": "Simple function points for effort estimation: a further assessment\n", "abstract": " Simple Function Points were proposed as a lightweight alternative to standard Function Points. The idea at the base of the definition of Simple Function Points is that it is possible to get equally effective size measures even without considering fine-grained details of functional specifications. Skipping the analysis and measurement of such details should allow for saving time and effort when measuring the functional size of software. In a previous study, the Simple Function Point method was employed to size software applications included in the ISBSG repository, thus employing data from different companies. In this paper, we aim at getting further evidence of the qualities of Simple Function Points via the empirical study of 25 Web applications developed by a single software company. The study highlights the correlation between Simple Function Points and standard Function Points measures and the existence of a\u00a0\u2026", "num_citations": "13\n", "authors": ["1210"]}
{"title": "Approximate cosmic size: the quick/early method\n", "abstract": " The COSMIC method is based on the counting of data movements from/to persistent storage and users. This requires some kind of data analysis to identify data groups. Project managers often need functional size at the beginning of the project life cycle but usually data analysis is not performed in the requirements elicitation phase. Moreover, rapid sizing can be requested since there is insufficient time or resources to apply the standard detailed method. Thus, there is the need of a simplified and rapid COSMIC measurement method to be applied to requirements elicitation documents. Such a method should avoid the use of scale factors since incorrect calibrations of the scale factors can lead to inaccurate approximations. To address the problem we proposed a simplified measurement process (named Quick/Early) that can be applied on the use case models and aims to reduce the measurement time, reaching a\u00a0\u2026", "num_citations": "13\n", "authors": ["1210"]}
{"title": "A web-based e-testing system supporting test quality improvement\n", "abstract": " In e-testing it is important to administer tests composed of good quality question items. By the term \u201cquality\u201d we intend the potential of an item in effectively discriminating between strong and weak students and in obtaining tutor\u2019s desired difficulty level. Since preparing items is a difficult and time-consuming task, good items can be re-used for future tests. Among items with lower performances, instead, some should be discarded, while some can be modified and then re-used. This paper presents a Web-based e-testing system which detects defective question items and, when possible, provides the tutors with advice to improve their quality. The system detects defective items by firing rules. Rules are evaluated by a fuzzy logic inference engine. The proposed system has been used in a course at the University of Salerno.", "num_citations": "13\n", "authors": ["1210"]}
{"title": "Adding symbolic information to picture models: definitions and properties\n", "abstract": " In the paper we propose extensions of some picture models, such as colored, drawn and pixel pictures. Such extensions are conceived by observing that a picture may embed more information than the shape, such as colors, labels, etc., which can be represented by a symbol from an alphabet and can be associated to segments, points or pixels. New interesting issues derived from the introduction of symbols will be investigated together with some complexity and decidability questions for the proposed extensions.", "num_citations": "13\n", "authors": ["1210"]}
{"title": "A web based tool for assessment and self-assessment\n", "abstract": " In the paper we present a Web application, named eWorkbook, which allows us to easily create and enjoy on-line tests. The system can be used for evaluating learner's knowledge by means of multiple choice questions. Its use is suitable within the academic environment in order to improve a blended learning approach by providing tutors with an additional assessment tool, and learners with a distance self-assessment means. In the paper, the main characteristics of the tool are presented together with a rationale behind them and an outline of the architectural design of the system.", "num_citations": "12\n", "authors": ["1210"]}
{"title": "The use of the GXL approach for supporting visual language specification and interchanging\n", "abstract": " GXL (Graph Exchange Language) has been proposed to be a standard exchange format for graph-based tools. By using XML as notation, GXL provides a scaleable and versatile approach to facilitate interoperability of reengineering tools. In this paper we propose a methodology to generate visual programming environments, which use GXL as data exchange format for visual languages. The methodology is conceived to be supported by grammar-based tools for the automatic generation of visual languages. In particular, we illustrate how it can be effectively supported by the Visual Language Compiler-Compiler (VLCC) system. As a matter of fact, we apply the methodology to generate a visual environment for statecharts languages using VLCC. In the generated environment we can edit a statechart and obtain its translation into the GXL format.", "num_citations": "12\n", "authors": ["1210"]}
{"title": "Semantics of visual languages\n", "abstract": " The general syntactical model of Relation Grammars has been introduced to describe any kind of graphical languages. This paper describes a technique for the semantic analysis of visual languages specified by relation grammars. The technique is based on the definition of Attribute Relation Grammars (ARG), which are an extension of attribute context-free grammars to the case of non-linear grammars. We study the static properties of an ARG under which each sentence can be translated with a cost linear in the size of the sentence.", "num_citations": "12\n", "authors": ["1210"]}
{"title": "Ensemble techniques for software change prediction: A preliminary investigation\n", "abstract": " Predicting the classes more likely to change in the future helps developers to focus on the more critical parts of a software system, with the aim of preventively improving its maintainability. The research community has devoted a lot of effort in the definition of change prediction models, i.e., models exploiting a machine learning classifier to relate a set of independent variables to the change-proneness of classes. Besides the good performances of such models, key results of previous studies highlight how classifiers tend to perform similarly even though they are able to correctly predict the change-proneness of different code elements, possibly indicating the presence of some complementarity among them. In this paper, we aim at analyzing the extent to which ensemble methodologies, i.e., machine learning techniques able to combine multiple classifiers, can improve the performances of change-prediction models\u00a0\u2026", "num_citations": "11\n", "authors": ["1210"]}
{"title": "A metric for the size estimation of object-oriented graphical user interfaces\n", "abstract": " In order to achieve quality products with reliable cost and effort estimations, one of the main tasks for planning software project development is size estimation. This is especially true when dealing with interactive applications which represent critical components in a software project. In the paper, we address the problem of the size estimation of interactive graphical applications developed using the object-oriented methodology. In particular, we define and validate a metric, the Class Point metric, for estimating the size of object-oriented GUIs. The method is based on the idea of quantifying classes in a program analogous to function counting performed by the function point metric. Theoretical validation has proven the consistency of the Class Point metric as size measure. Empirical validation provides evidence that the Class Point metric is a useful measure for OO software size.", "num_citations": "11\n", "authors": ["1210"]}
{"title": "A container-based infrastructure for fuzzy-driven root causing of flaky tests\n", "abstract": " Intermittent test failures (test flakiness) is common during continuous integration as modern software systems have become inherently non-deterministic. Understanding the root cause of test flakiness is crucial as intermittent test failures might be the result of real non-deterministic defects in the production code, rather than mere errors in the test code. Given a flaky test, existing techniques for root causing test flakiness compare the runtime behavior of its passing and failing executions. They achieve this by repetitively executing the flaky test on an instrumented version of the system under test. This approach has two fundamental limitations: (i) code instrumentation might prevent the manifestation of test flakiness; (ii) when test flakiness is rare passively re-executing a test many times might be inadequate to trigger intermittent test outcomes. To address these limitations, we propose a new idea for root causing test\u00a0\u2026", "num_citations": "10\n", "authors": ["1210"]}
{"title": "Formalization of slas for cloud forensic readiness\n", "abstract": " The provisioning of a Cloud service requires a number of parties to engage in a legal commitment towards one another. The responsibilities and expectations of both customers and providers are governed by means of a Service Level Agreement (SLA) contract that they sign prior the activation of the service. Once a Cloud service is provided by a party to another it is assumed that all the conditions, ie, clauses, mentioned in the SLA are read and fulfilled by those who signed it. The notion of Forensic Readiness (FR) is introduced in literature to help controlling and monitoring the behaviour of a computing architecture through a dedicated system; the essence of this capability is motivated by the necessity of facilitating some digital investigations in terms of time and costs. In some cases, such capability can be meant also for alerting and prevent any system attack attempts. In the Cloud, some crimes can be related to violations of the previously agreed upon service security measures. The logging process or documentation of Cloud service violations can then be used by either the provider or the customer to evaluate the quality of the service in subject. In addition, they can lead any of the involved parties to take the necessary legal actions. In this paper we emphasize the importance of automating the process of discovering Service Level Agreement violations in Cloud services. We propose a formal framework for building a Cloud Forensic Readiness System (CFRS) that considers the technical aspects of SLAs while monitoring the fulfilment of the addressed service. The system can eventually issue warnings and alerts to the involved parties as soon as\u00a0\u2026", "num_citations": "10\n", "authors": ["1210"]}
{"title": "Reference architecture for a cloud forensic readiness system\n", "abstract": " The Digital Forensic science is participating to a brand new change represented by the management of incidents in the Cloud Computing Services. Due that the Cloud Computing architecture is uncontrollable because of some specific features,its use to commit crimes is becoming a very critical issue, too. Proactive Cloud Forensics becomes a matter of urgency, due to its capability of collecting critical data before crimes happen, thus saving time and money for the subsequent investigations. In this paper, a proposal for a Cloud Forensic Readiness System is presented. It is conceived as reference architecture, in order to be of general applicability, not technically constrained by any Cloud architecture. The principal aim of this work is to extend our initial proposed Cloud Forensic Readiness System reference architecture, by providing more details and an example of its application by exploiting the Open Stack Cloud Platform.", "num_citations": "10\n", "authors": ["1210"]}
{"title": "Towards the automatic generation of web GIS\n", "abstract": " In the present paper, we propose an approach for the development of Web GIS based on WebML, a high-level, formal visual language specifically conceived to design data-intensive Web applications. The proposal is motivated by the observation that Web GIS can be considered as a particular class of data-intensive Web applications. In the paper, we describe the extension of the visual formalism for modeling relevant interaction and navigation operations typical of Web GIS.", "num_citations": "10\n", "authors": ["1210"]}
{"title": "Visual languages for defining adaptive and collaborative e-learning activities\n", "abstract": " In order to support instructional designers in the creation of distance courses, involving learning contents, collaborative activities, and assessment tests, a suite of visual languages are proposed. In particular, we define an extension of UML Activity Diagrams, named eXtended Learning Activity Diagram, to make them suitable for defining e-learning courses based on e-learning activities. We also propose the Adaptive Self consistent Learning Object SET language for defining learning contents, the SYnchronous Collaborative Learning Environment used to define synchronous and asynchronous learning environments, and the Test Maker Language for defining assessment and self-assessment tests. The proposed visual languages have been implemented in the SEAMAN tool (System for E-learning Activity MANagement) which provides means to fully design, implement, and deploy adaptive e-learning courses.", "num_citations": "10\n", "authors": ["1210"]}
{"title": "An approach for parallel genetic algorithms in the cloud using software containers\n", "abstract": " Genetic Algorithms (GAs) are a powerful technique to address hard optimisation problems. However, scalability issues might prevent them from being applied to real-world problems. Exploiting parallel GAs in the cloud might be an affordable approach to get time efficient solutions that benefit of the appealing features of the cloud, such as scalability, reliability, fault-tolerance and cost-effectiveness. Nevertheless, distributed computation is very prone to cause considerable overhead for communication and making GAs distributed in an on-demand fashion is not trivial. Aiming to keep under control the communication overhead and support GAs developers in the construction and deployment of parallel GAs in the cloud, in this paper we propose an approach to distribute GAs using the global parallelisation model, exploiting software containers and their cloud orchestration. We also devised a conceptual workflow covering each cloud GAs distribution phase, from resources allocation to actual deployment and execution, in a DevOps fashion.", "num_citations": "9\n", "authors": ["1210"]}
{"title": "Supporting Geographical Measures through a New Visualization Metaphor in Spatial OLAP.\n", "abstract": " Pivot tables are the de-facto standard paradigm for the visualization of data in the context of multidimensional OLAP analysis. However it is recognized that they are not suited, in their original definition, to support spatio-temporal data analysis (and in particular geographical measures). In this paper, we propose the GeOlaPivot Table, a visual metaphor intended as an extension of the pivot tables specifically conceived to assist decision makers in analyzing geographical measures in spatial data warehouses. In order to show the analysis capabilities of our metaphor we describe it using an example concerning the supervision of infectious diseases in Italy. This approach represents a first effort in adapting advanced geovisualization techniques to SOLAP ones, in order to create a specific visual paradigm for Spatial OLAP able to effectively support and fully exploit spatial multidimensional analysis process. Moreover, we present an architecture for a web-based environment able to support geographical measures in SOLAP analyses exploiting the GeOlaPivot Table visual metaphor.", "num_citations": "9\n", "authors": ["1210"]}
{"title": "On regular drawn symbolic picture languages\n", "abstract": " Drawn symbolic pictures are an extension of drawn pictures obtained by associating a symbol from an alphabet to each point of the picture. In the paper we will address some new interesting issues derived from the introduction of the symbols and we will identify the conditions, which ensure the preservation of properties holding for drawn pictures in the setting of the proposed extension.", "num_citations": "9\n", "authors": ["1210"]}
{"title": "On the pLR parsability of visual languages\n", "abstract": " The widespread use of visual languages has motivated the need for grammar-based tools to support designers in the definition and implementation of graphical environments. The effective use of such systems requires efficient parsing techniques. The VLCC system makes use of a suitable LR-like methodology that allows us to efficiently parse visual sentences. However there exist particular grammars which are non pLR parsable because they can produce run-time conflicts during the parsing of some sentences. In this paper we will introduce an algorithm that statically verifies the pLR parsability of a positional grammar by detecting whether or not it would produce run-time conflicts.", "num_citations": "9\n", "authors": ["1210"]}
{"title": "An Interpreter for Diagrammatic Languages Based on SR Grammars\n", "abstract": " The authors describe a general-purpose tool for the specification and interpretation of visual languages based on the formalism of SR grammars. The major components of the system are a structure analyzer and an interpretation module. The structure analyzer consists of a general diagrammatic editor and a lexical analyzer. The main task of the lexical analyzer is then the identification of the relationships among the visual tokens composing the diagram. The resulting SR sentence is passed over to the interpretation module. The interpretation system consists of a syntactic and a semantic analyzer which make use of a user-supplied SR grammar and an attribute SR grammar, respectively. The syntactic analysis of the SR sentence is accomplished by means of a polynomial time parsing algorithm that outputs a tree structure, called SR-tree, describing the generation of both the s-items and the r-items composing the\u00a0\u2026", "num_citations": "9\n", "authors": ["1210"]}
{"title": "Automatic generation of an adaptive WebGIS\n", "abstract": " With the continuous increase in the availability of WebGIS platforms and on-line spatial data, information overload within the spatial domain is becoming a critical issue. In order to address this and assist users to understand and manage the large amount of geospatial data available to them, techniques to personalise this content are being introduced in WebGIS applications. By monitoring users as they interact with map data, inferences can be made regarding their preferences and interests by generating a user profile that can be exploited to adapt content. However, to date, the development of adaptive WebGIS solutions is a difficult task as the practitioner has to deal with many different and non-trivial technologies. To address this issue, in this paper we propose an approach to automatically generate WebGIS applications able to recommend content to users and adapt the interface of a web-based spatial\u00a0\u2026", "num_citations": "8\n", "authors": ["1210"]}
{"title": "A visual language for designing presenting e-learning activities\n", "abstract": " We propose a visual language based approach to support an instruction designer in the creation of e-learning activities, distance courses and assessment tests. In particular, we have extended UML activity diagrams to make them suitable for the definition and generation of e-learning activities. The language is turned out to be also a powerful tool for presenting e-learning activities to end-users by providing them an easy user interface which allows us also to keep track of students' progresses. We also present a system prototype based on the proposed approach. The system includes integrated modules for several authoring activities, such as distance courses, assessment and self-assessment.", "num_citations": "8\n", "authors": ["1210"]}
{"title": "Symbolic picture languages and their decidability and complexity properties\n", "abstract": " In this paper, some subclasses of Positional Grammars have been formalized as an extension of thepicture grammars which were introduced by Maurer, Rozenberg and Welzl. This allows us to exploit the theoretical background established for picture languages and context-free languages to get insight into the features of the Positional grammar model. In particular, we have focused on several decidability and complexity issues for the (drawn) symbolic picture languages and their striped versions.", "num_citations": "8\n", "authors": ["1210"]}
{"title": "Design and automation of a COSMIC measurement procedure based on UML models\n", "abstract": " Context. Many organizations are adopting the COSMIC method to size software products for estimating and controlling their development costs and performances. Using a functional size measurement method requires specialized expertise and can be time-consuming. Objectives. Since UML is the de facto industrial modeling language standard for object-oriented systems, it is very useful to understand how to exploit UML models for measuring software systems and for developing tools that can automatically derive the COSMIC size from them. This paper provides an answer to these needs. Method. We present a measurement procedure to derive the COSMIC functional size from UML software artifacts and a tool, named J-UML COSMIC, for the automation of the procedure. Based on the observation that different development processes are characterized by the use of different UML models, the tool has been\u00a0\u2026", "num_citations": "7\n", "authors": ["1210"]}
{"title": "SLAFM: A service level agreements formal model for cloud computing\n", "abstract": " Cloud Computing services are regulated by a contract called Service Level Agreement (SLA). They are cosigned between the customers and the providers after a negotiation phase, and during their validity time several constraints have to be respected by the involved parties. Due to their popularity, cloud services are enormously used and unfortunately also abused, specially by cyber-criminals. Sometimes the crimes have the consequence of violating some contractual constraints without the parties are aware of. A manner for guaranteeing more control of the SLA respect is to consider a dedicated system interacting with the cloud services and detecting the SLA violations by analysing the log files. Our proposal will introduce a formal model aimed to represent the contents of such SLAs with rules in the context of an automatic mechanism for detecting SLA violations.", "num_citations": "7\n", "authors": ["1210"]}
{"title": "Embedding google maps APIs into WebRatio for the automatic generation of web GIS applications\n", "abstract": " The success of WebML (Web Modeling Language) and of the supporting tool WebRatio for designing and generating data-intensive web applications suggested us to extend the approach to the Web GIS context. The proposal was based on Geo Server and Map Server, two standard, open solutions, to handle spatial data. In the present paper, we propose an alternative approach based on Google Maps, a freely available web mapping application provided by Google, which allows for the search and the visualization of geographic information. This solution is so diffuse that many Internet users are identifying it as a \u201cstandard\u201d way for the presentation of geographical informa-tion. Moreover, Google Maps can be integrated into a Web application by exploiting Google Maps APIs. In the paper, we describe the proposed WebML-based visual language to design Web GIS applications and how it has been\u00a0\u2026", "num_citations": "7\n", "authors": ["1210"]}
{"title": "Implementing statecharts using extended positional grammars\n", "abstract": " In this note we show how the formalism of eXtended Positional Grammars (XPGs) allow us to model a wide class of statecharts. Statecharts are a very rich graphical specification formalism. They are an extension of conventional finite state machines with more powerful concepts such as hierarchy of states, orthogonality, interlevel transitions, etc. It is widely recognized that the main difficulties for modelling statecharts derive from the presence of interlevel transitions, multiple source/multiple target transitions, joint and fork connectors, and history connectors [3, 4]. The class of statecharts language described by XPG formalism is that proposed in the commercial tool STATEMATE [3] with the constraint that consecutive joints or forks are not admitted. In the following we will sketch how the formalism of XPGs allows us to effectively capture such characteristics. We start by recalling some basic notions concerning with XPGs (a more complete description can be found in [2]). In such a formalism a visual sentence is conceived as a set of attributed graphical objects, where each object is described as a symbol of the grammar. A symbol of an XPG is a generalized symbol gs (gsymbol for short) defined as a triple (M, S, L) where M physically describes gs, S is the syntactic component (ie, a set of syntactic attributes) used to relate gs to others symbols, and L is the semantic interpretation of gs. Sentences of a language are obtained by combining gsymbols through positional relations specified on the syntactic attributes of the gsymbols. XPGs are a direct extension of Positional Grammars [1]. In particular an XPG is the pair (G, PE), where PE is a positional\u00a0\u2026", "num_citations": "7\n", "authors": ["1210"]}
{"title": "Redundancy elimination and loop checks for logic programs\n", "abstract": " A simple analysis of the arguments developed by Bol et al. (Theoret. Comput. Sci.86, 35-79 (1991)) shows that an actual reason for the nonexistence of a complete sound simple check for all function-free programs is the presence in the resolvents of potentially unlimited sequences of atoms chained by common variables. This hints that a limitation of the number of variables generating this kind of chain could guarantee the applicability of complete simple loop checks. This line is followed in the paper, and quite general classes of logic programs are characterized, without any direct imposition on the structures of the rules. This objective is accomplished by exploiting a variant of SLD-resolution, which is able to perform a systematic elimination of redundant atoms from resolvents. As a notable result, it turns out that the equality loop check is complete for our class of logic programs. This seems to suggest that the\u00a0\u2026", "num_citations": "7\n", "authors": ["1210"]}
{"title": "Towards evolutionary machine learning comparison, competition, and collaboration with a multi-cloud platform\n", "abstract": " We present cCube, an open source architecture used to automatically create an application of one or more Evolutionary Machine Learning (EML) classification algorithms that can be deployed to the cloud with automatic data factorization, training, result filtering and fusion. cCube enables automated EML classification algorithmsc omparison,c ompetition and multi-partyc ollaboration. It can be used by an algorithm developer, a community working together or a black box user of EML classification. It requires minimal extra code to cloud-scale shared-memory implementations. It employs a microservices architecture and software containers into which user code is integrated allowing to access to the full benefits of cloud computing, eg, on demand and elastic computing, while not committing (code or patronage) to a specific cloud provider such as Amazon Web Services or OpenStack. We demonstrate cCube, straddling\u00a0\u2026", "num_citations": "6\n", "authors": ["1210"]}
{"title": "A webml-based approach for the development of web gis applications\n", "abstract": " The goal of disseminating and manipulating spatial knowledge over the Internet, has led to the development of Web applications, known as Web Geographic Information Systems (Web GIS). Web GIS can be considered as a particular class of data-intensive Web applications, since they are mainly devoted to handle (spatial) information to and from the user. The success of WebML (Web Modeling Language) for designing traditional data-intensive web applications suggested use to extend this visual formalism to model relevant interaction and navigation operations typical of Web GIS. In the paper, we describe the proposed extension and provide an example of its application.", "num_citations": "6\n", "authors": ["1210"]}
{"title": "Visual language-based system for designing and presenting e-learning courses\n", "abstract": " In this chapter we present a system supporting instruction designers in the design and deployment of e-learning courses. The system includes integrated modules for several authoring activities, such as the definition of knowledge content objects, and the creation of assessment and self-assessment tests. The distinguishing characteristics of the proposed system is that it is based on a suite of visual languages, enabling the modelling of different aspects of the construction process for Web-based distance courses. The languages include a Learning Activity Diagram, which extends UML Activity Diagrams to make them suitable for modelling distance course structures; a Self-Consistent Learning Object language used to define knowledge contents; and a Test Maker Language for specifying assessment and self-assessment tests. The use of visual languages provides an intuitive and friendly system user interface that\u00a0\u2026", "num_citations": "6\n", "authors": ["1210"]}
{"title": "Semantics-based inference algorithms for adaptive visual environments\n", "abstract": " The paper presents a grammatical inference methodology for the generation of visual languages, that benefits from the availability of semantic information about the sample sentences. Several well-known syntactic inference algorithms are shown to obey a general inference scheme, which the authors call the Gen-Inf scheme. Then, all the algorithms of the Gen-Inf scheme are modified in agreement with the introduced semantics-based inference methodology. The use of grammatical inference techniques in the design of adaptive user interfaces was previously experimented with the VLG system for visual language generation. The system is a powerful tool for specifying, designing, and interpreting customized visual languages for different applications. They enhance the adaptivity of the VLG system to any visual environment by exploiting the proposed semantics-based inference methodology. As a matter of fact, a\u00a0\u2026", "num_citations": "6\n", "authors": ["1210"]}
{"title": "Mining spatio-temporal datasets: relevance, challenges and current research directions\n", "abstract": " Spatio-temporal data usually records the states over time of an object, an event or a position in space. Spatio-temporal data can be found in several application fields, such as traffic management, environment monitoring, weather forecast, etc. In the past, huge effort was devoted to spatial data representation and manipulation with particular focus on its visualisation. More recently, the interest of many users has shifted from static views of geospatial phenomena, which capture its \u201cspatiality\u201d only, to more advanced means of discovering dynamic relationships among the patterns and events contained in the data as well as understanding the changes occurring in spatial data over time. Spatio-temporal datasets present several characteristics that distinguish them from other datasets. Usually, they carry distance and/or topological information, organised as multidimensional spatial and temporal indexing structures. The access to these structures is done through special methods, which generally require spatial and temporal knowledge representation, geometric and temporal computation, as well as spatial and temporal reasoning. Until recently, the research in spatial and temporal data handling has been mostly done separately. The research in the spatial domain has focussed on supporting the modelling and querying along spatial dimensions of objects/patterns in the datasets. On the other hand, the research in the temporal domain has focussed on extending the knowledge about the current state of the system governed by the temporal data. However, spatial and temporal aspects of the same data should be studied in conjunction as they are often\u00a0\u2026", "num_citations": "5\n", "authors": ["1210"]}
{"title": "Boosting the adoption of computer managed instruction functionalities in e-learning systems\n", "abstract": " Standardization efforts in e-learning are mainly aimed at achieving interoperability among Learning Management Systems (LMSs) and Learning Object (LO) authoring tools. In particular, the main standard producers are giving special attention to a set of functionalities, referred to as Computer Managed Instruction (CMI) and also known as SCORM Run-Time Environment. Their adoption is crucial in the achievement of full interoperability among LMSs and LO authoring tools since they allow LOs to be launched in the LMS and to exchange data with it. Even desirable, standard compliancy and guideline adoption are difficult to obtain for LMS producers. This paper presents two design solutions aimed at boosting the adoption of CMI functionalities in Object-Oriented and Message-Oriented LMS systems, respectively. The former is a framework, named CMIFramework, which allows LMS developers to rapidly adopt CMI functionalities in Object-Oriented systems. The latter is a Service Oriented Architecture (SOA)-based reference model for offering the CMI functionalities as a service, external to the LMS. We investigate several case studies concerning the adoption of CMI functionalities, using our solutions, in different e-learning contexts.", "num_citations": "5\n", "authors": ["1210"]}
{"title": "Towards a flexible system for exploratory spatio-temporal data mining and visualization\n", "abstract": " Many natural phenomena present intrinsic spatial and temporal characteristics. With the recent advances in data collection technologies, high resolution spatio-temporal datasets can be stored and analyzed to accurately study the behavior of such events. However, these datasets are often very large and difficult to analyze and display. Recently much attention has been dedicated to the application of innovative data-mining techniques to filter out relevant subsets of very large repositories as well as to the development of visualization tools to effectively display the corresponding results. In this paper we describe our approach to deal with very large spatio-temporal datasets. Our framework includes new techniques to efficiently support the data-mining process, address the spatial and temporal dimensions of the dataset, and visualize and interpret results. Within this framework, we have developed two complementary 3D visualization environments, one based on Google Earth and one relying on a Java3D graphical user interface. In this paper we provide an overview of the system we have developed and we highlight the challenges we are dealing with, to handle a new, wide dataset containing heterogeneous multi-dimensional information on traffic events.", "num_citations": "5\n", "authors": ["1210"]}
{"title": "An approach for the creation of collaborative environments\n", "abstract": " In this paper, we propose an approach for the creation of collaborative e-learning environments. The approach provides suitable visual languages allowing the instruction designer to specify e-learning courses in a simple way. The defined courses are based on synchronous and asynchronous activities. Moreover, we describe a system prototype based on the presented approach, which provides automated support for the generation of e-learning courses starting from their visual specification. Another distinctive characteristic of our approach is the possibility to specify and generate full collaborative environments. This learning paradigm let us augment the effectiveness of the e-learning courses allowing learners to share experiences and knowledge.", "num_citations": "5\n", "authors": ["1210"]}
{"title": "Prototype of a visual language for spatial data mining based on the'miner trip'metaphor: VisMiner\n", "abstract": " Spatial data mining has wide applications in different fields, so different types of users are involved. Spatial data mining systems integrate the functionalities of both geographic information systems and data mining systems. They should provide means to manage the complexity of their underlying concepts and to properly assist both experienced and naive users. One possible solution is to enhance them by means of visual languages. Generalizing the concepts of the different spatial data mining tasks, we propose a visual language for spatial data mining named VisMiner, based on the 'Miner Trip' metaphor. It provides a simple and intuitive way to configure all the spatial data mining tasks in a uniform way, to specify the spatial relations to be used by the mining algorithms, and to create different data mining models by exploiting the resolution of precision topological ambiguities.", "num_citations": "5\n", "authors": ["1210"]}
{"title": "Exploiting Visual Languages Generation and UML Meta Modeling to Construct Meta-CASE Workbenches\n", "abstract": " In the paper we propose an approach for the construction of meta-CASE workbenches. The approach is based on the technology of visual language generation systems and on UML meta modeling. Visual modeling environments are generated starting from UML class diagrams specifying abstract syntax of the underlying visual language. The meta-CASE generates a workbench by integrating a set of visual modeling environments through inter-consistency constraints defined on the corresponding UML class diagrams.", "num_citations": "5\n", "authors": ["1210"]}
{"title": "cCube: a cloud microservices architecture for evolutionary machine learning classification\n", "abstract": " We present cCube, a microservices open source architecture used to automatically create an application of one or more Evolutionary Machine Learning (EML) classification algorithms that can be deployed to the cloud with automatic data factorization, training, result filtering and fusion.", "num_citations": "4\n", "authors": ["1210"]}
{"title": "Using cosmic for the functional size measurement of distributed applications in cloud environments\n", "abstract": " The competitiveness of software companies greatly depends on the ability of their project managers to carry out a reliable and accurate software size estimation. Among the approaches for software sizing, functional size measurement (FSM) methods are widely used in the industry since they can be applied early, based on the user functional requirements. COSMIC represents a second-generation FSM method, and its adoption is rapidly growing in the software industry. The idea underlying the COSMIC method is that, for many types of software, most of the development efforts is devoted to handling data movements. In this chapter, we analyse various aspects of the use of COSMIC to measure distributed applications in cloud environments. We take into account three distinct provision models of the cloud computing stack, namely, the Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and\u00a0\u2026", "num_citations": "4\n", "authors": ["1210"]}
{"title": "A Cloud Forensic Readiness Model for Service Level Agreements Management\n", "abstract": " Cloud computing is increasingly becoming a target of cyber-criminal attacks. Often the committed crimes violate the Service Level Agreement (SLA) contracts, which must be respected by all the involved parties. Cloud Forensics is a branch of Digital Forensic discipline dealing with crimes involving the Cloud. A manner for leveraging some of the attacks is the provisioning of a Forensic Readiness capability, by performing some activities before the crimes happen. In this paper we introduce a model aimed to represent the management of SLAs through a cloud system.", "num_citations": "4\n", "authors": ["1210"]}
{"title": "A Cosmic-FFP Approach to Estimate WEB Application Development Effort.\n", "abstract": " Web applications are constantly increasing both in complexity and number of offered features. In this paper we address the problem of estimating the effort required to develop dynamic web applications, which represents an emerging issue in the field of web engineering. In particular, we formalize a method which is based on the main ideas underlying COSMIC-FFP (Cosmic Full Function Point), which is an adaptation of the Function Point method, especially devised to tackle real-time and embedded applications. The method is focused on counting data movements and turns out to be suitable for capturing the specific aspects of dynamic web applications which are characterized by data movements to and from web servers. The method can be applied to analysis and design documentation in order to provide an early estimation. We also describe the empirical analysis carried out to verify the usefulness of the method for predicting web application development effort.", "num_citations": "4\n", "authors": ["1210"]}
{"title": "A system for the generation of 3D-learning simulations\n", "abstract": " The use of 3D contents for the e-learning is a very fascinating field, because the virtual reality is a very effective way to convey educational contents. But currently the realization of 3D courseware is still a very challenging task. In this paper we propose an innovative authoring system allowing teachers to easily define 3D interactive simulations. The key idea of the system is to provide a new level of abstraction, useful to specify the simulations context. In this way the tool can be profitably used by teachers, as an LCMS, to represent all the domains that can be described through some vectorial rules. Moreover, the most of the authoring tasks are achieved through the use of some wizards, to minimize the needing of 3D knowledge. Finally, the resulting virtual scenarios are rendered to the students in a highly interactive 3D browser. We successfully employed the system to model simulations in some different 3D-learning\u00a0\u2026", "num_citations": "4\n", "authors": ["1210"]}
{"title": "Exploiting XPG for visual languages definition, analysis and development\n", "abstract": " In this paper we present the approach based on the formalism of Extended Positional Grammars (XPG) for specifying, designing and implementing visual languages. Special emphasis is put on describing the benefits deriving from the use of such formalism. Indeed, it allows us to exploit the well-established theoretical background and techniques developed for string languages in the setting of visual languages. As a matter of fact, an efficient syntactic analysis of visual languages can be effectively perfomed by using a suitable extension of LR techniques. Moreover, syntax-direct translations can be used to verify properties of visual sentences during a semantic analysis phase. Finally, a visual environment for a target visual language can be automatically generated by exploiting a YACC-like tool based on XPG.", "num_citations": "4\n", "authors": ["1210"]}
{"title": "Decidability of the consistency problem for regular symbolic picture description languages\n", "abstract": " In the paper we address the consistency problem for drawn symbolic picture grammars. In particular we prove that it is always possible to decide whether or not a regular grammar generates only consistent descriptions of drawn symbolic pictures.", "num_citations": "4\n", "authors": ["1210"]}
{"title": "A lean approach to estimate the functional size of operating applications\n", "abstract": " Functional size measures have been gaining increasing acceptance not only for project estimation and productivity comparisons but also for the evaluation of the company assets concerning with operating applications. However, functional sizing operating applications can represent a complex task (they could be developed in past projects, in some cases by others, with long standing technologies, and without useful documentation supporting them). Thus, companies require cheaper strategies to estimate functional size of these applications. To this end, we proposed some measurement approaches concerning with the number of physical tables and the number of read and read/written tables that can be easily collected from the database schema and the application interfaces. We assessed the effectiveness of the proposals performing an empirical study based on 17 applications of an Italian company. The results\u00a0\u2026", "num_citations": "3\n", "authors": ["1210"]}
{"title": "An Empirical Study on the Use of Web-COBRA and Web Objects to Estimate Web Application Development Effort\n", "abstract": " We have performed a replication of a previous study in order to further assess the effectiveness of Web-COBRA method, with the Web Objects measure, in predicting Web application development effort. The results of the empirical analysis confirm the interesting results of the previous study.", "num_citations": "3\n", "authors": ["1210"]}
{"title": "GoOlap Vers l'Analyse Spatio-Multidimensionnelle \u00e0 l'aide du Geobrowser Google Earth.\n", "abstract": " Les outils OLAP Spatial (SOLAP) existants n\u2019int\u00e8grent pas encore compl\u00e8tement toutes les fonctionnalit\u00e9s de visualisation, d\u2019interaction et d\u2019analyse des SIG. Dans cet article, nous pr\u00e9sentons l\u2019impl\u00e9mentation d\u2019un syst\u00e8me SOLAP Web flexible, GoOlap, qui combine \u00e0 la fois des fonctionnalit\u00e9s OLAP et des fonctionnalit\u00e9s \u00e9volu\u00e9es de g\u00e9ovisualisation. Ce syst\u00e8me int\u00e9gre le geobrowser Google Earth avec le syst\u00e8me OLAP Mondrian/JPivot. Google Earth enrichie les capacit\u00e9s d\u2019analyse spatio-multidimensionnelles \u00e0 travers la visualisation 3D, la \u00abcontextualisation\u00bb de l\u2019application SOLAP et la personnalisation des affichages cartographiques.ABSTRACT. Spatial OLAP (SOLAP) systems do not completely integrate visualization, interaction and analysis functionalities of Geographic Information Systems. In this paper, we propose a flexible Web SOLAP tool, GoOlap, which combines OLAP and Geovisualization functionalities through the integration of the geobrowser Google Earth and the OLAP tool Mondrian/JPivot. Google Earth enriches spatio-multidimensional analysis capabilities with 3D visualizations, SOLAP applications contextualization and cartographic displays customization.", "num_citations": "3\n", "authors": ["1210"]}
{"title": "E-World: A Platform for the Management of Adaptive E-Learning Processes\n", "abstract": " In this chapter the authors present E-World, an e-learning platform able to manage and trace adaptive learning processes which are designed and created by means of a visual language based tool. To address the goal to have a platform easily extensible with new services, they have designed it selecting a software architecture based on the use of Web Services and a suitable Middleware component. To trace adaptive learning processes E-World also integrates as Web Service a suitable implementation of a Run-Time Environment compliant with the Sharable Content Object Reference Model (SCORM) standard. Their proposal also supports the \u201canytime and anywhere\u201d learning paradigm as it enables learners to enjoy linear or adaptive processes using any device equipped with a standard Web browser. In the chapter they also report on the experiment we have carried out to assess the usability of the proposed e\u00a0\u2026", "num_citations": "3\n", "authors": ["1210"]}
{"title": "Logging and Analyzing User\u2019s Interactions in Web Portals\n", "abstract": " Content Management Systems and Web Portal Frameworks are more and more widely adopted in Web development. Those kinds of software often produce Web pages whose layout is divided in sections called, in the case of Web Portals, \u201cportlets\u201d. Portlets can be produced by different sources and then aggregated in the same page by the portal. For Web portals, traditional Web metrics based on page visits can be inadequate for fully understanding user\u2019s interest, due to the heterogeneity of content and the variety of sources. This paper proposes a system for evaluating the Web traffic at a deeper level than the page visit one: the level of the sections, or of the portlets. The interest of the user in the sections of the page is gauged through implicit interest indicators, such as, section visibility, mouse movements and other client-side interactions. Our system is composed of two different products: a framework that\u00a0\u2026", "num_citations": "3\n", "authors": ["1210"]}
{"title": "Case Studies on the Support of Computer Managed Instruction Functionalities in e-Learning Systems\n", "abstract": " The term computer managed instruction (CMI) often refers to a set of functionalities which allow learning objects to be launched in the learning management system and to exchange data with it. A framework for the support of CMI functionalities in learning management systems, named CMIFramework, has been developed at the University of Salerno. In this paper, we present two case studies concerning the adoption of CMI functionalities, using CMIFramework, in different e-learning contexts. Our present work is aimed at demonstrating the ease in using the framework and its power in solving several problems connected to the adoption of CMI functionalities", "num_citations": "3\n", "authors": ["1210"]}
{"title": "A Framework for the Evaluation of Automotive Telematics Systems.\n", "abstract": " The evaluation of interfaces for in-car communication and information applications is an important and challenging task. Indeed, it is necessary not only to consider the user interaction with the interface but also to understand the effects of this interaction on driver-vehicle performances. As a result, there is a strong need of tools and approaches that allow researchers to effectively evaluate such interfaces while user is driving. To address the problem in the paper we propose a framework that has been specifically conceived for such evaluation. It is based on the integration of a suitable car simulator and an in-car system and allows us to get a high amount of data and carry out repeatable tests in a safe and controlled environment. Moreover, the proposed solution is not much expensive and quite simple to set-up.", "num_citations": "3\n", "authors": ["1210"]}
{"title": "A Web-based Computer Aided Assessment Tool Supporting Question Quality Improvement\n", "abstract": " Computer Aided Assessment (CAA) tools are more and more widely adopted in academic environments mixed to other assessment means. In this context, there is an increasing demand for a better assessment material. It would be quite an interesting feature for a CAA tool to tell the tutor how her/his questions are effective in judging the learners. In this paper we show how eWorkbook, a CAA system, developed at Dipartimento di Matematica e Informatica of University of Salerno, supports such a feature. We chose to mix the statistical indexes given by the Item Analysis to the opinion of the learners, both of them available after one or more test sessions. This information is a good feedback for the tutor, useful to modify her/his assessment material, improving it. Every time a question is modified, a newer and, hopefully, better version of it is generated and the question\u2019s lifecycle continues.", "num_citations": "3\n", "authors": ["1210"]}
{"title": "An Innovative Vocal Interface for Automotive Information Systems.\n", "abstract": " The design of interfaces for automotive information systems is a critical task. In fact, in the vehicular domain the user is busy in the primary task of the driving, and any visual distraction inducted by the telematic systems can bring to serious consequences. Since road safety is paramount, it is needed to define new interaction metaphors, not affecting the driver\u2019s visual workload, such as auditory interfaces. In this paper we propose an innovative automotive auditory interaction paradigm, whose main goals are not to require visual attention, to be smart for expert users, as well as easy to use for inexperienced users. This is achieved by a new atomic dialogue paradigm, based on a help-on-demand mechanism, to provide a vocal support to users in trouble. Finally, we present some examples of dialogue based on such approach.", "num_citations": "3\n", "authors": ["1210"]}
{"title": "The Impact of Accessibility and Usability on the Development of Web Applications.\n", "abstract": " Ease of use is definitively one of the key aspects characterizing the quality of web applications and includes accessibility and usability. In this paper we describe how these factors can affect the development of web applications. In particular, we describe the activities that should be targeted at accessibility based upon the W3C guidelines and propose a list of elements that could be used as predictors of the effort needed to ensure accessibility. As for the usability, we report on the tasks carried out to achieve this goal and the time commonly devoted to these tasks.", "num_citations": "3\n", "authors": ["1210"]}
{"title": "Relation grammars: A formalism for syntactic and semantic analysis of visual languages\n", "abstract": " Formal grammars have been widely used for the formal description of visual languages and for the implementation of general lexical analyzers, parsers, semantic analyzers, syntax-driven visual programming environments, etc. This chapter analyzes the formalism ofsymbol relation grammarsand compares its features with the ones of other existing models. In this formalism each sentence is composed of a set ofsymbol occurrencesrepresenting visual elementary objects, which are related through a set of binaryrelational items.The main feature of symbol relation grammars is the uniform way they use context-free productions to rewrite symbol occurrences as well as relational items. The clearness and uniformity of the derivation process for symbol relation grammars allows syntactic tree structures to be easily defined as a natural extension of the traditional syntactic trees of context-free string grammars. The main\u00a0\u2026", "num_citations": "3\n", "authors": ["1210"]}
{"title": "On the refinement of logic specifications\n", "abstract": " Refining a specification S1 means to provide another specification S2 which contains all the information given in S1 but with more detail. In this paper, we use logical implication from lower to higher levels of logic specifications to give a definition of refinement between these levels. This guarantees that any property of the higher level is also verified at the lower one. The definition of the relation \"is refinement of\" is given for specifications which are general first-order theories and it is proved to be transitive. A relevant aspect is that the different levels of logic specifications are in general not immediately comparable, because they can use different vocabularies. For this reason, the concept of transcription is introduced formally in our definition. Then the particular case of Horn specifications is considered. Horn specification semantics can be given by the methodology of least models. This may suggest definitions of the\u00a0\u2026", "num_citations": "3\n", "authors": ["1210"]}
{"title": "A heuristic extending the Squarified treemapping algorithm\n", "abstract": " A heuristic extending the Squarified Treemap technique for the representation of hierarchical information as treemaps is presented. The original technique gives high quality treemap views, since items are laid out with rectangles that approximate squares, allowing easy comparison and selection operations. New key steps, with a low computational impact, have been introduced to yield treemaps with even better aspect ratios and higher homogeneity among items.", "num_citations": "2\n", "authors": ["1210"]}
{"title": "LOG4P: An innovative logger framework for web portals\n", "abstract": " Content Management Systems and Web Portal Frameworks are more and more widely adopted in Web development. Those kinds of software often produce web pages whose layout is divided in sections called, in the case of Web Portals,\u201cportlets\u201d. Portlets can be produced by different sources and then aggregated in the same page by the portal. For Web portals, traditional web metrics based on page visits can be inadequate for fully understanding user\u2019s interest, due to the heterogeneity of content and the variety of sources. This paper proposes a system for evaluating the web traffic at a deeper level than the page visit one: the level of the sections, or of the portlets. The interest of the user in the sections of the page is gauged through implicit interest indicators, such as, section visibility, mouse movements and other client-side interactions. Our system is composed of two different products: a framework that, opportunely instantiated in a web portal, allows the production of a log, and a log analyzer. The possible uses and benefits gained by research in the fields of web traffic analysis, portal design and usability are investigated in depth.", "num_citations": "2\n", "authors": ["1210"]}
{"title": "A User-Centered Methodology to Generate Visual Modeling Environments\n", "abstract": " CASE tools supporting many activities of the software development process embed visual modeling environments. Indeed, visual languages are practical means to allow engineers to define models and different views of software systems. However the effectiveness of visual modeling environments strongly depends from the process and tools used for their development. In this paper we present a user-centered methodology for the development of customized visual environments, and a tool to support it. The use of UML meta-modeling techniques and formal methods characterizes the proposed approach. Moreover, incremental development and rapid prototyping are ensured by the use of an automatic generation tool that allows designers to focus on structural features of the target language disregarding the visual environment creation.", "num_citations": "2\n", "authors": ["1210"]}
{"title": "Visual languages for non expert instructional designers: a usability study\n", "abstract": " In this paper we propose a usability study on a visual language based tool for the definition of adaptive learning processes. To this aim, we recruited a group of seven teachers with different teaching experiences to evaluate the usability of the proposed tool and as well as to assess the value of visual languages in the definition of learning processes. Interesting results in terms of satisfaction and performance have been achieved on the recruited teachers without computer science background.", "num_citations": "2\n", "authors": ["1210"]}
{"title": "Using Alternating Words to Describe Symbolic Pictures\n", "abstract": " In this chapter we present the concepts of drawn symbolic picture and symbolic picture. We provide an elegant string description for such models consisting of alternating words, ie strings whose letters are in alternation from an alphabet of symbols and an alphabet of directions. We characterize the grammars for alternating words and define the generative model for (drawn) symbolic pictures.", "num_citations": "2\n", "authors": ["1210"]}
{"title": "A Framework for the Support of the SCORM Run-Time Environment\n", "abstract": " In order to allow interoperability among Learning Management Systems there is a need for a standard environment in which the Learning Objects could be launched and exchange data with the Learning Management System. The functionalities of such an environment are often referred to as Computer Managed Instruction and are at present defined in several specification documents issued by the producers of the main standards and guidelines. The most famous of them is SCORM Run-Time Environment, produced by ADL. In this paper we propose an Object Oriented framework which allows the development of Learning Management Systems with the support of Computer Managed Instruction functionalities. The framework can be opportunely instanced to obtain an environment in which Learning Objects, compliant with different versions of the specifications, can be launched without incurring incompatibility problems.", "num_citations": "2\n", "authors": ["1210"]}
{"title": "An Integrated System for Designing, Implementing and Managing Adaptive E-learning Activities\n", "abstract": " Donne in cerca di avventure IRIS annuncio uomo cerca donna nascondi/visualizza icone a destradonna cerca ragazzo roma siti chat gratis nascondi/visualizza menu in altoannunci bakeca incontri milano singles in durban south africa Sfoglia bakeca incontri palermo donne Scorri i prodotti per: singles dating events melbourne incontra la tua anima gemella gratis inserisci annuncio gratis chat per conoscersi gianna nannini donne in amore live bakeca incontri per adulti torino incontro kiko catania diretta Login IRIS baralho cigano do amor online gratis chat per rimorchiare gratis kijiji ebay annunci adulti napoli siti di incontro completamente gratis chinese singles dating sites An Integrated System for Designing, Implementing and Managing Adaptive E-learning Activities donne di cagliari per chattare gratis Italiano incontri adulti torino trovare una donna incontri a trento incontro \u00e8 facile giurisprudenza An Integrated \u2026", "num_citations": "2\n", "authors": ["1210"]}
{"title": "Can Expert Opinion Improve Effort Predictions When Exploiting Cross-Company Datasets?-A Case Study in a Small/Medium Company\n", "abstract": " Many studies have shown that the accuracy of the predictions obtained by estimation models built considering data collected by other companies (cross-company models) can be significantly worse than those of estimation models built employing a dataset collected by the single company (within-company models). This is due to the different characteristics among cross-company and within-company datasets. In this paper, we propose an approach based on the opinion of the experts that could help in the context of small/medium company that do not have data available from past developed projects. In particular, experts are in charge of selecting data from public cross-company datasets looking at the information about employed software development process and software technologies. The proposed strategy is based on the use of a Delphi approach to reach consensus among experts. To assess the\u00a0\u2026", "num_citations": "1\n", "authors": ["1210"]}
{"title": "A Fuzzy-Based Distance to Improve Empirical Methods for Menu Clustering.\n", "abstract": " An effective menu organization is fundamental to obtain usable applications. A common practice to achieve this is to adopt empirical methods in the menu design phase, by requesting a number of intended final users to provide their ideal tasks arrangements. However, to improve the effectiveness of this approach, it is necessary to filter results, by identifying and discarding data coming from subjects whose mental models are too weak on the considered domain. To this aim, in the paper, we propose a formal tool suited to support menu designers, which is based on a fuzzy-based distance we defined. This measure can be easily calculated on the empirical datasets, thanks to a specifically conceived supporting application we developed. As a result, by exploiting the proposed solution, menu designers can rely on a formal tool to evaluate significance of empirical data, thus leading towards more effective menu clustering.", "num_citations": "1\n", "authors": ["1210"]}
{"title": "A Simulation Environment to Assess Driving Performances while Interacting with On-board Telematics Systems\n", "abstract": " The evaluation of user interfaces for vehicular telematics systems is a challenging task, since it is necessary to understand the effects of interaction on driving performances. To this aim, in 2005 we developed and presented a framework specifically conceived for the indoor evaluation of these systems. In this paper we present some significant improvements of that proposal. In particular, we describe a graphical analysis tool able to provide a clear and deep insight about driver behaviors using the high amount of data generated by the simulator. Moreover, we report on the evaluation analysis that has been performed to assess the effectiveness of the framework for measuring driving performances.", "num_citations": "1\n", "authors": ["1210"]}
{"title": "eWorkbook: a Web based tool for assessment and self-assessment\n", "abstract": " This paper introduces a Web application for creating and making use of on-line tests to evaluate learner\u2019s competency in different subjects by means of multiple choice questions. Its use is suitable within the academic environment in a blended-learning fashion both by tutors, for having an additional assessment tool, and by learners, for performing a distant selfassessment. Main features, architectural design, technical notes and future extensions of our application, called eWorkbook, are covered in this paper.", "num_citations": "1\n", "authors": ["1210"]}
{"title": "A Visual System for Designing and Realizing Adaptive Distance Courses\n", "abstract": " We propose a visual language based approach to support the instructional during the definition, designing and organization of distance courses. Three visual languages are presented, which allow us to model a set of didactic contents by taking into account the learner knowledge. A system prototype supporting the proposed approach is also described. It assists instructional designer in the definition of adaptive learning processes and automatically generates the designed distance courses.", "num_citations": "1\n", "authors": ["1210"]}
{"title": "The development of hierarchical visual languages\n", "abstract": " The development of a visual language requires a specification of its syntax and semantics and the implementation of a visual environment which embeds it. In the present paper we describe VLCC, a graphical system for the automatic generation of visual programming environments. We show that the system is able to support the development of complex real-world visual languages which exhibit hierarchical aspects, such as Statecharts and UML notations.", "num_citations": "1\n", "authors": ["1210"]}
{"title": "Grammatical inference for the automatic generation of visual languages\n", "abstract": " In this paper we address the problem of the automatic generation of visual languages from a sample set of visual sentences. We present an improvement of the inference module of the VLG system which was originally conceived for the generation of iconic languages [11]. With this extension any kind of visual languages, like diagrams and forms, can be considered. To this aim, we present an inference algorithm for the class of Boundary SR grammars. These grammars are a subclass of the SR grammars with the interesting property of confluence, which extends the concept of context-freeness to the case of nonlinear grammars. Moreover, in spite of the simplicity and naturalness of the formalism, the generative power of this class is sufficient to specify interesting visual languages.           The inference algorithm exploits an elegant characterization of Boundary SR languages in terms of tree and string languages. More\u00a0\u2026", "num_citations": "1\n", "authors": ["1210"]}
{"title": "On the generation and recognition of visual languages: relation grammars and related approaches\n", "abstract": " A visual language is conceived as a collection of sentences composed of pictorial elements related in two or more dimensions (see, eg, Chang, 1990). A common approach to the formal description of visual languages makes use of formal grammars and rewriting mechanisms able to generate this kind of sentences. Such an approach allows those languages to be used with general syntactic specification mechanisms. As it was the case for traditional programming languages, formal models for visual languages allow for the automatic creation of lexical analyzers, parsers, semantic analyzers, syntax-driven visual programming environments, etc.It is commonly accepted that the main difficulty in dealing with visual languages is the non-sequential nature of the sentences whose symbols can be related by several relationships rather than the only adjacency typical of string languages. This problem has been addressed\u00a0\u2026", "num_citations": "1\n", "authors": ["1210"]}