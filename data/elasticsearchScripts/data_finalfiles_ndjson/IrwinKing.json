{"title": "Recommender systems with social regularization\n", "abstract": " Although Recommender Systems have been comprehensively analyzed in the past decade, the study of social-based recommender systems just started. In this paper, aiming at providing a general method for improving recommender systems by incorporating social network information, we propose a matrix factorization framework with social regularization. The contributions of this paper are four-fold:(1) We elaborate how social network information can benefit recommender systems;(2) We interpret the differences between social-based recommender systems and trust-aware recommender systems;(3) We coin the term Social Regularization to represent the social constraints on recommender systems, and we systematically illustrate how to design a matrix factorization objective function with social regularization; and (4) The proposed method is quite general, which can be easily extended to incorporate other\u00a0\u2026", "num_citations": "1678\n", "authors": ["1175"]}
{"title": "Sorec: social recommendation using probabilistic matrix factorization\n", "abstract": " Data sparsity, scalability and prediction quality have been recognized as the three most crucial challenges that every collaborative filtering algorithm or recommender system confronts. Many existing approaches to recommender systems can neither handle very large datasets nor easily deal with users who have made very few ratings or even none at all. Moreover, traditional recommender systems assume that all the users are independent and identically distributed; this assumption ignores the social interactions or connections among users. In view of the exponential growth of information generated by online social networks, social network analysis is becoming important for many Web applications. Following the intuition that a person's social network will affect personal behaviors on the Web, this paper proposes a factor analysis approach based on probabilistic matrix factorization to solve the data sparsity and\u00a0\u2026", "num_citations": "1528\n", "authors": ["1175"]}
{"title": "Learning to recommend with social trust ensemble\n", "abstract": " As an indispensable technique in the field of Information Filtering, Recommender System has been well studied and developed both in academia and in industry recently. However, most of current recommender systems suffer the following problems:(1) The large-scale and sparse data of the user-item matrix seriously affect the recommendation quality. As a result, most of the recommender systems cannot easily deal with users who have made very few ratings.(2) The traditional recommender systems assume that all the users are independent and identically distributed; this assumption ignores the connections among users, which is not consistent with the real world recommendations. Aiming at modeling recommender systems more accurately and realistically, we propose a novel probabilistic factor analysis framework, which naturally fuses the users' tastes and their trusted friends' favors together. In this framework\u00a0\u2026", "num_citations": "983\n", "authors": ["1175"]}
{"title": "Fused matrix factorization with geographical and social influence in location-based social networks\n", "abstract": " Recently, location-based social networks (LBSNs), such as Gowalla, Foursquare, Facebook, and Brightkite, etc., have attracted millions of users to share their social friendship and their locations via check-ins. The available check-in information makes it possible to mine users\u2019 preference on locations and to provide favorite recommendations. Personalized Point-of-interest (POI) recommendation is a significant task in LBSNs since it can help targeted users explore their surroundings as well as help third-party developers to provide personalized services. To solve this task, matrix factorization is a promising tool due to its success in recommender systems. However, previously proposed matrix factorization (MF) methods do not explore geographical influence, eg, multi-center check-in property, which yields suboptimal solutions for the recommendation. In this paper, to the best of our knowledge, we are the first to fuse MF with geographical and social influence for POI recommendation in LBSNs. We first capture the geographical influence via modeling the probability of a user\u2019s check-in on a location as a Multi-center Gaussian Model (MGM). Next, we include social information and fuse the geographical influence into a generalized matrix factorization framework. Our solution to POI recommendation is efficient and scales linearly with the number of observations. Finally, we conduct thorough experiments on a large-scale real-world LBSNs dataset and demonstrate that the fused matrix factorization framework with MGM utilizes the distance information sufficiently and outperforms other state-of-the-art methods significantly.", "num_citations": "659\n", "authors": ["1175"]}
{"title": "Effective missing data prediction for collaborative filtering\n", "abstract": " Memory-based collaborative filtering algorithms have been widely adopted in many popular recommender systems, although these approaches all suffer from data sparsity and poor prediction quality problems. Usually, the user-item matrix is quite sparse, which directly leads to inaccurate recommendations. This paper focuses the memory-based collaborative filtering problems on two crucial factors:(1) similarity computation between users or items and (2) missing data prediction algorithms. First, we use the enhanced Pearson Correlation Coefficient (PCC) algorithm by adding one parameter which overcomes the potential decrease of accuracy when computing the similarity of users or items. Second, we propose an effective missing data prediction algorithm, in which information of both users and items is taken into account. In this algorithm, we set the similarity threshold for users and items respectively, and the\u00a0\u2026", "num_citations": "607\n", "authors": ["1175"]}
{"title": "Where you like to go next: Successive point-of-interest recommendation\n", "abstract": " Personalized point-of-interest (POI) recommendation is a significant task in location-based social networks (LBSNs) as it can help provide better user experience as well as enable third-party services, eg, launching advertisements. To provide a good recommendation, various research has been conducted in the literature. However, pervious efforts mainly consider the \u201ccheck-ins\u201d in a whole and omit their temporal relation. They can only recommend POI globally and cannot know where a user would like to go tomorrow or in the next few days. In this paper, we consider the task of successive personalized POI recommendation in LBSNs, which is a much harder task than standard personalized POI recommendation or prediction. To solve this task, we observe two prominent properties in the check-in sequence: personalized Markov chain and region localization. Hence, we propose a novel matrix factorization method, namely FPMCLR, to embed the personalized Markov chains and the localized regions. Our proposed FPMC-LR not only exploits the personalized Markov chain in the check-in sequence, but also takes into account users\u2019 movement constraint, ie, moving around a localized region. More importantly, utilizing the information of localized regions, we not only reduce the computation cost largely, but also discard the noisy information to boost recommendation. Results on two real-world LBSNs datasets demonstrate the merits of our proposed FPMC-LR.", "num_citations": "542\n", "authors": ["1175"]}
{"title": "A survey of crowdsourcing systems\n", "abstract": " Crowd sourcing is evolving as a distributed problem-solving and business production model in recent years. In crowd sourcing paradigm, tasks are distributed to networked people to complete such that a company's production cost can be greatly reduced. In 2003, Luis von Ahn and his colleagues pioneered the concept of \"human computation\", which utilizes human abilities to perform computation tasks that are difficult for computers to process. Later, the term \"crowdsourcing\" was coined by Jeff Howe in 2006. Since then, a lot of work in crowd sourcing has focused on different aspects of crowd sourcing, such as computational techniques and performance analysis. In this paper, we give a survey on the literature on crowd sourcing which are categorized according to their applications, algorithms, performances and datasets. This paper provides a structured view of the research on crowd sourcing to date.", "num_citations": "514\n", "authors": ["1175"]}
{"title": "Discriminative semi-supervised feature selection via manifold regularization\n", "abstract": " Feature selection has attracted a huge amount of interest in both research and application communities of data mining. We consider the problem of semi-supervised feature selection, where we are given a small amount of labeled examples and a large amount of unlabeled examples. Since a small number of labeled samples are usually insufficient for identifying the relevant features, the critical problem arising from semi-supervised feature selection is how to take advantage of the information underneath the unlabeled data. To address this problem, we propose a novel discriminative semi-supervised feature selection method based on the idea of manifold regularization. The proposed approach selects features through maximizing the classification margin between different classes and simultaneously exploiting the geometry of the probability distribution that generates both labeled and unlabeled data. In\u00a0\u2026", "num_citations": "364\n", "authors": ["1175"]}
{"title": "Ratings meet reviews, a combined approach to recommend\n", "abstract": " Most existing recommender systems focus on modeling the ratings while ignoring the abundant information embedded in the review text. In this paper, we propose a unified model that combines content-based filtering with collaborative filtering, harnessing the information of both ratings and reviews. We apply topic modeling techniques on the review text and align the topics with rating dimensions to improve prediction accuracy. With the information embedded in the review text, we can alleviate the cold-start problem. Furthermore, our model is able to learn latent topics that are interpretable. With these interpretable topics, we can explore the prior knowledge on items or users and recommend completely\" cold\"'items. Empirical study on 27 classes of real-life datasets show that our proposed model lead to significant improvement compared with strong baseline methods, especially for datasets which are extremely\u00a0\u2026", "num_citations": "334\n", "authors": ["1175"]}
{"title": "Leveraging social connections to improve personalized ranking for collaborative filtering\n", "abstract": " Recommending products to users means estimating their preferences for certain items over others. This can be cast either as a problem of estimating the rating that each user will give to each item, or as a problem of estimating users' relative preferences in the form of a ranking. Although collaborative-filtering approaches can be used to identify users who rate and rank products similarly, another source of data that informs us about users' preferences is their set of social connections. Both rating-and ranking-based paradigms are important in real-world recommendation settings, though rankings are especially important in settings where explicit feedback in the form of a numerical rating may not be available. Although many existing works have studied how social connections can be used to build better models for rating prediction, few have used social connections as a means to derive more accurate ranking-based\u00a0\u2026", "num_citations": "321\n", "authors": ["1175"]}
{"title": "Simple and efficient multiple kernel learning by group lasso\n", "abstract": " We consider the problem of how to improve the efficiency of Multiple Kernel Learning (MKL). In literature, MKL is often solved by an alternating approach:(1) the minimization of the kernel weights is solved by complicated techniques, such as Semi-infinite Linear Programming, Gradient Descent, or Level method;(2) the maximization of SVM dual variables can be solved by standard SVM solvers. However, the minimization step in these methods is usually dependent on its solving techniques or commercial softwares, which therefore limits the efficiency and applicability. In this paper, we formulate a closed-form solution for optimizing the kernel weights based on the equivalence between group-lasso and MKL. Although this equivalence is not our invention, our derived variant equivalence not only leads to an efficient algorithm for MKL, but also generalizes to the case for Lp-MKL (p\u2265 1 and denoting the Lp-norm of kernel weights). Therefore, our proposed algorithm provides a unified solution for the entire family of Lp-MKL models. Experiments on multiple data sets show the promising performance of the proposed technique compared with other competitive methods.", "num_citations": "304\n", "authors": ["1175"]}
{"title": "Mining social networks using heat diffusion processes for marketing candidates selection\n", "abstract": " Social Network Marketing techniques employ pre-existing social networks to increase brands or products awareness through word-of-mouth promotion. Full understanding of social network marketing and the potential candidates that can thus be marketed to certainly offer lucrative opportunities for prospective sellers. Due to the complexity of social networks, few models exist to interpret social network marketing realistically. We propose to model social network marketing using Heat Diffusion Processes. This paper presents three diffusion models, along with three algorithms for selecting the best individuals to receive marketing samples. These approaches have the following advantages to best illustrate the properties of real-world social networks:(1) We can plan a marketing strategy sequentially in time since we include a time factor in the simulation of product adoptions;(2) The algorithm of selecting marketing\u00a0\u2026", "num_citations": "304\n", "authors": ["1175"]}
{"title": "Gaan: Gated attention networks for learning on large and spatiotemporal graphs\n", "abstract": " We propose a new network architecture, Gated Attention Networks (GaAN), for learning on graphs. Unlike the traditional multi-head attention mechanism, which equally consumes all attention heads, GaAN uses a convolutional sub-network to control each attention head's importance. We demonstrate the effectiveness of GaAN on the inductive node classification problem. Moreover, with GaAN as a building block, we construct the Graph Gated Recurrent Unit (GGRU) to address the traffic speed forecasting problem. Extensive experiments on three real-world datasets show that our GaAN framework achieves state-of-the-art results on both tasks.", "num_citations": "295\n", "authors": ["1175"]}
{"title": "Improving recommender systems by incorporating social contextual information\n", "abstract": " Due to their potential commercial value and the associated great research challenges, recommender systems have been extensively studied by both academia and industry recently. However, the data sparsity problem of the involved user-item matrix seriously affects the recommendation quality. Many existing approaches to recommender systems cannot easily deal with users who have made very few ratings. In view of the exponential growth of information generated by online users, social contextual information analysis is becoming important for many Web applications. In this article, we propose a factor analysis approach based on probabilistic matrix factorization to alleviate the data sparsity and poor prediction accuracy problems by incorporating social contextual information, such as social networks and social tags. The complexity analysis indicates that our approach can be applied to very large datasets since\u00a0\u2026", "num_citations": "277\n", "authors": ["1175"]}
{"title": "Support vector machine regression for volatile stock market prediction\n", "abstract": " Recently, Support Vector Regression (SVR) has been introduced to solve regression and prediction problems. In this paper, we apply SVR to financial prediction tasks. In particular, the financial data are usually noisy and the associated risk is time-varying. Therefore, our SVR model is an extension of the standard SVR which incorporates margins adaptation. By varying the margins of the SVR, we could reflect the change in volatility of the financial data. Furthermore, we have analyzed the effect of asymmetrical margins so as to allow for the reduction of the downside risk. Our experimental results show that the use of standard deviation to calculate a variable margin gives a good predictive result in the prediction of Hang Seng Index.", "num_citations": "249\n", "authors": ["1175"]}
{"title": "Dynamic key-value memory networks for knowledge tracing\n", "abstract": " Knowledge Tracing (KT) is a task of tracing evolving knowledge state of students with respect to one or more concepts as they engage in a sequence of learning activities. One important purpose of KT is to personalize the practice sequence to help students learn knowledge concepts efficiently. However, existing methods such as Bayesian Knowledge Tracing and Deep Knowledge Tracing either model knowledge state for each predefined concept separately or fail to pinpoint exactly which concepts a student is good at or unfamiliar with. To solve these problems, this work introduces a new model called Dynamic Key-Value Memory Networks (DKVMN) that can exploit the relationships between underlying concepts and directly output a student's mastery level of each concept. Unlike standard memory-augmented neural networks that facilitate a single memory matrix or two static memory matrices, our model has one\u00a0\u2026", "num_citations": "226\n", "authors": ["1175"]}
{"title": "Learning to recommend with trust and distrust relationships\n", "abstract": " With the exponential growth of Web contents, Recommender System has become indispensable for discovering new information that might interest Web users. Despite their success in the industry, traditional recommender systems suffer from several problems. First, the sparseness of the user-item matrix seriously affects the recommendation quality. Second, traditional recommender systems ignore the connections among users, which loses the opportunity to provide more accurate and personalized recommendations. In this paper, aiming at providing more realistic and accurate recommendations, we propose a factor analysis-based optimization framework to incorporate the user trust and distrust relationships into the recommender systems. The contributions of this paper are three-fold:(1) We elaborate how user distrust information can benefit the recommender systems.(2) In terms of the trust relations, distinct from\u00a0\u2026", "num_citations": "220\n", "authors": ["1175"]}
{"title": "Routing questions to appropriate answerers in community question answering services\n", "abstract": " Community Question Answering (CQA) service provides a platform for increasing number of users to ask and answer for their own needs but unanswered questions still exist within a fixed period. To address this, the paper aims to route questions to the right answerers who have a top rank in accordance of their previous answering performance. In order to rank the answerers, we propose a framework called Question Routing (QR) which consists of four phases:(1) performance profiling,(2) expertise estimation,(3) availability estimation, and (4) answerer ranking. Applying the framework, we conduct experiments with Yahoo! Answers dataset and the results demonstrate that on average each of 1,713 testing questions obtains at least one answer if it is routed to the top 20 ranked answerers.", "num_citations": "215\n", "authors": ["1175"]}
{"title": "STELLAR: Spatial-temporal latent ranking for successive point-of-interest recommendation\n", "abstract": " Successive point-of-interest (POI) recommendation in location-based social networks (LBSNs) becomes a significant task since it helps users to navigate a number of candidate POIs and provides the best POI recommendations based on users\u2019 most recent check-in knowledge. However, all existing methods for successive POI recommendation only focus on modeling the correlation between POIs based on users\u2019 check-in sequences, but ignore an important fact that successive POI recommendation is a time-subtle recommendation task. In fact, even with the same previous check-in information, users would prefer different successive POIs at different time. To capture the impact of time on successive POI recommendation, in this paper, we propose a spatial-temporal latent ranking (STELLAR) method to explicitly model the interactions among user, POI, and time. In particular, the proposed STELLAR model is built upon a ranking-based pairwise tensor factorization framework with a fine-grained modeling of user-POI, POI-time, and POI-POI interactions for successive POI recommendation. Moreover, we propose a new interval-aware weight utility function to differentiate successive check-ins\u2019 correlations, which breaks the time interval constraint in prior work. Evaluations on two real-world datasets demonstrate that the STELLAR model outperforms state-of-the-art successive POI recommendation model about 20% in Precision@ 5 and Recall@ 5.", "num_citations": "205\n", "authors": ["1175"]}
{"title": "Formal models for expert finding on dblp bibliography data\n", "abstract": " Finding relevant experts in a specific field is often crucial for consulting, both in industry and in academia. The aim of this paper is to address the expert-finding task in a real world academic field. We present three models for expert finding based on the large-scale DBLP bibliography and Google scholar for data supplementation. The first, a novel weighted language model, models an expert candidate based on the relevance and importance of associated documents by introducing a document prior probability, and achieves much better results than the basic language model. The second, a topic-based model, represents each candidate as a weighted sum of multiple topics, whilst the third, a hybrid model, combines the language model and the topic-based model. We evaluate our system using a benchmark dataset based on human relevance judgments of how well the expertise of proposed experts matches a query\u00a0\u2026", "num_citations": "205\n", "authors": ["1175"]}
{"title": "Learning to recommend with explicit and implicit social relations\n", "abstract": " Recommender systems have been well studied and developed, both in academia and in industry recently. However, traditional recommender systems assume that all the users are independent and identically distributed; this assumption ignores the connections among users, which is not consistent with the real-world observations where we always turn to our trusted friends for recommendations. Aiming at modeling recommender systems more accurately and realistically, we propose a novel probabilistic factor analysis framework which naturally fuses the users' tastes and their trusted friends' favors together. The proposed framework is quite general, and it can also be applied to pure user-item rating matrix even if we do not have explicit social trust information among users. In this framework, we coin the term social trust ensemble to represent the formulation of the social trust restrictions on the recommender\u00a0\u2026", "num_citations": "183\n", "authors": ["1175"]}
{"title": "A generalized co-hits algorithm and its application to bipartite graphs\n", "abstract": " Recently many data types arising from data mining and Web search applications can be modeled as bipartite graphs. Examples include queries and URLs in query logs, and authors and papers in scientific literature. However, one of the issues is that previous algorithms only consider the content and link information from one side of the bipartite graph. There is a lack of constraints to make sure the final relevance of the score propagation on the graph, as there are many noisy edges within the bipartite graph. In this paper, we propose a novel and general Co-HITS algorithm to incorporate the bipartite graph with the content information from both sides as well as the constraints of relevance. Moreover, we investigate the algorithm based on two frameworks, including the iterative and the regularization frameworks, and illustrate the generalized Co-HITS algorithm from different views. For the iterative framework, it\u00a0\u2026", "num_citations": "173\n", "authors": ["1175"]}
{"title": "Localized support vector regression for time series prediction\n", "abstract": " Time series prediction, especially financial time series prediction, is a challenging task in machine learning. In this issue, the data are usually non-stationary and volatile in nature. Because of its good generalization power, the support vector regression (SVR) has been widely applied in this application. The standard SVR employs a fixed \u03b5-tube to tolerate noise and adopts the \u2113 p-norm (p= 1 or 2) to model the functional complexity of the whole data set. One problem of the standard SVR is that it considers data in a global fashion only. Therefore it may lack the flexibility to capture the local trend of data; this is a critical aspect of volatile data, especially financial time series data. Aiming to attack this issue, we propose the localized support vector regression (LSVR) model. This novel model is demonstrated to provide a systematic and automatic scheme to adapt the margin locally and flexibly; while the margin in the\u00a0\u2026", "num_citations": "166\n", "authors": ["1175"]}
{"title": "Bridging the semantic gap between image contents and tags\n", "abstract": " With the exponential growth of Web 2.0 applications, tags have been used extensively to describe the image contents on the Web. Due to the noisy and sparse nature in the human generated tags, how to understand and utilize these tags for image retrieval tasks has become an emerging research direction. As the low-level visual features can provide fruitful information, they are employed to improve the image retrieval results. However, it is challenging to bridge the semantic gap between image contents and tags. To attack this critical problem, we propose a unified framework in this paper which stems from a two-level data fusions between the image contents and tags: 1) A unified graph is built to fuse the visual feature-based image similarity graph with the image-tag bipartite graph; 2) A novel random walk model is then proposed, which utilizes a fusion parameter to balance the influences between the image\u00a0\u2026", "num_citations": "158\n", "authors": ["1175"]}
{"title": "Geo-teaser: Geo-temporal sequential embedding rank for point-of-interest recommendation\n", "abstract": " Point-of-interest (POI) recommendation is an important application for location-based social networks (LBSNs), which learns the user preference and mobility pattern from check-in sequences to recommend POIs. Previous studies show that modeling the sequential pattern of user check-ins is necessary for POI recommendation. Markov chain model, recurrent neural network, and the word2vec framework are used to model check-in sequences in previous work. However, all previous sequential models ignore the fact that check-in sequences on different days naturally exhibit the various temporal characteristics, for instance,\" work\" on weekday and\" entertainment\" on weekend. In this paper, we take this challenge and propose a Geo-Temporal sequential embedding rank (Geo-Teaser) model for POI recommendation. Inspired by the success of the word2vec framework to model the sequential contexts, we propose a\u00a0\u2026", "num_citations": "154\n", "authors": ["1175"]}
{"title": "Learning classifiers from imbalanced data based on biased minimax probability machine\n", "abstract": " We consider the problem of the binary classification on imbalanced data, in which nearly all the instances are labelled as one class, while far fewer instances are labelled as the other class, usually the more important class. Traditional machine learning methods seeking an accurate performance over a full range of instances are not suitable to deal with this problem, since they tend to classify all the data into the majority, usually the less important class. Moreover, some current methods have tried to utilize some intermediate factors, e.g., the distribution of the training set, the decision thresholds or the cost matrices, to influence the bias of the classification. However, it remains uncertain whether these methods can improve the performance in a systematic way. In this paper, we propose a novel model named biased minimax probability machine. Different from previous methods, this model directly controls the worst\u00a0\u2026", "num_citations": "135\n", "authors": ["1175"]}
{"title": "Learning latent semantic relations from clickthrough data for query suggestion\n", "abstract": " For a given query raised by a specific user, the Query Suggestion technique aims to recommend relevant queries which potentially suit the information needs of that user. Due to the complexity of the Web structure and the ambiguity of users' inputs, most of the suggestion algorithms suffer from the problem of poor recommendation accuracy. In this paper, aiming at providing semantically relevant queries for users, we develop a novel, effective and efficient two-level query suggestion model by mining clickthrough data, in the form of two bipartite graphs (user-query and query-URL bipartite graphs) extracted from the clickthrough data. Based on this, we first propose a joint matrix factorization method which utilizes two bipartite graphs to learn the low-rank query latent feature space, and then build a query similarity graph based on the features. After that, we design an online ranking algorithm to propagate similarities on\u00a0\u2026", "num_citations": "134\n", "authors": ["1175"]}
{"title": "Analyzing and predicting question quality in community question answering services\n", "abstract": " Users tend to ask and answer questions in community question answering (CQA) services to seek information and share knowledge. A corollary is that myriad of questions and answers appear in CQA service. Accordingly, volumes of studies have been taken to explore the answer quality so as to provide a preliminary screening for better answers. However, to our knowledge, less attention has so far been paid to question quality in CQA. Knowing question quality provides us with finding and recommending good questions together with identifying bad ones which hinder the CQA service. In this paper, we are conducting two studies to investigate the question quality issue. The first study analyzes the factors of question quality and finds that the interaction between askers and topics results in the differences of question quality. Based on this finding, in the second study we propose a Mutual Reinforcement-based Label\u00a0\u2026", "num_citations": "132\n", "authors": ["1175"]}
{"title": "A survey of human computation systems\n", "abstract": " Human computation is a technique that makes use of human abilities for computation to solve problems. The human computation problems are the problems those computers are not good at solving but are trivial for humans. In this paper, we give a survey of various human computation systems which are categorized into initiatory human computation, distributed human computation and social game-based human computation with volunteers, paid engineers and online players. For the existing large number of social games, some previous works defined various types of social games, but the recent developed social games cannot be categorized based on the previous works. In this paper, we define the categories and the characteristics of social games which are suitable for all existing ones. Besides, we present a survey on the performance aspects of human computation system. This paper gives a better\u00a0\u2026", "num_citations": "132\n", "authors": ["1175"]}
{"title": "A classification-based approach to question routing in community question answering\n", "abstract": " Community-based Question and Answering (CQA) services have brought users to a new era of knowledge dissemination by allowing users to ask questions and to answer other users' questions. However, due to the fast increasing of posted questions and the lack of an effective way to find interesting questions, there is a serious gap between posted questions and potential answerers. This gap may degrade a CQA service's performance as well as reduce users' loyalty to the system. To bridge the gap, we present a new approach to Question Routing, which aims at routing questions to participants who are likely to provide answers. We consider the problem of question routing as a classification task, and develop a variety of local and global features which capture different aspects of questions, users, and their relations. Our experimental results obtained from an evaluation over the Yahoo!~ Answers dataset\u00a0\u2026", "num_citations": "126\n", "authors": ["1175"]}
{"title": "Magnn: Metapath aggregated graph neural network for heterogeneous graph embedding\n", "abstract": " A large number of real-world graphs or networks are inherently heterogeneous, involving a diversity of node types and relation types. Heterogeneous graph embedding is to embed rich structural and semantic information of a heterogeneous graph into low-dimensional node representations. Existing models usually define multiple metapaths in a heterogeneous graph to capture the composite relations and guide neighbor selection. However, these models either omit node content features, discard intermediate nodes along the metapath, or only consider one metapath. To address these three limitations, we propose a new model named Metapath Aggregated Graph Neural Network (MAGNN) to boost the final performance. Specifically, MAGNN employs three major components, ie, the node content transformation to encapsulate input node attributes, the intra-metapath aggregation to incorporate intermediate\u00a0\u2026", "num_citations": "125\n", "authors": ["1175"]}
{"title": "A brief survey of computational approaches in social computing\n", "abstract": " Web 2.0 technologies have brought new ways of connecting people in social networks for collaboration in various on-line communities. Social Computing is a novel and emerging computing paradigm that involves a multi-disciplinary approach in analyzing and modeling social behaviors on different media and platforms to produce intelligent and interactive applications and results. In this paper, we give a brief survey of the various machine learning and computational techniques used in Social Computing by first examining the social platforms, e.g., social network sites, social media, social games, social bookmarking, and social knowledge sites, where computational methodology is required to collect, extract, process, mine, and visualize the data. We then present surveys on more specific instances of computation tasks and techniques, e.g., social network analysis, link modeling and mining, ranking, sentiment\u00a0\u2026", "num_citations": "120\n", "authors": ["1175"]}
{"title": "Diffusionrank: a possible penicillin for web spamming\n", "abstract": " While the PageRank algorithm has proven to be very effective for ranking Web pages, the rank scores of Web pages can be manipulated. To handle the manipulation problem and to cast a new insight on the Web structure, we propose a ranking algorithm called DiffusionRank. DiffusionRank is motivated by the heat diffusion phenomena, which can be connected to Web ranking because the activities flow on the Web can be imagined as heat flow, the link from a page to another can be treated as the pipe of an air-conditioner, and heat flow can embody the structure of the underlying Web graph. Theoretically we show that DiffusionRank can serve as a generalization of PageRank when the heat diffusion co-efficient \u03b3 tends to infinity. In such a case 1= \u03b3= 0, DiffusionRank (PageRank) has low ability of anti-manipulation. When \u03b3= 0, DiffusionRank obtains the highest ability of anti-manipulation, but in such a case, the\u00a0\u2026", "num_citations": "112\n", "authors": ["1175"]}
{"title": "Task recommendation in crowdsourcing systems\n", "abstract": " In crowdsourcing systems, tasks are distributed to networked people to complete such that a company's production cost can be greatly reduced. Obviously, it is not efficient that the amount of time for a worker spent on selecting a task is comparable with that spent on working on a task, but the monetary reward of a task is just a small amount. The available worker history makes it possible to mine workers' preference on tasks and to provide favorite recommendations. Our exploratory study on the survey results collected from Amazon Mechanical Turk (MTurk) shows that workers' histories can reflect workers' preferences on tasks in crowdsourcing systems. Task recommendation can help workers to find their right tasks faster as well as help requesters to receive good quality output quicker. However, previously proposed classification based task recommendation approach only considers worker performance history, but\u00a0\u2026", "num_citations": "105\n", "authors": ["1175"]}
{"title": "Task matching in crowdsourcing\n", "abstract": " Crowd sourcing is evolving as a distributed problem-solving and business production model in recent years. In crowd sourcing paradigm, tasks are distributed to networked people to complete such that a company's production cost can be greatly reduced. A crowd sourcing process involves operations of both requesters and workers. A requester submits a task request, a worker selects and completes a task, and the requester only pays the worker for the successful completion of the task. Obviously, it is not efficient that the amount of time spent on selecting a task is comparable with that spent on working on a task, but the monetary reward of a task is just a small amount. Literature mainly focused on exploring what type of tasks can be deployed to the crowd and analyzing the performance of crowd sourcing platforms. However, no existing work investigates on how to support workers to select tasks on crowd sourcing\u00a0\u2026", "num_citations": "99\n", "authors": ["1175"]}
{"title": "Aspect-level sentiment classification with heat (hierarchical attention) network\n", "abstract": " Aspect-level sentiment classification is a fine-grained sentiment analysis task, which aims to predict the sentiment of a text in different aspects. One key point of this task is to allocate the appropriate sentiment words for the given aspect. Recent work exploits attention neural networks to allocate sentiment words and achieves the state-of-the-art performance. However, the prior work only attends to the sentiment information and ignores the aspect-related information in the text, which may cause mismatching between the sentiment words and the aspects when an unrelated sentiment word is semantically meaningful for the given aspect. To solve this problem, we propose a HiErarchical ATtention (HEAT) network for aspect-level sentiment classification. The HEAT network contains a hierarchical attention module, consisting of aspect attention and sentiment attention. The aspect attention extracts the aspect-related\u00a0\u2026", "num_citations": "98\n", "authors": ["1175"]}
{"title": "A social recommendation framework based on multi-scale continuous conditional random fields\n", "abstract": " This paper addresses the issue of social recommendation based on collaborative filtering (CF) algorithms. Social recommendation emphasizes utilizing various attributes information and relations in social networks to assist recommender systems. Although recommendation techniques have obtained distinct developments over the decades, traditional CF algorithms still have these following two limitations:(1) relational dependency within predictions, an important factor especially when the data is sparse, is not being utilized effectively; and (2) straightforward methods for combining features like linear integration suffer from high computing complexity in learning the weights by enumerating the whole value space, making it difficult to combine various information into an unified approach. In this paper, we propose a novel model, Multi-scale Continuous Conditional Random Fields (MCCRF), as a framework to solve\u00a0\u2026", "num_citations": "96\n", "authors": ["1175"]}
{"title": "Probabilistic factor models for web site recommendation\n", "abstract": " Due to the prevalence of personalization and information filtering applications, modeling users' interests on the Web has become increasingly important during the past few years. In this paper, aiming at providing accurate personalized Web site recommendations for Web users, we propose a novel probabilistic factor model based on dimensionality reduction techniques. We also extend the proposed method to collective probabilistic factor modeling, which further improves model performance by incorporating heterogeneous data sources. The proposed method is general, and can be applied to not only Web site recommendations, but also a wide range of Web applications, including behavioral targeting, sponsored search, etc. The experimental analysis on Web site recommendation shows that our method outperforms other traditional recommendation approaches. Moreover, the complexity analysis indicates that\u00a0\u2026", "num_citations": "94\n", "authors": ["1175"]}
{"title": "Efficient sparse generalized multiple kernel learning\n", "abstract": " Kernel methods have been successfully applied in various applications. To succeed in these applications, it is crucial to learn a good kernel representation, whose objective is to reveal the data similarity precisely. In this paper, we address the problem of multiple kernel learning (MKL), searching for the optimal kernel combination weights through maximizing a generalized performance measure. Most MKL methods employ the -norm simplex constraints on the kernel combination weights, which therefore involve a sparse but non-smooth solution for the kernel weights. Despite the success of their efficiency, they tend to discard informative complementary or orthogonal base kernels and yield degenerated generalization performance. Alternatively, imposing the -norm constraint on the kernel weights will keep all the information in the base kernels. This leads to non-sparse solutions and brings the risk of being sensitive\u00a0\u2026", "num_citations": "94\n", "authors": ["1175"]}
{"title": "Distributed content-based visual information retrieval system on peer-to-peer networks\n", "abstract": " With the recent advances of distributed computing, the limitation of information retrieval from a centralized image collection can be removed by allowing distributed image data sources to interact with each other for data storage sharing and information retrieval. In this article, we present our design and implementation of DISCOVIR: DIStributed COntent-based Visual Information Retrieval system using the Peer-to-Peer (P2P) Network. We describe the system architecture and detail the interactions among various system modules. Specifically, we propose a Firework Query Model for distributed information retrieval, which aims to reduce the network traffic of query passing in the network. We carry out experiments to show the distributed image retrieval system and the Firework information retrieval algorithm. The results show that the algorithm reduces network traffic while increases searching performance.", "num_citations": "93\n", "authors": ["1175"]}
{"title": "Maxi\u2013min margin machine: learning large margin classifiers locally and globally\n", "abstract": " In this paper, we propose a novel large margin classifier, called the maxi-min margin machine (M 4 ). This model learns the decision boundary both locally and globally. In comparison, other large margin classifiers construct separating hyperplanes only either locally or globally. For example, a state-of-the-art large margin classifier, the support vector machine (SVM), considers data only locally, while another significant model, the minimax probability machine (MPM), focuses on building the decision hyperplane exclusively based on the global information. As a major contribution, we show that SVM yields the same solution as M 4  when data satisfy certain conditions, and MPM can be regarded as a relaxation model of M 4 . Moreover, based on our proposed local and global view of data, another popular model, the linear discriminant analysis, can easily be interpreted and extended as well. We describe the M 4\u00a0\u2026", "num_citations": "88\n", "authors": ["1175"]}
{"title": "A distance measure for video sequences\n", "abstract": " Video is a unique multimedia data type, in that it comes with distinguished spatio-temporal constraints. Content-based video retrieval thus requires methods for video sequence-to-sequence matching, incorporating the temporal ordering inherent in a video sequence, without losing sight of the visual nature of the information in the sequence. Such methods will require reliable measures of similarity between the video sequences. In this paper, we formulate the problem of video sequence-to-sequence matching as a pattern-matching problem and propose the vstring edit distance as a suitable distance measure for video sequences.", "num_citations": "87\n", "authors": ["1175"]}
{"title": "Imbalanced learning with a biased minimax probability machine\n", "abstract": " Imbalanced learning is a challenged task in machine learning. In this context, the data associated with one class are far fewer than those associated with the other class. Traditional machine learning methods seeking classification accuracy over a full range of instances are not suitable to deal with this problem, since they tend to classify all the data into a majority class, usually the less important class. In this correspondence, the authors describe a new approach named the biased minimax probability machine (BMPM) to deal with the problem of imbalanced learning. This BMPM model is demonstrated to provide an elegant and systematic way for imbalanced learning. More specifically, by controlling the accuracy of the majority class under all possible choices of class-conditional densities with a given mean and covariance matrix, this model can quantitatively and systematically incorporate a bias for the minority\u00a0\u2026", "num_citations": "83\n", "authors": ["1175"]}
{"title": "Mining web graphs for recommendations\n", "abstract": " As the exponential explosion of various contents generated on the Web, Recommendation techniques have become increasingly indispensable. Innumerable different kinds of recommendations are made on the Web every day, including movies, music, images, books recommendations, query suggestions, tags recommendations, etc. No matter what types of data sources are used for the recommendations, essentially these data sources can be modeled in the form of various types of graphs. In this paper, aiming at providing a general framework on mining Web graphs for recommendations, (1) we first propose a novel diffusion method which propagates similarities between different nodes and generates recommendations; (2) then we illustrate how to generalize different recommendation problems into our graph diffusion framework. The proposed framework can be utilized in many recommendation tasks on the\u00a0\u2026", "num_citations": "82\n", "authors": ["1175"]}
{"title": "Taskrec: A task recommendation framework in crowdsourcing systems\n", "abstract": " Crowdsourcing is evolving as a distributed problem-solving and business production model in recent years. In crowdsourcing paradigm, tasks are distributed to networked people to complete such that a company\u2019s production cost can be greatly reduced. In crowdsourcing systems, task recommendation can help workers to find their right tasks faster as well as help requesters to receive good quality output quicker. However, previously proposed classification based task recommendation approach, which is the only one in the literature, does not consider the dynamic scenarios of new workers and new tasks in the crowdsourcing system. In this paper, we propose a Task Recommendation (TaskRec) framework based on a unified probabilistic matrix factorization, aiming to recommend tasks to workers in dynamic scenarios. Unlike traditional recommendation systems, workers do not provide their ratings on\u00a0\u2026", "num_citations": "80\n", "authors": ["1175"]}
{"title": "Entropy-biased models for query representation on the click graph\n", "abstract": " Query log analysis has received substantial attention in recent years, in which the click graph is an important technique for describing the relationship between queries and URLs. State-of-the-art approaches based on the raw click frequencies for modeling the click graph, however, are not noise-eliminated. Nor do they handle heterogeneous query-URL pairs well. In this paper, we investigate and develop a novel entropy-biased framework for modeling click graphs. The intuition behind this model is that various query-URL pairs should be treated differently, ie, common clicks on less frequent but more specific URLs are of greater value than common clicks on frequent and general URLs. Based on this intuition, we utilize the entropy information of the URLs and introduce a new concept, namely the inverse query frequency (IQF), to weigh the importance (discriminative ability) of a click on a certain URL. The IQF\u00a0\u2026", "num_citations": "80\n", "authors": ["1175"]}
{"title": "Star-gcn: Stacked and reconstructed graph convolutional networks for recommender systems\n", "abstract": " We propose a new STAcked and Reconstructed Graph Convolutional Networks (STAR-GCN) architecture to learn node representations for boosting the performance in recommender systems, especially in the cold start scenario. STAR-GCN employs a stack of GCN encoder-decoders combined with intermediate supervision to improve the final prediction performance. Unlike the graph convolutional matrix completion model with one-hot encoding node inputs, our STAR-GCN learns low-dimensional user and item latent factors as the input to restrain the model space complexity. Moreover, our STAR-GCN can produce node embeddings for new nodes by reconstructing masked input node embeddings, which essentially tackles the cold start problem. Furthermore, we discover a label leakage issue when training GCN-based models for link prediction tasks and propose a training strategy to avoid the issue. Empirical results on multiple rating prediction benchmarks demonstrate our model achieves state-of-the-art performance in four out of five real-world datasets and significant improvements in predicting ratings in the cold start scenario. The code implementation is available in https://github.com/jennyzhang0215/STAR-GCN.", "num_citations": "77\n", "authors": ["1175"]}
{"title": "A PCA approach for fast retrieval of structural patterns in attributed graphs\n", "abstract": " An attributed graph (AG) is a useful data structure for representing complex patterns in a wide range of applications such as computer vision, image database retrieval, and other knowledge representation tasks where similar or exact corresponding structural patterns must be found. Existing methods for attributed graph matching (AGM) often suffer from the combinatorial problem whereby the execution cost for finding an exact or similar match is exponentially related to the number of nodes the AG contains. The square matching error of two AGs subject to permutations is approximately relaxed to a square matching error of two AGs subject to orthogonal transformations. Hence, the principal component analysis (PCA) algorithm can be used for the fast computation of the approximate matching error, with a considerably reduced execution complexity. Experiments demonstrate that this method works well and is robust\u00a0\u2026", "num_citations": "75\n", "authors": ["1175"]}
{"title": "Non-monotonic feature selection\n", "abstract": " We consider the problem of selecting a subset of m most informative features where m is the number of required features. This feature selection problem is essentially a combinatorial optimization problem, and is usually solved by an approximation. Conventional feature selection methods address the computational challenge in two steps:(a) ranking all the features by certain scores that are usually computed independently from the number of specified features m, and (b) selecting the top m ranked features. One major shortcoming of these approaches is that if a feature f is chosen when the number of specified features is m, it will always be chosen when the number of specified features is larger than m. We refer to this property as the\" monotonic\" property of feature selection. In this work, we argue that it is important to develop efficient algorithms for non-monotonic feature selection. To this end, we develop an\u00a0\u2026", "num_citations": "72\n", "authors": ["1175"]}
{"title": "Learning large margin classifiers locally and globally\n", "abstract": " A new large margin classifier, named Maxi-Min Margin Machine (M 4) is proposed in this paper. This new classifier is constructed based on both a\" local: and a\" global\" view of data, while the most popular large margin classifier, Support Vector Machine (SVM) and the recently-proposed important model, Minimax Probability Machine (MPM) consider data only either locally or globally. This new model is theoretically important in the sense that SVM and MPM can both be considered as its special case. Furthermore, the optimization of M 4 can be cast as a sequential conic programming problem, which can be solved efficiently. We describe the M 4 model definition, provide a clear geometrical interpretation, present theoretical justifications, propose efficient solving methods, and perform a series of evaluations on both synthetic data sets and real world benchmark data sets. Its comparison with SVM and MPM also\u00a0\u2026", "num_citations": "72\n", "authors": ["1175"]}
{"title": "Gradient boosting factorization machines\n", "abstract": " Recommendation techniques have been well developed in the past decades. Most of them build models only based on user item rating matrix. However, in real world, there is plenty of auxiliary information available in recommendation systems. We can utilize these information as additional features to improve recommendation performance. We refer to recommendation with auxiliary information as context-aware recommendation. Context-aware Factorization Machines (FM) is one of the most successful context-aware recommendation models. FM models pairwise interactions between all features, in such way, a certain feature latent vector is shared to compute the factorized parameters it involved. In practice, there are tens of context features and not all the pairwise feature interactions are useful. Thus, one important challenge for context-aware recommendation is how to effectively select\" good\" interaction features\u00a0\u2026", "num_citations": "70\n", "authors": ["1175"]}
{"title": "Introduction to social recommendation\n", "abstract": " As the exponential growth of information generated on the World Wide Web, Social Recommendation has emerged as one of the hot research topics recently. Social Recommendation forms a specific type of information filtering technique that attempts to suggest information (blogs, news, music, travel plans, web pages, images, tags, etc.) that are likely to interest the users. Social Recommendation involves the investigation of collective intelligence by using computational techniques such as machine learning, data mining, natural language processing, etc. on social behavior data collected from blogs, wikis, recommender systems, question & answer communities, query logs, tags, etc. from areas such as social networks, social search, social media, social bookmarks, social news, social knowledge sharing, and social games. In this tutorial, we will introduce Social Recommendation and elaborate on how the various\u00a0\u2026", "num_citations": "67\n", "authors": ["1175"]}
{"title": "Modeling and exploiting heterogeneous bibliographic networks for expertise ranking\n", "abstract": " Recently expertise retrieval has received increasing interests in both academia and industry. Finding experts with demonstrated expertise for a given query is a nontrivial task especially from a large-scale Web 2.0 systems, such as question answering and bibliography data, where users are actively publishing useful content online, interacting with each other, and forming social networks in various ways, leading to heterogeneous networks in addition to the large amounts of textual content information. Many approaches have been proposed and shown to be useful for expertise ranking. However, most of these methods only consider the textual documents while ignoring heterogeneous network structures or can merely integrate with one additional kind of information. None of them can fully exploit the characteristics of heterogeneous networks. In this paper, we propose a joint regularization framework to enhance\u00a0\u2026", "num_citations": "64\n", "authors": ["1175"]}
{"title": "Online learning for collaborative filtering\n", "abstract": " Collaborative filtering (CF), aiming at predicting users' unknown preferences based on observational preferences from some users, has become one of the most successful methods to building recommender systems. Various approaches to CF have been proposed in this area, but seldom do they consider the dynamic scenarios: 1) new items arriving in the system, 2) new users joining the system; or 3) new rating updating the system are all dynamically obtained with respect to time. To capture these changes, in this paper, we develop an online learning framework for collaborative filtering. Specifically, we construct this framework consisting of two state-of-the-art matrix factorization based CF methods: the probabilistic matrix factorization and the top-one probability based ranking matrix factorization. Moreover, we demonstrate that the proposed online algorithms bring several attractive advantages: 1) they scale\u00a0\u2026", "num_citations": "62\n", "authors": ["1175"]}
{"title": "Machine learning: modeling data locally and globally\n", "abstract": " Machine Learning-Modeling Data Locally and Globally presents a novel and unified theory that tries to seamlessly integrate different algorithms. Specifically, the book distinguishes the inner nature of machine learning algorithms as either\" local learning\" or\" global learning.\" This theory not only connects previous machine learning methods, or serves as roadmap in various models, but\u2013more importantly\u2013it also motivates a theory that can learn from data both locally and globally. This would help the researchers gain a deeper insight and comprehensive understanding of the techniques in this field. The book reviews current topics, new theories and applications. Kaizhu Huang was a researcher at the Fujitsu Research and Development Center and is currently a research fellow in the Chinese University of Hong Kong. Haiqin Yang leads the image processing group at HiSilicon Technologies. Irwin King and Michael R. Lyu are professors at the Computer Science and Engineering department of the Chinese University of Hong Kong.", "num_citations": "62\n", "authors": ["1175"]}
{"title": "A distance measure for video sequence similarity matching\n", "abstract": " Contrary to current approaches which generally treat the video data as a random collection of static images, content-based video retrieval requires methods for video sequence-to-sequence matching incorporating the temporal order inherent in video data. We formulate the problem of video sequence-to-sequence matching as a pattern matching problem. New string edit operations required for the special characteristics of video sequences and the unique features of the vstring representation are introduced. Based on the edit operations, the vstring edit distance is proposed as a new similarity measure for video sequence matching.", "num_citations": "62\n", "authors": ["1175"]}
{"title": "Online app review analysis for identifying emerging issues\n", "abstract": " Detecting emerging issues (eg, new bugs) timely and precisely is crucial for developers to update their apps. App reviews provide an opportunity to proactively collect user complaints and promptly improve apps' user experience, in terms of bug fixing and feature refinement. However, the tremendous quantities of reviews and noise words (eg, misspelled words) increase the difficulties in accurately identifying newly-appearing app issues. In this paper, we propose a novel and automated framework IDEA, which aims to IDentify Emerging App issues effectively based on online review analysis. We evaluate IDEA on six popular apps from Google Play and Apple's App Store, employing the official app changelogs as our ground truth. Experiment results demonstrate the effectiveness of IDEA in identifying emerging app issues. Feedback from engineers and product managers shows that 88.9% of them think that the\u00a0\u2026", "num_citations": "61\n", "authors": ["1175"]}
{"title": "Managing knowledge on the Web\u2013Extracting ontology from HTML Web\n", "abstract": " In recent years, the Internet has become one of the most important sources of information, and it is now imperative that companies are able to collect, retrieve, process, and manage information from the Web. However, due to the sheer amount of information available, browsing web content by searches using keywords is inefficient, largely because unstructured HTML web pages are written for human comprehension and not for direct machine processing. For the same reason, the degree of web automation is limited. It is recognized that semantics can enhance web automation, but it will take an indefinite amount of effort to convert the current HTML Web into the Semantic Web. This study proposes a novel ontology extractor, called OntoSpider, for extracting ontology from the HTML Web. The contribution of this work is the design and implementation of a six-phase process that includes the preparation, transformation\u00a0\u2026", "num_citations": "61\n", "authors": ["1175"]}
{"title": "MatchSim: a novel similarity measure based on maximum neighborhood matching\n", "abstract": " Measuring object similarity in a graph is a fundamental data- mining problem in various application domains, including Web linkage mining, social network analysis, information retrieval, and recommender systems. In this paper, we focus on the neighbor-based approach that is based on the intuition that \u201csimilar objects have similar neighbors\u201d and propose a novel similarity measure called MatchSim. Our method recursively defines the similarity between two objects by the average similarity of the maximum-matched similar neighbor pairs between them. We show that MatchSim conforms to the basic intuition of similarity; therefore, it can overcome the counterintuitive contradiction in SimRank. Moreover, MatchSim can be viewed as an extension of the traditional neighbor-counting scheme by taking the similarities between neighbors into account, leading to higher flexibility. We present the MatchSim score\u00a0\u2026", "num_citations": "59\n", "authors": ["1175"]}
{"title": "Randomized generalized Hough transform for 2-D gray scale object detection\n", "abstract": " This paper proposes a new algorithm for 2D object detection called randomized generalized Hough transform (RGHT). It combines the generalized Hough transform (GHT) with the randomized Hough transform (RHT). Our algorithm can detect arbitrary objects of various scales and orientations in gray level images. We also demonstrate RGHT's advantages of high speed, low storage requirement, high accuracy and arbitrary resolution through comparison with other related algorithms.", "num_citations": "59\n", "authors": ["1175"]}
{"title": "Efficient online learning for multitask feature selection\n", "abstract": " Learning explanatory features across multiple related tasks, or MultiTask Feature Selection (MTFS), is an important problem in the applications of data mining, machine learning, and bioinformatics. Previous MTFS methods fulfill this task by batch-mode training. This makes them inefficient when data come sequentially or when the number of training data is so large that they cannot be loaded into the memory simultaneously. In order to tackle these problems, we propose a novel online learning framework to solve the MTFS problem. A main advantage of the online algorithm is its efficiency in both time complexity and memory cost. The weights of the MTFS models at each iteration can be updated by closed-form solutions based on the average of previous subgradients. This yields the worst-case bounds of the time complexity and memory cost at each iteration, both in the order of O(d \u00d7 Q), where d is the number of\u00a0\u2026", "num_citations": "58\n", "authors": ["1175"]}
{"title": "Tagrec: Leveraging tagging wisdom for recommendation\n", "abstract": " Due to the exponential growth of information on the Web, Recommender Systems have been developed to generate suggestions to help users overcome information overload and sift through huge amounts of information efficiently. Many existing approaches to recommender systems can neither handle very large datasets nor easily deal with users who have made very few ratings. Moreover, traditional recommender systems consider only the rating information, resulting in the loss of flexibility. Tagging has recently emerged as a popular way for users to annotate, organize and share resources on the Web. Several research tasks have shown that tags can represent userspsila judgments about Web contents quite accurately. In the light of the facts that both the rating activity and tagging activity can reflect userspsila opinions, this paper proposes a factor analysis approach called TagRec based on a unified\u00a0\u2026", "num_citations": "54\n", "authors": ["1175"]}
{"title": "An efficient iterative pose estimation algorithm\n", "abstract": " A novel model-based pose estimation algorithm is presented which estimates the motion of a three-dimensional object from a image sequence. The nonlinear estimation process within iteration is divided into two linear estimation stages, namely the depth approximation and the pose calculation. In the depth approximation stage, the depths of the feature points in three-dimensional space are estimated. In the pose calculation stage, the rotation and translation parameters between the estimated feature points and the model point set arer calculated by a fast singular value decomposition method. The whole process is executed recursively until the result is stable. Since both stages can be solved efficiently, the computational cost is low. As a result, the algorithm is well-suited for real computer vision applications. We demonstrate the capability of this algorithm by applying it to a real time head tracking problem. The\u00a0\u2026", "num_citations": "53\n", "authors": ["1175"]}
{"title": "A unified point-of-interest recommendation framework in location-based social networks\n", "abstract": " Location-based social networks (LBSNs), such as Gowalla, Facebook, Foursquare, Brightkite, and so on, have attracted millions of users to share their social friendship and their locations via check-ins in the past few years. Plenty of valuable information is accumulated based on the check-in behaviors, which makes it possible to learn users\u2019 moving patterns as well as their preferences. In LBSNs, point-of-interest (POI) recommendation is one of the most significant tasks because it can help targeted users explore their surroundings as well as help third-party developers provide personalized services. Matrix factorization is a promising method for this task because it can capture users\u2019 preferences to locations and is widely adopted in traditional recommender systems such as movie recommendation. However, the sparsity of the check-in data makes it difficult to capture users\u2019 preferences accurately. Geographical\u00a0\u2026", "num_citations": "51\n", "authors": ["1175"]}
{"title": "A study of the relationship between support vector machine and Gabriel graph\n", "abstract": " One of the major tasks in the support vector machine (SVM) algorithm is to locate the discriminant boundary in classification task. It is crucial to understand various approaches to this particular task. In this paper, we survey several different methods of finding the boundary from different disciplines. In particular, we examine SVM from the statistical learning theory, the convex hull problem from the computational geometry's point of view, and Gabriel's graph from the computational geometry perspective to describe their theoretical connections and practical implementation implications. Moreover, we implement these methods and demonstrate their respective results on the classification accuracy and run time complexity. Finally, we conclude with some discussions about these three different techniques.", "num_citations": "50\n", "authors": ["1175"]}
{"title": "Heavy-tailed symmetric stochastic neighbor embedding\n", "abstract": " Stochastic Neighbor Embedding (SNE) has shown to be quite promising for data visualization. Currently, the most popular implementation, t-SNE, is restricted to a particular Student t-distribution as its embedding distribution. Moreover, it uses a gradient descent algorithm that may require users to tune parameters such as the learning step size, momentum, etc., in finding its optimum. In this paper, we propose the Heavy-tailed Symmetric Stochastic Neighbor Embedding (HSSNE) method, which is a generalization of the t-SNE to accommodate various heavytailed embedding similarity functions. With this generalization, we are presented with two difficulties. The first is how to select the best embedding similarity among all heavy-tailed functions and the second is how to optimize the objective function once the heavy-tailed function has been selected. Our contributions then are:(1) we point out that various heavy-tailed embedding similarities can be characterized by their negative score functions. Based on this finding, we present a parameterized subset of similarity functions for choosing the best tail-heaviness for HSSNE;(2) we present a fixed-point optimization algorithm that can be applied to all heavy-tailed functions and does not require the user to set any parameters; and (3) we present two empirical studies, one for unsupervised visualization showing that our optimization algorithm runs as fast and as good as the best known t-SNE implementation and the other for semi-supervised visualization showing quantitative superiority using the homogeneity measure as well as qualitative advantage in cluster separation over t-SNE.", "num_citations": "49\n", "authors": ["1175"]}
{"title": "Integrated probability function and its application to content-based image retrieval by relevance feedback\n", "abstract": " In the last few years, we have seen an upsurge of interest in content-based image retrieval (CBIR)\u2014the selection of images from a collection via features extracted from images themselves. Often, a single image attribute may not have enough discriminative information for successful retrieval. On the other hand when multiple features are used, it is hard to determine the suitable weighing factors for various features for optimal retrieval. In this paper, we present a relevance feedback framework with Integrated Probability Function (IPF) which combines multiple features for optimal retrieval. The IPF is based on a new posterior probability estimator and a novel weight updating approach. We perform experiments on 1400 monochromatic trademark images have been performed. The proposed IPF is shown to be more effective and efficient to retrieve deformed trademark images than the commonly used integrated\u00a0\u2026", "num_citations": "49\n", "authors": ["1175"]}
{"title": "Improving latent factor models via personalized feature projection for one class recommendation\n", "abstract": " Latent Factor models, which transform both users and items into the same latent feature space, are one of the most successful and ubiquitous models in recommender systems. Most existing models in this paradigm define both users' and items' latent factors to be of the same size and use an inner product to represent a user's\" compatibility\" with an item. Intuitively, users' factors encode\" preferences\" while item factors encode\" properties\", so that the inner product encodes how well an item matches a user's preferences. However, a user's opinion of an item may be more complex, for example each dimension of each user's opinion may depend on a combination of multiple item factors simultaneously. Thus it may be better to view each dimension of a user's preference as a personalized projection of an item's properties so that the preference model can capture complex relationships between items' properties and\u00a0\u2026", "num_citations": "48\n", "authors": ["1175"]}
{"title": "A topic-biased user reputation model in rating systems\n", "abstract": " In rating systems like Epinions and Amazon\u2019s product review systems, users rate items on different topics to yield item scores. Traditionally, item scores are estimated by averaging all the ratings with equal weights. To improve the accuracy of estimated item scores, user reputation [a.k.a., user reputation (UR)] is incorporated. The existing algorithms on UR, however, have underplayed the role of topics in rating systems. In this paper, we first reveal that UR is topic-biased from our empirical investigation. However, existing algorithms cannot capture this characteristic in rating systems. To address this issue, we propose a topic-biased model (TBM) to estimate UR in terms of different topics as well as item scores. With TBM, we develop six topic-biased algorithms, which are subsequently evaluated with experiments using both real-world and synthetic data sets. Results of the experiments demonstrate that the topic\u00a0\u2026", "num_citations": "46\n", "authors": ["1175"]}
{"title": "Robust BMPM training based on second-order cone programming and its application in medical diagnosis\n", "abstract": " Abstract The Biased Minimax Probability Machine (BMPM) constructs a classifier which deals with the imbalanced learning tasks. It provides a worst-case bound on the probability of misclassification of future data points based on reliable estimates of means and covariance matrices of the classes from the training data samples, and achieves promising performance. In this paper, we develop a novel yet critical extension training algorithm for BMPM that is based on Second-Order Cone Programming (SOCP). Moreover, we apply the biased classification model to medical diagnosis problems to demonstrate its usefulness. By removing some crucial assumptions in the original solution to this model, we make the new method more accurate and robust. We outline the theoretical derivatives of the biased classification model, and reformulate it into an SOCP problem which could be efficiently solved with global optima\u00a0\u2026", "num_citations": "45\n", "authors": ["1175"]}
{"title": "Maximizing sensitivity in medical diagnosis using biased minimax probability machine\n", "abstract": " The challenging task of medical diagnosis based on machine learning techniques requires an inherent bias, i.e., the diagnosis should favor the \"ill\" class over the \"healthy\" class, since misdiagnosing a patient as a healthy person may delay the therapy and aggravate the illness. Therefore,the objective in this task is not to improve the overall accuracy of the classification,but to focus on improving the sensitivity (the accuracy of the \"ill\" class) while maintaining an acceptable specificity (the accuracy of the \"healthy\" class). Some current methods adopt roundabout ways to impose a certain bias toward the important class, i.e., they try to utilize some intermediate factors to influence the classification. However, it remains uncertain whether these methods can improve the classification performance systematically. In this paper, by engaging a novel learning tool, the biased minimax probability machine(BMPM), we deal with\u00a0\u2026", "num_citations": "44\n", "authors": ["1175"]}
{"title": "Neural keyphrase generation via reinforcement learning with adaptive rewards\n", "abstract": " Generating keyphrases that summarize the main points of a document is a fundamental task in natural language processing. Although existing generative models are capable of predicting multiple keyphrases for an input document as well as determining the number of keyphrases to generate, they still suffer from the problem of generating too few keyphrases. To address this problem, we propose a reinforcement learning (RL) approach for keyphrase generation, with an adaptive reward function that encourages a model to generate both sufficient and accurate keyphrases. Furthermore, we introduce a new evaluation method that incorporates name variations of the ground-truth keyphrases using the Wikipedia knowledge base. Thus, our evaluation method can more robustly evaluate the quality of predicted keyphrases. Extensive experiments on five real-world datasets of different scales demonstrate that our RL approach consistently and significantly improves the performance of the state-of-the-art generative models with both conventional and new evaluation methods.", "num_citations": "43\n", "authors": ["1175"]}
{"title": "Arcade: Augmented reality computing arena for digital entertainment\n", "abstract": " Augmented reality (AR) technology for digital composition of animation with real scenes is to bring new digital entertainment experience to the viewers. Augmented reality is a form of human-machine interaction. The key feature of the augmented reality technology is to present auxiliary information in the field of view for an individual automatically without human intervention. The effect is similar to composing computer-animated images with real scenes. To achieve the new augmented reality experience, two main problems are: How to keep track of the viewing parameters of the individual viewer? How to render a virtual image in the field of view correctly and seamlessly? To tackle the above, we are designing and implementing an enabling framework, called augmented reality computing arena for digital entertainment (ARCADE), to support the creation of augmented reality entertainment applications. Moreover, we\u00a0\u2026", "num_citations": "43\n", "authors": ["1175"]}
{"title": "Capturing geographical influence in POI recommendations\n", "abstract": " Point-of-Interest (POI) recommendation is a significant service for location-based social networks (LBSNs). It recommends new places such as clubs, restaurants, and coffee bars to users. Whether recommended locations meet users\u2019 interests depends on three factors: user preference, social influence, and geographical influence. Hence extracting the information from users\u2019 check-in records is the key to POI recommendation in LBSNs. Capturing user preference and social influence is relatively easy since it is analogical to the methods in a movie recommender system. However, it is a new topic to capture geographical influence. Previous studies indicate that check-in locations disperse around several centers and we are able to employ Gaussian distribution based models to approximate users\u2019 check-in behaviors. Yet centers discovering methods are dissatisfactory. In this paper, we propose two models\u00a0\u2026", "num_citations": "41\n", "authors": ["1175"]}
{"title": "Effective latent space graph-based re-ranking model with global consistency\n", "abstract": " Recently the re-ranking algorithms have been quite popular for web search and data mining. However, one of the issues is that those algorithms treat the content and link information individually. Inspired by graph-based machine learning algorithms, we propose a novel and general framework to model the re-ranking algorithm, by regularizing the smoothness of ranking scores over the graph, along with a regularizer on the initial ranking scores (which are obtained by the base ranker). The intuition behind the model is the global consistency over the graph: similar entities are likely to have the same ranking scores with respect to a query. Our approach simultaneously incorporates the content with other explicit or implicit link information in a latent space graph. Then an effective unified re-ranking algorithm is performed on the graph with respect to the query. To illustrate our methodology, we apply the framework to\u00a0\u2026", "num_citations": "41\n", "authors": ["1175"]}
{"title": "Enhanced models for expertise retrieval using community-aware strategies\n", "abstract": " Expertise retrieval, whose task is to suggest people with relevant expertise on the topic of interest, has received increasing interest in recent years. One of the issues is that previous algorithms mainly consider the documents associated with the experts while ignoring the community information that is affiliated with the documents and the experts. Motivated by the observation that communities could provide valuable insight and distinctive information, we investigate and develop two community-aware strategies to enhance expertise retrieval. We first propose a new smoothing method using the community context for statistical language modeling, which is employed to identify the most relevant documents so as to boost the performance of expertise retrieval in the document-based model. Furthermore, we propose a query-sensitive AuthorRank to model the authors' authorities based on the community coauthorship\u00a0\u2026", "num_citations": "40\n", "authors": ["1175"]}
{"title": "Genetic algorithm for weights assignment in dissimilarity function for trademark retrieval\n", "abstract": " Trademark image retrieval is becoming an important application for logo registry, verification, and design. There are two major problems about the current approaches to trademark image retrieval based on shape features. First, researchers often focus on using a single feature, e.g., Fourier descriptors, invariant moments or Zernike moments, without combining them for possible better results. Second, even if they combine the shape features, the weighting factors assigned to the various shape features are often determined with an ad hoc procedure. Hence, we propose to group different shape features together and suggest a technique to determine a suitable weighting factors for different shape features in trademark image retrieval.               In this paper, we use a supervised learning method for finding the weighting factors in the dissimilarity function by integrating five shape features using a genetic algorithm\u00a0\u2026", "num_citations": "39\n", "authors": ["1175"]}
{"title": "Intra-block algorithm for digital watermarking\n", "abstract": " We present a variant to the DCT-based block algorithm proposed in Hsu and Wu (1996) for signal embedding in digital images. Instead of inter-block relations, our algorithm uses intra-block relations to generate the watermarked image. We describe the algorithm and its performance against translation and cropping. The features of our method are: (1) the watermark is perceptually invisible; (2) little loss of relevant information of original image; (3) the watermark can be retrieved by using a secret key; and (4) the watermark is robust against translation and area cropping.", "num_citations": "39\n", "authors": ["1175"]}
{"title": "Face recognition committee machine\n", "abstract": " Face recognition has been of interest to a growing number of researchers due to its applications on security. Within past years, there are numerous face recognition algorithms proposed by researchers. However, there is no unified framework for the integration. We implement different existing well-known algorithms, eigenface, Fisherface, elastic graph matching (EGM), support vector machine (SVM) and neural network, to give a comprehensive testing under same face databases. Moreover, we present a face recognition committee machine (FRCM), which is a novel approach for assembling the outputs of various face recognition algorithms to obtain a unified decision with improved accuracy. The machine consists of an ensemble of the above algorithms to cope with various face images. We have tested our system with the ORL face database and Yale face database. A comparative experimental result of different\u00a0\u2026", "num_citations": "38\n", "authors": ["1175"]}
{"title": "Taskrec: probabilistic matrix factorization in task recommendation in crowdsourcing systems\n", "abstract": " In crowdsourcing systems, task recommendation can help workers to find their right tasks faster as well as help requesters to receive good quality output quicker. However, previously proposed classification approach does not consider the dynamic scenarios of new workers and new tasks in the system. In this paper, we propose a Task Recommendation (TaskRec) framework based on a unified probabilistic matrix factorization, aiming to recommend tasks to workers in dynamic scenarios. Unlike traditional recommendation systems, workers do not provide their ratings on tasks in crowdsourcing systems, and thus we propose to transform worker behaviors into ratings. Complexity analysis shows that our framework is efficient and is scalable to large datasets. Finally, we conduct experiments on real-world datasets for performance evaluation.", "num_citations": "37\n", "authors": ["1175"]}
{"title": "Collection of user judgments on spoken dialog system with crowdsourcing\n", "abstract": " This paper presents an initial attempt at the use of crowd-sourcing for collection of user judgments on spoken dialog systems (SDSs). This is implemented on Amazon Mechanical Turk (MTurk), where a Requester can design a human intelligence task (HIT) to be performed by a large number of Workers efficiently and cost-effectively. We describe a design methodology for two types of HITs - the first targets at fast rating of a large number of dialogs regarding some dimensions of the SDS's performance and the second aims to assess the reliability of Workers on MTurk through the variability in ratings across different Workers. A set of approval rules are also designed to control the quality of ratings from MTurk. At the end of the collection work, user judgments for about 8,000 dialogs rated by around 700Workers are collected in 45 days. We observe reasonable consistency between the manual MTurk ratings and an\u00a0\u2026", "num_citations": "37\n", "authors": ["1175"]}
{"title": "Mathematical modeling of social games\n", "abstract": " Human computation is a technique that makes use of human abilities for computation to solve problems. Social games use the power of the Internet game players to solve human computation problems. In previous works, many social games were proposed and were quite successful, but no formal framework exists for designing social games in general. A formal framework is important because it lists out the design elements of a social game, the characteristics of a human computation problem, and their relationships. With a formal framework, it simplifies the way to design a social game for a specific problem. In this paper, our contributions are: (1) formulate a formal model on social games, (2) analyze the framework and derive some interesting properties based on model's interactions, (3) illustrate how some current social games can be realized with the proposed formal model, and (4) describe how to design a\u00a0\u2026", "num_citations": "36\n", "authors": ["1175"]}
{"title": "Exploit of online social networks with semi-supervised learning\n", "abstract": " With the rapid growth of the Internet, more and more people interact with their friends in online social networks like Facebook. Current online social networks have designed some strategies to protect users' privacy, but they are not stringent enough. Some public information of profile or relationship can be utilized to infer users' private information. Online social networks usually contain little public available information of users (labeled data) but with a large number of hidden ones (unlabeled data). Recently, Semi-Supervised Learning (SSL), which has the advantage of utilizing fewer labeled data to achieve better performance compared to classical Supervised Learning, attracts much attention from the web research community with a massive set of unlabeled data. In our paper, we focus on the privacy issue of online social networks, which is a hot and dynamic research topic. More specifically, we propose a novel\u00a0\u2026", "num_citations": "34\n", "authors": ["1175"]}
{"title": "Web page classification with heterogeneous data fusion\n", "abstract": " Web pages are more than text and they contain much contextual and structural information, eg, the title, the meta data, the anchor text, etc., each of which can be seen as a data source or are presentation. Due to the different dimensionality and different representing forms of these heterogeneous data sources, simply putting them together would not greatly enhance the classification performance. We observe that via a kernel function, different dimensions and types of data sources can be represented into acommon format of kernel matrix, which can be seen as a generalized similarity measure between a pair of web pages. In this sense, a kernel learning approach is employed to fuse these heterogeneous data sources. The experimental results on a collection of the ODP database validate the advantages of the proposed method over traditional methods based on any single data source and the uniformly weighted\u00a0\u2026", "num_citations": "34\n", "authors": ["1175"]}
{"title": "Hierarchical classification of documents with error control\n", "abstract": " Classification is a function that matches a new object with one of the predefined classes. Document classification is characterized by the large number of attributes involved in the objects (documents). The traditional method of building a single classifier to do all the classification work would incur a high overhead. Hierarchical classification is a more efficient method \u2014 instead of a single classifier, we use a set of classifiers distributed over a class taxonomy, one for each internal node. However, once a misclassification occurs at a high level class, it may result in a class that is far apart from the correct one. An existing approach to coping with this problem requires terms also to be arranged hierarchically. In this paper, instead of overhauling the classifier itself, we propose mechanisms to detect misclassification and take appropriate actions. We then discuss an alternative that masks the misclassification based\u00a0\u2026", "num_citations": "34\n", "authors": ["1175"]}
{"title": "Multi-task learning for one-class classification\n", "abstract": " In this paper, we address the problem of one-class classification. Taking into account the fact that in some applications, the given training samples are rather limited, we attempt to utilize the advantages of Multi-task Learning (MTL), where the data of related tasks may share similar structure and helpful information. We then propose an MTL framework for one-class classification. The framework derives from the one-class v-SVM and makes use of related tasks by constraining them to have similar solutions. This formulation can be cast into a second-order cone program, which achieves a global solution and is solved efficiently. Further, the framework also maintains the favorable property of the v parameter in the v-SVM, which can control the fraction of outliers and support vectors, in one-class classification. This framework also connects with several existing models. Experimental results on both synthetic and real-world\u00a0\u2026", "num_citations": "33\n", "authors": ["1175"]}
{"title": "A novel kernel-based maximum a posteriori classification method\n", "abstract": " Kernel methods have been widely used in pattern recognition. Many kernel classifiers such as Support Vector Machines (SVM) assume that data can be separated by a hyperplane in the kernel-induced feature space. These methods do not consider the data distribution and are difficult to output the probabilities or confidences for classification. This paper proposes a novel Kernel-based Maximum A Posteriori (KMAP) classification method, which makes a Gaussian distribution assumption instead of a linear separable assumption in the feature space. Robust methods are further proposed to estimate the probability densities, and the kernel trick is utilized to calculate our model. The model is theoretically and empirically important in the sense that: (1) it presents a more generalized classification model than other kernel-based algorithms, e.g.,\u00a0Kernel Fisher Discriminant Analysis (KFDA); (2) it can output probability or\u00a0\u2026", "num_citations": "32\n", "authors": ["1175"]}
{"title": "Online nonlinear AUC maximization for imbalanced data sets\n", "abstract": " Classifying binary imbalanced streaming data is a significant task in both machine learning and data mining. Previously, online area under the receiver operating characteristic (ROC) curve (AUC) maximization has been proposed to seek a linear classifier. However, it is not well suited for handling nonlinearity and heterogeneity of the data. In this paper, we propose the kernelized online imbalanced learning (KOIL) algorithm, which produces a nonlinear classifier for the data by maximizing the AUC score while minimizing a functional regularizer. We address four major challenges that arise from our approach. First, to control the number of support vectors without sacrificing the model performance, we introduce two buffers with fixed budgets to capture the global information on the decision boundary by storing the corresponding learned support vectors. Second, to restrict the fluctuation of the learned decision function\u00a0\u2026", "num_citations": "31\n", "authors": ["1175"]}
{"title": "Non-fixed and asymmetrical margin approach to stock market prediction using support vector regression\n", "abstract": " Recently, support vector regression (SVR) has been applied to financial time series prediction. Typical characteristics of financial time series are non-stationary and noisy in nature. The volatility, usually time-varying, of the time series is therefore some valuable information about the series. Previously, we had proposed to use the volatility to adaptively change the width of the margin of SVR. We have noticed that upside margin and downside margin do not necessary be the same, and we have observed that their choice would affect the upside risk, downside risk and as well as the overall prediction result. In this paper, we introduce a novel approach to adapt the asymmetrical margins using momentum. We applied and compared this method to predict the Hang Seng Index and Dow Jones Industrial Average.", "num_citations": "31\n", "authors": ["1175"]}
{"title": "Shifu: Deep learning based advisor-advisee relationship mining in scholarly big data\n", "abstract": " Scholars in academia are involved in various social relationships such as advisor-advisee relationships. The analysis of such relationship can provide invaluable information for understanding the interactions among scholars as well as providing many researcher-specific applications such as advisor recommendation and academic rising star identification. However, in most cases, high quality advisor-advisee relationship dataset is unavailable. To address this problem, we propose Shifu, a deep-learning-based advisor-advisee relationship identification method which takes into account both the local properties and network characteristics. In particular, we explore how to crawl advisor-advisee pairs from PhDtree project and extract their publication information by matching them with DBLP dataset as the experimental dataset. To the best of our knowledge, no prior effort has been made to address the scientific\u00a0\u2026", "num_citations": "30\n", "authors": ["1175"]}
{"title": "Semantic video summarization using mutual reinforcement principle and shot arrangement patterns\n", "abstract": " We propose a novel semantic video summarization framework, which generates video skimmings that guarantee both the balanced content coverage and the visual coherence. First, we collect video semantic information with a semi-automatic video annotation tool. Secondly, we analyze the video structure and determine each video scene\u2019s target skim length. Then, mutual reinforcement principle is used to compute the relative importance value and cluster the video shots according to their semantic descriptions. Finally, we analyze the arrangement pattern of the video shots, and the key shot arrangement patterns are extracted to form the final video skimming, where the video shot importance value is used as guidance. Experiments are conducted to evaluate the effectiveness of our proposed approach.", "num_citations": "30\n", "authors": ["1175"]}
{"title": "Locating support vectors via/spl beta/-skeleton technique\n", "abstract": " Recently, support vector machine (SVM) has become a very dynamic and popular topic in the neural network community for its abilities to perform classification, estimation, and regression. One of the major tasks in the SVM algorithm is to locate the points, or rather support vectors, based on which we construct the discriminant boundary in classification task. In the process of studying the methods for finding the decision boundary, we conceive a method, /spl beta/-skeleton algorithm, which reduces the size of the training set for SVM. We describe their theoretical connections and practical implementation implications. In this paper, we also survey four different methods for classification: the SVM method, k-nearest neighbor method, /spl beta/-skeleton algorithm used in the above two methods. Compared with the methods without using /spl beta/-skeleton algorithm, prediction with the edited set obtained from /spl beta\u00a0\u2026", "num_citations": "30\n", "authors": ["1175"]}
{"title": "A novel video summarization framework for document preparation and archival applications\n", "abstract": " With the rapid growth of network bandwidth and high-capacity storage devices, videos have become an important way of communication in the aerospace industry and many other entities. However, browsing and managing huge video databases are quite tedious. To solve the problem, in this paper, we propose a novel video summarization framework, and discuss its potential usage in the document preparation and archival applications. The proposed framework generates video skimmings that guarantee both the balanced content coverage and the visual coherence. First, we segment the raw video into video shots, analyze the structure of the video, find the boundaries of semantic scenes, then calculate each scene's skimming length by its structure and content entropy. Second, we define a spatial-temporal dissimilarity function between video shots, model each video scene as a graph, and find each scene's\u00a0\u2026", "num_citations": "29\n", "authors": ["1175"]}
{"title": "Outliers treatment in support vector regression for financial time series prediction\n", "abstract": " Recently, the Support Vector Regression (SVR) has been applied in the financial time series prediction. The financial data are usually highly noisy and contain outliers. Detecting outliers and deflating their influence are important but hard problems. In this paper, we propose a novel \u201ctwo-phase\u201d SVR training algorithm to detect outliers and reduce their negative impact. Our experimental results on three indices: Hang Seng Index, NASDAQ, and FSTE 100 index show that the proposed \u201ctwo-phase\u201d algorithm has improvement on the prediction.", "num_citations": "29\n", "authors": ["1175"]}
{"title": "Gaussian mixture distance for information retrieval\n", "abstract": " We propose a Gaussian mixture distance for performing accurate nearest-neighbor search for information retrieval. Under an established Gaussian finite mixture model for the distribution of the data in the database, the Gaussian mixture distance is formulated based on minimizing the Kullback-Leibler divergence between the distribution of the retrieval data and the data in database. We compared the performance of the Gaussian mixture distance with the well-known Euclidean and Mahalanobis distance based on a precision performance measurement. Experimental results demonstrate that the Gaussian mixture distance function is superior in the others for different types of testing data.", "num_citations": "28\n", "authors": ["1175"]}
{"title": "An integrated approach for keyphrase generation via exploring the power of retrieval and extraction\n", "abstract": " In this paper, we present a novel integrated approach for keyphrase generation (KG). Unlike previous works which are purely extractive or generative, we first propose a new multi-task learning framework that jointly learns an extractive model and a generative model. Besides extracting keyphrases, the output of the extractive model is also employed to rectify the copy probability distribution of the generative model, such that the generative model can better identify important contents from the given document. Moreover, we retrieve similar documents with the given document from training data and use their associated keyphrases as external knowledge for the generative model to produce more accurate keyphrases. For further exploiting the power of extraction and retrieval, we propose a neural-based merging module to combine and re-rank the predicted keyphrases from the enhanced generative model, the extractive model, and the retrieved keyphrases. Experiments on the five KG benchmarks demonstrate that our integrated approach outperforms the state-of-the-art methods.", "num_citations": "27\n", "authors": ["1175"]}
{"title": "Fast Relative-Error Approximation Algorithm for Ridge Regression.\n", "abstract": " Ridge regression is one of the most popular and effective regularized regression methods, and one case of particular interest is that the number of features p is much larger than the number of samples n, ie p\u226b n. In this case, the standard optimization algorithm for ridge regression computes the optimal solution x\u2217 in O (n2p+ n3) time. In this paper, we propose a fast relativeerror approximation algorithm for ridge regression. More specifically, our algorithm outputs a solution x satisfying x\u2212 x\u2217 2\u2264 \u03f5x\u2217 2 with high probability and runs inO (nnz (A)+ n3/\u03f52) time, where nnz (A) is the number of non-zero entries of matrix A.To the best of our knowledge, this is the first algorithm for ridge regression that runs in o (n2p) time with provable relative-error approximation bound on the output vector. In addition, we analyze the risk inflation bound of our algorithm and apply our techniques to two generalizations of ridge regression, including multiple response ridge regression and a non-linear ridge regression problem. Finally, we show empirical results on both synthetic and real datasets.", "num_citations": "27\n", "authors": ["1175"]}
{"title": "Social media tools and platforms in learning environments\n", "abstract": " Online social media have transformed the face of human interaction in the 21st century. Wikis, blogs, online groups and forums, podcasts, virtual worlds, and social tagging are but a few of the applications enabling innovative behaviors that support acquisition, access, manipulation, retrieval, and visualization of information. It is, therefore, no surprise that educational practitioners and theorists have begun to explore how social media can be harnessed to describe and implement new paradigms for communication, learning, and education. The editors\u2019 goal in publishing this book was to identify original research on the application of online social media and related technologies in education as well as emerging applications in Web technologies that could provide and shape future educational platforms. The selected contributions deal with questions such as how social media can truly enrich and enhance learning and teaching experiences in ways not otherwise possible; how learning can be integrated in a distributed and ubiquitous social computing environment; or what theories, paradigms, and models are applicable for the support of social computing in education. Researchers in education or educational software will find interesting and sometimes provocative chapters on paradigms and methodologies, virtual and mobile learning spaces, and assessment and social factors. Practitioners in these fields will benefit from an additional section devoted to case studies and first experience reports.", "num_citations": "27\n", "authors": ["1175"]}
{"title": "Discriminative training of Bayesian Chow-Liu multinet classifiers\n", "abstract": " Discriminative classifiers such as support vector machines directly learn a discriminant function or a posterior probability model to perform classification. On the other hand, generative classifiers often learn a joint probability model and then use Bayes rules to construct a posterior classifier from this model. In general, generative classifiers are not as accurate as discriminant classifier. However generative classifiers provide a principled way to handle the missing information problems, which discriminant classifiers cannot easily deal with. To achieve good performances in various classification tasks, it is better to combine these two strategies. In this paper, we develop a novel method to iteratively train a kind of generative Bayesian classifier: Bayesian Chow-Liu multinet classifier in a discriminative way. Different with the traditional Bayesian multinet classifiers, our discriminative method adds into the optimization\u00a0\u2026", "num_citations": "27\n", "authors": ["1175"]}
{"title": "Content-based image retrieval by relevance feedback\n", "abstract": " Relevance feedback is a powerful technique for content-based image retrieval. Many parameter estimation approaches have been proposed for relevance feedback. However, most of them have only utilized information of the relevant retrieved images, and have given up, or have not made great use of information of the irrelevant retrieved images. This paper presents a novel approach to update the interweights of integrated probability function by using the information of both relevant and irrelevant retrieved images. Experimental results have shown the effectiveness and robustness of our proposed approach, especially in the situation of no relevant retrieved images.", "num_citations": "27\n", "authors": ["1175"]}
{"title": "Neural relational topic models for scientific article analysis\n", "abstract": " Topic modelling and citation recommendation of scientific articles are important yet challenging research problems in scientific article analysis. In particular, the inference on coherent topics can be easily affected by irrelevant contents in articles. Meanwhile, the extreme sparsity of citation networks brings difficulty to a valid citation recommendation. Intuitively, articles with similar topics are more likely to cite each other, and cited articles tend to share similar themes. Motivated from this intuition, we aim to boost the performance of both topic modelling and citation recommendation by effectively leverage this underlying correlation between latent topics and citation networks. To this end, we propose a novel Bayesian deep generative model termed as Neural Relational Topic Model (NRTM), which is composed with a Stacked Variational Auto-Encoder (SVAE) and a multilayer perception (MLP). Specifically, the SVAE\u00a0\u2026", "num_citations": "26\n", "authors": ["1175"]}
{"title": "Aggregated temporal tensor factorization model for point-of-interest recommendation\n", "abstract": " Point-of-interest\u00a0(POI) recommendation is an important application in location-based social networks\u00a0(LBSNs), which mines user check-in sequences to suggest interesting locations for users. Because user check-in behavior exhibits strong temporal patterns\u2014for instance, users would like to check-in at restaurants at noon and visit bars at night. Hence, capturing the temporal influence is necessary to ensure the high performance in a POI recommendation system. Previous studies observe that the temporal characteristics of user mobility in LBSNs can be summarized in three aspects: periodicity, consecutiveness, and non-uniformness. However, previous work does not model the three characteristics together. More importantly, we observe that the temporal characteristics exist at different time scales, which cannot be modeled in prior work. In this paper, we propose an Aggregated Temporal Tensor\u00a0\u2026", "num_citations": "26\n", "authors": ["1175"]}
{"title": "Smooth optimization for effective multiple kernel learning\n", "abstract": " Multiple Kernel Learning (MKL) can be formulated as a convex-concave minmax optimization problem, whose saddle point corresponds to the optimal solution to MKL. Most MKL methods employ the L1-norm simplex constraints on the combination weights of kernels, which therefore involves optimization of a non-smooth function of the kernel weights. These methods usually divide the optimization into two cycles: one cycle deals with the optimization on the kernel combination weights, and the other cycle updates the parameters of SVM. Despite the success of their efficiency, they tend to discard informative complementary kernels. To improve accuracy, we introduce smoothness to the optimization procedure. Furthermore, we transform the optimization into a single smooth convex optimization problem and employ the Nesterov\u2019s method to efficiently solve the optimization problem. Experiments on benchmark data sets demonstrate that the proposed algorithm clearly improves current MKL methods in a number scenarios.", "num_citations": "25\n", "authors": ["1175"]}
{"title": "Branching competitive learning network: A novel self-creating model\n", "abstract": " This paper presents a new self-creating model of a neural network in which a branching mechanism is incorporated with competitive learning. Unlike other self-creating models, the proposed scheme, called branching competitive learning (BCL), adopts a special node-splitting criterion, which is based mainly on the geometrical measurements of the movement of the synaptic vectors in the weight space. Compared with other self-creating and nonself-creating competitive learning models, the BCL network is more efficient to capture the spatial distribution of the input data and, therefore, tends to give better clustering or quantization results. We demonstrate the ability of the BCL model to appropriately estimate the cluster number in a data distribution, show its adaptability to nonstationary data inputs and, moreover, present a scheme leading to a multiresolution data clustering. Extensive experiments on vector\u00a0\u2026", "num_citations": "25\n", "authors": ["1175"]}
{"title": "Peer Clustering and Firework Query Model in Peer-to-Peer Networks\n", "abstract": " Clustering technique is used in database and information retrieval system for organizing data and improving retrieval efficiency. We surmise such functionality is valuable in a Peer-to-Peer (P2P) distributed environment. In this thesis, we introduce the concept of Peer Clustering at the level of overlaying network topology; thus, data inside the P2P network are organized in a fashion similar to a Yellow Pages. Moreover, the usability of these systems depends on effective techniques to retrieve information; however, the current strategies used in existing P2P systems are inefficient. To avoid query messages flooding and save resources in handling irrelevant queries, we propose a content-based query routing strategy, the Firework Query Model, to improve existing retrieval methods. In contrast to broadcasting the query message, our query message is routed intelligently according to its content. Once it reaches the target cluster, the query message is broadcasted to all peers inside the cluster much like an exploding firework. We design and implement a Distributed COntent-based Visual Information Retrieval (DISCOVIR) system with content-based query functionality and improved query efficiency. We demonstrate its scalability and efficiency through simulation. ii", "num_citations": "25\n", "authors": ["1175"]}
{"title": "Relevance feedback based on parameter estimation of target distribution\n", "abstract": " Relevance feedback formulations have been proposed to refine query result in content-based image retrieval in the past few years. Many of them focus on a learning approach to solve the feedback problem. In this paper, we present an expectation maximization approach to estimate the user's target distribution through user's feedback. Furthermore, we describe how to use the maximum entropy display to fully utilize user's feedback information. We detail the process and also demonstrate the result through experiments.", "num_citations": "25\n", "authors": ["1175"]}
{"title": "Exclusive hierarchical decoding for deep keyphrase generation\n", "abstract": " Keyphrase generation (KG) aims to summarize the main ideas of a document into a set of keyphrases. A new setting is recently introduced into this problem, in which, given a document, the model needs to predict a set of keyphrases and simultaneously determine the appropriate number of keyphrases to produce. Previous work in this setting employs a sequential decoding process to generate keyphrases. However, such a decoding method ignores the intrinsic hierarchical compositionality existing in the keyphrase set of a document. Moreover, previous work tends to generate duplicated keyphrases, which wastes time and computing resources. To overcome these limitations, we propose an exclusive hierarchical decoding framework that includes a hierarchical decoding process and either a soft or a hard exclusion mechanism. The hierarchical decoding process is to explicitly model the hierarchical compositionality of a keyphrase set. Both the soft and the hard exclusion mechanisms keep track of previously-predicted keyphrases within a window size to enhance the diversity of the generated keyphrases. Extensive experiments on multiple KG benchmark datasets demonstrate the effectiveness of our method to generate less duplicated and more accurate keyphrases.", "num_citations": "24\n", "authors": ["1175"]}
{"title": "An efficient decoding technique for Huffman codes\n", "abstract": " We present a new data structure for Huffman coding in which in addition to sending symbols in order of their appearance in the Huffman tree one needs to send codes of all circular leaf nodes (nodes with two adjacent external nodes), the number of which is always bounded above by half the number of symbols. We decode the text by using the memory efficient data structure proposed by Chen et\u00a0al. [Inform. Process. Lett. 69 (1999) 119\u2013122].", "num_citations": "24\n", "authors": ["1175"]}
{"title": "Shifu2: A network representation learning based model for advisor-advisee relationship mining\n", "abstract": " The advisor-advisee relationship represents direct knowledge heritage, and such relationship may not be readily available from academic libraries and search engines. This work aims to discover advisor-advisee relationships hidden behind scientific collaboration networks. For this purpose, we propose a novel model based on Network Representation Learning (NRL), namely Shifu2, which takes the collaboration network as input and the identified advisor-advisee relationship as output. In contrast to existing NRL models, Shifu2 considers not only the network structure but also the semantic information of nodes and edges. Shifu2 encodes nodes and edges into low-dimensional vectors respectively, both of which are then utilized to identify advisor-advisee relationships. Experimental results illustrate improved stability and effectiveness of the proposed model over state-of-the-art methods. In addition, we generate a\u00a0\u2026", "num_citations": "23\n", "authors": ["1175"]}
{"title": "Traffic prediction based power saving in cellular networks: A machine learning method\n", "abstract": " In smart cities, green cellular networks play a crucial role to support wireless access for numerous devices anywhere and anytime with efficiency and sustainability. Because base stations (BSes) consume more than 70% of overall cellular network infrastructure energy, saving the power consumption of BSes is the key task to build a green cellular network. Except for low power design of the BS hardware and software, the traffic-driven BS sleeping operation is an economical way to improve existing cellular networks, which can reduce the BS power consumption at low traffic load. However, prior BS sleeping strategies establish on the static temporal characteristics of traffic load, which ignore the fact that network traffic is influenced by many factors such as time, human mobility, holiday, weather, etc. Hence, prior traffic estimation is coarse, and the BS sleeping strategies cannot apply to the changing network traffic. In\u00a0\u2026", "num_citations": "23\n", "authors": ["1175"]}
{"title": "Extracting translations from comparable corpora for Cross-Language Information Retrieval using the language modeling framework\n", "abstract": " A main challenge in Cross-Language Information Retrieval (CLIR) is to estimate a proper translation model from available translation resources, since translation quality directly affects the retrieval performance. Among different translation resources, we focus on obtaining translation models from comparable corpora, because they provide appropriate translations for both languages and domains with limited linguistic resources. In this paper, we employ a two-step approach to build an effective translation model from comparable corpora, without requiring any additional linguistic resources, for the CLIR task. In the first step, translations are extracted by deriving correlations between source\u2013target word pairs. These correlations are used to estimate word translation probabilities in the second step. We propose a language modeling approach for the first step, where modeling based on probability distribution provides\u00a0\u2026", "num_citations": "23\n", "authors": ["1175"]}
{"title": "Local learning vs. global learning: An introduction to maxi-min margin machine\n", "abstract": " Abstract                          We present a unifying theory of the Maxi-Min Margin Machine (M4) that subsumes the Support Vector Machine (SVM), the Minimax Probability Machine (MPM), and the Linear Discriminant Analysis (LDA). As a unified approach, M4 combines some merits from these three models. While LDA and MPM focus on building the decision plane using global information and SVM focuses on constructing the decision plane in a local manner, M4 incorporates these two seemingly different yet complementary characteristics in an integrative framework that achieves good classification accuracy. We give some historical perspectives on the three models leading up to the development of M4. We then outline the M4 framework and perform investigations on various aspects including the mathematical definition, the geometrical interpretation, the time complexity, and its relationship with other existing\u00a0\u2026", "num_citations": "23\n", "authors": ["1175"]}
{"title": "Information retrieval in P2P networks using genetic algorithm\n", "abstract": " Hybrid Peer-to-Peer (P2P) networks based on the direct connection model have two shortcomings which are high bandwidth consumption and poor semi-parallel search. However, they can further be improved by the query propagation model. In this paper, we propose a novel query routing strategy called GAroute based on the query propagation model. By giving the current P2P network topology and relevance level of each peer, GAroute returns a list of query routing paths that cover as many relevant peers as possible. We model this as the Longest Path Problem in a directed graph which is NP-complete and we obtain high quality (0.95 in 100 peers) approximate solutions in polynomial time by using Genetic Algorithm (GA). We describe the problem modeling and proposed GA for finding long paths. Finally, we summarize the experimental results which measure the scalability and quality of different searching\u00a0\u2026", "num_citations": "23\n", "authors": ["1175"]}
{"title": "Intra-block max-min algorithm for embedding robust digital watermark into images\n", "abstract": " We present a new DCT-based block max-min algorithm for digital watermark embedding in images. Our algorithm uses intra-block bordering upon pixels relations to generate the watermarked image. The features of our method to embed the watermark are: (1) the watermark is perceptually invisible; (2) low loss of relevant information of the original image; (3) the watermark can be read only by using a secret key, (4) the watermark is robust against translation and area cropping; and (5) retrieval of embedded watermark does not need the original image. We describe the algorithm framework and its performance against translation and area cropping with experiments.", "num_citations": "23\n", "authors": ["1175"]}
{"title": "Montage: An image database for the fashion, textile, and clothing industry in Hong Kong\n", "abstract": " The fashion, textile, and clothing industry is a main constituent in Hong Kong. In this industry, handling a large amount of images is an important task in various phases, for example, the designing, sourcing, and merchandising phase. We develop an image database system called, Montage for managing and retrieving these visual information efficiently and effectively. Montage is an image database supporting content-based retrieval by color histogram, sketch, texture, and shape. One important feature of Montage is the Open Architecture design which makes the system extensible, customizible, and flexible. There are two aspects of this open architecture design: (1) Open DataBase Connectivity (ODBC) and (2) plug-in framework which we will discuss in more details. Moreover, we describe an experimental Java system enabling internet access to Montage. In the paper, we also present an experiment to\u00a0\u2026", "num_citations": "23\n", "authors": ["1175"]}
{"title": "Localized principal component analysis learning for face feature extraction and recognition\n", "abstract": " We present a novel face feature extraction approach using localized Principal Component Analysis (PCA) learning in face recognition tasks. The localized PCA approach produces a set of fine-tuned feature specific masks from a constrained subset of the input distribution. This method is a guided-learning based on a set of pre-defined feature points over a short training sequence. The result is the set of eigenfeatures specifically tailored for face recognition. The procedure and result of our feature extraction approach and face recognition are illustrated and discussed.", "num_citations": "23\n", "authors": ["1175"]}
{"title": "Boosting response aware model-based collaborative filtering\n", "abstract": " Recommender systems are promising for providing personalized favorite services. Collaborative filtering (CF) technologies, making prediction of users' preference based on users' previous behaviors, have become one of the most successful techniques to build modern recommender systems. Several challenging issues occur in previously proposed CF methods: (1) most CF methods ignore users' response patterns and may yield biased parameter estimation and suboptimal performance; (2) some CF methods adopt heuristic weight settings, which lacks a systematical implementation; and (3) the multinomial mixture models may weaken the computational ability of matrix factorization for generating the data matrix, thus increasing the computational cost of training. To resolve these issues, we incorporate users' response models into the probabilistic matrix factorization (PMF), a popular matrix factorization CF model\u00a0\u2026", "num_citations": "22\n", "authors": ["1175"]}
{"title": "Direct zero-norm optimization for feature selection\n", "abstract": " Zero-norm, defined as the number of non-zero elements in a vector, is an ideal quantity for feature selection. However, minimization of zero-norm is generally regarded as a combinatorially difficult optimization problem. In contrast to previous methods that usually optimize a surrogate of zero-norm, we propose a direct optimization method to achieve zero-norm for feature selection in this paper. Based on Expectation Maximization (EM), this method boils down to solving a sequence of Quadratic Programming problems and hence can be practically optimized in polynomial time. We show that the proposed optimization technique has a nice Bayesian interpretation and converges to the true zero norm asymptotically, provided that a good starting point is given. Following the scheme of our proposed zero-norm, we even show that an arbitrary-norm based Support Vector Machine can be achieved in polynomial time. A\u00a0\u2026", "num_citations": "22\n", "authors": ["1175"]}
{"title": "Constructing reliable gradient exploration for online learning to rank\n", "abstract": " With the rapid development of information retrieval (IR) systems, online learning to rank (OLR) approaches, which allow retrieval systems to automatically learn best parameters from user interactions, have attracted great research interests in recent years. In OLR, the algorithms usually need to explore some uncertain retrieval results for updating current parameters meanwhile guaranteeing to produce quality retrieval results by exploiting what have already been learned, and the final retrieval results is an interleaved list from both exploratory and exploitative results. However, existing OLR algorithms perform exploration based on either only one stochastic direction or multiple randomly selected stochastic directions, which always involve large variance and uncertainty into the exploration, and may further harm the retrieval quality. Moreover, little historical exploration knowledge is considered when conducting current\u00a0\u2026", "num_citations": "21\n", "authors": ["1175"]}
{"title": "Arbitrary norm support vector machines\n", "abstract": " Support vector machines (SVM) are state-of-the-art classifiers. Typically L2-norm or L1-norm is adopted as a regularization term in SVMs, while other norm-based SVMs, for example, the L0-norm SVM or even the L\u221e-norm SVM, are rarely seen in the literature. The major reason is that L0-norm describes a discontinuous and nonconvex term, leading to a combinatorially NP-hard optimization problem. In this letter, motivated by Bayesian learning, we propose a novel framework that can implement arbitrary norm-based SVMs in polynomial time. One significant feature of this framework is that only a sequence of sequential minimal optimization problems needs to be solved, thus making it practical in many real applications. The proposed framework is important in the sense that Bayesian priors can be efficiently plugged into most learning methods without knowing the explicit form. Hence, this builds a connection\u00a0\u2026", "num_citations": "21\n", "authors": ["1175"]}
{"title": "Semi-supervised learning from general unlabeled data\n", "abstract": " We consider the problem of semi-supervised learning (SSL) from general unlabeled data, which may contain irrelevant samples. Within the binary setting, our model manages to better utilize the information from unlabeled data by formulating them as a three-class (-1,+1, 0) mixture, where class 0 represents the irrelevant data. This distinguishes our work from the traditional SSL problem where unlabeled data are assumed to contain relevant samples only, either +1 or -1, which are forced to be the same as the given labeled samples. This work is also different from another family of popular models, universum learning (universum means \"irrelevant\" data), in that the universum need not to be specified beforehand. One significant contribution of our proposed framework is that such irrelevant samples can be automatically detected from the available unlabeled data, even though they are mixed with relevant data. This\u00a0\u2026", "num_citations": "21\n", "authors": ["1175"]}
{"title": "Bilingual web page and site readability assessment\n", "abstract": " Readability assessment is a method to measure the difficulty of a piece of text material, and it is widely used in educational field to assist instructors to prepare appropriate materials for students. In this paper, we investigate the applications of readability assessment in Web development, such that users can retrieve information which is appropriate to their levels. We propose a bilingual (English and Chinese) assessment scheme for Web page and Web site readability based on textual features, and conduct a series of experiments with real Web data to evaluate our scheme. Experimental results show that, apart from just indicating the readability level, the estimated score acts as a good heuristic to figure out pages with low textual content. Furthermore, we can obtain the overall content distribution in a Web site by studying the variation of its readability.", "num_citations": "21\n", "authors": ["1175"]}
{"title": "Emerging app issue identification from user feedback: Experience on wechat\n", "abstract": " It is vital for popular mobile apps with large numbers of users to release updates with rich features while keeping stable user experience. Timely and accurately locating emerging app issues can greatly help developers to maintain and update apps. User feedback (i.e., user reviews) is a crucial channel between app developers and users, delivering a stream of information about bugs and features that concern users. Methods to identify emerging issues based on user feedback have been proposed in the literature, however, their applicability in industry has not been explored. We apply the recent method IDEA to WeChat, a popular messenger app with over 1 billion monthly active users, and find that the emerging issues detected by IDEA are not stable (i.e., due to its inherent randomness, its results change when run multiple times even for the same inputs), and there are other problems such as long running time. To\u00a0\u2026", "num_citations": "20\n", "authors": ["1175"]}
{"title": "Pure exploration of multi-armed bandits with heavy-tailed payoffs\n", "abstract": " Inspired by heavy-tailed distributions in practical scenarios, we investigate the problem on pure exploration of Multi-Armed Bandits (MAB) with heavy-tailed payoffs by breaking the assumption of payoffs with sub-Gaussian noises in MAB, and assuming that stochastic payoffs from bandits are with finite p-th moments, where p\u2208(1,+\u221e). The main contributions in this paper are three-fold. First, we technically analyze tail probabilities of empirical average and truncated empirical average (TEA) for estimating expected payoffs in sequential decisions with heavy-tailed noises via martingales. Second, we propose two effective bandit algorithms based on different prior information (ie, fixed confidence or fixed budget) for pure exploration of MAB generating payoffs with finite p-th moments. Third, we derive theoretical guarantees for the proposed two bandit algorithms, and demonstrate the effectiveness of two algorithms in pure exploration of MAB with heavy-tailed payoffs in synthetic data and real-world financial data.", "num_citations": "20\n", "authors": ["1175"]}
{"title": "Modeling the Homophily Effect between Links and Communities for Overlapping Community Detection.\n", "abstract": " Overlapping community detection has drawn much attention recently since it allows nodes in a network to have multiple community memberships. A standard framework to deal with overlapping community detection is Matrix Factorization (MF). Although all existing MF-based approaches use links as input to identify communities, the relationship between links and communities is still under-investigated. Most of the approaches only view links as consequences of communities (community-to-link) but fail to explore how nodes\u2019 community memberships can be represented by their linked neighbors (link-to-community). In this paper, we propose a Homophily-based Nonnegative Matrix Factorization (HNMF) to model both-sided relationships between links and communities. From the community-to-link perspective, we apply a preference-based pairwise function by assuming that nodes with common communities have a higher probability to build links than those without common communities. From the link-to-community perspective, we propose a new community representation learning with network embedding by assuming that linked nodes have similar community representations. We conduct experiments on several real-world networks and the results show that our HNMF model is able to find communities with better quality compared with state-of-the-art baselines.", "num_citations": "20\n", "authors": ["1175"]}
{"title": "Measuring credibility of users in an e-learning environment\n", "abstract": " Learning Villages (LV) is an E-learning platform for people's online discussions and frequently citing postings of one another. In this paper, we propose a novel method to rank credit authors in the LV system. We first propose a k-EACM graph to describe the article citation structure in the LV system. And then we build a weighted graph model k-UCM graph to reveal the implicit relationship between authors hidden behind the citations among their articles. Furthermore, we design a graph-based ranking algorithm, the Credit Author Ranking (CAR) algorithm, which can be applied to rank nodes in a graph with negative edges. Finally, we perform experimental evaluations by simulations. The results of evaluations illustrate that the proposed method works pretty well on ranking the credibility of users in the LV system.", "num_citations": "20\n", "authors": ["1175"]}
{"title": "Finite mixture model of bounded semi-naive Bayesian networks classifier\n", "abstract": " The Semi-Naive Bayesian network (SNB) classifier, a probabilistic model with an assumption of conditional independence among the combined attributes, shows a good performance in classification tasks. However, the traditional SNBs can only combine two attributes into a combined attribute. This inflexibility together with its strong independency assumption may generate inaccurate distributions for some datasets and thus may greatly restrict the classification performance of SNBs. In this paper we develop a Bounded Semi-Naive Bayesian network (B-SNB) model based on direct combinatorial optimization. Our model can join any number of attributes within a given bound and maintains a polynomial time cost at the same time. This improvement expands the expressive ability of the SNB and thus provide potentials to increase accuracy in classification tasks. Further, aiming at relax the strong independency\u00a0\u2026", "num_citations": "20\n", "authors": ["1175"]}
{"title": "Deep validation: Toward detecting real-world corner cases for deep neural networks\n", "abstract": " The exceptional performance of Deep neural networks (DNNs) encourages their deployment in safety-and dependability-critical systems. However, DNNs often demonstrate erroneous behaviors in real-world corner cases. Existing countermeasures center on improving the testing and bug-fixing practice. Unfortunately, building a bug-free DNN-based system is almost impossible currently due to its black-box nature, so anomaly detection is imperative in practice. Motivated by the idea of data validation in a traditional program, we propose and implement Deep Validation, a novel framework for detecting real-world error-inducing corner cases in a DNN-based system during runtime. We model the specifications of DNNs by resorting to their training data and cast checking input validity of DNNs as the problem of discrepancy estimation. Deep Validation achieves excellent detection results against various corner case\u00a0\u2026", "num_citations": "19\n", "authors": ["1175"]}
{"title": "Difficulty controllable question generation for reading comprehension\n", "abstract": " We investigate the difficulty levels of questions in reading comprehension datasets such as SQuAD, and propose a new question generation setting, named Difficulty-controllable Question Generation (DQG). Taking as input a sentence in the reading comprehension paragraph and some of its text fragments (ie, answers) that we want to ask questions about, a DQG method needs to generate questions each of which has a given text fragment as its answer, and meanwhile the generation is under the control of specified difficulty labels---the output questions should satisfy the specified difficulty as much as possible. To solve this task, we propose an end-to-end framework to generate questions of designated difficulty levels by exploring a few important intuitions. For evaluation, we prepared the first dataset of reading comprehension questions with difficulty labels. The results show that the question generated by our\u00a0\u2026", "num_citations": "19\n", "authors": ["1175"]}
{"title": "Learning to suggest questions in social media\n", "abstract": " Social media systems with Q&A functionalities have accumulated large archives of questions and answers. Two representative types are online forums and community-based Q&A services. To enable users to explore the large number of questions and answers in social media systems effectively, it is essential to suggest interesting items to an active user. In this article, we address the problem of question suggestion, which targets at suggesting questions that are semantically related to a queried question. Existing bag-of-words approaches suffer from the shortcoming that they could not bridge the lexical chasm between semantically related questions. Therefore, we present a new framework, and propose the topic-enhanced translation-based language model (TopicTRLM), which fuses both the lexical and latent semantic knowledge. This fusing enables TopicTRLM to find semantically related questions to a\u00a0\u2026", "num_citations": "19\n", "authors": ["1175"]}
{"title": "Scmf: sparse covariance matrix factorization for collaborative filtering\n", "abstract": " Matrix factorization (MF) is a popular collaborative filtering approach for recommender systems due to its simplicity and effectiveness. Existing MF methods either assume that all latent features are uncorrelated or assume that all are correlated. To address the important issue of what structure should be imposed on the features, we investigate the covariance matrix of the latent features learned from real data. Based on the findings, we propose an MF model with a sparse covariance prior which favors a sparse yet non-diagonal covariance matrix. Not only can this reflect the semantics more faithfully, but imposing sparsity can also have a side effect of preventing overfitting. Starting from a probabilistic generative model with a sparse covariance prior, we formulate the model inference problem as a maximum a posteriori (MAP) estimation problem. The optimization procedure makes use of stochastic gradient descent and majorization-minimization. For empirical validation, we conduct experiments using the MovieLens and Netflix datasets to compare the proposed method with two strong baselines which use different priors. Experimental results show that our sparse covariance prior can lead to performance improvement.", "num_citations": "19\n", "authors": ["1175"]}
{"title": "Performance analysis of clustering algorithms for information retrieval in image databases\n", "abstract": " In image databases, a good indexing method makes nearest-neighbor retrieval of images accurate and efficient. Since existing alphanumeric indexing methods are not particularly suitable in image databases, researchers have proposed new methods for indexing by clustering methods. In this paper, we analyze the performance of two unsupervised neural network clustering algorithms, the competitive learning (CL) and rival penalized competitive learning (RPCL), together with k-means and VP-tree for image database indexing. We present some performance experiments to measure their accuracy and efficiency. Based on the experimental results, we concluded that RPCL and CL are good information retrieval in image database.", "num_citations": "19\n", "authors": ["1175"]}
{"title": "Social Media Modeling and Computing\n", "abstract": " The emergence of user-centric multimedia applications on social networks has been instrumental in the creation of a new form of \u201csocial\u201d media\u2013created using highly accessible and scalable publishing technologies for sharing via the internet. This timely text/reference presents the latest advances in various aspects of social media modeling and social media computing research. Gathering together superb research from a range of established international conferences and workshops, the editors coherently organize and present each of the topics in relation to the basic principles and practices of social media modeling and computing. Individual chapters can be also be used as self-contained references on the material covered. Topics and features: presents contributions from an international selection of preeminent experts in the field; discusses topics on social-media content analysis, including social-image tag analysis and ranking, tag-based social image search, analysis by combining multimodal features, and multi-label social-image annotation; examines social-media system design and analysis, covering mechanisms for incentivizing contributions, analysis of users and online behaviors in video sharing portals, and visual analytic tools for event analysis; investigates access control for privacy and security issues in social networks; describes emerging applications of social media, for music recommendation, automatic image annotation, and the analysis and improvement of photo-books. This unique text is a must-read, must-use tool for software developers, researchers and graduate students working on multimedia, web search, data mining\u00a0\u2026", "num_citations": "18\n", "authors": ["1175"]}
{"title": "Ensemble learning for imbalanced e-commerce transaction anomaly classification\n", "abstract": " This paper presents the main results of our on-going work, one month before the deadline, on the 2009 UC San Diego data mining contest. The tasks of the contest are to rank the samples in two e-commerce transaction anomaly datasets according to the probability each sample has a positive label. The performance is evaluated by the lift at 20% on the probability of the two datasets. A main difficulty for the tasks is that the data is highly imbalanced, only about 2% of data are labeled as positive, for both tasks. We first preprocess the data on the categorical features and normalize all the features. Here, we present our initial results on several popular classifiers, including Support Vector Machines, Neural Networks, AdaBoosts, and Logistic Regression. The objective is to get benchmark results of these classifiers without much modification, so it will help us to select a classifier for future tuning. Further, based on\u00a0\u2026", "num_citations": "18\n", "authors": ["1175"]}
{"title": "Improving recommendation accuracy using networks of substitutable and complementary products\n", "abstract": " Recommender systems are ubiquitous in applications ranging from e-commerce to social media, helping users to navigate a huge selection of items and to meet a variety of special needs and user tastes. Incorporating contextual knowledge into such systems - such as relational information - has proven to be an effective way to improve recommendation accuracy. A popular line of research aims to model relationships between users, through their connections in a social network. In contrast, we aim to model complex relationships between products, using data based on co-purchase and co-browsing behavior. Modeling such networks presents a variety of challenges, in particular because the features that make two items complementary (or likely to be co-purchased) are far more complex than mere similarity. To model these complex relationships we develop a method based on pairwise ranking and embedding\u00a0\u2026", "num_citations": "17\n", "authors": ["1175"]}
{"title": "Bridging the P2P and WWW Divide with DISCOVIR-DIStributed COntent-based Visual Information Retrieval.\n", "abstract": " In the light of image retrieval evolving from text annotation to content-based and from standalone applications to web-based search engines, we foresee the need for deploying content-based image retrieval (CBIR) into Peer-to-Peer (P2P) architecture. By doing so, we not only distribute the tasks of feature extraction, indexing and storage of image data into peers, we also introduce another aspect of searching in addition to filename-based method in prevalent P2P applications. Through the deployment of DISCOVIR, we introduce a model to improve query efficiency targeting on content-based search.Current P2P applications require installing special purpose software and proprietary protocols for information retrieval, which limit the number of audience. To make use of the WWW to increase popularity of P2P, we propose DISCOVIR Everywhere to bridge the two different worlds, P2P and WWW. We outline the process of accessing DISCOVIR network through web browsers or mobile devices, by the coordination of a light weighted gateway, with reduced workload compared to existing methodology.", "num_citations": "17\n", "authors": ["1175"]}
{"title": "A two-stage framework for polygon retrieval\n", "abstract": " We propose a two-stage framework for polygon retrieval which incorporates both qualitative and quantitative measures of polygons in the first and second stage respectively. The first stage uses Binary Shape Descriptor as a mean to prune the search space. The second stage uses any available polygon matching and similarity measuring technique to compare model polygons with the target polygon. This two-stage framework uses a combination of model-driven approach and data-driven approach. It is more efficient than model-driven approach since it reduces the number of polygons needed to be compared. By using binary string as index, it also avoids the difficulty and inefficiency of manipulating complex multi-dimensional index structure. This two-stage framework can be incorporated into image database systems for providing query-by-shape facility. We also propose two similarity measures for\u00a0\u2026", "num_citations": "17\n", "authors": ["1175"]}
{"title": "Multilingual information retrieval in the language modeling framework\n", "abstract": " Multilingual information retrieval (MLIR) provides results that are more comprehensive than those of mono- and cross-lingual retrieval. Methods for MLIR are categorized as: (1) Fusion-based methods that merge results from multiple retrieval runs, and (2) Direct methods that build a unique index for the entire collection. Merging results of individual runs reduces the overall effectiveness, while more effective direct methods suffer from either time complexity and memory overhead, or over-weighting of index terms. In this paper, we propose a direct MLIR approach by using the language modeling framework that includes a novel multilingual language model estimation for documents, and a new way to globally estimate word statistics. These contributions enable ranking documents in multiple languages in one retrieval phase without having the problems of the previous direct methods. Moreover, our approach\u00a0\u2026", "num_citations": "16\n", "authors": ["1175"]}
{"title": "Communities of Yahoo! answers and Baidu Zhidao: Complementing or competing?\n", "abstract": " Community Question Answering (CQA) attracts increasing volume of research on question retrieval, high quality content discovery and experts finding. However, few studies are focused on community per se of CQA services and also provide an in-depth analysis of them. This paper aims to enrich our knowledge on two of these CQA services, namely Yahoo! Answers and Baidu Zhidao through reviewing their communities, comparing similarities and differences of the two communities, together with analyzing their influence on solving questions. Six data sets are employed for comparative analysis. In this paper: (1) We analyze the social network structures of Yahoo! Answers and Baidu Zhidao; (2) We compare the the social community characteristics of top contributors; (3) We reveal the behaviors of users in different categories in these two portals; (4) We reveal temporal trends of these characteristics; (5) We find that\u00a0\u2026", "num_citations": "16\n", "authors": ["1175"]}
{"title": "Location-based topic evolution\n", "abstract": " As the advance of mobile technologies, geographical records can be easily embedded in the data to form the location-associated documents. For example, in Twitter, the location of tweets can be identified by the GPS locations or IP addresses from smart phones. In Flickr, photos may be tagged and recorded with GPS locations. With the geographical information, it is more likely to model users' interests in different regions so as to determine the corresponding marketing strategy. Due to its potential in providing personalized and context-aware services, several pieces of work have started to explore in this area. One stream of work tries to discover users' interest topics from location-associated documents. These models work under the assumption that words close in geographical positions are likely to be clustered into the same geographical topic. However, they attain this in a static mode. That is, they do not consider\u00a0\u2026", "num_citations": "16\n", "authors": ["1175"]}
{"title": "A biased minimax probability machine-based scheme for relevance feedback in image retrieval\n", "abstract": " In recent years, minimax probability machines (MPMs) have demonstrated excellent performance in a variety of pattern recognition problems. At the same time various machine learning methods have been applied on relevance feedback tasks in content-based image retrieval (CBIR). One of the problems in typical techniques for relevance feedback is that they treat the relevant feedback and irrelevant feedback equally. Since the negative instances largely outnumber the positive instances, the assumption that they are balanced is incorrect as the data are biased. In this paper we study how biased minimax probability machine (BMPM), a variation of MPM, can be applied for relevance feedback in image retrieval tasks. Different from previous methods, this model directly controls the accuracy of classification of the future data to construct biased classifiers. Hence, it provides a rigorous treatment on imbalanced dataset\u00a0\u2026", "num_citations": "16\n", "authors": ["1175"]}
{"title": "Using biased support vector machine to improve retrieval result in image retrieval with self-organizing map\n", "abstract": " The relevance feedback approach is a powerful technique in content-based image retrieval (CBIR) tasks. In past years, many intra-query learning techniques have been proposed to solve the relevance feedback problem. Among these techniques, Support Vector Machines (SVM) have shown promising results in the area. More specifically, in relevance feedback applications the SVMs are typically been used as binary classifiers with the balanced input data assumption. In other words, they do not consider the imbalanced dataset problem in relevance feedback, i.e., the non-relevant examples outnumbered the relevant examples. In this paper, we propose to apply our Biased Support Vector Machine (BSVM) to address this problem. Moreover, we apply our Self-Organizing Map-based inter-query technique to reorganize the feature vector space, in order to incorporate the information provided by past queries\u00a0\u2026", "num_citations": "16\n", "authors": ["1175"]}
{"title": "A neural network based testbed for modelling sensorimotor integration in robotic applications\n", "abstract": " Preliminary work toward the integration of sensorimotor interactions using the Neural Simulation Language (NSL) and the Rapid Robotics Application Development (R/sup 2/AD) environment for computing sensory information and creating motor behavior, respectively, for the purpose of visuomotor coordination in the real world is described. It is noted that, by combining these environments, one gains greater flexibility in designing neural networks to model various perceptions and behaviors in biological systems. This system also gives the computational neurobiologist a new avenue of investigation: the ability to see one's algorithms, based upon neurophysiological and behavioral data, come to life within an artificial creature. Such a capability can allow a better behavioural comparison between the real system and the artificial algorithm. As an application example, the modeling of the visual sensory modality in\u00a0\u2026", "num_citations": "16\n", "authors": ["1175"]}
{"title": "Geo-pairwise ranking matrix factorization model for point-of-interest recommendation\n", "abstract": " Point-of-interest (POI) recommendation that suggests new locations for people to visit is an important application in location-based social networks (LBSNs). Compared with traditional recommendation problems, e.g., movie recommendation, geographical influence is a special feature that plays an important role in recommending POIs. Various methods that incorporate geographical influence into collaborative filtering techniques have recently been proposed for POI recommendation. However, previous geographical models have struggled with a problem of geographically noisy POIs, defined as POIs that follow the geographical influence but do not satisfy users\u2019 preferences. We observe that users in the same geographical region share many POIs, and thus we propose the co-geographical influence to filter geographically noisy POIs. Furthermore, we propose the Geo-Pairwise Ranking Matrix\u00a0\u2026", "num_citations": "15\n", "authors": ["1175"]}
{"title": "Exploit of online social networks with community-based graph semi-supervised learning\n", "abstract": " With the rapid growth of the Internet, more and more people interact with their friends in online social networks like Facebook. Currently, the privacy issue of online social networks becomes a hot and dynamic research topic. Though some privacy protecting strategies are implemented, they are not stringent enough. Recently, Semi-Supervised Learning (SSL), which has the advantage of utilizing the unlabeled data to achieve better performance, attracts much attention from the web research community. By utilizing a large number of unlabeled data from websites, SSL can effectively infer hidden or sensitive information on the Internet. Furthermore, graph-based SSL is much more suitable for modeling real-world objects with graph characteristics, like online social networks. Thus, we propose a novel Community-based Graph (CG) SSL model that can be applied to exploit security issues in online social\u00a0\u2026", "num_citations": "15\n", "authors": ["1175"]}
{"title": "Local support vector regression for financial time series prediction\n", "abstract": " We consider the regression problem for financial time series. Typically, financial time series are non-stationary and volatile in nature. Because of its good generalization power and the tractability of the problem, the Support Vector Regression (SVR) has been extensively applied in financial time series prediction. The standard SVR adopts the l p -norm (p = 1 or 2) to model the functional complexity of the whole data set and employs a fixed e-tube to tolerate noise. Although this approach has proved successful both theoretically and empirically, it considers data in a global fashion only. Therefore it may lack the flexibility to capture the local trend of data; this is a critical aspect of volatile data, especially financial time series data. Aiming to address this issue, we propose the Local Support Vector Regression (LSVR) model. This novel model is demonstrated to provide a systematic and automatic scheme to adapt the\u00a0\u2026", "num_citations": "15\n", "authors": ["1175"]}
{"title": "A short summary of digital watermarking techniques for multimedia data\n", "abstract": " The growth of networked multimedia systems has created the need for the copyright protection of various digital medium, eg, images, audio clips, video, etc. Copyright protection involves the authentication of ownership and the identification of illegal copies of a (possibly forged) image. One approach used to address this problem is to add a visible or invisible structure to an image that can be used to seal or mark it. These structures are known as digital watermarks. The watermark is capable of carrying such information as authentication or authorization codes, or a legend essential for image interpretation. This capability is envisaged to find application in image tagging, copyright enforcement, counterfeit protection, and controlled access. In this paper, we first outline the desirable characteristics of digital watermarks. Previous work in digital watermarking is then summarized. Several recent approaches that address these issues are also discussed.", "num_citations": "15\n", "authors": ["1175"]}
{"title": "Using rival penalized competitive clustering for feature indexing in Hong Kong's textile and fashion image database\n", "abstract": " Efficient content-based information retrieval in image databases depends on good indexing structures of the extracted features. While indexing structures for text retrieval are well understood, efficient and robust indexing structures for image retrieval are still elusive. We use the rival penalized competitive learning (RPCL) clustering algorithm to partition extracted feature vectors from images to produce an indexing structure for Montage, an image database developed for Hong Kong's textile, clothing, and fashion industry supporting content-based retrieval, e.g., by color, texture, sketch, and shape. RPCL is a stochastic heuristic clustering method which provides good cluster center approximation and is computationally efficient. Using synthetic data, we demonstrate the recall and precision performance of nearest-neighbor feature retrieval based on the indexing structure generated by RPCL.", "num_citations": "15\n", "authors": ["1175"]}
{"title": "Graphical lasso quadratic discriminant function and its application to character recognition\n", "abstract": " Multivariate Gaussian distribution is a popular assumption in many pattern recognition tasks. The quadratic discriminant function (QDF) is an effective classification approach based on this assumption. An improved algorithm, called modified QDF (or MQDF in short) has achieved great success and is widely recognized as the state-of-the-art method in character recognition. However, because both of the two approaches estimate the mean and covariance by the maximum-likelihood estimation (MLE), they often lead to the loss of the classification accuracy when the number of the training samples is small. To attack this problem, in this paper, we engage the graphical lasso method to estimate the covariance and propose a new classification method called the graphical lasso quadratic discriminant function (GLQDF). By exploiting a coordinate descent procedure for the lasso, GLQDF can estimate the covariance matrix\u00a0\u2026", "num_citations": "14\n", "authors": ["1175"]}
{"title": "Supervised self-taught learning: Actively transferring knowledge from unlabeled data\n", "abstract": " We consider the task of Self-taught Learning (STL) from unlabeled data. In contrast to semi-supervised learning, which requires unlabeled data to have the same set of class labels as labeled data, STL can transfer knowledge from different types of unlabeled data. STL uses a three-step strategy: (1) learning high-level representations from unlabeled data only, (2) re-constructing the labeled data via such representations and (3) building a classifier over the re-constructed labeled data. However, the high-level representations which are exclusively determined by the unlabeled data, may be inappropriate or even misleading for the latter classifier training process. In this paper, we propose a novel Supervised Self-taught Learning (SSTL) framework that successfully integrates the three isolated steps of STL into a single optimization problem. Benefiting from the interaction between the classifier optimization and the\u00a0\u2026", "num_citations": "14\n", "authors": ["1175"]}
{"title": "Let\u2019s tango\u2013finding the right couple for feature-opinion association in sentiment analysis\n", "abstract": " One approach in opinion mining is to perform sentiment classification at the sentence level. User\u2019s view on a discovered product feature is predicted by the opinion words, e.g. adjectives, appeared in the same sentence. A number of previous works has been proposed and these approaches typically treat the feature and word relations identically. Blindly using sentiments of all opinion words to perform classification would lead to false results. In this paper, we investigate the relationship between features and opinion words using the corpus-based approach. We proposed a Feature-Opinion Association (FOA) algorithm to match these two in sentences to improve sentiment analysis results. We construct a feature-based sentiment lexicon using the proposed algorithm in the sentiment identification process. Extensive experiments based on a commercial product review site show that our method is quite effective\u00a0\u2026", "num_citations": "14\n", "authors": ["1175"]}
{"title": "Financial time series prediction using non-fixed and asymmetrical margin setting with momentum in support vector regression\n", "abstract": " Recently, Support Vector Regression (SVR) has been applied to financial time series prediction. The financial time series usually contains the characteristics of small sample size, high noise and non-stationary. Especially the volatility of the time series is time-varying and embeds some valuable information about the series. Previously, we had proposed to use the volatility in the data to adaptively change the width of the margin in SVR. We have noticed that up margin and down margin would not necessary be the same, and also observed that their choice would affect the upside risk, downside risk and as well as the overall prediction performance. In this work, we introduce a novel approach to adopt the momentum in the asymmetrical margins setting. We applied and compared this method to predict the Hang Seng Index and Dow Jones Industrial Average.", "num_citations": "14\n", "authors": ["1175"]}
{"title": "A feature-based image retrieval database for the fashion, textile, and clothing industry in Hong Kong\n", "abstract": " We present an image database system for the fashion, textile, and clothing industry in Hong Kong supporting featurebased retrieval by color histogram, color sketch, shape, and texture. The Query-by-color-histogram method uses feature vectors extracted from the color distribution of an image for retrieval. The Query-by-color-sketch method makes use of the regionalized color information of the image for retrieval. The Query-by-shape method uses a two-stage polygon representation for shape searching. The Query-by-texture method uses statistical texture analysis to compute textural features for texture matching. One important feature of our system is the Open Architecture design. This design allows the system to be extensible, maintainable, and exible. There are two aspects of this open architecture:(1) Open DataBase Connectivity (ODBC) and (2) plug-in framework. Moreover, we describe a server/client system design enabling internet access to the system. Based on our system design, we demonstrate a fashion image database and a fabric image database.", "num_citations": "14\n", "authors": ["1175"]}
{"title": "Mining business opportunities from location-based social networks\n", "abstract": " Urbanization's rapid progress has modernized a large number of human beings' lives. This urbanization progress is accompanied by the increase of a variety of shops (eg, restaurants and fitness centers) to meet the increasing citizens, which means business opportunities for the investors. Nevertheless, it is difficult for the investors to catch such opportunities because opening what kind of business at which place is not easy to decide. In this paper, we take this challenge and define the business opportunity mining problem, which recommends new business categories at a partitioned business district. Specifically, we exploit the data from location-based social networks (LBSNs) to mine the business opportunities, guiding the business owners to open new commercial shops in certain categories at a particular area. First, we define the properties of a business district and propose a greedy algorithm to partition a city\u00a0\u2026", "num_citations": "13\n", "authors": ["1175"]}
{"title": "Bibliographic attributes extraction with layer-upon-layer tagging\n", "abstract": " Bibliographic attributes extraction is an important research topic for digital libraries. In this paper we propose a rule-based method for bibliographic attributes extraction with Layer-upon-Layer Tagging (LLT). The method analyzes bibliographic attributes' appearances and punctuations to perform format and semantic taggings on two defined parsing layers. The method also resolves to specifically constructed lexicons to achieve high accuracy of semantic tagging. In the experimental evaluation on 1,000 reference strings, the accuracy of author tagging reaches to 96.8% and the accuracy of whole reference tagging is 82.9%. The experimental results demonstrate that the proposed LLT method can tag bibliographic attributes in reference strings with high degree of accuracy.", "num_citations": "13\n", "authors": ["1175"]}
{"title": "Relevance feedback content-based image retrieval using query distribution estimation based on maximum entropy principle\n", "abstract": " In the last few years, we have seen an upsurge of interest in content-based image retrieval (CBIR){the selection of images from a collection via features extracted from images themselves. Typically the nearest-neighbor rule is used to retrieve images from a query image. However, the underlying query distribution may not be isotropic in nature. Hence, a more sophisticated estimation for the query distribution is required. We propose a novel relevance feedback framework for image retrieval which contains two stages:(1) to estimate the query distribution based on relevance feedback information and (2) to generate a set of inquiries for relevance selection based on the Maximum Entropy Principle. We demonstrate these two stages in detail. Moreover, experiments have been performed on a trademark image database. The results show our proposed framework is effective in image retrieval with a few relevant samples.", "num_citations": "13\n", "authors": ["1175"]}
{"title": "Can irrelevant data help semi-supervised learning, why and how?\n", "abstract": " Previous semi-supervised learning (SSL) techniques usually assume unlabeled data are relevant to the target task. That is, they follow the same distribution as the targeted labeled data. In this paper, we address a different and very difficult scenario in SSL, where the unlabeled data may be a mixture of data relevant or irrelevant to the target binary classification task. In our framework, we do not require explicitly prior knowledge on the relatedness of the unlabeled data to the target data. In order to alleviate the effect of the irrelevant unlabeled data and utilize the implicit knowledge among all available data, we develop a novel maximum margin classifier, named the tri-class support vector machine (3C-SVM), to seek an inductive rule to separate the target binary classification task well while finding out the irrelevant data by-product. To attain this goal, we introduce a new min loss function, which can relieve the impact\u00a0\u2026", "num_citations": "12\n", "authors": ["1175"]}
{"title": "Collaborative filtering model for user satisfaction prediction in spoken dialog system evaluation\n", "abstract": " Developing accurate models to automatically predict user satisfaction about the overall quality of a Spoken Dialog System (SDS) is highly desirable for SDS evaluation. In the original PARADISE framework, a linear regression model is trained using measures drawn from rated dialogs as predictors with user satisfaction as the target. In this paper, we extend PARADISE by introducing a collaborative filtering (CF) model for user satisfaction prediction and its corresponding extension. This prediction model is drawn from the idea of CF in recommendation systems, which uses information from near neighbors of an unrated dialog to predict its user satisfaction. We also present the methodology of collecting user judgments on SDS quality with crowdsourcing through Amazon Mechanical Turk. Experimental results show that the CF approaches could distinctly improve the prediction accuracy of user satisfaction.", "num_citations": "12\n", "authors": ["1175"]}
{"title": "Facial expression synthesis by radial basis function network and image warping\n", "abstract": " This paper presents a novel approach in synthesizing various facial expressions by image warping, using spatial displacement of facial landmark point generated by radial basis function (RBF) networks. We trained two RBF networks from test images to obtain these spatial displacement. One RBF network can be used to generate different degrees of expressions, while the other can be used to obtain mixed facial expressions. We discuss the method used and demonstrate the results.", "num_citations": "12\n", "authors": ["1175"]}
{"title": "A unified dual-view model for review summarization and sentiment classification with inconsistency loss\n", "abstract": " Acquiring accurate summarization and sentiment from user reviews is an essential component of modern e-commerce platforms. Review summarization aims at generating a concise summary that describes the key opinions and sentiment of a review, while sentiment classification aims to predict a sentiment label indicating the sentiment attitude of a review. To effectively leverage the shared sentiment information in both review summarization and sentiment classification tasks, we propose a novel dual-view model that jointly improves the performance of these two tasks. In our model, an encoder first learns a context representation for the review, then a summary decoder generates a review summary word by word. After that, a source-view sentiment classifier uses the encoded context representation to predict a sentiment label for the review, while a summary-view sentiment classifier uses the decoder hidden states\u00a0\u2026", "num_citations": "11\n", "authors": ["1175"]}
{"title": "Revisiting parameter sharing for automatic neural channel number search\n", "abstract": " Recent advances in neural architecture search inspire many channel number search algorithms~(CNS) for convolutional neural networks. To improve searching efficiency, parameter sharing is widely applied, which reuses parameters among different channel configurations. Nevertheless, it is unclear how parameter sharing affects the searching process. In this paper, we aim at providing a better understanding and exploitation of parameter sharing for CNS. Specifically, we propose affine parameter sharing~(APS) as a general formulation to unify and quantitatively analyze existing channel search algorithms. It is found that with parameter sharing, weight updates of one architecture can simultaneously benefit other candidates. However, it also results in less confidence in choosing good architectures. We thus propose a new strategy of parameter sharing towards a better balance between training efficiency and architecture discrimination. Extensive analysis and experiments demonstrate the superiority of the proposed strategy in channel configuration against many state-of-the-art counterparts on benchmark datasets.", "num_citations": "11\n", "authors": ["1175"]}
{"title": "Infar: Insight extraction from app reviews\n", "abstract": " App reviews play an essential role for users to convey their feedback about using the app. The critical information contained in app reviews can assist app developers for maintaining and updating mobile apps. However, the noisy nature and large-quantity of daily generated app reviews make it difficult to understand essential information carried in app reviews. Several prior studies have proposed methods that can automatically classify or cluster user reviews into a few app topics (eg, security). These methods usually act on a static collection of user reviews. However, due to the dynamic nature of user feedback (ie, reviews keep coming as new users register or new app versions being released) and multiple analysis dimensions (eg, review quantity and user rating), developers still need to spend substantial effort in extracting contrastive information that can only be teased out by comparing data from multiple time\u00a0\u2026", "num_citations": "11\n", "authors": ["1175"]}
{"title": "Leveraging social connections to improve peer assessment in MOOCs\n", "abstract": " With the advent of Massive Open Online Courses (MOOCs), students from all over the world can access to quality courses via a web browser. Due to their great convenience, a popular MOOC can easily attract tens of thousands of students to enroll. Hence, a challenging problem in MOOCs is to find an efficient way to grade a large scale of assignments. To address this problem, peer assessment was proposed to grade the assignments in a scalable way. In peer assessment, each student is asked to access a subset of his/her peers' assignments via a web interface, then all these peer grades are aggregated to predict a final grade for each submitted assignment. These peer grades are very noisy due to the fact that different students have different bias and reliability. Several probabilistic models were proposed to improve the accuracy of the predicted grades by explicitly modeling the bias and reliability of each\u00a0\u2026", "num_citations": "11\n", "authors": ["1175"]}
{"title": "Exploiting game theoretic analysis for link recommendation in social networks\n", "abstract": " The popularity of Online Social Networks (OSNs) has attracted great research interests in different fields. In Economics, researchers use game theory to analyze the mechanism of network formation, which is called Network Formation Game. While in Computer Science, much effort has been done in building machine learning models to predict future or missing links. However, there are few works considering how to combine game theoretic analysis and machine learning models. Therefore, in this paper, we study the problem of Exploiting Game Theoretic Analysis for Link Recommendation in Social Networks. Our goal is to improve link recommendation accuracy via leveraging the power of Network Formation Games into machine learning models. We present two different approaches to solve this problem. First, we propose a three-phase method that straightforwardly combines game theoretic analysis with machine\u00a0\u2026", "num_citations": "11\n", "authors": ["1175"]}
{"title": "A probabilistic cooperative\u2013competitive hierarchical model for global optimization\n", "abstract": " Stochastic searching methods have been applied widely to areas such as continuous and combinatorial optimization problems in a number of disciplines. Many existing methods solve these problems by navigating on the surface of the possibly rugged landscape. This kind of navigation is not very effective because the property of the landscape at different resolutions can be very different. Time spent at the beginning of the search on the detailed part of the landscape is often useless. Appropriate searching strategies should be adopted at different resolutions. In this paper, we propose a new probabilistic searching model for global optimization. The main contributions of the model are (1) to provide a basis for resolution control and smoothing of search space and (2) to introduce continuous memory into stochastic search. The basis of resolution control is achieved by dividing the search space into a finite number of n\u00a0\u2026", "num_citations": "11\n", "authors": ["1175"]}
{"title": "Non-hierarchical clustering with rival penalized competitive learning for information retrieval\n", "abstract": " In large content-based image database applications, efficient information retrieval depends heavily on good indexing structures of the extracted features. While indexing techniques for text retrieval are well understood, efficient and robust indexing methodology for image retrieval is still in its infancy. In this paper, we present a non-hierarchical clustering scheme for index generation using the Rival Penalized Competitive Learning (RPCL) algorithm. RPCL is a stochastic heuristic clustering method which provides good cluster center approximation and is computationally efficient. Using synthetic data as well as real data, we demonstrate the recall and precision performance measurement of nearest-neighbor feature retrieval based on the indexing structure generated by RPCL.", "num_citations": "11\n", "authors": ["1175"]}
{"title": "Weight assignment in dissimilarity function for Chinese cursive script character image retrieval using genetic algorithm\n", "abstract": " When solving the problem of content basedimage retrieval, using a single image attribute may not have enough discriminative information for retrieval. On the other hand, when multiple features are used, it is hard to determine the suitable weighting factors to various shape features. Therefore, we proposed to use a Genetic Algorithm (GA) to determine the weighting factors in the dissimilarity function for trademark image retrieval in 3]. In this paper, we use the same technique to find the weights in the dissimilarity function for image retrieval in a Chinese cursive script character image database. Several shape features are chosen to represent a Chinese calligraphy character. They are edge direction histogram of the original image, eccentricity of the original, thinned, and normalized image, and the first three invariant moments of the original, thinned, and normalized image. A database of 1400 monochromatic images was tested. From the results, the learned dissimilarity function increased the accuracy of retrievals. Besides, our system was robust to retrieve deformed images. We also compared our approach with other integration methods. Experimental results are presented to show the feasibility and practicability of the proposed system.", "num_citations": "11\n", "authors": ["1175"]}
{"title": "A Survey on Deep Semi-supervised Learning\n", "abstract": " Deep semi-supervised learning is a fast-growing field with a range of practical applications. This paper provides a comprehensive survey on both fundamentals and recent advances in deep semi-supervised learning methods from model design perspectives and unsupervised loss functions. We first present a taxonomy for deep semi-supervised learning that categorizes existing methods, including deep generative methods, consistency regularization methods, graph-based methods, pseudo-labeling methods, and hybrid methods. Then we offer a detailed comparison of these methods in terms of the type of losses, contributions, and architecture differences. In addition to the past few years' progress, we further discuss some shortcomings of existing methods and provide some tentative heuristic solutions for solving these open problems.", "num_citations": "10\n", "authors": ["1175"]}
{"title": "Maximum margin semi-supervised learning with irrelevant data\n", "abstract": " Semi-supervised learning (SSL) is a typical learning paradigms training a model from both labeled and unlabeled data. The traditional SSL models usually assume unlabeled data are relevant to the labeled data, ie, following the same distributions of the targeted labeled data. In this paper, we address a different, yet formidable scenario in semi-supervised classification, where the unlabeled data may contain irrelevant data to the labeled data. To tackle this problem, we develop a maximum margin model, named tri-class support vector machine (3C-SVM), to utilize the available training data, while seeking a hyperplane for separating the targeted data well. Our 3C-SVM exhibits several characteristics and advantages. First, it does not need any prior knowledge and explicit assumption on the data relatedness. On the contrary, it can relieve the effect of irrelevant unlabeled data based on the logistic principle and\u00a0\u2026", "num_citations": "10\n", "authors": ["1175"]}
{"title": "Enrichment and reductionism: Two approaches for web query classification\n", "abstract": " Classifying web queries into predefined target categories, also known as web query classification, is important to improve search relevance and online advertising. Web queries are however typically short, ambiguous and in constant flux. Moreover, target categories often lack standard taxonomies and precise semantic descriptions. These challenges make the web query classification task a non-trivial problem. In this paper, we present two complementary approaches for the web query classification task. First is the enrichment method that uses the World Wide Web (WWW) to enrich target categories and further models the web query classification as a search problem. Our second approach, the reductionist approach, works by reducing web queries to few central tokens. We evaluate the two approaches based on few thousands human labeled local and non-local web queries. From our study, we find the two\u00a0\u2026", "num_citations": "10\n", "authors": ["1175"]}
{"title": "Improving question retrieval in community question answering with label ranking\n", "abstract": " Community question answering services (CQA), which provides a platform for people with diverse backgrounds to share information and knowledge, has become an increasingly popular research topic recently as made popular by sites such as Yahoo! Answers 1 , answerbag 2 , zhidao 3 , etc. Question retrieval (QR) in CQA can automatically find the most relevant and recent questions that have been solved by other users. Current QR approaches typically consider using diverse retrieval models, but they fail to analyze users' intention. User intentions such as finding facts, interacting with others, seeking reasons, etc. reflect what the users really want to know. Hence, we propose to integrate user intention analysis into QR. Firstly, we classify questions into different and multiple types of users' intentions. Another practical problem is that there naturally exist some preferences among the possible questions types. The\u00a0\u2026", "num_citations": "10\n", "authors": ["1175"]}
{"title": "The generalized dependency degree between attributes\n", "abstract": " Inspired by the dependency degree \u03b3, a traditional measure in Rough Set Theory, we propose a generalized dependency degree, \u0393, between two given sets of attributes, which counts both deterministic and indeterministic rules while \u03b3 counts only deterministic rules. We first give its definition in terms of equivalence relations and then interpret it in terms of minimal rules, and further describe the algorithm for its computation. To understand \u0393 better, we investigate its various properties. We further extend \u0393 to incomplete information systems. To show its advantage, we make a comparative study with the conditional entropy and \u03b3 in a number of experiments. Experimental results show that the speed of the new C4.5 using \u0393 is greatly improved when compared with the original C4.5R8 using conditional entropy, while the prediction accuracy and tree size of the new C4.5 are comparable with the original one. Moreover, \u0393\u00a0\u2026", "num_citations": "10\n", "authors": ["1175"]}
{"title": "Two-stage multi-class AdaBoost for facial expression recognition\n", "abstract": " Although AdaBoost has achieved great success, it still suffers from following problems: (1) the training process could be unmanageable when the number of features is extremely large; (2) the same weak classifier may be learned multiple times from a weak classifier pool, which does not provide additional information for updating the model; (3) there is an imbalance between the amount of the positive samples and that of the negative samples for multi-class classification problems. In this paper, we propose a two-stage AdaBoost learning framework to select and fuse the discriminative feature effectively. Moreover, an improved AdaBoost algorithm is developed to select weak classifiers. Instead of boosting in the original feature space, whose dimensionality is usually very high, multiple feature subspaces with lower dimensionality are generated. In the first stage, boosting is carried out in each subspace. Then the\u00a0\u2026", "num_citations": "10\n", "authors": ["1175"]}
{"title": "Competitive learning clustering for information retrieval in image databases\n", "abstract": " Efficient and accurate information retrieval is a key issue in image databases. Since image databases use image features for retrieval, traditional alphanumeric indexing methods are not particularly suitable for content-based retrieval. Therefore, new indexing methods must be designed and implemented specifically for image retrieval. In this paper, we propose to use competitive learning clustering algorithm to produce an indexing structure for Montage, which is an image database supporting content-based retrieval using color, texture, sketch, and shape for Hong Kong's fashion, textile, and clothing industry. Competitive learning is a stochastic and efficient clustering method which provides good cluster center approximation for image database indexing. Using synthetic data, we demonstrate the Recall and Precision performance of nearest neighbor feature retrieval based on the indexing structure generated by competitive learning clustering and show that the algorithm works well. 1Introd...", "num_citations": "10\n", "authors": ["1175"]}
{"title": "Two-stage polygon representation for efficient shape retrieval in image databases\n", "abstract": " We propose a two-stage polygon representation for polygon shape matching in image databases. The first stage performs qualitative measure of shape by using the Binary String Descriptor to quickly find equivalent classes of polygons. The second stage performs quantitative measure of shape by using a Multi-Resolution Area Matching which operates on the subset of shapes belonging to the same equivalent class by a coarse-to-fine area matching strategy. We describe these techniques and demonstrate how this two-stage representation works for a simple shape image database.", "num_citations": "10\n", "authors": ["1175"]}
{"title": "Deepobfuscation: Securing the structure of convolutional neural networks via knowledge distillation\n", "abstract": " This paper investigates the piracy problem of deep learning models. Designing and training a well-performing model is generally expensive. However, when releasing them, attackers may reverse engineer the models and pirate their design. This paper, therefore, proposes deep learning obfuscation, aiming at obstructing attackers from pirating a deep learning model. In particular, we focus on obfuscating convolutional neural networks (CNN), a widely employed type of deep learning architectures for image recognition. Our approach obfuscates a CNN model eventually by simulating its feature extractor with a shallow and sequential convolutional block. To this end, we employ a recursive simulation method and a joint training method to train the simulation network. The joint training method leverages both the intermediate knowledge generated by a feature extractor and data labels to train a simulation network. In this way, we can obtain an obfuscated model without accuracy loss. We have verified the feasibility of our approach with three prevalent CNNs, i.e., GoogLeNet, ResNet, and DenseNet. Although these networks are very deep with tens or hundreds of layers, we can simulate them in a shallow network including only five or seven convolutional layers. The obfuscated models are even more efficient than the original models. Our obfuscation approach is very effective to protect the critical structure of a deep learning model from being exposed to attackers. Moreover, it can also thwart attackers from pirating the model with transfer learning or incremental learning techniques because the shallow simulation network bears poor learning ability. To\u00a0\u2026", "num_citations": "9\n", "authors": ["1175"]}
{"title": "Learning to rank using localized geometric mean metrics\n", "abstract": " Many learning-to-rank~(LtR) algorithms focus on query-independent model, in which query and document do not lie in the same feature space, and the rankers rely on the feature ensemble about query-document pair instead of the similarity between query instance and documents. However, existing algorithms do not consider local structures in query-document feature space, and are fragile to irrelevant noise features. In this paper, we propose a novel Riemannian metric learning algorithm to capture the local structures and develop a robust LtR algorithm. First, we design a concept called ideal candidate document to introduce metric learning algorithm to query-independent model. Previous metric learning algorithms aiming to find an optimal metric space are only suitable for query-dependent model, in which query instance and documents belong to the same feature space and the similarity is directly computed\u00a0\u2026", "num_citations": "9\n", "authors": ["1175"]}
{"title": "An online-updating algorithm on probabilistic matrix factorization with active learning for task recommendation in crowdsourcing systems\n", "abstract": " To ensure the output quality, current crowdsourcing systems highly rely on redundancy of answers provided by multiple workers with varying expertise, however massive redundancy is very expensive and time-consuming. Task recommendation can help requesters to receive good quality output quicker as well as help workers to find their right tasks faster. To reduce the cost, a number of previous works adopted active learning in crowdsourcing systems for quality assurance. Active learning is a learning approach to achieve certain accuracy with a very low cost. However, previous works do not consider the varying expertise of workers for various task categories in real crowdsourcing scenarios; and they do not consider new workers who are not willing to work on a large amount of tasks before having a list of preferred tasks recommended. In this paper, we propose ActivePMFv2, Probabilistic Matrix Factorization with\u00a0\u2026", "num_citations": "9\n", "authors": ["1175"]}
{"title": "Remote augmented reality for multiple players over network\n", "abstract": " Augmented Reality (AR) in multimedia gaming is a dynamic and exciting field of research. One of the challenges is to have multiple users interacting in the networked augmented reality environment. In recent years, camera-based body motion capturing console games, which captures the player's body movement to control the objects rendered by the computer, have been developed. In this paper, we present a system called, Tele-Table which allows multiple users to interact with each other through the network using real objects. Each player's set-up consists of an overhead mounted camera perceiving real objects, a plasma TV placed horizontally to act as a game table, and a computer. One of the most challenging tasks is data synchronization between two terminals. There are mainly three synchronization tasks we need to handle. They are temporal synchronization, spatial synchronization, and game states\u00a0\u2026", "num_citations": "9\n", "authors": ["1175"]}
{"title": "Comparison of several partitioning methods for information retrieval in image databases\n", "abstract": " Efficient and accurate information retrieval is one of the main issues in image databases. Since traditional alphanumeric indexing methods are not particularly suitable for image database indexing, new indexing methods are designed specially for image retrieval. In this paper, we are going to discuss four partitioning methods: VP-tree, k-means, Competitive Learning (CL), and Rival Penalized Competitive Learning (RPCL) for image database indexing. Our aim is to evaluate and compare the performances of these methods for information retrieval in image database based on the performance measurements: Recall, Precision, and Speed. From the result of some performance experiments, it is concluded that RPCL followed by CL are the most appropriate to be used for image retrieval among these four methods.", "num_citations": "9\n", "authors": ["1175"]}
{"title": "Performance analysis of a new updating rule for TD (/spl lambda/) learning in feedforward networks for position evaluation in Go game\n", "abstract": " In this paper, a new updating rule for applying temporal difference (TD) learning to multilayer feedforward networks is derived. Networks are trained to evaluate Go board positions by TD(/spl lambda/) learning with different values of /spl lambda/. Performance of each network is estimated by letting it play against other networks. Results show that nonzero /spl lambda/ gives better learning for the network and statistically, larger /spl lambda/ gives better performance.", "num_citations": "9\n", "authors": ["1175"]}
{"title": "Simple and efficient parallelization for probabilistic temporal tensor factorization\n", "abstract": " Probabilistic Temporal Tensor Factorization (PTTF) is an effective algorithm to model the temporal tensor data. It leverages a time constraint to capture the evolving properties of tensor data. Nowadays the exploding dataset demands a large scale PTTF analysis, and a parallel solution is critical to accommodate the trend. Whereas, the parallelization of PTTF still remains unexplored. In this paper, we propose a simple yet efficient Parallel Probabilistic Temporal Tensor Factorization, referred to as P 2 T 2 F, to provide a scalable PTTF solution. P 2 T 2 F is fundamentally disparate from existing parallel tensor factorizations by considering the probabilistic decomposition and the temporal effects of tensor data. It adopts a new tensor data split strategy to subdivide a large tensor into independent sub-tensors, the computation of which is inherently parallel. We train P 2 T 2 F with an efficient algorithm of stochastic Alternating\u00a0\u2026", "num_citations": "8\n", "authors": ["1175"]}
{"title": "Trust-aware peer assessment using multi-armed bandit algorithms\n", "abstract": " Massive Open Online Coursers (MOOCs) offer a convenient way for people to access quality courses via the internet. However, the problem of grading open-ended assignments at such a large scale still remains challenging. Although peer assessment have been proposed to handle the large-scale grading problem in MOOCs, existing methods still suffer several limitations:(1) most current peer assessment research ignore the importance of how to allocate the assessment tasks among peers,(2) existing approaches for peer grading learn the complete ranking in an offline manner,(3) theoretical analysis for trust-aware peer grading is missing. In this work, we consider the case that we have prior knowledge about all students' reliability. We formulate the problem of peer assessment as a sequential noisy ranking aggregation problem. We derive a trust-aware allocation scheme for peer assessment to maximize the\u00a0\u2026", "num_citations": "8\n", "authors": ["1175"]}
{"title": "Budget constrained non-monotonic feature selection\n", "abstract": " Feature selection is an important problem in machine learning and data mining. We consider the problem of selecting features under the budget constraint on the feature subset size. Traditional feature selection methods suffer from the \u201cmonotonic\u201d property. That is, if a feature is selected when the number of specified features is set, it will always be chosen when the number of specified feature is larger than the previous setting. This sacrifices the effectiveness of the non-monotonic feature selection methods. Hence, in this paper, we develop an algorithm for non-monotonic feature selection that approximates the related combinatorial optimization problem by a Multiple Kernel Learning (MKL) problem. We justify the performance guarantee for the derived solution when compared to the global optimal solution for the related combinatorial optimization problem. Finally, we conduct a series of empirical evaluation on both\u00a0\u2026", "num_citations": "8\n", "authors": ["1175"]}
{"title": "Language technologies for enhancement of teaching and learning in writing\n", "abstract": " Writing is a vital issue for education as well as a fundamental skill in teaching and learning. With the development of information technologies, more and more professional writing tools emerge. As each of them mostly concentrates on addressing a specific issue, people need a one-stop platform, which could integrate multiply functions. In addition, with the supported concept of e-learning ecosystem for future education, a comprehensive platform will be more promising. Therefore, we introduce VeriGuide Platform, which provides a professional writing toolbox to promote the enhancement of teaching and learning in writing. It contains six vertical components, which could be split into two groups. The first group, Editing Assistance, facilitates students write papers and point out grammar and spelling errors. While the second group, Text Analysis, offers document analysis results, which enables students to achieve further\u00a0\u2026", "num_citations": "8\n", "authors": ["1175"]}
{"title": "A hierarchical entity-based approach to structuralize user generated content in social media: A case of Yahoo! answers\n", "abstract": " Social media like forums and microblogs have accumulated a huge amount of user generated content (UGC) containing human knowledge. Currently, most of UGC is listed as a whole or in pre-defined categories. This \u201clist-based\u201d approach is simple, but hinders users from browsing and learning knowledge of certain topics effectively. To address this problem, we propose a hierarchical entity-based approach for structuralizing UGC in social media. By using a large-scale entity repository, we design a three-step framework to organize UGC in a novel hierarchical structure called \u201ccluster entity tree (CET)\u201d. With Yahoo! Answers as a test case, we conduct experiments and the results show the effectiveness of our framework in constructing CET. We further evaluate the performance of CET on UGC organization in both user and system aspects. From a user aspect, our user study demonstrates that, with CET-based structure, users perform significantly better in knowledge learning than using traditional list-based approach. From a system aspect, CET substantially boosts the performance of two information retrieval models (ie, vector space model and query likelihood language model).", "num_citations": "8\n", "authors": ["1175"]}
{"title": "Introduction to social computing\n", "abstract": " With the advent of Web 2.0, Social Computing has emerged as one of the hot research topics recently. Social Computing involves the collecting, extracting, accessing, processing, computing, visualizing, etc.\u00a0of social signals and information. More specifically, this tutorial places special emphases in machine learning, data mining, information retrieval, and other computational techniques involved in collective intelligence processing of social behavior data collected from blogs, wikis, clickthrough data, query logs, tags, etc.,\u00a0and from areas such as social networks, social search, social media, social bookmarks, social news, social knowledge sharing, and social games. In this tutorial, I plan to give an introduction to Social Computing and elaborate on how the various characteristics and aspects are involved in the social platforms for collective intelligence. The topics include social network theory and modeling\u00a0\u2026", "num_citations": "8\n", "authors": ["1175"]}
{"title": "Automobile, car and BMW: Horizontal and hierarchical approach in social tagging systems\n", "abstract": " Social tagging systems have recently emerged as an effective way for users to annotate and organize large collections of resources on the Web. Moreover, they also facilitate an efficient sharing of vast amounts of resources among different users. In this paper, we analyze tags' usage pattern in real world data sets and find that among tags representing the same concept, some tags are less popular, resulting in reduced exploring effectiveness in the current social tagging systems. Another limitation is that users cannot roll-up or drill-down the concept hierarchy of tag queries, resulting in the limited scope of service and a failure to meet users' dynamic information needs which often change with the current information provided. In order to overcome these shortcomings, we propose a novel three-phase approach as the following:(1) finding semantically-related tags for tag query;(2) constructing clusters of tags\u00a0\u2026", "num_citations": "8\n", "authors": ["1175"]}
{"title": "Semi-nonnegative matrix factorization with global statistical consistency for collaborative filtering\n", "abstract": " Collaborative Filtering, considered by many researchers as the most important technique for information filtering, has been extensively studied by both academic and industrial communities. One of the most popular approaches to collaborative filtering recommendation algorithms is based on low-dimensional factor models. The assumption behind such models is that a user's preferences can be modeled by linearly combining item factor vectors using user-specific coefficients. In this paper, aiming at several aspects ignored by previous work, we propose a semi-nonnegative matrix factorization method with global statistical consistency. The major contribution of our work is twofold:(1) We endow a new understanding on the generation or latent compositions of the user-item rating matrix. Under the new interpretation, our work can be formulated as the semi-nonnegative matrix factorization problem.(2) Moreover, we\u00a0\u2026", "num_citations": "8\n", "authors": ["1175"]}
{"title": "Sprinkled latent semantic indexing for text classification with background knowledge\n", "abstract": " In text classification, one key problem is its inherent dichotomy of polysemy and synonym; the other problem is the insufficient usage of abundant useful, but unlabeled text documents. Targeting on solving these problems, we incorporate a sprinkling Latent Semantic Indexing (LSI) with background knowledge for text classification. The motivation comes from: 1) LSI is a popular technique for information retrieval and it also succeeds in text classification solving the problem of polysemy and synonym; 2) By fusing the sprinkling terms and unlabeled terms, our method not only considers the class relationship, but also explores the unlabeled information. Finally, experimental results on text documents demonstrate our proposed method benefits for improving the classification performance.", "num_citations": "8\n", "authors": ["1175"]}
{"title": "Video sequence similarity matching\n", "abstract": " Content-based retrieval of multimedia data with temporal constraints, such as video and audio sequences, requires a consideration of the temporal ordering inherent in such sequences. Video sequence-tosequence matching is therefore an important step in realizing content-based video retrieval. This paper provides an overview of the general issues involved in video sequence matching, points out the immediate problems that must be addressed before video sequence matching becomes practical, and proposes some general methods to address the problems. Implications of the video sequence matching problem on other areas of multimedia information retrieval are also highlighted.", "num_citations": "8\n", "authors": ["1175"]}
{"title": "Efficient community search over large directed graphs: An augmented index-based approach\n", "abstract": " Given a graph G and a query vertex q, the topic of community search (CS), aiming to retrieve a dense subgraph of G containing q, has gained much attention. Most existing works focus on undirected graphs which overlooks the rich information carried by the edge directions. Recently, the problem of community search over directed graphs (or CSD problem) has been studied [Fang et al., 2019b]; it finds a connected subgraph containing q, where the in-degree and out-degree of each vertex within the subgraph are at least k and l, respectively. However, existing solutions are inefficient, especially on large graphs. To tackle this issue, in this paper we propose a novel index called D-Forest, which allows a CSD query to be completed within the optimal time cost. We further propose efficient index construction methods. Extensive experiments on six real large graphs show that our index-based query algorithm is up to two orders of magnitude faster than existing solutions.", "num_citations": "7\n", "authors": ["1175"]}
{"title": "Mixing business with politics: the value of business and political elites to Chinese firms\n", "abstract": " By constructing a comprehensive database of business and political networks of each corporate leader (Chairmen, CEOs and board members) of all Chinese listed firms from 1999 to 2012, we explore whether business networks (social ties among themselves) and political networks (social ties with senior politicians) of these corporate leaders are associated with firm value (Tobin\u2019s Q). Our evidence shows that both business and political networks are significantly positively associated Tobin\u2019s Q. The firms\u2019 value is incrementally higher when these corporate leaders are strong in both business and political ties, even after considering the value of each of the two networks separately. This result is stronger among non-SOEs than SOEs.", "num_citations": "7\n", "authors": ["1175"]}
{"title": "Online learning for big data analytics\n", "abstract": " Online Learning for Big Data Page 1 Online Learning for Big Data Analytics Irwin King, Michael R. Lyu and Haiqin Yang Department of Computer Science & Engineering The Chinese University of Hong Kong Tutorial presentation at IEEE Big Data, Santa Clara, CA, 2013 1 Page 2 Outline \u2022 Introduction (60 min.) \u2013 Big data and big data analytics (30 min.) \u2013 Online learning and its applications (30 min.) \u2022 Online Learning Algorithms (60 min.) \u2013 Perceptron (10 min.) \u2013 Online non-sparse learning (10 min.) \u2013 Online sparse learning (20 min.) \u2013 Online unsupervised learning (20. min.) \u2022 Discussions + Q & A (5 min.) 2 Page 3 Outline \u2022 Introduction (60 min.) \u2013 Big data and big data analytics (30 min.) \u2013 Online learning and its applications (30 min.) \u2022 Online Learning Algorithms (60 min.) \u2013 Perceptron (10 min.) \u2013 Online non-sparse learning (10 min.) \u2013 Online sparse learning (20 min.) \u2013 Online unsupervised learning (20. min.) \u2022 \u2026", "num_citations": "7\n", "authors": ["1175"]}
{"title": "Weaving services and people on the World Wide Web\n", "abstract": " Ever since its inception, the Web has changed the landscape of human experiences on how we interact with one another and data through service infrastructure via various computing devices. This interweaving environment is now becoming ever more embedded into devices and systems that integrates seamlessly on how we live, in our working or leisure time.This special volume on \u201cWeaving Services and People on the WWW\u201d, features some of the cutting-edge research work that were presented at the Workshop Track of the 17th International World Wide Web Conference (WWW2008) held at Beijing, China, from April 21\u201325, 2008. The Workshop Track received 24 proposals and after a rigorous reviewing process ten full-day workshops were selected, of which two workshops were half-day workshops. They were:", "num_citations": "7\n", "authors": ["1175"]}
{"title": "Imbalanced learning in relevance feedback with biased minimax probability machine for image retrieval tasks\n", "abstract": " In recent years, Minimax Probability Machine (MPM) have demonstrated excellent performance in a variety of pattern recognition problems. At the same time various machine learning methods have been used on relevance feedback tasks in Content-based Image Retrieval (CBIR). One of the problems in typical techniques for relevance feedback is that they treat the relevant feedback and irrelevant feedback equally. In other words, the negative instances largely outnumber the positive instances. Hence, the assumption that they are balanced is incorrect. In this paper we study how MPM can be applied to image retrieval, more precisely, Biased MPM during the relevance feedback iterations. We formulate the relevance feedback based on a modified MPM called Biased Minimax Probability Machine (BMPM). Different from previous methods, this model directly controls the accuracy of classification of the future\u00a0\u2026", "num_citations": "7\n", "authors": ["1175"]}
{"title": "Improving the Transferability of Adversarial Samples With Adversarial Transformations\n", "abstract": " Although deep neural networks (DNNs) have achieved tremendous performance in diverse vision challenges, they are surprisingly susceptible to adversarial examples, which are born of intentionally perturbing benign samples in a human-imperceptible fashion. It thus poses security concerns on the deployment of DNNs in practice, particularly in safety-and security-sensitive domains. To investigate the robustness of DNNs, transfer-based attacks have attracted a growing interest recently due to their high practical applicability, where attackers craft adversarial samples with local models and employ the resultant samples to attack a remote black-box model. However, existing transfer-based attacks frequently suffer from low success rates due to overfitting to the adopted local model. To boost the transferability of adversarial samples, we propose to improve the robustness of synthesized adversarial samples via adversarial transformations. Specifically, we employ an adversarial transformation network to model the most harmful distortions that can destroy adversarial noises and require the synthesized adversarial samples to become resistant to such adversarial transformations. Extensive experiments on the ImageNet benchmark showcase the superiority of our method to state-of-the-art baselines in attacking both undefended and defended models.", "num_citations": "6\n", "authors": ["1175"]}
{"title": "Personalized sequential check-in prediction: Beyond geographical and temporal contexts\n", "abstract": " Check-in prediction is an important task for location-based systems, which maps a noisy estimate of a user's current location to a semantically meaningful point-of-interest (POI), such as a restaurant or store. In this paper, we leverage the personalized preference and sequential check-in pattern to improve the traditional methods that base on the geographical and temporal contexts. In our approach, we propose a Gaussian mixture model and a histogram distribution estimation model to learn the contextual features from relevant spatial and temporal information, respectively. Furthermore, we employ user and POI embeddings to model the personalized preference and leverage a stacked Long-Short Term Memory (LSTM) model to learn the sequential check-in pattern. Combining the contextual features and the personalized sequential patterns together, we propose a wide and deep neural network for the check-in\u00a0\u2026", "num_citations": "6\n", "authors": ["1175"]}
{"title": "Sparse Poisson coding for high dimensional document clustering\n", "abstract": " Document clustering plays an important role in large scale textual data analysis, which generally faces with great challenge of the high dimensional textual data. One remedy is to learn the high-level sparse representation by the sparse coding techniques. In contrast to traditional Gaussian noise-based sparse coding methods, in this paper, we employ a Poisson distribution model to represent the word-count frequency feature of a text for sparse coding. Moreover, a novel sparse-constrained Poisson regression algorithm is proposed to solve the induced optimization problem. Different from previous Poisson regression with the family of \u2113 1 -regularization to enhance the sparse solution, we introduce a sparsity ratio measure which make use of both \u2113 1 -norm and \u2113 2 -norm on the learned weight. An important advantage of the sparsity ratio is that it bounded in the range of 0 and 1. This makes it easy to set for practical\u00a0\u2026", "num_citations": "6\n", "authors": ["1175"]}
{"title": "Proceedings of the 7th ACM Conference on Recommender Systems\n", "abstract": " The proceedings contain 95 papers. The topics discussed include: context-aware review helpfulness rating prediction; query-driven context aware recommendation; location-aware music recommendation using auto-tagging and hybrid matching; spatial topic modeling in online social media for location recommendation; orthogonal query recommendation; understanding and improving relational matrix factorization in recommender systems; retargeted matrix factorization for collaborative filtering; trading-off among accuracy, similarity, diversity, and long-tail: a graph-based recommendation approach; nonlinear latent factorization by embedding multiple user interests; diffusion-aware personalized social update recommendation; recommending branded products from social media; and exploring temporal effects for location recommendation on location-based social networks.", "num_citations": "6\n", "authors": ["1175"]}
{"title": "Towards a top-down and bottom-up bidirectional approach to joint information extraction\n", "abstract": " Most high-level information extraction (IE) consists of compound and aggregated subtasks. Such IE problems are generally challenging and they have generated increasing interest recently. We investigate two representative IE tasks:(1) entity identification and relation extraction from Wikipedia, and (2) citation matching, and we formally define joint optimization of information extraction. We propose a joint paradigm integrating three factors--segmentation, relation, and segmentation-relation joint factors, to solve all relevant subtasks simultaneously. This modeling offers a natural formalism for exploiting bidirectional rich dependencies and interactions between relevant subtasks to capture mutual benefits. Since exact parameter estimation is prohibitively intractable, we present a general, highly-coupled learning algorithm based on variational expectation maximization (VEM) to perform parameter estimation\u00a0\u2026", "num_citations": "6\n", "authors": ["1175"]}
{"title": "Using finite state machines for evaluating spoken dialog systems\n", "abstract": " Development of spoken dialog systems (SDSs) can be facilitated by better evaluation methods. Previous methods seldom consider the efficiency of the system, which is important to users. We study the problem of evaluating SDSs and propose a new framework by generalizing states from utterances of dialogs to build finite state machine (FSM). These states can be regarded as efficiency measurement of SDSs. The FSM framework models dialogs as paths in an FSM to combine efficiency measurement with regression models. The proposed FSM framework can be applied in conjunction with regression models to improve evaluation accuracy. We compare our FSM framework combined with three regression models in several experiments. We obtain promising results on a collection of dialogs from the \u201cLet's Go!\u201d system, with our approach outperforming regression models.", "num_citations": "6\n", "authors": ["1175"]}
{"title": "Probabilistic cooperative-competitive hierarchical modeling as a genetic operator in global optimization\n", "abstract": " Existing search-based discrete global optimization methods share two characteristics: 1) searching at the highest resolution; and 2) searching without memorizing past searching information. In this paper, we provide a model which copes: 1) structurally, it transforms the optimization problem into a selection problem by organizing the continuous search space into a binary hierarchy of partitions; and 2) algorithmically, it is an iterative stochastic cooperative-competitive searching algorithm with memory. It is pointed out that the competition model eliminates the requirement of the niche radius required in the existing niching techniques. The model is applied to (but not limited to) function optimization problems (including high-dimensional problems) with experimental results which show that our model is promising for global optimization. We show how pccBHS can be integrated into genetic algorithms as an operator.", "num_citations": "6\n", "authors": ["1175"]}
{"title": "Visual perception of translational and rotational motion\n", "abstract": " Motion perception is crucial to the survival of the animal. For example, a sudden movement in the visual field might indicate a looming predator or a desirable prey. An impending collision can be signaled by the expansion of retinal image cast by an object. Thus, it is not surprising that the analysis of moving stimuli begins at a very early stage of visual information processing, and in many species as early as the retina. For instance, direction-selective cells (cells responsive only to motion in a certain direction) have been found in the retina of the frog [1, 2, 3], the turtle [4, 5], the pigeon,[6], the rabbit [7, 8], ground squirrel [9 [, and the cat [10]. In primates, the direction-selective neurons are among the First ones in the visual cortex to receive input from the retina [11]. Biological visual systems analyze and interpret intensity changes in the visual field produced by dynamic stimuli. There has been great progress in research on 2-D motion perception (for a review see [12, 13, 14]). The best known 2-D motion detection scheme is based on the neural mechanisms underlying insect optomotor response [15, 16, 17]. The basic unit of motion detection here is a pair of receptors connected in such a way that the delayed output of one receptor is multiplied by the output of the other. Barlow and Levick [8] proposed another", "num_citations": "6\n", "authors": ["1175"]}
{"title": "AutoGraph: Automated Graph Neural Network\n", "abstract": " Graphs play an important role in many applications. Recently, Graph Neural Networks (GNNs) have achieved promising results in graph analysis tasks. Some state-of-the-art GNN models have been proposed, e.g., Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs), etc. Despite these successes, most of the GNNs only have shallow structure. This causes the low expressive power of the GNNs. To fully utilize the power of the deep neural network, some deep GNNs have been proposed recently. However, the design of deep GNNs requires significant architecture engineering. In this work, we propose a method to automate the deep GNNs design. In our proposed method, we add a new type of skip connection to the GNNs search space to encourage feature reuse and alleviate the vanishing gradient problem. We also allow our evolutionary algorithm to increase the layers of GNNs\u00a0\u2026", "num_citations": "5\n", "authors": ["1175"]}
{"title": "Making online sketching hashing even faster\n", "abstract": " Data-dependent hashing methods have demonstrated good performance in various machine learning applications to learna low-dimensional representation from the original data. However, they still meet several obstacles: First, most of existing hashingmethods are trained in a batch mode, yielding inefficiency for training streaming data. Second, the computational cost and the memoryconsumption increase extraordinarily in the big data era, which hinders the training procedure. Third, the scarcity of label informationhinders the improvement of the model performance. To address these difficulties, we utilize online sketching hashing (OSH) andpresent a FasteR Online Sketching Hashing (FROSH) algorithm to sketch the data in a more compact form via an independenttransformation. Theoretical justification is provided to guarantee that our proposed FROSH consumes less time and achieves acomparable sketching\u00a0\u2026", "num_citations": "5\n", "authors": ["1175"]}
{"title": "Geo-teaser: Geo-temporal sequential embedding rank for POI recommendation\n", "abstract": " This chapter proposes a Geo-Temporal sequential embedding rank (Geo-Teaser) model for POI recommendation. Inspired by the success of the word2vec framework to model the sequential contexts, a temporal POI embedding model is proposed to learn POI representations under some particular temporal state. The temporal POI embedding model captures the contextual check-in information in sequences and the various temporal characteristics on different days as well. Furthermore, a new way of incorporating the geographical influence into the pairwise preference ranking method through discriminating the unvisited POIs according to geographical information, is employed to develop a geographically hierarchical pairwise preference ranking model. Finally, a unified framework is proposed to recommend POIs combining these two models. Experimental results on two real-life datasets show that the Geo\u00a0\u2026", "num_citations": "5\n", "authors": ["1175"]}
{"title": "It's about time! modeling customer behaviors as the secretary problem in daily deal websites\n", "abstract": " Daily deal websites, such as Groupon and Living-Social, are now becoming increasingly popular current shopping trends worth multi-billion dollars. Understanding customers' purchase behaviors in daily deal websites is important to provide accurate and precise personalized recommendations in order for companies to gain more revenue. However, different from traditional online shopping sites, such as Amazon and Target, in which consumers can evaluate and purchase multiple items at the same time, customer's behaviors in daily deal websites have their unique characteristics and thus pose several challenges for modeling these behaviors: (1) daily deals are not available all the time and customers have to decide whether to purchase today's deal or forgo the opportunity and wait for future deals; (2) daily deals are made sequentially available to the consumers and the future quality of the deals are uncertain\u00a0\u2026", "num_citations": "5\n", "authors": ["1175"]}
{"title": "Topological order discovery via deep knowledge tracing\n", "abstract": " The goal of discovering topological order of skills is to generate a sequence of skills satisfying all prerequisite requirements. Very few previous studies have examined this task from knowledge tracing perspective. In this paper, we introduce a new task of discovering topological order of skills using students\u2019 exercise performance and explore the utility of Deep Knowledge Tracing (DKT) to solve this task. The learned topological results can be used to improve students\u2019 learning efficiency by providing students with personalized learning paths and predicting students\u2019 future exercise performance. Experimental results demonstrate that our method is effective to generate reasonable topological order of skills.", "num_citations": "5\n", "authors": ["1175"]}
{"title": "Locality-sensitive linear bandit model for online social recommendation\n", "abstract": " Recommender systems provide personalized suggestions by learning users\u2019 preference based on their historical feedback. To alleviate the heavy relying on historical data, several online recommendation methods are recently proposed and have shown the effectiveness in solving data sparsity and cold start problems in recommender systems. However, existing online recommendation methods neglect the use of social connections among users, which has been proven as an effective way to improve recommendation accuracy in offline settings. In this paper, we investigate how to leverage social connections to improve online recommendation performance. In particular, we formulate the online social recommendation task as a contextual bandit problem and propose a Locality-sensitive Linear Bandit (LS.Lin) method to solve it. The proposed model incorporates users\u2019 local social relations into a linear\u00a0\u2026", "num_citations": "5\n", "authors": ["1175"]}
{"title": "Methods, systems, and computer program products for integrated world wide web query classification\n", "abstract": " Implementing query classification includes receiving a core term from a search query responsive to execution of a first module. The first module searches a table for the core term and yields a first result. The query classification also includes receiving a second result from the search query responsive to execution of a second module. The second module searches an index of terms that are mapped to documents and corresponding categories in the index. The second result is indicative of one of the corresponding categories in the index based on a probability score. Upon determining the first result is a category associated with the core term in the table, the query classification also includes calculating a weighted average for the first result and the second result. The calculation yields a third result. The query classification further includes transmitting the third result to a computer device that generated the query.", "num_citations": "5\n", "authors": ["1175"]}
{"title": "Measuring credibility of users in an E-learning social network\n", "abstract": " Learning Villages (LV) is an E-learning platform for people's online discussions and frequently citing postings of one another. It will greatly improve learning efficiency if credible users can be accurately identified in the E-learnning community. In this paper, we propose a novel method to rank credibility of users in the LV system. We first propose a k-EACM graph to describe the article citation structure in the LV system. The k-EACM graph not only describes the citation attitude between articles but also takes into account indirect citation links. We further build a weighted graph model k-UCM graph to reveal the implicit relationships between users hidden behind the citations among their articles. Finally, we design a graph based ranking algorithm, called Credible Author Ranking (CAR) algorithm, which can be applied to rank nodes in a graph with negative edges. We perform experiments on three simulated data sets\u00a0\u2026", "num_citations": "5\n", "authors": ["1175"]}
{"title": "Maximum margin based semi-supervised spectral kernel learning\n", "abstract": " Semi-supervised kernel learning is attracting increasing research interests recently. It works by learning an embedding of data from the input space to a Hilbert space using both labeled data and unlabeled data, and then searching for relations among the embedded data points. One of the most well-known semi-supervised kernel learning approaches is the spectral kernel learning methodology which usually tunes the spectral empirically or through optimizing some generalized performance measures. However, the kernel designing process does not involve the bias of a kernel-based learning algorithm, the deduced kernel matrix cannot necessarily facilitate a specific learning algorithm. To supplement the spectral kernel learning methods, this paper proposes a novel approach, which not only learns a kernel matrix by maximizing another generalized performance measure, the margin between two classes of data\u00a0\u2026", "num_citations": "5\n", "authors": ["1175"]}
{"title": "Biased minimax probability machine active learning for relevance feedback in content-based image retrieval\n", "abstract": " In this paper we apply Biased Minimax Probability Machine (BMPM) to address the problem of relevance feedback in Content-based Image Retrieval (CBIR). In our proposed methodology we treat relevance feedback task in CBIR as an imbalanced learning task which is more reasonable than traditional methods since the negative instances largely outnumber the positive instances. Furthermore we incorporate active learning in order to improve the framework performance, i.e., try to reduce the number of iterations used to achieve the optimal boundary between relevant and irrelevant images. Different from previous works, this model builds up a biased classifier and achieves the optimal boundary using fewer iterations. Experiments are performed to evaluate the efficiency of our method, and promising experimental results are obtained.", "num_citations": "5\n", "authors": ["1175"]}
{"title": "A user profile-based approach for personal information access: shaping your information portfolio\n", "abstract": " In the spread of internet, internet-based information service business has started to become profitable. One of the key technologies is personalization. Successful internet information services must realize personalized information delivery, by which the users can automatically receive highly tuned information according to their personal needs and preferences. In order to realize such personalized information services, we have developed an automatic user preference capture and an automatic information clipping function based on a Personalized Information Access technique. In this paper, those techniques will be demonstrated by showing a deployed personalized webpage service application.", "num_citations": "5\n", "authors": ["1175"]}
{"title": "Improving naive Bayesian classifier by discriminative training\n", "abstract": " Discriminative classifiers such as Support Vector Machines (SVM) directly learn a discriminant function or a posterior probability model to perform classification. On the other hand, generative classifiers often learn a joint probability model and then use the Bayes rule to construct a posterior classifier. In general, generative classifiers are not as accurate as discriminative classifiers. However generative classifiers provide a principled way to deal with the missing information problem, which discriminative classifiers cannot easily handle. To achieve good performance in various classification tasks, it is better to combine these two strategies. In this paper, we develop a method to train one of the popular generative classifiers, the Naive Bayesian classifier (NB) in a discriminative way. We name this new model as the Discriminative Naive Bayesian classifier. We provide theoretic justifications, outline the algorithm, and perform a serious of experiments on benchmark real-world datasets to demonstrate our model\u2019s advantages. Its performance outperforms NB in classification tasks and outperforms SVM in handling missing information tasks.", "num_citations": "5\n", "authors": ["1175"]}
{"title": "NHDC and PHDC: Non-propagating and propagating heat diffusion classifiers\n", "abstract": " By imitating the way that heat flows in a medium with a geometric structure, we propose two novel classification algorithms, Non-propagating Heat Diffusion Classifier (NHDC) and Propagating Heat Diffusion Classifier (PHDC). In NHDC, an unlabelled data is classified into the class that diffuses the most heat to the unlabelled data after one local diffusion from time 0 to a small time period, while in PHDC, an unlabelled data is classified into the class that diffuses the most heat to the unlabelled data in the propagating effect of the heat flow from time 0 to time t, which means that in PHDC, the heat diffuses infinitely many times from time 0 and each time period is infinitely small. In other words, we measure the similarity between an unlabelled data and a class by the heat amount that the unlabelled data receives from the set of labelled data in the class, and then classify the unlabelled data into the class with the most similarity. Unlike the traditional method, in which the heat kernel is applied to a kernel-based classifier we employ the heat kernel to construct the classifier directly; moreover, instead of imitating the way that the heat flows along a linear or nonlinear manifold, we let the heat flow along a graph formed by the k-nearest neighbors. An important and special feature in both NHDC and PHDC is that the kernel is not symmetric. We show theoretically that PWA (Parzen Window Approach when the window function is a multivariate normal kernel) and KNN are actually special cases of NHDC model, and that PHDC has the ability to approximate NHDC. Experiments show that NHDC performs better than PWA and KNN in prediction accuracy, and that\u00a0\u2026", "num_citations": "5\n", "authors": ["1175"]}
{"title": "P2P content-based query routing using firework query model\n", "abstract": " Clustering technique is used in database and information retrieval system for organizing data and improving retrieval efficiency. We surmise such functionality is valuable to a Peer-to-Peer (P2P) distributed environment. In this paper, we introduce the concept of peer clustering at the level of overlaying network topology, and content-based query routing strategy to improve existing retrieval methods. We design and implement a DIStributed COntent-based Visual Information Retrieval (DISCOVIR) system with content-based query functionality and improved query efficiency. We demonstrate its scalability and efficiency through simulation.", "num_citations": "5\n", "authors": ["1175"]}
{"title": "Utilizing inter and intra-query relevance feedback for content-based image retrieval\n", "abstract": " The relevance feedback approach is a powerful technique in content-based image retrieval (CBIR) tasks. Many parametric and non-parametric estimation approaches to refine user\u2019s query that are based on low-level image features have been proposed. Most of them often fail when the underlying distribution of a user\u2019s target is not clustered in the low-level feature vector space. To address this, researchers have proposed the use of long-term relevance information to assist in discovering the semantics of images in retrieval process. However, these methods are either not working properly when the number of query results is small or not concerned about the subjectivity of different user. In this paper, we propose a SOM-based technique to construct a vector space which represents the similarities of images under human perception from long-term relevance information. The target distribution of user\u2019s query is then estimated on the newly constructed vector space. Experiments indicate that retrieval performance is increased when a parameter estimation approach is used on the newly formed vector spaced after learning the inter-query relevance feedback information.", "num_citations": "5\n", "authors": ["1175"]}
{"title": "Radial basis network for facial expression synthesis\n", "abstract": " Many multimedia applications require the synthesis of facial expressions. We demonstrate the synthesis of di erent degrees of various 2D grayscale facial expressions using the Radial Basis Function (RBF) neural network. The RBF network is used to generate spatial displacement of a set of facial feature points as in multidimensional density interpolation. We have implemented two RBF networks for synthesizing facial expressions. One network generates the spatial displacement of facial feature points for di erent degrees of expressions and the other generates the spatial displacement of facial feature points of mixed facial expressions. The predicted facial landmark displacement information is then fed into our image warping algorithm along with the expressionless facial image to produce the nal synthesized facial image. We discuss the method used and demonstrate the results.", "num_citations": "5\n", "authors": ["1175"]}
{"title": "Adaptive Contrast Enhancement by Entropy Maximization with a 1-K-1 Constrained Network1\n", "abstract": " This paper uses the Maximum Entropy Principle to construct a 1-K-1 constrained sigmoidal neural network which adaptively adjusts its gain parameters to control the transfer function in order to maximize the entropy measure at the output for image contrast enhancement. We demonstrate how the model works with the standard lena image.", "num_citations": "5\n", "authors": ["1175"]}
{"title": "Three neural models which process temporal information\n", "abstract": " Using temporal summation mechanism of a single synapse which is modeled and implemented in SLONN simulation language (Wang & Hsu, 1988), we propose three neural models that can deal with three different aspects of temporal information processing. The first model will separate multiple temporal patterns into an array of neurons. Each neuron N i in the array passes the temporal patterns whose frequencies are greater than and equal to certain value fi. With one-sided lateral inhibition mechanism in the second model, each neuron Nl will only pass the temporal patterns whose frequencies are closest to fi. Therefore, Ni behaves exactly as a frequency filter. By combining the second model with short-term memory mechanism (Grossberg, 1976) and associative learning, the third model can be used to store and recall sequences of temporal patterns. Below we will describe them in some details.1. The main\u00a0\u2026", "num_citations": "5\n", "authors": ["1175"]}
{"title": "Attributed collaboration network embedding for academic relationship mining\n", "abstract": " Finding both efficient and effective quantitative representations for scholars in scientific digital libraries has been a focal point of research. The unprecedented amounts of scholarly datasets, combined with contemporary machine learning and big data techniques, have enabled intelligent and automatic profiling of scholars from this vast and ever-increasing pool of scholarly data. Meanwhile, recent advance in network embedding techniques enables us to mitigate the challenges of large scale and sparsity of academic collaboration networks. In real-world academic social networks, scholars are accompanied with various attributes or features, such as co-authorship and publication records, which result in attributed collaboration networks. It has been observed that both network topology and scholar attributes are important in academic relationship mining. However, previous studies mainly focus on network topology\u00a0\u2026", "num_citations": "4\n", "authors": ["1175"]}
{"title": "What changed your mind: The roles of dynamic topics and discourse in argumentation process\n", "abstract": " In our world with full of uncertainty, debates and argumentation contribute to the progress of science and society. Despite of the increasing attention to characterize human arguments, most progress made so far focus on the debate outcome, largely ignoring the dynamic patterns in argumentation processes. This paper presents a study that automatically analyzes the key factors in argument persuasiveness, beyond simply predicting who will persuade whom. Specifically, we propose a novel neural model that is able to dynamically track the changes of latent topics and discourse in argumentative conversations, allowing the investigation of their roles in influencing the outcomes of persuasion. Extensive experiments have been conducted on argumentative conversations on both social media and supreme court. The results show that our model outperforms state-of-the-art models in identifying persuasive arguments via\u00a0\u2026", "num_citations": "4\n", "authors": ["1175"]}
{"title": "Risk control of best arm identification in multi-armed bandits via successive rejects\n", "abstract": " Best arm identification in stochastic Multi-Armed Bandits (MAB) has become an essential variant in the research line of bandits for decision-making problems. In previous work, the best arm usually refers to an arm with the highest expected payoff in a given decision-arm set. However, in many practical scenarios, it would be more important and desirable to incorporate the risk of an arm into the best decision. In this paper, motivated by practical applications with risk via bandits, we investigate the problem of Risk Control of Best Arm Identification (RCBAI) in stochastic MAB. Based on the technique of Successive Rejects (SR), we show that the error resulting from the mean-variance estimation is sub-Gamma by setting mild assumptions on stochastic payoffs of arms. Besides, we develop an algorithm named as RCMAB. SR, and derive an upper bound for the probability of error for RCBAI in stochastic MAB. We\u00a0\u2026", "num_citations": "4\n", "authors": ["1175"]}
{"title": "Axiomatic analysis of cross-language information retrieval\n", "abstract": " A major challenge in Cross-Language Information Retrieval (CLIR) is the adoption of translation knowledge in retrieval models, as it affects the term weighting which is known to highly impact the retrieval performance. In this paper, we present an analytical study of using translation knowledge in CLIR. In particular, by adopting axiomatic analysis framework, we formulate the impacts of translation knowledge on document ranking as constraints that any cross-language retrieval model should satisfy. We then consider the state-of-the-art CLIR methods and check whether they satisfy these constraints. Finally, we show through empirical evaluation that violating one of the constraints harms the retrieval performance significantly which calls for further investigation.", "num_citations": "4\n", "authors": ["1175"]}
{"title": "Cmap: effective fusion of quality and relevance for multi-criteria recommendation\n", "abstract": " The research issue of recommender systems has been treated as a classical regression problem over the decades and has obtained a great success. In the next generation of recommender systems, multi-criteria recommendation has been predicted as an important direction. Different from traditional recommender systems that aim particularly at recommending high-quality items evaluated by users' ratings, inmulti-criteria recommendation, quality only serves as one criterion, and many other criteria such as relevance, coverage, and diversity should be simultaneously optimized. Although recently there is work investigating each single criterion, there is rarely any literature that reports how each single criterion impacts each other and how to combine them in real applications. Thus in this paper, we study the relationship of two criteria, quality and relevance, as a preliminary work in multi-criteria recommendation. We\u00a0\u2026", "num_citations": "4\n", "authors": ["1175"]}
{"title": "Predicting user evaluations of spoken dialog systems using semi-supervised learning\n", "abstract": " User evaluations of dialogs from a spoken dialog system (SDS) can be directly used to gauge the system's performance. However, it is costly to obtain manual evaluations of a large corpus of dialogs. Semi-supervised learning (SSL) provides a possible solution. This process learns from a small amount of manually labeled data, together with a large amount of unlabeled data, and can later be used to perform automatic labeling. We conduct comparative experiments among SSL approaches, classical regression and supervised learning in evaluation of dialogs from CMU's Let's Go Bus Information System. Two typical SSL methods, namely co-training and semi-supervised support vector machine (S3VM), are found to outperform the other approaches in automatically predicting user evaluations of unseen dialogs in the case of low training rate.", "num_citations": "4\n", "authors": ["1175"]}
{"title": "A volume-based heat-diffusion classifier\n", "abstract": " Heat-diffusion models have been successfully applied to various domains such as classification and dimensionality-reduction tasks in manifold learning. One critical local approximation technique is employed to weigh the edges in the graph constructed from data points. This approximation technique is based on an implicit assumption that the data are distributed evenly. However, this assumption is not valid in most cases, so the approximation is not accurate in these cases. To solve this challenging problem, we propose a volume-based heat-diffusion model (VHDM). In VHDM, the volume is theoretically justified by handling the input data that are unevenly distributed on an unknown manifold. We also propose a novel volume-based heat-diffusion classifier (VHDC) based on VHDM. One of the advantages of VHDC is that the computational complexity is linear on the number of edges given a constructed graph\u00a0\u2026", "num_citations": "4\n", "authors": ["1175"]}
{"title": "Rate: A review of reviewers in a manuscript review process\n", "abstract": " In this paper, we propose a novel approach called, Reviewers Authority Testing and Evaluation (RATE), to improve the effectiveness of a manuscript review process. In the proposed RATE approach, we define a RATE model to express a manuscript review process mathematically. We then design a RATE algorithm to rank the authority of each reviewer in the RATE model and consequently calculate the quality score for each manuscript. The experimental results demonstrate that the performance of the RATE algorithm is superior to existing approaches. Furthermore, the experiments on testing algorithm's parameter settings also demonstrate that the proposed RATE algorithm behaves effectively and stably.", "num_citations": "4\n", "authors": ["1175"]}
{"title": "Efficient minimax clustering probability machine by generalized probability product kernel\n", "abstract": " Minimax Probability Machine (MPM), learning a decision function by minimizing the maximum probability of misclassification, has demonstrated very promising performance in classification and regression. However, MPM is often challenged for its slow training and test procedures. Aiming to solve this problem, we propose an efficient model named Minimax Clustering Probability Machine (MCPM). Following many traditional methods, we represent training data points by several clusters. Different from these methods, a Generalized Probability Product Kernel is appropriately defined to grasp the inner distributional information over the clusters. Incorporating clustering information via a non-linear kernel, MCPM can fast train and test in classification problem with promising performance. Another appealing property of the proposed approach is that MCPM can still derive an explicit worst-case accuracy bound for the\u00a0\u2026", "num_citations": "4\n", "authors": ["1175"]}
{"title": "Large scale imbalanced classification with biased minimax probability machine\n", "abstract": " The biased minimax probability machine (BMPM) constructs a classifier which deals with the imbalanced learning tasks. It provides a worst-case bound on the probability of misclassification of future data points based on reliable estimates of means and covariance matrices of the classes from the training data samples, and achieves promising performance. In this paper, we apply the biased classification model to large scale imbalanced classification problem, and develop a critical extension to train the BMPM efficiently which is a novel training algorithm based on Second Order Cone Programming (SOCP). By removing some crucial assumptions in the original solution to this model, we make the new method more accurate and efficient. We outline the theoretical derivatives of the biased classification model, and reformulate it into a SOCP problem which could be efficiently solved with global optima guarantee. We\u00a0\u2026", "num_citations": "4\n", "authors": ["1175"]}
{"title": "Neural Information Processing: 13th International Conference, ICONIP 2006, Hong Kong, China, October 3-6, 2006: Proceedings\n", "abstract": " The three volume set LNCS 4232, LNCS 4233, and LNCS 4234 constitutes the refereed proceedings of the 13th International Conference on Neural Information Processing, ICONIP 2006, held in Hong Kong, China in October 2006. The 386 revised full papers presented were carefully reviewed and selected from 1175 submissions.", "num_citations": "4\n", "authors": ["1175"]}
{"title": "Two-phase lmr-rc tagging for Chinese word segmentation\n", "abstract": " In this paper we present a Two-Phase LMR-RC Tagging scheme to perform Chinese word segmentation. In the Regular Tagging phase, Chinese sentences are processed similar to the original LMR Tagging. Tagged sentences are then passed to the Correctional Tagging phase, in which the sentences are re-tagged using extra information from the first round tagging results. Two training methods, Separated Mode and Integrated Mode, are proposed to construct the models. Experimental results show that our scheme in Integrated Mode performs the best in terms of accuracy, where Separated Mode is more suitable under limited computational resources.", "num_citations": "4\n", "authors": ["1175"]}
{"title": "Improving Chow-Liu tree performance by mining association rules\n", "abstract": " We present a novel approach to construct a kind of tree belief network, in which the \u201cnodes\u201d are subsets of variables of dataset. We call this model Large Node Chow-Liu Tree (LNCLT). This technique uses the concept of the association rule as found in the database literature to guide the construction of the LNCLT. Similar to the Chow-Liu Tree (CLT), the LNCLT is also ideal for density estimation and classification applications. More importantly, our novel model partially solves the disadvantages of the CLT, i.e., the inability to represent non-tree structures, and is shown to be superior to the CLT theoretically. Moreover, based on the MNIST hand-printed digit database, we conduct a series of digit recognition experiments to verify our approach. From the result we find that both the approximation accuracy and the recognition rate on the data are improved with the LNCLT structure, when compared with the CLT.", "num_citations": "4\n", "authors": ["1175"]}
{"title": "Theoretical Aspects of Neural Computation: A Multidisciplinary Perspective-International Workshop (TANC'97) Hong Kong, 26-28 May 1997\n", "abstract": " Over the past decade or so, neural computation has emerged as a research area with active involvement by researchers from a number of different disciplines, including computer science, engineering, mathematics, neurobiology, physics, and statistics. The workshop brought together researchers with a diverse background to review the current status of neural computation research. Three aspects of neural computation have been emphasized: neuroscience aspects, computational and Mathematical aspects, and statistical physics aspects. This book contains 28 contributions from frontier researchers in these fields. Thoroughly re-edited, and in some cases revised post-workshop, these papers collated into this review volume provide a top-class reference summary of the state-of-the-art work done in this field.", "num_citations": "4\n", "authors": ["1175"]}
{"title": "A two-stage framework for polygon retrieval using minimum circular error bound\n", "abstract": " We have proposed a two-stage framework for polygon retrieval [12, 11] which incorporates both qualitative and quantitative measures of polygons in the first and second stage respectively. In this paper, we introduce an extension to our two-stage framework. We propose a new polygon matching technique using Circular Error Bound and describe how this technique works under translation and scaling of polygons. Base on this technique, we propose a new translation invariant similarity measure for polygons named Minimum Circular Error Bound, which can be used in the second stage of the two-stage framework. We compare the Minimum Circular Error Bound method with the Hausdorf Distance method and demonstrate the advantages of our method.", "num_citations": "4\n", "authors": ["1175"]}
{"title": "A neural network for the detection of rotational motion\n", "abstract": " Describes a biologically plausible neural network which detects rotational motion in the frontal-parallel plane (revolving around the Z-axis) produced by a multiple-dots stimulus against a stationary background. The network consists of multilayered velocity-sensitive sensory cells organized in a locally connected fashion. The network displays the ability to segment multiple rotational stimuli in time sequences as well as an object with both rotational and translational motion by extracting the center and the perimeter trace of the rotational stimulus. Different simulations have been performed, and the results are discussed.< >", "num_citations": "4\n", "authors": ["1175"]}
{"title": "Creation and Evaluation of a Pretertiary Artificial Intelligence (AI) Curriculum\n", "abstract": " Contributions: The Chinese University of Hong Kong (CUHK)-Jockey Club AI for the Future Project (AI4Future) co-created the first pretertiary AI curriculum at the secondary school level for Hong Kong and evaluated its efficacy. This study added to the AI education community by introducing a new AI curriculum framework. The preposttest multifactors evaluation about students' perceptions of AI learning confirmed that the curriculum is effective in promoting AI learning. The teachers also confirmed the co-creation process enhanced their capacity to implement AI education. Background: AI4Future is a cross-sector project that engages five major partners--CUHK's Faculty of Engineering and Faculty of Education, secondary schools, Hong Kong government, and AI industry. A team of 14 professors collaborated with 17 principals and teachers from six secondary schools to co-create the curriculum\u00a0\u2026", "num_citations": "3\n", "authors": ["1175"]}
{"title": "FeatureNorm: L2 Feature Normalization for Dynamic Graph Embedding\n", "abstract": " Dynamic graphs arise in a plethora of practical scenarios such as social networks, communication networks, and financial transaction networks. Given a dynamic graph, it is fundamental and essential to learn a graph representation that is expected not only to preserve structural proximity but also jointly capture the time-evolving patterns. Recently, graph convolutional network (GCN) has been widely explored and used in non-Euclidean application domains. The main success of GCN, especially in handling dependencies and passing messages within nodes, lies in its approximation to Laplacian smoothing. As a matter of fact, this smoothing technique can not only encourage must-link node pairs to get closer but also push cannot-link pairs to shrink together, which potentially cause serious feature shrink or oversmoothing problem, especially when stacking graph convolution in multiple layers or steps. For learning\u00a0\u2026", "num_citations": "3\n", "authors": ["1175"]}
{"title": "Proceedings of The Web Conference 2020\n", "abstract": " Proceedings of The Web Conference 2020 | ACM Conferences ACM Digital Library Logo ACM Logo Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search www Conference Proceedings Upcoming Events Authors Affiliations Award Winners More HomeConferencesWWWProceedingsWWW '20 Export Citation Select Citation format Download citation Copy citation Categories Journals Magazines Books Proceedings SIGs Conferences Collections People About About ACM Digital Library Subscription Information Author Guidelines Using ACM Digital Library All Holdings within the ACM Digital Library ACM Computing Classification System Join Join ACM Join SIGs Subscribe to Publications Institutions and Libraries Connect Contact Facebook Twitter \u2026", "num_citations": "3\n", "authors": ["1175"]}
{"title": "Architecture search for image inpainting\n", "abstract": " Neural Architecture Search (NAS) shows the ability to automate the architecture engineering for specific tasks recently which is extremely promising. Many published works apply reinforcement learning or evolutionary algorithm to design the neural architecture for image classification and achieve state-of-the-art performance. However, using NAS to perform other challenging tasks, such as inpainting irregular regions in an image, has not been explored yet. The target of image inpainting is to generate plausible image regions to fill the missing regions in the original image. It has been widely used in many applications. In this paper, we are interested in applying neural architecture search methods to image inpainting tasks. We propose to use reinforcement learning to automatically design the network architecture. Our method can efficiently explore new network structure based on existing architecture. The\u00a0\u2026", "num_citations": "3\n", "authors": ["1175"]}
{"title": "Distributed information-theoretic metric learning in apache spark\n", "abstract": " Distance metric learning (DML) is an effective similarity learning tool to learn a distance function from examples to enhance the model performance in applications of classification, regression, and ranking, etc. Most DML algorithms need to learn a Mahalanobis matrix, a positive semidefinite matrix that scales quadratically with the number of dimensions of input data. This brings huge computational cost in the learning procedure, and makes all proposed algorithms infeasible for extremely high-dimensional data even with the low-rank approximation. Differently, in this paper, we take advantage of the power of parallel computation and propose a novel distributed distance metric learning algorithm based on a state-of-the-art DML algorithm, Information-Theoretic Metric Learning (ITML).More specifically, we utilize the property that each positive semidefinite matrix can be decomposed into a combination of rank-one and\u00a0\u2026", "num_citations": "3\n", "authors": ["1175"]}
{"title": "Empirical comparisons of attack and protection algorithms for online social networks\n", "abstract": " Online social networks, like Facebook, are popular social networking websites, on which hundreds of millions of users make friends and interact with people. There is a large amount of personal information in these networking websites and their security is rather concerned by both users and researchers, because valuable private information will bring great profit to some people or groups. In the real world, profits motivate people and groups to obtain the personal private data lawlessly and many attacks are launched on the social networks. Facing various attacks, distinct protective strategies are proposed by researches to reduce the negative effect of attacks. However, the practical performance of protections is unknown when they are battling with the real attacks. Moreover, we also understand little about how strong attacks would be when they are facing protections. Therefore, this paper proposes an Attack-Protect\u00a0\u2026", "num_citations": "3\n", "authors": ["1175"]}
{"title": "Efficient training on biased minimax probability machine for imbalanced text classification\n", "abstract": " The Biased Minimax Probability Machine (BMPM) constructs a classifier which deals with the imbalanced learning tasks. In this paper, we propose a Second Order Cone Programming (SOCP) based algorithm to train the model. We outline the theoretical derivatives of the biased classification model, and address the text classification tasks where negative training documents significantly outnumber the positive ones using the proposed strategy. We evaluated the learning scheme in comparison with traditional solutions on three different datasets. Empirical results have shown that our method is more effective and robust to handle imbalanced text classification problems.", "num_citations": "3\n", "authors": ["1175"]}
{"title": "Fuzzy Clustering Method for Content-based Indexing\n", "abstract": " Efficient and accurate information retrieval is one of the main issues in multimedia databases. In content-based multimedia retrieval databases, contents or features of the database objects are used for retrieval. To retrieve similar database objects, we often perform a nearest-neighbor search. A nearest-neighbor search is used to retrieve similar database objects with features nearest to the query under the feature vector space with a given distance function (similarity measurement). Typically, data exist in natural cluster. However, many of the currently indexing methods do not utilize this data cluster information in the construction of the indexing structure which leads to performance degradation. To improve the retrieval performance, we (1) use Fuzzy Competitive Clustering (FCC), a noise resistance fuzzy clustering algorithm, to locate good approximate cluster prototypes efficiently,(2) use the result of FCC clustering to construct a good indexing structure (FCC-btree) for effective nearest-neighbor search and (3) Dervied two elimination rules for purning the indexing tree in searching process. Our experimental results show that:(1) FCC gets the better cluster prototypes then other traditional clustering algorithms in general. and (2) The FCC-b-tree always has a better performance than linear search.", "num_citations": "3\n", "authors": ["1175"]}
{"title": "Regression analysis for rival penalized competitive learning binary tree\n", "abstract": " The main aim of this paper is to develop a suitable regression analysis model for describing the relationship between the index efficiency and the parameters of the Rival Penalized Competitive Learning Binary Tree (RPCL-b-tree). RPCL-b-tree is a hierarchical indexing structure built with a hierarchical RPCL clustering implementation, which transforms the feature space into a sequence of nested clusters. Based on the RPCL-b-tree, the efficient Nearest-Neighbor search for a query can be performed with the branch-and-bound algorithm. The index efficiency of a RPCL-b-tree relates to a set of parameters: leaf node size of the tree, number of retrieved objects per search, feature dimensionality and database size. To formulate this relationship, we develop a nonlinear regression model in this paper. This regression model includes two components. One is used to describe the relationship between index efficiency and\u00a0\u2026", "num_citations": "3\n", "authors": ["1175"]}
{"title": "Information retrieval using local linear PCA\n", "abstract": " Efficient and accurate information retrieval (IR) is one of the main issues in multimedia databases. Clustering can help to generate the efficient indexing structures and provide the comparison between data types. The Most Expressive Feature (MEF) extraction can improve comparison accuracy between two data which belong to a same data type since it discards redundant features. The authors introduce a local linear principal component analysis (LLPCA) to design an optimal scheme for IR. The LLPCA realizes the clustering and local MEF extraction at the same time. Using these clusters and local MEFs, an IR scheme can be divided into two steps from coarse to fine. We apply the scheme to a trademark retrieval system to evaluate its performance based on the accuracy and efficiency measurements. The experimental results indicate this retrieval scheme is superior the other schemes using the original features or\u00a0\u2026", "num_citations": "3\n", "authors": ["1175"]}
{"title": "Gabor-wavelet decomposition based filtering of gray-level images for object and scene recognition experiments\n", "abstract": " A software image-processing method has been developed to generate partially filtered graylevel images for visual recognition experiments examining the interaction between spatial localization, spatial scale, and orientation sensitivity in higher-level perception.The program we describe is able to selectively mask or unmask specific scales and orientations at any position of an input gray-level image using Gabor-wavelet decomposition. The resulting image representations are then combined to obtain partially reconstructed images for use as stimuli in novel psychophysical experiments. The system can be used as a stand-alone application, typically for generating visual stimuli off-line.", "num_citations": "3\n", "authors": ["1175"]}
{"title": "Discrete-time Temporal Network Embedding via Implicit Hierarchical Learning in Hyperbolic Space\n", "abstract": " Representation learning over temporal networks has drawn considerable attention in recent years. Efforts are mainly focused on modeling structural dependencies and temporal evolving regularities in Euclidean space which, however, underestimates the inherent complex and hierarchical properties in many real-world temporal networks, leading to sub-optimal embeddings. To explore these properties of a complex temporal network, we propose a hyperbolic temporal graph network (HTGN) that fully takes advantage of the exponential capacity and hierarchical awareness of hyperbolic geometry. More specially, HTGN maps the temporal graph into hyperbolic space, and incorporates hyperbolic graph neural network and hyperbolic gated recurrent neural network, to capture the evolving behaviors and implicitly preserve hierarchical information simultaneously. Furthermore, in the hyperbolic space, we propose two\u00a0\u2026", "num_citations": "2\n", "authors": ["1175"]}
{"title": "A Training-free and Reference-free Summarization Evaluation Metric via Centrality-weighted Relevance and Self-referenced Redundancy\n", "abstract": " In recent years, reference-based and supervised summarization evaluation metrics have been widely explored. However, collecting human-annotated references and ratings are costly and time-consuming. To avoid these limitations, we propose a training-free and reference-free summarization evaluation metric. Our metric consists of a centrality-weighted relevance score and a self-referenced redundancy score. The relevance score is computed between the pseudo reference built from the source document and the given summary, where the pseudo reference content is weighted by the sentence centrality to provide importance guidance. Besides an -based relevance score, we also design an -based variant that pays more attention to the recall score. As for the redundancy score of the summary, we compute a self-masked similarity score with the summary itself to evaluate the redundant information in the summary. Finally, we combine the relevance and redundancy scores to produce the final evaluation score of the given summary. Extensive experiments show that our methods can significantly outperform existing methods on both multi-document and single-document summarization evaluation.", "num_citations": "2\n", "authors": ["1175"]}
{"title": "Temporal context-aware task recommendation in crowdsourcing systems\n", "abstract": " In crowdsourcing systems, tasks are distributed to networked people for completion. To ensure the output quality, current crowdsourcing systems highly rely on redundancy of answers provided by multiple workers, however massive redundancy is very expensive. Task recommendation can help requesters to receive good quality output quicker as well as help workers to find their right tasks faster. In our previous works, we proposed a task recommendation framework which performs a factor analysis based on probabilistic matrix factorization (PMF) with which the worker and task latent feature spaces are learned. Our framework adopts active learning on our factor analysis model to minimize the number of task assignments to achieve a target output quality. Moreover, our framework adopts an online-updating approach on model update process to greatly improve the system performance in terms of the running time of\u00a0\u2026", "num_citations": "2\n", "authors": ["1175"]}
{"title": "Graph-based Semi-supervised Learning: A Comprehensive Review\n", "abstract": " Semi-supervised learning (SSL) has tremendous value in practice due to its ability to utilize both labeled data and unlabelled data. An important class of SSL methods is to naturally represent data as graphs such that the label information of unlabelled samples can be inferred from the graphs, which corresponds to graph-based semi-supervised learning (GSSL) methods. GSSL methods have demonstrated their advantages in various domains due to their uniqueness of structure, the universality of applications, and their scalability to large scale data. Focusing on this class of methods, this work aims to provide both researchers and practitioners with a solid and systematic understanding of relevant advances as well as the underlying connections among them. This makes our paper distinct from recent surveys that cover an overall picture of SSL methods while neglecting fundamental understanding of GSSL methods. In particular, a major contribution of this paper lies in a new generalized taxonomy for GSSL, including graph regularization and graph embedding methods, with the most up-to-date references and useful resources such as codes, datasets, and applications. Furthermore, we present several potential research directions as future work with insights into this rapidly growing field.", "num_citations": "2\n", "authors": ["1175"]}
{"title": "Self-supervised contrastive learning for integrative single cell RNA-seq data analysis\n", "abstract": " Single-cell RNA-sequencing (scRNA-seq) has become a powerful tool to reveal the complex biological diversity and heterogeneity among cell populations. However, the technical noise and bias of the technology still have negative impacts on the downstream analysis. Here, we present a self-supervised Contrastive LEArning framework for scRNA-seq (CLEAR) profile representation and the downstream analysis. CLEAR overcomes the heterogeneity of the experimental data with a specifically designed representation learning task and thus can handle batch effects and dropout events. In the task, the deep learning model learns to pull together the representations of similar cells while pushing apart distinct cells, without manual labeling. It achieves superior performance on a broad range of fundamental tasks, including clustering, visualization, dropout correction, batch effect removal, and pseudo-time inference. The proposed method successfully identifies and illustrates inflammatory-related mechanisms in a COVID-19 disease study with 43,695 single cells from peripheral blood mononuclear cells. Further experiments to process a million-scale single-cell dataset demonstrate the scalability of CLEAR. This scalable method generates effective scRNA-seq data representation while eliminating technical noise, and it will serve as a general computational framework for single-cell data analysis.", "num_citations": "2\n", "authors": ["1175"]}
{"title": "Overlapping community detection with preference and locality information: a non-negative matrix factorization approach\n", "abstract": " Community detection plays an important role in understanding structures and patterns in complex networks. In real-world networks, a node in most cases belongs to multiple communities, which makes communities overlap with each other. One popular technique to cope with overlapping community detection is matrix factorization (MF). However, existing MF approaches only make use of the existence of a link, but ignore the implicit preference information inside it. In this paper, we first propose a Preference-based Non-negative Matrix Factorization (PNMF) model to take link preference information into consideration. Distinguished from traditional value approximation-based matrix factorization approaches, our model maximizes the likelihood of the preference order for each node so that it overcomes the indiscriminate penalty problem in which non-linked pairs inside one community are equally penalized in\u00a0\u2026", "num_citations": "2\n", "authors": ["1175"]}
{"title": "Communication-efficient distributed deep metric learning with hybrid synchronization\n", "abstract": " Deep metric learning is widely used in extreme classification and image retrieval because of its powerful ability to learn the semantic low-dimensional embedding of high-dimensional data. However, the heavy computational cost of mining valuable pair or triplet of training data and updating models frequently in existing deep metric learning approaches becomes a barrier to apply such methods to a large-scale real-world context in a distributed environment. Moreover, existing distributed deep learning framework is not designed for deep metric learning tasks, because it is difficult to implement a smart mining policy of valuable training data. In this paper, we introduce a novel distributed framework to speed up the training process of the deep metric learning using multiple machines. Specifically, we first design a distributed sampling method to find the hard-negative samples from a broader scope of candidate samples\u00a0\u2026", "num_citations": "2\n", "authors": ["1175"]}
{"title": "Thread popularity prediction and tracking with a permutation-invariant model\n", "abstract": " The task of thread popularity prediction and tracking aims to recommend a few popular comments to subscribed users when a batch of new comments arrive in a discussion thread. This task has been formulated as a reinforcement learning problem, in which the reward of the agent is the sum of positive responses received by the recommended comments. In this work, we propose a novel approach to tackle this problem. First, we propose a deep neural network architecture to model the expected cumulative reward (Q-value) of a recommendation (action). Unlike the state-of-the-art approach, which treats an action as a sequence, our model uses an attention mechanism to integrate information from a set of comments. Thus, the prediction of Q-value is invariant to the permutation of the comments, which leads to a more consistent agent behavior. Second, we employ a greedy procedure to approximate the action that maximizes the predicted Q-value from a combinatorial action space. Different from the state-of-the-art approach, this procedure does not require an additional pre-trained model to generate candidate actions. Experiments on five real-world datasets show that our approach outperforms the state-of-the-art.", "num_citations": "2\n", "authors": ["1175"]}
{"title": "From mutual friends to overlapping community detection: A non-negative matrix factorization approach\n", "abstract": " Community detection provides a way to unravel complicated structures in complex networks. Overlapping community detection allows nodes to be associated with multiple communities. Matrix Factorization (MF) is one of the standard tools to solve overlapping community detection problems from a global view. Existing MF-based methods only exploit link information revealed by the adjacency matrix, but ignore other critical information. In fact, compared with the existence of a link, the number of mutual friends between two nodes can better reflect their similarity regarding community membership. In this paper, based on the concept of mutual friend, we incorporate Mutual Density as a new indicator to infer the similarity of community membership between two nodes in the MF framework for overlapping community detection. We conduct data observation on real-world networks with ground-truth communities to\u00a0\u2026", "num_citations": "2\n", "authors": ["1175"]}
{"title": "Methods, systems, and computer program products for integrated world wide web query classification\n", "abstract": " Implementing query classification includes executing a reductionist module on a query to extract a core term, which term is used to search a hash table that maps core terms to corresponding categories, deriving a first result including one of the categories from the search, and executing an enrichment module on the query to yield a second result. The enrichment module includes searching an index of terms that are mapped to documents and corresponding categories. Upon determining the core term is present in the hash table, a weighted average is calculated for values of the first and second results based on training data. Upon determining the core term from the query is not in the hash table, and also that a probability score of the category in the index for the second result meets a minimum confidence value, the core term and the corresponding categories are stored in the hash table.", "num_citations": "2\n", "authors": ["1175"]}
{"title": "Group buying in social coupon: Myths or facts\n", "abstract": " The social coupons industry, such as Groupon and LivingSocial, has experienced explosive growth in recent years. Social coupons that combine the features of daily deals and group buying create a new business strategy. In previous literature, theoretical hypotheses regarding this novel strategy have been developed. However, empirical investigation using real world data is few. In this paper, we aim to examine whether the group buying, as the main feature of social coupon, is effective. Utilizing a proprietary clickstream dataset about Groupon, we study three \u201cmyths\u201d about the group buying feature. We use Web tools to crawl information from other sources to augment clickstream data, and analytics tools to process and mine the information. From this study, we discover three significant \u201cfacts\u201d that: (1) group buying does not stimulate referrals, no matter whether the deal is tipped or not; (2) the information that the\u00a0\u2026", "num_citations": "2\n", "authors": ["1175"]}
{"title": "A comparison of lasso-type algorithms on distributed parallel machine learning platforms\n", "abstract": " Due to tremendous increase of data, scalability becomes a challenging issue for many modern machine learning algorithms. Various distributed machine learning platforms, eg, GraphLab, Spark and Petuum, are proposed to tackle this issue. Lasso algorithm, as its effectiveness in performing regression tasks while selecting the important features simultaneously, has become a benchmark machine learning method deployed in these platforms. However, rare work discusses the performance of the Lasso algorithm systematically and many other lasso-type algorithms are not well-studied yet. In addition, how to relieve the \u201cNinja performance gap\u201d between optimized code and most of these frameworks is a difficult task. To resolve the above tasks, we present a detailed deployment of the lassotype algorithms in several state-of-the-art distributed machine learning platforms. We characterize the performance of the native implementation and identify the potential parts to reduce the performance gap. We give a comprehensive comparison on running time, easy-of-deployment and capability of handling big data, which will enable end-users to choose platforms based on their goals.", "num_citations": "2\n", "authors": ["1175"]}
{"title": "Data management with flexible and extensible data schema in clans\n", "abstract": " Data Management plays an essential role in both research and industrial areas, especially for the fields need text processing, like business domain. Corporate Leaders Analytics and Network System (CLANS) is a system designed to identify and analyze social networks among corporations and business elites. It targets to tackle some of difficult problems such as natural language processing, network construction, relationship mining, and it requires high-quality management of data. For data management, we propose a novel approach by integrating the essential XML files and auxiliary databases, with a flexible and extensible data schema. This data schema is the kernel of our data management. It achieves plenty of superiorities, namely, separability, scalability, traceability, distinguishability, version control and maintainability. In this paper, we specifically illustrate the data schema as well as the management\u00a0\u2026", "num_citations": "2\n", "authors": ["1175"]}
{"title": "Policy and issues in deploying automated plagiarism detection systems in academic communities: A case study of veriguide\n", "abstract": " Plagiarism is becoming prevalent through the use of the Internet. Educational institutions are seeking technology to combat plagiarism. This chapter describes policy and issues encountered by an educational institution that deploys an automated plagiarism detection system. Background information of plagiarism and the benefits of using automated plagiarism detection systems are presented as motivation. A detailed account on the benefits of using automated plagiarism detection system in the academic setting is given. Associated policy issues (administrative issues, submission policy issues, disciplinary issues, copyright issues, security and privacy issues, and ethical issues) and resources needed to deploy such a system are discussed in details. VeriGuide, an automated plagiarism detection system designed and implemented at the Chinese University of Hong Kong, is presented as a case study on how the\u00a0\u2026", "num_citations": "2\n", "authors": ["1175"]}
{"title": "An enhanced semi-supervised recommendation model based on green\u2019s function\n", "abstract": " Recommendation, in the filed of machine learning, is known as a technique of identifying user preferences to new items with ratings from recommender systems. Recently, one novel recommendation model using Green\u2019s function treats recommendation as the process of label propagation. Although this model outperforms many standard recommendation methods, it suffers from information loss during graph construction because of data sparsity. In this paper, aiming at solving this problem and improving prediction accuracy, we propose an enhanced semi-supervised Green\u2019s function recommendation model. The main contributions are two-fold: 1) To reduce information loss, we propose a novel graph construction method with global and local consistent similarity; 2) We enhance the recommendation algorithm with the multi-class semi-supervised learning framework. Finally, experimental results on real\u00a0\u2026", "num_citations": "2\n", "authors": ["1175"]}
{"title": "Learning with unlabeled data\n", "abstract": " Machine learning is a subfield of artificial intelligence that is concerned with the design and development of algorithms and techniques that allow computers to make inductions or deduction [102]. In general, machine learning studies a variety of different types of problems. In terms of the different settings and ways of dealing with data, machine learning algorithms can typically be categorized as unsupervised learning, supervised learning, semisupervised learning, and reinforcement learning, and others. We give a simple description of these learning algorithms in the following:\u2022 Supervised learning that generates a function that maps inputs to desired outputs. In supervised learning, each instance of the training data consists of a data vector and it corresponding output. In terms of the output, there are two supervised supervised learning tasks: classification where the output is discrete and regression where the output is continuous.", "num_citations": "2\n", "authors": ["1175"]}
{"title": "First ACM SIGMM International Workshop on Social Media (WSM'09)\n", "abstract": " The ACM SIGMM International Workshop on Social Media (WSM\u201909) is the first workshop held in conjunction withthe ACM International Multimedia Conference (MM\u201909) atBejing, PR China, 2009. This workshop provides a forumfor researchers and practitioners from all over the world toshare information on their latest investigations on social mediaanalysis, exploration, search, mining, and emerging newsocial media applications.", "num_citations": "2\n", "authors": ["1175"]}
{"title": "Modeling Data Locally and Globally. Advanced Topics in Science and Tecnology in China: Machine Learning\n", "abstract": " Machine Learning-Modeling Data Locally and Globally presents a novel and unified theory that tries to seamlessly integrate different algorithms. Specifically, the book distinguishes the inner nature of machine learning algorithms as either\" local learning\" or\" global learning.\" This theory not only connects previous machine learning methods, or serves as roadmap in various models, but\u2013more importantly\u2013it also motivates a theory that can learn from data both locally and globally. This would help the researchers gain a deeper insight and comprehensive understanding of the techniques in this field. The book reviews current topics, new theories and applications.", "num_citations": "2\n", "authors": ["1175"]}
{"title": "A novel discriminative naive Bayesian network for classification\n", "abstract": " Naive Bayesian network (NB) is a simple yet powerful Bayesian network. Even with a strong independency assumption among the features, it demonstrates competitive performance against other state-of-the-art classifiers, such as support vector machines (SVM). In this chapter, we propose a novel discriminative training approach originated from SVM for deriving the parameters of NB. This new model, called discriminative naive Bayesian network (DNB), combines both merits of discriminative methods (eg, SVM) and Bayesian networks. We provide theoretic justifications, outline the algorithm, and perform a series of experiments on benchmark real-world datasets to demonstrate our model\u2019s advantages. Its performance outperforms NB in classification tasks and outperforms SVM in handling missing information tasks.", "num_citations": "2\n", "authors": ["1175"]}
{"title": "Semantic video summarization using mutual reinforcement and shot arrangement patterns\n", "abstract": " We propose a novel semantic video summarization framework, which generates video skimmings that guarantee both the balanced content coverage and the visual coherence. First, we collect video semantic information with a semi-automatic video annotation tool. Secondly, we analyze the video structure and determine each video scene\u2019s target skim length. Then, mutual reinforcement principle is used to compute the relative importance value and cluster the video shots according to their semantic descriptions. Finally, we analyze the arrangement pattern of the video shots, and the key shot arrangement patterns are extracted to form the final video skimming, where the video shot importance value is used as guidance. Experiments are conducted to evaluate the effectiveness of our proposed approach. 1.", "num_citations": "2\n", "authors": ["1175"]}
{"title": "Biased Minimax Probability Machine\n", "abstract": " A recently-proposed novel classifier called Minimax Probability Machine (MPM) achieves the comparative performance with a state-of-the-art classifier, the Support Vector Machine. MPM trains the classifier by minimizing the worst-case probability of misclassification of future data points. However, this model assumes the unbiased weight for each class and thus lacks the ability to deal with biased classification tasks. In this paper, aiming at solving this problem, we develop an extension named Biased Minimax Probability Machine (BMPM). By setting an acceptable lower bound to the accuracy for the less important class, we maximize the worst-case probability of the accuracy for the biased class. This model is the first quantitative method to control how the decision hyperplane moves in favor of the classification of the more important class. We present the formulation and implement a series of experiments on both a\u00a0\u2026", "num_citations": "2\n", "authors": ["1175"]}
{"title": "Hierarchical rival penalized competitive learning binary tree for multimedia feature-based indexing\n", "abstract": " The main aim of this paper is to develop an efficient and accurate indexing method for retrieval of feature-based multimedia information. In query-by-example type of retrieval, we often perform nearest-neighbor search based on an pre-calculated indexing structure. Currently, many of the indexing methods have the boundary problem. This problem causes performance degradation when the query lies near a partition boundary in the feature space. Using natural clusters to partition feature space can reduce the influence of boundary problem. In this paper, we use Rival Penalized Competitive Learning (RPCL) to cluster multimedia feature vectors efficiently. Through a hierarchical RPCL clustering framework, the feature space is transformed into a sequence of nested clusters. Using these clusters, we can then build a hierarchical binary indexing tree named, RPCL-b-tree, for efficient information retrieval. The RPCL-b\u00a0\u2026", "num_citations": "2\n", "authors": ["1175"]}
{"title": "FF99: a novel fuzzy first-order logic learning system\n", "abstract": " This paper describes a novel learning system, named FF99, that learns fuzzy first-order logic concepts from various kinds of data. FF99 builds on the ideas from both fuzzy set theory and first-order logic. Object relationships are described using fuzzy relations based on which FF99 generates classification rules expressed in a restricted form of fuzzy first-order logic. This new system has been applied successfully to several tasks taken from the machine learning literature. We demonstrate its usefulness in the applications of data mining through several experiments.", "num_citations": "2\n", "authors": ["1175"]}
{"title": "Facial expression synthesis using radial basis function networks\n", "abstract": " Facial expression synthesis using radial basis function networks | Intelligent biometric techniques in fingerprint and face recognition ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksIntelligent biometric techniques in fingerprint and face recognitionFacial expression synthesis using radial basis function networks chapter Facial expression synthesis using radial basis function networks Share on Authors: I. King View Profile , XQ Li View Profile Authors Info & Affiliations Publication: Intelligent biometric techniques in fingerprint and face recognitionOctober 1999 Pages 399\u2013421 0citation 0 Downloads Metrics Total Citations0 Total \u2026", "num_citations": "2\n", "authors": ["1175"]}
{"title": "A two-stage framework for efficient simple polygon retrieval in image databases\n", "abstract": " We propose a two-stage framework for efficient polygon matching in image databases. The first stage performs a coarse polygon classification based on qualitative features of polygons and the second stage performs quantitative measure of polygons. We use Binary String Descriptor to quickly find equivalent classes of polygons in the first stage. In the second stage, we have two possible approaches:(1) a Multi-Resolution Area Matching technique based on Quad-Tree method and (2) the Hausdorff Distance method. The technique incorporated in the second stage will only operate on a subset of polygons belonging to the same equivalent class which is produced in the first stage. This two-stage framework can prune the search space of a polygon matching query and speed up the matching process. We have built an experimental system. We will also discuss the experimental results.", "num_citations": "2\n", "authors": ["1175"]}
{"title": "Using global PCA generated receptive fields for face recognition\n", "abstract": " We apply the global Principal Component Analysis (PCA) learning for face recognition tasks. The global unsupervised PCA learning generates a set of plausible visual receptive fields that are ideal for image decomposition during the feature extraction process for recognition. The procedure and results of our approach are illustrated and discussed.", "num_citations": "2\n", "authors": ["1175"]}
{"title": "Lucent Technologies\n", "abstract": " Discriminative classifiers such as Support Vector Machines (SVM) directly learn a discriminant function or a posterior probability model to perform classification. On the other hand, generative classifiers often learn a joint probability model and then use the Bayes rule to construct a posterior classifier. In general, generative classifiers are not as accurate as discriminative classifiers. However generative classifiers provide a principled way to deal with the missing information problem, which discriminative classifiers cannot easily handle. To achieve good performance in various classification tasks, it is better to combine these two strategies. In this paper, we develop a method to train one of the popular generative classifiers, the Naive Bayesian classifier (NB) in a discriminative way. We name this new model as the Discriminative Naive Bayesian classifier. We provide theoretic justifications, outline the algorithm, and perform a serious of experiments on benchmark real-world datasets to demonstrate our model\u2019s advantages. Its performance outperforms NB in classification tasks and outperforms SVM in handling missing information tasks. I.", "num_citations": "2\n", "authors": ["1175"]}
{"title": "Dialogue summarization with supporting utterance flow modelling and fact regularization\n", "abstract": " Dialogue summarization aims to generate a summary that indicates the key points of a given dialogue. In this work, we propose an end-to-end neural model for dialogue summarization with two novel modules, namely, the supporting utterance flow modelling module and the fact regularization module. The supporting utterance flow modelling helps to generate a coherent summary by smoothly shifting the focus from the former utterances to the later ones. The fact regularization encourages the generated summary to be factually consistent with the ground-truth summary during model training, which helps to improve the factual correctness of the generated summary in inference time. Furthermore, we also introduce a new benchmark dataset for dialogue summarization. Extensive experiments on both existing and newly-introduced datasets demonstrate the effectiveness of our model.", "num_citations": "1\n", "authors": ["1175"]}
{"title": "Towards efficient post-training quantization of pre-trained language models\n", "abstract": " Network quantization has gained increasing attention with the rapid growth of large pre-trained language models~(PLMs). However, most existing quantization methods for PLMs follow quantization-aware training~(QAT) that requires end-to-end training with full access to the entire dataset. Therefore, they suffer from slow training, large memory overhead, and data security issues. In this paper, we study post-training quantization~(PTQ) of PLMs, and propose module-wise quantization error minimization~(MREM), an efficient solution to mitigate these issues. By partitioning the PLM into multiple modules, we minimize the reconstruction error incurred by quantization for each module. In addition, we design a new model parallel training strategy such that each module can be trained locally on separate computing devices without waiting for preceding modules, which brings nearly the theoretical training speed-up (e.g.,  on  GPUs). Experiments on GLUE and SQuAD benchmarks show that our proposed PTQ solution not only performs close to QAT, but also enjoys significant reductions in training time, memory overhead, and data consumption.", "num_citations": "1\n", "authors": ["1175"]}
{"title": "A condense-then-select strategy for text summarization\n", "abstract": " Select-then-compress is a popular hybrid, framework for text summarization due to its high efficiency. This framework first selects salient sentences and then independently condenses each of the selected sentences into a concise version. However, compressing sentences separately ignores the context information of the document, and is therefore prone to delete salient information. To address this limitation, we propose a novel condense-then-select framework for text summarization. Our framework first concurrently condenses each document sentence. Original document sentences and their compressed versions then become the candidates for extraction. Finally, an extractor utilizes the context information of the document to select candidates and assembles them into a summary. If salient information is deleted during condensing, the extractor can select an original sentence to retain the information. Thus, our\u00a0\u2026", "num_citations": "1\n", "authors": ["1175"]}
{"title": "Learning by Distillation: A Self-Supervised Learning Framework for Optical Flow Estimation\n", "abstract": " We present DistillFlow, a knowledge distillation approach to learning optical flow. DistillFlow trains multiple teacher models and a student model, where challenging transformations are applied to the input of the student model to generate hallucinated occlusions as well as less confident predictions. Then, a self-supervised learning framework is constructed: confident predictions from teacher models are served as annotations to guide the student model to learn optical flow for those less confident predictions. The self-supervised learning framework enables us to effectively learn optical flow from unlabeled data, not only for non-occluded pixels, but also for occluded pixels. DistillFlow achieves state-of-the-art unsupervised learning performance on both KITTI and Sintel datasets. Our self-supervised pre-trained model also provides an excellent initialization for supervised fine-tuning, suggesting an alternate training\u00a0\u2026", "num_citations": "1\n", "authors": ["1175"]}
{"title": "Crisis resilience pedagogy (CRP) for teaching and learning\n", "abstract": " Schools and universities face unprecedented challenges in times of crisis. Traditional teaching and learning approaches become inadequate in knowledge transmission when face-to-face teaching is unavailable. In this paper, we explore the use of resilience pedagogy in times of crisis. First, we propose Crisis Resilience Pedagogy (CRP) by analyzing key attributes of resilience and how they can be incorporated into education. Second, we discuss how CRP can be widely adopted with reference to the diffusion theory of innovation. Third, we explore how CRP can be applied and incorporated as part of the education system. CRP brings flexibility to the current education system and ensures students learn effectively in times of crisis.", "num_citations": "1\n", "authors": ["1175"]}
{"title": "A Literature Review of Recent Graph Embedding Techniques for Biomedical Data\n", "abstract": " With the rapid development of biomedical software and hardware, a large amount of relational data interlinking genes, proteins, chemical components, drugs, diseases, and symptoms has been collected for modern biomedical research. Many graph-based learning methods have been proposed to analyze such type of data, giving a deeper insight into the topology and knowledge behind the biomedical data. However, the main difficulty is how to handle high dimensionality and sparsity of the data. Recently, graph embedding methods provide an effective and efficient way to address the above issues. It converts graph-based data into a low dimensional vector space where the graph structural properties and knowledge information are well preserved. In this paper, we conduct a literature review of recent graph embedding techniques for biomedical data. We also introduce important applications and tasks in\u00a0\u2026", "num_citations": "1\n", "authors": ["1175"]}
{"title": "Learning 3D Face Reconstruction with a Pose Guidance Network\n", "abstract": " We present a self-supervised learning approach to learning monocular 3D face reconstruction with a pose guidance network (PGN). First, we unveil the bottleneck of pose estimation in prior parametric 3D face learning methods, and propose to utilize 3D face landmarks for estimating pose parameters. With our specially designed PGN, our model can learn from both faces with fully labeled 3D landmarks and unlimited unlabeled in-the-wild face images. Our network is further augmented with a self-supervised learning scheme, which exploits face geometry information embedded in multiple frames of the same person, to alleviate the ill-posed nature of regressing 3D face geometry from a single image. These three insights yield a single approach that combines the complementary strengths of parametric model learning and data-driven learning techniques. We conduct a rigorous evaluation on the challenging AFLW2000-3D, Florence and FaceWarehouse datasets, and show that our method outperforms the state-of-the-art for all metrics.", "num_citations": "1\n", "authors": ["1175"]}
{"title": "Effective Data-Aware Covariance Estimator From Compressed Data\n", "abstract": " Estimating covariance matrix from massive high-dimensional and distributed data is significant for various real-world applications. In this paper, we propose a data-aware weighted sampling-based covariance matrix estimator, namely DACE, which can provide an unbiased covariance matrix estimation and attain more accurate estimation under the same compression ratio. Moreover, we extend our proposed DACE to tackle multiclass classification problems with theoretical justification and conduct extensive experiments on both synthetic and real-world data sets to demonstrate the superior performance of our DACE.", "num_citations": "1\n", "authors": ["1175"]}
{"title": "Regularizing the loss layer of CNNs for facial expression recognition using crowdsourced labels\n", "abstract": " Deep, convolutional neural networks have become the state-of-the-art method for automatic Facial Expression Recognition (FER). Because of the small size and controlled conditions of most FER datasets, however, models can still overfit to the training dataset and struggle to generalize well to new data. We present a novel approach of using crowdsourced label distributions for improving the generalization performance of convolutional neural networks for FER. We implement this as a loss layer regularizer, where the ground truth labels are combined with crowdsourced labels in order to construct a noisy output distribution during training. We use a label disturbance method in which training examples are randomly replaced with incorrect labels drawn from the combined label probability distribution. We compare the performance of our disturbed and undisturbed models in cross-validation testing on the extended\u00a0\u2026", "num_citations": "1\n", "authors": ["1175"]}
{"title": "An online-updating approach on task recommendation in crowdsourcing systems\n", "abstract": " In crowdsourcing systems, task recommendation can help workers to find their right tasks faster as well as help requesters to receive good quality output quicker. A number of previous works adopted active learning for task recommendation in crowdsourcing systems to achieve certain accuracy with a very low cost. However, the model updating methods in previous works are not suitable for real-world applications. In our paper, we propose a generic online-updating method for learning a factor analysis model, ActivePMF on TaskRec (Probabilistic Matrix Factorization with Active Learning on Task Recommendation Framework), for crowdsourcing systems. The larger the profile of a worker (or task) is, the less important is retraining its profile on each new work done. In case of the worker (or task) having large profile, our algorithm only retrains the whole feature vector of the worker (or task) and keeps all other\u00a0\u2026", "num_citations": "1\n", "authors": ["1175"]}
{"title": "Online non-negative dictionary learning via moment information for sparse poisson coding\n", "abstract": " Online dictionary learning for sparse coding is an effective tool for data analysis. It incrementally learns a set of basis vectors with sparse linear combinations of these vectors when new samples appear. Previous work assumes that the samples embed Gaussian noises, which weaken the power of these methods in handling real applications with non-negative data (e.g., frequency data in word counts). Differently, in this paper, we concentrate on online learning for non-negative dictionary by using moment information for sparse Poisson coding. We exploit the non-negativity of Poisson models to learn a set of non-negative basis vectors and a non-negative sparse linear combination for the moment information of samples. Specifically, we first formulate the online learning problem via the maximum-a-posteriori (MAP) framework. We then propose a novel online algorithm which alternatively updates the sparse\u00a0\u2026", "num_citations": "1\n", "authors": ["1175"]}
{"title": "A framework for describing multimedia circulation in a smartphone ecosystem\n", "abstract": " Contemporary mobile devices allow almost unrestricted sharing of multimedia and other types of files. However, because smartphones and tablets can easily access the Internet and exchange files wirelessly, they have also become useful tools for criminals who perform illegal activities such as sharing contraband and distributing illegal images. Thus, the need to investigate the source and destination of a multimedia file that resides in the internal memory of a smartphone is apparent. This chapter presents a framework for illustrating and visualizing the flow of digital images extracted from Android smartphones during a forensic investigation. The approach uses \u201cbig data\u201d concepts to facilitate the processing of diverse (semi-structured) evidence from mobile devices and extends the idea of digital evidence bags. The data used for evaluation was obtained by running experiments that involved image exchange\u00a0\u2026", "num_citations": "1\n", "authors": ["1175"]}
{"title": "Non-monotonic feature selection for regression\n", "abstract": " Feature selection is an important research problem in machine learning and data mining. It is usually constrained by the budget of the feature subset size in practical applications. When the budget changes, the ranks of features in the selected feature subsets may also change due to nonlinear cost functions for acquisition of features. This property is called non-monotonic feature selection. In this paper, we focus on non-monotonic selection of features for regression tasks and approximate the original combinatorial optimization problem by a Multiple Kernel Learning (MKL) problem and show the performance guarantee for the derived solution when compared to the global optimal solution for the combinatorial optimization problem. We conduct detailed experiments to demonstrate the effectiveness of the proposed method. The empirical results indicate the promising performance of the proposed framework\u00a0\u2026", "num_citations": "1\n", "authors": ["1175"]}
{"title": "Policy and Issues in Deploying Automated Plagiarism Detection Systems in Academic Communities\n", "abstract": " Plagiarism is becoming prevalent through the use of the Internet. Educational institutions are seeking technology to combat plagiarism. This chapter describes policy and issues encountered by an educational institution that deploys an automated plagiarism detection system. Background information of plagiarism and the benefits of using automated plagiarism detection systems are presented as motivation. A detailed account on the benefits of using automated plagiarism detection system in the academic setting is given. Associated policy issues (administrative issues, submission policy issues, disciplinary issues, copyright issues, security and privacy issues, and ethical issues) and resources needed to deploy such a system are discussed in details. VeriGuide, an automated plagiarism detection system designed and implemented at the Chinese University of Hong Kong, is presented as a case study on how the technology can be used to alleviate workload for the teachers and also provide a fair academic environment for the students. It is hoped that the case study would be helpful for those who are interested in using such a system to promote academic quality and integrity.", "num_citations": "1\n", "authors": ["1175"]}
{"title": "Social network analysis\n", "abstract": " Generate a set of biased PageRank vectors using a set of basis topics Cluster the Web page repository into a small number of clusters Utilize the hand constructed Open Directory Performed offline, during preprocessing of crawled data Let Tj be the set of URLs in the ODP category cj, we compute the damping vector p= vj where vji=", "num_citations": "1\n", "authors": ["1175"]}
{"title": "Advanced Data Mining and Applications: 7th International Conference, ADMA 2011, Beijing, China, December 17-19, 2011, Proceedings, Part I\n", "abstract": " The two-volume set LNAI 7120 and LNAI 7121 constitutes the refereed proceedings of the 7th International Conference on Advanced Data Mining and Applications, ADMA 2011, held in Beijing, China, in December 2011. The 35 revised full papers and 29 short papers presented together with 3 keynote speeches were carefully reviewed and selected from 191 submissions. The papers cover a wide range of topics presenting original research findings in data mining, spanning applications, algorithms, software and systems, and applied disciplines.", "num_citations": "1\n", "authors": ["1175"]}
{"title": "Graphical lasso quadratic discriminant function for character recognition\n", "abstract": " The quadratic discriminant function (QDF) derived from the multivariate Gaussian distribution is effective for classification in many pattern recognition tasks. In particular, a variant of QDF, called MQDF, has achieved great success and is widely recognized as the state-of-the-art method in character recognition. However, when the number of training samples is small, covariance estimation involved in QDF will usually be ill-posed, and it leads to the loss of the classification accuracy. To attack this problem, in this paper, we engage the graphical lasso method to estimate the covariance and propose a new classification method called the Graphical Lasso Quadratic Discriminant Function (GLQDF). By exploiting a coordinate descent procedure for the lasso, GLQDF can estimate the covariance matrix (and its inverse) more precisely. Experimental results demonstrate that the proposed method can perform better\u00a0\u2026", "num_citations": "1\n", "authors": ["1175"]}
{"title": "\u201cLike Attracts Like!\u201d\u2013A Social Recommendation Framework Through Label Propagation\n", "abstract": " Recently label propagation recommendation receives much attention from both industrial and academic fields due to its low requirement of labeled training data and effective prediction. Previous methods propagate preferences on a user or item similarity graph for making recommendation. However, they still suffer some major problems, including data sparsity, lack of trustworthiness, cold-start problem. By observation, the currently booming social network has some characteristics to remedy these problems.(1) Most of the user connections in either social network or real life can inflect information about users\u2019 interest similarity by \u201cLike Attracts Like\u201d, which can improve propagation graph construction.(2) Social connections can inflect trustworthiness information for user similarity, where connections are not built randomly but based on their trust.(3) Social network can provide user connection data as the supplementation of sparse ratings, which can also solve the cold-start problem when one new user has no rating history but social network. In order to improve the recommendation accuracy, we propose a social label propagation recommendation framework. In addition, we also construct the traditional user similarity graph for combination with social network to solve the noise and multi-interest problem in social network. Finally, we implement Green\u2019s function semi-supervised learning algorithm for label propagation recommendation on the real world recommendation data. The empirical results demonstrate the effectiveness of our proposed social recommendation framework.", "num_citations": "1\n", "authors": ["1175"]}
{"title": "Label ranking with semi-supervised learning\n", "abstract": " Label ranking is considered as an efficient approach for object recognition, document classification, recommendation task, which has been widely studied in recent years. It aims to learn a mapping from instances to a ranking list over a finite set of predefined labels. Traditional solutions for label rankings cannot obtain satisfactory results by only utilizing labeled data and ignore large amount of unlabeled data. This paper introduces a novel Semi-Supervised Learning (SSL) framework by exploiting unlabeled data to improve the performance. Under this framework, we also propose a new Information Gain Decision Tree (IGDT) with aims to make full use of latent information and as such raise the efficiency and accuracy. Then we outline our models involving another two algorithms, Instance Based Learning (IBL) and Mallows Model Decision Tree (MMDT) within this framework. Experiment results demonstrate our approaches can obtain a better performance comparing with only applying labeled data.", "num_citations": "1\n", "authors": ["1175"]}
{"title": "Site-to-Site (S2S) Searching with Query Routing Using Distributed Registrars\n", "abstract": " Site-To-Site (S2S) searching is a novel Web information retrieval method which uses peer-to-peer framework with CGI as protocol. It helps site owners to turn their websites into autonomous search engines without extra hardware and software costs. Thus, it improves some shortcomings of Conventional Search Engines (CSE) such as centralized and outdated indexing by distributing search engines over websites which maintain their updated local contents. However, it has query flooding problem. In this work, we extend S2S searching and propose our query routing algorithm to solve the query flooding problem by using distributed registrars for storing content summaries of adjacent sites. We also address some shortcomings of CSE and introduce S2S searching with some related work and comparisons. Moreover, we describe the system architecture and query routing algorithm. Finally, we summarize the experimental results and show that S2S searching works well in a large scaled S2S network.", "num_citations": "1\n", "authors": ["1175"]}
{"title": "An adaptive codebook design using the branching competitive learning network\n", "abstract": " This paper presents an adaptive scheme for codebook design by using a self-creating neural network, called branching competitive learning network. In our scheme, not only codevectors, but also codebook size are adaptively modified according to input image data and a distortion tolerance. In the situation that the input image is visually simple or the image data have a centralized distribution, our codebook design algorithm will assign a relatively small codebook; and for a complex image, our algorithm will give a relatively large codebook. Experimental results are given to illustrate the adaptability and effectiveness of our scheme.", "num_citations": "1\n", "authors": ["1175"]}
{"title": "Chinese cursive script character image retrieval based on an integrated probability function\n", "abstract": " Often in content-based image retrieval, a single image at- tribute may not have enough discriminative information for retrieval. On the other hand, when multiple features are used, it is hard to determine the suitable weighting factors for various features for optimal retrieval. In this paper, we present an idea of integrated probability function and use it to combine features for Chinese cursive script character image retrieval. A database of 1400 monochromatic images is used. Experimental results show that the proposed system based on Legendre moment feature, Zernike moment feature, and pseudo Zernike moment feature is robust to retrieval deformed images. Using our integrated probability function, ninety-nine percent of the targets are ranked at the top 2 positions.", "num_citations": "1\n", "authors": ["1175"]}
{"title": "Generating complementary gray-level images for object recognition experiments using Gabor wavelet decomposition\n", "abstract": " We present a software image processing methodology to generate complementary gray-scale images for visual perception experiments examining the interaction between the spatial localization and orientation sensitivity of visual perception. Specifically, our system is able to selectively mask or unmask specific resolutions, positions, and/or orientations of an input gray-level image using Gabor wavelet decomposition. The resulting representations are then combined to obtain partially reconstructed images for novel psychophysical experimentations.", "num_citations": "1\n", "authors": ["1175"]}
{"title": "Using Natural Clusters Information to Build Fuzzy Indexing Structure\n", "abstract": " Efficient and accurate information retrieval is one of the main issues in multimedia databases. However, the key for this is how to build an efficient indexing structure. In this paper, we demonstrate how to use a fuzzy clustering algorithm, Sequential Fuzzy Competitive Clustering (SFCC), to get the natural clusters information from the data. Then use the information to build an efficient indexing structure, SFCC-binary tree (SFCC-b-tree). We will show in the experimental results that SFCC-b-tree performs better that VP-tree in most of the cases.1 introduction", "num_citations": "1\n", "authors": ["1175"]}