{"title": "An empirical study of investigating mobile applications development challenges\n", "abstract": " Context: mobile application development is rapidly evolving with substantial economic and scientific interest. One of the primary reasons for mobile application development failure is the increasing number of mobile platforms; some organizations endorse mobile application development before understanding the associated development challenges of each target platform. Objective: the objective of this paper is to identify the challenges of native, web, and hybrid mobile applications, which can undermine the successful development of such applications. Method: we adopted a two-phase research approach: at first, the challenges were identified via a systematic literature review (SLR); and then, the identified challenges were validated through conducting interviews with practitioners. Results: through both research approaches, we identified nine challenges vital to the success of mobile application development and\u00a0\u2026", "num_citations": "54\n", "authors": ["252"]}
{"title": "A survey on sentiment analysis of scientific citations\n", "abstract": " Sentiment analysis of scientific citations has received much attention in recent years because of the increased availability of scientific publications. Scholarly databases are valuable sources for publications and citation information where researchers can publish their ideas and results. Sentiment analysis of scientific citations aims to analyze the authors\u2019 sentiments within scientific citations. During the last decade, some review papers have been published in the field of sentiment analysis. Despite the growth in the size of scholarly databases and researchers\u2019 interests, no one as far as we know has carried out an in-depth survey in a specific area of sentiment analysis in scientific citations. This paper presents a comprehensive survey of sentiment analysis of scientific citations. In this review, the process of scientific citation sentiment analysis is introduced and recently proposed methods with the main\u00a0\u2026", "num_citations": "46\n", "authors": ["252"]}
{"title": "Requirements understanding: a challenge in global software development, industrial surveys in Kingdom of Saudi Arabia\n", "abstract": " In recent years, Global Software Development (GSD) increasingly spread across the globe due to benefits it provides like low cost, availability of resources and access to wider and cheap human resource market. However, it is evident from literature that software development teams face many challenges in this new overwhelming paradigm like culture difference, coordination, communication and loss of teamness and so on. Further, it is also evident that Requirements Engineering (RE) is the most complicated and sturdy phase of software development even in collocated, but increasing pace of GSD has made it more diverse and complicated. Consequently in such fashion, cross functional stakeholders must specify, analyze and manage requirements across diverse cultures, time zones and organizational boundaries; thereby Requirements Understanding (RU) is necessary. In this paper, the authors identified\u00a0\u2026", "num_citations": "27\n", "authors": ["252"]}
{"title": "A survey on mining stack overflow: question and answering (Q&A) community\n", "abstract": " PurposeSoftware developers extensively use stack overflow (SO) for knowledge sharing on software development. Thus, software engineering researchers have started mining the structured/unstructured data present in certain software repositories including the Q&A software developer community SO, with the aim to improve software development. The purpose of this paper is show that how academics/practitioners can get benefit from the valuable user-generated content shared on various online social networks, specifically from Q&A community SO for software development.Design/methodology/approachA comprehensive literature review was conducted and 166 research papers on SO were categorized about software development from the inception of SO till June 2016.FindingsMost of the studies revolve around a limited number of software development tasks; approximately 70 percent of the papers used\u00a0\u2026", "num_citations": "25\n", "authors": ["252"]}
{"title": "The importance of knowledge management practices in overcoming the global software engineering challenges in requirements understanding\n", "abstract": " Going offshore has become a norm in current software organizations due to several benefits like availability of competent people, cost, proximity to market and customers, time and so on. Despite the fact that Global Software Engineering (GSE) offers many benefits to software organizations but it has also created several challenges/issues for practitioners and researchers like culture, communication, co-ordination and collaboration, team building and so on.As Requirements Engineering (RE) is more human intensive activity and is one of the most challenging and important phase in software development. Therefore, RE becomes even more challenging when comes to GSE context because of culture, communication, coordination, collaboration and so on. Due to the fore mentioned GSE factors, requirements\u2019 understanding has become a challenge for software organizations involved in GSE. Furthermore, Knowledge Management (KM) is considered to be the most important asset of an organization because it not only enables organizations to efficiently share and create knowledge but also helps in resolving culture, communication and co-ordination issues especially in GSE.", "num_citations": "24\n", "authors": ["252"]}
{"title": "Requirements understanding in global software engineering: Industrial surveys\n", "abstract": " Going offshore has become a norm in current software organizations due to several benefits like availability of competent people, cost, proximity to market and customers, time and so on. Despite the fact that Global Software Engineering (GSE) offers many benefits to software organizations but it has also created several challenges/issues for practitioners and researchers like culture, communication, co-ordination and collaboration, team building and so on. Further, Requirements Engineering (RE) itself is a very complicated and human intensive activity but GSE had made it more complicated and diverse. Therefore, people working in offshore environment face challenges in Requirements Understanding (RU). In this paper, we identified different GSE challenges and its impact on RU. Furthermore, several industrial surveys have been conducted with the intent to get real environment industrial perceptions and opinions regarding the identified challenges and its impact on RU.", "num_citations": "18\n", "authors": ["252"]}
{"title": "News Recommendation Systems - Accomplishments, Challenges & Future Directions\n", "abstract": " News publishers have decreased disseminating news through conventional newspapers and have migrated to the use of digital means like websites and purpose-built mobile applications. It is observed that news recommendation systems can automatically process lengthy articles and identify similar articles for readers considering predefined criteria. The objectives of the current work are to identify and classify the challenges in news recommendation domain, to identify state-of-the-art approaches and classify on the application domain, to identify datasets used for evaluation and their sources, the evaluation approaches used and to highlight the challenges explicitly addressed. The literature is thoroughly studied over the time span of 2001-2019 and shortlisted 81 related studies, broadly classified into six categories and discussed. The analysis showed that 60% of news recommendation system adopted a hybrid\u00a0\u2026", "num_citations": "16\n", "authors": ["252"]}
{"title": "Underwater routing protocols: Analysis of link selection challenges\n", "abstract": " AIMS Electronics and Electrical Engineering, 4 (3): 234\u2013248. DOI: 10.3934/ElectrEng. 2020.3. 234 Received: 10 April 2020 Accepted: 08 June 2020 Published: 19 June 2020 http://www. aimspress. com/journal/ElectrEng", "num_citations": "14\n", "authors": ["252"]}
{"title": "Knowledge management: a solution to requirements understanding in global software engineering\n", "abstract": " The aim of the study is to identify useful Knowledge Management (KM) practices/tools in order to overcome Requirements Understanding (RU) challenges in Global Software Engineering (GSE). As Requirements Engineering (RE) is considered one of the most crucial, human intensive and challenging phase of software engineering. A paradigm shift from traditional co-located to offshore development has introduced additional complications in RE specifically in RU. Issues in GSE like involvement of people from diverse culture, different inter-personal communication and coordination skills leads to RU problems. For this, the need of proper practices/tools to overcome RU challenges in global setting is obvious from literature. So, this study focuses on two things. Firstly, in this study authors have mentioned major RU challenges in GSE which were identified in author's pervious study. Secondly, authors have identified\u00a0\u2026", "num_citations": "13\n", "authors": ["252"]}
{"title": "A Systematic Review on Cloud Storage Mechanisms Concerning e-Healthcare Systems\n", "abstract": " As the expenses of medical care administrations rise and medical services experts are becoming rare, it is up to medical services organizations and institutes to consider the implementation of medical Health Information Technology (HIT) innovation frameworks. HIT permits health associations to smooth out their considerable cycles and offer types of assistance in a more productive and financially savvy way. With the rise of Cloud Storage Computing (CSC), an enormous number of associations and undertakings have moved their healthcare data sources to distributed storage. As the information can be mentioned whenever universally, the accessibility of information becomes an urgent need. Nonetheless, outages in cloud storage essentially influence the accessibility level. Like the other basic variables of cloud storage (eg, reliability quality, performance, security, and protection), availability also directly impacts the data in cloud storage for e-Healthcare systems. In this paper, we systematically review cloud storage mechanisms concerning the healthcare environment. Additionally, in this paper, the state-of-the-art cloud storage mechanisms are critically reviewed for e-Healthcare systems based on their characteristics. In short, this paper summarizes existing literature based on cloud storage and its impact on healthcare, and it likewise helps researchers, medical specialists, and organizations with a solid foundation for future studies in the healthcare environment. View Full-Text", "num_citations": "9\n", "authors": ["252"]}
{"title": "Biomedical Relation Extraction Using Distant Supervision\n", "abstract": " With the accelerating growth of big data, especially in the healthcare area, information extraction is more needed currently than ever, for it can convey unstructured information into an easily interpretable structured data. Relation extraction is the second of the two important tasks of relation extraction. This study presents an overview of relation extraction using distant supervision, providing a generalized architecture of this task based on the state-of-the-art work that proposed this method. Besides, it surveys the methods used in the literature targeting this topic with a description of different knowledge bases used in the process along with the corpora, which can be helpful for beginner practitioners seeking knowledge on this subject. Moreover, the limitations of the proposed approaches and future challenges were highlighted, and possible solutions were proposed.", "num_citations": "9\n", "authors": ["252"]}
{"title": "Toward Empirically Investigating Non-Functional Requirements of iOS Developers on Stack Overflow\n", "abstract": " Context: Mobile application developers are getting more concerned due to the importance of quality requirements or non-functional requirements (NFR) in software quality. Developers around the globe are actively asking a question(s) and sharing solutions to the problems related to software development on Stack Overflow (SO). The knowledge shared by developers on SO contains useful information related to software development such as feature requests (functional/non-functional), code snippets, reporting bugs or sentiments. Extracting the NFRs shared by iOS developers on programming Q&A website SO has become a challenge and a less researched area. Objective: To identify and understand the real problems, needs, trends, and the critical NFRs or quality requirements discussed on Stack Overflow related to iOS mobile application development. Method: We extracted and used only the iOS posts data of\u00a0\u2026", "num_citations": "9\n", "authors": ["252"]}
{"title": "Underwater Pragmatic Routing Approach through Packet Reverberation Mechanism\n", "abstract": " The advances in underwater sensor communication has become imperative getting up-to-date information about underwater happenings, especially when world has already faced the calamity like Tsunami. The underwater environment possessed freak and unpredictable movements which becomes more harsh time to time. The sensor nodes deployed under such juncture are the main source of information which in fact, facing numerous challenges. These nodes are mainly energy-constrained and rely on limited battery source. Due to most intricated underwater routing architecture, the biggest detriment is the limited battery lifespan. Therefore, it is imperative to adopt the pragmatic and possible alternate to improve the life expectancy of these sensor nodes. The solution of such shortcomings and identifying the varieties of impingements impelled by forwarding node on battery lifespan during packet transmission course are\u00a0\u2026", "num_citations": "8\n", "authors": ["252"]}
{"title": "Challenges of mobile applications development: Initial results\n", "abstract": " Mobile application development is rapidly evolving with prodigious economic and scientific interest. One of the major reasons for mobile application development failure is the increasing number of mobile platforms; a number of organizations endorse mobile application development prior to understanding the associated development challenges of each target platform. The objective of this paper is to identify the challenges of native, web and hybrid mobile applications, which can undermine the successful development of such applications. We have performed Systematic Literature Review (SLR) by applying customized search strings derived from our research question. We have identified challenges such as fragmentation, testing, compatibility, and performance etc. as key challenges in mobile application development. Our ultimate aim is to develop a framework in order to enable organizations to develop mobile\u00a0\u2026", "num_citations": "8\n", "authors": ["252"]}
{"title": "Energy Harvested and Cooperative Enabled Efficient Routing Protocol (EHCRP) for IoT-WBAN\n", "abstract": " The health industry is one of the most auspicious domains for the application of Internet of Things (IoT) based technologies. Lots of studies have been carried out in the health industry field to minimize the use of resources and increase the efficiency. The use of IoT combined with other technologies has brought quality advancement in the health sector at minimum expense. One such technology is the use of wireless body area networks (WBANs), which will help patients incredibly in the future and will make them more productive because there will be no need for staying at home or a hospital for a long time. WBANs and IoT have an integrated future as WBANs, like any IoT application, are a collection of heterogeneous sensor-based devices. For the better amalgamation of the IoT and WBANs, several hindrances blocking their integration need to be addressed. One such problem is the efficient routing of data in limited resource sensor nodes (SNs) in WBANs. To solve this and other problems, such as transmission of duplicate sensed data, limited network lifetime, etc., energy harvested and cooperative-enabled efficient routing protocol (EHCRP) for IoT-WBANs is proposed. The proposed protocol considers multiple parameters of WBANs for efficient routing such as residual energy of SNs, number of hops towards the sink, node congestion levels, signal-to-noise ratio (SNR) and available network bandwidth. A path cost estimation function is calculated to select forwarder node using these parameters. Due to the efficient use of the path-cost estimation process, the proposed mechanism achieves efficient and effective multi-hop routing of data and\u00a0\u2026", "num_citations": "6\n", "authors": ["252"]}
{"title": "A Systematic Literature Review on Using Machine Learning Algorithms for Software Requirements Identification on Stack Overflow\n", "abstract": " Context. The improvements made in the last couple of decades in the requirements engineering (RE) processes and methods have witnessed a rapid rise in effectively using diverse machine learning (ML) techniques to resolve several multifaceted RE issues. One such challenging issue is the effective identification and classification of the software requirements on Stack Overflow (SO) for building quality systems. The appropriateness of ML-based techniques to tackle this issue has revealed quite substantial results, much effective than those produced by the usual available natural language processing (NLP) techniques. Nonetheless, a complete, systematic, and detailed comprehension of these ML based techniques is considerably scarce. Objective. To identify or recognize and classify the kinds of ML algorithms used for software requirements identification primarily on SO. Method. This paper reports a systematic literature review (SLR) collecting empirical evidence published up to May 2020. Results. This SLR study found 2,484 published papers related to RE and SO. The data extraction process of the SLR showed that (1) Latent Dirichlet Allocation (LDA) topic modeling is among the widely used ML algorithm in the selected studies and (2) precision and recall are amongst the most commonly utilized evaluation methods for measuring the performance of these ML algorithms. Conclusion. Our SLR study revealed that while ML algorithms have phenomenal capabilities of identifying the software requirements on SO, they still are confronted with various open problems/issues that will eventually limit their practical applications and performances\u00a0\u2026", "num_citations": "6\n", "authors": ["252"]}
{"title": "QuPiD Attack: Machine Learning-Based Privacy Quantification Mechanism for PIR Protocols in Health-Related Web Search\n", "abstract": " With the advancement in ICT, web search engines have become a preferred source to find health-related information published over the Internet. Google alone receives more than one billion health-related queries on a daily basis. However, in order to provide the results most relevant to the user, WSEs maintain the users\u2019 profiles. These profiles may contain private and sensitive information such as the user\u2019s health condition, disease status, and others. Health-related queries contain privacy-sensitive information that may infringe user\u2019s privacy, as the identity of a user is exposed and may be misused by the WSE and third parties. This raises serious concerns since the identity of a user is exposed and may be misused by third parties. One well-known solution to preserve privacy involves issuing the queries via peer-to-peer private information retrieval protocol, such as useless user profile (UUP), thereby hiding the user\u2019s identity from the WSE. This paper investigates the level of protection offered by UUP. For this purpose, we present QuPiD (query profile distance) attack: a machine learning-based attack that evaluates the effectiveness of UUP in privacy protection. QuPiD attack determines the distance between the user\u2019s profile (web search history) and upcoming query using our proposed novel feature vector. The experiments were conducted using ten classification algorithms belonging to the tree-based, rule-based, lazy learner, metaheuristic, and Bayesian families for the sake of comparison. Furthermore, two subsets of an America Online dataset (noisy and clean datasets) were used for experimentation. The results show that the proposed\u00a0\u2026", "num_citations": "6\n", "authors": ["252"]}
{"title": "ABioNER: a BERT-based model for Arabic biomedical named-entity recognition\n", "abstract": " The web is being loaded daily with a huge volume of data, mainly unstructured textual data, which increases the need for information extraction and NLP systems significantly. Named-entity recognition task is a key step towards efficiently understanding text data and saving time and effort. Being a widely used language globally, English is taking over most of the research conducted in this field, especially in the biomedical domain. Unlike other languages, Arabic suffers from lack of resources. This work presents a BERT-based model to identify biomedical named entities in the Arabic text data (specifically disease and treatment named entities) that investigates the effectiveness of pretraining a monolingual BERT model with a small-scale biomedical dataset on enhancing the model understanding of Arabic biomedical text. The model performance was compared with two state-of-the-art models (namely, AraBERT and multilingual BERT cased), and it outperformed both models with 85% F1-score.", "num_citations": "5\n", "authors": ["252"]}
{"title": "Fetal Heart Rate Classification and Comparative Analysis Using Cardiotocography Data and Known Classifiers\n", "abstract": " The problem of fetal distress usually become one of the major reason of complication during child delivery. Fetal heart rate (FHR) is one of the pivotal ways to identify the occurrence of fetal distress. Cardiotocography (CTG) is the most widely practiced technique to record FHR. Improper analysis of CTG\u2019s graph may lead to serious loss. This study presents six classification algorithms: Decision Tree (DT), K-Nearest Neighbors (KNN), Logistic Regression (LR), Support Vector Machine (SVM), Random Forest (RF) and Na\u00efve Bayes (NB), used for the classification of CTG data. To improve the performance of the classifiers, a corelation based feature selection technique is employed over the dataset to remove the unnecessary attributes. The performance of the classification algorithms is evaluated using evaluation metrics: Accuracy, Precision, Recall, and F-measure. The results revealed that Na\u00efve Bayes achieved 83.06% accuracy, 92.20% precision, 83.10% recall and 86.90% f-measure.", "num_citations": "5\n", "authors": ["252"]}
{"title": "An efficient skewed line segmentation technique for cursive script OCR\n", "abstract": " Segmentation of cursive text remains the challenging phase in the recognition of text. In OCR systems, the recognition accuracy of text is directly dependent on the quality of segmentation. In cursive text OCR systems, the segmentation of handwritten Urdu language text is a complex task because of the context sensitivity and diagonality of the text. This paper presents a line segmentation algorithm for Urdu handwritten and printed text and subsequently to ligatures. In the proposed technique, the counting pixel approach is employed for modified header and baseline detection, in which the system first removes the skewness of the text page, and then the page is converted into lines and ligatures. The algorithm is evaluated on manually generated Urdu printed and handwritten dataset. The proposed algorithm is tested separately on handwritten and printed text, showing 96.7% and 98.3% line accuracy, respectively. Furthermore, the proposed line segmentation algorithm correctly extracts the lines when tested on Arabic text.", "num_citations": "4\n", "authors": ["252"]}
{"title": "A review on data preprocessing methods for class imbalance problem\n", "abstract": " Data mining methods are often impaired by datasets with desperate nature. Such real-world datasets contain imbalanced data distri-butions among classes, which affects the learning process negatively. In this scenario, the number of samples pertaining to one class (majority class) surpasses adequately the number of samples of other class (minority class)\u2013resulting in ignorance of the minority class by classification methods. To address this, various useful approaches related to data preprocessing are considered mandatory for developing an effective model by using contemporary data mining algorithms. Oversampling and undersampling are two of the fundamental approaches for preprocessing data in order to balance the distribution among dataset. In this study, we thoroughly discuss about the preprocessing techniques and approaches, as well as, challenges faced by researchers to overcome the weaknesses of resampling techniques. This paper highlights the basic issues of classifiers, which endorse bias for majority class and ignore the minority class. Additionally, we synthesize viable solutions and potential suggestions on how to handle the problems in prepro-cessing of data effectively, also present open issues that call for further research.", "num_citations": "4\n", "authors": ["252"]}
{"title": "An Empirical Study on How iOS Developers Report Quality Aspects on Stack Overflow\n", "abstract": " \uf020 Abstract\u2014Software developers around the globe are actively asking a question (s) and sharing solutions to the problems related to software development on Stack Overflow-a social question and answer (Q&A) website. The knowledge shared by software developers on Stack Overflow contains useful information related to software development such as feature requests (functional/non-functional), code snippets, reporting bugs or sentiments. How to extract the functional and nonfunctional requirements shared by mobile application developers on social/programming Q&A website Stack Overflow has become a challenge and a less researched area. To understand the problems, needs, and trend in the iOS mobile application development, we evaluated the quality requirements or non-functional requirements (NFRs) on Stack Overflow posts. To this end, we applied Latent Dirichlet Allocation (LDA) topic models, to identify the main topics in iOS posts on Stack Overflow. Besides, we labeled the extracted topics with quality requirements or NFRs by using the wordlists to evaluate the trend, evolution, hot and unresolved NFRS in all iOS discussions. Our findings revealed that the highly frequent topics the iOS developers discussed are related to usability, reliability, and functionality followed by efficiency. Interestingly, the most problematic areas unresolved are also usability, reliability, and functionality though followed by portability. Besides, the evolution trend of each of the six different quality requirements or NFRs over time is depicted through comprehensive visualization.", "num_citations": "4\n", "authors": ["252"]}
{"title": "Fusion of machine learning and privacy preserving for secure facial expression recognition\n", "abstract": " The interest in Facial Expression Recognition (FER) is increasing day by day due to its practical and potential applications, such as human physiological interaction diagnosis and mental disease detection. This area has received much attention from the research community in recent years and achieved remarkable results; however, a significant improvement is required in spatial problems. This research work presents a novel framework and proposes an effective and robust solution for FER under an unconstrained environment; it also helps us to classify facial images in the client/server model along with preserving privacy. There are a lot of cryptography techniques available but they are computationally expensive; on the other side, we have implemented a lightweight method capable of ensuring secure communication with the help of randomization. Initially, we perform preprocessing techniques to encounter the unconstrained environment. Face detection is performed for the removal of excessive background and it detects the face in the real-world environment. Data augmentation is for the insufficient data regime. A dual-enhanced capsule network is used to handle the spatial problem. The traditional capsule networks are unable to sufficiently extract the features, as the distance varies greatly between facial features. Therefore, the proposed network is capable of spatial transformation due to the action unit aware mechanism and thus forwards the most desiring features for dynamic routing between capsules. The squashing function is used for classification purposes. Simple classification is performed through a single party, whereas we also\u00a0\u2026", "num_citations": "3\n", "authors": ["252"]}
{"title": "USAD: an intelligent system for slang and abusive text detection in PERSO-Arabic-scripted Urdu\n", "abstract": " The use of slang, abusive, and offensive language has become common practice on social media. Even though social media companies have censorship polices for slang, abusive, vulgar, and offensive language, due to limited resources and research in the automatic detection of abusive language mechanisms other than English, this condemnable act is still practiced. This study proposes USAD (Urdu Slang and Abusive words Detection), a lexicon-based intelligent framework to detect abusive and slang words in Perso-Arabic-scripted Urdu Tweets. Furthermore, due to the nonavailability of the standard dataset, we also design and annotate a dataset of abusive, offensive, and slang word Perso-Arabic-scripted Urdu as our second significant contribution for future research. The results show that our proposed USAD model can identify 72.6% correctly as abusive or nonabusive Tweet. Additionally, we have also identified some key factors that can help the researchers improve their abusive language detection models.", "num_citations": "3\n", "authors": ["252"]}
{"title": "Bodacious-instance coverage mechanism for wireless sensor network\n", "abstract": " Due to unavoidable environmental factors, wireless sensor networks are facing numerous tribulations regarding network coverage. These arose due to the uncouth deployment of the sensor nodes in the wireless coverage area that ultimately degrades the performance and confines the coverage range. In order to enhance the network coverage range, an instance (node) redeployment-based Bodacious-instance Coverage Mechanism (BiCM) is proposed. The proposed mechanism creates new instance positions in the coverage area. It operates in two stages; in the first stage, it locates the intended instance position through the Dissimilitude Enhancement Scheme (DES) and moves the instance to a new position, while the second stage is called the depuration, when the moving distance between the initial and intended instance positions is sagaciously reduced. Further, the variations of various parameters of BiCM such as loudness, pulse emission rate, maximum frequency, grid points, and sensing radius have been explored, and the optimized parameters are identified. The performance metric has been meticulously analyzed through simulation results and is compared with the state-of-the-art Fruit Fly Optimization Algorithm (FOA) and, one step above, the tuned BiCM algorithm in terms of mean coverage rate, computation time, and standard deviation. The coverage range curve for various numbers of iterations and sensor nodes is also presented for the tuned Bodacious-instance Coverage Mechanism (tuned BiCM), BiCM, and FOA. The performance metrics generated by the simulation have vouched for the effectiveness of tuned BiCM as it\u00a0\u2026", "num_citations": "3\n", "authors": ["252"]}
{"title": "Towards an Improved Energy Efficient and End-to-End Secure Protocol for IoT Health Care Applications\n", "abstract": " In this paper, we proposed LCX-MAC (local coordination X-MAC) as an extension of X-MAC. X-MAC is an asynchronous duty cycle medium access control (MAC) protocol. X-MAC used one important technique of short preamble which is to allow sender nodes to quickly send their actual data when the corresponding receivers wake up. X-MAC node keeps sending short preamble to wake up its receiver node, which causes energy, increases transmission delay, and makes the channel busy since a lot of short preambles are discarded, as these days Internet of Things (IoT) healthcare with different sensor nodes for the healthcare is time-critical applications and needs a quick response. A possible improvement over X-MAC is that local information of each node will share with its neighbour node. This local information exchanged will cause much less overhead than in the nodes which are synchronized. To calculate the effect of this the local coordination on X-MAC in this paper, we built an analytical model of LCX-MAC that incorporates the local coordination in X-MAC. The analytical results show that LCX-MAC outperformed X-MAC and X-MAC/BEB in terms of throughput, delay, and energy.", "num_citations": "3\n", "authors": ["252"]}
{"title": "Predicting Politician\u2019s Supporters\u2019 Network on Twitter Using Social Network Analysis and Semantic Analysis\n", "abstract": " Politics is one of the hottest and most commonly mentioned and viewed topics on social media networks nowadays. Microblogging platforms like Twitter and Weibo are widely used by many politicians who have a huge number of followers and supporters on those platforms. It is essential to study the supporters\u2019 network of political leaders because it can help in decision making when predicting their political futures. This study focuses on the supporters\u2019 network of three famous political leaders of Pakistan, namely, Imran Khan (IK), Maryam Nawaz Sharif (MNS), and Bilawal Bhutto Zardari (BBZ). This is done using social network analysis and semantic analysis. The proposed method (1) detects and removes fake supporter(s), (2) mines communities in the politicians\u2019 social network(s), (3) investigates the supporters\u2019 reply network for conversations between supporters about each leader, and, finally, (4) analyses the retweet network for information diffusion of each political leader. Furthermore, sentiment analysis of the supporters of politicians is done using machine learning techniques, which ultimately predicted and revealed the strongest supporter network(s) among the three political leaders. Analysis of this data reveals that as of October 2017 (1) IK was the most renowned of the three politicians and had the strongest supporter\u2019s community while using Twitter in a very controlled manner, (2) BBZ had the weakest supporters\u2019 network on Twitter, and (3) the supporters of the political leaders in Pakistan are flexible on Twitter, communicating with each other, and that any group of supporters has a low level of isolation.", "num_citations": "3\n", "authors": ["252"]}
{"title": "Towards Energy-Efficient Framework for IoT Big Data Healthcare Solutions\n", "abstract": " The aim of the Internet of things (IoT) is to bring every object (wearable sensors, healthcare sensors, cameras, home appliances, smart phones, etc.) online. These different objects generate huge data which consequently lead to the need of requirements of efficient storage and processing. Cloud computing is an emerging technology to overcome this problem. However, there are some applications (healthcare) which need to process data in real time to improve its performance and require low latency and delay. Fog computing is one of the promising solutions which facilitate healthcare domain in terms of reducing the delay multihop data communication, distributing resource demands, and promoting service flexibility. In this study, a fog-based IoT healthcare framework is proposed in order to minimize the energy consumption of the fog nodes. Experimental results reveal that the performance of the proposed framework is efficient in terms of network delay and energy usage. Furthermore, the authors discussed and suggested important services of big data infrastructure which need to be present in fog devices for the analytics of healthcare big data.", "num_citations": "3\n", "authors": ["252"]}
{"title": "Analyzing and evaluating critical challenges and practices for software vendor organizations to secure big data on cloud computing: an ahp-based systematic approach\n", "abstract": " Recently, its becomes easy to track down the data due to its availability in a large number. Although for data management, processing, and obtainability, cloud computing is considered a well-known approach for organizational development on the internet. Despite many advantages, cloud computing has still numerous security challenges that can affect the big-data usage on cloud computing. To find the security issues/challenges that are faced by software vendors\u2019 organizations we conducted a systematic literature review (SLR) through which we have find out 103 relevant research publications by developing a search string that is inspired by the research questions. This relevant data was comprised from different databases e.g. Google Scholar, IEEE Explore, ScienceDirect, ACM Digital Library, and SpringerLink. Furthermore, for the detailed literature review, we have accomplished all the steps in SLR, for\u00a0\u2026", "num_citations": "2\n", "authors": ["252"]}
{"title": "Empirical assessment of machine learning techniques for software requirements risk prediction\n", "abstract": " Software risk prediction is the most sensitive and crucial activity of Software Development Life Cycle (SDLC). It may lead to the success or failure of a project. The risk should be predicted earlier to make a software project successful. A model is proposed for the prediction of software requirement risks using requirement risk dataset and machine learning techniques. In addition, a comparison is made between multiple classifiers that are K-Nearest Neighbour (KNN), Average One Dependency Estimator (A1DE), Na\u00efve Bayes (NB), Composite Hypercube on Iterated Random Projection (CHIRP), Decision Table (DT), Decision Table/Na\u00efve Bayes Hybrid Classifier (DTNB), Credal Decision Trees (CDT), Cost-Sensitive Decision Forest (CS-Forest), J48 Decision Tree (J48), and Random Forest (RF) achieve the best suited technique for the model according to the nature of dataset. These techniques are evaluated using various evaluation metrics including CCI (correctly Classified Instances), Mean Absolute Error (MAE), Root Mean Square Error (RMSE), Relative Absolute Error (RAE), Root Relative Squared Error (RRSE), precision, recall, F-measure, Matthew\u2019s Correlation Coefficient (MCC), Receiver Operating Characteristic Area (ROC area), Precision-Recall Curves area (PRC area), and accuracy. The inclusive outcome of this study shows that in terms of reducing error rates, CDT outperforms other techniques achieving 0.013 for MAE, 0.089 for RMSE, 4.498% for RAE, and 23.741% for RRSE. However, in terms of increasing accuracy, DT, DTNB, and CDT achieve better results. View Full-Text", "num_citations": "2\n", "authors": ["252"]}
{"title": "Investigating tree family machine learning techniques for a predictive system to unveil software defects\n", "abstract": " Software defects prediction at the initial period of the software development life cycle remains a critical and important assignment. Defect prediction and correctness leads to the assurance of the quality of software systems and has remained integral to study in the previous years. The quick forecast of imperfect or defective modules in software development can serve the development squad to use the existing assets competently and effectively to provide remarkable software products in a given short timeline. Hitherto, several researchers have industrialized defect prediction models by utilizing statistical and machine learning techniques that are operative and effective approaches to pinpoint the defective modules. Tree family machine learning techniques are well-thought-out to be one of the finest and ordinarily used supervised learning methods. In this study, different tree family machine learning techniques are employed for software defect prediction using ten benchmark datasets. These techniques include Credal Decision Tree (CDT), Cost-Sensitive Decision Forest (CS-Forest), Decision Stump (DS), Forest by Penalizing Attributes (Forest-PA), Hoeffding Tree (HT), Decision Tree (J48), Logistic Model Tree (LMT), Random Forest (RF), Random Tree (RT), and REP-Tree (REP-T). Performance of each technique is evaluated using different measures, i.e., mean absolute error (MAE), relative absolute error (RAE), root mean squared error (RMSE), root relative squared error (RRSE), specificity, precision, recall, F-measure (FM), G-measure (GM), Matthew\u2019s correlation coefficient (MCC), and accuracy. The overall outcomes of this paper suggested RF\u00a0\u2026", "num_citations": "2\n", "authors": ["252"]}
{"title": "A Silver Standard Biomedical Corpus for Arabic Language\n", "abstract": " The rapidly growing data in many areas, as well as in the biomedical domain, require the assistance of information extraction systems to acquire the much needed knowledge about specific entities such as proteins, drugs, or diseases practically within a short time. Annotated corpora serve the purpose of facilitating the process of building NLP systems. While colossal work has been done in this area for English language, other languages like Arabic seem to lack these resources, especially in the healthcare area. Therefore, in this work, we present a method to develop a silver standard medical corpus for the Arabic language with a dictionary as a minimal supervision tool. The corpus contains 49,856 sentences tagged with 13 entity types corresponding to a subset of UMLS (Unified Medical Language System) concept types. The evaluation of a subset of corpus showed the efficiency of the method used to annotate it with 90% accuracy.", "num_citations": "2\n", "authors": ["252"]}
{"title": "A Content-based Technique for Linking Dual Language News Articles in an Archive\n", "abstract": " To retrieve a specific news article from a vast archive containing multilingual news articles against a user query or based on similarity among news articles is a challenging task. The task becomes even further complicated when the archive contains articles from a low resourced and morphologically complex language like Urdu, along with English new articles. The article proposes a content-based (lexical) similarity measure, that is, Common Ratio Measure for Dual Language (CRMDL), for linking digital news articles published in various online news sources. The similarity measure links Urdu-to-English news articles during the preservation process using an Urdu-to-English lexicon. A literature review showed that an Urdu-to-English lexicon did not exist, and therefore, the first task was to build a lexicon from multiple sources. The proposed similarity measure, that is, CRMDL, is evaluated rigorously on different data\u00a0\u2026", "num_citations": "2\n", "authors": ["252"]}
{"title": "Enhanced Bat Algorithm for Solving Non-Convex Economic Dispatch Problem\n", "abstract": " Bat algorithm lags behind other modern metaheuristic algorithms in terms of search efficiency, due to premature convergence. Once trapped in any sub-optimal region, the algorithm is unable to escape because of deficiency in population diversity. To address this, an enhanced Bat Algorithm (EBA) is introduced in this paper. The EBA algorithm comes with adaptive exploration and exploitation capability, as well as, additional population diversity. This enables EBA improve its convergence ability to find even better solutions towards the end of search process, where standard BA is often trapped. To illustrate effectiveness of the proposed method, EBA is applied on non-linear, non-convex economic dispatch problem with a power generation system comprising of twenty thermal units. The experimental results suggest that EBA not only saved power generation cost but also reduced transmission losses, more efficiently\u00a0\u2026", "num_citations": "2\n", "authors": ["252"]}
{"title": "An Empirical Evaluation of Machine Learning Algorithms for Identifying Software Requirements on Stack Overflow: Initial Results\n", "abstract": " Context: The recent developments made during the last decade or two in requirements engineering (RE) methods have seen a rise in using different machine-learning (ML) algorithms to solve some complex RE problems. One such problem is identifying and classifying software requirements on Stack Overflow (SO). The suitability of ML-based techniques to this tackle problem has shown convincing results, much better than those generated by some traditional natural language processing (NLP) techniques. Nevertheless, a comprehensive and systematic comprehension of these ML based techniques is still deficient. Objective: To identify and classify the type of ML algorithms used for identifying software requirements on SO. Method: This article reports systematic literature review (SLR) gathering evidence published up to August, 2019. Results: This study identified 1073 published papers related to RE and SO\u00a0\u2026", "num_citations": "2\n", "authors": ["252"]}
{"title": "Evaluating and Enhancing the Robustness of Sustainable Neural Relationship Classifiers Using Query-Efficient Black-Box Adversarial Attacks\n", "abstract": " Neural relation extraction (NRE) models are the backbone of various machine learning tasks, including knowledge base enrichment, information extraction, and document summarization. Despite the vast popularity of these models, their vulnerabilities remain unknown; this is of high concern given their growing use in security-sensitive applications such as question answering and machine translation in the aspects of sustainability. In this study, we demonstrate that NRE models are inherently vulnerable to adversarially crafted text that contains imperceptible modifications of the original but can mislead the target NRE model. Specifically, we propose a novel sustainable term frequency-inverse document frequency (TFIDF) based black-box adversarial attack to evaluate the robustness of state-of-the-art CNN, CGN, LSTM, and BERT-based models on two benchmark RE datasets. Compared with white-box adversarial attacks, black-box attacks impose further constraints on the query budget; thus, efficient black-box attacks remain an open problem. By applying TFIDF to the correctly classified sentences of each class label in the test set, the proposed query-efficient method achieves a reduction of up to 70% in the number of queries to the target model for identifying important text items. Based on these items, we design both character-and word-level perturbations to generate adversarial examples. The proposed attack successfully reduces the accuracy of six representative models from an average F1 score of 80% to below 20%. The generated adversarial examples were evaluated by humans and are considered semantically similar. Moreover, we\u00a0\u2026", "num_citations": "1\n", "authors": ["252"]}
{"title": "The role of news title for linking during preservation process in digital archives\n", "abstract": " PurposeThe World Wide Web has become an essential platform for a news publication, and it has become one of the primary sources of information dissemination in the past few years. Electronic media, i.e., television channels, magazines and newspapers, have started publishing news online. This online information is prompt to be disappeared because of short life-span and imperative to be archived for the long-term and future generations. This paper presents a content-based similarity measure based on the headings of the news articles for linking digital news stories published in various newspapers during the preservation process that helps to ensure future accessibility.Design/methodology/approachTo evaluate the accuracy and assess the effectiveness and worth of the proposed measure for linking news articles in Digital News Story Archive (DNSA), we adopted both, system-centric and user-centric (human\u00a0\u2026", "num_citations": "1\n", "authors": ["252"]}
{"title": "Software Cost Estimation using Flower Pollination Algorithm\n", "abstract": " Software Development Organizations (SDO) develop a massive number of projects per year. One of the elementary and significant features of any SDO is to use a tool that can precisely estimate the software cost. It directly affects nearly all management activities including resource allocation, project planning, and project bidding. Imprecise estimation causes troubles eg dropping the worth of the project, waste the company\u2019s budgets and can outcome in the disaster of the project. During the last few decades\u2019 researchers have developed a large number of models for software cost estimation (SCE). However, SCE is still a challenging task. Algorithmic and non-algorithmic approaches were firstly used to achieve the goal. Each of them has their own merits and demerits but still, these are considered as primary tools for SCE. This study proposes Flower Pollination Algorithm (FPA) for SCE. Mean Magnitude of Relative Error (MMRE) is used as an evaluation metric for benchmarking the proposed model with the existing model. All the results of FPA are compared with the COCOMO model. Experimental results show a better performance of FPA as compare to COCOMO. Three datasets from NASA software projects are selected, NASA93, NASA63, and NASA60. On NASA93 dataset the improvement is 10.17%, on NASA63 the improvement is 77.38% and on NASA60 it is 22.96%.", "num_citations": "1\n", "authors": ["252"]}